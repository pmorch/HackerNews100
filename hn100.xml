<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 10 Dec 2025 16:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[In New York City, congestion pricing leads to marked drop in pollution (182 pts)]]></title>
            <link>https://e360.yale.edu/digest/new-york-congestion-pricing-pollution</link>
            <guid>46218725</guid>
            <pubDate>Wed, 10 Dec 2025 15:25:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://e360.yale.edu/digest/new-york-congestion-pricing-pollution">https://e360.yale.edu/digest/new-york-congestion-pricing-pollution</a>, See on <a href="https://news.ycombinator.com/item?id=46218725">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                  
<div>

  <figure>

    <div>
      
                  
      <p><a href="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1765283167&amp;s=0cbefdad5bd8aac05b696a3ccd664a41" data-caption="" data-credit="Pexels">
  
  
  
    
  
  
  
      
    
                
    
                
    
                
    
                
    
                        
  <img sizes="(min-width: 1450px) 832px, (min-width: 620px) 620px, 100vw" srcset="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1765283167&amp;s=0cbefdad5bd8aac05b696a3ccd664a41 1200w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=200&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=ce71b84136fe60ca9ab40e66fe6e62f0 200w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=514435a5842d6a703560bc3e8dcf8a84 400w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=600&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=6dec6ff9eef4bf5345d6ff07f9de00d5 600w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=800&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=6ec63769954ae19251cc99827541364e 800w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1000&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=22956faaf223e612682176b0f9ac41a9 1000w" src="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=514435a5842d6a703560bc3e8dcf8a84" alt="">
</a>
      </p>
          </div>

        <figcaption>
              <p><span></span>
          <span>Pexels</span></p>
    </figcaption>
    
  </figure>

</div> <!-- imageBlock -->
            

<div>
  <p>A new toll applied to cars driving in parts of New York City has led to a measurable drop in traffic, and with it, a 22 percent decline in particulate pollution, according to a new study.</p><p>Congestion pricing came into effect in January, with cars paying $9 to drive through busy parts of Manhattan during peak hours. In the first six months of the program, traffic in the congestion zone dropped by 11 percent, accidents by 14 percent, and complaints of excessive honking or other noise by 45 percent, <a href="https://www.cbsnews.com/newyork/news/congestion-pricing-first-6-months/">officials said</a>.&nbsp;</p><p>A new study from Cornell has now tallied the impact on particulate pollution. Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death.</p><p>Analyzing data on air quality, traffic, and weather conditions, researchers determined that in the first half of this year, particulate pollution was down 22 percent in parts of Manhattan affected by congestion pricing.&nbsp;</p><p>The decline seen in New York was greater than in other cities with congestion pricing, such as Stockholm and London, researchers note. And the effect extended beyond Lower Manhattan. Pricing led to a drop in pollution across the greater metropolitan area, according to the <a href="https://www.nature.com/articles/s44407-025-00037-2">study</a>, published in the journal <i>npj Clean Air.</i></p><p>“It’s really exciting to me that air quality improved throughout the entire metro area,” <a href="https://news.cornell.edu/stories/2025/12/congestion-pricing-improved-air-quality-nyc-and-suburbs">said lead author</a> Timothy Fraser, of Cornell University. “This tells us that congestion pricing didn’t simply relocate air pollution to the suburbs by rerouting traffic. Instead, folks are likely choosing cleaner transportation options altogether, like riding public transportation or scheduling deliveries at night. This thins traffic and limits how smog compounds when many cars are on the road.”</p><h2><strong>ALSO ON YALE E360</strong></h2><p><a href="https://e360.yale.edu/features/free-parking-reform"><i><strong>How Parking Reform Is Helping Transform American Cities</strong></i></a></p>
</div>
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Breaking TLS (134 pts)]]></title>
            <link>https://www.markround.com/blog/2025/12/09/stop-breaking-tls/</link>
            <guid>46214950</guid>
            <pubDate>Wed, 10 Dec 2025 07:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.markround.com/blog/2025/12/09/stop-breaking-tls/">https://www.markround.com/blog/2025/12/09/stop-breaking-tls/</a>, See on <a href="https://news.ycombinator.com/item?id=46214950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          


          
  <p><strong> Updated:</strong> <time datetime="2025-12-09T08:40:51+00:00">December 9, 2025</time></p>


        </header>
      

      <section itemprop="text">
        


        
        <p><a href="https://news.ycombinator.com/item?id=46214950">Discussion on Hacker News</a>  <a href="https://lobste.rs/s/h7a3xy/stop_breaking_tls">Discussion on lobste.rs</a></p>

<p>Rant ahead: I hate TLS “Inspection” software with a burning passion and I wish we collectively as an industry would just knock it the <em>fuck</em> off and stop pretending it’s some great security benefit. Every time I encounter it, in whatever form, it’s a gigantic headache that makes everyone’s life worse off and as far as I am concerned offers next to zero tangible benefits.</p>

<p>For those blissfully unaware, this is a class of “security” software or appliance that is supposed to let organisations monitor all encrypted traffic. It does this by inserting itself in the middle of traffic, stripping the encryption off so it can inspect it and then re-signing it with its own certificate. If that sounds familiar, it’s because it’s a widely known class of attack - the Man In The Middle attack. Great stuff, we’re literally deploying the exact attack vector that TLS was designed to prevent, but slapping a “security” label on it.</p>

<p>Firstly, it undermines one of the most important protocols of the modern Internet as it deliberately breaks all the guarantees that TLS encryption is supposed to offer. If the MITM certificate is installed everywhere, your company can intercept and monitor everything you say and do. Consider the ramifications of that - confidential messages to HR, medical information, insider trading information, your banking sessions - would you feel happy BCC’ing every single email to your IT department? Would you print out your therapy notes and pin them to the kitchen notice board?</p>

<p>But even ignoring the philosophical arguments about privacy and trust, I argue it actively makes your security <em>worse</em>. Consider this - what is the likelihood of every certificate authority on the Internet having their private keys compromised simultaneously? I’d wager that’s almost at the whatever is the statistics equivalent of the Planck length level of probability.¹</p>

<p>On the other hand, what’s the chance of your company’s MITM private key getting compromised by an attacker? Even if you completely trust your IT team and vendor (and if you do, you clearly haven’t been paying attention to any tech news for oh… the last few decades), you have to admit that chance is a lot higher. And depending on the vendor or tech stack involved, it could be a LOT higher. One disgruntled employee, one unpatched vulnerability, one phishing email to the right admin and choo-choo, it’s all aboard the FAIL train. Now an attacker could have the keys to your entire kingdom.</p>

<p>Then there’s the practicalities of it. It’s simply a massive hassle. Different Operating Systems expect certificates in different formats (PEM? DER? PFX? P7B?) installed in different places with different tooling to manage it all. <code>update-ca-certificates</code> vs <code>update-ca-trust</code> is just the tip of the iceberg - and that’s just the OS level. You then have language runtimes (Java keystore anyone?) and the applications themselves that all need to be configured.</p>

<p>And the problem is compounded with modern cloud-native apps. In a Kubernetes cluster, as well as having to handle updating the node VM images and container runtimes, you’ll have dozens if not hundreds of different base images each of which has their own standards. Alpine uses a different certificate path than Ubuntu. Your Node app expects them somewhere else entirely. The various CRDs or Helm charts you are using may or may not support custom CA bundles, and if they do there’s no agreed-on standard.</p>

<p>Now I’m not saying that because a problem is hard we should simply give up, but even if the benefits were worth it the simple fact is even with the best tooling and automation, you are <strong>guaranteed</strong> to miss something. Whether it’s some obscure tool that has a custom keystore and non-standard tooling, a quick “one off” command in an ephemeral container, some app that uses certificate pinning or an aging switch firmware that doesn’t even support custom certificate bundles, <em>something</em> will slip through the cracks. And when it does, guess what happens?</p>

<p>Which brings me to my biggest peeve: it normalizes bad security practices. Given that you will never have 100% coverage of your CA certificate installation - particularly amongst your technical teams who will be using a multitude of different tools and platforms - you get developers and sysadmins used to TLS errors. Instead of treating each one as an anomaly and something to be investigated, you get used to just running with <code>--insecure</code> or <code>curl -k</code> because you just need to get shit done. Turning off certificate verification becomes a routine troubleshooting step. “Oh, it’s probably just the corporate proxy again” becomes the reflexive response to any TLS error. You’ve just trained your entire technical staff to ignore one of the most important security warnings on the Internet!</p>

<p>And don’t even get me started on the performance and availability implications. All your traffic now has to be decrypted and re-encrypted by your magic box. Hope you sized that appliance correctly! Hope it doesn’t become a single point of failure! Hope it supports all the latest TLS versions and cipher suites!</p>

<p>There are a multitude of ways to protect yourself that are not only less invasive but are often <em>more</em> effective because they’re designed for how modern infrastructure actually works. Anomaly detection, Zero Trust network architecture, EDR, Netflow analysis… You don’t need to create single points of failure, and you can actually work with modern cloud-native infrastructure instead of fighting it. Plus, y’know, there’s this AI thing which as it turns out is actually quite useful at analysing metadata and spotting odd behavioral patterns.</p>

<p>In my experience: TLS <del>Inspection</del> MITM is a gigantic administrative burden, it normalizes bad practice, it creates bottlenecks and availability risks, and actively worsens your security posture.</p>

<p>Just stop it already.</p>

<p><strong>NOTE :</strong> This was a particularly cathartic rant, and I didn’t expect it to blow up and hit the front page of Hacker News! While I was venting away, I do appreciate that there is actually some nuance at play here so for a fuller discussion with some dissenting opinions, please do check out the <a href="https://news.ycombinator.com/item?id=46214950">comment thread</a>.</p>

<p>¹ = In particular, I worded this poorly. What I was thinking of was more along the lines of being able to do this without detection via CT logs etc. A commenter on HN <a href="https://news.ycombinator.com/item?id=46214950#46215764">pointed out</a> that you only need one trusted CA to be compromised which is of course true.</p>

        
      </section>

      

      

      
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Revisiting "Let's Build a Compiler" (191 pts)]]></title>
            <link>https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</link>
            <guid>46214693</guid>
            <pubDate>Wed, 10 Dec 2025 06:22:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/">https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</a>, See on <a href="https://news.ycombinator.com/item?id=46214693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>There's an old compiler-building tutorial that has become part of the field's
lore: the <a href="https://compilers.iecc.com/crenshaw/">Let's Build a Compiler</a>
series by Jack Crenshaw (published between 1988 and 1995).</p>
<p>I <a href="https://eli.thegreenplace.net/2003/07/29/great-compilers-tutorial">ran into it in 2003</a>
and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite
often <a href="https://hn.algolia.com/?dateRange=pastYear&amp;page=0&amp;prefix=true&amp;query=crenshaw&amp;sort=byDate&amp;type=all">in Hacker News threads</a>.
Why is that? Why does a tutorial from 35
years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that
are virtually unknown for the new generation of programmers - hold sway over
compiler enthusiasts? I've decided to find out.</p>
<p>The tutorial is <a href="https://compilers.iecc.com/crenshaw/">easily available and readable online</a>, but
just re-reading it seemed insufficient. So I've decided on meticulously
translating the compilers built in it to Python and emit a more modern target -
WebAssembly. It was an enjoyable process and I want to share the outcome and
some insights gained along the way.</p>
<p>The result is <a href="https://github.com/eliben/letsbuildacompiler">this code repository</a>.
Of particular interest is the <a href="https://github.com/eliben/letsbuildacompiler/blob/main/TUTORIAL.md">TUTORIAL.md file</a>,
which describes how each part in the original tutorial is mapped to my code. So
if you want to read the original tutorial but play with code you can actually
easily try on your own, feel free to follow my path.</p>
<div id="a-sample">
<h2>A sample</h2>
<p>To get a taste of the input language being compiled and the output my compiler
generates, here's a sample program in the KISS language designed by Jack
Crenshaw:</p>
<div><pre><span></span>var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
</pre></div>
<p>It's from part 13 of the tutorial, so it showcases procedures along with control
constructs like the <tt>while</tt> loop, and passing parameters both by value and by
reference. Here's the WASM text generated by my compiler for part 13:</p>
<div><pre><span></span><span>(</span><span>module</span>
  <span>(</span><span>memory</span> <span>8</span><span>)</span>
  <span>;; Linear stack pointer. Used to pass parameters by ref.</span>
  <span>;; Grows downwards (towards lower addresses).</span>
  <span>(</span><span>global</span> <span>$__sp</span> <span>(</span><span>mut</span> <span>i32</span><span>)</span> <span>(</span><span>i32.const</span> <span>65536</span><span>))</span>

  <span>(</span><span>global</span> <span>$X</span> <span>(</span><span>mut</span> <span>i32</span><span>)</span> <span>(</span><span>i32.const</span> <span>0</span><span>))</span>

  <span>(</span><span>func</span> <span>$ADDSEQ</span> <span>(</span><span>param</span> <span>$N</span> <span>i32</span><span>)</span> <span>(</span><span>param</span> <span>$RESULT</span> <span>i32</span><span>)</span>
    <span>(</span><span>local</span> <span>$I</span> <span>i32</span><span>)</span>
    <span>(</span><span>local</span> <span>$SUM</span> <span>i32</span><span>)</span>
    <span>loop</span> <span>$loop1</span>
      <span>block</span> <span>$breakloop1</span>
        <span>local.get</span> <span>$I</span>
        <span>local.get</span> <span>$N</span>
        <span>i32.lt_s</span>
        <span>i32.eqz</span>
        <span>br_if</span> <span>$breakloop1</span>
        <span>local.get</span> <span>$SUM</span>
        <span>local.get</span> <span>$I</span>
        <span>i32.add</span>
        <span>local.set</span> <span>$SUM</span>
        <span>local.get</span> <span>$I</span>
        <span>i32.const</span> <span>1</span>
        <span>i32.add</span>
        <span>local.set</span> <span>$I</span>
        <span>br</span> <span>$loop1</span>
      <span>end</span>
    <span>end</span>
    <span>local.get</span> <span>$RESULT</span>
    <span>local.get</span> <span>$RESULT</span>
    <span>i32.load</span>
    <span>local.get</span> <span>$SUM</span>
    <span>i32.add</span>
    <span>i32.store</span>
  <span>)</span>

  <span>(</span><span>func</span> <span>$main</span> <span>(</span><span>export</span> <span>"main"</span><span>)</span> <span>(</span><span>result</span> <span>i32</span><span>)</span>
    <span>i32.const</span> <span>11</span>
    <span>global.get</span> <span>$__sp</span>      <span>;; make space on stack</span>
    <span>i32.const</span> <span>4</span>
    <span>i32.sub</span>
    <span>global.set</span> <span>$__sp</span>
    <span>global.get</span> <span>$__sp</span>
    <span>global.get</span> <span>$X</span>
    <span>i32.store</span>
    <span>global.get</span> <span>$__sp</span>    <span>;; push address as parameter</span>
    <span>call</span> <span>$ADDSEQ</span>
    <span>;; restore parameter X by ref</span>
    <span>global.get</span> <span>$__sp</span>
    <span>i32.load</span> <span>offset</span><span>=</span><span>0</span>
    <span>global.set</span> <span>$X</span>
    <span>;; clean up stack for ref parameters</span>
    <span>global.get</span> <span>$__sp</span>
    <span>i32.const</span> <span>4</span>
    <span>i32.add</span>
    <span>global.set</span> <span>$__sp</span>
    <span>global.get</span> <span>$X</span>
  <span>)</span>
<span>)</span>
</pre></div>
<p>You'll notice that there is some trickiness in the emitted code w.r.t. handling
the by-reference parameter (my <a href="https://eli.thegreenplace.net/2025/notes-on-the-wasm-basic-c-abi/">previous post</a>
deals with this issue in more detail). In general, though, the emitted code is
inefficient - there is close to 0 optimization applied.</p>
<p>Also, if you're very diligent you'll notice something odd about the global
variable <tt>X</tt> - it seems to be implicitly returned by the generated <tt>main</tt>
function. This is just a testing facility that makes my compiler easy to test.
All the compilers are extensively tested - usually by running the
generated WASM code <a href="#footnote-1" id="footnote-reference-1">[1]</a> and verifying expected results.</p>
</div>
<div id="insights-what-makes-this-tutorial-so-special">
<h2>Insights - what makes this tutorial so special?</h2>
<p>While reading the original tutorial again, I had on opportunity to reminisce on
what makes it so effective. Other than the very fluent and conversational
writing style of Jack Crenshaw, I think it's a combination of two key
factors:</p>
<ol>
<li>The tutorial builds a recursive-descent parser step by step, rather than
giving a long preface on automata and table-based parser generators. When
I first encountered it (in 2003), it was taken for granted that if you want
to write a parser then lex + yacc are the way to go <a href="#footnote-2" id="footnote-reference-2">[2]</a>. Following the
development of a simple and clean hand-written
parser was a revelation that wholly changed my approach to the subject;
subsequently, hand-written recursive-descent parsers have been my go-to approach
<a href="https://eli.thegreenplace.net/tag/recursive-descent-parsing">for almost 20 years now</a>.</li>
<li>Rather than getting stuck in front-end minutiae, the tutorial goes straight
to generating working assembly code, from very early on. This was also a
breath of fresh air for engineers who grew up with more traditional courses
where you spend 90% of the time on parsing, type checking and other semantic
analysis and often run entirely out of steam by the time code generation
is taught.</li>
</ol>
<p>To be honest, I don't think either of these are a big problem with modern
resources, but back in the day the tutorial clearly hit the right nerve with
many people.</p>
</div>
<div id="what-else-does-it-teach-us">
<h2>What else does it teach us?</h2>
<p>Jack Crenshaw's tutorial takes the <a href="https://en.wikipedia.org/wiki/Syntax-directed_translation">syntax-directed translation</a>
approach, where code is emitted <em>while parsing</em>, without having to divide the
compiler into explicit phases with IRs. As I said above, this is a fantastic
approach for getting started, but in the latter parts of the tutorial it starts
showing its limitations. Especially once we get to types, it becomes painfully
obvious that it would be very nice if we knew the types of expressions <em>before</em>
we generate code for them.</p>
<p>I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial
at some point after part 14, but it may very well be. He keeps writing how
the emitted code is clearly sub-optimal <a href="#footnote-3" id="footnote-reference-3">[3]</a> and can be improved, but IMHO it's
just not that easy to improve using the syntax-directed translation strategy.
With perfect hindsight vision, I would probably use Part 14 (types) as a turning
point - emitting some kind of AST from the parser and then doing simple type
checking and analysis on that AST prior to generating code from it.</p>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>All in all, the original tutorial remains a wonderfully readable introduction
to building compilers. This post and the <a href="https://github.com/eliben/letsbuildacompiler">GitHub repository</a>
it describes are a modest
contribution that aims to improve the experience of folks reading the original
tutorial today and not willing to use obsolete technologies. As always, let
me know if you run into any issues or have questions!</p>
<hr>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td>This is done using the <a href="https://pypi.org/project/wasmtime/">Python bindings to wasmtime</a>.</td></tr>
</tbody>
</table>
<table id="footnote-2">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-2">[2]</a></td><td>By the way, gcc switched from YACC to hand-written recursive-descent
parsing in the 2004-2006 timeframe, and Clang has been implemented with
a recursive-descent parser from the start (2007).</td></tr>
</tbody>
</table>
<table id="footnote-3">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-3">[3]</a></td><td><p>Concretely: when we compile <tt>subexpr1 + subexpr2</tt> and the two sides have different
types, it would be mighty nice to know that <em>before</em> we actually generate
the code for both sub-expressions. But the syntax-directed translation
approach just doesn't work that way.</p>
<p>To be clear: it's easy to generate <em>working</em> code; it's just not easy
to generate optimal code without some sort of type analysis that's
done before code is actually generated.</p>
</td></tr>
</tbody>
</table>
</div>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Source available' is not open source (and that's okay) (119 pts)]]></title>
            <link>https://dri.es/source-available-is-not-open-source-and-that-is-okay</link>
            <guid>46213709</guid>
            <pubDate>Wed, 10 Dec 2025 03:33:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dri.es/source-available-is-not-open-source-and-that-is-okay">https://dri.es/source-available-is-not-open-source-and-that-is-okay</a>, See on <a href="https://news.ycombinator.com/item?id=46213709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
            <p>This week, Ruby on Rails creator David Heinemeier Hansson and WordPress founding developer Matt Mullenweg started fighting about what "open source" means. I've spent twenty years working on open source sustainability, and I have some thoughts.</p>
<p>David Heinemeier Hansson (also known as DHH) released a new kanban tool, Fizzy, this week and <a href="https://world.hey.com/dhh/fizzy-is-our-fun-modern-take-on-kanban-and-we-made-it-open-source-54ac41b6">called it open source</a>.</p>
<p>People quickly pointed out that the <a href="https://www.fizzy.do/license">O'Saasy license</a> that Fizzy is released under blocks others from offering a competing SaaS version, which violates the <a href="https://opensource.org/osd">Open Source Initiative's definition</a>. When challenged, he brushed it off on X and said, "You know this is just some shit people made up, right?". He followed with "Open source is when the source is open. Simple as that".</p>
<p>This morning, <a href="https://ma.tt/2025/12/dhh-open-source/">Matt Mullenweg rightly pushed back</a>. He argued that you can't ignore the Open Source Initiative definition. He compared it to North Korea calling itself a democracy. A clumsy analogy, but the point stands.</p>
<p>Look, the term "open source" has a specific, shared meaning. It is not a loose idea and not something you can repurpose for marketing. Thousands of people shaped that definition over decades. Ignoring that work means benefiting from the community while setting aside its rules.</p>
<p>This whole debate becomes spicier knowing that <a href="https://www.youtube.com/watch?v=vagyIcmIGOQ">DHH was on Lex Fridman's podcast</a> only a few months ago, appealing to the spirit and ethics of open source to <a href="https://youtube.com/watch?v=vagyIcmIGOQ&amp;t=20506">criticize Matt's handling of the WP Engine dispute</a>. If the definition is just "shit people made up", what spirit was Matt violating?</p>
<p>The definition debate matters, but the bigger issue here is sustainability. DHH's choice of license reacts to a real pressure in open source: many companies make real money from open source software while leaving the hard work of building and maintaining it to others.</p>
<p>This tension also played a role in <a href="https://dri.es/solving-the-maker-taker-problem">Matt's fight with WP Engine</a>, so he and DHH share some common ground, even if they handle it differently. We see the same thing in Drupal, where contributions from the biggest companies in our ecosystem is extremely uneven.</p>
<p>DHH can experiment because Fizzy is new. He can choose a different license and see how it works. Matt can't as WordPress has been licensed under the GPL for more than twenty years. Changing that now is virtually impossible.</p>
<p>Both conversations are important, but watching two of the most influential people in open source argue about definitions while we all wrestle with <a href="https://dri.es/scaling-open-source-communities">free riders</a> feels a bit like firefighters arguing about hose lengths during a fire.</p>
<p>The definition debate matters because open source only works when we agree on what the term means. But sustainability decides whether projects like Drupal, WordPress, and Ruby on Rails keep thriving for decades to come. That is the conversation we need to have.</p>
<p>In Drupal, we are experimenting with contribution credits and with guiding work toward companies that support the project. These ideas have helped, but also have not solved the imbalance.</p>
<p>Six years ago I wrote in <a href="https://dri.es/balancing-makers-and-takers-to-scale-and-sustain-open-source">my Makers and Takers blog post</a> that I would love to see new licenses that "encourage software free riding", but "discourage customer free riding". O'Saasy is exactly that kind of experiment.</p>
<p>A more accurate framing would be that Fizzy is <a href="https://en.wikipedia.org/wiki/Source-available_software">source available</a>. You can read it, run it, and modify it. But DHH's company is keeping the SaaS rights because they want to be able to build a sustainable business. That is defensible and generous, but it is <em>not</em> open source.</p>
<p>I still do not have the full answer to the open source sustainability problem. I have been wrestling with it for more than twenty years. But I do know the solution is not renaming the problem.</p>
<p>Some questions are worth asking, and answering:</p>
<ul>
<li>How do we distinguish between companies that can't contribute and those that won't?</li>
<li>What actually changes corporate behavior: shame, self-interest, punitive action, exclusive benefits, or regulation?</li>
</ul>
<p>If this latest fight nudges us away from word games and toward these questions, some good may come from it.</p>

      
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The end of the kernel Rust experiment (809 pts)]]></title>
            <link>https://lwn.net/Articles/1049831/</link>
            <guid>46213585</guid>
            <pubDate>Wed, 10 Dec 2025 03:15:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1049831/">https://lwn.net/Articles/1049831/</a>, See on <a href="https://news.ycombinator.com/item?id=46213585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>[Posted December 10, 2025 by corbet]
               </p></div><div><p>
The topic of the Rust experiment was just discussed at the annual
Maintainers Summit.  The consensus among the assembled developers is that
Rust in the kernel is no longer experimental — it is now a core part of the
kernel and is here to stay.  So the "experimental" tag will be coming off.
Congratulations are in order for all of the Rust for Linux team.
</p><p>
(Stay tuned for details in our Maintainers Summit coverage.)<br clear="all"></p><hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NYC congestion pricing cuts air pollution by a fifth in six months (150 pts)]]></title>
            <link>https://airqualitynews.com/cars-freight-transport/nyc-congestion-pricing-cuts-air-pollution-by-22-in-six-months/</link>
            <guid>46213504</guid>
            <pubDate>Wed, 10 Dec 2025 02:58:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://airqualitynews.com/cars-freight-transport/nyc-congestion-pricing-cuts-air-pollution-by-22-in-six-months/">https://airqualitynews.com/cars-freight-transport/nyc-congestion-pricing-cuts-air-pollution-by-22-in-six-months/</a>, See on <a href="https://news.ycombinator.com/item?id=46213504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																				
														<p><strong>In its first six months, New York City’s controversial congestion pricing scheme has reduced air pollution by 22% in Manhattan’s toll zone, while improving air quality across the entire metropolitan region, according to new research.</strong></p>
<p>The Cornell University study analysed data from 42 air quality monitors throughout the New York area between January 2024 and June 2025, tracking PM2.5 concentrations before and after the January 2025 launch of the Congestion Relief Zone (CRZ).</p>
<p><a target="_blank" href="https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4.jpg"><img fetchpriority="high" decoding="async" src="https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4.jpg" alt="yellow cab on road during daytime" width="800" height="508" srcset="https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4.jpg 1600w, https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4-300x191.jpg 300w, https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4-1024x650.jpg 1024w, https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4-768x488.jpg 768w, https://airqualitynews.com/wp-content/uploads/sites/2/2025/12/ahygosiiqo4-1536x975.jpg 1536w" sizes="(max-width: 800px) 100vw, 800px"></a><br>
The findings provide the first rigorous evidence that charging drivers to enter Manhattan’s core delivers substantial public health benefits.</p>
<p>Within the CRZ, which covers Manhattan streets at or below 60th Street, average daily peak concentrations of PM2.5 dropped by 3.05 µg/m³. For context, background pollution levels in the region typically hover around 8-9 µg/m³, making this reduction particularly significant for public health.</p>
<p>Notably, the benefits were found to extend far beyond the toll zone itself. Across New York City’s five boroughs, pollution levels fell by an average of 1.07 µg/m³, while the broader metropolitan area saw reductions of 0.70 µg/m³. This refutes claims that congestion pricing merely pushes traffic and its associated pollution to neighboring communities.</p>
<p>The improvements grew stronger over time, suggesting drivers are increasingly adapting their behavior. In the CRZ’s first week, pollution reductions within the toll zone averaged just 0.8 µg/m³. By the 20th week, that figure had grown to 4.9 µg/m³, suggesting commuters were switching to public transit, rescheduling trips or finding alternative routes.</p>
<p>Indeed, traffic data supports this. Between January and June 2025, vehicle entries into the toll zone dropped approximately 11% overall, with heavy-duty truck traffic falling by 18% and passenger cars declining by 9%. The disproportionate reduction in truck traffic appears particularly important, as these vehicles contribute heavily to urban air pollution despite representing a smaller share of total traffic.</p>
<p>The results exceed outcomes from similar programs in European cities. Stockholm’s congestion pricing reduced air pollution by 5-15% over several years, while London’s Ultra Low Emission Zone achieved roughly a 7% citywide decline. The researchers suggest that New York’s comparatively larger impact reflects the city’s exceptional transit infrastructure and the high volume of discretionary trips that drivers can easily shift to subways and buses.</p>
<p>The findings arrive as other American cities, including San Francisco and Los Angeles, consider implementing their own congestion pricing systems. New York’s experience suggests such programs can deliver rapid environmental benefits while generating revenue for transit improvements – a dual outcome that urban planners have long sought but rarely achieved.</p>
<p>Senior author Oliver Gao said: ‘Our overall conclusion is that congestion pricing in New York City, like many other cities in the world that have implemented it, helped not only improve traffic, but also helped reduce air pollutant concentration, improve air quality and should be good for public health.’</p>
<p>The study’s co-lead author Timothy Fraser added: ‘It’s really exciting to me that air quality improved throughout the entire metro area. This tells us that congestion pricing didn’t simply relocate air pollution to the suburbs by rerouting traffic. Instead, folks are likely choosing cleaner transportation options altogether, like riding public transportation or scheduling deliveries at night. This thins traffic and limits how smog compounds when many cars are on the road.’</p>

<p><strong>Photo</strong>: Franz Boccalatte / Unsplash</p>

											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Django: what’s new in 6.0 (346 pts)]]></title>
            <link>https://adamj.eu/tech/2025/12/03/django-whats-new-6.0/</link>
            <guid>46210240</guid>
            <pubDate>Tue, 09 Dec 2025 20:33:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adamj.eu/tech/2025/12/03/django-whats-new-6.0/">https://adamj.eu/tech/2025/12/03/django-whats-new-6.0/</a>, See on <a href="https://news.ycombinator.com/item?id=46210240">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><time datetime="2025-12-03">2025-12-03</time><img alt="Django 6.0: codename “mosaic”" title="Django 6.0: codename “mosaic”" src="https://adamj.eu/tech/assets/2025-12-03-django-mosaic.webp"><p>Django 6.0 was <a href="https://www.djangoproject.com/weblog/2025/dec/03/django-60-released/">released today</a>, starting another release cycle for the loved and long-lived Python web framework (now 20 years old!). It comes with a <em>mosaic</em> of new features, contributed to by many, some of which I am happy to have helped with. Below is my pick of highlights from <a href="https://docs.djangoproject.com/en/stable/releases/6.0/">the release notes</a>.</p><div id="upgrade-with-help-from-django-upgrade"><h2>Upgrade with help from django-upgrade<a title="Permalink to this headline" href="#upgrade-with-help-from-django-upgrade"></a></h2><p>If you’re upgrading a project from Django 5.2 or earlier, please try my tool <a href="https://django-upgrade.readthedocs.io/en/latest/">django-upgrade</a>. It will automatically update old Django code to use new features, fixing some deprecation warnings for you, including five fixers for Django 6.0. (One day, I’ll propose django-upgrade to become an official Django project, when energy and time permit…)</p></div><div id="template-partials"><h2>Template partials<a title="Permalink to this headline" href="#template-partials"></a></h2><p>There are four headline features in Django 6.0, which we’ll cover before other notable changes, starting with this one:</p><blockquote>The Django Template Language now supports <a href="https://docs.djangoproject.com/en/stable/ref/templates/language/#template-partials">template partials</a>, making it easier to encapsulate and reuse small named fragments within a template file.</blockquote><p>Partials are sections of a template marked by the new <code>{% partialdef %}</code> and <code>{% endpartialdef %}</code> tags. They can be reused within the same template or rendered in isolation. Let’s look at examples for each use case in turn.</p><div id="reuse-partials-within-the-same-template"><h3>Reuse partials within the same template<a title="Permalink to this headline" href="#reuse-partials-within-the-same-template"></a></h3><p>The below template reuses a partial called <code>filter_controls</code> within the same template. It’s defined once at the top of the template, then used twice later on. Using a partial allows the template avoid repetition without pushing the content into a separate include file.</p><div><pre><span></span><span>&lt;</span><span>section</span> <span>id</span><span>=</span><span>videos</span><span>&gt;</span>
  <span>{%</span> <span>partialdef</span> <span>filter_controls</span> <span>%}</span>
    <span>&lt;</span><span>form</span><span>&gt;</span>
      <span>{{</span> <span>filter_form</span> <span>}}</span>
    <span>&lt;/</span><span>form</span><span>&gt;</span>
  <span>{%</span> <span>endpartialdef</span> <span>%}</span>

  <span>{%</span> <span>partial</span> <span>filter_controls</span> <span>%}</span>

  <span>&lt;</span><span>ul</span><span>&gt;</span>
    <span>{%</span> <span>for</span> <span>video</span> <span>in</span> <span>videos</span> <span>%}</span>
      <span>&lt;</span><span>li</span><span>&gt;</span>
        <span>&lt;</span><span>h2</span><span>&gt;</span><span>{{</span> <span>video.title</span> <span>}}</span><span>&lt;/</span><span>h2</span><span>&gt;</span>
        ...
      <span>&lt;/</span><span>li</span><span>&gt;</span>
    <span>{%</span> <span>endfor</span> <span>%}</span>
  <span>&lt;/</span><span>ul</span><span>&gt;</span>

  <span>{%</span> <span>partial</span> <span>filter_controls</span> <span>%}</span>
<span>&lt;/</span><span>section</span><span>&gt;</span>
</pre></div><p>Actually, we can simplify this pattern further, by using the <code>inline</code> option on the <code>partialdef</code> tag, which causes the definition to also render in place:</p><div><pre><span></span><span>&lt;</span><span>section</span> <span>id</span><span>=</span><span>videos</span><span>&gt;</span>
  <span>{%</span> <span>partialdef</span> <span>filter_controls</span> <span>inline</span> <span>%}</span>
    <span>&lt;</span><span>form</span><span>&gt;</span>
      <span>{{</span> <span>filter_form</span> <span>}}</span>
    <span>&lt;/</span><span>form</span><span>&gt;</span>
  <span>{%</span> <span>endpartialdef</span> <span>%}</span>

  <span>&lt;</span><span>ul</span><span>&gt;</span>
    <span>{%</span> <span>for</span> <span>video</span> <span>in</span> <span>videos</span> <span>%}</span>
      <span>&lt;</span><span>li</span><span>&gt;</span>
        <span>&lt;</span><span>h2</span><span>&gt;</span><span>{{</span> <span>video.title</span> <span>}}</span><span>&lt;/</span><span>h2</span><span>&gt;</span>
        ...
      <span>&lt;/</span><span>li</span><span>&gt;</span>
    <span>{%</span> <span>endfor</span> <span>%}</span>
  <span>&lt;/</span><span>ul</span><span>&gt;</span>

  <span>{%</span> <span>partial</span> <span>filter_controls</span> <span>%}</span>
<span>&lt;/</span><span>section</span><span>&gt;</span>
</pre></div><p>Reach for this pattern any time you find yourself repeating template code within the same template. Because partials can use variables, you can also use them to de-duplicate when rendering similar controls with different data.</p></div><div id="render-partials-in-isolation"><h3>Render partials in isolation<a title="Permalink to this headline" href="#render-partials-in-isolation"></a></h3><p>The below template defines a <code>view_count</code> partial that’s intended to be re-rendered in isolation. It uses the <code>inline</code> option, so when the whole template is rendered, the partial is included.</p><p>The page uses <a href="https://htmx.org/">htmx</a>, via my <a href="https://django-htmx.readthedocs.io/en/latest/">django-htmx package</a>, to periodically refresh the view count, through the <code><span>hx-*</span></code> attributes. The request from htmx goes to a dedicated view that re-renders the <code>view_count</code> partial.</p><div><pre><span></span><span>{%</span> <span>load</span> <span>django_htmx</span> <span>%}</span>
<span>&lt;!doctype html&gt;</span>
<span>&lt;</span><span>html</span><span>&gt;</span>
  <span>&lt;</span><span>body</span><span>&gt;</span>
    <span>&lt;</span><span>h1</span><span>&gt;</span><span>{{</span> <span>video.title</span> <span>}}</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;</span><span>video</span> <span>width</span><span>=</span><span>1280</span> <span>height</span><span>=</span><span>720</span> <span>controls</span><span>&gt;</span>
      <span>&lt;</span><span>source</span> <span>src</span><span>=</span><span>"</span><span>{{</span> <span>video.file.url</span> <span>}}</span><span>"</span> <span>type</span><span>=</span><span>"video/mp4"</span><span>&gt;</span>
      Your browser does not support the video tag.
    <span>&lt;/</span><span>video</span><span>&gt;</span>

    <span>{%</span> <span>partialdef</span> <span>view_count</span> <span>inline</span> <span>%}</span>
    <span>&lt;</span><span>section</span>
      <span>class</span><span>=</span><span>view-count</span>
      <span>hx-trigger</span><span>=</span><span>"every 1s"</span>
      <span>hx-swap</span><span>=</span><span>outerHTML</span>
      <span>hx-get</span><span>=</span><span>"</span><span>{%</span> <span>url</span> <span>'video-view-count'</span> <span>video.id</span> <span>%}</span><span>"</span>
    <span>&gt;</span>
      <span>{{</span> <span>video.view_count</span> <span>}}</span> views
    <span>&lt;/</span><span>section</span><span>&gt;</span>
    <span>{%</span> <span>endpartialdef</span> <span>%}</span>

    <span>{%</span> <span>htmx_script</span> <span>%}</span>
  <span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</pre></div><p>The relevant code for the two views could look like this:</p><div><pre><span></span><span>from</span> <span>django.shortcuts</span> <span>import</span> <span>render</span>


<span>def</span> <span>video</span><span>(</span><span>request</span><span>,</span> <span>video_id</span><span>):</span>
    <span>...</span>
    <span>return</span> <span>render</span><span>(</span><span>request</span><span>,</span> <span>"video.html"</span><span>,</span> <span>{</span><span>"video"</span><span>:</span> <span>video</span><span>})</span>


<span>def</span> <span>video_view_count</span><span>(</span><span>request</span><span>,</span> <span>video_id</span><span>):</span>
    <span>...</span>
    <span>return</span> <span>render</span><span>(</span><span>request</span><span>,</span> <span>"video.html#view_count"</span><span>,</span> <span>{</span><span>"video"</span><span>:</span> <span>video</span><span>})</span>
</pre></div><p>The initial <code>video</code> view renders the full template <code>video.html</code>. The <code>video_view_count</code> view renders just the <code>view_count</code> partial, by appending <code>#view_count</code> to the template name. This syntax is similar to how you’d reference an HTML fragment by its ID in a URL.</p></div><div id="history"><h3>History<a title="Permalink to this headline" href="#history"></a></h3><p>htmx was the main motivation for this feature, as promoted by htmx creator Carson Gross in <a href="https://htmx.org/essays/template-fragments/">a cross-framework review post</a>. Using partials definitely helps maintain “Locality of behaviour” within your templates, easing authoring, debugging, and maintenance by avoiding template file sprawl.</p><p>Django’s support for template partials was initially developed by Carlton Gibson in the <a href="https://pypi.org/project/django-template-partials/">django-template-partials package</a>, which remains available for older Django versions. The integration into Django itself was done in a Google Summer of Code project this year, worked on by student Farhan Ali and mentored by Carlton, in <a href="https://code.djangoproject.com/ticket/36410">Ticket #36410</a>. You can read more about the development process in <a href="https://www.farhana.li/blog/my-gsoc25-journey-django">Farhan’s retrospective blog post</a>. Many thanks to Farhan for authoring, Carlton for mentoring, and Natalia Bidart, Nick Pope, and Sarah Boyce for reviewing!</p></div></div><div id="tasks-framework"><h2>Tasks framework<a title="Permalink to this headline" href="#tasks-framework"></a></h2><p>The next headline feature we’re covering:</p><blockquote>Django now includes a built-in Tasks framework for running code outside the HTTP request–response cycle. This enables offloading work, such as sending emails or processing data, to background workers.</blockquote><p>Basically, there’s a new API for defining and enqueuing background tasks—very cool!</p><p>Background tasks are a way of running code outside of the request-response cycle. They’re a common requirement in web applications, used for sending emails, processing images, generating reports, and more.</p><p>Historically, Django has not provided any system for background tasks, and kind of ignored the problem space altogether. Developers have instead relied on third-party packages like <a href="https://docs.celeryq.dev/en/stable/">Celery</a> or <a href="https://django-q2.readthedocs.io/en/master/">Django Q2</a>. While these systems are fine, they can be complex to set up and maintain, and often don’t “go with the grain” of Django.</p><p>The new Tasks framework fills this gap by providing an interface to define background tasks, which task runner packages can then integrate with. This common ground allows third-party Django packages to define tasks in a standard way, assuming you’ll be using a compatible task runner to execute them.</p><p>Define tasks with the new <a href="https://docs.djangoproject.com/en/stable/ref/tasks/#django.tasks.task"><code>@task</code></a> decorator:</p><div><pre><span></span><span>from</span> <span>django.tasks</span> <span>import</span> <span>task</span>


<span>@task</span>
<span>def</span> <span>resize_video</span><span>(</span><span>video_id</span><span>):</span> <span>...</span>
</pre></div><p>…and enqueue them for background execution with the <a href="https://docs.djangoproject.com/en/stable/ref/tasks/#django.tasks.Task.enqueue"><code>Task.enqueue()</code></a> method:</p><div><pre><span></span><span>from</span> <span>example.tasks</span> <span>import</span> <span>resize_video</span>


<span>def</span> <span>upload_video</span><span>(</span><span>request</span><span>):</span>
    <span>...</span>
    <span>resize_video</span><span>.</span><span>enqueue</span><span>(</span><span>video</span><span>.</span><span>id</span><span>)</span>
    <span>...</span>
</pre></div><div id="execute-tasks"><h3>Execute tasks<a title="Permalink to this headline" href="#execute-tasks"></a></h3><p>At this time, Django does not include a production-ready task backend, only two that are suitable for development and testing:</p><ul><li><a href="https://docs.djangoproject.com/en/stable/topics/tasks/#immediate-execution"><code>ImmediateBackend</code></a> - runs tasks synchronously, blocking until they complete.</li><li><a href="https://docs.djangoproject.com/en/stable/topics/tasks/#dummy-backend"><code>DummyBackend</code></a> - does nothing when tasks are enqueued, but allows them to be inspected later. Useful for tests, where you can assert that tasks were enqueued without actually running them.</li></ul><p>For production use, you’ll need to use a third-party package that implements one, for which <a href="https://pypi.org/project/django-tasks/">django-tasks</a>, the reference implementation, is the primary option. It provides <code>DatabaseBackend</code> for storing tasks in your SQL database, a fine solution for many projects, avoiding extra infrastructure and allowing atomic task enqueuing within database transactions. We may see this backend merged into Django in due course, or at least become an official package, to help make Django “batteries included” for background tasks.</p><p>To use django-tasks’ <code>DatabaseBackend</code> today, first install the package:</p><p><strong>Second,</strong> add these two apps to your <code>INSTALLED_APPS</code> setting:</p><div><pre><span></span><span>INSTALLED_APPS</span> <span>=</span> <span>[</span>
    <span># ...</span>
    <span>"django_tasks"</span><span>,</span>
    <span>"django_tasks.backends.database"</span><span>,</span>
    <span># ...</span>
<span>]</span>
</pre></div><p><strong>Third,</strong> configure <code>DatabaseBackend</code> as your tasks backend in the <a href="https://docs.djangoproject.com/en/stable/ref/settings/#tasks">new <code>TASKS</code> setting</a>:</p><div><pre><span></span><span>TASKS</span> <span>=</span> <span>{</span>
    <span>"default"</span><span>:</span> <span>{</span>
        <span>"BACKEND"</span><span>:</span> <span>"django_tasks.backends.database.DatabaseBackend"</span><span>,</span>
    <span>},</span>
<span>}</span>
</pre></div><p><strong>Fourth,</strong> run migrations to create the necessary database tables:</p><p><strong>Finally,</strong> to run the task worker process, use the package’s <code>db_worker</code> management command:</p><div><pre><span></span>$<span> </span>./manage.py<span> </span>db_worker
Starting<span> </span>worker<span> </span><span>worker_id</span><span>=</span>jWLMLrms3C2NcUODYeatsqCFvd5rK6DM<span> </span><span>queues</span><span>=</span>default
</pre></div><p>This process runs indefinitely, polling for tasks and executing them, logging events as it goes:</p><div><pre><span></span>Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=RUNNING
Hello from test task!
Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=SUCCEEDED
</pre></div><p>You’ll want to run <code>db_worker</code> in production, and also in development if you want to test background task execution.</p></div><div id="history-1"><h3>History<a title="Permalink to this headline" href="#history-1"></a></h3><p>It’s been a long path to get the Tasks framework into Django, and I’m super excited to see it finally available in Django 6.0. Jake Howard started on the idea for Wagtail, a Django-powered CMS, back in 2021, as they have a need for common task definitions across their package ecosystem. He upgraded the idea to target Django itself in 2024, when he proposed <a href="https://github.com/django/deps/blob/main/accepted/0014-background-workers.rst">DEP 0014</a>. As a member of the Steering Council at the time, I had the pleasure of helping review and accept the DEP.</p><p>Since then, Jake has been leading the implementation effort, building pieces first in the separate <a href="https://pypi.org/project/django-tasks/">django-tasks package</a> before preparing them for inclusion in Django itself. This step was done under <a href="https://code.djangoproject.com/ticket/35859">Ticket #35859</a>, with <a href="https://github.com/django/django/pull/18627">a pull request</a> that took nearly a year to review and land. Thanks to Jake for his perseverance here, and to all reviewers: Andreas Nüßlein, Dave Gaeddert, Eric Holscher, Jacob Walls, Jake Howard, Kamal Mustafa, @rtr1, @tcely, Oliver Haas, Ran Benita, Raphael Gaschignard, and Sarah Boyce.</p><p>Read more about this feature and story in <a href="https://theorangeone.net/posts/django-dot-tasks-exists/">Jake’s post celebrating when it was merged</a>.</p></div></div><div id="content-security-policy-support"><h2>Content Security Policy support<a title="Permalink to this headline" href="#content-security-policy-support"></a></h2><p>Our third headline feature:</p><blockquote>Built-in support for the <a href="https://docs.djangoproject.com/en/stable/topics/security/#security-csp">Content Security Policy (CSP)</a> standard is now available, making it easier to protect web applications against content injection attacks such as cross-site scripting (XSS). CSP allows declaring trusted sources of content by giving browsers strict rules about which scripts, styles, images, or other resources can be loaded.</blockquote><p>I’m really excited about this, because I’m a bit of a security nerd who’s been deploying CSP for client projects for years.</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/CSP">CSP</a> is a security standard that can protect your site from cross-site scripting (XSS) and other code injection attacks. You set a <code><span>content-security-policy</span></code> header to declare which content sources are trusted for your site, and then browsers will block content from other sources. For example, you might declare that only scripts your domain are allowed, so an attacker who manages to inject a <code>&lt;script&gt;</code> tag pointing to evil.com would be thwarted, as the browser would refuse to load it.</p><p>Previously, Django had no built-in support for CSP, and developers had to rely on building their own, or using a third-party package like the very popular <a href="https://django-csp.readthedocs.io/en/latest/">django-csp</a>. But this was a little bit inconvenient, as it meant that other third-party packages couldn’t reliably integrate with CSP, as there was no common API to do so.</p><p>The new CSP support provides all the core features that django-csp did, with a slightly tidier and more Djangoey API. To get started, <strong>first</strong> add <a href="https://docs.djangoproject.com/en/stable/ref/middleware/#django.middleware.csp.ContentSecurityPolicyMiddleware"><code>ContentSecurityPolicyMiddleware</code></a> to your <code>MIDDLEWARE</code> setting:</p><div><pre><span></span><span>MIDDLEWARE</span> <span>=</span> <span>[</span>
    <span># ...</span>
    <span>"django.middleware.csp.ContentSecurityPolicyMiddleware"</span><span>,</span>
    <span># ...</span>
<span>]</span>
</pre></div><p>Place it next to <a href="https://docs.djangoproject.com/en/stable/ref/middleware/#django.middleware.security.SecurityMiddleware"><code>SecurityMiddleware</code></a>, as it similarly adds security-related headers to all responses. (You <em>do</em> have <code>SecurityMiddleware</code> enabled, right?)</p><p><strong>Second,</strong> configure your CSP policy using the new settings:</p><ul><li><a href="https://docs.djangoproject.com/en/stable/ref/settings/#secure-csp"><code>SECURE_CSP</code></a> to configure the <code><span>content-security-policy</span></code> header, which is your actively enforced policy.</li><li><a href="https://docs.djangoproject.com/en/stable/ref/settings/#secure-csp-report-only"><code>SECURE_CSP_REPORT_ONLY</code></a> to configure the <code><span>content-security-policy-report-only</span></code> header, which sets a non-enforced policy for which browsers report violations to a specified endpoint. This option is useful for testing and monitoring a policy before enforcing it.</li></ul><p>For example, to adopt the nonce-based strict CSP <a href="https://web.dev/articles/strict-csp">recommended by web.dev</a>, you could start with the following setting:</p><div><pre><span></span><span>from</span> <span>django.utils.csp</span> <span>import</span> <span>CSP</span>

<span>SECURE_CSP_REPORT_ONLY</span> <span>=</span> <span>{</span>
    <span>"script-src"</span><span>:</span> <span>[</span><span>CSP</span><span>.</span><span>NONCE</span><span>,</span> <span>CSP</span><span>.</span><span>STRICT_DYNAMIC</span><span>],</span>
    <span>"object-src"</span><span>:</span> <span>[</span><span>CSP</span><span>.</span><span>NONE</span><span>],</span>
    <span>"base-uri"</span><span>:</span> <span>[</span><span>CSP</span><span>.</span><span>NONE</span><span>],</span>
<span>}</span>
</pre></div><p>The <a href="https://docs.djangoproject.com/en/stable/ref/csp/#django.utils.csp.CSP"><code>CSP</code></a> enum used above provides constants for CSP directives, to help avoid typos.</p><p>This policy is quite restrictive and will break most existing sites if deployed as-is, because it requires nonces, as covered next. That’s why the example shows starting with the report-only mode header, to help track down places that need fixing before enforcing the policy. You’d later change to setting the <code>SECURE_CSP</code> setting to enforce the policy.</p><p>Anyway, those are the two basic steps to set up the new CSP support!</p><div id="nonce-generation"><h3>Nonce generation<a title="Permalink to this headline" href="#nonce-generation"></a></h3><p>A key part of the new feature is that <strong>nonce generation</strong> is now built-in to Django, when using the CSP middleware. Nonces are a security feature in CSP that allow you to mark specific <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> tags as trusted with a <code>nonce</code> attribute:</p><div><pre><span></span><span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>/static/app.js</span> <span>type</span><span>=</span><span>module</span> <span>nonce</span><span>=</span><span>55vsH4w7ATHB85C3MbPr_g</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
</pre></div><p>The nonce value is randomly generated per-request, and included in the CSP header. An attacker performing content injection couldn’t guess the nonce, so browsers can trust only those tags that include the correct nonce. Because nonce generation is now part of Django, third-party packages can depend on it for their <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> tags and they’ll continue to work if you adopt CSP with nonces.</p><p>Nonces are the recommended way to use CSP today, avoiding problems with previous allow-list based approaches. That’s why the above recommended policy enables them. To adopt a nonce-based policy, you’ll need to annotate your <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> tags with the nonce value through the following steps.</p><p><strong>First,</strong> add the new <a href="https://docs.djangoproject.com/en/stable/ref/templates/api/#django.template.context_processors.csp"><code>csp</code></a> template context processor to your <code>TEMPLATES</code> setting:</p><div><pre><span></span><span>TEMPLATES</span> <span>=</span> <span>[</span>
    <span>{</span>
        <span>"BACKEND"</span><span>:</span> <span>"django.template.backends.django.DjangoTemplates"</span><span>,</span>
        <span>"OPTIONS"</span><span>:</span> <span>{</span>
            <span>"context_processors"</span><span>:</span> <span>[</span>
                <span># ...</span>
                <span>"django.template.context_processors.csp"</span><span>,</span>
            <span>],</span>
        <span>},</span>
    <span>},</span>
<span>]</span>
</pre></div><p><strong>Second,</strong> annotate your <code>&lt;script&gt;</code> and <code>&lt;style&gt;</code> tags with <code><span>nonce="{{</span> csp_nonce }}"</code>:</p><div><pre><span></span><span>-   &lt;script src="{% static 'app.js' %}" type="module"&gt;&lt;/script&gt;</span>
<span>+   &lt;script src="{% static 'app.js' %}" type="module" nonce="{{ csp_nonce }}"&gt;&lt;/script&gt;</span>
</pre></div><p>This can be tedious and error-prone, hence using the report-only mode first to monitor violations might be useful, especially on larger projects.</p><p>Anyway, deploying CSP right would be another post in itself, or even a book chapter, so we’ll stop here for now. For more info, check out <a href="https://web.dev/articles/strict-csp">that web.dev article</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">the MDN CSP guide</a>.</p></div><div id="history-2"><h3>History<a title="Permalink to this headline" href="#history-2"></a></h3><p>CSP itself was proposed for browsers way back in 2004, and was first implemented in Mozilla Firefox version 4, released 2011. That same year, <a href="https://code.djangoproject.com/ticket/15727">Django Ticket #15727</a> was opened, proposing adding CSP support to Django. Mozilla created <a href="https://django-csp.readthedocs.io/en/latest/">django-csp</a> from 2010, before the first public availability of CSP, using it on their own Django-powered sites. The first comment on Ticket #15727 pointed to django-csp, and the community basically rolled with it as the de facto solution.</p><p>Over the years, CSP itself evolved, as did django-csp, with <a href="https://rob.cogit8.org/">Rob Hudson</a> ending up as its maintainer. Focusing on the package motivated to finally get CSP into Django itself. He made a draft PR and posted on Ticket #15727 in 2024, which I enjoyed helping review. He iterated on the PR over the next 13 months until it was finally merged for Django 6.0. Thanks to Rob for his heroic dedication here, and to all reviewers: Benjamin Balder Bach, Carlton Gibson, Collin Anderson, David Sanders, David Smith, Florian Apolloner, Harro van der Klauw, Jake Howard, Natalia Bidart, Paolo Melchiorre, Sarah Boyce, and Sébastien Corbin.</p></div></div><div id="email-api-updates"><h2>Email API updates<a title="Permalink to this headline" href="#email-api-updates"></a></h2><p>The fourth and final headline feature:</p><blockquote>Email handling in Django now uses Python’s modern email API, introduced in Python 3.6. This API, centered around the <a href="https://docs.python.org/3/library/email.message.html#email.message.EmailMessage"><code>email.message.EmailMessage</code></a> class, offers a cleaner and Unicode-friendly interface for composing and sending emails.</blockquote><p>This is a major change, but it’s unlikely to affect projects using basic email features. You can still use Django’s <a href="https://docs.djangoproject.com/en/stable/topics/email/#django.core.mail.send_mail"><code>send_mail()</code> function</a> and <a href="https://docs.djangoproject.com/en/stable/topics/email/#django.core.mail.EmailMessage"><code>EmailMessage</code> class</a> as before, like:</p><div><pre><span></span><span>from</span> <span>django.core.mail</span> <span>import</span> <span>EmailMessage</span>

<span>email</span> <span>=</span> <span>EmailMessage</span><span>(</span>
    <span>subject</span><span>=</span><span>"🐼 Need more bamboo"</span><span>,</span>
    <span>body</span><span>=</span><span>"We are desperately low, please restock before the pandas find out!"</span><span>,</span>
    <span>from_email</span><span>=</span><span>"zookeeper@example.com"</span><span>,</span>
    <span>to</span><span>=</span><span>[</span><span>"supplies@example.com"</span><span>],</span>
<span>)</span>
<span>email</span><span>.</span><span>attach_file</span><span>(</span><span>"/media/bamboo_cupboard.jpg"</span><span>)</span>
<span>email</span><span>.</span><span>send</span><span>()</span>
</pre></div><p>The key change is that, under-the-hood, when you call <code>send()</code> on a Django <code>EmailMessage</code> object, it now translates itself into a Python’s newer <code>email.message.EmailMessage</code> type before sending.</p><p>Modernizing provides these benefits:</p><ol><li><strong>Fewer bugs</strong> - many edge case bugs in Python’s old email API have been fixed in the new one.</li><li><strong>Django is less hacky</strong> - a bunch of workarounds and security fixes in Django‘s email code have been removed.</li><li><strong>More convenient API</strong> - the new API supports some niceties, like the below inline attachment example.</li></ol><div id="easier-inline-attachments-with-mimepart"><h3>Easier inline attachments with <code>MIMEPart</code><a title="Permalink to this headline" href="#easier-inline-attachments-with-mimepart"></a></h3><p>Django’s <a href="https://docs.djangoproject.com/en/stable/topics/email/#django.core.mail.EmailMessage"><code>EmailMessage.attach()</code></a> method allows you to attach a file as an attachment. Emails support images as <strong>inline attachments</strong>, which can be displayed within the HTML email body.</p><p>While you could previously use <code>EmailMessage.attach()</code> to add inline attachments, it was a bit fiddly, using a legacy class. Now, you can call the method with a Python <a href="https://docs.python.org/3/library/email.message.html#email.message.MIMEPart"><code>email.message.MIMEPart</code></a> object to add an inline attachment in a few steps:</p><div><pre><span></span><span>import</span> <span>email.utils</span>
<span>from</span> <span>email.message</span> <span>import</span> <span>MIMEPart</span>
<span>from</span> <span>django.core.mail</span> <span>import</span> <span>EmailMultiAlternatives</span>

<span>message</span> <span>=</span> <span>EmailMultiAlternatives</span><span>(</span>
    <span>subject</span><span>=</span><span>"Cute Panda Alert"</span><span>,</span>
    <span>body</span><span>=</span><span>"Here's a cute panda picture for you!"</span><span>,</span>
    <span>from_email</span><span>=</span><span>"cute@example.com"</span><span>,</span>
    <span>to</span><span>=</span><span>[</span><span>"fans@example.com"</span><span>],</span>
<span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"panda.jpg"</span><span>,</span> <span>"rb"</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>panda_jpeg</span> <span>=</span> <span>f</span><span>.</span><span>read</span><span>()</span>

<span>cid</span> <span>=</span> <span>email</span><span>.</span><span>utils</span><span>.</span><span>make_msgid</span><span>()</span>
<span>inline_image</span> <span>=</span> <span>MIMEPart</span><span>()</span>
<span>inline_image</span><span>.</span><span>set_content</span><span>(</span>
    <span>panda_jpeg</span><span>,</span>
    <span>maintype</span><span>=</span><span>"image"</span><span>,</span>
    <span>subtype</span><span>=</span><span>"jpeg"</span><span>,</span>
    <span>disposition</span><span>=</span><span>"inline"</span><span>,</span>
    <span>cid</span><span>=</span><span>cid</span><span>,</span>
<span>)</span>
<span>message</span><span>.</span><span>attach</span><span>(</span><span>inline_image</span><span>)</span>
<span>message</span><span>.</span><span>attach_alternative</span><span>(</span>
    <span>f</span><span>'&lt;h1&gt;Cute panda baby alert!&lt;/h1&gt;&lt;img src="cid:</span><span>{</span><span>cid</span><span>[</span><span>1</span><span>:</span><span>-</span><span>1</span><span>]</span><span>}</span><span>"&gt;'</span><span>,</span>
    <span>"text/html"</span><span>,</span>
<span>)</span>
</pre></div><p>It’s not the simplest API, but it does expose all the power of the underlying email system, and it’s better than the past situation.</p></div><div id="history-3"><h3>History<a title="Permalink to this headline" href="#history-3"></a></h3><p>The new email API was added to Python as provisional <a href="https://docs.python.org/3/whatsnew/3.4.html#email">in version 3.4 (2014)</a>, and made stable <a href="https://docs.python.org/3/whatsnew/3.6.html#email">in version 3.6 (2016)</a>. The legacy API, however, was never planned for deprecation, so there was never any deadline to upgrade Django’s email handling.</p><p>In 2024, Mike Edmunds <a href="https://groups.google.com/g/django-developers/c/2zf9GQtjdIk">posted on the (old) django-developers mailing list</a>, proposing the upgrade with strong reasoning and planning. This conversation led to <a href="https://code.djangoproject.com/ticket/35581">Ticket #35581</a>, which he worked on for eight months until it was merged. Many thanks to Mike for leading this effort, and to Sarah Boyce for reviewing! Email is not a glamorous feature, but it’s a critical communication channel for nearly every Django project, so props for this.</p></div></div><div id="positional-arguments-in-django-core-mail-apis"><h2>Positional arguments in <code>django.core.mail</code> APIs<a title="Permalink to this headline" href="#positional-arguments-in-django-core-mail-apis"></a></h2><p>We’re now out of the headline features and onto the “minor” changes, starting with this deprecation related to the above email changes:</p><blockquote><p><a href="https://docs.djangoproject.com/en/stable/topics/email/#module-django.core.mail"><code>django.core.mail</code></a> APIs now require keyword arguments for less commonly used parameters. Using positional arguments for these now emits a deprecation warning and will raise a <code>TypeError</code> when the deprecation period ends:</p><ul><li>All optional parameters (<code>fail_silently</code> and later) must be passed as keyword arguments to <code>get_connection()</code>, <code>mail_admins()</code>, <code>mail_managers()</code>, <code>send_mail()</code>, and <code>send_mass_mail()</code>.</li><li>All parameters must be passed as keyword arguments when creating an <code>EmailMessage</code> or <code>EmailMultiAlternatives</code> instance, except for the first four (<code>subject</code>, <code>body</code>, <code>from_email</code>, and <code>to</code>), which may still be passed either as positional or keyword arguments.</li></ul></blockquote><p>Previously, Django would let you pass all parameters positionally, which gets a bit silly and hard to read with long parameter lists, like:</p><div><pre><span></span><span>from</span> <span>django.core.mail</span> <span>import</span> <span>send_mail</span>

<span>send_mail</span><span>(</span>
    <span>"🐼 Panda of the week"</span><span>,</span>
    <span>"This week’s panda is Po Ping, sha-sha booey!"</span><span>,</span>
    <span>"updates@example.com"</span><span>,</span>
    <span>[</span><span>"adam@example.com"</span><span>],</span>
    <span>True</span><span>,</span>
<span>)</span>
</pre></div><p>The final <code>True</code> doesn’t provide any clue what it means without looking up the function signature. Now, using positional arguments for those less-commonly-used parameters raises a deprecation warning, nudging you to write:</p><div><pre><span></span><span>from</span> <span>django.core.mail</span> <span>import</span> <span>send_mail</span>

<span>send_mail</span><span>(</span>
    <span>subject</span><span>=</span><span>"🐼 Panda of the week"</span><span>,</span>
    <span>body</span><span>=</span><span>"This week’s panda is Po Ping, sha-sha booey!"</span><span>,</span>
    <span>from_email</span><span>=</span><span>"updates@example.com"</span><span>,</span>
    <span>[</span><span>"adam@example.com"</span><span>],</span>
    <span>fail_silently</span><span>=</span><span>True</span><span>,</span>
<span>)</span>
</pre></div><p>This change is appreciated for API clarity, and Django is generally moving towards using keyword-only arguments more often. django-upgrade can automatically fix this one for you, via its <a href="https://django-upgrade.readthedocs.io/en/latest/fixers.html#mail-api-kwargs"><code>mail_api_kwargs</code> fixer</a>.</p><p>Thanks to Mike Edmunds, again, for making this improvement in <a href="https://code.djangoproject.com/ticket/36163">Ticket #36163</a>.</p></div><div id="extended-automatic-shell-imports"><h2>Extended automatic <code>shell</code> imports<a title="Permalink to this headline" href="#extended-automatic-shell-imports"></a></h2><p>Next up:</p><blockquote>Common utilities, such as django.conf.settings, are now automatically imported to the shell by default.</blockquote><p>One of the headline features back in Django 5.2 was <a href="https://adamj.eu/tech/2025/04/07/django-whats-new-5.2/#automatic-model-imports-in-the-shell">automatic model imports in the shell</a>, making <code>./manage.py shell</code> import all of your models automatically. Building on that DX boost, Django 6.0 now also imports other common utilities, for which we can find the full list by running <code>./manage.py shell</code> with <code><span>-v</span> 2</code>:</p><div><pre><span></span><span>$ </span>./manage.py<span> </span>shell<span> </span>-v<span> </span><span>2</span>
<span>6 objects imported automatically:</span>

<span>  from django.conf import settings</span>
<span>  from django.db import connection, models, reset_queries</span>
<span>  from django.db.models import functions</span>
<span>  from django.utils import timezone</span>

<span>...</span>
</pre></div><p>(This is from a project without any models, so only the utilities are listed.)</p><p>So that’s:</p><ul><li><p><a href="https://docs.djangoproject.com/en/stable/topics/settings/#using-settings-in-python-code"><code>settings</code></a>, useful for checking your runtime configuration:</p> <div><pre><span></span><span>In</span> <span>[</span><span>1</span><span>]:</span> <span>settings</span><span>.</span><span>DEBUG</span>
<span>Out</span><span>[</span><span>1</span><span>]:</span> <span>False</span>
</pre></div></li><li><p><a href="https://docs.djangoproject.com/en/5.2/topics/db/sql/#executing-custom-sql-directly"><code>connection</code></a> and <code>reset_queries()</code>, great for <a href="https://docs.djangoproject.com/en/stable/faq/models/#how-can-i-see-the-raw-sql-queries-django-is-running">checking the executed queries</a>:</p> <div><pre><span></span><span>In</span> <span>[</span><span>1</span><span>]:</span> <span>Book</span><span>.</span><span>objects</span><span>.</span><span>select_related</span><span>(</span><span>'author'</span><span>)</span>
<span>Out</span><span>[</span><span>1</span><span>]:</span> <span>&lt;</span><span>QuerySet</span> <span>[]</span><span>&gt;</span>

<span>In</span> <span>[</span><span>2</span><span>]:</span> <span>connection</span><span>.</span><span>queries</span>
<span>Out</span><span>[</span><span>2</span><span>]:</span>
<span>[{</span><span>'sql'</span><span>:</span> <span>'SELECT "example_book"."id", "example_book"."title", "example_book"."author_id", "example_author"."id", "example_author"."name" FROM "example_book" INNER JOIN "example_author" ON ("example_book"."author_id" = "example_author"."id") LIMIT 21'</span><span>,</span>
  <span>'time'</span><span>:</span> <span>'0.000'</span><span>}]</span>
</pre></div></li><li><p><a href="https://docs.djangoproject.com/en/stable/topics/db/models/#defining-models"><code>models</code></a> and <a href="https://docs.djangoproject.com/en/stable/ref/models/database-functions/#module-django.db.models.functions"><code>functions</code></a>, useful for advanced ORM work:</p> <div><pre><span></span><span>In</span> <span>[</span><span>1</span><span>]:</span> <span>Book</span><span>.</span><span>objects</span><span>.</span><span>annotate</span><span>(</span>
   <span>...</span><span>:</span>   <span>title_lower</span><span>=</span><span>functions</span><span>.</span><span>Lower</span><span>(</span><span>"title"</span><span>)</span>
   <span>...</span><span>:</span> <span>)</span><span>.</span><span>filter</span><span>(</span>
   <span>...</span><span>:</span>   <span>title_lower__startswith</span><span>=</span><span>"a"</span>
   <span>...</span><span>:</span> <span>)</span><span>.</span><span>count</span><span>()</span>
<span>Out</span><span>[</span><span>1</span><span>]:</span> <span>71</span>
</pre></div></li><li><p><a href="https://docs.djangoproject.com/en/stable/ref/utils/#module-django.utils.timezone"><code>timezone</code></a>, useful for using Django’s timezone-aware date and time utilities:</p> <div><pre><span></span><span>In</span> <span>[</span><span>1</span><span>]:</span> <span>timezone</span><span>.</span><span>now</span><span>()</span>
<span>Out</span><span>[</span><span>1</span><span>]:</span> <span>datetime</span><span>.</span><span>datetime</span><span>(</span><span>2025</span><span>,</span> <span>12</span><span>,</span> <span>1</span><span>,</span> <span>23</span><span>,</span> <span>42</span><span>,</span> <span>22</span><span>,</span> <span>558418</span><span>,</span> <span>tzinfo</span><span>=</span><span>datetime</span><span>.</span><span>timezone</span><span>.</span><span>utc</span><span>)</span>
</pre></div></li></ul><p>It remains possible to extend the automatic imports with whatever you’d like, as documented in <a href="https://docs.djangoproject.com/en/stable/howto/custom-shell/">How to customize the <code>shell</code> command</a> documentation page.</p><p>Salvo Polizzi contributed the original automatic shell imports feature in Django 5.2. He’s then returned to offer these extra imports for Django 6.0, in <a href="https://code.djangoproject.com/ticket/35680">Ticket #35680</a>. Thanks to everyone that contributed to the forum discussion agreeing on which imports to add, and to Natalia Bidart and Sarah Boyce for reviewing!</p></div><div id="dynamic-field-refresh-on-save"><h2>Dynamic field refresh on <code>save()</code><a title="Permalink to this headline" href="#dynamic-field-refresh-on-save"></a></h2><p>Now let’s discuss a series of ORM improvements, starting with this big one:</p><blockquote><code>GeneratedField</code>s and fields assigned expressions are now refreshed from the database after <code>save()</code> on backends that support the <code>RETURNING</code> clause (SQLite, PostgreSQL, and Oracle). On backends that don’t support it (MySQL and MariaDB), the fields are marked as deferred to trigger a refresh on subsequent accesses.</blockquote><p>Django models support having the database generate field values for you in three cases:</p><ol><li><p>The <a href="https://docs.djangoproject.com/en/stable/ref/models/fields/#django.db.models.Field.db_default"><code>db_default</code></a> field option, which lets the database generate the default value when creating an instance:</p> <div><pre><span></span><span>from</span> <span>django.db</span> <span>import</span> <span>models</span>
<span>from</span> <span>django.db.models.functions</span> <span>import</span> <span>Now</span>


<span>class</span> <span>Video</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span>
    <span>...</span>
    <span>created</span> <span>=</span> <span>models</span><span>.</span><span>DateTimeField</span><span>(</span><span>db_default</span><span>=</span><span>Now</span><span>())</span>
</pre></div></li><li><p>The <a href="https://docs.djangoproject.com/en/stable/ref/models/fields/#django.db.models.GeneratedField"><code>GeneratedField</code></a> field type, which is always computed by the database based on other fields in the same instance:</p> <div><pre><span></span><span>from</span> <span>django.db</span> <span>import</span> <span>models</span>
<span>from</span> <span>django.db.models.functions</span> <span>import</span> <span>Concat</span>


<span>class</span> <span>Video</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span>
    <span>...</span>
    <span>full_title</span> <span>=</span> <span>models</span><span>.</span><span>GeneratedField</span><span>(</span>
        <span>models</span><span>.</span><span>TextField</span><span>(),</span>
        <span>expression</span><span>=</span><span>Concat</span><span>(</span>
            <span>"title"</span><span>,</span>
            <span>models</span><span>.</span><span>Value</span><span>(</span><span>" - "</span><span>),</span>
            <span>"subtitle"</span><span>,</span>
        <span>),</span>
    <span>)</span>
</pre></div></li><li><p>Assigning expression values to fields before saving:</p> <div><pre><span></span><span>from</span> <span>django.db</span> <span>import</span> <span>models</span>
<span>from</span> <span>django.db.models.functions</span> <span>import</span> <span>Now</span>


<span>class</span> <span>Video</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span>
    <span>...</span>
    <span>last_updated</span> <span>=</span> <span>models</span><span>.</span><span>DateTimeField</span><span>()</span>


<span>video</span> <span>=</span> <span>Video</span><span>.</span><span>objects</span><span>.</span><span>get</span><span>(</span><span>id</span><span>=</span><span>1</span><span>)</span>
<span>...</span>
<span>video</span><span>.</span><span>last_updated</span> <span>=</span> <span>Now</span><span>()</span>
<span>video</span><span>.</span><span>save</span><span>()</span>
</pre></div></li></ol><p>Previously, only the first method, using <code>db_default</code>, would refresh the field value from the database after saving. The other two methods would leave you with only the old value or the expression object, meaning you’d need to call <a href="https://docs.djangoproject.com/en/stable/ref/models/instances/#django.db.models.Model.refresh_from_db"><code>Model.refresh_from_db()</code></a> to get any updated value if necessary. This was hard to remember and it costs an extra database query.</p><p>Now Django takes advantage of the <code>RETURNING</code> SQL clause to save the model instance and fetch updated dynamic field values in a single query, on backends that support it (SQLite, PostgreSQL, and Oracle). A <code>save()</code> call may now issue a query like:</p><div><pre><span></span><span>UPDATE</span><span> </span><span>"example_video"</span>
<span>SET</span><span> </span><span>"last_updated"</span><span> </span><span>=</span><span> </span><span>NOW</span><span>()</span>
<span>WHERE</span><span> </span><span>"example_video"</span><span>.</span><span>"id"</span><span> </span><span>=</span><span> </span><span>1</span>
<span>RETURNING</span><span> </span><span>"example_video"</span><span>.</span><span>"last_updated"</span>
</pre></div><p>Django puts the return value into the model field, so you can read it immediately after saving:</p><div><pre><span></span><span>video</span> <span>=</span> <span>Video</span><span>.</span><span>objects</span><span>.</span><span>get</span><span>(</span><span>id</span><span>=</span><span>1</span><span>)</span>
<span>...</span>
<span>video</span><span>.</span><span>last_updated</span> <span>=</span> <span>Now</span><span>()</span>
<span>video</span><span>.</span><span>save</span><span>()</span>
<span>print</span><span>(</span><span>video</span><span>.</span><span>last_updated</span><span>)</span>  <span># Updated value from the database</span>
</pre></div><p>On backends that don’t support <code>RETURNING</code> (MySQL and MariaDB), Django now marks the dynamic fields as deferred after saving. That way, the later access, as in the above example, will automatically call <code>Model.refresh_from_db()</code>. This ensures that you always read the updated value, even if it costs an extra query.</p><div id="history-4"><h3>History<a title="Permalink to this headline" href="#history-4"></a></h3><p>This feature was proposed in <a href="https://code.djangoproject.com/ticket/27222">Ticket #27222</a> way back in 2016, by Anssi Kääriäinen. It sat dormant for most of the nine years since, but ORM boss Simon Charette picked it up earlier this year, found an implementation, and pushed it through to completion. Thanks to Simon for continuing to push the ORM forward, and to all reviewers: David Sanders, Jacob Walls, Mariusz Felisiak, nessita, Paolo Melchiorre, Simon Charette, and Tim Graham.</p></div></div><div id="universal-stringagg-aggregate"><h2>Universal <code>StringAgg</code> aggregate<a title="Permalink to this headline" href="#universal-stringagg-aggregate"></a></h2><p>The next ORM change:</p><blockquote>The new <a href="https://docs.djangoproject.com/en/stable/ref/models/aggregates/#django.db.models.StringAgg"><code>StringAgg</code></a> aggregate returns the input values concatenated into a string, separated by the <code>delimiter</code> string. This aggregate was previously supported only for PostgreSQL.</blockquote><p>This aggregate is often used for making comma-separated lists of related items, among other things. Previously, it was only supported on PostgreSQL, as part of <a href="https://docs.djangoproject.com/en/stable/ref/contrib/postgres/"><code>django.contrib.postgres</code></a>:</p><div><pre><span></span><span>from</span> <span>django.contrib.postgres.aggregates</span> <span>import</span> <span>StringAgg</span>
<span>from</span> <span>example.models</span> <span>import</span> <span>Video</span>

<span>videos</span> <span>=</span> <span>Video</span><span>.</span><span>objects</span><span>.</span><span>annotate</span><span>(</span>
    <span>chapter_ids</span><span>=</span><span>StringAgg</span><span>(</span><span>"chapter"</span><span>,</span> <span>delimiter</span><span>=</span><span>","</span><span>),</span>
<span>)</span>

<span>for</span> <span>video</span> <span>in</span> <span>videos</span><span>:</span>
    <span>print</span><span>(</span><span>f</span><span>"Video </span><span>{</span><span>video</span><span>.</span><span>id</span><span>}</span><span> has chapters: </span><span>{</span><span>video</span><span>.</span><span>chapter_ids</span><span>}</span><span>"</span><span>)</span>
</pre></div><p>…which might give you output like:</p><div><pre><span></span>Video 104 has chapters: 71,72,74
Video 107 has chapters: 88,89,138,90,91,93
</pre></div><p>Now this aggregate is available on all database backends supported by Django, imported from <code>django.db.models</code>:</p><div><pre><span></span><span>from</span> <span>django.db.models</span> <span>import</span> <span>StringAgg</span><span>,</span> <span>Value</span>
<span>from</span> <span>example.models</span> <span>import</span> <span>Video</span>

<span>videos</span> <span>=</span> <span>Video</span><span>.</span><span>objects</span><span>.</span><span>annotate</span><span>(</span>
    <span>chapter_ids</span><span>=</span><span>StringAgg</span><span>(</span><span>"chapter"</span><span>,</span> <span>delimiter</span><span>=</span><span>Value</span><span>(</span><span>","</span><span>)),</span>
<span>)</span>

<span>for</span> <span>video</span> <span>in</span> <span>videos</span><span>:</span>
    <span>print</span><span>(</span><span>f</span><span>"Video </span><span>{</span><span>video</span><span>.</span><span>id</span><span>}</span><span> has chapters: </span><span>{</span><span>video</span><span>.</span><span>chapter_ids</span><span>}</span><span>"</span><span>)</span>
</pre></div><p>Note the <code>delimiter</code> argument now requires a <a href="https://docs.djangoproject.com/en/stable/ref/models/expressions/#django.db"><code>Value()</code></a> expression wrapper for literal strings, as above. This change allows you to use database functions or fields as the delimiter if desired.</p><p>While most Django projects stick to PostgreSQL, having this aggregate available on all backends is a nice improvement for cross-database compatibility, and it means third-party packages can use it without affecting their database support.</p><div id="history-5"><h3>History<a title="Permalink to this headline" href="#history-5"></a></h3><p>The PostgreSQL-specific <code>StringAgg</code> was added way back in Django 1.9 (2015) by Andriy Sokolovskiy, in <a href="https://code.djangoproject.com/ticket/24301">Ticket #24301</a>. In <a href="https://code.djangoproject.com/ticket/35444">Ticket #35444</a>, Chris Muthig proposed adding the <code>Aggregate.order_by</code> option, something used by <code>StringAgg</code> to specify the ordering of concatenated elements, and as a side effect this made it possible to generalize <code>StringAgg</code> to all backends.</p><p>Thanks to Chris for proposing and implementing this change, and to all reviewers: Paolo Melchiorre, Sarah Boyce, and Simon Charette.</p></div></div><div id="bigautofield-as-the-default-primary-key-type"><h2><code>BigAutoField</code> as the default primary key type<a title="Permalink to this headline" href="#bigautofield-as-the-default-primary-key-type"></a></h2><p>Next up:</p><blockquote><code>DEFAULT_AUTO_FIELD</code> setting now defaults to <code>BigAutoField</code></blockquote><p>This important change helps lock in scalable larger primary keys.</p><p>Django 3.2 (2021) introduced <a href="https://docs.djangoproject.com/en/stable/ref/settings/#default-auto-field">the <code>DEFAULT_AUTO_FIELD</code> setting</a> for changing the default primary key type used in models. Django uses this setting to add a primary key field called <code>id</code> to models that don’t explicitly define a primary key field. For example, if you define a model like this:</p><div><pre><span></span><span>from</span> <span>django.db</span> <span>import</span> <span>models</span>


<span>class</span> <span>Video</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span>
    <span>title</span> <span>=</span> <span>models</span><span>.</span><span>TextField</span><span>()</span>
</pre></div><p>…then it will have two fields: <code>id</code> and <code>title</code>, where <code>id</code> uses the type defined by <code>DEFAULT_AUTO_FIELD</code>.</p><p>The setting can also be overridden on a per-app basis by defining <a href="https://docs.djangoproject.com/en/stable/ref/applications/#django.apps.AppConfig.default_auto_field"><code>AppConfig.default_auto_field</code></a> in the app’s <code>apps.py</code> file:</p><div><pre><span></span><span>from</span> <span>django.apps</span> <span>import</span> <span>AppConfig</span>


<span>class</span> <span>ChannelConfig</span><span>(</span><span>AppConfig</span><span>):</span>
    <span>name</span> <span>=</span> <span>"channel"</span>
    <span>default_auto_field</span> <span>=</span> <span>"django.db.models.BigAutoField"</span>
</pre></div><p>A key motivation for adding the setting was to allow projects to switch from <code>AutoField</code> (a 32-bit integer) to <code>BigAutoField</code> (a 64-bit integer) for primary keys, without needing changes to every model. <code>AutoField</code> can store values up to about 2.1 billion, which sounds large but it becomes easy to hit at scale. <code>BigAutoField</code> can store values up to about 9.2 quintillion, which is “more than enough” for every practical purpose.</p><p>If a model using <code>AutoField</code> hits its maximum value, it can no longer accept new rows, a problem known as <strong>primary key exhaustion</strong>. The table is effectively blocked, requiring an urgent fix to switch the model from <code>AutoField</code> to <code>BigAutoField</code> via a locking database migration on a large table. For a great watch on how Kraken is fixing this problem, see <a href="https://www.youtube.com/watch?v=kZ4q0k_FNhw">Tim Bell’s DjangoCon Europe 2025 talk</a>, detailing some clever techniques to proactively migrate large tables with minimal downtime.</p><p>To stop this problem arising for new projects, Django 3.2 made new projects created with <code>startproject</code> set <code>DEFAULT_AUTO_FIELD</code> to <code>BigAutoField</code>, and new apps created with <code>startapp</code> set their <code>AppConfig.default_auto_field</code> to <code>BigAutoField</code>. It also added a system check to ensure that projects set <code>DEFAULT_AUTO_FIELD</code> explicitly, to ensure users were aware of the feature and could make an informed choice.</p><p>Now Django 6.0 changes the actual default values of the setting and app config attribute to <code>BigAutoField</code>. Projects using <code>BigAutoField</code> can remove the setting:</p><div><pre><span></span><span>-DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"</span>
</pre></div><p>…and app config attribute:</p><div><pre><span></span>from django.apps import AppConfig

<span> </span>class ChannelConfig(AppConfig):
<span> </span>    name = "channel"
<span>-    default_auto_field = "django.db.models.BigAutoField"</span>
</pre></div><p>The default <code>startproject</code> and <code>startapp</code> templates also no longer set these values. This change reduces the amount of boilerplate in new projects, and the problem of primary key exhaustion can fade into history, becoming something that most Django users no longer need to think about.</p><div id="history-6"><h3>History<a title="Permalink to this headline" href="#history-6"></a></h3><p>The addition of <code>DEFAULT_AUTO_FIELD</code> in Django 3.2 was proposed by Caio Ariede and implemented by Tom Forbes, in <a href="https://code.djangoproject.com/ticket/31007">Ticket #31007</a>. This new change in Django 6.0 was proposed and implemented by ex-Fellow Tim Graham, in <a href="https://code.djangoproject.com/ticket/36564">Ticket #36564</a>. Thanks to Tim for spotting that this cleanup was now possible, and to Jacob Walls and Clifford Gama for reviewing!</p></div></div><div id="template-variable-forloop-length"><h2>Template variable <code>forloop.length</code><a title="Permalink to this headline" href="#template-variable-forloop-length"></a></h2><p>Moving on to templates, let’s start with this nice little addition:</p><blockquote>The new variable forloop.length is now available within a for loop.</blockquote><p>This small extension makes it possible to write a template loop like this:</p><div><pre><span></span><span>&lt;</span><span>ul</span><span>&gt;</span>
  <span>{%</span> <span>for</span> <span>goose</span> <span>in</span> <span>geese</span> <span>%}</span>
    <span>&lt;</span><span>li</span><span>&gt;</span>
      <span>&lt;</span><span>strong</span><span>&gt;</span><span>{{</span> <span>forloop</span><span>.counter</span> <span>}}</span>/<span>{{</span> <span>forloop</span><span>.length</span> <span>}}</span><span>&lt;/</span><span>strong</span><span>&gt;</span>: <span>{{</span> <span>goose.name</span> <span>}}</span>
    <span>&lt;/</span><span>li</span><span>&gt;</span>
  <span>{%</span> <span>endfor</span> <span>%}</span>
<span>&lt;/</span><span>ul</span><span>&gt;</span>
</pre></div><p>Previously, you’d need to refer to the length in an another way, like <code>{{ geese|length }}</code>, which is a bit less flexible.</p><p>Thanks to Jonathan Ströbele for contributing this idea and implementation in <a href="https://code.djangoproject.com/ticket/36186">Ticket #36186</a>, and to David Smith, Paolo Melchiorre, and Sarah Boyce for reviewing.</p></div><div id="querystring-template-tag-enhancements"><h2><code>querystring</code> template tag enhancements<a title="Permalink to this headline" href="#querystring-template-tag-enhancements"></a></h2><p>There are two extensions to <a href="https://docs.djangoproject.com/en/stable/ref/templates/builtins/#django-template">the <code>querystring</code> template tag</a>, which was added in Django 5.1 to help with building links that modify the current request’s query parameters.</p><ol><li><p>Release note:</p> <blockquote><p>The <code>querystring</code> template tag now consistently prefixes the returned query string with a <code>?</code>, ensuring reliable link generation behavior.</p></blockquote> <p>This small change improves how the tag behaves when an empty mapping of query parameters are provided. Say you had a template like this:</p> <div><pre><span></span><span>&lt;</span><span>a</span> <span>href</span><span>=</span><span>"</span><span>{%</span> <span>querystring</span> <span>params</span> <span>%}</span><span>"</span><span>&gt;</span>Reset search<span>&lt;/</span><span>a</span><span>&gt;</span>
</pre></div> <p>…where <code>params</code> is a dictionary that may sometimes be empty. Previously, if <code>params</code> was empty, the output would be:</p> <div><pre><span></span><span>&lt;</span><span>a</span> <span>href</span><span>=</span><span>""</span><span>&gt;</span>Reset search<span>&lt;/</span><span>a</span><span>&gt;</span>
</pre></div> <p>Browsers treat this as a link to the same URL <em>including the query parameters</em>, so it would not clear the query parameters as intended. Now, with this change, the output will be:</p> <div><pre><span></span><span>&lt;</span><span>a</span> <span>href</span><span>=</span><span>"?"</span><span>&gt;</span>Reset search<span>&lt;/</span><span>a</span><span>&gt;</span>
</pre></div> <p>Browsers treat <code>?</code> as a link to the same URL <em>without any query parameters</em>, clearing them as the user would expect.</p> <p>Thanks to Django Fellow Sarah Boyce for spotting this improvement and implementing the fix in <a href="https://code.djangoproject.com/ticket/36268">Ticket #36268</a>, and for Django Fellow Natalia Bidart for reviewing!</p></li><li><p>Release note:</p> <blockquote><p>The <code>querystring</code> template tag now accepts multiple positional arguments, which must be mappings, such as <code>QueryDict</code> or <code>dict</code>.</p></blockquote> <p>This enhancement allows the tag to merge multiple sources of query parameters when building the output. For example, you might have a template like this:</p> <div><pre><span></span><span>&lt;</span><span>a</span> <span>href</span><span>=</span><span>"</span><span>{%</span> <span>querystring</span> <span>request.GET</span> <span>super_search_params</span> <span>%}</span><span>"</span><span>&gt;</span>Super search<span>&lt;/</span><span>a</span><span>&gt;</span>
</pre></div> <p>…where <code>super_search_params</code> is a dictionary of extra parameters to add to make the current search “super”. The tag merges the two mappings, with later mappings taking precedence for duplicate keys.</p> <p>Thanks again to Sarah Boyce for proposing this improvement in <a href="https://code.djangoproject.com/ticket/35529">Ticket #35529</a>, to Giannis Terzopoulos for implementing it, and to Natalia Bidart, Sarah Boyce, and Tom Carrick for reviewing!</p></li></ol></div><div id="fin"><h2>Fin<a title="Permalink to this headline" href="#fin"></a></h2><p>That’s a wrap! Thank you for reading my highlights. There are plenty more changes to read about in <a href="https://docs.djangoproject.com/en/stable/releases/6.0/">the release notes</a>.</p><p>Also, there are always many more behind-the-scenes improvements and bug fixes that don’t make it into the release notes. Optimizations and micro-improvements get merged all the time, so don’t delay, upgrade today!</p><p>Thank you to <strong>all 174 people</strong> who contributed to Django 6.0, as counted in <a href="https://gist.github.com/felixxm/99501cdbf6ed5a69295b4cb3f8c21d80">this list</a> by Mariusz Felisiak.</p><p>May your upgrade be swift, smooth, safe, and secure,</p><p>—Adam</p></div><hr><p>😸😸😸 Check out my new book on using GitHub effectively, <strong><a href="https://adamj.eu/tech/2025/11/11/boost-your-github-dx-out-now/">Boost Your GitHub DX</a></strong>! 😸😸😸</p><hr><p><small>One summary email a week, no spam, I pinky promise.</small></p><p><strong>Related posts:</strong></p><ul><li><a href="https://adamj.eu/tech/2025/04/07/django-whats-new-5.2/">Django: what’s new in 5.2</a></li></ul><p><strong>Tags:</strong> <a href="https://adamj.eu/tech/tag/django/" rel="tag">django</a></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Agentic AI Foundation (116 pts)]]></title>
            <link>https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation</link>
            <guid>46209846</guid>
            <pubDate>Tue, 09 Dec 2025 20:00:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation">https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation</a>, See on <a href="https://news.ycombinator.com/item?id=46209846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--[--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->An initiative to advance open source agentic AI under the Linux Foundation umbrella<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->Today, the industry is making a pivotal choice. Block, Anthropic, OpenAI, and other leaders in AI are launching the Agentic AI Foundation (AAIF) to ensure agentic AI develops as an open, collaborative ecosystem. Agentic AI refers to artificial intelligence systems that can take initiative, make decisions, and act independently to achieve goals with minimal human direction.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->The AAIF is a vendor-neutral home for open source agentic AI projects where no single company dominates, providing funding for critical community programs and research, and building open protocols that let systems from different builders work together seamlessly. Block is contributing its open source agent <!--]--><!--]--><!--[2--><!----><strong><!--[--><!--[2--><!----><!--[--><span><a href="https://block.github.io/goose/" target="_blank"><!--[--><!--[4--><!--[!-->goose<!--]--><!--]--><!--]--><!----><!----></a><!----></span><!--]--><!----><!--]--><!--[4--><!--[!--> <!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->to the AAIF, along with Anthropic’s <!--]--><!--]--><!--[2--><!----><!--[--><span><a href="https://modelcontextprotocol.io/docs/getting-started/intro" target="_blank"><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Model Context Protocol<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--]--><!----><!----></a><!----></span><!--]--><!----><!--]--><!--[4--><!--[!--> <!--]--><!--]--><!--[2--><!----><!--[--><span><a href="https://modelcontextprotocol.io/docs/getting-started/intro" target="_blank"><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->(MCP)<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--]--><!----><!----></a><!----></span><!--]--><!----><!--]--><!--[4--><!--[!--> and OpenAI’s <!--]--><!--]--><!--[2--><!----><!--[--><span><a href="http://agents.md/" target="_blank"><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->AGENTS.md<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--]--><!----><!----></a><!----></span><!--]--><!----><!--]--><!--[4--><!--[!-->.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->In addition to the three founding members, the AAIF’s platinum members include Amazon Web Services, Bloomberg, Cloudflare, Google, and MicrosoftI. Gold members of the AAIF include Adyen, Arcade.dev, Cisco, Datadog, Docker, Ericsson, IBM, JetBrains, Okta, Oracle, Runlayer, Salesforce, SAP, Shopify, Snowflake, Temporal, Tetrate, and Twilio Inc. Silver members of the AAIF include Apify, Chronosphere, Cosmonic, Elasticsearch, Eve Security, Hugging Face, Kubermatic, KYXStart, LanceDB, Mirantis, NinjaTech AI, Obot.ai, Prefect.io, Pydantic, Shinkai.com, Solo.io, Spectro Cloud, Stacklok, SUSE, Uber, WorkOS, Zapier and ZED.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->Why This Matters Now<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->AI systems represent one of the most significant technological shifts in decades. These systems are fundamentally reshaping how developers build software, how businesses operate, and how people solve complex problems. Use of autonomous agents promises to accelerate this even further.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->But we're at a critical juncture. We have an unprecedented opportunity to shape how this technology develops. Will we build open, interoperable infrastructure that serves everyone? Or will we see fragmentation that limits this powerful technology's potential? Without collaborative open development, we risk missing the full potential of agentic AI where everyone benefits thanks to open standards, open protocols, and open systems on which other tools are built. We also risk concentrating the power in the hands of a few, which dampers competition and restricts accessibility. In a proprietary, siloed ecosystem, breakthrough ideas can't easily build on each other, integration challenges slow enterprise adoption and limit use cases, accessibility barriers prevent smaller organizations from benefiting, and research limitations slow academic and independent innovation.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->History proves there’s a better path. The Internet, Linux, and the Web succeeded precisely because they were open. They empowered anyone with talent and determination to build, innovate, and create value on top of open infrastructure. Agentic AI deserves the same opportunity. We hope that the AAIF can become what the W3C is for the Web: a set of standards and protocols that guarantee interoperability, open access, and freedom of choice with open source reference implementations.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->What AAIF Will Do<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->The Agentic AI Foundation provides a neutral home where companies, researchers, and independent developers can collaborate on open source agentic AI.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->Following the Linux Foundation's trusted governance model, AAIF will operate on several core principles:<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Open Governance<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->: AAIF operates under a transparent and inclusive governance model where contributors from all backgrounds are empowered to shape the direction of the foundation and its projects. Decisions, policies, and criteria are open and accessible to members.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->AI Innovation<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->: AAIF encourages agentic AI innovation and exploration from a diverse and collaborative ecosystem of open source developers, researchers, and practitioners. We move at the speed of AI, keeping governance small and responsive.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Sustainability and Neutrality<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->: AAIF provides neutral infrastructure and funding mechanisms to ensure long-term sustainability of projects. Project inclusion is based on demonstrated adoption, quality, and community health - not how well funded it may be.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Focused, not broad:<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!--> The AAIF exists to further open source agentic AI - not to cover all of open source AI, machine learning, or data science.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->Founding Projects<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->AAIF launches with contributions from Block, Anthropic, and OpenAI:<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->goose<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->, Block's open source agentic AI framework, will transition to community governance under AAIF. Since its release earlier this year, goose has become a reference implementation for Anthropic's Model Context Protocol (MCP) and has attracted thousands of developers worldwide. Under AAIF, goose will maintain its open source license and commercial-friendly terms while gaining the benefits of neutral governance and broader community input.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Model Context Protocol (MCP)<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->, developed by Anthropic, is an open protocol that enables seamless integration between AI systems and external data sources, providing a standardized way for AI agents to access context. MCP demonstrates AAIF's potential as the neutral hub for cross-industry agentic AI standards. From MCP’s very first release, Block engineers have been active <!--]--><!--]--><!--[2--><!----><!--[--><span><a href="https://github.com/modelcontextprotocol/modelcontextprotocol/commit/e0b586c65748e99cd7f2fe086329061dde67989c" target="_blank"><!--[--><!--[4--><!--[!-->contributors<!--]--><!--]--><!--]--><!----><!----></a><!----></span><!--]--><!----><!--]--><!--[4--><!--[!-->, and several continue to participate as members of the MCP steering committee.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->AGENTS.md<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->, developed by OpenAI, is an open format for guiding coding agents. It is used by more than 20,000 open source projects and serves as a README for agents: a dedicated, predictable place to provide the context and instructions to help AI coding agents work on projects.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->Additional projects from other member organizations have been proposed and are being evaluated to join, and will be selected based on demonstrated adoption, strong governance, and alignment with AAIF's mission to advance open source agentic AI.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->How to Get Involved<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->AAIF succeeds only if it truly represents the community. Whether you're a developer, researcher, company, or simply someone who believes AI should be open, there are multiple ways to participate:<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Contribute to projects<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->: All AAIF projects welcome community contributions. Check project repositories for contribution guidelines and good first issues.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Join the conversation<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!--> &amp; <!--]--><!--]--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->propose new projects: <!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->Have an agentic AI project that could benefit from neutral governance, foundation support, collaboration with leaders in agentic AI, and more visibility? Projects that promote the agentic AI ecosystem, operate under OSI-approved open source licenses, demonstrate open governance, and foster community growth are welcome to apply. For more information about the AAIF and how to become a member, please visit AAIF.io.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[2--><!----><strong><!--[--><!--[4--><!--[!-->Attend events<!--]--><!--]--><!--]--><!----><!----></strong><!----><!--]--><!--[4--><!--[!-->: Participate in AAIF-sponsored conferences, hackathons, and meetups to connect with the community and learn about the latest developments.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->The foundation's governance structure ensures that community voices matter, not just corporate interests. Technical decisions will be made by project maintainers and steering committees, with AAIF providing resources and neutral oversight.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->Building the Future Together<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->The next decade of AI development will be defined by choices we make today. By establishing the AAIF, the industry is making a clear statement: agentic AI will be open, accessible, and community-driven. The world has repeatedly proven that open collaboration produces better outcomes than competition in isolation. The AAIF provides the structure for that open collaboration to flourish in agentic AI.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->This isn't just about technology: it's about values. It's about ensuring that powerful tools serve everyone. It's about creating an ecosystem where the best ideas win, regardless of where they come from.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><p><span><!--[--><!--[4--><!--[!-->The future is being written in the open. Join us.<!--]--><!--]--><!--]--><!----><!----><!----></span><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><!----><!--]--><!--[3--><!----><p><!----><h5><!--[--><!--[4--><!--[!-->Learn more and get involved:<!--]--><!--]--><!--]--><!----><!----><!----></h5><!----><!----></p><!----><!--]--><!--[3--><!----><!----><!--]--><!--[5--><!----><!--[--><!--[--><!--]--><!--]--><!----><!--]--><!--]--><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[10 Years of Let's Encrypt (756 pts)]]></title>
            <link>https://letsencrypt.org/2025/12/09/10-years</link>
            <guid>46208962</guid>
            <pubDate>Tue, 09 Dec 2025 18:54:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2025/12/09/10-years">https://letsencrypt.org/2025/12/09/10-years</a>, See on <a href="https://news.ycombinator.com/item?id=46208962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>On September 14, 2015, <a href="https://crt.sh/?id=9314793">our first publicly-trusted certificate</a> went live. We were proud that we had issued a certificate that a significant majority of clients could accept, and had done it using <a href="https://github.com/letsencrypt/boulder">automated software</a>. Of course, in retrospect this was just the first of billions of certificates. Today, Let’s Encrypt is the largest certificate authority in the world in terms of certificates issued, the ACME protocol we helped create and standardize is integrated throughout the server ecosystem, and we’ve become a household name among system administrators. We’re closing in on protecting one billion web sites.</p>
<p><a href="https://letsencrypt.org/stats/"><img src="https://letsencrypt.org/images/blog/blog-2025-12-09-chart1.jpg" alt=""></a></p>
<p>In 2023, we marked the <a href="https://www.abetterinternet.org/tenth-anniversary/">tenth anniversary of the creation of our nonprofit</a>, Internet Security Research Group, which continues to host Let’s Encrypt and other public benefit infrastructure projects. Now, in honor of the tenth anniversary of Let’s Encrypt’s public certificate issuance and the start of the general availability of our services, we’re looking back at a few milestones and factors that contributed to our success.</p>
<h2 id="growth">Growth</h2>
<p>A conspicuous part of Let’s Encrypt’s history is how thoroughly our vision of scalability through automation has succeeded.</p>
<p>In March 2016, we issued our one millionth certificate. Just two years later, in September 2018, we were issuing a million certificates every day. In 2020 we reached a billion total certificates issued and as of late 2025 we’re frequently issuing ten million certificates per day. We’re now on track to reach a billion active sites, probably sometime in the coming year. (The “certificates issued” and “certificates active” metrics are quite different because our certificates regularly expire and get replaced.)</p>
<p>The steady growth of our issuance volume shows the strength of our architecture, the validity of our vision, and the great efforts of our engineering team to scale up our own infrastructure. It also reminds us of the confidence that the Internet community is placing in us, making the use of a Let’s Encrypt certificate a normal and, dare we say, boring choice. But I often point out that our ever-growing issuance volumes are only an indirect measure of value. What ultimately matters is improving the security of people’s use of the web, which, as far as Let’s Encrypt’s contribution goes, is not measured by issuance volumes so much as by the prevalence of HTTPS encryption. For that reason, we’ve always emphasized the graph of the percentage of encrypted connections that web users make (here represented by statistics from Firefox).</p>
<p><a href="https://letsencrypt.org/stats/"><img src="https://letsencrypt.org/images/blog/blog-2025-12-09-chart2.jpg" alt=""></a></p>
<p>(These graphs are snapshots as of the date of this post; a dynamically updated version is found <a href="https://letsencrypt.org/stats/#percent-pageloads">on our stats page</a>.) Our biggest goal was to make a concrete, measurable security impact on the web by getting HTTPS connection prevalence to increase—and it’s worked. It took five years or so to get the global percentage from below 30% to around 80%, where it’s remained ever since. In the U.S. it has been close to 95% for a while now.</p>
<p>A good amount of the remaining unencrypted traffic probably comes from internal or private organizational sites (intranets), but other than that we don’t know much about it; this would be a great topic for Internet security researchers to look into.</p>
<p>We believe our present growth in certificate issuance volume is essentially coming from growth in the web as a whole. In other words, if we protect 20% more sites over some time period, it’s because the web itself grew by 20%.</p>
<h2 id="a-few-milestones">A few milestones</h2>
<p>We’ve <a href="https://letsencrypt.org/blog/">blogged about most of Let’s Encrypt’s most significant milestones</a> as they’ve happened, and I invite everyone in our community to look over those blog posts to see how far we’ve come. We’ve also <a href="https://www.abetterinternet.org/annual-reports/">published annual reports for the past seven years</a>, which offer elegant and concise summaries of our work.</p>
<p>As I personally think back on the past decade, just a few of the many events that come to mind include:</p>
<ul>
<li>
<p><a href="https://letsencrypt.org/2014/11/18/announcing-lets-encrypt">Telling the world about the project</a> in November 2014</p>
</li>
<li>
<p><a href="https://letsencrypt.org/2015/09/14/our-first-cert">Our first certificate issuance</a> in September 2015</p>
</li>
<li>
<p><a href="https://letsencrypt.org/2016/03/08/our-millionth-cert">Our one millionth certificate</a> in March 2016, then <a href="https://letsencrypt.org/2017/06/28/hundred-million-certs">our 100 millionth certificate</a> in June 2017, and then <a href="https://letsencrypt.org/2020/02/27/one-billion-certs">our billionth certificate</a> in 2020</p>
</li>
<li>
<p>Along the way, first issuing one million certificates in a single day (in September 2018), significantly contributed to by the SquareSpace and <a href="https://letsencrypt.org/2021/09/14/speed-at-scale-shopify">Shopify</a> Let’s Encrypt integrations</p>
</li>
<li>
<p>Just at the end of September 2025, we issued more than ten million certificates in a day for the first time.</p>
</li>
</ul>
<p>We’ve also periodically rolled out new features such as <a href="https://letsencrypt.org/2016/10/21/introducing-idn-support">internationalized domain name support</a> (2016), <a href="https://letsencrypt.org/2017/07/06/wildcard-certificates-coming-jan-2018">wildcard support</a> (2018), and <a href="https://letsencrypt.org/2025/02/20/first-short-lived-cert-issued">short-lived</a> and <a href="https://letsencrypt.org/2025/07/01/issuing-our-first-ip-address-certificate">IP address</a> (2025) certificates. We’re always working on <a href="https://letsencrypt.org/upcoming-features/">more new features</a> for the future.</p>
<p>There are many technical milestones like <a href="https://letsencrypt.org/2021/01/21/next-gen-database-servers">our database server upgrades</a> in 2021, where we found we needed a serious server infrastructure boost because of the tremendous volumes of data we were dealing with. Similarly, our original infrastructure was using Gigabit Ethernet internally, and, with the growth of our issuance volume and logging, we found that our Gigabit Ethernet network eventually became too slow to synchronize database instances! (Today we’re using 25-gig Ethernet.) More recently, we’ve <a href="https://letsencrypt.org/2025/06/11/reflections-on-a-year-of-sunlight">experimented with architectural upgrades</a> to our ever-growing Certificate Transparency logs, and <a href="https://letsencrypt.org/2025/08/14/rfc-6962-logs-eol">decided to go ahead with deploying those upgrades</a>—to help us not just keep up with, but get ahead of, our continuing growth.</p>
<p>These kinds of growing pains and successful responses to them are nice to remember because they point to the inexorable increase in demands on our infrastructure as we’ve become a more and more essential part of the Internet. I’m proud of our technical teams which have handled those increased demands capably and professionally.</p>
<p>I also recall the ongoing work involved in <a href="https://letsencrypt.org/2018/08/06/trusted-by-all-major-root-programs">making sure our certificates would be as widely accepted as possible</a>, which has meant managing the original cross-signature from IdenTrust, and <a href="https://letsencrypt.org/2020/11/06/own-two-feet">subsequently creating and propagating our own root CA certificates</a>. This process has required PKI engineering, key ceremonies, root program interactions, documentation, and community support associated with certificate migrations. Most users never have reason to look behind the scenes at <a href="https://letsencrypt.org/certificates/">our chains of trust</a>, but our engineers update it as root and intermediate certificates have been replaced. We’ve engaged at the <a href="https://cabforum.org/">CA/B Forum</a>, <a href="https://www.ietf.org/">IETF</a>, and in other venues with the browser root programs to help shape the web PKI as a technical leader.</p>
<p><a href="https://letsencrypt.org/2020/12/28/executive-director-letter">As I wrote in 2020</a>, our ideal of complete automation of the web PKI aims at a world where most site owners wouldn’t even need to think about certificates at all. We continue to get closer and closer to that world, which creates a risk that people will take us and our services for granted, as the details of certificate renewal occupy less of site operators’ mental energy. As I said at the time,</p>
<p>When your strategy as a nonprofit is to get out of the way, to offer services that people don’t need to think about, you’re running a real risk that you’ll eventually be taken for granted. There is a tension between wanting your work to be invisible and the need for recognition of its value. If people aren’t aware of how valuable our services are then we may not get the support we need to continue providing them.</p>
<p>I’m also grateful to our communications and fundraising staff who help make clear what we’re doing every day and how we’re making the Internet safer.</p>
<h2 id="recognition-of-let-s-encrypt">Recognition of Let’s Encrypt</h2>
<p>Our community continually recognizes our work in tangible ways by using our certificates—now by the tens of millions per day—and by <a href="https://www.abetterinternet.org/sponsor/">sponsoring us</a>.</p>
<p>We were honored to be recognized with awards including the <a href="https://rwc.iacr.org/LevchinPrize/winners.html#certs">2022 Levchin Prize for Real-World Cryptography</a> and the <a href="https://www.abetterinternet.org/documents/2019-ISRG-Annual-Report-Desktop.pdf">2019 O’Reilly Open Source Award</a>. In October of this year some of the individuals who got Let’s Encrypt started were honored to receive the <a href="https://secdev.ieee.org/2025/awardees/">IEEE Cybersecurity Award for Practice</a>.</p>
<p>We documented the history, design, and goals of the project in <a href="https://dl.acm.org/doi/abs/10.1145/3319535.3363192">an academic paper at the ACM CCS ‘19 conference</a>, which has subsequently been cited hundreds of times in academic research.</p>

<p>Ten years later, I’m still deeply grateful to the five initial sponsors that got Let’s Encrypt off the ground - Mozilla, EFF, Cisco, Akamai, and IdenTrust. When they committed significant resources to the project, it was just an ambitious idea. They saw the potential and believed in our team, and because of that we were able to build the service we operate today.</p>
<h2 id="identrust-a-critical-technical-partner">IdenTrust: A critical technical partner</h2>
<p>I’d like to particularly recognize <a href="https://www.identrust.com/">IdenTrust</a>, a PKI company that worked as a partner from the outset and enabled us to issue publicly-trusted certificates via a cross-signature from one of their roots. We would simply not have been able to launch our publicly-trusted certificate service without them. Back when I first told them that we were starting a new nonprofit certificate authority that would give away millions of certificates for free, there wasn’t any precedent for this arrangement, and there wasn’t necessarily much reason for IdenTrust to pay attention to our proposal. But the company really understood what we were trying to do and was willing to engage from the beginning. Ultimately, IdenTrust’s support made our original issuance model a reality.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I’m proud of what we have achieved with our staff, partners, and donors over the past ten years. I hope to be even more proud of the next ten years, as we use our strong footing to continue to pursue our mission to protect Internet users by lowering monetary, technological, and informational barriers to a more secure and privacy-respecting Internet.</p>
<p>Let’s Encrypt is a project of the nonprofit Internet Security Research Group, a 501(c)(3) nonprofit. You can help us make the next ten years great as well by <a href="http://letsencrypt.org/donate">donating</a> or becoming a <a href="https://www.abetterinternet.org/sponsor/">sponsor</a>.</p>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you want to speak at software conferences? (219 pts)]]></title>
            <link>https://dylanbeattie.net/2025/12/08/so-you-want-to-speak-at-software-conferences.html</link>
            <guid>46208773</guid>
            <pubDate>Tue, 09 Dec 2025 18:42:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dylanbeattie.net/2025/12/08/so-you-want-to-speak-at-software-conferences.html">https://dylanbeattie.net/2025/12/08/so-you-want-to-speak-at-software-conferences.html</a>, See on <a href="https://news.ycombinator.com/item?id=46208773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
					<article>
						
						
						<p>I run a <a href="https://ldnug.org/">.NET user group here in London</a>, and we host a lot of talks from people who are relatively inexperienced presenters. Sometimes they’ve done presentations internally but never spoken before a public audience. Sometimes they’re developers who have been in theatre or played in bands; people with plenty of stage experience but who haven’t presented on technical topics before - and sometimes they’ve never done any kind of public presentations or performance at all. We aim to be a friendly, supportive crowd; public speaking can be daunting, and the first public outing of somebody’s first talk can be… let’s just say that the presenter sometimes learns a lot more than the audience, and leave it at that.</p>

<p>But it can also be a hugely rewarding experience, and as a seasoned tech presenter who’s been doing this for a while, aspiring speakers often ask me for advice on how to take it to the next level.</p>

<p>Before we get into the specifics, there are two things to bear in mind.</p>

<p>One: ask yourself why you want to do this. What does “the next level” mean for you? Are you looking to promote your consultancy, or your training courses, or your software products? Do you want to become a professional speaker and actually get paid to give talks? Are you doing it ‘cos you want to go places and meet people? Figure out what “success” looks like for you.</p>

<p>Two: be realistic about how much work is involved. It took me <em>seven years</em> to go from my first user group lightning talk, back 2008, to my first international conference. If you think you can hack together some code, write a talk about it, stick it on Sessionize and three months later you’re on your way to a major international event like NDC or Yow! or Devoxx… well, no. That’s not how this works. Strap in; it’s a long ride.</p>

<h3 id="year-1-get-good">Year 1: Get Good</h3>

<p>Write the talk. Write a talk nobody else could do; tell a story nobody else can tell. Figure out what your audience is going to learn, and why you’re the best person to teach them that. Then give it at local user group. It might go great. It might be a train wreck. Don’t worry. That’s one of the reasons user groups exist. Learn from the experience. Fix the demos. Fix the slides. If it was too short? Write some more. If it was too long? Cut something. Give it at another user group. Do it again. Do it again. Maybe write a second talk, shop that one around a couple of user groups too.</p>

<p>If you can’t find user groups, look on Meetup.com. Yes, it’s a horrible platform, but it works; search by topic, search by region, find groups that look like a good match for your content, and ask if they’re looking for speakers. They probably are.</p>

<h3 id="year-2-get-seen">Year 2: Get Seen</h3>

<p>After user groups and meetups come the community conferences. Typically small, one-day events, with a few tracks, and usually free (or very cheap) to attend. For me, these were <a href="https://en.wikipedia.org/wiki/Developer!/_Developer!/_Developer!#External\_links">the DDD events</a> _(that’s DDD as in Developers! Developers! Developers!, not to be confused with DDD as in Domain Driven Design), _a series of one-day free developer events around the UK, organised by volunteers, usually on a Saturday so people don’t have to take time off work. They bring in a good crowd, they’re a great way to get to know other presenters and people who are involved in tech events, and you’ll almost certainly meet a few people who are on the programme committees for the bigger conferences.</p>

<p>Events like this are your chance to get noticed. Turn up the day before, join the pre-conference dinner and drinks, introduce yourself. Yeah, it’s awkward when you don’t know anybody. There will be other people there who don’t know anybody and will appreciate you making the effort. Enjoy yourself, but don’t end up doing tequila shots in a karaoke bar at 3am. Not now. You’re there to give a talk, remember?</p>

<p>Go to the event. Spend the whole day there, do your talk, watch the other sessions. Communicate with the organisers. You don’t want their memorable impression of you to be a half-hour of panic and missed calls because one of their speakers has gone AWOL and nobody knows where they are.</p>

<p>Figure out how to keep in touch with the people you met. Join the Signal or WhatsApp group chat; if there isn’t one, create one. Follow them on LinkedIn, or Bluesky - be prepared to go where people are; don’t expect folks to join Mastodon just because that’s where you want to talk to them. That’s not how this works. If you really don’t want to play the social media game - and I can’t blame you - there’s always good old-fashioned email. A short email a week later saying “hey, thanks for having me” or “hey, I loved your session at DDD, let’s keep in touch” can pay off in a big way.</p>

<p>Finally, watch out for events that put video of their sessions online. Having a couple of YouTube links of you doing your thing in front of a live, appreciate audience can make all the difference when a programme committee is looking at a handful of talks and can only accept one of them.</p>

<h3 id="year-3-get-accepted">Year 3: Get Accepted</h3>

<p>You’ve got a couple of talks. You’ve delivered then enough times that you know they’re good *(and if they’re not good, make them good - or scrap them and write new ones)*. You know people. People know you. If somebody asks “hey, do we know anybody who could do a good session about $topic”, your name comes up. You’ve got a decent network of connections - group chats, LinkedIn, email addresses.</p>

<p>Now, find all the conferences in your field with an open Call for Papers (CfP), and get submitting. Dave Aronson over at codeasaur.us maintains a really useful <a href="https://www.codosaur.us/speaking/cfps-ending-soon">list of CfPs which are closing soon</a>. Check that regularly. Many events will cover your travel &amp; hotel costs, although with sponsorship budgets drying up right across the industry that’s not as prevalent as it was a few years ago. If not, maybe you can persuade your employer to pay your travel - “hey, boss, if I can get a free ticket to this amazing conference with all these industry experts, do you think the company will pay my air fare &amp; hotel?”</p>

<p>Lean on your network. What are people submitting to? Which events should you look out for? Which topics are getting a lot of traction (and which topics are not?)</p>

<p>Keep your content fresh. Write new talks. Keep giving them at user groups and community events.</p>

<p>Keep your submissions focused. 2-3 talks per event; don’t submit ten wildly different abstracts to the same conference in the hope one of them will get accepted. Every selection committee I’ve been on, if we see that, we assume the presenter hasn’t actually written *any* of them yet and is throwing everything they can think of into the mix and hoping one of them gets chosen. Not a great way to stand out. An open CFP at a big tech conference typically gets 20+ submissions for every available slot, which means if you reduce it to a numbers game, you’re submitting 20 talks for every one that gets accepted. Keep track of the numbers, and be objective about it.</p>

<h3 id="year-4-get-bored">Year 4: Get Bored.</h3>

<p>It’s great fun doing this for a while… but it’s also exhausting. Some people hit it hard for a few years, do all the things, go to all the places, make a lot of great friends and happy memories, and then wake up one day and decide that’s enough. Some people do a few talks, tick it off their bucket list and decide that’s enough for them. Some settle into a gentle routine of 3-4 events they’ll do every year. And yes, some of us end up treating our calendars like a game of Tetris, juggling flights and trains and hotels and meetups and conferences and spending half the year on the road and the other half writing talks and workshops and all the other things it’s hard to do when you’re at the airport.</p>

<p>That’s why you gotta figure out ahead of time what “success” looks like. If you’re doing it for fun, remember to have fun - and if you find you’re not enjoying it any more? Stop. If you’re doing it as promotion or marketing? Track your leads. Make sure it’s actually generating the attention and the revenue it’s supposed to. If you’re doing it for money, be mercenary: no pay, no play. Not every event is the same, of course. In a given year I’ll have some events that are fun, some that are lucrative, some that are running alongside workshops or training engagements. Just make sure you know which is which.</p>

<p>Finally: respect your audience. Whether you’re talking to five people at a meetup, fifty at a community event, or five thousand at a huge international conference: those people are the reason you get to do this. They have given up their time - and often a substantial amount of money - to hear what you have to say. They deserve your best shot, every time. If you find you’re bored, fed up, tired, running talks on autopilot or making mistakes because you just don’t care? It’s time to try something else - and remember, there’s a thousand aspiring speakers out there who would dearly love to take that spot instead of you.</p>

<p>Now get out there. Work hard, have fun, teach us awesome things, and if you ever want me to look over an abstract or a slide deck, drop me a line - <a href="https://dylanbeattie.net/cdn-cgi/l/email-protection#8aeef3e6ebe4caeef3e6ebe4e8efebfefee3efa4e4effe"><span data-cfemail="c8acb1a4a9a688acb1a4a9a6aaada9bcbca1ade6a6adbc">[email&nbsp;protected]</span></a>. I’d be happy to help.</p>

					</article>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The stack circuitry of the Intel 8087 floating point chip, reverse-engineered (130 pts)]]></title>
            <link>https://www.righto.com/2025/12/8087-stack-circuitry.html</link>
            <guid>46208409</guid>
            <pubDate>Tue, 09 Dec 2025 18:16:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2025/12/8087-stack-circuitry.html">https://www.righto.com/2025/12/8087-stack-circuitry.html</a>, See on <a href="https://news.ycombinator.com/item?id=46208409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1883798277085402615" itemprop="description articleBody">
<p>Early microprocessors were very slow when operating with floating-point numbers.
But in 1980, Intel introduced the 8087 floating-point coprocessor, performing
floating-point operations up
to 100 times faster.
This was a huge benefit for IBM PC
applications such as AutoCAD, spreadsheets, and flight simulators.
The 8087 was so effective that today's computers still use a floating-point system based on the 8087.<span id="fnref:ieee-754"><a href="#fn:ieee-754">1</a></span></p>
<!--
It's hard to compute floating-point operations both quickly and accurately.
Problems can arise from overflow, rounding, transcendental operations, and numerous edge cases.
Prior to the 8087, each manufacturer had their own incompatible ad hoc implementation of floating point.
Intel, however, enlisted numerical analysis expert [William Kahan](https://en.wikipedia.org/wiki/William_Kahan) to design accurate floating point
based on rigorous principles.
    The 8087 has its problems, but it was a large improvement on earlier floating-point systems.
    The designers of the 8087 commented on the guidance offered by Professor Kahan: "We did not do as well as he wanted, but we did better than he expected."
-- The 8087 Primer, page viii
-->

<p>The 8087 was an extremely complex chip for its time, containing somewhere between
40,000 and 75,000 transistors, depending on the source.<span id="fnref:count"><a href="#fn:count">2</a></span>
To explore how the 8087 works, I opened up a chip and took numerous photos of the silicon die with a microscope.
Around the edges of the die, you can see the hair-thin bond wires that connect the chip to its 40 external pins.
The complex patterns on the die are formed by its metal wiring, as well as the polysilicon and silicon underneath.
The bottom half of the chip is the "datapath", the circuitry that performs calculations on 80-bit floating point values. 
At the left of the datapath, a <a href="https://www.righto.com/2020/05/extracting-rom-constants-from-8087-math.html">constant ROM</a> holds important constants such as π.
At the right are the eight registers that form the stack, along with the stack control circuitry.</p>
<p><a href="https://static.righto.com/images/8087-stack/8087-die-labeled.jpg"><img alt="Die of the Intel 8087 floating point unit chip, with main functional blocks labeled. The die is 5mm×6mm.  Click for a larger image." height="587" src="https://static.righto.com/images/8087-stack/8087-die-labeled-w450.jpg" title="Die of the Intel 8087 floating point unit chip, with main functional blocks labeled. The die is 5mm×6mm.  Click for a larger image." width="450"></a></p><p>Die of the Intel 8087 floating point unit chip, with main functional blocks labeled. The die is 5mm×6mm.  Click for a larger image.</p>
<p>The chip's instructions are defined by the large <a href="https://www.righto.com/2018/09/two-bits-per-transistor-high-density.html">microcode ROM</a> in the middle.
This ROM is very unusual; it is semi-analog, storing two bits per transistor by using four transistor sizes.
To execute a floating-point instruction, the 8087 decodes the instruction and the microcode engine starts executing
the appropriate micro-instructions from the microcode ROM.
The decode circuitry to the right of the ROM generates the appropriate control signals from each micro-instruction.
The bus registers and control circuitry handle interactions with the main 8086 processor and the rest of the system.
Finally, the <a href="https://www.righto.com/2018/08/inside-die-of-intels-8087-coprocessor.html">bias generator</a>
uses a charge pump to create a negative voltage to bias the chip's substrate, the underlying silicon.</p>
<p>The stack registers and control circuitry (in red above) are the subject of this blog post. 
Unlike most processors, the 8087 organizes its registers in a stack, with instructions operating on the top of the stack.
For instance, the square root instruction replaces the value on the top of the stack with its square root.
You can also access a register relative to the top of the stack, for instance, adding the top value to the value two positions down from the top.
The stack-based architecture was intended to improve the instruction set, simplify compiler design, and make function
calls more efficient, although it didn't work as well as hoped.</p>
<p><a href="https://static.righto.com/images/8087-stack/stack-diagram.jpg"><img alt="The stack on the 8087. From The 8087 Primer, page 60." height="204" src="https://static.righto.com/images/8087-stack/stack-diagram-w350.jpg" title="The stack on the 8087. From The 8087 Primer, page 60." width="350"></a></p><p>The stack on the 8087. From <i>The 8087 Primer</i>, page 60.</p>
<p>The diagram above shows how the stack operates. The stack consists of eight registers, with the Stack Top
(ST) indicating the current top of the stack.
To push a floating-point value onto the stack, the Stack Top is decremented and then the value is stored in the new top register.
A pop is performed by copying the value from the stack top and then incrementing the Stack Top.
In comparison, most processors specify registers directly, so register 2 is always the same register.</p>
<h2>The registers</h2>
<p>The stack registers occupy a substantial area on the die of the 8087 because floating-point numbers take many bits.
A floating-point number consists of a fractional part (sometimes called the mantissa or significand), along with
the exponent part; the exponent allows floating-point numbers to cover a range from extremely small to extremely
large.
In the 8087, floating-point numbers are 80 bits: 64 bits of significand, 15 bits of exponent, and a sign bit.
An 80-bit register was very large in the era of 8-bit or 16-bit computers; the eight registers in the 8087
would be equivalent to 40 registers in the 8086 processor.</p>
<p><a href="https://static.righto.com/images/8087-stack/registers.jpg"><img alt="The registers in the 8087 form an 8×80 grid of cells. The close-up shows an 8×8 block. I removed the metal layer with acid to reveal the underlying silicon circuitry." height="684" src="https://static.righto.com/images/8087-stack/registers-w500.jpg" title="The registers in the 8087 form an 8×80 grid of cells. The close-up shows an 8×8 block. I removed the metal layer with acid to reveal the underlying silicon circuitry." width="500"></a></p><p>The registers in the 8087 form an 8×80 grid of cells. The close-up shows an 8×8 block. I removed the metal layer with acid to reveal the underlying silicon circuitry.</p>
<p>The registers store each bit in a static RAM cell. Each cell has two inverters connected in a loop.
This circuit forms a stable feedback loop, with one inverter on and one inverter off.
Depending on which inverter is on, the circuit stores a 0 or a 1.
To write a new value into the circuit, one of the lines is pulled low, flipping the loop into the desired state.
The trick is that each inverter uses a very weak transistor to pull the output high, so its output is easily overpowered
to change the state.</p>
<p><a href="https://static.righto.com/images/8087-stack/inverter-loop.png"><img alt="Two inverters in a loop can store a 0 or a 1." height="121" src="https://static.righto.com/images/8087-stack/inverter-loop-w250.png" title="Two inverters in a loop can store a 0 or a 1." width="250"></a></p><p>Two inverters in a loop can store a 0 or a 1.</p>
<p>These inverter pairs are arranged in an 8 × 80 grid that implements eight words of 80 bits. Each of the 80 rows has two <em>bitlines</em> that provide access to a bit.
The bitlines provide both read and write access to a bit; the pair of bitlines allows either inverter to be pulled low to store the desired bit value.
Eight vertical <em>wordlines</em> enable access to one word, one column of 80 bits.
Each wordline turns on 160 pass transistors, connecting the bitlines to the inverters in the selected column.
Thus, when a wordline is enabled, the bitlines can be used to read or write that word.</p>
<p>Although the chip looks two-dimensional, it actually consists of multiple layers.
The bottom layer is silicon.
The pinkish regions below are where the silicon has been "doped" to change its electrical properties, making it an active
part of the circuit.
The doped silicon forms a grid of horizontal and vertical wiring, with larger doped regions in the middle.
On top of the silicon, polysilicon wiring provides two functions. First, it provides a layer of wiring to connect the circuit.
But more importantly, when polysilicon crosses doped silicon, it forms a transistor. The polysilicon provides the gate, turning the transistor on and off.
In this photo, the polysilicon is barely visible, so I've highlighted part of it in red.
Finally, horizontal metal wires provide a third layer of interconnecting wiring.
Normally, the metal hides the underlying circuitry, so I removed the metal with acid for this photo.
I've drawn blue lines to represent the metal layer.
Contacts provide connections between the various layers.</p>
<p><a href="https://static.righto.com/images/8087-stack/memory-cell-layers.jpg"><img alt="A close-up of a storage cell in the registers. The metal layer and most of the polysilicon have been removed to show the underlying silicon." height="336" src="https://static.righto.com/images/8087-stack/memory-cell-layers-w500.jpg" title="A close-up of a storage cell in the registers. The metal layer and most of the polysilicon have been removed to show the underlying silicon." width="500"></a></p><p>A close-up of a storage cell in the registers. The metal layer and most of the polysilicon have been removed to show the underlying silicon.</p>
<p>The layers combine to form the inverters and selection transistors of a memory cell, indicated with the dotted line below.
There are six transistors (yellow), where polysilicon crosses doped silicon. Each inverter has a transistor that
pulls the output low and a weak transistor to pull the output high.
When the word line (vertical polysilicon) is active, it connects the selected inverters to the bit lines (horizontal metal) through the two selection
transistors.
This allows the bit to be read or written.</p>
<p><a href="https://static.righto.com/images/8087-stack/memory-cell-labeled.jpg"><img alt="The function of the circuitry in a storage cell." height="303" src="https://static.righto.com/images/8087-stack/memory-cell-labeled-w500.jpg" title="The function of the circuitry in a storage cell." width="500"></a></p><p>The function of the circuitry in a storage cell.</p>
<p>Each register has two tag bits associated with it, an unusual form of metadata to indicate
if the register is empty, contains zero, contains a valid value, or
contains a special value such as infinity.
The tag bits are used to optimize performance internally and are mostly irrelevant to the programmer.
As well as being accessed with a register, the tag bits can be accessed in parallel as a 16-bit "Tag Word".
This allows the tags to be saved or loaded as part of the 8087's state, for instance,
during interrupt handling.</p>
<h2>The decoder</h2>
<p>The decoder circuit, wedged into the middle of the register file, selects one of the registers.
A register is specified internally with a 3-bit value. The decoder circuit energizes one of the eight register select
lines based on this value.</p>
<p>The decoder circuitry is straightforward: it has eight 3-input NOR gates to match one of the eight bit patterns.
The select line is then powered through a high-current driver that uses large transistors.
(In the photo below, you can compare the large serpentine driver transistors to the small transistors in a bit cell.)</p>
<p><a href="https://static.righto.com/images/8087-stack/decoder.jpg"><img alt="The decoder circuitry has eight similar blocks to drive the eight select lines." height="273" src="https://static.righto.com/images/8087-stack/decoder-w600.jpg" title="The decoder circuitry has eight similar blocks to drive the eight select lines." width="600"></a></p><p>The decoder circuitry has eight similar blocks to drive the eight select lines.</p>
<p>The decoder has an interesting electrical optimization.
As shown earlier, the register select lines are eight polysilicon lines running vertically, the length of the
register file. 
Unfortunately, polysilicon has fairly high resistance, better than silicon but much worse than metal.
The problem is that the resistance of a long polysilicon line will slow down the system.
That is, the capacitance of transistor gates in combination with high resistance causes an RC (resistive-capacitive) delay in the signal.</p>
<p>The solution is that the register select lines also run in the metal layer, a second set of lines immediately to the
right of the register file.
These lines branch off from the register file about 1/3 of the way down, run to the bottom, and then connect back
to the polysilicon select lines at the bottom.
This reduces the maximum resistance through a select line, increasing the speed.</p>
<p><a href="https://static.righto.com/images/8087-stack/select.jpg"><img alt="A diagram showing how 8 metal lines run parallel to the main select lines. The register file is much taller than shown; the middle has been removed to make the diagram fit." height="419" src="https://static.righto.com/images/8087-stack/select-w300.jpg" title="A diagram showing how 8 metal lines run parallel to the main select lines. The register file is much taller than shown; the middle has been removed to make the diagram fit." width="300"></a></p><p>A diagram showing how 8 metal lines run parallel to the main select lines. The register file is much taller than shown; the middle has been removed to make the diagram fit.</p>
<h2>The stack control circuitry</h2>
<p>A stack needs more control circuitry than a regular register file, since the circuitry must keep track of the
position of the top of the stack.<span id="fnref:status-word"><a href="#fn:status-word">3</a></span>
The control circuitry increments and decrements the top of stack (TOS) pointer as values are pushed or popped
(purple).<span id="fnref:patents"><a href="#fn:patents">4</a></span>
Moreover, an 8087 instruction can access a register based on its offset, for instance the third register
from the top.
To support this, the control circuitry can temporarily add an offset to the top of stack position (green).
A multiplexer (red) selects either the top of stack or the adder output, and feeds it to the decoder (blue),
which selects one of the eight stack registers in the register file (yellow), as described earlier.</p>
<p><a href="https://static.righto.com/images/8087-stack/patent-diagram.jpg"><img alt="The register stack in the 8087. Adapted from Patent USRE33629E. I don't know what the GRX field is. I also don't know why this shows a subtractor and not an adder." height="378" src="https://static.righto.com/images/8087-stack/patent-diagram-w700.jpg" title="The register stack in the 8087. Adapted from Patent USRE33629E. I don't know what the GRX field is. I also don't know why this shows a subtractor and not an adder." width="700"></a></p><p>The register stack in the 8087. Adapted from <a href="https://patents.google.com/patent/USRE33629E">Patent USRE33629E</a>. I don't know what the GRX field is. I also don't know why this shows a subtractor and not an adder.</p>
<!--
    The stack has a key role in most 8087 instructions.
    The `FLD` (Load Real) and `FSTP` (Store Real and Pop) instructions and their variants push or pop a stack value respectively.
    The `FST` (Store Real) instruction reads a stack value without popping it.
    Many instructions affect the top stack register and a specified position in the stack, such as
    `FXCH` (Exchange Registers).
    The standard arithmetic operations (add, subtract, multiply, divide) can use the stack in multiple ways.
    The "classical" form is to perform the operation on the top two stack locations and replace the top stack value
    with the result.
    Alternatively, the second argument can come from an arbitrary stack location, with the result going into either
    the top of stack or the second location.
    The top value can also be popped, shrinking the stack.
    Finally, one argument can come from memory.
    The less common arithmetic operations (e.g. square root, partial remainder) operate on the top of stack or the
    two top elements as appropriate.
    The point of this is that the 8087 uses the stack in a wide variety of ways, so the circuitry reflects this
    complexity.

    The stack pointer can be directly manipulated with the
    `FINCSTP` and `FDECSTP` instructions (increment or decrement stack pointer).
    The stack pointer is part of the Status Word, and can be stored to memory with the `FSTSW` (Store Status Word)
    instruction. It can also be stored to memory or loaded from memory as part of the `FLDENV` and `FSTENV`
    (Load Environment or Store Environment) instructions or the `FSAVE` and `FRSTOR` (Save State and Restore State)
    instructions.
-->

<p>The physical implementation of the stack circuitry is shown below.
The logic at the top selects the stack operation based on the 16-bit micro-instruction.<span id="fnref:microcode"><a href="#fn:microcode">5</a></span>
Below that are the three latches that hold the top of stack value.
(The large white squares look important, but they are simply "jumpers" from the ground line to the circuitry, passing
under metal wires.)</p>
<p><a href="https://static.righto.com/images/8087-stack/stack-circuitry.jpg"><img alt="The stack control circuitry. The blue regions on the right are oxide residue that remained when I dissolved the metal rail for the 5V power.
" height="653" src="https://static.righto.com/images/8087-stack/stack-circuitry-w350.jpg" title="The stack control circuitry. The blue regions on the right are oxide residue that remained when I dissolved the metal rail for the 5V power.
" width="350"></a></p><p>The stack control circuitry. The blue regions on the right are oxide residue that remained when I dissolved the metal rail for the 5V power.
</p>
<p>The three-bit adder is at the bottom, along with the multiplexer.
You might expect the adder to use a simple "full adder" circuit. Instead, it is
a faster <a href="https://en.wikipedia.org/wiki/Carry-lookahead_adder">carry-lookahead</a> adder.
I won't go into details here, but the summary is that at each bit position, an AND gate produces a Carry Generate
signal while an XOR gate produces a Carry Propagate signal.
Logic gates combine these signals to produce the output bits in parallel, avoiding the slowdown of the carry rippling
through the bits.</p>
<p>The incrementer/decrementer uses a completely different approach.
Each of the three bits uses a toggle flip-flop.
A few logic gates determine if each bit should be toggled or should keep its previous value.
For instance, when incrementing, the top bit is toggled if the lower bits are 11 (e.g. incrementing from 011 to 100).
For decrementing, the top bit is toggled if the lower bits are 00 (e.g. 100 to 011).
Simpler logic determines if the middle bit should be toggled.
The bottom bit is easier, toggling every time whether incrementing or decrementing.</p>
<p>The schematic below shows the circuitry for one bit of the stack.
Each bit is implemented with a moderately complicated flip-flop that can be cleared, loaded with
a value, or toggled, based on control signals from the microcode.
The flip-flop is constructed from two set-reset (SR) latches. Note that the flip-flop outputs are crossed when fed back
to the input, providing the inversion for the toggle action.
At the right, the multiplexer selects either the register value or the sum from the adder (not shown), generating the signals
to the decoder.</p>
<p><a href="https://static.righto.com/images/8087-stack/stack-schematic.jpg"><img alt="Schematic of one bit of the stack." height="294" src="https://static.righto.com/images/8087-stack/stack-schematic-w700.jpg" title="Schematic of one bit of the stack." width="700"></a></p><p>Schematic of one bit of the stack.</p>
<h2>Drawbacks of the stack approach</h2>
<p>According to the designers of the 8087,<span id="fnref:references"><a href="#fn:references">7</a></span>
the main motivation for using a stack rather than a flat register set was that instructions didn't have enough bits to address multiple register operands.
In addition, a stack has "advantages over general registers for expression parsing and nested function calls."
That is, a stack works well for a mathematical expression since sub-expressions can be evaluated on the top
of the stack.
And for function calls, you avoid the cost of saving registers to memory, since the subroutine can use the stack without disturbing the values underneath.
At least that was the idea.</p>
<!--
The designers considered a "classical" stack architecture, which has only two or three cells in hardware and accesses
the rest of the stack from memory. However, this approach was rejected because the excessive traffic between the memory and stack would have been a bottleneck.
-->

<p>The main problem is "stack overflow".
The 8087's stack has eight entries, so if you push a ninth value onto the stack, the stack will overflow.
Specifically, the top-of-stack pointer will wrap around, obliterating the bottom value on the stack.
The 8087 is designed to detect a stack overflow using the register tags:
pushing a value to a non-empty register triggers an invalid operation exception.<span id="fnref:underflow"><a href="#fn:underflow">6</a></span></p>
<p>The designers expected that stack overflow would be rare and could be handled by the operating system (or library code).
After detecting a stack overflow, the software should dump the existing stack to memory to
provide the illusion of an infinite stack.
Unfortunately, bad design decisions made it difficult "both technically and commercially" to handle stack overflow.</p>
<p>One of the 8087's designers (Kahan) attributes the 8087's stack problems to the time difference between California,
where the designers lived, and Israel, where the 8087 was implemented.
Due to a lack of communication, each team thought the other was implementing the overflow software.
It wasn't until the
8087 was in production that they realized that "it might not be possible to handle 8087 stack underflow/overflow in a reasonable way. It's not impossible, just impossible to do it in a reasonable way."</p>
<p>As a result, the stack was largely a problem rather than a solution.
Most 8087 software saved the full stack to memory before performing
a function call, creating more memory traffic.
Moreover, compilers turned out to work better with regular registers than a stack,
so compiler writers awkwardly used the stack to emulate regular registers.
The <code>GCC</code> compiler <a href="https://langdev.stackexchange.com/a/2408">reportedly</a> needs 3000 lines of extra code to support the x87 stack.</p>
<p>In the 1990s, Intel introduced a new floating-point system called <a href="https://www.cs.uaf.edu/2012/fall/cs301/lecture/11_02_other_float.html">SSE</a>, followed by AVX in 2011.
These systems use regular (non-stack) registers and provide parallel operations for higher performance,
making the 8087's stack instructions largely obsolete.</p>
<h2>The success of the 8087</h2>
<p>At the start, Intel was unenthusiastic about producing the 8087, viewing it as unlikely to be a success.
John Palmar, a principal architect of the chip, had little success convincing
skeptical Intel management that the market for the 8087 was enormous.
Eventually,
he said, "I'll tell you what. I'll relinquish my salary, provided you'll write down your number of how many you expect to sell, then give me a dollar for every one you sell beyond that."<span id="fnref2:references"><a href="#fn:references">7</a></span>
Intel didn't agree to the deal—which would have made a fortune for Palmer—but they reluctantly agreed to produce the chip.</p>
<p>Intel's Santa Clara engineers shunned the 8087, considering it unlikely to work:
the 8087 would be two to three times more complex than the 8086,
with a die so large that a wafer might not have a single working die.
Instead, Rafi Nave, at Intel's Israel site, took on the risky project: “Listen, everybody knows it's not going to work, so if it won't work, I would just fulfill their expectations or their assessment.
If, by chance, it works, okay, then we'll gain tremendous respect and tremendous breakthrough on our abilities.”</p>
<p>A small team of seven engineers developed the 8087 in Israel.
They designed the chip on Mylar sheets: a millimeter on Mylar represented a micron on the physical chip.
The drawings were then digitized on a Calma system by clicking on each polygon to create the layout.
When the chip was moved into production,
the yield was very low but better than feared: two working dies per four-inch wafer.</p>
<p>The 8087 ended up being a large success, said to have been Intel's most profitable product line at times.
The success of the 8087 (along with the 8088) cemented the reputation of Intel Israel, which eventually became Israel's largest tech employer.
The benefits of floating-point hardware proved to be so great that Intel integrated the floating-point unit into later processors
starting with the 80486 (1989).
Nowadays, most modern computers, from cellphones to mainframes, provide floating point based on the
8087,
so I consider the 8087 one of the most influential chips ever created.</p>
<p>For more, follow me on
 Bluesky (<a href="https://bsky.app/profile/righto.com">@righto.com</a>),
Mastodon (<a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="e58e808b968d8c97978c8383a58a8981879c918096cb9695848680">[email&nbsp;protected]</span></a>),
or <a href="https://www.righto.com/feeds/posts/default">RSS</a>.
I wrote some articles about the 8087 a few years ago, including <a href="https://www.righto.com/2018/08/inside-die-of-intels-8087-coprocessor.html">the die</a>,
<a href="https://www.righto.com/2018/09/two-bits-per-transistor-high-density.html">the ROM</a>,
the <a href="https://www.righto.com/2020/05/die-analysis-of-8087-math-coprocessors.html">bit shifter</a>,
and <a href="https://www.righto.com/2020/05/extracting-rom-constants-from-8087-math.html">the constants</a>, so you may have seen some of this material before.</p>
<h2>Notes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“The Matilda Effect”: Pioneering Women Scientists Written Out of Science History (103 pts)]]></title>
            <link>https://www.openculture.com/2025/12/matilda-effect.html</link>
            <guid>46208160</guid>
            <pubDate>Tue, 09 Dec 2025 17:57:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openculture.com/2025/12/matilda-effect.html">https://www.openculture.com/2025/12/matilda-effect.html</a>, See on <a href="https://news.ycombinator.com/item?id=46208160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img loading="lazy" fetchpriority="high" decoding="async" src="https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner.jpg" alt="" width="790" height="561" srcset="https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner.jpg 790w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-360x256.jpg 360w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-240x170.jpg 240w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-768x545.jpg 768w" sizes="(max-width: 790px) 100vw, 790px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner.jpg" data-srcset="https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner.jpg 790w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-360x256.jpg 360w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-240x170.jpg 240w, https://cdn8.openculture.com/2025/12/07212351/Otto_Hahn_und_Lise_Meitner-768x545.jpg 768w"></p>
<p><small><em>Pho­to via <a href="https://en.wikipedia.org/wiki/Lise_Meitner#/media/File:Otto_Hahn_und_Lise_Meitner.jpg">Wiki­me­dia Com­mons</a></em></small></p>
<p>The his­to­ry of sci­ence, like most every his­to­ry we learn, comes to us as a pro­ces­sion of great, almost exclu­sive­ly white, men, unbro­ken but for the occa­sion­al token woman—well-deserving of her hon­ors but seem­ing­ly anom­alous nonethe­less. “If you believe the his­to­ry books,” notes the <a href="https://medium.com/s/the-matilda-effect">Time­line series The Matil­da Effect</a>, “sci­ence is a guy thing. Dis­cov­er­ies are made by men, which spur fur­ther inno­va­tion by men, fol­lowed by acclaim and prizes for men. But too often, there is an unsung woman genius who deserves just as much cred­it” and who has been over­shad­owed by male col­leagues who grabbed the glo­ry.</p>
<p>In 1993, Cor­nell Uni­ver­si­ty his­to­ri­an of sci­ence <a href="https://sts.cornell.edu/margaret-rossiter">Mar­garet Rossiter</a> dubbed the denial of recog­ni­tion to women sci­en­tists “the Matil­da effect,” for suf­frag­ist and abo­li­tion­ist <a href="https://www.womenshistory.org/education-resources/biographies/matilda-joslyn-gage">Matil­da Joslyn Gage</a>, whose 1893 essay “<a href="https://www.jstor.org/stable/25118273?seq=1">Woman as an Inven­tor</a>” protest­ed the com­mon asser­tion that “woman… pos­sess­es no inven­tive or mechan­i­cal genius.” Such asser­tions, Gage pro­ceed­ed to demon­strate, “are care­less­ly or igno­rant­ly made… although woman’s sci­en­tif­ic edu­ca­tion has been gross­ly neglect­ed, yet some of the most impor­tant inven­tions of the world are due to her.”</p>


<p>Over 100 years lat­er, Rossiter’s tena­cious work in unearthing the con­tri­bu­tions of U.S. women sci­en­tists inspired the His­to­ry of Sci­ence Soci­ety to <a href="https://hssonline.org/page/rossiter">name a pres­ti­gious prize after her</a>. The <a href="https://medium.com/s/the-matilda-effect">Time­line series</a> pro­files a few of the women whom it describes as prime exam­ples of the Matil­da effect, includ­ing <a href="https://en.wikipedia.org/wiki/Lise_Meitner">Dr. Lise Meit­ner</a>, the Aus­tri­an-born physi­cist and pio­neer of nuclear tech­nol­o­gy who escaped the Nazis and became known in her time as “the Jew­ish Moth­er of the Bomb,” though she had noth­ing to do with the atom­ic bomb. Instead, “Meit­ner led the research that ulti­mate­ly dis­cov­ered nuclear fis­sion.”&nbsp;But Meit­ner would become “lit­tle more than a foot­note in the his­to­ry of Nazi sci­en­tists and the birth of the Atom­ic age.”</p>
<p>Instead, Meitner’s col­league Otto Hahn received the acco­lades, a Nobel Prize in Chem­istry and “renown as the dis­cov­er­er of nuclear fis­sion. Meit­ner, who direct­ed Hahn’s most sig­nif­i­cant exper­i­ments and cal­cu­lat­ed the ener­gy release result­ing from fis­sion, received a few essen­tial­ist head­lines fol­lowed by decades of obscu­ri­ty.” (See Meit­ner and Hahn in the pho­to above.) Like­wise, the name of <a href="https://medium.com/s/the-matilda-effect/alice-ball-matilda-effect-6b5fb64c74d6">Alice Augus­ta Ball</a> has been “all but scrubbed from the his­to­ry of med­i­cine,” though it was Ball, an African Amer­i­can chemist from Seat­tle, Wash­ing­ton, who pio­neered what became known as the Dean Method, a rev­o­lu­tion­ary treat­ment for lep­rosy.</p>
<p>Ball con­duct­ed her research at the Uni­ver­si­ty of Hawaii, but she trag­i­cal­ly died at the age of 24, in what was like­ly a lab acci­dent, before the results could be pub­lished. Instead, Uni­ver­si­ty Pres­i­dent Dr. Arthur Dean, who had co-taught chem­istry class­es with Ball, con­tin­ued her work. But he failed “to men­tion Ball’s key con­tri­bu­tion” despite protes­ta­tions from Dr. Har­ry Holl­mann, a sur­geon who worked with Ball on treat­ing lep­rosy patients. Dean claimed cred­it and pub­lished their work under his name. Decades lat­er, “the scant archival trail of Alice Ball was redis­cov­ered…. In 2000, a plaque was installed at the Uni­ver­si­ty of Hawaii com­mem­o­rat­ing Ball’s accom­plish­ments.”</p>
<p>Oth­er women in the <a href="https://medium.com/s/the-matilda-effect">Matil­da effect series</a> include bac­te­r­i­al geneti­cist <a href="https://en.wikipedia.org/wiki/Esther_Lederberg">Esther Leder­berg</a>, who made amaz­ing dis­cov­er­ies in genet­ics that won her hus­band a Nobel Prize; Irish astro­physi­cist <a href="https://medium.com/s/the-matilda-effect/jocelyn-bell-burnell-matilda-effect-5362bef36308?source=---------4----------------">Joce­lyn Bell Bur­nell</a>, who dis­cov­ered the first radio pul­sars in 1967, but was exclud­ed from the Nobel award­ed to her the­sis super­vi­sor Antony Hewish and astronomer Mar­tin Ryle. A sim­i­lar fate befell <a href="https://medium.com/s/the-matilda-effect/rosalind-franklin-dna-matilda-8c54e6222848">Dr. Ros­alind Franklin</a>, the chemist exclud­ed from the Nobel award­ed to her col­leagues James Wat­son, Fran­cis Crick, and Mau­rice Wilkins for the dis­cov­ery of DNA.</p>
<p>These promi­nent exam­ples are but the tip of the ice­berg when it comes to women who made sig­nif­i­cant con­tri­bu­tions to sci­en­tif­ic his­to­ry and were reward­ed by being writ­ten out of it and denied awards and recog­ni­tion in their life­time.&nbsp;For more on the his­to­ry of U.S. women in sci­ence and the social forces that worked to exclude them, see Mar­garet Rossiter’s three-vol­ume&nbsp;<em>Women Sci­en­tists in Amer­i­ca&nbsp;</em>series: <em><a href="https://amzn.to/2KiHsGx">Strug­gles and Strate­gies to 1940</a></em>, <em><a href="https://amzn.to/2O6KoIH">Before Affir­ma­tive Action, 1940–1972</a></em>, and <em><a href="https://amzn.to/2n0K4j4">Forg­ing a New World since 1972</a></em>. And read <a href="https://medium.com/s/the-matilda-effect">Timeline’s Matil­da Effect series of arti­cles here</a>.</p>
<p>Note: An ear­li­er ver­sion of this post appeared on our site in 2018.</p>
<p><strong>Relat­ed Con­tent:</strong></p>
<p><a href="http://www.openculture.com/2017/12/read-the-dont-let-the-bastards-get-you-down-letter-that-albert-einstein-sent-to-marie-curie-during-a-time-of-personal-crisis-1911.html">Read the “Don’t Let the Bas­tards Get You Down” Let­ter That Albert Ein­stein Sent to Marie Curie Dur­ing a Time of Per­son­al Cri­sis (1911)</a></p>
<p><a title="Permanent Link to Women Scientists Launch a Database Featuring the Work of 9,000 Women Working in the Sciences" href="https://www.openculture.com/2019/11/women-scientists-launch-a-database-featuring-the-work-of-9000-women-working-in-the-sciences.html" rel="bookmark">Women Sci­en­tists Launch a Data­base Fea­tur­ing the Work of 9,000 Women Work­ing in the Sci­ences</a></p>
<p><a href="http://www.openculture.com/2016/07/marie-curie-attended-a-secret-underground-flying-university-when-poland-blocked-her-other-women-from-advancing-their-education.html">Marie Curie Attend­ed a Secret, Under­ground “Fly­ing Uni­ver­si­ty” When Women Were Banned from Pol­ish Uni­ver­si­ties</a></p>
<p><a href="http://www.openculture.com/2018/06/the-encyclopedia-of-women-philosophers.html">The Ency­clo­pe­dia of Women Philoso­phers: A New Web Site Presents the Con­tri­bu­tions of Women Philoso­phers, from Ancient to Mod­ern</a></p>
<p><a title="Permanent Link to Meet the Physicist Who Has Created 1600+ Wikipedia Entries for Important Female &amp; Minority Scientists" href="https://www.openculture.com/2022/10/meet-the-physicist-who-has-created-1600-wikipedia-entries-for-important-female-minority-scientists.html" rel="bookmark">Meet the Physi­cist Who Has Cre­at­ed 1600+ Wikipedia Entries for Impor­tant Female &amp; Minor­i­ty Sci­en­tists</a></p>
<p><em>Josh Jones is a writer and musi­cian based in Durham, NC.&nbsp;</em></p>

<br>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How private equity is changing housing (114 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/2025/12/private-equity-housing-changes/685138/</link>
            <guid>46207727</guid>
            <pubDate>Tue, 09 Dec 2025 17:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/2025/12/private-equity-housing-changes/685138/">https://www.theatlantic.com/ideas/2025/12/private-equity-housing-changes/685138/</a>, See on <a href="https://news.ycombinator.com/item?id=46207727">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-event-module="hero"><div><div><p>In some communities, corporations control more than 20 percent of properties.</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Row of townhouses" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/Iw56BoMDD0dpyeQY4r_kMeLjI4w=/0x0:4720x2655/750x422/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 750w, https://cdn.theatlantic.com/thumbor/Q69EHRO8WaqzTEB9p2v4tDEFjkU=/0x0:4720x2655/828x466/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 828w, https://cdn.theatlantic.com/thumbor/MY6Kbem8Tq71ZIftsdXixuSlHmY=/0x0:4720x2655/960x540/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 960w, https://cdn.theatlantic.com/thumbor/HNIJfYNw_F7L70cAgV9izd-47h8=/0x0:4720x2655/976x549/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 976w, https://cdn.theatlantic.com/thumbor/FfwEfduAMlpkzL3TOUXvRS6ITU0=/0x0:4720x2655/1952x1098/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 1952w" src="https://cdn.theatlantic.com/thumbor/MY6Kbem8Tq71ZIftsdXixuSlHmY=/0x0:4720x2655/960x540/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png" id="article-lead-image" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Nathan Howard / Bloomberg / Getty</figcaption></figure></div></div><div><p><time datetime="2025-12-08T12:57:51Z" data-flatplan-timestamp="true">December 8, 2025, 7:57 AM ET</time> </p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></div><div data-view-action="view - audio player - start" data-view-label="685138" data-event-module="audio player" data-event-content-type="narrated" data-event-module-state="start" data-event-view="true"><div><p><img alt="Row of townhouses" sizes="80px" srcset="https://cdn.theatlantic.com/thumbor/oXmLMQBiykQo2jZlUBrHg8sNebw=/1033x0:3688x2655/80x80/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 80w, https://cdn.theatlantic.com/thumbor/1n7S6BavtWL847_V0GYafWUekaY=/1033x0:3688x2655/96x96/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 96w, https://cdn.theatlantic.com/thumbor/fISh73tjpGD_C1lDnSbp62Xf4Aw=/1033x0:3688x2655/128x128/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 128w, https://cdn.theatlantic.com/thumbor/9zP_YfuQLoNWr7uOqJmrTibrc5Q=/1033x0:3688x2655/160x160/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 160w, https://cdn.theatlantic.com/thumbor/9XXmjx_f6NiYV6C8XMvBpiE6Zn0=/1033x0:3688x2655/192x192/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 192w, https://cdn.theatlantic.com/thumbor/pgnoAdMkVb6BOltLVwUq3xlHizo=/1033x0:3688x2655/256x256/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 256w, https://cdn.theatlantic.com/thumbor/qEZnI7MjXX4cRI6WLn_e2LisJYU=/1033x0:3688x2655/384x384/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 384w, https://cdn.theatlantic.com/thumbor/g-xSVpXrR9A7Mo_eCNgDfJLkC5I=/1033x0:3688x2655/512x512/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png 512w" src="https://cdn.theatlantic.com/thumbor/oXmLMQBiykQo2jZlUBrHg8sNebw=/1033x0:3688x2655/80x80/media/img/mt/2025/12/2025_12_4_Private_Equity_Responsible_for_the_Housing_Crisis_/original.png" width="80" height="80"></p></div><p>Listen to more stories on the<!-- --> <a href="https://newsoveraudio.com/?offerId=atl_reader_exclusive_jks1kjl"> <!-- -->Noa</a> <!-- -->app.</p></div><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">We have a housing crisis, as you probably, painfully, know. Wouldn’t you like to have someone to blame for it?</p><p data-flatplan-paragraph="true">The United States is short <a data-event-element="inline link" href="https://upforgrowth.org/apply-the-vision/2023-housing-underproduction/">4 million</a> housing units, with a particular dearth of starter homes, <a data-event-element="inline link" href="https://www.nlc.org/article/2024/01/23/what-is-missing-middle-housing/">moderately priced</a> apartments in low-rises, and family-friendly dwellings. Interest rates are high, which has stifled construction and pushed up the cost of mortgages. As a result, more Americans are renting, and roughly <a data-event-element="inline link" href="https://www.jchs.harvard.edu/arh-2024-cost-burden-share">half of those households</a> are spending more than a third of their income on shelter.</p><p data-flatplan-paragraph="true">This crisis has many causes: restrictive zoning codes, arcane permitting processes, excessive <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2022/04/local-government-community-input-housing-public-transportation/629625/">community input</a>, declining construction productivity, expensive labor, and expensive lumber. And, some say, the aggressive entry of private equity into the housing market. Institutional investors have bought up hundreds of thousands of American homes since the start of the coronavirus pandemic, outbidding families and <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2023/01/housing-crisis-hedge-funds-private-equity-scapegoat/672839/">pushing up rents</a>—a trend lamented by everyone from <a data-event-element="inline link" href="https://truthout.org/articles/ocasio-cortez-digs-into-private-equity-for-buying-houses-and-jacking-up-rents/">Alexandria Ocasio-Cortez</a> to <a data-event-element="inline link" href="https://www.politico.com/news/2024/10/14/harris-vance-housing-crisis-00183484">J. D. Vance</a>.</p><p data-flatplan-paragraph="true">Casting private equity as a central villain in the country’s real-estate tragedy makes intuitive sense. Who’s going to win in a bidding war for a three-bedroom in a suburb of Cincinnati: a single-income family with a scrabbled-together 10 percent down payment or a Wall Street LLC offering cash? Still, housing economists and policy analysts have argued that institutional investors have played at most a bit part. Supply constraints began cropping up on the coasts a generation ago, if not earlier, whereas Wall Street started buying up significant numbers of homes only after the Great Recession and especially after the pandemic. Moreover, even if big investors are purchasing thousands of homes, they don’t own significant numbers of homes compared with small-scale landlords and individuals.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/">Rogé Karma: The secretive industry devouring the U.S. economy</a></p><p data-flatplan-paragraph="true">Yet in some markets, the balance has shifted. Last month, the Lincoln Institute of Land Policy and the Center for Geospatial Solutions published <a data-event-element="inline link" href="https://www.lincolninst.edu/publications/other/who-owns-america-mapping-corporate-ownership-residential-land/?utm_term=cgs_publication_housing&amp;utm_content=outreach_cgs_whoa_report_2025&amp;utm_campaign=whoa_report_2025_launch_opub">a report</a> showing that corporations now own a remarkable one in 11 residential real-estate parcels in the 500 urban counties with data robust enough to analyze. In some communities, they control more than 20 percent of properties.</p><p data-flatplan-paragraph="true">I figured that big investors might be picking up vacation rentals in Colorado and expensive apartment buildings in the Bay Area and the Acela Corridor. They are, the report’s authors told me. But these investors are pouring the most money into “buy low, rent high” neighborhoods: communities, many of them in the South and the Rust Belt, where large shares of families can’t afford a mortgage.</p><p data-flatplan-paragraph="true">“They’re pulling all the starter homes off of the market in low-income, high-minority-density neighborhoods,” George McCarthy, the president of the Lincoln Institute, told me—a trend that is intensifying the country’s yawning racial wealth and homeownership gaps. In Cleveland, corporations own 17.5 percent of residential real-estate parcels. In the city’s East Side, which contains many predominantly <a data-event-element="inline link" href="https://visual.clevelandhistory.org/black-population-suburbs/">Black neighborhoods</a>, just one in five homebuyers in 2021 took out a mortgage. The rest—many investors, presumably—paid in cash or took out a loan from a <a data-event-element="inline link" href="https://signalcleveland.org/wp-content/uploads/2022/10/Cuyahoga-Home-Mortgage-Lending-3-20-23.pdf">non-traditional financier</a>.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/ideas/archive/2023/01/housing-crisis-hedge-funds-private-equity-scapegoat/672839/">Jerusalem Demsas: Meet the latest housing-crisis scapegoat</a></p><p data-flatplan-paragraph="true">In Baltimore’s majority-Black McElderry Park and Ellwood Park/Monument neighborhoods, owner-occupants made just 13 percent of purchases in 2022. In a majority-white neighborhood not far away, owner-occupants bought more than 80 percent of homes that same year, and out-of-state corporations owned less than 1 percent of residential parcels.</p><p data-flatplan-paragraph="true">The report made me see the country’s real-estate crisis in a different light. Private-equity firms and other deep-pocketed investors aren’t why Seattle and Boston are unaffordable. Those cities have had shortage-driven housing crises that have intensified over decades. The firms aren’t why many towns in the Mountain West have seen jumps in home values and a corresponding increase in homelessness, displacement, and eviction. In those communities, white-collar emigrants from big cities have arrived and outbid locals. But investor money is distorting the housing market in communities with low wages and decent-enough housing supply, pushing thousands of Black and Latino families off the property ladder. Tens of thousands of workers who would like to invest in a home are instead stuck paying rent, and putting up with the associated uncertainty.</p><p data-flatplan-paragraph="true">While not all corporate landlords are bad landlords, <em>some </em>are bad landlords. Corporations are more likely to threaten to evict and to actually evict <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2021/06/real-problem-corporate-landlords/619244/">their tenants</a>. They are also prone to skimping on maintenance and upkeep. “At the neighborhood level, when more than half of the properties are owned by outside investors—when you’ve now flipped that neighborhood from being primarily homeowner driven to investor driven—that matters, because homeowners behave very differently, politically and otherwise,” McCarthy said. An out-of-state investment firm might be less likely than a longtime resident or a local property manager to plant shade trees and demand safe sidewalks, for instance.</p><p data-flatplan-paragraph="true">In response to the rising corporate ownership of homes, a variety of politicians have pushed for policy fixes. In New York, Governor Kathy Hochul has proposed legislation barring firms from <a data-event-element="inline link" href="https://www.governor.ny.gov/news/fighting-new-yorkers-governor-hochul-highlights-2025-state-state-proposal-disincentivize">bidding on single-family or two-family homes</a> for the first 75 days they are on the market. Washington State is contemplating capping the number of units that <a data-event-element="inline link" href="https://mynorthwest.com/mynorthwest-politics/washington-bill-4/4040703">corporations can own</a>. Other legislators have suggested revoking <a data-event-element="inline link" href="https://www.congress.gov/bill/118th-congress/senate-bill/2224">tax benefits</a> from large-scale owners.</p><p data-flatplan-paragraph="true">McCarthy said that caps probably would not work well: Corporations might simply set up multiple entities to get around the rules and keep purchasing properties, for instance. “It’s just not going to fly,” he said. But he supports treating firms that own more than 10 properties in a given jurisdiction as commercial owners rather than residential owners, subjecting them to higher property-tax rates and higher taxes on their capital gains.</p><p data-flatplan-paragraph="true">If nothing is done, what’s happening to majority-Black communities in Ohio and Virginia and Georgia and Michigan might start happening in communities around the country. Private equity might not be causing the housing crisis, but corporate owners could end up making it a lot worse for everyone.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If you're going to vibe code, why not do it in C? (580 pts)]]></title>
            <link>https://stephenramsay.net/posts/vibe-coding.html</link>
            <guid>46207505</guid>
            <pubDate>Tue, 09 Dec 2025 17:11:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stephenramsay.net/posts/vibe-coding.html">https://stephenramsay.net/posts/vibe-coding.html</a>, See on <a href="https://news.ycombinator.com/item?id=46207505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p><strong>Stephen Ramsay</strong></p>
    <p>Or hell, why not do it in <em>x86 assembly?</em></p>
    <p>Let’s get a few things out of the way before I go any
    further with this seemingly impertinent thought, because it’s
    nowhere near as snarky as it sounds.</p>
    <p>First, I don’t particularly <em>like</em> vibe coding. I
    love programming, and I have loved it since I made my first
    tentative steps with it sometime back in the mid-to-late 90s. I
    love programming so much, it always feels like I’m having too
    much fun for it to count as real work. I’ve done it
    professionally, but I also do it as a hobby. Someone apparently
    once said, “Do what you love and you’ll never work a day in
    your life.” That’s how I feel about writing code. I’ve also
    been teaching the subject for twenty-five years, and I can
    honestly say I am as excited about the first day of the
    semester now as I was when I first started. I realize it’s a
    bit precious to say so, but I’ll say it anyway: Turning
    non-programmers into programmers is my life’s work. It is the
    thing of which I am most proud as a college professor.</p>
    <p>Vibe coding makes me feel <em>dirty</em> in ways that I
    struggle to articulate precisely. It’s not just that it feels
    like “cheating” (though it does). I also think it takes a lot
    of the fun out of the whole thing. I sometimes tell people
    (like the aforementioned students) that programming is like
    doing the best crossword puzzle in the world, except that when
    you solve it, it actually dances and sings. Vibe coding robs me
    of that moment, because I don’t feel like <em>I</em> really did
    it at all. And even though to be a programmer is to live with a
    more-or-less permanent set of aporias (you don’t
    <em>really</em> understand what the compiler is doing,
    really—and even if you do, you probably don’t <em>really</em>
    understand how the virtual memory subsystem works, really),
    it’s satisfying to understand every inch of my code and
    frustrating—all the way to the borderlands of active
    anxiety—not quite understanding what Claude just wrote.</p>
    <p>But this leads me to my second point, which I must make as
    clearly and forcefully as I can. Vibe coding actually works. It
    creates robust, complex systems that work. You can tell
    yourself (as I did) that it can’t possibly do that, but you are
    wrong. You can then tell yourself (as I did) that it’s good as
    a kind of alternative search engine for coding problems, but
    not much else. You are also wrong about that. Because when you
    start giving it little programming problems that you can’t be
    arsed to work out yourself (as I did), you discover (as I did)
    that it’s awfully good at those. And then one day you muse out
    loud (as I did) to an AI model something like, “I have an idea
    for a program…” And you are astounded. If you aren’t astounded,
    you either haven’t actually done it or you are at some stage of
    grief prior to acceptance. Perfect? Hardly. But then neither
    are human coders. The future? I think the questions answers
    itself.</p>
    <p>But to get to my impertinent question…</p>
    <p>Early on in my love affair with programming, I read <a href="https://web.mit.edu/6.001/6.037/sicp.pdf"><em>Structure and
    Interpretation of Computer Programs,</em></a> which I now
    consider one of the great pedagogical masterpieces of the
    twentieth century. I learned a great deal about programming
    from that book, but among the most memorable lessons was one
    that appears in the second paragraph of the original preface.
    There, Hal Abelson and Gerald Sussman make a point that hits
    with the force of the obvious, and yet is very often
    forgotten:</p>
    <blockquote>
      <p>[W]e want to establish the idea that a computer language
      is not just a way of getting a computer to perform operations
      but rather that it is a novel formal medium for expressing
      ideas about methodology. Thus, programs must be written for
      people to read, and only incidentally for machines to
      execute.</p>
    </blockquote>
    <p>I’ve been repeating some version of this to my students ever
    since. Computers, I remind them, do not need the code to be
    “readable” or “ergonomic” for humans; they only need it to be
    readable and ergonomic for a computer, which is a considerably
    lower bar.</p>
    <p>Every programming language—<em>including assembly
    language</em>—was and is intended for the convenience of humans
    who need to read it and write it. If a language is innovative,
    it is usually not because it has <em>allowed</em> for automatic
    memory management, or concurrency, or safety, or robust error
    checking, but because it has made it easier for humans to
    express and reason about these matters. When we extol the
    virtues of this or that language—Rust’s safety guarantees,
    C++’s “no-cost abstractions,” or Go’s approach to
    concurrency—we are not talking about an affordance that the
    computer has gained, but about an affordance that <em>we</em>
    have gained as programmers of said computer. From our
    standpoint as programmers, object-oriented languages offer
    certain ways to organize our code—and, I think Abelson and
    Sussman would say, our thinking—that are potentially conducive
    to the noble treasures of maintainability, extensibility, error
    checking, and any number of other condign matters. From the
    standpoint of the computer, this little OO kink of ours seems
    mostly to indicate a strange affinity for heap memory.
    “Whatevs!” (says the computer). And pick your poison here,
    folks: functional programming, algebraic data types, dependent
    types, homoiconicity, immutable data structures, brace styles…
    We can debate the utility of these things, but we must
    understand that we are primarily talking about <em>human</em>
    problems. The set of “machine problems” to which these matters
    correspond is considerably smaller.</p>
    <p>So my question is this: Why vibe code with a language that
    has <em>human</em> convenience and ergonomics in view? Or to
    put that another way: Wouldn’t a language designed <em>for vibe
    coding</em> naturally dispense with much of what is convenient
    and ergonomic <em>for humans</em> in favor of what is
    convenient and ergonomic for machines? Why not have it just
    write C? Or hell, why not x86 assembly?</p>
    <p>Now, at this point, you will want to say that the need for
    human understanding isn’t erased entirely thereby. Some version
    of this argument has merit, but I would remind you that if you
    are really vibe coding for real you already don’t understand a
    great deal of what it is producing. But if you look carefully,
    you will notice that it doesn’t struggle with undefined
    behavior in C. Or with making sure that all memory is properly
    freed. Or with off-by-one errors. It sometimes struggles to
    understand what it is that you actually want, but it rarely
    struggles with the actual execution of the code. It’s better
    than you are at keeping track of those things in the same way
    that a compiler is better at optimizing code than you are.
    Perfect? No.&nbsp;But as I said before…</p>
    <p>Is C the ideal language for vibe coding? I think I could
    mount an argument for why it is not, but surely Rust is even
    less ideal. To say nothing of Haskell, or OCaml, or even
    Python. All of these languages, after all, are for people to
    read, and only incidentally for machines to execute. They are
    practically adorable in their concern for problems that AI
    models do not have.</p>
    <p>I suppose what I’m getting at, here, is that <em>if</em>
    vibe coding is the future of software development (and it is),
    then why bother with languages that were designed for people
    who are not vibe coding? Shouldn’t there be such a thing as a
    “vibe-oriented programming language?” VOP. You read it here
    first.</p>
    <p>One possibility is that such a language truly would be
    executable pseudocode beyond even the most extravagant fever
    dreams of the most earnest Pythonistas; it shows you what it’s
    doing in truly pseudo code, but all the while it’s writing
    assembly. Or perhaps it’s something like the apotheosis of
    literate programming. You write a literary document “expressing
    ideas about methodology,” and the AI produces machine code (and
    a kind of literary critical practice evolves around this
    activity, eventually ordering itself into structuralist and
    post-structuralist camps. But I’m getting ahead of myself).
    Perhaps your job as a programmer is mostly running tests that
    verify this machine code (tests which have also been produced
    by AI). Or maybe a VOPL is really a certain kind of language
    that comes closer to natural language than any existing
    programming language, but which has a certain (easily learned)
    set of idioms and expressions that guide the AI more reliably
    and more quickly toward particular solutions. It doesn’t have
    goroutines. It has a “concurrency slang.”</p>
    <p>Now obviously, the reason a large language model focused on
    coding is good at Javascript and C++ is precisely because it
    has been trained on billions of lines of code in those
    languages along with countless forum posts, StackOverflow
    debates, and so on. Bootstrapping a VOPL presents a certain
    kind of difficulty, but then one also suspects that LLMs are
    <em>already</em> being trained in some future version of this
    language, because so many programmers are already groping their
    way toward a system like this by virtue of the fact that so
    many of them are already vibe coding production-level
    systems.</p>
    <p>I don’t know how I feel about all of this (see my first and
    second points above). It saddens me to think of “coding by
    hand” becoming a kind of quaint Montessori-school stage in the
    education of a vibe coder—something like the contour drawings
    we demand from future photoshopers or the balanced equations we
    insist serve as a rite of passage for people who will never be
    without a calculator to the end of their days.</p>
    <p>At the same time, there is something exciting about the
    birth of a computational paradigm. It wasn’t that long ago, in
    the grand scheme of things, that someone realized that rewiring
    the entire machine every time you wanted to do a calculation
    (think ENIAC, circa 1945) was a rather suboptimal way to do
    things. And it is worth recalling that people
    <em>complained</em> when the stored-program computer rolled
    around (think EDVAC, circa 1951). Why? Well, the answer should
    be obvious. It was less reliable. It was slower. It removed the
    operator from the loop. It threatened specialized labor. It was
    conceptually impure. I’m not kidding about any of this. No less
    an authority than Grace Hopper had to argue against the quite
    popular idea that there was no way anyone could ever trust a
    machine to write instructions for another machine.</p>
    <p>Same vibe, as the kids say.</p>
    <hr>
    <p>Incoming: <a href="https://stephenramsay.net/index.html">home</a> | <a href="https://stephenramsay.net/posts/index.html">blog</a> | <a href="https://stephenramsay.net/meta/index.html">index</a></p>
    <p>Keywords: programming, AI</p>
    <p>Last Modified: 2025-12-07T16:29:42:-0600</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PeerTube is recognized as a digital public good by Digital Public Goods Alliance (625 pts)]]></title>
            <link>https://www.digitalpublicgoods.net/r/peertube</link>
            <guid>46207464</guid>
            <pubDate>Tue, 09 Dec 2025 17:08:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.digitalpublicgoods.net/r/peertube">https://www.digitalpublicgoods.net/r/peertube</a>, See on <a href="https://news.ycombinator.com/item?id=46207464">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><nav data-slot="base" aria-label="Breadcrumbs"><ol data-slot="list"><li data-slot="base" href="/"><a href="https://www.digitalpublicgoods.net/" data-slot="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"></path><path d="M3 10a2 2 0 0 1 .709-1.528l7-5.999a2 2 0 0 1 2.582 0l7 5.999A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg>Home</a></li><li data-slot="base" href="/registry"><a href="https://www.digitalpublicgoods.net/registry" data-slot="item">DPG Registry</a></li><li data-slot="base"><span data-slot="item" data-current="true" aria-disabled="true" role="link" aria-current="page">PeerTube</span></li></ol></nav><div><div><p><img src="https://www.digitalpublicgoods.net/img/DPG_verified_logo_turqoise_blue_h50.png" alt="Verified DPG logo" height="32"></p><p>Verified DPG</p></div><div><p><img alt="DPG logo image" loading="lazy" width="200" height="200" decoding="async" data-nimg="1" srcset="https://www.digitalpublicgoods.net/_next/image?url=https%3A%2F%2Fapp.digitalpublicgoods.net%2Fstorage%2Fimages%2Fpeertube.png&amp;w=256&amp;q=75 1x, https://www.digitalpublicgoods.net/_next/image?url=https%3A%2F%2Fapp.digitalpublicgoods.net%2Fstorage%2Fimages%2Fpeertube.png&amp;w=640&amp;q=75 2x" src="https://www.digitalpublicgoods.net/_next/image?url=https%3A%2F%2Fapp.digitalpublicgoods.net%2Fstorage%2Fimages%2Fpeertube.png&amp;w=640&amp;q=75"></p></div></div></section><section id="quick-info"><div><h3>Release date</h3><p>-</p></div><div><h3>DPG since</h3><p>-</p></div></section><div id="description"><h3>Description</h3><p>PeerTube is a tool for hosting, managing, and sharing videos or live streams.</p><br><h3>Core Components Assessed/Included Repositories</h3><p>The following repositories were submitted by the solution and included in our evaluation. Any repositories, add-ons, features not included in here were not reviewed by us.</p><ul><li><a target="_blank" underline="hover" limit="20" href="https://github.com/Chocobozzz/PeerTube/">github.com/Chocobozzz/PeerTube/</a></li><li><a target="_blank" underline="hover" limit="20" href="https://framagit.org/framasoft/peertube/">framagit.org/framasoft/peertube/</a></li></ul></div><div id="feature-sectors"><h3>Feature</h3><div><p><span>livestreaming</span></p><p><span>video-hosting</span></p></div></div><div id="scale-of-the-solution-2"><h3>Scale of the Solution*</h3><div><h3>Available Languages</h3><p>Esperanto, English, Slovenčina, Gàidhlig, العربية, Norsk, Magyar, Deutsch, Toki Pona, Euskara, Polski, Português (Portugal), Suomi, Tiếng Việt, Italiano, فارسی, Español, Taqbaylit, 简体中文（中国）, Hrvatski, ελληνικά, Occitan, украї́нська мо́ва, Français, ไทย, Türkçe, 繁體中文（台灣）, 日本語, Galego, Íslenska, Svenska, Nederlands, Pусский, bokmål, Čeština, Shqip, Català, Português (Brasil), Norsk nynorsk</p></div><div><h3>Organisations using it</h3><p> <!-- -->French Ministry of National Education (~100K videos), Italy’s National Research Council, a few French alternative media, the Weißensee Kunsthochschule in Berlin, as well as the Universität der Künste in the same city, a few universities worldwide, the Blender and Debian projects, and various activist groups</p></div><p>* This information is self-reported and updated annually</p></div><div id="feature-sectors"><h3>Github insights</h3></div><section id="accordions"><p>Learn how this product has met the requirements of the <a href="https://www.digitalpublicgoods.net/standard" tabindex="0" role="link">DPG Standard</a> by exploring the indicators below.</p></section><div id="application-details"><h3>Application Details</h3><div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>DPG ID</h4></p><h4>GID0092472</h4></div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>Status</h4></p><h4>DPG</h4></div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>Date Created</h4></p><h4>2025-08-11</h4></div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>Date Submitted</h4></p><h4>2025-08-25</h4></div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>Date Reviewed</h4></p><h4>2025-10-07</h4></div><hr role="separator"><div><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle></svg><h4>Date of Expiry</h4></p><h4>2026-10-07</h4></div><hr role="separator"></div></div><div id="application-details"><h3>Application Log Details</h3><div><p><h4>Timestamp</h4><h4>Activity</h4></p></div><div><div><p>2025-10-07 08:40:13</p><p>Ricardo Torres (L2 Reviewer) submitted their review of PeerTube (152) and found it to be a DPG</p></div><div><p>2025-10-07 08:40:12</p><p>System unmarked PeerTube (12958) as a nominee</p></div><div><p>2025-10-07 08:40:07</p><p>Ricardo Torres (L2 Reviewer) passed 4. Platform Independence for PeerTube (12958)</p></div><div><p>2025-10-07 08:40:02</p><p>Ricardo Torres (L2 Reviewer) moved PeerTube (12958) to under review</p></div><div><p>2025-10-07 08:38:21</p><p>Ricardo Torres (L2 Reviewer) finished consultation on 4. Platform Independence for PeerTube (12958)</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Donating the Model Context Protocol and Establishing the Agentic AI Foundation (273 pts)]]></title>
            <link>https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</link>
            <guid>46207425</guid>
            <pubDate>Tue, 09 Dec 2025 17:05:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation">https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</a>, See on <a href="https://news.ycombinator.com/item?id=46207425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div data-theme="ivory"><p>Today, we’re donating the <a href="https://modelcontextprotocol.io/">Model Context Protocol</a> (MCP) to the Agentic AI Foundation (AAIF), a directed fund under the <a>Linux Foundation</a>, co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, Amazon Web Services (AWS), Cloudflare, and Bloomberg.</p><p>One year ago, we <a href="https://www.anthropic.com/news/model-context-protocol">introduced</a> MCP as a universal, open standard for connecting AI applications to external systems. Since then, MCP has achieved incredible adoption:</p><ul><li>Across the ecosystem: There are now more than 10,000 active public MCP servers, covering everything from developer tools to Fortune 500 deployments;</li><li>Across platforms: MCP has been adopted by ChatGPT, Cursor, Gemini, Microsoft Copilot, Visual Studio Code, and other popular AI products;</li><li>Across infrastructure: Enterprise-grade infrastructure now exists with deployment support for MCP from providers including AWS, Cloudflare, Google Cloud, and Microsoft Azure.</li></ul><div><figure><img alt="Significant Milestone in MCP's first year" loading="lazy" width="1920" height="2500" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa056db8301f67466de34a19181e7428ec6b6e17f-1920x2500.png&amp;w=1920&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa056db8301f67466de34a19181e7428ec6b6e17f-1920x2500.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa056db8301f67466de34a19181e7428ec6b6e17f-1920x2500.png&amp;w=3840&amp;q=75"></figure></div><div><p>We’re continuing to invest in MCP’s growth. Claude now has a directory with over 75 <a href="https://claude.com/connectors">connectors</a> (powered by MCP), and we recently launched <a href="https://www.anthropic.com/engineering/advanced-tool-use">Tool Search and Programmatic Tool Calling</a> capabilities in our API to help optimize production-scale MCP deployments, handling thousands of tools efficiently and reducing latency in complex agent workflows.</p><p>MCP now has an official, community-driven <a href="https://github.com/modelcontextprotocol/registry">Registry</a> for discovering available MCP servers, and the <a href="https://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary/">November 25th</a> spec release introduced many new features, including asynchronous operations, statelessness, server identity, and official extensions. There are also official SDKs (Software Development Kits) for MCP in all major programming languages with 97M+ monthly SDK downloads across Python and TypeScript. </p><p>Since its inception, we’ve been committed to ensuring MCP remains open-source, community-driven and vendor-neutral. Today, we further that commitment by donating MCP to the Linux Foundation.</p></div><h2 id="the-linux-foundation-and-the-agentic-ai-foundation"><strong>The Linux Foundation and the Agentic AI Foundation</strong></h2><p>The <a href="https://www.linuxfoundation.org/">Linux Foundation</a> is a non-profit organization dedicated to fostering the growth of sustainable, open-source ecosystems through neutral stewardship, community building, and shared infrastructure. It has decades of experience stewarding the most critical and globally-significant open-source projects, including The Linux Kernel, Kubernetes, Node.js, and PyTorch. Importantly, the Linux Foundation has a proven track record in facilitating open collaboration and maintaining vendor neutrality.<br></p><p>The Agentic AI Foundation (AAIF) is a directed fund under the Linux Foundation co-founded by Anthropic, <a href="https://block.xyz/">Block</a> and <a href="https://openai.com/">OpenAI</a>, with support from <a href="https://www.google.com/">Google</a><span>, </span><a href="http://microsoft.com/">Microsoft</a>, <a href="https://aws.amazon.com/">AWS</a>, <a href="https://www.cloudflare.com/">Cloudflare</a> and <a href="https://www.bloomberg.com/">Bloomberg</a>. The AAIF aims to ensure agentic AI evolves transparently, collaboratively, and in the public interest through strategic investment, community building, and shared development of open standards.</p><h2 id="donating-the-model-context-protocol"><strong>Donating the Model Context Protocol</strong></h2><div><p>Anthropic is donating the Model Context Protocol to the Linux Foundation's new Agentic AI Foundation, where it will join <a href="https://github.com/block/goose">goose</a> by Block and <a href="http://agents.md/">AGENTS.md</a> by OpenAI as founding projects. Bringing these and future projects under the AAIF will foster innovation across the agentic AI ecosystem and ensure these foundational technologies remain neutral, open, and community-driven. </p><p>The Model Context Protocol’s <a href="https://modelcontextprotocol.io/community/governance">governance model</a> will remain unchanged: the project’s maintainers will continue to prioritize community input and transparent decision-making.</p></div><h2 id="the-future-of-mcp"><strong>The future of MCP</strong></h2><div><p>Open-source software is essential for building a secure and innovative ecosystem for agentic AI. Today’s donation to the Linux Foundation demonstrates our commitment to ensuring MCP remains a neutral, open standard. We’re excited to continue contributing to MCP and other agentic AI projects through the AAIF.</p><p>Learn more about MCP at <a href="https://modelcontextprotocol.io/">modelcontextprotocol.io</a> and get involved with the AAIF <a href="https://aaif.io/">here</a>.</p></div></div></article></div><div data-theme="ivory"><p><h2>Related content</h2></p><div><div><h3>Accenture and Anthropic launch multi-year partnership to move enterprises from AI pilots to production</h3><p><a href="https://www.anthropic.com/news/anthropic-accenture-partnership" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>Snowflake and Anthropic announce $200 million partnership to bring agentic AI to global enterprises</h3><p><a href="https://www.anthropic.com/news/snowflake-anthropic-expanded-partnership" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>Anthropic acquires Bun as Claude Code reaches $1B milestone</h3><p><a href="https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>