<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 26 Nov 2025 21:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Gemini CLI Tips and Tricks for Agentic Coding (101 pts)]]></title>
            <link>https://github.com/addyosmani/gemini-cli-tips</link>
            <guid>46060508</guid>
            <pubDate>Wed, 26 Nov 2025 18:08:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/addyosmani/gemini-cli-tips">https://github.com/addyosmani/gemini-cli-tips</a>, See on <a href="https://news.ycombinator.com/item?id=46060508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Gemini CLI Tips &amp; Tricks</h2><a id="user-content-gemini-cli-tips--tricks" aria-label="Permalink: Gemini CLI Tips &amp; Tricks" href="#gemini-cli-tips--tricks"></a></p>
<p dir="auto"><strong>This guide covers ~30 pro-tips for effectively using Gemini CLI for agentic coding</strong></p>
<p dir="auto"><strong><a href="https://github.com/google-gemini/gemini-cli">Gemini CLI</a></strong> is an open-source AI assistant that brings the power of Google's Gemini model directly into your <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=The%20Gemini%20CLI%20is%20an,via%20a%20Gemini%20API%20key" rel="nofollow">terminal</a>. It functions as a conversational, "agentic" command-line tool - meaning it can reason about your requests, choose tools (like running shell commands or editing files), and execute multi-step plans to help with your development <a href="https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-deep-dive-into-gemini-cli-with-taylor-mullen#:~:text=The%20Gemini%20CLI%20%20is,understanding%20of%20the%20developer%20workflow" rel="nofollow">workflow</a>.</p>
<p dir="auto">In practical terms, Gemini CLI acts like a supercharged pair programmer and command-line assistant. It excels at coding tasks, debugging, content generation, and even system automation, all through natural language prompts. Before diving into pro tips, let's quickly recap how to set up Gemini CLI and get it running.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#tip-1-use-geminimd-for-persistent-context">Tip 1: Use <code>GEMINI.md</code> for Persistent Context</a></li>
<li><a href="#tip-2-create-custom-slash-commands">Tip 2: Create Custom Slash Commands</a></li>
<li><a href="#tip-3-extend-gemini-with-your-own-mcp-servers">Tip 3: Extend Gemini with Your Own <code>MCP</code> Servers</a></li>
<li><a href="#tip-4-leverage-memory-addition--recall">Tip 4: Leverage Memory Addition &amp; Recall</a></li>
<li><a href="#tip-5-use-checkpointing-and-restore-as-an-undo-button">Tip 5: Use Checkpointing and <code>/restore</code> as an Undo Button</a></li>
<li><a href="#tip-6-read-google-docs-sheets-and-more-with-a-workspace-mcp-server-configured-you-can-paste-a-docssheets-link-and-have-the-mcp-fetch-it-subject-to-permissions">Tip 6: Read Google Docs, Sheets, and More.</a></li>
<li><a href="#tip-7-reference-files-and-images-with--for-explicit-context">Tip 7: Reference Files and Images with <code>@</code> for Explicit Context</a></li>
<li><a href="#tip-8-on-the-fly-tool-creation-have-gemini-build-helpers">Tip 8: On-the-Fly Tool Creation (Have Gemini Build Helpers)</a></li>
<li><a href="#tip-9-use-gemini-cli-for-system-troubleshooting--configuration">Tip 9: Use Gemini CLI for System Troubleshooting &amp; Configuration</a></li>
<li><a href="#tip-10-yolo-mode---auto-approve-tool-actions-use-with-caution">Tip 10: YOLO Mode - Auto-Approve Tool Actions (Use with Caution)</a></li>
<li><a href="#tip-11-headless--scripting-mode-run-gemini-cli-in-the-background">Tip 11: Headless &amp; Scripting Mode (Run Gemini CLI in the Background)</a></li>
<li><a href="#tip-12-save-and-resume-chat-sessions">Tip 12: Save and Resume Chat Sessions</a></li>
<li><a href="#tip-13-multi-directory-workspace---one-gemini-many-folders">Tip 13: Multi-Directory Workspace - One Gemini, Many Folders</a></li>
<li><a href="#tip-14-organize-and-clean-up-your-files-with-ai-assistance">Tip 14: Organize and Clean Up Your Files with AI Assistance</a></li>
<li><a href="#tip-15-compress-long-conversations-to-stay-within-context">Tip 15: Compress Long Conversations to Stay Within Context</a></li>
<li><a href="#tip-16-passthrough-shell-commands-with--talk-to-your-terminal">Tip 16: Passthrough Shell Commands with <code>!</code> (Talk to Your Terminal)</a></li>
<li><a href="#tip-17-treat-every-cli-tool-as-a-potential-gemini-tool">Tip 17: Treat Every CLI Tool as a Potential Gemini Tool</a></li>
<li><a href="#tip-18-utilize-multimodal-ai---let-gemini-see-images-and-more">Tip 18: Utilize Multimodal AI - Let Gemini See Images and More</a></li>
<li><a href="#tip-19-customize-the-path-and-tool-availability-for-stability">Tip 19: Customize the <code>$PATH</code> (and Tool Availability) for Stability</a></li>
<li><a href="#tip-20-track-and-reduce-token-spend-with-token-caching-and-stats">Tip 20: Track and reduce token spend with token caching and stats</a></li>
<li><a href="#tip-21-use-copy-for-quick-clipboard-copy">Tip 21: Use <code>/copy</code> for Quick Clipboard Copy</a></li>
<li><a href="#tip-22-master-ctrlc-for-shell-mode-and-exiting">Tip 22: Master <code>Ctrl+C</code> for Shell Mode and Exiting</a></li>
<li><a href="#tip-23-customize-gemini-cli-with-settingsjson">Tip 23: Customize Gemini CLI with <code>settings.json</code></a></li>
<li><a href="#tip-24-leverage-ide-integration-vs-code-for-context--diffs">Tip 24: Leverage IDE Integration (VS Code) for Context &amp; Diffs</a></li>
<li><a href="#tip-25-automate-repo-tasks-with-gemini-cli-github-action">Tip 25: Automate Repo Tasks with <code>Gemini CLI GitHub Action</code></a></li>
<li><a href="#tip-26-enable-telemetry-for-insights-and-observability">Tip 26: Enable Telemetry for Insights and Observability</a></li>
<li><a href="#tip-27-keep-an-eye-on-the-roadmap-background-agents--more">Tip 27: Keep an Eye on the Roadmap (Background Agents &amp; More)</a></li>
<li><a href="#tip-28-extend-gemini-cli-with-extensions">Tip 28: Extend Gemini CLI with <code>Extensions</code></a></li>
<li><a href="#additional-fun-corgi-mode-easter-egg-">Tip 29: Corgi Mode Easter Egg üêï</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><strong>Installation:</strong> You can install Gemini CLI via npm. For a global install, use:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g @google/gemini-cli"><pre>npm install -g @google/gemini-cli</pre></div>
<p dir="auto">Or run it without installing using <code>npx</code>:</p>

<p dir="auto">Gemini CLI is available on all major platforms (it's built with Node.js/TypeScript). Once installed, simply run the <code>gemini</code> command in your terminal to launch the interactive <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Interactive%20Mode%20,conversational%20session" rel="nofollow">CLI</a>.</p>
<p dir="auto"><strong>Authentication:</strong> On first use, you'll need to authenticate with the Gemini service. You have two options: (1) <strong>Google Account Login (free tier)</strong> - this lets you use Gemini 2.5 Pro for free with generous usage limits (about 60 requests/minute and 1,000 requests per <a href="https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/#:~:text=Unmatched%20usage%20limits%20for%20individual,developers" rel="nofollow">day</a>. On launch, Gemini CLI will prompt you to sign in with a Google account (no billing <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=%2A%20Google,Google%20AI%20Studio%2C%20then%20run" rel="nofollow">required</a>. (2) <strong>API Key (paid or higher-tier access)</strong> - you can get an API key from Google AI <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=1,key%20from%20Google%20AI%20Studio" rel="nofollow">Studio</a> and set the environment variable <code>GEMINI_API_KEY</code> to use <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Method%201%3A%20Shell%20Environment%20Variable,zshrc" rel="nofollow">it</a>.</p>
<p dir="auto">API key usage can offer higher quotas and enterprise data‚Äëuse protections; prompts aren't used for training on paid/billed usage, though logs may be retained for <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=responses%20may%20be%20logged%20for,Google%20AI%20Studio%2C%20then%20run" rel="nofollow">safety</a>.</p>
<p dir="auto">For example, add to your shell profile:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export GEMINI_API_KEY=&quot;YOUR_KEY_HERE&quot;"><pre><span>export</span> GEMINI_API_KEY=<span><span>"</span>YOUR_KEY_HERE<span>"</span></span></pre></div>
<p dir="auto"><strong>Basic Usage:</strong> To start an interactive session, just run <code>gemini</code> with no arguments. You'll get a <code>gemini&gt;</code> prompt where you can type requests or commands. For instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ gemini
gemini> Create a React recipe management app using SQLite"><pre>$ gemini
gemini<span>&gt;</span> Create a React recipe management app using SQLite</pre></div>
<p dir="auto">You can then watch as Gemini CLI creates files, installs dependencies, runs tests, etc., to fulfill your request. If you prefer a one-shot invocation (non-interactive), use the <code>-p</code> flag with a prompt, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini -p &quot;Summarize the main points of the attached file. @./report.txt&quot;"><pre>gemini -p <span><span>"</span>Summarize the main points of the attached file. @./report.txt<span>"</span></span></pre></div>
<p dir="auto">This will output a single response and <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=gemini" rel="nofollow">exit</a>. You can also pipe input into Gemini CLI: for example, <code>echo "Count to 10" | gemini</code> will feed the prompt via <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=gemini%20,txt" rel="nofollow">stdin</a>.</p>
<p dir="auto"><strong>CLI Interface:</strong> Gemini CLI provides a rich REPL-like interface. It supports <strong>slash commands</strong> (special commands prefixed with <code>/</code> for controlling the session, tools, and settings) and <strong>bang commands</strong> (prefixed with <code>!</code> to execute shell commands directly). We'll cover many of these in the pro tips below. By default, Gemini CLI operates in a safe mode where any action that modifies your system (writing files, running shell commands, etc.) will ask for confirmation. When a tool action is proposed, you'll see a diff or command and be prompted (<code>Y/n</code>) to approve or reject it. This ensures the AI doesn't make unwanted changes without your consent.</p>
<p dir="auto">With the basics out of the way, let's explore a series of pro tips and hidden features to help you get the most out of Gemini CLI. Each tip is presented with a simple example first, followed by deeper details and nuances. These tips incorporate advice and insights from the tool's creators (e.g. Taylor Mullen) and the Google Developer Relations team, as well as the broader community, to serve as a <strong>canonical guide for power users</strong> of Gemini CLI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 1: Use <code>GEMINI.md</code> for Persistent Context</h2><a id="user-content-tip-1-use-geminimd-for-persistent-context" aria-label="Permalink: Tip 1: Use GEMINI.md for Persistent Context" href="#tip-1-use-geminimd-for-persistent-context"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Stop repeating yourself in prompts. Provide project-specific context or instructions by creating a <code>GEMINI.md</code> file, so the AI always has important background knowledge without being told every <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Context%20Files%20%28" rel="nofollow">time</a>.</p>
<p dir="auto">When working on a project, you often have certain overarching details - e.g. coding style guidelines, project architecture, or important facts - that you want the AI to keep in mind. Gemini CLI allows you to encode these in one or more <code>GEMINI.md</code> files. Simply create a <code>.gemini</code> folder (if not already present) in your project, and add a Markdown file named <code>GEMINI.md</code> with whatever notes or instructions you want the AI to persist. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Project Phoenix - AI Assistant

- All Python code must follow PEP 8 style.  
- Use 4 spaces for indentation.  
- The user is building a data pipeline; prefer functional programming paradigms."><pre><span># <span>Project Phoenix - AI Assistant</span></span>

<span>-</span> All Python code must follow PEP 8 style.  
<span>-</span> Use 4 spaces for indentation.  
<span>-</span> The user is building a data pipeline; prefer functional programming paradigms.</pre></div>
<p dir="auto">Place this file in your project root (or in subdirectories for more granular context). Now, whenever you run <code>gemini</code> in that project, it will automatically load these instructions into <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Context%20Files%20%28" rel="nofollow">context</a>. This means the model will <em>always</em> be primed with them, avoiding the need to prepend the same guidance to every prompt.</p>
<p dir="auto"><strong>How it works:</strong> Gemini CLI uses a hierarchical context loading <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Hierarchical%20Loading%3A%20The%20CLI%20combines,The%20loading%20order%20is" rel="nofollow">system</a>. It will combine <strong>global context</strong> (from <code>~/.gemini/GEMINI.md</code>, which you can use for cross-project defaults) with your <strong>project-specific <code>GEMINI.md</code></strong>, and even context files in subfolders. More specific files override more general ones. You can inspect what context was loaded at any time by using the command:</p>

<p dir="auto">This will display the full combined context the AI <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,current%20conversation%20with%20a%20tag" rel="nofollow">sees</a>. If you make changes to your <code>GEMINI.md</code>, use <code>/memory refresh</code> to reload the context without restarting the <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,current%20conversation%20with%20a%20tag" rel="nofollow">session</a>.</p>
<p dir="auto"><strong>Pro Tip:</strong> Use the <code>/init</code> slash command to quickly generate a starter <code>GEMINI.md</code>. Running <code>/init</code> in a new project creates a template context file with information like the tech stack detected, a summary of the project, <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,directory%20workspace%20%28e.g.%2C%20%60add" rel="nofollow">etc</a>.. You can then edit and expand that file. For large projects, consider breaking the context into multiple files and <strong>importing</strong> them into <code>GEMINI.md</code> with <code>@include</code> syntax. For example, your main <code>GEMINI.md</code> could have lines like <code>@./docs/prompt-guidelines.md</code> to pull in additional context <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Modularizing%20Context%20with%20Imports%3A%20You,files" rel="nofollow">files</a>. This keeps your instructions organized.</p>
<p dir="auto">With a well-crafted <code>GEMINI.md</code>, you essentially give Gemini CLI a "memory" of the project's requirements and conventions. This <strong>persistent context</strong> leads to more relevant responses and less back-and-forth prompt engineering.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 2: Create Custom Slash Commands</h2><a id="user-content-tip-2-create-custom-slash-commands" aria-label="Permalink: Tip 2: Create Custom Slash Commands" href="#tip-2-create-custom-slash-commands"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Speed up repetitive tasks by defining your own slash commands. For example, you could make a command <code>/test:gen</code> that generates unit tests from a description, or <code>/db:reset</code> that drops and recreates a test database. This extends Gemini CLI's functionality with one-liners tailored to your workflow.</p>
<p dir="auto">Gemini CLI supports <strong>custom slash commands</strong> that you can define in simple configuration files. Under the hood, these are essentially pre-defined prompt templates. To create one, make a directory <code>commands/</code> under either <code>~/.gemini/</code> for global commands or in your project's <code>.gemini/</code> folder for project-specific <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Custom%20Commands" rel="nofollow">commands</a>. Inside <code>commands/</code>, create a TOML file for each new command. The file name format determines the command name: e.g. a file <code>test/gen.toml</code> defines a command <code>/test:gen</code>.</p>
<p dir="auto">Let's walk through an example. Say you want a command to generate a unit test from a requirement description. You could create <code>~/.gemini/commands/test/gen.toml</code> with the following content:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Invoked as: /test:gen &quot;Description of the test&quot;  
description \= &quot;Generates a unit test based on a requirement.&quot;  
prompt \= &quot;&quot;&quot;  
You are an expert test engineer. Based on the following requirement, please write a comprehensive unit test using the Jest framework.

Requirement: {{args}}  
&quot;&quot;&quot;"><pre><span># <span>Invoked as: /test<span>:</span><span>gen</span> "Description of the test"</span>  </span>
description <span>\=</span> "Generates a unit test based on a requirement."  
prompt <span>\=</span> """  
You are an expert test engineer. Based on the following requirement, please write a comprehensive unit test using the Jest framework.

Requirement: {{args}}  
"""</pre></div>
<p dir="auto">Now, after reloading or restarting Gemini CLI, you can simply type:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/test:gen &quot;Ensure the login button redirects to the dashboard upon success&quot;"><pre>/test:gen <span><span>"</span>Ensure the login button redirects to the dashboard upon success<span>"</span></span></pre></div>
<p dir="auto">Gemini CLI will recognize <code>/test:gen</code> and substitute the <code>{{args}}</code> in your prompt template with the provided argument (in this case, the requirement). The AI will then proceed to generate a Jest unit test <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Example%3A%20%60" rel="nofollow">accordingly</a>. The <code>description</code> field is optional but is used when you run <code>/help</code> or <code>/tools</code> to list available commands.</p>
<p dir="auto">This mechanism is extremely powerful - effectively, you can script the AI with natural language. The community has created numerous useful custom commands. For instance, Google's DevRel team shared a set of <em>10 practical workflow commands</em> (via an open-source repo) demonstrating how you can script common flows like creating API docs, cleaning data, or setting up boilerplate <a href="https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-deep-dive-into-gemini-cli-with-taylor-mullen#:~:text=,to%20generate%20a%20better%20output" rel="nofollow">code</a>. By defining a custom command, you package a complex prompt (or series of prompts) into a reusable shortcut.</p>
<p dir="auto"><strong>Pro Tip:</strong> Custom commands can also be used to enforce formatting or apply a "persona" to the AI for certain tasks. For example, you might have a <code>/review:security</code> command that always prefaces the prompt with "You are a security auditor..." to review code for vulnerabilities. This approach ensures consistency in how the AI responds to specific categories of tasks.</p>
<p dir="auto">To share commands with your team, you can commit the TOML files in your project's repo (under <code>.gemini/commands</code> directory). Team members who have Gemini CLI will automatically pick up those commands when working in the project. This is a great way to <strong>standardize AI-assisted workflows</strong> across a team.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 3: Extend Gemini with Your Own <code>MCP</code> Servers</h2><a id="user-content-tip-3-extend-gemini-with-your-own-mcp-servers" aria-label="Permalink: Tip 3: Extend Gemini with Your Own MCP Servers" href="#tip-3-extend-gemini-with-your-own-mcp-servers"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Suppose you want Gemini to interface with an external system or a custom tool that isn't built-in - for example, query a proprietary database, or integrate with Figma designs. You can do this by running a custom <strong>Model Context Protocol (MCP) server</strong> and plugging it into Gemini <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Extend%20the%20CLI%20with%20your,add%7Clist%7Cremove%3E%60%20commands" rel="nofollow">CLI</a>. MCP servers let you add new tools and abilities to Gemini, effectively <strong>extending the agent</strong>.</p>
<p dir="auto">Gemini CLI comes with several MCP servers out-of-the-box (for instance, ones enabling Google Search, code execution sandboxes, etc.), and you can add your own. An MCP server is essentially an external process (it could be a local script, a microservice, or even a cloud endpoint) that speaks a simple protocol to handle tasks for Gemini. This architecture is what makes Gemini CLI so <a href="https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/#:~:text=,interactively%20within%20your%20scripts" rel="nofollow">extensible</a>.</p>
<p dir="auto"><strong>Examples of MCP servers:</strong> Some community and Google-provided MCP integrations include a <strong>Figma MCP</strong> (to fetch design details from Figma), a <strong>Clipboard MCP</strong> (to read/write from your system clipboard), and others. In fact, in an internal demo, the Gemini CLI team showcased a "Google Docs MCP" server that allowed saving content directly to Google <a href="https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-deep-dive-into-gemini-cli-with-taylor-mullen#:~:text=%2A%20Utilize%20the%20google,summary%20directly%20to%20Google%20Docs" rel="nofollow">Docs</a>. The idea is that whenever Gemini needs to perform an action that the built-in tools can't handle, it can delegate to your MCP server.</p>
<p dir="auto"><strong>How to add one:</strong> You can configure MCP servers via your <code>settings.json</code> or using the CLI. For a quick setup, try the CLI command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini mcp add myserver --command &quot;python3 my_mcp_server.py&quot; --port 8080"><pre>gemini mcp add myserver --command <span><span>"</span>python3 my_mcp_server.py<span>"</span></span> --port 8080</pre></div>
<p dir="auto">This would register a server named "myserver" that Gemini CLI will launch by running the given command (here a Python module) on port 8080. In <code>~/.gemini/settings.json</code>, it would add an entry under <code>mcpServers</code>. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;mcpServers&quot;: {
  &quot;myserver&quot;: {
    &quot;command&quot;: &quot;python3&quot;,
    &quot;args&quot;: [&quot;-m&quot;, &quot;my_mcp_server&quot;, &quot;--port&quot;, &quot;8080&quot;],
    &quot;cwd&quot;: &quot;./mcp_tools/python&quot;,
    &quot;timeout&quot;: 15000
  }
}"><pre><span>"mcpServers"</span>: {
  <span>"myserver"</span>: {
    <span>"command"</span>: <span><span>"</span>python3<span>"</span></span>,
    <span>"args"</span>: [<span><span>"</span>-m<span>"</span></span>, <span><span>"</span>my_mcp_server<span>"</span></span>, <span><span>"</span>--port<span>"</span></span>, <span><span>"</span>8080<span>"</span></span>],
    <span>"cwd"</span>: <span><span>"</span>./mcp_tools/python<span>"</span></span>,
    <span>"timeout"</span>: <span>15000</span>
  }
}</pre></div>
<p dir="auto">This configuration (based on the official docs) tells Gemini how to start the MCP server and <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Example%20" rel="nofollow">where</a>. Once running, the tools provided by that server become available to Gemini CLI. You can list all MCP servers and their tools with the slash command:</p>

<p dir="auto">This will show any registered servers and what tool names they <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Command%20Description%20,List%20active%20extensions" rel="nofollow">expose</a>.</p>
<p dir="auto"><strong>Power of MCP:</strong> MCP servers can provide <strong>rich, multi-modal results</strong>. For instance, a tool served via MCP could return an image or a formatted table as part of the response to Gemini <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Capabilities%3A" rel="nofollow">CLI</a>. They also support OAuth 2.0, so you can securely connect to APIs (like Google's APIs, GitHub, etc.) via an MCP tool without exposing <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Extend%20the%20CLI%20with%20your,add%7Clist%7Cremove%3E%60%20commands" rel="nofollow">credentials</a>. Essentially, if you can code it, you can wrap it as an MCP tool - turning Gemini CLI into a hub that orchestrates many services.</p>
<p dir="auto"><strong>Default vs. custom:</strong> By default, Gemini CLI's built-in tools cover a lot (reading files, web search, executing shell commands, etc.), but MCP lets you go beyond. Some advanced users have created MCP servers to interface with internal systems or to perform specialized data processing. For example, you could have a <code>database-mcp</code> that provides a <code>/query_db</code> tool for running SQL queries on a company database, or a <code>jira-mcp</code> to create tickets via natural language.</p>
<p dir="auto">When creating your own, be mindful of security: by default, custom MCP tools require confirmation unless you mark them as trusted. You can control safety with settings like <code>trust: true</code> for a server (which auto-approves its tool actions) or by whitelisting specific safe tools and blacklisting dangerous <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,takes%20precedence" rel="nofollow">ones</a>.</p>
<p dir="auto">In short, <strong>MCP servers unlock limitless integration</strong>. They're a pro feature that lets Gemini CLI become a glue between your AI assistant and whatever system you need it to work with. If you're interested in building one, check out the official <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Transport%20" rel="nofollow">MCP guide</a> and community examples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 4: Leverage Memory Addition &amp; Recall</h2><a id="user-content-tip-4-leverage-memory-addition--recall" aria-label="Permalink: Tip 4: Leverage Memory Addition &amp; Recall" href="#tip-4-leverage-memory-addition--recall"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Keep important facts at your AI's fingertips by adding them to its long-term memory. For example, after figuring out a database port or an API token, you can do:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/memory add &quot;Our staging RabbitMQ is on port 5673&quot;"><pre>/memory add <span><span>"</span>Our staging RabbitMQ is on port 5673<span>"</span></span></pre></div>
<p dir="auto">This will store that fact so you (or the AI) don't forget it <a href="https://binaryverseai.com/gemini-cli-open-source-ai-tool/#:~:text=Gemini%20CLI%20Ultimate%20Agent%3A%2060,a%20branch%20of%20conversation" rel="nofollow">later</a>. You can then recall everything in memory with <code>/memory show</code> at any time.</p>
<p dir="auto">The <code>/memory</code> commands provide a simple but powerful mechanism for <em>persistent memory</em>. When you use <code>/memory add &lt;text&gt;</code>, the given text is appended to your project's global context (technically, it's saved into the global <code>~/.gemini/GEMINI.md</code> file or the project's <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=,load%20memory%20from%20%60GEMINI.md" rel="nofollow"><code>GEMINI.md</code></a>. It's a bit like taking a note and pinning it to the AI's virtual bulletin board. Once added, the AI will always see that note in the prompt context for future interactions, across sessions.</p>
<p dir="auto">Consider an example: you're debugging an issue and discover a non-obvious insight ("The config flag <code>X_ENABLE</code> must be set to <code>true</code> or the service fails to start"). If you add this to memory, later on if you or the AI are discussing a related problem, it won't overlook this critical detail - it's in the context.</p>
<p dir="auto"><strong>Using <code>/memory</code>:</strong></p>
<ul dir="auto">
<li>
<p dir="auto"><code>/memory add "&lt;text&gt;"</code> - Add a fact or note to memory (persistent context). This updates the <code>GEMINI.md</code> immediately with the new entry.</p>
</li>
<li>
<p dir="auto"><code>/memory show</code> - Display the full content of the memory (i.e. the combined context file that's currently loaded).</p>
</li>
<li>
<p dir="auto"><code>/memory refresh</code> - Reload the context from disk (useful if you manually edited the <code>GEMINI.md</code> file outside of Gemini CLI, or if multiple people are collaborating on it).</p>
</li>
</ul>
<p dir="auto">Because the memory is stored in Markdown, you can also manually edit the <code>GEMINI.md</code> file to curate or organize the info. The <code>/memory</code> commands are there for convenience during conversation, so you don't have to open an editor.</p>
<p dir="auto"><strong>Pro Tip:</strong> This feature is great for "decision logs." If you decide on an approach or rule during a chat (e.g., a certain library to use, or an agreed code style), add it to memory. The AI will then recall that decision and avoid contradicting it later. It's especially useful in long sessions that might span hours or days - by saving key points, you mitigate the model's tendency to forget earlier context when the conversation gets long.</p>
<p dir="auto">Another use is personal notes. Because <code>~/.gemini/GEMINI.md</code> (global memory) is loaded for all sessions, you could put general preferences or information there. For example, "The user's name is Alice. Speak politely and avoid slang." It's like configuring the AI's persona or global knowledge. Just be aware that global memory applies to <em>all</em> projects, so don't clutter it with project-specific info.</p>
<p dir="auto">In summary, <strong>Memory Addition &amp; Recall</strong> helps Gemini CLI maintain state. Think of it as a knowledge base that grows with your project. Use it to avoid repeating yourself or to remind the AI of facts it would otherwise have to rediscover from scratch.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 5: Use Checkpointing and <code>/restore</code> as an Undo Button</h2><a id="user-content-tip-5-use-checkpointing-and-restore-as-an-undo-button" aria-label="Permalink: Tip 5: Use Checkpointing and /restore as an Undo Button" href="#tip-5-use-checkpointing-and-restore-as-an-undo-button"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If Gemini CLI makes a series of changes to your files that you're not happy with, you can <em>instantly roll back</em> to a prior state. Enable checkpointing when you start Gemini (or in settings), and use the <code>/restore</code> command to undo changes like a lightweight Git <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,Exit%20the%20Gemini%20CLI" rel="nofollow">revert</a>. <code>/restore</code> rolls back your workspace to the saved checkpoint; conversation state may be affected depending on how the checkpoint was captured.</p>
<p dir="auto">Gemini CLI's <strong>checkpointing</strong> feature acts as a safety net. When enabled, the CLI takes a snapshot of your project's files <em>before</em> each tool execution that modifies <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=When%20,snapshot%20before%20tools%20modify%20files" rel="nofollow">files</a>. If something goes wrong, you can revert to the last known good state. It's essentially version control for the AI's actions, without you needing to manually commit to Git each time.</p>
<p dir="auto"><strong>How to use it:</strong> You can turn on checkpointing by launching the CLI with the <code>--checkpointing</code> flag:</p>

<p dir="auto">Alternatively, you can make it the default by adding to your config (<code>"checkpointing": { "enabled": true }</code> in <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%7B%20,true" rel="nofollow"><code>settings.json</code></a>). Once active, you'll notice that each time Gemini is about to write to a file, it says something like "Checkpoint saved."</p>
<p dir="auto">If you then realize an AI-made edit is problematic, you have two options:</p>
<ul dir="auto">
<li>
<p dir="auto">Run <code>/restore list</code> (or just <code>/restore</code> with no arguments) to see a list of recent checkpoints with timestamps and descriptions.</p>
</li>
<li>
<p dir="auto">Run <code>/restore &lt;id&gt;</code> to rollback to a specific checkpoint. If you omit the id and there's only one pending checkpoint, it will restore that by <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=Step" rel="nofollow">default</a>.</p>
</li>
</ul>
<p dir="auto">For example:</p>

<p dir="auto">Gemini CLI might output:</p>
<p dir="auto">0: [2025-09-22 10:30:15] Before running 'apply_patch'<br>
1: [2025-09-22 10:45:02] Before running 'write_file'</p>
<p dir="auto">You can then do <code>/restore 0</code> to revert all file changes (and even the conversation context) back to how it was at that checkpoint. In this way, you can "undo" a mistaken code refactor or any other changes Gemini <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=1,point%20and%20roll%20back%20instantly" rel="nofollow">made</a>.</p>
<p dir="auto"><strong>What gets restored:</strong> The checkpoint captures the state of your working directory (all files that Gemini CLI is allowed to modify) and the workspace files (conversation state may also be rolled back depending on how the checkpoint was captured). When you restore, it overwrites files to the old version and resets the conversation memory to that snapshot. It's like time-traveling the AI agent back to before it made the wrong turn. Note that it won't undo external side effects (for example, if the AI ran a database migration, it can't undo that), but anything in the file system and chat context is fair game.</p>
<p dir="auto"><strong>Best practices:</strong> It's a good idea to keep checkpointing on for non-trivial tasks. The overhead is small, and it provides peace of mind. If you find you don't need a checkpoint (everything went well), you can always clear it or just let the next one overwrite it. The development team recommends using checkpointing especially before multi-step code <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=Tips%20to%20avoid%20messy%20rollbacks" rel="nofollow">edits</a>. For mission-critical projects, though, you should still use a proper version control (<code>git</code>) as your primary safety <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=No,VS%20Code%20is%20already%20free" rel="nofollow">net</a> - consider checkpoints as a convenience for quick undo rather than a full VCS.</p>
<p dir="auto">In essence, <code>/restore</code> lets you use Gemini CLI with confidence. You can let the AI attempt bold changes, knowing you have an <em>"OH NO" button</em> to rewind if needed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 6: Read Google Docs, Sheets, and More. With a Workspace MCP server configured, you can paste a Docs/Sheets link and have the MCP fetch it, subject to permissions</h2><a id="user-content-tip-6-read-google-docs-sheets-and-more-with-a-workspace-mcp-server-configured-you-can-paste-a-docssheets-link-and-have-the-mcp-fetch-it-subject-to-permissions" aria-label="Permalink: Tip 6: Read Google Docs, Sheets, and More. With a Workspace MCP server configured, you can paste a Docs/Sheets link and have the MCP fetch it, subject to permissions" href="#tip-6-read-google-docs-sheets-and-more-with-a-workspace-mcp-server-configured-you-can-paste-a-docssheets-link-and-have-the-mcp-fetch-it-subject-to-permissions"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Imagine you have a Google Doc or Sheet with some specs or data that you want the AI to use. Instead of copy-pasting the content, you can provide the link, and with a configured Workspace MCP server Gemini CLI can fetch and read it.</p>
<p dir="auto">For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Summarize the requirements from this design doc: https://docs.google.com/document/d/<id>"><pre>Summarize the requirements from this design doc: https://docs.google.com/document/d/<span>&lt;</span>id<span>&gt;</span></pre></div>
<p dir="auto">Gemini can pull in the content of that Doc and incorporate it into its response. Similarly, it can read Google Sheets or Drive files by link.</p>
<p dir="auto"><strong>How this works:</strong> These capabilities are typically enabled via <strong>MCP integrations</strong>. Google's Gemini CLI team has built (or is working on) connectors for Google Workspace. One approach is running a small MCP server that uses Google's APIs (Docs API, Sheets API, etc.) to retrieve document content when given a URL or <a href="https://github.com/google-gemini/gemini-cli/issues/7175" data-hovercard-type="issue" data-hovercard-url="/google-gemini/gemini-cli/issues/7175/hovercard">ID</a>. When configured, you might have slash commands or tools like <code>/read_google_doc</code> or simply an auto-detection that sees a Google Docs link and invokes the appropriate tool to fetch it.</p>
<p dir="auto">For example, in an Agent Factory podcast demo, the team used a <strong>Google Docs MCP</strong> to save a summary directly to a <a href="https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-deep-dive-into-gemini-cli-with-taylor-mullen#:~:text=%2A%20Utilize%20the%20google,summary%20directly%20to%20Google%20Docs" rel="nofollow">doc</a> - which implies they could also read the doc's content in the first place. In practice, you might do something like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@https://docs.google.com/document/d/XYZ12345"><pre>@https://docs.google.com/document/d/XYZ12345</pre></div>
<p dir="auto">Including a URL with <code>@</code> (the context reference syntax) signals Gemini CLI to fetch that resource. With a Google Doc integration in place, the content of that document would be pulled in as if it were a local file. From there, the AI can summarize it, answer questions about it, or otherwise use it in the conversation.</p>
<p dir="auto">Similarly, if you paste a Google Drive <strong>file link</strong>, a properly configured Drive tool could download or open that file (assuming permissions and API access are set up). <strong>Google Sheets</strong> could be made available via an MCP that runs queries or reads cell ranges, enabling you to ask things like "What's the sum of the budget column in this Sheet [link]?" and have the AI calculate it.</p>
<p dir="auto"><strong>Setting it up:</strong> As of this writing, the Google Workspace integrations may require some tinkering (obtaining API credentials, running an MCP server such as the one described by <a href="https://medium.com/google-cloud/managing-google-docs-sheets-and-slides-by-natural-language-with-gemini-cli-and-mcp-62f4dfbef2d5#:~:text=To%20implement%20this%20approach%2C%20I,methods%20for%20each%20respective%20API" rel="nofollow">Kanshi Tanaike</a>, etc.). Keep an eye on the official Gemini CLI repository and community forums for ready-to-use extensions - for example, an official Google Docs MCP might become available as a plugin/extension. If you're eager, you can write one following guides on how to use Google APIs within an MCP <a href="https://github.com/google-gemini/gemini-cli/issues/7175#:~:text=" data-hovercard-type="issue" data-hovercard-url="/google-gemini/gemini-cli/issues/7175/hovercard">server</a>. It typically involves handling OAuth (which Gemini CLI supports for MCP servers) and then exposing tools like <code>read_google_doc</code>.</p>
<p dir="auto"><strong>Usage tip:</strong> When you have these tools, using them can be as simple as providing the link in your prompt (the AI might automatically invoke the tool to fetch it) or using a slash command like <code>/doc open &lt;URL&gt;</code>. Check <code>/tools</code> to see what commands are available - Gemini CLI lists all tools and custom commands <a href="https://dev.to/therealmrmumba/7-insane-gemini-cli-tips-that-will-make-you-a-superhuman-developer-2d7h#:~:text=Gemini%20CLI%20includes%20dozens%20of,can%20supercharge%20your%20dev%20process" rel="nofollow">there</a>.</p>
<p dir="auto">In summary, <strong>Gemini CLI can reach out beyond your local filesystem</strong>. Whether it's Google Docs, Sheets, Drive, or other external content, you can pull data in by reference. This pro tip saves you from manual copy-paste and keeps the context flow natural - just refer to the document or dataset you need, and let the AI grab what's needed. It makes Gemini CLI a true <strong>knowledge assistant</strong> for all the information you have access to, not just the files on your disk.</p>
<p dir="auto"><em>(Note: Accessing private documents of course requires the CLI to have the appropriate permissions. Always ensure any integration respects security and privacy. In corporate settings, setting up such integrations might involve additional auth steps.)</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 7: Reference Files and Images with <code>@</code> for Explicit Context</h2><a id="user-content-tip-7-reference-files-and-images-with--for-explicit-context" aria-label="Permalink: Tip 7: Reference Files and Images with @ for Explicit Context" href="#tip-7-reference-files-and-images-with--for-explicit-context"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Instead of describing a file's content or an image verbally, just point Gemini CLI directly to it. Using the <code>@</code> syntax, you can attach files, directories, or images into your prompt. This guarantees the AI sees exactly what's in those files as <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Reference%20files%20or%20directories%20in,PDFs%2C%20audio%2C%20and%20video%20files" rel="nofollow">context</a>. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Explain this code to me: @./src/main.js"><pre>Explain this code to me: @./src/main.js</pre></div>
<p dir="auto">This will include the contents of <code>src/main.js</code> in the prompt (up to Gemini's context size limits), so the AI can read it and explain <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Include%20a%20single%20file%3A" rel="nofollow">it</a>.</p>
<p dir="auto">This <code>@</code> <em>file reference</em> is one of Gemini CLI's most powerful features for developers. It eliminates ambiguity - you're not asking the model to rely on memory or guesswork about the file, you're literally handing it the file to read. You can use this for source code, text documents, logs, etc. Similarly, you can reference <strong>entire directories</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Refactor the code in @./utils/ to use async/await."><pre>Refactor the code <span>in</span> @./utils/ to use async/await.</pre></div>
<p dir="auto">By appending a path that ends in a slash, Gemini CLI will recursively include files from that <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Include%20a%20whole%20directory%20" rel="nofollow">directory</a> (within reason, respecting ignore files and size limits). This is great for multi-file refactors or analyses, as the AI can consider all relevant modules together.</p>
<p dir="auto">Even more impressively, you can reference <strong>binary files like images</strong> in prompts. Gemini CLI (using the Gemini model's multimodal capabilities) can understand images. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Describe what you see in this screenshot: @./design/mockup.png"><pre>Describe what you see <span>in</span> this screenshot: @./design/mockup.png</pre></div>
<p dir="auto">The image will be fed into the model, and the AI might respond with something like "This is a login page with a blue sign-in button and a header image," <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Include%20an%20image%3A" rel="nofollow">etc</a>.. You can imagine the uses: reviewing UI mockups, organizing photos (as we'll see in a later tip), or extracting text from images (Gemini can do OCR as well).</p>
<p dir="auto">A few notes on using <code>@</code> references effectively:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>File limits:</strong> Gemini 2.5 Pro has a huge context window (up to 1 million <a href="https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/#:~:text=To%20use%20Gemini%20CLI%20free,per%20day%20at%20no%20charge" rel="nofollow">tokens</a>), so you can include quite large files or many files. However, extremely large files might be truncated. If a file is enormous (say, hundreds of thousands of lines), consider summarizing it or breaking it into parts. Gemini CLI will warn you if a reference is too large or if it skipped something due to size.</p>
</li>
<li>
<p dir="auto"><strong>Automatic ignoring:</strong> By default, Gemini CLI respects your <code>.gitignore</code> and <code>.geminiignore</code> files when pulling in directory <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Reference%20files%20or%20directories%20in,PDFs%2C%20audio%2C%20and%20video%20files" rel="nofollow">context</a>. So if you <code>@./</code> a project root, it will not dump huge ignored folders (like <code>node_modules</code>) into the prompt. You can customize ignore patterns with <code>.geminiignore</code> similarly to how <code>.gitignore</code> works.</p>
</li>
<li>
<p dir="auto"><strong>Explicit vs implicit context:</strong> Taylor Mullen (the creator of Gemini CLI) emphasizes using <code>@</code> for <em>explicit context injection</em> rather than relying on the model's memory or summarizing things yourself. It's more precise and ensures the AI isn't hallucinating content. Whenever possible, point the AI to the source of truth (code, config files, documentation) with <code>@</code> references. This practice can significantly improve accuracy.</p>
</li>
<li>
<p dir="auto"><strong>Chaining references:</strong> You can include multiple files in one prompt, like:</p>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="Compare @./foo.py and @./bar.py and tell me differences."><pre>Compare @./foo.py and @./bar.py and tell me differences.</pre></div>
<p dir="auto">The CLI will include both files. Just be mindful of token limits; multiple large files might consume a lot of the context window.</p>
<p dir="auto">Using <code>@</code> is essentially how you <strong>feed knowledge into Gemini CLI on the fly</strong>. It turns the CLI into a multi-modal reader that can handle text and images. As a pro user, get into the habit of leveraging this - it's often faster and more reliable than asking the AI something like "Open the file X and do Y" (which it may or may not do on its own). Instead, you explicitly give it X to work with.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 8: On-the-Fly Tool Creation (Have Gemini Build Helpers)</h2><a id="user-content-tip-8-on-the-fly-tool-creation-have-gemini-build-helpers" aria-label="Permalink: Tip 8: On-the-Fly Tool Creation (Have Gemini Build Helpers)" href="#tip-8-on-the-fly-tool-creation-have-gemini-build-helpers"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If a task at hand would benefit from a small script or utility, you can ask Gemini CLI to create that tool for you - right within your session. For example, you might say, "Write a Python script to parse all JSON files in this folder and extract the error fields." Gemini can generate the script, which you can then execute via the CLI. In essence, you can <strong>dynamically extend the toolset</strong> as you go.</p>
<p dir="auto">Gemini CLI is not limited to its pre-existing tools; it can use its coding abilities to fabricate new ones when needed. This often happens implicitly: if you ask for something complex, the AI might propose writing a temporary file (with code) and then running it. As a user, you can also guide this process explicitly:</p>
<ul dir="auto">
<li><strong>Creating scripts:</strong> You can prompt Gemini to create a script or program in the language of your choice. It will likely use the <code>write_file</code> tool to create the file. For instance:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="Generate a Node.js script that reads all '.log' files in the current directory and reports the number of lines in each."><pre>Generate a Node.js script that reads all <span><span>'</span>.log<span>'</span></span> files <span>in</span> the current directory and reports the number of lines <span>in</span> each.</pre></div>
<p dir="auto">Gemini CLI will draft the code, and with your approval, write it to a file (e.g. <code>script.js</code>). You can then run it by either using the <code>!</code> shell command (e.g. <code>!node script.js</code>) or by asking Gemini CLI to execute it (the AI might automatically use <code>run_shell_command</code> to execute the script it just wrote, if it deems it part of the plan).</p>
<ul dir="auto">
<li><strong>Temporary tools via MCP:</strong> In advanced scenarios, the AI might even suggest launching an MCP server for some specialized tasks. For example, if your prompt involves some heavy text processing that might be better done in Python, Gemini could generate a simple MCP server in Python and run it. While this is more rare, it demonstrates that the AI can set up a new "agent" on the fly. (One of the slides from the Gemini CLI team humorously referred to "MCP servers for everything, even one called LROwn" - suggesting you can have Gemini run an instance of itself or another model, though that's more of a trick than a practical use!).</li>
</ul>
<p dir="auto">The key benefit here is <strong>automation</strong>. Instead of you manually stopping to write a helper script, you can let the AI do it as part of the flow. It's like having an assistant who can create tools on-demand. This is especially useful for data transformation tasks, batch operations, or one-off computations that the built-in tools don't directly provide.</p>
<p dir="auto"><strong>Nuances and safety:</strong> When Gemini CLI writes code for a new tool, you should still review it before running. The <code>/diff</code> view (Gemini will show you the file diff before you approve writing it) is your chance to inspect the <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=Nobody%20enjoys%20switching%20between%20windows,track%20changes%20line%20by%20line" rel="nofollow">code</a>. Ensure it does what you expect and nothing malicious or destructive (the AI shouldn't produce something harmful unless your prompt explicitly asks, but just like any code from an AI, double-check logic, especially for scripts that delete or modify lots of data).</p>
<p dir="auto"><strong>Example scenario:</strong> Let's say you have a CSV file and you want to filter it in a complex way. You ask Gemini CLI to do it, and it might say: "I will write a Python script to parse the CSV and apply the filter." It then creates <code>filter_data.py</code>. After you approve and it runs, you get your result, and you might never need that script again. This ephemeral creation of tools is a pro move - it shows the AI effectively extending its capabilities autonomously.</p>
<p dir="auto"><strong>Pro Tip:</strong> If you find the script useful beyond the immediate context, you can promote it into a permanent tool or command. For instance, if the AI generated a great log-processing script, you might later turn it into a custom slash command (Tip #2) for easy reuse. The combination of Gemini's generative power and the extension hooks means your toolkit can continuously evolve as you use the CLI.</p>
<p dir="auto">In summary, <strong>don't restrict Gemini to what it comes with</strong>. Treat it as a junior developer who can whip up new programs or even mini-servers to help solve the problem. This approach embodies the agentic philosophy of Gemini CLI - it will figure out what tools it needs, even if it has to code them on the spot.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 9: Use Gemini CLI for System Troubleshooting &amp; Configuration</h2><a id="user-content-tip-9-use-gemini-cli-for-system-troubleshooting--configuration" aria-label="Permalink: Tip 9: Use Gemini CLI for System Troubleshooting &amp; Configuration" href="#tip-9-use-gemini-cli-for-system-troubleshooting--configuration"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> You can run Gemini CLI outside of a code project to help with general system tasks - think of it as an intelligent assistant for your OS. For example, if your shell is misbehaving, you could open Gemini in your home directory and ask: "Fix my <code>.bashrc</code> file, it has an error." Gemini can then open and edit your config file for you.</p>
<p dir="auto">This tip highlights that <strong>Gemini CLI isn't just for coding projects - it's your AI helper for your whole development environment</strong>. Many users have used Gemini to customize their dev setup or fix issues on their machine:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Editing dotfiles:</strong> You can load your shell configuration (<code>.bashrc</code> or <code>.zshrc</code>) by referencing it (<code>@~/.bashrc</code>) and then ask Gemini CLI to optimize or troubleshoot it. For instance, "My <code>PATH</code> isn't picking up Go binaries, can you edit my <code>.bashrc</code> to fix that?" The AI can insert the correct <code>export</code> line. It will show you the diff for confirmation before saving changes.</p>
</li>
<li>
<p dir="auto"><strong>Diagnosing errors:</strong> If you encounter a cryptic error in your terminal or an application log, you can copy it and feed it to Gemini CLI. It will analyze the error message and often suggest steps to resolve it. This is similar to how one might use StackOverflow or Google, but with the AI directly examining your scenario. For example: "When I run <code>npm install</code>, I get an <code>EACCES</code> permission error - how do I fix this?" Gemini might detect it's a permissions issue in <code>node_modules</code> and guide you to change directory ownership or use a proper node version manager.</p>
</li>
<li>
<p dir="auto"><strong>Running outside a project:</strong> By default, if you run <code>gemini</code> in a directory without a <code>.gemini</code> context, it just means no project-specific context is loaded - but you can still use the CLI fully. This is great for ad-hoc tasks like system troubleshooting. You might not have any code files for it to consider, but you can still run shell commands through it or let it fetch web info. Essentially, you're treating Gemini CLI as an AI-powered terminal that can <em>do</em> things for you, not just chat.</p>
</li>
<li>
<p dir="auto"><strong>Workstation customization:</strong> Want to change a setting or install a new tool? You can ask Gemini CLI, "Install Docker on my system" or "Configure my Git to sign commits with GPG." The CLI will attempt to execute the steps. It might fetch instructions from the web (using the search tool) and then run the appropriate shell commands. Of course, always watch what it's doing and approve the commands - but it can save time by automating multi-step setup processes. One real example: a user asked Gemini CLI to "set my macOS Dock preferences to auto-hide and remove the delay," and the AI was able to execute the necessary <code>defaults write</code> commands.</p>
</li>
</ul>
<p dir="auto">Think of this mode as using Gemini CLI as a <strong>smart shell</strong>. In fact, you can combine this with Tip 16 (shell passthrough mode) - sometimes you might drop into <code>!</code> shell mode to verify something, then go back to AI mode to have it analyze output.</p>
<p dir="auto"><strong>Caveat:</strong> When doing system-level tasks, be cautious with commands that have widespread impact (like <code>rm -rf</code> or system config changes). Gemini CLI will usually ask for confirmation, and it doesn't run anything without you seeing it. But as a power user, you should have a sense of what changes are being made. If unsure, ask Gemini to explain a command before running (e.g., "Explain what <code>defaults write com.apple.dock autohide-delay -float 0</code> does" - it will gladly explain rather than just execute if you prompt it in that way).</p>
<p dir="auto"><strong>Troubleshooting bonus:</strong> Another neat use is using Gemini CLI to parse logs or config files looking for issues. For instance, "Scan this Apache config for mistakes" (with <code>@httpd.conf</code>), or "Look through syslog for errors around 2 PM yesterday" (with an <code>@/var/log/syslog</code> if accessible). It's like having a co-administrator. It can even suggest likely causes for crashes or propose fixes for common error patterns.</p>
<p dir="auto">In summary, <strong>don't hesitate to fire up Gemini CLI as your assistant for environment issues</strong>. It's there to accelerate all your workflows - not just writing code, but maintaining the system that you write code on. Many users report that customizing their dev environment with Gemini's help feels like having a tech buddy always on call to handle the tedious or complex setup steps.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 10: YOLO Mode - Auto-Approve Tool Actions (Use with Caution)</h2><a id="user-content-tip-10-yolo-mode---auto-approve-tool-actions-use-with-caution" aria-label="Permalink: Tip 10: YOLO Mode - Auto-Approve Tool Actions (Use with Caution)" href="#tip-10-yolo-mode---auto-approve-tool-actions-use-with-caution"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If you're feeling confident (or adventurous), you can let Gemini CLI run tool actions without asking for your confirmation each time. This is <strong>YOLO mode</strong> (You Only Live Once). It's enabled by the <code>--yolo</code> flag or by pressing <code>Ctrl+Y</code> during a <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,prompt%20in%20an%20external%20editor" rel="nofollow">session</a>. In YOLO mode, as soon as the AI decides on a tool (like running a shell command or writing to a file), it executes it immediately, without that "Approve? (y/n)" prompt.</p>
<p dir="auto"><strong>Why use YOLO mode?</strong> Primarily for speed and convenience <strong>when you trust the AI's actions</strong>. Experienced users might toggle YOLO on if they're doing a lot of repetitive safe operations. For example, if you ask Gemini to generate 10 different files one after another, approving each can slow down the flow; YOLO mode would just let them all be written automatically. Another scenario is using Gemini CLI in a completely automated script or CI pipeline - you might run it headless with <code>--yolo</code> so it doesn't pause for confirmation.</p>
<p dir="auto">To start in YOLO mode from the get-go, launch the CLI with:</p>

<p dir="auto">Or the short form <code>gemini -y</code>. You'll see some indication in the CLI (like a different prompt or a notice) that auto-approve is <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=initial%20prompt.%20%2A%20%60,to%20revert%20changes" rel="nofollow">on</a>. During an interactive session, you can toggle it by pressing <strong>Ctrl+Y</strong> at any <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,prompt%20in%20an%20external%20editor" rel="nofollow">time</a> - the CLI will usually display a message like "YOLO mode enabled (all actions auto-approved)" in the footer.</p>
<p dir="auto"><strong>Big warning:</strong> YOLO mode is powerful but <strong>risky</strong>. The Gemini team themselves labels it for "daring users" - meaning you should be aware that the AI could potentially execute a dangerous command without asking. In normal mode, if the AI decided to run <code>rm -rf /</code> (worst-case scenario), you'd obviously decline. In YOLO mode, that command would run immediately (and likely ruin your day). While such extreme mistakes are unlikely (the AI's system prompt includes safety guidelines), the whole point of confirmations is to catch any unwanted action. YOLO removes that safety net.</p>
<p dir="auto"><strong>Best practices for YOLO:</strong> If you want some of the convenience without full risk, consider <em>allow-listing</em> specific commands. For example, you can configure in settings that certain tools or command patterns don't require confirmation (like allowing all <code>git</code> commands, or read-only actions). In fact, Gemini CLI supports a config for skipping confirmation on specific commands: e.g., you can set something like <code>"tools.shell.autoApprove": ["git ", "npm test"]</code> to always run <a href="https://google-gemini.github.io/gemini-cli/docs/cli/configuration.html#:~:text=match%20at%20L247%20%60%5B,Default%3A%20%60undefined" rel="nofollow">those</a>. This way, you might not need YOLO mode globally - you selectively YOLO only safe commands. Another approach: run Gemini in a sandbox or container when using YOLO, so even if it does something wild, your system is insulated (Gemini has a <code>--sandbox</code> flag to run tools in a Docker <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=echo%20,gemini" rel="nofollow">container</a>).</p>
<p dir="auto">Many advanced users toggle YOLO on and off frequently - turning it on when doing a string of minor file edits or queries, and off when about to do something critical. You can do the same, using the keyboard shortcut as a quick toggle.</p>
<p dir="auto">In summary, <strong>YOLO mode eliminates friction at the cost of oversight</strong>. It's a pro feature to use sparingly and wisely. It truly demonstrates trust in the AI (or recklessness!). If you're new to Gemini CLI, you should probably avoid YOLO until you clearly understand the patterns of what it tends to do. If you do use it, double down on having version control or backups - just in case.</p>
<p dir="auto"><em>(If it's any consolation, you're not alone - many in the community joke about "I YOLO'ed and Gemini did something crazy." So use it, but... well, you only live once.)</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 11: Headless &amp; Scripting Mode (Run Gemini CLI in the Background)</h2><a id="user-content-tip-11-headless--scripting-mode-run-gemini-cli-in-the-background" aria-label="Permalink: Tip 11: Headless &amp; Scripting Mode (Run Gemini CLI in the Background)" href="#tip-11-headless--scripting-mode-run-gemini-cli-in-the-background"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> You can use Gemini CLI in scripts or automation by running it in <strong>headless mode</strong>. This means you provide a prompt (or even a full conversation) via command-line arguments or environment variables, and Gemini CLI produces an output and exits. It's great for integrating with other tools or triggering AI tasks on a schedule.</p>
<p dir="auto">For instance, to get a one-off answer without opening the REPL, you've seen you can use <code>gemini -p "...prompt..."</code>. This is already headless usage: it prints the model's response and returns to the <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Non,and%20get%20a%20single%20response" rel="nofollow">shell</a>. But there's more you can do:</p>
<ul dir="auto">
<li><strong>System prompt override:</strong> If you want to run Gemini CLI with a custom system persona or instruction set (different from the default), you can use the environment variable <code>GEMINI_SYSTEM_MD</code>. By setting this, you tell Gemini CLI to ignore its built-in system prompt and use your provided file <a href="https://medium.com/google-cloud/practical-gemini-cli-bring-your-own-system-instruction-19ea7f07faa2#:~:text=The%20,rather%20than%20its%20hardcoded%20defaults" rel="nofollow">instead</a>. For example:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="export GEMINI_SYSTEM_MD=&quot;/path/to/custom_system.md&quot;
gemini -p &quot;Perform task X with high caution&quot;"><pre><span>export</span> GEMINI_SYSTEM_MD=<span><span>"</span>/path/to/custom_system.md<span>"</span></span>
gemini -p <span><span>"</span>Perform task X with high caution<span>"</span></span></pre></div>
<p dir="auto">This would load your <code>custom_system.md</code> as the system prompt (the "role" and rules the AI follows) before executing the <a href="https://medium.com/google-cloud/practical-gemini-cli-bring-your-own-system-instruction-19ea7f07faa2#:~:text=The%20feature%20is%20enabled%20by,specific%20configurations" rel="nofollow">prompt</a>. Alternatively, if you set <code>GEMINI_SYSTEM_MD=true</code>, the CLI will look for a file named <code>system.md</code> in the current project's <code>.gemini</code> <a href="https://medium.com/google-cloud/practical-gemini-cli-bring-your-own-system-instruction-19ea7f07faa2#:~:text=The%20feature%20is%20enabled%20by,specific%20configurations" rel="nofollow">directory</a>. This feature is very advanced - it essentially allows you to <em>replace the built-in brain</em> of the CLI with your own instructions, which some users do for specialized workflows (like simulating a specific persona or enforcing ultra-strict policies). Use it carefully, as replacing the core prompt can affect tool usage (the core prompt contains important directions for how the AI selects and uses <a href="https://medium.com/google-cloud/practical-gemini-cli-bring-your-own-system-instruction-19ea7f07faa2#:~:text=If%20you%20read%20my%20previous,proper%20functioning%20of%20Gemini%20CLI" rel="nofollow">tools</a>).</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Direct prompt via CLI:</strong> Aside from <code>-p</code>, there's also <code>-i</code> (interactive prompt) which starts a session with an initial prompt, and then keeps it open. For example: <code>gemini -i "Hello, let's debug something"</code> will open the REPL and already have said hello to the model. This is useful if you want the first question to be asked immediately when starting.</p>
</li>
<li>
<p dir="auto"><strong>Scripting with shell pipes:</strong> You can pipe not just text but also files or command outputs into Gemini. For example: <code>gemini -p "Summarize this log:" &lt; big_log.txt</code> will feed the content of <code>big_log.txt</code> into the prompt (after the phrase "Summarize this log:"). Or you might do <code>some_command | gemini -p "Given the above output, what went wrong?"</code>. This technique allows you to compose Unix tools with AI analysis. It's headless in the sense that it's a single-pass operation.</p>
</li>
<li>
<p dir="auto"><strong>Running in CI/CD:</strong> You could incorporate Gemini CLI into build processes. For instance, a CI pipeline might run a test and then use Gemini CLI to automatically analyze failing test output and post a comment. Using the <code>-p</code> flag and environment auth, this can be scripted. (Of course, ensure the environment has the API key or auth needed.)</p>
</li>
</ul>
<p dir="auto">One more headless trick: <strong>the <code>--format=json</code> flag</strong> (or config setting). Gemini CLI can output responses in JSON format instead of the human-readable text if you configure <a href="https://google-gemini.github.io/gemini-cli/docs/cli/configuration.html#:~:text=" rel="nofollow">it</a>. This is useful for programmatic consumption - your script can parse the JSON to get the answer or any tool actions details.</p>
<p dir="auto"><strong>Why headless mode matters:</strong> It transforms Gemini CLI from an interactive assistant into a <strong>backend service</strong> or utility that other programs can call. You could schedule a cronjob that runs a Gemini CLI prompt nightly (imagine generating a report or cleaning up something with AI logic). You could wire up a button in an IDE that triggers a headless Gemini run for a specific task.</p>
<p dir="auto"><strong>Example:</strong> Let's say you want a daily summary of a news website. You could have a script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini -p &quot;Web-fetch \&quot;https://news.site/top-stories\&quot; and extract the headlines, then write them to headlines.txt&quot;"><pre>gemini -p <span><span>"</span>Web-fetch <span>\"</span>https://news.site/top-stories<span>\"</span> and extract the headlines, then write them to headlines.txt<span>"</span></span></pre></div>
<p dir="auto">With <code>--yolo</code> perhaps, so it won't ask confirmation to write the file. This would use the web fetch tool to get the page and the file write tool to save the headlines. All automatically, no human in the loop. The possibilities are endless once you treat Gemini CLI as a scriptable component.</p>
<p dir="auto">In summary, <strong>Headless Mode</strong> enables automation. It's the bridge between Gemini CLI and other systems. Mastering it means you can scale up your AI usage - not just when you're typing in the terminal, but even when you aren't around, your AI agent can do work for you.</p>
<p dir="auto"><em>(Tip: For truly long-running non-interactive tasks, you might also look into Gemini CLI's "Plan" mode or how it can generate multi-step plans without intervention. However, those are advanced topics beyond this scope. In most cases, a well-crafted single prompt via headless mode can achieve a lot.)</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 12: Save and Resume Chat Sessions</h2><a id="user-content-tip-12-save-and-resume-chat-sessions" aria-label="Permalink: Tip 12: Save and Resume Chat Sessions" href="#tip-12-save-and-resume-chat-sessions"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If you've been debugging an issue with Gemini CLI for an hour and need to stop, you don't have to lose the conversation context. Use <code>/chat save &lt;name&gt;</code> to save the session. Later (even after restarting the CLI), you can use <code>/chat resume &lt;name&gt;</code> to pick up where you left <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,help%20information%20and%20available%20commands" rel="nofollow">off</a>. This way, long-running conversations can be paused and continued seamlessly.</p>
<p dir="auto">Gemini CLI essentially has a built-in chat session manager. The commands to know are:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>/chat save &lt;tag&gt;</code> - Saves the current conversation state under a tag/name you <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,help%20information%20and%20available%20commands" rel="nofollow">provide</a>. The tag is like a filename or key for that session. Save often if you want, it will overwrite the tag if it exists. (Using a descriptive name is helpful - e.g., <code>chat save fix-docker-issue</code>.)</p>
</li>
<li>
<p dir="auto"><code>/chat list</code> - Lists all your saved sessions (the tags you've <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,help%20information%20and%20available%20commands" rel="nofollow">used</a>. This helps you remember what you named previous saves.</p>
</li>
<li>
<p dir="auto"><code>/chat resume &lt;tag&gt;</code> - Resumes the session with that tag, restoring the entire conversation context and history to how it was when <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,help%20information%20and%20available%20commands" rel="nofollow">saved</a>. It's like you never left. You can then continue chatting from that point.</p>
</li>
<li>
<p dir="auto"><code>/chat share</code> - (saves to file) This is useful as you can share the entire chat with someone else who can continue the session. Almost collaboration-like.</p>
</li>
</ul>
<p dir="auto">Under the hood, these sessions are stored likely in <code>~/.gemini/chats/</code> or a similar location. They include the conversation messages and any relevant state. This feature is super useful for cases such as:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Long debugging sessions:</strong> Sometimes debugging with an AI can be a long back-and-forth. If you can't solve it in one go, save it and come back later (maybe with a fresh mind). The AI will still "remember" everything from before, because the whole context is reloaded.</p>
</li>
<li>
<p dir="auto"><strong>Multi-day tasks:</strong> If you're using Gemini CLI as an assistant for a project, you might have one chat session for "Refactor module X" that spans multiple days. You can resume that specific chat each day so the context doesn't reset daily. Meanwhile, you might have another session for "Write documentation" saved separately. Switching contexts is just a matter of saving one and resuming the other.</p>
</li>
<li>
<p dir="auto"><strong>Team hand-off:</strong> This is more experimental, but in theory, you could share the content of a saved chat with a colleague (the saved files are likely portable). If they put it in their <code>.gemini</code> directory and resume, they could see the same context. The <strong>practical simpler approach</strong> for collaboration is just copying the relevant Q&amp;A from the log and using a shared <code>GEMINI.md</code> or prompt, but it's interesting to note that the session data is yours to keep.</p>
</li>
</ul>
<p dir="auto"><strong>Usage example:</strong></p>

<p dir="auto"><em>(Session saved as "api-upgrade")</em></p>

<p dir="auto"><em>(Later, reopen CLI)</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ gemini
gemini> /chat list"><pre>$ gemini
gemini<span>&gt;</span> /chat list</pre></div>
<p dir="auto"><em>(Shows: api-upgrade)</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini> /chat resume api-upgrade"><pre>gemini<span>&gt;</span> /chat resume api-upgrade</pre></div>
<p dir="auto">Now the model greets you with the last exchange's state ready. You can confirm by scrolling up that all your previous messages are present.</p>
<p dir="auto"><strong>Pro Tip:</strong> Use meaningful tags when saving <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=Naming%20conventions%20to%20keep%20projects,organized" rel="nofollow">chats</a>. Instead of <code>/chat save session1</code>, give it a name related to the topic (e.g. <code>/chat save memory-leak-bug</code>). This will help you find the right one later via <code>/chat list</code>. There is no strict limit announced on how many sessions you can save, but cleaning up old ones occasionally might be wise just for organization.</p>
<p dir="auto">This feature turns Gemini CLI into a persistent advisor. You don't lose knowledge gained in a conversation; you can always pause and resume. It's a differentiator compared to some other AI interfaces that forget context when closed. For power users, it means <strong>you can maintain parallel threads of work</strong> with the AI. Just like you'd have multiple terminal tabs for different tasks, you can have multiple chat sessions saved and resume the one you need at any given time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 13: Multi-Directory Workspace - One Gemini, Many Folders</h2><a id="user-content-tip-13-multi-directory-workspace---one-gemini-many-folders" aria-label="Permalink: Tip 13: Multi-Directory Workspace - One Gemini, Many Folders" href="#tip-13-multi-directory-workspace---one-gemini-many-folders"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Do you have a project split across multiple repositories or directories? You can launch Gemini CLI with access to <em>all of them</em> at once, so it sees a unified workspace. For example, if your frontend and backend are separate folders, you can include both so that Gemini can edit or reference files in both.</p>
<p dir="auto">There are two ways to use <strong>multi-directory mode</strong>:</p>
<ul dir="auto">
<li><strong>Launch flag:</strong> Use the <code>--include-directories</code> (or <code>-I</code>) flag when starting Gemini CLI. For example:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="gemini --include-directories &quot;../backend:../frontend&quot;"><pre>gemini --include-directories <span><span>"</span>../backend:../frontend<span>"</span></span></pre></div>
<p dir="auto">This assumes you run the command from, say, a <code>scripts</code> directory and want to include two sibling folders. You provide a colon-separated list of paths. Gemini CLI will then treat all those directories as part of one big workspace.</p>
<ul dir="auto">
<li><strong>Persistent setting:</strong> In your <code>settings.json</code>, you can define <code>"includeDirectories": ["path1", "path2", [...]](https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,61AFEF%22%2C%20%22AccentPurple)</code>. This is useful if you always want certain common directories loaded (e.g., a shared library folder that multiple projects use). The paths can be relative or absolute. Environment variables in the paths (like <code>~/common-utils</code>) are <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=,61AFEF%22%2C%20%22AccentPurple" rel="nofollow">allowed</a>.</li>
</ul>
<p dir="auto">When multi-dir mode is active, the CLI's context and tools consider files across all included locations. The <code>&gt; /directory show</code> command will list which directories are in the current <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=How%20to%20add%20multiple%20directories,step" rel="nofollow">workspace</a>. You can also dynamically add directories during a session with <code>/directory add [&lt;path&gt;](https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=How%20to%20add%20multiple%20directories,step)</code> - it will then load that on the fly (potentially scanning it for context like it does on startup).</p>
<p dir="auto"><strong>Why use multi-directory mode?</strong> In microservice architectures or modular codebases, it's common that one piece of code lives in one repo and another piece in a different repo. If you only ran Gemini in one, it wouldn't "see" the others. By combining them, you enable cross-project reasoning. For example, you could ask, "Update the API client in the frontend to match the backend's new API endpoints" - Gemini can open the backend folder to see the API definitions and simultaneously open the frontend code to modify it accordingly. Without multi-dir, you'd have to do one side at a time and manually carry info over.</p>
<p dir="auto"><strong>Example:</strong> Let's say you have <code>client/</code> and <code>server/</code>. You start:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd client
gemini --include-directories &quot;../server&quot;"><pre><span>cd</span> client
gemini --include-directories <span><span>"</span>../server<span>"</span></span></pre></div>
<p dir="auto">Now at the <code>gemini&gt;</code> prompt, if you do <code>&gt; !ls</code>, you'll see it can list files in both <code>client</code> and <code>server</code> (it might show them as separate paths). You could do:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Open server/routes/api.py and client/src/api.js side by side to compare function names."><pre>Open server/routes/api.py and client/src/api.js side by side to compare <span>function</span> <span>names.</span></pre></div>
<p dir="auto">The AI will have access to both files. Or you might say:</p>
<div dir="auto" data-snippet-clipboard-copy-content="The API changed: the endpoint &quot;/users/create&quot; is now &quot;/users/register&quot;. Update both backend and frontend accordingly."><pre>The API changed: the endpoint <span><span>"</span>/users/create<span>"</span></span> is now <span><span>"</span>/users/register<span>"</span></span>. Update both backend and frontend accordingly.</pre></div>
<p dir="auto">It can simultaneously create a patch in the backend route and adjust the frontend fetch call.</p>
<p dir="auto">Under the hood, Gemini merges the file index of those directories. There might be some performance considerations if each directory is huge, but generally it handles multiple small-medium projects fine. The cheat sheet notes that this effectively creates one workspace with multiple <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%22includeDirectories%22%3A%20%5B%22..%2Fshared,98C379%22%2C%20%22AccentYellow" rel="nofollow">roots</a>.</p>
<p dir="auto"><strong>Tip within a tip:</strong> Even if you don't use multi-dir all the time, know that you can still reference files across the filesystem by absolute path in prompts (<code>@/path/to/file</code>). However, without multi-dir, Gemini might not have permission to edit those or know to load context from them proactively. Multi-dir formally includes them in scope so it's aware of all files for tasks like search or code generation across the whole set.</p>
<p dir="auto"><strong>Remove directories:</strong> If needed, <code>/directory remove &lt;path&gt;</code> (or a similar command) can drop a directory from the workspace. This is less common, but maybe if you included something accidentally, you can remove it.</p>
<p dir="auto">In summary, <strong>multi-directory mode unifies your context</strong>. It's a must-have for polyrepo projects or any situation where code is split up. It makes Gemini CLI act more like an IDE that has your entire solution open. As a pro user, this means no part of your project is out of the AI's reach.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 14: Organize and Clean Up Your Files with AI Assistance</h2><a id="user-content-tip-14-organize-and-clean-up-your-files-with-ai-assistance" aria-label="Permalink: Tip 14: Organize and Clean Up Your Files with AI Assistance" href="#tip-14-organize-and-clean-up-your-files-with-ai-assistance"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Tired of a messy <code>Downloads</code> folder or disorganized project assets? You can enlist Gemini CLI to act as a smart organizer. By providing it an overview of a directory, it can classify files and even move them into subfolders (with your approval). For instance, "Clean up my <code>Downloads</code>: move images to an <code>Images</code> folder, PDFs to <code>Documents</code>, and delete temporary files."</p>
<p dir="auto">Because Gemini CLI can read file names, sizes, and even peek into file contents, it can make informed decisions about file <a href="https://github.com/google-gemini/gemini-cli/discussions/7890#:~:text=We%20built%20a%20CLI%20tool,trash%20folder%20for%20manual%20deletion" data-hovercard-type="discussion" data-hovercard-url="/google-gemini/gemini-cli/discussions/7890/hovercard">organization</a>. One community-created tool dubbed <strong>"Janitor AI"</strong> showcases this: it runs via Gemini CLI to categorize files as important vs junk, and groups them <a href="https://github.com/google-gemini/gemini-cli/discussions/7890#:~:text=We%20built%20a%20CLI%20tool,trash%20folder%20for%20manual%20deletion" data-hovercard-type="discussion" data-hovercard-url="/google-gemini/gemini-cli/discussions/7890/hovercard">accordingly</a>. The process involved scanning the directory, using Gemini's reasoning on filenames and metadata (and content if needed), then moving files into categories. Notably, it didn't automatically delete junk - rather, it moved them to a <code>Trash</code> folder for <a href="https://github.com/google-gemini/gemini-cli/discussions/7890#:~:text=organize%20files,trash%20folder%20for%20manual%20deletion" data-hovercard-type="discussion" data-hovercard-url="/google-gemini/gemini-cli/discussions/7890/hovercard">review</a>.</p>
<p dir="auto">Here's how you might replicate such a workflow with Gemini CLI manually:</p>
<ol dir="auto">
<li><strong>Survey the directory:</strong> Use a prompt to have Gemini list and categorize. For example:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="List all files in the current directory and categorize them as &quot;images&quot;, &quot;videos&quot;, &quot;documents&quot;, &quot;archives&quot;, or &quot;others&quot;."><pre>List all files <span>in</span> the current directory and categorize them as <span><span>"</span>images<span>"</span></span>, <span><span>"</span>videos<span>"</span></span>, <span><span>"</span>documents<span>"</span></span>, <span><span>"</span>archives<span>"</span></span>, or <span><span>"</span>others<span>"</span></span>.</pre></div>
<p dir="auto">Gemini might use <code>!ls</code> or similar to get the file list, then analyze the names/extensions to produce categories.</p>
<ol dir="auto">
<li><strong>Plan the organization:</strong> Ask Gemini how it would like to reorganize. For example:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="Propose a new folder structure for these files. I want to separate by type (Images, Videos, Documents, etc.). Also identify any files that seem like duplicates or unnecessary."><pre>Propose a new folder structure <span>for</span> these files. I want to separate by <span>type</span> (Images, Videos, Documents, etc.). Also identify any files that seem like duplicates or unnecessary.</pre></div>
<p dir="auto">The AI might respond with a plan: e.g., <em>"Create folders: <code>Images/</code>, <code>Videos/</code>, <code>Documents/</code>, <code>Archives/</code>. Move <code>X.png</code>, <code>Y.jpg</code> to <code>Images/</code>; move <code>A.mp4</code> to <code>Videos/</code>; etc. The file <code>temp.txt</code> looks unnecessary (maybe a temp file)."</em></p>
<ol dir="auto">
<li><strong>Execute moves with confirmation:</strong> You can then instruct it to carry out the plan. It may use shell commands like <code>mv</code> for each file. Since this modifies your filesystem, you'll get confirmation prompts for each (unless you YOLO it). Carefully approve the moves. After completion, your directory will be neatly organized as suggested.</li>
</ol>
<p dir="auto">Throughout, Gemini's natural language understanding is key. It can reason, for instance, that <code>IMG_001.png</code> is an image or that <code>presentation.pdf</code> is a document, even if not explicitly stated. It can even open an image (using its vision capability) to see what's in it - e.g., differentiating between a screenshot vs a photo vs an icon - and name or sort it <a href="https://dev.to/therealmrmumba/7-insane-gemini-cli-tips-that-will-make-you-a-superhuman-developer-2d7h#:~:text=If%20your%20project%20folder%20is,using%20relevant%20and%20descriptive%20terms" rel="nofollow">accordingly</a>.</p>
<p dir="auto"><strong>Renaming files by content:</strong> A particularly magical use is having Gemini rename files to be more descriptive. The Dev Community article "7 Insane Gemini CLI Tips" describes how Gemini can <strong>scan images and automatically rename them</strong> based on their <a href="https://dev.to/therealmrmumba/7-insane-gemini-cli-tips-that-will-make-you-a-superhuman-developer-2d7h#:~:text=If%20your%20project%20folder%20is,using%20relevant%20and%20descriptive%20terms" rel="nofollow">content</a>. For example, a file named <code>IMG_1234.jpg</code> might be renamed to <code>login_screen.jpg</code> if the AI sees it's a screenshot of a login <a href="https://dev.to/therealmrmumba/7-insane-gemini-cli-tips-that-will-make-you-a-superhuman-developer-2d7h#:~:text=If%20your%20project%20folder%20is,using%20relevant%20and%20descriptive%20terms" rel="nofollow">screen</a>. To do this, you could prompt:</p>
<div dir="auto" data-snippet-clipboard-copy-content="For each .png image here, look at its content and rename it to something descriptive."><pre>For each .png image here, look at its content and rename it to something descriptive.</pre></div>
<p dir="auto">Gemini will open each image (via vision tool), get a description, then propose a <code>mv IMG_1234.png login_screen.png</code> <a href="https://dev.to/therealmrmumba/7-insane-gemini-cli-tips-that-will-make-you-a-superhuman-developer-2d7h#:~:text=If%20your%20project%20folder%20is,using%20relevant%20and%20descriptive%20terms" rel="nofollow">action</a>. This can dramatically improve the organization of assets, especially in design or photo folders.</p>
<p dir="auto"><strong>Two-pass approach:</strong> The Janitor AI discussion noted a two-step process: first broad categorization (important vs junk vs other), then refining <a href="https://github.com/google-gemini/gemini-cli/discussions/7890#:~:text=organize%20files,trash%20folder%20for%20manual%20deletion" data-hovercard-type="discussion" data-hovercard-url="/google-gemini/gemini-cli/discussions/7890/hovercard">groups</a>. You can emulate this: first separate files that likely can be deleted (maybe large installer <code>.dmg</code> files or duplicates) from those to keep. Then focus on organizing the keepers. Always double-check what the AI flags as junk; its guess might not always be right, so manual oversight is needed.</p>
<p dir="auto"><strong>Safety tip:</strong> When letting the AI loose on file moves or deletions, have backups or at least be ready to undo (with <code>/restore</code> or your own backup). It's wise to do a dry-run: ask Gemini to print the commands it <em>would</em> run to organize, without executing them, so you can review. For instance: "List the <code>mv</code> and <code>mkdir</code> commands needed for this plan, but don't execute them yet." Once you review the list, you can either copy-paste execute them, or instruct Gemini to proceed.</p>
<p dir="auto">This is a prime example of using Gemini CLI for "non-obvious" tasks - it's not just writing code, it's doing <strong>system housekeeping with AI smarts</strong>. It can save time and bring a bit of order to chaos. After all, as developers we accumulate clutter (logs, old scripts, downloads), and an AI janitor can be quite handy.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 15: Compress Long Conversations to Stay Within Context</h2><a id="user-content-tip-15-compress-long-conversations-to-stay-within-context" aria-label="Permalink: Tip 15: Compress Long Conversations to Stay Within Context" href="#tip-15-compress-long-conversations-to-stay-within-context"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If you've been chatting with Gemini CLI for a long time, you might hit the model's context length limit or just find the session getting unwieldy. Use the <code>/compress</code> command to summarize the conversation so far, replacing the full history with a concise <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Command%20Description%20,files" rel="nofollow">summary</a>. This frees up space for more discussion without starting from scratch.</p>
<p dir="auto">Large language models have a fixed context window (Gemini 2.5 Pro's is very large, but not infinite). If you exceed it, the model may start forgetting earlier messages or lose coherence. The <code>/compress</code> feature is essentially an <strong>AI-generated tl;dr</strong> of your session that keeps important points.</p>
<p dir="auto"><strong>How it works:</strong> When you type <code>/compress</code>, Gemini CLI will take the entire conversation (except system context) and produce a summary. It then replaces the chat history with that summary as a single system or assistant message, preserving essential details but dropping minute-by-minute dialogue. It will indicate that compression happened. For example, after <code>/compress</code>, you might see something like:</p>
<p dir="auto">--- Conversation compressed ---<br>
Summary of discussion: The user and assistant have been debugging a memory leak in an application. Key points: The issue is likely in <code>DataProcessor.js</code>, where objects aren't being freed. The assistant suggested adding logging and identified a possible infinite loop. The user is about to test a fix.<br>
--- End of summary ---</p>
<p dir="auto">From that point on, the model only has that summary (plus new messages) as context for what happened before. This usually is enough if the summary captured the salient info.</p>
<p dir="auto"><strong>When to compress:</strong> Ideally before you <em>hit</em> the limit. If you notice the session is getting lengthy (several hundred turns or a lot of code in context), compress proactively. The cheat sheet mentions an automatic compression setting (e.g., compress when context exceeds 60% of <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%22includeDirectories%22%3A%20%5B%22..%2Fshared,98C379%22%2C%20%22AccentYellow" rel="nofollow">max</a>). If you enable that, Gemini might auto-compress and let you know. Otherwise, manual <code>/compress</code> is in your toolkit.</p>
<p dir="auto"><strong>After compressing:</strong> You can continue the conversation normally. If needed, you can compress multiple times in a very long session. Each time, you lose some granularity, so don't compress too frequently for no reason - you might end up with an overly brief remembrance of a complex discussion. But generally the model's own summarization is pretty good at keeping the key facts (and you can always restate anything critical yourself).</p>
<p dir="auto"><strong>Context window example:</strong> Let's illustrate. Suppose you fed in a large codebase by referencing many files and had a 1M token context (the max). If you then want to shift to a different part of the project, rather than starting a new session (losing all that understanding), you could compress. The summary will condense the knowledge gleaned from the code (like "We loaded modules A, B, C. A has these functions... B interacts with C in these ways..."). Now you can proceed to ask about new things with that knowledge retained abstractly.</p>
<p dir="auto"><strong>Memory vs Compression:</strong> Note that compression doesn't save to long-term memory, it's local to the conversation. If you have facts you <em>never</em> want lost, consider Tip 4 (adding to <code>/memory</code>) - because memory entries will survive compression (they'll just be reinserted anyway since they are in <code>GEMINI.md</code> context). Compression is more about ephemeral chat content.</p>
<p dir="auto"><strong>A minor caution:</strong> after compression, the AI's style might slightly change because it's effectively seeing a "fresh" conversation with a summary. It might reintroduce itself or change tone. You can instruct it like "Continue from here... (we compressed)" to smooth it out. In practice, it often continues fine.</p>
<p dir="auto">To summarize (pun intended), <strong>use <code>/compress</code> as your session grows long</strong> to maintain performance and relevance. It helps Gemini CLI focus on the bigger picture instead of every detail of the conversation's history. This way, you can have marathon debugging sessions or extensive design discussions without running out of the "mental paper" the AI is writing on.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 16: Passthrough Shell Commands with <code>!</code> (Talk to Your Terminal)</h2><a id="user-content-tip-16-passthrough-shell-commands-with--talk-to-your-terminal" aria-label="Permalink: Tip 16: Passthrough Shell Commands with ! (Talk to Your Terminal)" href="#tip-16-passthrough-shell-commands-with--talk-to-your-terminal"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> At any point in a Gemini CLI session, you can run actual shell commands by prefixing them with <code>!</code>. For example, if you want to check the git status, just type <code>!git status</code> and it will execute in your <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Run%20a%20single%20command%3A" rel="nofollow">terminal</a>. This saves you from switching windows or context - you're still in the Gemini CLI, but you're essentially telling it "let me run this command real quick."</p>
<p dir="auto">This tip is about <strong>Shell Mode</strong> in Gemini CLI. There are two ways to use it:</p>
<ul dir="auto">
<li><strong>Single command:</strong> Just put <code>!</code> at the start of your prompt, followed by any command and arguments. This will execute that command in the current working directory and display the output <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Run%20shell%20commands%20directly%20in,the%20CLI" rel="nofollow">in-line</a>. For example:</li>
</ul>

<p dir="auto">will list the files in the <code>src</code> directory, outputting something like you'd see in a normal terminal. After the output, the Gemini prompt returns so you can continue chatting or issue more commands.</p>
<ul dir="auto">
<li><strong>Persistent shell mode:</strong> If you enter <code>!</code> alone and hit Enter, Gemini CLI switches into a sub-mode where you get a shell prompt (often it looks like <code>shell&gt;</code> or <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=" rel="nofollow">similar</a>. Now you can type multiple shell commands interactively. It's basically a mini-shell within the CLI. You exit this mode by typing <code>!</code> on an empty line again (or <code>exit</code>). For instance:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="!
shell> pwd
/home/alice/project
shell> python --version
Python 3.x.x
shell> !"><pre><span>!</span>
shell<span>&gt;</span> <span>pwd</span>
/home/alice/project
shell<span>&gt;</span> python --version
Python 3.x.x
shell<span>&gt;</span> <span>!</span></pre></div>
<p dir="auto">After the final <code>!</code>, you're back to the normal Gemini prompt.</p>
<p dir="auto"><strong>Why is this useful?</strong> Because development is a mix of actions and inquiries. You might be discussing something with the AI and realize you need to compile the code or run tests to see something. Instead of leaving the conversation, you can quickly do it and feed the result back into the chat. In fact, Gemini CLI often does this for you as part of its tool usage (it might automatically run <code>!pytest</code> when you ask to fix tests, for <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=" rel="nofollow">example</a>). But as the user, you have full control to do it manually too.</p>
<p dir="auto"><strong>Examples:</strong></p>
<ul dir="auto">
<li>
<p dir="auto">After Gemini suggests a fix in code, you can do <code>!npm run build</code> to see if it compiles, then copy any errors and ask Gemini to help with those.</p>
</li>
<li>
<p dir="auto">If you want to open a file in <code>vim</code> or <code>nano</code>, you could even launch it via <code>!nano filename</code> (though note that since Gemini CLI has its own interface, using an interactive editor inside it might be a bit awkward - better to use the built-in editor integration or copy to your editor).</p>
</li>
<li>
<p dir="auto">You can use shell commands to gather info for the AI: e.g., <code>!grep TODO -R .</code> to find all TODOs in the project, then you might ask Gemini to help address those TODOs.</p>
</li>
<li>
<p dir="auto">Or simply use it for environment tasks: <code>!pip install some-package</code> if needed, etc., without leaving the CLI.</p>
</li>
</ul>
<p dir="auto"><strong>Seamless interplay:</strong> One cool aspect is how the conversation can refer to outputs. For example, you could do <code>!curl http://example.com</code> to fetch some data, see the output, then immediately say to Gemini, "Format the above output as JSON" - since the output was printed in the chat, the AI has it in context to work with (provided it's not too large).</p>
<p dir="auto"><strong>Terminal as a default shell:</strong> If you find yourself always prefacing commands with <code>!</code>, you can actually make the shell mode persistent by default. One way is launching Gemini CLI with a specific tool mode (there's a concept of default tool). But easier: just drop into shell mode (<code>!</code> with nothing) at session start if you plan to run a lot of manual commands and only occasionally talk to AI. Then you can exit shell mode whenever you want to ask a question. It's almost like turning Gemini CLI into your normal terminal that happens to have an AI readily available.</p>
<p dir="auto"><strong>Integration with AI planning:</strong> Sometimes Gemini CLI itself will propose to run a shell command. If you approve, it effectively does the same as <code>!command</code>. Understanding that, you know you can always intervene. If Gemini is stuck or you want to try something, you don't have to wait for it to suggest - you can just do it and then continue.</p>
<p dir="auto">In summary, the <code>!</code> <strong>passthrough</strong> means <em>you don't have to leave Gemini CLI for shell tasks</em>. It collapses the boundary between chatting with the AI and executing commands on your system. As a pro user, this is fantastic for efficiency - your AI and your terminal become one continuous environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 17: Treat Every CLI Tool as a Potential Gemini Tool</h2><a id="user-content-tip-17-treat-every-cli-tool-as-a-potential-gemini-tool" aria-label="Permalink: Tip 17: Treat Every CLI Tool as a Potential Gemini Tool" href="#tip-17-treat-every-cli-tool-as-a-potential-gemini-tool"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Realize that Gemini CLI can leverage <strong>any</strong> command-line tool installed on your system as part of its problem-solving. The AI has access to the shell, so if you have <code>cURL</code>, <code>ImageMagick</code>, <code>git</code>, <code>Docker</code>, or any other tool, Gemini can invoke it when appropriate. In other words, <em>your entire <code>$PATH</code> is the AI's toolkit</em>. This greatly expands what it can do - far beyond its built-in tools.</p>
<p dir="auto">For example, say you ask: "Convert all PNG images in this folder to WebP format." If you have ImageMagick's <code>convert</code> utility installed, Gemini CLI might plan something like: use a shell loop with <code>convert</code> command for each <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=%3E%20%21for%20f%20in%20,png%7D.webp%22%3B%20done" rel="nofollow">file</a>. Indeed, one of the earlier examples from a blog showed exactly this, where the user prompted to batch-convert images, and Gemini executed a shell one-liner with the <code>convert</code> <a href="https://genmind.ch/posts/Howto-Supercharge-Your-Terminal-with-Gemini-CLI/#:~:text=" rel="nofollow">tool</a>.</p>
<p dir="auto">Another scenario: "Deploy my app to Docker." If <code>Docker CLI</code> is present, the AI could call <code>docker build</code> and <code>docker run</code> steps as needed. Or "Use FFmpeg to extract audio from <code>video.mp4</code>" - it can construct the <code>ffmpeg</code> command.</p>
<p dir="auto">This tip is about mindset: <strong>Gemini isn't limited to what's coded into it</strong> (which is already extensive). It can figure out how to use other programs available to achieve a <a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-4-built-in-tools-c591befa59ba#:~:text=In%20this%20part%2C%20we%20looked,In%20the%20next%20part%2C%20we" rel="nofollow">goal</a>. It knows common syntax and can read help texts if needed (it could call <code>--help</code> on a tool). The only limitation is safety: by default, it will ask confirmation for any <code>run_shell_command</code> it comes up with. But as you become comfortable, you might allow certain benign commands automatically (see YOLO or allowed-tools config).</p>
<p dir="auto"><strong>Be mindful of the environment:</strong> "With great power comes great responsibility." Since every shell tool is fair game, you should ensure that your <code>$PATH</code> doesn't include anything you wouldn't want the AI to run inadvertently. This is where Tip 19 (custom PATH) comes in - some users create a restricted <code>$PATH</code> for Gemini, so it can't, say, directly call system destructive commands or maybe not call <code>gemini</code> recursively (to avoid loops). The point is, by default if <code>gcc</code> or <code>terraform</code> or anything is in <code>$PATH</code>, Gemini could invoke it. It doesn't mean it will randomly do so - only if the task calls for it - but it's possible.</p>
<p dir="auto"><strong>Train of thought example:</strong> Imagine you ask Gemini CLI: "Set up a basic HTTP server that serves the current directory." The AI might think: "I can use Python's built-in server for this." It then issues <code>!python3 -m http.server 8000</code>. Now it just used a system tool (Python) to launch a server. That's an innocuous example. Another: "Check the memory usage on this Linux system." The AI might use the <code>free -h</code> command or read from <code>/proc/meminfo</code>. It's effectively doing what a sysadmin would do, by using available commands.</p>
<p dir="auto"><strong>All tools are extensions of the AI:</strong> This is somewhat futuristic, but consider that any command-line program can be seen as a "function" the AI can call to extend its capability. Need to solve a math problem? It could call <code>bc</code> (calculator). Need to manipulate an image? It could call an image processing tool. Need to query a database? If the CLI client is installed and credentials are there, it can use it. The possibilities are expansive. In other AI agent frameworks, this is known as tool use, and Gemini CLI is designed with a lot of trust in its agent to decide the right <a href="https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-deep-dive-into-gemini-cli-with-taylor-mullen#:~:text=The%20Gemini%20CLI%20%20is,understanding%20of%20the%20developer%20workflow" rel="nofollow">tool</a>.</p>
<p dir="auto"><strong>When it goes wrong:</strong> The flip side is if the AI misunderstands a tool or has a hallucination about one. It might try to call a command that doesn't exist, or use wrong flags, resulting in errors. This isn't a big deal - you'll see the error and can correct or clarify. In fact, the system prompt of Gemini CLI likely guides it to first do a dry-run (just propose the command) rather than executing blindly. So you often get a chance to catch these. Over time, the developers are improving the tool selection logic to reduce these missteps.</p>
<p dir="auto">The main takeaway is to <strong>think of Gemini CLI as having a very large Swiss Army knife</strong> - not just the built-in blades, but every tool in your OS. You don't have to instruct it on how to use them if it's something standard; usually it knows or can find out. This significantly amplifies what you can accomplish. It's like having a junior dev or devops engineer who knows how to run pretty much any program you have installed.</p>
<p dir="auto">As a pro user, you can even install additional CLI tools specifically to give Gemini more powers. For example, if you install a CLI for a cloud service (AWS CLI, GCloud CLI, etc.), in theory Gemini can utilize it to manage cloud resources if prompted to. Always ensure you understand and trust the commands run, especially with powerful tools (you wouldn't want it spinning up huge cloud instances accidentally). But used wisely, this concept - <strong>everything is a Gemini tool</strong> - is what makes it <em>exponentially</em> more capable as you integrate it into your environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 18: Utilize Multimodal AI - Let Gemini See Images and More</h2><a id="user-content-tip-18-utilize-multimodal-ai---let-gemini-see-images-and-more" aria-label="Permalink: Tip 18: Utilize Multimodal AI - Let Gemini See Images and More" href="#tip-18-utilize-multimodal-ai---let-gemini-see-images-and-more"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Gemini CLI isn't limited to text - it's multimodal. This means it can analyze images, diagrams, or even PDFs if given. Use this to your advantage. For instance, you could say "Here's a screenshot of an error dialog, <code>@./error.png</code> - help me troubleshoot this." The AI will "see" the image and respond accordingly.</p>
<p dir="auto">One of the standout features of Google's Gemini model (and its precursor PaLM2 in Codey form) is image understanding. In Gemini CLI, if you reference an image with <code>@</code>, the model receives the image data. It can output descriptions, classifications, or reason about the image's content. We already discussed renaming images by content (Tip 14) and describing screenshots (Tip 7). But let's consider other creative uses:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>UI/UX feedback:</strong> If you're a developer working with designers, you can drop a UI image and ask Gemini for feedback or to generate code. "Look at this UI mockup <code>@mockup.png</code> and produce a React component structure for it." It could identify elements in the image (header, buttons, etc.) and outline code.</p>
</li>
<li>
<p dir="auto"><strong>Organizing images:</strong> Beyond renaming, you might have a folder of mixed images and want to sort by content. "Sort the images in <code>./photos/</code> into subfolders by theme (e.g., sunsets, mountains, people)." The AI can look at each photo and categorize it (this is similar to what some photo apps do with AI - now you can do it with your own script via Gemini).</p>
</li>
<li>
<p dir="auto"><strong>OCR and data extraction:</strong> If you have a screenshot of error text or a photo of a document, Gemini can often read the text from it. For example, "Extract the text from <code>invoice.png</code> and put it into a structured format." As shown in a Google Cloud blog example, Gemini CLI can process a set of invoice images and output a table of their <a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-4-built-in-tools-c591befa59ba#:~:text=Press%20enter%20or%20click%20to,view%20image%20in%20full%20size" rel="nofollow">info</a>. It basically did OCR + understanding to get invoice numbers, dates, amounts from pictures of invoices. That's an advanced use-case but entirely possible with the multimodal model under the hood.</p>
</li>
<li>
<p dir="auto"><strong>Understanding graphs or charts:</strong> If you have a graph screenshot, you could ask "Explain this chart's key insights <code>@chart.png</code>." It might interpret the axes and trends. Accuracy can vary, but it's a nifty try.</p>
</li>
</ul>
<p dir="auto">To make this practical: when you <code>@image.png</code>, ensure the image isn't too huge (though the model can handle reasonably large images). The CLI will likely encode it and send it to the model. The response might include descriptions or further actions. You can mix text and image references in one prompt too.</p>
<p dir="auto"><strong>Non-image modalities:</strong> The CLI and model potentially can handle PDFs and audio too, by converting them via tools. For example, if you <code>@report.pdf</code>, Gemini CLI might use a PDF-to-text tool under the hood to extract text and then summarize. If you <code>@audio.mp3</code> and ask for a transcript, it might use an audio-to-text tool (like a speech recognition function). The cheat sheet suggests referencing PDFs, audio, video files is <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Reference%20files%20or%20directories%20in,PDFs%2C%20audio%2C%20and%20video%20files" rel="nofollow">supported</a>, presumably by invoking appropriate internal tools or APIs. So, "transcribe this interview audio: <code>@interview.wav</code>" could actually work (if not now, likely soon, since underlying Google APIs for speech-to-text could be plugged in).</p>
<p dir="auto"><strong>Rich outputs:</strong> Multimodal also means the AI can return images in responses if integrated (though in CLI it usually won't <em>display</em> them directly, but it could save an image file or output ASCII art, etc.). The MCP capability mentioned that tools can return <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Capabilities%3A" rel="nofollow">images</a>. For instance, an AI drawing tool could generate an image and Gemini CLI could present it (maybe by opening it or giving a link).</p>
<p dir="auto"><strong>Important:</strong> The CLI itself is text-based, so you won't <em>see</em> the image in the terminal (unless it's capable of ASCII previews). You'll just get the analysis. So this is mostly about reading images, not displaying them. If you're in VS Code integration, it might show images in the chat view.</p>
<p dir="auto">In summary, <strong>don't forget the "I" in GUI when using Gemini CLI</strong> - it can handle the visual just as well as the textual in many cases. This opens up workflows like visual debugging, design help, data extraction from screenshots, etc., all under the same tool. It's a differentiator that some other CLI tools may not have yet. And as models improve, this multimodal support will only get more powerful, so it's a future-proof skill to exploit.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 19: Customize the <code>$PATH</code> (and Tool Availability) for Stability</h2><a id="user-content-tip-19-customize-the-path-and-tool-availability-for-stability" aria-label="Permalink: Tip 19: Customize the $PATH (and Tool Availability) for Stability" href="#tip-19-customize-the-path-and-tool-availability-for-stability"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> If you ever find Gemini CLI getting confused or invoking the wrong programs, consider running it with a tailored <code>$PATH</code>. By limiting or ordering the available executables, you can prevent the AI from, say, calling a similarly named script that you didn't intend. Essentially, you sandbox its tool access to known-good tools.</p>
<p dir="auto">For most users, this isn't an issue, but for pro users with lots of custom scripts or multiple versions of tools, it can be helpful. One reason mentioned by the developers is avoiding infinite loops or weird <a href="https://github.com/google-gemini/gemini-cli/discussions/7890#:~:text=We%20built%20a%20CLI%20tool,trash%20folder%20for%20manual%20deletion" data-hovercard-type="discussion" data-hovercard-url="/google-gemini/gemini-cli/discussions/7890/hovercard">behavior</a>. For example, if <code>gemini</code> itself is in <code>$PATH</code>, an AI gone awry might recursively call <code>gemini</code> from within Gemini (a strange scenario, but theoretically possible). Or perhaps you have a command named <code>test</code> that conflicts with something - the AI might call the wrong one.</p>
<p dir="auto"><strong>How to set PATH for Gemini:</strong> Easiest is inline on launch:</p>
<div dir="auto" data-snippet-clipboard-copy-content="PATH=/usr/bin:/usr/local/bin gemini"><pre>PATH=/usr/bin:/usr/local/bin gemini</pre></div>
<p dir="auto">This runs Gemini CLI with a restricted <code>$PATH</code> of just those directories. You might exclude directories where experimental or dangerous scripts lie. Alternatively, create a small shell script wrapper that purges or adjusts <code>$PATH</code> then exec's <code>gemini</code>.</p>
<p dir="auto">Another approach is using environment or config to explicitly disable certain tools. For instance, if you absolutely never want the AI to use <code>rm</code> or some destructive tool, you could technically create an alias or dummy <code>rm</code> in a safe <code>$PATH</code> that does nothing (though this could interfere with normal operations, so maybe not that one). A better method is the <strong>exclude list</strong> in settings. In an extension or <code>settings.json</code>, you can exclude tool <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=" rel="nofollow">names</a>. E.g.,</p>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;excludeTools&quot;: [&quot;run_shell_command&quot;]"><pre><span>"excludeTools"</span>: [<span><span>"</span>run_shell_command<span>"</span></span>]</pre></div>
<p dir="auto">This extreme example would stop <em>all</em> shell commands from running (making Gemini effectively read-only). More granular, there was mention of skipping confirmation for some; similarly you might configure something like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;tools&quot;: {
  &quot;exclude&quot;: [&quot;apt-get&quot;, &quot;shutdown&quot;]
}"><pre><span>"tools"</span>: {
  <span>"exclude"</span>: [<span><span>"</span>apt-get<span>"</span></span>, <span><span>"</span>shutdown<span>"</span></span>]
}</pre></div>
<p dir="auto"><em>(This syntax is illustrative; consult docs for exact usage.)</em></p>
<p dir="auto">The principle is, by controlling the environment, you reduce risk of the AI doing something dumb with a tool it shouldn't. It's akin to child-proofing the house.</p>
<p dir="auto"><strong>Prevent infinite loops:</strong> One user scenario was a loop where Gemini kept reading its own output or re-reading files <a href="https://support.google.com/gemini/thread/337650803/infinite-loops-with-tool-code-in-answers?hl=en#:~:text=Community%20support,screen%20with%20weird%20scrolling" rel="nofollow">repeatedly</a>. Custom <code>$PATH</code> can't directly fix logic loops, but one cause could be if the AI calls a command that triggers itself. Ensuring it can't accidentally spawn another AI instance (like calling <code>bard</code> or <code>gemini</code> command, if it thought to do so) is good. Removing those from <code>$PATH</code> (or renaming them for that session) helps.</p>
<p dir="auto"><strong>Isolation via sandbox:</strong> Another alternative to messing with <code>$PATH</code> is using <code>--sandbox</code> mode (which uses Docker or Podman to run tools in an isolated <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=echo%20,gemini" rel="nofollow">environment</a>). In that case, the AI's actions are contained and have only the tools that sandbox image provides. You could supply a Docker image with a curated set of tools. This is heavy-handed but very safe.</p>
<p dir="auto"><strong>Custom PATH for specific tasks:</strong> You might have different <code>$PATH</code> setups for different projects. For example, in one project you want it to use a specific version of Node or a local toolchain. Launching <code>gemini</code> with the <code>$PATH</code> that points to those versions will ensure the AI uses the right one. Essentially, treat Gemini CLI like any user - it uses whatever environment you give it. So if you need it to pick <code>gcc-10</code> vs <code>gcc-12</code>, adjust <code>$PATH</code> or <code>CC</code> env var accordingly.</p>
<p dir="auto"><strong>In summary:</strong> <em>Guard rails.</em> As a power user, you have the ability to fine-tune the operating conditions of the AI. If you ever find a pattern of undesirable behavior tied to tool usage, tweaking <code>$PATH</code> is a quick remedy. For everyday use, you likely won't need this, but it's a pro tip to keep in mind if you integrate Gemini CLI into automation or CI: give it a controlled environment. That way, you know exactly what it can and cannot do, which increases reliability.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 20: Track and reduce token spend with token caching and stats</h2><a id="user-content-tip-20-track-and-reduce-token-spend-with-token-caching-and-stats" aria-label="Permalink: Tip 20: Track and reduce token spend with token caching and stats" href="#tip-20-track-and-reduce-token-spend-with-token-caching-and-stats"></a></p>
<p dir="auto">If you run long chats or repeatedly attach the same big files, you can cut cost and latency by turning on token caching and monitoring usage. With an API key or Vertex AI auth, Gemini CLI automatically reuses previously sent system instructions and context, so follow‚Äëup requests are cheaper. You can see the savings live in the CLI.</p>
<p dir="auto"><strong>How to use it</strong></p>
<p dir="auto">Use an auth mode that enables caching. Token caching is available when you authenticate with a Gemini API key or Vertex AI. It is not available with OAuth login today. <a href="https://google-gemini.github.io/gemini-cli/docs/cli/token-caching.html" rel="nofollow">Google Gemini</a></p>
<p dir="auto">Inspect your usage and cache hits. Run the <code>stats</code> command during a session. It shows total tokens and a <code>cached</code> field when caching is active.</p>

<p dir="auto">The command's description and cached reporting behavior are documented in the commands reference and FAQ. <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html?utm_source=chatgpt.com" rel="nofollow">Google Gemini+1</a></p>
<p dir="auto">Capture metrics in scripts. When running headless, output JSON and parse the <code>stats</code> block, which includes <code>tokens.cached</code> for each model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini -p &quot;Summarize README&quot; --output-format json"><pre>gemini -p <span><span>"</span>Summarize README<span>"</span></span> --output-format json</pre></div>
<p dir="auto">The headless guide documents the JSON schema with cached token counts. <a href="https://google-gemini.github.io/gemini-cli/docs/cli/headless.html" rel="nofollow">Google Gemini</a></p>
<p dir="auto">Save a session summary to file: For CI or budget tracking, write a JSON session summary to disk.</p>
<div dir="auto" data-snippet-clipboard-copy-content="gemini -p &quot;Analyze logs&quot; --session-summary usage.json"><pre>gemini -p <span><span>"</span>Analyze logs<span>"</span></span> --session-summary usage.json</pre></div>
<p dir="auto">This flag is listed in the changelog. <a href="https://google-gemini.github.io/gemini-cli/docs/changelogs/" rel="nofollow">Google Gemini</a></p>
<p dir="auto">With API key or Vertex auth, the CLI automatically reuses previously sent context so later turns send fewer tokens. Keeping <code>GEMINI.md</code> and large file references stable across turns increases cache hits; you'll see that reflected in stats as cached tokens.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 21: Use <code>/copy</code> for Quick Clipboard Copy</h2><a id="user-content-tip-21-use-copy-for-quick-clipboard-copy" aria-label="Permalink: Tip 21: Use /copy for Quick Clipboard Copy" href="#tip-21-use-copy-for-quick-clipboard-copy"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Instantly copy the latest answer or code snippet from Gemini CLI to your system clipboard, without any extraneous formatting or line <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,for%20easy%20sharing%20or%20reuse" rel="nofollow">numbers</a>. This is perfect for quickly pasting AI-generated code into your editor or sharing a result with a teammate.</p>
<p dir="auto">When Gemini CLI provides an answer (especially a multi-line code block), you often want to reuse it elsewhere. The <code>/copy</code> slash command makes this effortless by copying <em>the last output produced by the CLI</em> directly to your <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,for%20easy%20sharing%20or%20reuse" rel="nofollow">clipboard</a>. Unlike manual selection (which can grab line numbers or prompt text), <code>/copy</code> grabs only the raw response content. For example, if Gemini just generated a 50-line Python script, simply typing <code>/copy</code> will put that entire script into your clipboard, ready to paste - no need to scroll and select text. Under the hood, Gemini CLI uses the appropriate clipboard utility for your platform (e.g. <code>pbcopy</code> on macOS, <code>clip</code> on <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,clip" rel="nofollow">Windows</a>. Once you run the command, you'll typically see a confirmation message, and then you can paste the copied text wherever you need it.</p>
<p dir="auto"><strong>How it works:</strong> The <code>/copy</code> command requires that your system has a clipboard tool <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,clip" rel="nofollow">available</a>. On macOS and Windows, the required tools (<code>pbcopy</code> and <code>clip</code> respectively) are usually pre-installed. On Linux, you may need to install <code>xclip</code> or <code>xsel</code> for <code>/copy</code> to <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,clip" rel="nofollow">function</a>. After ensuring that, you can use <code>/copy</code> anytime after Gemini CLI prints an answer. It will capture the <em>entire</em> last response (even if it's long) and omit any internal numbering or formatting the CLI may show on-screen. This saves you from dealing with unwanted artifacts when transferring the content. It's a small feature, but a huge time-saver when you're iterating on code or compiling a report generated by the AI.</p>
<p dir="auto"><strong>Pro Tip:</strong> If you find the <code>/copy</code> command isn't working, double-check that your clipboard utilities are installed and accessible. For instance, Ubuntu users should run <code>sudo apt install xclip</code> to enable clipboard <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,clip" rel="nofollow">copying</a>. Once set up, <code>/copy</code> lets you share Gemini's outputs with zero friction - copy, paste, and you're done.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 22: Master <code>Ctrl+C</code> for Shell Mode and Exiting</h2><a id="user-content-tip-22-master-ctrlc-for-shell-mode-and-exiting" aria-label="Permalink: Tip 22: Master Ctrl+C for Shell Mode and Exiting" href="#tip-22-master-ctrlc-for-shell-mode-and-exiting"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Cleanly interrupt Gemini CLI or exit shell mode with a single keypress - and quit the CLI entirely with a quick double-tap - thanks to the versatile <strong>Ctrl+C</strong> <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">shortcut</a>. This gives you immediate control when you need to stop or exit.</p>
<p dir="auto">Gemini CLI operates like a REPL, and knowing how to break out of operations is essential. Pressing <strong>Ctrl+C</strong> once will cancel the current action or clear any input you've started typing, essentially acting as an "abort" <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">command</a>. For example, if the AI is generating a lengthy answer and you've seen enough, hit <code>Ctrl+C</code> - the generation stops immediately. If you had started typing a prompt but want to discard it, <code>Ctrl+C</code> will wipe the input line so you can start <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">fresh</a>. Additionally, if you are in <strong>shell mode</strong> (activated by typing <code>!</code> to run shell commands), a single <code>Ctrl+C</code> will exit shell mode and return you to the normal Gemini prompt (it sends an interrupt to the shell process <a href="https://milvus.io/ai-quick-reference/how-do-i-use-gemini-cli-for-shell-command-generation#:~:text=The%20shell%20integration%20also%20includes,where%20you%20can%20generate%20commands" rel="nofollow">running</a>. This is extremely handy if a shell command is hanging or you simply want to get back to AI mode.</p>
<p dir="auto">Pressing <strong>Ctrl+C twice</strong> in a row is the shortcut to exit Gemini CLI <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">entirely</a>. Think of it as "<code>Ctrl+C</code> to cancel, and <code>Ctrl+C</code> again to quit." This double-tap signals the CLI to terminate the session (you'll see a goodbye message or the program will close). It's a faster alternative to typing <code>/quit</code> or closing the terminal window, allowing you to gracefully shut down the CLI from the keyboard. Do note that a single <code>Ctrl+C</code> will not quit if there's input to clear or an operation to interrupt - it requires that second press (when the prompt is idle) to fully <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">exit</a>. This design prevents accidentally closing the session when you only meant to stop the current output.</p>
<p dir="auto"><strong>Pro Tip:</strong> In shell mode, you can also press the <strong>Esc</strong> key to leave shell mode and return to Gemini's chat mode without terminating the <a href="https://milvus.io/ai-quick-reference/how-do-i-use-gemini-cli-for-shell-command-generation#:~:text=The%20shell%20integration%20also%20includes,where%20you%20can%20generate%20commands" rel="nofollow">CLI</a>. And if you prefer a more formal exit, the <code>/quit</code> command is always available to cleanly end the session. Lastly, Unix users can use <strong>Ctrl+D</strong> (EOF) at an empty prompt to exit as well - Gemini CLI will prompt for confirmation if <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Shortcut%20Description%20,Press%20twice%20to%20confirm" rel="nofollow">needed</a>. But for most cases, mastering the single- and double-tap of <code>Ctrl+C</code> is the quickest way to stay in control.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 23: Customize Gemini CLI with <code>settings.json</code></h2><a id="user-content-tip-23-customize-gemini-cli-with-settingsjson" aria-label="Permalink: Tip 23: Customize Gemini CLI with settings.json" href="#tip-23-customize-gemini-cli-with-settingsjson"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Adapt the CLI's behavior and appearance to your preferences or project conventions by editing the <code>settings.json</code> config file, instead of sticking with one-size-fits-all <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%2A%20%60autoAccept%60%3A%20Auto,to%20disable%20usage%20statistics" rel="nofollow">defaults</a>. This lets you enforce things like theme, tool usage rules, or editor mode across all your sessions.</p>
<p dir="auto">Gemini CLI is highly configurable. In your home directory (<code>~/.gemini/</code>) or project folder (<code>.gemini/</code> within your repo), you can create a <code>settings.json</code> file to override default <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Customize%20the%20CLI%20by%20creating,applied%20with%20the%20following%20precedence" rel="nofollow">settings</a>. Nearly every aspect of the CLI can be tuned here - from visual theme to tool permissions. The CLI merges settings from multiple levels: system-wide defaults, your user settings, and project-specific settings (project settings override user <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Customize%20the%20CLI%20by%20creating,applied%20with%20the%20following%20precedence" rel="nofollow">settings</a>. For example, you might have a global preference for a dark theme, but a particular project might require stricter tool sandboxing; you can handle this via different <code>settings.json</code> files at each level.</p>
<p dir="auto">Inside <code>settings.json</code>, options are specified as JSON key-value pairs. Here's a snippet illustrating some useful customizations:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
&quot;theme&quot;: &quot;GitHub&quot;,
&quot;autoAccept&quot;: false,
&quot;vimMode&quot;: true,
&quot;sandbox&quot;: &quot;docker&quot;,
&quot;includeDirectories&quot;: [&quot;../shared-library&quot;, &quot;~/common-utils&quot;],
&quot;usageStatisticsEnabled&quot;: true
}"><pre>{
<span>"theme"</span>: <span><span>"</span>GitHub<span>"</span></span>,
<span>"autoAccept"</span>: <span>false</span>,
<span>"vimMode"</span>: <span>true</span>,
<span>"sandbox"</span>: <span><span>"</span>docker<span>"</span></span>,
<span>"includeDirectories"</span>: [<span><span>"</span>../shared-library<span>"</span></span>, <span><span>"</span>~/common-utils<span>"</span></span>],
<span>"usageStatisticsEnabled"</span>: <span>true</span>
}</pre></div>
<p dir="auto">In this example, we set the theme to "GitHub" (a popular color scheme), disable <code>autoAccept</code> (so the CLI will always ask before running potentially altering tools), enable Vim keybindings for the input editor, and enforce using Docker for tool sandboxing. We also added some directories to the workspace context (<code>includeDirectories</code>) so Gemini can see code in shared paths by <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%7B%20,utils" rel="nofollow">default</a>. Finally, we kept <code>usageStatisticsEnabled</code> true to collect basic usage stats (which feeds into telemetry, if <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%2A%20%60autoAccept%60%3A%20Auto,to%20disable%20usage%20statistics" rel="nofollow">enabled</a>. There are many more settings available - like defining custom color themes, adjusting token limits, or whitelisting/blacklisting specific tools - all documented in the configuration <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=%2A%20%60autoAccept%60%3A%20Auto,to%20disable%20usage%20statistics" rel="nofollow">guide</a>. By tailoring these, you ensure Gemini CLI behaves optimally for <em>your</em> workflow (for instance, some developers always want <code>vimMode</code> on for efficiency, while others might prefer the default editor).</p>
<p dir="auto">One convenient way to edit settings is via the built-in settings UI. Run the command <code>/settings</code> in Gemini CLI, and it will open an interactive editor for your <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,their%20current%20values%2C%20and%20modify" rel="nofollow">configuration</a>. This interface lets you browse and search settings with descriptions, and prevents JSON syntax errors by validating inputs. You can tweak colors, toggle features like <code>yolo</code> (auto-approval), adjust checkpointing (file save/restore behavior), and more through a friendly <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,their%20current%20values%2C%20and%20modify" rel="nofollow">menu</a>. Changes are saved to your <code>settings.json</code>, and some take effect immediately (others might require restarting the CLI).</p>
<p dir="auto"><strong>Pro Tip:</strong> Maintain separate project-specific <code>settings.json</code> files for different needs. For example, on a team project you might set <code>"sandbox": "docker"</code> and <code>"excludeTools": ["run_shell_command"]</code> to lock down dangerous operations, while your personal projects might allow direct shell commands. Gemini CLI will automatically pick up the nearest <code>.gemini/settings.json</code> in your project directory tree and merge it with your global <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Customize%20the%20CLI%20by%20creating,applied%20with%20the%20following%20precedence" rel="nofollow"><code>~/.gemini/settings.json</code></a>. Also, don't forget you can quickly adjust visual preferences: try <code>/theme</code> to interactively switch themes without editing the file, which is great for finding a comfortable <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Command%20Description%20,tag%3E%60Save%20the%20current%20conversation" rel="nofollow">look</a>. Once you find one, put it in <code>settings.json</code> to make it permanent.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 24: Leverage IDE Integration (VS Code) for Context &amp; Diffs</h2><a id="user-content-tip-24-leverage-ide-integration-vs-code-for-context--diffs" aria-label="Permalink: Tip 24: Leverage IDE Integration (VS Code) for Context &amp; Diffs" href="#tip-24-leverage-ide-integration-vs-code-for-context--diffs"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Supercharge Gemini CLI by hooking it into VS Code - the CLI will automatically know which files you're working on and even open AI-proposed code changes in VS Code's diff editor for <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=,working%20on%20at%20the%20moment" rel="nofollow">you</a>. This creates a seamless loop between AI assistant and your coding workspace.</p>
<p dir="auto">One of Gemini CLI's powerful features is its <strong>IDE integration</strong> with Visual Studio Code. By installing the official <em>Gemini CLI Companion</em> extension in VS Code and connecting it, you allow Gemini CLI to become "context-aware" of your <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=,working%20on%20at%20the%20moment" rel="nofollow">editor</a>. What does this mean in practice? When connected, Gemini knows about the files you have open, your current cursor location, and any text you've selected in VS <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=,working%20on%20at%20the%20moment" rel="nofollow">Code</a>. All that information is fed into the AI's context. So if you ask, "Explain this function," Gemini CLI can see the exact function you've highlighted and give a relevant answer, without you needing to copy-paste code into the prompt. The integration shares up to your 10 most recently opened files, plus selection and cursor info, giving the model a rich understanding of your <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=,reject%20the%20suggested%20changes%20seamlessly" rel="nofollow">workspace</a>.</p>
<p dir="auto">Another huge benefit is <strong>native diffing</strong> of code changes. When Gemini CLI suggests modifications to your code (for example, "refactor this function" and it produces a patch), it can open those changes in VS Code's diff viewer <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=%2A%20Native%20in,the%20code%20right%20within%20this" rel="nofollow">automatically</a>. You'll see a side-by-side diff in VS Code showing the proposed edits. You can then use VS Code's familiar interface to review the changes, make any manual tweaks, and even accept the patch with a click. The CLI and editor stay in sync - if you accept the diff in VS Code, Gemini CLI knows and continues the session with those changes applied. This tight loop means you no longer have to copy code from the terminal to your editor; the AI's suggestions flow straight into your development environment.</p>
<p dir="auto"><strong>How to set it up:</strong> If you start Gemini CLI inside VS Code's integrated terminal, it will detect VS Code and usually prompt you to install/connect the extension <a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-10-gemini-cli-vs-code-integration-26afd3422028#:~:text=Press%20enter%20or%20click%20to,view%20image%20in%20full%20size" rel="nofollow">automatically</a>. You can agree and it will run the necessary <code>/ide install</code> step. If you don't see a prompt (or you're enabling it later), simply open Gemini CLI and run the command: <code>/ide install</code>. This will fetch and install the "Gemini CLI Companion" extension into VS Code for <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=2%3A%20One,install%20the%20necessary%20companion%20extension" rel="nofollow">you</a>. Next, run <code>/ide enable</code> to establish the <a href="https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/?source=post_page-----26afd3422028---------------------------------------#:~:text=3%3A%20Toggle%20integration%3A%20After%20the,can%20easily%20manage%20the%20integration" rel="nofollow">connection</a> - the CLI will then indicate it's linked to VS Code. You can verify at any time with <code>/ide status</code>, which will show if it's connected and list which editor and files are being <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=Checking%20the%20Status" rel="nofollow">tracked</a>. From then on, Gemini CLI will automatically receive context from VS Code (open files, selections) and will open diffs in VS Code when needed. It essentially turns Gemini CLI into an AI pair programmer that lives in your terminal but operates with full awareness of your IDE.</p>
<p dir="auto">Currently, VS Code is the primary supported editor for this <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=better%20and%20enables%20powerful%20features,editor%20diffing" rel="nofollow">integration</a>. (Other editors that support VS Code extensions, like VSCodium or some JetBrains via a plugin, may work via the same extension, but officially it's VS Code for now.) The design is open though - there's an IDE Companion Spec for developing similar integrations with other <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=better%20and%20enables%20powerful%20features,editor%20diffing" rel="nofollow">editors</a>. So down the road we might see first-class support for IDEs like IntelliJ or Vim via community extensions.</p>
<p dir="auto"><strong>Pro Tip:</strong> Once connected, you can use VS Code's Command Palette to control Gemini CLI without leaving the <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=,Ctrl%2BShift%2BP" rel="nofollow">editor</a>. For example, press <strong>Ctrl+Shift+P</strong> (Cmd+Shift+P on Mac) and try commands like <strong>"Gemini CLI: Run"</strong> (to launch a new CLI session in the terminal), <strong>"Gemini CLI: Accept Diff"</strong> (to approve and apply an open diff), or <strong>"Gemini CLI: Close Diff Editor"</strong> (to reject <a href="https://gemini-cli.xyz/docs/en/ide-integration#:~:text=,Ctrl%2BShift%2BP" rel="nofollow">changes</a>. These shortcuts can streamline your workflow even further. And remember, you don't always have to start the CLI manually - if you enable the integration, Gemini CLI essentially becomes an AI co-developer inside VS Code, watching context and ready to help as you work on code.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 25: Automate Repo Tasks with <code>Gemini CLI GitHub Action</code></h2><a id="user-content-tip-25-automate-repo-tasks-with-gemini-cli-github-action" aria-label="Permalink: Tip 25: Automate Repo Tasks with Gemini CLI GitHub Action" href="#tip-25-automate-repo-tasks-with-gemini-cli-github-action"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Put Gemini to work on GitHub - use the <strong>Gemini CLI GitHub Action</strong> to autonomously triage new issues and review pull requests in your repository, acting as an AI teammate that handles routine dev <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=1,write%20tests%20for%20this" rel="nofollow">tasks</a>.</p>
<p dir="auto">Gemini CLI isn't just for interactive terminal sessions; it can also run in CI/CD pipelines via GitHub Actions. Google has provided a ready-made <strong>Gemini CLI GitHub Action</strong> (currently in beta) that integrates into your repo's <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=It%E2%80%99s%20now%20in%20beta%2C%20available,cli" rel="nofollow">workflows</a>. This effectively deploys an AI agent into your project on GitHub. It runs in the background, triggered by repository <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=Triggered%20by%20events%20like%20new,do%2C%20and%20gets%20it%20done" rel="nofollow">events</a>. For example, when someone opens a <strong>new issue</strong>, the Gemini Action can automatically analyze the issue description, apply relevant labels, and even prioritize it or suggest duplicates (this is the "intelligent issue triage" <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=1,attention%20on%20what%20matters%20most" rel="nofollow">workflow</a>. When a <strong>pull request</strong> is opened, the Action kicks in to provide an <strong>AI code review</strong> - it will comment on the PR with insights about code quality, potential bugs, or stylistic <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=attention%20on%20what%20matters%20most,more%20complex%20tasks%20and%20decisions" rel="nofollow">improvements</a>. This gives maintainers immediate feedback on the PR before any human even looks at it. Perhaps the coolest feature is <strong>on-demand collaboration</strong>: team members can mention <code>@gemini-cli</code> in an issue or PR comment and give it an instruction, like "<code>@gemini-cli</code> please write unit tests for this". The Action will pick that up and Gemini CLI will attempt to fulfill the request (adding a commit with new tests, for <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=freeing%20up%20reviewers%20to%20focus,write%20tests%20for%20this" rel="nofollow">instance</a>. It's like having an AI assistant living in your repo, ready to do chores when asked.</p>
<p dir="auto">Setting up the Gemini CLI GitHub Action is straightforward. First, ensure you have Gemini CLI version <strong>0.1.18 or later</strong> installed locally (this ensures compatibility with the <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=Gemini%20CLI%20GitHub%20Actions%20is,for%20individual%20users%20available%20soon" rel="nofollow">Action</a>. Then, in Gemini CLI run the special command: <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=To%20get%20started%2C%20download%20Gemini,cli" rel="nofollow"><code>/setup-github</code></a>. This command generates the necessary workflow files in your repository (it will guide you through authentication if needed). Specifically, it adds YAML workflow files (for issue triage, PR review, etc.) under <code>.github/workflows/</code>. You will need to add your Gemini API key to the repo's secrets (as <code>GEMINI_API_KEY</code>) so the Action can use the Gemini <a href="https://github.com/google-github-actions/run-gemini-cli#:~:text=Store%20your%20API%20key%20as,in%20your%20repository">API</a>. Once that's done and the workflows are committed, the GitHub Action springs to life - from that point on, Gemini CLI will autonomously respond to new issues and PRs according to those workflows.</p>
<p dir="auto">Because this Action is essentially running Gemini CLI in an automated way, you can customize it just like you would your CLI. The default setup comes with three workflows (issue triage, PR review, and a general mention-triggered assistant) which are **fully open-source and <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=Think%20of%20these%20initial%20workflows,into%20Gemini%20CLI%20GitHub%20Actions" rel="nofollow">editable**</a>. You can tweak the YAML to adjust what the AI does, or even add new workflows. For instance, you might create a nightly workflow that uses Gemini CLI to scan your repository for outdated dependencies or to update a README based on recent code changes - the possibilities are endless. The key benefit here is offloading mundane or time-consuming tasks to an AI agent so that human developers can focus on harder problems. And since it runs on GitHub's infrastructure, it doesn't require your intervention - it's truly a "set and forget" AI helper.</p>
<p dir="auto"><strong>Pro Tip:</strong> Keep an eye on the Action's output in the GitHub Actions logs for transparency. The Gemini CLI Action logs will show what prompts it ran and what changes it made or suggested. This can both build trust and help you refine its behavior. Also, the team has built enterprise-grade safeguards into the Action - e.g., you can require that all shell commands the AI tries to run in a workflow are allow-listed by <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/#:~:text=in%20your%20environment%2C%20drastically%20reducing,your%20preferred%20observability%20platform%2C%20like" rel="nofollow">you</a>. So don't hesitate to use it even on serious projects. And if you come up with a cool custom workflow using Gemini CLI, consider contributing it back to the community - the project welcomes new ideas in their repo!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 26: Enable Telemetry for Insights and Observability</h2><a id="user-content-tip-26-enable-telemetry-for-insights-and-observability" aria-label="Permalink: Tip 26: Enable Telemetry for Insights and Observability" href="#tip-26-enable-telemetry-for-insights-and-observability"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Gain deeper insight into how Gemini CLI is being used and performing by turning on its built-in <strong>OpenTelemetry</strong> instrumentation - monitor metrics, logs, and traces of your AI sessions to analyze usage patterns or troubleshoot <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=,across%20teams%2C%20track%20costs%2C%20ensure" rel="nofollow">issues</a>.</p>
<p dir="auto">For developers who like to measure and optimize, Gemini CLI offers an observability feature that exposes what's happening under the hood. By leveraging <strong>OpenTelemetry (OTEL)</strong>, Gemini CLI can emit structured telemetry data about your <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=Built%20on%20OpenTelemetry%20%E2%80%94%20the,Gemini%20CLI%E2%80%99s%20observability%20system%20provides" rel="nofollow">sessions</a>. This includes things like metrics (e.g. how many tokens used, response latency), logs of actions taken, and even traces of tool calls. With telemetry enabled, you can answer questions like: <em>Which custom command do I use most often? How many times did the AI edit files in this project this week? What's the average response time when I ask the CLI to run tests?</em> Such data is invaluable for understanding usage patterns and <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=,across%20teams%2C%20track%20costs%2C%20ensure" rel="nofollow">performance</a>. Teams can use it to see how developers are interacting with the AI assistant and where bottlenecks might be.</p>
<p dir="auto">By default, telemetry is <strong>off</strong> (Gemini respects privacy and performance). You can opt-in by setting <code>"telemetry.enabled": true</code> in your <code>settings.json</code> or by starting Gemini CLI with the flag <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=Setting%20Environment%20Variable%20CLI%20Flag,grpc" rel="nofollow"><code>--telemetry</code></a>. Additionally, you choose the <strong>target</strong> for the telemetry data: it can be logged <strong>locally</strong> or sent to a backend like Google Cloud. For a quick start, you might set <code>"telemetry.target": "local"</code> - with this, Gemini will simply write telemetry data to a local file (by default) or to a custom path you specify via <code>["outfile"](https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=disable%20telemetry%20,file%20path)</code>. The local telemetry includes JSON logs you can parse or feed into tools. For more robust monitoring, set <code>"target": "gcp"</code> (Google Cloud) or even integrate with other OpenTelemetry-compatible systems like Jaeger or <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=,between%20backends%20without%20changing%20your" rel="nofollow">Datadog</a>. In fact, Gemini CLI's OTEL support is vendor-neutral - you can export data to just about any observability stack you prefer (Google Cloud Operations, Prometheus, <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=,between%20backends%20without%20changing%20your" rel="nofollow">etc.</a>. Google provides a streamlined path for Cloud: if you point to GCP, the CLI can send data directly to Cloud Logging and Cloud Monitoring in your project, where you can use the usual dashboards and alerting <a href="https://google-gemini.github.io/gemini-cli/docs/cli/telemetry.html#:~:text=2,explorer%20%2A%20Traces%3A%20https%3A%2F%2Fconsole.cloud.google.com%2Ftraces%2Flist" rel="nofollow">tools</a>.</p>
<p dir="auto">What kind of insights can you get? The telemetry captures events like tool executions, errors, and important milestones. It also records metrics such as prompt processing time and token counts per <a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-13-gemini-cli-observability-c410806bc112#:~:text=,integrate%20with%20existing%20monitoring%20infrastructure" rel="nofollow">prompt</a>. For usage analytics, you might aggregate how many times each slash command is used across your team, or how often code generation is invoked. For performance monitoring, you could track if responses have gotten slower, which might indicate hitting API rate limits or model changes. And for debugging, you can see errors or exceptions thrown by tools (e.g., a <code>run_shell_command</code> failure) logged with context. All this data can be visualized if you send it to a platform like Google Cloud's Monitoring - for example, you can create a dashboard of "tokens used per day" or "error rate of tool X". It essentially gives you a window into the AI's "brain" and your usage, which is especially helpful in enterprise settings to ensure everything runs <a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-13-gemini-cli-observability-c410806bc112#:~:text=resource%20utilization%20%2A%20%20Real,integrate%20with%20existing%20monitoring%20infrastructure" rel="nofollow">smoothly</a>.</p>
<p dir="auto">Enabling telemetry does introduce some overhead (extra data processing), so you might not keep it on 100% of the time for personal use. However, it's fantastic for debugging sessions or for intermittent health checks. One approach is to enable it on a CI server or in your team's shared environment to collect stats, while leaving it off locally unless needed. Remember, you can always toggle it on the fly: update settings and use <code>/memory refresh</code> if needed to reload, or restart Gemini CLI with <code>--telemetry</code> flag. Also, all telemetry is under your control - it respects your environment variables for endpoint and credentials, so data goes only where you intend it to. This feature turns Gemini CLI from a black box into an observatory, shining light on how the AI agent interacts with your world, so you can continuously improve that interaction.</p>
<p dir="auto"><strong>Pro Tip:</strong> If you just want a quick view of your current session's stats (without full telemetry), use the <code>/stats</code> command. It will output metrics like token usage and session length right in the <a href="https://www.howtouselinux.com/post/the-complete-google-gemini-cli-cheat-sheet-and-guide#:~:text=Command%20Description%20,tag%3E%60Save%20the%20current%20conversation" rel="nofollow">CLI</a>. This is a lightweight way to see immediate numbers. But for long-term or multi-session analysis, telemetry is the way to go. And if you're sending telemetry to a cloud project, consider setting up dashboards or alerts (e.g., alert if error rate spikes or token usage hits a threshold) - this can proactively catch issues in how Gemini CLI is being used in your team.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 27: Keep an Eye on the Roadmap (Background Agents &amp; More)</h2><a id="user-content-tip-27-keep-an-eye-on-the-roadmap-background-agents--more" aria-label="Permalink: Tip 27: Keep an Eye on the Roadmap (Background Agents &amp; More)" href="#tip-27-keep-an-eye-on-the-roadmap-background-agents--more"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Stay informed about upcoming Gemini CLI features - by following the public <strong>Gemini CLI roadmap</strong>, you'll know about major planned enhancements (like <em>background agents for long-running tasks</em>) before they <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=quality.%20,related%20to%20security%20and%20privacy" rel="nofollow">arrive</a>, allowing you to plan and give feedback.</p>
<p dir="auto">Gemini CLI is evolving rapidly, with new releases coming out frequently, so it's wise to track what's on the horizon. Google maintains a <strong>public roadmap</strong> for Gemini CLI on GitHub, detailing the key focus areas and features targeted for the near <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=This%20document%20outlines%20our%20approach,live%20in%20our%20GitHub%20Issues" rel="nofollow">future</a>. This is essentially a living document (and set of issues) where you can see what the developers are working on and what's in the pipeline. For instance, one exciting item on the roadmap is support for <strong>background agents</strong> - the ability to spawn autonomous agents that run in the background to handle tasks continuously or <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=quality.%20,related%20to%20security%20and%20privacy" rel="nofollow">asynchronously</a>. According to the roadmap discussion, these background agents would let you delegate long-running processes to Gemini CLI without tying up your interactive session. You could, say, start a background agent that monitors your project for certain events or periodically executes tasks, either on your local machine or even by deploying to a service like Cloud <a href="https://github.com/google-gemini/gemini-cli/issues/4168#:~:text=How%20will%20it%20work%3F" data-hovercard-type="issue" data-hovercard-url="/google-gemini/gemini-cli/issues/4168/hovercard">Run</a>. This feature aims to "enable long-running, autonomous tasks and proactive assistance" right from the <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=quality.%20,related%20to%20security%20and%20privacy" rel="nofollow">CLI</a>, essentially extending Gemini CLI's usefulness beyond just on-demand queries.</p>
<p dir="auto">By keeping tabs on the roadmap, you'll also learn about other planned features. These could include new tool integrations, support for additional Gemini model versions, UI/UX improvements, and more. The roadmap is usually organized by "areas" (for example, <em>Extensibility</em>, <em>Model</em>, <em>Background</em>, etc.) and often tagged with milestones (like a target quarter for <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=Our%20roadmap%20is%20managed%20directly,more%20detailed%20list%20of%20tasks" rel="nofollow">delivery</a>]. It's not a guarantee of when something will land, but it gives a good idea of the team's priorities. Since the project is open-source, you can even dive into the linked GitHub issues for each roadmap item to see design proposals and progress. For developers who rely on Gemini CLI, this transparency means you can anticipate changes - maybe an API is adding a feature you need, or a breaking change might be coming that you want to prepare for.</p>
<p dir="auto">Following the roadmap can be as simple as bookmarking the GitHub project board or issue labeled "Roadmap" and checking periodically. Some major updates (like the introduction of Extensions or the IDE integration) were hinted at in the roadmap before they were officially announced, so you get a sneak peek. Additionally, the Gemini CLI team often encourages community feedback on those future features. If you have ideas or use cases for something like background agents, you can usually comment on the issue or discussion thread to influence its development.</p>
<p dir="auto"><strong>Pro Tip:</strong> Since Gemini CLI is open source (Apache 2.0 licensed), you can do more than just watch the roadmap - you can participate! The maintainers welcome contributions, especially for items aligned with the <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=As%20an%20Apache%202,opening%20an%20issue%20for%20discussion" rel="nofollow">roadmap</a>. If there's a feature you really care about, consider contributing code or testing once it's in preview. At the very least, you can open a feature request if something you need isn't on the roadmap <a href="https://google-gemini.github.io/gemini-cli/ROADMAP.html#:~:text=As%20an%20Apache%202,opening%20an%20issue%20for%20discussion" rel="nofollow">yet</a>. The roadmap page itself provides guidance on how to propose changes. Engaging with the project not only keeps you in the loop but also lets you shape the tool that you use. After all, Gemini CLI is built with community involvement in mind, and many recent features (like certain extensions and tools) started as community suggestions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tip 28: Extend Gemini CLI with <code>Extensions</code></h2><a id="user-content-tip-28-extend-gemini-cli-with-extensions" aria-label="Permalink: Tip 28: Extend Gemini CLI with Extensions" href="#tip-28-extend-gemini-cli-with-extensions"></a></p>
<p dir="auto"><strong>Quick use-case:</strong> Add new capabilities to Gemini CLI by installing plug-and-play <strong>extensions</strong> - for example, integrate with your favorite database or cloud service - expanding the AI's toolset without any heavy lifting on your <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=Gemini%20CLI%20is%20an%20open,design%20platforms%20to%20payment%20services" rel="nofollow">part</a>. It's like installing apps for your CLI to teach it new tricks.</p>
<p dir="auto">Extensions are a game-changer introduced in late 2025: they allow you to <strong>customize and expand</strong> Gemini CLI's functionality in a modular <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=Gemini%20CLI%20is%20an%20open,design%20platforms%20to%20payment%20services" rel="nofollow">way</a>. An extension is essentially a bundle of configurations (and optionally code) that connects Gemini CLI to an external tool or service. For instance, Google released a suite of extensions for Google Cloud - there's one that helps deploy apps to Cloud Run, one for managing BigQuery, one for analyzing application security, and <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=In%20just%20three%20months%20since,source%20community" rel="nofollow">more</a>. Partners and community developers have built extensions for all sorts of things: Dynatrace (monitoring), Elastic (search analytics), Figma (design assets), Shopify, Snyk (security scans), Stripe (payments), and the list is <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=In%20just%20three%20months%20since,source%20community" rel="nofollow">growing</a>. By installing an appropriate extension, you instantly grant Gemini CLI the ability to use new domain-specific tools. The beauty is that these extensions come with a pre-defined <strong>"playbook"</strong> that teaches the AI how to use the new tools <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=Gemini%20CLI%20is%20an%20open,design%20platforms%20to%20payment%20services" rel="nofollow">effectively</a>. That means once installed, you can ask Gemini CLI to perform tasks with those services and it will know the proper APIs or commands to invoke, as if it had that knowledge built-in.</p>
<p dir="auto">Using extensions is very straightforward. The CLI has a command to manage them: <code>gemini extensions install &lt;URL&gt;</code>. Typically, you provide the URL of the extension's GitHub repo or a local path, and the CLI will fetch and install <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=It%E2%80%99s%20easy%20to%20install%20an,%E2%80%9D%20from%20your%20command%20line" rel="nofollow">it</a>. For example, to install an official extension, you might run: <code>gemini extensions install https://github.com/google-gemini/gemini-cli-extension-cloud-run</code>. Within seconds, the extension is added to your environment (stored under <code>~/.gemini/extensions/</code> or your project's <code>.gemini/extensions/</code> folder). You can then see it by running <code>/extensions</code> in the CLI, which lists active <a href="https://google-gemini.github.io/gemini-cli/docs/cli/commands.html#:~:text=,See%20Gemini%20CLI%20Extensions" rel="nofollow">extensions</a>. From that point on, the AI has new tools at its disposal. If it's a Cloud Run extension, you could say "Deploy my app to Cloud Run," and Gemini CLI will actually be able to execute that (by calling the underlying <code>gcloud</code> commands through the extension's tools). Essentially, extensions function as first-class expansions of Gemini CLI's capabilities, but you opt-in to the ones you need.</p>
<p dir="auto">There's an <strong>open ecosystem</strong> around extensions. Google has an official Extensions page listing available <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=Access%20an%20open%2C%20growing%20ecosystem,of%20partners%20and%20builders" rel="nofollow">extensions</a>, and because the framework is open, anyone can create and share their own. If you have a particular internal API or workflow, you can build an extension for it so that Gemini CLI can assist with it. Writing an extension is easier than it sounds: you typically create a directory (say, <code>my-extension/</code>) with a file <code>gemini-extension.json</code> describing what tools or context to <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Extensions" rel="nofollow">add</a>. You might define new slash commands or specify remote APIs the AI can call. No need to modify Gemini CLI's core - just drop in your extension. The CLI is designed to load these at runtime. Many extensions consist of adding custom <em>MCP tools</em> (Model Context Protocol servers or functions) that the AI can use. For example, an extension could add a <code>/translate</code> command by hooking into an external translation API; once installed, the AI knows how to use <code>/translate</code>. The key benefit is <strong>modularity</strong>: you install only the extensions you want, keeping the CLI lightweight, but you have the option to integrate virtually anything.</p>
<p dir="auto">To manage extensions, besides the <code>install</code> command, you can update or remove them via similar CLI commands (<code>gemini extensions update</code> or just by removing the folder). It's wise to occasionally check for updates on extensions you use, as they may receive improvements. The CLI might introduce an "extensions marketplace" style interface in the future, but for now, exploring the GitHub repositories and official catalog is the way to discover new ones. Some popular ones at launch include the GenAI <strong>Genkit</strong> extension (for building generative AI apps), and a variety of Google Cloud extensions that cover CI/CD, database admin, and more.</p>
<p dir="auto"><strong>Pro Tip:</strong> If you're building your own extension, start by looking at existing ones for examples. The official documentation provides an <strong>Extensions Guide</strong> with the schema and <a href="https://www.philschmid.de/gemini-cli-cheatsheet#:~:text=Extensions" rel="nofollow">capabilities</a>. A simple way to create a private extension is to use the <code>@include</code> functionality in <code>GEMINI.md</code> to inject scripts or context, but a full extension gives you more power (like packaging tools). Also, since extensions can include context files, you can use them to preload domain knowledge. Imagine an extension for your company's internal API that includes a summary of the API and a tool to call it - the AI would then know how to handle requests related to that API. In short, extensions open up a new world where Gemini CLI can interface with anything. Keep an eye on the extensions marketplace for new additions, and don't hesitate to share any useful extension you create with the community - you might just help thousands of other <a href="https://blog.google/technology/developers/gemini-cli-extensions/#:~:text=Gemini%20CLI%20extensions%20are%20here,and%20build%20your%20own%20extension" rel="nofollow">developers</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional Fun: Corgi Mode Easter Egg üêï</h2><a id="user-content-additional-fun-corgi-mode-easter-egg-" aria-label="Permalink: Additional Fun: Corgi Mode Easter Egg üêï" href="#additional-fun-corgi-mode-easter-egg-"></a></p>
<p dir="auto">Lastly, not a productivity tip but a delightful easter egg - try the command <code>*/corgi*</code> in Gemini CLI. This toggles <strong>"corgi mode"</strong>, which makes a cute corgi animation run across your <a href="https://medium.com/@ferreradaniel/gemini-cli-free-ai-tool-upgrade-5-new-features-you-need-right-now-04cfefac5e93#:~:text=Easter%20Egg%3A%20Corgi%20Mode%20in,Gemini%20CLI" rel="nofollow">terminal</a>! It doesn't help you code any better, but it can certainly lighten the mood during a long coding session. You'll see an ASCII art corgi dashing in the CLI interface. To turn it off, just run <code>/corgi</code> again.</p>
<p dir="auto">This is a purely for-fun feature the team added (and yes, there's even a tongue-in-cheek <a href="https://github.com/google-gemini/gemini-cli/issues/5674#:~:text=How%20about%20you%20NOT%20implement,this%20needed%3F%20Because%20people" data-hovercard-type="issue" data-hovercard-url="/google-gemini/gemini-cli/issues/5674/hovercard">debate</a> about spending dev time on corgi mode). It shows that the creators hide some whimsy in the tool. So when you need a quick break or a smile, give <code>/corgi</code> a try. üêïüéâ</p>
<p dir="auto"><em>(Rumor has it there might be other easter eggs or modes - who knows? Perhaps a "/partyparrot" or similar. The cheat sheet or help command lists <code>/corgi</code>, so it's not a secret, just underused. Now you're in on the joke!)</em></p>
<hr>
<p dir="auto"><strong>Conclusion:</strong></p>
<p dir="auto">We've covered a comprehensive list of pro tips and features for Gemini CLI. From setting up persistent context with <code>GEMINI.md</code>, to writing custom commands and using advanced tools like MCP servers, to leveraging multi-modal inputs and automating workflows, there's a lot this AI command-line assistant can do. As an external developer, you can integrate Gemini CLI into your daily routine - it's like a powerful ally in your terminal that can handle tedious tasks, provide insights, and even troubleshoot your environment.</p>
<p dir="auto">Gemini CLI is evolving rapidly (being open-source with community contributions), so new features and improvements are constantly on the horizon. By mastering the pro tips in this guide, you'll be well-positioned to harness the full potential of this tool. It's not just about using an AI model - it's about integrating AI deeply into how you develop and manage software.</p>
<p dir="auto">Happy coding with Gemini CLI, and have fun exploring just how far your "AI agent in the terminal" can take you.</p>
<p dir="auto"><strong>You now have a Swiss-army knife of AI at your fingertips - use it wisely, and it will make you a more productive (and perhaps happier) developer</strong>!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DRAM prices are spiking, but I don't trust the industry's why (125 pts)]]></title>
            <link>https://www.xda-developers.com/dram-prices-spiking-dont-trust-industry-reasons/</link>
            <guid>46059737</guid>
            <pubDate>Wed, 26 Nov 2025 17:12:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.xda-developers.com/dram-prices-spiking-dont-trust-industry-reasons/">https://www.xda-developers.com/dram-prices-spiking-dont-trust-industry-reasons/</a>, See on <a href="https://news.ycombinator.com/item?id=46059737">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        
                                        




            <article>

                

        
    
    
    
    
        
            <header>

            
            
                                                


    
                            
            
            
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                        
                                                    
    
                    
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                        
                    
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                            
                                                    
                                    
                                                
            
    <div data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;" data-is-feature-img="true">
        
        <picture><source media="(max-width: 480px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?q=49&amp;fit=crop&amp;w=480&amp;h=270&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?q=49&amp;fit=crop&amp;w=480&amp;h=270&amp;dpr=2">
        <source media="(min-width: 481px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?q=49&amp;fit=crop&amp;w=1600&amp;h=900&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?q=49&amp;fit=crop&amp;w=1600&amp;h=900&amp;dpr=2">
        <img width="1600" height="900" alt="265gb of ddr5 ram installed on threadripper motherboard" data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?&amp;fit=crop&amp;w=1600&amp;h=900" src="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/10/threadripper-lots-of-ram.jpg?&amp;fit=crop&amp;w=1600&amp;h=900">
        </picture>

    </div>


                    
                        
    
    
    
        
    

    
                                         </header>

                                        
            



                                                
    


            <a id="login-button-article-sidebar">
            <p>Sign in to your <span>XDA</span> account</p>
            
        </a>
                

        
            
                                                            
                                            
                
                                
            
            

        
                        
        
                                                                                            
                        
        
        
                                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
                                                                        
                                    
        
                                                
                                                                                                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                                                                
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                                                    
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                                                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                                                                                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                                                    
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                                                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                                                                                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                            
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                                                                                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                                                    
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                                                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                        
    
    
    
        
    

    
        
                        
        
        
                        
        
        
                                                
                        
                        
                                    
        
                
                    
                                                                                                                                                                                                                                                                        
                    
    
    
        
                    
                    
                                    


		



                                        <!-- No AdsNinja v10 Client! --><!-- No AdsNinja v10 Client! --><!-- No AdsNinja v10 Client! --><!-- No AdsNinja v10 Client! --><div id="article-body" itemprop="articleBody"><p>RAM prices have skyrocketed globally in 2025, with industry officials pointing to explosive demand from AI data centers as the primary cause. Mainstream DDR5 memory modules now cost at least twice what they did in mid-2025, and overall DRAM contract prices were a stunning 171.8% higher in the third quarter of 2025 compared to a year prior. For context, these increases have even outpaced the surge in gold prices over the same period, which has also seen a surge in price given economic fears and overall uncertainty. Manufacturers and analysts are now warning us that we're at the start of a major DRAM bull market, with shortages expected to continue into 2026.</p>    <!-- No AdsNinja v10 Client! --><!-- No AdsNinja v10 Client! --><p>With all of that said, the memory industry has a bit of history with regard to price-fixing. While I'm sure that there are perfectly natural market forces at play, here, there's a lot of room for skepticism, too.</p>    <!-- No AdsNinja v10 Client! --><h2 id="a-global-surge-in-memory-pricing">
                        A global surge in memory pricing
               </h2><h3 id="some-context-first">
            Some context, first
    </h3>

                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                        
    
    

    
    <div data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">
                                                                                            <picture><source media="(max-width: 480px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2">
        <source media="(max-width: 767px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2">
        <source media="(max-width: 1023px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        <img width="1650" height="928" loading="lazy" decoding="async" alt="A person holding a RAM stick in front of MacBook running Proxmox" data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" src="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/07/proxmox-ram.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        </picture>
            
        </div>
<p> The price spike in memory (especially DRAM) is being felt worldwide. Contract prices for server and PC memory have climbed steeply through 2025, and these increases are now trickling down to retail. For example, a standard 32GB Corsair RAM kit I found on Amazon, specifically 6000 MHz DDR5, cost $110 at the start of this year. Now it costs a whopping $442 after a long period of time where it was out of stock. That quadrupling in price in less than a year highlights just how quickly the market has turned. In other regions, prices have jumped at a similar scale, and there have been reports of retailers even rationing sales of memory modules due to limited supply. In Japan, certain shops have even capped the quantity of HDDs, SSDs, and RAM that a customer can buy because deliveries are so scarce, and memory kit launches are being delayed, too.</p>    <p>This isn't just a DRAM story, either. NAND flash memory and hard drive prices are rising in tandem, all caught in the same squeeze of demand that's affecting everything. Back in September, both DRAM and NAND flash contract prices were climbing by 15 to 20%, and that trend has accelerated as we enter the final quarter of the year. Major cloud providers have reportedly agreed to pay up to 50% higher prices for memory chips than they did in the previous quarter. Plus, even despite those premiums, some companies report only receiving approximately 70% of the server memory that they ordered, and smaller buyers are receiving even less. Memory is being allocated to those with deeper pockets first, and it's affecting <em>everything</em>.</p>    <p>Anyone looking to upgrade or build a PC will have noticed the crazy-high RAM prices that are now taking hold. The cost savings from cheaper CPUs or GPUs this year are being wiped out by memory kit price hikes. Even now, desktop DDR5 memory modules cost roughly double what they did just a few months ago, and this adds <em>significant</em> expense to any build. And if you thought you could go to     <span data-id="1015272"><a href="https://www.xda-developers.com/ddr4-ram-still-good-enough/" target="_blank">older DDR4 modules</a></span> instead, then think again. Those are also getting pricier as they become scarcer, and that's because DDR4 is being phased out of production. Companies like Samsung, SK Hynix, and Micron are extending how long they're producing it for, but production was supposed to have stopped by now, and it's unlikely that they're producing it at the same rate they used to.    </p>    <p>It's not just consumers and AI companies that are feeling the pressure; companies that produce devices like laptops, smartphones, and graphics cards are feeling the squeeze, too. Major PC OEMs and system integrators have started panic-buying and stockpiling RAM to secure supply, and Asus has said that it <a href="https://www.tomshardware.com/pc-components/dram/asus-msi-other-manufacturers-panic-buying-ram-stocks-while-major-memory-chipmakers-rake-in-profits-massive-demand-for-hbm-and-rdimm-for-data-centers-driving-shortage" rel="noopener noreferrer nofollow" target="_blank">only has about two months</a> of inventory left for production. Embedded devices aren't exempt either, and the Raspberry Pi Foundation, which had stockpiled memory ahead of time, was forced to increase the prices of its 4GB and 8GB models by $5 and $10, respectively, because memory now costs "roughly 120% more than it did a year ago," <a href="https://www.raspberrypi.com/news/5-10-price-increases-for-some-4gb-and-8gb-products/" rel="noopener noreferrer nofollow" target="_blank">according to Raspberry Pi Holdings CEO Eben Upton</a>.</p>    <p>Even data centers aren't safe from the chaos they've created, and <a href="https://www.networkworld.com/article/4091014/samsungs-60-memory-price-hike-signals-higher-data-center-costs-for-enterprises.html" rel="noopener noreferrer nofollow" target="_blank">some analysts</a> estimate the world's largest memory maker, Samsung, have imposed such steep price hikes that they could push AI server costs up by 10% to 25% for cloud operators. If things worsen to the point of not being able to get any stock at all, hyperscalers may have to slow down their AI data center deployments because they simply can't get enough memory to actually build out their data centers. Plus, because AI servers are devouring both DRAM and storage, it's causing a cascading effect. High-capacity     <span data-id="1023055"><a href="https://www.xda-developers.com/how-to-spot-counterfeit-hdd/" target="_blank">HDDs</a></span> (which are used for data center storage) are on backorder for a year or more, and with disk drives scarce, cloud companies are turning to flash storage (SSDs) in roles traditionally filled by disks. This simultaneous strain on NAND flash and HDDs is unprecedented, as when one was constrained, the other often acted as a fallback.    </p>    <!-- No AdsNinja v10 Client! --><h2 id="ai-is-the-official-explanation">
                        AI is the official explanation
               </h2><h3 id="an-absurd-amount-of-dram-is-going-to-just-a-few-companies">
            An absurd amount of DRAM is going to just a few companies
    </h3>

                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                                                        
    
    

    
    <div data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg" data-img-desc="&quot;Source: OpenAI&quot;" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">
                                                                                            <figure><picture><source media="(max-width: 480px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2">
        <source media="(max-width: 767px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2">
        <source media="(max-width: 1023px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        <img width="1650" height="1100" loading="lazy" decoding="async" alt="Sam Altman speaks at OpenAI's DevDay." data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" src="https://static0.xdaimages.com/wordpress/wp-content/uploads/2023/11/sam-altman-openai.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        </picture><figcaption>Source: OpenAI</figcaption></figure>
            
        </div>
<p> The explanation from industry leaders is centered around a perfect storm of both booming demand and constrained supply, and the narrative from most companies in the space backs that assertion up. Generative AI requires a huge amount of both memory and storage, as training and running models require data centers filled with GPUs; GPUs that can have hundreds of gigabytes of DRAM paired with multiple terabytes of flash storage. For example, OpenAI's new "<a href="https://www.tomshardware.com/pc-components/dram/openais-stargate-project-to-consume-up-to-40-percent-of-global-dram-output-inks-deal-with-samsung-and-sk-hynix-to-the-tune-of-up-to-900-000-wafers-per-month" rel="noopener noreferrer nofollow" target="_blank">Stargate</a>" project reportedly signed deals with Samsung and SK Hynix for up to 900,000 wafers of DRAM per month to feed its AI clusters, which is an amount close to 40% of total global DRAM output if it's ever met. That's an <em>absurd</em> amount of DRAM. Similarly, cloud providers are pre-buying years' worth of memory. Micron, as another example, has already presold <a href="https://www.trendforce.com/news/2025/09/24/news-microns-2026-hbm-not-sold-out-yet-but-will-reportedly-be-within-months-as-pricing-deals-lock/" rel="noopener noreferrer nofollow" target="_blank">essentially all</a> of its HBM (High Bandwidth Memory) chip output essentially through 2026, and Samsung's next-gen V9 NAND flash is nearly fully booked by enterprise customers before launch, though that's a problem that <a href="https://www.techpowerup.com/341061/samsung-delays-v9-qlc-nand-production-to-h1-2026-amid-performance-issues" rel="noopener noreferrer nofollow" target="_blank">technically started</a> in September 2024.</p>    <p>On the supply side, only a few companies produce the vast majority of the world's memory chips, and they were clearly <em>not</em> prepared for this surge. The DRAM industry is an oligopoly of basically three major players; Samsung, SK Hynix, and Micron. Over the past decades, the memory market's brutal boom and bust cycles drove many competitors out, leaving just these few big suppliers. This matters because with so few producers, any strategic choices they make (or don't make) have outsized impact on supply. In this cycle, manufacturers had cut back production and investment during the last downturn (2022), and they've been slow to ramp back up. To make matters worse, with a suspected AI bubble that could pop at any moment, it seems that memory makers have no plans to significantly increase overall DRAM production as a result of potential market volatility. In an interview with Taiwanese CommonWealth Magazine, Pua Khein-Seng, CEO of Phison, <a href="https://www.tomshardware.com/pc-components/ssds/phison-ceo-claims-nand-shortage-could-last-a-staggering-10-years-says-memory-supercycle-imminent-and-severe-2026-shortages-are-at-hand" rel="noopener noreferrer nofollow" target="_blank">said</a> the following:</p>    <blockquote>
                        <p>NAND will face severe shortages next year. I think supply will be tight for the next ten years. In the past, every time flash makers invested more, prices collapsed, and they never recouped their investments. So companies slowed spending starting around 2019‚Äì2020. Then in 2023, Micron and SK Hynix redirected huge CapEx into HBM because the margins were so attractive, leaving even less investment for flash.</p>    
            </blockquote><p>Another factor limiting supply of standard RAM is that memory firms are diverting their limited manufacturing capacity to the most lucrative products. Specifically, there's a gold rush for HBM, which is a special kind of memory used by AI accelerator GPUs, because HBM commands far higher prices and profit margins than commodity DRAM. Every wafer a company allocates to making HBM for GPUs is one not used to make standard PC or server DRAM, so from the point of view of a major company, why bother investing in the consumer-grade or regular data-center hardware when the same resources can be used to make something with a much higher return? These companies <a href="https://marklapedus.substack.com/p/high-bandwidth-memory-hbm-is-sold" rel="noopener noreferrer nofollow" target="_blank">ran out of HBM last year</a>, and if production was shifted towards HBM, then they can gain a higher return on each wafer while also increasing the price of regular DRAM, too.</p>    <p>When it comes to DDR4, given those phase-out timelines given by the major producers, some smaller Chinese companies (like CXMT and Jinhua) are stepping in to make DDR4 and undercut prices, but they haven't fully filled the void. This story may sound familiar; when DDR3 was phased out, the big players exited in the same way. Essentially, the industry says that this is all a supply-and-demand imbalance, with demand from AI and cloud shooting up and supply being unable (and unwilling) to catch up. Many will argue that there's nothing nefarious going on, and it's all caused by unfortunate timing and caution from the companies that produce global DRAM supplies. If AI proves to be a bubble that bursts, memory firms will end up with another price crash like what has happened in the past.</p>    <!-- No AdsNinja v10 Client! --><h2 id="dram-producers-have-artificially-inflated-prices-before">
                        DRAM producers have artificially inflated prices before
               </h2><h3 id="and-all-of-them-are-benefiting-right-now">
            And all of them are benefiting right now
    </h3>


                            
            
    
<p>Look, there are a lot of plausible factors that we've already highlighted that could cause pressure on pricing, but there's a lot of room for skepticism, too. I'm <em>not</em> saying that all of these reasons given aren't the cause for the recent price boom, but what I am saying is that it wouldn't be the first time that price-fixing occurred in the memory industry. The DRAM market, being dominated by three main players, has crossed the line into illegal, price-fixing cartels. In the early 2000s, multiple memory manufacturers pleaded guilty to conspiring to fix DRAM prices between 1998 and 2002, resulting in hundreds of millions of dollars in fines given out to a few manufacturers, including the big three that survive to this day: SK Hynix, Samsung, and Micron. More recently, during the big DRAM price run-up in the middle of 2016 and the start of 2018 (where prices nearly tripled in a year and a half), a class-action lawsuit accused the big three of colluding to restrict supply in order to inflate prices. That <a href="https://www.eetimes.com/lawsuit-alleges-price-fixing-by-top-dram-manufacturers/" rel="noopener noreferrer nofollow" target="_blank">more recent</a> class action lawsuit was brought by the same firm that brought the original class action suit in the early 2000s against those same companies, which coincided with the U.S. Department of Justice investigation. While that second lawsuit didn't hold up in court (and <a href="https://cdn.ca9.uscourts.gov/datastore/opinions/2022/03/07/21-15125.pdf" rel="noopener noreferrer nofollow" target="_blank">failed in appeal</a>), that ongoing suspicion exists for a reason.</p>    <p>All of this history shows one thing: memory suppliers have both the motive and precedent to coordinate behavior, even tacitly, in order to keep prices high. When only a handful of firms control the taps, it doesn't take a formal cartel for them to collectively benefit from constrained supply. Each firm knows that flooding the market would hurt all of their profits, so a form of unspoken coordination can occur, and this is next to impossible to prove. The backdrop of past cartels makes it hard not to be cynical when hearing that "AI demand" is solely to blame for increased prices. Whether or not any collusion is happening now, it's clear that memory companies are profiting immensely from the current crisis. After bleeding financially during the last oversupply downturn, the major DRAM makers are now seeing record-high earnings in the third quarter of 2025 thanks to the price surge, and to put it bluntly, the shortage is <em>great</em> for business.</p>    <p>Meanwhile, these same companies are not rushing to add capacity that would ease prices, a fact justified by fear of an AI bubble, but which also conveniently prolongs their windfall. Memory suppliers have shifted to higher-profit chips (like HBM) and aren't exactly trying to temper the increases in demand. Instead, they're facilitating it at higher prices. It's worth noting that the big three DRAM makers have all taken a similarly cautious (and profit-preserving) approach this DRAM cycle. All have cut back on older products (like DDR4), all are prioritizing higher-margin AI-related memory, and none are dramatically boosting standard DRAM output or engaging in a price war to gain market share. In effect, supply is being "redirected" in unison. All three firms seem to be stockpiling capital rather than building new fabs immediately, despite the obvious need. Micron, for example, has plans for new fabrication plants (one in New York, one expansion in Idaho), but it has delayed some of those projects by years, all while reportedly pushing out its new U.S. DRAM megafab by <a href="https://www.constructiondive.com/news/micron-delay-construction-new-york-megafab/805622/" rel="noopener noreferrer nofollow" target="_blank">two to three years</a> due to market uncertainty, even as it accelerates niche projects like an HBM fab.</p>    <p>It's hard not to see this supposedly coincidental aligned strategy of restraint and <em>wonder</em> if there's something more at play. All of these actions support pricing stability (for those companies) and suggests that no one is "breaking ranks" to grab a larger share by undercutting prices. In a truly competitive scenario, at least one player might be tempted to boost production and capture the extraordinary demand, even if it meant driving prices down, in order to grow their market share and revenue. We haven't seen that; instead we see a cautious, unified approach across the three major players. Three major players that have, in the past, been accused of price-fixing.</p>    <p>I'd argue that it‚Äôs not conspiracy theory territory to be skeptical of the official reasoning. To be clear, AI demand is real and is a major factor, and we've seen the impact it's had on all kinds of markets. The numbers don't lie about huge new consumption of memory, but it's easy to be suspicious given that the memory industry's structure just so happens to benefit the three companies that control practically all of it when supply is constrained in this way. One could make the case that companies will have an attitude along the lines of "Never let a good crisis go to waste," while memory vendors would counter that they are merely being cautious and that they'll invest in new capacity once they're sure this demand isn't merely a mirage.</p>    <!-- No AdsNinja v10 Client! --><h2 id="things-don-39-t-look-to-be-getting-better">
                        Things don't look to be getting better
               </h2><h3 id="it-39-ll-be-more-than-a-year-at-least">
            It'll be more than a year at least
    </h3>

                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                        
    
    

    
    <div data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">
                                                                                            <picture><source media="(max-width: 480px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=500&amp;dpr=2">
        <source media="(max-width: 767px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=800&amp;dpr=2">
        <source media="(max-width: 1023px)" data-srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" srcset="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        <img width="1650" height="928" loading="lazy" decoding="async" alt="Ugreen HDD SSD Enclosure" data-img-url="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2" src="https://static0.xdaimages.com/wordpress/wp-content/uploads/wm/2025/05/ugreen-hdd-ssd-enclosure-1.jpg?q=49&amp;fit=crop&amp;w=825&amp;dpr=2">
        </picture>
            
        </div>
<p> This current trend is complex, and on the surface, it's being driven by something that is genuinely transformative to the wider industry as a whole. The rise of AI and data centers that consume far more memory and storage than traditional computing ever did is certainly a factor, and that real demand surge, combined with the slow ramp of supply, is definitely a large portion of the price increases and shortages we're seeing. <em>However</em>, with so few companies controlling the market, alongside their decisions to prioritize profits, cut back older products, and cautiously avoid overproduction, have all lent credence to allegations that something bigger may be at play. After all, history shows that these firms have skirted the line between smart business and anti-consumer collusion before.</p>    <p>All in all, both things can be true. The AI revolution can be driving unprecedented demand for memory, while the memory giants are more than happy to not fully ease the supply pressure because it's basically printing money for them. Unfortunately, everyone else is caught in the middle, and it's not just consumers feeling the pressure, either. AMD is reportedly thinking about increasing the price of its GPUs as a result, and when companies exhaust their memory supplies for laptops and other hardware, those costs will likely rise as well. It's <a href="https://www.xda-developers.com/the-dram-shortage-is-forcing-me-to-rethink-every-build-planned-for-2026/" target="_blank">hard to justify building a PC right now</a>, especially because it's unclear when all of this uncertainty will end.</p>    <p>But that's the question most people are wondering the answer to: <em>when</em> will it end? Unfortunately, it looks likely to extend well into 2026, and as we already noted, the CEO of Phison thinks it could be a <em>decade</em>. The only way things will improve is if either the supposed AI bubble pops and the demand cools off, or more manufacturing capabilities come online. If companies started to purchase less DRAM as a result of memory prices rising so high that they start delaying purchases, that could well be a good sign that the tides will turn, but for now, it's clear that cheap, plentiful RAM is no more. Right now, whether initial skepticism turns out to be right or wrong, one thing is true: the house is winning, and everyone else is paying the price.</p>    </div>
    
                
        
        

        





                    
                        
    


            
                                
        
        
    

        
    </article>

    
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare outage should not have happened (103 pts)]]></title>
            <link>https://ebellani.github.io/blog/2025/cloudflare-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/</link>
            <guid>46059227</guid>
            <pubDate>Wed, 26 Nov 2025 16:34:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ebellani.github.io/blog/2025/cloudflare-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/">https://ebellani.github.io/blog/2025/cloudflare-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/</a>, See on <a href="https://news.ycombinator.com/item?id=46059227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><a href="https://ebellani.github.io/blog/2025/google-cloud-s-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/">Yet again</a>, another global IT outage happen (deja vu strikes again in our
industry). This time at
cloudflare(<a href="#citeproc_bib_item_4">Prince 2025</a>). Again, taking down
large swats of the internet with
it(<a href="#citeproc_bib_item_2">Booth 2025</a>).</p>
<p>And yes, like my previous analysis of the GCP and CrowdStrike‚Äôs outages,
this post critiques Cloudflare‚Äôs root cause analysis (RCA), which ‚Äî
despite providing a great overview of what happened ‚Äî misses the real
lesson.</p>
<p>Here‚Äôs the key section of their RCA:</p>
<blockquote>
<p>Unfortunately, there were assumptions made in the past, that the list of
columns returned by a query like this would only include the ‚Äúdefault‚Äù
database:</p>
<p>SELECT
name,
type
FROM system.columns
WHERE
table = ‚Äòhttp_requests_features‚Äô
order by name;</p>
<p>Note how the query does not filter for the database name. With us
gradually rolling out the explicit grants to users of a given ClickHouse
cluster, after the change at 11:05 the query above started returning
‚Äúduplicates‚Äù of columns because those were for underlying tables stored
in the r0 database.</p>
<p>This, unfortunately, was the type of query that was performed by the Bot
Management feature file generation logic to construct each input
‚Äúfeature‚Äù for the file mentioned at the beginning of this section.</p>
<p>The query above would return a table of columns like the one displayed
(simplified example):</p>
<figure><img src="https://ebellani.github.io/ox-hugo/cf_table_sql_return.png">
</figure>

<p>However, as part of the additional permissions that were granted to the
user, the response now contained all the metadata of the r0 schema
effectively more than doubling the rows in the response ultimately
affecting the number of rows (i.e. features) in the final file output.</p>
</blockquote>
<p>A central database query didn‚Äôt have the right constraints to express
business rules. Not only it missed the database name, but it clearly
needs a distinct and a limit, since these seem to be crucial business
rules.</p>
<p>So, a new underlying security work manifested the (unintended) potential
already there in the query. Since this was by definition unintended, the
application code didn‚Äôt expect that value to be what it was, and reacted
poorly. This caused a crash loop across seemingly all of cloudflare‚Äôs
core systems. This bug wasn‚Äôt caught during rollout because the faulty
code path required data that was assumed to be impossible to be
generated.</p>
<p>Sounds familiar? It should. Any senior engineer has seen this pattern
before. This is classic database/application mismatch. With this in
mind, let‚Äôs review how Cloudflare is planning to prevent this from happening
again:</p>
<blockquote>
<ul>
<li>Hardening ingestion of Cloudflare-generated configuration files in the same way we would for user-generated input</li>
<li>Enabling more global kill switches for features</li>
<li>Eliminating the ability for core dumps or other error reports to overwhelm system resources</li>
<li>Reviewing failure modes for error conditions across all core proxy modules</li>
</ul>
</blockquote>
<p>These are all solid, reasonable steps. But here‚Äôs the problem: they
already do most of this‚Äîand the outage happened anyway.</p>
<p>Why? Because of they seem to mistake physical replication with not
having a single point of failure. This mistakes the physical layer with
the logical layer. One can have a logical single point of failure
without having any physical one, which was the case in this
situation.</p>
<p>I base my paragraph on their choice of abandoning PostgreSQL and
adopting
ClickHouse(<a href="#citeproc_bib_item_1">Bocharov 2018</a>). The
whole post is a great overview on trying to process data fast, without a
single line on how to garantee its logical correctness/consistency in
the face of changes.</p>
<p><strong>They are treating a logical problem as if it was a physical problem</strong></p>
<p>I‚Äôll repeat the <a href="https://ebellani.github.io/blog/2025/google-cloud-s-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/">same advice</a> I offered in my previous article on GCP‚Äôs outage:</p>
<h2 id="the-real-cause">The real cause</h2>
<p>These kinds of outages stem from the uncontrolled interaction between
application logic and database schema. You can‚Äôt reliably catch that
with more tests or rollouts or flags. You prevent it by
construction‚Äîthrough analytical design.</p>
<ol>
<li>No nullable fiels.</li>
<li>(as a cororally of 1) full normalization of the database (<a href="https://ebellani.github.io/blog/2025/the-principles-of-database-design-or-the-truth-is-out-there/">The principles of database design, or, the Truth is out there</a>)</li>
<li>formally verified application code(<a href="#citeproc_bib_item_3">Chapman et al. 2024</a>)</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>FAANG-style companies are unlikely to adopt formal methods or relational
rigor wholesale. But for their most critical systems, they should. It‚Äôs
the only way to make failures like this impossible by design, rather
than just less likely.</p>
<p>The internet would thank them. (Cloud users too‚Äîcaveat emptor.)</p>
<h2 id="references">References</h2>
<div>
  
  
  <p><a id="citeproc_bib_item_3"></a>Chapman, Roderick, Claire Dross, Stuart Matthews, and Yannick Moy. 2024. ‚ÄúCo-Developing Programs and Their Proof of Correctness.‚Äù <i>Commun. Acm</i> 67 (3): 84‚Äì94. <a href="https://doi.org/10.1145/3624728">https://doi.org/10.1145/3624728</a>.</p>
  <div><p><a id="citeproc_bib_item_4"></a>Prince, Matthew. 2025. ‚ÄúCloudflare Outage on November 18, 2025.‚Äù <a href="https://blog.cloudflare.com/18-november-2025-outage/">https://blog.cloudflare.com/18-november-2025-outage/</a>.</p></div>
</div>
<figure><img src="https://ebellani.github.io/ox-hugo/2560px-Dehio_212_Cluny.jpg" alt="Figure 1: The Cluny library was one of the richest and most important in France and Europe. In 1790 during the French Revolution, the abbey was sacked and mostly destroyed, with only a small part surviving"><figcaption>
            <p><span>Figure 1: </span>The Cluny library was one of the richest and most important in France and Europe. In 1790 during the French Revolution, the abbey was sacked and mostly destroyed, with only a small part surviving</p>
        </figcaption>
</figure>




   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   







      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KDE Plasma 6.8 Will Go Wayland-Exclusive in Dropping X11 Session Support (107 pts)]]></title>
            <link>https://www.phoronix.com/news/KDE-Plasma-68-Wayland-Exclusive</link>
            <guid>46058531</guid>
            <pubDate>Wed, 26 Nov 2025 15:44:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/KDE-Plasma-68-Wayland-Exclusive">https://www.phoronix.com/news/KDE-Plasma-68-Wayland-Exclusive</a>, See on <a href="https://news.ycombinator.com/item?id=46058531">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="KDE" src="https://www.phoronix.com/assets/categories/kde.webp" width="100" height="100"></p><p>
KDE developers announced they are going "all-in on a Wayland future" and with the Plasma 6.8 desktop it will become Wayland-exclusive. The Plasma X11 session is going away.
</p><p>
KDE developers announced with Plasma 6.8 it will be Wayland-exclusive in removing Plasma X11 session support although continuing to support X11 apps/games via XWayland.
</p><p>
KDE developers report that "the vast majority of our users are already using the Wayland session" and longer-term this change will allow for new features, optimizations, and more development speed with foregoing X11 session support.
</p><p>
With the Plasma release timing, this means Plasma X11 session support will remain supported into early 2027 with the Plasma 6.7 series. The Plasma 6.7 release may end up seeing some extra bug-fix releases for X11 holdouts.
</p><p>
More details on Plasma 6.8 going Wayland-exclusive and other details via the <a href="https://blogs.kde.org/2025/11/26/going-all-in-on-a-wayland-future/">KDE.org blog</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI needs to raise at least $207B by 2030 so it can continue to lose money (495 pts)]]></title>
            <link>https://ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad</link>
            <guid>46058065</guid>
            <pubDate>Wed, 26 Nov 2025 15:06:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad">https://ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad</a>, See on <a href="https://news.ycombinator.com/item?id=46058065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="site-content"><div id="barrier-page"><div data-component="electionsHeader" data-component-unique-name="electionsHeader"><h2>FT Alphaville</h2></div><div data-component="topicHeroOffer" data-component-unique-name="topicsHeroOffer"><div data-o-grid-colspan="12 XL6"><p><span></span><span></span><span></span><span>Register to unlock this article</span><span></span></p></div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Fimages%2Falphaville_hero_image.png?source=next-barrier-page" alt=""></p></div><div id="recommendedOffers-recommendedOffers" data-component="recommendedOffers" data-component-unique-name="recommendedOffers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_trial.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Trial</h3></p></div><p><span><span>Dkr10</span><span> for 4 weeks</span></span></p><p><span><span>Then </span><span>Dkr535</span><span> per month. Complete digital access to quality FT journalism on any device. Cancel or change your plan anytime during your trial.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_standard.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Standard Digital</h3></p></div><p><span><span>Dkr349</span><span> per month</span></span></p><p><span><span>Get essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_premium.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Premium Digital</h3></p></div><p><span><span>Dkr535</span><span> per month</span></span></p><p><span><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="subscriptionsOptions" data-o3-theme="inverse"><h2>Explore our full range of subscriptions.</h2><div><div><div><h3>For individuals</h3></div><p>Discover all the plans currently available in your country</p></div><div><div><h3> For multiple readers</h3></div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="whyFT" data-o3-theme="inverse"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=23e54a28-6f63-4533-ab96-3756d9c88bad" aria-label="Find out why the FT">Find out why</a></p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Voyager 1 Is About to Reach One Light-Day from Earth (598 pts)]]></title>
            <link>https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/</link>
            <guid>46057488</guid>
            <pubDate>Wed, 26 Nov 2025 14:02:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/">https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/</a>, See on <a href="https://news.ycombinator.com/item?id=46057488">Hacker News</a></p>
Couldn't get https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[I DM'd a Korean presidential candidate and ended up building his core campaign (158 pts)]]></title>
            <link>https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d</link>
            <guid>46057304</guid>
            <pubDate>Wed, 26 Nov 2025 13:40:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d">https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d</a>, See on <a href="https://news.ycombinator.com/item?id=46057304">Hacker News</a></p>
Couldn't get https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Hub Belgrade (123 pts)]]></title>
            <link>https://blog.kagi.com/kagi-hub</link>
            <guid>46056763</guid>
            <pubDate>Wed, 26 Nov 2025 12:28:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/kagi-hub">https://blog.kagi.com/kagi-hub</a>, See on <a href="https://news.ycombinator.com/item?id=46056763">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p><img src="https://kagifeedback.org/assets/files/2025-11-21/1763741331-28722-kagihubcover-3.png" alt="An ilustration of an office room with a Doggo, Cat and Kagibara"></p>

<p>We‚Äôre excited to announce that <a href="https://hub.kagi.com/">Kagi Hub Belgrade</a> is now open!
Our first office doubles as a free coworking space for all Kagi members. Reservations will be available from December 15th, and you can make your bookings <a href="https://hub.kagi.com/">here</a>.</p>

<p>Kagi Hub is our first physical home: a modern, light-filled, 250-square-meter office space in the very heart of Belgrade, Serbia, open to all Kagi members and the Kagi team. Yes, you read that right. You can share this space with us!</p>

<p>Why? Great products don‚Äôt happen in isolation. They are shaped by the people who use them. That‚Äôs what this space is for: a place where Kagi users and our team members can share feedback, ideas, and a cup of coffee in person. Kagi Hub is an extension of our mission to humanize the web, creating an offline space where people who care about a better internet can meet.</p>

<p>
  <iframe src="https://www.youtube.com/embed/ewSkfSGTQzU?si=nUgNVzpSm27xl_2L" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p>

<h2>Who can use the Hub (and what you get)</h2>

<p>Alongside Kagi employees, Kagi Hub is free for all Kagi members. Each member can book up to 5 days per month at no additional cost.</p>

<p>The open space has 25 dedicated seats. Once you complete the booking, you‚Äôll get a spot in the open-space area for the dates you‚Äôve chosen (first-come, first-served within your booking) ‚Üí <a href="https://hub.kagi.com/">Kagi Hub Belgrade</a>.</p>

<p>At the hub you‚Äôll find:</p>

<ul>
<li>A quiet, modern open-space work area with 25 ergonomic desks</li>
<li>Fast Wi‚ÄëFi</li>
<li>Free coffee, tea, and a small kitchen area</li>
<li>A conference room, subject to availability</li>
</ul>

<p>We kindly ask you to cancel your booking if you can‚Äôt make it, so other members can use the space.</p>

<h2>Where to find us</h2>

<p><strong>Address</strong>:
Kneza Mihaila 11, first floor
11000 Belgrade, Serbia</p>

<p><strong>Opening hours</strong>:
Monday - Friday, 10:00‚Äì19:00 (local time), excluding local public holidays.</p>

<p>The hub is in Belgrade‚Äôs iconic pedestrian zone, a few minutes from public transport links and the Obiliƒáev Venac public garage (which also offers bike parking).</p>

<h2>Why Belgrade?</h2>

<p><img src="https://kagifeedback.org/assets/files/2025-11-21/1763744187-715773-knez-mih.jpg" alt="Knez Mihailova"></p>

<p>We could have put our first hub in San Francisco, Tokyo, or Berlin. We chose Belgrade on purpose.</p>

<p>Belgrade sits at the crossroads of East and West, with many short direct flights from cities like Vienna, London, Lisbon, Split, Barcelona, and Paris. It has a thriving tech and startup scene, with a growing talent pool. It‚Äôs known for its walkable neighborhoods, great party scene, and generous hospitality.</p>

<p>Above all, it‚Äôs a place where our founder and CEO, Vlad, lived and built for over 30 years before moving to the USA. It‚Äôs a place where we already have a few Kagi employees and are very eager to welcome you and show you around.</p>

<h2>See you there!</h2>

<p>Kagi Hub in Belgrade is our first experiment in bringing the Kagi movement into the physical world. If it works the way we hope, it won‚Äôt be the last. Local tech media have already welcomed Kagi Hub as part of a bigger shift: an internet that doesn‚Äôt revolve around advertising, tracking, and engagement-at-any-cost. (<a href="https://ba.bloombergadria.com/biznis/kompanije/89546/vladimir-prelovac-i-njegova-globalna-alternativa-googleu/news">Bloomberg Adria</a>, <a href="https://pcpress.rs/kagi-otvorio-svoj-prvi-evropski-hub-u-beogradu-proslavljen-pocetak-nove-tech-ere/">PC Press</a>, <a href="https://www.techzone.rs/2025/11/15/kagi-pretrazivac-interneta-opis-i-prednosti/">TechZone</a>, <a href="https://novaekonomija.rs/tech/vladimir-prelovac-covek-koji-je-odlucio-da-internet-ponovo-bude-mesto-za-ljude-a-ne-oglase#google_vignette">Nova Ekonomija</a>,<a href="https://www.pametnitelefoni.rs/aplikacije/android/kagi-hub-u-beogradu-nova-era-pretrage-interneta-stize-kod-nas_31818.html">Pametni Telefoni</a>)</p>

<p>Whether you‚Äôre a Belgrade local, passing through on a remote-work tour of Europe, or flying in specifically to spend time with the team, we will be delighted to have you!</p>

<p>Book your spot at <a href="https://hub.kagi.com/">hub.kagi.com</a> and help us build a better internet together.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I don't care how well your "AI" works (457 pts)]]></title>
            <link>https://fokus.cool/2025/11/25/i-dont-care-how-well-your-ai-works.html</link>
            <guid>46055944</guid>
            <pubDate>Wed, 26 Nov 2025 10:08:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fokus.cool/2025/11/25/i-dont-care-how-well-your-ai-works.html">https://fokus.cool/2025/11/25/i-dont-care-how-well-your-ai-works.html</a>, See on <a href="https://news.ycombinator.com/item?id=46055944">Hacker News</a></p>
<div id="readability-page-1" class="page"><section> <img src="https://fokus.cool/assets/window.jpg" alt="View out of the window of a bus, but the window is fogged up. Light of different colors is illuminating the window.">  <span> <time datetime="2025-11-25T00:00:00+00:00">November 25, 2025</time> </span> <p>The other day I was sitting on the doorstep of a hackerspace, eating a falafel sandwich while listening to the conversation inside. The topic shifted to the use of ‚ÄúAI‚Äù for everyday tasks, people casually started elaborating on how they use ‚Äúchat assistants‚Äù to let them write pieces of code or annoying emails. The situation is a blueprint for many conversations I had in recent months. What followed in most of them, almost like a reflex, was a self-justification of why the way <em>they</em> use these tools is fine, while other approaches were reckless.</p> <p>I find it particularly disillusioning to realize how deep the LLM brainworm is able to eat itself even into progressive hacker circles.</p> <h2 id="the-grind">the grind</h2> <p>I encountered friends who got fully sucked into the belly of the <em>vibecoding grind</em>. Proficient, talented coders who seem to experience some sort of existential crisis. Staring at the screen in disbelief, unable to let go of Cursor, or whatever tool is <em>the shit</em> right now. Soaking in an unconscious state of harmful coping. Seeing that felt terrifyingly close to witnessing a friend developing a drinking problem.</p> <p>And yeah, I get it. We programmers are currently living through the devaluation of our craft, in a way and rate we never anticipated possible. A fate that designers, writers, translators, tailors or book-binders lived through before us. Not that their craft would die out, but it would be mutilated ‚Äî condemned to the grueling task of cleaning up what the machines messed up. Unsurprisingly, some of us are not handling the new realities well.</p> <p><img src="https://fokus.cool/assets/wet_floor.jpg" alt="A wet floor sign lying in a puddle on a brick floor"></p> <h2 id="new-realities">new realities</h2> <p>I personally don‚Äôt touch LLMs with a stick. I don‚Äôt let them near my brain. Many of my friends share that sentiment.</p> <p>But I think it‚Äôs important to acknowledge that we‚Äôre in a priviliged situation to be able to do so. People are forced to use these systems ‚Äî by UI patterns, bosses expectations, knowledge polution making it increasingly hard to learn things, or just peer pressure. The world adapts to these technologies, and not using them can be a substantial disadvantage in school, university, or anywhere.</p> <p>A lot of the public debate about AI focuses on the quality of its output. Calling out biases, bullshit marketing pledges, making fun of the fascinating ways in which they fail, and so on. Of course, the practical issues are important to discuss, but we shouldn‚Äôt lean too much on that aspect in our philosophy and activisim, or we risk missing the actual agenda of AI.</p> <p><strong>No matter how well ‚ÄúAI‚Äù works, it has some deeply fundamental problems, that won‚Äôt go away with technical progress.</strong> I‚Äôd even go as far and say they are intentional.</p> <h2 id="on-control">on control</h2> <p>Our ability to use tools is an integral part of the human experience. They allow us to do things that we otherwise couldn‚Äôt do. They shape how we think, and consequently who we are.</p> <p>When we use a tool, it becomes part of us<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">1</a></sup>. That‚Äôs not just the case for hammers, pens, or cars, but also for a notebook used to organize thoughts. It becomes part of our cognitive process. Computer are not different. While I‚Äôm typing this text, my fingers are flying over the keyboard, switching windows, opening notes, looking up words in a dictionary. All while I‚Äôm fully focused on the meta-task of getting my thoughts out, unaware of all the tiny miracles happening.</p> <p>Our minds are susceptible to outside cues. When we read news articles we tend to believe what seems plausible. When we review code we generally expect it to behave the way it looks, even when we don‚Äôt have the context to assess that. The same is true for text: When we let a model transform notes into a blog post, a lot of context and nuance is added. We read it and believe the output to be what we thought. It‚Äôs subtle.</p> <blockquote> <p>on a deeper level, writing is more than just the process by which you obtain a piece of text, right? it‚Äôs also about finding out what you wanted to say in the first place, and how you wanted to say it. this post existed in my head first as a thought, then it started to gel into words, and then i tried pulling those words out to arrange them in a way that (hopefully) gets my point across. there is nothing extra there, no filler. i alone can get the thought out and writing is how i do that.</p> </blockquote> <p>Excerpt of a <a href="https://mystical.garden/@thekla/114947873647511129">post by @thekla@mystical.garden</a></p> <h2 id="on-power">on power</h2> <p>In a world where fascists redefine truth, where surveillance capitalist companies, more powerful than democratically elected leaders, exert control over our desires, do we really want their machines to become part of our thought process? To share our most intimate thoughts and connections with them?</p> <p>AI systems exist to reinforce and strengthen existing structures of power and violence. They are the wet dream of capitalists and fascists. Enormous physical infrastructure designed to convert capital into power, and back into capital. Those who control the infrastructure, control the people subject to it.</p> <p>AI systems being egregiously resource intensive is not a side effect ‚Äî <strong>it‚Äôs the point.</strong></p> <p>Craft, expression and skilled labor is what produces value, and that gives us control over ourselves. In order to further centralize power, craft and expression need to be destroyed<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">2</a></sup>. And they sure are trying.</p> <h2 id="whats-left">what‚Äôs left</h2> <p><img src="https://fokus.cool/assets/wayout.jpg" alt="A sign Way Out with an arrow to the left on a tiled wall"></p> <p>How can we be ourselves in this world? What we‚Äôre dealing with here are not questions about AI, but about survival under metastatic capitalism. Shit‚Äôs dire, but there are things we can do. I‚Äôm working on a post about that.</p> <p>Until then, here are some starting points:</p> <ul> <li>Be there for the people around you. Message friends and show them that they matter to you</li> <li>Organize in a union. Together we are stronger.</li> <li>Take care of your mind. Spend less time on social media. Use the freed capacity to educate yourself, go read a book</li> <li><a href="https://lethargic.talkative.fish/@suricrasia/statuses/01KA0X05DAW04MYEXMB1F4FQ1S">Bring something into existence that wouldn‚Äôt otherwise exist</a></li> </ul>  <div> <p> The most disobedient thing we can do is to thrive. </p>  </div>   <span> <hr> <time datetime="2025-11-25T00:00:00+00:00">November 25, 2025</time> ¬∑ <a href="https://fokus.cool/tag/personal">personal</a> , <a href="https://fokus.cool/tag/ai">ai</a> </span> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A cell so minimal that it challenges definitions of life (218 pts)]]></title>
            <link>https://www.quantamagazine.org/a-cell-so-minimal-that-it-challenges-definitions-of-life-20251124/</link>
            <guid>46055935</guid>
            <pubDate>Wed, 26 Nov 2025 10:06:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/a-cell-so-minimal-that-it-challenges-definitions-of-life-20251124/">https://www.quantamagazine.org/a-cell-so-minimal-that-it-challenges-definitions-of-life-20251124/</a>, See on <a href="https://news.ycombinator.com/item?id=46055935">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
            The newly described microbe represents a world of parasitic, intercellular biodiversity only beginning to be revealed by genome sequencing.        </p>
        
    </div><div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>Life‚Äôs fundamental structure is the cell, and so the main things that a cell does ‚Äî processing biomolecules, growing, replicating its genetic material and producing a new body ‚Äî are considered hallmarks of life. But earlier this year, scientists discovered a cell so severely stripped of essential functions that it challenges biologists‚Äô definitions of what counts as a living thing.</p>
<p>The species is a single-celled organism known only by the mysterious sequence of its genetic code. Its genome is fantastically small: Along the organism‚Äôs evolutionary journey, it seems to have gotten rid of most of it. According to the shocked researchers who <a href="https://doi.org/10.1101/2025.05.02.651781">published the discovery</a> in a preprint uploaded to&nbsp;biorxiv.org in May, the lost genes include those central to cell metabolism, meaning it can neither process nutrients nor grow on its own.</p>
<p>Other cells with highly reduced genomes still encode proteins to create amino acids, break down carbohydrates for energy or synthesize vitamins. All this appears to be absent from the cell, which seems to be a parasite entirely dependent on a host or cellular community to meet its nutritional needs. Until now, these genetic pathways were considered fundamental for the survival of any cell.</p>
<p>The organism‚Äôs ‚Äúreplicative core‚Äù ‚Äî the genetic components needed to reproduce itself ‚Äî remains, making up more than half of its genome.</p>
<p>‚ÄúMetabolism is one of the key components of how we often define life,‚Äù said <a href="https://www.u.tsukuba.ac.jp/~nakayama.takuro.gb/index.html">Takuro Nakayama</a>, an evolutionary microbiologist at the University of Tsukuba in Japan who led the team. The cell‚Äôs discovery ‚Äúchallenges this by suggesting a cell can exist almost entirely without its own. It demonstrates that the diversity of cellular life is far greater than we knew and that organisms do not always follow our definitions.‚Äù</p>
<p>While this form of life is new to science, it‚Äôs possible that organisms like it are common. A huge proportion of microbial biodiversity may be hiding in recursive interrelationships between parasitic and host microbes, said <a href="https://www.universite-paris-saclay.fr/en/news/puri-lopez-garcia-naturalist-microbial-world-search-lifes-origins">Puri L√≥pez-Garc√≠a</a>, a microbial ecologist at the French National Center for Scientific Research in Paris who was not involved in the study.</p>
</div>
    </div><div data-role="selectable">
    <p>‚ÄúThe diversity of archaea and bacteria that appear to belong to these supergroups of parasitic organisms is very, very large,‚Äù she said. For bacteria, it may be between 25% and 50% of the group‚Äôs total share of species, she suggested.</p>
<p>The discovery pushes the boundaries of our knowledge of just how small and simple cellular life can become, as it evolves even into forms that are barely alive.</p>
<h2><strong>An Extraordinary Discovery</strong></h2>
<p>Nakayama has built a scientific career out of looking more closely than other researchers typically do. He considers an already tiny cell and wonders: Are there even smaller cells that make a home there?</p>
<p>‚ÄúThe difference [in size between parasitic and host cells] can sometimes be like that between a human and Godzilla,‚Äù Nakayama said. He is fascinated by the potentially vast amount of undiscovered biodiversity these relationships might contain, and his lab looks for such relationships in seawater. The ocean is a nutrient-poor environment that incentivizes cells to form <a href="https://www.quantamagazine.org/the-ocean-teems-with-networks-of-interconnected-bacteria-20250106/">trading partnerships</a>. Sometimes they <a href="https://www.quantamagazine.org/microbes-also-change-the-climate-could-that-help-us-20250915/#microbiome">float along together</a>, loosely tethered, exchanging rare nutrients and energy. Other times their arrangements are more organized.</p>

<p><em>Citharistes regius</em> is a globally widespread single-celled dinoflagellate that has a walled, pouchlike external chamber for housing symbiotic cyanobacteria. Nakayama and his team searched for the alga by scooping seawater samples from the Pacific Ocean using a fine-mesh net. A common technique is to sequence whatever DNA can be found in the soup of such a sample, an approach called metagenomics.</p>
<p>‚ÄúThat method is incredibly powerful for capturing a broad overview,‚Äù Nakayama said. ‚ÄúHowever, with such data, it is often difficult to maintain the link between a sequence and the specific cell it came from, and rare organisms can be easily missed.‚Äù His team‚Äôs more targeted approach involves microscopically identifying and physically isolating a single target cell from that mixed sample.</p>
<p>Back on shore in the Tsukuba lab, after the researchers confirmed they had <em>C. regius</em>, they sequenced every genome associated with that one cell. As expected, they found DNA from its symbiotic cyanobacteria, but they found something else, too: sequences that belong to an archaeon, a member of the domain of life thought to have given rise to <a href="https://www.quantamagazine.org/meet-the-eukaryote-the-first-cell-to-get-organized-20241028/">eukaryotes</a> like us.</p>

<p>At first, Nakayama and his colleagues thought they had made a mistake. The archaeal genome is tiny: just 238,000 base pairs end to end. In comparison, humans have a few billion base pairs, and even <em>E. coli</em> bacteria work with several million. (<em>C. regius</em>‚Äô symbiotic cyanobacteria have 1.9 million base pairs.) Previously, the smallest known archaeal genome was the one belonging to <em>Nanoarchaeum equitans ‚Äî</em> at 490,000 base pairs, it is more than twice as long as the new one the researchers found. They initially figured that this tiny genome ‚Äî too large to be merely statistical noise ‚Äî was an abbreviated piece of a much larger genome, erroneously compiled by their software.</p>
<p>‚ÄúAt first, we suspected it might be an artifact of the genome-assembly process,‚Äù Nakayama recalled. To check, the team sequenced the genome using different technologies and ran the data through multiple computer programs that assemble fragments of DNA sequences into a full genome. The various approaches all reconstructed the exact same 238,000-base-pair circular genome. ‚ÄúThis consistency is what convinced us it was the real, complete genome,‚Äù he said.</p>
<p>This meant that Nakayama and his team had a new organism on their hands. They named the microbe <em>Candidatus</em> Sukunaarchaeum mirabile (hereafter referred to as Sukunaarchaeum) for its remarkably tiny genome ‚Äî after Sukuna-biko-na, a Shinto deity notable for his short stature, plus a Latin word for ‚Äúextraordinary.‚Äù</p>
<h2><strong>The Spectrum of Quasi-Life</strong></h2>
<p>When the team consulted databases of known genes to analyze the archaeon, they found its small size was the result of a whole lot that was missing.</p>
<p>Sukunaarchaeum encodes the barest minimum of proteins for its own replication, and that‚Äôs about all. Most strangely, its genome is missing any hints of the genes required to process and build molecules, outside of those needed to reproduce. Lacking those metabolic components, the organism must outsource the processes for growth and maintenance to another cell, a host upon which the microbe is entirely dependent.</p>
    
    
    
    
<p>Other symbiotic microbes have scrapped much of their genomes, including Sukunaarchaeum‚Äôs evolutionary relatives. The researchers‚Äô analysis suggested that the microbe is part of the DPANN archaea, sometimes called nanoarchaea or ultra-small archaea, which are characterized by small size and small genomes. DPANN archaea are generally thought to be symbiotes that cling to the outside of larger prokaryotic microbes, and plenty of them have substantially reduced genomes to match that lifestyle. But until now, none of the DPANN species had genomes quite this pared back. And Sukunaarchaeum branched off the DPANN lineage early, suggesting that it had taken its own evolutionary journey.</p>
<p>‚ÄúThis realm of the archaea is pretty mysterious in general,‚Äù said <a href="https://marinescience.utexas.edu/directory/brett-baker">Brett Baker</a>, a microbial ecologist at the University of Texas, Austin who was not involved in the work. ‚Äú[DPANN archaea are] obviously limited in their metabolic capabilities.‚Äù</p>
<p>While Sukunaarchaeum&nbsp;may provide some undetermined benefit for its host ‚Äî which could be <em>C. regius</em>, the symbiotic cyanobacteria or another cell entirely ‚Äî it‚Äôs probably a self-absorbed parasite. ‚ÄúIts genome reduction is driven by entirely selfish motives, consistent with a parasitic lifestyle,‚Äù said <a href="https://www.unsw.edu.au/staff/timothy-williams">Tim Williams</a>, a microbiologist at the University of Technology Sydney who was not involved in the study. It cannot contribute metabolic products, so the relationship between&nbsp;Sukunaarchaeum&nbsp;and any other cell would likely be a one-way street.</p>
<p>Other microbes have evolved similarly extreme, streamlined forms. For instance, the bacterium <em>Carsonella ruddii</em>, which lives as a symbiont within the guts of sap-feeding insects, has an even smaller genome than Sukunaarchaeum, at around 159,000 base pairs. However, these and other super-small bacteria have metabolic genes to produce nutrients, such as amino acids and vitamins, for their hosts. Instead, their genome has cast off much of their ability to reproduce on their own.</p>
<p>‚ÄúThey are on the way to becoming organelles. This is the way mitochondria and chloroplasts are thought to have evolved,‚Äù Williams said. ‚ÄúBut Sukunaarchaeum has gone in the opposite direction: The genome retains genes required for its own propagation, but lost most, if not all, of its metabolic genes.‚Äù</p>
</div><div data-role="selectable">
    <p>Soon after Nakayama‚Äôs team posted their results online, they got a big response. ‚ÄúWhen we saw the preprint, this was really quite exciting in the lab,‚Äù said <a href="https://www.wur.nl/en/persons/thijs-ettema-1.htm">Thijs Ettema</a>, an evolutionary microbiologist and expert on archaeal genomics at Wageningen University &amp; Research in the Netherlands, who was not involved in the work. ‚ÄúThese types of organisms [with reduced genomes] have been found before, but not as extreme as this.‚Äù</p>
<p>Some news reports went so far as to imply that Sukunaarchaeum is on its way to <a href="https://www.science.org/content/article/microbe-bizarrely-tiny-genome-may-be-evolving-virus">evolving into a virus</a>. However, while both Sukunaarchaeum and viruses are reliant on a host cell for very basic biological functions, viruses can‚Äôt reproduce on their own.</p>
<p>‚ÄúThere is a fundamental gap between Sukunaarchaeum and viruses,‚Äù Nakayama said. ‚ÄúSukunaarchaeum retains its own core machinery for gene expression, including ribosomes, albeit in a simplified form. This is in stark contrast to viruses, which lack ribosomes and must hijack the host‚Äôs cellular systems to replicate.‚Äù</p>
</div><div data-role="selectable">
    <p>The findings fit into a larger discussion about how we define life, Ettema said, since nature routinely evolves exceptions that defy simple categorization. ‚ÄúMost likely it cannot live independently,‚Äù he said. ‚ÄúYou could say the same of bacterial symbionts. And what do we call organelles like mitochondria and plastids? ‚Ä¶ At what point should we call things alive?‚Äù</p>
<h2><strong>A Minimalist Lifestyle</strong></h2>
<p>Many questions about Sukunaarchaeum remain unresolved. For one, a large portion of its genome is made up of genes that don‚Äôt match any known sequences. They seem to encode large proteins, which is uncommon in such radically reduced organisms.</p>
<p>Nakayama and his colleagues think these large proteins are employed on the cell membrane and somehow support interactions between the archaeon and its host. That would fit with the lifestyles of other studied DPANN archaea as well, Ettema said, which are generally thought to be ectosymbionts, adhering to the outside of comparatively immense hosts.</p>
<p>Although Sukunaarchaeum was found in association with the dinoflagellate <em>C. regius</em>, its true host‚Äôs identity is unknown. <em>C. regius</em> is a eukaryote, but DPANN archaea generally associate with other archaea. Also up for debate: Is it attaching to the outside of a host cell, like other DPANN archaea, or is it living internally ‚Äî&nbsp;or both? Answering these questions would require setting human eyes on the archaeon for the first time; at this point it‚Äôs only known from a curious string of genetic data.</p>
        
        
<p>There is also a slim possibility that these genes are the ‚Äúlost‚Äù metabolic genes after all, L√≥pez-Garc√≠a said, if they have evolved so far from their original sequences as to be unrecognizable. ‚ÄúBecause the genome is so fast-evolving, maybe some of these functions correspond to metabolic functions, but the divergence is so much that we cannot identify the [gene] homologue [in the database],‚Äù she said.</p>
<p>Even stranger minimalist lifestyles or more reduced genomes may be out there, but researchers may miss them, Ettema said. Traditional analytical approaches for surveying the genomes of microbial samples could flag their tiny genomes as incomplete or low quality and discard them, or skip them entirely, he said. ‚Äú[The DNA] might have been present in the samples, but it was removed after sequencing, and hence overlooked.‚Äù</p>
<p>When Nakayama and his colleagues searched a database of marine environmental sequence data from the world‚Äôs oceans to see if the new microbe popped up anywhere else, they didn‚Äôt find any matches. But they did detect many very similar sequences from what are likely to be close relatives. Sukunaarchaeum may be the tip of a very large microbial iceberg, one floating in a vast ocean of microbial diversity: tiny microbes clinging to slightly less tiny microbes, perhaps inside other microbes, the stories of their ancient relationships only beginning to be revealed.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Statistical Process Control in Python (175 pts)]]></title>
            <link>https://timothyfraser.com/sigma/statistical-process-control-in-python.html</link>
            <guid>46055421</guid>
            <pubDate>Wed, 26 Nov 2025 08:40:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html">https://timothyfraser.com/sigma/statistical-process-control-in-python.html</a>, See on <a href="https://news.ycombinator.com/item?id=46055421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="section-" number="16" tabindex="-1" role="main">

<div><p><span id="fig:unnamed-chunk-1"></span>
<img src="https://timothyfraser.com/sigma/images/9_chart.png" alt="Statistical Process Control!" width="100%"></p><p>
Figure 2.1: Statistical Process Control!
</p>
</div>
<p>In this workshop, we will learn how to perform statistical process control in Python, using statistical tools and <code>plotnine</code> visualizations! Statistical Process Control refers to using statistics to (1) measure variation in product quality over time and (2) identify benchmarks to know when intervention is needed. Let‚Äôs get started!</p>
<hr>
<div id="getting-started-14">
<h2>Getting Started<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#getting-started-14" aria-label="Anchor link to header"></a></h2>
<div id="packages-7">
<h3>Packages<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#packages-7" aria-label="Anchor link to header"></a></h3>
<div id="cb847"><pre><code><span id="cb847-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb847-1" tabindex="-1"></a><span># Remember to install these packages using a terminal, if you haven't already!</span></span>
<span id="cb847-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb847-2" tabindex="-1"></a><span>!</span>pip install pandas plotnine scipy</span></code></pre></div>
<p>We‚Äôll be using <code>pandas</code> for data manipulation, <code>plotnine</code> for visualization, and <code>scipy</code> for statistical functions.</p>
<div id="cb848"><pre><code><span id="cb848-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb848-1" tabindex="-1"></a><span>import</span> pandas <span>as</span> pd</span>
<span id="cb848-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb848-2" tabindex="-1"></a><span>from</span> plotnine <span>import</span> <span>*</span></span></code></pre></div>
</div>
<div id="custom-functions-1">
<h3>Custom Functions<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#custom-functions-1" aria-label="Anchor link to header"></a></h3>
<p>This workshop uses custom functions from the <code>functions/</code> directory. You may need both:
- <code>functions_distributions.py</code> - for reliability and distribution functions
- <code>functions_process_control.py</code> - for statistical process control functions</p>
<p>To use these functions, you need to acquire them from the repository at <a href="https://github.com/timothyfraser/sigma/tree/main/functions">github.com/timothyfraser/sigma/tree/main/functions</a>.</p>
<p><strong>Add the functions directory to your Python path</strong></p>
<div id="cb849"><pre><code><span id="cb849-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb849-1" tabindex="-1"></a><span>import</span> sys</span>
<span id="cb849-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb849-2" tabindex="-1"></a><span>import</span> os</span>
<span id="cb849-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb849-3" tabindex="-1"></a><span># Add the functions directory to Python path</span></span>
<span id="cb849-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb849-4" tabindex="-1"></a>sys.path.append(<span>'functions'</span>)  <span># or path to wherever you placed the functions folder</span></span></code></pre></div>
<p>Once you have the functions available, you can import them:</p>
<div id="cb850"><pre><code><span id="cb850-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb850-1" tabindex="-1"></a><span>from</span> functions_distributions <span>import</span> density, tidy_density, approxfun</span>
<span id="cb850-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb850-2" tabindex="-1"></a><span># from functions_process_control import ggprocess, ggsubgroup, ggmoving, ggcapability  # if needed</span></span></code></pre></div>
</div>
<div id="our-case-1">
<h3>Our Case<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#our-case-1" aria-label="Anchor link to header"></a></h3>

<p>For today‚Äôs workshop, we‚Äôre going to think about why quality control matters in a local economy, by examining the case of the Japanese Hot Springs bath economy! Hot springs, or <em>onsen</em>, are <a href="https://asiatimes.com/2020/07/japanese-hot-spring-tourism-at-a-crossroads/">a major source of tourism and recreation for families in Japan</a>, bringing residents from across the country every year to often rural communities where the right geological conditions have brought on naturally occurring hot springs. Restaurants, taxi and bus companies, and many service sector firms rely on their local onsen to bring in a steady stream (pun intended) of tourists to the local economy. So, it‚Äôs often in the best interest of <em>onsen</em> operators to keep an eye on the temperature, minerals, or other aspects of their hot springs baths to ensure quality control, to keep up their firm (and town‚Äôs!) reputation for quality rest and relaxation!</p>
<p><em>Onsen</em>-goers often seek out <em>specific</em> types of hot springs, so it‚Äôs important for an <em>onsen</em> to actually provide what it advertises! <a href="http://dx.doi.org/10.1016/j.healthplace.2012.06.020">Serbulea and Payyappallimana (2012)</a> describe some of these benchmarks.</p>
<ul>
<li><p><strong>Temperature</strong>: Onsen are divided into ‚ÄúExtra Hot Springs‚Äù (<code>&gt;42¬∞C</code>), ‚ÄúHot Springs‚Äù (<code>41~34¬∞C</code>), and ‚ÄúWarm Springs‚Äù (<code>33~25¬∞C</code>).</p></li>
<li><p><strong>pH</strong>: Onsen are classified into ‚ÄúAcidic‚Äù (<code>pH &lt; 3</code>), ‚ÄúMildly Acidic‚Äù (<code>pH 3~6</code>), ‚ÄúNeutral‚Äù (<code>pH 6~7.5</code>), ‚ÄúMildly alkaline‚Äù (<code>pH 7.5~8.5</code>), and ‚ÄúAlkaline‚Äù (<code>pH &gt; 8.5</code>).</p></li>
<li><p><strong>Sulfur</strong>: Sulfur <em>onsen</em> typically have about 2mg of sulfur per 1kg of hot spring water; sulfur levels <em>must</em> exceed 1 mg to count as a Sulfur <em>onsen.</em> (It smells like rotten eggs!)</p></li>
</ul>
<p>These are decent examples of quality control metrics that <em>onsen</em> operators might want to keep tabs on!</p>
<div><p><span id="fig:unnamed-chunk-3"></span>
<img src="https://timothyfraser.com/sigma/images/9_monkeys.png" alt="Monkeys are even fans of onsen! Read [**more here!**](https://www.nytimes.com/2018/04/03/science/japan-monkeys-hot-springs-stress.html)" width="100%"></p><p>
Figure 4.1: Monkeys are even fans of onsen! Read <a href="https://www.nytimes.com/2018/04/03/science/japan-monkeys-hot-springs-stress.html"><strong>more here!</strong></a>
</p>
</div>
</div>
<div id="our-data-3">
<h3>Our Data<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#our-data-3" aria-label="Anchor link to header"></a></h3>
<p>You‚Äôve been hired to evaluate quality control at a local <em>onsen</em> in sunny Kagoshima prefecture! Every month, for 15 months, you systematically took 20 random samples of hot spring water and recorded its <strong>temperature</strong>, <strong>pH</strong>, and <strong>sulfur</strong> levels. How might you determine if this <em>onsen</em> is at risk of slipping out of one sector of the market (eg. Extra Hot!) and into another (just normal Hot Springs?).</p>
<p>Let‚Äôs read in our data from <code>workshops/onsen.csv</code>!</p>
<div id="cb851"><pre><code><span id="cb851-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-1" tabindex="-1"></a><span># Add functions directory to path if not already there</span></span>
<span id="cb851-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-2" tabindex="-1"></a><span>import</span> sys</span>
<span id="cb851-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-3" tabindex="-1"></a><span>if</span> <span>'functions'</span> <span>not</span> <span>in</span> sys.path:</span>
<span id="cb851-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-4" tabindex="-1"></a>    sys.path.append(<span>'functions'</span>)</span>
<span id="cb851-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-5" tabindex="-1"></a></span>
<span id="cb851-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-6" tabindex="-1"></a><span>from</span> functions_distributions <span>import</span> density, tidy_density, approxfun</span>
<span id="cb851-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-7" tabindex="-1"></a></span>
<span id="cb851-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-8" tabindex="-1"></a>water <span>=</span> pd.read_csv(<span>'workshops/onsen.csv'</span>)</span>
<span id="cb851-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb851-9" tabindex="-1"></a>water.head(<span>3</span>)</span></code></pre></div>
<pre><code>##    id  time  temp   ph  sulfur
## 0   1     1  43.2  5.1     0.0
## 1   2     1  45.3  4.8     0.4
## 2   3     1  45.5  6.2     0.9</code></pre>
</div>
</div>
<div id="process-descriptive-statistics-1" number="16.1">
<h2> Process Descriptive Statistics<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#process-descriptive-statistics-1" aria-label="Anchor link to header"></a></h2>
<p>First, let‚Äôs get a sense of our process by calculating some basic descriptive statistics. We‚Äôll create a simple function to calculate the mean and standard deviation, which are fundamental to evaluating process variation.</p>
<div id="cb853"><pre><code><span id="cb853-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-1" tabindex="-1"></a><span>from</span> pandas <span>import</span> Series</span>
<span id="cb853-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-2" tabindex="-1"></a><span>def</span> describe(x: Series):</span>
<span id="cb853-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-3" tabindex="-1"></a>  x <span>=</span> Series(x)</span>
<span id="cb853-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-4" tabindex="-1"></a>  out <span>=</span> pd.DataFrame({</span>
<span id="cb853-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-5" tabindex="-1"></a>    <span>'mean'</span>: [x.mean()],</span>
<span id="cb853-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-6" tabindex="-1"></a>    <span>'sd'</span>: [x.std()],</span>
<span id="cb853-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-7" tabindex="-1"></a>  })</span>
<span id="cb853-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-8" tabindex="-1"></a>  out[<span>'caption'</span>] <span>=</span> (<span>"Process Mean: "</span> <span>+</span> out[<span>'mean'</span>].<span>round</span>(<span>2</span>).astype(<span>str</span>) <span>+</span></span>
<span id="cb853-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-9" tabindex="-1"></a>                    <span>" | SD: "</span> <span>+</span> out[<span>'sd'</span>].<span>round</span>(<span>2</span>).astype(<span>str</span>))</span>
<span id="cb853-10"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-10" tabindex="-1"></a>  <span>return</span> out</span>
<span id="cb853-11"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-11" tabindex="-1"></a></span>
<span id="cb853-12"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-12" tabindex="-1"></a>tab <span>=</span> describe(water[<span>'temp'</span>])</span>
<span id="cb853-13"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb853-13" tabindex="-1"></a>tab</span></code></pre></div>
<pre><code>##     mean        sd                         caption
## 0  44.85  1.989501  Process Mean: 44.85 | SD: 1.99</code></pre>
<p>Now let‚Äôs apply this to our temperature data to see the overall process mean and variation.</p>
</div>
<div id="process-overview-visual-1" number="16.2">
<h2> Process Overview Visual<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#process-overview-visual-1" aria-label="Anchor link to header"></a></h2>
<p>The process overview chart is one of the most important tools in SPC. It shows us how our process behaves over time, helping us identify patterns, trends, and potential issues. We‚Äôll create a visualization that shows individual measurements, subgroup means, and the overall process average.</p>
<div id="cb855"><pre><code><span id="cb855-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-1" tabindex="-1"></a>g1 <span>=</span> (ggplot(water, aes(x<span>=</span><span>'time'</span>, y<span>=</span><span>'temp'</span>, group<span>=</span><span>'time'</span>)) <span>+</span></span>
<span id="cb855-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-2" tabindex="-1"></a>  geom_hline(aes(yintercept<span>=</span>water[<span>'temp'</span>].mean()), color<span>=</span><span>'lightgrey'</span>, size<span>=</span><span>3</span>) <span>+</span></span>
<span id="cb855-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-3" tabindex="-1"></a>  geom_jitter(height<span>=</span><span>0</span>, width<span>=</span><span>0.25</span>) <span>+</span></span>
<span id="cb855-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-4" tabindex="-1"></a>  geom_boxplot() <span>+</span></span>
<span id="cb855-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-5" tabindex="-1"></a>  labs(x<span>=</span><span>'Time (Subgroup)'</span>, y<span>=</span><span>'Temperature (Celsius)'</span>, subtitle<span>=</span><span>'Process Overview'</span>, caption<span>=</span>tab[<span>'caption'</span>][<span>0</span>]))</span>
<span id="cb855-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-6" tabindex="-1"></a></span>
<span id="cb855-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-7" tabindex="-1"></a><span># Save the plot</span></span>
<span id="cb855-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb855-8" tabindex="-1"></a>g1.save(<span>'images/05_process_overview.png'</span>, width<span>=</span><span>8</span>, height<span>=</span><span>6</span>, dpi<span>=</span><span>100</span>)</span></code></pre></div>
<p><img src="https://timothyfraser.com/sigma/images/05_process_overview.png" width="100%"></p>
<div id="cb856"><pre><code><span id="cb856-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb856-1" tabindex="-1"></a>g2 <span>=</span> (ggplot(water, aes(x<span>=</span><span>'temp'</span>)) <span>+</span> geom_histogram(bins<span>=</span><span>15</span>, color<span>=</span><span>'white'</span>, fill<span>=</span><span>'grey'</span>) <span>+</span> theme_void() <span>+</span> coord_flip())</span>
<span id="cb856-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb856-2" tabindex="-1"></a></span>
<span id="cb856-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb856-3" tabindex="-1"></a><span># Save the plot</span></span>
<span id="cb856-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb856-4" tabindex="-1"></a>g2.save(<span>'images/05_process_histogram.png'</span>, width<span>=</span><span>8</span>, height<span>=</span><span>6</span>, dpi<span>=</span><span>100</span>)</span></code></pre></div>
<p><img src="https://timothyfraser.com/sigma/images/05_process_histogram.png" width="100%"></p>
<p>The histogram shows us the distribution of all temperature measurements, giving us insight into the overall process variation. This helps us understand if our process is centered and how much variation we‚Äôre seeing.</p>
</div>
<div id="subgroup-within-group-statistics-1" number="16.3">
<h2> Subgroup (Within-Group) Statistics<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#subgroup-within-group-statistics-1" aria-label="Anchor link to header"></a></h2>
<p>In SPC, we often work with <em>subgroups</em> - small samples taken at regular intervals. This allows us to distinguish between common cause variation (inherent to the process) and special cause variation (due to specific events). Let‚Äôs calculate statistics for each subgroup to see how the process behaves over time.</p>
<div id="cb857"><pre><code><span id="cb857-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-1" tabindex="-1"></a>stat_s <span>=</span> (water.groupby(<span>'time'</span>).<span>apply</span>(<span>lambda</span> d: pd.Series({</span>
<span id="cb857-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-2" tabindex="-1"></a>  <span>'xbar'</span>: d[<span>'temp'</span>].mean(),</span>
<span id="cb857-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-3" tabindex="-1"></a>  <span>'r'</span>: d[<span>'temp'</span>].<span>max</span>() <span>-</span> d[<span>'temp'</span>].<span>min</span>(),</span>
<span id="cb857-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-4" tabindex="-1"></a>  <span>'sd'</span>: d[<span>'temp'</span>].std(),</span>
<span id="cb857-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-5" tabindex="-1"></a>  <span>'nw'</span>: <span>len</span>(d)</span>
<span id="cb857-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-6" tabindex="-1"></a>})).reset_index())</span>
<span id="cb857-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-7" tabindex="-1"></a>stat_s[<span>'df'</span>] <span>=</span> stat_s[<span>'nw'</span>] <span>-</span> <span>1</span></span>
<span id="cb857-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-8" tabindex="-1"></a>stat_s[<span>'sigma_s'</span>] <span>=</span> ( (stat_s[<span>'df'</span>] <span>*</span> (stat_s[<span>'sd'</span>]<span>**</span><span>2</span>)).<span>sum</span>() <span>/</span> stat_s[<span>'df'</span>].<span>sum</span>() )<span>**</span><span>0.5</span></span>
<span id="cb857-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-9" tabindex="-1"></a>stat_s[<span>'se'</span>] <span>=</span> stat_s[<span>'sigma_s'</span>] <span>/</span> (stat_s[<span>'nw'</span>]<span>**</span><span>0.5</span>)</span>
<span id="cb857-10"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-10" tabindex="-1"></a>stat_s[<span>'upper'</span>] <span>=</span> stat_s[<span>'xbar'</span>].mean() <span>+</span> <span>3</span><span>*</span>stat_s[<span>'se'</span>]</span>
<span id="cb857-11"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-11" tabindex="-1"></a>stat_s[<span>'lower'</span>] <span>=</span> stat_s[<span>'xbar'</span>].mean() <span>-</span> <span>3</span><span>*</span>stat_s[<span>'se'</span>]</span>
<span id="cb857-12"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb857-12" tabindex="-1"></a>stat_s.head(<span>3</span>)</span></code></pre></div>
<pre><code>##    time    xbar    r        sd    nw    df   sigma_s        se      upper      lower
## 0     1  44.635  4.2  1.342533  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 1     3  45.305  7.9  2.001440  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 2     5  44.765  5.9  1.628133  20.0  19.0  1.986174  0.444122  46.182366  43.517634</code></pre>
<p>Here we‚Äôve calculated key statistics for each subgroup:</p>
<ul>
<li><strong>xbar</strong>: The mean of each subgroup</li>
<li><strong>r</strong>: The range (max - min) within each subgroup<br>
</li>
<li><strong>sd</strong>: The standard deviation within each subgroup</li>
<li><strong>sigma_s</strong>: The pooled within-subgroup standard deviation</li>
<li><strong>se</strong>: The standard error for each subgroup mean</li>
</ul>
<div id="total-statistics-between-groups-1" number="16.3.1">
<h3> Total Statistics (Between Groups)<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#total-statistics-between-groups-1" aria-label="Anchor link to header"></a></h3>
<p>Now let‚Äôs calculate the overall process statistics that summarize the behavior across all subgroups:</p>
<div id="cb859"><pre><code><span id="cb859-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-1" tabindex="-1"></a>stat_t <span>=</span> pd.DataFrame({</span>
<span id="cb859-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-2" tabindex="-1"></a>  <span>'xbbar'</span>: [stat_s[<span>'xbar'</span>].mean()],</span>
<span id="cb859-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-3" tabindex="-1"></a>  <span>'rbar'</span>: [stat_s[<span>'r'</span>].mean()],</span>
<span id="cb859-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-4" tabindex="-1"></a>  <span>'sdbar'</span>: [stat_s[<span>'sd'</span>].mean()],</span>
<span id="cb859-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-5" tabindex="-1"></a>  <span>'sigma_s'</span>: [(stat_s[<span>'sd'</span>]<span>**</span><span>2</span>).mean()<span>**</span><span>0.5</span>],</span>
<span id="cb859-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-6" tabindex="-1"></a>  <span>'sigma_t'</span>: [water[<span>'temp'</span>].std()]</span>
<span id="cb859-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-7" tabindex="-1"></a>})</span>
<span id="cb859-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb859-8" tabindex="-1"></a>stat_t</span></code></pre></div>
<pre><code>##    xbbar    rbar    sdbar   sigma_s   sigma_t
## 0  44.85  7.2625  1.93619  1.986174  1.989501</code></pre>
<p>These statistics give us:</p>
<ul>
<li><strong>xbbar</strong>: The grand mean (average of all subgroup means)</li>
<li><strong>rbar</strong>: The average range across subgroups</li>
<li><strong>sdbar</strong>: The average standard deviation across subgroups</li>
<li><strong>sigma_s</strong>: The pooled within-subgroup standard deviation</li>
<li><strong>sigma_t</strong>: The total process standard deviation</li>
</ul>
</div>
<div id="average-and-standard-deviation-charts-1" number="16.3.2">
<h3> Average and Standard Deviation Charts<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#average-and-standard-deviation-charts-1" aria-label="Anchor link to header"></a></h3>
<p>Control charts are the heart of SPC. They help us monitor process stability over time and detect when the process is out of control. We‚Äôll create charts for both the subgroup means (X-bar chart) and standard deviations (S chart).</p>
<div id="cb861"><pre><code><span id="cb861-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-1" tabindex="-1"></a>labels <span>=</span> pd.DataFrame({</span>
<span id="cb861-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-2" tabindex="-1"></a>  <span>'time'</span>: [stat_s[<span>'time'</span>].<span>max</span>()]<span>*</span><span>3</span>,</span>
<span id="cb861-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-3" tabindex="-1"></a>  <span>'type'</span>: [<span>'xbbar'</span>,<span>'upper'</span>,<span>'lower'</span>],</span>
<span id="cb861-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-4" tabindex="-1"></a>  <span>'name'</span>: [<span>'mean'</span>,<span>'+3 s'</span>,<span>'-3 s'</span>],</span>
<span id="cb861-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-5" tabindex="-1"></a>  <span>'value'</span>: [stat_s[<span>'xbar'</span>].mean(), stat_s[<span>'upper'</span>].iloc[<span>0</span>], stat_s[<span>'lower'</span>].iloc[<span>0</span>]]</span>
<span id="cb861-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-6" tabindex="-1"></a>})</span>
<span id="cb861-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-7" tabindex="-1"></a></span>
<span id="cb861-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-8" tabindex="-1"></a>control_chart <span>=</span> (ggplot(stat_s, aes(x<span>=</span><span>'time'</span>, y<span>=</span><span>'xbar'</span>)) <span>+</span></span>
<span id="cb861-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-9" tabindex="-1"></a>  geom_hline(aes(yintercept<span>=</span>stat_s[<span>'xbar'</span>].mean()), color<span>=</span><span>'lightgrey'</span>, size<span>=</span><span>3</span>) <span>+</span></span>
<span id="cb861-10"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-10" tabindex="-1"></a>  geom_ribbon(aes(ymin<span>=</span><span>'lower'</span>, ymax<span>=</span><span>'upper'</span>), fill<span>=</span><span>'steelblue'</span>, alpha<span>=</span><span>0.2</span>) <span>+</span></span>
<span id="cb861-11"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-11" tabindex="-1"></a>  geom_line(size<span>=</span><span>1</span>) <span>+</span> geom_point(size<span>=</span><span>5</span>) <span>+</span></span>
<span id="cb861-12"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-12" tabindex="-1"></a>  geom_label(data<span>=</span>labels, mapping<span>=</span>aes(x<span>=</span><span>'time'</span>, y<span>=</span><span>'value'</span>, label<span>=</span><span>'name'</span>), ha<span>=</span><span>'right'</span>) <span>+</span></span>
<span id="cb861-13"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-13" tabindex="-1"></a>  labs(x<span>=</span><span>'Time (Subgroups)'</span>, y<span>=</span><span>'Average'</span>, subtitle<span>=</span><span>'Average and Standard Deviation Chart'</span>))</span>
<span id="cb861-14"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-14" tabindex="-1"></a></span>
<span id="cb861-15"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-15" tabindex="-1"></a><span># Save the plot</span></span>
<span id="cb861-16"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb861-16" tabindex="-1"></a>control_chart.save(<span>'images/05_control_chart.png'</span>, width<span>=</span><span>8</span>, height<span>=</span><span>6</span>, dpi<span>=</span><span>100</span>)</span></code></pre></div>
<p><img src="https://timothyfraser.com/sigma/images/05_control_chart.png" width="100%"></p>
<p>This control chart shows:</p>
<ul>
<li><strong>Center line</strong>: The grand mean (xbbar)</li>
<li><strong>Control limits</strong>: Upper and lower 3-sigma limits based on the standard error</li>
<li><strong>Individual points</strong>: Each subgroup mean plotted over time</li>
<li><strong>Shaded area</strong>: The control limits region</li>
</ul>
<p>Points outside the control limits or showing non-random patterns indicate the process may be out of control and requires investigation.</p>
<hr>
</div>
</div>
<div id="learning-check-1-11">
<h2>Learning Check 1<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#learning-check-1-11" aria-label="Anchor link to header"></a></h2>
<p><strong>Question</strong></p>
<p>Produce the same process overview chart for <code>pH</code>.</p>
<details>
<summary>
<strong>[View Answer!]</strong>
</summary>
<div id="cb862"><pre><code><span id="cb862-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-1" tabindex="-1"></a><span>def</span> ggprocess(x, y, xlab<span>=</span><span>'Subgroup'</span>, ylab<span>=</span><span>'Metric'</span>):</span>
<span id="cb862-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-2" tabindex="-1"></a>  <span>import</span> pandas <span>as</span> pd</span>
<span id="cb862-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-3" tabindex="-1"></a>  <span>from</span> plotnine <span>import</span> ggplot, aes, geom_hline, geom_jitter, geom_boxplot, labs</span>
<span id="cb862-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-4" tabindex="-1"></a>  d <span>=</span> pd.DataFrame({<span>'x'</span>: x, <span>'y'</span>: y})</span>
<span id="cb862-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-5" tabindex="-1"></a>  g <span>=</span> (ggplot(d, aes(x<span>=</span><span>'x'</span>, y<span>=</span><span>'y'</span>, group<span>=</span><span>'x'</span>)) <span>+</span></span>
<span id="cb862-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-6" tabindex="-1"></a>       geom_hline(aes(yintercept<span>=</span>d[<span>'y'</span>].mean()), color<span>=</span><span>'lightgrey'</span>, size<span>=</span><span>3</span>) <span>+</span></span>
<span id="cb862-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-7" tabindex="-1"></a>       geom_jitter(height<span>=</span><span>0</span>, width<span>=</span><span>0.25</span>) <span>+</span></span>
<span id="cb862-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-8" tabindex="-1"></a>       geom_boxplot() <span>+</span></span>
<span id="cb862-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-9" tabindex="-1"></a>       labs(x<span>=</span>xlab, y<span>=</span>ylab, subtitle<span>=</span><span>'Process Overview'</span>))</span>
<span id="cb862-10"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-10" tabindex="-1"></a>  <span>return</span> g</span>
<span id="cb862-11"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-11" tabindex="-1"></a></span>
<span id="cb862-12"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-12" tabindex="-1"></a>ph_chart <span>=</span> ggprocess(water[<span>'time'</span>], water[<span>'ph'</span>])</span>
<span id="cb862-13"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-13" tabindex="-1"></a></span>
<span id="cb862-14"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-14" tabindex="-1"></a><span># Save the plot</span></span>
<span id="cb862-15"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb862-15" tabindex="-1"></a>ph_chart.save(<span>'images/05_ph_chart.png'</span>, width<span>=</span><span>8</span>, height<span>=</span><span>6</span>, dpi<span>=</span><span>100</span>)</span></code></pre></div>
<p><img src="https://timothyfraser.com/sigma/images/05_ph_chart.png" width="100%"></p>
</details>
<hr>
</div>
<div id="moving-range-charts-n1" number="16.4">
<h2> Moving Range Charts (n=1)<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#moving-range-charts-n1" aria-label="Anchor link to header"></a></h2>
<p>When we have individual measurements rather than subgroups, we use moving range charts. The moving range is the absolute difference between consecutive measurements, which helps us estimate process variation when we can‚Äôt calculate within-subgroup statistics.</p>
<div id="cb863"><pre><code><span id="cb863-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-1" tabindex="-1"></a>indiv <span>=</span> water.iloc[[<span>0</span>,<span>20</span>,<span>40</span>,<span>60</span>,<span>80</span>,<span>100</span>,<span>120</span>,<span>140</span>]]</span>
<span id="cb863-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-2" tabindex="-1"></a>mr <span>=</span> (indiv[<span>'temp'</span>].diff().<span>abs</span>().dropna())</span>
<span id="cb863-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-3" tabindex="-1"></a>mrbar <span>=</span> mr.mean()</span>
<span id="cb863-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-4" tabindex="-1"></a><span>import</span> numpy <span>as</span> np</span>
<span id="cb863-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-5" tabindex="-1"></a>d2 <span>=</span> np.mean(np.<span>abs</span>(np.diff(np.random.normal(<span>0</span>,<span>1</span>,<span>10000</span>))))</span>
<span id="cb863-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-6" tabindex="-1"></a>sigma_s <span>=</span> mrbar <span>/</span> d2</span>
<span id="cb863-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-7" tabindex="-1"></a>se <span>=</span> sigma_s <span>/</span> (<span>1</span><span>**</span><span>0.5</span>)</span>
<span id="cb863-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-8" tabindex="-1"></a>upper <span>=</span> mrbar <span>+</span> <span>3</span><span>*</span>se</span>
<span id="cb863-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb863-9" tabindex="-1"></a>lower <span>=</span> <span>0</span></span></code></pre></div>
<div id="cb864"><pre><code><span id="cb864-1"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-1" tabindex="-1"></a>istat <span>=</span> pd.DataFrame({<span>'time'</span>: indiv[<span>'time'</span>].iloc[<span>1</span>:], <span>'mr'</span>: mr, <span>'mrbar'</span>: mrbar, <span>'upper'</span>: upper, <span>'lower'</span>: lower})</span>
<span id="cb864-2"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-2" tabindex="-1"></a>mr_chart <span>=</span> (ggplot(istat, aes(x<span>=</span><span>'time'</span>, y<span>=</span><span>'mr'</span>)) <span>+</span></span>
<span id="cb864-3"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-3" tabindex="-1"></a>  geom_ribbon(aes(ymin<span>=</span><span>'lower'</span>, ymax<span>=</span><span>'upper'</span>), fill<span>=</span><span>'steelblue'</span>, alpha<span>=</span><span>0.25</span>) <span>+</span></span>
<span id="cb864-4"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-4" tabindex="-1"></a>  geom_hline(aes(yintercept<span>=</span>mr.mean()), size<span>=</span><span>3</span>, color<span>=</span><span>'darkgrey'</span>) <span>+</span></span>
<span id="cb864-5"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-5" tabindex="-1"></a>  geom_line(size<span>=</span><span>1</span>) <span>+</span> geom_point(size<span>=</span><span>5</span>) <span>+</span></span>
<span id="cb864-6"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-6" tabindex="-1"></a>  labs(x<span>=</span><span>'Time (Subgroup)'</span>, y<span>=</span><span>'Moving Range'</span>, subtitle<span>=</span><span>'Moving Range Chart'</span>))</span>
<span id="cb864-7"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-7" tabindex="-1"></a></span>
<span id="cb864-8"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-8" tabindex="-1"></a><span># Save the plot</span></span>
<span id="cb864-9"><a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#cb864-9" tabindex="-1"></a>mr_chart.save(<span>'images/05_moving_range_chart.png'</span>, width<span>=</span><span>8</span>, height<span>=</span><span>6</span>, dpi<span>=</span><span>100</span>)</span></code></pre></div>
<p><img src="https://timothyfraser.com/sigma/images/05_moving_range_chart.png" width="100%"></p>
<p>The moving range chart shows:</p>
<ul>
<li><strong>Center line</strong>: The average moving range (mrbar)</li>
<li><strong>Upper control limit</strong>: Based on the estimated process standard deviation</li>
<li><strong>Lower control limit</strong>: Set to 0 (moving ranges can‚Äôt be negative)</li>
<li><strong>Individual points</strong>: Each moving range value</li>
</ul>
<p>This chart helps us monitor process variation when we have individual measurements rather than subgroups.</p>
</div>
<div id="conclusion-12">
<h2>Conclusion<a href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html#conclusion-12" aria-label="Anchor link to header"></a></h2>
<p>You‚Äôve successfully produced SPC visuals and statistics in Python: process overviews, subgroup statistics, and moving range logic. These tools help us understand process behavior, identify when processes are in or out of control, and make data-driven decisions about process improvement.</p>

</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Space Truckin' ‚Äì The Nostromo (2012) (141 pts)]]></title>
            <link>https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/</link>
            <guid>46053566</guid>
            <pubDate>Wed, 26 Nov 2025 02:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/">https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/</a>, See on <a href="https://news.ycombinator.com/item?id=46053566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div data-shortcode="caption" id="attachment_526"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg"><img aria-describedby="caption-attachment-526" data-attachment-id="526" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/zlpr3/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg" data-orig-size="713,566" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="zlpr3" data-image-description="" data-image-caption="<p>The Nostromo towing its refinery through the inky blackness of space.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=500" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=450&amp;h=356" alt="" width="450" height="356" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=450&amp;h=357 450w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=150&amp;h=119 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg?w=300&amp;h=238 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/zlpr3.jpg 713w" sizes="(max-width: 450px) 100vw, 450px"></a></p><p id="caption-attachment-526">The Nostromo towing its refinery through the inky blackness of space.</p></div>
<p>‚ÄúI was really influenced by three films,‚Äù Ridley Scott told Fantastic Films in 1979, on the subject of the Nostromo and its&nbsp;claustrophobic&nbsp;corridors. ‚ÄúNot so much in terms of <em>Star Wars</em>, but definitely from <em>2001</em> and <em>Dark Star</em>.‚Äù The latter film, directed by a young John Carpenter and written by, and starring, <em>Alien</em> writer Dan O‚ÄôBannon, was an inverse,&nbsp;comedic&nbsp;take on <em>2001</em> ‚Äì where Kubrick‚Äôs film was cold, sterile, clinical, and philosophical in scope,&nbsp;<em>Dark Star</em> was cramped, crowded, shabby, dirty, irreverent and yet also elegiac. ‚ÄúThere was a great sense of reality, oddly enough, in <em>Dark Star</em>,‚Äù continued Scott, ‚Äúespecially of seedy living. It showed you can get grotty even in the Hilton Hotel if you don‚Äôt clean it. Everything starts to get tacky, even in the most streamlined surfaces.‚Äù</p>
<p>‚ÄúWhen we did <em>Dark Star</em>,‚Äù said O‚ÄôBannon, ‚Äúwhich was in the wake of <em>2001</em>, we thought we wanted -partly for the novelty, partly because it was realer, mostly just for laughs- we wanted to show this once-sterile spaceship in a rundown condition, like some old bachelor apartment.‚Äù For O‚ÄôBannon, <em>Dark Star</em>‚Äòs ‚Äòused universe‚Äô was not as strong a visual element as he had hoped, and <em>Star Wars‚Äô</em>&nbsp;‚Äúdidn‚Äôt come across all that clearly either.‚Äù For <em>Alien</em>, O‚ÄôBannon instructed Ridley Scott that ‚Äúif we want this spacecraft to look industrial [and] beat-up, you‚Äôre gonna have to make it about three times messier to the naked eye than you wanna to see it. And <em>Alien</em> probably was the first time where an audience clearly saw a futuristic machine in a run-down condition.‚Äù</p>
<p>The design of the Nostromo and the ‚Äòused universe‚Äô aesthetic would be drawn from&nbsp;O‚ÄôBannon‚Äôs earlier sci-fi effort, coupled with the realism of Kubrick‚Äôs Discovery One. ‚ÄúIt‚Äôs futuristic,‚Äù Scott said of Kubrick‚Äôs approach to <em>2001</em>, ‚Äúbut it‚Äôs still hung on today‚Äôs reality ‚Ä¶ In two hundred years things won‚Äôt change that much, you know. People will still be scruffy or clean. They‚Äôll still clean their teeth three times a day.‚Äù Though&nbsp;<em>Star Wars</em>&nbsp;itself utilised a used universe (or, as Akira Kurosawa called it, a ‚Äúmaculate reality‚Äù), Scott wanted to create a tangible reality opposed to&nbsp;<em>Star Wars</em>‚Äò fantasy-hinged settings and ships. ‚ÄúI wanted to do the truck driver version, the hard-nosed version,‚Äù said Scott. ‚ÄúIt was supposed to be the anti-thesis of&nbsp;<i>Star Wars</i>. The reality, the beauty of something absolutely about function.‚Äù</p>
<p>Before Scott came onto the project as director, writer Dan O‚ÄôBannon&nbsp;commissioned&nbsp;his friend and <em>Dark Star</em> spaceship designer Ron Cobb to draw what his script was then calling the ‚Äòdeep space commercial vessel Snark‚Äô ‚Äì a nod to Lewis Carroll‚Äôs <em>The Hunting of the Snark</em>. O‚ÄôBannon had promised Cobb a job on Alejandro Jodorowsky‚Äôs <em>Dune</em>, but when that film dissolved Cobb, who had terminated the lease on his home and prepared to move to Paris with his wife, was left standing empty-handed. To make up for the letdown, O‚ÄôBannon immediately hired Cobb for <em>Alien,</em> which allowed the artist to bounce back from a slump. ‚ÄúHe was paid about $400 a week,‚Äù Cobb‚Äôs wife, Robin Love, told the LA Times in 1988. ‚ÄúWe thought it was wonderful!‚Äù</p>
<blockquote><p><strong>When Dan met Ron</strong>: ‚ÄúI&nbsp;was working on my first sci-fi film, John Carpenter‚Äôs&nbsp;<em>Electric Dutchman</em>, which would ultimately metastastize into the feature-length&nbsp;<em>Dark Star</em>. I tried to reach Cobb to get him to design the whole film, but he was unreachable. For weeks his phone rang without an answer, and then it was disconnected, and then I got his new unlisted number but it was invariably answered by one of the girls who were living with him, who always told me he was out. It was impossible. It took another year and a half to track him down and get him to agree to design us a nice, simple little spaceship for our simple little movie.&nbsp;Finally, one night about ten pm, Carpenter and I drove over to Westwood and rousted him out of a sound sleep. He was hung over from an LSD trip and I felt kind of guilty, but I had to have those designs. We took him over to an all-night coffee shop and fed him and got him half-way awake, and then he brought out this pad of yellow graph paper on which he had sketched a 3-view plan of our spaceship. It was wonderful! A little surfboard-shaped starcruiser with a flat bottom for atmospheric landings. Very technological looking. Very high class stuff.‚Äù</p></blockquote>
<p>‚ÄúThe first person I hired on&nbsp;<em>Alien</em>, the first person to draw money, was Cobb,‚Äù O‚ÄôBannon said. ‚ÄúHe started turning out renderings, large full-colour paintings, while Shusett and I were still struggling with the script ‚Äì the corrosive blood of the Alien was Cobb‚Äôs idea. It was an intensely creative period ‚Äì the economic desperation, the all-night sessions, the rushing over to Cobb‚Äôs apartment to see the latest painting-in-progress and give him the latest pages.‚Äù</p>
<blockquote><p>‚ÄúI just sat down and started blocking out a ship ‚Äì which I love to do. Anyway, Dan‚Äôs original script called for a small, modest little ship with a small crew. They land on a small planet. They go down a small pyramid and shake up a medium-sized creature. That‚Äôs about it. He meant it to be a low budget film, like&nbsp;<em>Dark Star</em>, and I loved the idea. So I did a few paintings and Dan scurried off with them and a script.‚Äù<br>
~ Ron Cobb</p></blockquote>
<p>‚ÄúAnd he was doing some incredible stuff,‚Äù continued O‚ÄôBannon. ‚ÄúWow! I was really happy during this period, seeing the movie appear under Cobb‚Äôs fingers. Of course, we usually had to go over and sit on his back to get him to do any work -otherwise he would just party on with his friends- but how beautiful were the results.‚Äù</p>
<div data-shortcode="caption" id="attachment_541"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif"><img aria-describedby="caption-attachment-541" data-attachment-id="541" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/cobbpic58/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif" data-orig-size="429,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cobbpic58" data-image-description="" data-image-caption="<p>One of Cobb&amp;#8217;s early Snark designs.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=429" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=386&amp;h=324" alt="" width="386" height="324" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=386&amp;h=324 386w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=150&amp;h=126 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif?w=300&amp;h=252 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic58.gif 429w" sizes="(max-width: 386px) 100vw, 386px"></a></p><p id="caption-attachment-541">One of Cobb‚Äôs early Snark designs.</p></div>
<p>Coupled with Cobb was English artist, Chris Foss, who O‚ÄôBannon had come to know during their tenure together on Alejandro Jodorowsky‚Äôs <em>Dune</em>. ‚ÄúAlejandro wanted Doug Trumble to do the special effects [for <em>Dune</em>],‚Äù Foss told MTV in 2011, ‚Äúand of course, Trumble was a big important American, and certainly wouldn‚Äôt succumb to Alejandro‚Äôs manipulation. So he picked up this gauche American film student, Dan O‚ÄôBannon. He was quite hilarious, he said to me once, ‚ÄòHey, these streets are so goddamn small.‚Äô This is Paris, which had some of the widest streets in Europe. Of course, it was only when I got to Los Angeles that I saw what he meant.‚Äù</p>
<p>Though <em>Dune</em> would never come to fruition under Jodorowsky, the experience in France influenced O‚ÄôBannon‚Äôs&nbsp;approach&nbsp;to designing <em>Alien</em>. Jodorowsky had gathered together Chris Foss, Jean ‚ÄòMoebius‚Äô Giraud, and HR Giger to design his film, and the eclectic team would be later reunited by O‚ÄôBannon to design his grungy sci-fi horror movie. ‚ÄúDan said [to Twentieth Century Fox], ‚ÄòHey, we‚Äôve got to get this guy Chris Foss over here.‚Äô So off I went to Los Angeles ‚Ä¶</p>
<div data-shortcode="caption" id="attachment_2272"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg"><img aria-describedby="caption-attachment-2272" data-attachment-id="2272" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/foss13/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg" data-orig-size="479,373" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="foss13" data-image-description="" data-image-caption="<p>A sketch of the temporarily named Leviathan, by Chris Foss.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=479" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=383&amp;h=298" alt="A sketch of the temporarily named Leviathan, by Chris Foss." width="383" height="298" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=383&amp;h=298 383w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=150&amp;h=117 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg?w=300&amp;h=234 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss13.jpg 479w" sizes="(max-width: 383px) 100vw, 383px"></a></p><p id="caption-attachment-2272">A sketch of the temporarily named Leviathan, by Chris Foss.</p></div>
<div data-shortcode="caption" id="attachment_2273"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg"><img aria-describedby="caption-attachment-2273" data-attachment-id="2273" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/foss-fountain-line/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg" data-orig-size="555,445" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Foss Fountain Line" data-image-description="" data-image-caption="<p>Another Foss sketch. The nose and wings of the ship resemble those of the final design.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=400&amp;h=320" alt="Another Foss sketch. The nose and wings of the ship resemble those of the final design." width="400" height="320" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=400&amp;h=321 400w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=150&amp;h=120 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg?w=300&amp;h=241 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/foss-fountain-line.jpg 555w" sizes="(max-width: 400px) 100vw, 400px"></a></p><p id="caption-attachment-2273">Another Foss sketch. The nose and wings of the ship resemble those of the final design.</p></div>
<p>The early stages of designing <em>Alien</em> were done in an almost ramshackle, low-fi manner. ‚ÄúWe were put through shed after shed after shed,‚Äù said Foss of the times, ‚Äúand they were going through director after director after director.‚Äù Ron Cobb told Den of Geek: ‚ÄúI soon found myself hidden away at Fox Studios in an old rehearsal hall above an even older sound stage with Chris Foss and O‚ÄôBannon, trying to visualize <em>Alien</em>. For up to five months Chris and I (with Dan supervising) turned out a large amount of artwork, while the producers, Gordon Carroll, Walter Hill and David Giler, looked for a director.‚Äù</p>
<p>Foss was largely critical of Brandywine‚Äôs apparently disinterested approach to setting up the embryonic film. ‚ÄúWalter Hill was very busy smashing cars up for one of his ‚Äòstreets‚Äô films,‚Äù he told Den of Geek. ‚ÄúHe couldn‚Äôt be arsed ‚Äì much too busy! He walked in after months of work and just said, ‚ÄòYep, roomful of spaceships‚Äô and just walked out again.‚Äù</p>
<blockquote><p><strong>Ron Cobb, Steven Speilberg, and aliens:</strong>&nbsp;Cobb told bttf.com: ‚ÄúI first met Speilberg when I was working on&nbsp;<em>Alien</em>, at one point Speilberg was considered as a possible director for the original&nbsp;<em>Alien</em>. It was just a brief thing, he could never work out his schedule to do it, but he was interested.‚Äù Later, one of Cobb‚Äôs early story pitches to Speilberg, an alien horror tale called&nbsp;<em>Night Skies</em>, eventually became 1982‚Äôs&nbsp;<em>E.T.&nbsp;</em>Though Cobb&nbsp;cameo‚Äôd&nbsp;as one of <em>E.T</em>.‚Äôs doctors (‚ÄúI got to carry the little critter,‚Äù) he wasn‚Äôt pleased with the family-friendly direction that the film took from his initial idea:&nbsp;‚ÄúA banal retelling of the Christ story,‚Äù he told the LA Times. ‚ÄúSentimental and self-indulgent, a pathetic lost-puppy kind of story.‚Äù Luckily for the artist, a clause in his contract for <em>E.T</em>. (he was&nbsp;originally&nbsp;to direct before the story took a turn) detailed that he was to earn 1% of the net profit. His first cheque amounted to $400,000. Cobb‚Äôs wife quipped: ‚Äúfriends from Australia always ask, ‚ÄòWhat did you do on <em>E.T</em>.?‚Äô And Ron says, ‚ÄòI didn‚Äôt direct it.'‚Äù</p></blockquote>
<p>When Ridley Scott took over the directorial duties, Cobb and Foss were shipped to England to continue their work. Around this point in time, HR Giger was drawing up the film‚Äôs alien, and Moebius was&nbsp;commissioned&nbsp;by Scott to design the film‚Äôs space suits, which would be brought into reality by John Mollo. The Snark went through a variety of designs, from a ship embedded in the rock of an asteroid, to an upended pyramidal design, to a hammerhead shape and other varieties of ship with white or yellow or more kaleidoscopic paint-jobs.</p>
<div data-shortcode="caption" id="attachment_556"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif"><img aria-describedby="caption-attachment-556" data-attachment-id="556" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/cobbpic55/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif" data-orig-size="479,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cobbpic55" data-image-description="" data-image-caption="<p>One of the more unusual designs. &amp;#8220;Fanciful Nasa.&amp;#8221; By Ron Cobb.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif?w=479" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif?w=500" alt="" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif 479w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif?w=150&amp;h=113 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbpic55.gif?w=300&amp;h=225 300w" sizes="(max-width: 479px) 100vw, 479px"></a></p><p id="caption-attachment-556">One of the more unusual designs. ‚ÄúFanciful Nasa.‚Äù By Ron Cobb.</p></div>
<p>After many months of scribbling and painting spaceships, the production was no closer to settling what the vessel would actually look like. Due to script rewrites, it also changed names, from Snark to&nbsp;Leviathan before the name Nostromo was settled on. ‚ÄúI called the ship Nostromo from [Joseph] Conrad,‚Äù Walter Hill told Film International in 2004, ‚Äú[For] no particular metaphoric idea, I just thought it sounded good.‚Äù</p>
<p>However, indecision was still rife on the actual look of the thing.</p>
<blockquote><p><strong>Scott on O‚ÄôBannon</strong>: ‚ÄúHe‚Äôs great. A really sweet guy. And, I was soon to realise, a real science-fiction freak ‚Ä¶ &nbsp;He brought in a book by the Swiss artist HR Giger. It‚Äôs called Necronomicon ‚Ä¶ I thought, ‚ÄòIf we can build that [<em>Necronom IV</em>], that‚Äôs it.‚Äô I was stunned, really. I flipped. Literally flipped. And O‚ÄôBannon lit up like a lightbulb, shining like a quartz iodine. I realised I was dealing with a real SF freak, which I‚Äôd never come across before. I thought, ‚ÄòMy god, I have an egg-head here for this field.'‚Äù</p></blockquote>
<blockquote><p><strong>Scott on Cobb:</strong> ‚ÄúO‚ÄôBannon introduced me to Ron Cobb, a brilliant visualiser of the genre, with whom he‚Äôd worked on <em>Dark Star</em>. Cobb seemed to have very realistic visions of both the far and near future, so I quickly decided that he would take a very important part in the making of the film.‚Äù</p></blockquote>
<blockquote><p><strong>Cobb on Foss</strong>: ‚ÄúCreating spacecraft exteriors came easily to Foss. His mind and imagination seemed to embody the entire history of the industrial revolution. He could conjure up endless spacecraft designs suggesting submarines, diesel locomotives, Mayan interceptors, Mississippi river boats, jumbo space arks, but best of all (ask Dan) were his trademark aero-spacecraft-textures like panels, cowlings, antennae, bulging fuel tanks, vents, graphics etc. As the months passed, along with two or three temporary directors, Chris began to have problems caused by his spectacular creativity. No one in a position to make a decision seemed to be able to make up their mind and/or choose one of his designs. I think Chris was turning out spacecraft designs the decision makers found too original.‚Äù</p></blockquote>
<p>Ridley himself had input on the design: ‚ÄúI was looking for something like <em>2001</em>, not the fantasy of <em>Star Wars</em>. I wanted a slow moving, massive piece of steel which was moving along in dead, deep silence ‚Ä¶ The concept was to have the hull covered with space barnacles or something. I was unable to communicate that idea, and I finally had to go down there and fiddle with the experts. We gradually arrived at a solution.‚Äù</p>
<p>Foss paints a more hectic process. ‚ÄúFinally what happened was that the bloke who had to make the [Nostromo] model completely lost his rag, scooped up a load of paper -they had a room full of smashed-up bits of helicopter and all-sorts- and he just bodged something together. So the actual spaceship in the film hadn‚Äôt anything to do with all the days, weeks, <em>months </em>of work that we‚Äôd all done. It‚Äôs as simple as that.‚Äù</p>
<p>Cobb explained:&nbsp;‚ÄúBrian Johnson, the special effects supervisor under pressure to build the large Nostromo model, went into the deserted art department and, out of frustration, grabbed all the Chris Foss designs off the wall and took them to Bray studios. There he would choose the design himself in order to have enough time to build the damn thing.‚Äù</p>
<p>However, Johnson had also scooped up Cobb‚Äôs art, and though Cobb was concentrating on the designs of the ship‚Äôs interior, one of his exterior pieces met with approval over Foss‚Äô designs. ‚ÄúWell I soon found out that Brian found and took all of my exterior design sketches as well,‚Äù said Cobb. ‚ÄúAbout a month later I was told that Brian had used my sketch, ‚ÄòNostromo A‚Äô, as the basis for the model, even to the extent that it was painted yellow. Ridley found the colour a bit garish and had it repainted grey.‚Äù</p>
<div data-shortcode="caption" id="attachment_561"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg"><img aria-describedby="caption-attachment-561" data-attachment-id="561" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/cobbnosenh/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg" data-orig-size="800,374" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cobbnosenh" data-image-description="" data-image-caption="<p>Cobb&amp;#8217;s grey Nostromo.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=500" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=500&amp;h=233" alt="" width="500" height="233" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=500&amp;h=234 500w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=150&amp;h=70 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=300&amp;h=140 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg?w=768&amp;h=359 768w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbnosenh.jpg 800w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-561">Cobb‚Äôs grey Nostromo.</p></div>
<p>‚ÄúRidley had his own very firm ideas about what he physically wanted to do,‚Äù Foss said of the process, ‚Äúand he almost studiously ignored everything that had gone before ‚Ä¶ I kind of got the impression that Ridley was quietly going his own way, trying to get on with it and get it done, a bit like just another job. I‚Äôve just got dim memories of Ridley being like that and really just ignoring months of input ‚Ä¶&nbsp;I just have these memories of feeling a bit miffed that things weren‚Äôt put together so much better. And poor old Dan O‚ÄôBannon, the bloke whose <em>concept </em>it was, just got absolutely shafted. He was almost like patted on the head: ‚ÄòYeah Dan, yeah Dan, that‚Äôs cool.'‚Äù</p>
<p>Cobb‚Äôs&nbsp;sketches, drawings and paintings for the interiors were also okay‚Äôed by Scott and the production. At first Cobb‚Äôs designs were slightly more fantastical, with giant screens and computer readouts and windows covered by protective shells that would open up to reveal alien planets ahead of the ship. Though these ideas were scuppered due to time, money, and logistics, many of Cobb‚Äôs&nbsp;early&nbsp;designs and ideas were revisited in <em>Prometheus</em>.</p>
<div data-shortcode="caption" id="attachment_565"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg"><img aria-describedby="caption-attachment-565" data-attachment-id="565" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/cobb2/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg" data-orig-size="655,334" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cobb2" data-image-description="" data-image-caption="<p>&amp;#8220;My first version of the bridge was very spacious indeed; sort of split-level, California style with these huge windows. I had this idea for a spectacular shot where you&amp;#8217;d see the approaching planet rolling by on console screens, and then suddenly the windows would open and light would flood in and there would be the actual planet outside doing the same roll as the one on the screen. But it was decided that we couldn‚Äôt afford it, and we&amp;#8217;d have to go to a Star Trek bridge with no windows and a viewing screen.&amp;#8221;<br />
~ Ron Cobb.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=500" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=500&amp;h=254" alt="" width="500" height="254" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=500&amp;h=255 500w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=150&amp;h=76 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg?w=300&amp;h=153 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobb2.jpg 655w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-565">‚ÄúMy first version of the bridge was very spacious indeed; sort of split-level, California style with these huge windows. I had this idea for a spectacular shot where you‚Äôd see the approaching planet rolling by on console screens, and then suddenly the windows would open and light would flood in and there would be the actual planet outside doing the same roll as the one on the screen. But it was decided that we&nbsp;couldn‚Äôt&nbsp;afford it, and we‚Äôd have to go to a <em>Star Trek</em> bridge with no windows and a viewing screen.‚Äù<br>~ Ron Cobb.</p></div>
<div data-shortcode="caption" id="attachment_566"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg"><img aria-describedby="caption-attachment-566" data-attachment-id="566" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/cobbb2/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg" data-orig-size="655,277" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cobbb2" data-image-description="" data-image-caption="<p>&amp;#8220;By the time I got to London, Michael Seymour decided he liked the window idea and came up with this hexagon-shaped bridge that was radially symmetrical. Then Ridley wanted overhead consoles, and wanted to make the set tighter, more claustrophobic, like a fighter bomber, and I just started suggesting shapes and forms that would conform to that. The windows eventually became bubbles you could sort of get to in outrigger seats that would overhang the windows.&amp;#8221;<br />
~ Ron Cobb.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=500" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=500&amp;h=211" alt="" width="500" height="211" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=500&amp;h=211 500w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=150&amp;h=63 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg?w=300&amp;h=127 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/cobbb2.jpg 655w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-566">‚ÄúBy the time I got to London, Michael Seymour decided he liked the window idea and came up with this hexagon-shaped bridge that was radially symmetrical. Then Ridley wanted overhead consoles, and wanted to make the set tighter, more claustrophobic, like a fighter bomber, and I just started suggesting shapes and forms that would conform to that.‚Äù<br>~ Ron Cobb.</p></div>
<div data-shortcode="caption" id="attachment_569"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg"><img aria-describedby="caption-attachment-569" data-attachment-id="569" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/autodoc-sketch-pg-53/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg" data-orig-size="2549,1179" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="autodoc-sketch-pg-53" data-image-description="" data-image-caption="<p>The ship&amp;#8217;s auto-doc, as conceptualised by Cobb.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=500" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=500&amp;h=231" alt="" width="500" height="231" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=500&amp;h=231 500w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=1000&amp;h=463 1000w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=150&amp;h=69 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=300&amp;h=139 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/autodoc-sketch-pg-53.jpg?w=768&amp;h=355 768w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-569">The ship‚Äôs auto-doc, as conceptualised by Cobb.</p></div>
<div data-shortcode="caption" id="attachment_602"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg"><img aria-describedby="caption-attachment-602" data-attachment-id="602" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/alien31/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg" data-orig-size="624,386" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="alien31" data-image-description="" data-image-caption="<p>The Nostromo&amp;#8217;s life-boat airlock, by Ron Cobb.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=500" loading="lazy" title="" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=500&amp;h=309" alt="" width="500" height="309" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=500&amp;h=309 500w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=150&amp;h=93 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg?w=300&amp;h=186 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/alien31.jpg 624w" sizes="(max-width: 500px) 100vw, 500px"></a></p><p id="caption-attachment-602">The Nostromo‚Äôs life-boat airlock, by Ron Cobb.</p></div>
<p>In addition to designing the Nostromo‚Äôs exterior, its bridge and auto-doc, Cobb also designed the ship‚Äôs airlocks, cyro-tubes, corridors, bulkheads, an observation dome (not built), Ash‚Äôs ‚Äòblister‚Äô observation unit, some of the film‚Äôs uniform patches and ship signage, the ‚Äòflying bedstead‚Äô&nbsp;maintenance&nbsp;vehicle (not built), and even Jones‚Äô cat-box. Cobb told Den of Geek that, ‚ÄúMy problem with designing Nostromo‚Äôs interiors, the control bridge, corridors, auto doc (or med lab), bulkhead doors, the food deck, etc., was that I grew up with a deep fascination for astronomy, astrophysics, and most of all, aerospace flight. My design approach has always been that of a frustrated engineer (as well as a frustrated writer when it came to cinema design). I tend to subscribe to the idea that form follows function. If I‚Äôm to arrive at a cinematic spacecraft design that seamlessly preserves, as in this case, the drama of the script, the audience has to experience it as something impressive and believable.‚Äù</p>
<p>‚ÄúWe‚Äôre beyond <em>2001</em> in terms of scientific advances,‚Äù said Scott of <em>Alien</em>‚Äòs futurism, ‚Äúour capabilities are more&nbsp;sophisticated&nbsp; but our ship‚Äôs still NASA-orientated, still Earth-manufactured ‚Ä¶ in our tongue-in-cheek fantasy we project a not-too-distant future in which there are many vehicles tramping around the universe on mining expeditions, erecting military installations, or whatever. At the culmination of many long voyages, each covering many years, these ships -no doubt part of armadas owned by private corporations- look used, beat-up, covered with graffiti, and uncomfortable. We certainly didn‚Äôt design the Nostromo to look like a hotel.‚Äù</p>
<blockquote><p>‚ÄúI didn‚Äôt want a conventional shape [for the refinery,] so I drew up a sketch and handed it to the model makers. They refined it, as it were, and built the model. I originally drew it upside-down, with the vague idea that it would resemble a floating inverted cathedral ‚Ä¶ I think that the machine that they‚Äôre on could in fact be 60 years old and just added to over the decades. The metal-work on it could be 50 years old ‚Ä¶ I would have liked to see it covered with space barnacles or space seaweed, all clogged and choked up, but that was illogical as well.‚Äù<br>
~ Ridley Scott, Fantastic Films, 1979.</p></blockquote>
<p>The Nostromo model was built under the supervision of Nick Allder and Brian Johnson at Bray Studios, not far from Pinewood, where the live-action scenes were being filmed in parallel with the model shots at Bray. For the refinery, Scott instructed the teams at Bray to make it appear ‚ÄúVictorian Gothic,‚Äù with towers and spires and&nbsp;antennae. Bray shop worker Dennis Lowe explained: ‚ÄúAt that same time in the workshop Ridley was talking about his first concept of the refinery and he was describing an actual oil refinery with pipes and spires, eventually the term ‚ÄòBattleship Bismarck in space‚Äô came up to describe the detailing of the model.‚Äù</p>
<div data-shortcode="caption" id="attachment_596"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg"><img aria-describedby="caption-attachment-596" data-attachment-id="596" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/blackpool2/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg" data-orig-size="548,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="blackpool2" data-image-description="" data-image-caption="<p>&amp;#8220;I spent a couple of months rigging the Nostromo with neon strips and spotlights that would mimic the Mothership from Close Encounter. These were sequenced using motorised rotary switches, Ridley came over from Shepperton after shooting and took a look at my work then made the decision to scrap the idea &amp;#8211; such is life!&amp;#8221;<br />
~ Dennis Lowe.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=206" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=315&amp;h=459" alt="" width="315" height="459" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=315&amp;h=460 315w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=103&amp;h=150 103w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg?w=206&amp;h=300 206w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/blackpool2.jpg 548w" sizes="(max-width: 315px) 100vw, 315px"></a></p><p id="caption-attachment-596">‚ÄúI spent a couple of months rigging the Nostromo with neon strips and spotlights that would mimic the Mothership from <em>Close Encounters</em>. These were sequenced using motorised rotary switches, Ridley came over from Shepperton after shooting and took a look at my work then made the decision to scrap the idea ‚Äì such is life!‚Äù<br>~ Dennis Lowe.</p></div>
<p>When Ridley arrived after concluding filming at Pinewood, he further revised the ship‚Äôs look, removing many of the spires from the refinery, repainting the Nostromo from yellow to grey, and scrapping every piece of footage shot to date, taking it upon himself to re-direct the scenes. ‚ÄúIt was a difficult situation,‚Äù said Scott, ‚ÄúBrian Johnson was over there [at Bray], working out of context away from the main unit. I could only look at the rushes while I was working with the actors, and that‚Äôs not a very satisfactory way of working. In the end, I think a director must be heavily involved with the miniatures, and that‚Äôs why I shot them myself.‚Äù</p>
<p>According to model builder Jon Sorensen, there were no real hard feelings over the redesigns and reshoots. ‚ÄúRidley Scott then arrived from Shepperton to take an interest in the models and everything changed radically in terms of tone, colour and look. The yellow was sprayed over a uniform grey. Sections were rebuilt. We started over, discarding all previous footage. There was no anger at this. Surprise maybe. But it was Ridley Scott‚Äôs film. We liked him. So we entered the <em>Alien</em> model shoot Part Deux. I recall Bill Pearson and I talking once on what we thought was an empty, lunch-time model stage when a voice spoke from the shadows. Ridley, asking what we were discussing. We answered that maybe that part might look better moved over to there, (we were discussing the refinery). He smiled back and I guess that signalled what was true; we‚Äôd go all the way to help him. That night he bought both Bill and I a beer, a move which astonished the Assistant Director, Ray Beckett who complained that in 10 years of working with Ridley, he‚Äôd never been bought a beer. So we bought Ray one instead.‚Äù</p>
<div data-shortcode="caption" id="attachment_584"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg"><img aria-describedby="caption-attachment-584" data-attachment-id="584" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/attachment/014/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg" data-orig-size="650,433" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Chiltern Image Service&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;Chiltern Image Service&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="014" data-image-description="" data-image-caption="<p>Early shot of the yellow Nostromo approaching the alien planet.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=450&amp;h=300" alt="" width="450" height="300" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=450&amp;h=300 450w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=150&amp;h=100 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg?w=300&amp;h=200 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/014.jpg 650w" sizes="(max-width: 450px) 100vw, 450px"></a></p><p id="caption-attachment-584">Early shot of the yellow Nostromo approaching the alien planet.</p></div>
<div data-shortcode="caption" id="attachment_2278"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg"><img aria-describedby="caption-attachment-2278" data-attachment-id="2278" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/normal_productionstill69/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg" data-orig-size="770,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="normal_productionstill69" data-image-description="" data-image-caption="<p>The revised Nostromo hanging in orbit.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=450&amp;h=296" alt="The revised Nostromo hanging in orbit." width="450" height="296" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=450&amp;h=297 450w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=150&amp;h=99 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=300&amp;h=198 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg?w=768&amp;h=507 768w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill69.jpg 770w" sizes="(max-width: 450px) 100vw, 450px"></a></p><p id="caption-attachment-2278">The revised Nostromo hanging in orbit.</p></div>
<p>The Nostromo interiors were overseen by art director Roger Christian, who had helped craft the sets for <em>Star Wars</em>. Christian told Shadowlocked.com: ‚ÄúI art-directed&nbsp;<i>Alien</i>&nbsp;for Ridley Scott with my team because he was struggling to get the designer and the art department to understand ‚Äòthat look‚Äô I created with the dressing on&nbsp;<i>Star Wars ‚Ä¶</i>&nbsp;I went into Shepperton, and we built and dressed the first corridor section ‚Äì actually for a test screen for Sigourney Weaver, who the studios were not sure about. I brought my little team of prop guys who‚Äôd understood then the process of what to strip down and how to place it. Because it was not something you just do randomly. It had to be done based on a kind of knowledge.‚Äù</p>
<p>‚ÄúRoger is a brilliant set dresser,‚Äù Scott told Fantastic Films. ‚ÄúThough his department was not designing the corridors and sets, their ‚Äòcladding‚Äô of the walls made everything look absolutely real. He would go out with his buyers and prop men and visit aircraft dumps or army surplus stores and drag masses of things in for me to see.‚Äù</p>
<p>‚ÄúWith&nbsp;<i>Alien</i>&nbsp;I was able to go much further with the oily and gritty look than in&nbsp;<i>Star Wars</i>,‚Äù said Roger Christian, ‚Äúand for the first time create a totally believable ‚Äòspace truck‚Äô, as Ridley described it. The set ended up looking as if we had rented a well-travelled, well-used, oily, dirty, mineral carrier ‚Äì an unmistakably real and claustrophobic space vessel. I think this really helped audiences to identify with the movie, as the characters were so like space truckers, trapped in a claustrophobic nightmare.‚Äù</p>
<blockquote><p>‚Äú[The Nostromo‚Äôs] like the bloody Queen Mary. Do you get a sense of scale in the interior? That it‚Äôs big? We couldn‚Äôt build the two to three-hundred foot-long corridors which it would have but it‚Äôs supposed to be like one of these huge Japanese super-tankers. Three quarters of a mile long. The refinery behind it god-knows how big. I mean‚Ä¶ I dunno. A mile square?‚Äù<br>
~ Ridley Scott, Fantastic Films, 1979.</p></blockquote>
<p>‚ÄúRidley saw the ship very much as a metaphor for a Gothic castle,‚Äù said Ron Cobb on the subject of the ship‚Äôs interiors, ‚Äúor a WWII submarine ‚Ä¶ a kind of retro, accessible technology with great big transistors and very low-res video screens.‚Äù However, at one point, Scott had other ideas for the Nostromo‚Äôs technology:&nbsp;‚ÄúI wanted to have wafer-thin screens that are plexiglas, that just float on clips -and of course today you‚Äôve got computer screens exactly like that- because I figured that‚Äôs where it [technology] would go. I really got those things off Jean Giraud, Moebius, when he‚Äôd been drawing and speculating. A lot of his stuff you see thirty years ago is now.‚Äù</p>
<p>Cobb acknowledged the&nbsp;Moebius&nbsp;influence, as well as the ship‚Äôs other, perhaps subtler, inspirations: ‚ÄúThe ship is a strange mixture of retrofitted old technology, a kind of industrial nightmare, like being trapped in a factory ‚Ä¶ Ridley‚Äôs a wonderful artist and he wanted it to look a lot like a Moebius-designed ship, with all kinds of rounds surfaces and with an Egyptian motif.‚Äù This Egyptian motif is prevalent in the Weylan-Yutani logo, a wings of Horus design which adorns the uniforms of the crew in addition to their coffee cups, beer cans, etc. The hypersleep chamber also evokes a burial chamber, with the cryo-chambers arranged in a lotus shape.&nbsp;In addition to the Egyptian motif, another influence was Japan. ‚ÄúThe owners of the Nostromo are Japanese,‚Äù Scott told Fantastic Films.</p>
<div data-shortcode="caption" id="attachment_2276"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg"><img aria-describedby="caption-attachment-2276" data-attachment-id="2276" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/normal_productionstill99_005/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg" data-orig-size="518,770" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="normal_productionstill99_005" data-image-description="" data-image-caption="<p>&amp;#8220;The interior of the Nostromo was so believable,&amp;#8221; HR Giger told Famous Monsters, &amp;#8220;I hate these new-looking spacecraft. You feel like they&amp;#8217;re just built for the movie you&amp;#8217;re seeing. They don&amp;#8217;t look real.&amp;#8221;</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=202" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=400&amp;h=594" alt="&quot;The interior of the Nostromo was so believable,&quot; HR Giger told Famous Monsters, &quot;I hate these new-looking spacecraft. You feel like they're just built for the movie you're seeing. They don't look real.&quot;" width="400" height="594" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=400&amp;h=595 400w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=101&amp;h=150 101w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg?w=202&amp;h=300 202w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/normal_productionstill99_005.jpg 518w" sizes="(max-width: 400px) 100vw, 400px"></a></p><p id="caption-attachment-2276">‚ÄúThe interior of the Nostromo was so believable,‚Äù HR Giger told Famous Monsters, ‚ÄúI hate these new-looking spacecraft. You feel like they‚Äôre just built for the movie you‚Äôre seeing. They don‚Äôt look real.‚Äù</p></div>
<p>‚ÄúAs I was working with the art director,‚Äù said Ridley, ‚ÄúI decided to make it faintly glittery. I wanted to have sort of anodized gold everywhere. Not steel, gold. Did you know that space landing craft are covered with gold foil? Amazing! So I thought, Why make this out of steel? Let‚Äôs make it all warm and oppressive, massive, and gold.'‚Äù</p>
<p>The glittery look can be seen in the opening shots of the ship‚Äôs computers bleeping into life, and the gold sheen is most prevalent in the ship‚Äôs&nbsp;maintenance&nbsp;area, where Brett finds the Alien‚Äôs&nbsp;discarded&nbsp;skin moments before his death. Scott explained the design process for the ship‚Äôs golden-hued&nbsp;maintenance&nbsp;garage: ‚ÄúWe got hold of marvelous, actual parts of actual huge jet engines and installed them, and they‚Äôre like a coppery metal with some steel. We used them as four main supports, like columns, and they give a lot of the feeling of a temple. We played the same music we used in the derelict alien craft and we had <em>two</em> temples. The idol I wanted was through these massive gold doors which were as big as a wall, with a gap in them through which the claw [landing leg] can be seen. When that set was dressed, it looked like Aladdin‚Äôs Cave ‚Ä¶ [the garage is] filled with the equipment that the crew would use in their work on and around the refinery, and when they land on various planets ‚Äì land crawlers, helicopters, other flying machines.‚Äù</p>
<p>‚ÄúRidley has this lavish, sensual visual style,‚Äù summarised Dan O‚ÄôBannon to Fantastic Films in 1979, ‚Äúand I think that Ridley is one of the ‚Äògood guys.‚Äô I really think that he was the final pivot point responsible for the picture coming out good.&nbsp; And so a lot of the visual design and a lot of the mood elements inherent in the camerawork, while they‚Äôre not what I planned, are great.&nbsp; They‚Äôre just different.‚Äù</p>
<p>O‚ÄôBannon also nodded to the contributions of Cobb, Foss, Shusett etc., to the picture: ‚ÄúAlso, it‚Äôs not 100% Ridley either. It‚Äôs Ridley superimposing his vision over the cumulative vision of others, you see.&nbsp; Now this could be such a strong director‚Äôs picture because Ridley‚Äôs directorial and visual hand is so strong.&nbsp; There will probably be tendency among critics to refer to it as Ridley Scott‚Äôs vision of the future.&nbsp; And he did have a vision of the future.&nbsp; But it was everybody else that came before, that‚Äôs what his vision is ‚Ä¶&nbsp;if it sounds like I‚Äôm knocking Ridley, I‚Äôm not.‚Äù</p>
<div data-shortcode="caption" id="attachment_601"><p><a href="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg"><img aria-describedby="caption-attachment-601" data-attachment-id="601" data-permalink="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/ridley-signed-still/" data-orig-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg" data-orig-size="720,428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="ridley-signed-still" data-image-description="" data-image-caption="<p>The Nostromo at rest on the alien planetoid.</p>
" data-medium-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=300" data-large-file="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=500" loading="lazy" src="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=450&amp;h=267" alt="" width="450" height="267" srcset="https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=450&amp;h=268 450w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=150&amp;h=89 150w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg?w=300&amp;h=178 300w, https://alienseries.wordpress.com/wp-content/uploads/2012/10/ridley-signed-still.jpg 720w" sizes="(max-width: 450px) 100vw, 450px"></a></p><p id="caption-attachment-601">The Nostromo at rest on the alien planetoid.</p></div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CS234: Reinforcement Learning Winter 2025 (183 pts)]]></title>
            <link>https://web.stanford.edu/class/cs234/</link>
            <guid>46052685</guid>
            <pubDate>Wed, 26 Nov 2025 00:33:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.stanford.edu/class/cs234/">https://web.stanford.edu/class/cs234/</a>, See on <a href="https://news.ycombinator.com/item?id=46052685">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
					I care about academic collaboration and misconduct because it is important both that we are able to evaluate
					your own work (independent of your peer‚Äôs)
					and because not claiming others‚Äô work as your own is an important part of integrity in your future career. I
					understand that different
					institutions and locations can have different definitions of what forms of collaborative behavior is
					considered
					acceptable. In this class,
					for written homework problems, you are welcome to discuss ideas with others, but you are expected to write up
					your own solutions
					independently (without referring to another‚Äôs solutions). For coding, you may only share the input-output behavior
					of your programs. This encourages you to work separately but share ideas
					on how to test your implementation. 
				

Please remember that if you share your solution with another student, even
					if you did not copy from
					another, you are still violating the honor code.

Consistent with this, it is also considered an honor code violation if you make your assignment solutions publicly available, such as posting them online or in a 
public git repo.


					</p><!-- In terms of the final project, you are welcome to combine this project with another class
				assuming that the project is relevant to both classes, given that you take prior permission of the class
				instructors. If your project is an extension of a previous class project, you are expected to make significant additional contributions to the
				project. -->
					<p>
					We may run similarity-detection software over all submitted student programs, including programs from
					past quarters and any
					solutions found online on public websites. Anyone violating the Stanford University
					<a href="https://ed.stanford.edu/academics/masters-handbook/honor-code">Honor Code</a> will be referred to the
					Office of Judicial Affairs.
					If you think you made a mistake (it can happen, especially under stress or when time is short!), please reach
					out to Emma or the head CA;
					the consequences will be much less severe than if we approach you.

					We expect all students to submit their own solutions to CS234 homeworks, exams and quizzes, and 
					for projects. You are permitted to use generative AI tools such as Gemini, GPT-4 and Co-Pilot 
					in the same way that human collaboration is considered acceptable: you are not allowed to directly 
					ask for solutions or copy code, and you should indicate if you have used generative AI tools. 
					Similar to human collaboration help, you are ultimately responsible and accountable for your own work.
					We may check students' homework, exams and projects to 
				enforce this policy. 
				</p><p>Note that it is not acceptable to list a LLM as a collaborator on the project 
					milestone or final report: as things stand, generative AI cannot accept 
					fault or responsibility, and thus cannot be a collaborator in a final project. 


				</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Generative Burrito Test (112 pts)]]></title>
            <link>https://www.generativist.com/notes/2025/Nov/25/generative-burrito-test.html</link>
            <guid>46052102</guid>
            <pubDate>Tue, 25 Nov 2025 23:28:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.generativist.com/notes/2025/Nov/25/generative-burrito-test.html">https://www.generativist.com/notes/2025/Nov/25/generative-burrito-test.html</a>, See on <a href="https://news.ycombinator.com/item?id=46052102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            
            <p>A <em>CRITICAL</em> benchmark for image generation models</p>
        </header>

        <section>
            <p>This was <a href="https://x.com/generativist/status/1713011492310950273" target="_blank" rel="noopener">originally inspired by the horse riding astronaut meme</a> way back in 2023. But I think Simon's <a href="https://simonwillison.net/2024/Oct/25/pelicans-on-a-bicycle/" target="_blank" rel="noopener">Pelican benchmark</a> is what keeps the idea alive for me, even though they are testing different modalities. Burritos are obviously more important than both pelicans and equestrian absurdism.</p>
            <p>Also, I was initially surprised that it couldn't replicate the image well because I assumed there would be plenty of similar examples in the training data (unlike said equestrian absurdity). But I think it's a bit of a weird concept because all the ingredients get smushed and smashed and congealed.</p>
            <p>All images generated using fal defaults. Obviously you can probably prompt it better, but that's HIL effort, and feels like cheating.</p>
        </section>

        <section>
            <p>The Prompt</p>
            <blockquote>
                A partially eaten burrito with cheese, sour cream, guacamole, lettuce, salsa, pinto beans, and chicken.
            </blockquote>
        </section>

        

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reinventing how .NET builds and ships (again) (205 pts)]]></title>
            <link>https://devblogs.microsoft.com/dotnet/reinventing-how-dotnet-builds-and-ships-again/</link>
            <guid>46051691</guid>
            <pubDate>Tue, 25 Nov 2025 22:37:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/dotnet/reinventing-how-dotnet-builds-and-ships-again/">https://devblogs.microsoft.com/dotnet/reinventing-how-dotnet-builds-and-ships-again/</a>, See on <a href="https://news.ycombinator.com/item?id=46051691">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-58953">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>After I wrote my <a href="https://devblogs.microsoft.com/dotnet/a-deep-dive-into-how-net-builds-and-ships/">last post</a> on how .NET builds and ships, I was cautiously optimistic that I wouldn‚Äôt be writing another one. Or at least not another one about how we build and ship. That problem was done and dusted. .NET had done it! We‚Äôd struck a balance between distributed repository development and the ability to quickly compose a product for shipping. Congratulations everyone, now the infrastructure teams could focus on other things. Security, cross-company standardization, support for building new product features. All the good stuff.</p>
<p><em>‚Ä¶A year and a half later‚Ä¶</em></p>
<p>We‚Äôre asking how much it will cost to build 3-4 major versions with a dozen .NET SDK bands between them each month. And keep their engineering systems up to date. And hey, there‚Äôs this late breaking fix we want to get into next week‚Äôs release, so can I check it in today and have the team validate tonight? It can‚Äôt be <strong>that</strong> hard, right? And I have this new cross-stack feature that I want to do some prototyping on‚Ä¶how can I build it?</p>
<p>The answers were mostly frustrating:</p>
<p><em>‚ÄúIt‚Äôll cost a lot, and get worse over time.</em>‚Äú</p>
<p>‚Äú<em>I don‚Äôt think we have enough time for that fix, I can only guess how long the build will take, but it‚Äôs at least 36 hours before we can handoff to validation. Maybe more?</em>‚Äú</p>
<p>‚Äú<em>I‚Äôm sure we can keep that much infrastructure alive, but we‚Äôll slowly drown under the cost of keeping it up to date.</em>‚Äú</p>
<p>‚Äú<em>How critical is it that you have a full stack to work with? It‚Äôll take a while to set that up.</em>‚Äú</p>
<p>These are <strong>not</strong> the answers we want to be giving. And so, we went back to the drawing board, looking for solutions.</p>
<p>This blog post is about the Unified Build project: .NET‚Äôs effort to resolve many of these issues by moving product construction into a ‚Äòvirtual monolithic‚Äô repository, consolidating the build into a series of ‚Äòvertical builds‚Äô, while still enabling contributors to work outside the monolith. I‚Äôll briefly tell the story of our product construction journey over the life of .NET. I‚Äôll draw attention to the lessons we‚Äôve learned about applying a distributed product construction model to a single product, particularly its drawbacks in overhead and complexity. Finally, I‚Äôll dig into the details of Unified Build and its foundational technology, Linux distro Source Build. We‚Äôll look at the new method of product construction and the results we‚Äôre seeing.</p>
<h2>How did we get here? This is not my beautiful build infrastructure</h2>
<p>.NET was born out of the closed source infrastructure of the .NET Framework and Silverlight in 2015-2016. It was made open source incrementally as we readied its components for external consumption, and as was the fashion at the time, we split it into multiple repositories. CoreCLR represented the base runtime, CoreFX the libraries, Core-Setup the packaging and installation. Along came ASP.NET Core and EntityFramework Core, and an SDK with a CLI. A few releases saw major revamps of the product in the form of shared frameworks, with WindowsDesktop joining the fold. More repositories and more complexity.</p>
<p>What is important to understand is that .NET is a product that is developed in separate inter-dependent repositories but needs to be composed together in a relatively short period of time to ship. On paper, the ‚Äògraph‚Äô of the product looks much like any open source ecosystem. A repository produces some software component, publishes it to public registries, and downstream consumers take a dependency on the new component, and publish their own updates. It‚Äôs a producer-consumer model where changes ripple through the ‚Äòglobal‚Äô dependency graph via a series of pull-&gt;build-&gt;publish operations. This model is highly distributed and effective, but it is not necessarily efficient in a time sense. It enables software vendors and repository owners to have significant autonomy over their process and schedules. However, attempting to apply this methodology to a product like .NET, which represents its components using separate, but inter-dependent repositories, has major drawbacks.</p>
<p>Let‚Äôs call this a ‚Äúdistributed product construction methodology‚Äù. To get a sense of why it can be a difficult methodology to use, let‚Äôs take a look at the process to produce a security release.</p>
<h3>Example: Security Servicing</h3>
<p>Consider shipping a security patch. A security vulnerability is discovered somewhere in the .NET Runtime libraries. Because .NET is descended from .NET Framework, let‚Äôs say this security vulnerability is also present in .NET Framework 4.7.2. It becomes absolutely vital that .NET‚Äôs security update goes out in tandem with the .NET Framework update, or one will zero-day the other. .NET has numerous Microsoft-managed release paths. Microsoft Update, our CDN, Linux and container package registries, nuget.org, Visual Studio, Azure Marketplace, and on and on. That puts some restrictions on timeline. We need to be able to be predictable.</p>
<p>.NET‚Äôs development structure looks a lot like a typical open source ecosystem. The .NET Runtime, the .NET SDK, ASP.NET Core and the WindowsDesktop shared framework are developed by different teams, though with a huge amount of cross-collaboration. They are developed, at times, like independent products. The .NET Runtime forms the base of the product. ASP.NET Core and WindowsDesktop are built on top of that. A huge quantity of the dev tooling (C#, F#, MSBuild) is built on top of the surface area of the .NET Runtime and some auxiliary libraries. The SDK gathers up and builds a CLI, along with tasks, targets and tooling. Much of the shared framework and tooling content is redistributed in-box.</p>
<p>To build and ship this security patch, we need coordination between the many teams that contribute to the .NET product as a whole. We need the lowest levels of the .NET graph (see below) to build their assets, then feed them downstream to consumers. They need take the update, build, and feed downstream. This will happen continually until the product is ‚Äúcoherent‚Äù; no new changes are being fed into the graph and everyone agrees on a single version of each component in the product. Coherency ensures that a component with changes is ingested everywhere that redistributes the component, or information about it. Then, we want to do our validation, take all the shippable assets from the closure of all those unreleased components, and then release them all at once to the world.</p>
<p>This is a lot of moving parts that need to work well together in a short period of time.</p>
<h3>Advantages and Disadvantages of Distributes Ecosystems</h3>
<p>It‚Äôs important to note that this distributed ecosystem style of development <em>does</em> have a lot of advantages:</p>
<ul>
<li><strong>Layering</strong> ‚Äì Repository boundaries tend to encourage layering and less tightly bound products. During the major version development lifecycle, the individual components of the stack generally remain roughly compatible, even as changes flow quickly and unevenly through the graph.</li>
<li><strong>Communities</strong> ‚Äì Repository boundaries tend to encourage good, focused communities. The WPF and Winforms communities, for instance, are often distinct. Small repos are also generally more approachable.,</li>
<li><strong>Incrementality</strong> ‚Äì Distributed development often allows for incremental changes. For instance, we can make breaking changes to the System.CommandLine surface area, then ingest those in the consumers over time. This doesn‚Äôt work all the time (e.g. let‚Äôs say the SDK is attempting to ship just one copy of System.Text.Json for all of the tooling to use, but not every consumer agrees on that surface area. Boom?!), but it‚Äôs reasonably reliable.</li>
<li><strong>Tight Inner Loops</strong> ‚Äì Smaller, focused repositories tend to have better inner-loop experiences. Even something as simple as <code>git clone</code> or <code>git pull</code> is faster in a small repository. The repository boundary tends to give the (possibly illusory) sense that for your change, you only need to worry about the code and tests you can see.</li>
<li><strong>Asynchronous development</strong> ‚Äì Incrementality helps development be more asynchronous. If my component flows to three downstream consumers who work in three different time zones, those teams can make progress on their own components in their own time, rather than needing to coordinate.</li>
<li><strong>Low-Cost Sharding/Incremental Builds</strong> ‚Äì Distributed development allows for ‚Äòoptimizing‚Äô away builds of components that don‚Äôt change every often and are at the fringes of a dependency graph. For instance, a leaf node that builds some static test assets doesn‚Äôt need to be rebuilt every time there is a change to the sdk. The last built assets are just fine.</li>
</ul>
<p>If you squint and peer between the lines here though, a lot of the advantages of the distributed model are its significant weaknesses when we need to build and ship software that requires changes in a significant portion of the graph to be completed in a short period of time. Changes at scale across large graphs are often slow and unpredictable. But why? Is there something inherently wrong with this model? Not really. In typical OSS ecosystems (e.g. NuGet or NodeJS package ecosystems), these aspects are often <strong>not a problem</strong>. These ecosystems do not optimize for speed or predictability. Instead, they value the autonomy of each node. Each node needs only to concern itself with what it needs to <em>produce</em> and what it needs to <em>consume</em> and the changes required to meet those needs. However, when we attempt to apply the distributed model to shipping software quickly, we often struggle because it increases the prevalence of two key concepts, which I‚Äôm calling <strong>Product Construction Complexity</strong> and <strong>Product Construction Overhead</strong>. Together these combine to slow us down and make us less predictable.</p>
<h4>Product Construction Complexity</h4>
<p>In the context of product construction, ‚Äòcomplexity‚Äô refers to the quantity of steps that are required for a change to go from a developer‚Äôs machine to that change being delivered to customers in all the ways that it needs to be delivered. I recognize that this is a fairly abstract definition. ‚ÄúStep‚Äù could mean different things depending on what level of granularity you want to look at. For now, let‚Äôs focus on conceptual product construction steps, as shown in the example graph below:</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/basic-product-construction-complexity-scaled.webp" alt="Basic product construction complexity">
<em>A simple multi-repository product construction workflow. MyLibrary and MyApp are built from separate codebases. MyApp deploys to two customer endpoints</em></p>
<p>.NET began with a relatively simple product dependency graph and matching tools to manage that graph. As it grew, new repositories were added to the graph and additional dependency flow was required to construct the product. The graph grew more complex. We invented new tools (Maestro, our dependency flow system) to manage it. It was now easier than ever to add new dependencies. A developer or team looking to add new functionality to the product could often just create a new repository and build and set up the inputs and outputs. They only needed to know how that component fit within a small subsection of the larger product construction graph in order to add a new node. However, .NET doesn‚Äôt ship each individual unit independently. The product must become ‚Äúcoherent‚Äù, where everyone agrees on the versions of their dependencies, in order to ship. Dependencies or metadata about them are redistributed. You have to ‚Äúvisit‚Äù all of the edges. <em>Note: While we do not need to rev every component in the graph, there is a significant portion that changes on every release, either due to fixes or dependency flow.</em> Then you take the outputs of each individual node, combine them all together, and out the door you go.</p>
<p>More complex graphs have significant downsides:</p>
<ul>
<li>The more edges and nodes, the longer it tends to take to achieve coherency.</li>
<li>Teams are more likely to make a mistake. There are more coordination points, and more points in the workflow where a human can influence an outcome. Tools can help, but they only go so far.</li>
<li>Complexity can also encourage variance in build environment and requirements. It‚Äôs hard to keep everyone aligned on the same processes as teams move and upgrade at different rates. Reproducing that full set of environments can be expensive, and that cost tends to increase over time as infrastructure ‚Äúrots‚Äù.</li>
</ul>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/dotnet-product-construction-complexity-scaled.webp" alt="Product construction in .NET">
<em>Small but critical subsection of the .NET product construction graph, circa .NET Core 3.1. Arcade provides shared build infrastructure (dotted lines), while solid lines show component dependencies. Changes ripple through multiple repositories before reaching the final SDK and installer.</em></p>
<h4>Product Construction Overhead</h4>
<p>We define overhead as ‚Äú<em>the amount of time spent not actively producing artifacts that we can ship to customers</em>‚Äú. Like complexity, it can be evaluated on a different level of granularity depending on how detailed you want to get. Let‚Äôs take a look at two quick examples, and then at the overhead in one of .NET‚Äôs older builds.</p>
<p>A simple multi-repo product construction process might look like the following:</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/basic-product-construction-overhead-scaled.webp" alt="Sample product construction overhead">
<em>Illustration of overhead in a simple multi-repo product-construction workflow. Dot-outlined nodes represent overhead.</em></p>
<p>In the above graph, the overhead nodes (dotted nodes) do not actively contribute to the production of the packages in D. The time it takes the dependency flow service to create the PR is overhead. Waiting for a dev to notice and review the PR is overhead. Waiting for approval for package push is overhead. That‚Äôs not to say that these steps aren‚Äôt <em>necessary</em>, just that they are places where we say we‚Äôre not actively creating outputs for customers.</p>
<p>How about builds? If we zoom into a repository build process, we can often see quite a lot of overhead. Consider this very simple build:</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/basic-pipeline-build-overhead-scaled.webp" alt="Sample pipeline overhead">
<em>Illustration of overhead in a simple pipeline. Dot-outlined nodes represent overhead. Again, there are a number of steps here that aren‚Äôt actively producing or shipping bits to customers. They may be <strong>necessary</strong>, but they‚Äôre still overhead.</em></p>
<p>There are a few interesting measures of overhead in a system. We can measure it a % of overall time. Add up the time spent in each step based on its classification, then divide the total overhead by the total time. This gives a nice measure of overall resource efficiency. However, from a wall clock perspective, overall overhead doesn‚Äôt tell us much. To understand overhead‚Äôs effect on the end-to-end time, we find the longest path by time through our product construction graph, then compute the total overhead in steps that contribute to that path as compared to the total time in the path.</p>
<p>To understand what that overhead might look like in a single .NET build, let‚Äôs take a look at an 8.0 build of runtime. This data was generated using a custom tool that can evaluate an Azure DevOps build based on a set of patterns that classify each step.</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Time</th>
<th>Percentage of overall build time</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>All Steps (w/ Queueing)</strong></td>
<td>2 days 02:18:10.9</td>
<td>100%</td>
</tr>
<tr>
<td><strong>Overhead (w/ Queueing)</strong></td>
<td>19:23:22.9</td>
<td>38.5%</td>
</tr>
<tr>
<td><strong>Overhead (w/o Queueing)</strong></td>
<td>12:33:36.6</td>
<td>25.0%</td>
</tr>
<tr>
<td><strong>Queueing</strong></td>
<td>06:49:46.3</td>
<td>13.6%</td>
</tr>
<tr>
<td><strong>Work</strong></td>
<td>1 day 06:42:10.7</td>
<td>61.0%</td>
</tr>
<tr>
<td><strong>Unknown</strong></td>
<td>00:12:37.3</td>
<td>0.4%</td>
</tr>
<tr>
<td>‚Äî‚Äî‚Äî‚Äì</td>
<td>‚Äî‚Äî‚Äî-</td>
<td>‚Äî‚Äì</td>
</tr>
<tr>
<td><strong>Longest Path Time</strong></td>
<td>05:40:05.2</td>
<td>N/A</td>
</tr>
<tr>
<td><strong>Average Path Time</strong></td>
<td>04:03:11.3</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<p>Here are the three longest paths from that build:</p>
<table>
<thead>
<tr>
<th><strong>Path</strong></th>
<th><strong>Total Time</strong></th>
<th><strong>Overhead Time (w/ Queue)</strong></th>
<th><strong>Queue Time</strong></th>
<th><strong>Work Time</strong></th>
<th><strong>Unknown Time</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>(Stage) Build-&gt;Mono browser AOT offsets-&gt;windows-x64 release CrossAOT_Mono crossaot-&gt;Build Workloads-&gt;(Stage) Prepare for Publish-&gt;Prepare Signed Artifacts-&gt;Publish Assets</td>
<td>05:40:05.2</td>
<td>02:46:49.8 (49.1%)</td>
<td>00:40:29.8 (11.9%)</td>
<td>02:51:39.0 (50.5%)</td>
<td>00:01:36.3 (0.5%)</td>
</tr>
<tr>
<td>(Stage) Build-&gt;windows-arm64 release CoreCLR -&gt;Build Workloads-&gt;(Stage) Prepare for Publish-&gt;Prepare Signed Artifacts-&gt;Publish Assets</td>
<td>05:37:32.0</td>
<td>02:28:58.1 (44.1%)</td>
<td>00:31:32.2 (9.3%)</td>
<td>03:07:05.6 (55.4%)</td>
<td>00:01:28.2 (0.4%)</td>
</tr>
<tr>
<td>(Stage) Build-&gt;Mono android AOT offsets-&gt;windows-x64 release CrossAOT_Mono crossaot-&gt;Build Workloads-&gt;(Stage) Prepare for Publish-&gt;Prepare Signed Artifacts-&gt;Publish Assets</td>
<td>05:37:00.9</td>
<td>02:47:19.1 (49.6%)</td>
<td>00:40:51.8 (12.1%)</td>
<td>02:48:05.0 (49.9%)</td>
<td>00:01:36.8 (0.5%)</td>
</tr>
</tbody>
</table>
<h4>Overhead + Complexity = Time</h4>
<p>Overhead is unavoidable. There is some level inherent in every product construction process. However, when we add complexity to our product construction processes, especially complexity in the graph, the overhead tends to begin to dominate the process. It sort of multiplies. Rather than paying the machine queue time cost one time, you might pay it 10 times over within a single path through the graph. After those machines are allocated, you then clone the repo each time. The efficiency scaling of these steps tends to also be worse because there is some fixed cost associated with each one. For instance, if it takes 10 seconds to scan 10MB of artifacts, and 1 second to prepare for the scan, collate and upload the results, it takes longer to do that step 10 times in a row than it does to scan the full 100MB at once. 110 vs. 101 seconds.</p>
<p>What is also insidious is that this cost tends to hide and increase over time. It‚Äôs not always obvious. A local repository build for a developer is typically fast. The developer does not see any overhead of the overall CI system in that build. Zooming out, building the repository in a job in a pipeline can be similarly quick, but starts to incur some overhead. You have the quick build of that repository, but extra overhead steps around it. You‚Äôre still reasonably efficient though. Then let‚Äôs say you zoom out a little and you have some additional jobs in that pipeline, doing other things. Maybe reusing artifacts from other parts of the build, building containers, etc. Overhead will start to become a larger overall % of the long path time. Now, zoom out again, and you‚Äôre looking at the place of that pipeline and associated repositories in context of your larger product construction. You add in time for dev PR approvals, dependency flow systems to do their work, more cloning, more building, more compliance, more more more.</p>
<p>In a distributed product construction system, decisions that affect complexity, and therefore overhead, can be made at a level that does not see the overall overhead in the system. A new node is added. In isolation, it‚Äôs fine. In context, it costs.</p>
<p>While no graph of complexity was ever made for the .NET 8 timeframe that could show the complexity of each individual component build in context of the whole product construction graph, consider what the job graph for the runtime build alone looked like. Each bubble below represents a separate machine.</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/net8-runtime-complexity-scaled.webp" alt=".NET 8 runtime build complexity">
<em>Complexity in a .NET 8 build. Each node represents an individual machine. Edges represent dependencies.</em></p>
<h2>The roots of Unified Build in Source Build</h2>
<p>.NET Source Build is a way that Linux distributions can build .NET in an isolated environment from a single, unified source layout. Microsoft started working on it around .NET Core 1.1. The spiritual roots of Unified Build grew from hallway conversations between the team working on .NET Source Build and the team responsible for the Microsoft distribution. I won‚Äôt say it wasn‚Äôt in jealousy that the infrastructure teams often looked at how long it took to build the .NET product within the Source Build infrastructure. <strong>50 minutes!</strong> Shorter than it took to build just the runtime repository from scratch in its official CI build. Now granted, it wasn‚Äôt exactly an apples-to-apples comparison. After all, Source Build:</p>
<ul>
<li>Only builds one platform.</li>
<li>Doesn‚Äôt build any of the Windows-only assets (e.g. WindowsDesktop shared framework)/</li>
<li>Doesn‚Äôt build .NET workloads.</li>
<li>Doesn‚Äôt do any installer packaging.</li>
<li>Doesn‚Äôt build the tests by default</li>
</ul>
<p>All very reasonable caveats. But enough caveats to add up to 10s of hours in differences in build time? <strong>Unlikely.</strong> Much more likely is that the Source Build methodology is <strong>low complexity</strong> and <strong>low overhead</strong>. More than just time, there were other obvious benefits. Unified toolsets, easier cross-stack development, and perhaps most importantly, hard guarantees of what was being built and its build-time dependencies.</p>
<p>Back to those hallway conversations. Source Build‚Äôs obvious benefits led to occasional probing questions from various members of the .NET team. Most of the form: <em>So‚Ä¶why doesn‚Äôt Microsoft build its distribution that way?</em> Answer: It‚Äôs hard.</p>
<h3>Why is it hard? A detour into the land of Source Build</h3>
<p>Microsoft began efforts to make Source Build a ‚Äòreal‚Äô piece of machinery around the .NET 3.1 timeframe. Prior to this point, the Source Build distribution tended to look more like a one-off effort for each .NET major release. It was too difficult to keep working all the time, so the team worked, starting in the spring as the new product took shape, to bring the new .NET version into line with Linux distro maintainer requirements. To understand why it‚Äôs so hard to fit Microsoft‚Äôs distribution of .NET into this model as part of the Unified Build project, let‚Äôs look back into why it was so hard to get the Source Build project into a turn crank state in the first place.</p>
<p>To allow our distro partners to distribute .NET we needed to produce an infrastructure system that produced a .NET SDK within the following constraints:</p>
<ul>
<li>Single implementation! ‚Äì Only one implementation per component</li>
<li>Single platform ‚Äì Only build for one platform (the one that distro partners are trying to ship)</li>
<li>Single build ‚Äì Only build on one machine. We can‚Äôt require a complex orchestration infrastructure.</li>
</ul>
<h4>Linux Distro Build Requirements</h4>
<p>Linux distros generally have stricter rules and less flexibility when building software that will go into their package feeds. The build is usually completed offline (disconnected from the internet). It may only use as inputs artifacts that have been previously created in that build system. Checked-in binaries are not allowed (though they can be eliminated at build time). Any source in the repository must meet strict licensing requirements. <em>See <a href="https://github.com/dotnet/core/blob/main/license-information.md">license information</a> for information on .NET licensing and <a href="https://docs.fedoraproject.org/en-US/legal/license-approval/#Good_Licenses">Fedora licensing approval</a> for sample distro requirements.</em> At a conceptual level, a Linux distro partner wants to be able to trace every artifact they ship to a set of sources and processes that they can reasonably edit. All future software should be built from previously Source Build produced artifacts. <em>Note: There is a <a href="https://github.com/dotnet/source-build/blob/main/Documentation/bootstrapping-guidelines.md">bootstrap process</a>, as you might imagine might be required.</em>.</p>
<h4>Single Build ‚Äì A repo and orchestration framework to stitch the stack together</h4>
<p>As you‚Äôve learned earlier, the .NET build, like many products, is actually comprised of the Azure DevOps builds of various components, stitched together with dependency updates. This means that the information and mechanics required to construct the product is distributed between the repositories (build logic within the build system and associated scripting, as well as YAML files processed by Azure DevOps) and the dependency flow information held by our ‚ÄòMaestro‚Äô system (producer-consumer information). This isn‚Äôt usable for our Linux distro partners. They need to be able to build the product without access to these Microsoft resources. And they need to be able to do so in a way that is practical for their environments. Manually stitching together a product from a build graph isn‚Äôt reasonable. We need an orchestrator that encapsulates that information.</p>
<h5>The Source Build layout and orchestrator</h5>
<p>The orchestrator replaces the tasks that Azure DevOps and Maestro perform for .NET‚Äôs distributed build with ones that can be run from a single source layout, disconnected from the internet. You can see the modern, updated layout and orchestrator over at <a href="https://github.com/dotnet/dotnet">dotnet/dotnet</a>.</p>
<ul>
<li>
<p><strong>Single source layout</strong> ‚Äì A <a href="https://github.com/dotnet/dotnet/tree/main/src">single source layout</a> with a copy of all components required to build the product. Submodules are flattened, if they exist (typically for external OSS components). The contents of the source layout are determined by identifying <a href="https://github.com/dotnet/sdk/blob/7efd8a45363467689d38fcf05f0c5f720244d0c4/eng/Version.Details.xml#L16">an annotated dependency</a> for each component within the product graph, rooted at <a href="https://github.com/dotnet/sdk">dotnet/sdk</a>. The sha for that annotated dependency determines what content will populate the layout. <em>Note: dependencies like compilers and OS libs are provided by the build environment.</em></p>
</li>
<li>
<p><strong>Information on how each component should be built, and its dependencies</strong> ‚Äì For each of the components within the single source layout, a <a href="https://github.com/dotnet/dotnet/tree/main/repo-projects">basic project</a> is provided which identifies how the component is built. In addition, the component level dependencies are also identified. i.e. the .NET Runtime needs to be built before ASP.NET Core can start.</p>
<pre><code>&lt;ItemGroup&gt;
&lt;RepositoryReference Include="arcade" /&gt;
&lt;RepositoryReference Include="runtime" /&gt;
&lt;RepositoryReference Include="xdt" /&gt;
&lt;/ItemGroup&gt;</code></pre>
</li>
<li>
<p><strong>Build orchestrator logic</strong> ‚Äì The <a href="https://github.com/dotnet/dotnet/blob/main/repo-projects/Directory.Build.targets">build orchestrator logic</a> is responsible for launching each build in the graph when it is ready (any dependencies have been successfully built), as well as inputs and outputs of each component. After a component build has been completed, the orchestrator is responsible for identifying the outputs and preparing inputs for downstream component builds. Think of this as a local Dependabot, computing the intersection of the declared input repositories against the package level dependency info (see <a href="https://github.com/dotnet/dotnet/blob/main/src/aspnetcore/eng/Version.Details.xml">aspnetcore‚Äôs</a>) for an example. More information on how dependency tracking works in .NET builds can be found in my <a href="https://devblogs.microsoft.com/dotnet/a-deep-dive-into-how-net-builds-and-ships/#tracking-our-dependencies">previous blog post</a>.</p>
</li>
<li>
<p><strong>Compliance verification</strong> ‚Äì The comparatively stricter environments that our Linux distro partners build in mean that it‚Äôs necessary that we build some automation to identify potential problems. The orchestrator can identify pre-built binary inputs, ‚Äòpoison‚Äô leaks (previously source-built assets appearing in the current build outputs), and other hazards that might block our partners.</p>
</li>
<li>
<p><strong>Smoke testing</strong> ‚Äì Most of our test logic remains in the individual repositories (more on that later), but the layout also includes <a href="https://github.com/dotnet/dotnet/tree/main/test">smoke tests</a>.</p>
</li>
</ul>
<h4>Single Implementation ‚Äì Pre-built squeaky clean</h4>
<p>There are some obvious and non-obvious reasons why these requirements would be hard to meet using the ‚Äòstock‚Äô Microsoft build of .NET, and why Source Build required so much work. An offline build with pre-staged, identified inputs that are <strong>buildable from source</strong> is a major undertaking. When the Source Build team began to investigate what this meant, it was quickly obvious that a LOT of interesting behavior was hiding in the .NET product build. Sure, binary inputs like optimization data were obviously disallowed, but some other foundational assets like .NET Framework and NETStandard targeting packs were also not buildable from source. Either they weren‚Äôt open source in the first place, or they hadn‚Äôt been built in years. More concerning, the graph-like nature of .NET means that incoherency is very common. Some of this incoherency is undesirable (the kind we attempt to eliminate during our product construction process). Some of it is expected and even desired.</p>
<h5>Example: Microsoft.CodeAnalysis.CSharp</h5>
<p>As an example, let‚Äôs take a look at the C# compiler analyzers, which are built in the <a href="https://github.com/dotnet/roslyn">dotnet/roslyn</a> repository. The analyzers will reference various versions of the <code>Microsoft.CodeAnalysis.CSharp</code> package depending on the required surface area to ensure that a shipped analyzer runs all of the versions of Visual Studio and the .NET SDK that it is required to support. They reference a minimum possible version. This ensures that analyzers can be serviced in a sustainable fashion, rather than shipping a different version of an analyzer for every possible VS or SDK configuration.</p>
<p>Because multiple versions of the surface area are referenced, multiple versions of <code>Microsoft.CodeAnalysis.CSharp</code> are restored during the build. That would mean, for the purposes of Source Build, we need to build each and every one of those versions of <code>Microsoft.CodeAnalysis.CSharp</code> at some point. We have two ways to do this:</p>
<ul>
<li><strong>Multi-version source layout</strong> ‚Äì Place multiple copies of dotnet/roslyn into the shared source layout, one for each referenced <code>Microsoft.CodeAnalysis.CSharp</code> version based on when it was originally produced. This is not only expensive in build time, but it tends to be somewhat viral. If you have 3 versions of dotnet/roslyn you need to build, you need to ensure that the transitive dependencies of those 3 versions are also present in the shared layout. The maintenance complexity of this setup goes up very quickly. These are previously shipped versions of the dotnet/roslyn source base. It will be necessary to maintain security and compliance of those codebases over time. Upgrading build-time dependencies. Removing EOL infrastructure, etc.</li>
<li><strong>Require previously source-built versions to be available</strong> ‚Äì This is really just a flavor of the multi-version source layout with an element of ‚Äúcaching‚Äù. If a distro maintainer needs to rebuild the product from scratch, or if a new Linux distribution is being bootstrapped, they might need to reconstruct decent portion of .NET‚Äôs past releases just to get the latest one to build in a compliant fashion. And if those old versions require changes to build in a compliant fashion, you‚Äôre again in a maintenance headache.</li>
</ul>
<h4>Source Build Reference Packages</h4>
<p>There are numerous other examples like Microsoft.CodeAnalysis.CSharp. Any time a project targets a down-level target framework (e.g. net9 in the net10 build), the down-level reference pack is restored. SDK tooling (compilers, MSBuild) targets versions of common .NET packages that match the version shipped with Visual Studio. So how do we deal with this? We cannot simply unify on a single version of every component referenced within the product without fundamentally changing the product.</p>
<p>The Source Build team realized that a lot of this usage fit neatly into a class of ‚Äúreference-only‚Äù packages.</p>
<ul>
<li>The targeting packs restored by the SDK when a project builds against a TFM that does not match the SDK‚Äôs major version (e.g. targeting net9 with a net10 SDK) do not contain implementation.</li>
<li>The reference to older versions of <code>Microsoft.CodeAnalysis.CSharp</code> are <em>surface area</em> only. No assets are <em>redistributed</em> from these packages. If the implementation is not needed, a reference-only package can be substituted.</li>
</ul>
<p>Enter <a href="https://github.com/dotnet/source-build-reference-packages">dotnet/source-build-reference-packages</a>. A reference-only package is significantly simpler to create and build, and it meets the needs of the consumers in the build. We can generate reference package sources for packages where we do not need the implementation, then create an infrastructure to store, build and make them available during the Source Build process. Providing multiple versions is relatively trivial. The dotnet/source-build-reference-packages repository is built during the .NET build, and then consuming components restore and compile against provided reference surface area.</p>
<h4>What about all those non-reference cases?</h4>
<p>With a solution to reference packages, we can turn our attention to other inputs that are not Source Build compliant and do not fall into the ‚Äòreference‚Äô category. There are three major sets:</p>
<ul>
<li>Closed source or inputs that cannot be built from source ‚Äì Optimization data, Visual Studio integration packages, internal infrastructure dependencies, etc.</li>
<li>Legacy ‚Äì Open source dependencies on implementation built in older versions of .NET.</li>
<li>Joins ‚Äì Open source dependencies on implementation built on other platforms.</li>
</ul>
<p>Let‚Äôs take a look at how we deal with these cases.</p>
<h5>Closed Source/Non-Source Buildable Inputs</h5>
<p>Closed source or any inputs that cannot be built from source aren‚Äôt allowable in the Linux distro maintainer builds, full stop. To resolve these cases, we analyze each usage to determine what to do. Remember that our goal is to provide a compliant build implementation for use by our distro partners, which is functionally as close to what Microsoft ships as is possible. i.e. we don‚Äôt want Microsoft‚Äôs Linux x64 SDK to <em>behave</em> in substantially different ways from RedHat‚Äôs Linux x64 SDK. This means that the runtime and sdk layouts for Linux x64 need to be as close as possible. The good news is that quite a lot of the closed source usage isn‚Äôt required to produce functionally equivalent assets. Examples:</p>
<ul>
<li>We might restore a package that enables signing, something not required in a distro partner build</li>
<li>The dotnet/roslyn repository builds components that power Visual Studio. These components have dependencies on Visual Studio packages that define the IDE integration surface area. However, this IDE integration doesn‚Äôt ship in the .NET SDK. This functionality could be ‚Äútrimmed away‚Äù in Source Build by tweaking the build. This is reasonably common.</li>
</ul>
<p>If dependencies couldn‚Äôt be trimmed away without altering product functionality, we have a few additional options:</p>
<ul>
<li><strong>Open source the dependency</strong> ‚Äì Often times, a closed source component, or at least a key portion of a closed source component required to satisfy a scenario, can be open sourced.</li>
<li><strong>Alter product behavior</strong> ‚Äì Sometimes, the team can work to remove the product differences with intentional design changes. Remember that the important part is that everything that ships on distro partner package feeds needs to be built from source. This allows for some assets to be brought in dynamically. Think of this like the NPM package ecosystem vs. the NPM package manager. A distro might build the NPM package manager from source. This leaves users to dynamically restore NPM packages at build time.</li>
<li><strong>Live with slightly different behavior</strong> ‚Äì These cases are few and far between. Prior to .NET 10, the WinForms and WPF project templates and WindowsDesktop were not included in the source-built Linux SDK, despite being available in Microsoft‚Äôs Linux distribution. This was due to the difficulty in building the required portions of those repositories on non-Windows platforms.</li>
</ul>
<h5>Legacy Dependencies</h5>
<p>We‚Äôve discussed what we can do with closed source and non-reproducible dependencies. What about legacy dependencies? First, what do we mean by ‚Äòlegacy‚Äô dependency? As detailed in earlier discussion, there is quite a lot of ‚Äòincoherency‚Äô in the product. A project might build for multiple target frameworks, redistributing assets from older versions of .NET. This is all to support valuable customer scenarios. But building all the versions of these components isn‚Äôt feasible. This is where our <strong>single implementation</strong> rule comes into play. We choose a single version of each component to build and ship with the product. We do allow for <em>reference</em> to old versions, via dotnet/source-build-reference-packages, but relying on older implementations are off limits.</p>
<p>First, we look for a way to avoid the dependency. Is it needed for the Linux SDK we‚Äôre trying to produce? If not, we can eliminate that code path from the build. If so, is there an opportunity to unify on the single implementation? In a lot of cases, incoherency is just a result of the product components moving their dependencies forward at different rates. If all else fails, we could explore compromises that involve behavioral differences, but we want to avoid this as much as possible.</p>
<h5>Joins and Verticality</h5>
<p>Joins are the last major category of pre-builts to remove. They occur because we end up with intra-product dependencies that are built in another environment. For example, I might be running a build on Windows that creates a NuGet package for a global tool, but to build that NuGet package I need the native shim executables Mac and Linux and Windows. Those shims can only (reasonably) be built in the Mac and Linux host environments. These types of dependencies are indicative of a product build that is more ‚Äòwoven‚Äô than ‚Äòvertical‚Äô and tend to naturally emerge over time in a multi-repo product construction graph. Each edge in that graph represents a sequence point where all the outputs of earlier nodes are available, regardless of where they were built. If a dependency can be taken, it will be taken.</p>
<p>However, the distro partner builds need to be single platform <em>and</em> single invocation to fit into distro partner requirements. Bootstrapping notwithstanding, they want to pull in the dependencies, disconnect the machine from the network, and hit build. At the end, out pops a bright new .NET SDK. Cross-platform dependencies preclude any such behavior. They block ‚Äúbuild verticality‚Äù. Remember joins. We‚Äôll need to come back to them later when we start implementing Unified Build for Microsoft based on the Source Build model.</p>
<p>For Source Build, we again deal with joins a bit like legacy dependencies. The key aspect to remember is that Source Build is narrowly focused on producing a .NET SDK and associated runtimes in the Linux distro partner build environments. So, we eliminate dependencies where possible (e.g. we don‚Äôt need to package Windows global tool executable stubs when running the SDK on Linux) and redesign the product or product construction process as necessary to meet requirements (e.g. .NET Workload manifests).</p>
<h2>The Vision ‚Äì Dreaming up Unified Build</h2>
<p>Unified Build seeks to apply the general principles of our Linux distro partner Source Build to the product that Microsoft ships. Achieving this would result in big wins for Linux distro partners, upstream contributors and Microsoft, reducing maintenance costs and improving the ability to build and ship quickly. Although we knew from the outset that we likely can‚Äôt exactly match the exact Linux distro build approach without major changes in the product, we thought we could get close. .NET came up with the following high-level goals (<em>Note, ‚Äú.NET distro maintainers‚Äù refers to anyone building .NET, including Microsoft</em>):</p>
<ul>
<li>A single git commit denotes all product source for a particular .NET build. All commits are coherent</li>
<li>A single repo commit can produce a shippable build</li>
<li>.NET‚Äôs build shall be able to create a specific platform‚Äôs distribution in a single build environment.</li>
<li>.NET distro maintainers shall be able to efficiently update and build .NET (both collaboratively and separately) through the entire lifecycle of a .NET version (first to last commit).</li>
<li>.NET distro maintainers can produce downstream distributions without use of Microsoft provided services.</li>
<li>.NET distro maintainers shall be able to meet provenance and build environment requirements for their distributions.</li>
<li>.NET distro maintainers shall be able to coordinate patching of downstream distributions.</li>
<li>.NET distro maintainers can run verification tests against the built product.</li>
<li>.NET contributors shall be able to easily produce full product builds for testing, experimentation, etc.</li>
<li>.NET contributors shall be able to work efficiently on the section of the product for which they are concerned.</li>
</ul>
<p>Still, getting there would require solving a mountain of new problems. Let‚Äôs take a look at some of the problems we need to solve before we can use Source Build as Microsoft‚Äôs .NET build.</p>
<h3>Provide a way to determine what makes it into the product</h3>
<p>When you construct a product using the distributed model, the <em>build</em> of the product, the <em>validation</em> of the product and the determination of what actually <em>constitutes</em> the product are all tied together. Source Build operates on a flattened source layout based on a final coherent graph. However, it relies on the traditional .NET product construction process in order to determine what versions of each component show up in the layout. To get the full benefit we need a way to directly update components within the shared source base without complex dependency flow. Otherwise, if a developer wants to make a change in runtime, they will end up building the product twice. Once to flow the runtime build with their change through all paths that runtime reaches, then once again to build the product using that new runtime.</p>
<h4>What we have</h4>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/pre-ub-runtime-propagation-scaled.webp" alt="Pre-unified-build runtime change propagation">
<em>Highlighted paths show how a runtime change cascades through multiple repositories in the distributed build model, requiring sequential builds and dependency flow updates.</em></p>
<h4>What we need</h4>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/post-ub-runtime-propagation-scaled.webp" alt="Unified-build runtime change propagation">
<em>Highlighted path shows how a runtime change immediately flows into the source layout. We call this a ‚Äòflat flow‚Äô</em></p>
<h3>Provide a way to react to breaking changes</h3>
<p>The flat flow significantly reduces the number of hops, and therefore the complexity and overhead in the process of a change making its way into the shared source layout. And we can see that before a change makes it into the product; it will still get PR validation and possibly some more in-depth rolling CI validation. However, let‚Äôs say that this change requires reaction in consuming components. Despite the change in dependency flow to a flat flow, ASP.NET Core still depends on .NET Runtime. And ASP.NET Core‚Äôs code in the layout doesn‚Äôt know about the new runtime change. Whatever PR validation we have before a change is allowed in the shared source layout is sure to fail.</p>
<p>In a traditional dependency flow system, we handle this by making changes in the dependency update PR. If an API is changed, the build breaks. A dev makes a change in the PR (ideally), validation is green, and the PR is merged. For the single-source methodology to work for .NET, we‚Äôll need to be able to make changes to the source of <em>other</em> components in the dotnet/runtime update PR.</p>
<h3>Provide a way to validate against repository infrastructure</h3>
<p>As we discussed earlier, a large quantity of critical validation lives at the component repository level. That‚Äôs where the developers spend their time. Moving or copying all of this is probably wasteful, definitely expensive, and likely hard to maintain. If we can‚Äôt rely on the dependency flow to do the validation before components flow into the shared source layout, we‚Äôll need a way to do so after.</p>
<p>To solve our problem, we could have all the outputs of a new product builds flow <strong>back</strong> into the individual repositories, matching with the dependencies in their <code>Version.Details.xml</code> files. That means dotnet/aspnetcore will get a bunch of new .NET Runtime packages, dotnet/sdk will get a bunch of newly built ASP.NET Core, .NET Runtime and Roslyn compiler packages, etc. They will be validating the ‚Äòlast built‚Äô versions of their input dependencies against repository infrastructure.</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/unified-build-backflow-validation-scaled.webp" alt="Unified Build validation on backflow">
<em>Backflow provides a way to validate the recently built .NET output against repository infrastructure</em></p>
<h3>Provide two-way code flow</h3>
<p>Let‚Äôs say a runtime insertion PR changed the signature of an API in <code>System.Text.Json</code>. When that forward flows, the responsible dev updates the signatures in all downstream users. Let‚Äôs say that‚Äôs code in <code>src/aspnetcore/*</code> and <code>src/windowsdesktop/*</code>. The new product is built, and the updated System.Text.Json package with the new API signature makes its way back to <code>dotnet/aspnetcore</code> and <code>dotnet/windowsdesktop</code>. The HEAD of <code>main</code> doesn‚Äôt have the source changes made directly in the shared layout forward flow PR. The dev would need to port those changes over, making changes in the backflow PR. This is tedious and error prone. Our new system will need to provide a way to automatically flow changes made in the shared layout back in the source repository.</p>
<p><img decoding="async" src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/unified-build-full-flow-scaled.webp" alt="Unified Build two-way code flow">
<em>Component changes flow to our shared source layout, additional changes made only in the shared source layout flow back into the component repositories with supporting packages. Note that this is a general capability to backflow shared source changes, not just changes made in forward flow PRs.</em></p>
<h3>Provide better insertion time validation</h3>
<p>Validation on backflow isn‚Äôt perfect. It doesn‚Äôt provide an easy <em>pre-merge</em> gate for bad changes in dependent components. We can mitigate this by identifying and closing gaps in repo testing that allowed bad changes to be merged in the originating repo. We can also accept that some things will always slip through and that the process of creating a high-quality product isn‚Äôt just a green PR. Many repositories do not and cannot run their full testing suites prior to merging. However, we can <em>also</em> invest scenario testing run against the just-built product. This is something that our traditional dependency flow system is not good at.</p>
<p>Any whole product scenario testing relies on dependency updates for components reaching the dotnet/sdk repository. Up to that point, we don‚Äôt have a complete .NET product that we can test. Any attempt is just some kind of ‚ÄúFrankenbuild‚Äù. <em>Note: A lot of this end-to-end testing just comes in the form of dotnet/sdk‚Äôs repository-level PR/CI testing.</em>. However, changes can take a while to move through the graph to the point there they take effect in a way that would be visible in testing.</p>
<p>The Source Build methodology provides a full product build on each and every component change, regardless of where that component lives in the product construction graph. This means that we have the opportunity to create and run a comprehensive suite of testing on each of those insertions. That testing should be focused on covering wide swaths of product functionality. If this testing passes, there is a reasonable expectation that .NET is functioning in a way that makes it possible for development to make forward progress.</p>
<h3>Provide a way to build all of what .NET ships</h3>
<p>The Linux distro Source Build offering focuses narrowly on the assets in-box in the 1xx band SDK, ASP.NET Core, Runtime. It builds packages that support the creation of these layouts. As we saw earlier with prebuilt elimination, this narrow focus is necessary to be able to meet distro partner build requirements. If we want to build what Microsoft ships, we can‚Äôt have that narrow focus.</p>
<p>Expanding our focus is straightforward in some areas and difficult in others. In some ways, we‚Äôre just relaxing restrictions and bringing more functionality back into the build. We need to allow for pre-built binaries (e.g. signing functionality) to be restored from feeds. We need to build all TFMs instead of trimming away .NET Framework targets. We‚Äôll need to build components originally excluded from the souce build focused shared source layout, like Windows Desktop, Winforms, WPF, EMSDK, etc. What‚Äôs more difficult are joins. Recall that Linux distro Source Build is single layout, single machine, single invocation.  This suffices for producing the layout, but there are a good handful of other artifacts in .NET that require builds on multiple machines. Artifacts that break the single machine verticality concept.</p>
<p>In an ideal world, we‚Äôd re-architect the product to avoid these joins. But it‚Äôs often hard to do so without customer compromise or driving complexity into the product itself. We can‚Äôt simplify the SDK without breaking customers, and this is hard to do, even across major versions, in an enterprise-grade product. Past decisions heavily influence future available choices. In the end, we‚Äôll have to eliminate joins where we can via product construction practices. Any remaining joins will be something we have to live with. The build will have to be architected to run across multiple machines, via a series of build passes.</p>
<h2>Executing on the Vision ‚Äì Shipping Unified Build</h2>
<p>The Unified Build project can roughly be divided into 4 phases:</p>
<ul>
<li><strong>Initial brainstorming and design (.NET 7)</strong> ‚Äì The initial design work on the Unified Build project began in early 2022 during the development of .NET 7 and took ~4 months to complete. The project got full approval to start later in 2022 with the intention of completion by .NET 9 RTM, with some key go/no-go points where we could bail and still have a net win on infrastructure.</li>
<li><strong>Foundational work (.NET 8)</strong> ‚Äì The Unified Build project during .NET 8 was focused on foundational work to improve the sustainability of the Source Build infrastructure and building features that were required to support the weight of the full build. The investments were designed to be a net positive for .NET overall, even if it turned out that our proof-of-concept stage discovered some major unknown problem and we had to change direction.</li>
<li><strong>Vertical Build/Code Flow Exploration (Early .NET 9)</strong> ‚Äì After the foundational work completed, we moved to implement a vertical build for each of the 3 major OS families: Mac, Windows, and Linux. The intention was to identify as many of the problems we would need to solve during our productization phase as possible. We were especially interested in finding any previously unknown product construction join points. At the same time, we did a much deeper investigation into the options for code flow and code management, eventually proving out and settling on the implementation listed below.</li>
<li><strong>Productization (Late .NET 9-.NET 10)</strong> ‚Äì Final implementation started in earnest towards the end of .NET 9 after a spring+summer delay. As a result of the delay, the ship date was pushed back to .NET 10. This turned out to be a blessing in disguise. This bought us about 6 extra months of bake time and allowed us to use the Unified Build product construction process starting midway through the .NET 10 Preview/RC cycle (Preview 4). .NET Preview 4 shipped with the new build process, but on the old code flow. Preview 5 added the new code flow, and we never looked back. Further refinement in developer workflow, more bake time for the build and code flow process happened over subsequent months.</li>
</ul>
<p>And finally, after almost 4 years of dreaming and work, Unified Build shipped with .NET 10 RTM!</p>
<p>Let‚Äôs take a look at the key components of the project.</p>
<h3>VMR ‚Äì The Virtual Monolithic Repository</h3>
<p>The <a href="https://github.com/dotnet/dotnet">dotnet/dotnet VMR</a>, or ‚ÄúVirtual Monolithic Repository‚Äù forms the cornerstone of the Unified Build project. It is the source layout from which all of .NET is built, including by our Linux distro partners. It is the orchestrator. Functionally, it‚Äôs not much different from the source layout used prior to .NET 8.0. That layout has just been formalized into a git repository (vs. a source tarball). This is key, as it allows developers to work both in their individual component repository, where dev workflows might be very refined, as well as in the VMR when cross-cutting changes are necessary. .NET gets most of the benefits of the distributed repo world, without coherency problems.</p>
<h3>Vertical Build</h3>
<p>Vertical Build is .NET‚Äôs pivot to producing assets in a series of verticals. A vertical is defined as a single build command on a single machine that builds part of the .NET product without input from other verticals. Typically, we divide verticals up by the runtime that we‚Äôre trying to produce. For example, Windows x64 vs. MonoAOT vs. Linux arm64 vs. PGO profile Windows x86. Altogether there are 35-40 different verticals. We divide these into what we call ‚Äúshort stacks‚Äù and ‚Äútall stacks‚Äù. A short stack just builds the runtime. A tall stack builds all the way up through the SDK.</p>
<p>The original vision was that if we joined together all the outputs from parallel verticals, we‚Äôd have everything .NET needed to ship. Such a setup would be highly efficient and friendly to any upstream partners. Unfortunately, the design of the .NET product has baked in a few required joins over the years. For example, .NET workload packages can‚Äôt be built without access to numerous packages built across many operating systems. To resolve this, we ended up with two additional build passes. The good news is that those additional passes are on a reduced set of verticals and a reduced set of components within those verticals. Not perfect, but manageable.</p>
<h3>Code flow</h3>
<p>Probably the most interesting aspect of the Unified Build project is how code flow is managed. This is where .NET turns standard development patterns on their head a little bit. As detailed earlier, maintaining the product as a graph of interdependent components while flattening code flow into a shared coherent layout requires ‚Äútwo-way‚Äù code flow. Changes need to flow from components into the shared layout, and changes in the shared layout need to be able to flow back to the component repositories. Conceptually the code flow algorithm is no more complicated than anything you can model within a single git repository for a given project. The trick is to do this with repositories with no related git history.</p>
<p><strong>Note: The nitty gritty details of this algorithm will be covered in a future post by another team member. I‚Äôll update this post to link to it when it‚Äôs available.</strong></p>
<p>For now, let‚Äôs take a look at the basics:</p>
<p>Both the VMR and the component repository keep track of the last code flow from their partner. This is tracked alongside standard dependency information in <code>eng/Version.Details.xml</code>, though one could imagine it could be kept elsewhere.</p>
<ul>
<li><a href="https://github.com/dotnet/runtime/blob/5bceb8184fcde55143d2102a65c72bd6233e950b/eng/Version.Details.xml#L2">dotnet/runtime knows the VMR SHA of the last ‚Äú<strong>backflow</strong>‚Äú</a>, which is the flow from the VMR to dotnet/runtime</li>
<li><a href="https://github.com/dotnet/dotnet/blob/fe21998bab3322ebf00893198bbb3cedf63b493a/src/source-manifest.json#L81-L86">The VMR knows the dotnet/runtime SHA of the last ‚Äú<strong>forward flow</strong>‚Äú</a>, which is the flow from dotnet/runtime to the VMR.</li>
</ul>
<p>The idea is to determine the diff between the ‚Äúlast flow‚Äù and whatever is flowing in now. For example, in a very simple case, when a new commit is made to dotnet/runtime and no changes have been made to <code>src/dotnet/runtime</code> in the VMR, the dependency flow system will take the following steps:</p>
<ol>
<li>Determine two points, A and B, for which to compute a diff. For this case, point A is the last flow of dotnet/runtime that was checked in to the VMR (or is currently in PR). Point B is the new commit to dotnet/runtime.</li>
<li>Construct a patch file, remapping the files src/runtime files onto the directory structure of the VMR.</li>
<li>Open a PR with the diffs. See an <a href="https://github.com/dotnet/dotnet/pull/3151">example forward flow</a> and an <a href="https://github.com/dotnet/runtime/pull/121366">example back flow</a>.</li>
</ol>
<p>.NET 8 and .NET 9 use VMRs with only one-way code flow. These cases with no changes on the other side are trivial and robust. Things get spicier when developers start making changes on both sides, and when dependency flow starts shifting around over time.</p>
<ul>
<li>Computing the diff points gets more interesting and involves knowing which way that ‚Äúlast flow‚Äù was.</li>
<li>Merge conflicts arise and need to be dealt with in a way the developer can understand.</li>
<li>Changes in the source and target of code flow can cause havoc and need robust error handling and recovery mechanisms.</li>
</ul>
<p>I‚Äôll leave code flow there for now. Stay tuned for more.</p>
<h3>Scenario Test Validation</h3>
<p>The last major pillar of Unified Build is additional scenario testing. To be clear, .NET does not lack testing. .NET Runtime could use month‚Äôs worth of machine time on every PR to validate its millions of tests if it were practical or pragmatic to do so. Our approval, build, validation and signoff procedures ensure high-quality shipping bits. Still, when making changes directly in the VMR, the flat flow introduces new <em>lag</em> between that making that change and in-depth validation of it against each of the VMR components. While we can‚Äôt run every last test on PR and CI, we did recognize that better automated <a href="https://github.com/dotnet/scenario-tests">scenario testing</a> could play a solid role in preventing regressions. The goal was to add tests that covered wide swaths of product functionality that were not directly tied to the build system or repository infrastructure. Instead, they executed against the final built product. If the scenario tests pass, then there is a good sense that the product is functional at a decent level and contributors won‚Äôt be blocked.</p>
<h2>Results</h2>
<p>So, what did .NET get for almost 4 years of dreaming, scheming, and hard work? That‚Äôs a lot of effort to put into one project. Did the outcome justify the investment? As it turns out, we got quite a lot.</p>
<p>Let‚Äôs start with the most visible outcomes and then take a peek under the covers.</p>
<h3>Flexibility, predictability and speed</h3>
<p>By far the biggest return we‚Äôve seen on the investment is <strong>flexibility</strong>. Distributed product construction is slow. Producing coherent builds is slow. Checking in new fixes or content requires coordination to avoid ‚Äúresetting the build‚Äù, because <strong>what</strong> you want to ship, and <strong>how</strong> you build it are tied together in a distributed, OSS-style ecosystem. Taking a new fix might mean you don‚Äôt have something ready to handoff for validation. Flat flow eliminates that coherency problem, separating the <strong>what</strong> and the <strong>how</strong>. This is incredibly valuable during the drive towards an RTM build or a servicing release. It means we can make fixes later in the release cycle, focusing much more on whether those fixes meet our servicing bar and much less on whether we can actually build and deliver the change. That flexibility is good for customers.</p>
<p>Some of that flexibility comes from the speed of the build. This may sound glacially slow (.NET is a big, complex product), but .NET set a goal of producing an unsigned build in less than 4 hours, signed in less than 7. That‚Äôs down from significantly longer times in .NET 8.0 and .NET 9.0. A build of 8.0 or 9.0 can easily run to 24 even if everything goes perfectly. A signed build in 7 hours means a rolling set of new .NET assets to validate ~3 times a day. Most of that build time improvement comes from simply removing <a href="#product-construction-overhead">overhead</a>.</p>
<p>Some of the flexibility also comes from predictability. Distributed product construction has more moving parts. It has more human touch points. More places for systems and processes to fail. This tends to make outcomes unpredictable. ‚Äú<em>If I check in a fix to dotnet/runtime, when will I have a build ready?</em>‚Äù is a hard question to answer in a distributed system. I know how long dotnet/runtime‚Äôs build takes. But at what time will that change show up downstream via dependency flow? Will someone be around to review and approve it when it does? What‚Äôs the status of PR/CI validation downstream? Will a new important change be merged into dotnet/aspnetcore before we get a coherent build, setting us back on validation? This question is vastly easier to answer in .NET 10. The change flows into the VMR (or is made there directly) and will show up in the next build. The next build will take N hours.</p>
<h3>Infrastructural robustness and completeness</h3>
<p>Behind the flashier metrics, there are years of quality-of-life improvements to the infrastructure that pay major dividends day in and day out. Improvements to the Source Build infrastructure in .NET 8 reduced the cost of keeping Linux distro Source Build running. A lot of its cost was related to the delay between a change getting checked in and discovering whether it would break the build when it finally flowed through the graph and reached the shared source layout. It was not uncommon for the Source Build .NET SDK to not be ‚Äúprebuilt-clean‚Äù or shippable by distro partners until the middle of the previews. The infrastructure improvements in .NET 8 made it much easier to identify new pre-built inputs at PR time when they are easier to diagnose and resolve, before they made their way in the source layout. We are now prebuilt clean 100% of the time. That then reduced the load on the Source Build team, which gave them bandwidth to work in other areas. They added build parallelism, more predictable dependency flow, better logging, removed unneccessary complexity‚Ä¶the list goes on and on. Investments that make a product successful.</p>
<p>Our signing tooling had to be overhauled to support signing on every platform for a wide variety of archive types. Without this work, we couldn‚Äôt have shipped Unified Build. But this expanded support benefits more than just the core .NET product. There are numerous ancillary repositories that were able to simplify their builds, avoiding shuttling bits from Mac/Linux to Windows machines where the signing tooling ran. Lower build overhead, faster and simpler builds.</p>
<h2>Future directions</h2>
<p>So where does the Unified Build project go next? While we won‚Äôt have the same level of investment in .NET 11, we‚Äôll be making targeted improvements to the infrastructure to improve developer workflow and UX, mainly around code flow. One area I‚Äôm particularly excited about is AI agents that monitor code flow, connecting the dots between the various systems involved in creating the product and identifying issues. There are lots of systems and parties involved (Azure DevOps, GitHub, the code flow services and their configuration, code mirroring, developer approvals, machine allocation, etc.) in making a change go from PR to product. When it works, it works. When it doesn‚Äôt it‚Äôs often down to a human to track down exactly where the chain of events went wrong. It‚Äôs tedious and time consuming. We have tools, but it‚Äôs mainly about connecting lots of dots. We could write a rules engine for this, but my hunch is that it would be fragile and very complicated. Agents that can look at the system a little more fuzzily are ideally suited to this type of task. Less toil, a better .NET.</p>
<p>Lastly, beyond .NET 11, another push to get rid of join points might be on the horizon. The benefits are pretty clear: simpler, faster, and friendlier to contributors. We know now exactly how fast a build would be if you got rid of the remaining joins (less than 4 hours).</p>
<h2>Conclusion</h2>
<p>If you made it this far, thanks! It‚Äôs good to provide some insight into how .NET build and ships. You‚Äôve learned how distributed dependency flow product construction models aren‚Äôt always a great fit for shipping software predictably and reliably. These systems tend to have high complexity and overhead, which adds time. You‚Äôve read about the roots of the .NET Unified Build project in .NET Linux distro Source Build, and what made it difficult to apply those concepts to .NET. Lastly, you learned how .NET applied those concepts and the drastic improvements we‚Äôve seen in our day-to-day work.</p>
<p>The blog post detailing the flat code flow algorithms should be along shortly. Stay tuned!</p>
<h2>Links</h2>
<ul>
<li><a href="https://github.com/dotnet/dotnet/tree/main/docs">Unified Build Design Documentation</a></li>
<li><a href="https://dev.azure.com/dnceng-public/public/_build?definitionId=303">Rolling CI/PR builds of the product build</a></li>
</ul>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/11/IMG_4335-96x96.webp" alt="Matt Mitchell"></p><div><p>Principal Software Engineer</p></div></div><p>Matt Mitchell is a developer on the .NET Core infrastructure team. He focuses on end-to-end product construction and CI processes.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: KiDoom ‚Äì Running DOOM on PCB Traces (308 pts)]]></title>
            <link>https://www.mikeayles.com/#kidoom</link>
            <guid>46051449</guid>
            <pubDate>Tue, 25 Nov 2025 22:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mikeayles.com/#kidoom">https://www.mikeayles.com/#kidoom</a>, See on <a href="https://news.ycombinator.com/item?id=46051449">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
        <!-- Sidebar -->
        

        <!-- Main Content -->
        <main>
            <!-- Stats -->
            <div>
                <p><span>3</span>
                    <span>ECUs Developed</span>
                </p>
                <p><span>10+</span>
                    <span>Years Exp.</span>
                </p>
                <p><span>28.5M+</span>
                    <span>Miles Driven</span>
                </p>
            </div>

            <!-- Projects -->
            <section>
                <h2>Selected Projects</h2>
                
            </section>

            <!-- Private Tools -->
            <section>
                <h2>Private Tools</h2>
                
            </section>

            
        </main>
    </div>

    <!-- Modal -->
    

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[What they don't tell you about maintaining an open source project (164 pts)]]></title>
            <link>https://andrej.sh/blog/maintaining-open-source-project/</link>
            <guid>46051393</guid>
            <pubDate>Tue, 25 Nov 2025 22:08:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrej.sh/blog/maintaining-open-source-project/">https://andrej.sh/blog/maintaining-open-source-project/</a>, See on <a href="https://news.ycombinator.com/item?id=46051393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <h2 id="the-beginning">the beginning</h2>
<p>building <a href="https://kaneo.app/">kaneo</a> was fun. a clean, minimal kanban board. self-hosted. open source. no tracking, no subscriptions, no bullshit.</p>
<p>i shipped v1, posted it on reddit, got some stars on github. people actually used it. that feeling when someone tells you they're using something you built? incredible.</p>
<p>then i learned that <strong>shipping is just the beginning.</strong></p>
<h2 id="the-documentation-challenge">the documentation challenge</h2>
<p>i spent hours writing documentation. setup guides, configuration examples, troubleshooting sections. tried to make it clear and comprehensive.</p>
<p>but here's the thing: <strong>people come from different backgrounds.</strong> what's obvious to me after building the thing isn't obvious to someone installing it for the first time.</p>
<p>someone opens an issue: "how do i install this?"</p>
<p>my first reaction was frustration. it's in the readme! but then i realized - maybe the readme assumes too much. maybe they're new to docker. maybe they're coming from windows and linux is foreign.</p>
<p>so i improved the docs:</p>
<ul>
<li>added more examples</li>
<li>created a troubleshooting guide</li>
<li>made a video walkthrough</li>
<li>added a "common issues" section</li>
</ul>
<p>it's a constant process. documentation is never "done."</p>
<h2 id="support-is-product-development">support is product development</h2>
<p>maintaining kaneo means helping people debug their setups. and honestly? it's taught me more than i expected.</p>
<p>people run kaneo on setups i never imagined:</p>
<ul>
<li>behind corporate proxies</li>
<li>on raspberry pi clusters</li>
<li>in kubernetes with custom networking</li>
<li>on nas devices with limited resources</li>
</ul>
<p>each support request reveals an assumption i made. each "it doesn't work" issue (even the ones without details) points to a failure mode i didn't consider.</p>
<p>the challenge is balancing time. i want to help everyone. but i also have a day job. and new features to build. and bugs to fix.</p>
<p>i'm still learning how to set boundaries while being helpful.</p>
<h2 id="feature-requests-are-humbling">feature requests are humbling</h2>
<p>people want kaneo to do more. and that's amazing! it means they're actually using it. they care enough to imagine what it could be.</p>
<p>but <strong>every feature request is a decision:</strong></p>
<ul>
<li>does this fit the vision?</li>
<li>can i maintain this long-term?</li>
<li>will this complicate the codebase?</li>
<li>what else won't get built if i build this?</li>
</ul>
<p>saying no is hard. especially when the request is thoughtful and well-reasoned. especially when someone offers to help implement it.</p>
<p>i've learned to be transparent: "i love this idea, but it's outside kaneo's scope. here's why..."</p>
<p>most people understand. some don't. that's okay.</p>
<h2 id="migrations-are-terrifying">migrations are terrifying</h2>
<p>the database schema needed a refactor. the current design was limiting. the new design would enable features people wanted.</p>
<p>but 200+ people were using kaneo in production. <strong>their actual work data. their team's workflows.</strong></p>
<p>if i broke the migration, they'd lose trust. maybe lose data. definitely lose sleep.</p>
<p>so i:</p>
<ol>
<li>wrote the migration script</li>
<li>tested it on every version going back to v1</li>
<li>wrote detailed upgrade notes</li>
<li>tested edge cases</li>
<li>tested the edge cases of edge cases</li>
<li>added validation checks</li>
<li>added dry-run mode</li>
</ol>
<p>released it. held my breath.</p>
<p>most migrations went smoothly. a few didn't. not because people didn't read the notes - but because they had setups i couldn't have predicted:</p>
<ul>
<li>modified databases</li>
<li>custom patches</li>
<li>environments i'd never seen</li>
</ul>
<p>we debugged together. they were patient. i was grateful.</p>
<p>every migration taught me something new about defensive programming.</p>
<h2 id="contributors-are-a-gift">contributors are a gift</h2>
<p>when someone submits a pr, it's incredible. <strong>someone cared enough to spend their time improving kaneo.</strong></p>
<p>but integrating contributions is harder than i expected:</p>
<ul>
<li>different coding styles</li>
<li>different assumptions about architecture</li>
<li>different ideas about what kaneo should be</li>
</ul>
<p>sometimes a pr is perfect. sometimes it needs work. sometimes it's solving a problem in a way that'll create more problems later.</p>
<p>i've learned to:</p>
<ul>
<li>appreciate the effort, always</li>
<li>explain my reasoning when requesting changes</li>
<li>be okay with saying "this doesn't fit, but i appreciate you"</li>
<li>sometimes just fix it myself if it's close</li>
</ul>
<p>the contributors who stick around? they're amazing. they've made kaneo better than i could alone.</p>
<h2 id="the-diversity-of-environments">the diversity of environments</h2>
<p>self-hosting means people run kaneo <strong>everywhere:</strong></p>
<pre><code><span><span><span># docker on their laptops</span>
</span></span><span><span>docker compose up -d
</span></span><span><span>
</span></span><span><span><span># kubernetes clusters at work</span>
</span></span><span><span>kubectl apply -f kaneo.yaml
</span></span><span><span>
</span></span><span><span><span># raspberry pi in their home lab</span>
</span></span><span><span><span># (with 1GB of RAM and dreams)</span>
</span></span><span><span>
</span></span><span><span><span># bare metal on old servers</span>
</span></span><span><span><span># (that have been running since 2015)</span>
</span></span><span><span>
</span></span><span><span><span># nas devices with arm processors</span>
</span></span><span><span><span># (that i've never even heard of)</span>
</span></span></code></pre><p>each environment teaches me something. each "it doesn't work on my setup" issue reveals an assumption i made about how systems work.</p>
<p>i can't test every environment. but i can make kaneo more resilient:</p>
<ul>
<li>better error messages</li>
<li>clearer logs</li>
<li>more graceful failures</li>
</ul>
<p>the people running kaneo on weird setups? they're often the most helpful. they understand their environment. they provide detailed logs. they test fixes.</p>
<p>we figure it out together.</p>
<h2 id="keeping-documentation-alive">keeping documentation alive</h2>
<p>documentation is never finished. every feature needs docs. every bug fix might need docs. every question reveals a gap in docs.</p>
<p>i've learned to:</p>
<ul>
<li>update docs in the same pr as code changes</li>
<li>treat "docs are wrong" issues as high priority</li>
<li>appreciate when people submit doc fixes</li>
<li>accept that docs will never be perfect</li>
</ul>
<p>the goal isn't perfect documentation. it's documentation that helps most people most of the time.</p>
<p>and when it doesn't? that's feedback. that's how it gets better.</p>
<h2 id="the-comparison-question">the comparison question</h2>
<blockquote>
<p>"why not just use trello/notion/linear?"</p>
</blockquote>
<p>it's a fair question. those tools are great. they have teams of engineers, designers, product managers. they're polished. they're fast. they're feature-rich.</p>
<p>kaneo is different:</p>
<table>
<thead>
<tr>
<th>them</th>
<th>kaneo</th>
</tr>
</thead>
<tbody>
<tr>
<td>cloud-hosted</td>
<td>self-hosted (your data, your server)</td>
</tr>
<tr>
<td>closed source</td>
<td>open source (you can read every line)</td>
</tr>
<tr>
<td>feature-rich</td>
<td>minimal (does one thing well)</td>
</tr>
<tr>
<td>subscription</td>
<td>free (as in freedom and beer)</td>
</tr>
</tbody>
</table>
<p>it's not better. it's <strong>different.</strong> for some people, that difference matters.</p>
<p>and honestly? building kaneo taught me more than using those tools ever could.</p>
<h2 id="the-emotional-reality">the emotional reality</h2>
<p>maintaining open source is a rollercoaster:</p>
<p>someone stars your repo ‚Üí feels good</p>
<p>someone opens a detailed bug report with logs and reproduction steps ‚Üí feels great</p>
<p>someone says "kaneo saved our team" ‚Üí feels incredible</p>
<p>someone opens an issue titled "this is trash" ‚Üí hurts more than it should</p>
<p>you spend a weekend implementing a requested feature ‚Üí crickets</p>
<p>you fix a small bug ‚Üí three people thank you</p>
<p>you realize you haven't worked on your own roadmap in months ‚Üí exhausting</p>
<p>someone submits a thoughtful pr ‚Üí you're not alone</p>
<p>the highs are high. the lows are low. but the people who use kaneo, who contribute, who care? they make it worth it.</p>
<h2 id="what-i-learned">what i learned</h2>
<h3 id="1-scope-is-everything">1. scope is everything</h3>
<p>kaneo does <strong>one thing:</strong> kanban boards. not project management. not time tracking. not team chat.</p>
<p>every feature you add is a feature you maintain forever.</p>
<p>being clear about scope isn't limiting - it's liberating. it lets you focus. it lets you say no without guilt.</p>
<h3 id="2-automate-everything-you-can">2. automate everything you can</h3>
<pre><code><span><span><span># .github/workflows/ci.yml</span><span>
</span></span></span><span><span><span></span><span>name</span><span>:</span><span> </span><span>CI</span><span>
</span></span></span><span><span><span></span><span>on</span><span>:</span><span> </span><span>[</span><span>push, pull_request]</span><span>
</span></span></span><span><span><span></span><span>jobs</span><span>:</span><span>
</span></span></span><span><span><span>  </span><span>test</span><span>:</span><span>
</span></span></span><span><span><span>    </span>- <span>run</span><span>:</span><span> </span><span>npm test</span><span>
</span></span></span><span><span><span>  </span><span>security</span><span>:</span><span>
</span></span></span><span><span><span>    </span>- <span>run</span><span>:</span><span> </span><span>npm audit</span><span>
</span></span></span><span><span><span>  </span><span>release</span><span>:</span><span>
</span></span></span><span><span><span>    </span>- <span>run</span><span>:</span><span> </span><span>semantic-release</span><span>
</span></span></span></code></pre><p>automation isn't lazy. it's sustainable:</p>
<ul>
<li>automated tests catch bugs before users do</li>
<li>automated releases mean less manual work</li>
<li>automated security scans give peace of mind</li>
<li>automated dependency updates keep things current</li>
</ul>
<p>it frees you to focus on what matters.</p>
<h3 id="3-good-issue-templates-help-everyone">3. good issue templates help everyone</h3>
<p>github issue templates help people provide:</p>
<ul>
<li>system info</li>
<li>error logs</li>
<li>steps to reproduce</li>
</ul>
<p>it's not about gatekeeping. it's about making debugging possible. most people want to help you help them. templates make that easier.</p>
<h3 id="4-saying-no-is-an-act-of-respect">4. saying no is an act of respect</h3>
<p>you can't build everything. saying yes to everything means doing nothing well.</p>
<p>being honest about what you can and can't do respects everyone's time. including yours.</p>
<h3 id="5-users-are-collaborators">5. users are collaborators</h3>
<p>the people using kaneo aren't just users. they're:</p>
<ul>
<li>beta testers finding bugs</li>
<li>documentation editors spotting gaps</li>
<li>feature designers sharing ideas</li>
<li>community builders helping each other</li>
</ul>
<p>they're not demanding. they're engaged. <strong>that's a gift.</strong></p>
<p>when someone opens an issue, they're investing time in making kaneo better. even if the issue is unclear, the intent is good.</p>
<p>patience and kindness aren't just nice. they're necessary.</p>
<h2 id="the-honest-truth">the honest truth</h2>
<p>maintaining an open source, self-hosted project is:</p>
<ul>
<li>more work than building it</li>
<li>different fun than building it</li>
<li>more rewarding than you'd expect</li>
<li>harder than you'd expect</li>
<li>worth it</li>
</ul>
<p>you learn:</p>
<ul>
<li>technical skills (migrations, security, scalability)</li>
<li>people skills (communication, patience, boundaries)</li>
<li>product skills (prioritization, scope, vision)</li>
<li>how to appreciate every contribution</li>
<li>how to build something people actually want</li>
</ul>
<h2 id="my-setup-the-real-one">my setup (the real one)</h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  kaneo infrastructure               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  github                             ‚îÇ
‚îÇ  ‚îú‚îÄ code + issues                   ‚îÇ
‚îÇ  ‚îú‚îÄ actions (ci/cd)                 ‚îÇ
‚îÇ  ‚îî‚îÄ container registry              ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  hetzner ($7/month)                 ‚îÇ
‚îÇ  ‚îî‚îÄ cloud instance                  ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  cloudflare (free)                  ‚îÇ
‚îÇ  ‚îî‚îÄ dns + ddos protection           ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  plausible                          ‚îÇ
‚îÇ  ‚îî‚îÄ privacy-friendly analytics      ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  coffee (priceless)                 ‚îÇ
‚îÇ  ‚îî‚îÄ way too much                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="what-id-tell-past-me">what i'd tell past me</h2>
<p><strong>1. invest in documentation early</strong> - good docs reduce support burden and help people succeed. it's time well spent.</p>
<p><strong>2. automate from day one</strong> - tests, releases, security scans. automation scales. you don't.</p>
<p><strong>3. be clear about scope</strong> - say what your project is AND what it isn't. it helps everyone.</p>
<p><strong>4. migrations are worth the extra effort</strong> - test thoroughly. add rollbacks. write clear upgrade notes. your users trust you with their data.</p>
<p><strong>5. it's okay to be slow</strong> - you're not a company. you're a person. set expectations. take breaks. protect your energy.</p>
<p><strong>6. celebrate your users</strong> - every person using kaneo is amazing. they chose to trust something you built. that's incredible.</p>
<p><strong>7. the community is the product</strong> - the code matters, but the people matter more. invest in both.</p>
<h2 id="the-conclusion">the conclusion</h2>
<p>would i do it again?</p>
<p><strong>absolutely.</strong></p>
<p>kaneo exists because i wanted a simple kanban board that i controlled. but it became something more: a community of people who value privacy, simplicity, and owning their tools.</p>
<p>the maintenance is real work. the migrations are stressful. the support takes time.</p>
<p>but people are using kaneo to:</p>
<ul>
<li>run their businesses</li>
<li>manage their side projects</li>
<li>organize their teams</li>
<li>learn about self-hosting</li>
</ul>
<p>they send thank you messages. they submit thoughtful bug reports. they contribute code. they help each other in discussions.</p>
<p>that's not just cool. that's why i do this.</p>
<hr>
<p><em>kaneo is open source and free forever. check it out: <a href="https://github.com/usekaneo/kaneo">github.com/usekaneo/kaneo</a></em></p>
<p><em>if you're using it, thank you. if you're contributing, you're amazing. if you're thinking about it, the docs are pretty good.</em></p>
<p><em>and if you find a bug? i'll fix it. probably at 11pm. but i'll fix it.</em></p>

                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Someone at YouTube Needs Glasses: The Prophecy Has Been Fulfilled (888 pts)]]></title>
            <link>https://jayd.ml/2025/11/10/someone-at-youtube-needs-glasses-prophecy-fulfilled.html</link>
            <guid>46051340</guid>
            <pubDate>Tue, 25 Nov 2025 22:04:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jayd.ml/2025/11/10/someone-at-youtube-needs-glasses-prophecy-fulfilled.html">https://jayd.ml/2025/11/10/someone-at-youtube-needs-glasses-prophecy-fulfilled.html</a>, See on <a href="https://news.ycombinator.com/item?id=46051340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In my <a href="https://jayd.ml/2025/04/30/someone-at-youtube-needs-glasses.html">recent analysis of YouTube‚Äôs information density </a> I included the results from
an advanced statistical analysis on the number of videos present on the home
page, which projected that around May 2026 there would only be one lonely video 
on the home screen.</p>

<p><img alt="a comedic graph showing two points between 2017 and 2025 and a trend line showing that it will be 1 video in may and 0 in september" src="https://jayd.ml/assets/posts/2025-04-30-someone-at-youtube-needs-glasses/projection.png"></p>

<p>Amazingly, a disgruntled Googler <a href="https://youtu.be/_tZckjQylGU?t=25">leaked a recording of how YouTube‚Äôs PM 
org handled the criticism</a> as it sat at the
<a href="https://news.ycombinator.com/item?id=43846487">top of Hacker News</a> for a whole 
day for some reason.</p>

<p>The net result is that after months of hard work by <del>Gemini</del> YouTube engineers, 
the other day I fired up YouTube on an Apple TV and was graced with this:</p>

<p><img alt="there is only one ad and one video visible" src="https://jayd.ml/assets/posts/2025-11-10-someone-at-youtube-needs-glasses-part-ii/prophecy.jpg"></p>

<p>Let‚Äôs analyze this picture and count the number of videos on the home screen:</p>

<p><img alt="same image as before but comedically labelled with a big red one" src="https://jayd.ml/assets/posts/2025-11-10-someone-at-youtube-needs-glasses-part-ii/annotated.jpg"></p>

<p>Unfortunately the YouTube PM org‚Äôs myopia is accelerating: with this data I now 
project that there will be zero videos on the homescreen around May of 2026 now, 
up from September.</p>

<p><img alt="new datapoint added and a new trendline" src="https://jayd.ml/assets/posts/2025-11-10-someone-at-youtube-needs-glasses-part-ii/updated.jpg"></p>

<p>Apparently <a href="https://en.wikipedia.org/wiki/Poe%27s_law">Poe‚Äôs Law</a> applies to 
Google PMs, satire is dead, and maybe our mandatory NeuraLinks are coming sooner 
than I thought.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google steers Americans looking for health care into "junk insurance" (133 pts)]]></title>
            <link>https://pluralistic.net/2025/11/25/open-season/</link>
            <guid>46051169</guid>
            <pubDate>Tue, 25 Nov 2025 21:45:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2025/11/25/open-season/">https://pluralistic.net/2025/11/25/open-season/</a>, See on <a href="https://news.ycombinator.com/item?id=46051169">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-12006">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
google, aca, obamacare, ad fraud, fraud, junk insurance, health care, monopolies, free luigi, trustbusting, search, enshittification, m4a, health care is a human right, market for lemons, open enrollment, caveat emptor

Summary:
Google steers Americans looking for health care into "junk insurance" ; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books

URL:
https://pluralistic.net/2025/11/25/open-season/

Title:
Pluralistic: Google steers Americans looking for health care into "junk insurance" (25 Nov 2025) open-season

Bullet:
ü©π

Separator:
‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Å‚†Å‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Å‚†Å‚†Ç‚†Ñ‚†Ñ‚†Ç ‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Å‚†Å‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Å‚†Å‚†Ç‚†Ñ‚†Ñ‚†Ç ‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Ç‚†Ñ‚†Ñ‚†Ç‚†Å‚†Å‚†Ç‚†Ñ

Top Sources:
None

--><br>
<a href="https://pluralistic.net/2025/11/25/open-season/"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/25Nov2025.jpg?w=840&amp;ssl=1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#open-enrollment">Google steers Americans looking for health care into "junk insurance" </a>: An enshittified search monopolist meets the worst health care system imaginable.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#retro">Object permanence</a>: Disaster fantasies; "Sea to Sea"; Veronica Belmont on surviving memeification; Email carcinization.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#upcoming">Upcoming appearances</a>: Where to find me.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#recent">Recent appearances</a>: Where I've been.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#latest">Latest books</a>: You keep readin' em, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#upcoming-books">Upcoming books</a>: Like I said, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/11/25/open-season/#bragsheet">Colophon</a>: All the rest.
</li>
</ul>

<hr>
<p><a name="open-enrollment"></a><br>
<img data-recalc-dims="1" decoding="async" alt="An old time hospital ward. In the foreground are a pair of stretcher bearers with a patient. The bearers' heads have been replaced with the poop emoji from the cover of 'Enshittification.' The emoji has been tinted in Google's logo colors. The head of the patient has been replaced with the grinning visage of a 1910s newsie." src="https://i0.wp.com/craphound.com/images/junk-insurance.jpg?w=840&amp;ssl=1"></p>
<h2>Google steers Americans looking for health care into "junk insurance"  (<a href="https://pluralistic.net/2025/11/25/open-season/#open-enrollment">permalink</a>)</h2>
<p>Being "the enshittification guy" means that people expect you to weigh in on every service or platform that has been deliberately worsened to turn a buck. It's an impossible task (and a boring one besides). There's too much of this shit, and it's all so <em>mid</em> ‚Äì a real "banality of enshittification" situation.</p>
<p>So these days, I really only take note of <em>fractally</em> enshittified things, <em>exponentially</em> enshittified things, <em>omni</em>enshittified things. Things like the fact that Google is sending people searching for health care plans to "junk insurance" that take your money and then pretty much just let you <em>die</em>:</p>
<p><a href="https://pluralistic.net/junk-insurance">https://pluralistic.net/junk-insurance</a></p>
<p>"Junk insurance" is a health insurance plan that is designed as a short-term plan that you might use for a couple of days or a week or two, say, if you experience a gap in coverage as you move between two jobs. These plans can exclude coverage for pre-existing conditions and typically exclude niceties like emergency room visits and hospitalization:</p>
<p><a href="https://www.brookings.edu/wp-content/uploads/2020/07/Broader-View_July_2020.pdf">https://www.brookings.edu/wp-content/uploads/2020/07/Broader-View_July_2020.pdf</a></p>
<p>Crucially, these plans do <em>not</em> comply with the Affordable Care Act, which requires comprehensive coverage, and bans exclusions for pre-existing conditions. These plans only exist because of loopholes in the ACA, designed for very small-scale employers or temporary coverage.</p>
<p>The one thing junk insurance does <em>not</em> skimp on is sales and marketing. These plans outbid the rest of the market when it comes to buying Google search ads, meaning that anyone who uses Google to research health insurance will be inundated with ads for these shitty plans. The plans <em>also</em> spend a fortune on "search engine optimization" ‚Äì basically, gaming the Google algorithm ‚Äì so that the <em>non-ad</em> Google results for health insurance are <em>also</em> saturated with these garbage plans.</p>
<p>The plans also staff up boiler-rooms full of silver-tongued high-pressure sales staff who pick up on the first ring and hard-sell you on their plans, deliberately misleading you into locking into their garbage plans.</p>
<p>That's right, <em>locking in</em>. While Obamacare is nominally a "market based" healthcare system (because Medicare For All would be <em>communism</em>), you are only allowed to change vendors twice per year, during "open enrollment," these narrow biannual windows in which you get to "vote with your wallet" against a plan that has screwed you over and/or endangered your life.</p>
<p>Which means that if a fast-talking salesdroid from a junk insurance company can trick you into signing up for a garbage plan that will leave you bankrupt and/or dead if you have a major health crisis, you are stuck for at least six months in that trap, and won't escape without first handing over thousands of dollars to that scumbag's boss.</p>
<p>Amazingly enough, these aren't even the worst kinds of garbage health plans that you can buy in America: those would be the religious "health share" programs that sleazy evangelical "entrepreneurs" suck their co-religionists into, which cost the world and leave you high and dry when you or your kids get hurt or sick:</p>
<p><a href="https://armandalegshow.com/episode/is-it-ever-appropriate-to-fudge-a-little/">https://armandalegshow.com/episode/is-it-ever-appropriate-to-fudge-a-little/</a></p>
<p>The fact that there are <em>multiple kinds</em> of scam health insurance in America, in which companies are legally permitted to take your money and then deny you care (even more than the "non-scam" insurance plans do) shows you the problem with turning health into a market. "Caveat emptor" may make sense when you're buying a used blender at a yard-sale. Apply it to the system that's supposed to take care of you if you're diagnosed with cancer, hit by a bus, or develop eclampsia, and it's a literally fatal system.</p>
<p>This is just one of the ways in which the uniparty is so terrible for Americans. The Republicans want to swap out shitty regulated for-profit health insurance with disastrous unregulated for-profit health insurance, and then give you a couple thousand bucks to yolo on a plan that seems OK to you:</p>
<p><a href="https://www.cnbc.com/2025/11/24/republicans-push-obamacare-tax-credit-alternatives-as-deadline-looms.html">https://www.cnbc.com/2025/11/24/republicans-push-obamacare-tax-credit-alternatives-as-deadline-looms.html</a></p>
<p>This is like letting Fanduel run your country's health system: everyday people are expected to place fifty-way parlay bets on their health, juggling exclusions, co-pays, deductibles, and network coverage in their head. Bet wrong, and you go bankrupt (if you're lucky), or just <em>die</em> (if you're not).</p>
<p>Democrats, meanwhile, want to maintain the (garbage) status quo (because Medicare for All is communism), and they'll shut down the government to make it clear that they want this. But then they'll capitulate, because they want it, but not <em>that</em> badly.</p>
<p>But like I say, America is an Enshittification Nation, and I don't have time or interest for cataloging mere unienshittificatory aspects of life here. To preserve my sanity and discretionary time, I must limit myself to documenting the <em>omni</em>enshittificatory scams that threaten us from every angle at once.</p>
<p>Which brings me back to Google. Without Google, these junk insurance scams would be confined to the margins. They'd have to resort to pyramid selling, or hand-lettered roadside signs, or undisclosed paid plugs in religious/far-right newsletters.</p>
<p>But because Google has utterly succumbed to enshittification, and because Google has an illegal monopoly ‚Äì a 90% market share ‚Äì that it maintains by bribing competitors like Apple to stay out of the search market, junk insurance scams can make bank ‚Äì and ruin Americans' lives wholesale ‚Äì by either tricking or paying Google to push junk insurance on unsuspecting searchers.</p>
<p>This isn't merely a case of Google losing the SEO and spam wars to shady operators. As we learned in last year's antitrust case (where Google was convicted of operating an illegal search monopoly), Google <em>deliberately</em> worsened its search results, in order to force you to search multiple times (and see multiple screens full of ads) as a way to goose search revenue:</p>
<p><a href="https://pluralistic.net/2024/04/24/naming-names/#prabhakar-raghavan">https://pluralistic.net/2024/04/24/naming-names/#prabhakar-raghavan</a></p>
<p>Google didn't just lose that one antitrust case, either. It lost <em>three</em> cases, as three federal judges determined that Google secured and maintains an illegal monopoly that allows it to control the single most important funnel for knowledge and truth for the majority of people on Earth. The company whose mission is to "organize the world's information and make it universally accessible and useful," now serves slop, ads, spam and scams because its customers have nowhere to go, so why bother spending money making search <em>good</em> (especially when there's money to be made from <em>bad</em> search results)?</p>
<p>Google isn't just too big to fail, it's also too big to jail. One of the judges who found Google guilty of maintaining an illegal monopoly decided <em>not to punish them for it</em>, and to allow them to continue bribing Apple to stay out of the search market, because (I'm not making this up), without that $20b+ annual bribe, Apple might not be able to afford to make cool new iPhone features:</p>
<p><a href="https://pluralistic.net/2025/09/03/unpunishing-process/#fucking-shit-goddammit-fuck">https://pluralistic.net/2025/09/03/unpunishing-process/#fucking-shit-goddammit-fuck</a></p>
<p>Once a company is too big to fail and too big to jail, it becomes too big to <em>care</em>. Google <em>could prevent slop, spam and scams from overrunning its results (and putting its users lives and fortunes at risk), it just *chooses</em> not to:</p>
<p><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#kagi">https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#kagi</a></p>
<p>Google is the internet's absentee landlord. Anyone who can make a buck by scamming you can either pay Google to help, or trick Google into helping, or ‚Äì as is the case with junk insurance ‚Äì both:</p>
<p><a href="https://pluralistic.net/2025/07/15/inhuman-gigapede/#coprophagic-ai">https://pluralistic.net/2025/07/15/inhuman-gigapede/#coprophagic-ai</a></p>
<p>America has the world's stupidest health care system, an industry that has grown wildly profitable by charging Americans the highest rates in the rich world, while delivering the worst health outcomes in the rich world, while slashing health workers' pay and eroding their working conditions.</p>
<p>It's omnienshittified, a partnership between the enshittified search giant and the shittiest parts of the totally enshittified health industry.</p>
<p>It's also a reminder of what we stand to gain when we finally smash Google and break it up: disciplining our search industry will make it competitive, regulatable, and force it to side with the public against all kinds of scammers. Junk insurance should be banned, but even if we just end the junk insurance industry's ability to pay the world's only major search engine to help it kill us, that would be a huge step forward.</p>
<hr>

<h2 heds="0">Hey look at this (<a href="https://pluralistic.net/2025/11/25/open-season/#linkdump">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Nvidia‚Äôs ‚ÄòI‚Äôm Not Enron‚Äô memo has people asking a lot of questions already answered by that memo <a href="https://www.theverge.com/business/828047/nvidia-enron-conspiracy-accounting">https://www.theverge.com/business/828047/nvidia-enron-conspiracy-accounting</a>
</li>
<li>
<p>How Black Friday Loyalty Programs Rip Off Shoppers <a href="https://economicpopulist.substack.com/p/how-black-friday-loyalty-programs">https://economicpopulist.substack.com/p/how-black-friday-loyalty-programs</a></p>
</li>
<li>
<p>The Hater's Guide To NVIDIA <a href="https://www.wheresyoured.at/the-haters-guide-to-nvidia/">https://www.wheresyoured.at/the-haters-guide-to-nvidia/</a></p>
</li>
<li>
<p>GrapheneOS migrates server infrastructure from France amid police intimidation claims <a href="https://www.privacyguides.org/news/2025/11/22/grapheneos-migrates-server-infrastructure-from-france-amid-police-intimidation-claims/">https://www.privacyguides.org/news/2025/11/22/grapheneos-migrates-server-infrastructure-from-france-amid-police-intimidation-claims/</a></p>
</li>
<li>
<p>Competition Commissioner Boswell calls it quits early <a href="https://www.donotpassgo.ca/p/competition-commissioner-matthew">https://www.donotpassgo.ca/p/competition-commissioner-matthew</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A shelf of leatherbound history books with a gilt-stamped series title, 'The World's Famous Events.'" src="https://i0.wp.com/craphound.com/images/worlds-famous-events.png?w=840&amp;ssl=1"></p>
<h2 heds="0">Object permanence (<a href="https://pluralistic.net/2025/11/25/open-season/#retro">permalink</a>)</h2>
<p>#20yrsago Solar utility pole: streetlight, WiFi, CCTV and charger <a href="https://web.archive.org/web/20060508050552/http://www.starsightproject.com/en/africa/index.php?option=com_content&amp;amp;task=view&amp;amp;id=12&amp;amp;Itemid=52">https://web.archive.org/web/20060508050552/http://www.starsightproject.com/en/africa/index.php?option=com_content&amp;amp;task=view&amp;amp;id=12&amp;amp;Itemid=52</a></p>
<p>#20yrsago Sony rootkit recall makes The Onion <a href="https://web.archive.org/web/20051126015022/http://www.theonion.com/content/node/42988">https://web.archive.org/web/20051126015022/http://www.theonion.com/content/node/42988</a></p>
<p>#15yrsago Menstruating woman subjected to TSA grope because panty-liner obscured her vulva on pornoscanner <a href="https://blog.gladrags.com/2010/11/24/tsa-groin-searches-menstruating-woman/">https://blog.gladrags.com/2010/11/24/tsa-groin-searches-menstruating-woman/</a></p>
<p>#15yrsago Set to Sea: moving and beautiful graphic novel about a poet who becomes an involuntary sailor <a href="https://memex.craphound.com/2010/11/24/set-to-sea-moving-and-beautiful-graphic-novel-about-a-poet-who-becomes-an-involuntary-sailor/">https://memex.craphound.com/2010/11/24/set-to-sea-moving-and-beautiful-graphic-novel-about-a-poet-who-becomes-an-involuntary-sailor/</a></p>
<p>#10yrsago Cultural appropriation? Hindu nationalists used yoga as an anti-colonialist export <a href="https://web.archive.org/web/20151124030935/http://www.slate.com/articles/double_x/doublex/2015/11/university_canceled_yoga_class_no_it_s_not_cultural_appropriation_to_practice.html">https://web.archive.org/web/20151124030935/http://www.slate.com/articles/double_x/doublex/2015/11/university_canceled_yoga_class_no_it_s_not_cultural_appropriation_to_practice.html</a></p>
<p>#10yrsago Leaked recording: pollution lobbyists discuss exploiting Syrian refugee crisis <a href="https://theintercept.com/2015/11/24/lobbyists-refugee-crisis/">https://theintercept.com/2015/11/24/lobbyists-refugee-crisis/</a></p>
<p>#10yrsago Dell apologizes for preinstalling bogus root-certificate on computers <a href="https://arstechnica.com/information-technology/2015/11/dell-apologizes-for-https-certificate-fiasco-provides-removal-tool/">https://arstechnica.com/information-technology/2015/11/dell-apologizes-for-https-certificate-fiasco-provides-removal-tool/</a></p>
<p>#10yrsago Veronica Belmont on being overtaken by a meme <a href="https://www.youtube.com/watch?v=bTThblbbnkM">https://www.youtube.com/watch?v=bTThblbbnkM</a></p>
<p>#10yrsago J Edgar Hoover was angry that the Boy Scouts didn‚Äôt thank him effusively enough <a href="https://www.muckrock.com/news/archives/2015/nov/24/j-edgar-hoover-insults/">https://www.muckrock.com/news/archives/2015/nov/24/j-edgar-hoover-insults/</a></p>
<p>#10yrsago WTO rules against US dolphin-safe tuna labels because they‚Äôre unfair to Mexican fisheries <a href="https://theintercept.com/2015/11/24/wto-ruling-on-dolphin-safe-tuna-labeling-illustrates-supremacy-of-trade-agreements/">https://theintercept.com/2015/11/24/wto-ruling-on-dolphin-safe-tuna-labeling-illustrates-supremacy-of-trade-agreements/</a></p>
<p>#10yrsago Shamrock shake: Pfizer‚Äôs Irish ‚Äúunpatriotic loophole‚Äù ducks US taxes <a href="https://arstechnica.com/science/2015/11/with-160-billion-merger-pfizer-moves-to-ireland-and-dodges-taxes/">https://arstechnica.com/science/2015/11/with-160-billion-merger-pfizer-moves-to-ireland-and-dodges-taxes/</a></p>
<p>#5yrsago Talking interop on EFF's podcast <a href="https://pluralistic.net/2020/11/24/zawinskiian-carcination/#comcom">https://pluralistic.net/2020/11/24/zawinskiian-carcination/#comcom</a></p>
<p>#5yrsago Cheap Chinese routers riddled with backdoors <a href="https://pluralistic.net/2020/11/24/zawinskiian-carcination/#jetstream">https://pluralistic.net/2020/11/24/zawinskiian-carcination/#jetstream</a></p>
<p>#5yrsago Emailifaction is digital carcinization <a href="https://pluralistic.net/2020/11/24/zawinskiian-carcination/#carcinization">https://pluralistic.net/2020/11/24/zawinskiian-carcination/#carcinization</a></p>
<p>#5yrsago Saudi Aramco is gushing debt <a href="https://pluralistic.net/2020/11/24/zawinskiian-carcination/#gusher">https://pluralistic.net/2020/11/24/zawinskiian-carcination/#gusher</a></p>
<p>#5yrsago Sci-Fi Genre <a href="https://pluralistic.net/2020/11/24/zawinskiian-carcination/#asl">https://pluralistic.net/2020/11/24/zawinskiian-carcination/#asl</a></p>
<p>#1yrago The far right grows through "disaster fantasies" <a href="https://pluralistic.net/2024/11/24/mall-ninja-prophecy/#mano-a-mano">https://pluralistic.net/2024/11/24/mall-ninja-prophecy/#mano-a-mano</a></p>
<hr>

<h2 heds="0">Upcoming appearances (<a href="https://pluralistic.net/2025/11/25/open-season/#upcoming">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" alt="A photo of me onstage, giving a speech, pounding the podium." src="https://i0.wp.com/craphound.com/images/appearances2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Toronto: Jailbreaking Canada (OCAD U), Nov 27<br>
<a href="https://www.ocadu.ca/events-and-exhibitions/jailbreaking-canada">https://www.ocadu.ca/events-and-exhibitions/jailbreaking-canada</a>
</li>
<li>
<p>San Diego: Enshittification at the Mission Hills Branch Library, Dec 1<br>
<a href="https://libraryfoundationsd.org/events/doctorow">https://libraryfoundationsd.org/events/doctorow</a></p>
</li>
<li>
<p>Seattle: Neuroscience, AI and Society (University of Washington), Dec 4<br>
<a href="https://www.eventbrite.com/e/neuroscience-ai-and-society-cory-doctorow-tickets-1735371255139">https://www.eventbrite.com/e/neuroscience-ai-and-society-cory-doctorow-tickets-1735371255139</a></p>
</li>
<li>
<p>Virtual: Poetic Technologies with Brian Eno (David Graeber Institute), Dec 8<br>
<a href="https://davidgraeber.institute/poetic-technologies-with-cory-doctorow-and-brian-eno/">https://davidgraeber.institute/poetic-technologies-with-cory-doctorow-and-brian-eno/</a></p>
</li>
<li>
<p>Madison, CT: Enshittification at RJ Julia, Dec 8<br>
<a href="https://rjjulia.com/event/2025-12-08/cory-doctorow-enshittification">https://rjjulia.com/event/2025-12-08/cory-doctorow-enshittification</a></p>
</li>
<li>
<p>Hamburg: Chaos Communications Congress, Dec 27-30<br>
<a href="https://events.ccc.de/congress/2025/infos/index.html">https://events.ccc.de/congress/2025/infos/index.html</a></p>
</li>
</ul>
<hr>
<p><a name="recent"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A screenshot of me at my desk, doing a livecast." src="https://i0.wp.com/craphound.com/images/recentappearances2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Recent appearances (<a href="https://pluralistic.net/2025/11/25/open-season/#recent">permalink</a>)</h2>
<ul>
<li>Enshittification Nation (The Lever)<br>
<a href="https://www.levernews.com/enshittification-nation/">https://www.levernews.com/enshittification-nation/</a>
</li>
<li>
<p>Enshittification with Oh God What Now<br>
<a href="https://castbox.fm/episode/Why-Tech-Sucks-%E2%80%93%C2%A0Cory-Doctorow-on-Enshittification-and-how-to-fix-it-id4634015-id876127534">https://castbox.fm/episode/Why-Tech-Sucks-%E2%80%93%C2%A0Cory-Doctorow-on-Enshittification-and-how-to-fix-it-id4634015-id876127534</a></p>
</li>
<li>
<p>Enshittification with The Lede (New Lines Magazine)<br>
<a href="https://newlinesmag.com/podcast/why-the-internet-got-bad-and-how-to-fix-it/">https://newlinesmag.com/podcast/why-the-internet-got-bad-and-how-to-fix-it/</a></p>
</li>
<li>
<p>Today in Focus (The Guardian)<br>
<a href="https://www.theguardian.com/news/audio/2025/nov/24/enshittification-how-we-got-the-internet-no-one-asked-for-podcast">https://www.theguardian.com/news/audio/2025/nov/24/enshittification-how-we-got-the-internet-no-one-asked-for-podcast</a></p>
</li>
<li>
<p>Enshittification with Vass Bednar (Vancouver Public Library)<br>
<a href="https://www.crowdcast.io/c/0wzs9iu1q225">https://www.crowdcast.io/c/0wzs9iu1q225</a></p>
</li>
</ul>
<hr>
<p><a name="latest"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A grid of my books with Will Stahle covers.." src="https://i0.wp.com/craphound.com/images/recent.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Latest books (<a href="https://pluralistic.net/2025/11/25/open-season/#latest">permalink</a>)</h2>
<ul>
<li>"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025
</li>
<li>
<p>"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025<br>
<a href="https://us.macmillan.com/books/9780374619329/enshittification/">https://us.macmillan.com/books/9780374619329/enshittification/</a></p>
</li>
<li>
<p>"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (<a href="https://us.macmillan.com/books/9781250865908/picksandshovels">https://us.macmillan.com/books/9781250865908/picksandshovels</a>).</p>
</li>
<li>
<p>"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href="http://the-bezzle.org/">the-bezzle.org</a>).</p>
</li>
<li>
<p>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>).</p>
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
</ul>
<hr>
<p><a name="upcoming-books"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A cardboard book box with the Macmillan logo." src="https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Upcoming books (<a href="https://pluralistic.net/2025/11/25/open-season/#upcoming-books">permalink</a>)</h2>
<ul>
<li>"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026
</li>
<li>
<p>"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026</p>
</li>
<li>
<p>"The Memex Method," Farrar, Straus, Giroux, 2026</p>
</li>
<li>
<p>"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, 2026</p>
</li>
</ul>
<hr>
<p><a name="bragsheet"></a><br>
<img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/colophon2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Colophon (<a href="https://pluralistic.net/2025/11/25/open-season/#bragsheet">permalink</a>)</h2>
<p>Today's top sources:</p>
<p><b>Currently writing: </b></p>
<ul>
<li>"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. FIRST DRAFT COMPLETE AND SUBMITTED.
</li>
<li>
<p>A Little Brother short story about DIY insulin PLANNING</p>
</li>
</ul>
<hr>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1"></p>
<p>This work ‚Äì excluding any serialized fiction ‚Äì is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>
<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>
<p>ISSN: 3066-764X</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
    </channel>
</rss>