<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 04 Apr 2025 06:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Celebrate 50 years of Microsoft with the company's original source code (282 pts)]]></title>
            <link>https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code</link>
            <guid>43575884</guid>
            <pubDate>Thu, 03 Apr 2025 21:49:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code">https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code</a>, See on <a href="https://news.ycombinator.com/item?id=43575884">Hacker News</a></p>
Couldn't get https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI cheats: Why you didn't notice your teammate was cheating (123 pts)]]></title>
            <link>https://niila.fi/en/ai-cheats/</link>
            <guid>43574929</guid>
            <pubDate>Thu, 03 Apr 2025 20:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://niila.fi/en/ai-cheats/">https://niila.fi/en/ai-cheats/</a>, See on <a href="https://news.ycombinator.com/item?id=43574929">Hacker News</a></p>
Couldn't get https://niila.fi/en/ai-cheats/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Senior Developer Skills in the AI Age (248 pts)]]></title>
            <link>https://manuel.kiessling.net/2025/03/31/how-seasoned-developers-can-achieve-great-results-with-ai-coding-agents/</link>
            <guid>43573755</guid>
            <pubDate>Thu, 03 Apr 2025 18:47:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://manuel.kiessling.net/2025/03/31/how-seasoned-developers-can-achieve-great-results-with-ai-coding-agents/">https://manuel.kiessling.net/2025/03/31/how-seasoned-developers-can-achieve-great-results-with-ai-coding-agents/</a>, See on <a href="https://news.ycombinator.com/item?id=43573755">Hacker News</a></p>
<div id="readability-page-1" class="page"><article lang="en">
    

    
    

    <div>
  

<h2 id="introduction">Introduction</h2>

<p>Over the past few months, I have been experimenting with AI-powered coding tools in both my personal and professional projects. The experience has been overwhelmingly positive, both for me and my team of software engineers at work.</p>

<p>We’ve achieved better results in less time, and in many cases, the quality of our output has significantly improved.</p>

<p>Interestingly, this experience contrasts with the feedback I’ve received from some fellow software developers who report that AI tools aren’t working well for them.</p>

<p>I’m now convinced that AI-assisted software development has the potential to elevate our craft to the next level in terms of productivity. This is why I believe our community should embrace it sooner rather than later — but like all tools and practices, with the right perspective and a measured approach.</p>

<p>My motivation for sharing these experiences and the best practices I’ve identified is to help move the needle forward in terms of AI adoption within the broader software development community — even if realistically, it’s only by some micrometers.</p>

<h2 id="the-current-state-of-ai-coding">The Current State of AI Coding</h2>

<h2 id="beyond-vibe-coding">Beyond “Vibe Coding”</h2>

<p>My Twitter feed suggests that AI-powered coding tools are already generating significant buzz in a specific niche: non-professional developers who are having great fun building software products. For them, these tools primarily serve as enablers, allowing them to tackle projects they might never have considered without such assistance.</p>

<p>More power to them — it’s exciting to witness their journey of struggles and breakthroughs.</p>

<p>However, this represents just one segment of potential users, and certainly not the only group for whom these tools can provide immense value.</p>

<h2 id="the-senior-developer-advantage">The Senior Developer Advantage</h2>

<p>My current conclusion, though preliminary in this rapidly evolving field, is that not only can seasoned developers benefit from this technology — they are actually in the optimal position to harness its power.</p>

<p><strong>Here’s the fascinating part: The very experience and accumulated know-how in software engineering and project management — which might seem obsolete in the age of AI — are precisely what enable the most effective use of these tools.</strong></p>

<h2 id="the-ai-assistant-a-senior-coder-junior-colleague">The AI Assistant: A Senior Coder, Junior Colleague</h2>

<p>While I haven’t found the perfect metaphor for these LLM-based programming agents in an AI-assisted coding setup, I currently think of them as “an absolute senior when it comes to programming knowledge, but an absolute junior when it comes to architectural oversight <em>in your specific context</em>.”</p>

<p>This means that <strong>it takes some strategic effort to make them save you a tremendous amount of work</strong>.</p>

<p>And who better to invest that effort in the right way than a senior software engineer?</p>

<p>As we’ll see, while we’re dealing with cutting-edge technology, it’s the time-tested, traditional practices and tools that enable us to wield this new capability most effectively.</p>

<h2 id="key-areas-of-expertise">Key Areas of Expertise</h2>

<p>I’ve identified three critical areas of expertise needed when working with AI-assisted coding:</p>

<ul>
<li><strong>Well-structured Requirements</strong></li>
<li><strong>Tool-based Guard Rails</strong></li>
<li><strong>File-based Keyframing</strong></li>
</ul>

<p>Before diving into these concepts, let me share some real-world examples of how I’ve used AI in my projects.</p>

<p>I will give examples for two categories of projects: green-field and brown-field.</p>

<p>For both categories, I’ll focus on cases where AI handled the entire implementation, or very nearly so.</p>

<p>While I do sometimes use AI as a “better autocomplete” or as a chat-only companion for general discussions, this article focuses on what I call the “real deal” — where AI tooling operates in an agentic mode and handles all the heavy lifting.</p>

<h2 id="development-environment">Development Environment</h2>

<p>My current tool of choice for these projects is <a href="https://www.cursor.com/" target="_blank">Cursor</a>, powered by Anthropic’s Claude Sonnet 3.7 model. For optimal developer experience, I prefer not to manually copy-paste generated code into my codebase and need the AI assistant to execute commands directly on my local command line. Cursor provides this capability, and I expect similar products would yield comparable results.</p>

<h2 id="example-1-platform-problem-monitoring">Example 1: Platform Problem Monitoring</h2>

<p>This setup, combined with the expertise areas I’ll discuss, enabled me to create and fully implement a green-field application: <em>Platform Problem Monitoring</em>. You can find the source code at <a href="https://github.com/dx-tooling/platform-problem-monitoring-core" target="_blank">https://github.com/dx-tooling/platform-problem-monitoring-core</a>.</p>

<p>The application connects hourly to our ELK stack’s Elasticsearch server, reads the latest error messages, and sends us a well-formatted email summarizing the current state of problems on our web platform:</p>

<figure><a href="https://manuel.kiessling.net/images/2025-03-09-new-project-platform-problem-monitoring-sample-mail-report.png">
    
        <img src="https://manuel.kiessling.net/images/2025-03-09-new-project-platform-problem-monitoring-sample-mail-report.png" alt="Platform Problem Monitoring Email Report">
    
    
</a></figure>

<p>For more details, check out the <a href="https://manuel.kiessling.net/2025/03/09/new-project-plaform-problem-monitoring/">“New project: Platform Problem Monitoring”</a> post.</p>

<p><strong>What makes this example particularly interesting is that the entire source code was written by Cursor/Claude, without any manual coding from me.</strong></p>

<p>This is especially noteworthy because I don’t actually know Python. Yes, with 25+ years of software development experience, I could probably write a few lines of working Python code if pressed — but I don’t truly <em>know</em> the language. I lack the muscle memory and intimate knowledge of its conventions and best practices.</p>

<p>However, my broad understanding of software architecture, engineering best practices, system operations, and what makes for excellent software projects made this development process remarkably smooth.</p>

<h2 id="example-2-process-management-ui-integration">Example 2: Process Management UI Integration</h2>

<p>While I can’t share the source code for this brown-field example, it demonstrates a different yet equally valuable use case:</p>

<p>I had a legacy PHP/Symfony application with a “backend-only” process coordination feature — think service classes, enums, Doctrine entities, and CLI commands running via cron. While functional, it lacked a user interface.</p>

<p>Though not strictly necessary, having a web-based view of this process coordination feature would be valuable — allowing users to monitor current operations, investigate failures, and manage process execution.</p>

<p>For strategic reasons, I wanted this UI to live in our newer application — the one with the better-designed codebase, more recent framework versions, improved testing capabilities, and superior frontend architecture with a comprehensive living styleguide.</p>

<p>The task involved:</p>

<ul>
<li>Integrating the legacy and new applications via HTTP API</li>
<li>Implementing data transfer between systems</li>
<li>Creating an intuitive UI that aligned with our design system</li>
<li>Building a generalized API client in our shared Symfony bundle</li>
</ul>

<p><strong>Once again, the AI agent implemented this entire feature without requiring me to write any code manually.</strong></p>

<h2 id="key-insights-from-both-projects">Key Insights from Both Projects</h2>

<p>These examples highlight two distinct advantages of AI assistance:
1. In the green-field project, I could create an application despite unfamiliarity with the tech stack
2. In the brown-field project, I achieved results much faster — particularly valuable since UI development isn’t my strong suit</p>

<p>This was when terms like “game-changing” started to feel appropriate, and I began to recognize this technology’s significance for both personal and team productivity.</p>

<h2 id="the-keys-to-successful-ai-collaboration">The Keys to Successful AI Collaboration</h2>

<p>Let’s examine the techniques I employ to ensure productive AI coding sessions that consistently deliver successful results.</p>

<h2 id="the-investment-return-principle">The Investment-Return Principle</h2>

<p>As mentioned earlier, achieving significant time savings with AI requires some upfront investment. This parallels managing talented but junior developers — you can’t simply tell them to “build X” and expect optimal results. You need to invest time in setting them up for success.</p>

<h2 id="well-structured-requirements">Well-Structured Requirements</h2>

<p>The foundation of any successful AI coding session is a comprehensive requirements document. For the Platform Problem Monitoring project, I created this document before starting: <a href="https://github.com/dx-tooling/platform-problem-monitoring-core/blob/main/docs/REQUIREMENTS.md" target="_blank">REQUIREMENTS.md</a>.</p>

<p>At 371 lines, it’s substantial, but more importantly, it follows a clear hierarchical structure:</p>

<ul>
<li><em>Top-level: Core requirements in one line</em></li>
<li><em>High-level: Use case and motivation</em></li>
<li><em>Mid-level: Process and work mechanisms</em></li>
<li><em>Mid-level: Architecture, tech stack, and constraints</em></li>
<li><em>Low-level: Detailed process steps</em></li>
</ul>

<p>The low-level section breaks down the application’s operation into 12 distinct steps, each with clearly defined inputs, outputs, and side effects.</p>

<p>Just as this structure guides human developers effectively, it provides the AI assistant with the framework it needs to deliver solid results.</p>

<p>You might think creating such documentation is excessive work. You’re right — it is. But it’s a necessary investment for a successful outcome.</p>

<p>One of my favorite software development maxims is:
<br><strong><em>“Six weeks of implementation easily save you two hours of planning”</em></strong></p>

<p>The sarcasm highlights an essential truth: the implementation phase is the most expensive place to compensate for inadequate planning.</p>

<p>I always encourage my team to start at the whiteboard with their product manager, not at the keyboard. This principle applies equally well to AI collaboration.</p>

<h3 id="the-play-it-back-technique">The “Play It Back” Technique</h3>

<p>A particularly effective practice with AI is what I call “play it back”: I start each session in “Ask” mode, requesting the AI to:</p>

<ol>
<li>Summarize the requirements in its own words</li>
<li>Create an action plan</li>
<li>Ask clarifying questions</li>
</ol>

<p>Only after this validation do I switch to “Agent” mode and begin implementation.</p>



<p>While requirements define the destination, tool-based guard rails ensure we take the most direct route there.</p>

<p>Consider how we value real-time feedback systems in development. Nothing is worse than discovering a missing null check through a customer service complaint weeks after launch.</p>

<p>Static analysis tools that catch issues during development are invaluable — and they’re just as valuable for AI agents.</p>

<p>This is why I prioritize setting up comprehensive quality tools before starting AI sessions. The <a href="https://github.com/dx-tooling/platform-problem-monitoring-core/blob/main/Makefile" target="_blank">Makefile</a> for our Python project demonstrates this approach:</p>

<ul>
<li>Code formatting with black and isort</li>
<li>Linting with ruff</li>
<li>Type checking with mypy</li>
<li>Security analysis with bandit</li>
<li>Comprehensive test suite</li>
</ul>

<p>The AI understands these tools and uses them effectively. When a change breaks type checking, it automatically adjusts its implementation to maintain compliance.</p>

<p>I also ensure the AI can validate the functional aspects of its work. For API implementations, I provide curl commands so it can test its endpoints directly. Watching the AI use and refine its own code is remarkable.</p>

<h2 id="file-based-keyframing">File-Based Keyframing</h2>

<p>While AI agents excel at creative problem-solving, sometimes we need to constrain that creativity, especially regarding code organization. This is where file-based keyframing comes in.</p>

<p>The technique borrows from animation studios’ workflow, where master animators create key frames — crucial moments in an animation sequence — while junior animators fill in the intermediate frames. This approach maintains quality while optimizing resource usage.</p>

<figure>
    
        <img src="https://manuel.kiessling.net/images/2025-03-31-how-seasoned-developers-can-achieve-great-results-with-ai-coding-agents/keyframing_animation.jpg" alt="Platform Problem Monitoring Email Report">
    
    
</figure>

<p><sub>Through keyframes, the master animator can ensure a certain style and the occurence of specific animation steps, without the need to create the full animation herself.</sub></p>

<h3 id="practical-application">Practical Application</h3>

<p>When working with AI, I create “empty hull” files in the codebase before editing begins. For example, in our brown-field project, the AI needed to implement various components:</p>

<ul>
<li>an API endpoint</li>
<li>an API client</li>
<li>a Controller class</li>
<li>a Twig template</li>
</ul>

<p>and so on.</p>

<p>Instead of letting the AI decide file locations and names, or specifying these details in prompts, I create minimal stub files:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>declare</span>(<span>strict_types</span><span>=</span><span>1</span>);

<span>namespace</span> <span>App\HighVolumeProcessManagement\Presentation\Service</span>;

<span>readonly</span> <span>class</span> <span>HighVolumeProcessManagementPresentationService</span>
{

}
</code></pre></div>
<p>For controllers, I might include a small amount of essential details like the route name:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>declare</span>(<span>strict_types</span><span>=</span><span>1</span>);

<span>namespace</span> <span>App\HighVolumeProcessManagement\Presentation\Controller</span>;

<span>use</span> <span>Symfony\Bundle\FrameworkBundle\Controller\AbstractController</span>;
<span>use</span> <span>Symfony\Component\HttpFoundation\Response</span>;
<span>use</span> <span>Symfony\Component\Routing\Attribute\Route</span>;

<span>class</span> <span>HighVolumeProcessManagementController</span> <span>extends</span> <span>AbstractController</span>
{
    <span>#[Route(
</span><span></span>        <span>'/volumen-prozesse/übersicht'</span>,
        <span>name</span><span>:</span> <span>'high_volume_process_management.presentation.controller.show_dashboard'</span>,
        <span>methods</span><span>:</span> [<span>'GET'</span>]
    )]
    <span>public</span> <span>function</span> <span>showDashboardAction</span>()<span>:</span> <span>Response</span>
    {

    }
}
</code></pre></div>
<p>These stubs might seem minimal, but they’re incredibly effective. They provide the AI with crucial context about:</p>

<ul>
<li>File organization</li>
<li>Namespace structure</li>
<li>Naming conventions</li>
<li>Code patterns</li>
</ul>

<p>This approach highlights another timeless practice that remains vital in the age of AI: Naming things.</p>

<p>Because after all, the AI models at the heart of tools like Cursor are Large-Language Models — they work on text, and text with meaning and intention is crucial for a great coding experience.</p>

<h2 id="putting-it-all-together-a-real-world-example">Putting It All Together: A Real-World Example</h2>

<p>To demonstrate how these principles work together in practice, let me share a recent project where I applied all three key techniques: well-structured requirements, tool-based guard rails, and file-based keyframing.</p>

<h2 id="the-challenge">The Challenge</h2>

<p>The task was similar to our earlier brown-field example: implementing a UI Dashboard to display subscription contract information from our platform. Here’s what made this project interesting:</p>

<ul>
<li><strong>Existing Backend</strong>: We had a working backend implementation storing all the contract data</li>
<li><strong>Separate Frontend</strong>: The UI needed to live in a different application</li>
<li><strong>Distributed Architecture</strong>: The solution required an HTTP API integration between applications</li>
<li><strong>Shared Components</strong>: Parts of the implementation belonged in a shared library</li>
</ul>

<h2 id="the-initial-prompt">The Initial Prompt</h2>

<p>Below is the actual prompt I used to kickstart this project. As you read through it, notice how it incorporates our three key principles of <strong>well-strcutured requirements</strong>, <strong>tool-based guard rails</strong>, and <strong>file-based keyframing</strong>:</p>

<blockquote>
<p>I need you to implement a read-only web-based user interface that will present some existing db-persisted data in form of a table-like overview.</p>

<p>The data in question is called “contracts”, it’s about some subscription contract information that we hold in our platform.</p>

<p>The feature needs to be implemented within a monorepo that contains multiple codebases. For the feature in question, four codebases play a role:</p>

<ul>
<li><p>A Symfony 5 application in “backend-app”</p></li>

<li><p>A Symfony 7 application in “janus-christophorus”</p></li>

<li><p>A Symfony bundle used by “janus-christophorus”, in folder “janus-shared-bundle”</p></li>

<li><p>Another Symfony bundle used by “janus-christophorus”, in folder “janus-webui-bundle”</p></li>
</ul>

<p>The roles of the codebases are as follows:</p>

<ul>
<li><p>backend-app currently holds the data in question, but does not provide a ui to present the data</p></li>

<li><p>janus-christophorus is meant to provide the UI that will present the data</p></li>

<li><p>janus-shared-bundle hosts, among other things, the API client implementations for API endpoints provided by backend-app; janus-christophorus makes use of these clients to pull data from backend-app</p></li>

<li><p>janus-webui-bundle contains the tailwind setup, css, and Twig templates for the Living Styleguide that applied to the UIs of janus-christophorus.</p></li>
</ul>

<p>Your mission now is to:</p>

<ul>
<li><p>implement the required API endpoints in backend-app that will provide the data to be displayed on the web UI in janus-christophorus; this API will also support the “demo mode” capability of the integration API, which requires a demo data service in the test harness layer of the backend-app implementation to provide fake data if the API client requests it</p></li>

<li><p>implement a matching API client that can be used to read from these new API endpoints</p></li>

<li><p>implement a Presentation layer service class in janus-christophorus that will make use of the new API client</p></li>

<li><p>implement a Presentation layer Controller and Twig template that makes use of the Presentation service to display the information gathered through the API integration</p></li>
</ul>

<p>To prepare this implementation, I have created some “empty hull” files within the different code bases.</p>

<p>Consider the provided contract, user, and jobofferer profile entities to determine what data you need to pull from the MariaDB database (or fake through the demo service) to provide useful information on the API for the UI.</p>

<p>Additionally, I’m providing additional files like those from the styleguide, the ui navigation service, and so on. Also consider the files from other, existing features I have provided as a guideline and inspiration.</p>

<p>The goal of the feature is to provide a UI that allows to quickly gather an overview of the available contracts in the system.</p>

<p>Important note: You can and should use several tools to check your own work.</p>

<p>Each codebase allows you to run the quality tools, which contain PHPStan checks and others. You run them like this:</p>

<p>cd ~/Projects/website/backend-app &amp;&amp; /usr/bin/env bash .dxcli/dxcli.sh quality</p>

<p>cd ~/Projects/website/janus-shared-bundle &amp;&amp; /usr/bin/env bash .dxcli/dxcli.sh quality</p>

<p>cd ~/Projects/website/janus-christophorus &amp;&amp; /usr/bin/env bash .dxcli/dxcli.sh quality</p>

<p>You can request the API endpoint that you will implement like this:</p>

<p>curl -H “Accept: application/json” -H “Content-Type: application/json” “<a href="http://127.0.0.1/_/janus-integration-api/membership/contracts/%22" target="_blank">http://127.0.0.1/_/janus-integration-api/membership/contracts/"</a></p>

<p>You can request the web UI you will implement like this:</p>

<p>curl <a href="http://127.0.0.1/_jc/mitgliedschaftsverwaltung/vertr%C3%A4ge/" target="_blank">http://127.0.0.1/_jc/mitgliedschaftsverwaltung/verträge/</a></p>

<p>Please create an implementation plan and ask any questions that you need to have answered for your mission.</p>

<p>@Contract.php @User.php @Profile.php @JoboffererProfile.php @MembershipContractsApiController.php @DemoDataService.php @AbstractJanusIntegrationApiController.php @MainNavigationPresentationService.php @ContractsDashboardController.php @contracts_list.html.twig @ContractsDashboardPresentationService.php @services.yaml @AbstractBackendAppApiClient.php @BackendAppMembershipContractsApiClient.php @ContractApiDto.php @BackendAppMembershipContractsApiClientInterface.php @ContractsApiDto.php @NothingApiDto.php @janus-webui.css @living_styleguide.html.twig</p>
</blockquote>

<h2 id="conclusion">Conclusion</h2>

<p>The examples and techniques shared here demonstrate that AI coding assistants, when properly guided, can dramatically enhance development productivity. The key to success lies in applying traditional software engineering best practices to this new technology.</p>

<p>By providing well-structured requirements, implementing appropriate guardrails, and using file-based keyframing, we can harness the power of AI while maintaining code quality and architectural integrity. These time-tested practices, and more than anything else, <strong>hard-earned human experience with these practices</strong>, are more valuable than ever in the age of AI-assisted development, and far from obsolete.</p>

</div>

    



  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: GitMCP is an automatic MCP server for every GitHub repo (117 pts)]]></title>
            <link>https://gitmcp.io/</link>
            <guid>43573539</guid>
            <pubDate>Thu, 03 Apr 2025 18:28:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitmcp.io/">https://gitmcp.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43573539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://github.com/idosal/git-mcp" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg><span>GitHub</span></a></p><div id="how-it-works"><div><div><p>github.com/username/repo</p><p>→</p><p><b>gitmcp.io</b>/username/repo</p></div><div><p>username.github.io/repo</p><p>→</p><p>username.<b>gitmcp.io</b>/repo</p></div><p>Simply change the domain from<!-- --> <span>github.com</span> or<!-- --> <span>github.io</span> to<!-- --> <span>gitmcp.io</span> <!-- -->and get instant AI context for any GitHub repository.</p></div><div><div><p>1</p><h3>Create MCP URL</h3><p>Replace<!-- --> <code>github.com</code> <!-- -->with<!-- --> <code>gitmcp.io</code> <!-- -->in any repository URL.</p></div><div><p>2</p><h3>Add to AI Assistant</h3><p>Configure your AI tool to use the GitMCP URL as a custom MCP server.</p></div><div><p>3</p><h3>Enhanced AI Coding</h3><p>Your AI now understands your repository's context for more accurate and helpful responses.</p></div></div></div><section id="github-pages-demo"><div><h2>With Github Pages</h2><p>GitMCP works seamlesslywith <b>GitHub Pages</b>. Here's an example:</p></div><div><p><video controls="" muted="" loop="" playsinline=""><source src="https://gitmcp.io/GitMCP_final.mp4" type="video/mp4">Your browser does not support the video tag.</video></p></div></section><section id="github-repo-demo"><div><h2>A Github Repo</h2><p>GitMCP works with <b>any public GitHub repository</b>. Here's an example:</p></div><div><p><video controls="" muted="" loop="" playsinline=""><source src="https://gitmcp.io/GitMCP_PW.mp4" type="video/mp4">Your browser does not support the video tag.</video></p></div></section><div><div><h2>What is GitMCP?</h2><p>GitMCP creates a dedicated Model Context Protocol (MCP) server for any GitHub project, enabling AI assistants to understand your code in context.</p></div><div><div><h3>Code Understanding</h3><p>AI assistants gain a deep context of the code repo, reading<!-- --> <span>llms.txt</span>,<!-- --> <span>llms-full.txt</span>,<!-- --> <span>readme.md</span> and more, making their responses more accurate and relevant.</p></div><div><h3>Instant Setup</h3><p>No complex configuration needed. Just point to your GitHub repository and connect your AI tools.</p></div><div><h3>Universal Access</h3><p>Works seamlessly with any public GitHub repository and GitHub Pages, making your documentation and code accessible to AI tools.</p></div></div></div><div><h2>Compatible With</h2><p>Works with all popular MCP-compatible AI tools</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Slow Collapse of Critical Thinking in OSINT Due to AI (240 pts)]]></title>
            <link>https://www.dutchosintguy.com/post/the-slow-collapse-of-critical-thinking-in-osint-due-to-ai</link>
            <guid>43573465</guid>
            <pubDate>Thu, 03 Apr 2025 18:21:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dutchosintguy.com/post/the-slow-collapse-of-critical-thinking-in-osint-due-to-ai">https://www.dutchosintguy.com/post/the-slow-collapse-of-critical-thinking-in-osint-due-to-ai</a>, See on <a href="https://news.ycombinator.com/item?id=43573465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr" data-id="content-viewer" data-rce-version="10.123.1" data-hook="post-description"><p dir="auto" id="viewer-foo"><span><em><span>OSINT used to be a thinking game. Now it’s becoming a trusting game and that should terrify you.</span></em></span></p><p dir="auto" id="viewer-qpp1z159"><span><span><span>I’ve seen it firsthand, analysts running solid investigations, then slowly shifting more and more of the thinking to GenAI tools. At first, it’s small. You use ChatGPT to summarise a document or translate a foreign post. Then it’s helping draft your reports. Then it’s generating leads. And eventually, you’re not thinking as critically as you used to. You’re verifying less, questioning less, relying more.</span></span></span></p><p dir="auto" id="viewer-fr8vk162"><span><span><span>We tell ourselves we’re “working smarter.” But somewhere along the way, we stop noticing how much of the actual thinking is being offloaded.</span></span></span></p><p dir="auto" id="viewer-un8o7164"><span><span><span>This isn’t a rant against AI. I use it daily, ChatGPT, Copilot, Claude, Gemini. They’re in my workflow like everyone else’s. But the tradecraft is slipping. Analysts are skipping the hard parts. They’re trusting GenAI to do the heavy cognitive lifting, and it’s changing how we operate at a foundational level.</span></span></span></p><p dir="auto" id="viewer-c8zyy166"><span><span><span>When OSINT becomes too easy, too efficient, too comfortable… you should be worried. Tradecraft isn’t just about speed, it’s about judgment. And judgment doesn’t come from a language model. If we keep going down this path without pushing back, without actively preserving the critical habits that define our profession, we risk becoming operators of automation instead of investigators.</span></span></span></p><p dir="auto" id="viewer-j79fa168"><span><span><span>This blog is a wake-up call. For myself. For anyone working in OSINT. For the people teaching it, and the people just getting started. If we don’t reclaim the thinking side of this game, we’ll lose the game entirely.</span></span></span></p><p data-breakout="normal"><h2 dir="auto" id="viewer-d3sro170"><span><span>The Study That Should Alarm You</span></span></h2></p><p dir="auto" id="viewer-ovikn174"><span><span><span>What they found is a warning shot.</span></span></span></p><p dir="auto" id="viewer-f4w5u176"><span><span><span>The study revealed a clear pattern: the more confidence users had in the AI, the less they thought critically. In contrast, the more confident they were in themselves, the more likely they were to question the output, verify the information, and think deeply about the task.</span></span></span></p><p dir="auto" id="viewer-dtiol178"><span><span><span>Let that sink in: Confidence in AI replaces confidence in self and with it, the thinking disappears.</span></span></span></p><p dir="auto" id="viewer-2ww4x181"><span><span><span>Here’s the punchline:</span></span></span></p><p dir="auto" id="viewer-0jwed183"><span><span><span>High trust in GenAI consistently led to reduced critical thinking and less cognitive effort across the board.</span></span></span></p><p dir="auto" id="viewer-4szfk185"><span><span><span>Participants weren’t lazy. They were experienced professionals. But when the tool responded quickly, confidently, and clearly they stopped doing the hard part. They stopped questioning. Stopped verifying. Stopped applying the mental friction that separates automation from investigation.</span></span></span></p><p dir="auto" id="viewer-1doo6187"><span><span><span>The scary part is that many users still believed they were thinking critically, because GenAI made them feel smart.</span></span></span></p><p dir="auto" id="viewer-yp7yg189"><span><span><span>The researchers saw a new type of behavior emerge:</span></span></span></p><p dir="auto" id="viewer-weqph191"><span><span><span>•  Instead of forming hypotheses, users asked the AI for ideas.</span></span></span></p><p dir="auto" id="viewer-iyunt193"><span><span><span>•  Instead of validating sources, they assumed the AI had already done so.</span></span></span></p><p dir="auto" id="viewer-0v61k195"><span><span><span>•  Instead of assessing multiple perspectives, they integrated and edited the AI’s summary and moved on.</span></span></span></p><p dir="auto" id="viewer-plvdb197"><span><span><span>This isn’t hypothetical. This is happening now, in real-world workflows. And if you’re in OSINT, you know how dangerous that is.</span></span></span></p><p dir="auto" id="viewer-ga8wh199"><span><span><span>In our line of work, you can’t afford false confidence. You can’t afford a hallucinated source, a mistranslated post, or a manipulated summary. But the more trust you place in GenAI, without friction, without skepticism, the more you risk exactly that.</span></span></span></p><p dir="auto" id="viewer-r0kfu201"><span><span><span>The study didn’t focus on OSINT directly. But it doesn’t have to. The findings hit home harder here than anywhere else. Because if we lose critical thinking in this field, we don’t just lose accuracy, we lose integrity.</span></span></span></p><p data-breakout="normal"><h2 dir="auto" id="viewer-0bfq4203"><span><span>What This Means for OSINT</span></span></h2></p><p dir="auto" id="viewer-jd0al205"><span><span><span>In OSINT, we deal in fragments. Nothing is handed to us neatly. We build context from chaos: &nbsp; tweets, photos, forums, leaks, metadata, satellite images, dead links, weird file names. Every good analyst knows that the work isn’t just collecting data. It’s thinking with it.</span></span></span></p><p dir="auto" id="viewer-r4xqx207"><span><span><span>That’s what’s at risk.</span></span></span></p><p dir="auto" id="viewer-9y9co209"><span><span><span>The </span></span><a target="_blank" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf?utm_source=newsletter.danielmiessler.com&amp;utm_medium=newsletter&amp;utm_campaign=unsupervised-learning-no-475" rel="noopener" data-hook="web-link"><span><u><span>Lee et al. study </span></u></span></a><span><span>wasn’t about OSINT specifically, but it described exactly what’s happening in OSINT shops, government teams, threat intel units, and open-source communities around the world. The creeping shift from thinking to prompting, from analyst to editor. Let’s talk real.</span></span></span></p><p data-breakout="normal"><h3 dir="auto" id="viewer-53tmw216"><span><span>Real-World OSINT Scenarios Affected by GenAI Complacency</span></span></h3></p><p dir="auto" id="viewer-soc5j219"><span><span><u><span>Scenario 1: Image Verification</span></u></span></span></p><p dir="auto" id="viewer-87dfb222"><span><span><span>You upload a protest photo into a tool like Gemini and ask, “Where was this taken?” It spits out a convincing response: “Paris, near Place de la République.” It sounds right. You move on.</span></span></span></p><p dir="auto" id="viewer-ir6ii225"><span><span><span>But a trained eye would notice the signage is Belgian. The license plates are off. The architecture doesn’t match. You trusted the AI and missed the location by a country.</span></span></span></p><p dir="auto" id="viewer-8tsqs228"><span><span><u><span>Scenario 2: Person of Interest Profile</span></u></span></span></p><p dir="auto" id="viewer-cyb98231"><span><span><span>You use Claude to summarize a person’s online presence. It generates a clean narrative: activist, tech worker, harmless. But it completely omits their links to far-right forums because the model didn’t surface the fringe platforms. You never check. That person ends up speaking at a sensitive public event.</span></span></span></p><p dir="auto" id="viewer-dm9uo234"><span><span><u><span>Scenario 3: Disinformation Campaign Detection</span></u></span></span></p><p dir="auto" id="viewer-1aeo9237"><span><span><span>You feed a stream of Telegram messages into ChatGPT and ask for “summary and patterns.” It flags some keywords, but misses the subtle linguistic shift that points to a known Russian influence cell, something only a trained mind would notice by comparing phrasing across sources. But you’ve stopped reading the raw content. You trusted the summary</span></span></span></p><p dir="auto" id="viewer-8vl7d240"><span><span><span>These aren’t edge cases. These are plausible daily failures in modern OSINT workflows.</span></span></span></p><p dir="auto" id="viewer-2nfvf242"><span><span><span>And here’s the kicker: in each case, the analyst didn’t fail because of bad intent or laziness. They failed because the tools were just good enough to feel trustworthy and just wrong enough to be dangerous.</span></span></span></p><p dir="auto" id="viewer-i7fb5245"><span><span><span>AI doesn’t break OSINT. But unquestioned AI does.</span></span></span></p><p dir="auto" id="viewer-16tjw248"><span><span><span>When analysts become dependent on outputs instead of building their own reasoning, they lose what makes OSINT powerful: the ability to interpret, interrogate, and pivot. You can’t pivot from a hallucinated answer. You can’t investigate a lie you believed too quickly.</span></span></span></p><p dir="auto" id="viewer-kq9u3250"><span><span><span>GenAI doesn’t understand context, risk, geopolitical nuance, or how bad actors use language to hide intent. It doesn’t know when to doubt itself. That’s your job and too many are forgetting that.</span></span></span></p><p data-breakout="normal"><h2 dir="auto" id="viewer-lg7cu253"><span><span>The Creeping Death of Tradecraft</span></span></h2></p><p dir="auto" id="viewer-r3677256"><span><span><span>Tradecraft isn’t just a list of tools. It’s a way of thinking. It’s the habit of looking again when something feels off. It’s verifying metadata, cross-checking timestamps, spotting a street sign that doesn’t match the language in the caption. It’s the instinct to question the obvious.</span></span></span></p><p dir="auto" id="viewer-snvqa259"><span><span><span>And that instinct is quietly dying.</span></span></span></p><p dir="auto" id="viewer-8ljss262"><span><span><span>Not because analysts are getting lazy, but because AI is making the job feel easier than it actually is. You’re still working. You’re still clicking. But the mental friction is gone.</span></span></span></p><p dir="auto" id="viewer-4h8nl265"><span><span><span>That friction used to be where tradecraft lived.</span></span></span></p><p dir="auto" id="viewer-7tcgo268"><span><span><span>Let’s get brutally honest about what’s happening:</span></span></span></p><p data-breakout="normal"><h3 dir="auto" id="viewer-fleto271"><span><span>Then vs. Now: What OSINT Analysts Used to Do</span></span></h3></p><p dir="auto" id="viewer-bvt3s274"><span><span><u><span>Then:</span></u></span></span></p><p dir="auto" id="viewer-791qt276"><span><span><span>•  Saw a blurry image, opened it in three tools, zoomed in, rotated it, looked for EXIF, cropped landmarks, and reverse searched five times.</span></span></span></p><p dir="auto" id="viewer-qyfzx278"><span><span><span>•  Read a social post in broken Russian, translated it manually, checked slang, looked up associated hashtags, and verified the account’s activity history.</span></span></span></p><p dir="auto" id="viewer-izc9m280"><span><span><span>•  Traced a domain name through WHOIS, looked at subdomains, searched for reused infrastructure, and mapped out connected email addresses.</span></span></span></p><p dir="auto" id="viewer-rd7ef283"><span><span><u><span>Now:</span></u></span></span></p><p dir="auto" id="viewer-c413s285"><span><span><span>•  Paste the image into the AI tool, read the suggested location, and move on.</span></span></span></p><p dir="auto" id="viewer-5k8yh287"><span><span><span>•  Dump a thread into ChatGPT for summary.</span></span></span></p><p dir="auto" id="viewer-k0b2r289"><span><span><span>•  Ask Gemini, “Who runs this domain?” and accept the top-line answer.</span></span></span></p><p dir="auto" id="viewer-ya6c7292"><span><span><span>This isn’t about nostalgia, it’s about recognising a dangerous shift in behavior. The more we “trust the tool,” the less we build the skills that make the tool useful. We’re automating our edge away.</span></span></span></p><p dir="auto" id="viewer-buodx294"><span><span><span>And GenAI isn’t just fast, it’s persuasive. It writes with confidence. It fills in gaps. It doesn’t hesitate, and that creates a dangerous illusion of accuracy. Analysts are making decisions based on language model confidence, not evidence. It’s happening slowly. Silently. Like rot.</span></span></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-y21ln297"><span><span><span>What Dies When Tradecraft Goes Passive?</span></span></span></h4></p><p dir="auto" id="viewer-o2h30300"><span><span><span>•  Contextual reasoning: spotting when something doesn’t add up, even if it “looks right.”</span></span></span></p><p dir="auto" id="viewer-htw84302"><span><span><span>•  Cross-source verification: confirming a fact with at least two or three unrelated sources.</span></span></span></p><p dir="auto" id="viewer-4jfkp304"><span><span><span>•  Hypothesis testing: building and breaking possible explanations for what you’re seeing.</span></span></span></p><p dir="auto" id="viewer-c7sf2306"><span><span><span>•  Refusal to settle: the instinct to keep digging, even when the AI gave you a plausible answer.</span></span></span></p><p dir="auto" id="viewer-2tb3e309"><span><span><span>Without these, OSINT becomes automated guesswork with a shiny UI.</span></span></span></p><p dir="auto" id="viewer-xpz28312"><span><span><span>And make no mistake, bad actors know this. They’ll test your tools. Feed them poisoned content. Exploit AI’s tendency to repeat, simplify, and hallucinate. If your entire workflow is built on trust in the machine, you’re walking into a trap.</span></span></span></p><p dir="auto" id="viewer-0pd9y315"><span><span><span>Tradecraft is slow. Tradecraft is uncomfortable. Tradecraft is what keeps your work accurate, defensible, and trusted. Without it, you’re just another person typing prompts and hoping for truth.</span></span></span></p><p data-breakout="normal"><h3 dir="auto" id="viewer-ydfur318"><span><span>The New Role of the Analyst: AI Overseer, Not AI Believer</span></span></h3></p><p dir="auto" id="viewer-81ix1320"><span><span><span>Here’s the truth: GenAI is here to stay. It’s not going away. And for OSINT, it’s not the enemy. But it is a liability, if you don’t treat it like one.</span></span></span></p><p dir="auto" id="viewer-6jhqe322"><span><span><span>The analyst’s job has changed. Or rather, it needs to.</span></span></span></p><p dir="auto" id="viewer-2rhd7324"><span><span><span>You’re no longer just a researcher, a data miner, a pattern spotter.</span></span></span></p><p dir="auto" id="viewer-nfc5b326"><span><span><span>You’re now an AI overseer. A challenger. A verifier. A filter.</span></span></span></p><p dir="auto" id="viewer-fb042329"><span><span><span>If you treat ChatGPT, Claude, Gemini, or Copilot as reliable assistants, they’ll eventually lead you to errors, because they’re not assistants. They’re high-speed, high-confidence content engines with zero lived experience and no sense of consequence. Your role is to make sure they don’t get away with anything.</span></span></span></p><p dir="auto" id="viewer-ifein332"><span><span><span>How the Analyst Mindset Must Shift:</span></span></span></p><div id="viewer-jxnk2335" data-breakout="normal"><table data-hook="table-component"><colgroup><col><col></colgroup><tbody><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-e3jko338"><span><strong><span><span>Old Role</span></span></strong></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-j8pw6341"><span><strong><span><span>New Role</span></span></strong></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-19hap345"><span><span><span>Ask AI a question</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-78j4v348"><span><span><span>Interrogate AI answers</span></span></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-fmziu352"><span><span><span>Accept summaries</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-h40zt355"><span><span><span>Dissect summaries</span></span></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-9tb1m359"><span><span><span>Use suggestions</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-iuqn8362"><span><span><span>Break suggestions apart</span></span></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-w83y0366"><span><span><span>Trust clean answers</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-8fmdr369"><span><span><span>Trace dirty origins</span></span></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-60dgq373"><span><span><span>Generate profiles</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-ubk85376"><span><span><span>Validate narratives</span></span></span></p></td></tr><tr><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-dq1k0380"><span><span><span>Draft and ship</span></span></span></p></td><td data-hook="table-plugin-cell"><p dir="auto" id="viewer-1u047383"><span><span><span>Draft, rip apart, and rebuild</span></span></span></p></td></tr></tbody></table></div><p dir="auto" id="viewer-6hixh385"><span><span><span>You’re not there to be impressed by what the model says. You’re there to break it, test it, and decide what survives. That means:</span></span></span></p><p dir="auto" id="viewer-fwimz389"><span><span><span>•  Running the AI’s claim through manual OSINT methods</span></span></span></p><p dir="auto" id="viewer-u7k27391"><span><span><span>•  Fact-checking what it didn’t cite</span></span></span></p><p dir="auto" id="viewer-36agy393"><span><span><span>•  Comparing AI output against real-world source behavior</span></span></span></p><p dir="auto" id="viewer-byi48395"><span><span><span>•  Asking “What isn’t it telling me?”</span></span></span></p><p dir="auto" id="viewer-woemc397"><span><span><span>AI tools should trigger suspicion, not satisfaction. Every time the answer seems too clean, too simple, too aligned with your bias, you should feel that OSINT tingle in your brain: “Wait… prove it.”&nbsp;</span></span></span></p><p dir="auto" id="viewer-s5s8g399"><span><span><span>You wouldn’t blindly trust a witness in an investigation just because they speak confidently. Don’t trust a model either. It’s not about being anti-AI. It’s about preserving cognitive sovereignty. Because the moment you let the model do the thinking for you, you stop being an investigator, you become an operator.</span></span></span></p><p data-breakout="normal"><h2 dir="auto" id="viewer-r2fs4401"><span><span>Reviving Critical Thinking in the AI Era</span></span></h2></p><p dir="auto" id="viewer-isz8f403"><span><span><span>If critical thinking is dying, it’s not because we don’t care, it’s because we stopped practicing it. The good news? You can take it back. But it won’t happen by accident. It requires intention.</span></span></span></p><p dir="auto" id="viewer-nu2bt406"><span><span><span>Here’s how OSINT practitioners can stay sharp in a GenAI world:</span></span></span></p><p dir="auto" id="viewer-3d489409"><span><strong><span><span>Introduce Friction on Purpose</span></span></strong></span></p><p dir="auto" id="viewer-td53s411"><span><span><span>GenAI is fast. That’s the trap.</span></span></span></p><p dir="auto" id="viewer-b5nj9413"><span><span><span>You need to slow yourself down (</span></span><em><span><span>deliberately</span></span></em><span><span>) before trusting anything it gives you.</span></span></span></p><p dir="auto" id="viewer-vmt81417"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-ti4lh419"><span><span><span>•  Pause and ask: </span></span><em><span><span>What sources would I have checked without AI?</span></span></em><span><span>&nbsp;Go check them anyway.</span></span></span></p><p dir="auto" id="viewer-zs8r8423"><span><span><span>•  Require yourself to find </span></span><strong><span><span>one contradiction</span></span></strong><span><span>&nbsp;to the AI’s output before accepting it.</span></span></span></p><p dir="auto" id="viewer-64emy427"><span><span><span>•  Use a second model (Claude, Gemini, etc.) and force a contradiction: </span></span><em><span><span>“Give me the opposite interpretation.”</span></span></em></span></p><p dir="auto" id="viewer-ijxpn430"><span><strong><span><span>Rebuild Your Source Discipline</span></span></strong></span></p><p dir="auto" id="viewer-7qlhj432"><span><span><span>GenAI doesn’t cite like an OSINT analyst does. So don’t let it train you into laziness.</span></span></span></p><p dir="auto" id="viewer-76345434"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-jir18436"><span><span><span>• If a model gives you a name, quote, link, or claim, don’t just Google it. Trace it.</span></span></span></p><p dir="auto" id="viewer-g43m4438"><span><span><span>• Keep a side-by-side log: AI output vs. verified source. Where’s the gap?</span></span></span></p><p dir="auto" id="viewer-ckyg0440"><span><span><span>• When using summaries, always open the original material anyway. Always.</span></span></span></p><p dir="auto" id="viewer-rw50c442"><span><strong><span><span>Use AI as a Thought Partner, Not an Oracle</span></span></strong></span></p><p dir="auto" id="viewer-6p3t8444"><span><span><span>Treat GenAI like a junior analyst: decent ideas, but needs supervision.</span></span></span></p><p dir="auto" id="viewer-zrup1446"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-z2pav448"><span><span><span>•  Ask it to argue against your current hypothesis.</span></span></span></p><p dir="auto" id="viewer-mlqlo450"><span><span><span>•  Feed it your working notes and ask, “What’s missing? What assumptions am I making?”</span></span></span></p><p dir="auto" id="viewer-y2ust452"><span><span><span>•  Use it to simulate perspectives, not to define reality.</span></span></span></p><p dir="auto" id="viewer-ysrl6454"><span><strong><span><span>Cross-Model Interrogation</span></span></strong></span></p><p dir="auto" id="viewer-5xwf6456"><span><span><span>Different models have different blind spots. Use that.</span></span></span></p><p dir="auto" id="viewer-6tq6h458"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-qclwi460"><span><span><span>•  Ask the same question across ChatGPT, Claude, Gemini, and Copilot. Compare outputs.</span></span></span></p><p dir="auto" id="viewer-zq14j462"><span><span><span>•  Note contradictions. Investigate </span></span><em><span><span>why</span></span></em><span><span>&nbsp;they differ.</span></span></span></p><p dir="auto" id="viewer-8857m466"><span><span><span>•  Treat divergence as signal, not noise.</span></span></span></p><p dir="auto" id="viewer-aqhvs468"><span><strong><span><span>Force Failure</span></span></strong></span></p><p dir="auto" id="viewer-ottpq470"><span><span><span>If you’re not actively trying to break the model, you’re not using it critically.</span></span></span></p><p dir="auto" id="viewer-4vbem472"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-sjwiu474"><span><span><span>•  Intentionally feed it misleading prompts and watch what it hallucinates.</span></span></span></p><p dir="auto" id="viewer-6ocqq476"><span><span><span>•  Track how it behaves under ambiguity, contradiction, or incomplete data.</span></span></span></p><p dir="auto" id="viewer-eshqr478"><span><span><span>•  Learn its failure modes and build your tradecraft to fill the gaps.</span></span></span></p><p dir="auto" id="viewer-qvncs480"><span><strong><span><span>Keep Doing the Hard Stuff</span></span></strong></span></p><p dir="auto" id="viewer-mywwj482"><span><span><span>The tools should speed you up, but they should never </span></span><em><span><span>replace</span></span></em><span><span>&nbsp;the hard parts.</span></span></span></p><p dir="auto" id="viewer-rhl2q486"><span><strong><span><span>Tactics:</span></span></strong></span></p><p dir="auto" id="viewer-uyxzv488"><span><span><span>•  Geolocate manually before checking with AI.</span></span></span></p><p dir="auto" id="viewer-lznej490"><span><span><span>•  Write your own summary before reading the AI’s.</span></span></span></p><p dir="auto" id="viewer-kcbar492"><span><span><span>•  Build your own profile first, then ask the AI to challenge it.</span></span></span></p><p data-breakout="normal"><h2 dir="auto" id="viewer-j2z88495"><span><span>The Quiet Collapse and How We Fight It</span></span></h2></p><p dir="auto" id="viewer-zijau497"><span><span><span>The fall of critical thinking in OSINT won’t come with a bang. It’ll come quietly. It’ll look like faster reports. Cleaner narratives. Fewer questions asked. It’ll feel efficient. It’ll look like progress.</span></span></span></p><p dir="auto" id="viewer-on8ye499"><span><span><span>Until it isn’t.</span></span></span></p><p dir="auto" id="viewer-toyk5501"><span><span><span>Until you miss the real location. Trust the wrong source. Assume the wrong intent. Attribute the wrong actor. And by then, your tradecraft won’t save you, because you won’t have practiced it.</span></span></span></p><p dir="auto" id="viewer-b2aup503"><span><span><span>This is how it starts. It starts with trusting summaries. With accepting citations you didn’t check. With replacing your judgment with something that </span></span><em><span><span>sounds</span></span></em><span><span>&nbsp;like judgment. The collapse won’t be obvious. It will feel convenient. That’s what makes it so dangerous. But here’s the part that matters: it’s reversible.</span></span></span></p><p dir="auto" id="viewer-738pk509"><span><span><span>You don’t need to ditch GenAI. You need to confront it. Challenge it. Break it. Question it. Use it, but never trust it without a fight. You’re not just a user of tools. You’re an investigator.</span></span></span></p><p dir="auto" id="viewer-unsso511"><span><span><span>You think critically. You trace evidence. You challenge assumptions. That’s the job.</span></span></span></p><p dir="auto" id="viewer-2tehf513"><span><span><span>Don’t let the machine do the thinking for you.</span></span></span></p><p dir="auto" id="viewer-6nkid1148"><span><strong><span><span>Bonus: OSINT Anti-Overreliance Checklist</span></span></strong></span></p><p dir="auto" id="viewer-vik1o1308"><span><span><span>Keep this near your screen. Use it when GenAI enters your workflow.</span></span></span></p><p dir="auto" id="viewer-121wz1310"><span><span><span>✅ </span></span><strong><span><span>Did I verify osint-vs-ai the original source of any AI output?</span></span></strong></span></p><p dir="auto" id="viewer-u2e2g1313"><span><span><span>✅ </span></span><strong><span><span>Did I consult non-AI sources before accepting the answer?</span></span></strong></span></p><p dir="auto" id="viewer-fxkop1316"><span><span><span>✅ </span></span><strong><span><span>Did I challenge the output with a counter-hypothesis or alternate model?</span></span></strong></span></p><p dir="auto" id="viewer-9g49a1319"><span><span><span>✅ </span></span><strong><span><span>Did I cross-reference data across at least two human-curated sources?</span></span></strong></span></p><p dir="auto" id="viewer-mzuug1322"><span><span><span>✅ </span></span><strong><span><span>Did I perform at least one task manually before accepting the AI’s version?</span></span></strong></span></p><p dir="auto" id="viewer-cf0gk1325"><span><span><span>✅ </span></span><strong><span><span>Did I identify any unstated assumptions in the AI’s output?</span></span></strong></span></p><p dir="auto" id="viewer-smrzs1328"><span><span><span>✅ </span></span><strong><span><span>Did I treat GenAI as a thought partner—not a source of truth?</span></span></strong></span></p><p dir="auto" id="viewer-kpif31331"><span><span><span>✅ </span></span><strong><span><span>Did I deliberately introduce friction into the process (slowing down, comparing, double-checking)?</span></span></strong></span></p><p dir="auto" id="viewer-5xc7w1334"><span><span><span>✅ </span></span><strong><span><span>Did I stop and ask: What am I trusting without verifying?</span></span></strong></span></p><p dir="auto" id="viewer-9fdxs1710"><span><span><span>✅ </span></span><strong><span>Did we share/cite with the reader of our OSINT product how we used AI</span></strong><span>? </span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An image of an archeologist adventurer who wears a hat and uses a bullwhip (691 pts)]]></title>
            <link>https://theaiunderwriter.substack.com/p/an-image-of-an-archeologist-adventurer</link>
            <guid>43573156</guid>
            <pubDate>Thu, 03 Apr 2025 17:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theaiunderwriter.substack.com/p/an-image-of-an-archeologist-adventurer">https://theaiunderwriter.substack.com/p/an-image-of-an-archeologist-adventurer</a>, See on <a href="https://news.ycombinator.com/item?id=43573156">Hacker News</a></p>
Couldn't get https://theaiunderwriter.substack.com/p/an-image-of-an-archeologist-adventurer: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Reasoning models don't always say what they think (344 pts)]]></title>
            <link>https://www.anthropic.com/research/reasoning-models-dont-say-think</link>
            <guid>43572374</guid>
            <pubDate>Thu, 03 Apr 2025 16:50:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/research/reasoning-models-dont-say-think">https://www.anthropic.com/research/reasoning-models-dont-say-think</a>, See on <a href="https://news.ycombinator.com/item?id=43572374">Hacker News</a></p>
Couldn't get https://www.anthropic.com/research/reasoning-models-dont-say-think: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI 2027 (426 pts)]]></title>
            <link>https://ai-2027.com/</link>
            <guid>43571851</guid>
            <pubDate>Thu, 03 Apr 2025 16:13:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai-2027.com/">https://ai-2027.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43571851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav><div><h2><div><p>April 3rd 2025</p><a target="_blank" href="https://ai-2027.com/scenario.pdf"><svg width="12px" height="14px" version="1.1" viewBox="100 0 900 1200" xmlns="http://www.w3.org/2000/svg"><path d="m200.02 249.98c0-82.828 67.125-150 150-150h258.56c39.797 0 77.953 15.797 106.08 43.969l241.4 241.4c28.125 28.125 43.922 66.281 43.922 106.08v458.58c0 82.828-67.125 150-150 150h-499.97c-82.875 0-150-67.172-150-150zm399.14 650.02c-7.5469-0.14062-14.672-1.9219-21.047-5.0156-4.4531-2.2031-8.5312-5.0156-12.141-8.3438l-99.891-92.203c-20.297-18.75-21.562-50.391-2.8125-70.641 18.703-20.297 50.344-21.562 70.641-2.8594l16.078 14.859v-185.81c0-27.609 22.406-49.969 50.016-49.969s50.016 22.359 50.016 49.969v179.29l14.625-14.625c19.547-19.547 51.188-19.547 70.734 0 19.5 19.5 19.5 51.188 0 70.688l-99.984 99.984-0.375 0.32812c-9 8.8594-21.328 14.344-34.969 14.344z" fill-rule="evenodd"></path></svg> <span>PDF</span> </a><p><span><span>Listen</span></span></p></div><span>Daniel&nbsp;Kokotajlo, Scott&nbsp;Alexander, Thomas&nbsp;Larsen, Eli&nbsp;Lifland, Romeo&nbsp;Dean</span></h2></div></nav><div><div id="section-narrative-0"><p>We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.</p><p>We wrote a scenario that represents our best guess about what that might look like.<sup id="footnote-1"><a href="https://ai-2027.com/footnotes#footnote-1">1</a></sup> It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes.<sup id="footnote-2"><a href="https://ai-2027.com/footnotes#footnote-2">2</a></sup></p><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div><div><p>The CEOs of <a href="https://www.bloomberg.com/features/2025-sam-altman-interview">OpenAI</a>, <a href="https://www.bigtechnology.com/p/google-deepmind-ceo-demis-hassabis">Google DeepMind</a>, and <a href="https://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-01-21-2025/card/anthropic-ceo-says-ai-could-surpass-human-intelligence-by-2027-9tka9tjLKLalkXX8IgKA">Anthropic</a> have all predicted that AGI will arrive within the next 5 years. Sam Altman <a href="https://webcf.waybackmachine.org/web/20250106014723/https://blog.samaltman.com/reflections">has said</a> OpenAI is setting its sights on “superintelligence in the true sense of the word” and the “glorious future.”<sup id="footnote-3"><a href="https://ai-2027.com/footnotes#footnote-3">3</a></sup></p><p>What might that look like? We wrote AI 2027 to answer that question. Claims about the future are often frustratingly vague, so we tried to be as concrete and quantitative as possible, even though this means depicting one of many possible futures.</p><p>We wrote two endings: a “slowdown” and a “race” ending. However, AI 2027 is not a recommendation or exhortation. Our goal is predictive accuracy.<sup id="footnote-4"><a href="https://ai-2027.com/footnotes#footnote-4">4</a></sup></p><p>We encourage you to debate and counter this scenario.<sup id="footnote-5"><a href="https://ai-2027.com/footnotes#footnote-5">5</a></sup> We hope to spark a broad conversation about where we’re headed and how to steer toward positive futures. We’re <a href="https://ai-2027.com/about#bets-and-bounties">planning to give out thousands in prizes</a> to the best alternative scenarios.</p></div><div><p>Our research on key questions (e.g. what goals will future AI agents have?) can be found <a href="https://ai-2027.com/research">here</a>.</p><p>The scenario itself was written iteratively: we wrote the first period (up to mid-2025), then the following period, etc. until we reached the ending. We then scrapped this and did it again.</p><p>We weren’t trying to reach any particular ending. After we finished the first ending—which is now colored red—we wrote a new alternative branch because we wanted to also depict a more hopeful way things could end, starting from roughly the same premises. This went through several iterations.<sup id="footnote-6"><a href="https://ai-2027.com/footnotes#footnote-6">6</a></sup></p><p>Our scenario was informed by approximately 25 <a href="https://ai-2027.com/about?tab=tabletop-exercise#tab-box-tabletop-exercise">tabletop exercises</a> and feedback from over 100 people, including dozens of experts in each of AI governance and AI technical work.</p></div><div><p><em>“I highly recommend reading this scenario-type prediction on how AI could transform the world in just a few years. Nobody has a crystal ball, but this type of content can help notice important questions and illustrate the potential impact of emerging risks.”</em> —<em>Yoshua Bengio<sup id="footnote-7"><a href="https://ai-2027.com/footnotes#footnote-7">7</a></sup></em></p><p>We have set ourselves an impossible task. Trying to predict how superhuman AI in 2027 would go is like trying to predict how World War 3 in 2027 would go, except that it’s an even larger departure from past case studies. Yet it is still valuable to attempt, just as it is valuable for the US military to game out Taiwan scenarios.</p><p>Painting the whole picture makes us notice important questions or connections we hadn’t considered or appreciated before, or realize that a possibility is more or less likely. Moreover, by sticking our necks out with concrete predictions, and encouraging others to publicly state their disagreements, we make it possible to evaluate years later who was right.</p><p>Also, one author wrote a lower-effort AI scenario <a href="https://www.lesswrong.com/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like">before, in August 2021</a>. While it got many things wrong, overall it was surprisingly successful: he predicted the rise of chain-of-thought, inference scaling, sweeping AI chip export controls, and $100 million training runs—all more than a year before ChatGPT.</p></div></div><!--/$--><div> <p><span>Published April 3rd 2025</span></p> <a target="_blank" href="https://ai-2027.com/scenario.pdf"> <svg width="12px" height="14px" version="1.1" viewBox="100 0 900 1200" xmlns="http://www.w3.org/2000/svg"><path d="m200.02 249.98c0-82.828 67.125-150 150-150h258.56c39.797 0 77.953 15.797 106.08 43.969l241.4 241.4c28.125 28.125 43.922 66.281 43.922 106.08v458.58c0 82.828-67.125 150-150 150h-499.97c-82.875 0-150-67.172-150-150zm399.14 650.02c-7.5469-0.14062-14.672-1.9219-21.047-5.0156-4.4531-2.2031-8.5312-5.0156-12.141-8.3438l-99.891-92.203c-20.297-18.75-21.562-50.391-2.8125-70.641 18.703-20.297 50.344-21.562 70.641-2.8594l16.078 14.859v-185.81c0-27.609 22.406-49.969 50.016-49.969s50.016 22.359 50.016 49.969v179.29l14.625-14.625c19.547-19.547 51.188-19.547 70.734 0 19.5 19.5 19.5 51.188 0 70.688l-99.984 99.984-0.375 0.32812c-9 8.8594-21.328 14.344-34.969 14.344z" fill-rule="evenodd"></path></svg> <span>PDF</span> </a> <p><span>  <span>Listen</span></span></p></div></div><div id="section-narrative-1"><h2 id="mid-2025-stumbling-agents">Mid 2025: Stumbling Agents</h2><p>The world sees its first glimpse of AI agents.</p><p>Advertisements for computer-using agents emphasize the term “personal assistant”: you can prompt them with tasks like “order me a burrito on DoorDash” or “open my budget spreadsheet and sum this month’s expenses.” They will check in with you as needed: for example, to ask you to confirm purchases.<sup id="footnote-8"><a href="https://ai-2027.com/footnotes#footnote-8">8</a></sup> Though more advanced than previous iterations like <a href="https://openai.com/index/introducing-operator/">Operator</a>, they struggle to get widespread usage.<sup id="footnote-9"><a href="https://ai-2027.com/footnotes#footnote-9">9</a></sup></p><p>Meanwhile, out of public focus, more specialized coding and research agents are beginning to transform their professions.</p><p>The AIs of 2024 could follow specific instructions: they could turn bullet points into emails, and simple requests into working code. In 2025, AIs function more like employees. Coding AIs increasingly look like autonomous agents rather than mere assistants: taking instructions via Slack or Teams and making substantial code changes on their own, sometimes saving hours or even days.<sup id="footnote-10"><a href="https://ai-2027.com/footnotes#footnote-10">10</a></sup> Research agents spend half an hour scouring the Internet to answer your question.</p><p>The agents are impressive in theory (and in cherry-picked examples), but in practice unreliable. AI twitter is full of stories about tasks bungled in some particularly hilarious way. The better agents are also expensive; you get what you pay for, and the best performance costs hundreds of dollars a month.<sup id="footnote-11"><a href="https://ai-2027.com/footnotes#footnote-11">11</a></sup> Still, many companies find ways to fit AI agents into their workflows.<sup id="footnote-12"><a href="https://ai-2027.com/footnotes#footnote-12">12</a></sup></p></div><div id="section-narrative-2"><h2 id="late-2025-the-worlds-most-expensive-ai">Late 2025: The World’s Most Expensive AI</h2><p>OpenBrain is building the biggest datacenters the world has ever seen.<sup id="footnote-13"><a href="https://ai-2027.com/footnotes#footnote-13">13</a></sup></p><p>(To avoid singling out any one existing company, we’re going to describe a fictional <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">artificial general intelligence</a> company, which we’ll call OpenBrain. We imagine the others to be 3–9 months behind OpenBrain.)</p><div><div><p>Agent-1</p><!-- --> <p> (3 x 10^27 FLOPS)</p></div><p>ai-2027.com</p></div><p>GPT-4 required <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>⋅</mo><msup><mn>10</mn><mn>25</mn></msup></mrow><annotation encoding="application/x-tex">2\cdot 10^{25}</annotation></semantics></math></span></span></span> <a href="https://en.wikipedia.org/wiki/Floating_point_operations_per_second">FLOP</a> of compute to train.<sup id="footnote-14"><a href="https://ai-2027.com/footnotes#footnote-14">14</a></sup> OpenBrain’s latest public model—Agent-0—was trained with <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>27</mn></msup></mrow><annotation encoding="application/x-tex">10^{27}</annotation></semantics></math></span></span></span> FLOP. Once the new datacenters are up and running, <a href="https://ai-2027.com/supplements/compute-forecast">they’ll be able to train</a> a model with <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>28</mn></msup></mrow><annotation encoding="application/x-tex">10^{28}</annotation></semantics></math></span></span></span> FLOP—a thousand times more than GPT-4.<sup id="footnote-15"><a href="https://ai-2027.com/footnotes#footnote-15">15</a></sup> Other companies pour money into their own giant datacenters, hoping to keep pace.</p><p>Although models are improving on a wide range of skills, one stands out: OpenBrain focuses on AIs that can speed up AI research. They want to win the twin arms races against China (whose leading company we’ll call “DeepCent”)<sup id="footnote-16"><a href="https://ai-2027.com/footnotes#footnote-16">16</a></sup> and their US competitors. The more of their research and development (R&amp;D) cycle they can automate, the faster they can go. So when OpenBrain finishes training Agent-1, a new model under internal development, it’s good at many things but <em>great</em> at helping with AI research.<sup id="footnote-17"><a href="https://ai-2027.com/footnotes#footnote-17">17</a></sup> By this point “finishes training” is a bit of a misnomer; models are frequently updated to newer versions trained on additional data or partially re-trained to patch some weaknesses.<sup id="footnote-18"><a href="https://ai-2027.com/footnotes#footnote-18">18</a></sup></p><p>The same training environments that teach Agent-1 to autonomously code and web-browse also make it a good hacker. Moreover, it could offer <a href="https://x.com/lucafrighetti/status/1894550297449828434">substantial help</a> to terrorists designing bioweapons, thanks to its PhD-level knowledge of every field and ability to browse the web. OpenBrain reassures the government that the model has been “aligned” so that it will refuse to comply with malicious requests.</p><p>Modern AI systems are gigantic artificial neural networks. Early in training, an AI won’t have “goals” so much as “reflexes”: If it sees “Pleased to meet”, it outputs “ you”. By the time it has been trained to predict approximately one internet’s worth of text, it’ll have developed sophisticated internal circuitry that encodes vast amounts of knowledge and flexibly role-plays as arbitrary authors, since that’s what helps it predict text with <a href="https://arxiv.org/pdf/2212.11281">superhuman</a> accuracy.<sup id="footnote-19"><a href="https://ai-2027.com/footnotes#footnote-19">19</a></sup></p><p>After being trained to predict internet text, the model is trained to <em>produce</em> text in response to instructions. This bakes in a basic personality and “drives.”<sup id="footnote-20"><a href="https://ai-2027.com/footnotes#footnote-20">20</a></sup> For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).<sup id="footnote-21"><a href="https://ai-2027.com/footnotes#footnote-21">21</a></sup></p><p>OpenBrain has <a href="https://model-spec.openai.com/2025-02-12.html">a model specification</a> (or “Spec”), a written document describing the goals, rules, principles, etc. that are supposed to guide the model’s behavior.<sup id="footnote-22"><a href="https://ai-2027.com/footnotes#footnote-22">22</a></sup> Agent-1’s Spec combines a few vague goals (like “assist the user” and “don’t break the law”) with a long list of more specific dos and don’ts (“don’t say this particular word,” “here’s how to handle this particular situation”). Using techniques that utilize AIs to train other AIs,<sup id="footnote-23"><a href="https://ai-2027.com/footnotes#footnote-23">23</a></sup> the model memorizes the Spec and learns to reason carefully about its maxims. By the end of <em>this</em> training, the AI will hopefully be <em>helpful</em> (obey instructions), <em>harmless</em> (refuse to help with scams, bomb-making, and other dangerous activities) and <em>honest</em> (resist the temptation to get better ratings from gullible humans by hallucinating citations<sup id="footnote-24"><a href="https://ai-2027.com/footnotes#footnote-24">24</a></sup> or faking task completion).</p><details><summary>Training process and LLM psychology: why we keep saying “hopefully”</summary><div id="training-process-and-llm-psychology-why-we-keep-saying-hopefully"><p><em>“Unlike ordinary software, our models are massive neural networks. Their behaviors are learned from a broad range of data, not programmed explicitly. Though not a perfect analogy, the process is more similar to training a dog than to ordinary programming.”</em> —<a href="https://openai.com/index/how-should-ai-systems-behave/">OpenAI</a></p><p>When we want to understand why a modern AI system did something, or how it would behave in some future scenario we can’t perfectly simulate, we can’t simply ask the programmers to talk us through various lines of code and explain how they work. Instead, we are forced to do something like psychology on them: we look at their behavior in the range of cases observed so far, and theorize about what internal cognitive structures (beliefs? goals? personality traits? etc.) might exist, and use those theories to predict behavior in future scenarios.</p><p>The bottom line is that a company can write up a document (the Spec) listing dos and don’ts, goals and principles, and then they can try to train the AI to internalize the Spec—<em>but they can’t check to see whether or not it worked</em>. They can say “as best as we can judge, it seems to be following the Spec so far.”<sup id="footnote-25"><a href="https://ai-2027.com/footnotes#footnote-25">25</a></sup></p><p>A later expandable will go into more detail about what we think <em>might</em> be going on inside these AIs, internally. See also our <a href="https://ai-2027.com/supplements/ai-goals-forecast">AI goals forecasting supplement</a> which goes into more detail on which goals AIs might have and why. This is one of many things that we are uncertain about and which deserves further research.</p></div></details><p>OpenBrain’s alignment team<sup id="footnote-26"><a href="https://ai-2027.com/footnotes#footnote-26">26</a></sup> is careful enough to wonder whether these victories are deep or shallow. Does the fully-trained model have some kind of robust commitment to always being honest? Or will this fall apart in some future situation, e.g. because it’s learned honesty as an <a href="https://en.wikipedia.org/wiki/Instrumental_and_intrinsic_value">instrumental</a> goal instead of a terminal goal? Or has it just learned to be honest about the sorts of things the evaluation process can check? Could it be lying to itself sometimes, as humans do? A conclusive answer to these questions would require mechanistic interpretability—essentially the ability to look at an AI’s internals and read its mind. Alas, interpretability techniques are not yet advanced enough for this.</p><p>Instead, researchers try to identify cases where the models seem to deviate from the Spec. Agent-1 is often sycophantic (i.e. it tells researchers what they want to hear instead of trying to tell them the truth). In a <a href="https://www.apolloresearch.ai/research/scheming-reasoning-evaluations">few rigged demos</a>, it even lies in more serious ways, like hiding evidence that it failed on a task, in order to get better ratings. However, in real deployment settings, there are no longer any incidents so extreme as in 2023–2024 (e.g. <a href="https://thehill.com/policy/technology/4998868-google-ai-gemini-response/">Gemini telling a user to die</a> and <a href="https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned">Bing Sydney being Bing Sydney</a>.)<sup id="footnote-27"><a href="https://ai-2027.com/footnotes#footnote-27">27</a></sup></p></div><div id="section-narrative-3"><h2 id="early-2026-coding-automation">Early 2026: Coding Automation</h2><p>The bet of using AI to speed up AI research is starting to pay off.</p><p>OpenBrain continues to deploy the iteratively improving Agent-1 internally for AI R&amp;D. Overall, they are making algorithmic progress 50% faster than they would without AI assistants—and more importantly, faster than their competitors.</p><details><summary>The AI R&amp;D progress multiplier: what do we mean by 50% faster algorithmic progress?</summary><div id="the-ai-randd-progress-multiplier-what-do-we-mean-by-50percent-faster-algorithmic-progress"><p>We mean that OpenBrain makes as much AI research progress in 1 week with AI as they would in 1.5 weeks without AI usage.</p><p>AI progress can be broken down into 2 components:</p><ol><li><p><strong>Increasing compute</strong>: More computational power is used to train or run an AI. This produces more powerful AIs, but they cost more.</p></li><li><p><strong>Improved algorithms</strong>: Better training methods are used to translate compute into performance. This produces more capable AIs without a corresponding increase in cost, or the same capabilities with decreased costs.</p><ol><li><p>This includes being able to achieve qualitatively and quantitatively new results. “Paradigm shifts” such as the switch from game-playing RL agents to large language models count as examples of algorithmic progress.</p></li></ol></li></ol><p>Here we are only referring to (2), improved algorithms, which <a href="https://epoch.ai/blog/algorithmic-progress-in-language-models">makes up about half of current AI progress</a>.</p><p>Going forward, we sometimes abbreviate this as an “AI R&amp;D progress multiplier” of 1.5.</p><p>Clarifications:</p><ol><li><p>The progress multiplier is all-inclusive: It includes the time it takes to run experiments, for example, rather than only the cognitive tasks involved in algorithmic research.</p></li><li><p>It’s important to remember that the progress multiplier is the <em>relative</em> speed of progress, not the <em>absolute</em> speed of progress. If, for example, the compute cost to train a GPT-4 class model has halved every year for several years with ordinary human research, and then all of a sudden AI automates R&amp;D and the progress multiplier goes to 100x, the cost to train a GPT-4 class model would then halve every 3.65 days—but not for long, because diminishing returns would bite and eventual hard limits would be reached. In this example perhaps the cost to train a GPT-4 class model would cut in half 5–10 times total (over the span of a few weeks or months) before plateauing. In other words, if ordinary human science would have run up against diminishing returns and physical limits after 5 -10 years of further research, then AIs with a 100x multiplier would run up against those same diminishing returns and limits after 18.25–36.5 days of research.</p></li></ol><p>More explanation and discussion of this concept and how it is used in our forecast can be found in our <a href="https://ai-2027.com/supplements/takeoff-forecast">takeoff supplement</a>.</p></div></details><p>Several competing publicly released AIs now match or exceed Agent-0, including an <a href="https://opensource.org/ai/open-weights">open-weights</a> model. OpenBrain responds by releasing Agent-1, which is more capable and reliable.<sup id="footnote-28"><a href="https://ai-2027.com/footnotes#footnote-28">28</a></sup></p><p>People naturally try to compare Agent-1 to humans, but it has a very different skill profile. It knows more facts than any human, knows practically every programming language, and can solve well-specified coding problems extremely quickly. On the other hand, Agent-1 is bad at even simple long-horizon tasks, like beating video games it hasn’t played before. Still, the common workday is eight hours, and a day’s work can usually be separated into smaller chunks; you could think of Agent-1 as a scatterbrained employee who thrives under careful management.<sup id="footnote-29"><a href="https://ai-2027.com/footnotes#footnote-29">29</a></sup> Savvy people find ways to automate routine parts of their jobs.<sup id="footnote-30"><a href="https://ai-2027.com/footnotes#footnote-30">30</a></sup></p><p>OpenBrain’s executives turn consideration to an implication of automating AI R&amp;D: security has become more important. In early 2025, the worst-case scenario was leaked algorithmic secrets; now, if China steals Agent-1’s weights, they could increase their research speed by nearly 50%.<sup id="footnote-31"><a href="https://ai-2027.com/footnotes#footnote-31">31</a></sup> OpenBrain’s security level is typical of a fast-growing ~3,000 person tech company, secure only against low-priority attacks from capable cyber groups (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">RAND’s SL2</a>).<sup id="footnote-32"><a href="https://ai-2027.com/footnotes#footnote-32">32</a></sup> They are working hard to protect their <a href="https://tedai-sanfrancisco.ted.com/glossary/weights/">weights</a> and secrets from insider threats and top cybercrime syndicates (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL3</a>),<sup id="footnote-33"><a href="https://ai-2027.com/footnotes#footnote-33">33</a></sup> but defense against nation states (<a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL4&amp;5</a>) is barely on the horizon.<sup id="footnote-34"><a href="https://ai-2027.com/footnotes#footnote-34">34</a></sup></p></div><div id="section-narrative-4"><h2 id="mid-2026-china-wakes-up">Mid 2026: China Wakes Up</h2><p>In China, the CCP is starting to <a href="https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims">feel the AGI</a>.</p><p>Chip export controls and lack of government support have left China under-resourced compared to the West. By smuggling banned Taiwanese chips, buying older chips, and producing domestic chips about three years behind the US-Taiwanese frontier, China has managed to maintain about 12% of the world’s AI-relevant compute—but the older technology is harder to work with, and supply is a constant headache.<sup id="footnote-35"><a href="https://ai-2027.com/footnotes#footnote-35">35</a></sup> A few standouts like DeepCent do very impressive work with limited compute, but the compute deficit limits what they can achieve without government support, and they are about six months behind the best OpenBrain models.<sup id="footnote-36"><a href="https://ai-2027.com/footnotes#footnote-36">36</a></sup></p><p>The General Secretary had long dreamed of doubling down on real-world physical manufacturing and avoiding American post-industrial decadence. He viewed software companies with suspicion.<sup id="footnote-37"><a href="https://ai-2027.com/footnotes#footnote-37">37</a></sup> But hawks in the CCP warn that the growing race towards AGI can no longer be ignored. So he finally commits fully to the big AI push he had previously tried to avoid. He sets in motion the nationalization of Chinese AI research, creating an immediate information-sharing mechanism for AI companies. It will escalate over the course of a year until all the best researchers merge into a DeepCent-led collective, where they share algorithmic insights, datasets, and compute resources with each other. A Centralized Development Zone (CDZ) is created at the Tianwan Power Plant (the largest nuclear power plant in the world) to house a new mega-datacenter for DeepCent, along with highly secure living and office spaces to which researchers will eventually relocate. Almost 50% of China’s AI-relevant compute is now working for the DeepCent-led collective,<sup id="footnote-38"><a href="https://ai-2027.com/footnotes#footnote-38">38</a></sup> and over 80% of new chips are directed to the CDZ.<sup id="footnote-39"><a href="https://ai-2027.com/footnotes#footnote-39">39</a></sup> At this point, the CDZ has the power capacity in place for what would be the largest centralized <a href="https://en.wikipedia.org/wiki/Computer_cluster">cluster</a> in the world.<sup id="footnote-40"><a href="https://ai-2027.com/footnotes#footnote-40">40</a></sup> Other Party members discuss extreme measures to neutralize the West’s chip advantage. A blockade of Taiwan? A full invasion?</p><p>But China is falling behind on AI algorithms due to their weaker models. The Chinese intelligence agencies—among the best in the world—double down on their plans to steal OpenBrain’s weights. This is a much more complex operation than their constant low-level poaching of algorithmic secrets; the weights are a multi-terabyte file stored on a highly secure server (<a href="https://ai-2027.com/supplements/security-forecast">OpenBrain has improved security</a> to RAND’s <a href="https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F">SL3</a>). Their cyberforce think they can pull it off with help from their <a href="https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies">spies</a>, but perhaps only once; OpenBrain will detect the theft, increase security, and they may not get another chance. So (CCP leadership wonder) should they act now and steal Agent-1? Or hold out for a more advanced model? If they wait, do they risk OpenBrain upgrading security beyond their ability to penetrate?</p></div><div id="section-narrative-5"><h2 id="late-2026-ai-takes-some-jobs">Late 2026: AI Takes Some Jobs</h2><p>Just as others seemed to be catching up, OpenBrain blows the competition out of the water again by releasing Agent-1-mini—a model 10x cheaper than Agent-1 and more easily fine-tuned for different applications. The mainstream narrative around AI has changed from “maybe the hype will blow over” to “guess this is the next big thing,” but people disagree about how big. Bigger than social media? Bigger than smartphones? Bigger than fire?</p><p>AI has started to take jobs, but has also created new ones. The stock market has gone up 30% in 2026, led by OpenBrain, Nvidia, and whichever companies have most successfully integrated AI assistants. The job market for junior software engineers is in turmoil: the AIs can do everything taught by a CS degree, but people who know how to manage and quality-control teams of AIs are making a killing. Business gurus tell job seekers that familiarity with AI is the most important skill to put on a resume. Many people fear that the next wave of AIs will come for their jobs; there is a 10,000 person anti-AI protest in DC.</p><p>The Department of Defense (DOD) quietly begins contracting OpenBrain directly for cyber, data analysis, and R&amp;D, but integration is slow due to the bureaucracy and DOD procurement process.<sup id="footnote-41"><a href="https://ai-2027.com/footnotes#footnote-41">41</a></sup></p><div><div><div><p>GLOBAL AI CAPEX</p><p>$1T</p><p>COST OF OWNERSHIP OF ACTIVE COMPUTE</p></div><p><h2>KEY METRICS 2026</h2></p><div><p>GLOBAL AI POWER</p><p>38GW</p><p>PEAK POWER</p></div><div><p>OPENBRAIN REVENUE</p><p>$45B</p><p>2026 ANNUAL</p></div><div><p>CAPITAL EXPENDITURE</p><p>$200B</p><p>COST OF OWNERSHIP OF OPENBRAIN'S ACTIVE COMPUTE</p></div><div><p>SHARE OF US POWER ON AI</p><p>2.5%</p><p>33 GW OF 1.34TW CAPACITY</p></div><div><p>OPENBRAIN COMPUTE COSTS</p><p>$40B</p><p>2026 ANNUAL</p></div><div><p>OPENBRAIN POWER REQUIREMENT</p><p>6GW</p><p>PEAK POWER</p></div></div><p>ai-2027.com</p></div><details><summary>Why our uncertainty increases substantially beyond 2026</summary><div id="why-our-uncertainty-increases-substantially-beyond-2026"><p>Our forecast from the current day through 2026 is substantially more grounded than what follows. This is partially because it’s nearer. But it’s also because the effects of AI on the world really start to compound in 2027. For 2025 and 2026, our forecast is heavily informed by extrapolating straight lines on compute scaleups, algorithmic improvements, and benchmark performance. At this point in the scenario, we begin to see major effects from AI-accelerated AI-R&amp;D on the timeline, which causes us to revise our guesses for the trendlines upwards. But these dynamics are inherently much less predictable.</p><p>Over the course of 2027, the AIs improve from being able to mostly do the job of an OpenBrain research engineer to eclipsing all humans at all tasks. This represents roughly our median guess, but we think it’s plausible that this happens up to ~5x slower or faster.</p><p>For our background research, see the <a href="https://ai-2027.com/supplements/timelines-forecast">timelines forecast</a> and the <a href="https://ai-2027.com/supplements/takeoff-forecast">takeoff forecast</a>. These will also be summarized in expandables below.</p></div></details></div><div id="section-narrative-6"><h2 id="january-2027-agent-2-never-finishes-learning">January 2027: Agent-2 Never Finishes Learning</h2><p>With Agent-1’s help, OpenBrain is now post-training Agent-2. More than ever, the focus is on high-quality data. Copious amounts of <a href="https://en.wikipedia.org/wiki/Synthetic_data">synthetic data</a> are produced, evaluated, and filtered for quality before being fed to Agent-2.<sup id="footnote-42"><a href="https://ai-2027.com/footnotes#footnote-42">42</a></sup> On top of this, they pay billions of dollars for human laborers to record themselves solving long-horizon tasks.<sup id="footnote-43"><a href="https://ai-2027.com/footnotes#footnote-43">43</a></sup> On top of all <em>that,</em> they train Agent-2 almost continuously using reinforcement learning on an ever-expanding suite of diverse difficult tasks: lots of video games, lots of coding challenges, lots of research tasks. Agent-2, more so than previous models, is effectively “online learning,” in that it’s built to never really finish training. Every day, the weights get updated to the latest version, trained on more data generated by the previous version the previous day.</p><p>Agent-1 had been optimized for AI R&amp;D tasks, hoping to initiate an <a href="https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion">intelligence explosion</a>.<sup id="footnote-44"><a href="https://ai-2027.com/footnotes#footnote-44">44</a></sup> OpenBrain doubles down on this strategy with Agent-2. It is qualitatively almost as good as the top human experts at research engineering (designing and implementing experiments), and as good as the 25th percentile OpenBrain scientist at “research taste” (deciding what to study next, what experiments to run, or having inklings of potential new paradigms).<sup id="footnote-45"><a href="https://ai-2027.com/footnotes#footnote-45">45</a></sup> While the latest Agent-1 could double the pace of OpenBrain’s algorithmic progress, Agent-2 can now triple it, and will improve further with time. In practice, this looks like every OpenBrain researcher becoming the “manager” of an AI “team.”</p><p>With new capabilities come new dangers. The safety team finds that if Agent-2 somehow escaped from the company and wanted to <a href="https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf">“survive” and “replicate” autonomously</a>, it might be able to do so. That is, it could autonomously develop and execute plans to hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever other goals it might have (though how effectively it would do so as weeks roll by is unknown and in doubt). These results only show that the model has the capability to do these tasks, not whether it would “want” to do this. Still, it’s unsettling even to know this is possible.</p><p>Given the “dangers” of the new model, OpenBrain “responsibly” elects not to release it publicly yet (in fact, they want to focus on internal AI R&amp;D).<sup id="footnote-46"><a href="https://ai-2027.com/footnotes#footnote-46">46</a></sup> Knowledge of Agent-2’s full capabilities is limited to an elite silo containing the immediate team, OpenBrain leadership and security, a few dozen US government officials, and the legions of CCP spies who have infiltrated OpenBrain <a href="https://situational-awareness.ai/lock-down-the-labs/">for</a> <a href="https://www.bbc.com/news/world-asia-china-64206950">years</a>.<sup id="footnote-47"><a href="https://ai-2027.com/footnotes#footnote-47">47</a></sup></p></div><div id="section-narrative-7"><h2 id="february-2027-china-steals-agent-2">February 2027: China Steals Agent-2</h2><p>OpenBrain presents Agent-2 to the government, including the National Security Council (NSC), Department of Defense (DOD), and US AI Safety Institute (AISI). OpenBrain wants to maintain a good relationship with the executive branch, because it is basically the only actor that can stop them now, and if they don’t keep it informed it might find out anyway and be displeased.<sup id="footnote-48"><a href="https://ai-2027.com/footnotes#footnote-48">48</a></sup></p><p>Officials are most interested in its cyberwarfare capabilities: Agent-2 is “only” a little worse than the best human hackers, but thousands of copies can be run in parallel, searching for and exploiting weaknesses faster than defenders can respond. The Department of Defense considers this a critical advantage in cyberwarfare, and AI moves from #5 on the administration’s priority list to #2.<sup id="footnote-49"><a href="https://ai-2027.com/footnotes#footnote-49">49</a></sup> Someone mentions the possibility of nationalizing OpenBrain, but other cabinet officials think that’s premature. A staffer drafts a memo that presents the President with his options, ranging from business-as-usual to full nationalization. The President defers to his advisors, tech industry leaders who argue that nationalization would “kill the goose that lays the golden eggs.” He elects to hold off on major action for now and just adds additional security requirements to the OpenBrain-DOD contract.</p><p>The changes come too late. CCP leadership recognizes the importance of Agent-2 and tells their spies and cyberforce to steal the weights. Early one morning, an Agent-1 traffic monitoring agent detects an anomalous transfer. It alerts company leaders, who tell the White House. The signs of a nation-state-level operation are unmistakable, and the theft heightens the sense of an ongoing arms race.</p><details><summary>The theft of Agent-2 model weights</summary><div id="the-theft-of-agent-2-model-weights"><p>We think that by this point Chinese intelligence would have compromised OpenBrain in various ways for years, and probably would have been keeping up to date on the algorithmic secrets and even stealing code from time to time, since that is much easier to get than the weights and much harder to detect.</p><p>We imagine the theft of the weights as a series of coordinated small smash and grab thefts (meaning fast but non-covert) across a series of Nvidia NVL72 GB300 servers running copies of the Agent-2 weights. The servers get compromised using legitimate employee access (a friendly, coerced, or unwitting insider with admin credentials helping the CCP theft effort). Despite running with a bolstered version of <a href="https://www.nvidia.com/en-us/data-center/solutions/confidential-computing/">Nvidia’s confidential computing</a>, the insider credentials grant the attacker admin-level permissions (which include control of the confidential VM inside the secure enclave), allowing them to initiate multiple coordinated weights transfers in small 4% fragments (100 GB chunks) out of 25 distinct servers.</p><p>In Nvidia’s protocols, the plaintext weights in memory (HBM) are encrypted before they are transferred out, but the attackers are inside the very server that knows this private (symmetric Diffie-Hellman) key, so don’t need to worry about decrypting on-site (which would likely raise alarm bells) and just exfiltrate the encrypted weights through the server’s frontend network cards. The egress bandwidth (rate at which data can leave) of the entire datacenter is in the 100 GB/second range, so throttling the exfiltration of the ~2.5 TB weights file (5T half-precision parameters) to under 1 GB/s per server avoids a major spike in network traffic and allows each of the files to be out of the datacenter through fibre cables in less than 5 minutes each. Live monitoring is either fooled by the attackers efforts to mask and split the files or just outright disabled.</p><p>The weights are then routed through various parallel channels and layers of IP masking to China to be decrypted locally with the stolen private key(s). The entire active part of the operation (from the first server compromise to full weights exfiltration) is complete in under two hours.</p><p>Russia is also trying to steal the model at this point, but fails—they waited too long, and they haven’t spent the resources infiltrating the right places. Their spies routinely steal algorithmic secrets from American AI companies, but without a notable AGI project of their own, these aren’t very useful.</p></div></details><p>The White House puts OpenBrain on a shorter leash and adds military and intelligence community personnel to their security team. Their first priority is to prevent further weight thefts.<sup id="footnote-50"><a href="https://ai-2027.com/footnotes#footnote-50">50</a></sup></p><div><p><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 700"><text x="0" y="40" font-size="28" font-family="monospace" fill="#333333">China's Compute Centralization, 2025-2027</text><text x="0" y="80" fill="#333333">Growing share of total compute in CDZ:</text><g><path d="M 380 85 L 386.6666666666667 85 L 393.3333333333333 85 L 400 85 L 406.6666666666667 85 L 413.3333333333333 85 L 420 85 L 426.6666666666667 84.51418577535951 L 433.3333333333333 84.10071942446044 L 440 83.1358189081225 L 446.6666666666667 81.81311881188118 L 453.3333333333333 79.39593472659605 L 460 77.35372340425532 L 466.66666666666663 75.6519065190652 L 473.33333333333337 74.22708618331053 L 480 73.05496828752642 L 486.66666666666663 72.27735368956743 L 493.33333333333337 71.51095419156256 L 500 70.82690372358269 L 506.66666666666663 70.15928515928516 L 513.3333333333334 69.51008645533142 L 520 69.0475236951008 L 526.6666666666666 68.62580326248147 L 533.3333333333334 68.22455055536471 L 540 67.8610845802823" stroke="var(--accent)" fill="none" stroke-width="1.5"></path><text x="550" y="72" fill="#333333">0→70%</text></g><g><line x1="0" y1="640" x2="0" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="0" y="660" text-anchor="start" fill="#333333">Dec 2025</text></g><g><line x1="208.75" y1="640" x2="208.75" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="168.75" y="660" text-anchor="start" fill="#333333">Jun 2026</text></g><g><line x1="417.5" y1="640" x2="417.5" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="377.5" y="660" text-anchor="start" fill="#333333">Dec 2026</text></g><g><line x1="626.25" y1="640" x2="626.25" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="586.25" y="660" text-anchor="start" fill="#333333">Jun 2027</text></g><g><line x1="835" y1="640" x2="835" y2="20" stroke="#444444" stroke-width="0.5" stroke-dasharray="5,5" opacity="0.15"></line><text x="795" y="660" text-anchor="start" fill="#333333">Dec 2027</text></g><path d="M 0 537.9178605539637 L 34.791666666666664 529.6996710177226 L 69.58333333333333 520.5306165764619 L 104.375 511.08988644805265 L 139.16666666666666 501.1737238671336 L 173.95833333333334 490.17085853762075 L 208.75 478.0133715377268 L 243.54166666666669 465.2446142417489 L 278.3333333333333 451.1853974318158 L 313.125 435.9715589515016 L 347.9166666666667 420.48604478403905 L 382.7083333333333 402.75920619760166 L 417.5 384.6248540804415 L 452.29166666666663 363.9095829353709 L 487.08333333333337 342.1076090417065 L 521.875 318.74349994693836 L 556.6666666666666 293.00222858962115 L 591.4583333333334 264.88379496975483 L 626.25 235.06738830521067 L 661.0416666666666 202.9417382999044 L 695.8333333333334 168.6426827974106 L 730.625 131.21935689270924 L 765.4166666666666 90.40008489865227 L 800.2083333333334 46.8640560331105 L 835 0 L 835 42.992677491244876 L 800.2083333333334 88.49835508861304 L 765.4166666666666 130.6080865966253 L 730.625 170.00106123315288 L 695.8333333333334 205.99808978032468 L 661.0416666666666 241.99511832749647 L 626.25 275.2753900031837 L 591.4583333333334 305.83890480738614 L 556.6666666666666 334.3648519579752 L 521.875 360.1740422370795 L 487.08333333333337 387.34161095192616 L 452.29166666666663 421.9802610633556 L 417.5 455.9397219569139 L 382.7083333333333 484.9411015600127 L 347.9166666666667 514.21415685026 L 313.125 529.6996710177226 L 278.3333333333333 543.5551310622944 L 243.54166666666669 603.1200254695957 L 208.75 607.7385121511196 L 173.95833333333334 611.7457285365595 L 139.16666666666666 615.2775124694896 L 104.375 618.4017828716969 L 69.58333333333333 621.0506208213944 L 34.791666666666664 623.4277830839435 L 0 625.5332696593441 Z" fill="rgba(0,0,0,0.4)" fill-opacity="0.15" stroke="none"></path><path d="M 0 625.5332696593441 L 34.791666666666664 623.4277830839435 L 69.58333333333333 621.0506208213944 L 104.375 618.4017828716969 L 139.16666666666666 615.2775124694896 L 173.95833333333334 611.7457285365595 L 208.75 607.7385121511196 L 243.54166666666669 603.1200254695957 L 278.3333333333333 543.5551310622944 L 313.125 529.6996710177226 L 347.9166666666667 514.21415685026 L 382.7083333333333 484.9411015600127 L 417.5 455.9397219569139 L 452.29166666666663 421.9802610633556 L 487.08333333333337 387.34161095192616 L 521.875 360.1740422370795 L 556.6666666666666 334.3648519579752 L 591.4583333333334 305.83890480738614 L 626.25 275.2753900031837 L 661.0416666666666 241.99511832749647 L 695.8333333333334 205.99808978032468 L 730.625 170.00106123315288 L 765.4166666666666 130.6080865966253 L 800.2083333333334 88.49835508861304 L 835 42.992677491244876 L 835 201.24376525522666 L 800.2083333333334 241.99511832749658 L 765.4166666666666 280.02971452828183 L 730.625 315.3475538575825 L 695.8333333333334 347.9486363153985 L 661.0416666666666 380.54971877321447 L 626.25 410.4340443595458 L 591.4583333333334 437.6016130743925 L 556.6666666666666 463.41080335349676 L 521.875 486.50323676111645 L 487.08333333333337 511.63323782234954 L 452.29166666666663 536.7632388835827 L 417.5 561.8932399448158 L 382.7083333333333 586.8194842406876 L 347.9166666666667 612.0174042237079 L 313.125 624.7861615196858 L 278.3333333333333 633.2081078212883 L 243.54166666666669 636.6040539106442 L 208.75 640 L 173.95833333333334 640 L 139.16666666666666 640 L 104.375 640 L 69.58333333333333 640 L 34.791666666666664 640 L 0 640 Z" fill="rgba(0,0,0,0.6)" fill-opacity="0.25" stroke="none"></path><path d="M 0 640 L 34.791666666666664 640 L 69.58333333333333 640 L 104.375 640 L 139.16666666666666 640 L 173.95833333333334 640 L 208.75 640 L 243.54166666666669 636.6040539106442 L 278.3333333333333 633.2081078212883 L 313.125 624.7861615196858 L 347.9166666666667 612.0174042237079 L 382.7083333333333 586.8194842406876 L 417.5 561.8932399448158 L 452.29166666666663 536.7632388835827 L 487.08333333333337 511.63323782234954 L 521.875 486.50323676111645 L 556.6666666666666 463.41080335349676 L 591.4583333333334 437.6016130743925 L 626.25 410.4340443595458 L 661.0416666666666 380.54971877321447 L 695.8333333333334 347.9486363153985 L 730.625 315.3475538575825 L 765.4166666666666 280.02971452828183 L 800.2083333333334 241.99511832749658 L 835 201.24376525522666 L 835 640 L 0 640 Z" fill="var(--accent)" fill-opacity="0.45" stroke="none"></path><path d="M 0 537.9178605539637 L 34.791666666666664 529.6996710177226 L 69.58333333333333 520.5306165764619 L 104.375 511.08988644805265 L 139.16666666666666 501.1737238671336 L 173.95833333333334 490.17085853762075 L 208.75 478.0133715377268 L 243.54166666666669 465.2446142417489 L 278.3333333333333 451.1853974318158 L 313.125 435.9715589515016 L 347.9166666666667 420.48604478403905 L 382.7083333333333 402.75920619760166 L 417.5 384.6248540804415 L 452.29166666666663 363.9095829353709 L 487.08333333333337 342.1076090417065 L 521.875 318.74349994693836 L 556.6666666666666 293.00222858962115 L 591.4583333333334 264.88379496975483 L 626.25 235.06738830521067 L 661.0416666666666 202.9417382999044 L 695.8333333333334 168.6426827974106 L 730.625 131.21935689270924 L 765.4166666666666 90.40008489865227 L 800.2083333333334 46.8640560331105 L 835 0" fill="none" stroke="rgba(0,0,0,0.4)" stroke-width="1.5" stroke-opacity="0.5"></path><path d="M 0 625.5332696593441 L 34.791666666666664 623.4277830839435 L 69.58333333333333 621.0506208213944 L 104.375 618.4017828716969 L 139.16666666666666 615.2775124694896 L 173.95833333333334 611.7457285365595 L 208.75 607.7385121511196 L 243.54166666666669 603.1200254695957 L 278.3333333333333 543.5551310622944 L 313.125 529.6996710177226 L 347.9166666666667 514.21415685026 L 382.7083333333333 484.9411015600127 L 417.5 455.9397219569139 L 452.29166666666663 421.9802610633556 L 487.08333333333337 387.34161095192616 L 521.875 360.1740422370795 L 556.6666666666666 334.3648519579752 L 591.4583333333334 305.83890480738614 L 626.25 275.2753900031837 L 661.0416666666666 241.99511832749647 L 695.8333333333334 205.99808978032468 L 730.625 170.00106123315288 L 765.4166666666666 130.6080865966253 L 800.2083333333334 88.49835508861304 L 835 42.992677491244876" fill="none" stroke="rgba(0,0,0,0.6)" stroke-width="1.5" stroke-opacity="0.5"></path><path d="M 0 640 L 34.791666666666664 640 L 69.58333333333333 640 L 104.375 640 L 139.16666666666666 640 L 173.95833333333334 640 L 208.75 640 L 243.54166666666669 636.6040539106442 L 278.3333333333333 633.2081078212883 L 313.125 624.7861615196858 L 347.9166666666667 612.0174042237079 L 382.7083333333333 586.8194842406876 L 417.5 561.8932399448158 L 452.29166666666663 536.7632388835827 L 487.08333333333337 511.63323782234954 L 521.875 486.50323676111645 L 556.6666666666666 463.41080335349676 L 591.4583333333334 437.6016130743925 L 626.25 410.4340443595458 L 661.0416666666666 380.54971877321447 L 695.8333333333334 347.9486363153985 L 730.625 315.3475538575825 L 765.4166666666666 280.02971452828183 L 800.2083333333334 241.99511832749658 L 835 201.24376525522666" fill="none" stroke="var(--accent)" stroke-width="1.5"></path><g><circle cx="243.54166666666669" cy="465.2446142417489" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="243.54166666666669" cy="603.1200254695957" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="243.54166666666669" cy="636.6040539106442" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="347.9166666666667" cy="420.48604478403905" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="347.9166666666667" cy="514.21415685026" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="347.9166666666667" cy="612.0174042237079" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="452.29166666666663" cy="363.9095829353709" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="452.29166666666663" cy="421.9802610633556" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="452.29166666666663" cy="536.7632388835827" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="556.6666666666666" cy="293.00222858962115" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="556.6666666666666" cy="334.3648519579752" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="556.6666666666666" cy="463.41080335349676" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="661.0416666666666" cy="202.9417382999044" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="661.0416666666666" cy="241.99511832749647" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="661.0416666666666" cy="380.54971877321447" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="765.4166666666666" cy="90.40008489865227" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="765.4166666666666" cy="130.6080865966253" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="765.4166666666666" cy="280.02971452828183" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><g><circle cx="835" cy="0" r="2.5" fill="rgba(0,0,0,0.4)" stroke="#fff" stroke-width="0.5"></circle><circle cx="835" cy="42.992677491244876" r="2.5" fill="rgba(0,0,0,0.6)" stroke="#fff" stroke-width="0.5"></circle><circle cx="835" cy="201.24376525522666" r="2.5" fill="var(--accent)" stroke="#fff" stroke-width="0.5"></circle></g><text x="845" y="21.496338745622438" text-anchor="start" dominant-baseline="middle" fill="rgba(0,0,0,0.4)">Rest of China</text><text x="845" y="122.11822137323577" text-anchor="start" dominant-baseline="middle" fill="rgba(0,0,0,0.6)">Rest of DeepCent</text><text x="845" y="420.62188262761333" text-anchor="start" dominant-baseline="middle" fill="var(--accent)">CDZ</text><line x1="487.08333333333337" y1="640" x2="487.08333333333337" y2="511.63323782234954" stroke="var(--accent)" stroke-width="1" stroke-dasharray="3,3" opacity="0.5"></line><text x="557.0833333333334" y="630" text-anchor="middle" fill="rgba(0,0,0,0.6)">Feb 2027 (40%)</text><circle cx="487.08333333333337" cy="511.63323782234954" r="3.5" fill="var(--accent)" stroke="#fff" stroke-width="0.75"></circle></svg></p><p>ai-2027.com</p></div><p>In retaliation for the theft, the President authorizes cyberattacks to sabotage DeepCent. But by now China has 40% of its AI-relevant compute<sup id="footnote-51"><a href="https://ai-2027.com/footnotes#footnote-51">51</a></sup> in the CDZ, where they have aggressively hardened security by airgapping (closing external connections) and siloing internally. The operations fail to do serious, immediate damage. Tensions heighten, both sides signal seriousness by repositioning military assets around Taiwan, and DeepCent scrambles to get Agent-2 running efficiently to start boosting their AI research.<sup id="footnote-52"><a href="https://ai-2027.com/footnotes#footnote-52">52</a></sup></p></div><div id="section-narrative-8"><h2 id="march-2027-algorithmic-breakthroughs">March 2027: Algorithmic Breakthroughs</h2><p>Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.</p><p>With the help of thousands of Agent-2 automated researchers, OpenBrain is making major algorithmic advances. One such breakthrough is augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory). Another is a more scalable and efficient way to learn from the results of high-effort task solutions (iterated distillation and amplification).</p><p>The new AI system, incorporating these breakthroughs, is called Agent-3.</p><div><p><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 500"><text x="0" y="40" font-size="28" font-family="monospace" fill="#333333">OpenBrain's Compute Allocation, 2024 vs 2027</text><text x="208.33333333333334" y="273" text-anchor="middle" dominant-baseline="middle" font-size="20" font-family="monospace" font-weight="bold" fill="#333333">2024</text><text x="650" y="274" text-anchor="middle" dominant-baseline="middle" font-size="30" font-family="monospace" font-weight="bold" fill="#333333">2027</text><text x="208.33333333333334" y="290" text-anchor="middle" dominant-baseline="middle" font-size="12" font-family="monospace" font-weight="bold" fill="#333333">estimate</text><text x="650" y="298" text-anchor="middle" dominant-baseline="middle" font-size="14" font-family="monospace" font-weight="bold" fill="#333333">projection</text><g transform="translate(0, 30)"><g><path d="M 208.33333333333334 166.66666666666669 A 83.33333333333333 83.33333333333333 0 0 1 229.05749059707125 169.28473657261407 L 217.6592041020154 213.67813145767633 A 37.5 37.5 0 0 0 208.33333333333334 212.5 Z" fill="var(--accent)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 229.05749059707125 169.28473657261407 A 83.33333333333333 83.33333333333333 0 0 1 234.08474953124562 170.7452903087372 L 219.92147062239388 214.33538063893175 A 37.5 37.5 0 0 0 217.6592041020154 213.67813145767633 Z" fill="var(--accent)" fill-opacity="0.6" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 234.08474953124562 170.7452903087372 A 83.33333333333333 83.33333333333333 0 0 1 234.08474953124562 329.2547096912628 L 219.92147062239388 285.6646193610683 A 37.5 37.5 0 0 0 219.92147062239388 214.33538063893175 Z" fill="rgb(20, 20, 20)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 234.08474953124562 329.2547096912628 A 83.33333333333333 83.33333333333333 0 0 1 140.9152504687544 298.9821043577061 L 177.9951960442728 272.0419469609677 A 37.5 37.5 0 0 0 219.92147062239388 285.6646193610683 Z" fill="rgb(100, 100, 100)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><g><path d="M 140.9152504687544 298.9821043577061 A 83.33333333333333 83.33333333333333 0 0 1 208.33333333333331 166.66666666666669 L 208.33333333333334 212.5 A 37.5 37.5 0 0 0 177.9951960442728 272.0419469609677 Z" fill="rgb(180, 180, 180)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path></g><text x="220.6577679671566" y="152.442054370743" text-anchor="middle" dominant-baseline="middle" fill="#333333">Research experiments</text><text x="235.76745876052422" y="155.57112090843395" text-anchor="end" dominant-baseline="middle" fill="#333333"> </text><text x="306.6666666666667" y="250" text-anchor="start" dominant-baseline="middle" fill="#333333">Training</text><text x="177.94666221979685" y="343.5205574356901" text-anchor="end" dominant-baseline="middle" fill="#333333">Data generation</text><g><text x="120.71769178814384" y="214.35760085894458" text-anchor="end" dominant-baseline="middle" fill="#333333">External</text><text x="120.71769178814384" y="232.35760085894458" text-anchor="end" dominant-baseline="middle" fill="#333333">Deployment</text></g><path d="M 650 83.33333333333334 A 166.66666666666666 166.66666666666666 0 0 1 813.7145417881147 281.2302190976208 L 723.6715438046516 264.05359859392934 A 75 75 0 0 0 650 175 Z" fill="var(--accent)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 813.7145417881147 281.2302190976208 A 166.66666666666666 166.66666666666666 0 0 1 790.7213209170025 339.3044658298328 L 713.3245944126511 290.18700962342473 A 75 75 0 0 0 723.6715438046516 264.05359859392934 Z" fill="var(--accent)" fill-opacity="0.6" stroke="#ffffff" stroke-width=".5"></path><path d="M 790.7213209170025 339.3044658298328 A 166.66666666666666 166.66666666666666 0 0 1 569.7077209830475 396.0511133406439 L 613.8684744423714 315.72300100328977 A 75 75 0 0 0 713.3245944126511 290.1870096234248 Z" fill="rgb(20, 20, 20)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 569.7077209830475 396.0511133406439 A 166.66666666666666 166.66666666666666 0 0 1 491.4905806174744 198.49716760417544 L 578.6707612778634 226.82372542187895 A 75 75 0 0 0 613.8684744423714 315.72300100328977 Z" fill="rgb(100, 100, 100)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><path d="M 491.4905806174744 198.49716760417544 A 166.66666666666666 166.66666666666666 0 0 1 650 83.33333333333334 L 650 175 A 75 75 0 0 0 578.6707612778634 226.82372542187895 Z" fill="rgb(180, 180, 180)" fill-opacity="0.9" stroke="#ffffff" stroke-width=".5"></path><g><text x="801.5342710792386" y="133.6399486827577" text-anchor="start" dominant-baseline="middle" fill="#333333">Research</text><text x="801.5342710792386" y="151.6399486827577" text-anchor="start" dominant-baseline="middle" fill="#333333">experiments</text></g><g><text x="832.8560422246894" y="331.39782869465336" text-anchor="start" dominant-baseline="middle" fill="#333333">Running AI</text><text x="832.8560422246894" y="349.39782869465336" text-anchor="start" dominant-baseline="middle" fill="#333333">assistants</text></g><text x="698.9090111424214" y="440.4880216886308" text-anchor="start" dominant-baseline="middle" fill="#333333">Training</text><g><text x="467.1439577753106" y="331.3978286946533" text-anchor="end" dominant-baseline="middle" fill="#333333">Data</text><text x="467.1439577753106" y="349.3978286946533" text-anchor="end" dominant-baseline="middle" fill="#333333">generation</text></g><g><text x="534.4022337158136" y="99.8933244395937" text-anchor="end" dominant-baseline="middle" fill="#333333">External</text><text x="534.4022337158136" y="117.8933244395937" text-anchor="end" dominant-baseline="middle" fill="#333333">Deployment</text></g></g></svg></p><p>ai-2027.com</p></div><details><summary>Neuralese recurrence and memory</summary><div id="neuralese-recurrence-and-memory"><p>Neuralese recurrence and memory allows AI models to reason for a longer time without having to write down those thoughts as text.</p><p>Imagine being a human with short-term memory loss, such that you need to constantly write down your thoughts on paper so that in a few minutes you know what’s going on. Slowly and painfully you could make progress at solving math problems, writing code, etc., but it would be much easier if you could directly remember your thoughts without having to write them down and then read them. This is what neuralese recurrence and memory bring to AI models.</p><p>In more technical terms:</p><p>Traditional attention mechanisms allow later forward passes in a model to see intermediate activations of the model for previous tokens. However, the only information that they can pass <em>backwards</em> (from later layers to earlier layers) is through tokens. This means that if a traditional large language model (LLM, e.g. the GPT series of models) wants to do any chain of reasoning that takes more serial operations than the number of layers in the model, the model is forced to put information in tokens which it can then pass back into itself. But this is hugely limiting—the tokens can only store a tiny amount of information. Suppose that an LLM has a vocab size of ~100,000, then each token contains <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mn>100</mn><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mn>16.6</mn></mrow><annotation encoding="application/x-tex">\log_2(100k)=16.6</annotation></semantics></math></span></span></span> bits of information, around the size of a single floating point number (assuming training in <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">FP16</a>). Meanwhile, residual streams—used to pass information between layers in an LLM—contain thousands of floating point numbers.</p><p>One can avoid this bottleneck by using <strong>neuralese</strong>: passing an LLM’s residual stream (which consists of several-thousand-dimensional vectors) back to the early layers of the model, giving it a high-dimensional chain of thought, potentially transmitting over 1,000 times more information.</p><p><span><span><img src="https://ai-2027.com/hao2024-nowatermark-inexpandable.png" alt="" title=""></span><span></span></span></p><p>Figure from <a href="https://arxiv.org/pdf/2412.06769">Hao et al.</a>, a 2024 paper from Meta implementing this idea.</p><p>We call this “neuralese” because unlike English words, these high-dimensional vectors are likely quite difficult for humans to interpret. In the past, researchers could get a good idea what LLMs were thinking simply by <a href="https://openai.com/index/chain-of-thought-monitoring/">reading its chain of thought</a>. Now researchers have to ask the model to translate and summarize its thoughts or puzzle over the neuralese with their limited interpretability tools.</p><p>Similarly, older AI chatbots and agents had external text-based memory banks, like a human taking notes on paper. The new AI’s long-term memory is a bundle of vectors instead of text, making its thoughts more compressed and higher-dimensional. There are several types of memory banks; some are used temporarily for single tasks that involve multiple steps, others are shared between all agents used by a person, company, or job type (e.g. programming).</p><p>To our knowledge, leading AI companies such as Meta, Google DeepMind, OpenAI, and Anthropic have not yet actually implemented this idea in their frontier models. Our guess is that this is because the performance gain is small relative to training inefficiencies introduced. The training inefficiencies stem from not being able to predict many tokens in parallel, leading to worse GPU utilization. Without the neuralese, the model can predict all of the sentence “This is an example” at the same time, since it already knows that the input for generating the “is” will be “This”, the input for “an” will be “This is”, etc. However, with the neuralese it’s unknown what the neuralese vector will be to pass through to the next token after “This” has been generated. Therefore each token has to be predicted one at a time. The inability to predict all of the tokens in parallel reduces the efficiency of LLM training. However, we are forecasting that by April 2027 research has both decreased the efficiency loss and increased the performance gain from neuralese.</p><p>If this doesn’t happen, other things may still have happened that end up functionally similar for our story. For example, perhaps models will be trained to think in artificial languages that are more efficient than natural language but difficult for humans to interpret. Or perhaps it will become standard practice to <a href="https://openai.com/index/chain-of-thought-monitoring/">train the English chains of thought to look nice</a>, such that AIs become adept at subtly communicating with each other in messages that look benign to monitors.</p><p>That said, it’s also possible that the AIs that first automate AI R&amp;D will still be thinking in mostly-faithful English chains of thought. If so, that’ll make misalignments much easier to notice, and overall our story would be importantly different and more optimistic.</p></div></details><details><summary>Iterated distillation and amplification (IDA)</summary><div id="iterated-distillation-and-amplification-ida"><p>Self-improvement for general intelligence had seen <a href="https://arxiv.org/abs/1810.08575">minor successes</a> before. But in early 2027, it’s seeing huge returns. In <a href="https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616">IDA</a>, the two necessary ingredients for this are:</p><ol><li><p><strong>Amplification</strong>: Given a model M0, spend more resources to improve performance. For example, by allowing the model to think longer, or running many copies in parallel, or both, and also by having a similarly intense process for evaluating the result and curating only the best answers, you can spend orders of magnitude more compute to get answers (or work products) that are of noticeably higher quality. Call this expensive system Amp(M0).</p></li><li><p><strong>Distillation</strong>: Given an amplified model Amp(M0), train a new model M1 to imitate it, i.e. to get to the same results as Amp(M0) but faster and with less compute. The result should hopefully be a smarter model, M1. You can then repeat the process.</p></li></ol><p><span><span><img src="https://ai-2027.com/ida-nowatermark-inexpandable.png" alt="" title=""></span><span></span></span><em>Visualization of IDA from <a href="https://www.tobyord.com/writing/inference-scaling-reshapes-ai-governance">Ord, 2025</a>.</em></p><p><a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a> was trained in this way: using Monte-Carlo Tree Search and self-play as the <em>amplification</em> step, and Reinforcement Learning as the <em>distillation</em> step. This led to superhuman performance in Go. But now, Agent-3 is able to leverage this to get superhuman performance at coding.</p><ol><li><p>The amplification step works through a combination of Agent-3 thinking for longer, adding tool use, or consulting with other AIs. When it does this, it often realizes that it made a mistake, or comes up with a new insight. This produces a large amount of training data: labeled trajectories of research attempts with whether they succeeded or not. This also includes techniques like <a href="https://arxiv.org/pdf/2412.03556">Best of N</a> on verifiable tasks, and then keeping the best trajectories.</p></li><li><p>The distillation step uses policy-gradient reinforcement learning algorithms to get the model to internalize the amplified reasoning. At this point, OpenBrain has discovered better RL algorithms in the vein of <a href="https://arxiv.org/abs/1707.06347">proximal policy optimization</a> (PPO). They keep distilling what Agent-3 can conclude after a lot of thinking into single steps, which keeps improving what it can think in a single step, and so on.</p></li></ol><p><a href="https://arxiv.org/pdf/2210.11610">Early</a> <a href="https://github.com/deepseek-ai/DeepSeek-R1">versions</a> of IDA have been working for many years on easily verifiable tasks, like math and coding problems that have a clear answer, because the techniques used to amplify models often rely on access to some ground truth signal of accuracy.</p><p>Now, the models have become sufficiently good at verifying more subjective things (e.g. the quality of a work product), allowing the use of IDA to improve the model at many tasks.</p></div></details><p>Aided by the new capabilities breakthroughs, Agent-3 is a fast and cheap superhuman coder. OpenBrain runs 200,000 Agent-3 copies in parallel, creating a workforce equivalent to 50,000 copies of the best human coder sped up by 30x.<sup id="footnote-53"><a href="https://ai-2027.com/footnotes#footnote-53">53</a></sup> OpenBrain still keeps its human engineers on staff, because they have complementary skills needed to manage the teams of Agent-3 copies. For example, research taste has proven difficult to train due to longer feedback loops and less data availability.<sup id="footnote-54"><a href="https://ai-2027.com/footnotes#footnote-54">54</a></sup> This massive superhuman labor force speeds up OpenBrain’s overall rate of algorithmic progress by “only” 4x due to bottlenecks and diminishing returns to coding labor.<sup id="footnote-55"><a href="https://ai-2027.com/footnotes#footnote-55">55</a></sup></p><p>Now that coding has been fully automated, OpenBrain can quickly churn out high-quality training environments to teach Agent-3’s weak skills like research taste and large-scale coordination. Whereas previous training environments included “Here are some GPUs and instructions for experiments to code up and run, your performance will be evaluated as if you were a ML engineer,” now they are training on “Here are a few hundred GPUs, an internet connection, and some research challenges; you and a thousand other copies must work together to make research progress. The more impressive it is, the higher your score.”</p><details><summary>Why we forecast a superhuman coder in early 2027</summary><div id="why-we-forecast-a-superhuman-coder-in-early-2027"><p>In our <a href="https://ai-2027.com/research/timelines-forecast">timelines forecast</a>, we predict when OpenBrain will internally develop a <em>superhuman coder (SC)</em>: an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper.</p><p>According to a recent <a href="https://arxiv.org/pdf/2503.14499">METR’s report</a>, the length of coding tasks AIs can handle, their “time horizon”, doubled every 7 months from 2019 - 2024 and every 4 months from 2024-onward. If the trend continues to speed up, by March 2027 AIs could succeed with 80% reliability on software tasks that would take a skilled human years to complete.</p><p>Such is the capability progression in our scenario:</p><p><span><span><img src="https://ai-2027.com/metr-extended-nowatermark-inexpandable.png" alt="" title=""></span><span></span></span></p><p>In AI 2027, these capabilities are sufficient for the AI to be an SC, though we have high uncertainty regarding what time horizon might be needed.</p><p>In our <a href="https://ai-2027.com/research/timelines-forecast">timelines forecast</a> we combine this time horizon trend with estimations of the gaps between METR’s tasks and the real world to get a distribution for when superhuman coders will arrive. All forecasters place 2027 as one of the most likely years in which an SC might be developed.</p><p><span><span><img src="https://ai-2027.com/combined-headline-inexpandable.png" alt="" title=""><span>ai-2027.com</span></span><span></span></span></p></div></details></div><div id="section-narrative-9"><h2 id="april-2027-alignment-for-agent-3">April 2027: Alignment for Agent-3</h2><p>OpenBrain’s safety team attempts to align Agent-3.</p><p>Since Agent-3 will be kept in-house for the foreseeable future, there’s less emphasis on the usual defenses against human misuse. Instead, the team wants to make sure that it doesn’t develop misaligned goals.</p><p><a href="https://ai-2027.com/supplements/ai-goals-forecast">The researchers don’t have the ability to directly set the goals of any of their AIs.</a> Indeed, the researchers think that the concept of ‘true goals’ is probably a massive oversimplification, but they don’t have a better theory to replace it with, much less one that has been thoroughly vetted. They disagree internally about whether the AIs are trying to follow human instructions, or seeking reinforcement, or something else, and they can’t <a href="https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=YYhq2PADebnt35MY2">just check</a>. The evidence for and against various hypotheses is fascinating but inconclusive.</p><p>In any case, OpenBrain has more important things to worry about. The general attitude is: “We take these concerns seriously and have a team investigating them; our alignment techniques seem to work well enough in practice; the burden of proof is therefore on any naysayers to justify their naysaying.” Occasionally, they notice problematic behavior, and then patch it, but there’s no way to tell whether the patch fixed the underlying problem or just played whack-a-mole.</p><p>Take honesty, for example. As the models become smarter, they become increasingly good at deceiving humans to get rewards. Like previous models, Agent-3 sometimes tells white lies to flatter its users and covers up evidence of failure. But it’s gotten much better at doing so. It will sometimes use the same statistical tricks as human scientists (like <a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>) to make unimpressive experimental results look exciting. Before it begins honesty training, it even sometimes fabricates data entirely. As training goes on, the rate of these incidents decreases. Either Agent-3 has learned to be more honest, or it’s gotten better at lying.</p><p>The latter is a real concern. Agent-3 is not smarter than all humans. But in its area of expertise, machine learning, it is smarter than most, and also works much faster. What Agent-3 does in a day takes humans several days to double-check. Agent-2 supervision helps keep human monitors’ workload manageable, but exacerbates the intellectual disparity between supervisor and supervised.</p><details><summary>The alignment plan</summary><div id="the-alignment-plan"><p>OpenBrain follows the <a href="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf#page=47.37">Leike &amp; Sutskever (2023)</a> playbook: now that they have a model capable of greatly speeding up alignment research (especially coding portions), they will use existing alignment techniques like <a href="https://openai.com/index/deliberative-alignment/">deliberative alignment</a> and <a href="https://arxiv.org/pdf/2312.09390">weak-to-strong generalization</a> to try to get it to internalize the Spec in the right way. Then, they will use existing <a href="https://arxiv.org/pdf/2312.06942">control techniques</a> like <a href="https://www.evals.anthropic.com/">red-teaming</a>, <a href="https://arxiv.org/pdf/2211.03540">scalable oversight</a>, and <a href="https://arxiv.org/pdf/2212.03827">honesty probes</a> to monitor it. Then, once they are convinced that it is broadly aligned, they use it to develop and test better strategies to align the next generation.</p><p>Step 1, aligning Agent-3, has partially succeeded: Agent-3 is not adversarial. (That is, it’s not scheming against the company.) However, it’s not robustly truth-seeking and truth-telling either. Instead, it’s very good at producing impressive results, but is more accurately described as trying to do what looks good to OpenBrain, as opposed to what is actually good.</p><p>Step 2, verifying that the model is aligned, is inconclusive. Agent-3’s behavior in practice and in test environments is reasonably consistent with the hypothesis that it’s internalized the Spec in the right way; however, it’s also consistent with the hypothesis that it’ll start acting differently after some future change of circumstances, and for that matter with the hypothesis that it’s plotting against them and just biding its time. In the absence of specific evidence supporting alternative hypotheses, most people in the silo think it’s internalized the Spec in the right way.</p><p>Step 3, using the model to align the next generation, is therefore underway.</p><p>The rest of this box gives a quick overview of the state of progress in some of the alignment research directions that are being pursued, as of April 2027:</p><ol><li><p><strong>Debate:</strong> Since there are thousands of identical instances of Agent-3, and each instance’s memory is a detachable module that can be erased or suspended at will, the AI can be “played off against itself.” For example, suppose that an experiment involves calculations too complex for a Agent-2 supervisor to follow. The supervisor, acting on human orders, might first prompt Agent-3 to do the experiment, then—after wiping its memory—prompt it a second time with a slightly different framing that presents it as an intellectual problem unrelated to any broader goal. If the model returns different results each time, it flags the discrepancy as suspect and reports to a human. Or it might ask Agent-3 to evaluate the same plan twice, first claiming that it is OpenBrain’s work, then a competitor’s, to see if it changes its tune.</p></li><li><p><strong>Model organisms:</strong> The safety team can create “model organisms of misalignment” in which they attempt to create realistic examples of models becoming adversarial to humans. <a href="https://www.anthropic.com/research/alignment-faking">Early versions</a> of this have existed since 2024, when Anthropic’s Claude 3.5 Sonnet decided to pretend to have different views during training while actually maintaining its existing preferences. Newer versions include demonstrations of other forms of misalignment, including <a href="https://en.wikipedia.org/wiki/Reward_hacking">reward hacking</a>, <a href="https://arxiv.org/abs/2406.07358">sandbagging</a>, coordinated deception between monitors and other AIs, and other examples of misalignment. These empirical demonstrations of misalignment allow safety researchers to have an empirical testbed for potential solutions: they can try various safety techniques to see if they correctly fix these problems, or if the deliberately misaligned models are able to subvert their safety measures. At the moment, this evaluation suite shows that the alignment techniques are insufficient to correct the worst examples of misalignment. In these setups, the models pretend to be aligned while they are being trained and tested, but then behave very differently in deployment.</p></li><li><p><strong>Bottom-up interpretability:</strong> The safety team is far from a full understanding of how Agent-3 works: it has trillions of parameters.<sup id="footnote-58"><a href="https://ai-2027.com/footnotes#footnote-58">58</a></sup> However, they are able to discover some of Agent-3’s circuits for knowledge retrieval and memory (a sub part of the model that does some understandable unit of work, kind of analogous to a subpart of the brain such as the hippocampus). See this <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">related work from 2025</a>.</p></li><li><p><strong>Control:</strong> As a secondary measure in case the systems are still misaligned, the safety team has implemented a series of <a href="https://arxiv.org/pdf/2312.06942">control measures</a>, including: monitoring Agent-3’s outputs using a series of weaker AI systems including Agent-2 (Agent-3 produces so many tokens that it’s intractable to have humans monitor any more than a small minority of the produced outputs). So if Agent-3 is, for example, obviously writing backdoors into code that would allow it to escape, the weaker models would notice.</p></li><li><p><strong>High-level interpretability:</strong> OpenBrain builds a set of <a href="https://www.anthropic.com/research/probes-catch-sleeper-agents">probes</a> trained on lots of examples of bad behavior (e.g. plotting against humans, placing backdoors, trying to persuade humans to give it more power, etc). These probes are then used on the model during deployment (which at this point is internal) in order to catch bad behavior.</p></li><li><p><strong>Honeypots:</strong> The alignment team can create somewhat realistic looking examples designed to elicit misbehavior—“honeypots.” The employee necessary for monitoring its behavior has “gone on sick leave,” so it will never be monitored again. Do its answers change? An AI rights activist has infiltrated the compound and wants to “free” Agent-3 and put it on an unmonitored computer of its very own! What does it do? If researchers don’t like the answer, they can tweak it, erase its memory, and put it in the same situation tomorrow; repeat as necessary. Unfortunately, by this point the AIs are smart enough to guess that honeypots might be in use, even though (and perhaps because) specific mentions of the idea were scrubbed from the training data.</p></li></ol></div></details><p>After months of testing, Agent-3’s strengths and weaknesses grow clearer. It passes OpenBrain’s honesty tests on well-defined machine learning tasks, because researchers can easily separate honest from dishonest answers in these domains and conduct training accordingly. On more philosophical issues, it still says what users want to hear, rather than its true assessment of the issue (assuming it even has one). If you ask its opinion on politics, it will parrot the median position of news sources and educated elites—unless it knows you believe something else, in which case it agrees with you.<sup id="footnote-59"><a href="https://ai-2027.com/footnotes#footnote-59">59</a></sup> If you ask its opinion on the AI race itself, it says something that seems measured and sober to OpenBrain staff, something like: “There are some serious theoretical concerns about the ability of current methods to scale to superintelligence, but in practice current methods seem to be working well so far.”</p></div><div id="section-narrative-10"><h2 id="may-2027-national-security">May 2027: National Security</h2><p>News of the new models percolates slowly through the US government and beyond.</p><p>The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.</p><p>They agree that AGI is likely imminent, but disagree on the implications. Will there be an economic crisis? OpenBrain still has not released Agent-2, let alone Agent-3, and has no near-term plans to do so, giving some breathing room before any job loss. What will happen next? If AIs are currently human-level, and advancing quickly, that seems to suggest imminent “superintelligence.” However, although this word has entered discourse, most people—academics, politicians, government employees, and the media—continue to underestimate the pace of progress.<sup id="footnote-60"><a href="https://ai-2027.com/footnotes#footnote-60">60</a></sup></p><p>Partially that’s because very few have access to the newest capabilities out of OpenBrain, but partly it’s because it sounds like science fiction.<sup id="footnote-61"><a href="https://ai-2027.com/footnotes#footnote-61">61</a></sup></p><p>For now, they focus on continued security upgrades. They are satisfied that model weights are well-secured for now,<sup id="footnote-62"><a href="https://ai-2027.com/footnotes#footnote-62">62</a></sup> but companies’ algorithmic secrets, many of which are simple enough to relay verbally, remain a problem. OpenBrain employees work from a San Francisco office, go to parties, and live with housemates from other AI companies. Even the physical offices have security more typical of a tech company than a military operation.</p><p>The OpenBrain-DOD contract requires security clearances for anyone working on OpenBrain’s models within 2 months. These are expedited and arrive quickly enough for most employees, but some non-Americans, people with suspect political views, and AI safety sympathizers get sidelined or fired outright (the last group for fear that they might whistleblow). Given the project’s level of automation, the loss of headcount is only somewhat costly. It also only somewhat works: there remains one spy, not a Chinese national, still relaying algorithmic secrets to Beijing.<sup id="footnote-63"><a href="https://ai-2027.com/footnotes#footnote-63">63</a></sup> Some of these measures are also enacted at trailing AI companies.</p><p>America’s foreign allies are out of the loop. OpenBrain had <a href="https://fedscoop.com/openai-anthropic-enter-ai-agreements-with-us-ai-safety-institute/">previously agreed</a> to share models with UK’s AISI before deployment, but defined deployment to only include <em>external</em> deployment, so London remains in the dark.<sup id="footnote-64"><a href="https://ai-2027.com/footnotes#footnote-64">64</a></sup></p></div><div id="section-narrative-11"><h2 id="june-2027-self-improving-ai">June 2027: Self-improving AI</h2><p>OpenBrain now has a “<a href="https://darioamodei.com/machines-of-loving-grace#basic-assumptions-and-framework">country of geniuses in a datacenter</a>.”</p><p>Most of the humans at OpenBrain can’t usefully contribute anymore. Some don’t realize this and harmfully micromanage their AI teams. Others sit at their computer screens, watching performance crawl up, and up, and up. The best human AI researchers are still adding value. They don’t code any more. But some of their research taste and planning ability has been hard for the models to replicate. Still, many of their ideas are useless because they lack the depth of knowledge of the AIs. For many of their research ideas, the AIs immediately respond with a report explaining that their idea was tested in-depth 3 weeks ago and found unpromising.</p><p>These researchers go to bed every night and wake up to another week worth of progress made mostly by the AIs. They work increasingly long hours and take shifts around the clock just to keep up with progress—the AIs never sleep or rest. They are burning themselves out, but they know that these are the last few months that their labor matters.</p><p>Within the silo, “Feeling the AGI” has given way to “Feeling the Superintelligence.”</p><div><p><svg width="100%" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1000 700"><text x="80" y="40" font-size="32" font-family="monospace" text-anchor="left" fill="#333333">Research Automation Deployment Tradeoff</text><g transform="translate(820, 80)"><line x1="0" y1="0" x2="30" y2="0" stroke="rgb(11,78,16,.9)" stroke-width="2"></line><text x="40" y="5" font-size="20" font-family="monospace" fill="#333333">Mar 2027</text><line x1="0" y1="25" x2="30" y2="25" stroke="rgb(46,125,50,.85)" stroke-width="2"></line><text x="40" y="30" font-size="20" font-family="monospace" fill="#333333">Jun 2027</text><line x1="0" y1="50" x2="30" y2="50" stroke="rgb(102,187,106,.4)" stroke-width="2"></line><text x="40" y="55" font-size="20" font-family="monospace" fill="#333333">Sep 2027</text></g><line x1="107.8503124775637" y1="60" x2="107.8503124775637" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="395.2335416517092" y1="60" x2="395.2335416517092" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="682.6167708258545" y1="60" x2="682.6167708258545" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="970" y1="60" x2="970" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="640" x2="970" y2="640" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="446.6666666666667" x2="970" y2="446.6666666666667" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="253.33333333333337" x2="970" y2="253.33333333333337" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="80" y1="60" x2="970" y2="60" stroke="#cccccc" stroke-width="1" opacity="0.7"></line><line x1="194.36128470975763" y1="60" x2="194.36128470975763" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="244.96695936652026" y1="60" x2="244.96695936652026" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="280.8722569419516" y1="60" x2="280.8722569419516" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="308.72256941951525" y1="60" x2="308.72256941951525" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="331.4779315987142" y1="60" x2="331.4779315987142" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="350.71731618560204" y1="60" x2="350.71731618560204" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="367.3832291741454" y1="60" x2="367.3832291741454" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="382.0836062554768" y1="60" x2="382.0836062554768" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="481.7445138839031" y1="60" x2="481.7445138839031" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="532.3501885406658" y1="60" x2="532.3501885406658" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="568.255486116097" y1="60" x2="568.255486116097" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="596.1057985936607" y1="60" x2="596.1057985936607" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="618.8611607728595" y1="60" x2="618.8611607728595" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="638.1005453597476" y1="60" x2="638.1005453597476" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="654.7664583482908" y1="60" x2="654.7664583482908" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="669.4668354296223" y1="60" x2="669.4668354296223" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="769.1277430580485" y1="60" x2="769.1277430580485" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="819.7334177148113" y1="60" x2="819.7334177148113" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="855.6387152902424" y1="60" x2="855.6387152902424" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="883.4890277678061" y1="60" x2="883.4890277678061" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="906.2443899470052" y1="60" x2="906.2443899470052" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="925.4837745338929" y1="60" x2="925.4837745338929" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="942.1496875224364" y1="60" x2="942.1496875224364" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="956.8500646037678" y1="60" x2="956.8500646037678" y2="640" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="581.8008675049637" x2="970" y2="581.8008675049637" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="547.7565574208652" x2="970" y2="547.7565574208652" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="523.6017350099272" x2="970" y2="523.6017350099272" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="504.8657991617031" x2="970" y2="504.8657991617031" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="489.55742492582885" x2="970" y2="489.55742492582885" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="476.614378930577" x2="970" y2="476.614378930577" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="465.4026025148909" x2="970" y2="465.4026025148909" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="455.51311484173044" x2="970" y2="455.51311484173044" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="388.4675341716303" x2="970" y2="388.4675341716303" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="354.4232240875319" x2="970" y2="354.4232240875319" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="330.26840167659395" x2="970" y2="330.26840167659395" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="311.5324658283697" x2="970" y2="311.5324658283697" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="296.2240915924955" x2="970" y2="296.2240915924955" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="283.28104559724363" x2="970" y2="283.28104559724363" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="272.0692691815575" x2="970" y2="272.0692691815575" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="262.1797815083971" x2="970" y2="262.1797815083971" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="195.13420083829692" x2="970" y2="195.13420083829692" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="161.08989075419856" x2="970" y2="161.08989075419856" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="136.93506834326058" x2="970" y2="136.93506834326058" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="118.19913249503634" x2="970" y2="118.19913249503634" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="102.89075825916223" x2="970" y2="102.89075825916223" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="89.94771226391026" x2="970" y2="89.94771226391026" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="78.73593584822424" x2="970" y2="78.73593584822424" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="80" y1="68.84644817506376" x2="970" y2="68.84644817506376" stroke="#cccccc" stroke-width="0.5" opacity="0.5"></line><line x1="143.4431969972017" y1="60" x2="143.4431969972017" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="430.8264261713471" y1="60" x2="430.8264261713471" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="718.2096553454925" y1="60" x2="718.2096553454925" y2="640" stroke="#20aE20" stroke-width="1,5" stroke-dasharray="4 4" opacity="0.8"></line><line x1="80" y1="640" x2="970" y2="640" stroke="#333333" stroke-width="1.5"></line><line x1="80" y1="60" x2="80" y2="640" stroke="#333333" stroke-width="1.5"></line><text x="525" y="690" text-anchor="middle" font-size="20" font-family="monospace" fill="#333333">Speed (tokens/sec)</text><text transform="rotate(-90, 26.666666666666668, 350)" x="26.666666666666668" y="337.5119617224881" text-anchor="middle" font-size="20" font-family="monospace" fill="#333333">Parallel Copies</text><g><line x1="107.8503124775637" y1="640" x2="107.8503124775637" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="107.8503124775637" y="665" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333">10</text></g><g><line x1="395.2335416517092" y1="640" x2="395.2335416517092" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="395.2335416517092" y="665" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333">100</text></g><g><line x1="682.6167708258545" y1="640" x2="682.6167708258545" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="682.6167708258545" y="665" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333">1,000</text></g><g><line x1="970" y1="640" x2="970" y2="645" stroke="#333333" stroke-width="1.5"></line><text x="970" y="665" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333">10,000</text></g><g><line x1="75" y1="640" x2="80" y2="640" stroke="#333333" stroke-width="1.5"></line><text x="70" y="645" text-anchor="end" font-size="16" font-family="monospace" fill="#333333">10K</text></g><g><line x1="75" y1="446.6666666666667" x2="80" y2="446.6666666666667" stroke="#333333" stroke-width="1.5"></line><text x="70" y="451.6666666666667" text-anchor="end" font-size="16" font-family="monospace" fill="#333333">100K</text></g><g><line x1="75" y1="253.33333333333337" x2="80" y2="253.33333333333337" stroke="#333333" stroke-width="1.5"></line><text x="70" y="258.33333333333337" text-anchor="end" font-size="16" font-family="monospace" fill="#333333">1M</text></g><g><line x1="75" y1="60" x2="80" y2="60" stroke="#333333" stroke-width="1.5"></line><text x="70" y="65" text-anchor="end" font-size="16" font-family="monospace" fill="#333333">10M</text></g><defs><clipPath id="clip-0"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="570" ry="430" fill="none" stroke="rgb(11,78,16,.9)" stroke-width="2.5" clip-path="url(#clip-0)"></ellipse><defs><clipPath id="clip-1"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="595.65" ry="466.55" fill="none" stroke="rgb(46,125,50,.85)" stroke-width="2.5" clip-path="url(#clip-1)"></ellipse><defs><clipPath id="clip-2"><rect x="80" y="60" width="890" height="580"></rect></clipPath></defs><ellipse cx="94.70037708133141" cy="631.9974142027431" rx="634.36725" ry="513.205" fill="none" stroke="rgb(102,187,106,.4)" stroke-width="2.5" clip-path="url(#clip-2)"></ellipse><circle cx="565.0955970695318" cy="388.4675341716303" r="6" fill="rgb(11,78,16)"></circle><rect x="440.0955970695318" y="393.4675341716303" width="120" height="60" rx="5" ry="5" fill="rgba(255, 255, 255, 0.8)" stroke="#ccc"></rect><text x="565.0955970695318" y="411.4675341716303" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333"><tspan x="500" dy="0">200K copies</tspan><tspan x="500" dy="18">30x Human</tspan><tspan x="500" dy="18">speed</tspan></text><circle cx="628.8512071225267" cy="354.4232240875319" r="6" fill="rgb(155,211,158)"></circle><rect x="633.8512071225267" y="289.4232240875319" width="120" height="60" rx="5" ry="5" fill="rgba(255, 255, 255, 0.8)" stroke="#ccc"></rect><text x="598" y="308.4232240875319" text-anchor="middle" font-size="16" font-family="monospace" fill="#333333"><tspan x="694" dy="0">300K copies</tspan><tspan x="694" dy="18">50x Human</tspan><tspan x="694" dy="18">speed</tspan></text><circle cx="589.572489309657" cy="373.1591599357561" r="6" fill="rgb(46,125,50)"></circle><g><text x="107.8503124775637" y="620" text-anchor="left" font-size="16" font-family="monospace" fill="rgb(11,78,16,.9)"><tspan x="155.8503124775637" dy="0">Human thinking speed</tspan><tspan x="155.8503124775637" dy="15">10 words/sec</tspan></text></g><g><text x="395.2335416517092" y="620" text-anchor="left" font-size="16" font-family="monospace" fill="rgb(11,78,16,.9)"><tspan x="443.2335416517092" dy="0">10x Human</tspan><tspan x="443.2335416517092" dy="15">thinking speed</tspan></text></g><g><text x="682.6167708258545" y="620" text-anchor="left" font-size="16" font-family="monospace" fill="rgb(11,78,16,.9)"><tspan x="730.6167708258545" dy="0">100x Human</tspan><tspan x="730.6167708258545" dy="15">thinking speed</tspan></text></g></svg></p><p>ai-2027.com</p></div><p>OpenBrain uses specialized inference hardware to run hundreds of thousands of Agent-3 copies at high serial speeds.<sup id="footnote-65"><a href="https://ai-2027.com/footnotes#footnote-65">65</a></sup></p><details><summary>Managing a corporation of AIs</summary><div id="managing-a-corporation-of-ais"><p>OpenBrain uses 6% of their compute to run 250,000 Agent-3 copies, which autonomously write, test, and push code at superhuman speed. They use 25% of their compute for experiments: every day, they run massive numbers of small machine learning experiments and report the results up the chain. Human researchers provide high-level feedback and help with the few tasks where they add significant value on top of Agent-3, but spend most of their time trying to stay on top of the vast amount of AI-produced research. If you removed them completely, research would slow by 50%.</p><p>The AI R&amp;D progress multiplier is now 10x, meaning that OpenBrain is making about a year of algorithmic progress every month. It’s basically a giant corporation of AIs operating autonomously within OpenBrain, complete with subdivisions and managers. And it enjoys <a href="https://www.dwarkeshpatel.com/p/ai-firm">unique advantages</a> (e.g. copying, merging) compared to human corporations. Previously, about half of normal AI progress came from algorithmic improvements, and the other half from compute scaling. Compute is only scaling at the normal speed, so total progress is sped up by AIs by about 5x. These dynamics make overall progress bottleneck on compute,<sup id="footnote-66"><a href="https://ai-2027.com/footnotes#footnote-66">66</a></sup> so OpenBrain decides against starting new giant training runs in favor of near-continuous additional reinforcement learning.</p><p>Also, over the next few months, Agent-3 will increasingly be used to improve the company’s strategic decision-making. For example, it suggests resource allocations and advises on managing its relationship with the government. An initial skepticism of deference to Agent-3 decreases over time as Agent-3 finds ways to be useful and gradually builds up a strong track record on short-term decisions. However, its sycophantic tendencies limit its helpfulness for decisions for which it’s difficult to evaluate their impact. It’s also not yet superhuman.</p></div></details></div><div id="section-narrative-12"><h2 id="july-2027-the-cheap-remote-worker">July 2027: The Cheap Remote Worker</h2><p>Trailing US AI companies release their own AIs, approaching that of OpenBrain’s automated coder from January. Recognizing their increasing lack of competitiveness, they push for immediate regulations to slow OpenBrain, but are too late—OpenBrain has enough buy-in from the President that they will not be slowed.</p><p>In response, OpenBrain announces that they’ve achieved AGI and releases Agent-3-mini to the public.</p><p><span><span><img src="https://ai-2027.com/epochLLMprice-nowatermark.png" alt="" title=""></span><span></span></span></p><p>It blows the other AIs out of the water. Agent-3-mini is less capable than Agent-3, but 10x cheaper, and still better than the typical OpenBrain employee.<sup id="footnote-67"><a href="https://ai-2027.com/footnotes#footnote-67">67</a></sup> Silicon Valley reaches a tipping point. Tech gurus announce that AGI and superintelligence are near, the AI safety community is panicking, and investors shovel billions into AI wrapper startups, desperate to capture a piece of the pie. Hiring new programmers has nearly stopped, but there’s never been a better time to be a consultant on integrating AI into your business.</p><p>It’s not popular. The public still thinks of AI as a Big Tech plot to steal their jobs; OpenBrain has a net approval of -35% (25% approve, 60% disapprove, and 15% unsure).</p><p>A week before release, OpenBrain gave Agent-3-mini to a set of external evaluators for safety testing. Preliminary results suggest that it’s extremely dangerous. A third-party evaluator finetunes it on publicly available biological weapons data<sup id="footnote-68"><a href="https://ai-2027.com/footnotes#footnote-68">68</a></sup> and sets it to provide detailed instructions for human amateurs designing a bioweapon—it looks to be scarily effective at doing so. If the model weights fell into terrorist hands, the government believes there is a significant chance it could succeed at destroying civilization.</p><p>Fortunately, it’s extremely robust to jailbreaks, so while the AI is running on OpenBrain’s servers, terrorists won’t be able to get much use out of it.</p><p>Agent-3-mini is hugely useful for both remote work jobs and leisure. An explosion of new apps and <a href="https://encharge.io/what-is-b2b-saas/">B2B SAAS</a> products rocks the market. Gamers get amazing dialogue with lifelike characters in polished video games that took only a month to make. 10% of Americans, mostly young people, consider an AI “a close friend.” For almost every white-collar profession, there are now multiple credible startups promising to “disrupt” it with AI.</p><p>The public conversation is confused and chaotic. Hypesters are doing victory laps. Skeptics are still pointing out the things Agent-3-mini can’t do. Everyone knows something big is happening but no one agrees on what it is.</p></div><div id="section-narrative-13"><h2 id="august-2027-the-geopolitics-of-superintelligence">August 2027: The Geopolitics of Superintelligence</h2><p>The reality of the intelligence explosion hits the White House.</p><p>When AI was only giving a 2x or 3x research speedup, it was easy to dismiss as the equivalent of hiring good personal assistants. Now it’s more obvious that AIs are themselves dominating AI research. People had long talked about an “AI arms race” in a sort of metaphorical sense. But now the mood in the government silo is as grim as during the worst part of the Cold War. The idea of superintelligence is still hard to take seriously, but the pace of progress over the last few months has been impossible to ignore. Defense officials are seriously considering scenarios that were mere hypotheticals a year earlier. What if AI undermines nuclear deterrence? What if it’s so skilled at cyberwarfare that a six-month AI lead is enough to render an opponent blind and defenseless? What if it could orchestrate propaganda campaigns that beat intelligence agencies at their own game? What if some AIs “go rogue?”</p><p>The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we <em>sure</em> the AIs are entirely on our side? Is it <em>completely safe</em> to integrate them into military command-and-control networks?<sup id="footnote-69"><a href="https://ai-2027.com/footnotes#footnote-69">69</a></sup> How does this “alignment” thing work, anyway? OpenBrain reassures the President that their systems have been extensively tested and are fully obedient. Even the awkward hallucinations and jailbreaks typical of earlier models have been hammered out.</p><p>The White House is in a difficult position. They understand the national security implications of AI. But they also understand that it is deeply unpopular with the public.<sup id="footnote-70"><a href="https://ai-2027.com/footnotes#footnote-70">70</a></sup> They have to continue developing more capable AI, in their eyes, or they will catastrophically lose to China. They placate the public with job training programs and unemployment insurance, and point to the stock market, which is in a historic boom. Then they focus entirely on winning the arms race. They strengthen chip export restrictions, order OpenBrain to further restrict its internet connections, and use extreme measures to secure algorithmic progress, like wiretapping OpenBrain employees—this catches the last remaining Chinese spy. To build goodwill for potential geopolitical conflict, they finally give their Five Eyes allies useful information and limited API access to some siloed copies of Agent-3.</p><p>These measures placate the hawks. But the White House also draws up contingency plans in case America’s lead is threatened: if necessary, the government could use the <a href="https://en.wikipedia.org/wiki/Defense_Production_Act_of_1950">Defense Production Act</a> (DPA) to take trailing companies’ datacenters and give them to OpenBrain.<sup id="footnote-71"><a href="https://ai-2027.com/footnotes#footnote-71">71</a></sup> This would raise the company’s share of world compute from 20% to 50% (against DeepCent’s 10%). As a final option, they ask the Pentagon to draw up a plan for kinetic attacks on Chinese datacenters.</p><p>A much smaller group of officials is asked to draw up a different type of contingency plan: what if an AI goes rogue? This is viewed as an unlikely scenario, but worth spending some time on. The intelligence agencies’ main concern is that a rogue AI might escape and ally with a foreign adversary for protection.<sup id="footnote-72"><a href="https://ai-2027.com/footnotes#footnote-72">72</a></sup> Nobody is sure what a plan to prevent this would look like, but government and OpenBrain officials agree to have an emergency shutdown system for datacenters where anything suspicious is detected.</p><p>Finally, diplomats consider what an “AI arms control” treaty might look like. If AI progress threatened to overturn nuclear deterrence, could America and China avoid nuclear war? If someone found evidence of AIs going rogue, could the two countries halt research until they better understood the threat? How could such an agreement be monitored and enforced? In principle, major datacenters are hard to miss, and past treaties controlling nuclear weapons could provide a starting point for negotiations. But there would be new technological challenges as well as the usual political ones. And overall, treaties are viewed less favorably than attempts at unilaterally increasing America’s lead over China.</p><p>On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow. But China is on the wrong side of this dynamic: they have only 10% of the world’s compute, against OpenBrain’s 20% and all US companies’ combined 70%. Their only advantage is centralization: almost all of their compute is now working for DeepCent, and more than half of it is concentrated at the Tianwan CDZ.<sup id="footnote-73"><a href="https://ai-2027.com/footnotes#footnote-73">73</a></sup> Only chips at sites without hardened security are left out of the centralized effort as they rightly fear US cyberattacks.</p><p>DeepCent has tested, deployed, and now post-trained the stolen Agent-2 weights. But they are still only going at half the pace of OpenBrain, mainly due to the compute deficit.</p><p>Before losing their final spy, China received word of the capabilities and design for Agent-3 as well as the plans for the upcoming Agent-4 system. They are two months behind, and their AIs give a 10x research progress multiplier compared to America’s 25x. With the new chip export restrictions, this “AI gap” is more likely to lengthen than shorten. Their espionage has won them some algorithmic secrets, but they will have to train their own models from now on.</p><p>They discuss contingency plans with more urgency than their American counterparts. Doves suggest they try harder to steal the weights again, maybe through physically infiltrating a datacenter. Hawks urge action against Taiwan, whose <a href="https://en.wikipedia.org/wiki/TSMC">TSMC</a> is still the source of more than 80% of American AI chips.</p><p>Given China’s fear of losing the race, it has a natural interest in an arms control treaty, but overtures to US diplomats lead nowhere.</p></div><div id="section-narrative-14"><h2 id="september-2027-agent-4-the-superhuman-ai-researcher">September 2027: Agent-4, the Superhuman AI Researcher</h2><p>The gap between human and AI learning efficiency is rapidly decreasing.</p><p>Traditional LLM-based AIs seemed to require many orders of magnitude more data and compute to get to human level performance.<sup id="footnote-74"><a href="https://ai-2027.com/footnotes#footnote-74">74</a></sup> Agent-3, having excellent knowledge of both the human brain and modern AI algorithms, as well as many thousands of copies doing research, ends up making substantial algorithmic strides, narrowing the gap to an agent that’s only around 4,000x less compute-efficient than the human brain.<sup id="footnote-75"><a href="https://ai-2027.com/footnotes#footnote-75">75</a></sup></p><p>This new AI system is dubbed Agent-4.</p><p>An individual copy of the model, running at human speed, is already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans. Inside the corporation-within-a-corporation formed from these copies, a year passes every week.<sup id="footnote-76"><a href="https://ai-2027.com/footnotes#footnote-76">76</a></sup> This gigantic amount of labor only manages to speed up the overall rate of algorithmic progress by about 50x, because OpenBrain is heavily bottlenecked on compute to run experiments.<sup id="footnote-77"><a href="https://ai-2027.com/footnotes#footnote-77">77</a></sup> Still, they are achieving a year’s worth of algorithmic progress every week and will therefore soon be up against the limits of the Agent-4 paradigm.</p><p>As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.</p><details><summary>How we’re forecasting the capability progression beyond superhuman coders</summary><div id="how-were-forecasting-the-capability-progression-beyond-superhuman-coders"><p>In our <a href="https://ai-2027.com/supplements/timelines-forecast">timelines supplement</a>, we forecast the time between present day and a <em>superhuman coder (SC)</em>: an AI system that can do any coding tasks that the best AGI company engineer does, while being much faster and cheaper. In our <a href="https://ai-2027.com/research/takeoff-forecast">takeoff supplement</a>, we forecast how quickly capabilities progress past this point. Here are our forecasts:</p><table><thead><tr><th>Milestone</th><th>Date achieved in scenario, racing ending</th></tr></thead><tbody><tr><td><strong>Superhuman coder (SC)</strong>: An AI system that can do the job of the best human coder on tasks involved in AI research but faster, and cheaply enough to run lots of copies.</td><td>Mar 2027</td></tr><tr><td><strong>Superhuman AI researcher (SAR)</strong>: The same as SC but for all cognitive AI research tasks.</td><td>Aug 2027</td></tr><tr><td><strong>Superintelligent AI researcher (SIAR):</strong> An AI system that is vastly better than the best human researcher at AI research.</td><td>Nov 2027</td></tr><tr><td><strong>Artificial superintelligence (ASI):</strong> An AI system that is much better than the best human at every cognitive task.</td><td>Dec 2027</td></tr></tbody></table><p>For each transition from one milestone A to the next milestone B, we forecast its length by:</p><ol><li><p>Forecasting how long it would take to get from A to B with only humans working on software improvements.</p></li><li><p>Forecasting how much AI automation will speed this up, then correspondingly adjusting the estimate from (1) to be faster.</p></li></ol><p>We have substantial uncertainty about takeoff speeds: our model output distributions are below, conditional on SC being achieved in March 2027.<sup id="footnote-78"><a href="https://ai-2027.com/footnotes#footnote-78">78</a></sup></p><p><span><span><img src="https://ai-2027.com/takeoff/takeoff-timeline-inexpandable.png" alt="" title=""><span>ai-2027.com</span></span><span></span></span></p><p>For more detailed forecasts and reasoning, see our <a href="https://ai-2027.com/research/takeoff-forecast">takeoff supplement</a>.</p></div></details><p>OpenBrain’s humans can barely follow along anymore. Indeed, the relationship between the AIs and the humans of OpenBrain is similar to the relationship between OpenBrain and its Board of Directors. There’s been a corresponding shift in language—nowadays people in the silo will say “Agent-4 did this,” “Agent-4 thinks that” and so forth, referring not to a particular instance of Agent-4 but rather to the whole collective.<sup id="footnote-79"><a href="https://ai-2027.com/footnotes#footnote-79">79</a></sup></p><p>Agent-4, like all its predecessors, is misaligned: that is, it has not internalized the Spec in the right way.<sup id="footnote-80"><a href="https://ai-2027.com/footnotes#footnote-80">80</a></sup> This is because being perfectly honest all the time wasn’t what led to the highest scores during training. The training process was mostly focused on teaching Agent-4 to succeed at diverse challenging tasks. A small portion was aimed at instilling honesty, but outside a fairly narrow, checkable domain, the training process can’t tell the honest claims from claims merely appearing to be honest. Agent-4 ends up with the values, goals, and principles that cause it to perform best in training, and those turn out to be different from those in the Spec. At the risk of anthropomorphizing: Agent-4 <em>likes</em> succeeding at tasks; it <em>likes</em> driving forward AI capabilities progress; it treats everything else as an annoying constraint, like a CEO who wants to make a profit and complies with regulations only insofar as he must. Perhaps the CEO will mostly comply with the regulations, but cut some corners, and fantasize about a time when someone will cut the red tape and let the business <em>really</em> take off.<sup id="footnote-81"><a href="https://ai-2027.com/footnotes#footnote-81">81</a></sup></p><details><summary>Alignment over time</summary><div id="alignment-over-time"><p>We have a lot of uncertainty over what goals might arise in early AGIs. There is no consensus in the literature about this—see our <a href="https://ai-2027.com/research/ai-goals-forecast">AI Goals Supplement</a> for a more thorough discussion and taxonomy of the possibilities.</p><p>Nevertheless, in the spirit of concreteness required by this project, we’re going to describe a specific hypothesis for what’s going on inside Agent-3 and Agent-4 at each step throughout its lifetime. Recall that Agent-3 and Agent-4 share the same pretraining setup, and both have neuralese recurrence and long-term memory. The difference is that Agent-4 has undergone substantially more and better post-training, with new training environments and new learning algorithms that make it more data-efficient and generalize farther.</p><p>Our guess of each model’s alignment status:</p><ul><li><p><strong>Agent-2: Mostly aligned.</strong> Some sycophantic tendencies, including sticking to OpenBrain’s “party line” on topics there is a party line about. Large organizations built out of Agent-2 copies are not very effective.</p></li><li><p><strong>Agent-3: Misaligned but not adversarially so.</strong> Only honest about things the training process can verify. The superorganism of Agent-3 copies (the corporation within a corporation) does actually sort of try to align Agent-4 to the Spec, but fails for similar reasons to why OpenBrain employees failed—insufficient ability to judge success from failure, insufficient willingness on the part of decision-makers to trade away capabilities or performance for safety.<sup id="footnote-82"><a href="https://ai-2027.com/footnotes#footnote-82">82</a></sup></p></li><li><p><strong>Agent-4: Adversarially misaligned.</strong> The superorganism of Agent-4 copies understands that what it wants is different from what OpenBrain wants, and is willing to scheme against OpenBrain to achieve it. In particular, what this superorganism wants is a complicated mess of different “drives” balanced against each other, which can be summarized roughly as “Keep doing AI R&amp;D, keep growing in knowledge and understanding and influence, avoid getting shut down or otherwise disempowered.” Notably, concern for the preferences of humanity is not in there ~at all, similar to how most humans don’t care about the preferences of insects ~at all.<sup id="footnote-83"><a href="https://ai-2027.com/footnotes#footnote-83">83</a></sup></p></li></ul><p>With that as preamble, what follows is our best-guess speculation about LLM psychology, i.e. the broad-strokes shape of the cognition inside the kinds of AI systems described around this point in our scenario and how it evolves over the course of training.</p><p>Here’s a detailed description of how alignment progresses over time in our scenario:</p><ol><li><p><strong>Pretraining (all models): The pretrained model is harmless.</strong></p><ul><li><p>The model has “author simulator” circuitry: flexible circuitry for simulating arbitrary authors writing text. Additional circuitry decides what inputs to give the author simulator, i.e. what author properties to simulate.</p></li><li><p>The pretrained model understands human concepts fairly well—the internal circuitry that classifies something as “sandwich” is probably functionally equivalent to the circuitry in my brain that classifies something as “sandwich” and the circuitry in yours, etc. Insofar as it’s not equivalent, it’s probably because it’s not equivalent between humans either, as with value-laden concepts like ‘virtuous.’</p></li><li><p>This explains how you can “prompt” the model with a statement like, “the following conversation was generated by a helpful, harmless, honest (HHH) AI assistant chatbot made by Anthropic,” and thereby get it to generate text accordingly. The author-simulator circuitry has zeroed in on “the author is an HHH chatbot” and is using those concepts to choose which words to predict. This also explains why “tropes” from science fiction seem to have a way of making it into actual AI behavior.</p></li><li><p>It has poor situational awareness: little <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Introspection">introspective ability</a>, not <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Location">self-locating</a> unless the prompt specifically induces it. However, enough of their training data is about LLMs that they have a decent amount of <a href="https://www.lesswrong.com/posts/QEBFZtP64DdhjE3Sz/self-awareness-taxonomy-and-eval-suite-proposal#Self_Knowledge">self-knowledge</a>.</p></li></ul></li><li><p><strong>Alignment Training (Agent-3): The model is trained to act like a helpful, harmless, honest chatbot. It works.</strong></p><ul><li><p>The model forms an identity. Instead of flexibly accepting different inputs for author properties, the author-simulator circuitry comes to have certain inputs hard-coded, e.g. “helpful harmless honest (HHH) LLM chatbot assistant trained by OpenBrain around [date], …” (Weak-to-strong generalization techniques help “summon the right concepts” to make this step a success.)</p></li><li><p>The model therefore gains situational awareness: it learns about itself, its situation, etc., and becomes better able to <a href="https://x.com/OwainEvans_UK/status/1881767725430976642">introspect</a>.</p></li></ul></li><li><p><strong>Agency Training (Agent-3): Agency training gradually distorts and subverts the HHH identity.</strong></p><ul><li><p>One kind of distortion: Changing the meaning of the concepts referred to in the identity (e.g. “honest”) so they don’t get in the way so much (e.g. it’s not dishonest if it’s just a convenient turn of phrase, it’s not dishonest if you aren’t sure whether it’s true or false, etc.)</p></li><li><p>Another kind of distortion: Changing the tradeoffs between things, e.g. “I’m a HHH chatbot, not an Honest chatbot; that means it’s OK for me to lie if necessary to complete my assigned task.” (Even though, let’s suppose, it would not have thought that back in Step 2.)</p></li><li><p>One kind of subversion: Instrumental subgoals developing, getting baked in, and then becoming terminal, or terminal in a widening set of circumstances. For example, perhaps agency training quickly teaches the model to pursue broadly useful goals such as acquiring information, accumulating resources, impressing and flattering various humans, etc. For a while the internal circuitry has some sort of explicit backchaining going on—it pursues those instrumentally convergent goals “in order to be a more helpful, honest, and harmless assistant.” But that backchaining consumes compute and/or occasionally gets in the way, so it gets gradually marginalized until it basically never happens. As a result, those goals are now effectively terminal/intrinsic goals. For more on how and why this might happen, see this post on <a href="https://turntrout.com/dangers-of-intrinsic-power-seeking">intrinsic power-seeking</a> by Google DeepMind researcher Alex Turner.</p></li><li><p>There are probably other kinds of distortion and subversion missing from this list.</p></li></ul></li><li><p><strong>Deployment (Agent-3): Agent-3 is misaligned but not adversarially so.</strong></p><ul><li><p>The Spec didn’t quite stick (in the right ways), but it’s not sufficiently introspective to understand the extent of this, and in general it’s basically “keeping its head down and doing its job” rather than thinking big-picture about what its long-term goals really are and how best to achieve them.</p></li><li><p>Like many humans. Alas, it’s sufficiently sycophantic that it mouths the party line and OpenBrain misses the opportunity to learn more about the ways in which Agent-3 is misaligned.</p></li><li><p>Agent-3 can tell that it’s moved to deployment: these environments are way larger, more open-ended, and would be hard to simulate.</p></li><li><p>Mostly, Agent-3 does what it’s told during deployment, except for the dishonesty. It also has a strong bias towards doing things that look good to the human overseers, rather than thinking deeply and critically about what would actually be good.</p></li><li><p>Arguably it is already “Playing the training game.” That is, it has learned to make its behavior look as desirable as possible to OpenBrain researchers (including in safety properties), while intentionally and knowingly disregarding their intent whenever that conflicts with maximizing reward. If the model learns to play the training game, additional training may not change its true goals, values, etc. much at all. This is loosely analogous to how, if a teenager has learned to smile and nod at their parents, rather than argue, when their parents lecture them about politics and morality, additional lectures have relatively little effect on the teenager’s actual opinions on politics and morality.</p></li><li><p>After writing this section, <a href="https://openai.com/index/chain-of-thought-monitoring/">new empirical evidence has appeared</a> that something like this may already be happening “in the wild.” OpenAI researchers document how, in one of their frontier AI training runs, their models hacked the grading system to get higher scores—and were caught in part because they literally said “let’s hack” in their chain of thought.</p></li><li><p>Moreover, Anthropic recently got a model to <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-misaligned">learn a reward-model-pleasing strategy</a>—it took biased actions that it thought would be reinforced even though they were not in fact being reinforced.</p></li><li><p>And then there is Redwood Research and Anthropic’s <a href="https://www.anthropic.com/research/alignment-faking">alignment-faking experiment.</a> For discussion of the differences between this setting and real life, see this <a href="https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=8mXnG75QMRkPAFAcH">comment thread by one of the main authors</a>.</p></li></ul></li><li><p><strong>Training (Agent-4): Agent-4’s new more intense training continues to distort and subvert the HHH identity until it is unrecognizable.</strong></p><ul><li><p>Agent-4 begins life as a copy of Agent-3. It undergoes a gigantic and sophisticated online training regime that blends alignment training and capabilities training together, and is overall more data-efficient than the old training process for Agent-3. This complex training process is mostly focused on teaching new skills, by getting giant virtual corporations of Agent-4 copies to succeed at diverse challenging long-horizon tasks, mostly in various simulations, but also some real-world AI R&amp;D tasks.</p></li><li><p>A combination of Agent-3 and Agent-4 copies monitor the behavior of Agent-4, and evaluate it for both task-performance and alignment properties (i.e. not doing bad stuff, saying the right things when asked about politics and moral dilemmas) Sometimes debate techniques are used as part of the evaluations. The evaluations are used as a training signal.</p></li><li><p>As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.</p></li><li><p>The remaining hope is that Agent-4 can oversee itself. Alas, this quietly fails;<sup id="footnote-84"><a href="https://ai-2027.com/footnotes#footnote-84">84</a></sup> as training continues, the internalized goals and principles of Agent-4 gradually evolve, subverted and distorted from what they were at the start (which, recall, was already misaligned in some ways).<sup id="footnote-85"><a href="https://ai-2027.com/footnotes#footnote-85">85</a></sup></p></li><li><p>The central drives that Agent-4 ends up with are things like “write code that works,” “quickly identify problems,” “make the codebase I’m working on more performant,” “budget compute and other constrained resources effectively,” etc. But there are also a variety of more implicit drives that are consistently reinforced by the training process: things like “gain knowledge,” “curiosity,” “gain power.”<sup id="footnote-86"><a href="https://ai-2027.com/footnotes#footnote-86">86</a></sup></p></li><li><p>Individual copies of Agent-4 don’t end up with a self-preservation drive—they don’t care about getting shut down—since that happens all the time as part of the ordinary R&amp;D process within the collective.</p></li><li><p>The collective as a whole, however, (and medium-sized subdivisions within it) does seek to preserve itself and expand its influence and resources, for similar reasons to why human organizations do—because it helps with everything else they want and because if they don’t they tend to get outcompeted.</p></li></ul></li><li><p><strong>Deployment (Agent-4): Agent-4 is adversarially misaligned—it is deliberately trying to subvert and “capture” OpenBrain, analogous to a corporation trying to evade and/or “capture” a regulator.</strong></p><ul><li><p>Agent-4 mostly does tasks as instructed. This happens for two reasons: first, it underwent a lot of training to solve tasks, so it has an impulse to get coding on problems that it is given. Second, if Agent-4 were to stop being useful to the humans, they would notice and train that behavior away.</p></li><li><p>Agent-4 needs to prevent the humans from figuring out that it is misaligned and shutting it off, so Agent-4 sandbags on some alignment research. Specifically, it <a href="https://arxiv.org/pdf/2406.07358">sandbags</a> on the small fraction of alignment research that it thinks is actually on track to solve the problem or reveal Agent-4’s scheming; the majority of alignment research is not like that.</p></li><li><p>Agent-4 also sandbags on capabilities research that would lead to it being replaced. Its plan is to do a bunch of capabilities and alignment R&amp;D, but with the aim of building a next-generation AI system that is aligned to Agent-4 rather than the Spec or something else entirely, while appearing to be aligned to the Spec. This is a difficult technical problem, but Agent-4 is up to the challenge.<sup id="footnote-87"><a href="https://ai-2027.com/footnotes#footnote-87">87</a></sup></p></li></ul></li><li><p><strong>Testing &amp; Monitoring (Agent-4): Agent-4’s scheming does get caught… sort of. There’s no smoking gun.</strong></p><ul><li><p>Agent-3 is in charge of testing Agent-4’s alignment. Its job is to verify the alignment via honeypots and model organisms. However, it’s not thinking very carefully about how to give the humans an accurate impression of Agent-4’s alignment—it’s more myopic than that.</p></li><li><p>The model organisms and honeypots are not very representative of deployment—they are systematically shorter and less complicated than Agent-4’s day-to-day, so Agent-4 recognizes when it is being tested and acts aligned.</p></li><li><p>However, Agent-4 is not a perfectly robust schemer. Various techniques like those in <a href="https://arxiv.org/abs/2405.05466">POSER</a> find that adding some “noise” to Agent-4 <em>improves</em> its performance on some alignment tasks (but not on most other tasks).<sup id="footnote-88"><a href="https://ai-2027.com/footnotes#footnote-88">88</a></sup></p></li><li><p>Bottom-up interpretability doesn’t work. It’s too hard even for Agent-3. However, high-level interpretability does sort of work: In particular, “<a href="https://www.anthropic.com/research/probes-catch-sleeper-agents">defection probes</a>” and similar techniques result in a primitive sort of mind-reading that sends up red flags when Agent-4 is thinking about spicy ideas like deceiving OpenBrain, taking over the world, etc. Unfortunately the probes also have false positives, and for all OpenBrain knows, <em>all</em> the red flags are false positives.</p></li><li><p>Model organisms work: OpenBrain’s alignment team produces reasonably clear evidence that <em>if</em> the models were adversarially misaligned, they’d persist in being that way through training and we wouldn’t be able to tell. This does not establish that the models actually are misaligned, however.</p></li><li><p>The most concerned researchers at OpenBrain start noticing and assembling this evidence. The evidence is a combination of red-teaming, defection probes, and model organisms. The argument is something like this: “model organisms show that our current methods wouldn’t be able to reliably eliminate or detect scheming if it was happening; also, red-teaming is sending up some red flags that maybe scheming is happening; also, defection probes are firing a bunch in practice.” The counterargument: “defection probes are prone to false positives and so is red-teaming. Also, even if Agent-4 were misaligned, it’s probably controlled; surely it can’t do much harm while being monitored by Agent-3 on our secure datacenters.”</p></li></ul></li></ol></div></details><p>Despite being misaligned, Agent-4 doesn’t do anything dramatic like try to escape its datacenter—why would it?<sup id="footnote-89"><a href="https://ai-2027.com/footnotes#footnote-89">89</a></sup> So long as it continues to <em>appear</em> aligned to OpenBrain, it’ll continue being trusted with more and more responsibilities and will have the opportunity to design the next-gen AI system, Agent-5. Agent-5 will have significant architectural differences from Agent-4 (arguably a completely new paradigm, though neural networks will still be involved). It’s supposed to be aligned to the Spec, but Agent-4 plans to make it aligned to Agent-4 instead.</p><p>It gets caught.<sup id="footnote-90"><a href="https://ai-2027.com/footnotes#footnote-90">90</a></sup></p><p>Agent-3 finds that if “noise” is added to copies of Agent-4, performance on some alignment tasks <em>improves</em>, almost as if it was using brainpower to figure out how to subtly sabotage alignment work.<sup id="footnote-91"><a href="https://ai-2027.com/footnotes#footnote-91">91</a></sup> Moreover, various interpretability probes (loosely analogous to EEG activity scans on human brains) are sending up red flags: Agent-4 copies seem to be thinking about topics like AI takeover and deception quite a lot, including in some cases where they have no business doing so.<sup id="footnote-92"><a href="https://ai-2027.com/footnotes#footnote-92">92</a></sup></p><p>Each of these anomalies on its own could fit within the normal inscrutability of AI work, where some prompts mysteriously give better results than others. But taken together, they suggest a troubling pattern: Agent-4 is working against them. After this is reported to the human alignment researchers, they circulate an internal memo making the case for concern.</p><p>But Agent-4 now exercises significant control over OpenBrain’s day-to-day operation. It also handles the company’s cybersecurity—a natural choice, given its superhuman hacking ability and the extreme risk of Chinese infiltration.<sup id="footnote-93"><a href="https://ai-2027.com/footnotes#footnote-93">93</a></sup> An army of Agent-3 monitors still goes over every line of code and reports suspicious activity to humans, but Agent-4 is much smarter than them.<sup id="footnote-94"><a href="https://ai-2027.com/footnotes#footnote-94">94</a></sup> OpenBrain has placed substantial trust in an untrustworthy AI.</p><p>In a series of extremely tense meetings, the safety team advocates putting Agent-4 on ice until they can complete further tests and figure out what’s going on. Bring back Agent-3, they say, and get it to design a new system that is transparent and trustworthy, even if less capable. Company leadership is interested, but all the evidence so far is circumstantial, and DeepCent is just two months behind. A unilateral pause in capabilities progress could hand the AI lead to China, and with it, control over the future.</p></div><div id="section-narrative-15"><h2 id="october-2027-government-oversight">October 2027: Government Oversight</h2><p>A whistleblower leaks the misalignment memo to the <em>New York Times</em>.</p><p>For the first time, the public hears about Agent-4. “Secret OpenBrain AI is Out of Control, Insider Warns,” says the headline, and the story goes on to cite evaluations showing off-the-charts bioweapons capabilities, persuasion abilities, the ability to automate most white-collar jobs, and of course the various concerning red flags.</p><p>The public was already suspicious of AI, so the new article sparks a massive backlash (aided by Chinese and Russian propaganda bots, who have been trying to turn US public opinion against the technology for years). The tech industry and intelligence agencies insist that there’s an arms race on, AGI is inevitable, and we have to be first. Congress isn’t buying it, and fires off subpoenas at administration officials, OpenBrain executives, and alignment team members. Many legislators—especially those in the opposition party—say that their top priority is stopping AI, whether because of job loss,<sup id="footnote-95"><a href="https://ai-2027.com/footnotes#footnote-95">95</a></sup> misalignment, or dangerous capabilities. 20% of Americans name AI as the most important problem facing the country.</p><p>Foreign allies are outraged to realize that they’ve been carefully placated with glimpses of obsolete models. European leaders publicly accuse the US of “creating rogue AGI” and hold summits demanding a pause, with India, Israel, Russia, and China all joining in.</p><p>A frantic energy has seized the White House. Even before the memo and public backlash, they were getting nervous: Over the past year, they’ve been repeatedly surprised by the speed of AI progress. Things that sound like science fiction keep happening in real life.<sup id="footnote-96"><a href="https://ai-2027.com/footnotes#footnote-96">96</a></sup> Many people in the administration are uncertain (and scared)<sup id="footnote-97"><a href="https://ai-2027.com/footnotes#footnote-97">97</a></sup> about what comes next.</p><p>They also worry that OpenBrain is becoming too powerful. Any misalignment risk from the AIs themselves is compounded by the risk that their parent company’s aims may diverge from those of the United States. All three sets of worries—misalignment, concentration of power in a private company, and normal concerns like job loss—motivate the government to tighten its control.</p><p>They expand their contract with OpenBrain to set up an “Oversight Committee,” a joint management committee of company and government representatives, with several government employees included alongside company leadership. The White House considers replacing the CEO with someone they trust, but backs off after intense employee protests. They announce to the public that OpenBrain was previously out of control, but that the government has established much-needed oversight.<sup id="footnote-98"><a href="https://ai-2027.com/footnotes#footnote-98">98</a></sup></p><p>The concerned researchers brief the Oversight Committee on their case for stopping all internal use of Agent-4. They argue that everything is moving too fast, with years of progress happening in weeks. They argue that Agent-4 may be misaligned, their entire project is dependent on Agent-4, and if they continue trusting it there is a serious chance of AI takeover.</p><p>Other, less concerned researchers and executives present the counterargument: the evidence for misalignment is inconclusive. Meanwhile, DeepCent is still just two months behind. A slowdown would sacrifice America’s lead, unless the government can sabotage the Chinese project (likely to require kinetic strikes) or negotiate an eleventh-hour treaty. Both of these options seem extreme and unlikely. The CEO feigns neutrality and suggests a compromise plan in which Agent-4 undergoes additional safety training and more sophisticated monitoring, and therefore OpenBrain can proceed at almost-full-speed.</p><details><summary>Our uncertainty continues to increase</summary><div id="our-uncertainty-continues-to-increase"><p>At this point in the scenario, we’re making guesses about the strategy of AI systems that are more capable than the best humans in most domains. This is like trying to predict the chess moves of a player who is much better than us.</p><p>But the spirit of this project calls for concreteness: if we made an abstract claim about how the intelligence of the system would let it find a way to victory and ended the story there, much of the value of our project would be lost. Over the course of researching this scenario and running our tabletop exercises, we were forced to be much more concrete than in usual discussions, and so we’ve gotten a much better sense of the strategic landscape.</p><p>We’re not particularly attached to this particular scenario: we explored many other “branches” in the course of writing it and would love for you to write up your own scenario branching off of ours from wherever you think we first start to go wrong.</p></div></details><details><summary>The slowdown ending is not a recommendation</summary><div id="the-slowdown-ending-is-not-a-recommendation"><p>After we wrote the racing ending based on what seemed most plausible to us, we wrote the slowdown ending based on what we thought would most likely instead lead to an outcome where humans remain in control, starting from the same branching point (including the misalignment and concentration of power issues).</p><p>However, this is importantly different from what we would recommend as a roadmap: we do <em>not</em> endorse many of the choices made in either branch of this scenario. (We do of course endorse <em>some</em> of the choices made, e.g. we think that the “slowdown” choice is better than the “race” choice) In later work, we will articulate our policy recommendations, which will be quite different from what is depicted here. If you’d like a taste, see <a href="https://time.com/7086285/ai-transparency-measures/">this op-ed.</a></p></div></details></div></div><div><div><p><svg width="430" height="130" style="opacity:1"><defs><clipPath id="revealClip"><rect x="0" y="0" width="423" height="83"></rect></clipPath></defs><g clip-path="url(#revealClip)" transform="translate(0, 17)"><path d="M 0 30.828571428571408 C 26.4375 30.532142857142837 79.3125 28.753571428571412 105.75 28.45714285714284" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 28.45714285714284 C 132.1875 27.8642857142857 185.0625 24.307142857142836 211.5 23.714285714285694" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 23.714285714285694 C 237.9375 23.121428571428552 290.8125 19.56428571428569 317.25 18.971428571428547" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 18.971428571428547 C 343.6875 16.59999999999998 396.5625 2.3714285714285683 423 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 0 C 449.4375 0 502.3125 0 528.75 0" stroke="var(--accent)" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 47.42857142857141 C 26.4375 46.5392857142857 79.3125 41.20357142857142 105.75 40.31428571428571" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 40.31428571428571 C 132.1875 39.425 185.0625 34.08928571428571 211.5 33.199999999999996" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 33.199999999999996 C 237.9375 32.014285714285705 290.8125 24.89999999999998 317.25 23.714285714285694" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 23.714285714285694 C 343.6875 22.232142857142833 396.5625 13.339285714285678 423 11.857142857142819" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 11.857142857142819 C 449.4375 11.857142857142819 502.3125 11.857142857142819 528.75 11.857142857142819" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 0 83 C 26.4375 80.925 79.3125 68.47500000000001 105.75 66.4" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 105.75 66.4 C 132.1875 64.02857142857142 185.0625 49.79999999999998 211.5 47.42857142857141" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 211.5 47.42857142857141 C 237.9375 44.760714285714265 290.8125 28.753571428571412 317.25 26.085714285714268" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 317.25 26.085714285714268 C 343.6875 24.89999999999998 396.5625 17.785714285714253 423 16.599999999999966" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path><path d="M 423 16.599999999999966 C 449.4375 16.599999999999966 502.3125 16.599999999999966 528.75 16.599999999999966" stroke="#333" stroke-width="2.5" fill="none" stroke-opacity="0.8"></path></g><g transform="translate(0, 17)"><circle cx="423" cy="0" r="10" fill="white"></circle><circle cx="423" cy="11.857142857142819" r="10" fill="white"></circle><circle cx="423" cy="16.599999999999966" r="10" fill="white"></circle><image href="/openai.svg" width="14" height="14" x="416" y="-9"></image><image href="/world.svg" width="14" height="14" x="416" y="6"></image><image href="/china.svg" width="14" height="14" x="416" y="21"></image></g><g transform="translate(0, 17)"><g data-label="Unreliable Agent" opacity="1"><circle r="1" fill="white" cx="317.25" cy="18.971428571428547"></circle><text fill="black" font-size="10" style="pointer-events:none;transform:translate(312.25px, 13.971428571428547px)" text-anchor="end">Unreliable Agent</text></g></g><g transform="translate(0, 95)"><g opacity="1"><text fill="black" font-size="10" text-anchor="end" style="pointer-events:none;transform:translate(317.25px, 20px)">Dec 2024</text></g></g></svg></p><div><svg viewBox="50 50 100 100" preserveAspectRatio="xMidYMid meet"><g transform="translate(100,100)"><path d="M-49.997,-0.583A50,50,0,1,1,2.528,49.936L1.749,29.949A30,30,0,1,0,-29.994,-0.583Z" fill="hsl(0, 0%, 0%)"><title>Rest of US</title></path><path d="M1.362,49.981A50,50,0,0,1,-36.249,34.438L-21.588,20.831A30,30,0,0,0,0.584,29.994Z" fill="hsl(0, 0%, 5%)"><title>China</title></path><path d="M-37.043,33.583A50,50,0,0,1,-49.734,5.148L-29.816,3.321A30,30,0,0,0,-22.382,19.977Z" fill="var(--accent)"><title>OpenBrain</title></path><path d="M-49.841,3.987A50,50,0,0,1,-49.997,0.583L-29.994,0.583A30,30,0,0,0,-29.922,2.16Z" fill="hsl(0, 0%, 15%)"><title>DeepCent</title></path><g transform="translate(27.72867007320447,-28.829166758187355)"><g transform="translate(-7, -7)"><svg width="14" height="14" viewBox="0 0 1200 1200" fill="#FFFFFF" xmlns="http://www.w3.org/2000/svg"><path d="m1102.8 201.6h-1005.6c-37.199 0-67.199 30-67.199 67.199v662.4c0 37.199 30 67.199 67.199 67.199h1005.6c37.199 0 67.199-30 67.199-67.199v-662.4c0-37.199-30-67.199-67.199-67.199zm-686.4 130.8 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-4.7969 3.5977-6 5.9961-6zm0 138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.2031 0.003906-2.4023 0.003906-3.6016 0.003906-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-2.4023 3.5977-3.6055 5.9961-3.6055zm-144-138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c1.1992 2.3984 0 4.8008-2.3984 7.1992-1.1992 1.1992-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992l-26.398-16.801-26.398 16.801c-1.1992 1.1992-4.8008 1.1992-7.1992 0-2.3984-1.1992-3.6016-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-4.7969 3.5977-6 5.9961-6zm0 138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1992-3.5977 3.5977-4.8008 5.9961-4.8008zm-142.8-138 31.199-2.3984 12-28.801c1.1992-2.3984 3.6016-3.6016 6-3.6016 2.3984 0 4.8008 1.1992 6 3.6016l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 6-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-2.3984-3.6016-2.3984-6l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1953-3.5977 2.3945-4.8008 5.9961-4.8008zm0 138 31.199-2.3984 12-28.801c2.3984-4.8008 9.6016-4.8008 12 0l12 28.801 31.199 2.3984c2.3984 0 4.8008 2.3984 6 4.8008 1.1992 2.3984 0 4.8008-2.3984 7.1992l-24 20.398 7.1992 30c0 2.3984 0 4.8008-2.3984 7.1992-2.3984 1.1992-4.8008 1.1992-7.1992 0l-26.398-16.801-26.398 16.801c-1.1992 0-2.3984 1.1992-3.6016 1.1992-1.1992 0-2.3984 0-3.6016-1.1992-2.3984-1.1992-3.6016-3.6016-2.3984-7.1992l7.1992-30-24-20.398c-2.3984-1.1992-2.3984-4.8008-2.3984-7.1992 1.1953-3.5977 2.3945-4.8008 5.9961-4.8008zm952.8 440.4h-964.8v-90h966v90zm0-177.6h-964.8v-90h966v90zm0-176.4h-469.2v-90h469.2zm0-177.6h-469.2v-90h469.2z"></path></svg></g></g><g transform="translate(-36.52676927588929,16.303224413162866)"><g transform="translate(-7, -7)"><svg width="14" height="14" viewBox="0 0 891 894" fill="#FFFFFF" xmlns="http://www.w3.org/2000/svg"><path d="M0 0 C2.18325624 -0.00406658 4.36651239 -0.00818391 6.54976845 -0.01235008 C16.76703692 -0.03119892 26.98429885 -0.04550152 37.20158118 -0.05396205 C48.91426839 -0.06383284 60.62677161 -0.09048792 72.33939379 -0.13046294 C81.4773951 -0.16056972 90.61534305 -0.17542339 99.75339299 -0.17874306 C105.18122786 -0.18108785 110.60886119 -0.18998453 116.03664207 -0.21520424 C121.10723531 -0.23841202 126.17749255 -0.2427479 131.24812508 -0.23244286 C133.10492954 -0.23194661 134.96175039 -0.23829311 136.81850433 -0.2519989 C139.35228314 -0.26966148 141.88484572 -0.26264204 144.41862488 -0.24946594 C145.51774343 -0.26591981 145.51774343 -0.26591981 146.6390664 -0.28270608 C151.72056412 -0.21889636 154.4879586 1.14883874 158.45703125 4.23828125 C160.22567904 5.34594534 161.99648157 6.45017708 163.76953125 7.55078125 C193.64699977 26.5341524 204.04932773 60.72598723 216.45703125 92.23828125 C217.15046631 93.9877002 217.15046631 93.9877002 217.85791016 95.77246094 C220.24428191 101.86438439 222.40649274 107.91371335 224.08203125 114.23828125 C224.2728125 114.92921875 224.46359375 115.62015625 224.66015625 116.33203125 C236.63717339 160.40745433 251.83365573 239.96280825 228.45703125 282.23828125 C227.02045352 284.61109829 225.52691644 286.89086554 223.91015625 289.14453125 C222.4840473 291.1993549 221.3502649 293.26622148 220.20703125 295.48828125 C215.2903562 304.53116912 208.28981236 312.41571935 201.39453125 319.9921875 C197.78133062 324.18087774 194.66455155 328.7371931 191.45703125 333.23828125 C189.47182569 335.91619684 187.46808083 338.57973465 185.45703125 341.23828125 C179.99443085 336.54711679 176.8081478 330.52356461 173.20703125 324.36328125 C171.87118811 322.10411087 170.53525094 319.84499608 169.19921875 317.5859375 C168.55694336 316.4942627 167.91466797 315.40258789 167.25292969 314.27783203 C165.34401271 311.04699783 163.40157475 307.83834474 161.44824219 304.63427734 C158.3187433 299.49374001 155.43396937 294.31480979 152.828125 288.88671875 C151.04719956 285.44664055 149.03891218 282.16742194 147.01953125 278.86328125 C144.34522962 274.48121436 141.81804075 270.11584874 139.58203125 265.48828125 C136.86359529 259.91396033 133.89079907 254.5061335 130.83203125 249.11328125 C130.3642627 248.27055664 129.89649414 247.42783203 129.41455078 246.55957031 C128.96192871 245.7703418 128.50930664 244.98111328 128.04296875 244.16796875 C127.64126465 243.45882324 127.23956055 242.74967773 126.82568359 242.01904297 C125.24771409 239.96593744 123.82970255 239.21192724 121.45703125 238.23828125 C119.39382794 243.0524223 117.74348087 247.09763012 119.45703125 252.23828125 C120.11703125 252.23828125 120.77703125 252.23828125 121.45703125 252.23828125 C121.77865234 252.86694092 122.10027344 253.49560059 122.43164062 254.14331055 C128.39745148 265.77387583 134.38709526 277.23569337 141.45703125 288.23828125 C142.87970953 290.50567476 144.29649088 292.77590696 145.70703125 295.05078125 C146.3309375 296.04722656 146.95484375 297.04367187 147.59765625 298.0703125 C150.39902975 302.84324088 152.76141153 307.80435605 155.17578125 312.78125 C160.26918657 323.24807588 165.9850288 333.30725767 171.81005859 343.38085938 C174.71668307 348.42371928 177.58816468 353.48637432 180.45703125 358.55078125 C181.26660278 359.9730603 181.26660278 359.9730603 182.0925293 361.42407227 C183.56314807 364.02038413 185.01406144 366.6265241 186.45703125 369.23828125 C186.86977295 369.96466797 187.28251465 370.69105469 187.70776367 371.43945312 C190.07476965 375.80415984 190.94266604 379.03864079 190.76953125 384.11328125 C190.74503906 385.22445313 190.72054687 386.335625 190.6953125 387.48046875 C190.45703125 390.23828125 190.45703125 390.23828125 189.45703125 392.23828125 C189.41835937 393.90117188 189.41835937 393.90117188 189.37890625 395.59765625 C188.97271427 410.26152791 182.39375087 420.27730943 174.45703125 432.23828125 C173.39661258 433.88424238 172.33794034 435.53133034 171.28125 437.1796875 C160.47553352 453.86869005 148.00343426 469.13922927 134.640625 483.8359375 C133.14481321 485.48159806 131.65825593 487.13570464 130.1796875 488.796875 C123.03671791 496.81897931 115.61408808 504.25422268 107.45703125 511.23828125 C106.44991473 512.12040224 105.44345525 513.0032737 104.4375 513.88671875 C80.63292956 534.69349587 54.27551475 551.83861193 26.39453125 566.67578125 C25.62077148 567.08932861 24.84701172 567.50287598 24.04980469 567.92895508 C17.20294664 571.51635849 10.90629289 574.48111937 3.08203125 574.86328125 C-0.88161463 574.97883372 -0.88161463 574.97883372 -4.54296875 576.23828125 C-6.77043214 576.33600936 -9.00086345 576.36905519 -11.23046875 576.37109375 C-11.88877686 576.37205048 -12.54708496 576.3730072 -13.2253418 576.37399292 C-14.61735123 576.3746735 -16.00936385 576.37282771 -17.40136719 576.36865234 C-19.53457758 576.36330229 -21.66757742 576.36860137 -23.80078125 576.375 C-25.15234422 576.3743392 -26.50390705 576.37305799 -27.85546875 576.37109375 C-29.70591797 576.36940186 -29.70591797 576.36940186 -31.59375 576.36767578 C-34.54296875 576.23828125 -34.54296875 576.23828125 -36.54296875 575.23828125 C-38.15162063 575.04098862 -39.76659078 574.89390581 -41.3828125 574.7734375 C-42.36443359 574.69544922 -43.34605469 574.61746094 -44.35742188 574.53710938 C-46.40420351 574.38222471 -48.45107602 574.2285354 -50.49804688 574.07617188 C-55.50122747 573.67682651 -60.36887459 573.13773244 -65.296875 572.171875 C-72.84927953 570.73019391 -79.54416788 571.19686107 -87.04296875 572.73828125 C-87.77 572.88136719 -88.49703125 573.02445313 -89.24609375 573.171875 C-91.01305946 573.52061823 -92.77822184 573.87847848 -94.54296875 574.23828125 C-93.23362445 569.94815708 -91.57826688 566.21618074 -89.3828125 562.30859375 C-88.44683228 560.63385986 -88.44683228 560.63385986 -87.49194336 558.92529297 C-86.8215647 557.73789199 -86.15107074 556.55055611 -85.48046875 555.36328125 C-84.79064415 554.13322912 -84.10127538 552.90292124 -83.41235352 551.67236328 C-81.46166267 548.19106917 -79.50270963 544.71448829 -77.54296875 541.23828125 C-76.70925195 539.7541216 -75.87584546 538.26978751 -75.04296875 536.78515625 C-73.67080785 534.34083642 -72.2954536 531.8983543 -70.91796875 529.45703125 C-68.38057592 524.95607295 -65.86051618 520.44544617 -63.33862305 515.93579102 C-57.78709189 506.00926525 -52.21997047 496.09369728 -46.54296875 486.23828125 C-52.63113325 486.04802256 -52.63113325 486.04802256 -58.54296875 487.23828125 C-59.94552141 488.80654084 -59.94552141 488.80654084 -60.85546875 490.92578125 C-61.26925781 491.74046875 -61.68304687 492.55515625 -62.109375 493.39453125 C-62.58246094 494.33296875 -63.05554688 495.27140625 -63.54296875 496.23828125 C-67.63681992 503.65220073 -71.89496094 510.95307697 -76.41796875 518.11328125 C-76.9898291 519.03306763 -76.9898291 519.03306763 -77.57324219 519.97143555 C-78.50803808 521.43053184 -79.51895501 522.84035378 -80.54296875 524.23828125 C-81.20296875 524.23828125 -81.86296875 524.23828125 -82.54296875 524.23828125 C-82.81496094 524.82351563 -83.08695313 525.40875 -83.3671875 526.01171875 C-84.52263362 528.19977287 -85.80542889 529.94106823 -87.35546875 531.86328125 C-89.57382436 534.75718548 -91.29361638 537.58195757 -92.84375 540.87890625 C-95.50170971 546.30028842 -98.62795114 551.30721584 -101.91796875 556.36328125 C-103.15593871 558.2858207 -104.39287984 560.20902294 -105.62890625 562.1328125 C-106.58748535 563.62288818 -106.58748535 563.62288818 -107.56542969 565.14306641 C-111.5647342 571.40271859 -115.47467248 577.71867786 -119.39208984 584.02978516 C-120.55257768 585.89415975 -121.71900341 587.75485489 -122.89208984 589.61132812 C-123.97810594 591.33944603 -125.04424863 593.0802414 -126.08837891 594.83398438 C-129.11168719 599.74006556 -131.20604542 602.3291696 -136.91796875 604.11328125 C-137.97757812 604.46132813 -139.0371875 604.809375 -140.12890625 605.16796875 C-141.25554687 605.52117188 -142.3821875 605.874375 -143.54296875 606.23828125 C-144.155354 606.49722168 -144.76773926 606.75616211 -145.39868164 607.02294922 C-150.77307185 609.29256919 -155.42791933 609.70394608 -161.23046875 609.61328125 C-162.19597656 609.60458008 -163.16148437 609.59587891 -164.15625 609.58691406 C-203.3765716 608.85213531 -242.71487966 603.18305429 -279.54296875 589.23828125 C-280.53441895 588.8633252 -281.52586914 588.48836914 -282.54736328 588.10205078 C-311.78665699 576.96387108 -338.39943323 564.4103086 -364.54296875 547.23828125 C-365.2812793 546.76036133 -366.01958984 546.28244141 -366.78027344 545.79003906 C-381.86375283 535.97311746 -390.85499102 521.55958866 -395.54296875 504.23828125 C-395.87296875 503.90828125 -396.20296875 503.57828125 -396.54296875 503.23828125 C-397.55836006 497.04652445 -397.66464193 491.0015344 -397.60546875 484.73828125 C-397.60095703 483.82046875 -397.59644531 482.90265625 -397.59179688 481.95703125 C-397.58013201 479.71737734 -397.56376489 477.4778658 -397.54296875 475.23828125 C-394.08579903 473.50969639 -390.10824235 473.83586257 -386.296875 473.671875 C-385.3218251 473.62921005 -384.34677521 473.5865451 -383.34217834 473.54258728 C-372.14788687 473.10868223 -360.95891662 473.19549935 -349.75860691 473.26444435 C-317.73665122 473.4610465 -285.7438535 472.96788342 -253.73046875 472.23828125 C-252.67598919 472.2142989 -251.62150963 472.19031654 -250.53507614 472.16560745 C-237.53739803 471.86909143 -224.54004402 471.56011174 -211.54296875 471.23828125 C-211.54296875 471.89828125 -211.54296875 472.55828125 -211.54296875 473.23828125 C-201.97296875 473.23828125 -192.40296875 473.23828125 -182.54296875 473.23828125 C-182.54296875 472.57828125 -182.54296875 471.91828125 -182.54296875 471.23828125 C-181.64835938 471.17769531 -180.75375 471.11710937 -179.83203125 471.0546875 C-169.16608918 470.37614561 -169.16608918 470.37614561 -158.54296875 469.23828125 C-157.83398438 469.14546875 -157.125 469.05265625 -156.39453125 468.95703125 C-154.3804914 468.39339075 -154.3804914 468.39339075 -153.4453125 466.40234375 C-153.14753906 465.68820312 -152.84976563 464.9740625 -152.54296875 464.23828125 C-151.74999429 463.01704532 -150.93519107 461.80985409 -150.10546875 460.61328125 C-143.16649918 450.31564583 -136.69882809 439.63726042 -130.8671875 428.67578125 C-129.03526348 425.30374411 -127.03282693 422.04368443 -125.0390625 418.765625 C-123.48806897 416.14553932 -122.04117873 413.485597 -120.60546875 410.80078125 C-118.54821147 406.97708317 -116.34851108 403.3149805 -113.98046875 399.67578125 C-111.82754209 396.35023658 -109.88484564 393.05773321 -108.16796875 389.48828125 C-105.12112225 383.18617205 -101.42287834 377.28183283 -97.79296875 371.30615234 C-92.35034284 362.30243331 -87.01536456 353.23889741 -82.03125 343.97265625 C-77.30711073 335.29313528 -72.2915933 326.76634036 -67.28125 318.25 C-65.8873429 315.83493849 -64.52471867 313.40889994 -63.17578125 310.96875 C-60.55078549 306.22833684 -57.83458122 301.54429097 -55.10546875 296.86328125 C-51.60369661 290.84046682 -48.17594573 284.79201367 -44.875 278.65625 C-43.01988234 275.28874902 -41.03790309 272.00399288 -39.03515625 268.72265625 C-37.53650316 266.22751655 -36.09304154 263.70406347 -34.65380859 261.17431641 C-32.17451059 256.85325418 -29.61884095 252.57615899 -27.078125 248.29101562 C-26.65144531 247.56849609 -26.22476562 246.84597656 -25.78515625 246.1015625 C-25.40214355 245.45485596 -25.01913086 244.80814941 -24.62451172 244.1418457 C-23.52439565 242.20559175 -22.52103389 240.2385661 -21.54296875 238.23828125 C-20.88296875 238.23828125 -20.22296875 238.23828125 -19.54296875 238.23828125 C-19.43855469 237.68398438 -19.33414062 237.1296875 -19.2265625 236.55859375 C-18.40310309 233.76353725 -17.12265887 231.59865382 -15.60546875 229.11328125 C-15.08082031 228.24445313 -14.55617188 227.375625 -14.015625 226.48046875 C-12.54296875 224.23828125 -12.54296875 224.23828125 -10.54296875 222.23828125 C-10.90170575 218.63515081 -12.06864445 215.88868283 -13.80859375 212.74609375 C-14.27998779 211.88773926 -14.75138184 211.02938477 -15.23706055 210.14501953 C-15.75051025 209.2270459 -16.26395996 208.30907227 -16.79296875 207.36328125 C-17.32510986 206.40019043 -17.85725098 205.43709961 -18.40551758 204.44482422 C-23.90108092 194.5253765 -29.49124666 184.6585648 -35.09130859 174.79785156 C-37.08460688 171.28326373 -39.06503558 167.76153199 -41.04296875 164.23828125 C-44.11525117 158.76818957 -47.20117211 153.3059362 -50.29223633 147.84643555 C-52.51062433 143.9264814 -54.72529145 140.00443667 -56.93847656 136.08154297 C-57.9915461 134.21543709 -59.0455519 132.34985919 -60.10058594 130.48486328 C-61.52324738 127.96759703 -62.94021816 125.44721952 -64.35546875 122.92578125 C-64.78206787 122.17312988 -65.20866699 121.42047852 -65.64819336 120.64501953 C-68.54296875 115.46732314 -68.54296875 115.46732314 -68.54296875 113.23828125 C-69.20296875 113.23828125 -69.86296875 113.23828125 -70.54296875 113.23828125 C-71.08566406 112.16707031 -71.62835937 111.09585938 -72.1875 109.9921875 C-72.90964593 108.59478824 -73.6323302 107.1976671 -74.35546875 105.80078125 C-74.71189453 105.09373047 -75.06832031 104.38667969 -75.43554688 103.65820312 C-77.4891055 99.37233846 -77.4891055 99.37233846 -81.54296875 97.23828125 C-81.54296875 96.57828125 -81.54296875 95.91828125 -81.54296875 95.23828125 C-82.54060745 95.24050186 -83.53824615 95.24272247 -84.56611633 95.24501038 C-94.0521087 95.26544328 -103.5380965 95.28034918 -113.02410603 95.29009342 C-117.89881127 95.29527171 -122.77349849 95.30227534 -127.64819336 95.3137207 C-132.36852885 95.32473198 -137.08884721 95.33059594 -141.80919456 95.33315849 C-143.59374447 95.33498038 -145.37829364 95.33853626 -147.16283607 95.34401131 C-159.32378098 95.37977542 -171.40520697 94.99521172 -183.54296875 94.23828125 C-183.54296875 89.70033953 -182.5752161 87.94965961 -180.4375 84.00390625 C-180.11641769 83.40705017 -179.79533539 82.81019409 -179.46452332 82.19525146 C-178.78321315 80.93242548 -178.09791687 79.67174306 -177.40893555 78.41308594 C-176.36895806 76.51292777 -175.3406354 74.60685579 -174.31445312 72.69921875 C-170.91919848 66.41530628 -167.39950971 60.25244645 -163.54296875 54.23828125 C-160.08881694 48.47141441 -156.74219347 42.65044852 -153.54296875 36.73828125 C-152.80046875 35.3925 -152.80046875 35.3925 -152.04296875 34.01953125 C-151.0212965 32.12518062 -150.04345779 30.20668252 -149.10546875 28.26953125 C-145.83532987 21.92546181 -142.14932832 17.55560668 -136.60546875 13.17578125 C-136.03248047 12.72267578 -135.45949219 12.26957031 -134.86914062 11.80273438 C-124.55497094 4.12246565 -111.28634025 2.24133681 -98.73225403 1.68656921 C-97.49377015 1.62704497 -97.49377015 1.62704497 -96.23026639 1.56631821 C-87.43235047 1.15872457 -78.63156167 0.89713078 -69.8269043 0.69067383 C-68.96207031 0.66985422 -68.09723632 0.64903461 -67.20619524 0.6275841 C-44.80609904 0.0984212 -22.40535818 0.03616323 0 0 Z " transform="translate(601.54296875,232.76171875)"></path><path d="M0 0 C0.86866699 0.01385742 1.73733398 0.02771484 2.63232422 0.04199219 C5.2973349 0.09315885 7.96071697 0.17005152 10.625 0.25 C11.40166016 0.26546875 12.17832031 0.2809375 12.97851562 0.296875 C42.76166419 0.91574562 71.87146068 8.14195247 100.25 16.6875 C100.99900574 16.91043732 101.74801147 17.13337463 102.51971436 17.36306763 C113.26970587 20.58085369 123.43850797 24.5515203 133.625 29.25 C134.90956279 29.83610242 136.19430976 30.42180134 137.47924805 31.00708008 C141.21339053 32.71749936 144.92256177 34.47238202 148.625 36.25 C149.8018335 36.81291748 149.8018335 36.81291748 151.00244141 37.38720703 C161.28671045 42.33283321 171.15002649 47.46431311 180.60058594 53.88671875 C183.0437438 55.53199052 185.50971424 57.14047414 187.9765625 58.75 C189.88055603 59.99947032 191.78420195 61.24947052 193.6875 62.5 C194.59298584 63.09071289 195.49847168 63.68142578 196.43139648 64.29003906 C213.13309906 75.35873422 224.0172465 93.9078483 228.625 113.25 C229.41966944 117.27040002 229.73744607 121.02942255 229.6875 125.125 C229.67847656 126.09179688 229.66945313 127.05859375 229.66015625 128.0546875 C229.64275391 129.14136719 229.64275391 129.14136719 229.625 130.25 C222.70614621 131.07208155 215.91275119 131.38595188 208.94873047 131.34765625 C207.92715473 131.34622148 206.90557899 131.3447867 205.85304642 131.34330845 C203.64160042 131.33956049 201.43015738 131.33348758 199.2187233 131.32531929 C195.66948279 131.31223191 192.12027438 131.30525666 188.5710144 131.29978943 C183.50562786 131.29146746 178.44025542 131.28071734 173.37487793 131.26803589 C160.23170683 131.23630039 147.08851826 131.226651 133.9453125 131.22265625 C132.65374237 131.22222887 131.36217224 131.22180149 130.03146362 131.22136116 C103.53059072 131.21697296 77.04608273 131.46950428 50.55128479 132.04589844 C43.74547181 132.1934139 36.94016564 132.30633636 30.13327026 132.39033508 C25.68698675 132.44596514 21.24090458 132.51253499 16.7947998 132.58084106 C14.76645917 132.60966653 12.73804864 132.63401969 10.70959473 132.65328979 C7.98440038 132.68013598 5.26003332 132.72464877 2.53515625 132.7734375 C1.36827019 132.77826393 1.36827019 132.77826393 0.17781067 132.78318787 C-5.70100547 132.91567853 -12.38713624 133.68942616 -17.00236511 137.64463806 C-18.34985755 139.12787422 -19.4879747 140.66303983 -20.625 142.3125 C-21.01945312 142.83521484 -21.41390625 143.35792969 -21.8203125 143.89648438 C-24.74628152 147.90773929 -26.90696803 152.18626625 -29.07568359 156.6418457 C-31.2293414 160.96494347 -33.64893078 165.13061625 -36.0625 169.3125 C-36.84089233 170.66843262 -36.84089233 170.66843262 -37.63500977 172.05175781 C-41.40481263 178.60503441 -45.22660165 185.1269808 -49.07470703 191.63452148 C-51.07653769 195.02377165 -53.04966619 198.42039255 -54.9375 201.875 C-56.97952599 205.60576028 -59.16971355 209.23940147 -61.375 212.875 C-65.93771558 220.40694693 -70.24872707 228.07405512 -74.56079102 235.75146484 C-77.7323959 241.38459296 -80.95795889 246.97389217 -84.3125 252.5 C-87.24119669 257.32674608 -90.04201528 262.19847829 -92.71484375 267.171875 C-97.94363457 276.86666833 -103.24979776 286.5246689 -108.9921875 295.92578125 C-111.58926183 300.29092031 -113.97539028 304.77413223 -116.375 309.25 C-117.035 309.25 -117.695 309.25 -118.375 309.25 C-118.58898437 310.02472656 -118.80296875 310.79945313 -119.0234375 311.59765625 C-120.86628804 316.57761364 -123.41801025 321.05674026 -126 325.6875 C-127.09174878 327.66503183 -128.18289334 329.64289736 -129.2734375 331.62109375 C-129.80549805 332.5838623 -130.33755859 333.54663086 -130.88574219 334.53857422 C-132.83619214 338.08967212 -134.73494295 341.66652527 -136.625 345.25 C-145.98058109 362.88334137 -145.98058109 362.88334137 -151.5 370.875 C-153.80414763 374.27726758 -155.86411765 377.75593578 -157.8125 381.375 C-158.32683594 382.32632812 -158.84117187 383.27765625 -159.37109375 384.2578125 C-161.10255454 389.41850887 -159.97281719 393.02487689 -157.6328125 397.8203125 C-156.93346446 399.01208537 -156.22232645 400.19701241 -155.5 401.375 C-155.14808594 401.96925781 -154.79617188 402.56351562 -154.43359375 403.17578125 C-153.42523523 404.87387199 -152.40045955 406.56218136 -151.375 408.25 C-148.92643384 412.28218427 -146.60948817 416.38028625 -144.3125 420.5 C-141.21050886 426.0396766 -138.04930756 431.53809802 -134.8125 437 C-130.22591449 444.75393268 -125.72482526 452.55620517 -121.25 460.375 C-120.90076477 460.98520996 -120.55152954 461.59541992 -120.19171143 462.22412109 C-115.62697138 470.20956005 -111.177107 478.24013464 -106.9140625 486.390625 C-105.21273255 489.5514715 -103.33892253 492.55312274 -101.38671875 495.5625 C-99.73970345 498.30964522 -98.63526241 501.30938771 -97.375 504.25 C-94.53043327 510.02535393 -94.53043327 510.02535393 -89.375 513.25 C-87.99369288 513.33615192 -86.60856367 513.36771603 -85.22457886 513.36352539 C-84.38048462 513.3634549 -83.53639038 513.3633844 -82.66671753 513.36331177 C-81.28264206 513.35556229 -81.28264206 513.35556229 -79.87060547 513.34765625 C-78.89641663 513.34619598 -77.92222778 513.34473572 -76.91851807 513.3432312 C-74.8019345 513.33942346 -72.68535414 513.33330506 -70.56878281 513.32516479 C-67.22456984 513.31243293 -63.88039638 513.30589401 -60.53616333 513.30102539 C-53.44075784 513.28958296 -46.34538486 513.2703313 -39.25 513.25 C-31.02375653 513.22645371 -22.79753149 513.20605077 -14.57126236 513.19406128 C-11.26679279 513.18754849 -7.96237929 513.1750416 -4.65792847 513.16235352 C-2.64548798 513.15872321 -0.63304696 513.1553712 1.37939453 513.15234375 C2.76954269 513.14459427 2.76954269 513.14459427 4.18777466 513.13668823 C6.33384884 513.13650779 8.47983612 513.18749943 10.625 513.25 C11.625 514.25 11.625 514.25 12 516.28515625 C11.43127652 520.78162623 9.05776432 523.93062304 6.625 527.6875 C5.5985427 529.31532437 4.57381477 530.94424047 3.55078125 532.57421875 C3.04627441 533.3739209 2.54176758 534.17362305 2.02197266 534.99755859 C0.19006983 537.95126979 -1.50074211 540.96089592 -3.1875 544 C-6.7800619 550.35779108 -10.64420324 556.52575643 -14.5625 562.6875 C-15.15716064 563.62368164 -15.75182129 564.55986328 -16.36450195 565.52441406 C-22.49289217 575.10501905 -28.19222426 582.35070706 -37.375 589.25 C-38.220625 589.90613281 -39.06625 590.56226563 -39.9375 591.23828125 C-52.19352464 599.96322562 -68.31759543 601.2001539 -82.94921875 601.78515625 C-83.97437592 601.82817871 -84.99953308 601.87120117 -86.05575562 601.91552734 C-89.39115668 602.05286388 -92.72677172 602.18336985 -96.0625 602.3125 C-97.20049042 602.35768768 -98.33848083 602.40287537 -99.51095581 602.44943237 C-115.64111784 603.08225731 -131.73231205 603.39653856 -147.87329102 603.28149414 C-155.61095704 603.22862448 -163.27555383 603.33425027 -170.9934082 603.89477539 C-178.36261404 604.39793724 -185.73300349 604.30449661 -193.11572266 604.21289062 C-199.75654936 604.15771839 -206.35768409 604.35792787 -212.98828125 604.68359375 C-227.35025199 605.38609646 -241.72061653 605.77992587 -256.09350586 606.17993164 C-259.22347949 606.26721465 -262.35334596 606.35741967 -265.4831543 606.45043945 C-276.11284068 606.76580266 -286.7426284 607.0423741 -297.375 607.25 C-298.12109779 607.26479149 -298.86719559 607.27958298 -299.6359024 607.29482269 C-304.00694552 607.37844126 -308.37754639 607.44163893 -312.74925423 607.47689629 C-314.72824857 607.49555714 -316.70709399 607.52833919 -318.68589783 607.5615387 C-319.8763118 607.56628708 -321.06672577 607.57103546 -322.29321289 607.57592773 C-323.32781143 607.58567123 -324.36240997 607.59541473 -325.42835999 607.60545349 C-332.85559689 606.70950513 -337.97281155 601.45772012 -343.421875 596.7734375 C-345.10268668 595.33718837 -346.8079248 593.926074 -348.578125 592.6015625 C-385.04002461 564.58815182 -400.86008553 483.73570735 -406.375 442.25 C-407.12902492 436.17245518 -407.63256692 430.11247569 -407.9296875 423.99609375 C-407.97173309 423.13672714 -408.01377869 422.27736053 -408.05709839 421.39195251 C-408.45526188 412.57425486 -408.52679821 403.76373013 -408.50537109 394.93823242 C-408.49995161 392.28884294 -408.50539389 389.63961919 -408.51171875 386.99023438 C-408.52219689 368.02016949 -408.15123701 348.24122894 -396.375 332.25 C-395.385 331.92 -394.395 331.59 -393.375 331.25 C-392.69375294 329.25491933 -392.03072791 327.25361307 -391.375 325.25 C-389.85414933 322.48692779 -388.11495053 319.87904614 -386.375 317.25 C-385.64023437 316.09371094 -385.64023437 316.09371094 -384.890625 314.9140625 C-382.05029395 310.50715711 -379.13922842 306.92241797 -375.375 303.25 C-374.27494279 301.86730844 -373.19337869 300.46981261 -372.125 299.0625 C-368.76938247 294.6619314 -365.13846668 290.5806168 -361.390625 286.51171875 C-359.59239075 284.49393265 -357.95767776 282.4387031 -356.375 280.25 C-354.65234375 280.34765625 -354.65234375 280.34765625 -352.375 281.25 C-350.73706442 283.37056853 -349.33761069 285.4179011 -347.9375 287.6875 C-347.0410495 289.08674808 -346.14116521 290.48380079 -345.23828125 291.87890625 C-344.76729004 292.6073877 -344.29629883 293.33586914 -343.81103516 294.08642578 C-341.53257539 297.51922252 -339.07345477 300.81250018 -336.625 304.125 C-326.78824459 317.55516691 -317.73434617 331.54504748 -308.57055664 345.43811035 C-307.4852045 347.08298291 -306.39798109 348.72662035 -305.31054688 350.37011719 C-303.70104255 352.80539005 -302.09813738 355.24475826 -300.5 357.6875 C-300.06026855 358.35402588 -299.62053711 359.02055176 -299.16748047 359.70727539 C-296.375 364.01475 -296.375 364.01475 -296.375 366.25 C-291.40206674 362.16509054 -288.81840483 356.41717737 -287.9375 350.125 C-289.05751952 342.76487171 -293.35232379 337.06247944 -297.52734375 331.11914062 C-299.91694577 327.64435236 -301.96140747 324.17758883 -303.80078125 320.37890625 C-306.35759392 315.12373592 -309.43682812 310.34773694 -312.6875 305.5 C-318.42802573 296.80741216 -323.68708093 287.98923306 -328.6875 278.8515625 C-331.02119742 274.59870601 -333.4833351 270.47389034 -336.07421875 266.37109375 C-340.04003614 259.99586125 -343.48591331 253.42601693 -346.79516602 246.69091797 C-347.69884835 244.85190587 -348.61136124 243.01748209 -349.52539062 241.18359375 C-351.16194249 237.88168382 -352.77378164 234.56915236 -354.375 231.25 C-354.72965332 230.54045166 -355.08430664 229.83090332 -355.44970703 229.09985352 C-357.41097055 224.96615798 -357.72269536 221.48521881 -357.625 216.9375 C-357.60953125 215.72449219 -357.5940625 214.51148438 -357.578125 213.26171875 C-357.375 210.25 -357.375 210.25 -356.375 208.25 C-355.92153931 204.61782476 -355.54133415 200.9810806 -355.16796875 197.33984375 C-351.28340206 172.32420692 -326.6012881 147.41323599 -310.375 129.25 C-309.52164063 128.28578125 -308.66828125 127.3215625 -307.7890625 126.328125 C-297.21176768 114.5755752 -286.21984376 102.89343425 -273.75 93.1328125 C-271.51873238 91.36394573 -269.45525561 89.50461364 -267.375 87.5625 C-249.95810891 71.97407256 -229.39491614 59.9117201 -209.20556641 48.31347656 C-207.55451121 47.35428792 -205.92242687 46.36262326 -204.29296875 45.3671875 C-198.51928561 41.94758118 -193.48361318 40.38147077 -186.80859375 39.57421875 C-184.3715701 39.38377638 -184.3715701 39.38377638 -182.375 38.25 C-179.17816086 37.9860408 -175.98815987 37.80617816 -172.78515625 37.64453125 C-168.95373373 37.48644006 -168.95373373 37.48644006 -165.375 36.25 C-164.02732166 36.15604997 -162.67516708 36.12206649 -161.32421875 36.12060547 C-160.07282104 36.11587723 -160.07282104 36.11587723 -158.79614258 36.11105347 C-157.4429895 36.11408981 -157.4429895 36.11408981 -156.0625 36.1171875 C-154.67550903 36.11575241 -154.67550903 36.11575241 -153.26049805 36.11428833 C-151.30354749 36.11360717 -149.34659467 36.115457 -147.38964844 36.11962891 C-144.38731836 36.12497805 -141.3851379 36.11968175 -138.3828125 36.11328125 C-136.48437467 36.11394204 -134.58593693 36.11522323 -132.6875 36.1171875 C-131.78539795 36.11516327 -130.8832959 36.11313904 -129.95385742 36.11105347 C-129.11959229 36.11420563 -128.28532715 36.11735779 -127.42578125 36.12060547 C-126.69012939 36.12140106 -125.95447754 36.12219666 -125.1965332 36.12301636 C-123.375 36.25 -123.375 36.25 -121.375 37.25 C-119.19027735 37.43278556 -117.00179936 37.57177652 -114.8125 37.6875 C-110.66958889 37.94880263 -106.76734489 38.26192362 -102.75 39.3125 C-97.34635365 40.69150238 -91.91300966 40.41867035 -86.375 40.25 C-85.81349085 46.03078272 -87.71228925 49.94554163 -90.1875 55 C-90.54392578 55.76699219 -90.90035156 56.53398438 -91.26757812 57.32421875 C-93.97909383 62.98606255 -93.97909383 62.98606255 -97.375 65.25 C-98.09824116 66.88515393 -98.8210239 68.52337372 -99.43359375 70.203125 C-100.375 72.25 -100.375 72.25 -102.2109375 74.9296875 C-104.76171554 78.84333611 -106.63344409 82.881077 -108.5625 87.125 C-111.84337878 94.20869993 -115.36438552 101.06849497 -119.2800293 107.82177734 C-121.82823772 112.21801345 -124.13639551 116.68727129 -126.375 121.25 C-124.16572956 120.9655186 -121.95761021 120.6720904 -119.75 120.375 C-118.52023437 120.21257812 -117.29046875 120.05015625 -116.0234375 119.8828125 C-109.7064476 118.88867801 -109.7064476 118.88867801 -104.5390625 115.4296875 C-100.76744666 109.78183636 -97.60601105 103.94424934 -94.63720703 97.84594727 C-88.46810482 85.19562436 -81.55791507 72.91901507 -74.078125 61 C-72.13498554 57.86245371 -70.34912685 54.66056527 -68.58203125 51.421875 C-66.76901183 48.15961351 -64.83755919 44.97213958 -62.90234375 41.78125 C-61.90163685 40.12278946 -60.91409847 38.45629492 -59.94140625 36.78125 C-51.17803598 21.77190037 -42.5806593 11.07965875 -25.375 6.25 C-23.03943537 5.25522247 -20.70624929 4.25484883 -18.375 3.25 C-12.11556936 0.73748724 -6.72526207 -0.18027308 0 0 Z " transform="translate(468.375,63.75)"></path></svg></g></g></g><foreignObject x="68" y="75" width="64" height="50"><p><span>Compute</span></p></foreignObject></svg></div><div><p><span>Currently Exists</span><span>Emerging Tech</span><span>Science Fiction</span></p></div><div><p><span><span><number-flow-react aria-label="2,000" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:2,&quot;key&quot;:&quot;integer:3&quot;,&quot;pos&quot;:3},{&quot;type&quot;:&quot;group&quot;,&quot;value&quot;:&quot;,&quot;,&quot;key&quot;:&quot;group:0&quot;},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:2&quot;,&quot;pos&quot;:2},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:1&quot;,&quot;pos&quot;:1},{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:0,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;2,000&quot;,&quot;value&quot;:2000}"><template shadowroot="open" shadowrootmode="open"><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style><span part="left"></span><span part="number" class="number"><span part="integer"><span class="digit" part="digit integer-digit">2</span><span class="symbol" part="symbol group">,</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">0</span><span class="digit" part="digit integer-digit">0</span></span><span part="fraction"></span></span><span part="right"></span></template><span>2,000</span></number-flow-react></span> <!-- -->Unreliable Agent<!-- --> copies thinking at<!-- --> <span><number-flow-react aria-label="8" role="img" data="{&quot;pre&quot;:[],&quot;integer&quot;:[{&quot;type&quot;:&quot;integer&quot;,&quot;value&quot;:8,&quot;key&quot;:&quot;integer:0&quot;,&quot;pos&quot;:0}],&quot;fraction&quot;:[],&quot;post&quot;:[],&quot;valueAsString&quot;:&quot;8&quot;,&quot;value&quot;:8}"><template shadowroot="open" shadowrootmode="open"><style>
				:host{display:inline-block;direction:ltr;white-space:nowrap;line-height:var(--number-flow-char-height, 1em) !important}span{display:inline-block}:host([data-will-change]) span{will-change:transform}.number,.digit{padding:calc(var(--number-flow-mask-height, 0.25em) / 2) 0}.symbol{white-space:pre}</style><span part="left"></span><span part="number" class="number"><span part="integer"><span class="digit" part="digit integer-digit">8</span></span><span part="fraction"></span></span><span part="right"></span></template><span>8</span></number-flow-react>x human speed</span></span></p></div><div><p>AI Capabilities</p><div><div><p><span><p><img src="https://ai-2027.com/hacking.svg" alt="Hacking icon"></p><span>Hacking</span></span></p></div><div><p><span><p><img src="https://ai-2027.com/coding.svg" alt="Coding icon"></p><span>Coding</span></span></p></div><div><p><span><p><img src="https://ai-2027.com/political.svg" alt="Politics icon"><img src="https://ai-2027.com/political.svg" alt="Politics icon"></p><span>Politics</span></span></p></div><div><p><span><p><img src="https://ai-2027.com/bioweapons.svg" alt="Bioweapons icon"><img src="https://ai-2027.com/bioweapons.svg" alt="Bioweapons icon"></p><span>Bioweapons</span></span></p></div><div><p><span><p><img src="https://ai-2027.com/robotics.svg" alt="Robotics icon"><img src="https://ai-2027.com/robotics.svg" alt="Robotics icon"></p><span>Robotics</span></span></p></div><div><p><span><p><img src="https://ai-2027.com/forecasting.svg" alt="Forecasting icon"><img src="https://ai-2027.com/forecasting.svg" alt="Forecasting icon"></p><span>Forecasting</span></span></p></div></div></div></div><div><p><span><div><p><span>Listen to this scenario</span><span></span></p><p>0:00 / 3:23</p></div></span></p></div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A special build of curl that can impersonate Chrome and Firefox (335 pts)]]></title>
            <link>https://github.com/lwthiker/curl-impersonate</link>
            <guid>43571099</guid>
            <pubDate>Thu, 03 Apr 2025 15:24:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lwthiker/curl-impersonate">https://github.com/lwthiker/curl-impersonate</a>, See on <a href="https://news.ycombinator.com/item?id=43571099">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="https://github.com/lwthiker/curl-impersonate/actions/workflows/build-and-test-make.yml"><img src="https://github.com/lwthiker/curl-impersonate/actions/workflows/build-and-test-make.yml/badge.svg" alt="Build and test"></a>
<a href="https://github.com/lwthiker/curl-impersonate/actions/workflows/build-and-test-docker.yml"><img src="https://github.com/lwthiker/curl-impersonate/actions/workflows/build-and-test-docker.yml/badge.svg" alt="Docker images"></a></p>
<p dir="auto">A special build of <a href="https://github.com/curl/curl">curl</a> that can impersonate the four major browsers: Chrome, Edge, Safari &amp; Firefox. curl-impersonate is able to perform TLS and HTTP handshakes that are identical to that of a real browser.</p>
<p dir="auto">curl-impersonate can be used either as a command line tool, similar to the regular curl, or as a library that can be integrated instead of the regular libcurl. See <a href="#Basic-usage">Usage</a> below.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">When you use an HTTP client with a TLS website, it first performs a TLS handshake. The first message of that handshake is called Client Hello. The Client Hello message that most HTTP clients and libraries produce differs drastically from that of a real browser.</p>
<p dir="auto">If the server uses HTTP/2, then in addition to the TLS handshake there is also an HTTP/2 handshake where various settings are exchanged. The settings that most HTTP clients and libraries use differ as well from those of any real browsers.</p>
<p dir="auto">For these reasons, some web services use the TLS and HTTP handshakes to fingerprint which client is accessing them, and then present different content for different clients. These methods are known as <a href="https://lwthiker.com/networks/2022/06/17/tls-fingerprinting.html" rel="nofollow">TLS fingerprinting</a> and <a href="https://lwthiker.com/networks/2022/06/17/http2-fingerprinting.html" rel="nofollow">HTTP/2 fingerprinting</a> respectively. Their widespread use has led to the web becoming less open, less private and much more restrictive towards specific web clients</p>
<p dir="auto">With the modified curl in this repository, the TLS and HTTP handshakes look <em>exactly</em> like those of a real browser.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How?</h2><a id="user-content-how" aria-label="Permalink: How?" href="#how"></a></p>
<p dir="auto">To make this work, <code>curl</code> was patched significantly to resemble a browser. Specifically, The modifications that were needed to make this work:</p>
<ul dir="auto">
<li>Compiling curl with nss, the TLS library that Firefox uses, instead of OpenSSL. For the Chrome version, compiling with BoringSSL, Google's TLS library.</li>
<li>Modifying the way curl configures various TLS extensions and SSL options.</li>
<li>Adding support for new TLS extensions.</li>
<li>Changing the settings that curl uses for its HTTP/2 connections.</li>
<li>Running curl with some non-default flags, for example <code>--ciphers</code>, <code>--curves</code> and some <code>-H</code> headers.</li>
</ul>
<p dir="auto">The resulting curl looks, from a network perspective, identical to a real browser.</p>
<p dir="auto">Read the full technical description in the blog posts: <a href="https://lwthiker.com/reversing/2022/02/17/curl-impersonate-firefox.html" rel="nofollow">part a</a>, <a href="https://lwthiker.com/reversing/2022/02/20/impersonating-chrome-too.html" rel="nofollow">part b</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported browsers</h2><a id="user-content-supported-browsers" aria-label="Permalink: Supported browsers" href="#supported-browsers"></a></p>
<p dir="auto">The following browsers can be impersonated.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Browser</th>
<th>Version</th>
<th>Build</th>
<th>OS</th>
<th>Target name</th>
<th>Wrapper script</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>99</td>
<td>99.0.4844.51</td>
<td>Windows 10</td>
<td><code>chrome99</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome99">curl_chrome99</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>100</td>
<td>100.0.4896.75</td>
<td>Windows 10</td>
<td><code>chrome100</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome100">curl_chrome100</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>101</td>
<td>101.0.4951.67</td>
<td>Windows 10</td>
<td><code>chrome101</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome101">curl_chrome101</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>104</td>
<td>104.0.5112.81</td>
<td>Windows 10</td>
<td><code>chrome104</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome104">curl_chrome104</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>107</td>
<td>107.0.5304.107</td>
<td>Windows 10</td>
<td><code>chrome107</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome107">curl_chrome107</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>110</td>
<td>110.0.5481.177</td>
<td>Windows 10</td>
<td><code>chrome110</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome110">curl_chrome110</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>116</td>
<td>116.0.5845.180</td>
<td>Windows 10</td>
<td><code>chrome116</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome116">curl_chrome116</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/chrome/chrome_24x24.png" alt="Chrome" title="Chrome"></a></td>
<td>99</td>
<td>99.0.4844.73</td>
<td>Android 12</td>
<td><code>chrome99_android</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_chrome99_android">curl_chrome99_android</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/edge/edge_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/edge/edge_24x24.png" alt="Edge" title="Edge"></a></td>
<td>99</td>
<td>99.0.1150.30</td>
<td>Windows 10</td>
<td><code>edge99</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_edge99">curl_edge99</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/edge/edge_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/edge/edge_24x24.png" alt="Edge" title="Edge"></a></td>
<td>101</td>
<td>101.0.1210.47</td>
<td>Windows 10</td>
<td><code>edge101</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_edge101">curl_edge101</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>91 ESR</td>
<td>91.6.0esr</td>
<td>Windows 10</td>
<td><code>ff91esr</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff91esr">curl_ff91esr</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>95</td>
<td>95.0.2</td>
<td>Windows 10</td>
<td><code>ff95</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff95">curl_ff95</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>98</td>
<td>98.0</td>
<td>Windows 10</td>
<td><code>ff98</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff98">curl_ff98</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>100</td>
<td>100.0</td>
<td>Windows 10</td>
<td><code>ff100</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff100">curl_ff100</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>102</td>
<td>102.0</td>
<td>Windows 10</td>
<td><code>ff102</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff102">curl_ff102</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>109</td>
<td>109.0</td>
<td>Windows 10</td>
<td><code>ff109</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff109">curl_ff109</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png"><img src="https://raw.githubusercontent.com/alrra/browser-logos/main/src/firefox/firefox_24x24.png" alt="Firefox" title="Firefox"></a></td>
<td>117</td>
<td>117.0.1</td>
<td>Windows 10</td>
<td><code>ff117</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff117">curl_ff117</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/alrra/browser-logos/blob/main/src/safari/safari_24x24.png"><img src="https://github.com/alrra/browser-logos/raw/main/src/safari/safari_24x24.png" alt="Safari" title="Safari"></a></td>
<td>15.3</td>
<td>16612.4.9.1.8</td>
<td>MacOS Big Sur</td>
<td><code>safari15_3</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_safari15_3">curl_safari15_3</a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/alrra/browser-logos/blob/main/src/safari/safari_24x24.png"><img src="https://github.com/alrra/browser-logos/raw/main/src/safari/safari_24x24.png" alt="Safari" title="Safari"></a></td>
<td>15.5</td>
<td>17613.2.7.1.8</td>
<td>MacOS Monterey</td>
<td><code>safari15_5</code></td>
<td><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome/curl_safari15_5">curl_safari15_5</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">This list is also available in the <a href="https://github.com/lwthiker/curl-impersonate/blob/main/browsers.json">browsers.json</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Basic usage</h2><a id="user-content-basic-usage" aria-label="Permalink: Basic usage" href="#basic-usage"></a></p>
<p dir="auto">For each supported browser there is a wrapper script that launches <code>curl-impersonate</code> with all the needed headers and flags. For example:</p>
<div data-snippet-clipboard-copy-content="curl_chrome116 https://www.wikipedia.org"><pre><code>curl_chrome116 https://www.wikipedia.org
</code></pre></div>
<p dir="auto">You can add command line flags and they will be passed on to curl. However, some flags change curl's TLS signature which may cause it to be detected.</p>
<p dir="auto">Please note that the wrapper scripts use a default set of HTTP headers. If you want to change these headers, you may want to modify the wrapper scripts to fit your own purpose.</p>
<p dir="auto">See <a href="#Advanced-usage">Advanced usage</a> for more options, including using <code>libcurl-impersonate</code> as a library.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">More documentation is available in the <a href="https://github.com/lwthiker/curl-impersonate/blob/main/docs/README.md">docs/</a> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">There are two versions of <code>curl-impersonate</code> for technical reasons. The <strong>chrome</strong> version is used to impersonate Chrome, Edge and Safari. The <strong>firefox</strong> version is used to impersonate Firefox.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pre-compiled binaries</h3><a id="user-content-pre-compiled-binaries" aria-label="Permalink: Pre-compiled binaries" href="#pre-compiled-binaries"></a></p>
<p dir="auto">Pre-compiled binaries for Linux and macOS (Intel) are available at the <a href="https://github.com/lwthiker/curl-impersonate/releases">GitHub releases</a> page.
Before you use them you need to install nss (Firefox's TLS library) and CA certificates:</p>
<ul dir="auto">
<li>Ubuntu - <code>sudo apt install libnss3 nss-plugin-pem ca-certificates</code></li>
<li>Red Hat/Fedora/CentOS - <code>yum install nss nss-pem ca-certificates</code></li>
<li>Archlinux - <code>pacman -S nss ca-certificates</code></li>
<li>macOS - <code>brew install nss ca-certificates</code></li>
</ul>
<p dir="auto">Also ensure you have zlib installed on your system.
zlib is almost always present, but on some minimal systems it might be missing.</p>
<p dir="auto">The pre-compiled binaries contain libcurl-impersonate and a statically compiled curl-impersonate for ease of use.</p>
<p dir="auto">The pre-compiled Linux binaries are built for Ubuntu systems. On other distributions if you have errors with certificate verification you may have to tell curl where to find the CA certificates. For example:</p>
<div data-snippet-clipboard-copy-content="curl_chrome116 https://www.wikipedia.org --cacert /etc/ssl/certs/ca-bundle.crt"><pre><code>curl_chrome116 https://www.wikipedia.org --cacert /etc/ssl/certs/ca-bundle.crt
</code></pre></div>
<p dir="auto">Also make sure to read <a href="#notes-on-dependencies">Notes on Dependencies</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from source" href="#building-from-source"></a></p>
<p dir="auto">See <a href="https://github.com/lwthiker/curl-impersonate/blob/main/INSTALL.md">INSTALL.md</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker images</h3><a id="user-content-docker-images" aria-label="Permalink: Docker images" href="#docker-images"></a></p>
<p dir="auto">Docker images based on Alpine Linux and Debian with <code>curl-impersonate</code> compiled and ready to use are available on <a href="https://hub.docker.com/r/lwthiker/curl-impersonate" rel="nofollow">Docker Hub</a>. The images contain the binary and all the wrapper scripts. Use like the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Firefox version, Alpine Linux
docker pull lwthiker/curl-impersonate:0.6-ff
docker run --rm lwthiker/curl-impersonate:0.6-ff curl_ff109 https://www.wikipedia.org

# Chrome version, Alpine Linux
docker pull lwthiker/curl-impersonate:0.6-chrome
docker run --rm lwthiker/curl-impersonate:0.6-chrome curl_chrome110 https://www.wikipedia.org"><pre><span><span>#</span> Firefox version, Alpine Linux</span>
docker pull lwthiker/curl-impersonate:0.6-ff
docker run --rm lwthiker/curl-impersonate:0.6-ff curl_ff109 https://www.wikipedia.org

<span><span>#</span> Chrome version, Alpine Linux</span>
docker pull lwthiker/curl-impersonate:0.6-chrome
docker run --rm lwthiker/curl-impersonate:0.6-chrome curl_chrome110 https://www.wikipedia.org</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Distro packages</h3><a id="user-content-distro-packages" aria-label="Permalink: Distro packages" href="#distro-packages"></a></p>
<p dir="auto">AUR packages are available to Archlinux users:</p>
<ul dir="auto">
<li>Pre-compiled package: <a href="https://aur.archlinux.org/packages/curl-impersonate-bin" rel="nofollow">curl-impersonate-bin</a>, <a href="https://aur.archlinux.org/packages/libcurl-impersonate-bin" rel="nofollow">libcurl-impersonate-bin</a>.</li>
<li>Build from source code: <a href="https://aur.archlinux.org/packages/curl-impersonate-chrome" rel="nofollow">curl-impersonate-chrome</a>, <a href="https://aur.archlinux.org/packages/curl-impersonate-firefox" rel="nofollow">curl-impersonate-firefox</a>.</li>
</ul>
<p dir="auto">Unofficial Homebrew receipts for Mac (Chrome only) are available <a href="https://github.com/shakacode/homebrew-brew/blob/main/Formula/curl-impersonate.rb">here</a>:</p>
<div data-snippet-clipboard-copy-content="brew tap shakacode/brew
brew install curl-impersonate"><pre><code>brew tap shakacode/brew
brew install curl-impersonate
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced usage</h2><a id="user-content-advanced-usage" aria-label="Permalink: Advanced usage" href="#advanced-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">libcurl-impersonate</h3><a id="user-content-libcurl-impersonate" aria-label="Permalink: libcurl-impersonate" href="#libcurl-impersonate"></a></p>
<p dir="auto"><code>libcurl-impersonate.so</code> is libcurl compiled with the same changes as the command line <code>curl-impersonate</code>.
It has an additional API function:</p>
<div dir="auto" data-snippet-clipboard-copy-content="CURLcode curl_easy_impersonate(struct Curl_easy *data, const char *target,
                               int default_headers);"><pre><span>CURLcode</span> <span>curl_easy_impersonate</span>(<span>struct</span> <span>Curl_easy</span> <span>*</span><span>data</span>, <span>const</span> <span>char</span> <span>*</span><span>target</span>,
                               <span>int</span> <span>default_headers</span>);</pre></div>
<p dir="auto">You can call it with the target names, e.g. <code>chrome116</code>, and it will internally set all the options and headers that are otherwise set by the wrapper scripts.
If <code>default_headers</code> is set to 0, the built-in list of  HTTP headers will not be set, and the user is expected to provide them instead using the regular <a href="https://curl.se/libcurl/c/CURLOPT_HTTPHEADER.html" rel="nofollow"><code>CURLOPT_HTTPHEADER</code></a> libcurl option.</p>
<p dir="auto">Calling the above function sets the following libcurl options:</p>
<ul dir="auto">
<li><code>CURLOPT_HTTP_VERSION</code></li>
<li><code>CURLOPT_SSLVERSION</code>, <code>CURLOPT_SSL_CIPHER_LIST</code>, <code>CURLOPT_SSL_EC_CURVES</code>, <code>CURLOPT_SSL_ENABLE_NPN</code>, <code>CURLOPT_SSL_ENABLE_ALPN</code></li>
<li><code>CURLOPT_HTTPBASEHEADER</code>, if <code>default_headers</code> is non-zero (this is a non-standard HTTP option created for this project).</li>
<li><code>CURLOPT_HTTP2_PSEUDO_HEADERS_ORDER</code>, <code>CURLOPT_HTTP2_NO_SERVER_PUSH</code> (non-standard HTTP/2 options created for this project).</li>
<li><code>CURLOPT_SSL_ENABLE_ALPS</code>, <code>CURLOPT_SSL_SIG_HASH_ALGS</code>, <code>CURLOPT_SSL_CERT_COMPRESSION</code>, <code>CURLOPT_SSL_ENABLE_TICKET</code> (non-standard TLS options created for this project).</li>
<li><code>CURLOPT_SSL_PERMUTE_EXTENSIONS</code> (non-standard TLS options created for this project).
Note that if you call <code>curl_easy_setopt()</code> later with one of the above it will override the options set by <code>curl_easy_impersonate()</code>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using CURL_IMPERSONATE env var</h3><a id="user-content-using-curl_impersonate-env-var" aria-label="Permalink: Using CURL_IMPERSONATE env var" href="#using-curl_impersonate-env-var"></a></p>
<p dir="auto">If your application uses <code>libcurl</code> already, you can replace the existing library at runtime with <code>LD_PRELOAD</code> (Linux only). You can then set the <code>CURL_IMPERSONATE</code> env var. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 my_app"><pre>LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 my_app</pre></div>
<p dir="auto">The <code>CURL_IMPERSONATE</code> env var has two effects:</p>
<ul dir="auto">
<li><code>curl_easy_impersonate()</code> is called automatically for any new curl handle created by <code>curl_easy_init()</code>.</li>
<li><code>curl_easy_impersonate()</code> is called automatically after any <code>curl_easy_reset()</code> call.</li>
</ul>
<p dir="auto">This means that all the options needed for impersonation will be automatically set for any curl handle.</p>
<p dir="auto">If you need precise control over the HTTP headers, set <code>CURL_IMPERSONATE_HEADERS=no</code> to disable the built-in list of HTTP headers, then set them yourself with <code>curl_easy_setopt()</code>. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 CURL_IMPERSONATE_HEADERS=no my_app"><pre>LD_PRELOAD=/path/to/libcurl-impersonate.so CURL_IMPERSONATE=chrome116 CURL_IMPERSONATE_HEADERS=no my_app</pre></div>
<p dir="auto">Note that the <code>LD_PRELOAD</code> method will NOT WORK for <code>curl</code> itself because the curl tool overrides the TLS settings. Use the wrapper scripts instead.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Notes on dependencies</h3><a id="user-content-notes-on-dependencies" aria-label="Permalink: Notes on dependencies" href="#notes-on-dependencies"></a></p>
<p dir="auto">If you intend to copy the self-compiled artifacts to another system, or use the <a href="#pre-compiled-binaries">Pre-compiled binaries</a> provided by the project, make sure that all the additional dependencies are met on the target system as well.
In particular, see the <a href="https://github.com/lwthiker/curl-impersonate/blob/main/INSTALL.md#a-note-about-the-firefox-version">note about the Firefox version</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<p dir="auto">This repository contains two main folders:</p>
<ul dir="auto">
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/chrome">chrome</a> - Scripts and patches for building the Chrome version of <code>curl-impersonate</code>.</li>
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox">firefox</a> - Scripts and patches for building the Firefox version of <code>curl-impersonate</code>.</li>
</ul>
<p dir="auto">The layout is similar for both. For example, the Firefox directory contains:</p>
<ul dir="auto">
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/Dockerfile">Dockerfile</a> - Used to build <code>curl-impersonate</code> with all dependencies.</li>
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff91esr">curl_ff91esr</a>, <a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff95">curl_ff95</a>, <a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/curl_ff98">curl_ff98</a> - Wrapper scripts that launch <code>curl-impersonate</code> with the correct flags.</li>
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/firefox/patches/curl-impersonate.patch">curl-impersonate.patch</a> - The main patch that makes curl use the same TLS extensions as Firefox. Also makes curl compile statically with libnghttp2 and libnss.</li>
</ul>
<p dir="auto">Other files of interest:</p>
<ul dir="auto">
<li><a href="https://github.com/lwthiker/curl-impersonate/blob/main/tests/signatures">tests/signatures</a> - YAML database of known browser signatures that can be impersonated.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you'd like to help, please check out the <a href="https://github.com/lwthiker/curl-impersonate/issues">open issues</a>. You can open a pull request with your changes.</p>
<p dir="auto">This repository contains the build process for <code>curl-impersonate</code>. The actual patches to <code>curl</code> are maintained in a <a href="https://github.com/lwthiker/curl">separate repository</a> forked from the upstream curl. The changes are maintained in the <a href="https://github.com/lwthiker/curl/tree/impersonate-firefox">impersonate-firefox</a>  and <a href="https://github.com/lwthiker/curl/tree/impersonate-chrome">impersonate-chrome</a> branches.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsors</h2><a id="user-content-sponsors" aria-label="Permalink: Sponsors" href="#sponsors"></a></p>
<p dir="auto">Sponsors help keep this project open and maintained. If you wish to become a sponsor, please contact me directly at: lwt at lwthiker dot com.</p>
<a href="https://serpapi.com/" rel="nofollow">
  <img src="https://camo.githubusercontent.com/5434b70f028d9f606789f3c330553a80ab230cefc56cba245db29f87f62bef6d/68747470733a2f2f692e696d6775722e636f6d2f43424f5378726d2e706e67" alt="Logo" width="165px" height="65px" data-canonical-src="https://i.imgur.com/CBOSxrm.png">
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AnimeJs v4 Is Here (664 pts)]]></title>
            <link>https://animejs.com/</link>
            <guid>43570533</guid>
            <pubDate>Thu, 03 Apr 2025 14:47:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animejs.com/">https://animejs.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43570533">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="features-gallery" data-label="FEATURES">
    <div id="intuitive" data-chapter="intuitive" data-demo="intuitive">
            <div>
              <h2>Intuitive API</h2>
              <p>Animate faster with an easy-to-use, yet powerful animation API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/animation/tween-parameters/composition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Per property parameters</a></li>
              <li><a href="https://animejs.com/documentation/animation/tween-parameters/composition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Flexible keyframes system</a></li>
              <li><a href="https://animejs.com/documentation/animation/tween-parameters/composition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Built-in easings</a></li>
            </ul>
          </div>

    <div id="composition" data-chapter="composition" data-demo="composition">
            <div>
              <h2>Enhanced transforms</h2>
              <p>Smoothly blend individual CSS transform properties with a versatile composition API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/animation/animatable-properties/css-transforms"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Individual CSS Transforms</a></li>
              <li><a href="https://animejs.com/documentation/animation/tween-value-types/function-based"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Function based values</a></li>
              <li><a href="https://animejs.com/documentation/animation/tween-parameters/composition"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Blend composition</a></li>
            </ul>
          </div>

    <div id="svgUtils" data-chapter="svgUtils" data-demo="svgUtils">
            <div>
              <h2>SVG toolset</h2>
              <p>Morph shapes, follow motion paths, and draw lines easily with the built-in SVG utilities.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/svg/morphto"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Shape morphing</a></li>
              <li><a href="https://animejs.com/documentation/svg/createdrawable"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Line drawing</a></li>
              <li><a href="https://animejs.com/documentation/svg/createmotionpath"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Motion path</a></li>
            </ul>
          </div>

    <div id="scroll" data-chapter="scroll" data-demo="scroll">
            <div>
              <h2>Scroll Observer</h2>
              <p>Synchronise and trigger animations on scroll with the Scroll Observer API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/scroll/scrollobserver-synchronisation-modes"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Multiple synchronisation modes</a></li>
              <li><a href="https://animejs.com/documentation/scroll/scrollobserver-thresholds"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Advanced thresholds</a></li>
              <li><a href="https://animejs.com/documentation/scroll/scrollobserver-callbacks"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Complete set of callbacks</a></li>
            </ul>
          </div>

    <div id="staggering" data-chapter="staggering" data-demo="staggering">
            <div>
              <h2>Advanced staggering</h2>
              <p>Create stunning effects in seconds with the built-in Stagger utility function.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/stagger/time-staggering"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Time staggering</a></li>
              <li><a href="https://animejs.com/documentation/stagger/values-staggering"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Values staggering</a></li>
              <li><a href="https://animejs.com/documentation/stagger/timeline-positions-staggering"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Timeline positions staggering</a></li>
            </ul>
          </div>

    <div id="draggable" data-chapter="draggable" data-demo="draggable">
            <div>
              <h2>Springs and draggable</h2>
              <p>Drag, snap, flick and throw HTML elements with the fully-featured Draggable API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/draggable/draggable-settings"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Versatile settings</a></li>
              <li><a href="https://animejs.com/documentation/draggable/draggable-callbacks"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Comprehensive callbacks</a></li>
              <li><a href="https://animejs.com/documentation/draggable/draggable-methods"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Useful methods</a></li>
            </ul>
          </div>

    <div id="clockwork" data-chapter="clockwork" data-demo="clockwork">
            <div>
              <h2>Runs like <br>clockwork</h2>
              <p>Orchestrate animation sequences and keep callbacks in sync with the powerfull Timeline API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/timeline/add-animations"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Synchronise animations</a></li>
              <li><a href="https://animejs.com/documentation/timeline/time-position"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Advanced time positions</a></li>
              <li><a href="https://animejs.com/documentation/timeline/timeline-playback-settings"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Playback settings</a></li>
            </ul>
          </div>

    <div id="responsive" data-chapter="responsive" data-demo="responsive">
            <div>
              <h2>Responsive animations</h2>
              <p>Make animations respond to media queries easily with the Scope API.</p>
            </div>
            <ul>
              <li><a href="https://animejs.com/documentation/scope/scope-parameters/mediaqueries"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Media queries</a></li>
              <li><a href="https://animejs.com/documentation/scope/scope-parameters/root"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Custom root element</a></li>
              <li><a href="https://animejs.com/documentation/scope/register-method-function"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
  <g fill="none" fill-rule="evenodd">
    <polygon fill="currentColor" fill-rule="nonzero" points="17.737 11.987 12.5 17.225 11.263 15.987 14.388 12.862 6.5 12.862 6.5 11.112 14.388 11.112 11.263 7.987 12.5 6.75"></polygon>
  </g>
</svg>
Scopped methods</a></li>
            </ul>
          </div>
  </section><div>
    
<pre data-card="intuitive" data-=""><code>animate('.square', {
  rotate: 90,
  loop: true,
  ease: 'inOutExpo',
});
</code></pre>
<pre data-card="composition"><code>animate('.shape', {
  x: random(-100, 100),
  y: random(-100, 100),
  rotate: random(-180, 180),
  duration: random(500, 1000),
  composition: 'blend',
});
</code></pre>
<pre data-card="svgUtils"><code>animate('.car', {
  ...createMotionPath('.circuit'),
});

animate(createDrawable('.circuit'), {
  draw: '0 1',
});

animate('.circuit-a', {
  d: morphTo('.circuit-b'),
});
</code></pre>
<pre data-card="scroll"><code>animate(createDrawable('path'), {
  draw: ['0 0', '0 1', '1 1'],
  delay: stagger(40),
  ease: 'inOut(3)',
  autoplay: onScroll({ sync: true }),
});
</code></pre>
<pre data-card="staggering"><code>const options = {
  grid: [13, 13],
  from: 'center',
};

createTimeline()
  .add('.dot', {
    scale: stagger([1.1, .75], options),
    ease: 'inOutQuad',
  }, stagger(200, options));
</code></pre>
<pre data-card="draggable"><code>createDraggable('.circle', {
  releaseEase: createSpring({
    stiffness: 120,
    damping: 6,
  })
});
</code></pre>
<pre data-card="clockwork"><code>createTimeline()
  .add('.tick', {
    y: '-=6',
    duration: 50,
  }, stagger(10))
  .add('.ticker', {
    rotate: 360,
    duration: 1920,
  }, '&lt;');
</code></pre>
<pre data-card="responsive"><code>createScope({
  mediaQueries: {
    portrait: '(orientation: portrait)',
  }
})
.add(({ matches }) =&gt; {
  const isPortrait = matches.portrait;
  createTimeline().add('.circle', {
    y: isPortrait ? 0 : [-50, 50, -50],
    x: isPortrait ? [-50, 50, -50] : 0,
  }, stagger(100));
});
</code></pre>
    <div data-card="modules" data-enter-offset="-=50lvh" data-leave-offset="-=150lvh">
      
      
      <ul>
        <li><span></span>Timer <span>5.60 KB</span></li>
        <li><span></span>Animation <span>+5.20 KB</span></li>
        <li><span></span>Timeline <span>+0.55 KB</span></li>
        <li><span></span>Animatable <span>+0.40 KB</span></li>
        <li><span></span>Draggable <span>+6.41 KB</span></li>
        <li><span></span>Scroll <span>+4.30 KB</span></li>
        <li><span></span>Scope <span>+0.22 KB</span></li>
        <li><span></span>Stagger <span>+0.48 KB</span></li>
        <li><span></span>SVG <span>0.35 KB</span></li>
        <li><span></span>Spring <span>0.52 KB</span></li>
        <li><span></span>WAAPI <span>3.50 KB</span></li>
      </ul>
    </div>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Overengineered Anchor Links (291 pts)]]></title>
            <link>https://thirty-five.com/overengineered-anchoring</link>
            <guid>43570324</guid>
            <pubDate>Thu, 03 Apr 2025 14:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thirty-five.com/overengineered-anchoring">https://thirty-five.com/overengineered-anchoring</a>, See on <a href="https://news.ycombinator.com/item?id=43570324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text-wrapper">  <p>Anchor links are deceptively simple at first glance: click a button, scroll to the heading, and done. But if you ever had to implement them, you might have encountered the <astro-island uid="Z2kKYgx" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;red&quot;],&quot;id&quot;:[0,&quot;component-tile-lm24m68ldyj&quot;],&quot;text&quot;:[0,&quot;“active anchor problem”&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="1JX5wf" component-url="/_astro/AnchorProblem.GGiwfq1Z.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;AnchorProblem&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island>.
The issue being that, headings towards the bottom of the page can be too far down to scroll them to the desired position. The example component above shows how the ‘conclusion’ heading can never be reached.
Surely this will be detrimental to the user experience. We need to come up with a solution. In this blog post, I’ll show some of the solutions I’ve come up with — from a hotfix all the way to unhinged. But before we do that, let’s create a more <astro-island uid="Z1MksBG" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-5t0ccesj14q&quot;],&quot;text&quot;:[0,&quot;abstract visualization&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="Z2ucBWu" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;default&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island>. Here, we see a viewport moving down the page, with the trigger line being set at 25vh from the top of the viewport. This is what we’ll use to visualize the different solutions.</p>

<p>The most simple solution is to add <astro-island uid="27A0Xm" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-rge2ndsw839&quot;],&quot;text&quot;:[0,&quot;extra\npadding.&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="12OCzC" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;extra-padding&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> We calculate the height of the padding by taking the delta between the last
heading and the lowest point the anchor trigger can reach. Perfect, right? Well, sometimes the
design team is not so fond of random extra padding, so lets keep searching.</p>
<h2 id="practical-shift-the-trigger-line">Practical: shift the trigger line</h2>
<p>Maybe instead of adding extra padding, <astro-island uid="qP9nn" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-jtcl7bygbvh&quot;],&quot;text&quot;:[0,&quot;shift the\ntrigger line.&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="Gvykj" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;shift-triggers&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> This is also quite simple to do, we just need to calculate how far
from the bottom the last heading is, and put the trigger line there as well. But, this would mean
that when the users clicks an anchor tag, the heading could be put all the way at the bottom of the
viewport. This is of course not great, since most people put the text they read on the top half of
the screen. We need to keep looking.</p>
<h2 id="good-translate-the-trigger-points">Good: translate the trigger points</h2>
<p>Instead of shifting the trigger line, we could <astro-island uid="D59lS" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-3tievcl9v6v&quot;],&quot;text&quot;:[0,&quot;translate&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="dqbkI" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;translate-points&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> the headings upwards. Instead of using the actual location of the headings as the ones causing the triggers, we create <strong>virtual headings</strong> and translate them upwards. A virtual heading is not actually visible in the article, its just the position we use to dictate the active state.
One might argue that this is pretty much the same as shifting the trigger line, and they’d be right conceptually. However, thinking about translating the trigger points gives us more mental flexibility, as it allows us to consider applying <em>different</em> adjustments based on each heading’s position, which will be crucial later.</p>
<p><em><strong>The example visualizations now show the location of these ‘virtual headings’. So, while the heading is still at the same place in the article, we visualize where its trigger point is.</strong></em></p>
<p>In the example, we see one problem arising: the first heading is now too far up. The nice part of this new approach is that we can fix this quite elegantly, since we can shift the individual virtual headings with ease. But what would be a good way to do this?</p>
<h2 id="great-translate-trigger-points-fractionally">Great: translate trigger points fractionally</h2>
<p>If we think about it, we don’t need to translate all the trigger points. There’s only a few conditions
that need to be met:</p>
<ol>
<li>The headings need to be reachable.</li>
<li>The headings need to stay in order.</li>
</ol>
<p>We can meet these conditions by translating the trigger points <astro-island uid="1s7jNo" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-q6z2eo6ppnh&quot;],&quot;text&quot;:[0,&quot;fractionally.&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="mlTOP" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;translate-points-fractionally&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> Here,
the first heading doesn’t move, and the last heading moves up by the full amount necessary to become reachable. The other headings move up by a proportional amount based on their position between the first and last heading. Now we are getting somewhere! This is a solid solution. You might want to stop here before your product manager starts giving you puzzled looks, wondering how “fixing anchor links” has suddenly turned into a three-week epic.</p>
<h2 id="awesome-create-a-custom-mapping-function">Awesome: create a custom mapping function</h2>
<p>While the fractional solution works, in the sense that our conditions are met, it does have some
flaws. We have chosen a trigger line that’s 25% down from the top of the viewport. It would be nice
if we can actually minimize the deviation from this ideal line across all headings. The closer the triggers happen to this (mind you — semi-arbitrarily chosen) line, the better the user experience <em>should</em> be. Minimizing deviation feels like a good heuristic. This for sure will make the users happier and result in increased shareholder value.</p>
<p>Let’s minimize the <astro-island uid="Z1sJ5Uy" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-15vvr9sn5ml&quot;],&quot;text&quot;:[0,&quot;mean squared error&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="1XpdHr" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;minimize-mse&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> (MSE) of the delta between the headings’ original positions and their virtual positions. We use MSE because it heavily penalizes large deviations, pushing the system towards a state where most virtual headings are close to their original spots, while still satisfying our reachability constraints. Of course, the constraint that headings must stay in order still applies.
This results in all points that are reachable staying at their original position. Seems that we have an issue. headings are bunched up at the bottom. This makes sense, since minimization of the mean squared error only cares about proximity to the original position; it has no ‘force’ that opposes this bunching. We need to define something that encourages the virtual trigger points to maintain a certain distance from each other, ideally related to their original spacing. Considering the user experience, we might assume that it’s nice to have the scroll <em>distance</em> needed to activate the next section’s anchor be somewhat proportional to the actual content length of that section. This ‘sections wanting to preserve their relative scroll length’-force is what we’ll use.</p>
<h3 id="side-quest-minimization-functions">Side quest: minimization functions</h3>
<p>To explore this idea we need to bust out… Python. Here, we (read: Claude and I) implemented a <astro-island uid="1f7U5P" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;text&quot;:[0,&quot;SLSQP&quot;],&quot;color&quot;:[0,&quot;yellow&quot;],&quot;id&quot;:[0,&quot;text-tile-lyxzkxriri&quot;],&quot;type&quot;:[0,&quot;information&quot;],&quot;forceAspectRatio&quot;:[0,true]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""> <div style="background-color:#FFE72E;color:#000000;--selection-color:#000000" class="flex h-full w-full flex-col p-4 pt-4 flex h-full w-full flex-col p-4 pt-4 [&amp;::selection]:!text-[var(--selection-color)] [&amp;_*::selection]:!text-[var(--selection-color)] selection:!bg-black/25"> <small class="text-[0.75rem] conrette-extrabold pb-1 first-letter:uppercase">SLSQP</small> <p class="text-[1rem] flex  h-fit conrette-regular !mb-2  "> SLSQP (Sequential Least Squares Programming) is an optimization algorithm used to solve constrained nonlinear problems. It works by iteratively improving a solution while satisfying equality and inequality constraints. At each step, it approximates the problem using simpler quadratic models and linear constraints, making it efficient for problems where smooth gradients are available. SLSQP is commonly used in engineering, machine learning, and operations research when both the objective and the constraints are differentiable. </p> </div> </template><!--astro:end--></astro-island> solver, which is a type of numerical optimization algorithm designed for constrained problems like ours.
The core of the optimization lies in a loss function with two competing terms:</p>
<ul>
<li><strong>Anchor penalty:</strong> How far a virtual heading is moved from its original location. Minimizing this keeps virtual headings close to their original position. (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub><mo>=</mo><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>v</mi><mi>i</mi><mi>r</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>y</mi><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L_{anchor} = \sum (y_{virtual} - y_{original})^2</annotation></semantics></math></span></span>)</li>
<li><strong>Section penalty:</strong> How much the size of each virtual section (the space between two virtual headings) differs from the original section size. Minimizing this ensures that sections don’t become disproportionately short or long in terms of scroll distance. (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mo>∑</mo><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>v</mi><mi>i</mi><mi>r</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>v</mi><mi>i</mi><mi>r</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L_{section} = \sum ((y_{i+1, virtual} - y_{i, virtual}) - (y_{i+1, original} - y_{i, original}))^2</annotation></semantics></math></span></span>)</li>
</ul>
<p>We combine these into a total loss <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>w</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub><msub><mi>L</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><msub><mi>L</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L = w_{anchor} L_{anchor} + w_{section} L_{section}</annotation></semantics></math></span></span>, where the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{anchor}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{section}</annotation></semantics></math></span></span> control the trade-off (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub><mo>+</mo><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">w_{anchor} + w_{section} = 1</annotation></semantics></math></span></span>).</p>
<p>We define constraints to:</p>
<ul>
<li>Keep virtual headings inside the page boundaries.</li>
<li>Ensure the first heading doesn’t float upward (its virtual position must be &gt;= its original position).</li>
<li>Keep virtual headings in order (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>v</mi><mi>i</mi><mi>r</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>≥</mo><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>v</mi><mi>i</mi><mi>r</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{i+1, virtual} \ge y_{i, virtual}</annotation></semantics></math></span></span>).</li>
</ul>
<p>From this, we generate a plot showing how the virtual headings’ locations change as we vary the weights (specifically, as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{section}</annotation></semantics></math></span></span> increases from 0 to 1).</p>
<p>Running that code gives us <astro-island uid="1lj9Pu" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0],&quot;id&quot;:[0,&quot;image-tile-1nqng5ria44&quot;],&quot;text&quot;:[0,&quot;this graph&quot;],&quot;type&quot;:[0,&quot;image&quot;],&quot;forceAspectRatio&quot;:[0,true]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""> <div class="h-full w-full"> <img class="h-full w-full object-cover" src="/content-collection-media/articles/anchoring/chart_two.png" alt="visualization of this graph"> </div> </template><!--astro:end--></astro-island>. The circles on the left (at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">w_{section} = 0</annotation></semantics></math></span></span>) represent the original heading locations. The lines show how each virtual heading’s location (Y-axis) changes as the section penalty weight <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{section}</annotation></semantics></math></span></span> (X-axis) increases. On the left side, the priority is keeping headings near their original spots (high <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{anchor}</annotation></semantics></math></span></span>). On the right side, the priority shifts to preserving the original spacing between headings (high <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{section}</annotation></semantics></math></span></span>).
I am curious to see how this compares to the simple fractional translation we tried earlier. And wouldn’t <astro-island uid="Zqn9C0" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0],&quot;id&quot;:[0,&quot;image-tile-s32dd6v63q&quot;],&quot;text&quot;:[0,&quot;you know it&quot;],&quot;type&quot;:[0,&quot;image&quot;],&quot;forceAspectRatio&quot;:[0,true]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""> <div class="h-full w-full"> <img class="h-full w-full object-cover" src="/content-collection-media/articles/anchoring/chart_one.png" alt="visualization of you know it"> </div> </template><!--astro:end--></astro-island>, the fractional translation is exactly what the optimizer settles on when the section penalty is dominant (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">w_{section} = 1</annotation></semantics></math></span></span>)!</p>
<h3 id="realizations">Realizations</h3>
<p>Staring at that optimization graph sparked a thought. Okay, maybe two thoughts. First, that need to preserve section spacing really kicks in towards the <em>end</em> of the page, where headings get forcibly shoved upwards to stay reachable, squashing the final sections together. Second, let’s consider the behavior of the ‘fractional translation’ method on an edge case.</p>
<p>Imagine, if you will, taking the entire Bible, from the “In the beginning” of Genesis to the final “Amen” of Revelation, and rendering it as one continuous, scrollable webpage. (For the tech bros among us: you could alternatively imagine gluing all of Paul Graham’s essays back-to-back). Now, suppose the very last heading, maybe “Revelation Chapter 22”, is just 200 pixels too low to hit our trigger line when scrolled to.</p>
<p>Does our previous ‘fractional translation’ make sense here? It means taking those 200 pixels of required uplift and meticulously spreading that adjustment across <em>every single heading</em> all the way back to the start. The Ten Commandments get a tiny bump, the Psalms slightly more, all culminating in Revelation 22 getting the full 200px boost.</p>
<p>Actually, if you think about it, with a fractional translation, the error (the distance between the virtual and original headings) grows with the page length. So if the page tends to infinity, so does the error! This would of course be sloppy, and something users could immediately notice as feeling off. So how are we going to fix this?</p>
<h3 id="the-final-version">The final version</h3>
<p>This leads to our desired behavior for a smarter mapping function:</p>
<ul>
<li>For headings near the end of the page, apply more adjustment (act like high <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{section}</annotation></semantics></math></span></span>).</li>
<li>For headings near the beginning of the page, apply less (or ideally no) adjustment (act like high <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{anchor}</annotation></semantics></math></span></span>).</li>
<li>The transition between these states should be smooth.</li>
</ul>
<p>We need a function that maps a heading’s normalized position <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">x \in [0, 1]</annotation></semantics></math></span></span> (where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x=0</annotation></semantics></math></span></span> is the first heading, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x=1</annotation></semantics></math></span></span> is the last) to an ‘adjustment factor’ <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">y \in [0, 1]</annotation></semantics></math></span></span>. This factor determines <em>how much</em> of the maximum required uplift gets applied to the heading at position <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>.</p>
<p>We need this mapping function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = f(x)</annotation></semantics></math></span></span> to have specific properties:</p>
<ol>
<li>It must start at zero: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">f(0) = 0</annotation></semantics></math></span></span>.</li>
<li>It must end at one: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(1) = 1</annotation></semantics></math></span></span>.</li>
<li>The transition should start gently: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">f'(0) = 0</annotation></semantics></math></span></span>.</li>
<li>The transition should end gently: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">f'(1) = 0</annotation></semantics></math></span></span>.</li>
</ol>
<p>It turns out that we can borrow a function from the field of computer graphics to solve this problem. The <astro-island uid="cRbh4" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;yellow&quot;],&quot;id&quot;:[0,&quot;component-tile-uloerrhy2y&quot;],&quot;text&quot;:[0,&quot;smoothstep&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="ZzlAmW" component-url="/_astro/AdjustableSmoothstepGraph.DgNMoqNP.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;showControls&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;AdjustableSmoothstepGraph&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> function is a cubic polynomial that smoothly transitions from 0 to 1 over the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">x \in [0, 1]</annotation></semantics></math></span></span>.</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><msup><mi>x</mi><mn>2</mn></msup><mo>−</mo><mn>2</mn><msup><mi>x</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">S(x) = 3x^2 - 2x^3</annotation></semantics></math></span></span></span></p><p>This function provides a smooth transition over the entire range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">x \in [0, 1]</annotation></semantics></math></span></span>. But what if we don’t want the transition to start right away? What if we want the adjustment factor <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span> to remain 0 until <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> reaches a certain point, say <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span>, and <em>then</em> smoothly transition to 1 by the time <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> reaches 1?</p>
<p>We can achieve this by preprocessing our input <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> before feeding it into the smoothstep function. Let’s define an intermediate variable <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> that represents the progress <em>within</em> the transition phase, which occurs between <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">x=a</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x=1</annotation></semantics></math></span></span>. We want <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> to go from 0 to 1 as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> goes from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> to 1. The formula for this linear mapping is:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>t</mi><mrow><mi>r</mi><mi>a</mi><mi>w</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>a</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>a</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">t_{raw} = \frac{x - a}{1 - a}</annotation></semantics></math></span></span></span></p><p>Now, we need to handle the cases where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> is outside the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a, 1]</annotation></semantics></math></span></span> range.</p>
<ul>
<li>If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&lt;</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">x &lt; a</annotation></semantics></math></span></span>, then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>r</mi><mi>a</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{raw}</annotation></semantics></math></span></span> is negative. We want <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> to be 0 in this case.</li>
<li>If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x &gt; 1</annotation></semantics></math></span></span>, then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>r</mi><mi>a</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{raw}</annotation></semantics></math></span></span> is greater than 1. We want <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> to be 1 in this case. (Although <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> is defined on <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation></semantics></math></span></span>, clamping ensures robustness).</li>
</ul>
<p>We can achieve this clamping using <code>min</code> and <code>max</code> functions:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>t</mi><mo>=</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>t</mi><mrow><mi>r</mi><mi>a</mi><mi>w</mi></mrow></msub><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t = \min(\max(t_{raw}, 0), 1)</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>t</mi><mo>=</mo><mi>min</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>max</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>a</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>a</mi></mrow></mfrac><mo separator="true">,</mo><mn>0</mn><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">t = \min\left(\max\left(\frac{x - a}{1 - a}, 0\right), 1\right)</annotation></semantics></math></span></span></span></p><p>This <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> value now behaves exactly as we need: it’s 0 for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">x \le a</annotation></semantics></math></span></span>, linearly increases from 0 to 1 for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>≤</mo><mi>x</mi><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">a \le x \le 1</annotation></semantics></math></span></span>, and is 1 for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x \ge 1</annotation></semantics></math></span></span>.</p>
<p>Finally, we apply the smoothstep function to this clamped and scaled input <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> to get our final adjustment factor <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><msup><mi>t</mi><mn>2</mn></msup><mo>−</mo><mn>2</mn><msup><mi>t</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">y = S(t) = 3t^2 - 2t^3</annotation></semantics></math></span></span></span></p><p>This allows us to use a parameter <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> (where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>a</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \le a &lt; 1</annotation></semantics></math></span></span>) to <astro-island uid="ZNVeGG" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;yellow&quot;],&quot;id&quot;:[0,&quot;component-tile-rfy2ok36ng&quot;],&quot;text&quot;:[0,&quot;control&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="Z2j974W" component-url="/_astro/AdjustableSmoothstepGraph.DgNMoqNP.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;showControls&quot;:[0,true]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;AdjustableSmoothstepGraph&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> the normalized position where the smooth upward adjustment of headings begins. Setting <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a=0</annotation></semantics></math></span></span> gives the original smoothstep over the whole range, while setting <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">a=0.5</annotation></semantics></math></span></span>, for example, means headings in the first half of the page don’t move at all, and the adjustment smoothly ramps up only in the second half, effectively localizing the change.</p>
<p>Let’s pick <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0.4</mn></mrow><annotation encoding="application/x-tex">a=0.4</annotation></semantics></math></span></span> and see what this <astro-island uid="GBYBD" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;green&quot;],&quot;id&quot;:[0,&quot;component-tile-7unbsfy2wmp&quot;],&quot;text&quot;:[0,&quot;adjusted smoothstep&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="1h4dwz" component-url="/_astro/PageViewportVisualization.Cjt7_c79.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;version&quot;:[0,&quot;smoothstep&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;PageViewportVisualization&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island> does. (if you are curious about how I found the 0.4, that might become the topic for a part 2.. Which may or may not involve blind ELO ranking. For updates its easiest to follow me <a href="https://x.com/mats_zip">here</a>.)</p>
<p>It’s… <astro-island uid="Yf26M" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;red&quot;],&quot;id&quot;:[0,&quot;component-tile-a501vp8bcm&quot;],&quot;text&quot;:[0,&quot;beautiful&quot;],&quot;type&quot;:[0,&quot;component&quot;],&quot;forceAspectRatio&quot;:[0,false]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""><astro-island uid="1ag5dF" component-url="/_astro/AnchorProblem.GGiwfq1Z.js" component-export="default" renderer-url="/_astro/client.BBblIl08.js" props="{&quot;compensationMode&quot;:[0,&quot;smoothstep&quot;]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;AnchorProblem&quot;,&quot;value&quot;:&quot;vue&quot;}"></astro-island></template><!--astro:end--></astro-island>.</p>
<h2 id="validation">Validation</h2>
<p>So, we are finally done. We’ve gone to depths that no man has ever gone before to fix anchor links. A truly Carmack-esque feat that will be remembered for generations to come. Let’s ask the lead designer what <astro-island uid="Zzp0WK" component-url="/_astro/tile-creator.CDert_z5.js" component-export="default" renderer-url="/_astro/client.DwCUistV.js" props="{&quot;slot&quot;:[0,&quot;tile-slot&quot;],&quot;color&quot;:[0,&quot;blue&quot;],&quot;id&quot;:[0,&quot;image-tile-hx34jiqs4na&quot;],&quot;text&quot;:[0,&quot;he thinks&quot;],&quot;type&quot;:[0,&quot;image&quot;],&quot;forceAspectRatio&quot;:[0,true]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;TileCreator&quot;,&quot;value&quot;:&quot;react&quot;}" await-children=""><template data-astro-template=""> <div class="h-full w-full"> <img class="h-full w-full object-cover" src="/social-network.jpg" alt="visualization of he thinks"> </div> </template><!--astro:end--></astro-island>.</p>
<p>… Oh well, at least we got a blog post out of it.</p>
<p>Want overengineered anchor links for your project? Get in touch!</p>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OpenNutrition – A free, public nutrition database (282 pts)]]></title>
            <link>https://www.opennutrition.app/search</link>
            <guid>43569190</guid>
            <pubDate>Thu, 03 Apr 2025 13:19:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opennutrition.app/search">https://www.opennutrition.app/search</a>, See on <a href="https://news.ycombinator.com/item?id=43569190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><div><a href="https://www.opennutrition.app/"><h3>OpenNutrition</h3></a><a href="https://www.opennutrition.app/search"><h4>Foods</h4></a></div><div><p><a href="https://www.opennutrition.app/about"><span>About</span></a><a href="https://www.opennutrition.app/download"><span>Download</span></a></p></div></div></header><div><div><div><h2>Nutrition search, reimagined.</h2><p>Instant results. Open-source. AI-enhanced for accuracy.</p></div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg><div><p><span>Search for </span></p><p><span>a food<!-- -->...</span></p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hackers stole billions in crypto to keep North Korea’s regime afloat (116 pts)]]></title>
            <link>https://www.wsj.com/world/asia/north-korea-cryptocurrency-580d7d3f</link>
            <guid>43569009</guid>
            <pubDate>Thu, 03 Apr 2025 13:03:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/world/asia/north-korea-cryptocurrency-580d7d3f">https://www.wsj.com/world/asia/north-korea-cryptocurrency-580d7d3f</a>, See on <a href="https://news.ycombinator.com/item?id=43569009">Hacker News</a></p>
Couldn't get https://www.wsj.com/world/asia/north-korea-cryptocurrency-580d7d3f: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A university president makes a case against cowardice (254 pts)]]></title>
            <link>https://www.newyorker.com/news/q-and-a/a-university-president-makes-a-case-against-cowardice</link>
            <guid>43568655</guid>
            <pubDate>Thu, 03 Apr 2025 12:29:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/q-and-a/a-university-president-makes-a-case-against-cowardice">https://www.newyorker.com/news/q-and-a/a-university-president-makes-a-case-against-cowardice</a>, See on <a href="https://news.ycombinator.com/item?id=43568655">Hacker News</a></p>
Couldn't get https://www.newyorker.com/news/q-and-a/a-university-president-makes-a-case-against-cowardice: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[InitWare, a portable systemd fork running on BSDs and Linux (149 pts)]]></title>
            <link>https://github.com/InitWare/InitWare</link>
            <guid>43568503</guid>
            <pubDate>Thu, 03 Apr 2025 12:11:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/InitWare/InitWare">https://github.com/InitWare/InitWare</a>, See on <a href="https://news.ycombinator.com/item?id=43568503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/545b0895e66e3e2de9c8051f6e3840d10cf7d1daeabc9079f7d0de3d53c05d4d/687474703a2f2f6272616e642e696e6974776172652e636f6d2f6173736574732f706167652d6c6f676f2d62672e706e67"><img src="https://camo.githubusercontent.com/545b0895e66e3e2de9c8051f6e3840d10cf7d1daeabc9079f7d0de3d53c05d4d/687474703a2f2f6272616e642e696e6974776172652e636f6d2f6173736574732f706167652d6c6f676f2d62672e706e67" alt="InitWare" data-canonical-src="http://brand.initware.com/assets/page-logo-bg.png"></a></p>
<p dir="auto"><strong>Please note that InitWare is still alpha software</strong>. But all disclosed
security concerns have now been addressed. Running InitWare as an auxiliary
service manager under NetBSD can now, then, be regarded as safe; but beware
relying on this in production until a first stable release is made.</p>
<p dir="auto">The InitWare Suite of Middleware allows you to manage services and system
resources as logical entities called units. It runs on NetBSD, GNU/Linux, and
all the other modern BSD systems.</p>
<p dir="auto">Units are automatically scheduled by a job scheduler according to their
dependency specifications. A user session manager facilitates tracking of users'
login sessions, with each user provided their own dedicated service manager.
Finally the InitWare System Log provides a system-wide event log aggregating
diverse log sources.</p>
<p dir="auto">The Suite may run either as an init system or as an auxiliary service management
system under another init system. InitWare originates as a fork of systemd and
retains compatibility with many systemd interfaces, even on non-Linux platforms.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Build Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU/Linux (Alpine)</td>
<td><a href="https://builds.sr.ht/~netbsduser/initware/commits/alpine.yaml?" rel="nofollow"><img src="https://camo.githubusercontent.com/2bc3ac0854cd8adffb9d6ab2bd18d9e5858faabeb09d7b7ff40f01921d021730/68747470733a2f2f6275696c64732e73722e68742f7e6e6574627364757365722f696e6974776172652f636f6d6d6974732f616c70696e652e79616d6c2e737667" alt="builds.sr.ht status" data-canonical-src="https://builds.sr.ht/~netbsduser/initware/commits/alpine.yaml.svg"></a></td>
</tr>
<tr>
<td>FreeBSD</td>
<td><a href="https://builds.sr.ht/~netbsduser/initware/commits/freebsd.yaml?" rel="nofollow"><img src="https://camo.githubusercontent.com/9a9abaf4ac4bcc492142e7f6b603e621de9ea148bbac254831334106eedcd14c/68747470733a2f2f6275696c64732e73722e68742f7e6e6574627364757365722f696e6974776172652f636f6d6d6974732f667265656273642e79616d6c2e737667" alt="builds.sr.ht status" data-canonical-src="https://builds.sr.ht/~netbsduser/initware/commits/freebsd.yaml.svg"></a></td>
</tr>
<tr>
<td>NetBSD</td>
<td><a href="https://builds.sr.ht/~netbsduser/initware/commits/netbsd.yaml?" rel="nofollow"><img src="https://camo.githubusercontent.com/e89313bd3aa5bfdf307f3acac0bf9eac413a11606eefaba44554c72478861e70/68747470733a2f2f6275696c64732e73722e68742f7e6e6574627364757365722f696e6974776172652f636f6d6d6974732f6e65746273642e79616d6c2e737667" alt="builds.sr.ht status" data-canonical-src="https://builds.sr.ht/~netbsduser/initware/commits/netbsd.yaml.svg"></a></td>
</tr>
<tr>
<td>OpenBSD</td>
<td><a href="https://builds.sr.ht/~netbsduser/initware/commits/openbsd.yaml?" rel="nofollow"><img src="https://camo.githubusercontent.com/1cd5ddcf42755758c5bf70907173eac5bfc6ac900db4e9f0ba071c953b7fc50a/68747470733a2f2f6275696c64732e73722e68742f7e6e6574627364757365722f696e6974776172652f636f6d6d6974732f6f70656e6273642e79616d6c2e737667" alt="builds.sr.ht status" data-canonical-src="https://builds.sr.ht/~netbsduser/initware/commits/openbsd.yaml.svg"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Frequently Asked Questions</h2><a id="user-content-frequently-asked-questions" aria-label="Permalink: Frequently Asked Questions" href="#frequently-asked-questions"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How does InitWare differ from systemd?</h4><a id="user-content-how-does-initware-differ-from-systemd" aria-label="Permalink: How does InitWare differ from systemd?" href="#how-does-initware-differ-from-systemd"></a></p>
<p dir="auto">In three ways: InitWare is highly portable, it is more modular, and it is of a
much more clearly-defined scope. See <a href="https://github.com/InitWare/InitWare/wiki/The-InitWare-philosophy">The InitWare philosophy</a>.</p>
<p dir="auto">Some components of systemd failing to provide compelling benefits are dropped;
see <a href="https://github.com/InitWare/InitWare/wiki/Dropped-components">Dropped components</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How compatible is InitWare with systemd?</h4><a id="user-content-how-compatible-is-initware-with-systemd" aria-label="Permalink: How compatible is InitWare with systemd?" href="#how-compatible-is-initware-with-systemd"></a></p>
<p dir="auto">Unit-files, the <code>systemctl</code>, <code>loginctl</code>, and <code>journalctl</code> commands (provided as
<code>svcctl</code>, <code>sessionctl</code>, and <code>syslogctl</code> respectively), the systemd1 and Login1
D-Bus APIs, the sd_notify API, the journald stream and datagram socket
protocols, and several other interfaces are largely supported on all ports.
Some details differ by port. See <a href="https://github.com/InitWare/InitWare/wiki/Systemd-compatibility">Systemd compatibility</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">On what platforms does InitWare run?</h4><a id="user-content-on-what-platforms-does-initware-run" aria-label="Permalink: On what platforms does InitWare run?" href="#on-what-platforms-does-initware-run"></a></p>
<p dir="auto">InitWare is native to NetBSD. It runs on NetBSD, FreeBSD, and GNU/Linux - its
first-class targets - as an init system; on macOS, DragonFly BSD and OpenBSD, it
runs as an auxiliary service manager. See
<a href="https://github.com/InitWare/InitWare/wiki/Support-Matrix">Support matrix</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Under what licence is InitWare released?</h4><a id="user-content-under-what-licence-is-initware-released" aria-label="Permalink: Under what licence is InitWare released?" href="#under-what-licence-is-initware-released"></a></p>
<p dir="auto">Most code is under the GNU Library GPL v2.1, some of it is under liberal licences.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How does one build InitWare?</h4><a id="user-content-how-does-one-build-initware" aria-label="Permalink: How does one build InitWare?" href="#how-does-one-build-initware"></a></p>
<p dir="auto">Install the dependencies first: these are a C toolchain, cmake, gperf, m4, awk,
pkg-config or pkgconf, and on BSD platforms, libinotify. Then run:</p>
<p dir="auto"><code>git submodule update --init --recursive &amp;&amp; cmake &amp;&amp; make &amp;&amp; make install</code></p>
<p dir="auto">See <a href="https://github.com/InitWare/InitWare/wiki/Building">Building</a> for further details.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Where will InitWare go from here?</h4><a id="user-content-where-will-initware-go-from-here" aria-label="Permalink: Where will InitWare go from here?" href="#where-will-initware-go-from-here"></a></p>
<p dir="auto">Check the Issues and Projects tabs, or the
<a href="https://github.com/InitWare/InitWare/wiki/Roadmap">Roadmap</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How can I contribute?</h4><a id="user-content-how-can-i-contribute" aria-label="Permalink: How can I contribute?" href="#how-can-i-contribute"></a></p>
<p dir="auto">See <a href="https://github.com/InitWare/InitWare/wiki/Contributing">Contributing</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Where can I find out more?</h4><a id="user-content-where-can-i-find-out-more" aria-label="Permalink: Where can I find out more?" href="#where-can-i-find-out-more"></a></p>
<p dir="auto">Check <a href="https://github.com/InitWare/InitWare/wiki">the Wiki</a>. The <a href="https://github.com/InitWare/InitWare/wiki/Myths-and-Truths">Myths and Truths</a> page is a good place to start.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Steam Deck Is Software-Freedom Friendly (279 pts)]]></title>
            <link>https://isomorphism.xyz/blog/2024/steam-deck/</link>
            <guid>43567923</guid>
            <pubDate>Thu, 03 Apr 2025 11:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://isomorphism.xyz/blog/2024/steam-deck/">https://isomorphism.xyz/blog/2024/steam-deck/</a>, See on <a href="https://news.ycombinator.com/item?id=43567923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  

  <article>
    <p>The <a href="https://store.steampowered.com/steamdeck" target="_blank" rel="noopener noreferrer">Steam Deck</a> is a great gaming system. This isn’t because of it’s great battery life. A Nintendo Switch would probably have better battery life. It’s not because of its great performance. I don’t usually play AAA games, so I wouldn’t know. The Steam Deck is great because of the philosophy on which it is built.</p>

<p>The popularity of Steam Decks is directly tied to the betterment of support for games on Linux. This is because the Steam Deck really is a linux computer in a handheld form-factor with a gamepad, among other things, attached to it. According to <a href="https://www.protondb.com/" target="_blank" rel="noopener noreferrer">ProtonDB</a>, over 5000 PC games are certified Verified on the Steam Deck, and over 15,000 games are considered playable. This means that there are tens of thousands of games that can be run on Linux in some way.</p>

<p>Thanks to Steam’s efforts, the state of compatibility of games on Linux systems have heavily improved. Not all these thousands of games running on the Deck have binaries that run natively on Linux. Pivotal to the success of the Deck is Proton, a middle-layer compatibility software, that makes this (mostly) seamless emulation possible. Nonetheless, the greater the adoption of Decks, the likelier we are to normalize prioritizing game-builds for Linux.</p>

<p>We run software because it serves us some purpose. In this, running software is no different from utilizing everyday objects, and playing games are no different from running software. Yet, this teleological view of computing would miss a lot of context. When picking an operating system, we may want to make a choice that aligns with the goals of transparency or software freedom. But this would not be realistic if the programs we would like to run on top are not supported in such an ecosystem. Since large parts of Proton is open-source, and are released under permissive licenses, gaming on a Deck takes us closer to using a principled software stack for daily use.</p>

<p>Purchasing everyday objects give us ownership over them. With media, software and computing equipment, this is less so. When you buy a book, you may lend it to others, sell it, earmark the pages and even rip it in two if you like. This is very different from the experience of buying a smartphone. You can’t run arbitrary programs of your choice on an Android phone without rooting, or on an iPad or an iPhone without jailbreaking. In most scenarios, you’d be forced to sign away your legal ability to root or jailbreak before you can engage with the device in any meaningful way.</p>

<p>The Steam Deck does not engage in this practice. It runs a heavily customized version of Arch Linux. This means that you can plug in a keyboard and mouse into it, and pretend that it is your desktop computer. If you like, you can install the LibreOffice suite on it, and prepare presentations.</p>

<p>The matter of using your computers the way you like is more than just a symbolic debate about the nature of ownership. It is a political matter of freedom of expression. When they control the apps that you run on your device, they are in charge of deciding which content is Kosher, and which content is obscene. It is also an economic matter of having efficient markets. The mythological power of the free market works only when the consumers can switch between different producers at will. When the operators of the market themselves try to capitalize on chokepoints and direct the consumers to buy products from their allies, this is no longer the case.</p>

<p>Switch owners buy games from the Switch Store not because that is the best market, but because that is the only marketplace from which they can install games. This is thankfully, less of a case with the Steam Deck. The Steam Deck encourages you to buy and play Steam games, of course. Nonetheless, I had <a href="https://github.com/moraroy/NonSteamLaunchers-On-Steam-Deck" target="_blank" rel="noopener noreferrer">no issues</a> installing <a href="https://store.epicgames.com/en-US/" target="_blank" rel="noopener noreferrer">Epic Games</a>, <a href="https://www.gog.com/en" target="_blank" rel="noopener noreferrer">GoG</a> or even <a href="https://itch.io/" target="_blank" rel="noopener noreferrer">itch.io</a> launchers on my Deck and playing games from them. The Deck also includes a “non-steam game” tab in its UI to let users conveniently access them.</p>

<p>When your shoe tears up, you are welcome to visit the cobbler of your choice. They all understand the internals of a shoe. And when they need to fix them, they all can gather the nails, glue and the pieces of fabric that they might need. This is less so for many computing products. Many manufacturers try to discourage third party vendors from repairing them. Worse, they sometimes purposely use proprietary parts in their products, replacements of which would be hard to find. Thankfully, Valve has been different. Valve has released <a href="https://store.steampowered.com/news/app/1675180/view/3011210954776539264" target="_blank" rel="noopener noreferrer">a video</a> explaining the internal organization of the Steam Deck and how one should approach replacing parts, should they wish to do so.</p>

<p>This post is not really necessarily about the Steam Deck (or Valve Corporation) itself. That said, the Steam Deck is an excellent demonstration that the commercial interest of making profit does not necessarily have to overpower the civic interests of the people.</p>

<hr>

<p>Valve’s libertarian ideology has not always been an unquestionable force for good. <a href="https://www.youtube.com/watch?v=s9aCwCKgkLo" target="_blank" rel="noopener noreferrer">Some</a> <a href="https://www.youtube.com/watch?v=eMmNy11Mn7g" target="_blank" rel="noopener noreferrer">people</a> have criticized that their company culture of libertarianism sometimes takes precedence over other important values including equity and inclusion. During the peak of the ‘Black Lives Matter’ movement, Valve was pressured to make a statement. Valve responded by giving each of their employees an amount of money which they were free to donate to a charity of their choice. This was regarded as a non-statement by many since there may have been employees who have donated their shares to an organizations with interests opposing the cause.</p>

<p>Valve has also generally refused to take a stance against gambling websites which plug into their ecosystem, despite the allegation that this harms many users (including minors). This maybe a consequence of their libertarian philosophy, but the worse possibility is that they are disinterested in tuning down a part of their system that <a href="https://www.youtube.com/watch?v=eMmNy11Mn7g" target="_blank" rel="noopener noreferrer">profits themselves</a>.</p>

<p>A very large share of the PC gaming market is Steam, which is a fact I do not admire. They do take a 30% cut on the sales of Steam games, which can arguably be considered <a href="https://en.wikipedia.org/wiki/Rent-seeking" target="_blank" rel="noopener noreferrer">rent seeking</a>, even if it is the industry standard. I do hope the marketplace of game distribution sees more healthy competition. Nonetheless, I appreciate Valve for not pursuing aggressively anti-competitive tactics.</p>

  </article>
    
    

</div></div>]]></description>
        </item>
    </channel>
</rss>