<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 11 Jun 2024 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Lynn Conway Has Died (754 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Lynn_Conway</link>
            <guid>40648470</guid>
            <pubDate>Tue, 11 Jun 2024 16:44:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Lynn_Conway">https://en.wikipedia.org/wiki/Lynn_Conway</a>, See on <a href="https://news.ycombinator.com/item?id=40648470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<table><tbody><tr><th colspan="2"><p>Lynn Conway</p></th></tr><tr><td colspan="2"><span typeof="mw:File/Frameless"><a href="https://en.wikipedia.org/wiki/File:Lynn_Conway_July_2006.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/220px-Lynn_Conway_July_2006.jpg" decoding="async" width="220" height="293" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/330px-Lynn_Conway_July_2006.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/440px-Lynn_Conway_July_2006.jpg 2x" data-file-width="751" data-file-height="1000"></a></span><p>Conway in 2006</p></td></tr><tr><th scope="row">Born</th><td>January 2, 1938<br><div><p><a href="https://en.wikipedia.org/wiki/Mount_Vernon,_New_York" title="Mount Vernon, New York">Mount Vernon, New York</a>, U.S.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></p></div></td></tr><tr><th scope="row">Died</th><td>June 9, 2024 (aged&nbsp;86)<p>Jackson, Michigan, U.S.</p></td></tr><tr><th scope="row">Alma&nbsp;mater</th><td><a href="https://en.wikipedia.org/wiki/Columbia_University" title="Columbia University">Columbia University</a></td></tr><tr><th scope="row">Known&nbsp;for</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Mead%E2%80%93Conway_VLSI_chip_design_revolution" title="Mead–Conway VLSI chip design revolution">Mead–Conway VLSI chip design revolution</a></li><li><a href="https://en.wikipedia.org/wiki/Transgender_activism" title="Transgender activism">transgender activism</a></li></ul></div></td></tr><tr><th scope="row">Spouse</th><td>
<div><p>Charles Rogers</p> <p>​</p><p>(<abbr title="married">m.</abbr>&nbsp;)<wbr>​</p></div></td></tr><tr><th scope="row">Awards</th><td><div>
<ul><li><a href="https://en.wikipedia.org/wiki/Harold_Pender_Award" title="Harold Pender Award">Harold Pender Award</a> (1984)</li>
<li><a href="https://en.wikipedia.org/wiki/John_Price_Wetherill_Medal" title="John Price Wetherill Medal">John Price Wetherill Medal</a> (1985)</li>
<li><a href="https://en.wikipedia.org/wiki/Secretary_of_Defense_Meritorious_Civilian_Service_Award" title="Secretary of Defense Meritorious Civilian Service Award">Secretary of Defense Meritorious Civilian Service Award</a> (1985)</li>
<li><a href="https://en.wikipedia.org/wiki/National_Academy_of_Engineering" title="National Academy of Engineering">National Academy of Engineering</a> (1989)</li>
<li><a href="https://en.wikipedia.org/wiki/Computer_Pioneer_Award" title="Computer Pioneer Award">Computer Pioneer Award</a> (2009)</li>
<li><a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a> Fellow (2014)<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/IEEE/RSE_James_Clerk_Maxwell_Medal" title="IEEE/RSE James Clerk Maxwell Medal">IEEE/RSE James Clerk Maxwell Medal</a> (2015)</li>
<li><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a> (2023)</li></ul>
</div></td></tr><tr><td colspan="2"><b>Scientific career</b></td></tr><tr><th scope="row">Fields</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Computer_science" title="Computer science">Computer science</a></li><li><a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">Electrical engineering</a></li></ul></div></td></tr><tr><th scope="row">Institutions</th><td><a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> Advanced Computing Systems (1964–68), <a href="https://en.wikipedia.org/wiki/Memorex" title="Memorex">Memorex</a>, <a href="https://en.wikipedia.org/wiki/Xerox_PARC" title="Xerox PARC">Xerox PARC</a> (1970s), <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a>, <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a></td></tr></tbody></table>
<p><b>Lynn Ann Conway</b> (January 2, 1938 - June 9, 2024<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>)<sup id="cite_ref-Lee1995_4-0"><a href="#cite_note-Lee1995-4">[4]</a></sup><sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> was an American <a href="https://en.wikipedia.org/wiki/Computer_scientist" title="Computer scientist">computer scientist</a>, <a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">electrical engineer</a> and <a href="https://en.wikipedia.org/wiki/Transgender_activist" title="Transgender activist">transgender activist</a>.<sup id="cite_ref-Time21Culture_6-0"><a href="#cite_note-Time21Culture-6">[6]</a></sup>
</p><p>She worked at <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> in the 1960s and invented generalized dynamic instruction handling, a key advance used in <a href="https://en.wikipedia.org/wiki/Out-of-order_execution" title="Out-of-order execution">out-of-order execution</a>, used by most modern computer processors to improve performance. She initiated the <a href="https://en.wikipedia.org/wiki/Mead%E2%80%93Conway_VLSI_chip_design_revolution" title="Mead–Conway VLSI chip design revolution">Mead–Conway VLSI chip design revolution</a> in very large scale integrated (<a href="https://en.wikipedia.org/wiki/VLSI" title="VLSI">VLSI</a>) microchip design. That revolution spread rapidly through the <a href="https://en.wikipedia.org/wiki/Research_universities" title="Research universities">research universities</a> and computing industries during the 1980s, incubating an emerging <a href="https://en.wikipedia.org/wiki/Electronic_design_automation" title="Electronic design automation">electronic design automation</a> industry, spawning the modern 'foundry' infrastructure for chip design and production, and triggering a rush of impactful high-tech startups in the 1980s and 1990s.<sup id="cite_ref-smoth01_7-0"><a href="#cite_note-smoth01-7">[7]</a></sup><sup id="cite_ref-comsocpioneeraward_8-0"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-comsocpioneersawardvideo_9-0"><a href="#cite_note-comsocpioneersawardvideo-9">[9]</a></sup><sup id="cite_ref-superproj60b_10-0"><a href="#cite_note-superproj60b-10">[10]</a></sup><sup id="cite_ref-IBMsmotherman_11-0"><a href="#cite_note-IBMsmotherman-11">[11]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Early_life_and_education">Early life and education</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=1" title="Edit section: Early life and education"><span>edit</span></a><span>]</span></span></h2>
<p>Conway grew up in <a href="https://en.wikipedia.org/wiki/White_Plains,_New_York" title="White Plains, New York">White Plains, New York</a>. Conway was shy and experienced <a href="https://en.wikipedia.org/wiki/Gender_dysphoria" title="Gender dysphoria">gender dysphoria</a> as a child. She became fascinated by <a href="https://en.wikipedia.org/wiki/Astronomy" title="Astronomy">astronomy</a> (building a 6-inch (150&nbsp;mm) <a href="https://en.wikipedia.org/wiki/Reflecting_telescope" title="Reflecting telescope">reflector telescope</a> one summer) and did well in math and science in high school. Conway entered <a href="https://en.wikipedia.org/wiki/MIT" title="MIT">MIT</a> in 1955, earning high grades but ultimately leaving in despair after an attempted <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>, from male to female in 1957–58, failed due to the medical climate at the time.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2022)">citation needed</span></a></i>]</sup> After working as an electronics technician for several years, Conway resumed education at <a href="https://en.wikipedia.org/wiki/Columbia_University" title="Columbia University">Columbia University</a>'s <a href="https://en.wikipedia.org/wiki/Fu_Foundation_School_of_Engineering_and_Applied_Science" title="Fu Foundation School of Engineering and Applied Science">School of Engineering and Applied Science</a>, earning B.S. and M.S.E.E. degrees in 1962 and 1963.<sup id="cite_ref-conI_12-0"><a href="#cite_note-conI-12">[12]</a></sup><sup id="cite_ref-kilbane_13-0"><a href="#cite_note-kilbane-13">[13]</a></sup>
</p>
<h2><span id="Early_research_at_IBM">Early research at IBM</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=2" title="Edit section: Early research at IBM"><span>edit</span></a><span>]</span></span></h2>
<p>Conway was recruited by <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> Research in <a href="https://en.wikipedia.org/wiki/Yorktown_Heights,_New_York" title="Yorktown Heights, New York">Yorktown Heights, New York</a> in 1964, and was soon selected to join the <a href="https://en.wikipedia.org/wiki/Computer_architecture" title="Computer architecture">architecture</a> team designing an advanced <a href="https://en.wikipedia.org/wiki/Supercomputer" title="Supercomputer">supercomputer</a>, working alongside <a href="https://en.wikipedia.org/wiki/John_Cocke_(computer_scientist)" title="John Cocke (computer scientist)">John Cocke</a>, <a href="https://en.wikipedia.org/wiki/Brian_Randell" title="Brian Randell">Brian Randell</a>, Herbert Schorr, <a href="https://en.wikipedia.org/wiki/Ed_Sussenguth" title="Ed Sussenguth">Ed Sussenguth</a>, <a href="https://en.wikipedia.org/wiki/Fran_Allen" title="Fran Allen">Fran Allen</a> and other IBM researchers on the <a href="https://en.wikipedia.org/wiki/ACS-1" title="ACS-1">Advanced Computing Systems</a> (ACS) project, inventing multiple-issue out-of-order dynamic instruction scheduling while working there.<sup id="cite_ref-smoth01_7-1"><a href="#cite_note-smoth01-7">[7]</a></sup><sup id="cite_ref-comsocpioneeraward_8-1"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-comsocpioneersawardvideo_9-1"><a href="#cite_note-comsocpioneersawardvideo-9">[9]</a></sup><sup id="cite_ref-sciam00_14-0"><a href="#cite_note-sciam00-14">[14]</a></sup><sup id="cite_ref-ABCnews01_15-0"><a href="#cite_note-ABCnews01-15">[15]</a></sup> The Computer History Museum has stated that "the ACS machines appears to have been the first <a href="https://en.wikipedia.org/wiki/Superscalar" title="Superscalar">superscalar</a> design, a computer architectural paradigm widely exploited in modern high-performance microprocessors."<sup id="cite_ref-superproj60b_10-1"><a href="#cite_note-superproj60b-10">[10]</a></sup><sup id="cite_ref-IBMsmotherman_11-1"><a href="#cite_note-IBMsmotherman-11">[11]</a></sup><sup id="cite_ref-chm_ibm_acs_reunion_16-0"><a href="#cite_note-chm_ibm_acs_reunion-16">[16]</a></sup><sup id="cite_ref-chm_ibm_acs_video_17-0"><a href="#cite_note-chm_ibm_acs_video-17">[17]</a></sup>
</p>
<h2><span id="Gender_transition">Gender transition</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=3" title="Edit section: Gender transition"><span>edit</span></a><span>]</span></span></h2>
<p>After learning of the pioneering research of <a href="https://en.wikipedia.org/wiki/Harry_Benjamin" title="Harry Benjamin">Harry Benjamin</a> in healthcare for <a href="https://en.wikipedia.org/wiki/Transsexual" title="Transsexual">transsexual</a> women<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> and realising that gender affirmation surgery was now possible, Conway sought his help and became his patient. After suffering from severe <a href="https://en.wikipedia.org/wiki/Clinical_depression" title="Clinical depression">depression</a> from <a href="https://en.wikipedia.org/wiki/Gender_dysphoria" title="Gender dysphoria">gender dysphoria</a>, Conway contacted Benjamin, who agreed to provide counseling and prescribe <a href="https://en.wikipedia.org/wiki/Hormone_replacement_therapy_(male-to-female)" title="Hormone replacement therapy (male-to-female)">hormones</a>. Under Benjamin's care, Conway began her medical <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>.<sup id="cite_ref-hiltzik_19-0"><a href="#cite_note-hiltzik-19">[19]</a></sup>
</p><p>While struggling with life in a male role,<sup id="cite_ref-hiltzik_19-1"><a href="#cite_note-hiltzik-19">[19]</a></sup> Conway had been married to a woman and had two children. Under the legal constraints then in place, she was denied access to their children after transitioning.<sup id="cite_ref-hiltzik_19-2"><a href="#cite_note-hiltzik-19">[19]</a></sup>
</p><p>Although she had hoped to be allowed to transition on the job, IBM fired Conway in 1968 after she revealed her intention to transition.<sup id="cite_ref-Conway2012_20-0"><a href="#cite_note-Conway2012-20">[20]</a></sup> IBM apologized for this in 2020.<sup id="cite_ref-:1_21-0"><a href="#cite_note-:1-21">[21]</a></sup>
</p>
<h2><span id="Career_as_computer_scientist">Career as computer scientist</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=4" title="Edit section: Career as computer scientist"><span>edit</span></a><span>]</span></span></h2>
<p>Upon completing her <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">transition</a> in 1968, Conway took a new name and identity, and restarted her career in what she called "<a href="https://en.wikipedia.org/wiki/Passing_(gender)#Stealth" title="Passing (gender)">stealth-mode</a>" as a contract programmer at <a href="https://en.wikipedia.org/wiki/Computer_Applications,_Inc." title="Computer Applications, Inc.">Computer Applications, Inc.</a> She went on to work at <a href="https://en.wikipedia.org/wiki/Memorex" title="Memorex">Memorex</a> during 1969–1972 as a digital system designer and computer architect.<sup id="cite_ref-hiltzik_19-3"><a href="#cite_note-hiltzik-19">[19]</a></sup><sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup>
</p><p>Conway joined <a href="https://en.wikipedia.org/wiki/Xerox_PARC" title="Xerox PARC">Xerox PARC</a> in 1973, where she led the "<a href="https://en.wikipedia.org/wiki/Large_Scale_Integration" title="Large Scale Integration">LSI</a> Systems" group under <a href="https://en.wikipedia.org/wiki/Bert_Sutherland" title="Bert Sutherland">Bert Sutherland</a>.<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup><sup id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> When in PARC, Conway founded the "multiproject wafers" (MPW). This new technology made it possible to pack multiple circuit designs from various sources into one single silicon wafer. Her new invention increased production and decreased costs.<sup id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup> Collaborating with <a href="https://en.wikipedia.org/wiki/Ivan_Sutherland" title="Ivan Sutherland">Ivan Sutherland</a> and <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a> of <a href="https://en.wikipedia.org/wiki/Caltech" title="Caltech">Caltech</a> on VLSI <a href="https://en.wikipedia.org/wiki/Design_methodology" title="Design methodology">design methodology</a>, she co-authored <i>Introduction to VLSI Systems</i>, a groundbreaking work that would soon become a standard textbook in chip design, used in nearly 120 universities by 1983.<sup id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup><sup id="cite_ref-auto_27-0"><a href="#cite_note-auto-27">[27]</a></sup><sup id="cite_ref-sciam002_28-0"><a href="#cite_note-sciam002-28">[28]</a></sup><sup id="cite_ref-compworld002_29-0"><a href="#cite_note-compworld002-29">[29]</a></sup> With over 70,000 copies sold, and the new integration of her MPC79/MOSIS innovations, the Mead and Conway revolution became part of VLSI design.<sup id="cite_ref-auto_27-1"><a href="#cite_note-auto-27">[27]</a></sup><sup id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup>
</p><p>In 1978, Conway served as visiting associate professor of electrical engineering and computer science at <a href="https://en.wikipedia.org/wiki/MIT" title="MIT">MIT</a>, teaching a now famous VLSI design course based on a draft of the Mead–Conway text.<sup id="cite_ref-hiltzik_19-4"><a href="#cite_note-hiltzik-19">[19]</a></sup> The course validated the new design methods and textbook, and established the syllabus and instructor's guidebook used in later courses worldwide.<sup id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup><sup id="cite_ref-penfield_32-0"><a href="#cite_note-penfield-32">[32]</a></sup>
</p><p>Among Conway's contributions were the invention of dimensionless, scalable <a href="https://en.wikipedia.org/wiki/Design_rule_checking" title="Design rule checking">design rules</a> that greatly simplified chip design and design tools,<sup id="cite_ref-comsocpioneeraward_8-2"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-kilbane_13-1"><a href="#cite_note-kilbane-13">[13]</a></sup><sup id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup> and invention of a new form of internet-based infrastructure for <a href="https://en.wikipedia.org/wiki/Rapid_prototyping" title="Rapid prototyping">rapid prototyping</a> and short-run fabrication of large numbers of chip designs.<sup id="cite_ref-comsocpioneeraward_8-3"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-NRC1999_34-0"><a href="#cite_note-NRC1999-34">[34]</a></sup> The problem they were solving was how to cope with the increasing complexity of chip design while the number of transistors per chip doubled every two years as <a href="https://en.wikipedia.org/wiki/Gordon_Moore" title="Gordon Moore">Gordon Moore</a>&nbsp;(chairman of Intel) had predicted in 1965. The design methods in use in the semiconductor industry were rapidly running out of steam.<sup id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup> The new infrastructure was institutionalized as the <a href="https://en.wikipedia.org/wiki/MOSIS" title="MOSIS">Metal Oxide Semiconductor Implementation Service (MOSIS)</a> system in 1981. Two years into its success, Mead and Conway received <i><a href="https://en.wikipedia.org/wiki/Electronics_(magazine)" title="Electronics (magazine)">Electronics</a></i> magazine's annual award of achievement.<sup id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup> Since then, MOSIS has fabricated more than 50,000 circuit designs for commercial firms, government agencies, and research and educational institutions around the world.<sup id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup> VLSI researcher Charles Seitz commented that "MOSIS represented the first period since the pioneering work of Eckert and Mauchley on the <a href="https://en.wikipedia.org/wiki/ENIAC" title="ENIAC">ENIAC</a> in the late 1940s that universities and small companies had access to state-of-the-art digital technology."<sup id="cite_ref-NRC1999_34-1"><a href="#cite_note-NRC1999-34">[34]</a></sup>
</p><p>The research methods used to develop the Mead–Conway <a href="https://en.wikipedia.org/wiki/VLSI" title="VLSI">VLSI</a> design methodology and the <a href="https://en.wikipedia.org/wiki/MOSIS" title="MOSIS">MOSIS</a> prototype are documented in a 1981 Xerox report<sup id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup> and the Euromicro Journal.<sup id="cite_ref-MPCAdv_39-0"><a href="#cite_note-MPCAdv-39">[39]</a></sup> The impact of the Mead–Conway work is described in a number of historical overviews of computing.<sup id="cite_ref-NRC1999_34-2"><a href="#cite_note-NRC1999-34">[34]</a></sup><sup id="cite_ref-sandtfedfund_40-0"><a href="#cite_note-sandtfedfund-40">[40]</a></sup><sup id="cite_ref-sandtfedfundfigureII13_41-0"><a href="#cite_note-sandtfedfundfigureII13-41">[41]</a></sup><sup id="cite_ref-evolvinghpc_42-0"><a href="#cite_note-evolvinghpc-42">[42]</a></sup><sup id="cite_ref-evolvinghpcfig1point2_43-0"><a href="#cite_note-evolvinghpcfig1point2-43">[43]</a></sup><sup id="cite_ref-44"><a href="#cite_note-44">[44]</a></sup> Conway and her colleagues have compiled an online archive of original papers that documents much of that work.<sup id="cite_ref-VLSIArchive_45-0"><a href="#cite_note-VLSIArchive-45">[45]</a></sup><sup id="cite_ref-46"><a href="#cite_note-46">[46]</a></sup> The methods also came under ethnographic study in 1980 by PARC anthropologist <a href="https://en.wikipedia.org/wiki/Lucy_Suchman" title="Lucy Suchman">Lucy Suchman</a>, who published her interviews with Conway in 2021.<sup id="cite_ref-47"><a href="#cite_note-47">[47]</a></sup><sup id="cite_ref-48"><a href="#cite_note-48">[48]</a></sup>
</p><p>In the early 1980s, Conway left Xerox to join <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a>, where she was a key architect of the <a href="https://en.wikipedia.org/wiki/United_States_Department_of_Defense" title="United States Department of Defense">Defense Department</a>'s <a href="https://en.wikipedia.org/wiki/Strategic_Computing_Initiative" title="Strategic Computing Initiative">Strategic Computing Initiative</a>, a research program studying high-performance computing, <a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)" title="Autonomous system (Internet)">autonomous systems</a> technology, and intelligent weapons technology.<sup id="cite_ref-kilbane_13-2"><a href="#cite_note-kilbane-13">[13]</a></sup><sup id="cite_ref-davis_49-0"><a href="#cite_note-davis-49">[49]</a></sup>
</p><p>In a <i><a href="https://en.wikipedia.org/wiki/USA_Today" title="USA Today">USA Today</a></i> article about Conway's joining DARPA, Mark Stefik, a Xerox scientist who worked with her, said "Lynn would like to live five lives in the course of one life" and that she's "charismatic and very energetic".<sup id="cite_ref-Osborn_50-0"><a href="#cite_note-Osborn-50">[50]</a></sup> Douglas Fairbairn, a former Xerox associate, said "She figures out a way so that everybody wins."<sup id="cite_ref-Osborn_50-1"><a href="#cite_note-Osborn-50">[50]</a></sup>
</p><p>Conway joined the <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a> in 1985 as professor of <a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">electrical engineering</a> and <a href="https://en.wikipedia.org/wiki/Computer_science" title="Computer science">computer science</a>, and associate dean of engineering. There she worked on "visual communications and control probing for basic system and user-interface concepts as applicable to hybridized internet/broadband-cable communications".<sup id="cite_ref-kilbane_13-3"><a href="#cite_note-kilbane-13">[13]</a></sup> She retired from active teaching and research in 1998, as <a href="https://en.wikipedia.org/wiki/Professor_emeritus#Other_designations" title="Professor emeritus">professor emerita</a> at Michigan.<sup id="cite_ref-emerita_51-0"><a href="#cite_note-emerita-51">[51]</a></sup>
</p>
<h2><span id="Legacy">Legacy</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=5" title="Edit section: Legacy"><span>edit</span></a><span>]</span></span></h2>
<p>As sociologist Thomas Streeter discusses in The Net Effect:<sup id="cite_ref-Streeter2013_52-0"><a href="#cite_note-Streeter2013-52">[52]</a></sup><sup id="cite_ref-Neff2013_53-0"><a href="#cite_note-Neff2013-53">[53]</a></sup> "By taking this job, Conway was demonstrating that she was no antiwar liberal. (In response to critics, she has said, 'if you have to fight, and sometimes you must in order to deal with bad people, history tells us that it really helps to have the best weapons available)".<sup id="cite_ref-conI_12-1"><a href="#cite_note-conI-12">[12]</a></sup> But Conway carried a sense of computers as tools for horizontal communications that she had absorbed at PARC right into <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a> – at one of the hottest moments of the cold war."
</p><p>In the fall of 2012, the <a href="https://en.wikipedia.org/wiki/IEEE" title="IEEE">IEEE</a> published a special issue of the <i><a href="https://en.wikipedia.org/w/index.php?title=IEEE_Solid-State_Circuits_Magazine&amp;action=edit&amp;redlink=1" title="IEEE Solid-State Circuits Magazine (page does not exist)">IEEE Solid-State Circuits Magazine</a></i> devoted to Lynn Conway's career,<sup id="cite_ref-Lanzerotti2012_54-0"><a href="#cite_note-Lanzerotti2012-54">[54]</a></sup><sup id="cite_ref-eecsnews2013_55-0"><a href="#cite_note-eecsnews2013-55">[55]</a></sup> including a career memoir by Conway<sup id="cite_ref-Conway2012_20-1"><a href="#cite_note-Conway2012-20">[20]</a></sup> and peer commentaries by Chuck House,<sup id="cite_ref-House2012_56-0"><a href="#cite_note-House2012-56">[56]</a></sup> former Director of Engineering at HP, <a href="https://en.wikipedia.org/wiki/S%C3%A9quin" title="Séquin">Carlo Séquin</a>, Professor of EECS at U.C. Berkeley,<sup id="cite_ref-Sequin2012_57-0"><a href="#cite_note-Sequin2012-57">[57]</a></sup> and <a href="https://en.wikipedia.org/wiki/Kenneth_L_Shepard" title="Kenneth L Shepard">Ken Shepard</a>, of Columbia University.<sup id="cite_ref-Shepard2012_58-0"><a href="#cite_note-Shepard2012-58">[58]</a></sup> Subsequently the scope of Conway's contributions gained wider retrospective attention. "Since I didn't <a href="https://en.wikipedia.org/wiki/I_Look_Like_an_Engineer" title="I Look Like an Engineer">#LookLikeanEngineer</a>, few people caught on to what I was really doing back in the 70s and 80s," says Conway.<sup id="cite_ref-:1_21-1"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>"Clearly a new paradigm had emerged ... Importantly, imaginative support in terms of infrastructure and idea dissemination proved as valuable as the concepts, tools, and chips. The "electronic book" and the "foundry" were both prescient and necessary, providing momentum and proof-points."<sup id="cite_ref-House2012_56-1"><a href="#cite_note-House2012-56">[56]</a></sup> <a href="https://en.wikipedia.org/wiki/James_F._Gibbons" title="James F. Gibbons">James F. "Jim" Gibbons</a>, former dean of engineering at Stanford University, further states that Lynn Conway, from his perspective, "...was the singular force behind the entire '<a href="https://en.wikipedia.org/wiki/Foundry_model" title="Foundry model">foundry</a>' development that emerged."<sup id="cite_ref-House2012_56-2"><a href="#cite_note-House2012-56">[56]</a></sup> <a href="https://en.wikipedia.org/wiki/Kenneth_L_Shepard" title="Kenneth L Shepard">Kenneth Shepard</a>, Professor of Biomedical and Electrical Engineering at Columbia University, stated that "Lynn's amazing story of accomplishment and personal triumph in the face of personal adversity and overt discrimination should serve as an inspiration to all young engineers."<sup id="cite_ref-Shepard2012_58-1"><a href="#cite_note-Shepard2012-58">[58]</a></sup><sup id="cite_ref-59"><a href="#cite_note-59">[59]</a></sup>
</p><p>In 2020, NAE President <a href="https://en.wikipedia.org/wiki/John_L._Anderson" title="John L. Anderson">John L. Anderson</a> stated that "Lynn Conway is not only a revolutionary pioneer in the design of VLSI systems ... But just as important, Lynn has been very brave in telling her own story, and her perseverance has been a reminder to society that it should not be blind to the innovations of women, people of color, or others who don't fit long outdated – but unfortunately, persistent – perceptions of what an engineer looks like."<sup id="cite_ref-:1_21-2"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>In 2023, Lynn Conway collaborated with Jim Boulton to create Lines in the Sand,<sup id="cite_ref-60"><a href="#cite_note-60">[60]</a></sup> a short comic book that tells the story of Conway's groundbreaking invention of <a href="https://en.wikipedia.org/wiki/Very-large-scale_integration" title="Very-large-scale integration">Very Large-Scale Integration</a> (VLSI). The launch event<sup id="cite_ref-61"><a href="#cite_note-61">[61]</a></sup> took place at the <a href="https://en.wikipedia.org/wiki/Centre_for_Computing_History" title="Centre for Computing History">Centre for Computing History</a> on November 23, 2023
</p>
<h2><span id="Transgender_activism">Transgender activism</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=6" title="Edit section: Transgender activism"><span>edit</span></a><span>]</span></span></h2>
<p>When nearing retirement, Conway learned that the story of her early work at <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> might soon be revealed through the investigations of Mark Smotherman that were being prepared for a 2001 publication.<sup id="cite_ref-smoth01_7-2"><a href="#cite_note-smoth01-7">[7]</a></sup> She began quietly <a href="https://en.wikipedia.org/wiki/Coming_out" title="Coming out">coming out</a> in 1999 to friends and colleagues about her past <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>,<sup id="cite_ref-BD06LC_62-0"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-ED03a_63-0"><a href="#cite_note-ED03a-63">[63]</a></sup><sup id="cite_ref-ASEEPrismOct2011_64-0"><a href="#cite_note-ASEEPrismOct2011-64">[64]</a></sup> using her personal website to tell the story in her own words.<sup id="cite_ref-conI_12-2"><a href="#cite_note-conI-12">[12]</a></sup> Her story was then more widely reported in 2000 in profiles in <i><a href="https://en.wikipedia.org/wiki/Scientific_American" title="Scientific American">Scientific American</a></i><sup id="cite_ref-sciam00_14-1"><a href="#cite_note-sciam00-14">[14]</a></sup> and the <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i>.<sup id="cite_ref-hiltzik_19-5"><a href="#cite_note-hiltzik-19">[19]</a></sup> In a later <i><a href="https://en.wikipedia.org/wiki/Forbes" title="Forbes">Forbes</a></i> interview, Conway commented "From the 1970s to 1999 I was recognized as breaking the gender barrier in the computer science field as a woman, but in 2000 it became the transgender barrier I was breaking."<sup id="cite_ref-:1_21-3"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>After going public with her story, she began work in <a href="https://en.wikipedia.org/wiki/Transgender_activism" title="Transgender activism">transgender activism</a>, intending to "illuminate and normalize the issues of gender identity and the processes of gender transition".<sup id="cite_ref-65"><a href="#cite_note-65">[65]</a></sup> She has worked to protect and expand the <a href="https://en.wikipedia.org/wiki/LGBT_rights_by_country_or_territory" title="LGBT rights by country or territory">rights of transgender people</a>. She has provided direct and indirect assistance to numerous other transgender women going through transition and maintains a website providing medical resources and emotional advice. Parts have been translated into most of the world's major languages.<sup id="cite_ref-translation_66-0"><a href="#cite_note-translation-66">[66]</a></sup> She maintained a listing of many successful post-transition transgender people, to, in her words "provide role models for individuals who are facing gender transition".<sup id="cite_ref-67"><a href="#cite_note-67">[67]</a></sup> Her website also provided news related to transgender issues and information on <a href="https://en.wikipedia.org/wiki/Sex_reassignment_surgery_male-to-female" title="Sex reassignment surgery male-to-female">sex reassignment surgery for transsexual women</a>, <a href="https://en.wikipedia.org/wiki/Facial_feminization_surgery" title="Facial feminization surgery">facial feminization surgery</a>, academic inquiries into the prevalence of <a href="https://en.wikipedia.org/wiki/Transsexualism" title="Transsexualism">transsexualism</a><sup id="cite_ref-prevalence_68-0"><a href="#cite_note-prevalence-68">[68]</a></sup> and transgender and transsexual issues in general.<sup id="cite_ref-HRCProfile_69-0"><a href="#cite_note-HRCProfile-69">[69]</a></sup><sup id="cite_ref-LGBTHistoryMonthProfile_70-0"><a href="#cite_note-LGBTHistoryMonthProfile-70">[70]</a></sup>
</p><p>She has also advocated for <a href="https://en.wikipedia.org/wiki/Equal_opportunity" title="Equal opportunity">equal opportunities</a> and <a href="https://en.wikipedia.org/wiki/Employment_protection_legislation" title="Employment protection legislation">employment protections</a> for <a href="https://en.wikipedia.org/wiki/Transgender_people" title="Transgender people">transgender people</a> in high-technology industry,<sup id="cite_ref-HP01_71-0"><a href="#cite_note-HP01-71">[71]</a></sup><sup id="cite_ref-FCC01_72-0"><a href="#cite_note-FCC01-72">[72]</a></sup><sup id="cite_ref-Adv01_73-0"><a href="#cite_note-Adv01-73">[73]</a></sup><sup id="cite_ref-Intel03_74-0"><a href="#cite_note-Intel03-74">[74]</a></sup><sup id="cite_ref-PT03_75-0"><a href="#cite_note-PT03-75">[75]</a></sup><sup id="cite_ref-76"><a href="#cite_note-76">[76]</a></sup> and for elimination of the <a href="https://en.wikipedia.org/wiki/Gender_identity_disorder" title="Gender identity disorder">pathologization of transgender people</a> by the psychiatric community.<sup id="cite_ref-77"><a href="#cite_note-77">[77]</a></sup><sup id="cite_ref-78"><a href="#cite_note-78">[78]</a></sup>
</p><p>Conway has been a critic of the <a href="https://en.wikipedia.org/wiki/Blanchard,_Bailey,_and_Lawrence_theory" title="Blanchard, Bailey, and Lawrence theory">Blanchard, Bailey, and Lawrence theory</a> of male-to-female transsexualism that all <a href="https://en.wikipedia.org/wiki/Trans_woman" title="Trans woman">trans women</a> are motivated either by <a href="https://en.wikipedia.org/wiki/Homosexual_transsexual" title="Homosexual transsexual">feminine homosexuality</a> or <a href="https://en.wikipedia.org/wiki/Autogynephilia" title="Autogynephilia">autogynephilia</a>.<sup id="cite_ref-carey_79-0"><a href="#cite_note-carey-79">[79]</a></sup> Along with American transgender rights activist <a href="https://en.wikipedia.org/wiki/Andrea_James" title="Andrea James">Andrea James</a> and University of Chicago economics professor <a href="https://en.wikipedia.org/wiki/Deirdre_McCloskey" title="Deirdre McCloskey">Dierdre McCloskey</a>, she was also a key person in the campaign against <a href="https://en.wikipedia.org/wiki/J._Michael_Bailey" title="J. Michael Bailey">J. Michael Bailey</a>'s book about the theory, <i><a href="https://en.wikipedia.org/wiki/The_Man_Who_Would_Be_Queen" title="The Man Who Would Be Queen">The Man Who Would Be Queen</a>.</i><sup id="cite_ref-dreger2008_80-0"><a href="#cite_note-dreger2008-80">[80]</a></sup><sup id="cite_ref-81"><a href="#cite_note-81">[81]</a></sup> Conway and McCloskey wrote letters to Northwestern University, accusing Bailey of "conducting intimate research observations on human subjects without telling them that they were objects of the study."<sup id="cite_ref-carey_79-1"><a href="#cite_note-carey-79">[79]</a></sup> American bioethicist <a href="https://en.wikipedia.org/wiki/Alice_Dreger" title="Alice Dreger">Alice Dreger</a> in her book <i>Galilieo's Middle Finger</i> criticized Conway for filing a lawsuit against Bailey which had "no legal basis", referring to her allegation that Bailey lacked a license as a clinical psychologist when he wrote letters in support of a young trans woman seeking to transition. According to Dreger, as Bailey did not receive compensation for his services, he would not have needed a license in Illinois, and was "completely forthright in his letters supporting the women, both about the fact that he had only had brief conversations with them (as opposed to having provided them with extensive counseling) and about his own qualifications and expertise... [and] even attached copies of his CV." As Dreger argues, "presumably all this was why [Illinois] never bothered to pursue the charge."<sup id="cite_ref-82"><a href="#cite_note-82">[82]</a></sup> In response, Conway argued that Dreger "deflects attention away from Bailey's book and the massive trans community protest, and caricatures the entire controversy as nothing more than a vicious effort by three rather witch-like women to 'ruin the life' of a brilliant scientist.<sup id="cite_ref-83"><a href="#cite_note-83">[83]</a></sup>
</p><p>Conway was a cast member in the first all-transgender performance of <i><a href="https://en.wikipedia.org/wiki/The_Vagina_Monologues" title="The Vagina Monologues">The Vagina Monologues</a></i> in <a href="https://en.wikipedia.org/wiki/Los_Angeles" title="Los Angeles">Los Angeles</a> in 2004,<sup id="cite_ref-VD04_84-0"><a href="#cite_note-VD04-84">[84]</a></sup> and appeared in a LOGO-Channel documentary film about that event entitled <i>Beautiful Daughters.</i><sup id="cite_ref-BD06LC_62-1"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-BD06_85-0"><a href="#cite_note-BD06-85">[85]</a></sup>
</p><p>In 2009, Conway was named one of the "Stonewall 40 trans heroes" on the 40th anniversary of the <a href="https://en.wikipedia.org/wiki/Stonewall_riots" title="Stonewall riots">Stonewall riots</a> by the <a href="https://en.wikipedia.org/wiki/International_Court_System" title="International Court System">International Court System</a>, one of the oldest and largest predominantly gay organizations in the world, and the <a href="https://en.wikipedia.org/wiki/National_Gay_and_Lesbian_Task_Force" title="National Gay and Lesbian Task Force">National Gay and Lesbian Task Force</a>.<sup id="cite_ref-trans40_86-0"><a href="#cite_note-trans40-86">[86]</a></sup><sup id="cite_ref-ngltf_87-0"><a href="#cite_note-ngltf-87">[87]</a></sup>
</p><p>In 2013, with support from many hi-tech thought-leaders, Conway and Leandra Vicci of the <a href="https://en.wikipedia.org/wiki/University_of_North_Carolina_at_Chapel_Hill" title="University of North Carolina at Chapel Hill">University of North Carolina at Chapel Hill</a> lobbied the directors of the <a href="https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers" title="Institute of Electrical and Electronics Engineers">Institute of Electrical and Electronics Engineers</a> (IEEE), the world's largest professional engineering society, for transgender inclusion in the IEEE's code of ethics.<sup id="cite_ref-Beyer2014_88-0"><a href="#cite_note-Beyer2014-88">[88]</a></sup> The code, known within the profession as much as a code of honor as one of ethics, became fully <a href="https://en.wikipedia.org/wiki/LGBT" title="LGBT">LGBT</a> inclusive in January 2014.<sup id="cite_ref-ieeeglance_89-0"><a href="#cite_note-ieeeglance-89">[89]</a></sup><sup id="cite_ref-ieeeethics_90-0"><a href="#cite_note-ieeeethics-90">[90]</a></sup><sup id="cite_ref-McCarty2014_91-0"><a href="#cite_note-McCarty2014-91">[91]</a></sup> 
</p><p>In 2014, <i><a href="https://en.wikipedia.org/wiki/Time_Magazine" title="Time Magazine">Time Magazine</a></i> named Conway as one of "21 Transgender People Who Influenced American Culture".<sup id="cite_ref-Time21Culture_6-1"><a href="#cite_note-Time21Culture-6">[6]</a></sup>
</p><p>In 2015, she was selected for inclusion in "The Trans100"<sup id="cite_ref-2015trans100_92-0"><a href="#cite_note-2015trans100-92">[92]</a></sup> and was interviewed in 2020 for inclusion in the Trans Activism Oral History Project.<sup id="cite_ref-93"><a href="#cite_note-93">[93]</a></sup>
</p>
<h2><span id="Personal_life">Personal life</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=7" title="Edit section: Personal life"><span>edit</span></a><span>]</span></span></h2>
<p>In 1987, Conway met her husband Charles "Charlie" Rogers, a professional engineer who shares her interest in the outdoors, including <a href="https://en.wikipedia.org/wiki/Whitewater_canoeing" title="Whitewater canoeing">whitewater canoeing</a> and <a href="https://en.wikipedia.org/wiki/Motocross_racing" title="Motocross racing">motocross racing</a>.<sup id="cite_ref-hiltzik_19-6"><a href="#cite_note-hiltzik-19">[19]</a></sup><sup id="cite_ref-Forman2013_94-0"><a href="#cite_note-Forman2013-94">[94]</a></sup> They soon started living together, and bought a house with 24 acres (9.7&nbsp;ha) of meadow, marsh, and woodland in rural <a href="https://en.wikipedia.org/wiki/Michigan" title="Michigan">Michigan</a> in 1994.<sup id="cite_ref-hiltzik_19-7"><a href="#cite_note-hiltzik-19">[19]</a></sup> On August 13, 2002, they were married.<sup id="cite_ref-ABCnews01_15-1"><a href="#cite_note-ABCnews01-15">[15]</a></sup><sup id="cite_ref-BD06LC_62-2"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-95"><a href="#cite_note-95">[95]</a></sup> In 2014, the University of Michigan's <i>The Michigan Engineer</i> alumni magazine documented the connections between Conway's engineering explorations and the adventures in her personal life.<sup id="cite_ref-moore2014_96-0"><a href="#cite_note-moore2014-96">[96]</a></sup><sup id="cite_ref-Szczepanski2014_97-0"><a href="#cite_note-Szczepanski2014-97">[97]</a></sup>
</p>
<h2><span id="Awards_and_honors">Awards and honors</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=8" title="Edit section: Awards and honors"><span>edit</span></a><span>]</span></span></h2>
<p>Conway has received a number of awards and distinctions:
</p>
<ul><li><i><a href="https://en.wikipedia.org/wiki/Electronics_(magazine)" title="Electronics (magazine)">Electronics</a></i> 1981 Award for Achievement, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a><sup id="cite_ref-98"><a href="#cite_note-98">[98]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Harold_Pender_Award" title="Harold Pender Award">Harold Pender Award</a> of the <a href="https://en.wikipedia.org/wiki/Moore_School" title="Moore School">Moore School</a>, <a href="https://en.wikipedia.org/wiki/University_of_Pennsylvania" title="University of Pennsylvania">University of Pennsylvania</a>, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a>, 1984<sup id="cite_ref-99"><a href="#cite_note-99">[99]</a></sup></li>
<li>IEEE EAB Major Educational Innovation Award, 1984<sup id="cite_ref-100"><a href="#cite_note-100">[100]</a></sup></li>
<li>Fellow of the <a href="https://en.wikipedia.org/wiki/IEEE" title="IEEE">IEEE</a>, 1985, "for contributions to VLSI technology"<sup id="cite_ref-101"><a href="#cite_note-101">[101]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/John_Price_Wetherill_Medal" title="John Price Wetherill Medal">John Price Wetherill Medal</a> of the <a href="https://en.wikipedia.org/wiki/Franklin_Institute" title="Franklin Institute">Franklin Institute</a>, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a>, 1985<sup id="cite_ref-102"><a href="#cite_note-102">[102]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Secretary_of_Defense_Meritorious_Civilian_Service_Award" title="Secretary of Defense Meritorious Civilian Service Award">Secretary of Defense Meritorious Civilian Service Award</a>, May 1985<sup id="cite_ref-emerita_51-1"><a href="#cite_note-emerita-51">[51]</a></sup><sup id="cite_ref-SecMAA_103-0"><a href="#cite_note-SecMAA-103">[103]</a></sup></li>
<li>Member of the <a href="https://en.wikipedia.org/wiki/National_Academy_of_Engineering" title="National Academy of Engineering">National Academy of Engineering</a>, 1989<sup id="cite_ref-104"><a href="#cite_note-104">[104]</a></sup></li>
<li>National Achievement Award, <a href="https://en.wikipedia.org/wiki/Society_of_Women_Engineers" title="Society of Women Engineers">Society of Women Engineers</a>, 1990<sup id="cite_ref-105"><a href="#cite_note-105">[105]</a></sup></li>
<li>Presidential Appointment to the <a href="https://en.wikipedia.org/wiki/United_States_Air_Force_Academy#Board_of_Visitors" title="United States Air Force Academy">United States Air Force Academy Board of Visitors</a>, 1996<sup id="cite_ref-106"><a href="#cite_note-106">[106]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Trinity_College_(Connecticut)" title="Trinity College (Connecticut)">Trinity College</a>, 1998<sup id="cite_ref-107"><a href="#cite_note-107">[107]</a></sup></li>
<li><i><a href="https://en.wikipedia.org/wiki/Electronic_Design_(magazine)" title="Electronic Design (magazine)">Electronic Design</a></i> Hall of Fame, 2002<sup id="cite_ref-108"><a href="#cite_note-108">[108]</a></sup></li>
<li>Engineer of the Year, <a href="https://en.wikipedia.org/wiki/National_Organization_of_Gay_and_Lesbian_Scientists_and_Technical_Professionals" title="National Organization of Gay and Lesbian Scientists and Technical Professionals">National Organization of Gay and Lesbian Scientists and Technical Professionals</a>, 2005<sup id="cite_ref-109"><a href="#cite_note-109">[109]</a></sup></li>
<li>Named one of the "Stonewall 40 trans heroes" by the <a href="https://en.wikipedia.org/wiki/Imperial_Court_System" title="Imperial Court System">Imperial Court System</a> and the <a href="https://en.wikipedia.org/wiki/National_LGBTQ_Task_Force" title="National LGBTQ Task Force">National LGBTQ Task Force</a>, 2009.<sup id="cite_ref-trans40_86-1"><a href="#cite_note-trans40-86">[86]</a></sup><sup id="cite_ref-ngltf_87-1"><a href="#cite_note-ngltf-87">[87]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Computer_Pioneer_Award" title="Computer Pioneer Award">Computer Pioneer Award</a>, <a href="https://en.wikipedia.org/wiki/IEEE_Computer_Society" title="IEEE Computer Society">IEEE Computer Society</a>, 2009<sup id="cite_ref-comsocpioneeraward_8-4"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup></li>
<li>Member of the Corporation, Emerita, The Charles Stark <a href="https://en.wikipedia.org/wiki/Draper_Laboratory" title="Draper Laboratory">Draper Laboratory</a>, 1993–2010<sup id="cite_ref-110"><a href="#cite_note-110">[110]</a></sup></li>
<li>Fellow Award, <a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a>, 2014, "For her work in developing and disseminating new methods of integrated circuit design."<sup id="cite_ref-111"><a href="#cite_note-111">[111]</a></sup><sup id="cite_ref-112"><a href="#cite_note-112">[112]</a></sup><sup id="cite_ref-113"><a href="#cite_note-113">[113]</a></sup><sup id="cite_ref-114"><a href="#cite_note-114">[114]</a></sup><sup id="cite_ref-115"><a href="#cite_note-115">[115]</a></sup><sup id="cite_ref-116"><a href="#cite_note-116">[116]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Illinois_Institute_of_Technology" title="Illinois Institute of Technology">Illinois Institute of Technology</a>, 2014<sup id="cite_ref-117"><a href="#cite_note-117">[117]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Steinmetz_Memorial_Lecture" title="Steinmetz Memorial Lecture">Steinmetz Memorial Lecture</a>, (Invitational), IEEE/<a href="https://en.wikipedia.org/wiki/Union_College" title="Union College">Union College</a>, 2015.<sup id="cite_ref-118"><a href="#cite_note-118">[118]</a></sup><sup id="cite_ref-119"><a href="#cite_note-119">[119]</a></sup><sup id="cite_ref-120"><a href="#cite_note-120">[120]</a></sup><sup id="cite_ref-121"><a href="#cite_note-121">[121]</a></sup><sup id="cite_ref-122"><a href="#cite_note-122">[122]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/IEEE_Maxwell_Award" title="IEEE Maxwell Award">IEEE/RSE James Clerk Maxwell Medal</a>, 2015<sup id="cite_ref-123"><a href="#cite_note-123">[123]</a></sup><sup id="cite_ref-124"><a href="#cite_note-124">[124]</a></sup><sup id="cite_ref-125"><a href="#cite_note-125">[125]</a></sup><sup id="cite_ref-126"><a href="#cite_note-126">[126]</a></sup><sup id="cite_ref-127"><a href="#cite_note-127">[127]</a></sup><sup id="cite_ref-128"><a href="#cite_note-128">[128]</a></sup><sup id="cite_ref-129"><a href="#cite_note-129">[129]</a></sup><sup id="cite_ref-130"><a href="#cite_note-130">[130]</a></sup></li>
<li>Magill Lecture in Science, Technology and the Arts (Invited), Columbia University, 2016<sup id="cite_ref-131"><a href="#cite_note-131">[131]</a></sup><sup id="cite_ref-132"><a href="#cite_note-132">[132]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/University_of_Victoria" title="University of Victoria">University of Victoria</a>, 2016<sup id="cite_ref-133"><a href="#cite_note-133">[133]</a></sup><sup id="cite_ref-134"><a href="#cite_note-134">[134]</a></sup><sup id="cite_ref-135"><a href="#cite_note-135">[135]</a></sup><sup id="cite_ref-136"><a href="#cite_note-136">[136]</a></sup><sup id="cite_ref-137"><a href="#cite_note-137">[137]</a></sup></li>
<li>Fellow Award, <a href="https://en.wikipedia.org/wiki/American_Association_for_the_Advancement_of_Science" title="American Association for the Advancement of Science">American Association for the Advancement of Science</a> (AAAS), 2016<sup id="cite_ref-138"><a href="#cite_note-138">[138]</a></sup><sup id="cite_ref-139"><a href="#cite_note-139">[139]</a></sup><sup id="cite_ref-140"><a href="#cite_note-140">[140]</a></sup><sup id="cite_ref-141"><a href="#cite_note-141">[141]</a></sup></li>
<li>Honorary Doctorate and Commencement Address, University of Michigan, Ann Arbor, 2018<sup id="cite_ref-142"><a href="#cite_note-142">[142]</a></sup><sup id="cite_ref-143"><a href="#cite_note-143">[143]</a></sup><sup id="cite_ref-144"><a href="#cite_note-144">[144]</a></sup><sup id="cite_ref-145"><a href="#cite_note-145">[145]</a></sup></li>
<li>Pioneer in Tech Award, National Center for Women in Technology (NCWIT), 2019<sup id="cite_ref-146"><a href="#cite_note-146">[146]</a></sup></li>
<li>Lifetime Achievement Award, IBM Corporation, 2020<sup id="cite_ref-:0_147-0"><a href="#cite_note-:0-147">[147]</a></sup></li>
<li>Induction into the <a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame (NIHF)</a>, 2023<sup id="cite_ref-148"><a href="#cite_note-148">[148]</a></sup><sup id="cite_ref-149"><a href="#cite_note-149">[149]</a></sup><sup id="cite_ref-150"><a href="#cite_note-150">[150]</a></sup><sup id="cite_ref-151"><a href="#cite_note-151">[151]</a></sup><sup id="cite_ref-152"><a href="#cite_note-152">[152]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Princeton_University" title="Princeton University">Princeton University</a>, 2023.<sup id="cite_ref-153"><a href="#cite_note-153">[153]</a></sup></li>
<li>Honorary Doctor of Science, <a href="https://en.wikipedia.org/wiki/Syracuse_University" title="Syracuse University">Syracuse University</a>, 2024<sup id="cite_ref-154"><a href="#cite_note-154">[154]</a></sup></li></ul>
<h2><span id="IBM.27s_apology"></span><span id="IBM's_apology">IBM's apology</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=9" title="Edit section: IBM's apology"><span>edit</span></a><span>]</span></span></h2>
<p>In 2020, 52 years after IBM fired her for being transgender, IBM officially and publicly apologized to Conway;<sup id="cite_ref-155"><a href="#cite_note-155">[155]</a></sup><sup id="cite_ref-156"><a href="#cite_note-156">[156]</a></sup><sup id="cite_ref-157"><a href="#cite_note-157">[157]</a></sup><sup id="cite_ref-158"><a href="#cite_note-158">[158]</a></sup><sup id="cite_ref-159"><a href="#cite_note-159">[159]</a></sup><sup id="cite_ref-160"><a href="#cite_note-160">[160]</a></sup> IBM held a public event "Tech Trailblazer and Transgender Pioneer Lynn Conway in conversation with Diane Gherson" (IBM's senior VP of HR); IBM's Director of Research Dario Gil said "Lynn was recently awarded the rare IBM Lifetime Achievement Award, given to individuals who have changed the world through technology inventions. Lynn's extraordinary technical achievements helped define the modern computing industry. She paved the way for how we design and make computing chips today – and forever changed microelectronics, devices, and people's lives."<sup id="cite_ref-:0_147-1"><a href="#cite_note-:0-147">[147]</a></sup>
</p>
<h2><span id="Selected_works">Selected works</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=10" title="Edit section: Selected works"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFMeadConway1980">Mead, Carver; Conway, Lynn (1980). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/introductiontovl00mead"><i>Introduction to VLSI Systems</i></a></span>. Addison-Wesley. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0201043580" title="Special:BookSources/0201043580"><bdi>0201043580</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+VLSI+Systems&amp;rft.pub=Addison-Wesley&amp;rft.date=1980&amp;rft.isbn=0201043580&amp;rft.aulast=Mead&amp;rft.aufirst=Carver&amp;rft.au=Conway%2C+Lynn&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fintroductiontovl00mead&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1981">Conway, L. (February 1981). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv.pdf">"THE MPC ADVENTURES: Experiences with the Generation of VLSI Design and Implementation Methodologies"</a> <span>(PDF)</span>. <i>Xerox PARC Technical Report VLSI-81-2</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Xerox+PARC+Technical+Report+VLSI-81-2&amp;rft.atitle=THE+MPC+ADVENTURES%3A+Experiences+with+the+Generation+of+VLSI+Design+and+Implementation+Methodologies&amp;rft.date=1981-02&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FMPCAdv%2FMPCAdv.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1982">Conway, L. (September 23, 1982). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/ESSCIRC82/The%20Design%20of%20VLSI%20Design%20Methods.pdf">"The Design of VLSI Design Methods"</a> <span>(PDF)</span>. <i>Proc. VUB European Solid-State Circuits Conference (Invited Lecture)</i>. Vrije Universiteit Brüssel, Brussels, Belgium: 106–117.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc.+VUB+European+Solid-State+Circuits+Conference+%28Invited+Lecture%29&amp;rft.atitle=The+Design+of+VLSI+Design+Methods&amp;rft.pages=106-117&amp;rft.date=1982-09-23&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FESSCIRC82%2FThe%2520Design%2520of%2520VLSI%2520Design%2520Methods.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2012">Conway, Lynn (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Lynn_Conway_VLSI_Reminiscences.pdf">"Reminiscences of the VLSI Revolution: How a Series of Failures Triggered a Paradigm Shift in Digital Design"</a> <span>(PDF)</span>. <i>Solid-State Circuits Magazine</i>. Vol.&nbsp;4, no.&nbsp;4. IEEE. pp.&nbsp;8–31. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215752">10.1109/MSSC.2012.2215752</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Solid-State+Circuits+Magazine&amp;rft.atitle=Reminiscences+of+the+VLSI+Revolution%3A+How+a+Series+of+Failures+Triggered+a+Paradigm+Shift+in+Digital+Design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=8-31&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215752&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FLynn_Conway_VLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2018">Conway, L. (October 2018). <a rel="nofollow" href="https://www.computer.org/csdl/magazine/co/2018/10/mco2018100066/17D45WXIkDI">"The Disappeared: Beyond Winning and Losing"</a>. <i>Computer</i>. Vol.&nbsp;51. IEEE Computer Society. pp.&nbsp;66–73.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer&amp;rft.atitle=The+Disappeared%3A+Beyond+Winning+and+Losing&amp;rft.volume=51&amp;rft.pages=66-73&amp;rft.date=2018-10&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fwww.computer.org%2Fcsdl%2Fmagazine%2Fco%2F2018%2F10%2Fmco2018100066%2F17D45WXIkDI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2011">Conway, Lynn (2011). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/ACS/Lynn_Conway_ACS_Reminiscences.pdf">"IBM-ACS: Reminiscences and Lessons Learned from a 1960's Supercomputer Project"</a> <span>(PDF)</span>. In Jones, C. B.; Lloyd, J. L. (eds.). <i>Dependable and Historic Computing: Essays Dedicated to Brian Randell on the Occasion of his 75th Birthday</i>. Springer-Verlag. pp.&nbsp;185–224. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-642-24541-1" title="Special:BookSources/978-3-642-24541-1"><bdi>978-3-642-24541-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=IBM-ACS%3A+Reminiscences+and+Lessons+Learned+from+a+1960%27s+Supercomputer+Project&amp;rft.btitle=Dependable+and+Historic+Computing%3A+Essays+Dedicated+to+Brian+Randell+on+the+Occasion+of+his+75th+Birthday&amp;rft.pages=185-224&amp;rft.pub=Springer-Verlag&amp;rft.date=2011&amp;rft.isbn=978-3-642-24541-1&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FACS%2FLynn_Conway_ACS_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway">Conway, Lynn. <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/Archive/ACSarchive.html">"Lynn Conway's IBM-ACS Archive"</a>. University of Michigan<span>. Retrieved <span>June 4,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway%27s+IBM-ACS+Archive&amp;rft.pub=University+of+Michigan&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FArchive%2FACSarchive.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConwayRandellSenzig1966">Conway, L.; <a href="https://en.wikipedia.org/wiki/Brian_Randell" title="Brian Randell">Randell, Brian</a>; Senzig, D. (February 23, 1966). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/DIS/DIS.pdf">"Dynamic Instruction Scheduling"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Dynamic+Instruction+Scheduling&amp;rft.date=1966-02-23&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft.au=Randell%2C+Brian&amp;rft.au=Senzig%2C+D.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FDIS%2FDIS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFRozenbergConwayRiekert1966">Rozenberg, D.; Conway, L.; Riekert, R. (March 15, 1966). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/SimTech/SimTech.pdf">"ACS Simulation Technique"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ACS+Simulation+Technique&amp;rft.date=1966-03-15&amp;rft.aulast=Rozenberg&amp;rft.aufirst=D.&amp;rft.au=Conway%2C+L.&amp;rft.au=Riekert%2C+R.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FSimTech%2FSimTech.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L. (August 25, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/MPMSim/MPMSim.pdf">"MPM Timing Simulation"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=MPM+Timing+Simulation&amp;rft.date=1967-08-25&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FMPMSim%2FMPMSim.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L. (November 29, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/LogDes/LogDes.pdf">"ACS Logic Design Conventions: A Guide for the Novice"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ACS+Logic+Design+Conventions%3A+A+Guide+for+the+Novice&amp;rft.date=1967-11-29&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FLogDes%2FLogDes.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L (October 31, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/LSS/LSS.pdf">"A Proposed ACS Logic Simulation System"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=A+Proposed+ACS+Logic+Simulation+System&amp;rft.date=1967-10-31&amp;rft.aulast=Conway&amp;rft.aufirst=L&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FLSS%2FLSS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1968">Conway, L. (August 6, 1968). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/DesProc/DesignProcess.pdf">"The Computer Design Process: A Proposed Plan for ACS"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Computer+Design+Process%3A+A+Proposed+Plan+for+ACS&amp;rft.date=1968-08-06&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FDesProc%2FDesignProcess.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li></ul>
<h2><span id="Patents">Patents</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=11" title="Edit section: Patents"><span>edit</span></a><span>]</span></span></h2>
<ul><li><span id="CITEREFConwayVolzWalker1991"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5046022">US 5046022</a>, Conway, Lynn; Volz, Richard &amp; Walker, Michael, "Teleautonomous System and Method Employing Time/Position Synchrony/Desynchrony", issued September 3, 1991.</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5046022&amp;rft.cc=US&amp;rft.title=Teleautonomous+System+and+Method+Employing+Time%2FPosition+Synchrony%2FDesynchrony&amp;rft.inventor=Conway&amp;rft.date=September 3, 1991."></span></li>
<li><span id="CITEREFConway1995"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5444476">US 5444476</a>, Conway, Lynn, "System and Method for Teleinteraction", issued August 22, 1995</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5444476&amp;rft.cc=US&amp;rft.title=System+and+Method+for+Teleinteraction&amp;rft.inventor=Conway&amp;rft.date=August 22, 1995"></span></li>
<li><span id="CITEREFConwayCohen1997"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5652849">US 5652849</a>, Conway, Lynn &amp; Cohen, Charles, "Apparatus and Method for Remote Control Using a Visual Information Stream", issued July 20, 1997</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5652849&amp;rft.cc=US&amp;rft.title=Apparatus+and+Method+for+Remote+Control+Using+a+Visual+Information+Stream&amp;rft.inventor=Conway&amp;rft.date=July 20, 1997"></span></li>
<li><span id="CITEREFConway1998"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5719622">US 5719622</a>, Conway, Lynn, "Visual Control Selection of Remote Mechanisms", issued February 17, 1998</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5719622&amp;rft.cc=US&amp;rft.title=Visual+Control+Selection+of+Remote+Mechanisms&amp;rft.inventor=Conway&amp;rft.date=February 17, 1998"></span></li>
<li><span id="CITEREFConway1998"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5745782">US 5745782</a>, Conway, Lynn, "Method and System for Organizing and Presenting Audio/Visual Information", issued April 28, 1998</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5745782&amp;rft.cc=US&amp;rft.title=Method+and+System+for+Organizing+and+Presenting+Audio%2FVisual+Information&amp;rft.inventor=Conway&amp;rft.date=April 28, 1998"></span></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=12" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div>
<ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite><a rel="nofollow" href="https://computerhistory.org/profile/lynn-conway/">"CHM 2014 Fellow "For her work in developing and disseminating new methods of integrated circuit design"<span></span>"</a>. <i>Computer History Museum</i>. <a rel="nofollow" href="https://web.archive.org/web/20160703014527/http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">Archived</a> from the original on July 3, 2016<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+History+Museum&amp;rft.atitle=CHM+2014+Fellow+%22For+her+work+in+developing+and+disseminating+new+methods+of+integrated+circuit+design%22&amp;rft_id=https%3A%2F%2Fcomputerhistory.org%2Fprofile%2Flynn-conway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFSaariAllisonEllavich1996">Saari, Peggy; Allison, Stephen; Ellavich, Marie C. (1996). <a rel="nofollow" href="https://books.google.com/books?id=8VVvtWrIxtAC"><i>Scientists: A-F</i></a>. U-X-L. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-7876-0960-3" title="Special:BookSources/978-0-7876-0960-3"><bdi>978-0-7876-0960-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Scientists%3A+A-F&amp;rft.pub=U-X-L&amp;rft.date=1996&amp;rft.isbn=978-0-7876-0960-3&amp;rft.aulast=Saari&amp;rft.aufirst=Peggy&amp;rft.au=Allison%2C+Stephen&amp;rft.au=Ellavich%2C+Marie+C.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D8VVvtWrIxtAC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFBoyd">Boyd, Helen. <a rel="nofollow" href="http://www.myhusbandbetty.com/wordPressNEW/2024/06/11/lynn-conway-january-2-1938-june-9-2024/">"Lynn Conway: Trans Icon and Pioneer, 1938 – 2024"</a>. <i>(En)gender</i>. <a rel="nofollow" href="https://web.archive.org/web/20240611172823/http://www.myhusbandbetty.com/wordPressNEW/2024/06/11/lynn-conway-january-2-1938-june-9-2024/">Archived</a> from the original on June 11, 2024<span>. Retrieved <span>June 11,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=%28En%29gender&amp;rft.atitle=Lynn+Conway%3A+Trans+Icon+and+Pioneer%2C+1938+%E2%80%93+2024&amp;rft.aulast=Boyd&amp;rft.aufirst=Helen&amp;rft_id=http%3A%2F%2Fwww.myhusbandbetty.com%2FwordPressNEW%2F2024%2F06%2F11%2Flynn-conway-january-2-1938-june-9-2024%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Lee1995-4"><span><b><a href="#cite_ref-Lee1995_4-0">^</a></b></span> <span><cite id="CITEREFLee1995">Lee, John A. N. (1995). <a rel="nofollow" href="https://archive.org/details/internationalbio00john"><i>International Biographical Dictionary of Computer Pioneers</i></a>. Fitzroy Dearborn. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-884964-47-8" title="Special:BookSources/1-884964-47-8"><bdi>1-884964-47-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=International+Biographical+Dictionary+of+Computer+Pioneers&amp;rft.pub=Fitzroy+Dearborn&amp;rft.date=1995&amp;rft.isbn=1-884964-47-8&amp;rft.aulast=Lee&amp;rft.aufirst=John+A.+N.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Finternationalbio00john&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20141110182854/http://computer.org/computer-pioneers/conway.html">"Computer Pioneers - Lynn Conway"</a>. <i>IEEE Computer Society</i>. IEEE. Archived from <a rel="nofollow" href="http://computer.org/computer-pioneers/conway.html">the original</a> on November 10, 2014<span>. Retrieved <span>November 10,</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IEEE+Computer+Society&amp;rft.atitle=Computer+Pioneers+-+Lynn+Conway&amp;rft_id=http%3A%2F%2Fcomputer.org%2Fcomputer-pioneers%2Fconway.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Time21Culture-6"><span>^ <a href="#cite_ref-Time21Culture_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Time21Culture_6-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="http://time.com/130734/transgender-celebrities-actors-athletes-in-america/">"21 Transgender People Who Influenced American Culture"</a>. <i>Time</i>. May 29, 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Time&amp;rft.atitle=21+Transgender+People+Who+Influenced+American+Culture&amp;rft.date=2014-05-29&amp;rft_id=http%3A%2F%2Ftime.com%2F130734%2Ftransgender-celebrities-actors-athletes-in-america%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-smoth01-7"><span>^ <a href="#cite_ref-smoth01_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-smoth01_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-smoth01_7-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFSmotherman">Smotherman, Mark. <a rel="nofollow" href="http://www.cs.clemson.edu/~mark/acs.html">"IBM Advanced Computing Systems (ACS) – 1961–1969"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IBM+Advanced+Computing+Systems+%28ACS%29+%E2%80%93+1961%E2%80%931969&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.cs.clemson.edu%2F~mark%2Facs.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-comsocpioneeraward-8"><span>^ <a href="#cite_ref-comsocpioneeraward_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-4"><sup><i><b>e</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20150103172210/http://www.computer.org/portal/web/awards/conway">"Lynn Conway: 2009 Computer Pioneer Award Recipient"</a>. <i>IEEE Computer Society</i>. Archived from <a rel="nofollow" href="http://www.computer.org/portal/web/awards/conway">the original</a> on January 3, 2015<span>. Retrieved <span>January 20,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IEEE+Computer+Society&amp;rft.atitle=Lynn+Conway%3A+2009+Computer+Pioneer+Award+Recipient&amp;rft_id=http%3A%2F%2Fwww.computer.org%2Fportal%2Fweb%2Fawards%2Fconway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-comsocpioneersawardvideo-9"><span>^ <a href="#cite_ref-comsocpioneersawardvideo_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-comsocpioneersawardvideo_9-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=i4Txvjia3p0"><i>Lynn Conway receives 2009 IEEE Computer Society Computer Pioneer Award</i></a>. IEEE Computer Society. July 30, 2010 – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+receives+2009+IEEE+Computer+Society+Computer+Pioneer+Award&amp;rft.pub=IEEE+Computer+Society&amp;rft.date=2010-07-30&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Di4Txvjia3p0&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-superproj60b-10"><span>^ <a href="#cite_ref-superproj60b_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-superproj60b_10-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://computerhistory.org/events/ibm-acs-system-pioneering-supercomputer/">"CHM Events: IBM ACS System: A Pioneering Supercomputer Project of the 1960's"</a>. <i>Computer History Museum</i>. February 18, 2010. <a rel="nofollow" href="https://web.archive.org/web/20100420225250/http://www.computerhistory.org/events/index.php?id=1264112339">Archived</a> from the original on April 20, 2010.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+History+Museum&amp;rft.atitle=CHM+Events%3A+IBM+ACS+System%3A+A+Pioneering+Supercomputer+Project+of+the+1960%27s&amp;rft.date=2010-02-18&amp;rft_id=https%3A%2F%2Fcomputerhistory.org%2Fevents%2Fibm-acs-system-pioneering-supercomputer%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-IBMsmotherman-11"><span>^ <a href="#cite_ref-IBMsmotherman_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-IBMsmotherman_11-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFSmothermanSpicer2010">Smotherman, Mark; Spicer, Dag (December 2010). <a rel="nofollow" href="https://cacm.acm.org/opinion/ibms-single-processor-supercomputer-efforts/">"IBM's single-processor supercomputer efforts"</a>. <i><a href="https://en.wikipedia.org/wiki/Communications_of_the_ACM" title="Communications of the ACM">Communications of the ACM</a></i>. <b>53</b> (12): 28–30. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1145%2F1859204.1859216">10.1145/1859204.1859216</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=IBM%27s+single-processor+supercomputer+efforts&amp;rft.volume=53&amp;rft.issue=12&amp;rft.pages=28-30&amp;rft.date=2010-12&amp;rft_id=info%3Adoi%2F10.1145%2F1859204.1859216&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft.au=Spicer%2C+Dag&amp;rft_id=https%3A%2F%2Fcacm.acm.org%2Fopinion%2Fibms-single-processor-supercomputer-efforts%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-conI-12"><span>^ <a href="#cite_ref-conI_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-conI_12-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-conI_12-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFConway2004">Conway, Lynn (March 15, 2004). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Retrospective1.html">"Lynn Conway's Retrospective PART I: CHILDHOOD AND EDUCATION"</a>. <i>lynnconway.com</i><span>. Retrieved <span>July 9,</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lynnconway.com&amp;rft.atitle=Lynn+Conway%27s+Retrospective+PART+I%3A+CHILDHOOD+AND+EDUCATION&amp;rft.date=2004-03-15&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FRetrospective1.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-kilbane-13"><span>^ <a href="#cite_ref-kilbane_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kilbane_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-kilbane_13-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-kilbane_13-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFKilbane2003">Kilbane, Doris (October 20, 2003). <a rel="nofollow" href="https://www.electronicdesign.com/news/products/article/21795291/lynn-conway-a-trailblazer-on-professional-personal-levels">"Lynn Conway: A Trailblazer On Professional, Personal Levels"</a>. Products &gt; News. <i><a href="https://en.wikipedia.org/wiki/Electronic_Design_(magazine)" title="Electronic Design (magazine)">Electronic Design</a></i>. <a rel="nofollow" href="https://web.archive.org/web/20080608190427/http://electronicdesign.com/Articles/Index.cfm?AD=1&amp;ArticleID=5833">Archived</a> from the original on 2008-06-08<span>. Retrieved <span>2023-02-17</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Electronic+Design&amp;rft.atitle=Lynn+Conway%3A+A+Trailblazer+On+Professional%2C+Personal+Levels&amp;rft.date=2003-10-20&amp;rft.aulast=Kilbane&amp;rft.aufirst=Doris&amp;rft_id=https%3A%2F%2Fwww.electronicdesign.com%2Fnews%2Fproducts%2Farticle%2F21795291%2Flynn-conway-a-trailblazer-on-professional-personal-levels&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-sciam00-14"><span>^ <a href="#cite_ref-sciam00_14-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-sciam00_14-1"><sup><i><b>b</b></i></sup></a></span> <span>Paul Wallich, "<a rel="nofollow" href="http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">Profile: Lynn Conway—Completing the Circuit</a> <a rel="nofollow" href="https://web.archive.org/web/20131004233454/http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">Archived</a> October 4, 2013, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>," Scientific American, December 2000.</span>
</li>
<li id="cite_note-ABCnews01-15"><span>^ <a href="#cite_ref-ABCnews01_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ABCnews01_15-1"><sup><i><b>b</b></i></sup></a></span> <span>Dianne Lynch, "<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/ABC%20NEWS/ABCNEWS_com%20%20Wired%20Women%20Engineer%20Lynn%20Conway%27s%20Secret.htm">The Secret Behind 'Project Y': One Woman's Success Story — 'What Works, Works'</a>", ABCNews.com, November 29, 2001.</span>
</li>
<li id="cite_note-chm_ibm_acs_reunion-16"><span><b><a href="#cite_ref-chm_ibm_acs_reunion_16-0">^</a></b></span> <span><cite id="CITEREFSmotherman">Smotherman, Mark. <a rel="nofollow" href="http://www.cs.clemson.edu/~mark/acs_reunion.html">"IBM ACS Reunion – February 18, 2010, in California"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IBM+ACS+Reunion+%E2%80%93+February+18%2C+2010%2C+in+California&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.cs.clemson.edu%2F~mark%2Facs_reunion.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-chm_ibm_acs_video-17"><span><b><a href="#cite_ref-chm_ibm_acs_video_17-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=pod53_F6urQ">"The IBM ACS System: A Pioneering Supercomputer Project – Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/pod53_F6urQ">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=The+IBM+ACS+System%3A+A+Pioneering+Supercomputer+Project+%E2%80%93+Video&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dpod53_F6urQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span>
<cite id="CITEREFBenjamin1966">Benjamin, Harry (1966). <i>The Transsexual Phenomenon</i>. Julian Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780446824262" title="Special:BookSources/9780446824262"><bdi>9780446824262</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Transsexual+Phenomenon&amp;rft.pub=Julian+Press&amp;rft.date=1966&amp;rft.isbn=9780446824262&amp;rft.aulast=Benjamin&amp;rft.aufirst=Harry&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-hiltzik-19"><span>^ <a href="#cite_ref-hiltzik_19-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hiltzik_19-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-hiltzik_19-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-hiltzik_19-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-hiltzik_19-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-hiltzik_19-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-hiltzik_19-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-hiltzik_19-7"><sup><i><b>h</b></i></sup></a></span> <span>Hiltzik, Michael A. (November 19, 2000.) <a rel="nofollow" href="https://pqasb.pqarchiver.com/latimes/access/64332921.html?dids=64332921:64332921&amp;FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+19%2C+2000&amp;author=MICHAEL+A.+HILTZIK&amp;pub=Los+Angeles+Times&amp;edition=&amp;startpage=1&amp;desc=COVER+STORY%3B+Through+the+Gender+Labyrinth%3B+How+a+bright+boy+with+a+penchant+for+tinkering+grew+up+to+be+one+of+the+top+women+in+her+high-+tech+field">"Through the Gender Labyrinth."</a> <a rel="nofollow" href="https://web.archive.org/web/20121015144026/http://pqasb.pqarchiver.com/latimes/access/64332921.html?dids=64332921:64332921&amp;FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+19,+2000&amp;author=MICHAEL+A.+HILTZIK&amp;pub=Los+Angeles+Times&amp;edition=&amp;startpage=1&amp;desc=COVER+STORY%3B+Through+the+Gender+Labyrinth%3B+How+a+bright+boy+with+a+penchant+for+tinkering+grew+up+to+be+one+of+the+top+women+in+her+high-+tech+field">Archived</a> October 15, 2012, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>. <i>Los Angeles Times</i>, Los Angeles Times Magazine, page 1. (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Through%20the%20Gender%20Labyrinth.pdf">Free reprint</a>. Retrieved on September 19, 2007.)</span>
</li>
<li id="cite_note-Conway2012-20"><span>^ <a href="#cite_ref-Conway2012_20-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Conway2012_20-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFConway2012">Conway, Lynn (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Lynn_Conway_VLSI_Reminiscences.pdf">"Reminiscences of the VLSI revolution: How a series of failures triggered a paradigm shift in digital design"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 8–31. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215752">10.1109/MSSC.2012.2215752</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:9286356">9286356</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Reminiscences+of+the+VLSI+revolution%3A+How+a+series+of+failures+triggered+a+paradigm+shift+in+digital+design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=8-31&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A9286356%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215752&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FLynn_Conway_VLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-:1-21"><span>^ <a href="#cite_ref-:1_21-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_21-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:1_21-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-:1_21-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFAlicandri">Alicandri, Jeremy. <a rel="nofollow" href="https://www.forbes.com/sites/jeremyalicandri/2020/11/18/ibm-apologizes-for-firing-computer-pioneer/">"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later"</a>. <i>Forbes</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=IBM+Apologizes+For+Firing+Computer+Pioneer+For+Being+Transgender...52+Years+Later&amp;rft.aulast=Alicandri&amp;rft.aufirst=Jeremy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fjeremyalicandri%2F2020%2F11%2F18%2Fibm-apologizes-for-firing-computer-pioneer%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Retrospective3.html">"Lynn Conway's Retrospective PART III: Starting Over"</a>. Ai.eecs.umich.edu. May 12, 1960<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway%27s+Retrospective+PART+III%3A+Starting+Over&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1960-05-12&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FRetrospective3.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-23"><span><b><a href="#cite_ref-23">^</a></b></span> <span><cite id="CITEREFGoldberg1980">Goldberg, Adele J. (September 1980). <a rel="nofollow" href="https://scholar.google.com/scholar?hl=en&amp;lr=&amp;safe=off&amp;q=conway+lsi-systems-group&amp;btnG=Search">"About This Issue..."</a> <i><a href="https://en.wikipedia.org/wiki/ACM_Computing_Surveys" title="ACM Computing Surveys">ACM Computing Surveys</a></i>. <b>12</b> (3): 257–258. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1145%2F356819.356820">10.1145/356819.356820</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/0360-0300">0360-0300</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:27661653">27661653</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Computing+Surveys&amp;rft.atitle=About+This+Issue...&amp;rft.volume=12&amp;rft.issue=3&amp;rft.pages=257-258&amp;rft.date=1980-09&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A27661653%23id-name%3DS2CID&amp;rft.issn=0360-0300&amp;rft_id=info%3Adoi%2F10.1145%2F356819.356820&amp;rft.aulast=Goldberg&amp;rft.aufirst=Adele+J.&amp;rft_id=https%3A%2F%2Fscholar.google.com%2Fscholar%3Fhl%3Den%26lr%3D%26safe%3Doff%26q%3Dconway%2Blsi-systems-group%26btnG%3DSearch&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-24"><span><b><a href="#cite_ref-24">^</a></b></span> <span><cite id="CITEREFWalkerTersini1992">Walker, Rob; Tersini, Nancy (1992). <a rel="nofollow" href="https://books.google.com/books?id=XA9Zx1bMH-oC&amp;q=lynn-conway+parc+sutherland&amp;pg=PT206"><i>Silicon Destiny: The Story of Application Specific Integrated Circuits and LSI Logic Corporation</i></a>. Walker Research Associates. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-9632654-0-7" title="Special:BookSources/0-9632654-0-7"><bdi>0-9632654-0-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Silicon+Destiny%3A+The+Story+of+Application+Specific+Integrated+Circuits+and+LSI+Logic+Corporation&amp;rft.pub=Walker+Research+Associates&amp;rft.date=1992&amp;rft.isbn=0-9632654-0-7&amp;rft.aulast=Walker&amp;rft.aufirst=Rob&amp;rft.au=Tersini%2C+Nancy&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DXA9Zx1bMH-oC%26q%3Dlynn-conway%2Bparc%2Bsutherland%26pg%3DPT206&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-25"><span><b><a href="#cite_ref-25">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/sense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway">"Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway"</a>. <i>American Association for the Advancement of Science</i><span>. Retrieved <span>March 20,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=American+Association+for+the+Advancement+of+Science&amp;rft.atitle=Sense+of+Wonder+Motivates+VLSI+Chip+Revolutionary%2C+Lynn+Conway&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Fsense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-26"><span><b><a href="#cite_ref-26">^</a></b></span> <span><cite id="CITEREFConway2012">Conway, Lynn (December 31, 2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/BackgroundContext/Sutherland_Letter.html">"The 'Sutherland Letter' of 1976"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+%27Sutherland+Letter%27+of+1976&amp;rft.date=2012-12-31&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FBackgroundContext%2FSutherland_Letter.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-auto-27"><span>^ <a href="#cite_ref-auto_27-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-auto_27-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html">"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service"</a>. <i>ai.eecs.umich.edu</i><span>. Retrieved <span>March 13,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.eecs.umich.edu&amp;rft.atitle=Impact+of+the+Mead-Conway+VLSI+Design+Methodology+and+of+the+MOSIS+Service&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-sciam002-28"><span><b><a href="#cite_ref-sciam002_28-0">^</a></b></span> <span><cite id="CITEREFWallich2000">Wallich, Paul (December 2000). <a rel="nofollow" href="https://web.archive.org/web/20061028031127/http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">"Profile: Lynn Conway—Completing the Circuit"</a>. <i>Scientific American</i>. Archived from <a rel="nofollow" href="http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">the original</a> on October 28, 2006<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Profile%3A+Lynn+Conway%E2%80%94Completing+the+Circuit&amp;rft.date=2000-12&amp;rft.aulast=Wallich&amp;rft.aufirst=Paul&amp;rft_id=http%3A%2F%2Fwww.sciamdigital.com%2Findex.cfm%3Ffa%3DProducts.ViewIssuePreview%26ARTICLEID_CHAR%3DD1E5F66F-2A45-4BF9-BE9E-001B49F7F67&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-compworld002-29"><span><b><a href="#cite_ref-compworld002_29-0">^</a></b></span> <span><cite id="CITEREFSmith2007">Smith, Gina (December 3, 2007). <a rel="nofollow" href="https://web.archive.org/web/20081226130335/http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9046420">"Unsung innovators: Lynn Conway and Carver Mead: They literally wrote the book on chip design"</a>. <i>Computerworld</i>. Archived from <a rel="nofollow" href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9046420">the original</a> on December 26, 2008<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computerworld&amp;rft.atitle=Unsung+innovators%3A+Lynn+Conway+and+Carver+Mead%3A+They+literally+wrote+the+book+on+chip+design&amp;rft.date=2007-12-03&amp;rft.aulast=Smith&amp;rft.aufirst=Gina&amp;rft_id=http%3A%2F%2Fwww.computerworld.com%2Faction%2Farticle.do%3Fcommand%3DviewArticleBasic%26articleId%3D9046420&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-30"><span><b><a href="#cite_ref-30">^</a></b></span> <span><cite id="CITEREFMiller2022">Miller, Chris (2022). <i>Chip War: The Fight for the World's Most Critical Technology</i>. Scribner. pp.&nbsp;136–137, 140, 166, 378.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Chip+War%3A+The+Fight+for+the+World%27s+Most+Critical+Technology&amp;rft.pages=136-137%2C+140%2C+166%2C+378&amp;rft.pub=Scribner&amp;rft.date=2022&amp;rft.aulast=Miller&amp;rft.aufirst=Chris&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-31"><span><b><a href="#cite_ref-31">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/InstGuide/InstGuide.pdf"><i>The MIT'78 VLSI System Design Course: A Guidebook for the Instructor of VLSI System Design</i></a>, Lynn Conway, Xerox Palo Alto Research Center, August 12, 1979.</span>
</li>
<li id="cite_note-penfield-32"><span><b><a href="#cite_ref-penfield_32-0">^</a></b></span> <span>Paul Penfield <a rel="nofollow" href="http://issuu.com/miteecs/docs/connector2014_acc15802878d20">"The VLSI Revolution at MIT" by Paul Penfield</a> <i>2014 MIT EECS Connector</i>, Spring 2014, pp. 11–13.</span>
</li>
<li id="cite_note-33"><span><b><a href="#cite_ref-33">^</a></b></span> <span><cite id="CITEREFCarliss_Y._Baldwin_and_Kim_B._Clark2000">Carliss Y. Baldwin and Kim B. Clark (2000). <i>Design Rules: The Power of Modularity</i>. MIT Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-262-02466-7" title="Special:BookSources/0-262-02466-7"><bdi>0-262-02466-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Design+Rules%3A+The+Power+of+Modularity&amp;rft.pub=MIT+Press&amp;rft.date=2000&amp;rft.isbn=0-262-02466-7&amp;rft.au=Carliss+Y.+Baldwin+and+Kim+B.+Clark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-NRC1999-34"><span>^ <a href="#cite_ref-NRC1999_34-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-NRC1999_34-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-NRC1999_34-2"><sup><i><b>c</b></i></sup></a></span> <span>National Research Council (1999), <i>Funding a Revolution: Government Support for Computing Research</i>, National Academy Press (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/FundingaRevolution.html#anchor200964">excerpt</a>)</span>
</li>
<li id="cite_note-35"><span><b><a href="#cite_ref-35">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20240425001048/https://interfaces.che.wisc.edu/lynn-conway/">"Lynn Conway"</a>. <i>Gebbie Lab</i>. January 29, 2024. Archived from <a rel="nofollow" href="https://interfaces.che.wisc.edu/lynn-conway/">the original</a> on April 25, 2024<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Gebbie+Lab&amp;rft.atitle=Lynn+Conway&amp;rft.date=2024-01-29&amp;rft_id=https%3A%2F%2Finterfaces.che.wisc.edu%2Flynn-conway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-36"><span><b><a href="#cite_ref-36">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html">"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service"</a>. <i>ai.eecs.umich.edu</i><span>. Retrieved <span>March 22,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.eecs.umich.edu&amp;rft.atitle=Impact+of+the+Mead-Conway+VLSI+Design+Methodology+and+of+the+MOSIS+Service&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-37"><span><b><a href="#cite_ref-37">^</a></b></span> <span>"The MOSIS Service – More than 50,000 designs in 25 years of operation", <a rel="nofollow" href="http://www.mosis.com/">http://www.mosis.com/</a>, 2008</span>
</li>
<li id="cite_note-38"><span><b><a href="#cite_ref-38">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv.pdf"><i>THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies</i></a>, Lynn Conway, Xerox PARC Technical Report VLSI-81-2, January 19, 1981.</span>
</li>
<li id="cite_note-MPCAdv-39"><span><b><a href="#cite_ref-MPCAdv_39-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv-MM-TEJ.pdf"><i>THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies</i></a>, by Lynn Conway, Microprocessing and Microprogramming – The Euromicro Journal, Vol. 10, No. 4, November 1982, pp 209–228.</span>
</li>
<li id="cite_note-sandtfedfund-40"><span><b><a href="#cite_ref-sandtfedfund_40-0">^</a></b></span> <span><a rel="nofollow" href="http://books.nap.edu/catalog.php?record_id=5040"><i>Allocating Federal Funds for Science and Technology</i></a>, by Committee on Criteria for Federal Support of Research and Development, National Academy of Sciences, National Academy of Engineering, Institute of Medicine, National Research Council, National Academy Press, Washington DC, 1995, page 75.</span>
</li>
<li id="cite_note-sandtfedfundfigureII13-41"><span><b><a href="#cite_ref-sandtfedfundfigureII13_41-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html#Figure.II.13">"<i>Figure II.13: Technological Developments in Computing", in Allocating Federal Funds for Science and Technology, National Academy Press, Washington, DC 1995, page 75.</i>"</a>. Ai.eecs.umich.edu. May 7, 1999<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Figure+II.13%3A+Technological+Developments+in+Computing%22%2C+in+Allocating+Federal+Funds+for+Science+and+Technology%2C+National+Academy+Press%2C+Washington%2C+DC+1995%2C+page+75.&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1999-05-07&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html%23Figure.II.13&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-evolvinghpc-42"><span><b><a href="#cite_ref-evolvinghpc_42-0">^</a></b></span> <span><a rel="nofollow" href="http://www.nap.edu/catalog/4948.html"><i>Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure</i></a>, by Committee to Study High Performance Computing and Communications: Status of a Major Initiative, National Research Council, National Academy Press, Washington DC, 1995, page 20.</span>
</li>
<li id="cite_note-evolvinghpcfig1point2-43"><span><b><a href="#cite_ref-evolvinghpcfig1point2_43-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html#Figure.1.2">"<i>Figure 1.2: Government-sponsored computing research and development stimulates creation of innovative ideas and industries", in Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure, National Academy Press, 1995, page 20.</i>"</a>. Ai.eecs.umich.edu. May 7, 1999<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Figure+1.2%3A+Government-sponsored+computing+research+and+development+stimulates+creation+of+innovative+ideas+and+industries%22%2C+in+Evolving+the+High+Performance+Computing+and+Communications+Initiative+to+Support+the+Nation%27s+Information+Infrastructure%2C+National+Academy+Press%2C+1995%2C+page+20.&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1999-05-07&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html%23Figure.1.2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-44"><span><b><a href="#cite_ref-44">^</a></b></span> <span><cite id="CITEREFFeinstein2023">Feinstein, Jonathan S. (2023). <i>Creativity in Large-Scale Contexts</i>. Stanford University Press. pp.&nbsp;196–199, 266–270, 299–304.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Creativity+in+Large-Scale+Contexts&amp;rft.pages=196-199%2C+266-270%2C+299-304&amp;rft.pub=Stanford+University+Press&amp;rft.date=2023&amp;rft.aulast=Feinstein&amp;rft.aufirst=Jonathan+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-VLSIArchive-45"><span><b><a href="#cite_ref-VLSIArchive_45-0">^</a></b></span> <span><i><a rel="nofollow" href="https://web.archive.org/web/20120509201451/http://www.edn.com/blog/EDA_Graffiti/35566-Guest_blog_Lynn_Conway.php">The VLSI Archive</a></i> <a rel="nofollow" href="https://archive.today/20130208045553/http://www.edn.com/blog/920000692/post/760045076.html">Archived</a> February 8, 2013, at <a href="https://en.wikipedia.org/wiki/Archive.today" title="Archive.today">archive.today</a>, by Lynn Conway, Electronic Design News, June 3, 2009.</span>
</li>
<li id="cite_note-46"><span><b><a href="#cite_ref-46">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/VLSIarchive.html">"VLSI Archive: An online archive of documents and artifacts from the Mead-Conway VLSI design revolution"</a>. Ai.eecs.umich.edu. <a rel="nofollow" href="https://web.archive.org/web/20071208161339/http://ai.eecs.umich.edu/people/conway/VLSI/VLSIarchive.html">Archived</a> from the original on December 8, 2007<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=VLSI+Archive%3A+An+online+archive+of+documents+and+artifacts+from+the+Mead-Conway+VLSI+design+revolution&amp;rft.pub=Ai.eecs.umich.edu&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FVLSIarchive.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-47"><span><b><a href="#cite_ref-47">^</a></b></span> <span><cite id="CITEREFSuchman2021">Suchman, Lucy (March 1, 2021). <a rel="nofollow" href="https://www.4sonline.org/a-sociotechnical-exchange-redux/">"A Sociotechnical Exchange, Redux"</a>. <i>Backchannels | Reflections</i>. <a rel="nofollow" href="https://web.archive.org/web/20210304182920/https://www.4sonline.org/a-sociotechnical-exchange-redux/">Archived</a> from the original on March 4, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Backchannels+%7C+Reflections&amp;rft.atitle=A+Sociotechnical+Exchange%2C+Redux&amp;rft.date=2021-03-01&amp;rft.aulast=Suchman&amp;rft.aufirst=Lucy&amp;rft_id=https%3A%2F%2Fwww.4sonline.org%2Fa-sociotechnical-exchange-redux%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-48"><span><b><a href="#cite_ref-48">^</a></b></span> <span><cite id="CITEREFConwaySuchman2021">Conway, Lynn; Suchman, Lucy (February 28, 2021). <a rel="nofollow" href="https://conwaysuchman-conv.pubpub.org/pub/93808pq4/release/4">"Conway-Suchman conversation"</a>. <i>Conway Suchman Conversation</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Conway+Suchman+Conversation&amp;rft.atitle=Conway-Suchman+conversation&amp;rft.date=2021-02-28&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft.au=Suchman%2C+Lucy&amp;rft_id=https%3A%2F%2Fconwaysuchman-conv.pubpub.org%2Fpub%2F93808pq4%2Frelease%2F4&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-davis-49"><span><b><a href="#cite_ref-davis_49-0">^</a></b></span> <span>Dwight B. Davis <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/CSE/SCI/HighTechnology4-85.pdf">"Assessing the Stragetic Computing Initiative," by Dwight B. Davis</a> <i>High Technology</i>, Vol. 5, No. 4, April 1985.</span>
</li>
<li id="cite_note-Osborn-50"><span>^ <a href="#cite_ref-Osborn_50-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Osborn_50-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFOsborn1983">Osborn, Michelle (June 7, 1983). <a rel="nofollow" href="https://web.archive.org/web/20140420032946/https://ai.eecs.umich.edu/people/conway/Memoirs/DARPA/USA_Today_6-07-83.pdf">"Hi-tech researcher chips in to develop smart computer"</a> <span>(PDF)</span>. USA Today. Archived from <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/DARPA/USA_Today_6-07-83.pdf">the original</a> <span>(PDF)</span> on April 20, 2014<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Hi-tech+researcher+chips+in+to+develop+smart+computer&amp;rft.pub=USA+Today&amp;rft.date=1983-06-07&amp;rft.aulast=Osborn&amp;rft.aufirst=Michelle&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FDARPA%2FUSA_Today_6-07-83.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-emerita-51"><span>^ <a href="#cite_ref-emerita_51-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-emerita_51-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20031205144225/https://ai.eecs.umich.edu/people/conway/Awards/Emerita.html">"Lynn Conway awarded Emerita status at the University of Michigan"</a>. University of Michigan. December 31, 1998. Archived from <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Emerita.html">the original</a> on December 5, 2003<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+awarded+Emerita+status+at+the+University+of+Michigan&amp;rft.pub=University+of+Michigan&amp;rft.date=1998-12-31&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FAwards%2FEmerita.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Streeter2013-52"><span><b><a href="#cite_ref-Streeter2013_52-0">^</a></b></span> <span><a rel="nofollow" href="http://www.uvm.edu/~tstreete/Net_Effect/">"The Net Effect, Romanticism, Capitalism, and the Internet"</a>, Thomas Steeter, New York University Press, 2011, p, 101.</span>
</li>
<li id="cite_note-Neff2013-53"><span><b><a href="#cite_ref-Neff2013_53-0">^</a></b></span> <span><a rel="nofollow" href="http://culturedigitally.org/2013/04/the-net-effect-a-culture-digitally-dialogue/">"On Streeter's The Net Effect: A Culture Digitally Dialogue"</a>, Gina Neff, Mary Gray, and Thomas Streeter, April 25, 2013.</span>
</li>
<li id="cite_note-Lanzerotti2012-54"><span><b><a href="#cite_ref-Lanzerotti2012_54-0">^</a></b></span> <span><cite id="CITEREFLanzerotti2012">Lanzerotti, Mary, ed. (2012). <a rel="nofollow" href="http://www.eecs.umich.edu/eecs/about/articles/2013/VLSI_Reminiscences.pdf">"Editor's Note"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b>. IEEE: 1. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2214274">10.1109/MSSC.2012.2214274</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Editor%27s+Note&amp;rft.volume=4&amp;rft.pages=1&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2214274&amp;rft_id=http%3A%2F%2Fwww.eecs.umich.edu%2Feecs%2Fabout%2Farticles%2F2013%2FVLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-eecsnews2013-55"><span><b><a href="#cite_ref-eecsnews2013_55-0">^</a></b></span> <span><a rel="nofollow" href="http://www.eecs.umich.edu/eecs/about/articles/2013/Conway_VLSI_memoir.html">"Solid-State Circuits Publishes Special Issue with Lynn Conway's Memoir of the VLSI Revolution"</a>, Michigan EECS News, January 31, 2013.</span>
</li>
<li id="cite_note-House2012-56"><span>^ <a href="#cite_ref-House2012_56-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-House2012_56-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-House2012_56-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFHouse2012">House, Chuck (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Commentaries/A_Paradigm_Shift_Was_Happening_by_Chuck_House.pdf">"A Paradigm Shift Was Happening All Around Us"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 32–35. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215759">10.1109/MSSC.2012.2215759</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:8738682">8738682</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=A+Paradigm+Shift+Was+Happening+All+Around+Us&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=32-35&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8738682%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215759&amp;rft.aulast=House&amp;rft.aufirst=Chuck&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FCommentaries%2FA_Paradigm_Shift_Was_Happening_by_Chuck_House.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Sequin2012-57"><span><b><a href="#cite_ref-Sequin2012_57-0">^</a></b></span> <span><cite id="CITEREFSequin2012">Sequin, Carlo (2012). <a rel="nofollow" href="http://www.cs.berkeley.edu/~sequin/PAPERS/2012_SSCM_VLSI.pdf">"Witnessing the Birth of VLSI Design"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 36–39. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215758">10.1109/MSSC.2012.2215758</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:20280958">20280958</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Witnessing+the+Birth+of+VLSI+Design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=36-39&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A20280958%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215758&amp;rft.aulast=Sequin&amp;rft.aufirst=Carlo&amp;rft_id=http%3A%2F%2Fwww.cs.berkeley.edu%2F~sequin%2FPAPERS%2F2012_SSCM_VLSI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Shepard2012-58"><span>^ <a href="#cite_ref-Shepard2012_58-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Shepard2012_58-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFShepard2012">Shepard, Ken (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Commentaries/Covering_by_Ken_Shepard.pdf">"<span></span>"Covering": How We Missed the Inside-Story of the VLSI Revolution"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 40–42. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215757">10.1109/MSSC.2012.2215757</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:25240158">25240158</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=%22Covering%22%3A+How+We+Missed+the+Inside-Story+of+the+VLSI+Revolution&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=40-42&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A25240158%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215757&amp;rft.aulast=Shepard&amp;rft.aufirst=Ken&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FCommentaries%2FCovering_by_Ken_Shepard.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-59"><span><b><a href="#cite_ref-59">^</a></b></span> <span><cite id="CITEREFACM_News2018">ACM News (October 12, 2018). <a rel="nofollow" href="https://cacm.acm.org/news/231829-lynn-conway-and-the-vlsi-revolution-in-microchip-design/fulltext">"Lynn Conway and the VLSI Revolution in Microchip Design"</a>. <i>Communications of the ACM</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Lynn+Conway+and+the+VLSI+Revolution+in+Microchip+Design&amp;rft.date=2018-10-12&amp;rft.au=ACM+News&amp;rft_id=https%3A%2F%2Fcacm.acm.org%2Fnews%2F231829-lynn-conway-and-the-vlsi-revolution-in-microchip-design%2Ffulltext&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-60"><span><b><a href="#cite_ref-60">^</a></b></span> <span><cite id="CITEREFBoulton2024">Boulton, Jim (2024). <i>Lines in the Sand, The Lynn Conway Story (Unsung Heroes of the Information Age)</i>. Unsung Heroes (published February 21, 2024). <a href="https://en.wikipedia.org/wiki/ASIN_(identifier)" title="ASIN (identifier)">ASIN</a>&nbsp;<a rel="nofollow" href="https://www.amazon.com/dp/B0CW1LNGFD">B0CW1LNGFD</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Lines+in+the+Sand%2C+The+Lynn+Conway+Story+%28Unsung+Heroes+of+the+Information+Age%29&amp;rft.pub=Unsung+Heroes&amp;rft.date=2024&amp;rft_id=https%3A%2F%2Fwww.amazon.com%2Fdp%2FB0CW1LNGFD%23id-name%3DASIN&amp;rft.aulast=Boulton&amp;rft.aufirst=Jim&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-61"><span><b><a href="#cite_ref-61">^</a></b></span> <span><cite id="CITEREFThe_Centre_for_Computing_History2024">The Centre for Computing History (April 26, 2024). <a rel="nofollow" href="https://www.youtube.com/watch?v=mw2jAZmnIqU"><i>Lynn Conway - If you want to change the future, start living as if you're already there</i></a><span>. Retrieved <span>June 6,</span> 2024</span> – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+-+If+you+want+to+change+the+future%2C+start+living+as+if+you%27re+already+there&amp;rft.date=2024-04-26&amp;rft.au=The+Centre+for+Computing+History&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dmw2jAZmnIqU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-BD06LC-62"><span>^ <a href="#cite_ref-BD06LC_62-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-BD06LC_62-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-BD06LC_62-2"><sup><i><b>c</b></i></sup></a></span> <span><a rel="nofollow" href="http://www.logoonline.com/shows/dyn/beautiful_daughters/personality.jhtml?personalityId=6829">"Beautiful Daughters Cast: Lynn Conway"</a>, LOGO Channel, 2006</span>
</li>
<li id="cite_note-ED03a-63"><span><b><a href="#cite_ref-ED03a_63-0">^</a></b></span> <span><a rel="nofollow" href="http://electronicdesign.com/Articles/Index.cfm?ArticleID=5836&amp;pg=3">"Class Notes: 2002 Inductees: Here's how many of our 2002 Hall Of Famers enjoy their leisure time and how they still give back to society"</a> <a rel="nofollow" href="https://web.archive.org/web/20081003000938/http://electronicdesign.com/Articles/Index.cfm?ArticleID=5836&amp;pg=3">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Doris Kilbane, Electronic Design, October 20, 2003.</span>
</li>
<li id="cite_note-ASEEPrismOct2011-64"><span><b><a href="#cite_ref-ASEEPrismOct2011_64-0">^</a></b></span> <span><a rel="nofollow" href="http://www.prism-magazine.org/oct11/feature_03.cfm">"Secrets Are Out: Lesbian, gay, bisexual, and transgender engineers are no longer willing to hide their true selves"</a> Jaimie Schock, Prism Magazine, American Society of Engineering Education, October 2011, pp. 44–47.</span>
</li>
<li id="cite_note-65"><span><b><a href="#cite_ref-65">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/conway.html">"Lynn Conway's homepage"</a>. <i>Ai.eecs.umich.edu</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Lynn+Conway%27s+homepage&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2Fconway.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-translation-66"><span><b><a href="#cite_ref-translation_66-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/conway-Translation%20status.htm">"Status of translations of Lynn's webpages, 12-10-13"</a>. December 10, 2013<span>. Retrieved <span>December 23,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Status+of+translations+of+Lynn%27s+webpages%2C+12-10-13&amp;rft.date=2013-12-10&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2Fconway-Translation%2520status.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-67"><span><b><a href="#cite_ref-67">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TSsuccesses/TSsuccesses.html">"Transsexual Women's Successes"</a>. <i>Ai.eecs.umich.edu</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Transsexual+Women%27s+Successes&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTSsuccesses%2FTSsuccesses.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-prevalence-68"><span><b><a href="#cite_ref-prevalence_68-0">^</a></b></span> <span>Olyslager F, Conway L (2008). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Prevalence/TvG_Paper/Transsexualism_is_more_common_than_you_think.pdf">Transseksualiteit komt vaker voor dan u denkt [Transsexualism is more common than you think].</a> <i>Tijdschrift voor Genderstudies</i>, Vol. 11, no. 2, pp. 39–51, 2008. (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Prevalence/TvG_Paper/Summaries-English.pdf">abstract in English</a>)</span>
</li>
<li id="cite_note-HRCProfile-69"><span><b><a href="#cite_ref-HRCProfile_69-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20131103234020/http://www.hrc.org/issues/3469.htm">"<span></span>"Profile: Lynn Conway," Human Rights Campaign (HRC) website"</a>. HRC. Archived from <a rel="nofollow" href="http://www.hrc.org/issues/3469.htm">the original</a> on November 3, 2013<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%22Profile%3A+Lynn+Conway%2C%22+Human+Rights+Campaign+%28HRC%29+website&amp;rft.pub=HRC&amp;rft_id=http%3A%2F%2Fwww.hrc.org%2Fissues%2F3469.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-LGBTHistoryMonthProfile-70"><span><b><a href="#cite_ref-LGBTHistoryMonthProfile_70-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20140406095129/http://www.lgbthistorymonth.org.uk/history/lynnconway.htm">"Biographies of famous LGBT people: Science: Professor Lynn Conway, Lesbian Gay Bisexual Trans History Month website"</a>. Lgbthistorymonth.org.uk. Archived from <a rel="nofollow" href="http://www.lgbthistorymonth.org.uk/history/lynnconway.htm">the original</a> on April 6, 2014<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Biographies+of+famous+LGBT+people%3A+Science%3A+Professor+Lynn+Conway%2C+Lesbian+Gay+Bisexual+Trans+History+Month+website&amp;rft.pub=Lgbthistorymonth.org.uk&amp;rft_id=http%3A%2F%2Fwww.lgbthistorymonth.org.uk%2Fhistory%2Flynnconway.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-HP01-71"><span><b><a href="#cite_ref-HP01_71-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/HP/HP.html">"Embracing Diversity – HP employees in Fort Collins, Colorado, welcome Dr. Lynn Conway"</a>, hpNOW, February 8, 2001.</span>
</li>
<li id="cite_note-FCC01-72"><span><b><a href="#cite_ref-FCC01_72-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/ColoradoanArticle/HP-CSU-lynncon.html">"Computer pioneer speaks from the heart about diversity: Transsexual talks at HP, CSU"</a>, by Kate Forgach, Fort Collins Coloradoan, January 26, 2001.</span>
</li>
<li id="cite_note-Adv01-73"><span><b><a href="#cite_ref-Adv01_73-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Advocate/Advocate.html">"Chipping Away at Prejudice"</a>, by Sarah Wildman, The Advocate, March 13, 2001.</span>
</li>
<li id="cite_note-Intel03-74"><span><b><a href="#cite_ref-Intel03_74-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Intel/iglobe.htm">"What's pride got to do with it?"</a>, by Teri Warner, Employee Communications, Circuit for Employees@Intel, July 1, 2003.</span>
</li>
<li id="cite_note-PT03-75"><span><b><a href="#cite_ref-PT03_75-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/PersonnelToday/PersonnelToday_com%20-%20Why%20HR%20should%20wake%20up%20to%20the%20needs%20of%20transsexual%20employees.htm">"Why HR should wake up to the needs of transsexual employees"</a>, by Christine Burns, Personnel Today, November 18, 2003.</span>
</li>
<li id="cite_note-76"><span><b><a href="#cite_ref-76">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/O&amp;E/Raytheon/Raytheon%20Adds%20GI&amp;E.html">"Professor Lynn Conway, Guest at Out &amp; Equal"</a>. <i>Ai.eecs.umich.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Professor+Lynn+Conway%2C+Guest+at+Out+%26+Equal&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FO%26E%2FRaytheon%2FRaytheon%2520Adds%2520GI%26E.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-77"><span><b><a href="#cite_ref-77">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.queerty.com/dr-kenneth-zuckers-war-on-transgenders-20090206/">"Dr. Kenneth Zucker's War on Transgenders"</a>. Queerty. February 6, 2009.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Dr.+Kenneth+Zucker%27s+War+on+Transgenders&amp;rft.date=2009-02-06&amp;rft_id=http%3A%2F%2Fwww.queerty.com%2Fdr-kenneth-zuckers-war-on-transgenders-20090206%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-78"><span><b><a href="#cite_ref-78">^</a></b></span> <span><cite id="CITEREFAntoine2009"><a href="https://en.wikipedia.org/wiki/Chagmion_Antoine" title="Chagmion Antoine">Antoine, Chagmion</a> (March 6, 2009). <a rel="nofollow" href="https://www.youtube.com/watch?v=JBRCo1KDX_o">"Transgender Crusader – A professor at the University of Michigan is taking on the psychiatric community's ideas about transgendered people and mental illness"</a>. CBS News / YouTube. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/JBRCo1KDX_o">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Transgender+Crusader+%E2%80%93+A+professor+at+the+University+of+Michigan+is+taking+on+the+psychiatric+community%27s+ideas+about+transgendered+people+and+mental+illness&amp;rft.date=2009-03-06&amp;rft.aulast=Antoine&amp;rft.aufirst=Chagmion&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJBRCo1KDX_o&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-carey-79"><span>^ <a href="#cite_ref-carey_79-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-carey_79-1"><sup><i><b>b</b></i></sup></a></span> <span>
<cite id="CITEREFCarey2007">Carey, Benedict (August 21, 2007). <a rel="nofollow" href="https://www.nytimes.com/2007/08/21/health/psychology/21gender.html?ei=5124&amp;en=0c11623b4c191f82&amp;ex=1345348800&amp;partner=permalink&amp;exprod=permalink&amp;pagewanted=all">"Criticism of a Gender Theory, and a Scientist Under Siege"</a>. <i>New York Times</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+York+Times&amp;rft.atitle=Criticism+of+a+Gender+Theory%2C+and+a+Scientist+Under+Siege&amp;rft.date=2007-08-21&amp;rft.aulast=Carey&amp;rft.aufirst=Benedict&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2007%2F08%2F21%2Fhealth%2Fpsychology%2F21gender.html%3Fei%3D5124%26en%3D0c11623b4c191f82%26ex%3D1345348800%26partner%3Dpermalink%26exprod%3Dpermalink%26pagewanted%3Dall&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-dreger2008-80"><span><b><a href="#cite_ref-dreger2008_80-0">^</a></b></span> <span><cite id="CITEREFDreger2008">Dreger, A. D. (2008). <a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3170124">"The controversy surrounding <i>The man who would be queen:</i> A case history of the politics of science, identity, and sex in the Internet age"</a>. <i>Archives of Sexual Behavior</i>. <b>37</b> (3): 366–421. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1007%2Fs10508-007-9301-1">10.1007/s10508-007-9301-1</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3170124">3170124</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/18431641">18431641</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Archives+of+Sexual+Behavior&amp;rft.atitle=The+controversy+surrounding+The+man+who+would+be+queen%3A+A+case+history+of+the+politics+of+science%2C+identity%2C+and+sex+in+the+Internet+age&amp;rft.volume=37&amp;rft.issue=3&amp;rft.pages=366-421&amp;rft.date=2008&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3170124%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F18431641&amp;rft_id=info%3Adoi%2F10.1007%2Fs10508-007-9301-1&amp;rft.aulast=Dreger&amp;rft.aufirst=A.+D.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3170124&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-81"><span><b><a href="#cite_ref-81">^</a></b></span> <span><cite id="CITEREFConway2003">Conway, Lynn (July 16, 2003). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/ShockingPublicity.html">"Shockingly defamatory official publicity by the US National Academies for Bailey's book"</a>. <i>lynnconway.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lynnconway.com&amp;rft.atitle=Shockingly+defamatory+official+publicity+by+the+US+National+Academies+for+Bailey%27s+book&amp;rft.date=2003-07-16&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FShockingPublicity.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-82"><span><b><a href="#cite_ref-82">^</a></b></span> <span><cite id="CITEREFDreger2015">Dreger, Alice (March 10, 2015). <a rel="nofollow" href="https://www.penguinrandomhouse.com/books/316214/galileos-middle-finger-by-alice-dreger/">"Galileo's Middle Finger: Heretics, Activists, and One Scholar's Search for Justice"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Galileo%27s+Middle+Finger%3A+Heretics%2C+Activists%2C+and+One+Scholar%27s+Search+for+Justice&amp;rft.date=2015-03-10&amp;rft.aulast=Dreger&amp;rft.aufirst=Alice&amp;rft_id=https%3A%2F%2Fwww.penguinrandomhouse.com%2Fbooks%2F316214%2Fgalileos-middle-finger-by-alice-dreger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-83"><span><b><a href="#cite_ref-83">^</a></b></span> <span><cite id="CITEREFConway2008">Conway, Lynn (June 18, 2008). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Dreger/ASB%20paper/PeerCommentaries/Peer_Papers_Critical_of_Dreger.html">"Dreger's Defense of J. Michael Bailey: The Peer Commentary Papers Tear It Apart"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Dreger%27s+Defense+of+J.+Michael+Bailey%3A+The+Peer+Commentary+Papers+Tear+It+Apart&amp;rft.date=2008-06-18&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FDreger%2FASB%2520paper%2FPeerCommentaries%2FPeer_Papers_Critical_of_Dreger.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-VD04-84"><span><b><a href="#cite_ref-VD04_84-0">^</a></b></span> <span><a rel="nofollow" href="http://www.deepstealth.com/vday/">VDay LA 2004 Commemorative Page</a>, DeepStealth Productions, Los Angeles California, 2004.</span>
</li>
<li id="cite_note-BD06-85"><span><b><a href="#cite_ref-BD06_85-0">^</a></b></span> <span><a rel="nofollow" href="http://www.logoonline.com/shows/dyn/beautiful_daughters/series.jhtml">"Beautiful Daughters"</a>, a documentary by Josh Aronson and Ariel Orr Jordan, LOGO Channel, 2006.</span>
</li>
<li id="cite_note-trans40-86"><span>^ <a href="#cite_ref-trans40_86-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-trans40_86-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20090615170758/http://www.impcourt.org/Trans40/LynnConway.htm">"Trans Hero: Lynn Conway"</a>. <i>Stonewall 40: Trans Heroes</i>. International Court System. 2009. Archived from <a rel="nofollow" href="http://www.impcourt.org/Trans40/LynnConway.htm">the original</a> on June 15, 2009<span>. Retrieved <span>June 14,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Stonewall+40%3A+Trans+Heroes&amp;rft.atitle=Trans+Hero%3A+Lynn+Conway&amp;rft.date=2009&amp;rft_id=http%3A%2F%2Fwww.impcourt.org%2FTrans40%2FLynnConway.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ngltf-87"><span>^ <a href="#cite_ref-ngltf_87-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ngltf_87-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20090930181348/http://www.commondreams.org/newswire/2009/06/10-17">"Recognizing Outstanding Transgender and Gender-Nonconforming Individuals in the Struggle for LGBT Equality"</a>. National Gay and Lesbian Task Force. June 10, 2009. Archived from <a rel="nofollow" href="http://www.commondreams.org/newswire/2009/06/10-17">the original</a> on September 30, 2009<span>. Retrieved <span>June 14,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Recognizing+Outstanding+Transgender+and+Gender-Nonconforming+Individuals+in+the+Struggle+for+LGBT+Equality&amp;rft.pub=National+Gay+and+Lesbian+Task+Force&amp;rft.date=2009-06-10&amp;rft_id=http%3A%2F%2Fwww.commondreams.org%2Fnewswire%2F2009%2F06%2F10-17&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Beyer2014-88"><span><b><a href="#cite_ref-Beyer2014_88-0">^</a></b></span> <span><cite id="CITEREFBeyer2014">Beyer, Dana (January 8, 2014). <a rel="nofollow" href="http://www.huffingtonpost.com/dana-beyer/leadership-and-the-value-of-exceptional-allies_b_4543460.html">"Leadership and the Value of Exceptional Allies"</a>. <i>Huffington Post</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Huffington+Post&amp;rft.atitle=Leadership+and+the+Value+of+Exceptional+Allies&amp;rft.date=2014-01-08&amp;rft.aulast=Beyer&amp;rft.aufirst=Dana&amp;rft_id=http%3A%2F%2Fwww.huffingtonpost.com%2Fdana-beyer%2Fleadership-and-the-value-of-exceptional-allies_b_4543460.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ieeeglance-89"><span><b><a href="#cite_ref-ieeeglance_89-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/about/today/at_a_glance.html">"IEEE at a Glace"</a>. IEEE.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+at+a+Glace&amp;rft.pub=IEEE&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fabout%2Ftoday%2Fat_a_glance.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ieeeethics-90"><span><b><a href="#cite_ref-ieeeethics_90-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/about/corporate/governance/p7-8.html">"IEEE Code of Ethics"</a>. IEEE.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+Code+of+Ethics&amp;rft.pub=IEEE&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fabout%2Fcorporate%2Fgovernance%2Fp7-8.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-McCarty2014-91"><span><b><a href="#cite_ref-McCarty2014_91-0">^</a></b></span> <span><cite id="CITEREFMcCarty2014">McCarty, Maureen (January 13, 2014). <a rel="nofollow" href="https://web.archive.org/web/20140201162715/http://www.hrc.org/blog/entry/the-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive">"The Institute of Electrical and Electronic Engineers Adopts LGBT-Inclusive Code of Ethics"</a>. HRC. Archived from <a rel="nofollow" href="http://www.hrc.org/blog/entry/the-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive">the original</a> on February 1, 2014<span>. Retrieved <span>January 17,</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Institute+of+Electrical+and+Electronic+Engineers+Adopts+LGBT-Inclusive+Code+of+Ethics&amp;rft.pub=HRC&amp;rft.date=2014-01-13&amp;rft.aulast=McCarty&amp;rft.aufirst=Maureen&amp;rft_id=http%3A%2F%2Fwww.hrc.org%2Fblog%2Fentry%2Fthe-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-2015trans100-92"><span><b><a href="#cite_ref-2015trans100_92-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://thetrans100.com/">"The 2015 Trans 100"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+2015+Trans+100&amp;rft_id=http%3A%2F%2Fthetrans100.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-93"><span><b><a href="#cite_ref-93">^</a></b></span> <span><cite id="CITEREFTaylor2020">Taylor, Evan (February 4, 2020). <a rel="nofollow" href="https://vimeo.com/501793564">"Trans Activism Oral History Project - Lynn Conway Full Interview"</a>. <i>The ArQuives</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+ArQuives&amp;rft.atitle=Trans+Activism+Oral+History+Project+-+Lynn+Conway+Full+Interview&amp;rft.date=2020-02-04&amp;rft.aulast=Taylor&amp;rft.aufirst=Evan&amp;rft_id=https%3A%2F%2Fvimeo.com%2F501793564&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Forman2013-94"><span><b><a href="#cite_ref-Forman2013_94-0">^</a></b></span> <span>Forman, Ross (September 18, 2013) <a rel="nofollow" href="http://www.windycitymediagroup.com/ARTICLE.php?AID=44404">"Transgender pioneer reflects on sports past"</a>. Windy City Times.</span>
</li>
<li id="cite_note-95"><span><b><a href="#cite_ref-95">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/MackinacIsland/MackinacIsland.html">"A Wedding Trip to Mackinac Island"</a>. 2002. <a rel="nofollow" href="https://web.archive.org/web/20020928000028/http://ai.eecs.umich.edu/people/conway/MackinacIsland/MackinacIsland.html">Archived</a> from the original on September 28, 2002.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Wedding+Trip+to+Mackinac+Island&amp;rft.date=2002&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMackinacIsland%2FMackinacIsland.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-moore2014-96"><span><b><a href="#cite_ref-moore2014_96-0">^</a></b></span> <span>Nicole Casal Moore,"<a rel="nofollow" href="http://dme.engin.umich.edu/lynnconway/">Life, Engineered: How Lynn Conway reinvented her world and ours</a> <a rel="nofollow" href="https://web.archive.org/web/20180106181053/http://dme.engin.umich.edu/lynnconway/">Archived</a> January 6, 2018, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>," <i>The Michigan Engineer</i>, College of Engineering, University of Michigan, Fall 2014, pp. 42–49.</span>
</li>
<li id="cite_note-Szczepanski2014-97"><span><b><a href="#cite_ref-Szczepanski2014_97-0">^</a></b></span> <span>Marcin Szczepanski and Evan Dougherty,"<a rel="nofollow" href="https://www.youtube.com/watch?v=7kJ-N54cQu4">A Place to Be Wild</a>," <i>Michigan Engineering</i>, October 8, 2014.</span>
</li>
<li id="cite_note-98"><span><b><a href="#cite_ref-98">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Electronics/ElectAchiev.html">"The 1981 Achievement Award – Lynn Conway, Carver Mead"</a> by Martin Marshall, Larry Waller, and Howard Wolff, <i>Electronics</i>, October 20, 1981</span>
</li>
<li id="cite_note-99"><span><b><a href="#cite_ref-99">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20080705051810/http://www.seas.upenn.edu/pubs/pender-award.html">"Penn Engineering: The Harold Pender Award"</a>. Archived from <a rel="nofollow" href="http://www.seas.upenn.edu/pubs/pender-award.html">the original</a> on July 5, 2008.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Penn+Engineering%3A+The+Harold+Pender+Award&amp;rft_id=http%3A%2F%2Fwww.seas.upenn.edu%2Fpubs%2Fpender-award.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-100"><span><b><a href="#cite_ref-100">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/web/education/awards/past_recipients.html">"IEEE EAB Major Educational Innovation Award, 1984"</a>. Ieee.org<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+EAB+Major+Educational+Innovation+Award%2C+1984&amp;rft.pub=Ieee.org&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fweb%2Feducation%2Fawards%2Fpast_recipients.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-101"><span><b><a href="#cite_ref-101">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/web/membership/fellows/Alphabetical/cfellows.html">"Services Update"</a>. <i>Ieee.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ieee.org&amp;rft.atitle=Services+Update&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fweb%2Fmembership%2Ffellows%2FAlphabetical%2Fcfellows.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-102"><span><b><a href="#cite_ref-102">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/FranklinInstitute/PhysToday/PhysToday7-85.pdf">"Franklin Institute honors eight physicists"</a>, <i>Physics Today</i>, July 1985.</span>
</li>
<li id="cite_note-SecMAA-103"><span><b><a href="#cite_ref-SecMAA_103-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Mementos_of_Lynn's_awards.html#SecDef">"Secretary of Defense Meritorious Achievement Award, May 1985"</a>, <i>Meritorious Service Award</i>, May 1985.</span>
</li>
<li id="cite_note-104"><span><b><a href="#cite_ref-104">^</a></b></span> <span><a rel="nofollow" href="http://www.nae.edu/nae/naepub.nsf/MembersSec?OpenForm&amp;05,M,1">NAE Member Directory, Section 05.</a> <a rel="nofollow" href="https://web.archive.org/web/20081004111411/http://www.nae.edu/nae/naepub.nsf/MembersSec?OpenForm&amp;05,M,1">Archived</a> October 4, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (year from <a rel="nofollow" href="https://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">The White House Office of the Press Secretary</a> <a rel="nofollow" href="https://web.archive.org/web/20081003143127/http://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>)</span>
</li>
<li id="cite_note-105"><span><b><a href="#cite_ref-105">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20120216084307/http://societyofwomenengineers.swe.org/index.php?option=com_content&amp;task=view&amp;id=657&amp;Itemid=42">"Society of Women Engineers: Achievement Award Winners"</a>. Archived from <a rel="nofollow" href="http://societyofwomenengineers.swe.org/index.php?option=com_content&amp;task=view&amp;id=657&amp;Itemid=42">the original</a> on February 16, 2012.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Society+of+Women+Engineers%3A+Achievement+Award+Winners.&amp;rft_id=http%3A%2F%2Fsocietyofwomenengineers.swe.org%2Findex.php%3Foption%3Dcom_content%26task%3Dview%26id%3D657%26Itemid%3D42&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-106"><span><b><a href="#cite_ref-106">^</a></b></span> <span><a rel="nofollow" href="https://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">President Clinton Names Lynn Conway to the Air Force Academy Board of Visitors"</a> <a rel="nofollow" href="https://web.archive.org/web/20081003143127/http://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, The White House Office of the Press Secretary, January 31, 1996.</span>
</li>
<li id="cite_note-107"><span><b><a href="#cite_ref-107">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20020615003757/http://lor.trincoll.edu/info/pub_college/reporter/winter98/engineer.htm">"100 years of engineering excellence"</a>. Archived from the original on June 15, 2002<span>. Retrieved <span>August 17,</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=100+years+of+engineering+excellence&amp;rft_id=http%3A%2F%2Flor.trincoll.edu%2Finfo%2Fpub_college%2Freporter%2Fwinter98%2Fengineer.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: bot: original URL status unknown (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_bot:_original_URL_status_unknown" title="Category:CS1 maint: bot: original URL status unknown">link</a>)</span>, Trinity Reporter, Trinity College, Hartford, CN, Winter 98.</span>
</li>
<li id="cite_note-108"><span><b><a href="#cite_ref-108">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/ElectronicDesign/ED%20Hall%20of%20Fame%202002.pdf">"Electronic Design Hall of Fame – 2002 Inductees"</a>, <i>Electronic Design</i>, October 21, 2002.</span>
</li>
<li id="cite_note-109"><span><b><a href="#cite_ref-109">^</a></b></span> <span><a rel="nofollow" href="http://www.noglstp.org/2005awards.html">"NOGLSTP to Honor Aberson, Conway, and Raytheon at Awards Ceremony in February"</a> <a rel="nofollow" href="https://web.archive.org/web/20081002215806/http://www.noglstp.org/2005awards.html">Archived</a> October 2, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Press Release, National Organization of Gay and Lesbian Scientists and Technical Professionals, January 25, 2005.</span>
</li>
<li id="cite_note-110"><span><b><a href="#cite_ref-110">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20131210085427/http://www.draper.com/members.html">"The Charles Stark Draper Laboratory, Members of the Corporation"</a>. Draper.com. Archived from <a rel="nofollow" href="http://www.draper.com/members.html">the original</a> on December 10, 2013<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Charles+Stark+Draper+Laboratory%2C+Members+of+the+Corporation&amp;rft.pub=Draper.com&amp;rft_id=http%3A%2F%2Fwww.draper.com%2Fmembers.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-111"><span><b><a href="#cite_ref-111">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20160703014527/http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">"<span></span>"Lynn Conway: 2014 Fellow", Computer History Museum, 2014 Fellow Awards"</a>. <i>Computerhistory.org</i>. Archived from <a rel="nofollow" href="http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">the original</a> on July 3, 2016<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computerhistory.org&amp;rft.atitle=%22Lynn+Conway%3A+2014+Fellow%22%2C+Computer+History+Museum%2C+2014+Fellow+Awards&amp;rft_id=http%3A%2F%2Fwww.computerhistory.org%2Ffellowawards%2Fhall%2Fbios%2FLynn%2CConway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-112"><span><b><a href="#cite_ref-112">^</a></b></span> <span><cite id="CITEREFComputer_History_Museum2014">Computer History Museum (May 29, 2014). <a rel="nofollow" href="https://www.youtube.com/watch?v=m93bvIiCL-c">"Computer History Museum 2014 Fellow Lynn Conway"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/m93bvIiCL-c">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Computer+History+Museum+2014+Fellow+Lynn+Conway&amp;rft.pub=YouTube&amp;rft.date=2014-05-29&amp;rft.au=Computer+History+Museum&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dm93bvIiCL-c&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-113"><span><b><a href="#cite_ref-113">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/CHM/Talk/What_Words_Can_We_Leave_to_Guide_Them.pdf">"<span></span>"Lynn Conway: Fellow Award Acceptance Speech", Computer History Museum, April 26, 2014"</a> <span>(PDF)</span>. <i>Ai.eecs.umich.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=%22Lynn+Conway%3A+Fellow+Award+Acceptance+Speech%22%2C+Computer+History+Museum%2C+April+26%2C+2014&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FAwards%2FCHM%2FTalk%2FWhat_Words_Can_We_Leave_to_Guide_Them.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-114"><span><b><a href="#cite_ref-114">^</a></b></span> <span><cite id="CITEREFComputer_History_Museum2014">Computer History Museum (May 20, 2014). <a rel="nofollow" href="https://www.youtube.com/watch?v=d0mBjP-gBik">"2014 Fellow Lynn Conway"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/d0mBjP-gBik">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=2014+Fellow+Lynn+Conway&amp;rft.pub=YouTube&amp;rft.date=2014-05-20&amp;rft.au=Computer+History+Museum&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dd0mBjP-gBik&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-115"><span><b><a href="#cite_ref-115">^</a></b></span> <span><cite><a rel="nofollow" href="http://archive.computerhistory.org/resources/access/text/2014/05/102746864-05-01-acc.pdf">"Oral History of Lynn Conway"</a> <span>(PDF)</span>. <a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a>. February 24, 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Oral+History+of+Lynn+Conway&amp;rft.pub=Computer+History+Museum&amp;rft.date=2014-02-24&amp;rft_id=http%3A%2F%2Farchive.computerhistory.org%2Fresources%2Faccess%2Ftext%2F2014%2F05%2F102746864-05-01-acc.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-116"><span><b><a href="#cite_ref-116">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20170701145358/http://www.engin.umich.edu/college/about/news/stories/2014/april/thank-lynn-conway-for-your-cell-phone">"<span></span>"Thank Lynn Conway for your cell phone" by Nicole Casal Moore, Michigan Engineering, 2014-04-24"</a>. <i>Engin.umich.edu</i>. Archived from <a rel="nofollow" href="http://www.engin.umich.edu/college/about/news/stories/2014/april/thank-lynn-conway-for-your-cell-phone">the original</a> on July 1, 2017<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Engin.umich.edu&amp;rft.atitle=%22Thank+Lynn+Conway+for+your+cell+phone%22+by+Nicole+Casal+Moore%2C+Michigan+Engineering%2C+2014-04-24&amp;rft_id=http%3A%2F%2Fwww.engin.umich.edu%2Fcollege%2Fabout%2Fnews%2Fstories%2F2014%2Fapril%2Fthank-lynn-conway-for-your-cell-phone&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-117"><span><b><a href="#cite_ref-117">^</a></b></span> <span><a rel="nofollow" href="http://www.iit.edu/news/iittoday/?p=31501">"Illinois Institute of Technology, ITT Commencement"</a>, May 17, 2014.</span>
</li>
<li id="cite_note-118"><span><b><a href="#cite_ref-118">^</a></b></span> <span><cite><a rel="nofollow" href="http://muse.union.edu/ece/steinmetz-memorial-lecture/">"Electrical &amp; Computer Engineering ‹&nbsp;Log In"</a>. <i>Muse.union.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Muse.union.edu&amp;rft.atitle=Electrical+%26+Computer+Engineering+%E2%80%B9+Log+In&amp;rft_id=http%3A%2F%2Fmuse.union.edu%2Fece%2Fsteinmetz-memorial-lecture%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-119"><span><b><a href="#cite_ref-119">^</a></b></span> <span><cite id="CITEREFGregg_Millett2015">Gregg Millett (March 17, 2015). <a rel="nofollow" href="https://www.youtube.com/watch?v=vrB0NpiU1bo">"Steinmetz Memorial Lecture on Schenectady Today"</a>. <i>Muse.union.de</i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/vrB0NpiU1bo">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span> – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Muse.union.de&amp;rft.atitle=Steinmetz+Memorial+Lecture+on+Schenectady+Today&amp;rft.date=2015-03-17&amp;rft.au=Gregg+Millett&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvrB0NpiU1bo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-120"><span><b><a href="#cite_ref-120">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.union.edu/news/stories/2015/04/prominent-woman-engineer-to-headline-steinmetz-memorial-lecture.php">"Technology innovator to headline Steinmetz Memorial Lecture"</a>. <i>Union.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Union.edu&amp;rft.atitle=Technology+innovator+to+headline+Steinmetz+Memorial+Lecture&amp;rft_id=http%3A%2F%2Fwww.union.edu%2Fnews%2Fstories%2F2015%2F04%2Fprominent-woman-engineer-to-headline-steinmetz-memorial-lecture.php&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-121"><span><b><a href="#cite_ref-121">^</a></b></span> <span><cite><a rel="nofollow" href="http://sites.ieee.org/schenectady/files/2012/05/2015_Steinmetz_Lecture_by_Lynn_Conway.pdf">"<span></span>"IEEE Online (Slideshow): Our Travels Through Time: Envisioning Historical Waves of Technological Innovation", The 2015 Steinmetz Memorial Lecture by Lynn Conway, Union College, Apr 21, 2015"</a> <span>(PDF)</span>. <i>Sites.ieee.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Sites.ieee.org&amp;rft.atitle=%22IEEE+Online+%28Slideshow%29%3A+Our+Travels+Through+Time%3A+Envisioning+Historical+Waves+of+Technological+Innovation%22%2C+The+2015+Steinmetz+Memorial+Lecture+by+Lynn+Conway%2C+Union+College%2C+Apr+21%2C+2015&amp;rft_id=http%3A%2F%2Fsites.ieee.org%2Fschenectady%2Ffiles%2F2012%2F05%2F2015_Steinmetz_Lecture_by_Lynn_Conway.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-122"><span><b><a href="#cite_ref-122">^</a></b></span> <span><cite><a rel="nofollow" href="https://ny6mediashare.ensemblevideo.com/app/sites/index.aspx?destinationID=1JvzXqjt10qf5DOB2sKxBQ&amp;contentID=v3vM-7uVukayYz_pRLVZgg">"Steinmetz Memorial Lecture"</a>. <i>Ny6mediashare.ensemblevideo.com</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ny6mediashare.ensemblevideo.com&amp;rft.atitle=Steinmetz+Memorial+Lecture&amp;rft_id=https%3A%2F%2Fny6mediashare.ensemblevideo.com%2Fapp%2Fsites%2Findex.aspx%3FdestinationID%3D1JvzXqjt10qf5DOB2sKxBQ%26contentID%3Dv3vM-7uVukayYz_pRLVZgg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-123"><span><b><a href="#cite_ref-123">^</a></b></span> <span><a rel="nofollow" href="http://www.ieee.org/about/awards/medals/maxwell.html">"IEEE/RSE James Clerk Maxwell Medal"</a>, December 2014.</span>
</li>
<li id="cite_note-124"><span><b><a href="#cite_ref-124">^</a></b></span> <span><a rel="nofollow" href="http://www.engin.umich.edu/college/about/news/stories/2014/december/lynn-conway-to-receive-award">"Lynn Conway to receive 2015 IEEE/RSE James Clerk Maxwell Medal"</a> <a rel="nofollow" href="https://web.archive.org/web/20150402103451/http://www.engin.umich.edu/college/about/news/stories/2014/december/lynn-conway-to-receive-award">Archived</a> April 2, 2015, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Michigan Engineering News, December 15, 2014.</span>
</li>
<li id="cite_note-125"><span><b><a href="#cite_ref-125">^</a></b></span> <span><a rel="nofollow" href="https://ieeetv.ieee.org/history/2015-ieee-honors-ieee-rse-james-clerk-maxwell-medal-lynn-conway">"2015 IEEE Honors: IEEE-RSE James Clerk Maxwell Medal – Lynn Conway"</a>, IEEE TV, July 2, 2015.</span>
</li>
<li id="cite_note-126"><span><b><a href="#cite_ref-126">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=bw2mPAp4XGk">"IEEE/RSE 2015 James Clerk Maxwell Medal Ceremony and Lecture – Professor Lynn Conway"</a>. IEEE-TV. November 12, 2015.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IEEE%2FRSE+2015+James+Clerk+Maxwell+Medal+Ceremony+and+Lecture+%E2%80%93+Professor+Lynn+Conway&amp;rft.date=2015-11-12&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dbw2mPAp4XGk&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-127"><span><b><a href="#cite_ref-127">^</a></b></span> <span><cite id="CITEREFConway2015">Conway, Lynn (November 12, 2015), <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/2015_RSE_Lecture_by_Lynn_Conway.pptx">"Our travels through time: envisioning historical waves of technological innovation"</a>, <i>IEEE/RSE James Clerk Maxwell Medal Lecture</i>, Royal Society of Edinburgh</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Our+travels+through+time%3A+envisioning+historical+waves+of+technological+innovation&amp;rft.btitle=IEEE%2FRSE+James+Clerk+Maxwell+Medal+Lecture&amp;rft.pub=Royal+Society+of+Edinburgh&amp;rft.date=2015-11-12&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2F2015_RSE_Lecture_by_Lynn_Conway.pptx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-128"><span><b><a href="#cite_ref-128">^</a></b></span> <span><cite id="CITEREFShoop2015">Shoop, Barry (November 12, 2015). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/Maxwell_Medal_Citation_by_Barry_Shoop.pdf">"IEEE/RSE Maxwell Medal Citation for Lynn Conway"</a> <span>(PDF)</span>. Royal Society of Edinburgh.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IEEE%2FRSE+Maxwell+Medal+Citation+for+Lynn+Conway&amp;rft.date=2015-11-12&amp;rft.aulast=Shoop&amp;rft.aufirst=Barry&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2FMaxwell_Medal_Citation_by_Barry_Shoop.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-129"><span><b><a href="#cite_ref-129">^</a></b></span> <span><cite id="CITEREFFarrar2015">Farrar, Steve (November 12, 2015). <a rel="nofollow" href="https://web.archive.org/web/20160324154326/https://www.royalsoced.org.uk/cms/files/events/reports/2014-2015/2015-IEEE-lecture-Lynn-Conway.pdf">"Review of Professor Lynn Conway's 2015 IEEE/RSE James Clerk Maxwell Medal Lecture"</a> <span>(PDF)</span>. Royal Society of Edinburgh. Archived from <a rel="nofollow" href="https://www.royalsoced.org.uk/cms/files/events/reports/2014-2015/2015-IEEE-lecture-Lynn-Conway.pdf">the original</a> <span>(PDF)</span> on March 24, 2016<span>. Retrieved <span>June 25,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Review+of+Professor+Lynn+Conway%27s+2015+IEEE%2FRSE+James+Clerk+Maxwell+Medal+Lecture&amp;rft.date=2015-11-12&amp;rft.aulast=Farrar&amp;rft.aufirst=Steve&amp;rft_id=https%3A%2F%2Fwww.royalsoced.org.uk%2Fcms%2Ffiles%2Fevents%2Freports%2F2014-2015%2F2015-IEEE-lecture-Lynn-Conway.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-130"><span><b><a href="#cite_ref-130">^</a></b></span> <span><cite id="CITEREFLinklater2015">Linklater, Magnus (November 14, 2015). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/Life_In_Stealth_of_Microchip_Genius_The_Times.pdf">"<span></span>'Life in stealth' of a microchip pioneer who migrated to a new identity: Lynn Conway beat transgender bias and began a revolution"</a> <span>(PDF)</span>. <i>The Times (UK), Scotland Edition</i>. pp.&nbsp;36–37.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Times+%28UK%29%2C+Scotland+Edition&amp;rft.atitle=%27Life+in+stealth%27+of+a+microchip+pioneer+who+migrated+to+a+new+identity%3A+Lynn+Conway+beat+transgender+bias+and+began+a+revolution&amp;rft.pages=36-37&amp;rft.date=2015-11-14&amp;rft.aulast=Linklater&amp;rft.aufirst=Magnus&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2FLife_In_Stealth_of_Microchip_Genius_The_Times.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-131"><span><b><a href="#cite_ref-131">^</a></b></span> <span><cite id="CITEREFConway2016">Conway, Lynn (March 23, 2016), "Our Travels Through Techno-Social Space-Time: Envisioning Incoming Waves of Technological Innovation", <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/Columbia/2016_Magill_Lecture.pptx"><i>2016 Magill Lecture in Science, Technology and the Arts</i></a>, Columbia University</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Our+Travels+Through+Techno-Social+Space-Time%3A+Envisioning+Incoming+Waves+of+Technological+Innovation&amp;rft.btitle=2016+Magill+Lecture+in+Science%2C+Technology+and+the+Arts&amp;rft.pub=Columbia+University&amp;rft.date=2016-03-23&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FColumbia%2F2016_Magill_Lecture.pptx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-132"><span><b><a href="#cite_ref-132">^</a></b></span> <span><cite id="CITEREFAdams2016">Adams, Jesse (April 7, 2016). <a rel="nofollow" href="http://engineering.columbia.edu/visionary-engineer-lynn-conway-bs%E2%80%9962-ms%E2%80%9963-heralds-dawn-techno-social-age">"Magill Lecture: Visionary Engineer Lynn Conway BS'62, MS'63 Heralds Dawn of the Techno-Social Age"</a>. Columbia University.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Magill+Lecture%3A+Visionary+Engineer+Lynn+Conway+BS%2762%2C+MS%2763+Heralds+Dawn+of+the+Techno-Social+Age&amp;rft.date=2016-04-07&amp;rft.aulast=Adams&amp;rft.aufirst=Jesse&amp;rft_id=http%3A%2F%2Fengineering.columbia.edu%2Fvisionary-engineer-lynn-conway-bs%25E2%2580%259962-ms%25E2%2580%259963-heralds-dawn-techno-social-age&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-133"><span><b><a href="#cite_ref-133">^</a></b></span> <span><a rel="nofollow" href="https://www.uvic.ca/home/about/campus-news/2016+nov-2016-honorary-degree-recipients+media-release?ticket=ST-1137198-ZQ5Ilc0GxZeV7Eye9oPi-jvm1">"University of Victoria News, Leaders in computing, athletics, telecommunications and public service receive honorary degrees"</a>, September 14, 2016.</span>
</li>
<li id="cite_note-134"><span><b><a href="#cite_ref-134">^</a></b></span> <span><cite id="CITEREFUVic_Transgender_Archives2016">UVic Transgender Archives (November 22, 2016). <a rel="nofollow" href="https://www.youtube.com/watch?v=PGx3h3mnIyI">"Lynn Conway UVic Convocation Nov. 9, 2016"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/PGx3h3mnIyI">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+UVic+Convocation+Nov.+9%2C+2016&amp;rft.pub=YouTube&amp;rft.date=2016-11-22&amp;rft.au=UVic+Transgender+Archives&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DPGx3h3mnIyI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-135"><span><b><a href="#cite_ref-135">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.uvic.ca/research/transchair/assets/images/misc/conway_event_poster.jpg">"Lynn Conway: Honorary Doctor of Engineering"</a>. <i>University of Victoria</i>. November 9, 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=Lynn+Conway%3A+Honorary+Doctor+of+Engineering&amp;rft.date=2016-11-09&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fresearch%2Ftranschair%2Fassets%2Fimages%2Fmisc%2Fconway_event_poster.jpg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-136"><span><b><a href="#cite_ref-136">^</a></b></span> <span><cite id="CITEREFMary_Sanseverino,_orator2016">Mary Sanseverino, orator (November 9, 2016). <a rel="nofollow" href="https://web.archive.org/web/20170615073242/https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-oration.pdf">"Professor Lynn Conway's Citation for the Degree Doctor of Engineering, Honoris Causa"</a> <span>(PDF)</span>. <i>University of Victoria</i>. Original physical document archived at University of Victoria Libraries, Transgender Archives. Archived from <a rel="nofollow" href="https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-oration.pdf">the original</a> <span>(PDF)</span> on June 15, 2017.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=Professor+Lynn+Conway%27s+Citation+for+the+Degree+Doctor+of+Engineering%2C+Honoris+Causa&amp;rft.date=2016-11-09&amp;rft.au=Mary+Sanseverino%2C+orator&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fengineering%2Fassets%2Fdocs%2FLynn_Conway-2016Nov-honorand-oration.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-137"><span><b><a href="#cite_ref-137">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20170615060747/https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-quoem.pdf">"What Words Will You Leave to Guide Them"</a> <span>(PDF)</span>. <i>University of Victoria</i>. Lynn Conway Honorary Degree Comments &amp; Convocation Quoem. November 9, 2016. Archived from <a rel="nofollow" href="https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-quoem.pdf">the original</a> <span>(PDF)</span> on June 15, 2017.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=What+Words+Will+You+Leave+to+Guide+Them&amp;rft.date=2016-11-09&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fengineering%2Fassets%2Fdocs%2FLynn_Conway-2016Nov-honorand-quoem.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-138"><span><b><a href="#cite_ref-138">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20180307214436/https://www.aaas.org/fellow/conway-lynn">"Lynn Conway. AAAS"</a>. <i>Aaas.org</i>. Archived from <a rel="nofollow" href="https://www.aaas.org/fellow/conway-lynn">the original</a> on March 7, 2018<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=Lynn+Conway.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Ffellow%2Fconway-lynn&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-139"><span><b><a href="#cite_ref-139">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/2016-fellows">"2016 Fellow". AAAS"</a>. <i>Aaas.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=2016+Fellow%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2F2016-fellows&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-140"><span><b><a href="#cite_ref-140">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/blog/member-spotlight/sense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway">"O'Hara, Delia (28 August 2017). "Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway". AAAS"</a>. <i>Aaas.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=O%27Hara%2C+Delia+%2828+August+2017%29.+%22Sense+of+Wonder+Motivates+VLSI+Chip+Revolutionary%2C+Lynn+Conway%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Fblog%2Fmember-spotlight%2Fsense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-141"><span><b><a href="#cite_ref-141">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20180307214804/https://www.aaas.org/taxonomy/term/3979/all/feed?page=3&amp;AMCV_242B6472541199F70A4C98A6%2540AdobeOrg_=793872103%257CMCIDTS%257C16834%257CMCMID%257C14052391524514714681898153359099533420%257CMCAID%257CNONE">"Member Spotlight. "Lynn Conway". AAAS"</a>. <i>Aaas.org</i>. Archived from <a rel="nofollow" href="https://www.aaas.org/taxonomy/term/3979/all/feed?page=3&amp;AMCV_242B6472541199F70A4C98A6%2540AdobeOrg_=793872103%257CMCIDTS%257C16834%257CMCMID%257C14052391524514714681898153359099533420%257CMCAID%257CNONE">the original</a> on March 7, 2018<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=Member+Spotlight.+%22Lynn+Conway%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Ftaxonomy%2Fterm%2F3979%2Fall%2Ffeed%3Fpage%3D3%26AMCV_242B6472541199F70A4C98A6%252540AdobeOrg_%3D793872103%25257CMCIDTS%25257C16834%25257CMCMID%25257C14052391524514714681898153359099533420%25257CMCAID%25257CNONE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-142"><span><b><a href="#cite_ref-142">^</a></b></span> <span><cite id="CITEREFRobertson2018">Robertson, Zach (October 18, 2018). <a rel="nofollow" href="https://news.engin.umich.edu/2018/10/computing-pioneer-to-receive-honorary-um-doctor-of-science-degree/">"Computing pioneer to receive honorary U-M doctorate"</a>. Michigan Engineering News. <a rel="nofollow" href="https://web.archive.org/web/20190615181704/https://news.engin.umich.edu/2018/10/computing-pioneer-to-receive-honorary-um-doctor-of-science-degree/">Archived</a> from the original on June 15, 2019.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Computing+pioneer+to+receive+honorary+U-M+doctorate&amp;rft.pub=Michigan+Engineering+News&amp;rft.date=2018-10-18&amp;rft.aulast=Robertson&amp;rft.aufirst=Zach&amp;rft_id=https%3A%2F%2Fnews.engin.umich.edu%2F2018%2F10%2Fcomputing-pioneer-to-receive-honorary-um-doctor-of-science-degree%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-143"><span><b><a href="#cite_ref-143">^</a></b></span> <span><cite id="CITEREFUniversity_of_Michigan,_Ann_Arbor,_Winter_2018_Commencement:_Honorary_Degree_Recipients2018">University of Michigan, Ann Arbor, Winter 2018 Commencement: Honorary Degree Recipients (December 16, 2018). <a rel="nofollow" href="https://www.youtube.com/watch?v=D78JVnip5v0&amp;feature=youtu.be&amp;t=2782">"University of Michigan Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. (t = 0:46:22 to 0:56:56).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=University+of+Michigan+Video&amp;rft.date=2018-12-16&amp;rft.au=University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement%3A+Honorary+Degree+Recipients&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD78JVnip5v0%26feature%3Dyoutu.be%26t%3D2782&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: location (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_location" title="Category:CS1 maint: location">link</a>) CS1 maint: multiple names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>) CS1 maint: numeric names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-144"><span><b><a href="#cite_ref-144">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/UM_2018/Conway_Honorary%20_Degree_Citation.pdf">"Citation: Lynn Conway, honorary Doctor of Science, University of Michigan, Ann Arbor, Winter 2018 Commencement"</a> <span>(PDF)</span>. December 16, 2018.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Citation%3A+Lynn+Conway%2C+honorary+Doctor+of+Science%2C+University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement&amp;rft.date=2018-12-16&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FUM_2018%2FConway_Honorary%2520_Degree_Citation.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-145"><span><b><a href="#cite_ref-145">^</a></b></span> <span><cite id="CITEREFUniversity_of_Michigan,_Ann_Arbor,_Winter_2018_Commencement:_Lynn_Conway_Commencement_Address2018">University of Michigan, Ann Arbor, Winter 2018 Commencement: Lynn Conway Commencement Address (December 16, 2018). <a rel="nofollow" href="https://www.youtube.com/watch?v=D78JVnip5v0&amp;feature=youtu.be&amp;t=4300">"University of Michigan Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. (t = 1:11:40 to 1:20:52).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=University+of+Michigan+Video&amp;rft.date=2018-12-16&amp;rft.au=University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement%3A+Lynn+Conway+Commencement+Address&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD78JVnip5v0%26feature%3Dyoutu.be%26t%3D4300&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: location (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_location" title="Category:CS1 maint: location">link</a>) CS1 maint: multiple names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>) CS1 maint: numeric names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-146"><span><b><a href="#cite_ref-146">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.ncwit.org/video/2019-ncwit-summit-lynn-conway-pioneer-award-ceremony">"2019 NCWIT Summit: Lynn Conway – Pioneer Award Ceremony"</a>. Nashville, TN. May 16, 2019.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=2019+NCWIT+Summit%3A+Lynn+Conway+%E2%80%93+Pioneer+Award+Ceremony&amp;rft.place=Nashville%2C+TN&amp;rft.date=2019-05-16&amp;rft_id=https%3A%2F%2Fwww.ncwit.org%2Fvideo%2F2019-ncwit-summit-lynn-conway-pioneer-award-ceremony&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-:0-147"><span>^ <a href="#cite_ref-:0_147-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_147-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFAlicandri2020">Alicandri, Jeremy (November 18, 2020). <a rel="nofollow" href="https://www.forbes.com/sites/jeremyalicandri/2020/11/18/ibm-apologizes-for-firing-computer-pioneer/?sh=25cf659667d5">"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later"</a>. Forbes<span>. Retrieved <span>November 21,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IBM+Apologizes+For+Firing+Computer+Pioneer+For+Being+Transgender...52+Years+Later&amp;rft.date=2020-11-18&amp;rft.aulast=Alicandri&amp;rft.aufirst=Jeremy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fjeremyalicandri%2F2020%2F11%2F18%2Fibm-apologizes-for-firing-computer-pioneer%2F%3Fsh%3D25cf659667d5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-148"><span><b><a href="#cite_ref-148">^</a></b></span> <span><cite><a rel="nofollow" href="https://cse.engin.umich.edu/stories/prof-emerita-lynn-conway-to-be-inducted-into-national-inventors-hall-of-fame">"Prof. Emerita Lynn Conway to be inducted into National Inventors Hall of Fame"</a>. <i>Computer Science &amp; Engineering News</i>. <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+Science+%26+Engineering+News&amp;rft.atitle=Prof.+Emerita+Lynn+Conway+to+be+inducted+into+National+Inventors+Hall+of+Fame&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fcse.engin.umich.edu%2Fstories%2Fprof-emerita-lynn-conway-to-be-inducted-into-national-inventors-hall-of-fame&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-149"><span><b><a href="#cite_ref-149">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.invent.org/inductees/lynn-conway">"Lynn Conway, Very Large-Scale Integration (VLSI)"</a>. <i><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a></i>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=Lynn+Conway%2C+Very+Large-Scale+Integration+%28VLSI%29&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fwww.invent.org%2Finductees%2Flynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-150"><span><b><a href="#cite_ref-150">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.invent.org/sites/default/files/2022-12/2023_Fact_Sheet_Conway_FINAL.pdf">"10 Things You Need to Know About Lynn Conway"</a> <span>(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a></i>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=10+Things+You+Need+to+Know+About+Lynn+Conway&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fwww.invent.org%2Fsites%2Fdefault%2Ffiles%2F2022-12%2F2023_Fact_Sheet_Conway_FINAL.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-151"><span><b><a href="#cite_ref-151">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=H6tb8qBgWXU">"Providing Freedom: The Lynn Conway Story"</a>. <i>National Inventors Hall of Fame</i> (Video). October 26, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=Providing+Freedom%3A+The+Lynn+Conway+Story&amp;rft.date=2023-10-26&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DH6tb8qBgWXU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-152"><span><b><a href="#cite_ref-152">^</a></b></span> <span><cite id="CITEREFDodds2023">Dodds, Io (November 25, 2023). <a rel="nofollow" href="https://www.independent.co.uk/news/world/americas/lynn-conway-biography-vlsi-transgender-b2452173.html">"<span></span>'I lived a pretty adventurous life': Meet Lynn Conway, the hidden figure behind the smartphone in your pocket"</a>. <i>The Telegraph (US Edition)</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Telegraph+%28US+Edition%29&amp;rft.atitle=%27I+lived+a+pretty+adventurous+life%27%3A+Meet+Lynn+Conway%2C+the+hidden+figure+behind+the+smartphone+in+your+pocket&amp;rft.date=2023-11-25&amp;rft.aulast=Dodds&amp;rft.aufirst=Io&amp;rft_id=https%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fworld%2Famericas%2Flynn-conway-biography-vlsi-transgender-b2452173.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-153"><span><b><a href="#cite_ref-153">^</a></b></span> <span>Princeton awards five honorary degrees. (2023, May 30). Princeton University. <a rel="nofollow" href="https://www.princeton.edu/news/2023/05/30/princeton-awards-five-honorary-degrees">https://www.princeton.edu/news/2023/05/30/princeton-awards-five-honorary-degrees</a></span>
</li>
<li id="cite_note-154"><span><b><a href="#cite_ref-154">^</a></b></span> <span><cite><a rel="nofollow" href="https://news.syr.edu/blog/2024/04/19/5-honorary-degrees-to-be-presented-at-2024-commencement/">"5 Honorary Degrees to Be Presented at 2024 Commencement"</a>. April 19, 2024.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=5+Honorary+Degrees+to+Be+Presented+at+2024+Commencement&amp;rft.date=2024-04-19&amp;rft_id=https%3A%2F%2Fnews.syr.edu%2Fblog%2F2024%2F04%2F19%2F5-honorary-degrees-to-be-presented-at-2024-commencement%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-155"><span><b><a href="#cite_ref-155">^</a></b></span> <span><cite id="CITEREFMaurice2020">Maurice, Emma Powys (November 20, 2020). <a rel="nofollow" href="https://www.pinknews.co.uk/2020/11/20/ibm-lynn-conway-transgender-computer-scientist-pioneer-apology-vsli-chip-silicone-valley/">"Business giant IBM finally apologises for firing a computer pioneer 52 years ago just because she was trans"</a>. <i><a href="https://en.wikipedia.org/wiki/PinkNews" title="PinkNews">PinkNews</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PinkNews&amp;rft.atitle=Business+giant+IBM+finally+apologises+for+firing+a+computer+pioneer+52+years+ago+just+because+she+was+trans&amp;rft.date=2020-11-20&amp;rft.aulast=Maurice&amp;rft.aufirst=Emma+Powys&amp;rft_id=https%3A%2F%2Fwww.pinknews.co.uk%2F2020%2F11%2F20%2Fibm-lynn-conway-transgender-computer-scientist-pioneer-apology-vsli-chip-silicone-valley%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-156"><span><b><a href="#cite_ref-156">^</a></b></span> <span><cite id="CITEREFHiltzik2020">Hiltzik, Michael (November 30, 2020). <a rel="nofollow" href="https://www.latimes.com/business/story/2020-11-23/ibm-apology-lynn-conway">"Column: IBM apologizes for firing a transgender pioneer, a half-century later"</a>. <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Los+Angeles+Times&amp;rft.atitle=Column%3A+IBM+apologizes+for+firing+a+transgender+pioneer%2C+a+half-century+later&amp;rft.date=2020-11-30&amp;rft.aulast=Hiltzik&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fwww.latimes.com%2Fbusiness%2Fstory%2F2020-11-23%2Fibm-apology-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-157"><span><b><a href="#cite_ref-157">^</a></b></span> <span><cite id="CITEREFPage2020">Page, Sydney (November 23, 2020). <a rel="nofollow" href="https://www.thelily.com/in-1968-ibm-fired-lynn-conway-for-being-transgender-she-finally-got-an-apology/">"In 1968, IBM fired Lynn Conway for being transgender – She finally got an apology"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Lily_(Washington_Post)" title="The Lily (Washington Post)">The Lily (Washington Post)</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Lily+%28Washington+Post%29&amp;rft.atitle=In+1968%2C+IBM+fired+Lynn+Conway+for+being+transgender+%E2%80%93+She+finally+got+an+apology&amp;rft.date=2020-11-23&amp;rft.aulast=Page&amp;rft.aufirst=Sydney&amp;rft_id=https%3A%2F%2Fwww.thelily.com%2Fin-1968-ibm-fired-lynn-conway-for-being-transgender-she-finally-got-an-apology%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-158"><span><b><a href="#cite_ref-158">^</a></b></span> <span><cite id="CITEREFKane2020">Kane, Roni (November 29, 2020). <a rel="nofollow" href="https://www.michigandaily.com/section/academics/ibm-fired-%E2%80%98u%E2%80%99-professor-lynn-conway-changing-her-gender-identity-1968-52-years">"IBM fired U-M professor Lynn Conway for coming out as trans in 1968. 52 years later, the company apologized"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Michigan_Daily" title="The Michigan Daily">The Michigan Daily</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Michigan+Daily&amp;rft.atitle=IBM+fired+U-M+professor+Lynn+Conway+for+coming+out+as+trans+in+1968.+52+years+later%2C+the+company+apologized&amp;rft.date=2020-11-29&amp;rft.aulast=Kane&amp;rft.aufirst=Roni&amp;rft_id=https%3A%2F%2Fwww.michigandaily.com%2Fsection%2Facademics%2Fibm-fired-%25E2%2580%2598u%25E2%2580%2599-professor-lynn-conway-changing-her-gender-identity-1968-52-years&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-159"><span><b><a href="#cite_ref-159">^</a></b></span> <span><cite id="CITEREFAssunção2020">Assunção, Muri (November 20, 2020). <a rel="nofollow" href="https://www.nydailynews.com/news/national/ny-ibm-apologizes-trans-tech-pioneer-lynn-conway-firing-20201120-jfhvu2e4yjbplb5r6256ev7gya-story.html">"IBM apologizes to 'tech trailblazer' Lynn Conway for firing her for being transgender, 52 years after the fact"</a>. <i><a href="https://en.wikipedia.org/wiki/New_York_Daily_News" title="New York Daily News">New York Daily News</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+York+Daily+News&amp;rft.atitle=IBM+apologizes+to+%27tech+trailblazer%27+Lynn+Conway+for+firing+her+for+being+transgender%2C+52+years+after+the+fact&amp;rft.date=2020-11-20&amp;rft.aulast=Assun%C3%A7%C3%A3o&amp;rft.aufirst=Muri&amp;rft_id=https%3A%2F%2Fwww.nydailynews.com%2Fnews%2Fnational%2Fny-ibm-apologizes-trans-tech-pioneer-lynn-conway-firing-20201120-jfhvu2e4yjbplb5r6256ev7gya-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-160"><span><b><a href="#cite_ref-160">^</a></b></span> <span><cite id="CITEREFCramer2020">Cramer, Maria (November 21, 2020). <a rel="nofollow" href="https://www.nytimes.com/2020/11/21/business/lynn-conway-ibm-transgender.html">"52 Years Later, IBM Apologizes for Firing Transgender Woman"</a>. <i><a href="https://en.wikipedia.org/wiki/The_New_York_Times" title="The New York Times">The New York Times</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=52+Years+Later%2C+IBM+Apologizes+for+Firing+Transgender+Woman&amp;rft.date=2020-11-21&amp;rft.aulast=Cramer&amp;rft.aufirst=Maria&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2020%2F11%2F21%2Fbusiness%2Flynn-conway-ibm-transgender.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
</ol></div>
<h2><span id="Further_reading">Further reading</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=13" title="Edit section: Further reading"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFSaariAllison1996">Saari, Peggy; Allison, Stephen (1996). <a rel="nofollow" href="https://archive.org/details/scientistslives000saar"><i>Scientists: The Lives and Works of 150 Scientists</i></a>. New York [u.a.]: UXL. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780787609603" title="Special:BookSources/9780787609603"><bdi>9780787609603</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Scientists%3A+The+Lives+and+Works+of+150+Scientists&amp;rft.place=New+York+%5Bu.a.%5D&amp;rft.pub=UXL&amp;rft.date=1996&amp;rft.isbn=9780787609603&amp;rft.aulast=Saari&amp;rft.aufirst=Peggy&amp;rft.au=Allison%2C+Stephen&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fscientistslives000saar&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li></ul>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=14" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<p><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Commons-logo.svg"><img alt="" src="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" decoding="async" width="12" height="16" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"></a></span> Media related to <a href="https://commons.wikimedia.org/wiki/Category:Lynn_Conway" title="commons:Category:Lynn Conway">Lynn Conway</a> at Wikimedia Commons
</p>
<ul><li><span><span><a rel="nofollow" href="http://www.lynnconway.com/">Official website</a></span></span></li></ul>

<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐6d76fd97c7‐gnkwn
Cached time: 20240611182607
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.762 seconds
Real time usage: 2.048 seconds
Preprocessor visited node count: 10574/1000000
Post‐expand include size: 264432/2097152 bytes
Template argument size: 11422/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 20/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 507547/5000000 bytes
Lua time usage: 1.190/10.000 seconds
Lua memory usage: 11569930/52428800 bytes
Lua Profile:
    ?                                                                280 ms       23.3%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::callParserFunction      140 ms       11.7%
    <mw.lua:694>                                                     120 ms       10.0%
    dataWrapper <mw.lua:672>                                         120 ms       10.0%
    citation0 <Module:Citation/CS1:2613>                              80 ms        6.7%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::getEntityStatements       40 ms        3.3%
    init <Module:Citation/CS1/Identifiers>                            40 ms        3.3%
    makeMessage <mw.message.lua:76>                                   40 ms        3.3%
    <Module:Citation/CS1:813>                                         40 ms        3.3%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::gsub       40 ms        3.3%
    [others]                                                         260 ms       21.7%
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1868.533      1 -total
 45.72%  854.337      1 Template:Reflist
 25.47%  475.986     80 Template:Cite_web
 15.92%  297.493      1 Template:Infobox_scientist
  9.14%  170.742     11 Template:Cite_book
  8.89%  166.178     24 Template:Cite_news
  7.16%  133.758      1 Template:Authority_control
  4.59%   85.776      1 Template:Short_description
  4.14%   77.280     10 Template:Cite_journal
  3.80%   71.068      1 Template:Marriage
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:747715-0!canonical and timestamp 20240611182607 and revision id 1228525334. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google shuts down GPay app and P2P payments in the US (144 pts)]]></title>
            <link>https://9to5google.com/2024/06/09/gpay-us/</link>
            <guid>40647517</guid>
            <pubDate>Tue, 11 Jun 2024 15:36:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2024/06/09/gpay-us/">https://9to5google.com/2024/06/09/gpay-us/</a>, See on <a href="https://news.ycombinator.com/item?id=40647517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>As announced <a href="https://9to5google.com/2024/02/22/gpay-app-p2p/">in February</a>, “GPay” is no longer available in the US. The redesigned Google Pay was announced in 2020 to “make money simple, secure, and helpful” with plans for a “mobile-first bank account” that never came to fruition.</p>



<p>Starting on June 4, GPay — as was the name of the app on Android homescreens — automatically signed US users out. Attempting to login again explains how: “The Google Pay US app is no longer available. You can still tap to pay using the Google Wallet app.”</p>



<figure><img decoding="async" width="864" height="1920" src="https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?quality=82&amp;strip=all&amp;w=461" alt="" srcset="https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg 864w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=59,130 59w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=315,700 315w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=768,1707 768w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=461,1024 461w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=691,1536 691w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=158,350 158w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=140,311 140w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=450,1000 450w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=150,333 150w" sizes="(max-width: 864px) 100vw, 864px"></figure>



<p>Additionally, Google no longer offers peer-to-peer payments in the US. You can use the <a href="http://pay.google.com/">Google Pay website</a> to view and transfer your balance — money you’ve received or rewards— to a bank account after June.&nbsp;</p>



<p>The focus is now on Google Wallet and digitizing everything in your physical wallet. There’s no equivalent finance tracking functionality. Meanwhile, “Google Pay” still exists as the name for what you’re actually using when making a physical or online purchase with your phone.</p>



<ul>
<li><strong>Related</strong>: <a href="https://9to5google.com/2024/06/02/google-wallet-android-notifications/">Direct Google Wallet app notifications start rolling out</a></li>
</ul>



<p>The main premise of the big redesign was an app centered “around your relationships with people and businesses” with message-like conversations serving as a purchase history. You could also keep track of your bank account and credit card (via Plaid) in the “Insights” tab, while a lot of deals and cash back offers were presented.</p>






<p>At the November 2022 announcement, co-branded checking and saving “Plex Accounts” were also <a href="https://9to5google.com/2020/11/18/google-pay-plex-account/">previewed</a>. Google partnered with banks and credit unions, most notably Citi. There would have been a physical card&nbsp;</p>



<p>Savings and the ability to create customizable goals was the other big tentpole. You could create specific tasks with milestones to break things up. One option would have been to “round-up transfers” on all purchases to help meet the goal.</p>


<div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/9to5google.com\/wp-content\/uploads\/sites\/4\/2020\/11\/google-pay-plex-account-card.jpg?quality=82\u0026strip=all&quot;,&quot;figureClassNames&quot;:&quot;tiled-gallery__item&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:702,&quot;targetHeight&quot;:702,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" srcset="https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?strip=info&amp;w=600&amp;ssl=1 600w,https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?strip=info&amp;w=702&amp;ssl=1 702w" alt="" data-height="702" data-id="391045" data-link="https://9to5google.com/2020/11/18/google-pay-plex-account/google-pay-plex-account-card/" data-url="https://9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?quality=82&amp;strip=all" data-width="702" src="https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?ssl=1" data-amp-layout="responsive"></figure></div>



<p>Plex was supposed to launch in 2021, but Google announced <a href="https://9to5google.com/2021/10/01/google-pay-abandons-plans-for-plex-bank-accounts-w-400000-on-the-waitlist/">that October</a> how the project was canceled. This was despite a waitlist of 400,000 people. Officially, Google was shifting to “delivering digital enablement for banks and other financial services providers rather than us serving as the provider of these services.”</p>



<hr>



	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA denies petition against use of phthalates in food packaging (140 pts)]]></title>
            <link>https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications</link>
            <guid>40647491</guid>
            <pubDate>Tue, 11 Jun 2024 15:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications">https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications</a>, See on <a href="https://news.ycombinator.com/item?id=40647491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                                 <article id="main-content" role="article">
          
                                                                <header role="heading" aria-level="1">
                         <div id="block-entityviewcontent-2" data-block-plugin-id="entity_view:node">

  <h2>FDA Responds to Petition on Phthalates in Food Packaging and Food Contact Applications</h2>
  
  	
    
 
</div>






                      </header>
                              
                                                                           <div role="main">

                            
                            
                            
                            
                                              
  
<h2>Constituent Update&nbsp;</h2>

<p>July 21, 2023&nbsp;</p>

<p>Today, the U.S. Food and Drug Administration (FDA) <a href="https://www.regulations.gov/document/FDA-2016-P-1171-0017"><u>denied a petition</u></a> requesting that the agency reconsider its denial of a <a href="https://www.regulations.gov/docket/FDA-2016-P-1171/document?sortBy=postedDate">citizen petition</a> issued on May 19, 2022. The citizen petition requested a ban on the use of eight <em>ortho</em>-phthalates<em> </em>and revocation of the prior sanctioned uses for five ortho-phthalates in food based on alleged safety concerns.</p>

<p><em>Ortho</em>-phthalates, often referred to as “phthalates,” are chemicals used in plastic products (most commonly in the specific type of plastic named polyvinyl chloride, also known as PVC or vinyl) to make the material soft and less brittle.</p>

<p>We evaluated the reconsideration petition and concluded that it does not provide a basis for modifying the FDA’s response to the original citizen petition. Our response explains that we adequately considered relevant information and views contained in the administrative record when responding to the original citizen petition. Additionally, we have considered the information submitted in the reconsideration petition and other relevant information in the administrative record. &nbsp;The FDA’s decision to deny the original petition remains unchanged.</p>

<p>We will continue to keep the food industry and the public informed of updates related to our activities on phthalates in food packaging and food contact applications. Up to date information is available on the FDA’s <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="520c05e8-8501-4ffb-b7cd-9885329219a2" href="https://www.fda.gov/food/food-additives-and-gras-ingredients-information-consumers/phthalates-food-packaging-and-food-contact-applications" title="Phthalates in Food Packaging and Food Contact Applications ">phthalates</a> website.</p>

<p><strong>For More Information:</strong></p>

<ul><li><a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="520c05e8-8501-4ffb-b7cd-9885329219a2" href="https://www.fda.gov/food/food-additives-and-gras-ingredients-information-consumers/phthalates-food-packaging-and-food-contact-applications" title="Phthalates in Food Packaging and Food Contact Applications ">Phthalates in Food Packaging and Food Contact Applications</a></li>
	<li>Constituent Update: <a href="https://www.fda.gov/food/cfsan-constituent-updates/fda-limits-use-certain-phthalates-food-packaging-and-issues-request-information-about-current-food">FDA Limits the Use of Certain Phthalates in Food Packaging and Issues Request for Information About Current Food Contact Uses and Safety Data</a>&nbsp;(September 2022)</li>
</ul>

<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->


<!--END WEBSITE FEEDBACK SNIPPET-->

<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->



              
                                            
              
            </div>

                                                                                  
            

                                                                                
            
                 </article>        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's official Minesweeper app has ads, pay-to-win, and is hundreds of MBs (310 pts)]]></title>
            <link>https://tech.lgbt/@nina_kali_nina/112594910070716090</link>
            <guid>40647278</guid>
            <pubDate>Tue, 11 Jun 2024 15:22:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tech.lgbt/@nina_kali_nina/112594910070716090">https://tech.lgbt/@nina_kali_nina/112594910070716090</a>, See on <a href="https://news.ycombinator.com/item?id=40647278">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Open-Sources Megalodon LLM for Efficient Long Sequence Modeling (112 pts)]]></title>
            <link>https://www.infoq.com/news/2024/06/meta-llm-megalodon/</link>
            <guid>40646820</guid>
            <pubDate>Tue, 11 Jun 2024 14:49:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.infoq.com/news/2024/06/meta-llm-megalodon/">https://www.infoq.com/news/2024/06/meta-llm-megalodon/</a>, See on <a href="https://news.ycombinator.com/item?id=40646820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<p>Researchers from <a href="https://ai.meta.com/">Meta</a>, <a href="https://www.usc.edu/">University of Southern California</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, and <a href="https://ucsd.edu/">University of California San Diego</a> recently open-sourced <a href="https://arxiv.org/abs/2404.08801">MEGALODON</a>, a large language model (LLM) with an unlimited context length. MEGALODON has linear computational complexity and outperforms a similarly-sized <a href="https://www.infoq.com/news/2023/07/meta-new-ai-model/">Llama 2</a> model on a range of benchmarks.</p>

<p>MEGALODON is designed to address several shortcomings of the Transformer neural architecture underlying most LLMs. Instead of the standard multihead attention, MEGALODON uses a chunk-wise attention. The research team also introduced sequence-based parallelism during training, improving scalability for long-context training. When evaluated on standard LLM benchmarks, such as <a href="https://paperswithcode.com/dataset/winogrande">WinoGrande</a> and <a href="https://paperswithcode.com/dataset/mmlu">MMLU</a>, MEGALODON outperformed a Llama 2 model with the same amount of parameters, training data, and training compute budget. According to the researchers:&nbsp;</p>

<blockquote>
<p>MEGALODON achieves impressive improvements on both training perplexity and across downstream benchmarks. Importantly, experimental results on long-context modeling demonstrate MEGALODON’s ability to model sequences of unlimited length. Additional experiments on small/medium-scale benchmarks across different data modalities illustrate the robust improvements of MEGALODON, which lead to a potential direction of future work to apply MEGALODON for large-scale multi-modality pretraining.</p>
</blockquote>

<p>Although the Transformer architecture has become the standard for most Generative AI models, Transformers do have some drawbacks. In particular, their self-attention mechanism has quadratic complexity in both compute and storage, which limits the models' input context length. Several alternatives to the standard self-attention model have been developed recently, including structured state space models (SSMs) like <a href="https://arxiv.org/abs/2312.00752">Mamba</a>, which scales linearly with context length. Another scheme that InfoQ recently covered is the <a href="https://www.infoq.com/news/2024/03/rwkv-llm-eagle-7b/">RWKV Project's</a> attention-free Transformer model, which has no maximum input context length.</p>

<p>MEGALODON builds on the research team's previous model, <a href="https://github.com/facebookresearch/mega">MEGA</a> (exponential moving average with gated attention), with several new features. First, while MEGA uses a "classical" exponential moving average (EMA) within its attention mechanism, MEGALODON computes a <em>complex</em>&nbsp;EMA (CEMA). Mathematically, the CEMA component makes MEGALODON equivalent to a "simplified state space model with diagonal state matrix."</p>

<p>The research team trained a seven-billion parameter model, MEGALODON-7B, using the same 2-trillion token dataset that Llama2-7B used; they also used the same training hyperparameters. The team observed that MEGALODON-7B was more computationally efficient. When the Llama model was scaled up to a 32k context length, MEGALODON-7B was "significantly" faster.</p>

<p>Besides evaluating MEGALODON-7B on standard LLM benchmarks, the researchers also tested its performance on the <a href="https://paperswithcode.com/dataset/scrolls">SCROLLS</a> long-context question-answering benchmark, and compared its results with several baseline models, including the modified Llama 2 model with a 32k context length. MEGALODON outperformed all baseline models on the NarrativeQA subtask, and on all tasks achieved results "competitive" with Llama 2.</p>

<p>In a discussion about MEGALODON on Hacker News, one user <a href="https://news.ycombinator.com/item?id=40054901">wondered how well the model performed on recall tasks</a>, given that other non-Transformer models tend to perform poorly. Another user replied:</p>

<blockquote>
<p>For what it's worth, RWKV's website on that matter mentions that yes it's bad on recall, but for the vast majority of tasks you can just ask the question *before* the content, and it'll handle the task just fine.</p>
</blockquote>

<p>The <a href="https://github.com/XuezheMax/megalodon">MEGALODON code</a> is available on GitHub.</p>

								









  
    <div> <!-- main wrapper for authors section -->
        <h2>About the Author</h2> <!-- section title -->

        
            
                
            
            <div data-id="author-Anthony-Alford">
                    <h4><strong>Anthony Alford</strong></h4>
                    
                </div>
        
    </div>

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway discovers Europe's largest deposit of rare earth metals (225 pts)]]></title>
            <link>https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html</link>
            <guid>40646658</guid>
            <pubDate>Tue, 11 Jun 2024 14:36:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html">https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html</a>, See on <a href="https://news.ycombinator.com/item?id=40646658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SpecialReportArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="SpecialReportArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-102737188" data-test="InlineImage"><p>Neodymium is displayed at the Inner Mongolia Baotou Steel Rare-Earth Hi-Tech Co. factory in Baotou, Inner Mongolia, China.</p><p>Nelson Ching | Bloomberg | Getty Images</p></div><div><p>Mining firm Rare Earths Norway says it has discovered Europe's largest proven deposit of <a href="https://www.cnbc.com/2024/02/14/us-energy-chief-concerned-about-chinas-critical-minerals-dominance.html">highly prized</a> rare earth elements, potentially reflecting a watershed moment for both the Nordic country and the broader region.</p><p>One of the few deposits not owned or controlled by China, the discovery of continental Europe's largest rare earths deposit is considered a welcome boost in Europe's bid to break <a href="https://www.cnbc.com/2024/01/29/norway-defends-deep-sea-mining-as-a-necessary-step-into-the-unknown.html">China's rare earths dominance</a>.</p><p>Demand for rare earths and critical minerals is expected to <a href="https://www.iea.org/topics/critical-minerals" target="_blank">grow exponentially</a> in the coming years as the <a href="https://www.cnbc.com/2023/12/13/countries-agree-to-deal-at-cop28-climate-summit.html">clean energy transition picks up pace</a>.</p><p>Rare Earths Norway <a href="https://rareearthsnorway.com/europes-largest-deposit-of-rare-earth-elements-discovered-at-fen-norway" target="_blank">said</a> in a June 6 statement that its Fen Carbonatite Complex in the southeast of the country boasts 8.8 million metric tons of total rare earth oxides (TREOs) with a reasonable prospect for economic extraction.</p><p>Within the TREOs, which are considered vital to the <a href="https://www.cnbc.com/2021/11/22/climate-how-to-navigate-the-energy-transition-away-from-fossil-fuels.html">global shift away from fossil fuels</a>, the company says there is an estimated 1.5 million metric tons of magnet-related rare earths which can be used in electric vehicles and wind turbines.</p><p>The discovery eclipses a massive rare earths deposit <a href="https://www.cnbc.com/2023/01/13/sweden-mining-company-lkap-finds-big-deposit-of-rare-earth-metals.html">found</a> last year in neighboring Sweden.</p><p>Alf Reistad, CEO of Rare Earths Norway, told CNBC that the discovery at Fen represents a "great milestone" for the company.</p><p>"It is important to state that there is absolutely no extraction of rare earth elements in Europe today," Reistad said via videoconference Monday.</p><p>One of the aims of the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_1661" target="_blank">Critical Raw Materials Act</a> is to extract at least 10% of the European Union's annual demand for rare earths by 2030 and Rare Earths Norway says it hopes to contribute to that goal.</p><p>Rare Earths Norway said the rare earths deposit in Telemark, roughly 210 kilometers (130 miles) southwest of Oslo, is likely to underscore Norway's position as an integral part of Europe's rare earth and critical raw material value chain.</p></div><h2><a id="headline0"></a>Rare earths 'more important' than oil and gas</h2><div><p>The International Energy Agency has <a href="https://www.iea.org/topics/critical-minerals" target="_blank">said</a> that today's supply falls short of what is needed to transform the energy sector. That's because there is a relatively high geographical concentration of the production of many energy transition elements.</p><p>Most rare earth elements are located in China, with the world's second-largest economy <a href="https://www.oxfordenergy.org/publications/chinas-rare-earths-dominance-and-policy-responses/" target="_blank">estimated</a> to account for 70% of global rare earth ore extraction and 90% of rare earth ore processing.</p><p>China was the EU's <a href="https://ec.europa.eu/eurostat/web/products-eurostat-news/w/ddn-20231113-1#:~:text" target="_blank">largest partner</a> for imports of rare earth elements in 2022, accounting for 40% of overall imports based on weight.</p></div><div id="ArticleBody-InlineImage-105939934" data-test="InlineImage"><p>Workers transport soil containing rare earth elements for export at a port in Lianyungang, Jiangsu province, China October 31, 2010.</p><p>Stringer | Reuters</p></div><div><p>Looking ahead, Rare Earths Norway said exploration work at the complex will continue, with further drilling scheduled for next month. The company said it is working to develop the first stage of mining by 2030.</p><p>Asked whether he believed the discovered resources could be considered of more value than Norway's <a href="https://www.cnbc.com/2023/01/26/russia-ukraine-war-norways-soaring-oil-and-gas-profits-stokes-debate.html">oil and gas supplies</a>, Rare Earths Norway's Reistad replied, "Not of more value but [European Commission President] Ursula von der Leyen has <a href="https://ec.europa.eu/commission/presscorner/detail/en/speech_22_5493" target="_blank">stated</a> that lithium and rare earth element will soon be more important than oil and gas."</p><p>"So, it will be more important but not have the same value, of course," he added.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Some people with insomnia think they're awake when they're asleep (160 pts)]]></title>
            <link>https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/</link>
            <guid>40646602</guid>
            <pubDate>Tue, 11 Jun 2024 14:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/">https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/</a>, See on <a href="https://news.ycombinator.com/item?id=40646602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><p>Up All Night? You May Have Actually Been Asleep<br></p></h2><p>You say you haven’t slept all night. Brain scans say you have. New science says both inferences may be right</p><figure><img src="https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=600" alt="Simple black and white vector illustration depicting a woman in bed, eyes closed, sleeping, with a white line scribble above her head" srcset="https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=600 600w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=900 900w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1000 1000w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1200 1200w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1350 1350w" sizes="(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw" fetchpriority="high"><figcaption> <p>Sulukhana Boonyarithsripong/Getty Images</p></figcaption></figure></div><div><p data-block="sciam/paragraph">Desperate for sleep, you go to a sleep clinic, where your head is fitted with electrodes to record your brain waves through various sleep stages. In the morning, you report that you barely slept at all. Yet according to the test—polysomnography, the gold standard for sleep measurement—you slept all night.</p><p data-block="sciam/paragraph">You’re not the classic example of a person with insomnia who waits for sleep to come, maybe checks the clock, paces, reads and waits for morning. What you have has been called subjective insomnia, paradoxical insomnia or sleep misperception. Scientists have doggedly attacked this stubborn puzzle for decades without result—until now. Now they say that you have not been misrepresenting your sleep; they have been mismeasuring it.</p><p data-block="sciam/paragraph">The most recent <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/jsr.14028">studies</a><u>,</u> using far more enhanced measurement, have found that many people with subjective insomnia show different brain activity from good sleepers—throughout the night. Neuroscientist Aurélie Stephan and colleagues at the Netherlands Institute for Neuroscience (NIN) realized that something unusual was going on after they asked people in their study to put onto their head a net of 256 electrodes rather than the typical six to 20 used in sleep clinics. In one <a href="https://www.cell.com/current-biology/pdf/S0960-9822(21)01366-X.pdf">series of experiments</a>, the researchers woke sleepers about 26 times on average during the night. The participants were asked whether they’d been asleep or awake and what they’d been thinking about.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">The most remarkable finding, Stephan says, is that these people showed pockets of arousal in the form of fast brain waves during rapid eye movement (REM) sleep. REM is the stage in normal sleep when your brain should completely disconnect from the systems that keep you aware and vigilant, Stephan says.</p><p data-block="sciam/paragraph">People with subjective insomnia with this interrupted REM do not experience their sleep as restful. When wakened, they reported having had thoughts similar to those when awake—adding lettuce to their shopping list, say, or reminding themselves to call their cousin. They were less likely to have what University of Montreal neuroscientist Claudia Picard-Deland calls immersive dreams, in which you feel physically present in the dream world and are fleeing down a dark hallway, feeling the hardness of the floor or battling a dragon, sensing its hot breath.</p><p data-block="sciam/paragraph">In a study of normal sleepers Picard-Deland recently presented at the <a href="https://www.cogneurosociety.org/symposia/">the Cognitive Neuroscience Society’s annual meeting</a>, participants said they felt most deeply asleep during immersive dreams, which occurred in the REM stage. People with interrupted REM, as Stephan’s research shows, do not report immersive dreams. They do not feel they’ve slept deeply, and they report fatigue similar to that of people who actually sleep very little.</p><p data-block="sciam/paragraph">Perhaps even more important, says NIN sleep scientist Eus van Someren, interrupted REM is strongly linked to disorders such as post-traumatic stress disorder (PTSD) and anxiety. If two people experience the same level of trauma, a good sleeper is probably less likely to develop PTSD than someone with disturbed sleep, he says. Those with disturbed sleep are therefore more vulnerable to developing PTSD. It’s a vicious cycle.</p><p data-block="sciam/paragraph">This occurs because interrupted REM interferes with the overnight dissolving of emotional distress that has accumulated throughout the daytime, which typically happens during good sleep. “Sound REM sleep is the only state during which the brain has a ‘<a href="https://journals.physiology.org/doi/full/10.1152/physrev.00046.2019">time-out</a>’ of noradrenaline [norepinephrine],” van Someren says. “The neurons are not firing anymore, so they don’t release noradrenaline downstream in the brain. But if you have even the slightest arousal from REM sleep..., then noradrenaline shoots up very fast.” He believes those with interrupted REM experience this arousal repeatedly and never reach the typical quiescent state that allows for the processing of troubled emotions.</p><p data-block="sciam/paragraph">A <a href="https://pubmed.ncbi.nlm.nih.gov/30590834/#:~:text=Conclusions%3A%20Our%20findings%20are%20the,actually%20aggravates%20physically%20perceived%20distress.">study</a> headed by van Someren’s former graduate student Rick Wassing, now at Macquarie University in Australia, demonstrates this experimentally. The researchers exposed people to a distressing emotional experience for three days in a row: they had to listen to a recording of themselves singing—often out of tune—to karaoke, which aroused shame. As measured by their physiological responses, normal sleepers felt less distress after a night’s sleep. Those with disturbed sleep felt more.</p><p data-block="sciam/paragraph">The percentage of people with insomnia that have interrupted REM is unknown, but these insights are suggesting new personalized treatments for insomnia, which is now understood as existing on a spectrum. Such treatments may be especially beneficial to people with insomnia who also have depression and anxiety disorders.</p><p data-block="sciam/paragraph">Currently, cognitive behavioral therapy for insomnia (CBTi) is the standard intervention for insomnia. People with insomnia learn to decrease their anxiety about sleeping and to employ behavioral strategies aimed at better sleep. But CBTi does not work for everyone. Those with interrupted REM, in particular, probably need different solutions.</p><p data-block="sciam/paragraph">One behavioral strategy used in CBTi—sleep restriction—does show promise for people with interrupted REM, however. Some sleep-restriction methods involve shortening a person’s time in bed to the average amount that they actually sleep per night. Other methods delay a person’s bedtime.” For example, If a person objectively sleeps for 5.5 hours, the experts allow the person to be in bed only for six hours. A preliminary lab <a href="https://www.nature.com/articles/s41598-021-03564-6">study</a> in which participants delayed their regular bedtime by two hours showed that such sleep restriction can reduce the number of arousals during REM. The researchers are hoping to replicate these results in a larger study of people sleeping at home.</p><p data-block="sciam/paragraph">This new science also opens the way for drug interventions. The NIN group is seeking approvals to test whether a beta-blocker typically prescribed to lower blood pressure might mitigate the effects of continuous bursts of norepinephrine. The researchers are also considering testing the blood pressure drug clonidine in the hopes that it may help the brain reach a more quiescent state.</p><p data-block="sciam/paragraph">Until these interventions are available, says sleep researcher Geoffroy Solelhac of the Center for Investigation and Research in Sleep in Switzerland, “just understanding that their sleep is objectively different is reassuring to patients. They feel a sort of relief.” Knowing all that may even help them sleep better.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All three game console makers have now abandoned X integration (115 pts)]]></title>
            <link>https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed</link>
            <guid>40646518</guid>
            <pubDate>Tue, 11 Jun 2024 14:24:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed">https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed</a>, See on <a href="https://news.ycombinator.com/item?id=40646518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As of June 10th, Nintendo has officially discontinued support for the Switch console’s integration with X (formerly Twitter), making it the last of the current-gen consoles to do so after <a href="https://www.theverge.com/2023/4/21/23692467/microsoft-disables-xbox-clip-sharing-to-twitter-from-consoles-and-pcs">Microsoft</a> and <a href="https://www.theverge.com/2023/11/6/23949343/playstation-x-sharing-options-ps5-ps4">Sony</a> disabled their own access last year.&nbsp;</p><p>The integration was removed as part of the <a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/22525/~/nintendo-switch-system-update-information">Nintendo Switch’s 18.1.0 update</a>, taking away the ability for users to link their X account with the console, or post in-game screenshots from <em>Super Smash Bros. Ultimate</em> directly to the social media platform. The removal of these features comprised the majority of the 18.1.0 update, which also includes some general stability improvements and ditches support for linking social media accounts via the Switch’s Friend Suggestions feature.</p><p>Nintendo announced these changes <a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/65057">last month</a> but didn’t explicitly state the reason for pulling support for X. Given Switch users can still share their content to Facebook, it likely has something to do with <a href="https://www.theverge.com/2023/3/30/23662832/twitter-api-tiers-free-bot-novelty-accounts-basic-enterprice-monthly-price">pricing changes to the X API</a> which now <em>starts</em> at <a href="https://developer.x.com/en/products/twitter-api/enterprise/enterprise-api-interest-form#:~:text=Enterprise%20API%20pricing%20starts%20at,based%20on%20usage%20and%20needs.&amp;text=Acknowledgment%20of%20X%20Terms%20%2D%20By,to%20accept%20messages%20from%20X.">$42,000 a month</a> for enterprise customers.</p><p>Microsoft didn’t mention X’s API update when it removed the ability for Xbox consoles to share game uploads to the service last April, nor did Sony when it followed suit in November for the PS5 and PS4. Cost may not be the only factor as <a href="https://www.theverge.com/2023/10/24/23930686/slack-x-twitter-integration-retires-api-pricing">Slack said it had also pulled support</a> because the API updates impacted the functionality of its own X integration, but regardless of the reason, console gamers will now have a hard time connecting directly with the platform.&nbsp;</p><p>That’s despite the <a href="https://www.theverge.com/2024/5/8/24152535/nintendo-switch-direct-sharing-to-x-twitter-ends-on-june-10th">X Gaming account saying</a> in a now-deleted post that its “partnership with Nintendo remains strong” after Nintendo announced its plans to kill Switch support.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox 127 (134 pts)]]></title>
            <link>https://www.mozilla.org/en-US/firefox/127.0/releasenotes/</link>
            <guid>40646477</guid>
            <pubDate>Tue, 11 Jun 2024 14:20:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mozilla.org/en-US/firefox/127.0/releasenotes/">https://www.mozilla.org/en-US/firefox/127.0/releasenotes/</a>, See on <a href="https://news.ycombinator.com/item?id=40646477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="outer-wrapper">
      
<main>
  <article id="main-content">

    
    <header>
      <div>
          
            <p>Version 127.0, first offered to Release channel users on June 11, 2024</p>
            
          
        </div></header>
  

    <section>
    
      
        
          <div>
              <ul>
        
        
  <li id="note-790131">
    <p>You can now set Firefox to automatically launch whenever you start or restart your Windows computer. Setting Firefox to auto-launch optimizes efficiency in our browser-centric digital routines, eliminating manual startup delays and facilitating immediate web access. (<a href="https://support.mozilla.org/kb/open-firefox-automatically-when-you-start-computer">Learn more</a>)</p>
    
  </li>

        
      
        
        
  <li id="note-790141">
    <p>We completed work to optimize and enable DNS prefetching for HTTPS documents via the <code>rel="dns-prefetch"</code> link hint. This standard allows web developers to specify domain names for important assets that should be resolved preemptively.</p>
    
  </li>

        
      
        
        
  <li id="note-790170">
    <p>It is now possible to close all duplicate tabs in a window with the <em>Close duplicate tabs</em> command available from the <em>List all tabs</em>  widget in the tab bar or a tab context menu.</p>
    
  </li>

        
      
        
        
  <li id="note-790194">
    <div>
      <p>Firefox will now automatically try to <a href="https://blog.mozilla.org/security/2024/06/05/firefox-will-upgrade-more-mixed-content-in-version-127/">upgrade <code>&lt;img&gt;</code>, <code>&lt;audio&gt;</code>, and <code>&lt;video&gt;</code> elements from HTTP to HTTPS</a> if they are embedded within an HTTPS page. If these so-called mixed content elements do not support HTTPS, they will no longer load.</p>
      
      
    </div>
    
  </li>

        
      
        
        
  <li id="note-790195">
    <p>For added protection on MacOS and Windows, a device sign in (e.g. your operating system password, fingerprint, face or voice login if enabled) can be required when accessing and filling stored passwords in the <a href="https://support.mozilla.org/kb/password-manager-remember-delete-edit-logins">Firefox Password Manager</a> about:logins page.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      
        
          
        
      

      
        
          <div>
              <ul>
        
          
  <li id="note-790142">
    <p>To reduce user fingerprinting information and the risk of some website compatibility issues, the CPU architecture for 32-bit x86 Linux will now be reported as x86_64 in Firefox's User-Agent string and <code>navigator.platform</code> and <code>navigator.oscpu</code> Web APIs.</p>
    
  </li>

        
      
        
          
  <li id="note-790143">
    <p>Links and other focusable elements are now tab-navigable by default on macOS, instead of following macOS' "Keyboard navigation" setting. This is a more accessible default and matches the default in all other platforms. A checkbox in the settings page still allows users to restore the old behavior.</p>
    
  </li>

        
      
        
          
  <li id="note-790169">
    <p>The Screenshots feature in Firefox has gotten a big update! It now supports taking screenshots of file types like SVG, XML, and more as well as various about: pages within Firefox. We've also made the screenshot tool more accessible to everyone by implementing new keyboard shortcuts and adding theme compatibility and High Contrast Mode (HCM) support. And finally, performance for capturing large screenshots has been improved.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      
        
          <div>
              <ul>
        
        
  <li id="note-790196">
    <div>
      <p>You can find information about policy updates and enterprise-specific bug fixes in the <a href="https://support.mozilla.org/kb/firefox-enterprise-127-release-notes">Firefox for Enterprise 127 Release Notes</a>.</p>
      
      
    </div>
    
  </li>

        
              </ul>
            </div>
        
      

      
      

      
        
        
          
        
      

      
        
          <div>
              <ul>
        
        
  <li id="note-790171">
    <p><code>navigator.clipboard.read()/write()</code> has been enabled (see <a href="https://developer.mozilla.org/docs/Web/API/Clipboard_API">documentation</a>). A paste context menu will appear for the user to confirm when attempting to read clipboard content that is not originated from a <code>same-origin</code> page.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      

      

      

      
        
          <div id="community">
            <ul>
        
        
  <li id="note-790193">
    <div>
      <p>With the release of Firefox 127, we are pleased to welcome the developers who contributed their first code change to Firefox in this release, 8 of whom were brand new volunteers! Please join us in thanking each of these diligent and enthusiastic individuals, and take a look at their contributions:</p>
<ul>
<li>alphare33: <a href="https://bugzilla.mozilla.org/1856611">1856611</a></li>
<li>ash: <a href="https://bugzilla.mozilla.org/1783183">1783183</a></li>
<li>Dongwoo Kang [:nyanrus]: <a href="https://bugzilla.mozilla.org/1891317">1891317</a></li>
<li>endington543: <a href="https://bugzilla.mozilla.org/1820570">1820570</a>, <a href="https://bugzilla.mozilla.org/1891816">1891816</a>, <a href="https://bugzilla.mozilla.org/1892348">1892348</a>, <a href="https://bugzilla.mozilla.org/1893985">1893985</a></li>
<li>jmc531: <a href="https://bugzilla.mozilla.org/1885695">1885695</a></li>
<li>Joseph Webster: <a href="https://bugzilla.mozilla.org/1825105">1825105</a>, <a href="https://bugzilla.mozilla.org/1893061">1893061</a>, <a href="https://bugzilla.mozilla.org/1894063">1894063</a></li>
<li>Leeya: <a href="https://bugzilla.mozilla.org/1742889">1742889</a></li>
<li>Steve P: <a href="https://bugzilla.mozilla.org/1836440">1836440</a>, <a href="https://bugzilla.mozilla.org/1844935">1844935</a>, <a href="https://bugzilla.mozilla.org/1880909">1880909</a></li>
</ul>
      
      
    </div>
    
  </li>

        
            </ul>
          </div>
        
      
    
    </section>

    <div>
      
      <p>
        <h2>Get the most recent version</h2>
        
      </p>
    </div>

    
    <section>
      <a href="https://www.mozilla.org/en-US/firefox/all/#product-desktop-release">All Firefox downloads</a>
    </section>
    

    
    
    
</article>
</main>


      
        




      

      
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Serve Dashboards (153 pts)]]></title>
            <link>https://briefer.cloud/blog/posts/self-serve-bi-myth/</link>
            <guid>40646312</guid>
            <pubDate>Tue, 11 Jun 2024 14:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://briefer.cloud/blog/posts/self-serve-bi-myth/">https://briefer.cloud/blog/posts/self-serve-bi-myth/</a>, See on <a href="https://news.ycombinator.com/item?id=40646312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Sales pitches are the only place where “self-serve dashboards" work. In the real world, it's a different story.</p>
<p>That story usually starts with an engineer or data scientist who's frustrated because they spend too much time writing queries and preparing dashboards for business people. They think that if they make BI easy enough, everyone will be able to “self-serve”, but that rarely ever happens.</p>
<p>What actually happens is that engineers and data scientists end up being the only people using the "self-serve" BI tool, which, ironically, makes it not self-serve at all.</p>
<br>
<h2>Why self-serve BI doesn't work</h2>
<p><strong>SQL is the only self-serve BI tool</strong>. Still, most "self-serve" BI vendors don't want to admit it, so they find ways to reinvent the wheel and disguise SQL as something else. Maybe that's what customers want to hear, or maybe they genuinely believe it, I'm not sure.</p>
<p>Either way, the problem with most approaches to "self-serve" BI is that they consider SQL to be the only barrier to business stakeholders querying data. That's not true.</p>
<p>Let's say you could wave a magic wand and make writing SQL queries as easy as writing an email. Do you think business stakeholders would suddenly start querying data? The answer is no.</p>
<p>Even if these people knew how to write SQL queries, they wouldn't understand the semantics of the data they're querying. They wouldn't know what the data means, where it comes from, or how it's calculated. They wouldn't know how to interpret the results, or how to validate them. In other words, writing the SQL query is actually the easy part.</p>
<p>Now, let's look at two attempts to make BI "self-serve" and see whether the hypothesis above holds.</p>
<br>
<h3>Attempt 1: The conventional "dropdowns and checkboxes" approach</h3>
<p>First, let's take a look at an example of a conventional "self-serve" BI interface which uses dropdowns and checkboxes as a way to make queries more accessible.</p>
<p><img src="https://briefer.cloud/posts/self-serve-bi/sql-by-mouse.png" alt=""></p>
<p>The first thing to notice is that this interface is just an attempt at what I call "SQL-by-mouse". I might be just an old grumpy person, but I don't see how this is any better than writing SQL. In fact, it's worse because it's slower, less reliable, more limited, and not generalizable to other tools.</p>
<p>In any case, I'll concede one thing: some non-technical people are just scared of any monospaced writing with syntax highlight, so this interface might be a good first step.</p>
<p>Anyway, let's ignore all these problems and just assume that this interface is the best thing since <a href="https://htmx.org/">htmx</a>. Let's assume that it's 100x easier to use than SQL.</p>
<p>Even if that were the case, your CFO, for example, wouldn't just go ahead and use these dropdowns and checkboxes to query data. The reason they wouldn't use it is that they don't have the context to understand the data they're querying, and they'll probably be insecure about the results, which they won't know how to validate because they don't understand how the data got there in the first place.</p>
<p>Now, I've got a question for you: if your CFO doesn't use this interface, who will? That's right, <em>you</em> will. And guess what's the first thing you'll do when you get to these dropdowns? Correct, you'll immediately look for somewhere to type in SQL. Oh, the irony.</p>
<br>
<h3>Attempt 2: The text-to-SQL approach</h3>
<p>Remember that magic wand that makes writing SQL queries as easy as writing an email? That's what text-to-SQL tools are. Nonetheless, they're not enough, just as I explained earlier.</p>
<p>Again, the problem is not the technology itself. In fact, LLMs are almost too effective at translating natural language into SQL. They will find a way to generate a query for any question you ask, even if that question doesn't make sense, which is exactly the problem.</p>
<p>On the other hand, a technical person would notice that the question doesn't make sense, and they would ask for more context. They would ask for details about the business person's hypothesis and the problem at hand. Then, they would explain what type of data is available, and work with the business person to formulate a precise and useful question.</p>
<p>Again, SQL is not the problem.</p>
<p>In any case, I do think LLMs could be the actual solution to self-serve BI, but not in its current form. For them to work, they'd need to be fed with more context, and <a href="https://allenpike.com/2024/llms-trained-on-internet">they need to get better at expressing uncertainty</a> and asking for more information.</p>
<br>
<h2>What actually works</h2>
<p>If we assume that the problem with self-serve BI is not SQL, but the context and semantics of the data, then it follows that the solution is to teach people about the data they're querying, regardless of interface.</p>
<p>The problem with this type of training is that it takes time, and most business stakeholders need answers this week, not next quarter.</p>
<p>Even in the best-case scenario, where companies train business stakeholders to understand the data they're querying, these people will need time to keep up with the changes in the database's schema, data models, and ETL processes.</p>
<p>Additionally, documenting all this knowledge generates significant overhead for the technical team, and it quickly gets out-of-date.</p>
<p>So what's the true solution to self-serve BI? The answer is simple: not to make BI self-serve for non-technical people. Instead, the solution is to make technical people support business stakeholders and help them do it more efficiently, using better tools.</p>
<p>The definition of a better tool may vary, but I have a few suggestions.</p>
<p>The first suggestion is to give LLMs to technical people, not business stakeholders. Even though text-to-SQL is not quite there in terms of understanding context and semantics, technical people <em>already</em> have context and semantics, so why not let <em>them</em> use it? That way, a single technical person can serve more business stakeholders, and do it faster.</p>
<p>The second suggestion is to give technical people more flexible tools. Instead of giving them dropdowns, or a SQL-only interface, let them play around with data using Python, R, or any other tool they're comfortable with. This way, they don't need to be passing data back and forth between different tools, and they're not limited by the capabilities of a BI tool.</p>
<p>The third and final suggestion is to make it easier for technical people to share their work. Notebooks and internal data applications are notoriously bad at that because they require others to deal with containers, dependencies, and infrastructure. It's a lot of overhead for a business stakeholder who just wants to see a chart. Instead, we need tools that have all the building blocks of a data application, but that are as easy to share as a Google Doc.</p>
<p>I'm obviously biased because I'm building <a href="https://briefer.cloud/">a data tool for technical people</a>, and it does exactly these three things. But what other choice do I have? I'd rather build tools that work than tools that don't. And, most importantly, I'd rather not pretend that the problem is something it's not.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I like the RP2040 (337 pts)]]></title>
            <link>https://dgroshev.com/blog/rp2040/</link>
            <guid>40646061</guid>
            <pubDate>Tue, 11 Jun 2024 13:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dgroshev.com/blog/rp2040/">https://dgroshev.com/blog/rp2040/</a>, See on <a href="https://news.ycombinator.com/item?id=40646061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      



  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/rp2040.jpg?hash=aa3e21f5" target="_blank">
  <img src="https://dgroshev.com/processed_images/rp2040.0c483830155c3532.jpg?hash=aa3e21f5" srcset="https://dgroshev.com/processed_images/rp2040.0c483830155c3532.jpg?hash=aa3e21f5, https://dgroshev.com/blog/rp2040/img/rp2040.jpg?hash=aa3e21f5 2x" alt="RaspberryPi's picture of a RP2040">
</a></p><p>The RP2040 is a microcontroller made by Raspberry Pi. Unlike their more widely known products, the
RP2040 is meant to be embedded in consumer electronics. It's cheap and available in tens of thousands
for immediate dispatch from your local Mouser.</p>
<p>I really like the RP2040 and I want you to know why.</p>
<h2 id="just-the-right-size">Just the right size</h2>
<p>Here is the Mouser stock for a microcontroller manufacturer Espressif:</p>




  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/espressif_stock.png?hash=7c8c85d9" target="_blank">
  <img src="https://dgroshev.com/processed_images/espressif_stock.72e7319c5dab554d.png?hash=7c8c85d9" srcset="https://dgroshev.com/processed_images/espressif_stock.72e7319c5dab554d.png?hash=7c8c85d9, https://dgroshev.com/blog/rp2040/img/espressif_stock.png?hash=7c8c85d9 2x" alt="A screenshot of the Mouser stock for Espressif microcontrollers">
</a></p><p>Dozens of slightly different controllers. Why?</p>
<p>Unlike software, physical products cost money to manufacture. Every cent saved on a gizmo's components
is a cent in earnings, which adds up when the gizmos are manufactured by the million. This creates an incentive 
to pick a microcontroller that is only just powerful enough (to "right size" it), and usually microcontroller 
manufacturers are happy to help, offering dozens of variations of the same microcontroller.</p>
<p>Here is the Mouser stock for Raspberry Pi:</p>




  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/raspberry_stock.png?hash=4680aaa1" target="_blank">
  <img src="https://dgroshev.com/processed_images/raspberry_stock.6cd109cef39fc572.png?hash=4680aaa1" srcset="https://dgroshev.com/processed_images/raspberry_stock.6cd109cef39fc572.png?hash=4680aaa1, https://dgroshev.com/blog/rp2040/img/raspberry_stock.png?hash=4680aaa1 2x" alt="A screenshot of Mouser stock for Raspberry microcontrollers">
</a></p><p>(This is the same microcontroller, just two different packaging options<sup><a href="#1">1</a></sup>.)</p>
<p>What?</p>
<h2 id="as-long-as-it-s-black">…as long as it's black</h2>
<p>Raspberry Pi pulled a Henry Ford and boldly went with just one microcontroller.</p>
<p>There is no choice, no right sizing, but that might be OK! An RP2040 costs ~70 cents, and not all gizmos are produced
by the million.</p>
<p>In return, Raspberry Pi ensured that everyone on the planet works with the same part. Compared to more traditional
wide lineups, there is a disproportionate number of StackExchange questions, blog posts (including this one), 
experience, Github issues, libraries, and tools for the RP2040<sup><a href="#2">2</a></sup>.</p>
<p>This is a good tradeoff for projects like <a href="https://late-mate.com/">Late Mate</a>, which are likely to save more on 
development costs than on parts<sup><a href="#3">3</a></sup>. </p>
<h2 id="down-the-stack">Down the stack</h2>
<p>This single model pragmatism is evident in the choices Raspberry Pi made for the microcontroller itself.
It is designed to be a jack-of-all-trades, trading "excellent" for "sufficient and flexible":</p>
<ul>
<li>Two decent cores. The second core is there if you need it.</li>
<li>30 GPIO pins, a very average number. </li>
<li>No on-board flash, spending the budget on more internal RAM that is much harder to wire externally.</li>
<li>An OK ADC, good USB support, and the usual peripherals (UART/SPI/I2C/PWM).</li>
</ul>
<p>Less conventionally, the RP2040 comes with a peripheral called "PIO" for Programmable Input/Output.
It's like two tiny coprocessors that can execute your IO fast, with precise timing, and without spending CPU time.
Some cool things people do with PIO:</p>
<ul>
<li>communication protocols like <a href="https://github.com/peterkrull/dshot-pio">DShot ESC</a></li>
<li><a href="https://github.com/sekigon-gonnoc/Pico-PIO-USB">a fully featured USB stack on PIO</a>, giving RP2040 
a second USB controller</li>
<li>coupled with DMA, <a href="https://dmitry.gr/?r=06.%20Thoughts&amp;proj=09.ComplexPioMachines">display drivers</a> that
completely offload display+touch communication from the CPU</li>
</ul>
<p>The RP2040 is impossible to brick. It comes with a read-only bootloader that can either mount as a USB mass storage device
(firmware updates can just be copypasted to the "storage device"), or use 
<a href="https://github.com/raspberrypi/picotool">its own simple USB protocol</a>.</p>
<p>In the same pragmatic vein, the RP2040 doesn't engage in security theatre. Protecting the firmware from a dedicated
attacker is nearly impossible, but there are complexity and DX costs to trying, so I'm glad Raspberry Pi 
made the call.</p>
<p>I just love the deliberate design of this little square of silicon. When I work with it, I can see how 
smart people thought hard about the niche the RP2040 is in and drove the tradeoffs accordingly. As an engineer 
<sup>aspiring to be good someday</sup>, I appreciate it.</p>
<p><a href="https://news.ycombinator.com/item?id=40646061">Discuss on Hackernews</a></p>
<p>
  More of ^this^ on <a href="https://mastodon.social/@dangroshev" target="_blank">Mastodon</a>,
  <a href="https://twitter.com/dangroshev" target="_blank">Twitter</a>,
  <a href="https://dgroshev.com/atom.xml">RSS</a>, or a
  <a href="https://buttondown.email/dgroshev" target="_blank">very occasional newsletter</a>.
</p>
<p>
  Or just let me know what you think at
  <a href="mailto:dan@dgroshev.com">dan@dgroshev.com</a>!
</p>
<hr>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new term, ‘slop’, has emerged to describe dubious A.I.-generated material (211 pts)]]></title>
            <link>https://www.nytimes.com/2024/06/11/style/ai-search-slop.html</link>
            <guid>40645983</guid>
            <pubDate>Tue, 11 Jun 2024 13:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/06/11/style/ai-search-slop.html">https://www.nytimes.com/2024/06/11/style/ai-search-slop.html</a>, See on <a href="https://news.ycombinator.com/item?id=40645983">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/06/11/style/ai-search-slop.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Titan Submersible Disaster. The Inside Story Is More Disturbing (108 pts)]]></title>
            <link>https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/</link>
            <guid>40645439</guid>
            <pubDate>Tue, 11 Jun 2024 12:29:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/">https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/</a>, See on <a href="https://news.ycombinator.com/item?id=40645439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>The Ocean Sciences</span> Building at the University of Washington in Seattle is a brightly modern, four-story structure, with large glass windows reflecting the bay across the street.</p><p>On the afternoon of July 7, 2016, it was being slowly locked down.</p><p>Red lights began flashing at the entrances as students and faculty filed out under overcast skies. Eventually, just a handful of people remained inside, preparing to unleash one of the most destructive forces in the natural world: the crushing weight of about 2½ miles of ocean water.</p><p>In the building’s high-pressure testing facility, a black, pill-shaped capsule hung from a hoist on the ceiling. About 3 feet long, it was a scale model of a submersible called <em>Cyclops 2</em>, developed by a local startup called <a href="https://www.wired.com/story/titan-sub-oceangate-hull-failure-loss-tragedy/">OceanGate</a>. The company’s CEO, Stockton Rush, had cofounded the company in 2009 as a sort of submarine charter service, anticipating a growing need for commercial and research trips to the ocean floor. At first, Rush acquired older, steel-hulled subs for expeditions, but in 2013 OceanGate had begun designing what the company called “a revolutionary new manned submersible.” Among the sub’s innovations were its lightweight hull, which was built from carbon fiber and could accommodate more passengers than the spherical cabins traditionally used in deep-sea diving. By 2016, Rush’s dream was to take paying customers down to the most famous shipwreck of them all: the <em>Titanic</em>, 3,800 meters below the surface of the Atlantic Ocean.</p><p>Engineers carefully lowered the <em>Cyclops 2</em> model into the testing tank nose-first, like a bomb being loaded into a silo, and then screwed on the tank’s 3,600-pound lid. Then they began pumping in water, increasing the pressure to mimic a submersible’s dive. If you’re hanging out at sea level, the weight of the atmosphere above you exerts 14.7 pounds per square inch (psi). The deeper you go, the stronger that pressure; at the <em>Titanic</em>’s depth, the pressure is about 6,500 psi. Soon, the pressure gauge on UW’s test tank read 1,000 psi, and it kept ticking up—2,000 psi, 5,000 psi. At about the 73-minute mark, as the pressure in the tank reached 6,500 psi, there was a sudden roar and the tank shuddered violently.</p><p>“I felt it in my body,” an OceanGate employee wrote in an email later that night. “The building rocked, and my ears rang for a long time.”</p><p>“Scared the shit out of everyone,” he added.</p><p>The model had imploded thousands of meters short of the safety margin OceanGate had designed for.</p><p>In the high-stakes, high-cost world of crewed <a href="https://www.wired.com/tag/submarines/">submersibles</a>, most engineering teams would have gone back to the drawing board, or at least ordered more models to test. Rush’s company didn’t do either of those things. Instead, within months, OceanGate began building a full-scale <em>Cyclops 2</em> based on the imploded model. This submersible design, later renamed <em>Titan</em>, eventually made it down to the <em>Titanic</em> in 2021. It even returned to the site for expeditions the next two years. But nearly one year ago, on June 18, 2023, <em>Titan</em> dove to the infamous wreck and imploded, instantly <a href="https://www.wired.com/story/titan-sub-debris-found/">killing all five people onboard</a>, including Rush himself.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The disaster captivated and horrified the world. Deep-sea experts criticized OceanGate’s choices, from <em>Titan</em>’s carbon-fiber construction to Rush’s public disdain for industry regulations, which he believed stifled innovation. Organizations that had worked with OceanGate, including the University of Washington as well as the Boeing Company, released statements denying that they contributed to <em>Titan</em>.</p><p>A trove of tens of thousands of internal OceanGate emails, documents, and photographs provided exclusively to WIRED by anonymous sources sheds new light on <em>Titan</em>’s development, from its initial design and manufacture through its first deep-sea operations. The documents, validated by interviews with two third-party suppliers and several former OceanGate employees with intimate knowledge of <em>Titan</em>, reveal never-before-reported details about the design and testing of the submersible. They show that Boeing and the University of Washington were both involved in the early stages of OceanGate’s carbon-fiber sub project, although their work did not make it into the final <em>Titan</em> design. The trove also reveals a company culture in which employees who questioned their bosses’ high-speed approach and decisions were dismissed as overly cautious or even fired. (The former employees who spoke to WIRED have asked not to be named for fear of being sued by the families of those who died aboard the vessel.) Most of all, the documents show how Rush, blinkered by his own ambition to be the Elon Musk of the deep seas, repeatedly overstated OceanGate’s progress and, on at least one occasion, outright lied about significant problems with <em>Titan</em>’s hull, which has not been previously reported.</p><p>A representative for OceanGate, which ceased all operations last summer, declined to comment on WIRED’s findings.</p><figure><p><span><p>OceanGate CEO Stockton Rush aboard the <em>Cyclops 1</em> in 2015.</p>
</span><span>Photograph: Courtesy of Mark Harris</span></p></figure><p><span>I met Stockton</span> Rush on June 24, 2015, while reporting on OceanGate for New Scientist magazine. A former flight engineer and tech investor, Rush was already styling himself a subaquatic Musk. “I wanted to be the first person on Mars until I realized there was nothing there,” Rush told me at a city center dock in Seattle. “But in the ocean, there are new life-forms, things people have never discovered.” Rush believed that Earth’s oceans, not outer space, were where humanity would find refuge from existential risks like climate change. “My goal is to move the needle,” he told me.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Around us, employees were prepping OceanGate’s prototype submersible, the <em>Cyclops 1</em>, for its deepest dive to date. The sub was a cylindrical, steel-hulled design rated for dives up to 500 meters. OceanGate had acquired it a few years earlier and refurbished it, adding LEDs and a PlayStation controller for easy steering, and replacing an ugly exterior cabin with a sleek white plastic fairing to protect components outside the hull. Together with the large acrylic viewport, the effect was a sort of one-eyed robot shark. Up to five people could squeeze inside—which is what Rush and I were about to do, for a test dive in Seattle’s Elliott Bay.</p><p>Ninety minutes later and 130 meters deeper, we were totally lost. First the thruster software had glitched, leaving us floating just above the seafloor. Now the sub’s compass was acting up. The shipwreck we aimed to explore, a rail ferry that had once carried Teddy Roosevelt, was nowhere to be seen. All I could spy outside the <em>Cyclops</em>’ forward dome was the occasional salmon dancing in the frigid water.</p><p>As I began to feel the chill seeping through the sub’s steel hull, Rush asked me to open my iPhone’s compass app. He wanted to compare it to the one on his phone. The headings did not match, but he rebooted the thrusters and we set off in what he was pretty sure was the right direction.</p><p>“You’re heading in exactly the wrong direction,” said a faint voice transmitted via an acoustic link from the support ship tracking us on the surface. We eventually located the sunken ship, its rotting bow emerging into the <em>Cyclops</em>’ headlight. It was an otherworldly experience, made more thrilling by the hint of danger.</p><p>Back at the dock, Rush brushed off the problems we had encountered. This is exactly why OceanGate started with the <em>Cyclops 1</em>, he said, rather than anything capable of diving deeper. “I could have built a multimillion-dollar version and all of a sudden I’ve got to figure out really stupid stuff like the magnetic compass,” he told me. “The <em>Cyclops 1</em> is getting us ready. When we do the <em>Cyclops 2</em>, then all these bugs will be out.”</p><p>The <em>Cyclops 2</em>, which Rush renamed <em>Titan</em> in 2018, was already on the drawing board. And Rush believed he had the biggest bug—how to make a vessel that could safely dive 20 times deeper than America’s nuclear subs—worked out. He would use a modern wonder material: carbon fiber.</p><p>Carbon-fiber composites are some of the strongest materials available to engineers. They are formed of thin strands of atomic carbon within plastic resins, layer upon layer, then cured carefully at high temperatures. The resulting composites can be both stronger and lighter than titanium, and it was this combination that caught Rush’s attention. A carbon-fiber <em>Titan</em> could be roughly the same size and weight as the steel <em>Cyclops</em> and yet be able to dive up to 12 times deeper. It would be much cheaper for a support vessel to carry and deploy at sea than a metal sub, and would also be more buoyant, reducing the risk of getting stranded on the ocean floor. While carbon fiber has been used in everything from cars to rockets, no one had ever dived in a deep-water carbon-fiber submersible. Rush wanted to be the first.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In 2013, OceanGate struck up a partnership with the University of Washington’s Applied Physics Laboratory to develop the new sub. The university has a long history of working with composites and designing its own underwater vehicles. It also already had a relationship with OceanGate, after using its subs for research; the physics lab helped write the software used by <em>Cyclops 1</em>. The university touted the arrangement in press releases at the time: “UW, Local Company Building Innovative Deep-Sea Manned Submarine,” read one headline from October 2013. The story was updated with a note in 2023 saying that “the vessel that resulted from this partnership” was the <em>Cyclops 1</em>. Emails from OceanGate leaked exclusively to WIRED indicate that UW researchers provided hundreds of detailed 3D CAD drawings of components for a carbon-fiber sub between 2013 and 2016, as part of a $5 million contract. But the relationship between the lab and OceanGate was contentious, according to emails.</p><p>UW claims that OceanGate and the lab parted ways after just $650,000 worth of work, and former OceanGate employees told WIRED that none of UW’s hardware or software work wound up in the finished sub.</p><p>OceanGate also announced that Boeing Research &amp; Technology was helping with the project. In October 2013, two engineers at Boeing, Mark Negley and William Koch, produced a detailed 70-page preliminary design containing renderings, manufacturing advice, and technical analysis. These details of Boeing’s involvement have not been reported before. “Boeing was not a partner on the <em>Titan</em> and did not design or build it,” Jessica Kowal, a spokesperson for Boeing, said in a statement. The company declined to answer on the record any other questions from WIRED. Negley and Koch, who are still employed by Boeing, did not respond to LinkedIn messages.</p><p>Even at this early stage, these engineers were warning of potential problems ahead.</p><p>Negley and Koch pointed out that although composites can be stronger than any metal, they have other challenges. Carbon fiber can get progressively weaker, sometimes in unexpected ways. The manufacturing process can introduce defects if the resin is cured too long or not long enough, if debris gets in, or if the material is laid or wound unevenly. And the more layers a structure has, the engineers wrote, the greater the risk of a defect that would weaken it. <em>Titan</em> would ultimately have 660 layers of carbon fiber. To mitigate these risks, the Boeing engineers suggested a rigorous quality assurance process during manufacture and ultrasound testing of the hull after it was made. Ultrasound scans could find defects or delaminations in the hull—places where the carbon-fiber layers had separated.</p><p>To manufacture the hull, Rush turned to a company called Spencer Composites. First, though, OceanGate needed a scaled-down model of the hull to test how it would fare against the intense pressures at the bottom of the sea. By 2015, according to a design document written by Spencer, OceanGate wanted its hull to be rated up to 6,000 meters and have a safety factor of up to 2.25—meaning that it should be stable to two and a quarter times that depth, or 13,500 meters. James Cameron’s record-setting <em>Deepsea Challenger</em> had a safety factor of 1.36. <em>Alvin</em>, the submersible that originally explored the <em>Titanic</em>, had a 1.8 or higher. (Spencer Composites did not respond to requests for comment.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In June 2015, just before my trip in <em>Cyclops 1</em>, engineers placed a one-third scale model of <em>Titan</em> in an 8-foot-long testing tank at APL-UW for its first pressure test. This model was built entirely of carbon fiber, including the end domes, which ended up failing at pressures equating to around just 3,000 meters, according to a report written by Rush. OceanGate commissioned Spencer to make more domes, but these would take months to arrive. Meanwhile, the cylinder was tested again, this time with solid aluminum discs on the ends, and reached 4,100 meters without incident. But when OceanGate received the new carbon-fiber domes and tested the hull in March 2016, the new domes again imploded at 3,000 meters.</p><p>The test that “scared the shit out of everyone,” in one engineer’s words, was OceanGate’s fourth. This time, the hull (again with aluminum caps) reached the equivalent of 4,500 meters before imploding, giving it a miserly 1.18 safety factor for any dives to <em>Titanic</em> depths.</p><figure><p><span><p>Damage to the scale model after imploding in the testing tank.</p>
</span><span>Photograph: Courtesy of a former OceanGate employee</span></p></figure><p>“Over the next months we will analyze the data in detail … and then run a test with a new cylinder through at least 1,000 cycles to confirm its durability,” Rush wrote to shareholders at the time. That replacement scale model was not made, and the new tests never happened, former employees tell WIRED, in part because Rush trusted OceanGate’s computer models. Even when OceanGate decided to change the domes in the final design from carbon fiber to titanium, Rush didn’t commission models to test the interactions between the new materials; one former employee who was familiar with Rush’s decision says the CEO balked at the high price tag.</p><p>“The modeling says it’s OK. The analysis says it’s OK,” one former employee says. “We build airplanes on the same type of analysis and then we go throw people in them.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But a low-pressure environment, like flying, is different from a high-pressure one. Carbon fiber is inherently stronger when holding pressure in, like what happens with an aircraft in the stratosphere, than when keeping pressure out, as happens underwater. And all cylindrical vessels resist buckling better when the air pressure is higher inside.</p><p>Submersible experts not associated with OceanGate told WIRED that they would do much more testing on a new design. “We did at least 10 scale-model pressure hulls that we tested to destruction,” says Adam Wright, an engineer who had worked on explorer Steve Fossett’s 2005 carbon-fiber sub, which was shelved after Fossett died in a plane crash. And that was for a submersible that would only be used for a single mission. OceanGate was planning to use its submersible repeatedly—up to 10,000 times, according to internal design documents.</p><p>“Carbon fiber is a very sensible material if it’s been engineered correctly and manufactured in a controlled way,” says Chase Hogoboom, president and cofounder of Composite Energy Technologies, which has successfully tested small carbon-fiber vessels to the equivalent of 6,000 meters hundreds of times. “It takes millions of dollars and many years, but it’s not rocket science. It’s just connecting the dots.”</p><p>OceanGate tested the model hull to destruction only once, and never used the titanium components that would become fixtures on the final sub. Instead, the company simply increased the thickness of the carbon-fiber hull in its design specs from 4.5 to 5 inches, and commissioned Spencer to build the real thing. (Later, OceanGate engineers found that <em>Titan</em>’s full-size hull was too thick for portable ultrasonic scanners, and a coating Spencer had applied to it would further block the signals. Rush decided that moving the entire sub to a lab for scanning would be too expensive, says a former employee who was familiar with Rush’s thinking. As a result, no scans were made—going against the advice of both Boeing and OceanGate engineers.)</p><figure><p><span><p>Key components of the <em>Titan</em> submersible</p>
</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Unlike <em>Cyclops 1</em>, with its large, 180-degree viewing dome, <em>Titan</em>’s front dome was made of solid titanium, with a smaller 23-inch viewport in the center. The viewport, made from 9-inch-thick acrylic, was an entirely new design by Tony Nissen, OceanGate’s director of engineering, and it was going to be manufactured by a company called Hydrospace Group.</p><p>Will Kohnen, Hydrospace’s CEO, told WIRED that he had originally expected Rush to thoroughly test the viewport according to rigorous standards set by the American Society of Mechanical Engineers. Under those standards, OceanGate would test at least five windows to destruction at high pressure, cycle a viewport from low to high pressure a thousand times, and subject another viewport to five times the intended pressure for 300 consecutive hours to see how much the plastic slowly shrank under pressure, says Kohnen.</p><p>“The more innovative you get, the more testing you’ve got to do,” Kohnen says. “Over a period of years, it was pretty obvious that OceanGate wasn’t going to do the testing.” The former employees who spoke to WIRED also said that OceanGate wasn’t testing the viewport to the society’s standards.</p><p>By the fall of 2017, Kohnen was getting worried. As a last-ditch effort, in November he sent Rush an email offering “a serious discount” to build a second viewport using a design that had been tested and certified to 4,000 meters. It could be swapped out for the experimental window within 24 hours, he wrote. Kohnen says that Rush told him he wasn’t interested.</p><p>Kohnen delivered OceanGate’s viewport in December. He would rate it to only 650 meters—one-sixth of the depth to the <em>Titanic</em>. He also shared an analysis, done pro bono by an independent expert, concluding that OceanGate’s design might fail after only a few 4,000-meter dives. OceanGate nevertheless installed the viewport in <em>Titan</em> later that month. Construction on the sub was almost complete, and the company was already advertising its first expedition to the <em>Titanic</em> in May.</p><p><span>It was time</span> for the engineers to hand it over to OceanGate’s operations team for testing at sea. But there was another snag. David Lochridge, who oversaw marine operations at the company and who needed to sign off on the transfer, became convinced that <em>Titan</em> was unsafe. In January 2018, Lochridge sent Rush a quality-control inspection report detailing 27 issues with the vehicle, from questionable O-ring seals on the domes and missing bolts to flammable materials and more concerns about its carbon-fiber hull. Rush fired him the next day. (Although Lochridge later made a whistleblower report to the Occupational Safety and Health Administration about <em>Titan</em>, Rush sued him for breach of contract. The settlement of that lawsuit resulted in Lochridge dropping his complaint, paying OceanGate nearly $10,000, and signing an NDA. Lochridge did not respond to WIRED.)</p><p>Will Kohnen also couldn’t forget about <em>Titan</em>, and the foreboding he had about the whole enterprise. “We have a rogue element within the submersible industry,” he remembers thinking. If something went wrong with <em>Titan</em>, it might scare people off deep-sea exploration more widely. In March 2018, he drafted a letter, signed by more than 30 crewed submersible experts, urging Rush to test the vessel with an accredited outside group. (The letter was earlier <a href="https://www.nytimes.com/2023/06/20/us/oceangate-titanic-missing-submersible.html">reported</a> by the New York Times.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Virtually all marine vessels are certified by organizations such as the American Bureau of Shipping, DNV, or Lloyd’s Register, which ensure that they are built using approved materials and methods and carry appropriate safety gear. It has been widely reported that Rush was dismissive of such certification, but what has not been made public until now is that OceanGate pursued certification with DNV (then known as DNV GL) in 2017—until Rush saw the price. “[DNV] informed me that this was not an easy few thousand dollar project as [it] had presented, but would cost around $50,000,” he later wrote in an email to Rob McCallum, a deep-sea explorer who had also signed Kohnen’s letter.</p><p>“<em>Titan</em> and its safety systems are way beyond anything currently in use … I have grown tired of industry players who try to use a safety argument to stop innovation and new entrants from entering their small existing market,” Rush wrote to McCallum. “Since [starting] OceanGate we have heard the baseless cries of ‘you are going to kill someone’ way too often.”</p><p>Days later, Rush received an even more pointed warning from Boeing’s Mark Negley, who had stayed in contact with the CEO after he helped with a preliminary design. Negley had recently carried out an analysis of Spencer Composites’ hull based on information Rush had shared. He did not mince words when sharing his findings, which WIRED is reporting for the first time. “We think you are at a high risk of a significant failure at or before you reach 4,000 meters. We do not think you have any safety margin,” he wrote in an email on March 30. “Be cautious and careful.”</p><p>Negley provided a graph charting the strain on the submersible against depth. It shows a skull and crossbones in the region below 4,000 meters.</p><figure><p><span><p>The chart Mark Negley shared with Stockton Rush</p>
</span><span>Chart: Courtesy of a former OceanGate employee</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Despite repeated warnings, Rush seemed unfazed. His confidence in <em>Titan</em> was based in part on the new safety systems OceanGate had designed. “A lot of risk mitigation was supposed to ride on the real-time health monitoring,” says one former employee. The heart of that system, designed by an experienced electrical engineer and OceanGate board member named Mike Furlotti, was a suite of sensors and microchips that analyzed the hull’s acoustic emissions—the little pops made by carbon fibers as they break under compression. OceanGate’s theory was that the hull would be fairly noisy on its first few dives but would get quieter when taken to the same depths over and over, one former employee explains. If the acoustic monitoring system started getting really loud on a dive, that would be a clear indication to surface immediately. (Multiple attempts to contact Furlotti for comment were unsuccessful.)</p><p>Wright and other industry experts have been extremely critical of this setup. “I’m sure you can pick up these acoustic events fine, but you just don’t know when the end point is,” he says. “You don’t know how many pops is too many, and it could be different for every vessel.”</p><p>There was even skepticism within OceanGate itself. In September 2017, the engineer responsible for integrating Furlotti’s design into <em>Titan</em> sent an anxious email to management expressing concerns about the system’s ability to accurately track fiber breakage over time.</p><p>OceanGate hired an outside consultant named Allen Green to assess the acoustic monitoring. Green, an authority on the sounds that materials make under stress, endorsed the system in 2018. Later, though, when Green saw how Rush was describing the system to the public—the CEO claimed it could detect the sound of “micro-buckling” in the sub’s hull “way before it fails”—he wrote a concerned email to an OceanGate employee, reported here for the first time.</p><p>Rather than warning of failure, Green explained that the sounds indicated “irreversible” damage. “It is my belief, substantiated by many years of experience, that composite structures all have a finite lifetime,” wrote Green, who died in 2021. “While I do not intend to be an alarmist, I did not sleep well and arose early to send this message.”</p><p><span>Rush had pitched</span> OceanGate’s board and investors on a grand vision of what his company could be. By 2018, that included a fleet of self-driving <em>Titan</em>s that could dive to 6,000 meters, and satellite offices in Croatia, Israel, and the South Pacific. He imagined a world whose oceans were populated by OceanGate’s crewed underwater bases, which could be used for data storage or even “Plan B habitats” for billionaire preppers.</p><p>Reality was more prosaic. Like most startups, OceanGate was in constant need of funds. Rush was trying to save money wherever he could. Interns, who made up around a third of the engineering team, were paid as little as $13 an hour. (When a manager pointed out in 2016 that Washington’s minimum wage was just $9.47 an hour, Rush responded, “I agree we are high. $10 seems fair.”) Rush also downgraded the sub’s titanium components from aerospace grade 5 quality to weaker and cheaper grade 3, says one former employee.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>According to internal documents, by 2018 the company had raised around $9 million in venture capital and another $4 million from subsidiary companies that profited off OceanGate’s research and scientific missions. But the real business opportunity would be trips to the <em>Titanic</em>.</p><p>Rush had planned six missions to visit the legendary shipwreck in the summer of 2018, each with nine people paying $105,000. With every mission bringing in nearly a million dollars in revenue but costing OceanGate only an estimated $333,000, the more visits <em>Titan</em> could make to the bottom of the North Atlantic, the better. Although the plan was for the finished sub to make more than 30 dives in shallow water before going to deeper waters, OceanGate managed just 18.</p><p>In mid-April, <em>Titan</em> was transported to Marsh Harbour in the Bahamas, where deep water could be found very close to land. But before <em>Titan</em> was even moved into the water, it was hit by lightning, damaging its electronics. Some of the damaged equipment was replaced, but the sub was without many components for weeks. Rush nevertheless insisted on attempting a shallow dive during high, rolling seas.</p><p>Choppy waves ripped fairings and foam from <em>Titan</em> as it was being towed back from the dive site, causing it to sink. “I was merely ‘spam in the can’ with no comms for 9+ hours inside the sub,” Rush wrote the next day. “I could see parts of the sub floating away on my cameras, but could not communicate to the tow team—a remarkably surreal and frustrating experience.”</p><p>Rush had to face facts: There was now no chance of OceanGate reaching the <em>Titanic</em> in 2018. Eager ticket holders (and investors) would have to wait another year.</p><p>While they were still in the Bahamas, the team did manage to lower <em>Titan</em> on a series of uncrewed dives, eventually reaching 4,000 meters. But engineers found the hull was warping more under compression than it was meant to, by perhaps as much as 37 percent. Nevertheless, Rush wanted to keep diving deeper with <em>Titan</em>, with himself at the helm. When one engineer expressed concern about performing crewed tests at this point, Nissen wrote to him, “Yesterday I told you if you don’t have the stomach for this type of engineering then OceanGate isn’t for you.”</p><p>On December 10, Rush successfully dove <em>Titan</em> to a depth of 3,939 meters—just enough to get to the <em>Titanic</em>. Nissen wrote to the engineering team: “Diving to such deep depths is extremely complicated if you want to be untethered, communicate with the surface, be location tracked with reasonable accuracy, and monitor the health of your vehicle. And, we have delivered. You all have a lot to brag about.”</p><p><em>Titan</em> reached a similar depth again in April, with a crew of four including Rush. While OceanGate touted the dive as history-making proof of its submersible’s bona fides, even Rush was getting worried about loud noises the hull was making at depth. Then on June 7, three weeks before <em>Titan</em>’s maiden voyage to the <em>Titanic</em>, an OceanGate pilot inspecting the interior with a flashlight noticed a crack in the hull. He sent Rush an email warning that the crack was “pretty serious.” A detailed internal report later showed that at least 11 square feet of carbon fiber had delaminated—meaning the bonds between layers had separated.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This time, Rush couldn’t ignore the data. The hull that was meant to last for 10,000 dives to the <em>Titanic</em> had made fewer than 50—and only three to 4,000 meters. It would have to be scrapped, and the <em>Titanic</em> missions would be delayed for yet another year. When Rush shared the news with <a data-offer-url="https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/&quot;}" href="https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/" rel="nofollow noopener" target="_blank">GeekWire</a> a few days later, however, he blamed the delay on legal complications with <em>Titan</em>’s support vessel.</p><p>It’s true that OceanGate ran into issues with maritime law, says one former employee: “The lie is that it was not the reason we delayed.”</p><p><span>After the crack</span> was found in <em>Titan</em>’s hull, OceanGate started searching for a new carbon-fiber contractor. By early 2020, many OceanGate engineers had been laid off or had left the company, insiders say. Tony Nissen was out, and a team that had once numbered more than 20 was reduced to just a handful. “Stockton never really wanted an engineering team, but he needed somebody to build it,” says one insider. “We were down to a skeleton team,” says another.</p><p>Rush then announced that the company had inked a partnership with NASA to “collaborate on the development, manufacturing, and testing” of a new carbon-fiber cylinder. (Covid-19 had other plans, shutting down NASA for months. Ultimately, the agency told ABC, “NASA did not conduct testing and manufacturing via its workforce or facilities.”)</p><p>The new hull would instead be made by two aerospace firms in Washington state, Electroimpact and Janicki Industries. Electroimpact laid the carbon fibers, and Janicki cured the material in its ovens, confirmed one former employee. Electroimpact did not provide a response to questions about its role, and Janicki declined to comment.</p><p>This time, OceanGate had two scale models made, which were once again tested at the University of Washington. Once again, the models imploded early, possibly due to warping of the hulls during manufacturing, says a former employee.</p><p>OceanGate scrambled to solve the issue. One idea: Rather than cure all the layers at once, they would cure the hull in stages. Electroimpact would wind about 100 layers of the hull, then ship it to Janicki to cure and settle. Then Janicki would send the hull back to Electroimpact to repeat the process. They were running out of time, so they went for it—skipping tests of the new procedure on samples and going straight to manufacturing the second hull. “The first time we did multiple cures was when we did the full hull,” says one former employee. The new hull was finished by January 2021. It passed pressure testing, similar to what was done at the University of Washington, but at a facility in Maryland that could accommodate the full-size cylinder.</p><p>OceanGate’s engineers now needed to integrate the new hull with the rest of <em>Titan</em>. But <em>Titan</em>’s two titanium domes were still attached to each end of the old hull, sitting on titanium rings glued to the carbon fiber with aerospace-grade epoxy adhesive. Commissioning new titanium interface rings and domes was ruled “an absolute no” by Rush, one former employee says, because of the extra cost and delay. The company that made the original titanium components told WIRED that it did not make new rings for Rush, and three former employees say that OceanGate did, in fact, salvage and reuse the originals.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But staff had difficulty working out how to separate the old hull from the interface rings without damaging even a sliver of titanium. Gaps or bumps could have weakened the join with the new hull, say the sources. On dives, the hull and the rings needed to compress under pressure in perfect harmony. “I can’t imagine a situation where you could reuse the titanium rings,” Wright, the independent engineer, says. OceanGate somehow managed it.</p><p>By February 2021, photos of the newly reconstructed <em>Titan</em> were popping up on OceanGate’s Facebook page and other social media. After the implosion in 2023, one ex-employee looked back at these and noticed an unexpected addition: The company had added metal lifting points to both interface rings, apparently to provide a new way to hoist <em>Titan</em> into and out of the water. The addition of the lifting rings, reported by WIRED for the first time, was confirmed by a former employee who saw the engineering drawings, and by another source.</p><p>Previously, OceanGate had lifted <em>Titan</em> using a sling beneath the sub to avoid putting stress on the critical joins between the rings and the carbon-fiber hull. As far back as 2017, when the original <em>Titan</em> was first shipped to OceanGate, Nissen had warned the operations team to use only the sling: “The titanium cannot take load/tension.”</p><p>“Lifting points are a very serious part of a pressure vessel design and must be considered carefully, tested, and qualified,” says Will Kohnen. “Any lifting arrangement may impose loads and stresses into the pressure vessel, and this must be mitigated by analysis and test.” It is unclear whether such analysis or tests were carried out.</p><figure><p><span><p>OceanGate originally used a sling system to lower its sub into the water, shown here.</p>
</span><span>Photograph: Courtesy of a former OceanGate employee</span></p></figure><p>The diving season was about to begin, and after three years of expensive delays, OceanGate desperately needed income from the <em>Titanic</em> missions (whose tickets now cost $125,000 per person). “We were running out of time,” says a former OceanGate employee. <em>Titan</em> had only a few relatively shallow dives in Puget Sound before the company put it on a truck and sent it all the way across Canada to Newfoundland, the port closest to the <em>Titanic</em> wreck.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>On July 13, 2021, OceanGate’s <em>Titan</em> made its first successful dive to the <em>Titanic</em>, with Rush serving as the pilot. “We had to overcome tremendous engineering, operational, business, and finally Covid-19 challenges to get here, and I am so proud of this team and grateful for the support of our many partners,” Rush said in a <a data-offer-url="https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm&quot;}" href="https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm" rel="nofollow noopener" target="_blank">press release</a>.</p><p>After the 2021 expedition, OceanGate was flush with success. The company announced plans for the following year’s expedition to document the wreck “in more detail than ever before” and urging “aspiring mission specialists” to get in touch.</p><p>The successes and warm media coverage continued in 2022. OceanGate was profiled by <em>CBS Sunday Morning</em>, which accompanied one of the missions that summer. When reporter David Pogue noticed how improvised the setup on the sub was, Rush reassured him. “The pressure vessel is not MacGyver at all, because that’s where we worked with Boeing and NASA and the University of Washington. Everything else can fail, your thrusters can go, your lights can go. You’re still going to be safe.” The rest of Pogue’s mission was sort of a farce—the sub got lost, things broke—but he came back safely.</p><p>That’s not what happened the following year. In June 2023, five eager people got ready to dive back down to the <em>Titanic</em>. They were Rush; Paul-Henri Nargeolet, a deep-sea explorer; and three paying passengers: a businessman named Hamish Harding and a father-son duo, Shahzada and Suleman Dawood. On June 18, they sealed <em>Titan</em> and dove. Within two hours, the support ship had lost contact with them.</p><p>Their disappearance set off a media frenzy. People speculated how long the crew might be able survive without power or aid. A massive search-and-rescue operation spent four days combing the sea before finding debris from the sub. The US Navy later confirmed it had detected loud sounds “consistent with an implosion” shortly after contact with <em>Titan</em> ended. OceanGate ceased its commercial and exploration activities a few weeks later.</p><p>The US Coast Guard is currently leading an international investigation into the deaths.</p><p>Several former employees said they were neither shocked nor surprised at OceanGate’s deadly accident. Three had left the company on safety grounds, and two separately described <em>Titan</em> as a ticking time bomb.</p><p>One former employee remembers preparing <em>Titan</em> for multiple successful <em>Titanic</em> missions, prior to 2023. “I put my heart and soul into building that sub,” he says. “Many, many hours inside the sub, outside the sub, building and testing it. She was my baby.”</p><p>Each time <em>Titan</em> was about to dip beneath the waves, he would pat her hull lightly. “I’d say, ‘Come on back to me baby, you’ll make it, you can do it.’ And when she’d come back up to the surface, I’d say, ‘Good job. You got everyone back up safe.’”</p><p>Until one day, she didn’t.</p><p>Now the bottom of the North Atlantic is littered with more evidence of human hubris, tiny pieces of a plastic video-game controller nestling among the barnacle-encrusted gold fixtures of the <em>Titanic</em>. Both vessels were at the cutting edge of technology, both exemplars of safety in the eyes of their overconfident creators. And in both cases, their passengers paid the price.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Battery-swap networks are preventing emergency blackouts (121 pts)]]></title>
            <link>https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/</link>
            <guid>40644745</guid>
            <pubDate>Tue, 11 Jun 2024 10:54:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/">https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/</a>, See on <a href="https://news.ycombinator.com/item?id=40644745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>On the morning of April 3, Taiwan was hit by a 7.4 magnitude earthquake. Seconds later, hundreds of battery-swap stations in Taiwan sensed something else: the power frequency of the electric grid took a sudden drop, a signal that some power plants had been disconnected in the disaster. The grid was now struggling to meet energy demand.&nbsp;</p>  <p>These stations, built by the Taiwanese company Gogoro for electric-powered two-wheeled vehicles like scooters, mopeds, and bikes, reacted immediately. According to numbers provided by the company, 590 Gogoro battery-swap locations (some of which have more than one swap station) stopped drawing electricity from the grid, lowering local demand by a total six megawatts—enough to power thousands of homes. It took 12 minutes for the grid to recover, and the battery-swap stations then resumed normal operation.</p> </div><div> <p>Gogoro is not the only company working on battery-swapping for electric scooters (New York City <a href="https://www.technologyreview.com/2024/03/20/1089960/battery-swap-ebike-fires/">recently launched a pilot program</a> to give delivery drivers the option to charge this way), but it’s certainly one of the most successful. Founded in 2011, the firm has a network of over 12,500 stations across Taiwan and boasts over 600,000 monthly subscribers who pay to swap batteries in and out when required. Each station is roughly the size of two vending machines and can hold around 30 scooter batteries.</p>  <p>Now the company is putting the battery network to another use: Gogoro has been working with Enel X, an Italian company, to incorporate the stations into <a href="https://www.technologyreview.com/2024/02/07/1087836/how-virtual-power-plants-are-shaping-tomorrows-energy-system/">a virtual power plant (VPP) system that helps the Taiwanese grid stay more resilient in emergencies</a> like April’s earthquake.&nbsp;</p> 
 <p>Battery-swap stations work well for VPP programs because they offer so much more flexibility than charging at home, where an electric-bike owner usually has just one or two batteries and thus must charge immediately after one runs out. With dozens of batteries in a single station as a demand buffer, Gogoro can choose when it charges them—for instance, doing so at night when there’s less power demand and it’s cheaper. In the meantime, the batteries can give power back to the grid when it is stressed—hence the comparison to power plants.</p>  <p>“What is beautiful is that the stations’ economic interest is aligned with the grid—the [battery-swap companies] have the incentive to time their charges during the low utilization period, paying the low electricity price, while feeding electricity back to the grid during peak period, enjoying a higher price,” says S. Alex Yang, a professor of management science at London Business School.&nbsp;</p> 
 <p>Gogoro is uniquely positioned to become a vital part of the VPP network because “there’s a constant load in energy, and then at the same time, we’re on standby that we can either stop taking or giving back [power] to the grid to provide stability,” Horace Luke, cofounder and CEO of Gogoro, tells <em>MIT Technology Review</em>.&nbsp;</p>  <p>Luke estimates that only 10% of Gogoro batteries are actually on the road powering scooters at any given time, so the rest, sitting on the racks waiting for customers to pick up, become a valuable resource that can be utilized by the grid.&nbsp;</p>  <p>Today, out of the 2,500 Gogoro locations, over 1,000 are part of the VPP program. Gogoro promises that the system will automatically detect emergencies and, in response, immediately lower its consumption by a certain total amount.</p>  <p>Which stations get included in the VPP depends on where they are and how much capacity they have. A smaller station right outside a metro stop—meaning high demand and low supply—probably can’t afford to stop charging during an emergency because riders could come looking for a battery soon. But a megastation with 120 batteries in a residential area is probably safe to stop charging batteries for a while.</p> </div><div><p>Plus, the entire station doesn’t go dark—Gogoro has a built-in system that decides which or how many batteries in a station stop charging. “We know exactly which batteries to spin down, which station to spin down, how much to spin down,” says Luke. “That was all calculated in real time in the back side of the server.” It can even consolidate the power left in several batteries into one, so a customer who comes in can still leave with a fully charged battery even if the whole system is operating below capacity.</p>  <p>The earthquake and its aftermath in Taiwan this year put the VPP stations to the test—but also showed the system’s strength. On April 15, 12 days after the initial earthquake, the grid in Taiwan was still recovering from the damage when another power drop happened. This time, 818 Gogoro locations reacted in five seconds, reducing power consumption by 11 megawatts for 30 minutes.</p>  <p>Numbers like 6 MW and 11 MW are “not a trivial amount of power but still substantially smaller than a centralized power plant,” says Joshua Pearce, an engineering professor at Western University in Ontario, Canada. For comparison, Taiwan lost 3,200 MW of power supply right after the April earthquake, and the gap was mostly filled by solar power, centralized battery storage, and hydropower. But the entire Taiwanese VPP network combined, <a href="https://money.udn.com/money/story/11799/7963052">which has reached a capacity of 1,350 MW</a>, can make a significant difference. “It helps the grid maintain stability during disasters. The more smart loads there are on the grid, the more resilient it is,” he says.&nbsp;</p>  <p>However, the potential of these battery-swap stations has not been fully achieved yet; the majority of the stations have not started giving energy back to the grid.&nbsp;</p> 

 <p>“The tech system is ready, but the business and economics are not ready,” Luke says. There are 10 Gogoro battery-swapping stations that can return electricity to the grid in a pilot program, but other stations haven’t received the technological update.&nbsp;</p>  <p>Upgrading stations to bi-directional charging makes economic sense only if Gogoro can profit from selling the electricity back. While the Taiwanese state-owned utility company currently allows private energy generators like solar farms to sell electricity to the grid at a premium, it hasn’t allowed battery-storage companies like Gogoro to do so.&nbsp;</p>  <p>This challenge is not unique to Taiwan. Incorporating technologies like VPP requires making fundamental changes to the grid, which won’t happen without policy support. “The technology is there, but the practices are being held back by antiquated utility business models where they provide all electric services,” says Pearce. “Fair policies are needed to allow solar energy and battery owners to participate in the electric market for the best interest of all electricity consumers.” </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jgs Font (118 pts)]]></title>
            <link>https://adelfaure.net/tools/jgs/</link>
            <guid>40643588</guid>
            <pubDate>Tue, 11 Jun 2024 07:36:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adelfaure.net/tools/jgs/">https://adelfaure.net/tools/jgs/</a>, See on <a href="https://news.ycombinator.com/item?id=40643588">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <main>
<pre>Font                          Size                       Mode
<a id="jgs5">[<span> </span>] jgs5</a> <a id="jgs7">[<span> </span>] jgs7</a> <a id="jgs9">[<span> </span>] jgs9</a>    <a id="x1">[<span> </span>] * 1</a> <a id="x2">[<span> </span>] * 2</a> <a id="x3">[<span> </span>] * 3</a>    <a id="day">[<span> </span>] Day</a> <a id="night">[<span> </span>] Night</a>
================================================================================
                   __ _____ _____       _____ _____ _____ _____ 
                  |  |   __|   __|     |   __|     |     |     |
                __|  |  |  |__   |     |   __|  |  |  |  |     |
               |_____|_____|_____|     |__|  |_____|__|__||___| 

================================================================================
X <a href="https://gitlab.com/velvetyne/jgs/-/archive/main/jgs-main.zip">Download Jgs Font</a> (SIL Open Font License)
FR <a href="https://adelfaure.net/tools/jgs/index_fr.html">Version française</a>
================================================================================
     
Jgs Font is a font family made in tribute to Joan G. Stark (aka jgs, Spunk), a
pioneer of ASCII art.

Jgs Font glyphs can be combined from one character to another, from one line to
another. Thus from single characters it is possible to draw continuous lines,
frames and patterns.

In order to change font size while keeping these effects of continuity at
pixel scale, the family is declined in three fonts.

Jgs5 for sizes multiples of 10 : 10px, 20px, 30px etc.
Jgs7 for sizes multiples of 14 : 14px, 28px, 42px etc.
Jgs9 for sizes multiples of 18: 18px, 36px, 54px etc.


Notes
-----

Jgs is still an unfinished project. Some characters are still missing
and the formal correspondences between the sizes remain to be worked.

You will find <a href="https://adelfaure.net/tools/jgs/jgs_table.html">here</a> a table of characters and comparison between fonts.


Continuous characters
---------------------

..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
                                                                                
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
                                                                                
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
                                                                                
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
                                                                                
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  


Curves
------

0.25 _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
                                                                        
0.5 -._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.
                                                                                
1 ._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-
                                                                        
1.25    _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   
     "~"         "~"         "~"         "~"         "~"         "~"         "~"
                                                                         
2.25           .-~"~-.           .-~"~-.           .-~"~-.           .-~"~-.    
     -._   _.-'       '-._   _.-'       `-._   _.-'       '-._   _.-'       `-._
        `~'               `~'               `~'               `~'               
                                                                
4.25                    .-'~"~`-.                   .-'~"~`-.                   
     `.               .'         `.               .'         '.               .'
       \             /             \             /             \             /  
        `-._     _.-'               `-._     _.-'               `-._     _.-'   
            `~"~'                       `~"~'                       `~"~'


Lines
-----

0/1 1/6 1/4 2/5 1/2 2/3 4/5 1/1 4/3 6/4 5/3 2/1 7/3 5/2 3/1 10/3 7/2 4/1 9/2
|   i   i   i   i   i   i   \   \   \   `.  `.  `.  `.  `-. `-.  `-. `~-.`~-._
|   |   |   |   !   !   !    \   \   `.   `.  `.  `.  `-.  `-. `-.  `~-. `~-. `~
|   |   |   !   `i   \   \    \   \    \    \   `.  `-.  `.   `-. `~-.  `-.  `~-
|   |   !   `i   !    i   \    \   `.   `.   `.   `.   `.  `-.   `-.  `-.  `~-.
|   |   `i   !   `i   !    \    \    \    \    `.   `.   `.   `.    `-.  `-.   `
|   !    |   `i   !    \    i    \    \    `.    \    `.   `-.  `-.    `-.  `~-.
|   `i   |    |   `i    i   !     \    \     \    `.    `.    `.   `.     `-.
|    |   !    !    !    !    \     \    `.    `.    `.    `.    `.   `-.     `-.
|    |   `i   `i   `i    \    \     \     \     \     \     `.    `-.   `.      
|    |    |    !    !     i    \     \     \     `.    `.     `.     `.   `-.   
|    |    |    `i   `i    !     i     \     \      \     `.     `.     `.    `. 
|    !    !     |    !     \    !      \     `.     `.     \      `.     `-.   `
|    `i   `i    !    `i     i    \      \      \      \     `.      `.      `.  
|     |    |    `i    !     !     \      \      \      `.     `.      `.      `.
|     |    |     |    `i     \     \      \      \       \      \       `.      
|     |    !     !     !      i     i      \      `.      `.     `.       `.
|     |    `i    `i    `i     !     !       \       \       \      `.       `.


Alphabet           
--------
 _____ _____ _____ ____  _____ _____ _____ _____ _____   ___ _____ ___   __ __
|  _  |  _  |     |    \|   __|   __|   __|  |  |     | |   |  |  |   | |  V  |
|     |  _ -|   --|  |  |   __|   __|  |  |     ||   | _|   |    -|   |_|     |
|__|__|_____|_____|____/|_____|__|  |_____|__|__|_____|_____|__|__|_____|__V__|
 _____ _____ _____ _____ _____ _____ _____ __ __ _____ _____ _____ _____ _____
|     |     |  _  |     |  _  |   __|     |  |  |  |  | | | |  |  |  |  |__   |
|  |  |  |  |   __|  | _|    _|__   |     |  |  |  |  | | | |-   -|  |  |   __|
|__|__|_____|__|  |_____|__\__|_____||___||_____|\___/|_____|__|__||___||_____|


Patterns           
--------

/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]

(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
  
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
 
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___

\////\\\\\/\\/\///////\/\/\\\//\////\\/\/\/////\\/\/\\/\\\\/\\\\\\\\/\\//\\\\\/\
///\///\/\\\\//\/\\/\/\\///\/\\/\\\//\//\///\/\///\///\\///\///\/\/\\\\/\\\///\\
\\///\\\\////\/\\\\\\/\///\\\/\\\///\\\\\/////\//\//\///\/\/\\\\\/\//\\/\\\\\\//
\/\/\/\\///\\\/\\\//\\\/\/\///\\\\\\///\\\\/\\\\/\\\/\/\/\\\//\/////\\///\\/\//\
\////\/\///////\\\\///////\//////\\\/\\\/\/\\/\\//\\\/\\\/////\//\//\/\//\/////\
//\\\//\//\\///\//\\///\\\\/\/\\\/\\/\\\\///\///\/\/\//\//\/\\\////\\\/\/\/\\///
\//\\/\//\\//\\/\////\\////\/\//\\///\\////\\/\\//\\//\\//\//\/\\/\/\\////\\//\\
//\/////\//\\\\///\\///\\/\\\\/\\/\/\\///\\\/\\\\//\/\/\//\\/\/\\//\\//\\\/\\\\\
\//////\/\\//\\////\////\/\/\\\/\//\\/\/\\//\/\\\///\\/\\\\\\///\\\\\/\\\\//////
//\//\/\\\/////\\\\//\\\\//\/\\\\\/\/\\/\\//\\//\/\\//\\\\\\\\//\\/\\\/\/\\////\
\\/\\/\\/////\///\\/\///\///\/\\\\//\///\\//\\\\//\//\///\\\\/\/\//\\\/\\///\\\/
///\//\\\/\\\\\\///\/\/\////\\\//\\\\\\/\//\\\////\\/\\////\\/\//\\\/\/////\\\//
\\\///\\//\\//\/\//\/\/\////\/\//\///\\\\\/\//\/\\\\\/\/\/\\////\/\\\//\/\\\/\//
//\\\\\\\\//////\///\\\\\\\////////\\\//\\\/\///\\\\//\/\\////\//\/\/\\/\\///\/\
\/////\\\\\\\/\\\/\\\\\\\//\//////\\/\/\\\////\\\\//\/\\///\///\\///\\\\\\///\/\
\\/\/\\\/\\/\\\/\\\/\///\\/\\//\/\\//\\\\///\//\//\\//\/\\/\//////\\////////\/\\

  :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   . 
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `


Faces
-----
                     
                                  .-'~~~`-.            
                                  |·.....·i            
         _..._                    |·.....·i                   _.---._       
       .~(|||)~.                .~!·.....·!~.               .(((|||))).     
      ((//'~`\\))               `·.._____..·'              (((/(((((\)))    
      (!__   __!)               ))! ~   ~ !((              ))! '   ` !((    
      (~(_)-(_)~)              (((. o   o .)))            (((. o   o .)))   
       |   L   |                )))   w   (((             i)))   &lt;   (((i   
       !  .-.  !               ((( \ `-' / )))           (((( \ )-( / ))))  
       (       )                )))!`---'!(((             ))))!`._.'!((((   
       /`~---~'\                  /`-._.-'\              ((((/       \))))  
  _.-~'  `. .'  `~-._        _.-~'\_/(_)\_/`~-._        _i))))       ((((i_ 
 '         V         `      '  \     / \     /  `      '(((((         )))))`
                                                                            
                                                                _._         
                                   _.---._                     (\!/)        
        .-~~~-.                  .(((|||))).                 .(|||||).      
       (//'~`\\)                (((//'~`\\)))               ((/·'~`·\))     
       ! .   . !                ))! '   ` !((               (! -   - !)     
      (. ·   · .)              (((. .   . .)))              (. o   o .)     
       7  (_)  &lt;                )))\  &lt;  /(((                 \  u  /       
      (    -    )              ((( |\.-./| )))                |\ - /|       
       `._   _.'                )))! \_/ !(((                 ! `-' !       
       /  `~'  \                  /`.___.'\                  /       \      
  _.-~'         `~-._        _.-~'`-.___.-'`~-._        _.-~'         `~-._ 
 '  \             /  `      '                   `      '  \             /  `
          ___                                                               
        .~...~.                                                             
       i·.....·i                   _.---._                                  
     .-!·.....·!-.               .(((|||))).                  .:=:=:.       
     `·.._____..·'              (((//'~`\\)))                i;'~ ~`:i      
     ((! ^   ^ !))              ))! `   ' !((                ! _   _ !      
     ((. o   o .))             (((. -   - .)))              (. .   . .)     
      ))   L   ((              i)))   U   (((i               !   L   !      
      (!   -   !)             (((( \  -  / ))))               \ ·-· /       
        \.___./                ))))!\._./!((((                !\._./!       
       /.     .\              ((((/`.___.'\))))              /'     `\      
  _.-~'  `. .'  `~-._        _i))))-.___.-((((i_        _.-~'.  \ /  .`~-._ 
 '         V         `      '(((((         )))))`      '      `-...-'   adl`
                     

Interior
--------

    i ||     |    .   ||   ||   ||   _______ ~-._ _.~ .-=-.  |(c)|       ||  .-=
    ! ||     |   / \  ||___||___||  |  ( )  |    Y    |(L)|  |/~\|       ||  |i 
      || .-° |  :---: ||   ||   ||  |-(( ))-|    |    |/~\|  `---'       ||  |: 
    i ||((   |  |  /| ||_  ||  _||  |___!___| .-.|    `---'              ||  |: 
    7 || )`. |  | //| || ~-||-~ ||           -'-`-       _               ||  |: 
. ~   ||(((  |  `---' |!   ||   !|  [=(O\=(O)}))_|      | |   .---.      ||  |: 
 .-~  || ;.\ |       _`-`. || .'-'   / .-.L_.-'  `-._.-.|_|   |adl|      ||  |! 
    ! ||(  \i| __ U / \&gt;_ `'`'____  !_-|  __  _  __  _ |       ~~~       !!  !/=
   .-.|| ;. !| \ (_)`-'[]\   |)--=)  ||| (( `'.\(( `' \| _.......__    ..-.   __
.-~ )||| ! ))| |`---------'  ||==-|  `L| .\\____.-~|· ·.' ........ `.  || |  ii 
 _.'|||| ((/ | |\  | ° | |   ||==-|._  |(  `~.--|| `--' .'  :   : `. `--. |  |:_
'_.:||||     |_||||¯¯¯|T||___|L_=o=_oi_| `..'   || ....':   :   :   :.... |   __
;-':||_|   _.' ||||.¯¯||||   |T.Y|.-Y| L;. \    || .    :   :   :   :   . |  ii 
;-;'~  ~-.:    `'||   `'|| : `' |Y  `'  . \ `.  || .    :   :   :   :   . |  |: 
.'  `.' ..(O ..  `'     `' :    `'   :     `. ~' | .    :   :   :   :   . |  |: 
.': '.`.`./|     :  ..     : ..     ..:      \   | .-.._:_ _:_ _:__.:..-. |  |! 
|;-.___Ov/)|    :          :           :      `. | :                   _: |  !_-
|=:---.||/)|   :         ..:      ..    : ..    || i~~--------------~~~|| |-.  `
|  ===·||/`'  :  ..        :             :      \|_|     ..   `.    .. \|_|  ~-.
)      !!    :             :..            :  ..               ..`.              


Landscape
---------

                                                                                
            .--..-.                        .--.  _.-.                           
           (    )  )                      (    )'    )                          
         .-'       `-.                  .-'.         `-.                        
  _     (   _.-~-._)-'              __ (    )       )   )                       
-~ ~-._ _.-~       ~-._..--~~--._.-~  ~~--..__-----' `-'                      _.
    _.-~               ~-._ _.-~              ~~--..__  ___...--~~~--..._ _.-~  
_.-~ ·          .          ~-._.                     .~~--..__ .      _.-~      
           ·     ·.            ~-._     .   .  ··  .       . .~~--..__      _.-~
v^vvv^vvVv ..VVVv.. v^^^Vvv^v^^v^Vv^ v.vv..v^vv^v VVv^vV.Vv^v^^vv^vv·..vVVvvv^vv
//\vv^vv^vv^/\vv^/\^vv^vv/\vvv^vV^v/\vv^vv^v^/\:\^vv^vv^/\^v/:\v/\v^vV^VV/\vv^vv
/,`\/\/\:/\/,`\//,`\\/:\/,`\/\/\/\/,`\/\/\://,`\\:/\:/\/,`\\/\//,`\:/\:\/,`\/\/\
/,`\`/,`\.:',`,:/,`\`/_:',`,:/,`\:',`,:/,`\:',`,:/,`\\'/,`\`,`'/,`\`,`\'/,`\`/,`
/,`\``,`\`/',`,\/,`\`||/',`,\`,`'/',`,\`,`'/',`,\`,`\`'/,`\`,`'/,`\`,`\'/,`\``,`
',`,:`,`,:,',`,:',`,: :,',`,`:,`:,',`,`:,`:,',`,`:,`,`:',`,:,`:',`,:,`,:',`,:`,`
',`,\`,`,/,',`,/',`,\,/,',`,`\,`/,',`,`\,`/,',`,`\,`,`/',`,\,`/',`,\,`,/',`,\`,`
',`,\``'/',',`,/',`,\:',',`,`\`'/,',`,`\`'/,',`,`\`','/',`,\`'/',`,\`''/',`,\``'
'ii`ii::'i''ii`i'ii`` '''ii`ii::'i'ii`i`::'''ii```::'ii'ii``::'iii``::'''ii`ii::
 || ||{0}|  || |.||'· '. || |||| | ||.|'||   ||  '|| || ||  .'\||| .||   || ||{0
.,...(\|/)_.,_..,..n,._._,._.,._,..,._..,...\|/..,..,._..../,` `.,_...,......(\|
.o:::.`o.`,\|/n..,:`.,·°o.::.·,'`::.:'.-.`:o:`,'.:`'-.`o\|/~`--'~..·`:`'`,:::.`o
=============================================================================adl
                                                                                
                                                                                
    ---__o         __o-        __o  ---    __o      ---             ---         
     _7\,L7      _7\,__o     __o,L7  __o _7\,__o                                
    (-)/'(-)    (|)_7\,L7  _7\,L7(-_7\,L7|)_7\,L7                               
                  (-)/'(-)(-)/'(-)(-)/'(-)(-)/'(-)
--------------------------------------------------------------------------------


Isometric view
--------------

:____:::::____:::::::____::/\  ·/    /\:::/   \ \  :   .  ::__::::__::::__:::/  
//_//:::://_//:::::://_//:/\ \  :  . \ \~~\  . \ \__:_   ::/_/:::/_/:::/_/::/   
/ //::::// //::_:::// //:/  \ \__:_   \ \  :  / \/::::  ::/_/:::/_/:::/_/::/    
¯¯¯:::::¯¯¯¯::/\\::¯¯¯¯:/  . \/::::  . \ \  :/ / ~~~~  :::::::::::::::::::/  .  
:::::::::::::/*//::::::/ .       _____  \ \  ·/       :::::::::::::::::::/      
:::::____:::/*//____::/\   .    /\:::/  .\ \  :   .  ::__::::__::::__:::/       
:::://_//::/*////_//:/\- _o   . \ \~~\    \ \__:_   ::/_/:::/_/:::/_/::/  .  .  
:::// //:::\//// //:/\_ !:: .    \ \  :  / \/::::  ::/_/:::/_/:::/_/::/         
:::¯¯¯¯::_::¯:¯¯¯¯:/\_\ //'    /\ \ \  :/ / ~~~~  :::::::::::::::::::/      .   
::::::::/\\:::::::/ :\_\`` \  /\/  \ \  ·/  .  . :::::::::::::::::::/   .      :
____:::/H//____::/   \\_\_\_\  / /\ \ \  :      ::__::::__::::__:::/   .  .   ::
/_//::/O////_//:/     :\_\_\_\  ·    \ \__:_ . ::/_/:::/_/:::/_/::/ :\/\     ::/
 //::/T//// //:/    .  \\_\_\_\ \  ·\ \/::::  ::/_/:::/_/:::/_/::/ / /\:    ::/_
¯¯::/E//:¯¯¯¯:/         :\_\_\_\  /\/  ~~~~  :::::::::::::::::::/ ' /:/\.  :::::
:::/L//::::::/           \\_\_\_\  / ·\  .  :::::::::::::::::::/   /\/ /  ::::::
:::\//::::::/     \       :\_\_\_\  /\:    ::__::::::::::__:::/\ \: / :  ::__:::
::::____:::/\              \\_\_\_\ \·    ::/_/::____:::/_/::/\_\  /`   ::/_/::_
:::/\___\:/\_:   .          :\_\_\_\   . ::/_/::/:/:/::/_/::/ _o \ \   ::/_/::/:
::/v/v/::/\_\_\      \       \\_\_\_\   :::::::/v/v/:::::::/\(::V \ _ _:_:_:_/v/
_/_/_/_:/\_\_\_:              :\_\_\_\ :_:_:_:/_/_/:_:_:_:/\_ ¡i  _|==========.=
\\:::\\=\_\_\_\_\          .   \\_\_\_\=\=\=\=\====:\=\=\=\_\ !L _\/ .     .  )-
=\\===:\=\_\_\_\_:      \       :\_\_\_\=\=\=\=\=\=\=\=\=\=\_\_ _\/ _  .  //\ )=
\=\= _________________________________\_\=\=\=\=\=\=: o :=\=\_\_\/ //\   (/\/))-
:~:~/\       /\____\   ___            \~:~:~:~:~:~:~ TJ)L~:~:~`~/ //o \   \// )=
:::/. \      \/____/  \___\            \   :::::::::/|C^|::::::/ . V://    ~  )-
::/\:\ \________________________________\   ::::::::0`'0':::::/     //      . )=
:/C \:./._._._._._._._./C16/._._._._./-/|    ::::::::::::::::/ .  .    . _    )-
(O 1 \/o/o/o/o/:/o/o/:/¯/¯/:/o/:/o/o/:/ |  -- ::::--::::--::/ //\    .  //\.  )=
:\\ 6/---------------/:/:/---------/:/: |      :::::::::::_/ (/\/\ .   //::\  )-
::\O/:::.--.:.--.:::/_/_/::::.--.:/_/'--i   .   :::::::::/\\ .\/\/)     \://  )=
:::·---'(_0/~(_0/`----------'(_0/`------'         o :::::\C\\  \// .  .  //   )-
:_:_:_:_:_:_:_:_:_::._._._._:::::::::::::   _._. /:):_:_/.\O\\  ~   .   .    ::¯
\=\=\=\=\=\=\=\=\=\=\=\=\=\=:::::::::::::: :\_\_'|¡ \=\/.-.\M\\  . //\      ::::
===========================\=\::::::::::::: \\_\_'! =\///\|.\P\\  (/\/\ .  :::::
 ____    .c---n.   .c---n. \\=:__::__::__::__:\_\_ _\/// /:/:\U\\  \/\/)  ::::::
(_°_°`. \ 0)/\¯¯¯\\ 0)/\¯¯¯\\\_\ \ \ \ \ \ \ \\\_\_\-^/^///:_:\T\\. \//  :::::::
 0) \¯¯¯\  \^/\___\  \^/\___\\\_: \ \ \ \ \ \ \:\_\_\\\///_/\\:\E\\  ~  ::::::::
\ \ ^\___\\ \^(___( \ \^(___( \\_\ \ \ \ \ \ \ \\\_\_\-^//\\//_:\R\\.  :::::::::
   \ ^|__|   0)\   \   0)\   \ \\_:_\ \_\ \_\ \_\:\_\_\_\\:\:/\\:\S\\ :::::::::/
  \ 0)    ) \ \(o==o) \ \(o==o) \)_\              \\_\_\_\\:\\//_:\//::::::adl/ 
     `º--º     ¯¯¯¯¯     ¯¯¯¯¯     _:      \       :\_\_\_\\:\:/\\:/:::::__::/  
  °  __        __        __   .     _\    .         \\_\_\_\\:\\///:/\/:/_/:/ . 
                                     _:              :\_\_\_\\:\_/::::_:__:/ //\
____  .   ____      °       .c---n. (\_\      \       \\_\_\_\\//:/\//-:/_/ (/\/
_°_°`.   (_°_°`.             0)/\¯¯¯\\\_:              :\_\_\_\/:_  _o _/\\ .\/\
0) \¯¯¯\\ 0) \¯¯¯\\     °   \ \^/\___\\\_\              \\_\_\_\=\ V::) \P\\  \/
 \ ^\___\  \ ^\___\            \^(___( \\_:      \       :\_\_\_\ .//  /.\H\\  ~
\ \ ^|__| \ \ ^|__| \ .       \ 0)\   \ \\_\         .    \\_\_\_\_  =/.-.\O\\ .
   0)    )   0)    )      .c_!   \(o==o) \\_:              :\_\_\_\=\///\|.\N\\ 
  \ `º--º   \ `º--º   \    !-!  \ ¯¯¯¯¯   \\_\      \       \\_\_\_\///\/:/:\E\\
                                                           

Copyright (c) 2022, Adel Faure contact@adelfaure.net, with Reserved Font Name
Jgs Font, jgs5, jgs7, jgs9.

This Font Software is licensed under the SIL Open Font License, Version 1.1.
This license is available with a FAQ at: http://scripts.sil.org/OFL

                                                                                
================================================================================

<a href="mailto:contact@adelfaure.net">contact@adelfaure.net</a> send me an email :-)

Find me on                                                                     
            <a href="https://adelfaure.itch.io/">Itch.io</a>
            <a href="https://www.gamejolt.com/@adelfaure">Gamejolt</a>
            <a href="https://www.gitlab.com/adelfaure">Gitlab</a>
            <a href="https://www.instagram.com/adelfaure">Instagram</a>
            <a href="https://www.reddit.com/user/AdelFaure">Reddit</a> (not often connected)
            <a href="https://www.twitter.com/adelfaure">Twitter</a>
            Soundcloud <a href="https://soundcloud.com/faureadel">2021</a> <a href="https://soundcloud.com/mostunderratedartist">2016</a> <a href="https://soundcloud.com/adelfaure">2014</a>

You can support me on <a href="https://ko-fi.com/adelfaure">Ko-fi</a>, you'll make my day \(♥3♥)/ !

================================================================================
/\ <a href="#top">Top</a>
================================================================================
</pre>
  
  

</main></div>]]></description>
        </item>
        <item>
            <title><![CDATA[POV-Ray – The Persistence of Vision Raytracer (285 pts)]]></title>
            <link>http://www.povray.org/</link>
            <guid>40643207</guid>
            <pubDate>Tue, 11 Jun 2024 06:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.povray.org/">http://www.povray.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40643207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="99%">


<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<p>
The <a href="http://www.povray.org/download/">Persistence of Vision Raytracer</a> is a high-quality, Free Software tool for
creating <a href="http://hof.povray.org/">stunning three-dimensional graphics</a>.
The source code is available for those wanting to do their own ports.
</p>
<!-- p align="center">
<a href="//hof.povray.org/ChristmasBaubles.html"><img src='//hof.povray.org/images/800x600/ChristmasBaubles.jpg' alt='Christmas Baubles' class='RaisedImage' border='0'></a> 
</p -->

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>

<p>
To navigate about this site please use the navigation links at the top of this page.
If you want to download POV-Ray, please visit our <b><a href="http://www.povray.org/download/">download page</a></b>.
</p>

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>

<p>
For general resources and support information, please visit our <a href="http://www.povray.org/resources/">resource and support page</a>.
For website-related issues <i>only</i>, please <a href="http://www.povray.org/webmaster.html">contact our webmaster</a>.
To contact us regarding licensing matters, please use the address given at the bottom of our <a href="http://www.povray.org/povlegal.html">license page</a>.
</p>

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>
<table><tbody><tr><td>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<div><p>DKBTrace (foundation of POV-Ray) creator has kickstarter for educational IDE</p></div>

<!-- NC 3 20 -->
<div><p>
David K. Buck - the creator of DKBTrace, the pioneering raytracer that was the genesis of POV-Ray - has created a <a href="https://www.kickstarter.com/projects/pigeontalk/pigeontalk-a-programming-environment-to-explore-computing">KickStarter campaign to fund creation of an open-source IDE for PigeonTalk</a> (PigeonTalk is a smalltalk implementation created by David that is aimed at being a programming environment to explore computing).
</p>

<blockquote>
"I chose Smalltalk as a language because it provides the most immersive experience I've encountered.  Smalltalk allows you to create, use, and explore software in a very hands-on way.  It's an ideal environment for learning and playing with software.
This Kickstarter project is to provide a development environment for this Smalltalk which I'm calling PigeonTalk.  The development environment would run in a web browser and would communicate with the Smalltalk engine using WebSockets.  Once this is available, PigeonTalk becomes a viable programming environment that others could use."
</blockquote>

<p>
We wish David the best in this endeavor and are hopeful the Kickstarter will meet its goal as POV-Ray itself would not exist if it were not for David's kind contribution of the DKBTrace source code.
</p></div>
<div><p>
[February&nbsp;04,&nbsp;2022]
[<a href="http://www.povray.org/news/index.php#336">Permalink</a>]
</p></div><div><p>POV-Ray v3.8.0 beta tests available</p></div>

<!-- NC 6 20 -->
<p>POV-Ray 3.8 is now in beta-test. You may obtain beta releases via our <a href="https://github.com/POV-Ray/povray/releases/">GitHub</a> repository. Discussion regarding the betas should be directed to the <a href="http://news.povray.org/povray.beta-test/">beta-test group</a> in our forums.</p>
<div><p>
[August&nbsp;31,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#335">Permalink</a>]
</p></div><div><p>POV-Ray turns 30</p></div>

<!-- NC 9 20 -->
<div><p>30 years ago today, on July 29 1991, the first beta of what would become POV-Ray became available in the GRAPHDEV forum on CompuServe. See <a href="http://www.povray.org/documentation/view/3.6.1/7/">"The Early History of POV-Ray"</a>, <a href="http://www.povray.org/documentation/view/3.6.1/8/">"The Original Creation Message"</a>, <a href="http://www.povray.org/documentation/view/3.6.1/9/">"The Name"</a> and <a href="http://www.povray.org/documentation/view/3.6.1/10/">"A Historic Version History"</a> in our v3.6 documentation for more details about the early days of this project.</p></div>
<div><p>
[July&nbsp;29,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#334">Permalink</a>]
</p></div><div><p>Wiki back online</p></div>

<!-- NC 12 20 -->
<p>The <a href="http://wiki.povray.org/">POV-Wiki</a> is now back online and is running the latest version of MediaWiki. Additionally we have restored our <a href="http://bugs.povray.org/">legacy bugtracker</a>, which tracked issues prior to moving our source code to GitHub.</p>
<div><p>
[April&nbsp;12,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#333">Permalink</a>]
</p></div><div><p>Forums back online</p></div>

<!-- NC 13 20 -->
<p>Following more recovery work since the server crash we're happy to say our ... ... <i><a href="http://www.povray.org/news/index.php#332">[read more]</a></i></p>
<div><p>
[March&nbsp;28,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#332">Permalink</a>]
</p></div><div><p>Server Recovery</p></div>

<!-- NC 14 20 -->
<p>The www.povray.org site is now back in read-write mode ... ... <i><a href="http://www.povray.org/news/index.php#331">[read more]</a></i></p>
<div><p>
[March&nbsp;21,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#331">Permalink</a>]
</p></div><div><p>POV-Ray Server Downtime</p></div>

<!-- NC 15 20 -->
<p>Our server recently experienced a catastrophic hardware failure ... ... <i><a href="http://www.povray.org/news/index.php#330">[read more]</a></i></p>
<div><p>
[March&nbsp;15,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#330">Permalink</a>]
</p></div><div><p>Blender to Persistence of Vision</p></div>

<!-- NC 16 20 -->
<p>New Release: Blender to Persistence of Vision ... <i><a href="http://www.povray.org/news/index.php#329">[read more]</a></i></p>
<div><p>
[August&nbsp;01,&nbsp;2020]
[<a href="http://www.povray.org/news/index.php#329">Permalink</a>]
</p></div><div><p>white_dune VRML/X3D editor adds POV-Ray export</p></div>

<!-- NC 19 20 -->
<div><p>
The folks at the open-source white_dune 3d editor project let us know that they've added POV-Ray export capability. Neat! It looks like a useful tool, definitely worth checking out.
</p>

<p>
You can find their <a href="https://github.com/mufti11/white_dune/">github repo here</a> or if you prefer you can go straight to their <a href="http://wdune.ourproject.org/">project website</a> for downloads.
</p></div>
<div><p>
[July&nbsp;23,&nbsp;2020]
[<a href="http://www.povray.org/news/index.php#328">Permalink</a>]
</p></div><div><p>Call for papers: Ray Tracing Gems</p></div>

<!-- NC 20 20 -->
<p>Eric Haines dropped us a line to let us know that there is still time to submit papers to Ray Tracing Gems ... ... <i><a href="http://www.povray.org/news/index.php#326">[read more]</a></i></p>
<div><p>
[July&nbsp;01,&nbsp;2018]
[<a href="http://www.povray.org/news/index.php#326">Permalink</a>]
</p></div><div><p>Older News</p></div>
<div><ul>
<li><a href="http://www.povray.org/news/index.php#325">POV-Ray 3.7.1 enters beta phase</a></li>
<li><a href="http://www.povray.org/news/index.php#324">Converting POV-Ray scenes into 3D-printable STL meshes</a></li>
<li><a href="http://www.povray.org/news/index.php#323">POV-Ray turns 25 (or 30)</a></li>
<li><a href="http://www.povray.org/news/index.php#322">Python modeller for POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#321">Routing problems for some users in Sweden and Finland</a></li>
<li><a href="http://www.povray.org/news/index.php#320">POV-Ray 3.7 released</a></li>
<li><a href="http://www.povray.org/news/index.php#318">Lathe and Prism Utility Available</a></li>
<li><a href="http://www.povray.org/news/index.php#317">Viewshed Analysis with POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#316">POV-Ray Helps Visualize Bee Keeper Data</a></li>
<li><a href="http://www.povray.org/news/index.php#315">POV-Ray, Export &amp; View, for Mathematica</a></li>
<li><a href="http://www.povray.org/news/index.php#314">Koppi's Bullet Physics Playground</a></li>
<li><a href="http://www.povray.org/news/index.php#313">Parallella supercomputer kickstarter nearing end</a></li>
<li><a href="http://www.povray.org/news/index.php#312">Spectral Rendering with POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#311">ANIMUSIC 3 kickstarter campaign in its last week</a></li>
<li><a href="http://www.povray.org/news/index.php#310">Update of Insert Menus Add-on</a></li>
<li><a href="http://www.povray.org/news/index.php#309">Caedium Version 4 Available</a></li>
<li><a href="http://www.povray.org/news/index.php#308">Another PoseRay Update</a></li>
<li><a href="http://www.povray.org/news/index.php#307">Making of a Rose</a></li>
<li><a href="http://www.povray.org/news/index.php#306">Colored Leaves</a></li>
<li><a href="http://www.povray.org/news/index.php#305">PoseRay Beta Release</a></li>
</ul>
</div>
</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<div><p>Visualization Library</p></div>

<!-- NC 3 20 -->
<p><a href="http://www.visualizationlibrary.com/jetcms/">Visualization Library</a> is a C++ middleware for high-performance 2D and 3D graphics applications based on the industry standard OpenGL 2.1, designed to develop portable applications for the Windows, Linux and Mac OS X operating systems.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#287">Permalink</a>]
</p></div><div><p>Jupiter Loses a Stripe</p></div>

<!-- NC 6 20 -->
<p>Lost: A giant <a href="http://science.nasa.gov/science-news/science-at-nasa/2010/20may_loststripe/">belt</a> of brown clouds big enough to swallow Earth twenty times over.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#285">Permalink</a>]
</p></div><div><p>OGRE 1.7.1</p></div>

<!-- NC 9 20 -->
<p>Since 2001, OGRE has grown to become one of the most popular open-source graphics rendering engines, and has been used in a large number of production projects. Check out the first maintenance release to the new 1.7 stable branch codenamed <a href="http://www.ogre3d.org/">Cthugha</a>.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#284">Permalink</a>]
</p></div><div><p>E-on Software Ships Vue 8.5</p></div>

<!-- NC 12 20 -->
<p>e-on software, maker of the leading solutions for Digital Nature, <a href="http://www.e-onsoftware.com/about/?page=PRIndex&amp;date=May%206,%202010">announced today</a> the immediate availability of Vue 8.5 xStream and Infinite, its professional solutions for the creation, animation and rendering of natural 3D environments. </p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#283">Permalink</a>]
</p></div><div><p>Solar Dynamics Observatory</p></div>

<!-- NC 13 20 -->
<p>NASA's Solar Dynamics Observatory ... <i><a href="http://www.povray.org/news/index.php#282">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#282">Permalink</a>]
</p></div><div><p>DAZ 3D-Gizmoz Introduces Digimi</p></div>

<!-- NC 14 20 -->
<p><a href="http://www.digimi.com/newsite/presite/home.jsp">Digimi</a> the ultimate platform for generating personalized avatars. ... <i><a href="http://www.povray.org/news/index.php#278">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#278">Permalink</a>]
</p></div><div><p>OpenTK Library 1.0 RC1</p></div>

<!-- NC 15 20 -->
<div><p>The <a href="http://www.opentk.com/">OpenTK</a> is an advanced, low-level C# library ... <i><a href="http://www.povray.org/news/index.php#277">[read more]</a></i></p></div>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#277">Permalink</a>]
</p></div><div><p>Rhino for OS X is in development</p></div>

<!-- NC 16 20 -->
<p>During development, pre-release Rhino OS X is free ... <i><a href="http://www.povray.org/news/index.php#274">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#274">Permalink</a>]
</p></div><div><p>SymLab RANS Flow</p></div>

<!-- NC 17 20 -->
<p><a href="http://www.symscape.com/">Symscape</a>'s commercial range of simulation products has now been expanded to include <a href="http://www.symscape.com/news/symlab-rans-flow-released">SymLab RANS Flow</a> for the simulation of realistic (viscous) ... <i><a href="http://www.povray.org/news/index.php#265">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#265">Permalink</a>]
</p></div></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
</td><td>&nbsp;</td><td>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="4" height="20" alt=""></td>
<td><span color="#ffffff">
<a href="http://hof.povray.org/rwmcgsphere2_final.html"><img src="http://hof.povray.org/images/thumb/rwmcgsphere2_final.jpg" width="320" height="320" alt="Hall of Fame Image"></a><br>
</span><center><span color="#ffffff"><span><b><cite>"My First CGSphere"</cite></b></span><p>
<a href="http://hof.povray.org/rwmdolphins.html"><img src="http://hof.povray.org/images/thumb/rwmdolphins.jpg" width="320" height="240" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Thanks for all the fish"</cite></b></span><p>
<a href="http://hof.povray.org/sherk-collins.html"><img src="http://hof.povray.org/images/thumb/sherk-collins.jpg" width="320" height="200" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Scherk-Collins sculpture"</cite></b></span><p>
<a href="http://hof.povray.org/BonsaiGirlA24.html"><img src="http://hof.povray.org/images/thumb/BonsaiGirlA24.jpg" width="320" height="400" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Bonsai Life"</cite></b></span><p>
<a href="http://hof.povray.org/TopMod_StarBall.html"><img src="http://hof.povray.org/images/thumb/TopMod_StarBall.jpg" width="320" height="320" alt="Hall of Fame Image"></a></p><center><span><b><cite>"TopMod StarBall"</cite></b></span><p>
<span><a href="http://hof.povray.org/">See more images...</a> <a href="http://hof.povray.org/index-lb.html"><i>[dialup version]</i></a></span></p></center>
</span></center></center></center></center></td>
<td><img src="http://www.povray.org/i/fill.gif" width="4" height="20" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="2" alt=""></td></tr>
</tbody></table>
<br>
</td></tr></tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
You may view our Privacy Policy <a href="http://www.povray.org/privacy.php">here</a>.
</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[macOS Sequoia to Allow iCloud Logins in Virtual Machines on ARM Macs (126 pts)]]></title>
            <link>https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc</link>
            <guid>40643181</guid>
            <pubDate>Tue, 11 Jun 2024 06:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc">https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc</a>, See on <a href="https://news.ycombinator.com/item?id=40643181">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Exploring Gleam, a type-safe language on the BEAM (178 pts)]]></title>
            <link>https://christopher.engineering/en/blog/gleam-overview/</link>
            <guid>40643167</guid>
            <pubDate>Tue, 11 Jun 2024 06:29:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christopher.engineering/en/blog/gleam-overview/">https://christopher.engineering/en/blog/gleam-overview/</a>, See on <a href="https://news.ycombinator.com/item?id=40643167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <p>If you know me, you’d probably say, “Omg Chris, yet another new language???!!!“.
The truth is, this is the only way I found to keep my motivation as a software
engineer. A new language means a new way of both building and thinking. I’m
trying to stay open-minded when it comes to my craft. I’ll just get the best out
of this new experience and move on. In this article, I’m going to talk about
Gleam, how I found it, and why I’m already LOVING it.</p>
<p><img src="https://christopher.engineering/_astro/gleam-banner.CSmos0T3_Z2gg4CB.webp" alt="Pink star representing Gleam's logo, followed by the label 'Gleam'" width="1200" height="630" loading="lazy" decoding="async"></p><h2 id="how-i-heard-about-gleam">How I heard about Gleam?</h2>
<p>Gleam V1 launched on March 4th 2024. As a
<a href="https://youtu.be/0sxXyLJe2N8?si=0ExH3E5ViqdEGlMM&amp;t=12">built different engineer</a>,
I found out about it back in November 2023, when I started being seriously
interested in Elixir.</p>
<p>The thing that always kind of put me off regarding Elixir was the dynamic
typing. I’m a static typing person; it solves a LOT of common issues in my
day-to-day job and provides cool benefits like:</p>
<ul>
<li>Less runtime errors, since the compiler YELLS at you when something is wrong
about your code structure.</li>
<li>Trust in what goes to production, since it was approved by the boss (the
compiler).</li>
<li>Code with typing indications is often (not always, but still, often) clearer
and easier to understand. If the documentation is incomplete or non-existent,
you still have something to go by, and new engineers can start contributing
faster.</li>
<li>Coding by thinking about the data structure FIRST, and then, the
implementation matches my thinking process.</li>
</ul>
<p>Anyway, you get it, I a type-sexual.</p>
<p>So, one day, I was googling “Static typing elixir”, and I saw
<a href="https://gleam.run/">Gleam</a> in the results. What did I do? I just ignored the
thing and moved on.</p>
<p><strong>WHY ?</strong></p>
<p>Because I’m more mature than ever. Like look, I did my due diligence on Gleam:
adoption, use cases, versions (it was on v0.something), and I wasn’t impressed.
I thought that Gleam was super early, a cool gimmick, an experimental toy, but
it stayed somewhere in my brain, in the box where I put the stuff I might get
into, but not RIGHT NOW.</p>
<p><img src="https://christopher.engineering/_astro/things-to-learn.CBPM5iSX_ng9Ue.webp" alt="Drawing representing the things I want to keep an eye on vs the things that are requiring my immediate attention, Gleam falls into the things I want to keep an eye on category" width="2943" height="1206" loading="lazy" decoding="async"></p><h2 id="what-gleam-brings-to-the-table">What Gleam brings to the table</h2>
<p>Fast forward, it’s March 1st, 2024:
<a href="https://gleam.run/news/gleam-version-1/">Gleam is officially on V1</a>. I read the
changelog, I get the SDK to play with the language and folks… the vibes are
IMMACULATE. I’m starting to regret the time I had the occasion to be involved
super early (I know it’s dumb), but as they (idk who’s “they”) said, better late
than never.</p>
<p>I’ll go through the features I love the most and tell you what I like, and what
can be better.</p>
<h3 id="types-and-structures">Types and structures</h3>
<p>I think it’s BEAUTIFUL, like:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>What you’re seeing here is a Gleam <code>custom type</code> or <code>Record</code>, with <code>Vehicle</code>
being the type’s name, <code>Car</code>, <code>Skateboard</code>, and <code>Spaceship</code> being the
constructors available for this type. This is basically a tagged union, or if
you prefer, some sort of enumeration, where each member gets its own set of
attributes. It’s being used like:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>let</span><span> my_car </span><span>=</span><span> Car</span><span>(</span><span>"Honda"</span><span>, </span><span>"Civic"</span><span>)</span></span>
<span></span></code></pre>
<p>and it allows pretty cool structures, like this cute pattern matching:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicule: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicule {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>Let’s spend some time on the function above:</p>
<ol>
<li><code>get_driving_requirements</code> takes only one <code>Vehicle</code> type argument and returns
a <code>String</code>. Both Gleam’s compiler and LSP will let you know if any of those
conditions are not respected. Specifying what a function returns in Gleam is
optional; due to type inference, Gleam will understand it anyway.</li>
<li>In the function’s body, you can see the <code>case</code> structure. This is how you
perform pattern matching, which is essentially a switch control on steroids.
Using a <code>case</code>, you can execute code path if a specific pattern is matched
for a given variable. It’s pretty crazy how deeply you leverage this
technique. In my example, I check every possible constructor for the
<code>vehicle</code> variable. Once again, the tooling will alert you if your pattern
matching is not exhaustive (safety first!).</li>
</ol>
<p>It’s super expressive, the code is concise and elegant (to me).</p>
<h3 id="gleams-tooling">Gleam’s tooling…</h3>
<p>…is CRAZY. Like, crazy CRAZY. I spent so much time in the cursed lands of
Javascript that I forgot grass could be THIS green elsewhere. The only thing you
need to do it to install the <code>gleam</code> CLI. To do so, I used
<a href="https://asdf-vm.com/">asdf</a>, but you can do the same using any other package
manager like Homebrew. What does the <code>gleam</code> command do? Check this out:</p>
<pre tabindex="0" data-language="bash"><code><span><span>❯</span><span> gleam</span></span>
<span><span>gleam</span><span> 1.2.0-rc1</span></span>
<span></span>
<span><span>Usage:</span><span> gleam</span><span> &lt;</span><span>COMMAN</span><span>D</span><span>&gt;</span></span>
<span></span>
<span><span>Commands:</span></span>
<span><span>  add</span><span>      Add</span><span> new</span><span> project</span><span> dependencies</span></span>
<span><span>  build</span><span>    Build</span><span> the</span><span> project</span></span>
<span><span>  check</span><span>    Type</span><span> check</span><span> the</span><span> project</span></span>
<span><span>  clean</span><span>    Clean</span><span> build</span><span> artifacts</span></span>
<span><span>  deps</span><span>     Work</span><span> with</span><span> dependency</span><span> packages</span></span>
<span><span>  docs</span><span>     Render</span><span> HTML</span><span> documentation</span></span>
<span><span>  export</span><span>   Export something useful from the Gleam project</span></span>
<span><span>  fix</span><span>      Rewrite</span><span> deprecated</span><span> Gleam</span><span> code</span></span>
<span><span>  format</span><span>   Format</span><span> source</span><span> code</span></span>
<span><span>  help</span><span>     Print</span><span> this</span><span> message</span><span> or</span><span> the</span><span> help</span><span> of</span><span> the</span><span> given</span><span> subcommand</span><span>(</span><span>s</span><span>)</span></span>
<span><span>  hex</span><span>      Work</span><span> with</span><span> the</span><span> Hex</span><span> package</span><span> manager</span></span>
<span><span>  lsp</span><span>      Run</span><span> the</span><span> language</span><span> server,</span><span> to</span><span> be</span><span> used</span><span> by</span><span> editors</span></span>
<span><span>  new</span><span>      Create</span><span> a</span><span> new</span><span> project</span></span>
<span><span>  publish</span><span>  Publish</span><span> the</span><span> project</span><span> to</span><span> the</span><span> Hex</span><span> package</span><span> manager</span></span>
<span><span>  remove</span><span>   Remove</span><span> project</span><span> dependencies</span></span>
<span><span>  run</span><span>      Run</span><span> the</span><span> project</span></span>
<span><span>  shell</span><span>    Start</span><span> an</span><span> Erlang</span><span> shell</span></span>
<span><span>  test</span><span>     Run</span><span> the</span><span> project</span><span> tests</span></span>
<span><span>  update</span><span>   Update</span><span> dependency</span><span> packages</span><span> to</span><span> their</span><span> latest</span><span> versions</span></span>
<span></span>
<span><span>Options:</span></span>
<span><span>  -h,</span><span> --help</span><span>     Print</span><span> help</span></span>
<span><span>  -V,</span><span> --version</span><span>  Print</span><span> version</span></span>
<span></span></code></pre>
<ul>
<li>package manager ➡️ <code>gleam add</code></li>
<li>repl ➡️ <code>gleam shell</code></li>
<li>test runner ➡️ <code>gleam test</code></li>
<li>formatter ➡️ <code>gleam format</code></li>
<li>lsp ➡️ <code>gleam lsp</code></li>
<li>and more…</li>
</ul>
<p>All you need to get started with Gleam is already in this CLI. You dont’t have
ANYTHING else check, there’s ZERO decision paralysis: THIS-IS-WHAT-WE-WANT.
Javascript makes you pick a tool among hundred of options, for each tool
provided in Gleam’s CLI.</p>
<p>One more thing: each language version comes bundled with its own set of tools;
to prevent tooling incompabilities.</p>
<p>Let’s reuse the previous example:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span></span>
<span><span>/// This is some type related to type Vehicle</span></span>
<span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  /// Car type used for... a car I guess...</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicle: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicle {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> fn</span><span> main</span><span>() {</span></span>
<span><span>  get_driving_requirements</span><span>(</span><span>Car</span><span>(</span><span>make: </span><span>"Hyundai"</span><span>, </span><span>brand: </span><span>"Kona"</span><span>))</span></span>
<span><span>  io.</span><span>println</span><span>(</span><span>"Hello from gl_playground!"</span><span>)</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>When I hover my mouse <code>vehcule</code> in my function body, I’m seeing:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-1.DnMdKRE2_zvw3v.webp" alt="Screenshot showing when you hover on vehicule, your texte editor show your types and documentation thanks to the LSP." width="1694" height="450" loading="lazy" decoding="async"></p><p>LSP is capable of getting both type and documentation related to the variable.
Another exemple if, what happens when I hover on the <code>Car</code> constructor:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-2.DRJwV_aI_Z1lhYEl.webp" alt="Screenshot showing when you hover on Car, the LSP shows the custom type name and the constructor's documentation" width="1432" height="410" loading="lazy" decoding="async"></p><p>Here, the LSP shows both the parent custom type’name and the associated
documentation.</p>
<p>One last example, when I hover on <code>brand</code>, for the code block executed when
<code>Skateboard</code> is matched:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-3.DTLffvNX_Z1iSOR0.webp" alt="Screenshot showing that when your hover on brand, it shows the variable type" width="1790" height="980" loading="lazy" decoding="async"></p><p>The LSP understands that <code>brand</code> is the first attribute in <code>Skateboard</code>.</p>
<p>This is the attention to details that makes you love an ecosystem. It helps you
ship quality code, and it drives the language adoption up: this is a true
win-win situation.</p>
<h3 id="otp-implementation">OTP implementation</h3>
<p>Earlier, I told you that Gleam runs on the
<a href="https://en.wikipedia.org/wiki/BEAM_(Erlang_virtual_machine)">BEAM</a> (never
said that tbh). BEAM means Erlang, and Erlang means OTP. Please, sit down and
relax, cuz I’m about to try to tell you what OTP is about.</p>
<blockquote>
<p>OTP (Open Telecom Platform) is an architecture (and some kind of philosophy)
for building fault-tolerant and highly concurrent software. The key principle
is to divide a program into small execution units called <em>processes</em>
(unrelated to OS processes) and making those processes communicate through
message passing. Those processes can die at any time for any reason, so OTP
advise you to put them under a supervision tree, so that a supervisor (which
is also a process) can restart them. Erlang and Elixir give the developer the
abstractions needed to build on top of OTP, with the BEAM allowing you to run
MILLIONS of processes, even on a tiny server.</p>
</blockquote>
<p><img src="https://christopher.engineering/_astro/big-brain-opt-meme.DmwjBMXb_Z1Wneqo.webp" alt="Big brain meme with 'Me when I explain OTP' as a legend" width="568" height="500" loading="lazy" decoding="async"></p><p>Dang, I really gave my everything on this one, but now you kind of know what OTP
is. That being said, Gleam also has its own OTP primitives, using an
<a href="https://github.com/gleam-lang/otp">external official package</a>. The abstraction
I used the most is the <code>actor</code> (btw, you should learn about the actor model;
this thing is CRAZY). Let me show you how this works:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>int</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>erlang</span><span>/</span><span>process.{</span><span>type</span><span> Subject</span><span>}</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>otp</span><span>/</span><span>actor</span></span>
<span></span>
<span><span>type</span><span> AsyncTaskMessage</span><span> {</span></span>
<span><span>  Increment</span><span>(</span><span>reply_to: </span><span>Subject</span><span>(</span><span>Int</span><span>))</span></span>
<span><span>  Decrement</span><span>(</span><span>reply_to: </span><span>Subject</span><span>(</span><span>Int</span><span>))</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> handle_async_task</span><span>(</span><span>message: </span><span>AsyncTaskMessage</span><span>, </span><span>state: </span><span>Int</span><span>) {</span></span>
<span><span>  case</span><span> message {</span></span>
<span><span>    Increment</span><span>(client) </span><span>-&gt;</span><span> {</span></span>
<span><span>      let</span><span> new_value </span><span>=</span><span> state </span><span>+</span><span> 1</span></span>
<span><span>      process.</span><span>send</span><span>(client, new_value)</span></span>
<span><span>      actor.</span><span>continue</span><span>(new_value)</span></span>
<span><span>    }</span></span>
<span><span>    Decrement</span><span>(client) </span><span>-&gt;</span><span> {</span></span>
<span><span>      let</span><span> new_value </span><span>=</span><span> state </span><span>-</span><span> 1</span></span>
<span><span>      process.</span><span>send</span><span>(client, new_value)</span></span>
<span><span>      actor.</span><span>continue</span><span>(new_value)</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> start_async_task</span><span>(</span><span>state: </span><span>Int</span><span>) {</span></span>
<span><span>  actor.</span><span>start</span><span>(state, handle_async_task)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> main</span><span>() {</span></span>
<span><span>  let</span><span> assert</span><span> Ok</span><span>(actor) </span><span>=</span><span> start_async_task</span><span>(</span><span>0</span><span>)</span></span>
<span><span>  let</span><span> response </span><span>=</span><span> actor.</span><span>call</span><span>(actor, </span><span>fn</span><span>(subject) { </span><span>Increment</span><span>(subject) }, </span><span>10_000</span><span>)</span></span>
<span><span>  io.</span><span>println</span><span>(</span><span>"New value: "</span><span> &lt;&gt;</span><span> int.</span><span>to_string</span><span>(response))</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>For a Gleam actor, you need a few things:</p>
<ol>
<li>A custom type for all kind of messages your actor can receive. It’s called
<code>AsyncTaskMessage</code> in this example.</li>
<li>A function which takes a message and a state (the state being whatever you’d
like) and returns a new state, or something indicating that the task should
end. This is <code>handle_async_task</code> in our example.</li>
<li>A function starting everything. In our example this is the <code>start_async</code>
function.</li>
</ol>
<p>With all of these pieces, you get a new stateful process that can live on its
own. You can send messages for it to do… stuffs, I guess. Yeah, I know the
demo is kind of lame, BUT it shows you how powerful Gleam’s type system is when
coupled with OTP. You cannot send any message to your process that isn’t
type-checked <strong>AT COMPILE TIME</strong>!</p>
<p>Something less cool, is the fact that OTP isn’t fully ported to Gleam. Few
features, like
<a href="https://medium.com/@StevenLeiva1/elixir-process-registries-a27f813d94e3">Registries</a>
are missing…</p>
<h3 id="lustre-a-curious-web-framework">Lustre, a curious web framework</h3>
<p><strong>YEAH, I KNOW</strong>, another new web framework. You have to understand, a new
language needs that kind of popular tooling. Some people (web devs) are waiting
for it. <a href="https://hexdocs.pm/lustre/4.2.4/">Lustre</a> is a Gleam web framework.
It’s been around in Gleam ecosystem for a long time and I think, is mature in
Gleam’s context.</p>
<p>I didn’t tried it yet, (it should be one of my next article), but we’re talking
about a tech with a lot of cool features:</p>
<ul>
<li>It’s isomorphic, it’s running on both backend and frontend.</li>
<li>It’s heavily inspired from <a href="https://elm-lang.org/">Elm</a>, this scary thing we
got from weed smoking Haskell geniuses (this is a compliment, huge respect for
them).</li>
<li>It’s opinionated, from an app to another, you supposed to see the same
conventions and code structure.</li>
</ul>
<p>I’ll let you check <a href="https://hexdocs.pm/lustre/4.2.4/">the documentation</a> and see
if it’s something that you’d be interrested in.</p>
<h3 id="javascript-interoperability">Javascript, interoperability</h3>
<p><img src="https://christopher.engineering/_astro/gleam-js.BZ_mi_eg_PHtwa.svg" alt="Edit show both Gleam's and Javascript logo" width="2105" height="2016" loading="lazy" decoding="async"></p><p>I JUST TOLD YOU!!! Gleam has a web framework and it’s ISOMORPHIC. How does it
run on web? It runs because Gleam can transpile to Javascript. This is an
interesting strategy. They are trying to convince the easiest crowd: Javascript
developers. Those people (me, I’m “these people”) are tired of Typescript /
Javascript nonsense. They’re looking for simplicity, robustness and Gleam has
all the tool they need for that. There’s few players in this space, like
<a href="https://reasonml.github.io/">ReasonML</a> and
<a href="https://rescript-lang.org/">ReScript</a>.</p>
<p>Check the code below:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span></span>
<span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicle: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicle {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> fn</span><span> main</span><span>() {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>"Hyundai"</span><span>, </span><span>brand: </span><span>"Kona"</span><span>)</span></span>
<span><span>  |&gt;</span><span> get_driving_requirements</span><span>()</span></span>
<span><span>  |&gt;</span><span> io.</span><span>println</span><span>()</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>This snippet is quite at exposing Gleam’s key features, there’s types, pattern
matching, pipe operator… See below the Javascript output after running
<code>gleam build --target javascript</code>:</p>
<pre tabindex="0" data-language="javascript"><code><span><span>import</span><span> *</span><span> as</span><span> $io </span><span>from</span><span> "../gleam_stdlib/gleam/io.mjs"</span><span>;</span></span>
<span><span>import</span><span> { CustomType </span><span>as</span><span> $CustomType } </span><span>from</span><span> "./gleam.mjs"</span><span>;</span></span>
<span></span>
<span><span>class</span><span> Car</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>make</span><span>, </span><span>brand</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.make </span><span>=</span><span> make;</span></span>
<span><span>    this</span><span>.brand </span><span>=</span><span> brand;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>class</span><span> Skateboard</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>brand</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.brand </span><span>=</span><span> brand;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>class</span><span> Spaceship</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>year</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.year </span><span>=</span><span> year;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>function</span><span> get_driving_requirements</span><span>(</span><span>vehicle</span><span>) {</span></span>
<span><span>  if</span><span> (vehicle </span><span>instanceof</span><span> Car</span><span>) {</span></span>
<span><span>    let</span><span> make </span><span>=</span><span> vehicle.make;</span></span>
<span><span>    let</span><span> brand </span><span>=</span><span> vehicle.brand;</span></span>
<span><span>    return</span><span> (</span></span>
<span><span>      "To drive the car "</span><span> +</span><span> make </span><span>+</span><span> " "</span><span> +</span><span> brand </span><span>+</span><span> ", your need a driver licence."</span></span>
<span><span>    );</span></span>
<span><span>  } </span><span>else</span><span> if</span><span> (vehicle </span><span>instanceof</span><span> Spaceship</span><span>) {</span></span>
<span><span>    return</span><span> "You need to be a NASA astronaut for that!"</span><span>;</span></span>
<span><span>  } </span><span>else</span><span> {</span></span>
<span><span>    let</span><span> brand </span><span>=</span><span> vehicle.brand;</span></span>
<span><span>    return</span><span> "Anybody can ride a "</span><span> +</span><span> brand </span><span>+</span><span> " skateboard!"</span><span>;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>export</span><span> function</span><span> main</span><span>() {</span></span>
<span><span>  let</span><span> _pipe </span><span>=</span><span> new</span><span> Car</span><span>(</span><span>"Hyundai"</span><span>, </span><span>"Kona"</span><span>);</span></span>
<span><span>  let</span><span> _pipe$1 </span><span>=</span><span> get_driving_requirements</span><span>(_pipe);</span></span>
<span><span>  return</span><span> $io.</span><span>println</span><span>(_pipe$1);</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>The JS code you’re getting is super understandable. You can read it, debug it
and understand how Gleam transforms Gleam code into Javascript code. There are
two important imports:</p>
<ol>
<li><code>$io</code>, which is library that matches what we have in the std lib <code>gleam/io</code>.</li>
<li><code>CustomType</code>, which is a class imported from <code>prelude.mjs</code>, that contains
stuff Gleam needs when operating in a Javascript context.</li>
</ol>
<h2 id="whats-next-with-gleam">What’s next with Gleam</h2>
<p>We spoke briefly about everything interesting with Gleam. As you may have
noticed, there’s nothing that I dislike, for now. I’ll keep experimenting while
doing <a href="https://app.codecrafters.io/join?via=Christopher2K">CodeCrafters puzzles</a>
(sponsored link). I’m currently building my own Redis with Gleam. Hit me up on
Twitter or Twitch if you want to talk about it.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NanoGPT: The simplest, fastest repository for training medium-sized GPTs (107 pts)]]></title>
            <link>https://github.com/karpathy/nanoGPT</link>
            <guid>40642871</guid>
            <pubDate>Tue, 11 Jun 2024 05:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karpathy/nanoGPT">https://github.com/karpathy/nanoGPT</a>, See on <a href="https://news.ycombinator.com/item?id=40642871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">nanoGPT</h2><a id="user-content-nanogpt" aria-label="Permalink: nanoGPT" href="#nanogpt"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/nanoGPT/blob/master/assets/nanogpt.jpg"><img src="https://github.com/karpathy/nanoGPT/raw/master/assets/nanogpt.jpg" alt="nanoGPT"></a></p>
<p dir="auto">The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of <a href="https://github.com/karpathy/minGPT">minGPT</a> that prioritizes teeth over education. Still under active development, but currently the file <code>train.py</code> reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: <code>train.py</code> is a ~300-line boilerplate training loop and <code>model.py</code> a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/nanoGPT/blob/master/assets/gpt2_124M_loss.png"><img src="https://github.com/karpathy/nanoGPT/raw/master/assets/gpt2_124M_loss.png" alt="repro124m"></a></p>
<p dir="auto">Because the code is so simple, it is very easy to hack to your needs, train new models from scratch, or finetune pretrained checkpoints (e.g. biggest one currently available as a starting point would be the GPT-2 1.3B model from OpenAI).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">install</h2><a id="user-content-install" aria-label="Permalink: install" href="#install"></a></p>
<div data-snippet-clipboard-copy-content="pip install torch numpy transformers datasets tiktoken wandb tqdm"><pre><code>pip install torch numpy transformers datasets tiktoken wandb tqdm
</code></pre></div>
<p dir="auto">Dependencies:</p>
<ul dir="auto">
<li><a href="https://pytorch.org/" rel="nofollow">pytorch</a> &lt;3</li>
<li><a href="https://numpy.org/install/" rel="nofollow">numpy</a> &lt;3</li>
<li><code>transformers</code> for huggingface transformers &lt;3 (to load GPT-2 checkpoints)</li>
<li><code>datasets</code> for huggingface datasets &lt;3 (if you want to download + preprocess OpenWebText)</li>
<li><code>tiktoken</code> for OpenAI's fast BPE code &lt;3</li>
<li><code>wandb</code> for optional logging &lt;3</li>
<li><code>tqdm</code> for progress bars &lt;3</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">quick start</h2><a id="user-content-quick-start" aria-label="Permalink: quick start" href="#quick-start"></a></p>
<p dir="auto">If you are not a deep learning professional and you just want to feel the magic and get your feet wet, the fastest way to get started is to train a character-level GPT on the works of Shakespeare. First, we download it as a single (1MB) file and turn it from raw text into one large stream of integers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python data/shakespeare_char/prepare.py"><pre>python data/shakespeare_char/prepare.py</pre></div>
<p dir="auto">This creates a <code>train.bin</code> and <code>val.bin</code> in that data directory. Now it is time to train your GPT. The size of it very much depends on the computational resources of your system:</p>
<p dir="auto"><strong>I have a GPU</strong>. Great, we can quickly train a baby GPT with the settings provided in the <a href="https://github.com/karpathy/nanoGPT/blob/master/config/train_shakespeare_char.py">config/train_shakespeare_char.py</a> config file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/train_shakespeare_char.py"><pre>python train.py config/train_shakespeare_char.py</pre></div>
<p dir="auto">If you peek inside it, you'll see that we're training a GPT with a context size of up to 256 characters, 384 feature channels, and it is a 6-layer Transformer with 6 heads in each layer. On one A100 GPU this training run takes about 3 minutes and the best validation loss is 1.4697. Based on the configuration, the model checkpoints are being written into the <code>--out_dir</code> directory <code>out-shakespeare-char</code>. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py --out_dir=out-shakespeare-char"><pre>python sample.py --out_dir=out-shakespeare-char</pre></div>
<p dir="auto">This generates a few samples, for example:</p>
<div data-snippet-clipboard-copy-content="ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman."><pre><code>ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
</code></pre></div>
<p dir="auto">lol  <code>¯\_(ツ)_/¯</code>. Not bad for a character-level model after 3 minutes of training on a GPU. Better results are quite likely obtainable by instead finetuning a pretrained GPT-2 model on this dataset (see finetuning section later).</p>
<p dir="auto"><strong>I only have a macbook</strong> (or other cheap computer). No worries, we can still train a GPT but we want to dial things down a notch. I recommend getting the bleeding edge PyTorch nightly (<a href="https://pytorch.org/get-started/locally/" rel="nofollow">select it here</a> when installing) as it is currently quite likely to make your code more efficient. But even without it, a simple train run could look as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0"><pre>python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0</pre></div>
<p dir="auto">Here, since we are running on CPU instead of GPU we must set both <code>--device=cpu</code> and also turn off PyTorch 2.0 compile with <code>--compile=False</code>. Then when we evaluate we get a bit more noisy but faster estimate (<code>--eval_iters=20</code>, down from 200), our context size is only 64 characters instead of 256, and the batch size only 12 examples per iteration, not 64. We'll also use a much smaller Transformer (4 layers, 4 heads, 128 embedding size), and decrease the number of iterations to 2000 (and correspondingly usually decay the learning rate to around max_iters with <code>--lr_decay_iters</code>). Because our network is so small we also ease down on regularization (<code>--dropout=0.0</code>). This still runs in about ~3 minutes, but gets us a loss of only 1.88 and therefore also worse samples, but it's still good fun:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py --out_dir=out-shakespeare-char --device=cpu"><pre>python sample.py --out_dir=out-shakespeare-char --device=cpu</pre></div>
<p dir="auto">Generates samples like this:</p>
<div data-snippet-clipboard-copy-content="GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear"><pre><code>GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear
</code></pre></div>
<p dir="auto">Not bad for ~3 minutes on a CPU, for a hint of the right character gestalt. If you're willing to wait longer, feel free to tune the hyperparameters, increase the size of the network, the context length (<code>--block_size</code>), the length of training, etc.</p>
<p dir="auto">Finally, on Apple Silicon Macbooks and with a recent PyTorch version make sure to add <code>--device=mps</code> (short for "Metal Performance Shaders"); PyTorch then uses the on-chip GPU that can <em>significantly</em> accelerate training (2-3X) and allow you to use larger networks. See <a href="https://github.com/karpathy/nanoGPT/issues/28" data-hovercard-type="issue" data-hovercard-url="/karpathy/nanoGPT/issues/28/hovercard">Issue 28</a> for more.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">reproducing GPT-2</h2><a id="user-content-reproducing-gpt-2" aria-label="Permalink: reproducing GPT-2" href="#reproducing-gpt-2"></a></p>
<p dir="auto">A more serious deep learning professional may be more interested in reproducing GPT-2 results. So here we go - we first tokenize the dataset, in this case the <a href="https://openwebtext2.readthedocs.io/en/latest/" rel="nofollow">OpenWebText</a>, an open reproduction of OpenAI's (private) WebText:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python data/openwebtext/prepare.py"><pre>python data/openwebtext/prepare.py</pre></div>
<p dir="auto">This downloads and tokenizes the <a href="https://huggingface.co/datasets/openwebtext" rel="nofollow">OpenWebText</a> dataset. It will create a <code>train.bin</code> and <code>val.bin</code> which holds the GPT2 BPE token ids in one sequence, stored as raw uint16 bytes. Then we're ready to kick off training. To reproduce GPT-2 (124M) you'll want at least an 8X A100 40GB node and run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py"><pre>torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py</pre></div>
<p dir="auto">This will run for about 4 days using PyTorch Distributed Data Parallel (DDP) and go down to loss of ~2.85. Now, a GPT-2 model just evaluated on OWT gets a val loss of about 3.11, but if you finetune it it will come down to ~2.85 territory (due to an apparent domain gap), making the two models ~match.</p>
<p dir="auto">If you're in a cluster environment and you are blessed with multiple GPU nodes you can make GPU go brrrr e.g. across 2 nodes like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run on the first (master) node with example IP 123.456.123.456:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
# Run on the worker node:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py"><pre><span><span>#</span> Run on the first (master) node with example IP 123.456.123.456:</span>
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
<span><span>#</span> Run on the worker node:</span>
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py</pre></div>
<p dir="auto">It is a good idea to benchmark your interconnect (e.g. iperf3). In particular, if you don't have Infiniband then also prepend <code>NCCL_IB_DISABLE=1</code> to the above launches. Your multinode training will work, but most likely <em>crawl</em>. By default checkpoints are periodically written to the <code>--out_dir</code>. We can sample from the model by simply <code>python sample.py</code>.</p>
<p dir="auto">Finally, to train on a single GPU simply run the <code>python train.py</code> script. Have a look at all of its args, the script tries to be very readable, hackable and transparent. You'll most likely want to tune a number of those variables depending on your needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">baselines</h2><a id="user-content-baselines" aria-label="Permalink: baselines" href="#baselines"></a></p>
<p dir="auto">OpenAI GPT-2 checkpoints allow us to get some baselines in place for openwebtext. We can get the numbers as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py"><pre>$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py</pre></div>
<p dir="auto">and observe the following losses on train and val:</p>
<table>
<thead>
<tr>
<th>model</th>
<th>params</th>
<th>train loss</th>
<th>val loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>gpt2</td>
<td>124M</td>
<td>3.11</td>
<td>3.12</td>
</tr>
<tr>
<td>gpt2-medium</td>
<td>350M</td>
<td>2.85</td>
<td>2.84</td>
</tr>
<tr>
<td>gpt2-large</td>
<td>774M</td>
<td>2.66</td>
<td>2.67</td>
</tr>
<tr>
<td>gpt2-xl</td>
<td>1558M</td>
<td>2.56</td>
<td>2.54</td>
</tr>
</tbody>
</table>
<p dir="auto">However, we have to note that GPT-2 was trained on (closed, never released) WebText, while OpenWebText is just a best-effort open reproduction of this dataset. This means there is a dataset domain gap. Indeed, taking the GPT-2 (124M) checkpoint and finetuning on OWT directly for a while reaches loss down to ~2.85. This then becomes the more appropriate baseline w.r.t. reproduction.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">finetuning</h2><a id="user-content-finetuning" aria-label="Permalink: finetuning" href="#finetuning"></a></p>
<p dir="auto">Finetuning is no different than training, we just make sure to initialize from a pretrained model and train with a smaller learning rate. For an example of how to finetune a GPT on new text go to <code>data/shakespeare</code> and run <code>prepare.py</code> to download the tiny shakespeare dataset and render it into a <code>train.bin</code> and <code>val.bin</code>, using the OpenAI BPE tokenizer from GPT-2. Unlike OpenWebText this will run in seconds. Finetuning can take very little time, e.g. on a single GPU just a few minutes. Run an example finetuning like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/finetune_shakespeare.py"><pre>python train.py config/finetune_shakespeare.py</pre></div>
<p dir="auto">This will load the config parameter overrides in <code>config/finetune_shakespeare.py</code> (I didn't tune them much though). Basically, we initialize from a GPT2 checkpoint with <code>init_from</code> and train as normal, except shorter and with a small learning rate. If you're running out of memory try decreasing the model size (they are <code>{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}</code>) or possibly decreasing the <code>block_size</code> (context length). The best checkpoint (lowest validation loss) will be in the <code>out_dir</code> directory, e.g. in <code>out-shakespeare</code> by default, per the config file. You can then run the code in <code>sample.py --out_dir=out-shakespeare</code>:</p>
<div data-snippet-clipboard-copy-content="THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold."><pre><code>THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold.
</code></pre></div>
<p dir="auto">Whoa there, GPT, entering some dark place over there. I didn't really tune the hyperparameters in the config too much, feel free to try!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">sampling / inference</h2><a id="user-content-sampling--inference" aria-label="Permalink: sampling / inference" href="#sampling--inference"></a></p>
<p dir="auto">Use the script <code>sample.py</code> to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. For example, here is a way to sample from the largest available <code>gpt2-xl</code> model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py \
    --init_from=gpt2-xl \
    --start=&quot;What is the answer to life, the universe, and everything?&quot; \
    --num_samples=5 --max_new_tokens=100"><pre>python sample.py \
    --init_from=gpt2-xl \
    --start=<span><span>"</span>What is the answer to life, the universe, and everything?<span>"</span></span> \
    --num_samples=5 --max_new_tokens=100</pre></div>
<p dir="auto">If you'd like to sample from a model you trained, use the <code>--out_dir</code> to point the code appropriately. You can also prompt the model with some text from a file, e.g. <code>python sample.py --start=FILE:prompt.txt</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">efficiency notes</h2><a id="user-content-efficiency-notes" aria-label="Permalink: efficiency notes" href="#efficiency-notes"></a></p>
<p dir="auto">For simple model benchmarking and profiling, <code>bench.py</code> might be useful. It's identical to what happens in the meat of the training loop of <code>train.py</code>, but omits much of the other complexities.</p>
<p dir="auto">Note that the code by default uses <a href="https://pytorch.org/get-started/pytorch-2.0/" rel="nofollow">PyTorch 2.0</a>. At the time of writing (Dec 29, 2022) this makes <code>torch.compile()</code> available in the nightly release. The improvement from the one line of code is noticeable, e.g. cutting down iteration time from ~250ms / iter to 135ms / iter. Nice work PyTorch team!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">todos</h2><a id="user-content-todos" aria-label="Permalink: todos" href="#todos"></a></p>
<ul dir="auto">
<li>Investigate and add FSDP instead of DDP</li>
<li>Eval zero-shot perplexities on standard evals (e.g. LAMBADA? HELM? etc.)</li>
<li>Finetune the finetuning script, I think the hyperparams are not great</li>
<li>Schedule for linear batch size increase during training</li>
<li>Incorporate other embeddings (rotary, alibi)</li>
<li>Separate out the optim buffers from model params in checkpoints I think</li>
<li>Additional logging around network health (e.g. gradient clip events, magnitudes)</li>
<li>Few more investigations around better init etc.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto">Note that by default this repo uses PyTorch 2.0 (i.e. <code>torch.compile</code>). This is fairly new and experimental, and not yet available on all platforms (e.g. Windows). If you're running into related error messages try to disable this by adding <code>--compile=False</code> flag. This will slow down the code but at least it will run.</p>
<p dir="auto">For some context on this repository, GPT, and language modeling it might be helpful to watch my <a href="https://karpathy.ai/zero-to-hero.html" rel="nofollow">Zero To Hero series</a>. Specifically, the <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="nofollow">GPT video</a> is popular if you have some prior language modeling context.</p>
<p dir="auto">For more questions/discussions feel free to stop by <strong>#nanoGPT</strong> on Discord:</p>
<p dir="auto"><a href="https://discord.gg/3zy8kqD9Cp" rel="nofollow"><img src="https://camo.githubusercontent.com/f3b057ade47ec925300af6567ec645a7a1178b1a823f6285daf317cd42cb1fb9/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f337a79386b71443943703f636f6d706163743d74727565267374796c653d666c6174" alt="" data-canonical-src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;style=flat"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">All nanoGPT experiments are powered by GPUs on <a href="https://lambdalabs.com/" rel="nofollow">Lambda labs</a>, my favorite Cloud GPU provider. Thank you Lambda labs for sponsoring nanoGPT!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[British duo arrested for SMS phishing via homemade cell tower (173 pts)]]></title>
            <link>https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/</link>
            <guid>40642801</guid>
            <pubDate>Tue, 11 Jun 2024 05:40:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/">https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/</a>, See on <a href="https://news.ycombinator.com/item?id=40642801">Hacker News</a></p>
Couldn't get https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DuckDB Isn't Just Fast (101 pts)]]></title>
            <link>https://csvbase.com/blog/6</link>
            <guid>40642476</guid>
            <pubDate>Tue, 11 Jun 2024 04:51:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://csvbase.com/blog/6">https://csvbase.com/blog/6</a>, See on <a href="https://news.ycombinator.com/item?id=40642476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- DuckDB is more than just fast -->
<p>DuckDB is a single file SQL database.  It's designed for data analysis and so,
probably because of the bent of people who are into that sort of thing, a lot
of the evaluations of it end up being quantitative.  This isn't just true of
DuckDB - most comparisons of most data tools tend to focus on the measureable.</p>
<p>That means they
<a href="https://medium.com/@kayrnt/how-duckdb-can-be-up-to-1000x-more-efficient-than-bigquery-36bab2405259">mainly</a>
<a href="https://github.com/prrao87/duckdb-study">look</a>
<a href="https://www.fivetran.com/blog/how-fast-is-duckdb-really">at</a>
<a href="https://duckdblabs.github.io/db-benchmark/">speed</a>.  And DuckDB generally does
well.</p>
<p>The notes on benchmark performance graphs often read "higher is better" and
performance improvements are even called "optimisations".  But the truth is, at
least as a user, once performance reaches a satisfactory level - enough for
your own data analysis to complete in a reasonable about of time - there is no
further benefit from increased speed.  Instead of being called "performance
optimisation" it should probably be called "performance satisfaction" as once
it is satisfactory you have finished.</p>
<p>Usability is different.  The whole point of computers is as an aid to
productivity so user-friendliness is actually the bit you want to optimise.
Unlike speed, being easier to use is always better and there is very little
limit to that.  So it's "usability improvements" that should be called
"optimisations" but perhaps the relevant ships on all of these terms have
sailed.</p>
<p>Anyway to balance out the force out I want to demonstrate some usability
benefits of DuckDB.  Mostly, they cannot be measured:</p>
<ol>
<li>Good developer ergonomics</li>
<li>It handles larger than memory ("out of core") datasets</li>
<li>Easy to install &amp; run</li>
</ol>
<h2>Ergonomics</h2>
<p>DuckDB takes care to make the common stuff straightward.  For example, you can
create tables (including inferring the table schema) straight from <a href="https://csvbase.com/meripaterson/stock-exchanges">input
files</a>:</p>
<div><pre><span></span><span>-- loading a table from a parquet file</span>
<span>CREATE</span><span> </span><span>TABLE</span><span> </span><span>stock_exchanges</span><span> </span><span>AS</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_parquet</span><span>(</span><span></span>
<span>        </span><span>"https://csvbase.com/meripaterson/stock-exchanges.parquet"</span><span></span>
<span>);</span><span></span>
</pre></div>
<p>Looking at the schema of that table:</p>
<div><pre><span></span><span>-- the output of: .schema stock_exchanges</span>
<span>CREATE</span><span> </span><span>TABLE</span><span> </span><span>stock_exchanges</span><span> </span><span>(</span><span></span>
<span>    </span><span>csvbase_row_id</span><span> </span><span>bigint</span><span>,</span><span></span>
<span>    </span><span>Continent</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>Country</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>"Name"</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>MIC</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>"Last changed"</span><span> </span><span>date</span><span></span>
<span>);</span><span></span>
</pre></div>
<p>DuckDB has inferred all the columns, including their types, from the Parquet
file.  Brill.  And as you can see, that Parquet file can come from anywhere on
the web, it need not be local.  That's perhaps not a big advance on some of the
common dataframe libraries, but it is a big advance in the world of SQL-based
tools, most of which can only read CSV (not Parquet) and then also require the
schema to be created beforehand.</p>
<p>And you don't actually have to create a table first in order to query the data.
The <code>read_parquet</code> function returns a relation and so can act as a sub-query.
A specific example of that, this time with a csv file:</p>
<div><pre><span></span><span>-- pulling down the most recent EUR:USD exchange rate</span>
<span>SELECT</span><span></span>
<span>    </span><span>rate</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_csv_auto</span><span>(</span><span>"https://csvbase.com/table-munger/eurofxref.csv"</span><span>)</span><span></span>
<span>WHERE</span><span></span>
<span>    </span><span>currency</span><span> </span><span>=</span><span> </span><span>'USD'</span><span>;</span><span></span>
</pre></div>
<p>So you can freely query parquet and csv files on the web with the minimum of
fuss.</p>
<p>But how much of SQL does DuckDB support?  A very wide swathe.  I haven't done
any comprehensive analysis but of the stuff I use in Postgres I haven't found
much if anything that isn't also implemented in DuckDB.</p>
<p>For example, window functions are fully supported:</p>
<div><pre><span></span><span>-- smoothed history of the eur:usd exchange rate</span>
<span>SELECT</span><span></span>
<span>    </span><span>date</span><span>,</span><span></span>
<span>    </span><span>avg</span><span>(</span><span>rate</span><span>)</span><span> </span><span>OVER</span><span> </span><span>(</span><span></span>
<span>        </span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>date</span><span></span>
<span>        </span><span>ROWS</span><span> </span><span>BETWEEN</span><span> </span><span>100</span><span> </span><span>PRECEDING</span><span> </span><span>AND</span><span> </span><span>CURRENT</span><span> </span><span>ROW</span><span></span>
<span>    </span><span>)</span><span> </span><span>AS</span><span> </span><span>rolling</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_parquet</span><span>(</span><span>'https://csvbase.com/table-munger/eurofxref-hist.parquet'</span><span>)</span><span></span>
<span>WHERE</span><span></span>
<span>    </span><span>currency</span><span> </span><span>=</span><span> </span><span>'USD'</span><span>;</span><span></span>
</pre></div>
<p>And that's not the end of DuckDB making the simple stuff easy.  I did the above
query at the library on a slow internet connection and DuckDB helpfully started
to display a progress bar, which even Postgres doesn't have.</p>
<p>Then, when the query was done it politely avoided swamping my terminal with the
6500 lines of output by abbreviating them, just like Pandas does.</p>
<h2>Datasets larger than memory</h2>
<p>One of the problems that arises with more than a few data tools is that once
the dataset gets bigger than the computer memory (or gets within 50%) the tool
breaks down.</p>
<p>This is an underrated source of pain.  Sometimes I've seen someone write
something quickly with one tool as a quick prototype.  The prototype works
great and you want to run it on the full dataset - but wait - you can't.
You're getting memory errors, heavy swapping, etc.  The problem is that the
tool was loading the whole dataset into memory and so suddenly you have to
change technology.  Always an unpleasant discovery.</p>
<p>DuckDB fully supports datasets larger than memory.  That's in contrast to
Pandas, which starts to struggle once your dataframe is &gt;50% of system memory.
The majority of dataframe libraries do not support datasets larger than memory
or require <a href="https://docs.pola.rs/user-guide/concepts/streaming/">alternate, more limited, modes of
operation</a> when using
them - but in DuckDB everything works.</p>
<h2>Single file, single machine model - and the magic of WASM</h2>
<p>DuckDB (which, like <a href="https://github.com/calpaterson/csvbase">csvbase</a>, is <a href="https://github.com/duckdb/duckdb/">an
open source project</a>) gets compiled to a
single executable file, <code>duckdb</code>.  That means trying it out just means copying
<code>duckdb</code> onto your computer and running it.  Find the right executable for your
machine <a href="https://duckdb.org/docs/installation/">here</a>.</p>
<p>But it actually gets even easier than that.  Through the magic of
<a href="https://en.wikipedia.org/wiki/WebAssembly">WASM</a> you can experience the full
majesty of DuckDB directly in your browser on
<a href="https://shell.duckdb.org/">shell.duckdb.org</a>!</p>
<p><img src="https://csvbase.com/blog-static/shelldotduckdbdotorg.png" alt="screenshot of shell.duckdb.org in a web browser"></p>
<p><code>shell.duckdb.org</code> is an based on the <a href="https://en.wikipedia.org/wiki/WebAssembly">WASM (aka
WebAssembly)</a> target of the <code>duckdb</code>
build.  WASM is a newish binary format that allows you to run native code
(think: <code>.exe</code> files) inside a web browser.  It's <a href="https://www.usenix.org/conference/atc19/presentation/jangda">not quite as fast as real
native code</a>, but
it's usually close enough and has the key advantage that you can execute random
binaries in a sandboxed virtual machine - mostly without rewriting them.</p>
<p>As a result <code>shell.duckdb.org</code> is fully powered - it can be because everything
is running in your browser, not on a server.  You can use <code>shell.duckdb.org</code> to
import files off the web, you have the full SQL dialect, you can execute
long-running queries, whatever you want.  And you can even share sessions as
links.  Try this one:</p>
<p><a href="https://shell.duckdb.org/#queries=v0,select-*-from-read_parquet(%22https%3A%2F%2Fcsvbase.com%2Fmeripaterson%2Fstock%20exchanges.parquet%22)~">https://shell.duckdb.org/#queries=v0,select-*-from-read_parquet(%22https%3A%2F%2Fcsvbase.com%2Fmeripaterson%2Fstock%20exchanges.parquet%22)~</a></p>
<h2>DuckDB as a lo-fi dataframe library</h2>
<p>DuckDB also has good quality integration with the lingua franca of data
analysis.  For better or worse that means: Python.</p>
<p>First, install the DuckDB python library (and csvbase's client, which I will
use later).</p>
<div><pre><span></span>pip install duckdb csvbase-client
</pre></div>
<p>Now you can execute queries inside Python:</p>
<div><pre><span></span><span>import</span> <span>duckdb</span>

<span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"select 1"</span><span>)</span>
</pre></div>
<p>Easy enough.  But there is one more trick: you can query return values.</p>
<p>That means you you can start to do imperative-style programming to build up a
bigger data operation step by step - in an analogous way to how you would write
dataframe code.  A worked example:</p>
<div><pre><span></span><span># get all stock exchanges</span>
<span>stock_exchanges</span> <span>=</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>'''</span>
<span>    SELECT</span>
<span>        *</span>
<span>    FROM</span>
<span>        read_parquet(</span>
<span>            "https://csvbase.com/meripaterson/stock-exchanges.parquet"</span>
<span>        )</span>
<span>'''</span><span>)</span>

<span># exclude non-North American exchanges</span>
<span>na_stock_exchanges</span> <span>=</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>    SELECT</span>
<span>        *</span>
<span>    FROM</span>
<span>        stock_exchanges -- a variable reference to the above</span>
<span>    WHERE</span>
<span>        "Continent" = 'North America'</span>
<span>"""</span><span>)</span>

<span># get the MIC codes as a Python set</span>
<span>na_mic_codes</span> <span>=</span> <span>{</span>
    <span>t</span><span>[</span><span>0</span><span>]</span> <span>for</span> <span>t</span> <span>in</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>        SELECT</span>
<span>            "MIC"</span>
<span>        FROM</span>
<span>            na_stock_exchanges</span>
<span>    """</span><span>)</span><span>.</span><span>fetchall</span><span>()</span> <span>if</span> <span>t</span> <span>is</span> <span>not</span> <span>None</span>
<span>}</span>
</pre></div>
<p>Allowing for dataframe-style programming starts to bridge the benefits of SQL
with the benefits of dataframes.  You get all the benefits of SQL:</p>
<ol>
<li>Lazy evaluation</li>
<li>The query planner (ie: an optimising compiler)</li>
<li>That SQL is already very well known</li>
</ol>
<p>And then you also get the benefits of dataframes</p>
<ol start="4">
<li>
Easy to write larger programs by doing larger operations step-by-step<ul>
<li><em>without</em> resorting to string concat tricks or sprocs</li>
</ul>
</li>
<li>
Can use an imperative language to build up your data operation<ul>
<li>and wrap it</li>
</ul>
</li>
</ol>
<p>That's not to say that this is a fully developed replacement for Pandas.
Pandas' API still does a lot more than just this.  But being able to build up
larger programs using the dataframe-style of programming certainly makes them
easier to write.</p>
<h2>Saving your game with csvbase (fsspec)</h2>
<p>I <a href="https://csvbase.com/blog/7">wrote before</a> about how csvbase's client library
is designed to slot in to anything by being written against a standard API
called "fsspec".  I gave <a href="https://csvbase.com/faq/pandas">Pandas</a>, Polars and Dask as examples but
the same is true for <a href="https://csvbase.com/faq/duckdb">DuckDB</a>:</p>
<div><pre><span></span><span>import</span> <span>duckdb</span><span>,</span> <span>fsspec</span>

<span># you'd put this bit into __init__.py</span>
<span>duckdb</span><span>.</span><span>register_filesystem</span><span>(</span><span>fsspec</span><span>.</span><span>filesystem</span><span>(</span><span>'csvbase'</span><span>))</span>

<span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>    COPY stock_exchanges TO</span>
<span>    'csvbase://calpaterson/duckdb-example?public=true' (HEADER, DELIMITER ',')</span>
<span>"""</span><span>)</span>
</pre></div>
<p>And it's not just csvbase that implements fsspec but plenty of others like
Google Drive, SFTP, HFDS - there are lots and lots of implementations.  Find a
list of them this way:</p>
<div><pre><span></span><span>from</span> <span>fsspec.registry</span> <span>import</span> <span>known_implementations</span><span>;</span> <span>import</span> <span>pprint</span>

<span>pprint</span><span>.</span><span>pprint</span><span>(</span><span>known_implementations</span><span>)</span>
</pre></div>
<p>The majority of Python-based data libraries have support for fsspec so this is
nothing particularly special - but it's just nice to know that DuckDB can
easily plug into anything that already has an fsspec implementation.</p>
<h2>Scale - "lower is better"</h2>
<p>After speed, the next much-discussed quantitative dimension is "scalability".
Scale is probably an even more vexed topic than speed because while more speed
is not always better it at least does no harm.  Greater scale though, usually
comes with greater complexity.</p>
<p>DuckDB does not scale to thousands of machines.  Apache Spark does though, and
is now the established "big tech company" way to do larger data analyses.  But
the hassle involved in Spark is actually considerable.  Even the cloud services
that take a huge bite out of your team's monthly budget don't really make all
of the hassle go away.</p>
<p>In my view, scale is not just a one-way road.  Scaling <em>down</em> is just as
important - perhaps more - than scaling <em>up</em>.  Down, down, down - to a single
person trying to get stuff done, not an uncommon scale in the field of data
analysis.</p>
<p>DuckDB operates on this scale and it requires very little of you.  If you're
doing data analysis you probably already know SQL.  DuckDB supports
larger-than-memory data. And there isn't a lot to install.  That makes it a
highly desirable alternative to full blown Spark code for many many cases.</p>
<h2>See also</h2>
<p>csvbase now supports <a href="https://csvbase.com/faq/git">tables backed by git
repos</a>.  It's a nice way to get both easy reads
and writes as well as change history of git.  You can also use it to publish csv
files from repos onto the web (including private repos).</p>
<p>As I mentioned, <code>csvbase-client</code> <a href="https://csvbase.com/faq/duckdb">works with
DuckDB</a> via <a href="https://csvbase.com/blog/7">the magic of
fsspec</a>.  That includes the
<a href="https://csvbase.com/faq/csvbase-client-cache">cache</a> - so repeated references to a table don't
pointlessly re-download it each time.</p>
<p>I'm pretty interested in WASM.  Perhaps it would be possible to allow people to
upload their data cleanup/transformation scripts as wasm binaries and run them
on csvbase each time an upstream dataset changed?  <a href="mailto:cal@calpaterson.com">Write to
me</a> if you're interested in this.</p>
<p>DuckDB seems to have come out of the Netherland's national computer science and
maths institute,
<a href="https://en.wikipedia.org/wiki/Centrum_Wiskunde_%26_Informatica">CWI</a>.  Many
other columar databases have links with CWI, including
<a href="https://en.wikipedia.org/wiki/MonetDB">MonetDB</a> as well as
<a href="https://www.cwi.nl/en/news/cwi-born-technology-behind-record-ipo-company-snowflake/">Snowflake</a>.
Clearly there is something in the water at CWI.</p>
<p>DuckDB is obviously influenced by SQLite.  What's the difference?  SQLite uses a
<a href="https://calpaterson.com/how-a-sql-database-works.html">more traditional "row store" storage
system</a> which is ideal
for transaction-heavy workloads but less amenable to data analysis workloads
then the columnar form of DuckDB.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[macOS 15.0 supports Nested Virtualization on M3 chips (130 pts)]]></title>
            <link>https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported</link>
            <guid>40642328</guid>
            <pubDate>Tue, 11 Jun 2024 04:26:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported">https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported</a>, See on <a href="https://news.ycombinator.com/item?id=40642328">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Biodiversity enhances immune regulation among daycare children (2020) (120 pts)]]></title>
            <link>https://www.science.org/doi/10.1126/sciadv.aba2578</link>
            <guid>40641704</guid>
            <pubDate>Tue, 11 Jun 2024 02:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/doi/10.1126/sciadv.aba2578">https://www.science.org/doi/10.1126/sciadv.aba2578</a>, See on <a href="https://news.ycombinator.com/item?id=40641704">Hacker News</a></p>
Couldn't get https://www.science.org/doi/10.1126/sciadv.aba2578: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Noam Chomsky 'no longer able to talk' after 'medical event' (267 pts)]]></title>
            <link>https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html</link>
            <guid>40641361</guid>
            <pubDate>Tue, 11 Jun 2024 01:39:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html">https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html</a>, See on <a href="https://news.ycombinator.com/item?id=40641361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-newsletter-key="receiveIndyBreakingNews"><p><img src="https://static.independent.co.uk/static-assets/images/newsletter/breaking-news/breaking-news-thumb.png" loading="lazy" alt="Breaking News"></p><div><p><h3 data-nosnippet="">For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails</h3><h3 data-nosnippet="">Sign up to our free breaking news emails</h3></p></div></div><p><a href="https://www.independent.co.uk/topic/noam-chomsky">Noam Chomsky</a>’s health has deterioriated following a medical event, leaving him unable to communicate, his former assistant has revealed. </p><p>The 95-year-old famed linguist has not been seen in public since June last year, with many commenting on the weight of his absence from the broader debate <a href="https://www.independent.co.uk/news/world/middle-east/israel-children-un-military-hamas-b2558864.html">surrounding the war</a> in <a href="https://www.independent.co.uk/topic/gaza">Gaza</a>. </p><p>Chomsky, who has been vocal about his support for the Palestinian cause and what he has called the “crimes” of the Israeli state, has been <a href="https://www.independent.co.uk/climate-change/news/trump-climate-change-noam-chomsky-book-interview-hitler-robert-pollin-b1374789.html">notably absent from demonstrations and discussions </a>on the issue over the last year. </p><p>In a <a rel="nofollow" target="_blank" href="https://www.facebook.com/MediaLensUK/posts/861747505988619">post shared by <em>Media Lens</em>,</a> it was revealed that the MIT professor is unlikely to ever return to the public eye following the deterioration of his health. </p><p>The post quoted Professor Chomsky’s former assistant Bev Stohl, who first shared<a rel="nofollow" target="_blank" href="https://www.reddit.com/r/chomsky/comments/1aj56hj/updates_on_noams_health_from_his_longtime_mit/"> the news on a reddit forum</a> as she explained why the usually responsive academic “hasn’t been returning emails, or interviewing”. </p><p>Stohl, who worked as Chomsky’s office manager at MIT for 24 years until her retirement in 2017, wrote on 5 February: “I’m in contact with a close family member, and we know the basics, and hope to know more in the near future. </p><p>“In a nutshell, Noam is 95-years-old and suffered a medical event in June. As many have noticed, he has not been writing, corresponding, or interviewing, as his health situation has taken the majority of his time and energy. </p><p>“He is still with us, now watching the news (he doesn’t look happy about what he’s watching).”</p><p>Stohl shared further details on the linguist’s ability to communicate, adding that he was no longer mobile or walking either.</p><div><figure><p><img src="https://static.independent.co.uk/2024/06/10/13/newFile.jpg" srcset="https://static.independent.co.uk/2024/06/10/13/newFile.jpg?quality=75&amp;width=320&amp;auto=webp 320w, https://static.independent.co.uk/2024/06/10/13/newFile.jpg?quality=75&amp;width=640&amp;auto=webp 640w" loading="lazy" alt="" on="tap:auto-image-gallery,inline-image-carousel.goToSlide(index=0)" tabindex="0" role="button" data-gallery-length="2"></p><figcaption><span>(<!-- -->AFP via Getty Images<!-- -->)</span></figcaption></figure></div><p>“His ability to speak is complicated by factors I can’t yet disclose,” she continued. “When the relative I’m in touch with visited him a month ago, he did not communicate with her. </p><p>“He is not ambulatory. I’m not sure for how long this will go on. He is not in pain. His eyes are open and he seems to be watching what’s happening around him.”</p><p>The assistant, who also wrote a memoir titled <em>Chomsky and Me</em> on her time working with the world-renowned thinker, provided an update in April as she wrote, “Noam has not made significant progress, I’m sorry to say. I doubt he will be able to return to the public eye, as he is not communicating much if at all.”</p><div><blockquote><p lang="en" dir="ltr">Chomsky has been unbelievably kind over the years I've known him. He treats everyone as an equal. Doesn't care who you are. He would give as much of his time to a high school student as some celebrity or NYT reporter. And devoted himself to attacking cruelty and injustice. <a rel="nofollow" target="_blank" href="https://t.co/6aQBZSSSQX">https://t.co/6aQBZSSSQX</a></p>— Nathan J Robinson (@NathanJRobinson) <a rel="nofollow" target="_blank" href="https://twitter.com/NathanJRobinson/status/1799518761063465286?ref_src=twsrc%5Etfw">June 8, 2024</a></blockquote> </div><p>Some of the comments have since been deleted as Stohl edited a post to say that Chomsky’s “family is very private” and she will “no longer be adding to this discussion”. </p><p><em>The Independent</em> has contacted Noam Chomsky and his literary agent for comment. </p><p>Tributes have poured in from across the media industry as many noted the linguist’s passion for language, having dedicated over seven decades to the study of words and communication, and expressed sadness at his now limited ability.</p><p>Nathan Robinson, founder and editor of socialist magazine, <em>Current Affairs</em>, is also co-author of Chomsky’s forthcoming book, <em>The Myth of American Idealism: How US Foreign Policy Endangers the World</em>. He wrote: “Chomsky has been unbelievably kind over the years I’ve known him. </p><p>“He treats everyone as an equal. Doesn’t care who you are. He would give as much of his time to a high school student as some celebrity or <em>NYT</em> reporter. And devoted himself to attacking cruelty and injustice.</p><p>“So many thousands of people have stories about how he has changed their lives. He certainly changed mine.”</p><p>British-American journalist and <em>Zeteo</em> founder Mehdi Hasan added, “Sending prayers Noam’s way. There has been no one else like him in our lifetime.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ship Something Every Day (185 pts)]]></title>
            <link>https://maxleiter.com/blog/ship-every-day</link>
            <guid>40640927</guid>
            <pubDate>Tue, 11 Jun 2024 00:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maxleiter.com/blog/ship-every-day">https://maxleiter.com/blog/ship-every-day</a>, See on <a href="https://news.ycombinator.com/item?id=40640927">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2>Ship something every day</h2><p><strong>Edit</strong>: A better title would've been "<em>commit</em> every day <em>that you work</em>". I don't mean you should work on weekends or not take time off, and
whatever you work on doesn't need to "ship to prod".</p>
<hr>
<p>I don't feel particularly qualified to give advice (I blame imposter syndrome),
but I do have one tip to share that I think has been useful for me.
It applies both to professional software dev and personal projects.</p>
<p>You probably guessed it from the title: <strong>ship something every day</strong>.</p>
<p>It doesn't need to be a major feature or even a bug fix. It just needs to be something you can point to.</p>
<p>Why? A few reasons:</p>
<ul>
<li>The dopamine rush of your code being shipped</li>
<li>Your team sees you're working<!-- -->
<ul>
<li>There's more to this than just performance reviews; with remote work, it's easy for you and co-workers to feel isolated.</li>
</ul>
</li>
<li>It encourages incremental work. Your future self and co-workers will thank you</li>
<li>Your git commit streak looks good<!-- -->
<ul>
<li>Yes, people say this doesn't matter. But I'm sure people like recruiters look at GitHub profiles, and an empty page isn't a great look.</li>
</ul>
</li>
<li>The satisfaction and mental benefits of getting something done.</li>
</ul>
<br>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Siberia's 'mammoth graveyard' reveals 800-year human interactions with mammoths (122 pts)]]></title>
            <link>https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html</link>
            <guid>40640833</guid>
            <pubDate>Tue, 11 Jun 2024 00:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html">https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html</a>, See on <a href="https://news.ycombinator.com/item?id=40640833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/siberias-mammoth-grave-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/siberias-mammoth-grave-1.jpg" data-sub-html="Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/siberias-mammoth-grave-1.jpg" alt="Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts" title="Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024." width="800" height="530">
             <figcaption>
                Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024.
            </figcaption>        </figure>
    </div><p>Woolly mammoths are evocative of a bygone era, when Earth was gripped within an Ice Age. Current knowledge places early mammoth ancestors in the Pliocene (2.58–5.33 million years ago, Ma) before their populations expanded in the Pleistocene (2.58 Ma–11,700 years ago, kyr). However, as climate changed, their numbers dwindled to isolated populations in modern Siberia and Alaska, until their last dated survival 4 kyr ago.</p>


										      
																																	
<p>In the East Siberian Arctic (&gt;70 °N), there is not only evidence of significant woolly mammoth populations, but also how humans interacted with them, the focus of <a href="https://linkinghub.elsevier.com/retrieve/pii/S0277379124001938" target="_blank">new research</a> in <i>Quaternary Science Reviews</i>.</p>
<p>Along the Berelekh River, Russia, a 'mammoth graveyard' can be found. Here, thousands of disarticulated bones, representing a minimum of 156 individual mammoths, found alongside an <a href="https://phys.org/tags/archaeological+site/" rel="tag">archaeological site</a> indicate the close proximity of these two communities, forming the Berelekh geoarchaeological complex.</p>
<p>Dr. Vladimir Pitulko, of the Russian Academy of Sciences, and colleagues aimed to assess the relationship between the 'mammoth graveyard' and the archaeological site through a re-examination of stratigraphic and paleogeographic data obtained in 2009, with new fieldwork focused on the left riverbanks where <a href="https://phys.org/tags/mammoth+bones/" rel="tag">mammoth bones</a> have readily yielded from their home in the sediment and appeared on the water's edge. Alongside them are remains of Pleistocene hare, Arctic fox and wolves, as well as soot and charcoal from hearths and worked mammoth tusks (one being an unfinished throwing spear).</p>

																																						
																																			<p>The researchers suggest humans created these bone accumulations as a byproduct of the production of mammoth ivory technology, while hares may have been targeted for fur to produce winter clothing.</p>
<p>Notably, evidence of blowfly pupae activity on cavities in skulls and bones is indicative that the mammoth carcasses were added to the 'graveyard' de-fleshed. Indeed, there appears to be evidence of sorting of the bones, with only the most valuable transported to Berelekh from the area in which the mammoth was killed, leaving behind parts such as spinal columns, carpal ('hand') and tarsal ('foot') bones.</p>

<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/siberias-mammoth-grave.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/siberias-mammoth-grave.jpg" data-sub-html="a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/siberias-mammoth-grave.jpg" alt="Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts" title="a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.">
             <figcaption>
                a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.
            </figcaption>        </figure>
    </div>
<p>There are three radiocarbon dated peaks in woolly mammoth accumulation at 11.8, 12.2 and 12.4 kyr ago, which fall within known human settlement of the area (11.2–12.4 kyr ago) during the Bølling-Allerød deglacial, when the <a href="https://phys.org/tags/northern+hemisphere/" rel="tag">northern hemisphere</a> warmed and pollen evidence suggests the region became more arid.</p>
<p>Fluctuations in the abundance of mammoths in the 'graveyard' suggest human settlement of the area may also have changed through time (frequent occupation but not permanent), which the researchers attribute to <a href="https://phys.org/tags/environmental+changes/" rel="tag">environmental changes</a> on the floodplain permitting suitability for erecting campsites.</p>
<p>Radiocarbon dating of mammoth remains identifies their presence here pre-dating human settlement (beginning ~12.5 kyr ago), but also shows that humans remained in the area (until ~11.2 kyr ago) after mass mammoth remains accumulation declined (~11.8 kyr ago).</p>

																																			<p>Given this, four possible causes are suggested by the scientists to explain such a significant mass accumulation of bones: 1) mass death by natural causes or human, 2) repeated group deaths in the same location, likely due to human predation, 3) concentration of remains by <a href="https://phys.org/tags/geological+processes/" rel="tag">geological processes</a>, such as river action, or 4) solely derived from human predation or scavenging from deceased carcasses.</p>
<p>However, the latter is considered to be the most likely to produce useful tools from ivory tusks, as well as meat to feed the community, as there is no evidence on the bones for a cause of mass death, radiocarbon ages do not cluster into multiple phases for recurrent death deposits and stream flows were unlikely to reach sufficient velocities to transport such heavy bones.</p>
<p>These findings are concurrent with mammoth remains at the Yana Paleolithic site, also in Siberia. Here, estimates suggest the 'graveyard' increased by 1–2 mammoths per year rather than a mass death event, a figure Dr. Pitulko and colleagues conclude could be similar or even higher for Berelekh.</p>
<p>This research is significant as it alters the previously-held belief that there was a lag of 50–80 years between mammoth bone accumulation from natural processes (such as deposition in flood channels) and <a href="https://phys.org/tags/human+settlement/" rel="tag">human settlement</a>, instead now defining a close relationship between the two over 700–800 years. Sadly, now that human-mammoth relationship has continued as ivory hunters have looted the site beyond further study.</p>


																																																					
																				<div>
																						<p><strong>More information:</strong>
												Vladimir V. Pitulko et al, From the Berelekh 'mammoth graveyard' to Berelekh geo-archaeological complex: Paleoenvironment, site formation processes, and human-mammoth relationships, <i>Quaternary Science Reviews</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1016/j.quascirev.2024.108692" target="_blank">DOI: 10.1016/j.quascirev.2024.108692</a>
																						
																						</p>
																					</div>
                               											
																															 <p>
												  © 2024 Science X Network
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts (2024, June 10)
												retrieved 11 June 2024
												from https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel pauses work on $25B Israel fab (136 pts)]]></title>
            <link>https://www.theregister.com/2024/06/10/intel_israeli_fab/</link>
            <guid>40640499</guid>
            <pubDate>Mon, 10 Jun 2024 23:26:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/06/10/intel_israeli_fab/">https://www.theregister.com/2024/06/10/intel_israeli_fab/</a>, See on <a href="https://news.ycombinator.com/item?id=40640499">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Construction work on Intel's $25 billion semiconductor manufacturing plant in Kiryat Gat, Israel, has reportedly been postponed.</p>
<p>According to <a target="_blank" rel="nofollow" href="https://www.mako.co.il/news-money/2024_q2/Article-78566163f330091026.htm?sCh=31750a2610f26110&amp;pId=173113802">Israeli media</a> [in Hebrew], Intel has asked an infrastructure construction firm to pause work on the project.</p>
<p>In a statement to <em>The Register</em> on Monday, the x86 giant reaffirmed its commitment to Israel, where the biz employs nearly 12,000 workers, explaining that projects of this scope have many dependencies that delay work. Which is a fancy way of saying: Yes, the project's been paused.</p>

    

<p>"Israel continues to be one of our key global manufacturing and R&amp;D sites and we remain fully committed to the region. As we've previously noted, the scope and pace of Intel's manufacturing expansion at our sites around the world depends heavily on various factors," the chip giant explained.</p>

        


        

<p>"Managing large-scale projects, especially in our industry, often involves adapting to changing timelines. Our decisions are based on business conditions, market dynamics and responsible capital management."</p>
<p>It isn't clear how long the project will remain on hold. Intel's comment regarding capital management suggests it may be stalling while figuring out how to pay for the project. Intel has relied on private equity from the likes of Brookfield Asset Management and Apollo Global Management to help <a target="_blank" href="https://www.theregister.com/2022/08/23/intel_asks_private_equity_firms/">finance</a> some of its fab projects.</p>
<ul>

<li><a href="https://www.theregister.com/2024/06/05/intel_gets_11b_from_apollo/">Intel gets $11B from Apollo for joint venture at Irish chip fab</a></li>

<li><a href="https://www.theregister.com/2024/06/04/intel_gelsinger_computex_keynote/">Fired-up Pat Gelsinger shoots from the lip at Qualcomm and Nvidia</a></li>

<li><a href="https://www.theregister.com/2024/05/22/ai_chips_driving_recovery/">Even TSMC can't cook chips fast enough to sate AI's hunger</a></li>

<li><a href="https://www.theregister.com/2024/05/13/biden_polar_chip_fab/">Biden admin shells out $120M to return chip startup to US ownership</a></li>
</ul>
<p>News of the delay comes less than six months after Intel <a target="_blank" href="https://www.theregister.com/2023/12/27/intel_israel_fab/">revealed</a> its plans to expand fab operations in Israel. The $25 billion project was slated to receive $3.2 billion in government subsidies and "foster a more resilient global supply chain."</p>
<p>The site is one of several fab projects announced by Intel following former-VMware CEO Pat Gelsinger's <a target="_blank" href="https://www.theregister.com/2021/01/13/intel_ceo_pat_gelsinger/">return</a> to Chipzilla as chief exec in early 2021. To date Intel has committed to spending more than $100 billion to establish itself as the number two foundry, behind TSMC, by 2030.</p>

        

<p>The plans include fab expansions in Arizona, New Mexico, Oregon, and Ireland, plus new facilities in Ohio and Germany.</p>
<p>The decision to pause work on the Israeli fab – which was reportedly already under construction – comes roughly a year and a half after Intel <a target="_blank" href="https://www.theregister.com/2023/01/18/intel_israeli_research/">abandoned</a> its plans to build a luxury research and development complex in the Israeli city of Haifa.</p>
<p>The $200 million facility was slated to include creature comforts such as outdoor sports fields, green areas, pop-up restaurants, and even a rooftop health center and spa. However, the project was later reimagined as a parking lot, with the cash redirected to fuelling Intel's foundry push. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Engage your audience: get to the point, use story structure, force specificity (184 pts)]]></title>
            <link>https://iandanielstewart.com/2024/06/09/engage-your-audience-by-getting-to-the-point-using-story-structure-and-forcing-specificity/</link>
            <guid>40639628</guid>
            <pubDate>Mon, 10 Jun 2024 21:55:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iandanielstewart.com/2024/06/09/engage-your-audience-by-getting-to-the-point-using-story-structure-and-forcing-specificity/">https://iandanielstewart.com/2024/06/09/engage-your-audience-by-getting-to-the-point-using-story-structure-and-forcing-specificity/</a>, See on <a href="https://news.ycombinator.com/item?id=40639628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I came across this recent video from <a href="https://www.youtube.com/@VickyZhaoBEEAMP/videos">Vicky Zhao</a> last week and loved her brief summary of how she grew in her ability to clearly articulate ideas on the spot by getting to the point, using story structure from improv, and forcing specificty in sharp, boilerplate phrasing with clever mental models. Highly recommended watch.</p>



<figure><p><span><iframe loading="lazy" width="640" height="360" src="https://www.youtube.com/embed/vVvcK74h1Mg?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>



<p>I loved it so much, I took notes. I’m sharing those here but with some other related advice for writing, reading, thinking, and decision-making folded in.  I hope you’ll find it useful as you watch, or re-watch. </p>



<h2>Get to the point</h2>



<p>Vicky Zhao recommends following the framework of “the one thing you must know about this topic is …” when you start sharing an idea.</p>



<ul>
<li>Use your language to guide your thinking before you even have chance to ramble.</li>



<li>The easiest way to get to the point is to use the word “one.”</li>



<li>Start with, “the one thing you must know about this topic is …”</li>



<li>It doesn’t have to be a groundbreaking statement. The purpose is to provide clarity and direction for you and your audience.</li>



<li>As you continue, you’ll be able to refine the initial statement.</li>
</ul>



<p>This idea is a lot like a McKinsey- or BCG-style <a href="https://slideworks.io/resources/how-to-write-action-titles-like-mckinsey">Action Title for presentations in Slide Decks</a>. An action title is like the “So what?” statement for your slide that captures the singular point and key takeaway of what your slide is all about.</p>



<figure><table><thead><tr><th>Conventional title</th><th>Action title</th></tr></thead><tbody><tr><td>Survey results</td><td>Survey output indicates main root cause of churn is awareness of better value for money offering.</td></tr><tr><td>Monthly churn by customer tenure</td><td>Yearly renewal prompt found to be strong driver of churn</td></tr><tr><td>Overview of churn management initiatives</td><td>Based on current performance and required implementation efforts we have identified 11 initiatives to initiate in the short run</td></tr><tr><td>Sales in M USD and number of widgets sold</td><td>Widget market in US is estimated to be 907 mUSD with 5.1% growth p.a. but with DtC segment in decline</td></tr></tbody></table></figure>



<p>Providing this at the top of a slide — just like starting with “the one thing you must know about this topic is,” — frames the whole presentation you’re making, grabs your audience right away, and helps them evaluate and understand everything you’re going to say next.</p>



<p>Lately, I’ve been doing this even in my Slack communication, leading with <a href="https://www.rd.com/article/what-does-tldr-mean/">a tl;dr</a> or something like <a href="https://iandanielstewart.com/2024/04/28/dharmesh-shahs-communication-with-flashtags/">Dharmesh Shah’s communication with Flashtags</a> and then following with a short, bullet list expansion of the statement.</p>



<p>You can also follow this framework when it’s <em>you</em> who is the audience.</p>



<p>If you’re reading a non-fiction book, follow <a href="https://iandanielstewart.com/2010/09/20/ideas-on-how-to-read-a-book/">Mortimer Adler’s advice on <em>How to Read a Book</em></a>. Read the book backwards, read the index, and skim the whole book — before you even consider reading it. This lets you absorb the main thesis, the “one thing”, and better understand the arguments to follow.</p>



<h2>Add story structure</h2>



<p>Sharing ideas in the framework of a 3-line scene will help you think on your feet and get your point across.</p>



<p><strong>Line 1</strong></p>



<ul>
<li>The first line sets the scene and you already have this in place if you’re starting with “the one thing you must know about this topic is …”</li>



<li>This will put everyone on the edge of their seat eager to know more.</li>
</ul>



<p><strong>Line 2</strong></p>



<ul>
<li>The second line adds depth and you can add depth in two ways.</li>



<li>First, you can go deeper with statements like, “What I mean by X is …” and follow up with an explanation of your “one thing.”</li>



<li>Or you can add depth by introducing a surprise — something that people wouldn’t know by staying on the surface. Introduce a “BUT the surprising thing about X is …” statement that adds a surprising wrinkle to the “one thing.” This really puts people on the edge of their seat.</li>
</ul>



<p><strong>Line 3</strong></p>



<ul>
<li>The third line answers the question, “What’s next?” and you have two options for resolution here.</li>



<li>First, you can open the conversation with a Question, “And the question is X — discuss.” This will propel you into a discussion and contribution phase.</li>



<li>Or, you can close the conversation with an Answer by using the phrase, “And it’s because … X.”</li>
</ul>



<p>This 3-line scene framework of setting the stage, introducing a new wrinkle, and then swinging into a resolution phase follows the structure of all great storytelling. <a href="https://www.aerogrammestudio.com/2013/03/22/the-story-spine-pixars-4th-rule-of-storytelling/#google_vignette">The Story Spine</a> is a great example of what that looks like in a structure we’re all probably more familiar with.</p>



<blockquote>
<p>Once upon a time there was ______. Every day, ______. One day ______. Because of that, ______. Because of that, ______. Until finally ______.</p>
</blockquote>



<figure><a href="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?ssl=1"><img loading="lazy" decoding="async" width="640" height="800" data-attachment-id="11331" data-permalink="https://iandanielstewart.com/2024/06/09/engage-your-audience-by-getting-to-the-point-using-story-structure-and-forcing-specificity/image/" data-orig-file="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?fit=640%2C800&amp;ssl=1" data-orig-size="640,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?fit=240%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?fit=640%2C800&amp;ssl=1" src="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?resize=640%2C800&amp;ssl=1" alt="" srcset="https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?w=640&amp;ssl=1 640w, https://i0.wp.com/iandanielstewart.com/wp-content/uploads/2024/06/image.png?resize=240%2C300&amp;ssl=1 240w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></a><figcaption>The Story Spine with optional moral <a href="https://sketchplanations.com/the-story-spine">via Sketchplanations</a>.</figcaption></figure>



<p>You’ll find stories like that set up everywhere. <a href="https://bootcamp.uxdesign.cc/unlocking-emotion-and-engagement-storytelling-techniques-in-ux-design-855afb9cecdf">Even in UX Design</a>.</p>



<h2>Be specific</h2>



<p>Specificity forces articulate communicaiton.</p>



<ul>
<li>The advice above uses set phrases to introduce specificity like, “The one thing you need to know about this topic is …”, “What I mean by X is …”, “But the surprising thing about X is …”, “And the question is …”, “And it’s because … X.”</li>



<li>To practice being more specific use <a href="https://www.wealest.com/articles/via-negativa">Via Negativa</a>: talking about what something is not rather than what it is.</li>



<li>Sometimes it can be really difficult to articulate exactly what something is but it’s easier to say what it’s not.</li>



<li>When you’re on the spot and under pressure, using Via Negativa can really help you rethink what you’re trying to say, and focus in on the specific things people need to understand.</li>
</ul>



<p>This is also just great advice when you’re not on the spot and trying to check your own thinking. I’ll leave you with the advice of legendary investor <a href="https://en.wikipedia.org/wiki/Charlie_Munger">Charlie Munger</a> here in his famous speech at Harvard in 1986, <a href="https://www.alexanderjarvis.com/how-to-guarantee-a-life-of-misery-by-charlie-munger/">How to Guarantee a Life of Misery</a>, and expanded version of Johnny Carson’s similar speech to the Harvard Class, which itself is Via Negativa in action. His recommendation to always “invert” reminds me of it most though.</p>



<blockquote>
<p>What Carson did was to approach the study of how to create X by turning the question backward, that is, by studying how to create non-X. The great algebraist, Jacobi, had exactly the same approach as Carson and was known for his constant repetition of one phrase: “Invert, always invert.” It is in the nature of things, as Jacobi knew, that many hard problems are best solved only when they are addressed backward</p>
</blockquote>



<p>I’ve also heard this expressed as a way to get to decisions faster. When people can’t decide on a several options you can promote a “bad idea” and watch people start defining better ones in answer to it. Like suggesting McDonald’s as the choice when no one can decide on a restaurant. Suddenly, people can decide pretty quickly in the moment then. 🙂 </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private Cloud Compute: A new frontier for AI privacy in the cloud (553 pts)]]></title>
            <link>https://security.apple.com/blog/private-cloud-compute/</link>
            <guid>40639606</guid>
            <pubDate>Mon, 10 Jun 2024 21:53:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.apple.com/blog/private-cloud-compute/">https://security.apple.com/blog/private-cloud-compute/</a>, See on <a href="https://news.ycombinator.com/item?id=40639606">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Written by Apple Security Engineering and Architecture (SEAR), User Privacy, Core Operating Systems (Core OS), Services Engineering (ASE), and Machine Learning and AI (AIML)</p></div><article><div><p>Apple Intelligence is the personal intelligence system that brings powerful generative models to iPhone, iPad, and Mac. For advanced features that need to reason over complex data with <a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models">larger foundation models</a>, we created Private Cloud Compute (PCC), a groundbreaking cloud intelligence system designed specifically for private AI processing. For the first time ever, Private Cloud Compute extends the industry-leading security and privacy of Apple devices into the cloud, making sure that personal user data sent to PCC isn’t accessible to anyone other than the user — not even to Apple. Built with custom Apple silicon and a hardened operating system designed for privacy, we believe PCC is the most advanced security architecture ever deployed for cloud AI compute at scale.</p>
<hr>
<p>Apple has long championed on-device processing as the cornerstone for the security and privacy of user data. Data that exists only on user devices is by definition disaggregated and not subject to any centralized point of attack. When Apple is responsible for user data in the cloud, we protect it with state-of-the-art security in our services — and for the most sensitive data, we believe <a href="https://www.lawfaremedia.org/article/personal-data-in-the-cloud-is-under-siege.-end-to-end-encryption-is-our-most-powerful-defense">end-to-end encryption is our most powerful defense</a>. For cloud services where end-to-end encryption is not appropriate, we strive to process user data ephemerally or under uncorrelated randomized identifiers that obscure the user’s identity.</p>
<p>Secure and private AI processing in the cloud poses a formidable new challenge. Powerful AI hardware in the data center can fulfill a user’s request with large, complex machine learning models — but it requires unencrypted access to the user's request and accompanying personal data. That precludes the use of end-to-end encryption, so cloud AI applications have to date employed traditional approaches to cloud security. Such approaches present a few key challenges:</p>
<ul>
<li><strong>Cloud AI security and privacy guarantees are difficult to verify and enforce.</strong> If a cloud AI service states that it does not log certain user data, there is generally no way for security researchers to verify this promise — and often no way for the service provider to durably enforce it. For example, a new version of the AI service may introduce additional routine logging that inadvertently logs sensitive user data without any way for a researcher to detect this. Similarly, a perimeter load balancer that terminates TLS may end up logging thousands of user requests wholesale during a troubleshooting session.</li>
<li><strong>It’s difficult to provide runtime transparency for AI in the cloud.</strong> Cloud AI services are opaque: providers do not typically specify details of the software stack they are using to run their services, and those details are often considered proprietary. Even if a cloud AI service relied only on open source software, which is inspectable by security researchers, there is no widely deployed way for a user device (or browser) to confirm that the service it’s connecting to is running an unmodified version of the software that it purports to run, or to detect that the software running on the service has changed.</li>
<li><strong>It’s challenging for cloud AI environments to enforce strong limits to privileged access.</strong> Cloud AI services are complex and expensive to run at scale, and their runtime performance and other operational metrics are constantly monitored and investigated by site reliability engineers and other administrative staff at the cloud service provider. During outages and other severe incidents, these administrators can generally make use of highly privileged access to the service, such as via SSH and equivalent remote shell interfaces. Though access controls for these privileged, break-glass interfaces may be well-designed, it’s exceptionally difficult to place enforceable limits on them while they’re in active use. For example, a service administrator who is trying to back up data from a live server during an outage could inadvertently copy sensitive user data in the process. More perniciously, criminals such as ransomware operators routinely strive to compromise service administrator credentials precisely to take advantage of privileged access interfaces and make away with user data.</li>
</ul>
<p>When on-device computation with Apple devices such as iPhone and Mac is possible, the security and privacy advantages are clear: users control their own devices, researchers can inspect both hardware and software, runtime transparency is cryptographically assured through Secure Boot, and Apple retains no privileged access (as a concrete example, the <a href="https://support.apple.com/guide/security/data-protection-overview-secf6276da8a/web">Data Protection</a> file encryption system cryptographically prevents Apple from disabling or guessing the passcode of a given iPhone).</p>
<p>However, to process more sophisticated requests, Apple Intelligence needs to be able to enlist help from larger, more complex models in the cloud. For these cloud requests to live up to the security and privacy guarantees that our users expect from our devices, the traditional cloud service security model isn't a viable starting point. Instead, we need to bring our industry-leading device security model, for the first time ever, to the cloud.</p>
<p>The rest of this post is an initial technical overview of Private Cloud Compute, to be followed by a deep dive after PCC becomes available in beta. We know researchers will have many detailed questions, and we look forward to answering more of them in our follow-up post.</p>
<h3>Designing Private Cloud Compute</h3>
<p>We set out to build Private Cloud Compute with a set of core requirements:</p>
<ol>
<li><strong>Stateless computation on personal user data.</strong> Private Cloud Compute must use the personal user data that it receives exclusively for the purpose of fulfilling the user’s request. This data must never be available to anyone other than the user, not even to Apple staff, not even during active processing. And this data must not be retained, including via logging or for debugging, after the response is returned to the user. In other words, we want a strong form of stateless data processing where personal data leaves no trace in the PCC system.</li>
<li><strong>Enforceable guarantees.</strong> Security and privacy guarantees are strongest when they are entirely technically enforceable, which means it must be possible to constrain and analyze all the components that critically contribute to the guarantees of the overall Private Cloud Compute system. To use our example from earlier, it’s very difficult to reason about what a TLS-terminating load balancer may do with user data during a debugging session. Therefore, PCC must not depend on such external components for its core security and privacy guarantees. Similarly, operational requirements such as collecting server metrics and error logs must be supported with mechanisms that do not undermine privacy protections.</li>
<li><strong>No privileged runtime access.</strong> Private Cloud Compute must not contain privileged interfaces that would enable Apple’s site reliability staff to bypass PCC privacy guarantees, even when working to resolve an outage or other severe incident. This also means that PCC must not support a mechanism by which the privileged access envelope could be enlarged at runtime, such as by loading additional software.</li>
<li><strong>Non-targetability.</strong> An attacker should not be able to attempt to compromise personal data that belongs to specific, targeted Private Cloud Compute users without attempting a broad compromise of the entire PCC system. This must hold true even for exceptionally sophisticated attackers who can attempt physical attacks on PCC nodes in the supply chain or attempt to obtain malicious access to PCC data centers. In other words, a limited PCC compromise must not allow the attacker to steer requests from specific users to compromised nodes; targeting users should require a wide attack that’s likely to be detected. To understand this more intuitively, contrast it with a traditional cloud service design where every application server is provisioned with database credentials for the entire application database, so a compromise of a single application server is sufficient to access any user’s data, even if that user doesn’t have any active sessions with the compromised application server.</li>
<li><strong>Verifiable transparency.</strong> Security researchers need to be able to verify, with a high degree of confidence, that our privacy and security guarantees for Private Cloud Compute match our public promises. We already have an earlier requirement for our guarantees to be enforceable. Hypothetically, then, if security researchers had sufficient access to the system, they would be able to verify the guarantees. But this last requirement, verifiable transparency, goes one step further and does away with the hypothetical: security researchers <em>must be able to verify</em> the security and privacy guarantees of Private Cloud Compute, and they <em>must be able to verify</em> that the software that’s running in the PCC production environment is the same as the software they inspected when verifying the guarantees.</li>
</ol>
<p>This is an extraordinary set of requirements, and one that we believe represents a generational leap over any traditional cloud service security model.</p>
<h3>Introducing Private Cloud Compute nodes</h3>
<p>The root of trust for Private Cloud Compute is our compute node: custom-built server hardware that brings the power and security of Apple silicon to the data center, with the same hardware security technologies used in iPhone, including the <a href="https://support.apple.com/guide/security/secure-enclave-sec59b0b31ff/web">Secure Enclave</a> and <a href="https://support.apple.com/guide/security/boot-process-for-iphone-and-ipad-devices-secb3000f149/web">Secure Boot</a>. We paired this hardware with a new operating system: a hardened subset of the foundations of iOS and macOS tailored to support Large Language Model (LLM) inference workloads while presenting an extremely narrow attack surface. This allows us to take advantage of iOS security technologies such as <a href="https://support.apple.com/guide/security/app-code-signing-process-sec7c917bf14/web">Code Signing</a> and <a href="https://support.apple.com/guide/security/security-of-runtime-process-sec15bfe098e/web">sandboxing</a>.</p>
<p>On top of this foundation, we built a custom set of cloud extensions with privacy in mind. We excluded components that are traditionally critical to data center administration, such as remote shells and system introspection and observability tools. We replaced those general-purpose software components with components that are purpose-built to deterministically provide only a small, restricted set of operational metrics to SRE staff. And finally, we used <a href="https://www.swift.org/documentation/server/">Swift on Server</a> to build a new Machine Learning stack specifically for hosting <a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models">our cloud-based foundation model</a>.</p>
<p>Let’s take another look at our core Private Cloud Compute requirements and the features we built to achieve them.</p>
<h4>Stateless computation and enforceable guarantees</h4>
<p>With services that are end-to-end encrypted, such as iMessage, the service operator cannot access the data that transits through the system. One of the key reasons such designs can assure privacy is specifically because they prevent the service from performing computations on user data. Since Private Cloud Compute needs to be able to access the data in the user’s request to allow a large foundation model to fulfill it, complete end-to-end encryption is not an option. Instead, the PCC compute node must have technical enforcement for the privacy of user data during processing, and must be incapable of retaining user data after its duty cycle is complete.</p>
<p>We designed Private Cloud Compute to make several guarantees about the way it handles user data:</p>
<ul>
<li>A user’s device sends data to PCC for the sole, exclusive purpose of fulfilling the user’s inference request. PCC uses that data only to perform the operations requested by the user.</li>
<li>User data stays on the PCC nodes that are processing the request only until the response is returned. PCC deletes the user’s data after fulfilling the request, and no user data is retained in any form after the response is returned.</li>
<li>User data is never available to Apple — even to staff with administrative access to the production service or hardware.</li>
</ul>
<p>When Apple Intelligence needs to draw on Private Cloud Compute, it constructs a request — consisting of the prompt, plus the desired model and inferencing parameters — that will serve as input to the cloud model. The PCC client on the user’s device then encrypts this request directly to the public keys of the PCC nodes that it has first confirmed are valid and cryptographically certified. This provides end-to-end encryption from the user’s device to the validated PCC nodes, ensuring the request cannot be accessed in transit by anything outside those highly protected PCC nodes. Supporting data center services, such as load balancers and privacy gateways, run outside of this trust boundary and do not have the keys required to decrypt the user’s request, thus contributing to our enforceable guarantees.</p>
<p>Next, we must protect the integrity of the PCC node and prevent any tampering with the keys used by PCC to decrypt user requests. The system uses Secure Boot and Code Signing for an enforceable guarantee that only authorized and cryptographically measured code is executable on the node. All code that can run on the node must be part of a trust cache that has been signed by Apple, approved for that specific PCC node, and loaded by the Secure Enclave such that it cannot be changed or amended at runtime. This also ensures that JIT mappings cannot be created, preventing compilation or injection of new code at runtime. Additionally, all code and model assets use the same integrity protection that powers the <a href="https://support.apple.com/guide/security/signed-system-volume-security-secd698747c9/web">Signed System Volume</a>. Finally, the Secure Enclave provides an enforceable guarantee that the keys that are used to decrypt requests cannot be duplicated or extracted.</p>
<p>The Private Cloud Compute software stack is designed to ensure that user data is not leaked outside the trust boundary or retained once a request is complete, even in the presence of implementation errors.  The Secure Enclave randomizes the data volume’s encryption keys on every reboot and <em>does not persist these random keys</em>, ensuring that data written to the data volume cannot be retained across reboot. In other words, there is an enforceable guarantee that the data volume is cryptographically erased every time the PCC node’s Secure Enclave Processor reboots. The inference process on the PCC node deletes data associated with a request upon completion, and the address spaces that are used to handle user data are periodically recycled to limit the impact of any data that may have been unexpectedly retained in memory.</p>
<p>Finally, for our enforceable guarantees to be meaningful, we also need to protect against exploitation that could bypass these guarantees. Technologies such as <a href="https://support.apple.com/guide/security/operating-system-integrity-sec8b776536b/1/web/1#sec0167b469d">Pointer Authentication Codes</a> and <a href="https://support.apple.com/guide/security/security-of-runtime-process-sec15bfe098e/1/web/1">sandboxing</a> act to resist such exploitation and limit an attacker’s horizontal movement within the PCC node. The inference control and dispatch layers are written in Swift, ensuring memory safety, and use separate address spaces to isolate initial processing of requests. This combination of memory safety and the principle of least privilege removes entire classes of attacks on the inference stack itself and limits the level of control and capability that a successful attack can obtain.</p>
<h4>No privileged runtime access</h4>
<p>We designed Private Cloud Compute to ensure that privileged access doesn’t allow anyone to bypass our stateless computation guarantees.</p>
<p>First, we intentionally did not include remote shell or interactive debugging mechanisms on the PCC node. Our Code Signing machinery prevents such mechanisms from loading additional code, but this sort of open-ended access would provide a broad attack surface to subvert the system’s security or privacy. Beyond simply not including a shell, remote or otherwise, PCC nodes cannot enable Developer Mode and do not include the tools needed by debugging workflows.</p>
<p>Next, we built the system’s observability and management tooling with privacy safeguards that are designed to prevent user data from being exposed. For example, the system doesn’t even include a general-purpose logging mechanism. Instead, only pre-specified, structured, and audited logs and metrics can leave the node, and multiple independent layers of review help prevent user data from accidentally being exposed through these mechanisms. With traditional cloud AI services, such mechanisms might allow someone with privileged access to observe or collect user data.</p>
<p>Together, these techniques provide enforceable guarantees that only specifically designated code has access to user data and that user data cannot leak outside the PCC node during system administration.</p>
<h4>Non-targetability</h4>
<p>Our threat model for Private Cloud Compute includes an attacker with physical access to a compute node and a high level of sophistication — that is, an attacker who has the resources and expertise to subvert some of the hardware security properties of the system and potentially extract data that is being actively processed by a compute node.</p>
<p>We defend against this type of attack in two ways:</p>
<ol>
<li>We supplement the built-in protections of Apple silicon with a hardened supply chain for PCC hardware, so that performing a hardware attack at scale would be both prohibitively expensive and likely to be discovered.</li>
<li>We limit the impact of small-scale attacks by ensuring that they cannot be used to target the data of a specific user.</li>
</ol>
<p>Private Cloud Compute hardware security starts at manufacturing, where we inventory and perform high-resolution imaging of the components of the PCC node before each server is sealed and its tamper switch is activated. When they arrive in the data center, we perform extensive revalidation before the servers are allowed to be provisioned for PCC. The process involves multiple Apple teams that cross-check data from independent sources, and the process is further monitored by a third-party observer not affiliated with Apple. At the end, a certificate is issued for keys rooted in the <a href="https://support.apple.com/guide/security/secure-enclave-sec59b0b31ff/web#sec293d3d1f5">Secure Enclave UID</a> for each PCC node. The user’s device will not send data to any PCC nodes if it cannot validate their certificates.</p>
<p>These processes broadly protect hardware from compromise. To guard against smaller, more sophisticated attacks that might otherwise avoid detection, Private Cloud Compute uses an approach we call <em>target diffusion</em> to ensure requests cannot be routed to specific nodes based on the user or their content.</p>
<p>Target diffusion starts with the request metadata, which leaves out any personally identifiable information about the source device or user, and includes only limited contextual data about the request that’s required to enable routing to the appropriate model. This metadata is the only part of the user’s request that is available to load balancers and other data center components running outside of the PCC trust boundary. The metadata also includes a single-use credential, based on <a href="https://www.rfc-editor.org/rfc/rfc9474.html">RSA Blind Signatures</a>, to authorize valid requests without tying them to a specific user. Additionally, PCC requests go through an <a href="https://www.rfc-editor.org/rfc/rfc9458">OHTTP relay</a> — operated by a third party — which hides the device’s source IP address before the request ever reaches the PCC infrastructure. This prevents an attacker from using an IP address to identify requests or associate them with an individual. It also means that an attacker would have to compromise both the third-party relay and our load balancer to steer traffic based on the source IP address.</p>
<p>User devices encrypt requests only for a subset of PCC nodes, rather than the PCC service as a whole. When asked by a user device, the load balancer returns a subset of PCC nodes that are most likely to be ready to process the user’s inference request — however, as the load balancer has no identifying information about the user or device for which it’s choosing nodes, it cannot bias the set for targeted users. By limiting the PCC nodes that can decrypt each request in this way, we ensure that if a single node were ever to be compromised, it would not be able to decrypt more than a small portion of incoming requests. Finally, the selection of PCC nodes by the load balancer is statistically auditable to protect against a highly sophisticated attack where the attacker compromises a PCC node as well as obtains complete control of the PCC load balancer.</p>
<h4>Verifiable transparency</h4>
<p>We consider allowing security researchers to verify the end-to-end security and privacy guarantees of Private Cloud Compute to be a critical requirement for ongoing public trust in the system. Traditional cloud services do not make their full production software images available to researchers — and even if they did, there’s no general mechanism to allow researchers to verify that those software images match what’s actually running in the production environment. (Some specialized mechanisms exist, such as Intel SGX and AWS Nitro attestation.)</p>
<p>When we launch Private Cloud Compute, we’ll take the extraordinary step of making software images of <strong>every production build of PCC publicly available for security research</strong>. This promise, too, is an enforceable guarantee: user devices will be willing to send data only to PCC nodes that can cryptographically attest to running publicly listed software. We want to ensure that security and privacy researchers can inspect Private Cloud Compute software, verify its functionality, and help identify issues — just like they can with Apple devices.</p>
<p>Our commitment to verifiable transparency includes:</p>
<ol>
<li>Publishing the measurements of all code running on PCC in an append-only and cryptographically tamper-proof transparency log.</li>
<li>Making the log and associated binary software images publicly available for inspection and validation by privacy and security experts.</li>
<li>Publishing and maintaining an official set of tools for researchers analyzing PCC node software.</li>
<li>Rewarding important research findings through the <a href="https://security.apple.com/bounty/">Apple Security Bounty</a> program.</li>
</ol>
<p>Every production Private Cloud Compute software image will be published for independent binary inspection — including the OS, applications, and all relevant executables, which researchers can verify against the measurements in the transparency log. Software will be published within 90 days of inclusion in the log, or after relevant software updates are available, whichever is sooner. Once a release has been signed into the log, it cannot be removed without detection, much like the log-backed map data structure used by the Key Transparency mechanism for <a href="https://security.apple.com/blog/imessage-contact-key-verification/">iMessage Contact Key Verification</a>.</p>
<p>As we mentioned, user devices will ensure that they’re communicating only with PCC nodes running authorized and verifiable software images. Specifically, the user’s device will wrap its request payload key only to the public keys of those PCC nodes whose attested measurements match a software release in the public transparency log. And the same strict Code Signing technologies that prevent loading unauthorized software also ensure that all code on the PCC node is included in the attestation.</p>
<p>Making Private Cloud Compute software logged and inspectable in this way is a strong demonstration of our commitment to enable independent research on the platform. But we want to ensure researchers can rapidly get up to speed, verify our PCC privacy claims, and look for issues, so we’re going further with three specific steps:</p>
<ul>
<li>We’ll release a PCC Virtual Research Environment: a set of tools and images that simulate a PCC node on a Mac with Apple silicon, and that can boot a version of PCC software minimally modified for successful virtualization.</li>
<li>While we’re publishing the binary images of every production PCC build, to further aid research we will periodically also publish a subset of the security-critical PCC source code.</li>
<li>In a first for any Apple platform, PCC images will include the sepOS firmware and the iBoot bootloader <em>in plaintext</em>, making it easier than ever for researchers to study these critical components.</li>
</ul>
<p>The Apple Security Bounty will reward research findings in the entire Private Cloud Compute software stack — with especially significant payouts for any issues that undermine our privacy claims.</p>
<h3>More to come</h3>
<p>Private Cloud Compute continues Apple’s profound commitment to user privacy. With sophisticated technologies to satisfy our requirements of stateless computation, enforceable guarantees, no privileged access, non-targetability, and verifiable transparency, we believe Private Cloud Compute is nothing short of the world-leading security architecture for cloud AI compute at scale.</p>
<p>We look forward to sharing many more technical details about PCC, including the implementation and behavior behind each of our core requirements. And we’re especially excited to soon invite security researchers for a first look at the Private Cloud Compute software and our PCC Virtual Research Environment.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple's On-Device and Server Foundation Models (823 pts)]]></title>
            <link>https://machinelearning.apple.com/research/introducing-apple-foundation-models</link>
            <guid>40639506</guid>
            <pubDate>Mon, 10 Jun 2024 21:42:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models">https://machinelearning.apple.com/research/introducing-apple-foundation-models</a>, See on <a href="https://news.ycombinator.com/item?id=40639506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main"><div><p>At the 2024 <a href="https://developer.apple.com/wwdc24/">Worldwide Developers Conference</a>, we introduced Apple Intelligence, a personal intelligence system integrated deeply into iOS&nbsp;18, iPadOS&nbsp;18, and macOS&nbsp;Sequoia.</p>
<p>Apple Intelligence is comprised of multiple highly-capable generative models that are specialized for our users’ everyday tasks, and can adapt on the fly for their current activity. The foundation models built into Apple Intelligence have been fine-tuned for user experiences such as writing and refining text, prioritizing and summarizing notifications, creating playful images for conversations with family and friends, and taking in-app actions to simplify interactions across apps.</p>
<p>In the following overview, we will detail how two of these models — a ~3 billion parameter on-device language model, and a larger server-based language model available with <a href="https://security.apple.com/blog/private-cloud-compute/">Private Cloud Compute</a> and running on Apple silicon servers — have been built and adapted to perform specialized tasks efficiently, accurately, and responsibly. These two foundation models are part of a larger family of generative models created by Apple to support users and developers; this includes a coding model to build intelligence into Xcode, as well as a diffusion model to help users express themselves visually, for example, in the Messages app. We look forward to sharing more information soon on this broader set of models.</p>
<h2>Our Focus on Responsible AI Development</h2>
<p>Apple Intelligence is designed with our core values at every step and built on a foundation of groundbreaking privacy innovations.</p>
<p>Additionally, we have created a set of Responsible AI principles to guide how we develop AI tools, as well as the models that underpin them:</p>
<ol>
<li><span>Empower users with intelligent tools</span>: We identify areas where AI can be used responsibly to create tools for addressing specific user needs. We respect how our users choose to use these tools to accomplish their goals.</li>
<li><span>Represent our users</span>: We build deeply personal products with the goal of representing users around the globe authentically. We work continuously to avoid perpetuating stereotypes and systemic biases across our AI tools and models.</li>
<li><span>Design with care</span>: We take precautions at every stage of our process, including design, model training, feature development, and quality evaluation to identify how our AI tools may be misused or lead to potential harm. We will continuously and proactively improve our AI tools with the help of user feedback.</li>
<li><span>Protect privacy</span>: We protect our users' privacy with powerful on-device processing and groundbreaking infrastructure like Private Cloud Compute. We do not use our users' private personal data or user interactions when training our foundation models.</li>
</ol>
<p>These principles are reflected throughout the architecture that enables Apple Intelligence, connects features and tools with specialized models, and scans inputs and outputs to provide each feature with the information needed to function responsibly.</p>
<p>In the remainder of this overview, we provide details on decisions such as: how we develop models that are highly capable, fast, and power-efficient; how we approach training these models; how our adapters are fine-tuned for specific user needs; and how we evaluate model performance for both helpfulness and unintended harm.</p>
<figure id="figure1" aria-labelledby="figure-figure1-caption" data-aos="fade-up"><p><a href="https://mlr.cdn-apple.com/media/Fig1_Responsible_AI_8bf7727ab5.png" aria-label="Modeling overview" tabindex="-1" target="_blank"><img src="https://mlr.cdn-apple.com/media/Fig1_Responsible_AI_8bf7727ab5.png" alt="Modeling overview" loading="lazy"></a></p><figcaption id="figure-figure1-caption" aria-hidden="false">Figure 1: Modeling overview for the Apple foundation models.</figcaption></figure>
<h2>Pre-Training</h2>
<p>Our foundation models are trained on <a href="https://github.com/apple/axlearn" target="_blank" aria-label="Apple's AXLearn framework - Opens in a new window" rel="noopener nofollow">Apple's AXLearn framework</a>, an open-source project we released in 2023. It builds on top of JAX and XLA, and allows us to train the models with high efficiency and scalability on various training hardware and cloud platforms, including TPUs and both cloud and on-premise GPUs. We used a combination of data parallelism, tensor parallelism, sequence parallelism, and Fully Sharded Data Parallel (FSDP) to scale training along multiple dimensions such as data, model, and sequence length.</p>
<p>We train our foundation models on licensed data, including data selected to enhance specific features, as well as publicly available data collected by our web-crawler, AppleBot. Web publishers have <a href="https://support.apple.com/en-us/119829">the option to opt out</a> of the use of their web content for Apple Intelligence training with a data usage control.</p>
<p>We never use our users’ private personal data or user interactions when training our foundation models, and we apply filters to remove personally identifiable information like social security and credit card numbers that are publicly available on the Internet. We also filter profanity and other low-quality content to prevent its inclusion in the training corpus. In addition to filtering, we perform data extraction, deduplication, and the application of a model-based classifier to identify high quality documents.</p>
<h2>Post-Training</h2>
<p>We find that data quality is essential to model success, so we utilize a hybrid data strategy in our training pipeline, incorporating both human-annotated and synthetic data, and conduct thorough data curation and filtering procedures. We have developed two novel algorithms in post-training: (1) a rejection sampling fine-tuning algorithm with teacher committee, and (2) a reinforcement learning from human feedback (RLHF) algorithm with mirror descent policy optimization and a leave-one-out advantage estimator. We find that these two algorithms lead to significant improvement in the model’s instruction-following quality.</p>
<h2>Optimization</h2>
<p>In addition to ensuring our generative models are highly capable, we have used a range of innovative techniques to optimize them on-device and on our private cloud for speed and efficiency. We have applied an extensive set of optimizations for both first token and extended token inference performance.</p>
<p>Both the on-device and server models use grouped-query-attention. We use shared input and output vocab embedding tables to reduce memory requirements and inference cost. These shared embedding tensors are mapped without duplications. The on-device model uses a vocab size of 49K, while the server model uses a vocab size of 100K, which includes additional language and technical tokens.</p>
<p>For on-device inference, we use low-bit palletization, a critical optimization technique that achieves the necessary memory, power, and performance requirements. To maintain model quality, we developed a new framework using LoRA adapters that incorporates a mixed 2-bit and 4-bit configuration strategy — averaging 3.5 bits-per-weight — to achieve the same accuracy as the uncompressed models.</p>
<p>Additionally, we use an interactive model latency and power analysis tool, <a href="https://machinelearning.apple.com/research/talaria">Talaria</a>, to better guide the bit rate selection for each operation. We also utilize activation quantization and embedding quantization, and have developed an approach to enable efficient Key-Value (KV) cache update on our neural engines.</p>
<p>With this set of optimizations, on iPhone 15 Pro we are able to reach time-to-first-token latency of about 0.6 millisecond per prompt token, and a generation rate of 30 tokens per second. Notably, this performance is attained before employing token speculation techniques, from which we see further enhancement on the token generation rate.</p>
<h2>Model Adaptation</h2>
<p>Our foundation models are fine-tuned for users’ everyday activities, and can dynamically specialize themselves on-the-fly for the task at hand. We utilize adapters, small neural network modules that can be plugged into various layers of the pre-trained model, to fine-tune our models for specific tasks. For our models we adapt the attention matrices, the attention projection matrix, and the fully connected layers in the point-wise feedforward networks for a suitable set of the decoding layers of the transformer architecture.</p>
<p>By fine-tuning only the adapter layers, the original parameters of the base pre-trained model remain unchanged, preserving the general knowledge of the model while tailoring the adapter layers to support specific tasks.</p>
<figure id="figure2" aria-labelledby="figure-figure2-caption" data-aos="fade-up"><figcaption id="figure-figure2-caption" aria-hidden="false">Figure 2: Adapters are small collections of model weights that are overlaid onto the common base foundation model. They can be dynamically loaded and swapped — giving the foundation model the ability to specialize itself on-the-fly for the task at hand. Apple Intelligence includes a broad set of adapters, each fine-tuned for a specific feature. It’s an efficient way to scale the capabilities of our foundation model.</figcaption></figure>
<p>We represent the values of the adapter parameters using 16 bits, and for the ~3 billion parameter on-device model, the parameters for a rank 16 adapter typically require 10s of megabytes. The adapter models can be dynamically loaded, temporarily cached in memory, and swapped — giving our foundation model the ability to specialize itself on the fly for the task at hand while efficiently managing memory and guaranteeing the operating system's responsiveness.</p>
<p>To facilitate the training of the adapters, we created an efficient infrastructure that allows us to rapidly retrain, test, and deploy adapters when either the base model or the training data gets updated. The adapter parameters are initialized using&nbsp;the accuracy-recovery adapter introduced in the Optimization section.</p>
<h2>Performance and Evaluation</h2>
<p>Our focus is on delivering generative models that can enable users to communicate, work, express themselves, and get things done across their Apple products. When benchmarking our models, we focus on human evaluation as we find that these results are highly correlated to user experience in our products. We conducted performance evaluations on both feature-specific adapters and the foundation models.</p>
<p>To illustrate our approach, we look at how we evaluated our adapter for summarization. As product requirements for summaries of emails and notifications differ in subtle but important ways, we fine-tune accuracy-recovery low-rank (LoRA) adapters on top of the palletized model to meet these specific requirements. Our training data is based on synthetic summaries generated from bigger server models, filtered by a rejection sampling strategy that keeps only the high quality summaries.</p>
<p>To evaluate the product-specific summarization, we use a set of 750 responses carefully sampled for each use case. These evaluation datasets emphasize a diverse set of inputs that our product features are likely to face in production, and include a stratified mixture of single and stacked documents of varying content types and lengths. As product features, it was important to evaluate performance against datasets that are representative of real use cases. We find that our models with adapters generate better summaries than a comparable model.</p>
<p>As part of responsible development, we identified and evaluated specific risks inherent to summarization. For example, summaries occasionally remove important nuance or other details in ways that are undesirable. However, we found that the summarization adapter did not amplify sensitive content in over 99% of targeted adversarial examples. We continue to adversarially probe to identify unknown harms and expand our evaluations to help guide further improvements.</p>
<figure id="figure3" aria-labelledby="figure-figure3-caption" data-aos="fade-up"><figcaption id="figure-figure3-caption" aria-hidden="false">Figure 3: Ratio of "good" and "poor" responses for two summarization use cases relative to all responses. Summaries are classified as "good", "neutral", "poor" given the grader's scores across five dimensions. A result is classified as "good" if all of the dimensions are good (higher is better). A result is classified as "poor" if any of the dimensions are poor (lower is better). Our models with adapters generate better summaries than a comparable model.</figcaption></figure>
<p>In addition to evaluating feature specific performance powered by foundation models and adapters, we evaluate both the on-device and server-based models’ general capabilities. We utilize a comprehensive evaluation set of real-world prompts to test the general model capabilities. These prompts are diverse across different difficulty levels and cover major categories such as brainstorming, classification, closed question answering, coding, extraction, mathematical reasoning, open question answering, rewriting, safety, summarization, and writing.</p>
<p>We compare our models with both open-source models (Phi-3, Gemma, Mistral, DBRX) and commercial models of comparable size (GPT-3.5-Turbo, GPT-4-Turbo)<sup><a href="#footnotes">1</a></sup>. We find that our models are preferred by human graders over most comparable competitor models. On this benchmark, our on-device model, with ~3B parameters, outperforms larger models including Phi-3-mini, Mistral-7B, and Gemma-7B. Our server model compares favorably to DBRX-Instruct, Mixtral-8x22B, and GPT-3.5-Turbo while being highly efficient.</p>
<figure id="figure4" aria-labelledby="figure-figure4-caption" data-aos="fade-up"><figcaption id="figure-figure4-caption" aria-hidden="false">Figure 4: Fraction of preferred responses in side-by-side evaluation of Apple's foundation model against comparable models. We find that our models are preferred by human graders.</figcaption></figure>
<p>We use a set of diverse adversarial prompts to test the model performance on harmful content, sensitive topics, and factuality. We measure the violation rates of each model as evaluated by human graders on this evaluation set, with a lower number being desirable. Both the on-device and server models are robust when faced with adversarial prompts, achieving violation rates lower than open-source and commercial models.</p>
<figure id="figure5" aria-labelledby="figure-figure5-caption" data-aos="fade-up"><figcaption id="figure-figure5-caption" aria-hidden="false">Figure 5: Fraction of violating responses for harmful content, sensitive topics, and factuality (lower is better). Our models are robust when faced with adversarial prompts.</figcaption></figure>
<p>Our models are preferred by human graders as safe and helpful over competitor models for these prompts. However, considering the broad capabilities of large language models, we understand the limitation of our safety benchmark. We are actively conducting both manual and automatic red-teaming with internal and external teams to continue evaluating our models' safety.</p>
<figure id="figure6" aria-labelledby="figure-figure6-caption" data-aos="fade-up"><figcaption id="figure-figure6-caption" aria-hidden="false">Figure 6: Fraction of preferred responses in side-by-side evaluation of Apple's foundation model against comparable models on safety prompts. Human graders found our responses safer and more helpful.</figcaption></figure>
<p>To further evaluate our models, we use the Instruction-Following Eval (IFEval) benchmark to compare their instruction-following capabilities with models of comparable size. The results suggest that both our on-device and server model follow detailed instructions better than the open-source and commercial models of comparable size.</p>
<figure id="figure7" aria-labelledby="figure-figure7-caption" data-aos="fade-up"><figcaption id="figure-figure7-caption" aria-hidden="false">Figure 7: Instruction-following capability (measured with IFEval) for Apple's foundation models and models of comparable size (higher is better).</figcaption></figure>
<p>We evaluate our models’ writing ability on our internal summarization and composition benchmarks, consisting of a variety of writing instructions. These results do not refer to our feature-specific adapter for summarization (seen in <a href="#figure3">Figure 3</a>), nor do we have an adapter focused on composition.</p>
<figure id="figure8" aria-labelledby="figure-figure8-caption" data-aos="fade-up"><figcaption id="figure-figure8-caption" aria-hidden="false">Figure 8: Writing ability on internal summarization and composition benchmarks (higher is better).</figcaption></figure>
<h2>Conclusion</h2>
<p>The Apple foundation models and adapters introduced at WWDC24 underlie Apple Intelligence, the new personal intelligence system that is integrated deeply into iPhone, iPad, and Mac, and enables powerful capabilities across language, images, actions, and personal context. Our models have been created with the purpose of helping users do everyday activities across their Apple products, and developed responsibly at every stage and guided by Apple’s core values. We look forward to sharing more information soon on our broader family of generative models, including language, diffusion, and coding models.</p>

<p>[1]   We compared against the following model versions: gpt-3.5-turbo-0125, gpt-4-0125-preview, Phi-3-mini-4k-instruct, Mistral-7B-Instruct-v0.2, Mixtral-8x22B-Instruct-v0.1, Gemma-1.1-2B, and Gemma-1.1-7B. The open-source and Apple models are evaluated in bfloat16 precision.</p></div><section><p><h2>Related readings and updates.</h2></p><div><div><p>A voice replicator is a powerful tool for people at risk of losing their ability to speak, including those with a recent diagnosis of amyotrophic lateral sclerosis (ALS) or other conditions that can progressively impact speaking ability. First introduced in May 2023 and made available on iOS&nbsp;17 in September 2023, <a href="https://support.apple.com/en-us/104993">Personal Voice</a> is a tool that creates a synthesized voice for such users to speak in FaceTime, phone calls, assistive communication apps, and in-person conversations.</p><p><a href="https://machinelearning.apple.com/research/personal-voice" aria-label="See full highlight details regarding Advancing Speech Accessibility with Personal Voice">See highlight details</a></p></div><div><div><p>Earlier this year, Apple hosted the Natural Language Understanding workshop. This two-day hybrid event brought together Apple and members of the academic research community for talks and discussions on the state of the art in natural language understanding.</p>
<p>In this post, we share highlights from workshop discussions and recordings of select workshop talks.</p></div><p><a href="https://machinelearning.apple.com/updates/nlu-workshop-2023" aria-label="See full event details regarding Apple Natural Language Understanding Workshop 2023">See event details</a></p></div></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New GitHub Organization for the Swift Project (152 pts)]]></title>
            <link>https://www.swift.org/blog/swiftlang-github/</link>
            <guid>40639137</guid>
            <pubDate>Mon, 10 Jun 2024 21:10:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swift.org/blog/swiftlang-github/">https://www.swift.org/blog/swiftlang-github/</a>, See on <a href="https://news.ycombinator.com/item?id=40639137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
<article>
  <header>
    

    <time pubdate="" datetime="2024-06-10T06:00:00-04:00">June 10, 2024</time>
    
  </header>

  <p>Today, we are announcing an exciting development for the Swift programming language: its migration to a dedicated GitHub organization at <a href="http://github.com/swiftlang">GitHub.com/swiftlang</a>.</p>

<p>This migration reflects the growth and maturity of the Swift community and highlights Swift’s versatility beyond Apple’s own ecosystems. Over the last decade, many inspiring individuals’ hard and creative work has elevated Swift into various creative and practical applications. With a GitHub organization dedicated to Swift, we are creating an even more conducive environment for collaboration and innovation. This change will allow Swift to expand its reach to more platforms and use cases, sparking fresh possibilities and broadening Swift’s impact across the technology landscape.</p>

<h2 id="timeline-and-initial-scope">Timeline and Initial Scope <a title="Permalink for Timeline and Initial Scope section" href="#timeline-and-initial-scope">
            <!--?xml version="1.0" encoding="utf-8"?--> 
          </a></h2>

<p>The migration to the <code>swiftlang</code> organization will be phased over the coming weeks and months, striking a balance between minimizing disruption and ensuring a deliberate completion. Initially, the <code>swiftlang</code> organization will include foundational elements of the Swift project, such as:</p>

<ul>
  <li>Compiler and core tools</li>
  <li>Standard libraries and core APIs</li>
  <li>Samples</li>
  <li>The <a href="http://swift.org/">Swift.org</a> website</li>
  <li>Official clients, drivers, and other packages (<em>coming soon</em>)</li>
</ul>

<p>As we move forward, we will address several key governance aspects:</p>

<ul>
  <li>Methods for integrating new projects into the organization and guiding them through a successful maturity cycle</li>
  <li>Utilization of GitHub teams and other tools to expand our contributor base and clearly define roles for commiters</li>
  <li>Extend and augment continuous integration (CI) support to ensure Swift and all of its components is a well-tested, production-ready programming language for all use cases</li>
</ul>



<p><a href="https://www.swift.org/community/#community-structure">Various groups within our community</a> will spearhead this migration, including the Core Team, the Contributor Experience Workgroup, the Swift Server Workgroup, and the Website Workgroup. This initiative represents a community-wide effort, with full transparency as changes progressively unfold.</p>

<p>As a first step, we will move the <code>swift-evolution</code> repository today, with other repositories transitioning over the coming weeks. We will post updates to the accompanying forum posts as the migration unfurls.</p>

<p>On behalf of the core team, I want to express our deep gratitude to everyone who has contributed to the Swift dream, from its inception a decade ago to today.  Together, we are building the pathways for the next chapter of Swift!</p>

<p>Onward!</p>

<p>Ted (and the Swift Core Team)</p>


  
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The new math of how large-scale order emerges (162 pts)]]></title>
            <link>https://www.quantamagazine.org/the-new-math-of-how-large-scale-order-emerges-20240610/</link>
            <guid>40638764</guid>
            <pubDate>Mon, 10 Jun 2024 20:42:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/the-new-math-of-how-large-scale-order-emerges-20240610/">https://www.quantamagazine.org/the-new-math-of-how-large-scale-order-emerges-20240610/</a>, See on <a href="https://news.ycombinator.com/item?id=40638764">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>We care about your data, and we'd like to use cookies to give you a smooth browsing experience. Please agree and read more about our <a href="https://www.quantamagazine.org/privacy-policy">privacy policy</a>.</p><div id="postContent"><div id="postBody"><div><p>The puzzle of emergence asks how regularities emerge on macro scales out of uncountable constituent parts. A new framework has researchers hopeful that a solution is near.</p></div><figure></figure><div><h2>Introduction</h2><div><p>A few centuries ago, the swirling polychromatic chaos of Jupiter’s atmosphere spawned the immense vortex that we call the Great Red Spot.</p>
<p>From the frantic firing of billions of neurons in your brain comes your unique and coherent experience of reading these words.</p>
<p>As pedestrians each try to weave their path on a crowded sidewalk, they begin to follow one another, forming streams that no one ordained or consciously chose.</p>
<p>The world is full of such emergent phenomena: large-scale patterns and organization arising from innumerable interactions between component parts. And yet there is no agreed scientific theory to explain emergence. Loosely, the behavior of a complex system might be considered emergent if it can’t be predicted from the properties of the parts alone. But when will such large-scale structures and patterns arise, and what’s the criterion for when a phenomenon is emergent and when it isn’t? Confusion has reigned. “It’s just a muddle,” said <a href="https://csc.ucdavis.edu/~chaos/">Jim Crutchfield</a>, a physicist at the University of California, Davis.</p>
<p>“Philosophers have long been arguing about emergence, and going round in circles,” said <a href="https://profiles.sussex.ac.uk/p22981-anil-seth">Anil Seth</a>, a neuroscientist at the University of Sussex in England. The problem, according to Seth, is that we haven’t had the right tools — “not only the tools for analysis, but the tools for thinking. Having measures and theories of emergence would not only be something we can throw at data but would also be tools that can help us think about these systems in a richer way.”</p>
<p>Though the problem remains unsolved, over the past few years, a community of physicists, computer scientists and neuroscientists has been working toward a better understanding. These researchers have developed theoretical tools for identifying when emergence has occurred. And in February, <a href="https://profiles.imperial.ac.uk/f.rosas">Fernando Rosas</a>, a complex systems scientist at Sussex, together with Seth and five co-authors, went further, with <a href="https://arxiv.org/abs/2402.09090">a framework</a> for understanding how emergence arises.</p>

<p>A complex system exhibits emergence, according to the new framework, by organizing itself into a hierarchy of levels that each operate independently of the details of the lower levels. The researchers suggest we think about emergence as a kind of “software in the natural world.” Just as the software of your laptop runs without having to keep track of all the microscale information about the electrons in the computer circuitry, so emergent phenomena are governed by macroscale rules that seem self-contained, without heed to what the component parts are doing.</p>
<p>Using a mathematical formalism called computational mechanics, the researchers identified criteria for determining which systems have this kind of hierarchical structure. They tested these criteria on several model systems known to display emergent-type phenomena, including neural networks and Game-of-Life-style cellular automata. Indeed, the degrees of freedom, or independent variables, that capture the behavior of these systems at microscopic and macroscopic scales have precisely the relationship that the theory predicts.</p>
<p>No new matter or energy appears at the macroscopic level in emergent systems that isn’t there microscopically, of course. Rather, emergent phenomena, from Great Red Spots to conscious thoughts, demand a new language for describing the system. “What these authors have done is to try to formalize that,” said <a href="https://adami.natsci.msu.edu/">Chris Adami</a>, a complex-systems researcher at Michigan State University. “I fully applaud this idea of making things mathematical.”</p>
<h2><strong>A Need for Closure</strong></h2>
<p>Rosas came at the topic of emergence from multiple directions. His father was a famous conductor in Chile, where Rosas first studied and played music. “I grew up in concert halls,” he said. Then he switched to philosophy, followed by a degree in pure mathematics, giving him “an overdose of abstractions” that he “cured” with a Ph.D. in electrical engineering.</p>
<p>A few years ago, Rosas started thinking about the vexed question of whether the brain is a computer. Consider what goes on in your laptop. The software generates predictable and repeatable outputs for a given set of inputs. But if you look at the actual physics of the system, the electrons won’t all follow identical trajectories each time. “It’s a mess,” said Rosas. “It’ll never be exactly the same.”</p>
<p>The software seems to be “closed,” in the sense that it doesn’t depend on the detailed physics of the microelectronic hardware. The brain behaves somewhat like this too: There’s a consistency to our behaviors even though the neural activity is never identical in any circumstance.</p>
<p>Rosas and colleagues figured that in fact there are three different types of closure involved in emergent systems. Would the output of your laptop be any more predictable if you invested lots of time and energy in collecting information about all the microstates — electron energies and so forth — in the system? Generally, no. This corresponds to the case of <em>informational closure</em>: As Rosas put it, “All the details below the macro are not helpful for predicting the macro.”</p>
<p>What if you want not just to predict but to control the system — does the lower-level information help there? Again, typically no: Interventions we make at the macro level, such as changing the software code by typing on the keyboard, are not made more reliable by trying to alter individual electron trajectories. If the lower-level information adds no further control of macro outcomes, the macro level is <em>causally closed</em>: It alone is causing its own future.</p>
</div></div><figure><div><p><img alt="A man with gray hair stands next to an array of gadgets on a table, including a stainless-steel sphere with wires coming out of it." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/06/JamesCrutchfield-crTonjeHessenSchei.webp"></p></div><figcaption><div><p>Jim Crutchfield, a physicist at the University of California, Davis, is shown with an underwater microphone he recently designed for recording humpback whale vocalizations, to which he is applying his pattern discovery methods in hopes of decoding the causal relationships between vocalizations.</p><p>Tonje Hessen Schei</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>This situation is rather common. Consider, for instance, that we can use macroscopic variables like pressure and viscosity to talk about (and control) fluid flow, and knowing the positions and trajectories of individual molecules doesn’t add useful information for those purposes. And we can describe the market economy by considering companies as single entities, ignoring any details about the individuals that constitute them.</p>
<p>The existence of a useful coarse-grained description doesn’t, however, by itself define an emergent phenomenon, said Seth. “You want to say something else in terms of the relationship between levels.” Enter the third level of closure that Rosas and colleagues think is needed to complete the conceptual apparatus: <em>computational closure</em>. For this they have turned to computational mechanics, <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.63.105">a discipline pioneered by Crutchfield</a>.</p>
<p>Crutchfield introduced a conceptual device called the ε- (epsilon) machine. This device can exist in some finite set of states and can predict its own future state on the basis of its current one. It’s a bit like an elevator, said Rosas; an input to the machine, like pressing a button, will cause the machine to transition to a different state (floor) in a deterministic way that depends on its past history — namely, its current floor, whether it’s going up or down and which other buttons were pressed already. Of course an elevator has myriad component parts, but you don’t need to think about them. Likewise, an ε-machine is an optimal way to represent how unspecified interactions between component parts “compute” — or, one might say, cause — the machine’s future state.</p>
<p>Computational mechanics allows the web of interactions between a complex system’s components to be reduced to the simplest description, called its causal state. The state of the complex system at any moment, which includes information about its past states, produces a distribution of possible future states. Whenever two or more such present states have the same distribution of possible futures, they are said to be in the same causal state. Our brains will never twice have exactly the same firing pattern of neurons, but there are plenty of circumstances where nevertheless we’ll end up doing the same thing.</p>
<p>Rosas and colleagues considered a generic complex system as a set of ε-machines working at different scales. One of these might, say, represent all the molecular-scale ions, ion channels and so forth that produce currents in our neurons; another represents the firing patterns of the neurons themselves; another, the activity seen in compartments of the brain such as the hippocampus and frontal cortex. The system (here the brain) evolves at all those levels, and in general the relationship between these ε-machines is complicated. But for an emergent system that is computationally closed, the machines at each level can be constructed by coarse-graining the components on just the level below: They are, in the researchers’ terminology, “strongly lumpable.” We might, for example, imagine lumping all the dynamics of the ions and neurotransmitters moving in and out of a neuron into a representation of whether the neuron fires or not. In principle, one could imagine all kinds of different “lumpings” of this sort, but the system is only computationally closed if the ε-machines that represent them are coarse-grained versions of each other in this way. “There is a nestedness” to the structure, Rosas said.</p>
<p>A highly compressed description of the system then emerges at the macro level that captures those dynamics of the micro level that matter to the macroscale behavior — filtered, as it were, through the nested web of intermediate ε-machines. In that case, the behavior of the macro level can be predicted as fully as possible using only macroscale information — there is no need to refer to finer-scale information. It is, in other words, fully emergent. The key characteristic of this emergence, the researchers say, is this hierarchical structure of “strongly lumpable causal states.”</p>
<h2><strong>Leaky Emergence</strong></h2>
<p>The researchers tested their ideas by seeing what they reveal about a range of emergent behaviors in some model systems. One is a version of a random walk, where some agent wanders around haphazardly in a network that could represent, for example, the streets of a city. A city often exhibits a hierarchy of scales, with densely connected streets within neighborhoods and much more sparsely connected streets between neighborhoods. The researchers find that the outcome of a random walk through such a network is highly lumpable. That is, the probability of the wanderer starting in neighborhood A and ending up in neighborhood B — the macroscale behavior — remains the same regardless of which streets within A or B the walker randomly traverses.</p>
<p>The researchers also considered artificial neural networks like those used in machine-learning and artificial-intelligence algorithms. Some of these networks organize themselves into states that can reliably identify macroscopic patterns in data regardless of microscopic differences between the states of individual neurons in the network. The decision of which pattern will be output by the network “works at a higher level,” said Rosas.</p>
</div></div><figure><div><p><img alt="A man in profile strokes a paintbrush on the chests of a man in a VR head and a manequin." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/06/AnilSeth-crTomMedwell-1.webp"></p></div><figcaption><div><p>Anil Seth, a neuroscientist at the University of Sussex who studies consciousness, conducts an experiment on perception.</p><p>Tom Medwell</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Would Rosas’ scheme help to understand the emergence of robust, large-scale structure in a case like Jupiter’s Great Red Spot? The huge vortex “might satisfy computational closure” Rosas said, “but we’d need to do a proper analysis before being able to claim anything.”</p>
<p>As for living organisms, they seem sometimes to be emergent but sometimes more “vertically integrated,” where microscopic changes do influence large-scale behavior. Consider, for example, a heart. Despite considerable variations in the details of which genes are being expressed, and how much, or what the concentrations of proteins are from place to place, all of our heart muscle cells seem to work in essentially the same way, enabling them to function en masse as a pump driven by coherent, macroscopic electrical pulses passing through the tissue. But it’s not always this way. While many of our genes carry mutations that make no difference to our health, sometimes a mutation — just one genetic “letter” in a DNA sequence that is “wrong” — can be catastrophic. So the independence of the macro from the micro is not complete: There is some leakage between levels. Rosas wonders if living organisms are in fact optimized by allowing for such “leaky” partial emergence — because in life, sometimes it is essential for the macro to heed the details of the micro.</p>
<h2><strong>Emergent Causes</strong></h2>
<p>Rosas’ framework could help complex systems researchers see when they can and can’t hope to develop predictive coarse-grained models. When a system meets the key requirement of being computationally closed, “you don’t lose any faithfulness by simulating the upper levels and neglecting the lower levels,” he said. But ultimately Rosas hopes an approach like his might answer some deep questions about the structure of the universe — why, for example, life seems to exist only at scales intermediate between the atomic and the galactic.</p>
<p>The framework also has implications for understanding the tricky question of cause and effect in complex and emergent systems. Traditionally, causation has been assumed to flow from the bottom up: Our choices and actions, for example, are ultimately attributed to those firing patterns of our neurons, which in turn are caused by flows of ions across cell membranes.</p>

<p>But in an emergent system, this is not necessarily so; causation can operate at a higher level independently from lower-level details. Rosas’ new computational framework seems to capture this aspect of emergence, which was also explored in earlier work. In 2013, neuroscientist <a href="https://www.psychiatry.wisc.edu/staff/tononi-giulio/">Giulio Tononi</a> of the University of Wisconsin, Madison, working with Erik Hoel and Larissa Albantakis (also at Wisconsin), <a href="https://www.pnas.org/doi/10.1073/pnas.1314922110">claimed</a> that, according to a particular measure of causal influence called effective information, the overall behavior of some complex systems is caused more at the higher than the lower levels. This is called <a href="https://www.mdpi.com/1099-4300/19/5/188">causal emergence</a>.</p>
<p>The 2013 work using effective information could have been just a quirk of measuring causal influence this way. But recently, Hoel and neuroscientist <a href="https://centerforsleepandconsciousness.psychiatry.wisc.edu/people/renzo-comolatti/">Renzo Comolatti</a> have <a href="https://arxiv.org/abs/2202.01854">shown</a> that it is not. They took 12 different measures of causal power proposed in the literature and found that with all of them, some complex systems show causal emergence. “It doesn’t matter what measure of causation you pick,” Hoel said. “We just went out into the literature and picked other people’s definitions of causation, and all of them showed causal emergence.” It would be bizarre if this were some chance quirk of all those different measures.</p>
<p>For Hoel, emergent systems are ones whose macroscale behavior has some immunity to randomness or noise at the microscale. For many complex systems, there’s a good chance you can find coarse-grained, macroscopic descriptions that minimize that noise. “It’s that minimization that lies at the heart of a good notion of emergence,” he said.</p>
<p>Tononi says that, while his approach and that of Rosas and colleagues address the same kinds of systems, they have somewhat different criteria for causal emergence. “They define emergence as being when the macro system can predict itself as much as it can be predicted from the micro level,” he said. “But we require <em>more</em> causal information at the macro level than at the micro level.”</p>

<p>The new ideas touch on the issue of free will. While hardened reductionists have argued that there can be no free will because all causation ultimately arises from interactions of atoms and molecules, free will may be rescued by the formalism of higher-level causation. If the main cause of our actions is not our molecules but the emergent mental states that encode memories, intentions, beliefs and so forth, isn’t that enough for a meaningful notion of free will? The new work shows that “there are sensible ways to think about macro-level causation that explain how agents can have a worthwhile form of causal efficacy,” Seth said.</p>
<p>Still, there remains disagreement among researchers about whether macroscopic, agent-level causation can emerge in complex systems. “I’m uncomfortable with this idea that the macroscale can drive the microscale,” said Adami. “The macroscale is just degrees of freedom that you’ve invented.” This is the sort of issue that the scheme proposed by Rosas and colleagues might help to resolve, by burrowing into the mechanics of how different levels of the system speak to one another, and how this conversation must be structured to achieve independence of the macro from the details of the levels below.</p>
<p>At this point, some of the arguments are pretty fuzzy. But Crutchfield is optimistic. “We’ll have this figured out in five or 10 years,” he said. “I really think the pieces are there.”</p>
</div></div></div><div id="newsletter"><p>The Quanta Newsletter</p><p><em>Get highlights of the most important news delivered to your email inbox</em></p></div><section id="comments"><h2>Comment on this article</h2></section><div><h2>Next article</h2><p>In Highly Connected Networks, There’s Always a Loop</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>