<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 18 Dec 2025 02:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I got hacked: My Hetzner server started mining Monero (197 pts)]]></title>
            <link>https://blog.jakesaunders.dev/my-server-started-mining-monero-this-morning/</link>
            <guid>46305585</guid>
            <pubDate>Wed, 17 Dec 2025 21:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jakesaunders.dev/my-server-started-mining-monero-this-morning/">https://blog.jakesaunders.dev/my-server-started-mining-monero-this-morning/</a>, See on <a href="https://news.ycombinator.com/item?id=46305585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <blockquote>
  <p>Edit: A few people on HN have pointed out that this article sounds a little LLM generated. That’s because 
it’s largely a transcript of me panicking and talking to Claude. Sorry if it reads poorly, the incident really
happened though!</p>
</blockquote>

<p><em>Or: How I learned that “I don’t use Next.js” doesn’t mean your dependencies don’t use Next.js</em></p>

<h2 id="825-am-the-email">8:25 AM: The Email</h2>

<p>I woke up to this beauty from Hetzner:</p>

<blockquote>
  <p>Dear Mr Jake Saunders,</p>
</blockquote>

<blockquote>
  <p>We have indications that there was an attack from your server.
Please take all necessary measures to avoid this in the future and to solve the issue.</p>
</blockquote>

<blockquote>
  <p>We also request that you send a short response to us. This response should contain information about how this could
have happened and what you intend to do about it.
In the event that the following steps are not completed successfully, your server can be blocked at any time after the
2025-12-17 12:46:15 +0100.</p>
</blockquote>

<blockquote>
  <p>Attached was evidence of network scanning from my server to some IP range in Thailand. Great. Nothing says “good
morning” like an abuse report and the threat of getting your infrastructure shut down in 4 hours.</p>
</blockquote>

<p>Background: I run a Hetzner server with Coolify. It runs all my <em>stuff</em>, like my little corner of the internet:</p>

<ul>
  <li><a href="https://inventronix.club/connect">My IoT Side Project</a></li>
  <li>This Blog</li>
  <li>Analytics</li>
  <li>My dads site (he’s an electrician)</li>
</ul>

<h2 id="830-am-oh-fuck">8:30 AM: Oh Fuck</h2>

<p>First thing I did was SSH in and check the load average:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>$ </span>w
 08:25:17 up 55 days, 17:23,  5 <span>users</span>,  load average: 15.35, 15.44, 15.60
</pre></td></tr></tbody></table></code></pre></div>

<p>For context, my load average is normally around 0.5-1.0. <strong>Fifteen</strong> is “something is very wrong.”</p>

<p>I ran <code>ps aux</code> to see what was eating my CPU:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
1001      714822  819  3.6 2464788 2423424 ?     Sl   Dec16 9385:36 /tmp/.XIN-unix/javae
1001       35035  760  0.0      0     0 ?        Z    Dec14 31638:25 [javae] &lt;defunct&gt;
1001     3687838  586  0.0      0     0 ?        Z    Dec07 82103:58 [runnv] &lt;defunct&gt;
1001     4011270  125  0.0      0     0 ?        Z    Dec11 10151:54 [xmrig] &lt;defunct&gt;
1001       35652 62.3  0.0      0     0 ?        Z    Dec12 4405:17 [xmrig] &lt;defunct&gt;
</pre></td></tr></tbody></table></code></pre></div>

<p><strong>819% CPU usage.</strong> On a process called <code>javae</code> running from <code>/tmp/.XIN-unix/</code>. And multiple <code>xmrig</code> processes - that’s
literally cryptocurrency mining software (Monero, specifically).</p>

<p>I’d been mining cryptocurrency for someone since December 7th. For <strong>ten days</strong>. Brilliant.</p>

<h2 id="the-investigation">The Investigation</h2>

<p>My first thought was “I’m completely fucked.” Cryptominers on the host, running for over a week - time to nuke
everything from orbit and rebuild, right?</p>

<p>But then I noticed something interesting. All these processes were running as user <code>1001</code>. Not root. Not a system user.
UID 1001.</p>

<p>Let me check what’s actually running:</p>



<p>I’ve got about 20 containers running via Coolify (my self-hosted PaaS). Inventronix (my IoT platform), some monitoring
stuff, Grafana, a few experiments.</p>

<p>And <strong>Umami</strong> - a privacy-focused analytics tool I’d re-deployed 9 days ago to track traffic on my blog.</p>

<p>Wait. 9 days ago. The malware started December 7th. Same timeline.</p>

<p>Let me check which container has user 1001:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>$ </span>docker ps <span>-q</span> | <span>while </span><span>read </span>container<span>;</span> <span>do
  </span><span>echo</span> <span>"=== </span><span>$container</span><span> ==="</span>
  docker <span>exec</span> <span>$container</span> <span>ls</span> <span>-la</span> /app/node_modules/next/dist/server/lib/ 2&gt;/dev/null | <span>grep </span>xmrig
<span>done</span>
</pre></td></tr></tbody></table></code></pre></div>

<p>Output:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>=== a42f72cb1bc5 ===
drwxr-xr-x    2 nextjs   nogroup       4096 Dec 17 05:11 xmrig-6.24.0
</pre></td></tr></tbody></table></code></pre></div>

<p><strong>There it is.</strong> Container <code>a42f72cb1bc5</code> - that’s my Umami analytics container. And it’s got a whole <code>xmrig-6.24.0</code>
directory sitting in what should be Next.js server internals.</p>

<p>The mining command in the process list confirmed it:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>/app/node_modules/next/dist/server/lib/xmrig-6.24.0/xmrig 
  --url auto.c3pool.org:443 
  --user 8Bt9BEG98SbBPNTp1svQtDQs7PMztqzGoNQHo58eaUYdf8apDkbzp8HbLJH89fMzzciFQ7fb4ZiqUbymDZR6S9asKHZR6wn 
  --pass WUZHRkYOHh1GW1RZWBxaWENRX0ZBWVtdSRxQWkBWHg== 
  --donate-level 0
</pre></td></tr></tbody></table></code></pre></div>

<p>Someone had exploited my analytics container and was mining Monero using my CPU. Nice.</p>

<h2 id="wait-i-dont-use-nextjs">Wait, I Don’t Use Next.js</h2>

<p>Here’s the kicker. A few days ago I saw
a <a href="https://www.reddit.com/r/nextjs/comments/1pgiaj3/i_got_hacked_and_traced_how_much_money_hacker/">Reddit post</a> about a
critical Next.js/Puppeteer RCE vulnerability (
CVE-2025-66478). My immediate reaction was “lol who cares, I don’t run Next.js.”</p>

<blockquote>
  <p>Oh my sweet summer child.</p>
</blockquote>

<p>Except… Umami <strong>is built with Next.js</strong>. I did not know this, nor did I bother looking. Oops.</p>

<p>The vulnerability (CVE-2025-66478) was in Next.js’s React Server Components deserialization. The “Flight” protocol that
RSC uses to serialize/deserialize data between client and server had an unsafe deserialization flaw. An attacker could
send a specially crafted HTTP request with a malicious payload to any App Router endpoint, and when deserialized, it
would execute arbitrary code on the server.</p>

<p>No Puppeteer involved - just broken deserialization in the RSC protocol itself. The attack flow:</p>

<ol>
  <li>Attacker sends crafted HTTP request to Umami’s Next.js endpoint</li>
  <li>RSC deserializes the malicious payload</li>
  <li>RCE achieved via unsafe deserialization</li>
  <li>Download and install cryptominers</li>
  <li>Profit (for them)</li>
</ol>

<p>So much for “I don’t use Next.js.”</p>

<h2 id="the-panic-has-it-escaped-the-container">The Panic: Has It Escaped the Container?</h2>

<p>This is where I started to properly panic. Looking at that process list:</p>

<div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>1001      714822  819  3.6 2464788 2423424 ?     Sl   Dec16 9385:36 /tmp/.XIN-unix/javae
</pre></td></tr></tbody></table></code></pre></div>

<p>That path - <code>/tmp/.XIN-unix/javae</code> - looks like it’s on the <strong>host filesystem</strong>, not inside a container. If the malware
had escaped the container onto my actual server, I’d need to:</p>

<ol>
  <li>Assume everything is compromised</li>
  <li>Check for rootkits, backdoors, persistence mechanisms</li>
  <li>Probably rebuild from scratch</li>
  <li>Spend my entire day unfucking this</li>
</ol>

<p>I checked for persistence mechanisms:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>$ </span>crontab <span>-l</span>
no crontab <span>for </span>root

<span>$ </span>systemctl list-unit-files | <span>grep </span>enabled
<span># ... all legitimate system services, nothing suspicious</span>
</pre></td></tr></tbody></table></code></pre></div>

<p>No malicious cron jobs. No fake systemd services pretending to be <code>nginxs</code> or <code>apaches</code> (common trick to blend in).
That’s… good?</p>

<p>But I still needed to know: <strong>Did the malware actually escape the container or not?</strong></p>

<h2 id="the-moment-of-truth">The Moment of Truth</h2>

<p>Here’s the test. If <code>/tmp/.XIN-unix/javae</code> exists on my host, I’m fucked. If it doesn’t exist, then what I’m seeing is
just Docker’s default behavior of showing container processes in the host’s <code>ps</code> output, but they’re actually isolated.</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>$ </span><span>ls</span> <span>-la</span> /tmp/.XIN-unix/javae
<span>ls</span>: cannot access <span>'/tmp/.XIN-unix/javae'</span>: No such file or directory
</pre></td></tr></tbody></table></code></pre></div>

<p><strong>IT NEVER ESCAPED.</strong></p>

<p>The malware was entirely contained within the Umami container. When you run <code>ps aux</code> on a Docker host, you see processes
from all containers because they share the same kernel. But those processes are in their own mount namespace - they
can’t see or touch the host filesystem.</p>

<p>Let me verify what user that container was actually running as:</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre><span>$ </span>docker inspect umami-bkc4kkss848cc4kw4gkw8s44 | <span>grep</span> <span>'"User"'</span>
<span>"User"</span>: <span>"nextjs"</span>,

<span>$ </span>docker inspect umami-bkc4kkss848cc4kw4gkw8s44 | <span>grep</span> <span>'"Privileged"'</span>
<span>"Privileged"</span>: <span>false</span>,

<span>$ </span>docker inspect umami-bkc4kkss848cc4kw4gkw8s44 | <span>grep</span> <span>-A</span> 30 <span>"Mounts"</span>
<span>"Mounts"</span>: <span>[]</span>,
</pre></td></tr></tbody></table></code></pre></div>

<p><strong>This is why I’m not fucked:</strong></p>

<ul>
  <li>Container ran as user <code>nextjs</code> (UID 1001), not root ✅</li>
  <li>Container was not privileged ✅</li>
  <li>Container had <strong>zero volume mounts</strong> ✅</li>
</ul>

<p>The malware could:</p>

<ul>
  <li>Run processes inside the container ✅</li>
  <li>Mine cryptocurrency ✅</li>
  <li>Scan networks (hence the Hetzner abuse report) ✅</li>
  <li>Consume 100% CPU ✅</li>
</ul>

<p>The malware could NOT:</p>

<ul>
  <li>Access the host filesystem ❌</li>
  <li>Install cron jobs ❌</li>
  <li>Create systemd services ❌</li>
  <li>Persist across container restarts ❌</li>
  <li>Escape to other containers ❌</li>
  <li>Install rootkits ❌</li>
</ul>

<p>Container isolation actually worked. Nice.</p>

<h2 id="why-this-matters-dockerfiles-vs-auto-generated-images">Why This Matters: Dockerfiles vs. Auto-Generated Images</h2>

<p>Here’s the thing that saved me. I write my own Dockerfiles for my applications. I don’t use auto-generation tools like
Nixpacks (which Coolify supports) that default to <code>USER root</code> in containers.</p>

<p>The Reddit post I’d seen earlier? That guy got completely owned because his container was running as root. The malware
could:</p>

<ul>
  <li>Install cron jobs for persistence</li>
  <li>Create systemd services</li>
  <li>Write anywhere on the filesystem</li>
  <li>Survive reboots</li>
</ul>

<p>His fix required a full server rebuild because he couldn’t trust anything anymore. Mine required… deleting a
container.</p>

<p>What I did not do, was keep track of the tolling I was using and what tooling <em>that</em> was using. In fact, I installed
Umami from Coolify’s services screen. I didn’t even configure it.</p>

<p>Obviously none of this is Umami’s fault by the way. They released a fix for their free software like a week ago. I just
didn’t think to do anything about it.</p>

<h2 id="the-fix">The Fix</h2>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span># Stop and remove the compromised container</span>
<span>$ </span>docker stop umami-bkc4kkss848cc4kw4gkw8s44
<span>$ </span>docker <span>rm </span>umami-bkc4kkss848cc4kw4gkw8s44

<span># Check CPU usage</span>
<span>$ </span><span>uptime
 </span>08:45:17 up 55 days, 17:43,  1 user,  load average: 0.52, 1.24, 4.83
</pre></td></tr></tbody></table></code></pre></div>

<p>CPU back to normal. All those cryptomining processes? Gone. They only existed inside the container.</p>

<p>I also enabled UFW (which I should have done ages ago):</p>

<div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>$ </span><span>sudo </span>ufw default deny incoming
<span>$ </span><span>sudo </span>ufw default allow outgoing
<span>$ </span><span>sudo </span>ufw allow ssh
<span>$ </span><span>sudo </span>ufw allow 80/tcp
<span>$ </span><span>sudo </span>ufw allow 443/tcp
<span>$ </span><span>sudo </span>ufw <span>enable</span>
</pre></td></tr></tbody></table></code></pre></div>

<p>This blocks all inbound connections except SSH, HTTP, and HTTPS. No more exposed PostgreSQL ports, no more RabbitMQ
ports open to the internet.</p>

<p>I sent Hetzner a brief explanation:</p>

<blockquote>
  <p>Investigation complete. The scanning originated from a compromised Umami analytics container (CVE-2025-66478 -
Next.js/Puppeteer RCE).</p>

  <p>The container ran as non-root user with no privileged access or host mounts, so the compromise was fully contained.
Container has been removed and firewall hardened.</p>
</blockquote>

<p>They closed the ticket within an hour.</p>

<h2 id="lessons-learned">Lessons Learned</h2>

<h3 id="1-i-dont-use-x-doesnt-mean-your-dependencies-dont-use-x">1. “I don’t use X” doesn’t mean your dependencies don’t use X</h3>

<p>I don’t write Next.js applications. But I run third-party tools that are built with Next.js. When CVE-2025-66478 was
disclosed, I thought “not my problem.” Wrong.</p>

<p>Know what your dependencies are actually built with. That “simple analytics tool” is a full web application with a
complex stack.</p>

<h3 id="2-container-isolation-works-when-configured-properly">2. Container isolation works (when configured properly)</h3>

<p>This could have been so much worse. If that container had been running as root, or had volume mounts to sensitive
directories, or had access to the Docker socket, I’d be writing a very different blog post about rebuilding my entire
infrastructure.</p>

<p>Instead, I deleted one container and moved on with my day.</p>

<p><strong>Write your own Dockerfiles.</strong> Understand what user your processes run as. Avoid <code>USER root</code> unless you have a very
good reason. Don’t mount volumes you don’t need. Don’t give containers <code>--privileged</code> access.</p>

<h3 id="3-the-sophistication-gap">3. The sophistication gap</h3>

<p>This malware wasn’t like those people who auto-poll for <code>/wpadmin</code> <em>every</em> time I make a DNS change. This was spicy.</p>

<ul>
  <li>Disguised itself in legitimate-looking paths (<code>/app/node_modules/next/dist/server/lib/</code>)</li>
  <li>Used process names that blend in (<code>javae</code>, <code>runnv</code>)</li>
  <li>Attempted to establish persistence</li>
  <li>According to other reports, even had “killer scripts” to murder competing miners</li>
</ul>

<p>But it was still limited by container isolation. Good security practices beat sophisticated malware.</p>

<h3 id="4-defense-in-depth-matters">4. Defense in depth matters</h3>

<p>Even though the container isolation held, I still should have:</p>

<ul>
  <li>Had a firewall enabled from day one (not “I’ll do it later”)</li>
  <li>Been running fail2ban to stop those SSH brute force attempts</li>
  <li>Had proper monitoring/alerting (I only noticed because of the Hetzner email)</li>
  <li>Updated Umami when the CVE was disclosed</li>
</ul>

<p>I got lucky. Container isolation saved me from my own laziness.</p>

<h2 id="what-im-doing-differently">What I’m Doing Differently</h2>

<ol>
  <li>
    <p><strong>No more Umami.</strong> I’m salty. The CVE was disclosed, they patched it, but I’m not running Next.js-based analytics
anymore. Considering GoatCounter (written in Go) or just parsing server logs with GoAccess.</p>
  </li>
  <li><strong>Audit all third-party containers.</strong> Going through everything I run and checking:
    <ul>
      <li>What user does it run as?</li>
      <li>What volumes does it have?</li>
      <li>When was it last updated?</li>
      <li>Do I actually need it?</li>
    </ul>
  </li>
  <li>
    <p><strong>SSH hardening.</strong> Moving to key-based authentication only, disabling password auth, and setting up fail2ban.</p>
  </li>
  <li>
    <p><strong>Proper monitoring.</strong> Setting up alerts for CPU usage, load average, and suspicious network activity. I shouldn’t
find out about compromises from my hosting provider.</p>
  </li>
  <li><strong>Regular security updates.</strong> No more “I’ll update it later.” If there’s a CVE, I patch or I remove the service.</li>
</ol>

<h2 id="the-weird-silver-lining">The Weird Silver Lining</h2>

<p>This was actually a pretty good learning experience. I got to:</p>

<ul>
  <li>Practice incident response on a real compromise</li>
  <li>Prove that container isolation actually works</li>
  <li>Learn about Docker namespaces, user mapping, and privilege boundaries</li>
  <li>Harden my infrastructure without the pressure of active data loss</li>
</ul>

<p>And I only lost about 2 hours of my morning before work. Could’ve been way worse.</p>

<p>Though I do wonder how much Monero I mined for that dickhead. Based on the CPU usage and duration… probably enough for
them to have a nice lunch. You’re welcome, mysterious attacker. Hope you enjoyed it.</p>

<h2 id="tldr">TL;DR</h2>

<ul>
  <li>Umami analytics (built with Next.js) had a Puppeteer RCE vulnerability</li>
  <li>Got exploited, installed cryptominers</li>
  <li>Mined Monero for 10 days at 1000%+ CPU</li>
  <li>Container isolation saved me because it ran as non-root with no mounts</li>
  <li>Fix: <code>docker rm umami</code> and enable firewall</li>
  <li>Lesson: Know what your dependencies are built with, and configure containers properly</li>
</ul>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OBS Studio Gets a New Renderer (119 pts)]]></title>
            <link>https://obsproject.com/blog/obs-studio-gets-a-new-renderer</link>
            <guid>46305428</guid>
            <pubDate>Wed, 17 Dec 2025 20:59:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://obsproject.com/blog/obs-studio-gets-a-new-renderer">https://obsproject.com/blog/obs-studio-gets-a-new-renderer</a>, See on <a href="https://news.ycombinator.com/item?id=46305428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <figure><img alt="Official Apple Metal Logo" src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/00a9fd825b-1762495292/apple_metal_logo.png"></figure>
<p>Starting with OBS Studio 32.0.0 a new renderer backend based on Apple's <strong>Metal</strong> graphics API is available for users to test as an experimental alternative to the existing OpenGL backend on macOS. This marks an important step in OBS Studio's development to adapt one of the modern APIs that deliberately broke with the past to unlock better performance and efficiency gains for end users, but also require fundamental changes to how an application interacts with a GPU.</p>
<figure><img alt="Screenshot of OBS Studio with experimental Metal renderer selected." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/23727844c2-1762495292/obs_studio_with_metal.jpg"></figure>
<p>These fundamental changes were necessary to achieve the goals of lower overhead, faster performance, and to better represent the way that modern GPUs actually work, particularly when the GPU is used for more than just 3D rendering. Yet other changes were also necessary due to the way Metal was specifically designed to fit into Apple's operating systems.</p>
<p>Due to the sheer amount of information around this topic, it made sense to split it into separate posts:</p>
<ul>
<li><strong>The first post (this one)</strong> will go into specific challenges and insights from writing the Metal backend for OBS Studio.</li>
<li>The second post will look at the history of 3D graphics APIs, their core differences, and how the design of the new generation creates challenges for existing renderers like the one in OBS Studio.</li>
</ul>
<p>The Metal backend is explicitly marked as <strong>"Experimental"</strong> in the application because it has some known quirks (for which no good solutions have been found yet, more about that below) but also because it has not yet been tested by a larger user audience. The OpenGL renderer is still <em>the default choice</em> offered to users and will be available for the foreseeable future, but we still would like to invite users to try out the Metal backend for themselves, and report any critical bugs they might encounter.</p>
<p>Better yet, if you happen to have prior experience working with Metal on Apple Silicon platforms (including iPhones), we'd be happy to hear feedback about specific aspects of the current implementation or even review pull-requests with improvements to it.</p>
<h2>Part 1.1: The Why Of Metal</h2>
<figure><img alt="Craig Federighi announcing Metal during WWDC 2014, jokingly making a 'fork' hand gesture." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/4ef70e7e9e-1762495292/craig_federighi_metal_wwdc_2014.jpg"></figure>
<p>In June 2014 Apple announced (and - more importantly - also <em>released to developers</em>) the first version of Metal for iPhones with Apple's A7 SOC, extending its support to current Macs of the time in 2015. Thus Metal was not only available on what became later known as "Apple Silicon" GPUs, but also Intel, AMD, and NVIDIA GPUs, being the first "next generation" graphics API to support all mainstream GPUs of the time.</p>
<p>Metal combined many benefits to Apple specifically: The API was based on concepts and ideas that not only already found their way into AMD's "Mantle" API (which was announced in September 2013) but had also been discussed for and adopted to some degree in the existing graphics APIs (OpenGL and Direct3D) at the time. But as a new API written from scratch it had the chance to omit all the <em>legacy aspects of existing APIs</em> and fully lean into these new concepts. It was able to provide the performance gains unlocked by this different approach and as it was originally designed for iOS and macOS, an entirely new API implemented in <em>Objective-C and Swift</em> (the latter of which was also introduced in 2014).</p>
<figure><a href="https://gdcvault.com/play/1020791/Approaching-Zero-Driver-Overhead-in" rel="noopener noreferrer" target="_blank"><img alt="Opening slide of GDC 2014 presentation by NVIDIA, AMD, and Intel, about approaching zero driver overhead in OpenGL" src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/5894ade6c0-1762495292/gdc_2014_approaching_zero_driver_overhead.jpg"></a></figure>
<p>While OpenGL did (and still does) provide a well-established C-based API, it incorporates a binding model that is considered inelegant by many. Direct3D to this day uses a C++-based object-oriented API design (primarily via the COM binary interface), making it easier for developers to keep track of state and objects in their application code. Notably existing APIs in COM-based systems are not allowed to change, instead new variants have to be introduced, providing a decent amount of backwards-compatibility for applications originally written for older versions of Direct3D.</p>
<p>Metal takes Direct3D's object-oriented approach one step further by combining it with the more "verbal" API design common in Objective-C and Swift in an attempt to provide a <em>more intuitive and easier API</em> for app developers to use (and not just game developers) and to further motivate those to integrate more 3D and general GPU functionality into their apps. This lower barrier of entry was very much the point of earlier Metal versions, which combined the comparatively easier API with extensive graphics debugging capabilities built right into Xcode, providing developers with in-depth insights into every detail of their GPU processing (including built-in debugging of shader code) in the same IDE used for the rest of their application development.</p>
<h2>Part 1.2: Differences In API Design</h2>
<p>All modern APIs share the same concepts and approaches in their designs, which attempt to solve a major design issue of OpenGL and Direct3D:</p>
<ul>
<li>The old APIs took care of a lot of resource management and synchronization for the developer, "hiding" much of the actual complexity involved in preparing the GPU for workloads.</li>
<li>The old APIs presented the GPU as a big state machine (particularly OpenGL) where the developer can change bits and pieces between issuing draw calls.</li>
<li>Due to the possibility to change bits and pieces of a pipeline at will, the old APIs had to check if the current "state" of the API is valid before issuing any work to the GPU, adding considerable overhead to the API "driver".</li>
</ul>
<figure><a href="https://developer.apple.com/videos/play/wwdc2019/611" rel="noopener noreferrer" target="_blank"><img alt="Slide from WWDC 2019 presentation about moving from OpenGL to Metal - example of validation requirements of typical OpenGL state approach" src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/e13d2d364b-1762495292/wwdc_2018_opengl_state.jpg"></a></figure>
<ul>
<li>The new APIs removed most of that and now require developers to manage their resources and synchronization themselves, only providing methods to communicate their intent to the API and thus the GPU.</li>
<li>The new APIs present the GPU as a highly parallelized processing unit that can be issued a list of commands that will be added to a queue and are then picked up by the GPU, "drawing" just being one of many operations.</li>
<li>To avoid having to re-validate the pipeline state before each draw call, pipelines have become immutable objects, whose validity is checked once during their creation, removing the overhead from draw commands using the pipeline, leaving some overhead whenever the pipelines themselves are switched.</li>
</ul>
<figure><a href="https://developer.apple.com/videos/play/wwdc2019/611" rel="noopener noreferrer" target="_blank"><img alt="Slide from WWDC 2019 presentation about moving from OpenGL to Metal - example of Metal variant of the same OpenGL state approach" src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/76531a7abf-1762495292/wwdc_2018_metal_state.jpg"></a></figure>
<p>Of course there are many other differences (large and small) but those are the ones that had the most impact on the attempt to write a "next generation" graphics API backend for OBS Studio. The current renderer is obviously built around the way the old APIs work (particularly Direct3D) and thus makes certain assumptions about the state the APIs will be in at any given point in time. The issue is that those assumptions are not correct as soon as any of those new APIs are used and a lot of the work that the APIs used to do for OBS Studio now <em>has to be taken care of by the application itself</em>.</p>
<p>So a decision had to be made: Either the core renderer can be updated or even rewritten to take care of the responsibilities expected by the modern APIs, adapting more modern "indirect drawing" techniques in Direct3D and OpenGL to make them more compatible with that approach (making <em>those</em> renderers potentially more performant as well), or put this additional work entirely into the backend for one of the new APIs, leaving the core renderer as-is. At least for the Metal backend, the second path was chosen.</p>
<h2>Part 1.3: The Expectations Of OBS Studio's Renderer</h2>
<p>Before the new release, OBS Studio shipped with two graphics APIs: <strong>Direct3D</strong> on Windows and <strong>OpenGL</strong> on Linux and macOS. This is achieved by having a core rendering subsystem that is (for the most part) API-independent and requires an API-specific backend to be loaded at runtime. This backend then implements a generic set of render commands issued by the core renderer and translates those into the actual commands and operations required by its API. That said, the core renderer has <em>some quirks</em> that become apparent once one tries to add support for an API that works <em>slightly</em> different than it might expect:</p>
<ul>
<li>As OBS Studio's shader files are effectively written in an older dialect of Microsoft's <strong>High Level Shader Language (HLSL)</strong>, every shader needs to be analyzed and translated into a valid variant for the modern API at runtime.</li>
<li>Shaders are expected to use the <strong>same data structure as input and output type</strong>, as well as support <strong>global variables</strong>.</li>
<li>The application expects all operations made by the graphics API to be strictly sequential, and to always <strong>execute</strong> operations involving the same resources strictly <strong>in order</strong> of submission to the API.</li>
<li>OBS Studio's texture operations (creating textures from data loaded by the application, updating textures, reading from textures, and more) are directly modelled after Direct3D's API design. Any other API needs to work around this expectation and do housekeeping "behind the scenes" to meet it.</li>
<li>OBS Studio also expects to be able to <strong>render previews</strong> (such as the program view, the main preview, the multi-view, and others) <strong>directly at its own pace</strong> (and framerate), expecting every platform to effectively behave like Windows and provide "swapchains" with the "discard model" used by DXGI, and thus is not decoupled from the render loop for the video output.</li>
</ul>
<figure><img alt="Flowchart presenting the logical relationship between effects files and their shaders." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/1257eb3f4d-1762495292/obs_shader_overview.png"></figure>
<p>Most of these issues either fall into the realm of shaders or the API design itself, all of which had to be overcome by the Metal backend.</p>
<h3>Part 1.3.1: Transpiling Shaders</h3>
<p>OBS Studio makes extensive use of <em>shader programs</em> that run on the GPU to do efficient image processing. Both <code>libobs</code> (OBS Studio's main library that includes the core renderer) as well as plugins like the first-party <code>obs-filters</code> plugin provide their own "effect" files, which are implemented using the HLSL dialect mentioned above.</p>
<p>These effects files contain "techniques", each potentially made of up of a number of render passes (although all current OBS Studio effect files use a single pass) that provide a vertex and fragment shader pair. The vertex shader is the little program a GPU runs for every vertex (a "point" of a triangle) to calculate its actual position in a scene relative to a camera looking at it. The fragment shader (also called "pixel shader" in Direct3D) calculates the actual color value for each fragment (a visible pixel in the output image).</p>
<figure><img alt="Flowchart presenting the steps required to generate a Metal shader string from an OBS effects file." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/53989c4ccf-1762495292/obs_shader_transpile.png"></figure>
<p>To make these files work with OpenGL and Direct3D, they need to be converted into bespoke shader source code for each "technique" first, which OBS Studio achieves through multiple steps:</p>
<ul>
<li>Each effect file is parsed in its entirety and converted <strong>into a data structure</strong> representing each "part" of the effect file:<ul>
<li>The "<em>uniforms</em>", that is data (or a data structure) that is updated by application code at every rendered frame.</li>
<li>The "<em>vertex</em>" or "<em>fragment</em>" data (usually a data struct) that is kept in GPU memory.</li>
<li><em>Texture descriptions</em> (textures can be 1-, 2-, or 3-dimensional) and <em>sampler descriptions</em> (samplers describe how a color value is read from a texture for use in a shader).</li>
<li>The <em>shader functions</em>, including their return type and argument types.</li>
</ul>
</li>
<li>Additionally each technique (and pass(es) within) are parsed into a <strong>nested data structure</strong>:<ul>
<li>OBS Studio will then iterate over every technique and its passes to pick up the names of the vertex and fragment shader functions mentioned in each.</li>
<li>The uniforms, shader data, as well as the texture and sampler descriptions, are shared among each technique within the same file. The created data structures are used to <em>re-create the (partial) HLSL source code</em> that was parsed originally.</li>
<li>The shader functions and their content are then copied and a "main" function is generated (as the entry-point for the shader) calling the actual shader function. The generated <em>final HLSL string</em> is kept as the shader representation of each "technique".</li>
</ul>
</li>
<li>Each technique is sent in its HLSL form to each graphics API and is then <strong>transpiled into its API-specific form</strong>:<ul>
<li>For Direct3D this means replacing text tokens with their more current variants.</li>
<li>For GLSL this means parsing the HLSL string back into structured data <em>again</em>, before iterating over this data and composing a <em>GLSL shader string</em> from it. As shader function code is not analyzed, it needs to be parsed <em>word-for-word</em> and translated into GLSL-specific variants if necessary.</li>
</ul>
</li>
</ul>
<p>Adapting this process for Metal led to a few challenges, born out of the stricter shader language used by the API:</p>
<ul>
<li>MSL is <strong>stricter</strong> around types and semantics:<ul>
<li>Direct3D uses "semantics" to mark parts of shader data structs and give them meaning, like <code>TEXCOORD0</code>, <code>COLOR0</code>, or <code>SV_VertexID</code>, while OpenGL uses global variables that shader code instead reads from or writes into.</li>
<li>Metal uses a <em>similar semantics-based model as Direct3D</em> via attributes, but their use is more strict. Some attributes are allowed for input data, but not for output data.</li>
<li>Thus the same struct definition <em>cannot</em> be used as input and output type definition, instead the single struct type used by HLSL <strong>needs to be split into two separate structs</strong> for MSL.</li>
<li>Every function's content then needs to be scanned for <em>any</em> use of the struct type and needs to be replaced with the appropriate input or output variant.</li>
</ul>
</li>
<li>MSL has <strong>no support for global variables</strong>:<ul>
<li>This means that "<em>uniforms</em>" as used by Direct3D (and set up by OBS Studio's renderer) cannot be used by Metal - uniform data needs to be provided <strong>as a buffer of data in GPU memory</strong>.</li>
<li>This buffer of data can be referenced as an input parameter to a shader function, thus any use of the global variable (used by HLSL and GLSL) needs to be replaced with a use of the function argument.</li>
<li>However any other function called by the "main" shader function also accessing a global variable needs this local variable passed explicitly to it, thus - once again - <em>every function's code needs to be parsed and analyzed</em>.</li>
<li>Any time a function uses a global, it needs to have a new function argument added to its signature to accept the "global" data as an explicit function parameter.</li>
<li>Any time a function <em>calls</em> a function that uses a global, it <em>also</em> needs to have its signature changed to accept the data explicitly and also change the call signature to pass the data along.</li>
</ul>
</li>
</ul>
<p>And these are just two examples of major differences in the shader language that require the transpiler to <strong>almost rewrite every effect file</strong> used by <code>libobs</code>.</p>
<p>Here's a trivial example, OBS Studio's most basic vertex shader that simply multiplies each vertex position with a matrix to calculate the actual coordinates in "clip space" (coordinates that describe the position as a percentage of the width and height of the camera's view):</p>
<pre><code>uniform float4x4 ViewProj;

struct VertInOut {
    float4 pos : POSITION;
    float2 uv : TEXCOORD0;
};

VertInOut VSDefault(VertInOut vert_in)
{
    VertInOut vert_out;
    vert_out.pos = mul(float4(vert_in.pos.xyz, 1.0), ViewProj);
    vert_out.uv  = vert_in.uv;
    return vert_out;
}

VertInOut main(VertInOut vert_in)
{
    return VSDefault(vert_in);
}</code></pre>
<p>In this shader the view projection matrix is provided as a global variable called <code>ViewProj</code> and it's used by the <code>VSDefault</code> shader function. The Metal Shader variant needs to be a bit more explicit about the flow of data:</p>
<pre><code>#include &lt;metal_stdlib&gt;
using namespace metal;

typedef struct {
    float4x4 ViewProj;
} UniformData;

typedef struct {
    float4 pos [[attribute(0)]];
    float2 uv [[attribute(1)]];
} VertInOut_In;

typedef struct {
    float4 pos [[position]];
    float2 uv;
} VertInOut_Out;

VertInOut_Out VSDefault(VertInOut_In vert_in, constant UniformData &amp;uniforms) {
    VertInOut_Out vert_out;
    vert_out.pos = (float4(vert_in.pos.xyz, 1.0)) * (uniforms.ViewProj);
    vert_out.uv  = vert_in.uv;
    return vert_out;
}

[[vertex]] VertInOut_Out _main(VertInOut_In vert_in [[stage_in]], constant UniformData &amp;uniforms [[buffer(30)]]) {
    return VSDefault(vert_in, uniforms);
}</code></pre>
<p>As explained above, the single <code>VertInOut</code> struct had to be split into <em>two separate variants for input and output</em>, as the <code>attribute(n)</code> mapping is only valid for <em>input</em> data. It uses a pattern more common in modern APIs where memory is typically organized in <em>larger heaps</em> into which all other data (buffers, textures, etc.) is placed and referenced. In this case the <code>stage_in</code> decoration allows the developer to access vertex or fragment data for which a vertex descriptor had been set up and is used for convenience. Otherwise the variable would just represent a buffer of GPU memory.</p>
<p>To tell Metal which part of the <em>output</em> structure contains the calculated vertex positions, the corresponding field has to be decorated with <code>[[position]]</code> or return a <code>float4</code> explicitly. Every vertex shader <strong>has</strong> to do one or the other, as it would otherwise fail shader compilation.</p>
<p>The <code>uniform</code> global used by HLSL is transformed into a <em>buffer variable</em>: The uniform data is uploaded into the buffer in slot 30 and referenced by the <code>[[buffer(30)]]</code> decorator and uses the ampersand (<code>&amp;</code>) to make it a C++ reference using the <code>constant</code> address space attribute, which marks this reference to be read-only. The <code>uniforms</code> reference is also passed into the <code>VSDefault</code> function, as the transpiler detected that the function accesses <code>ViewProj</code> within its function body, and thus adds it as an argument to the function signature and converts the reference of <code>ViewProj</code> into the correct form <code>uniforms.ViewProj</code>.</p>
<p>Similar work has to be done for all those cases where GLSL or HLSL will opportunistically accept data with the "wrong" types and alias or convert them into the correct one. Metal does not allow this, the developer <em>has</em> to put any such conversion into code explicitly and also requires any function call to match the function signature. Here is one such example:</p>
<pre><code>float PS_Y(FragPos frag_in)
{
    float3 rgb = image.Load(int3(frag_in.pos.xy, 0)).rgb;
    float y = dot(color_vec0.xyz, rgb) + color_vec0.w;
    return y;
}</code></pre>
<p>In this example the HLSL shader uses the <code>Load</code> function to load color values from a texture and passes in a vector of 3 signed integer values. A valid Metal Shader variant would look like this:</p>
<pre><code>float PS_Y(FragPos frag_in, constant UniformData &amp;uniforms, texture2d&lt;float&gt; image) {
    float3 rgb = image.read(uint2(int2(frag_in.pos.xy)), uint( int( 0))).rgb;
    float y = dot(uniforms.color_vec0.xyz, rgb) + uniforms.color_vec0.w;
    return y;
}</code></pre>
<p>The signature of the corresponding <code>read</code> function in MSL requires a vector of 2 unsigned integer values and a single unsigned integer. Thus the transpiler needs to <strong>detect any (known) invocation of a function that uses type aliasing</strong> or other kinds of type punning and explicitly convert the provided function arguments into the types required by the MSL shader function, in this case converting a single <code>int3</code> into a pair of <code>uint2</code> and <code>uint</code> and ensuring that the data passed into the <code>uint</code> constructor is actually of a specific type that <em>can</em> be converted.</p>
<p>These and many other changes are necessary because MSL is effectively C++14 code and thus requires the same adherence to type safety and function signatures as any other application code written in C++. This allows <strong>sharing header files of data type and structure definitions between application and shader code</strong>, but also requires shader code to be more correct than it had to be for HLSL or GLSL in the past. And in the case of OBS Studio, the transpiler has to partially "rewrite" the HLSL shader code into more compliant MSL code at runtime.</p>
<h3>Part 1.3.2: Pretending To Be Direct3D</h3>
<p>The next hurdle was to simulate the behavior of Direct3D inside the Metal API implementation. As it was deemed infeasible to rewrite the core renderer itself, it must be "kept in the dark" about what actually happens behind the scenes.</p>
<p>One of the main jobs OBS Studio has to do for every video frame is convert images (or "frames") provided by the CPU into textures on the GPU, and - depending on the video encoder used - convert the final output texture back into a frame in CPU memory that can be sent to the encoder. In Direct3D this involves the "mapping" and "unmapping" of a texture:</p>
<ul>
<li>When a texture is "mapped" it is made available for the application code in CPU memory.</li>
<li>When the texture is mapped for writing, Direct3D will provide a pointer to some CPU memory that it has either allocated directly or had been "lying around" from an earlier map operation. OBS Studio can then copy its frame data into the location.</li>
<li>When the texture is mapped for reading, Direct3D will provide a pointer to CPU memory that contains a copy of the texture data from GPU memory. OBS Studio can copy this data into its own "cache" of frames.</li>
<li>When OBS Studio is done with either operation, it has to "unmap" the texture. The provided pointer is then invalidated and any data pointed to it can and will be changed randomly.</li>
</ul>
<p>By itself a naïve implementation of this operation can have severe consequences: When a texture is mapped for writing, any pending GPU operation (e.g., a shader's sampler reading color data from it) might be blocked from being executed as the texture is still being written to. Likewise when a texture is mapped for reading, any pending CPU operation (e.g., copying the frame data into a cache for the video encoder) might have to wait for any GPU operation that currently uses that texture.</p>
<p>As part of its resource tracking behind the scenes, Direct3D 11 <strong>keeps track of texture access operations</strong> and will try to keep any such interruptions to a minimum, which leads specifically to the kind of overhead the modern APIs try to avoid:</p>
<ul>
<li>When a texture is mapped for writing, Direct3D will keep track of the mapping request and provide a pointer to get the data copied into, even while the texture is in use, and schedule a synchronization of the texture data.</li>
<li>Once the texture is <em>unmapped</em>, Direct3D will upload the data to GPU memory and once this has taken place, schedule an update of the texture with the new image data.</li>
<li>If any consecutive draw call that uses the same texture was issued by the application code <em>after</em> the unmapping, Direct3D will implicitly ensure that all pending GPU commands are scheduled and thus the texture update will take place before any consecutive GPU command might access the same texture.</li>
<li>When a texture is mapped for reading, Direct3D will also ensure that all pending GPU commands writing to that texture are executed first to ensure that the copy it will provide will represent the result of any draw commands issued by the application before that.</li>
<li>These are just examples of what <em>might</em> happen, as the specifics are highly dependent on the current state of the pipelines, the internal caches of the API's "driver" and other heuristics.</li>
</ul>
<figure><img alt="Two flowcharts presenting the differences between Direct3D and Metal when updating a texture with new image data." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/158d06d766-1762495292/obs_texture_update_direct3d_vs_metal.png"></figure>
<p>OBS Studio's entire render pipeline is designed around the characteristics of the <code>map</code> and <code>unmap</code> commands in Direct3D 11 and expect any other graphics API to behave in a similar way. Metal (as other modern APIs) <strong>does not do all of this work</strong> (Metal 3 will indeed still do hazard tracking of resources, but developers can opt-out of this behavior, and Metal 4 removed it entirely) and thus the API-specific backend has to simulate the behavior of Direct3D 11 in its own implementation:</p>
<ul>
<li>When a texture is mapped for writing, a GPU buffer is opportunistically <em>set up to hold the image data</em>.</li>
<li>As the Metal backend is only supported on Apple Silicon devices, GPU and CPU share the same memory. This means that a pointer to the buffer's memory can be <em>directly shared with the renderer</em>,</li>
<li>When the texture is "unmapped", a simple block transfer (or blit) operation is scheduled on the GPU to copy the contents of the GPU buffer into the GPU texture. The unmap operation will "wait" until the blit operation has been scheduled on the GPU to prohibit the renderer from issuing any new render commands which would potentially run in parallel.</li>
<li>When a texture is mapped for reading, the same pointer to the GPU buffer is shared with application code. As the buffers are never used by any render command directly, <em>no hazard tracking is necessary</em>. An "unmapping" thus does nothing.</li>
<li>"Staging" a texture for reading thus only requires scheduling a blit from the source texture into its associated staging buffer (as buffers and textures are effectively the same thing and differ only by their API). To ensure that no further render commands are issued by the application, the copy operation is made to wait until it is completed by the GPU, but also has to ensure that if the source texture has any pending render commands, that those are scheduled to be run on the GPU explicitly.</li>
</ul>
<p>The same applies to other operations closely following Direct3D's design: To ensure that the Metal backend reacts in a way that meets the way OBS Studio's renderer expects, it had the <strong>"hidden" functionality of Direct3D implemented explicitly</strong>, particularly the tracking of texture use by prior render commands before any staging takes place.</p>
<h2>Part 1.4: But Wait, There's More (Issues)</h2>
<p>One major reason why the backend is considered "experimental" is due to the way its preview rendering had to be implemented for now. To understand the core reason for those issues, it is important to first understand how OBS Studio expects preview rendering to work, which closely shaped by the way <strong>DXGI (DirectX Graphics Infrastructure)</strong> allows applications to present 3D content on Windows. DXGI swapchains hold a number of buffers with image data created by the application, one of which the application can ask to be <em>"presented" by the operating system</em>.</p>
<p>To avoid an application potentially generating too many frames than can be presented (and thus potentially blocking the application), DXGI swapchains can be set to have a "<em>discard</em>" mode and a <em>synchronization interval of <code>0</code></em>, which effectively allows an application to force the presentation of a back buffer immediately (without waiting for the operating system's own screen refresh interval) and because the contents of the buffer are discarded, it becomes available to be overwritten by the application with the the next frame's data.</p>
<figure><a href="https://learn.microsoft.com/en-us/windows/win32/direct3ddxgi/dxgi-flip-model" rel="noopener noreferrer" target="_blank"><img alt="Microsoft info graphic presenting differences between blt mode and flip mode presentation in DXGI" src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/d71332d150-1762495292/dxgi_swap_chain.png"></a></figure>
<p>Unfortunately this is the <strong>opposite</strong> of how Metal (or more precisely Metal Layers) allows one to render 3D contents into application windows: With the introduction of <em>ProMotion on iPhones and Macbooks</em>, macOS controls the effective frame rates used by devices to provide fluid motion during interaction, but potentially throttle the desktop rendering to single digit framerates when no interaction or updates happen. This allows iOS and macOS to <strong>limit the operating system framerate</strong> (and the framerate of all applications within it) when the device is set to "low power" mode and is thus not designed to be "overruled" by an application (as it would allow such an application to violate the "low power" decision made by the user).</p>
<p>Thus applications cannot just render frames to be presented by the OS at their own pace, instead they <strong>have to ask for a surface to render to</strong> and the number of surfaces an application can be provided with is <strong>limited</strong>. This means that if OBS Studio is running at twice the frame rate of the operating system, it would <em>exhaust its allowance of surfaces to render into</em>. And because OBS Studio renders previews as part of its single render loop, any delay introduced by a preview render operation also stalls or delays the generation of new frames for video encoders.</p>
<p>The solution (at least for this first experimental release) was for OBS Studio to always render into a texture that "pretends" to be the window surface to allow the renderer to finish all its work in its required frame time. Then a different thread (running globally for the entire app with a fixed screen refresh interval) will pick up this texture, request a window surface to render into, and then schedule a block transfer (blit) to copy the contents into the surface. This also requires explicit synchronization of the textures' use on the GPU to ensure that the "pretender" texture is fully rendered to by OBS before the copy to the surface is executed.</p>
<p><strong>In a nutshell:</strong> Whenever the operating system compositor requires a refresh, a <em>separate thread</em> will wait for OBS Studio to render a new frame of the associated preview texture and only once that has happened, the texture data is copied into the surface provided by the compositor. But as the preview rendering is now decoupled from the main render loop, framerate inconsistencies are inevitable. The kernel-level timer provided by the operating system will not align with OBS Studio's render loop (which requires the render thread to be woken up when it's calculated "time for the next frame" has been reached) and thus either a new frame might have been rendered in time or an old frame could not be copied in time.</p>
<p>Starting with macOS 14, the approach suggested by Apple would require OBS Studio to <strong>decouple these intervals even further</strong>, as every window (and thus potentially every preview) will have its own independent timer at which the application will receive a call from the operating system with a surface ready to be rendered into, which would bring a whole new set of potential challenges as it's even further removed from how OBS Studio expects to be able to render previews in the application.</p>
<h2>Part 1.5: The Hidden Costs Of Modern Graphics APIs</h2>
<p>The complexity of the endeavor was high and took <em>several months of research</em>, trial and error, bugfixing, multiple redesigns of specific aspects, and many long weekends. During the course of development it also became clear why some applications that simply switched from OpenGL to Vulkan or Direct3D 11 to Direct3D 12 might have potentially faced <em>worse</em> performance than before, seemingly <em>contradicting those API's promise</em> of improved performance.</p>
<p>Part of the reason is that a lot of the work that had been taken care of the by API's drivers are <strong>now application responsibilities</strong> and thus need to be taken care of by developers themselves. This however requires a more intimate understanding of "how the GPU works" and familiarization with those parts of Direct3D or OpenGL that were purposefully hidden from developers up to this point. And it also requires a more in-depth understanding of how the render commands interact with each other, what their dependencies are, and similarly how to encode and communicate these dependencies to the GPU to ensure that render commands are executed in the right order.</p>
<p>In the case of the Metal backend, this means that a certain amount of overhead that was removed from the API itself had to be <em>reintroduced into the backend again</em>, as even though it would be in a far better position for adoption, the core renderer was not available for a rewrite. Nevertheless even with this overhead, the Metal backend provides multiple benefits:</p>
<ul>
<li>In Release configuration and even in its non-optimized current form, it performs <em>as well or even better</em> as the OpenGL renderer.</li>
<li>In Debug configuration it provides <em>an amazing set of capabilities to analyze render passes</em> in all their detail, including shader debugging, texture lookups, and so much more.</li>
<li>As it's written in Swift, it uses a <em>safer programming language</em> than the OpenGL renderer, one that is at the same time easier and less time consuming to work with.</li>
<li>Because preview rendering is effectively handled separately from the main render loop, <strong>the Metal renderer enables EDR previews on macOS</strong> for high-bitrate video setups.</li>
</ul>
<figure><img alt="Screenshot of Xcode profiling rendered frames by OBS Studio with bound resources view open." src="https://obsproject.com/media/pages/blog/obs-studio-gets-a-new-renderer/5bc601ecae-1762495292/xcode_metal_profiling.jpg"></figure>
<p>As far as maintenance of the macOS version of OBS Studio is concerned, the Metal backend brings considerable benefits as Xcode can now provide insights that haven't been available to developers since the deprecation of OpenGL on all Apple platforms in 2018. But it is due to these complexities that the project would like to extend an invitation to all developers (and users that might be so inclined) to <strong>provide feedback and suggestions for changes to improve the design and implementation</strong> of the Metal backend to first move it out of the "experimental" stage and later make it the default graphics backend on macOS.</p>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pornhub extorted after hackers steal Premium member activity data (106 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/pornhub-extorted-after-hackers-steal-premium-member-activity-data/</link>
            <guid>46304955</guid>
            <pubDate>Wed, 17 Dec 2025 20:18:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/pornhub-extorted-after-hackers-steal-premium-member-activity-data/">https://www.bleepingcomputer.com/news/security/pornhub-extorted-after-hackers-steal-premium-member-activity-data/</a>, See on <a href="https://news.ycombinator.com/item?id=46304955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="PornHub" height="900" src="https://www.bleepstatic.com/content/hl-images/2025/06/05/PornHub.png" width="1600"></p>


<p>Adult video platform PornHub is being extorted by the ShinyHunters extortion gang after the search and watch history of its Premium members was reportedly stolen in a recent Mixpanel data breach.</p>


<p>Last week, PornHub disclosed that it was impacted by a <a href="https://www.bleepingcomputer.com/news/security/openai-discloses-api-customer-data-breach-via-mixpanel-vendor-hack/" target="_blank" rel="nofollow noopener">recent breach at analytics vendor Mixpanel</a>. Mixpanel suffered a breach on November 8th, 2025, after an SMS phishing (smishing) attack enabled threat actors to compromise its systems.</p>


<p>"A recent cybersecurity incident involving Mixpanel, a third-party data analytics provider, has impacted some Pornhub Premium users," reads a <a href="https://help.pornhub.com/hc/en-us/articles/47334442459283-Important-Message-From-Pornhub" target="_blank" rel="nofollow noopener">PornHub security notice</a> posted on Friday.</p>

<p><a href="https://www.bleepingcomputer.com/mgo/72/" rel="nofollow noopener" target="_blank"><img src="https://www.bleepstatic.com/content/webinar-images/Action1-970x250-watch-now.jpg" alt="Wiz"></a>
</p>


<p>"Specifically, this situation affects only select Premium users. It is important to note this was not a breach of Pornhub Premium's systems. Passwords, payment details, and financial information remain secure and were not exposed."</p>


<p>PornHub says it has not worked with Mixpanel since 2021, indicating the stolen records are historical analytics data from 2021 or earlier.</p>


<p>Mixpanel <a href="https://mixpanel.com/blog/sms-security-incident/" target="_blank" rel="nofollow noopener">says the breach affected</a>&nbsp;a "limited number" of customers, with OpenAI and CoinTracker previously disclosing they were affected.</p>


<p>This is the first time it has been publicly confirmed that ShinyHunters was behind the Mixpanel breach.</p>


<p>When contacting PornHub, the company did not provide additional comment to BleepingComputer beyond the security notice.</p>


<p>After publishing our story, Mixpanel told BleepingComputer that it does not believe this data originated from the recent November breach.</p>


<p>"Mixpanel is aware of reports that Pornhub has been extorted with data that that was allegedly stolen from us," Mixpanel told BleepingComputer.</p>


<p>"We can find no indication that this data was stolen from Mixpanel during our November 2025 security Incident or otherwise."</p>


<p>"The data was last accessed by a legitimate employee account at Pornhub’s parent company in 2023. If this data is in the hands of an unauthorized party, we do not believe that is the result of a security incident at Mixpanel."</p>


<h2>PornHub search and watch history exposed</h2>

<p>Today, BleepingComputer learned that ShinyHunters began extorting Mixpanel customers last week, sending emails that began with "We are ShinyHunters" and warned that their stolen data would be published if a ransom was not paid.</p>


<p>In an extortion demand sent to PornHub, ShinyHunters claims it stole 94GB of data containing over 200 million records of personal information in the Mixpanel breach.</p>


<p>ShinyHunters later confirmed to BleepingComputer that they were behind the extortion emails, claiming the data consists of 201,211,943 records of historical search, watch, and download activity for the platform's Premium members.</p>


<p>A small sample of data shared with BleepingComputer shows that the analytic events sent to Mixpanel contain a large amount of sensitive information that a member would not likely want publicly disclosed.</p>


<p>This data includes a PornHub Premium member's email address, activity type, location, video URL, video name, keywords associated with the video, and the time the event occurred.</p>


<p>Activity types seen by BleepingComputer include whether the PornHub subscriber watched or downloaded a video or viewed a channel. However, ShinyHunters also said the events include search histories.</p>


<p>The ShinyHunters extortion group has been behind a string&nbsp;of data breaches this year by compromising various Salesforce integration&nbsp;companies to gain access to Salesforce instances and steal company data.</p>


<p>The threat group is linked to&nbsp;<a href="https://www.bleepingcomputer.com/news/security/oracle-silently-fixes-zero-day-exploit-leaked-by-shinyhunters/" target="_blank" rel="nofollow noopener">the exploitation of the Oracle E-Business Suite zero-day</a> (CVE-2025-61884), as well as&nbsp;<a href="https://www.bleepingcomputer.com/news/security/shinyhunters-claims-15-billion-salesforce-records-stolen-in-drift-hacks/" target="_blank" rel="nofollow noopener">to Salesforce/Drift attacks</a> that impacted a&nbsp;<a href="https://www.bleepingcomputer.com/news/security/shinyhunters-starts-leaking-data-stolen-in-salesforce-attacks/" target="_blank" rel="nofollow noopener">large number of organizations</a> earlier this year.</p>


<p>More recently ShinyHunters <a href="https://www.bleepingcomputer.com/news/security/salesforce-investigates-customer-data-theft-via-gainsight-breach/" target="_blank" rel="nofollow noopener">conducted a breach at GainSight</a> that allowed the threat actors to steal further Salesforce data from organizations.</p>


<p>With it now confirmed that ShinyHunters is also behind the Mixpanel breach, the threat actors are responsible for some of the most significant data breaches in 2025, impacting hundreds of companies.</p>


<p>ShinyHunters is also creating a <a href="https://www.bleepingcomputer.com/news/security/meet-shinysp1d3r-new-ransomware-as-a-service-created-by-shinyhunters/" target="_blank" rel="nofollow noopener">new ransomware-as-a-service called ShinySpid3r,</a> which will serve as a platform for them and threat actors associated with Scattered Spider to conduct ransomware attacks.</p>



	   
<div>
    <p><a href="https://www.tines.com/access/guide/unlocking-it-agility-with-automation-and-orchestration-iam/?utm_source=BleepingComputer&amp;utm_medium=paid_media&amp;utm_content=dec-in-article-banner" target="_blank" rel="noopener sponsored">
            <img src="https://www.bleepstatic.com/c/t/tines/tines-keyhole.jpg" alt="tines"></a>
    </p>
    <div>
        <h2><a href="https://www.tines.com/access/guide/unlocking-it-agility-with-automation-and-orchestration-iam/?utm_source=BleepingComputer&amp;utm_medium=paid_media&amp;utm_content=dec-in-article-banner" target="_blank" rel="noopener sponsored">Break down IAM silos like Bitpanda, KnowBe4, and PathAI </a></h2>
<p>Broken IAM isn't just an IT problem - the impact ripples across your whole business.</p>
<p>This practical guide covers why traditional IAM practices fail to keep up with modern demands, examples of what "good" IAM looks like, and a simple checklist for building a scalable strategy.</p>

        </div>
</div>

           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Doublespeed hacked, revealing what its AI-generated accounts are promoting (193 pts)]]></title>
            <link>https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/</link>
            <guid>46303291</guid>
            <pubDate>Wed, 17 Dec 2025 18:16:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/">https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/</a>, See on <a href="https://news.ycombinator.com/item?id=46303291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>Doublespeed, a startup backed by Andreessen Horowitz (a16z) that uses a phone farm to manage at least hundreds of AI-generated social media accounts and promote products has been hacked. The hack reveals what products the AI-generated accounts are promoting, often without the required disclosure that these are advertisements, and allowed the hacker to take control of&nbsp; more than 1,000 smartphones that power the company.&nbsp;</p><p>The hacker, who asked for anonymity because he feared retaliation from the company, said he reported the vulnerability to Doublespeed on October 31. At the time of writing, the hacker said he still has access to the company’s backend, including the phone farm itself. Doublespeed did not respond to a request for comment.&nbsp;</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How SQLite is tested (231 pts)]]></title>
            <link>https://sqlite.org/testing.html</link>
            <guid>46303277</guid>
            <pubDate>Wed, 17 Dec 2025 18:15:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite.org/testing.html">https://sqlite.org/testing.html</a>, See on <a href="https://news.ycombinator.com/item?id=46303277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>
How SQLite Is Tested
</p>
<details>
<summary>Table Of Contents</summary>

</details>
</div>







<h2 id="introduction"><span>1. </span>Introduction</h2>

<p>The reliability and robustness of SQLite is achieved in part
by thorough and careful testing.</p>

<p>As of <a href="https://sqlite.org/releaselog/3_42_0.html">version 3.42.0</a> (2023-05-16),
the SQLite library consists of approximately
155.8 KSLOC of C code.
(KSLOC means thousands of "Source Lines Of Code" or, in other words,
lines of code excluding blank lines and comments.)
By comparison, the project has
590 times as much
test code and test scripts -
92053.1 KSLOC.</p>

<h2 id="executive_summary"><span>1.1. </span>Executive Summary</h2>

<ul>
<li> Four independently developed test harnesses
</li><li> 100% branch test coverage in an as-deployed configuration
</li><li> Millions and millions of test cases
</li><li> Out-of-memory tests
</li><li> I/O error tests
</li><li> Crash and power loss tests
</li><li> Fuzz tests
</li><li> Boundary value tests
</li><li> Disabled optimization tests
</li><li> Regression tests
</li><li> Malformed database tests
</li><li> Extensive use of assert() and run-time checks
</li><li> Valgrind analysis
</li><li> Undefined behavior checks
</li><li> Checklists
</li></ul>

<h2 id="test_harnesses"><span>2. </span>Test Harnesses</h2>

<p>There are four independent test harnesses used for testing the
core SQLite library.
Each test harness is designed, maintained, and managed separately
from the others.
</p>

<ol>
<li><p>
<a name="tcl"></a>

The <b>TCL Tests</b> are the original tests for SQLite.
They are contained in the same source tree as the
SQLite core and like the SQLite core are in the public domain.  The
TCL tests are the primary tests used during development.
The TCL tests are written using the
<a href="http://www.tcl-lang.org/">TCL scripting language</a>.
The TCL test harness itself consists of 27.2 KSLOC
of C code used to create the TCL interface.  The test scripts are contained
in 1390 files totaling
23.2MB in size.  There are
51445 distinct test cases, but many of the test
cases are parameterized and run multiple times (with different parameters)
so that on a full test run millions of
separate tests are performed.
</p>
</li>

<li><p>
The <b><a href="https://sqlite.org/th3.html">TH3</a></b> test harness is a set of proprietary tests, written in
C that provide 100% branch test coverage
(and <a href="https://sqlite.org/testing.html#mcdc">100% MC/DC test coverage</a>) to
the core SQLite library.  The TH3 tests are designed to run
on embedded and specialized platforms that would not easily support
TCL or other workstation services.  TH3 tests use only the published
SQLite interfaces. TH3 consists of about
76.9 MB or 1055.4 KSLOC
of C code implementing 50362 distinct test cases.
TH3 tests are heavily parameterized, though, so a full-coverage test runs
about 2.4 million different test
instances.
The cases that provide 100% branch test coverage constitute
a subset of the total TH3 test suite.  A soak test
prior to release does about
248.5 million tests.
Additional information on TH3 is <a href="https://sqlite.org/th3.html">available separately</a>.</p></li>

<li><p>
<a name="slt"></a>

The <a href="https://sqlite.org/sqllogictest"><b>SQL Logic Test</b></a>
or SLT test harness is used to run huge numbers
of SQL statements against both SQLite and several other SQL database engines
and verify that they all get the same answers.  SLT currently compares
SQLite against PostgreSQL, MySQL, Microsoft SQL Server, and Oracle 10g.
SLT runs 7.2 million queries comprising
1.12GB of test data.
</p></li>

<li><p>
The <a href="#dbsqlfuzz"><b>dbsqlfuzz</b></a> engine is a
proprietary fuzz tester.  Other <a href="https://sqlite.org/testing.html#fuzztesting">fuzzers for SQLite</a>
mutate either the SQL inputs or the database file.  Dbsqlfuzz mutates
both the SQL and the database file at the same time, and is thus able
to reach new error states.  Dbsqlfuzz is built using the
<a href="http://llvm.org/docs/LibFuzzer.html">libFuzzer</a> framework of LLVM
with a custom mutator.  There are
336 seed files. The dbsqlfuzz fuzzer
runs about one billion test mutations per day.
Dbsqlfuzz helps ensure
that SQLite is robust against attack via malicious SQL or database
inputs.
</p></li></ol>

<p>In addition to the four main test harnesses, there are many other
small programs that implement specialized tests.  Here are a few
examples:
</p><ol>
<li value="5">The "speedtest1.c" program
estimates the performance of SQLite under a typical workload.
</li><li>The "mptester.c" program is a stress test for multiple processes
concurrently reading and writing a single database.
</li><li>The "threadtest3.c" program is a stress test for multiple threads using
SQLite simultaneously.
</li><li>The "fuzzershell.c" program is used to
run some <a href="#fuzztesting">fuzz tests</a>.
</li><li>The "jfuzz" program is a libfuzzer-based fuzzer for
<a href="https://sqlite.org/json1.html#jsonbx">JSONB</a> inputs to the <a href="https://sqlite.org/json1.html">JSON SQL functions</a>.
</li></ol>


<p>All of the tests above must run successfully, on multiple platforms
and under multiple compile-time configurations,
before each release of SQLite.</p>

<p>Prior to each check-in to the SQLite source tree, developers
typically run a subset (called "veryquick") of the Tcl tests
consisting of about
304.7 thousand test cases.
The veryquick tests include most tests other than the anomaly, fuzz, and
soak tests.  The idea behind the veryquick tests are that they are
sufficient to catch most errors, but also run in only a few minutes
instead of a few hours.</p>

<h2 id="anomaly_testing"><span>3. </span>Anomaly Testing</h2>

<p>Anomaly tests are tests designed to verify the correct behavior
of SQLite when something goes wrong.  It is (relatively) easy to build
an SQL database engine that behaves correctly on well-formed inputs
on a fully functional computer.  It is more difficult to build a system
that responds sanely to invalid inputs and continues to function following
system malfunctions.  The anomaly tests are designed to verify the latter
behavior.</p>

<h2 id="out_of_memory_testing"><span>3.1. </span>Out-Of-Memory Testing</h2>

<p>SQLite, like all SQL database engines, makes extensive use of
malloc()  (See the separate report on
<a href="https://sqlite.org/malloc.html">dynamic memory allocation in SQLite</a> for
additional detail.)
On servers and workstations, malloc() never fails in practice and so correct
handling of out-of-memory (OOM) errors is not particularly important.
But on embedded devices, OOM errors are frighteningly common and since
SQLite is frequently used on embedded devices, it is important that
SQLite be able to gracefully handle OOM errors.</p>

<p>OOM testing is accomplished by simulating OOM errors.
SQLite allows an application to substitute an alternative malloc()
implementation using the <a href="https://sqlite.org/c3ref/config.html">sqlite3_config</a>(<a href="https://sqlite.org/c3ref/c_config_covering_index_scan.html#sqliteconfigmalloc">SQLITE_CONFIG_MALLOC</a>,...)
interface.  The TCL and TH3 test harnesses are both capable of
inserting a modified version of malloc() that can be rigged to fail
after a certain number of allocations.  These instrumented mallocs
can be set to fail only once and then start working again, or to
continue failing after the first failure.  OOM tests are done in a
loop.  On the first iteration of the loop, the instrumented malloc
is rigged to fail on the first allocation.  Then some SQLite operation
is carried out and checks are done to make sure SQLite handled the
OOM error correctly.  Then the time-to-failure counter
on the instrumented malloc is increased by one and the test is
repeated.  The loop continues until the entire operation runs to
completion without ever encountering a simulated OOM failure.
Tests like this are run twice, once with the instrumented malloc
set to fail only once, and again with the instrumented malloc set
to fail continuously after the first failure.</p>

<h2 id="i_o_error_testing"><span>3.2. </span>I/O Error Testing</h2>

<p>I/O error testing seeks to verify that SQLite responds sanely
to failed I/O operations.  I/O errors might result from a full disk drive,
malfunctioning disk hardware, network outages when using a network
file system, system configuration or permission changes that occur in the
middle of an SQL operation, or other hardware or operating system
malfunctions.  Whatever the cause, it is important that SQLite be able
to respond correctly to these errors and I/O error testing seeks to
verify that it does.</p>

<p>I/O error testing is similar in concept to OOM testing; I/O errors
are simulated and checks are made to verify that SQLite responds
correctly to the simulated errors.  I/O errors are simulated in both
the TCL and TH3 test harnesses by inserting a new
<a href="https://sqlite.org/c3ref/vfs.html">Virtual File System object</a> that is specially rigged
to simulate an I/O error after a set number of I/O operations.
As with OOM error testing, the I/O error simulators can be set to
fail just once, or to fail continuously after the first failure.
Tests are run in a loop, slowly increasing the point of failure until
the test case runs to completion without error.  The loop is run twice,
once with the I/O error simulator set to simulate only a single failure
and a second time with it set to fail all I/O operations after the first
failure.</p>

<p>In I/O error tests, after the I/O error simulation failure mechanism
is disabled, the database is examined using
<a href="https://sqlite.org/pragma.html#pragma_integrity_check">PRAGMA integrity_check</a> to make sure that the I/O error has not
introduced database corruption.</p>

<h2 id="crash_testing"><span>3.3. </span>Crash Testing</h2>

<p>Crash testing seeks to demonstrate that an SQLite database will not
go corrupt if the application or operating system crashes or if there
is a power failure in the middle of a database update.  A separate
white-paper titled
<a href="https://sqlite.org/atomiccommit.html">Atomic Commit in SQLite</a> describes the
defensive measures SQLite takes to prevent database corruption following
a crash.  Crash tests strive to verify that those defensive measures
are working correctly.</p>

<p>It is impractical to do crash testing using real power failures, of
course, and so crash testing is done in simulation.  An alternative
<a href="https://sqlite.org/c3ref/vfs.html">Virtual File System</a> is inserted that allows the test
harness to simulate the state of the database file following a crash.</p>

<p>In the TCL test harness, the crash simulation is done in a separate
process.  The main testing process spawns a child process which runs
some SQLite operation and randomly crashes somewhere in the middle of
a write operation.  A special <a href="https://sqlite.org/vfs.html">VFS</a> randomly reorders and corrupts
the unsynchronized
write operations to simulate the effect of buffered filesystems.  After
the child dies, the original test process opens and reads the test
database and verifies that the changes attempted by the child either
completed successfully or else were completely rolled back.  The
<a href="https://sqlite.org/pragma.html#pragma_integrity_check">integrity_check</a> <a href="https://sqlite.org/pragma.html#syntax">PRAGMA</a> is used to make sure no database corruption
occurs.</p>

<p>The TH3 test harness needs to run on embedded systems that do not
necessarily have the ability to spawn child processes, so it uses
an in-memory <a href="https://sqlite.org/vfs.html">VFS</a> to simulate crashes.  The in-memory <a href="https://sqlite.org/vfs.html">VFS</a> can be rigged
to make a snapshot of the entire filesystem after a set number of I/O
operations.  Crash tests run in a loop.  On each iteration of the loop,
the point at which a snapshot is made is advanced until the SQLite
operations being tested run to completion without ever hitting a
snapshot.  Within the loop, after the SQLite operation under test has
completed, the filesystem is reverted to the snapshot and random file
damage is introduced that is characteristic of the kinds of damage
one expects to see following a power loss.  Then the database is opened
and checks are made to ensure that it is well-formed and that the
transaction either ran to completion or was completely rolled back.
The interior of the loop is repeated multiple times for each
snapshot with different random damage each time.</p>

<h2 id="compound_failure_tests"><span>3.4. </span>Compound failure tests</h2>

<p>The test suites for SQLite also explore the result of stacking
multiple failures.  For example, tests are run to ensure correct behavior
when an I/O error or OOM fault occurs while trying to recover from a
prior crash.

<a name="fuzztesting"></a>

</p><h2 id="fuzz_testing"><span>4. </span>Fuzz Testing</h2>

<p><a href="http://en.wikipedia.org/wiki/Fuzz_testing">Fuzz testing</a>
seeks to establish that SQLite responds correctly to invalid, out-of-range,
or malformed inputs.</p>

<h2 id="sql_fuzz"><span>4.1. </span>SQL Fuzz</h2>

<p>SQL fuzz testing consists of creating syntactically correct yet
wildly nonsensical SQL statements and feeding them to SQLite to see
what it will do with them.  Usually some kind of error is returned
(such as "no such table").  Sometimes, purely by chance, the SQL
statement also happens to be semantically correct.  In that case, the
resulting prepared statement is run to make sure it gives a reasonable
result.</p>

<h3 id="sql_fuzz_using_the_american_fuzzy_lop_fuzzer"><span>4.1.1. </span>SQL Fuzz Using The American Fuzzy Lop Fuzzer</h3>

<p>The concept of fuzz testing has been around for decades, but fuzz
testing was not an effective way to find bugs until 2014 when
Michal Zalewski invented the first practical profile-guided fuzzer,
<a href="http://lcamtuf.coredump.cx/afl/">American Fuzzy Lop</a> or "AFL".
Unlike prior fuzzers that blindly generate random inputs, AFL
instruments the program being tested (by modifying the assembly-language
output from the C compiler) and uses that instrumentation to detect when
an input causes the program to do something different - to follow
a new control path or loop a different number of times.  Inputs that provoke
new behavior are retained and further mutated.  In this way, AFL is able
to "discover" new behaviors of the program under test, including behaviors
that were never envisioned by the designers.

</p><p>AFL proved adept at finding arcane bugs in SQLite.
Most of the findings have been assert() statements where the conditional
was false under obscure circumstances.  But AFL has also found
a fair number of crash bugs in SQLite, and even a few cases where SQLite
computed incorrect results.

</p><p>Because of its past success, AFL became a standard part of the testing
strategy for SQLite beginning with <a href="https://sqlite.org/releaselog/3_8_10.html">version 3.8.10</a> (2015-05-07) until
it was superseded by better fuzzers in <a href="https://sqlite.org/releaselog/3_29_0.html">version 3.29.0</a> (2019-07-10).

<a name="ossfuzz"></a>

</p><h3 id="google_oss_fuzz"><span>4.1.2. </span>Google OSS Fuzz</h3>

<p>Beginning in 2016, a team of engineers at Google started the
<a href="https://github.com/google/oss-fuzz">OSS Fuzz</a> project.
OSS Fuzz uses a AFL-style guided fuzzer running on Google's infrastructure.
The Fuzzer automatically downloads the latest check-ins for participating
projects, fuzzes them, and sends email to the developers reporting any
problems.  When a fix is checked in, the fuzzer automatically detects this
and emails a confirmation to the developers.

</p><p>SQLite is one of many open-source projects that OSS Fuzz tests. The
<a href="https://sqlite.org/src/file/test/ossfuzz.c">test/ossfuzz.c</a> source file
in the SQLite repository is SQLite's interface to OSS fuzz.

</p><p>OSS Fuzz no longer finds historical bugs in SQLite.  But it is still
running and does occasionally find issues in new development check-ins.
Examples:
<a href="https://sqlite.org/src/timeline?y=ci&amp;c=c422afb507dc8757">[1]</a>
<a href="https://sqlite.org/src/timeline?y=ci&amp;c=0a2eb949f8a759e5">[2]</a>
<a href="https://sqlite.org/src/timeline?y=ci&amp;c=62f2235adf796c72">[3]</a>.

<a name="dbsqlfuzz"></a>

</p><h3 id="the_dbsqlfuzz_and_jfuzz_fuzzers"><span>4.1.3. </span>The dbsqlfuzz and jfuzz fuzzers</h3>

<p>Beginning in late 2018, SQLite has been fuzzed using a proprietary
fuzzer called "dbsqlfuzz".  Dbsqlfuzz is built using the
<a href="http://llvm.org/docs/LibFuzzer.html">libFuzzer</a> framework of LLVM.

</p><p>The dbsqlfuzz fuzzer mutates both the SQL input and the database file
at the same time.  Dbsqlfuzz uses a custom
<a href="https://github.com/google/fuzzing/blob/master/docs/structure-aware-fuzzing.md">Structure-Aware Mutator</a>
on a specialized input file that defines both an input database and SQL
text to be run against that database. Because it mutates both the input
database and the input SQL at the same time, dbsqlfuzz has been able to
find some obscure faults in SQLite that were missed by prior fuzzers that
mutated only SQL inputs or only the database file.
The SQLite developers keep dbsqlfuzz running against trunk in about
16 cores at all times.  Each instance of dbsqlfuzz program is able to
evalutes about 400 test cases per second, meaning that about 500 million
cases are checked every day.</p>

<p>The dbsqlfuzz fuzzer has been very successful at hardening the
SQLite code base against malicious attack.  Since dbsqlfuzz has been
added to the SQLite internal test suite, bug reports from external
fuzzers such as OSSFuzz have all but stopped.

</p><p>Note that dbsqlfuzz is <i>not</i> the Protobuf-based structure-aware
fuzzer for SQLite that is used by Chromium and described in the
<a href="https://github.com/google/fuzzing/blob/master/docs/structure-aware-fuzzing.md#user-content-example-sqlite">Structure-Aware Mutator article</a>.
There is no connection between these two fuzzers, other than the fact that they
are both based on <a href="http://llvm.org/docs/LibFuzzer.html">libFuzzer</a>
The Protobuf fuzzer for SQLite is written and maintained by the Chromium
team at Google, whereas dbsqlfuzz is written and maintained by the original
SQLite developers.  Having multiple independently-developed fuzzers for SQLite
is good, as it means that obscure issues are more likely to be uncovered.

</p><p>Near the end of January 2024, a second libFuzzer-based tool called
"jfuzz" came into use.  Jfuzz generates corrupt <a href="https://sqlite.org/json1.html#jsonbx">JSONB</a> blobs and feeds
them into the <a href="https://sqlite.org/json1.html">JSON SQL functions</a> to verify that the JSON functions
are able to safely and efficiently deal with corrupt binary inputs.


<a name="3pfuzz"></a>

</p><h3 id="other_third_party_fuzzers"><span>4.1.4. </span>Other third-party fuzzers</h3>

<p>SQLite seems to be a popular target for third-parties to fuzz.
The developers hear about many attempts to fuzz SQLite
and they do occasionally get bug reports found by independent
fuzzers.  All such reports are promptly fixed, so the product is
improved and that the entire SQLite user community benefits.
This mechanism of having many independent testers is similar to
<a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus's law</a>:
"given enough eyeballs, all bugs are shallow".

</p><p>One fuzzing researcher of particular note is
<a href="https://www.manuelrigger.at/">Manuel Rigger</a>.
Most fuzzers only look for assertion faults, crashes, undefined behavior (UB),
or other easily detected anomalies.  Dr. Rigger's fuzzers, on the other hand,
are able to find cases where SQLite computes an incorrect answer.
Rigger has found
<a href="https://sqlite.org/src/timeline?y=t&amp;u=mrigger&amp;n=all">many such cases</a>.
Most of these finds are obscure corner cases involving type
conversions and affinity transformations, and a good number of the finds
are against unreleased features.  Nevertheless, his finds are still important
as they are real bugs,
and the SQLite developers are grateful to be able to identify and fix
the underlying problems.

<a name="fuzzcheck"></a>

</p><h3 id="the_fuzzcheck_test_harness"><span>4.1.5. </span>The fuzzcheck test harness</h3>

<p>Historical test cases from <a href="https://sqlite.org/testing.html#aflfuzz">AFL</a>, <a href="https://sqlite.org/testing.html#ossfuzz">OSS Fuzz</a>, and <a href="https://sqlite.org/testing.html#dbsqlfuzz">dbsqlfuzz</a> are
collected in a set of database files in the main SQLite source tree
and then rerun by the "fuzzcheck" utility program whenever one runs
"make test".  Fuzzcheck only runs a few thousand "interesting" cases
out of the billions of cases that the various fuzzers have
examined over the years.  "Interesting" cases are cases that exhibit
previously unseen behavior.  Actual bugs found by fuzzers are always
included among the interesting test cases, but most of the cases run
by fuzzcheck were never actual bugs.

<a name="tension"></a>

</p><h3 id="tension_between_fuzz_testing_and_100_mc_dc_testing"><span>4.1.6. </span>Tension Between Fuzz Testing And 100% MC/DC Testing</h3>

<p>Fuzz testing and <a href="https://sqlite.org/testing.html#mcdc">100% MC/DC testing</a> are in tension with
one another.
That is to say, code tested to 100% MC/DC will tend to be
more vulnerable to problems found by fuzzing and code that performs
well during fuzz testing will tend to have (much) less than
100% MC/DC.
This is because MC/DC testing discourages <a href="https://sqlite.org/testing.html#defcode">defensive code</a> with
unreachable branches, but without defensive code, a fuzzer is
more likely to find a path that causes problems.  MC/DC testing
seems to work well for building code that is robust during
normal use, whereas fuzz testing is good for building code that is
robust against malicious attack.

</p><p>Of course, users would prefer code that is both robust in normal
use and resistant to malicious attack.  The SQLite developers are
dedicated to providing that.  The purpose of this section is merely
to point out that doing both at the same time is difficult.

</p><p>For much of its history SQLite has been focused on 100% MC/DC testing.
Resistance to fuzzing attacks only became a concern with the introduction
of AFL in 2014.  For a while there, fuzzers were finding many problems
in SQLite.  In more recent years, the testing strategy of SQLite has
evolved to place more emphasis on fuzz testing.  We still maintain
100% MC/DC of the core SQLite code, but most testing CPU cycles are
now devoted to fuzzing.

</p><p>While fuzz testing and 100% MC/DC testing are in tension, they
are not completely at cross-purposes.  The fact that the SQlite test
suite does test to 100% MC/DC means that when fuzzers do find problems,
those problems can be fixed quickly and with little risk of introducing
new errors.

</p><h2 id="malformed_database_files"><span>4.2. </span>Malformed Database Files</h2>

<p>There are numerous test cases that verify that SQLite is able to
deal with malformed database files.
These tests first build a well-formed database file, then add
corruption by changing one or more bytes in the file by some means
other than SQLite.  Then SQLite is used to read the database.
In some cases, the bytes changes are in the middle of data.
This causes the content of the database to change while keeping the
database well-formed.
In other cases, unused bytes of the file are modified, which has
no effect on the integrity of the database.
The interesting cases are when bytes of the file that
define database structure get changed.  The malformed database tests
verify that SQLite finds the file format errors and reports them
using the <a href="https://sqlite.org/rescode.html#corrupt">SQLITE_CORRUPT</a> return code without overflowing
buffers, dereferencing NULL pointers, or performing other
unwholesome actions.</p>

<p>The <a href="https://sqlite.org/testing.html#dbsqlfuzz">dbsqlfuzz</a> fuzzer also does an excellent job of verifying
that SQLite responds sanely to malformed database files.</p>

<h2 id="boundary_value_tests"><span>4.3. </span>Boundary Value Tests</h2>

<p>SQLite defines certain <a href="https://sqlite.org/limits.html">limits</a> on its operation, such as the
maximum number of columns in a table, the maximum length of an
SQL statement, or the maximum value of an integer.  The TCL and TH3 test
suites both contains numerous tests that push SQLite right to the edge
of its defined limits and verify that it performs correctly for
all allowed values.  Additional tests go beyond the defined limits
and verify that SQLite correctly returns errors.  The source code
contains <a href="https://sqlite.org/testing.html#testcase">testcase macros</a> to verify that both sides of each boundary
have been tested.</p>

<h2 id="regression_testing"><span>5. </span>Regression Testing</h2>

<p>Whenever a bug is reported against SQLite, that bug is not considered
fixed until new test cases that would exhibit the bug have been added
to either the TCL or TH3 test suites.
Over the years,
this has resulted in thousands and thousands of new tests.
These regression tests ensure that bugs that have
been fixed in the past are not reintroduced into future versions of
SQLite.</p>

<h2 id="automatic_resource_leak_detection"><span>6. </span>Automatic Resource Leak Detection</h2>

<p>Resource leak occurs when system resources
are allocated and never freed.  The most troublesome resource leaks
in many applications are memory leaks - when memory is allocated using
malloc() but never released using free().  But other kinds of resources
can also be leaked:  file descriptors, threads, mutexes, etc.</p>

<p>Both the TCL and TH3 test harnesses automatically track system
resources and report resource leaks on <u>every</u> test run.
No special configuration or setup is required.   The test harnesses
are especially vigilant with regard to memory leaks.  If a change
causes a memory leak, the test harnesses will recognize this
quickly.  SQLite is designed to never leak memory, even after
an exception such as an OOM error or disk I/O error.  The test
harnesses are zealous to enforce this.</p>

<h2 id="test_coverage"><span>7. </span>Test Coverage</h2>

<p>The SQLite core, including the unix <a href="https://sqlite.org/vfs.html">VFS</a>,
has 100% branch test coverage under <a href="https://sqlite.org/th3.html">TH3</a> in
its default configuration as measured by
<a href="http://gcc.gnu.org/onlinedocs/gcc/Gcov.html">gcov</a>.
Extensions such as FTS3 and RTree are excluded from this
analysis.</p>

<h2 id="statement_versus_branch_coverage"><span>7.1. </span>Statement versus branch coverage</h2>

<p>There are many ways to measure test coverage.  The most popular
metric is "statement coverage".  When you hear someone say that their
program as "XX% test coverage" without further explanation, they usually
mean statement coverage.  Statement coverage measures what percentage
of lines of code are executed at least once by the test suite.</p>

<p>Branch coverage is more rigorous than statement coverage.  Branch
coverage measures the number of machine-code branch instructions that
are evaluated at least once on both directions.</p>

<p>To illustrate the difference between statement coverage and
branch coverage, consider the following hypothetical
line of C code:</p>

<div><pre>if( a&gt;b &amp;&amp; c!=25 ){ d++; }
</pre></div>

<p>Such a line of C code might generate a dozen separate machine code
instructions.  If any one of those instructions is ever evaluated, then
we say that the statement has been tested.  So, for example, it might
be the case that the conditional expression is
always false and the "d" variable is
never incremented.  Even so, statement coverage counts this line of
code as having been tested.</p>

<p>Branch coverage is more strict.  With branch coverage, each test and
each subblock within the statement is considered separately.  In order
to achieve 100% branch coverage in the example above, there must be at
least three test cases:</p>

<ul>
<li> a&lt;=b
</li><li> a&gt;b &amp;&amp; c==25
</li><li> a&gt;b &amp;&amp; c!=25
</li></ul>

<p>Any one of the above test cases would provide 100% statement coverage
but all three are required for 100% branch coverage.  Generally speaking,
100% branch coverage implies 100% statement coverage, but the converse is
not true.  To reemphasize, the
<a href="https://sqlite.org/th3.html">TH3</a> test harness for SQLite provides the stronger form of
test coverage - 100% branch test coverage.</p>

<h2 id="coverage_testing_of_defensive_code"><span>7.2. </span>Coverage testing of defensive code</h2>

<p>A well-written C program will typically contain some defensive
conditionals which in practice are always true or always false.
This leads to a
programming dilemma:  Does one remove defensive code in order to obtain
100% branch coverage?</p>

<p>In SQLite, the answer to the previous question is "no".
For testing purposes, the SQLite source code defines
macros called ALWAYS() and NEVER().   The ALWAYS() macro
surrounds conditions
which are expected to always evaluate as true and NEVER() surrounds
conditions that are always evaluated to false.  These macros serve as
comments to indicate that the conditions are defensive code.
In release builds, these macros are pass-throughs:</p>

<div><pre>#define ALWAYS(X)  (X)
#define NEVER(X)   (X)
</pre></div>

<p>During most testing, however, these macros will throw an assertion
fault if their argument does not have the expected truth value.  This
alerts the developers quickly to incorrect design assumptions.

</p><div><pre>#define ALWAYS(X)  ((X)?1:assert(0),0)
#define NEVER(X)   ((X)?assert(0),1:0)
</pre></div>

<p>When measuring test coverage, these macros are defined to be constant
truth values so that they do not generate assembly language branch
instructions, and hence do not come into play when calculating the
branch coverage:</p>

<div><pre>#define ALWAYS(X)  (1)
#define NEVER(X)   (0)
</pre></div>

<p>The test suite is designed to be run three times, once for each of
the ALWAYS() and NEVER() definitions shown above.  All three test runs
should yield exactly the same result.  There is a run-time test using
the <a href="https://sqlite.org/c3ref/test_control.html">sqlite3_test_control</a>(<a href="https://sqlite.org/c3ref/c_testctrl_always.html">SQLITE_TESTCTRL_ALWAYS</a>, ...) interface that
can be used to verify that the macros are correctly set to the first
form (the pass-through form) for deployment.</p>

<h2 id="forcing_coverage_of_boundary_values_and_boolean_vector_tests"><span>7.3. </span>Forcing coverage of boundary values and boolean vector tests</h2>

<p>Another macro used in conjunction with test coverage measurement is
the <tt>testcase()</tt> macro.  The argument is a condition for which
we want test cases that evaluate to both true and false.
In non-coverage builds (that is to say, in release builds) the
<tt>testcase()</tt> macro is a no-op:</p>



<p>But in a coverage measuring build, the <tt>testcase()</tt> macro
generates code that evaluates the conditional expression in its argument.
Then during analysis, a check
is made to ensure tests exist that evaluate the conditional to both true
and false.  <tt>Testcase()</tt> macros are used, for example, to help verify
that boundary values are tested.  For example:</p>

<div><pre>testcase( a==b );
testcase( a==b+1 );
if( a&gt;b &amp;&amp; c!=25 ){ d++; }
</pre></div>

<p>Testcase macros are also used when two or more cases of a switch
statement go to the same block of code, to make sure that the code was
reached for all cases:</p>

<div><pre>switch( op ){
  case OP_Add:
  case OP_Subtract: {
    testcase( op==OP_Add );
    testcase( op==OP_Subtract );
    /* ... */
    break;
  }
  /* ... */
}
</pre></div>

<p>For bitmask tests, <tt>testcase()</tt> macros are used to verify that every
bit of the bitmask affects the outcome.  For example, in the following block
of code, the condition is true if the mask contains either of two bits
indicating either a MAIN_DB or a TEMP_DB is being opened.
The <tt>testcase()</tt>
macros that precede the if statement verify that both cases are tested:</p>

<div><pre>testcase( mask &amp; SQLITE_OPEN_MAIN_DB );
testcase( mask &amp; SQLITE_OPEN_TEMP_DB );
if( (mask &amp; (SQLITE_OPEN_MAIN_DB|SQLITE_OPEN_TEMP_DB))!=0 ){ ... }
</pre></div>

<p>The SQLite source code contains 1184
uses of the <tt>testcase()</tt> macro.</p>

<h2 id="branch_coverage_versus_mc_dc"><span>7.4. </span>Branch coverage versus MC/DC</h2>

<p>Two methods of measuring test coverage were described above:
"statement" and "branch" coverage.  There are many other test coverage
metrics besides these two.  Another popular metric is "Modified
Condition/Decision Coverage" or MC/DC.
<a href="http://en.wikipedia.org/wiki/Modified_Condition/Decision_Coverage">Wikipedia</a>
defines MC/DC as follows:</p>

<ul>
<li> Each decision tries every possible outcome.
</li><li> Each condition in a decision takes on every possible outcome.
</li><li> Each entry and exit point is invoked.
</li><li> Each condition in a decision is shown to independently
     affect the outcome of the decision.
</li></ul>

<p>In the C programming language
where <b><tt>&amp;&amp;</tt></b> and <b><tt>||</tt></b>
are "short-circuit" operators, MC/DC and branch coverage are very nearly
the same thing.  The primary difference is in boolean vector tests.
One can test for any of several bits in bit-vector and still obtain
100% branch test coverage even though the second element of MC/DC - the
requirement that each condition in a decision take on every possible outcome -
might not be satisfied.</p>

<p>SQLite uses <tt>testcase()</tt> macros as described in the previous
subsection to make sure that every condition in a bit-vector decision takes
on every possible outcome.  In this way, SQLite also achieves 100% MC/DC
in addition to 100% branch coverage.</p>

<h2 id="measuring_branch_coverage"><span>7.5. </span>Measuring branch coverage</h2>

<p>Branch coverage in SQLite is currently measured
using <a href="https://gcc.gnu.org/onlinedocs/gcc/Gcov.html">gcov</a> with the "-b"
option.  First the test program is compiled using options
"-g -fprofile-arcs -ftest-coverage" and then the test program is run.
Then "gcov -b" is run to generate a coverage report.
The coverage report is verbose and inconvenient to read,
so the gcov-generated report is processed using
some simple scripts to put it into a more human-friendly format.
This entire process is automated using scripts, of course.

</p><p>Note that running SQLite with gcov is not a test of SQLite —
it is a test of the test suite.  The gcov run does not test SQLite because
the -fprofile-args and -ftest-coverage options cause the compiler to
generate different code.
The gcov run merely verifies that the test suite provides 100% branch test
coverage.  The gcov run is a test of the test - a meta-test.

</p><p>After gcov has been run to verify 100% branch test coverage,
then the test program is recompiled using delivery compiler options
(without the special -fprofile-arcs and -ftest-coverage options)
and the test program is rerun.
This second run is the actual test of SQLite.

</p><p>It is important to verify that the gcov test run
and the second real test run both give the same output.  Any
differences in output indicate either the use of undefined or
indeterminate behavior in the SQLite code (and hence a bug),
or a bug in the compiler.
Note that SQLite has, over the previous decade, encountered bugs
in each of GCC, Clang, and MSVC.  Compiler bugs, while rare, do happen,
which is why it is so important to test the code in an as-delivered
configuration.

<a name="mutationtests"></a>

</p><h2 id="mutation_testing"><span>7.6. </span>Mutation testing</h2>

<p>Using gcov (or similar) to show that every branch instruction is taken
at least once in both directions is a good measure of test suite quality.
But even better is showing that every branch instruction makes
a difference in the output.  In other words, we want to show
not only that every branch instruction both jumps and falls through but also
that every branch is doing useful work and that the test suite is able
to detect and verify that work.  When a branch is found that does not
make a difference in the output, that suggests that code associated with
the branch can be removed (reducing the size of the library and perhaps
making it run faster) or that the test suite is inadequately testing the
feature that the branch implements.

</p><p>SQLite strives to verify that every branch instruction makes a difference
using <a href="https://en.wikipedia.org/wiki/Mutation_testing">mutation testing</a>.
<a href="https://sqlite.org/th3.html#muttest">A script</a>
first compiles the SQLite source code into assembly language
(using, for example, the -S option to gcc).  Then the script steps through
the generated assembly language and, one by one, changes each branch
instruction into either an unconditional jump or a no-op, compiles the
result, and verifies that the test suite catches the mutation.

</p><p>
Unfortunately, SQLite contains many branch instructions that
help the code run faster without changing the output.
Such branches generate false-positives during mutation testing.
As an example, consider the following
<a href="https://sqlite.org/src/artifact/55b5fb474?ln=55-62">hash function</a>
used to accelerate table-name lookup:

</p><div><pre>55  static unsigned int strHash(const char *z){
56    unsigned int h = 0;
57    unsigned char c;
58    while( (c = (unsigned char)*z++)!=0 ){     /*OPTIMIZATION-IF-TRUE*/
59      h = (h&lt;&lt;3) ^ h ^ sqlite3UpperToLower[c];
60    }
61    return h;
62  }
</pre></div>

<p>
If the branch instruction that implements the "c!=0" test on line 58
is changed into a no-op, then the while-loop will loop forever and the
test suite will fail with a time-out.  But if that branch is changed
into an unconditional jump, then the hash function will always return 0.
The problem is that 0 is a valid hash.  A hash function that always
returns 0 still works in the sense that SQLite still always gets the correct
answer.  The table-name hash table degenerates into a linked-list
and so the table-name lookups that occur while parsing SQL statements
might be a little slower, but the end result will be the same.

</p><p>
To work around this problem, comments of the form
"<code>/*OPTIMIZATION-IF-TRUE*/</code>" and
"<code>/*OPTIMIZATION-IF-FALSE*/</code>" are inserted into the SQLite
source code to tell the mutation testing script to ignore some branch
instructions.

<a name="thoughts1"></a>

</p><h2 id="experience_with_full_test_coverage"><span>7.7. </span>Experience with full test coverage</h2>

<p>The developers of SQLite have found that full coverage testing is an
extremely effective method for locating and preventing bugs.
Because every single branch
instruction in SQLite core code is covered by test cases, the developers
can be confident that changes made in one part of the code
do not have unintended consequences in other parts of the code.
The many new features and performance improvements that have been
added to SQLite in recent years would not have been possible without
the availability of full-coverage testing.</p>

<p>Maintaining 100% MC/DC is laborious and time-consuming.
The level of effort needed to maintain full-coverage testing
is probably not cost effective for a typical application.
However, we think that full-coverage testing is justified for a
<a href="https://sqlite.org/mostdeployed.html">very widely deployed</a> infrastructure library
like SQLite, and especially for a database library which by its very
nature "remembers" past mistakes.


<a name="dynamicanalysis"></a>

</p><h2 id="dynamic_analysis"><span>8. </span>Dynamic Analysis</h2>

<p>Dynamic analysis refers to internal and external checks on the
SQLite code which are performed while the code is live and running.
Dynamic analysis has proven to be a great help in maintaining the
quality of SQLite.</p>

<h2 id="assert"><span>8.1. </span>Assert</h2>

<p>The SQLite core contains 6754 <tt>assert()</tt>
statements that verify function preconditions and postconditions and
loop invariants.  Assert() is a macro which is a standard part of
ANSI-C.  The argument is a boolean value that is assumed to always be
true.  If the assertion is false, the program prints an error message
and halts.</p>

<p>Assert() macros are disabled by compiling with the NDEBUG macro defined.
In most systems, asserts are enabled by default.  But in SQLite, the
asserts are so numerous and are in such performance critical places, that
the database engine runs about three times slower when asserts are enabled.
Hence, the default (production) build of SQLite disables asserts.
Assert statements are only enabled when SQLite is compiled with the
SQLITE_DEBUG preprocessor macro defined.</p>

<p>See the <a href="https://sqlite.org/assert.html">Use Of assert in SQLite</a> document
for additional information about how SQLite uses assert().</p>

<h2 id="valgrind"><span>8.2. </span>Valgrind</h2>

<p><a href="http://valgrind.org/">Valgrind</a> is perhaps the most amazing
and useful developer tool in the world.  Valgrind is a simulator - it simulates
an x86 running a Linux binary.  (Ports of Valgrind for platforms other
than Linux are in development, but as of this writing, Valgrind only
works reliably on Linux, which in the opinion of the SQLite developers
means that Linux should be the preferred platform for all software development.)
As Valgrind runs a Linux binary, it looks for all kinds of interesting
errors such as array overruns, reading from uninitialized memory,
stack overflows, memory leaks, and so forth.  Valgrind finds problems
that can easily slip through all of the other tests run against SQLite.
And, when Valgrind does find an error, it can dump the developer directly
into a symbolic debugger at the exact point where the error occurs, to
facilitate a quick fix.</p>

<p>Because it is a simulator, running a binary in Valgrind is slower than
running it on native hardware.  (To a first approximation, an application
running in Valgrind on a workstation will perform about the same as it
would running natively on a smartphone.)  So it is impractical to run the full
SQLite test suite through Valgrind.  However, the veryquick tests and
the coverage of the TH3 tests are run through Valgrind prior to every
release.</p>

<h2 id="memsys2"><span>8.3. </span>Memsys2</h2>

<p>SQLite contains a pluggable
<a href="https://sqlite.org/malloc.html">memory allocation subsystem</a>.
The default implementation uses system malloc() and free().
However, if SQLite is compiled with <a href="https://sqlite.org/compile.html#memdebug">SQLITE_MEMDEBUG</a>, an alternative
memory allocation wrapper (<a href="https://sqlite.org/malloc.html#memdebug">memsys2</a>)
is inserted that looks for memory allocation
errors at run-time.  The memsys2 wrapper checks for memory leaks, of
course, but also looks for buffer overruns, uses of uninitialized memory,
and attempts to use memory after it has been freed.  These same checks
are also done by valgrind (and, indeed, Valgrind does them better)
but memsys2 has the advantage of being much faster than Valgrind, which
means the checks can be done more often and for longer tests.</p>

<h2 id="mutex_asserts"><span>8.4. </span>Mutex Asserts</h2>

<p>SQLite contains a pluggable mutex subsystem.  Depending on
compile-time options, the default mutex system contains interfaces
<a href="https://sqlite.org/c3ref/mutex_held.html">sqlite3_mutex_held()</a> and <a href="https://sqlite.org/c3ref/mutex_held.html">sqlite3_mutex_notheld()</a> that detect
whether or not a particular mutex is held by the calling thread.
These two interfaces are used extensively within assert() statements
in SQLite to verify mutexes are held and released at all the right
moments, in order to double-check that SQLite does work correctly
in multi-threaded applications.</p>

<h2 id="journal_tests"><span>8.5. </span>Journal Tests</h2>

<p>One of the things that SQLite does to ensure that transactions
are atomic across system crashes and power failures is to write
all changes into the rollback journal file prior to changing the
database.  The TCL test harness contains an alternative
<a href="https://sqlite.org/vfs.html">OS backend</a> implementation that helps to
verify this is occurring correctly.  The "journal-test VFS" monitors
all disk I/O traffic between the database file and rollback journal,
checking to make sure that nothing is written into the database
file which has not first been written and synced to the rollback journal.
If any discrepancies are found, an assertion fault is raised.</p>

<p>The journal tests are an additional double-check over and above
the crash tests to make sure that SQLite transactions will be atomic
across system crashes and power failures.</p>

<h2 id="undefined_behavior_checks"><span>8.6. </span>Undefined Behavior Checks</h2>

<p>In the C programming language, it is very easy to write code that
has "undefined" or "implementation defined" behavior.
That means that the code might work during development, but then give
a different answer on a different system, or when recompiled using different
compiler options.
Examples of undefined and implementation-defined behavior in
ANSI C include:
</p><ul>
<li>Signed integer overflow.  (Signed integer overflow does <u>not</u>
necessarily wrap around, as most people expect.)
</li><li>Shifting an N-bit integer by more than N bits.
</li><li>Shifting by a negative amount.
</li><li>Shifting a negative number.
</li><li>Using the memcpy() function on overlapping buffers.
</li><li>The order of evaluation of function arguments.
</li><li>Whether or not "char" variables are signed or unsigned.
</li><li>And so forth....
</li></ul>

<p>Since undefined and implementation-defined behavior is non-portable
and can easily lead to incorrect answers, SQLite works very hard to avoid it.
For example,
when adding two integer column values together as part of an SQL statement,
SQLite does not simply add them together using the C-language "+" operator.
Instead, it first checks to make sure the
addition will not overflow, and if it will, it does the addition using
floating point instead.

</p><p>To help ensure that SQLite does not make use of undefined or
implementation defined behavior, the test suites are rerun using
instrumented builds that try to detect undefined behavior.  For example,
test suites are run using the "-ftrapv" option of GCC.  And they
are run again using the "-fsanitize=undefined" option on Clang.  And
again using the "/RTC1" option in MSVC.  Then the test suites are rerun
using options like "-funsigned-char" and "-fsigned-char" to make sure
that implementation differences do not matter either.  Tests are then repeated
on 32-bit and 64-bit systems and on big-endian and little-endian systems,
using a variety of CPU architectures.
Furthermore, the test suites are augmented with many test cases that are
deliberately designed to provoke undefined behavior.  For example:
"<b>SELECT -1*(-9223372036854775808);</b>".

<a name="disopttest"></a>

</p><h2 id="disabled_optimization_tests"><span>9. </span>Disabled Optimization Tests</h2>

<p>The <a href="https://sqlite.org/c3ref/test_control.html">sqlite3_test_control</a>(<a href="https://sqlite.org/c3ref/c_testctrl_always.html">SQLITE_TESTCTRL_OPTIMIZATIONS</a>, ...) interface
allows selected SQL statement optimizations to be disabled at run-time.
SQLite should always generate exactly the same answer with optimizations
enabled and with optimizations disabled; the answer simply arrives quicker
with the optimizations turned on.  So in a production environment, one always
leaves the optimizations turned on (the default setting).</p>

<p>One verification technique used on SQLite is to run an entire test suite
twice, once with optimizations left on and a second time with optimizations
turned off, and verify that the same output is obtained both times.  This
shows that the optimizations do not introduce errors.</p>

<p>Not all test cases can be handled this way.  Some test cases check
to verify that the optimizations really are reducing the amount of
computation by counting the number of disk accesses, sort operations,
full-scan steps, or other processing steps that occur during queries.
Those test cases will appear to fail when optimizations are disabled.
But the majority of test cases simply check that the correct answer
was obtained, and all of those cases can be run successfully with and
without the optimizations, in order to show that the optimizations do not
cause malfunctions.</p>


<h2 id="checklists"><span>10. </span>Checklists</h2>

<p>The SQLite developers use an on-line checklist to coordinate testing
activity and to verify that all tests pass prior to each SQLite release.
<a href="https://sqlite.org/checklists/index.html">Past checklists</a>
are retained for historical reference.
(The checklists are read-only for anonymous internet viewers, but
developers can log in and update checklist items in their web
browsers.)
The use of checklists for SQLite testing and other development activities
is inspired by <i>
<a href="http://atulgawande.com/book/the-checklist-manifesto/">The Checklist Manifesto</a>
</i>.</p>

<p>The latest checklists contain approximately 200 items that are
individually verified for each release.  Some checklist items only take
a few seconds to verify and mark off.  Others involve test suites
that run for many hours.</p>

<p>The release checklist is not automated: developers run each item on
the checklist manually.  We find that it is important to keep a human in
the loop.  Sometimes problems are found while running a checklist item
even though the test itself passed.  It is important to have a human
reviewing the test output at the highest level, and constantly asking
"Is this really right?"</p>

<p>The release checklist is continuously evolving.  As new problems or
potential problems are discovered, new checklist items are added to
make sure those problems do not appear in subsequent releases.  The
release checklist has proven to be an invaluable tool in helping to
ensure that nothing is overlooked during the release process.</p>


<h2 id="static_analysis"><span>11. </span>Static Analysis</h2>

<p>Static analysis means analyzing source code at compile-time to
check for correctness.  Static analysis includes compiler
warning messages and more in-depth analysis engines such as the
<a href="http://clang-analyzer.llvm.org/">Clang Static Analyzer</a>.
SQLite compiles without warnings on GCC and Clang using
the -Wall and -Wextra flags on Linux and Mac and on MSVC on Windows.
No valid warnings are generated by the Clang Static Analyzer tool "scan-build"
either (though recent versions of clang seem to generate many false-positives.)
Nevertheless, some warnings might be generated by other
static analyzers.  Users are encouraged not to stress over these
warnings and to instead take solace in the intense testing of SQLite
described above.
</p>

<p>Static analysis has not been helpful in finding
bugs in SQLite.  Static analysis has found a few bugs in SQLite, but
those are the exceptions.  More bugs have been
introduced into SQLite while trying to get it to compile without
warnings than have been found by static analysis.</p>

<h2 id="summary"><span>12. </span>Summary</h2>

<p>SQLite is open source.  This gives many people the idea that
it is not well tested as commercial software and is perhaps unreliable.
But that impression is false.
SQLite has exhibited very high reliability in the field and
a very low defect rate, especially considering how rapidly it is evolving.
The quality of SQLite is achieved in part by careful code design and
implementation.  But extensive testing also plays a vital role in
maintaining and improving the quality of SQLite.  This document has
summarized the testing procedures that every release of SQLite undergoes
with the hope of inspiring confidence that SQLite is
suitable for use in mission-critical applications.</p>
<p><small><i>This page was last updated on 2025-05-31 13:08:22Z </i></small></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC chair suggests agency isn't independent, word cut from mission statement (140 pts)]]></title>
            <link>https://www.axios.com/2025/12/17/brendan-carr-fcc-independent-senate-testimony-website</link>
            <guid>46303260</guid>
            <pubDate>Wed, 17 Dec 2025 18:14:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2025/12/17/brendan-carr-fcc-independent-senate-testimony-website">https://www.axios.com/2025/12/17/brendan-carr-fcc-independent-senate-testimony-website</a>, See on <a href="https://news.ycombinator.com/item?id=46303260">Hacker News</a></p>
Couldn't get https://www.axios.com/2025/12/17/brendan-carr-fcc-independent-senate-testimony-website: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Kernel Rust Code Sees Its First CVE Vulnerability (101 pts)]]></title>
            <link>https://www.phoronix.com/news/First-Linux-Rust-CVE</link>
            <guid>46302621</guid>
            <pubDate>Wed, 17 Dec 2025 17:30:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/First-Linux-Rust-CVE">https://www.phoronix.com/news/First-Linux-Rust-CVE</a>, See on <a href="https://news.ycombinator.com/item?id=46302621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="LINUX KERNEL" src="https://www.phoronix.com/assets/categories/linuxkernel.webp" width="100" height="100"></p><p>
The first CVE vulnerability has been assigned to a piece of the Linux kernel's Rust code.
</p><p>
Greg Kroah-Hartman <a href="https://social.kernel.org/notice/B1JLrtkxEBazCPQHDM">announced</a> that the first CVE has been assigned to a piece of Rust code within the mainline Linux kernel.
</p><p>
This first CVE for Rust code in the Linux kernel pertains to <a href="https://www.phoronix.com/news/Rust-Binder-For-Linux-6.18">the Android Binder rewrite in Rust</a>. There is a race condition that can occur due to some noted unsafe Rust code. That code can lead to memory corruption of the previous/next pointers and in turn cause a crash.
</p><p>
This CVE for the possible system crash is for Linux 6.18 and newer since the introduction of the Rust Binder driver. At least though it's just a possible system crash and not any more serious system compromise with remote code execution or other more severe issues.
</p><p>
More details on CVE-2025-68260 via the <a href="https://lore.kernel.org/linux-cve-announce/2025121614-CVE-2025-68260-558d@gregkh/T/#u">Linux CVE mailing list</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Safer Container Ecosystem with Docker: Free Docker Hardened Images (278 pts)]]></title>
            <link>https://www.docker.com/blog/docker-hardened-images-for-every-developer/</link>
            <guid>46302337</guid>
            <pubDate>Wed, 17 Dec 2025 17:13:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.docker.com/blog/docker-hardened-images-for-every-developer/">https://www.docker.com/blog/docker-hardened-images-for-every-developer/</a>, See on <a href="https://news.ycombinator.com/item?id=46302337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Containers are the universal path to production for most developers, and Docker has always been the steward of the ecosystem. Docker Hub has over 20 billion monthly pulls, with nearly 90% of organizations now relying on containers in their software delivery workflows. That gives us a responsibility: to help secure the software supply chain for the world.</p>



<p>Why? Supply-chain attacks are exploding. In 2025, they caused more than $60 billion in damage, tripling from 2021. No one is safe. Every language, every ecosystem, every build and distribution step is a target.&nbsp;</p>



<p>For this reason, we launched Docker Hardened Images (DHI), a secure, minimal, production-ready set of images, in May 2025, and since then have hardened over 1,000 images and helm charts in our catalog. Today, we are establishing a new industry standard by making DHI freely available and open source to everyone who builds software. All 26 Million+ developers in the container ecosystem. DHI is fully open and free to use, share, and build on with no licensing surprises, backed by an Apache 2.0 license. DHI now gives the world a secure, minimal, production-ready foundation from the very first pull.</p>



<p>If it sounds too good to be true, here’s the bottom line up front: every developer and every application can (and should!) use DHI without restrictions. When you need continuous security patching, applied in under 7 days, images for regulated industries (e.g., FIPS, FedRAMP), you want to build customized images on our secure build infrastructure, or you need security patches beyond end-of-life, DHI has commercial offerings. Simple.</p>



<p>Since the introduction of DHI, enterprises like Adobe and Qualcomm have bet on Docker for securing their entire enterprise to achieve the most stringent levels of compliance, while startups like Attentive and Octopus Deploy have accelerated their ability to get compliance and sell to larger businesses.</p>



<p>Now everyone and every application can build securely from the first <span><code>docker build</code></span>. Unlike other opaque or proprietary hardened images, DHI is compatible with Alpine and Debian, trusted and familiar open source foundations teams already know and can adopt with minimal change. And while some vendors suppress CVEs in their feed to maintain a green scanner, Docker is <em>always </em>transparent, even when we’re still working on patches, because we fundamentally believe you should always know what your security posture is. The result: dramatically reduced CVEs (guaranteed near zero in DHI Enterprise), images up to 95 percent smaller, and secure defaults without ever compromising transparency or trust.</p>



<p>There’s more. We’ve already built Hardened Helm Charts to leverage DHI images in Kubernetes environments; those are open source too. And today, we’re expanding that foundation with Hardened MCP Servers. We’re bringing DHI’s security principles to the MCP interface layer, the backbone of every agentic app. And starting now, you can run hardened versions of the MCP servers developers rely on most: Mongo, Grafana, GitHub, and more. And this is just the beginning. In the coming months, we will extend this hardened foundation across the entire software stack with hardened libraries, hardened system packages, and other secure components everyone depends on. The goal is simple: be able to secure your application from <code><span>main()</span></code> down.&nbsp;</p>







<h2><br><strong>The philosophy of Docker Hardened Images</strong></h2>



<p>Base images define your application’s security from the very first layer, so it’s critical to know exactly what goes into them. Here’s how we approach it.</p>



<p>First: total transparency in every part of our minimal, opinionated, secure images.</p>



<p>DHI uses a distroless runtime to shrink the attack surface while keeping the tools developers rely on. But security is more than minimalism; it requires full transparency. Too many vendors blur the truth with proprietary CVE scoring, downgraded vulnerabilities, or vague promises about reaching SLSA Build Level 3.</p>



<p>DHI takes a different path. Every image includes a complete and verifiable SBOM. Every build provides SLSA Build Level 3 provenance. Every vulnerability is assessed using transparent public CVE data; we won’t hide vulnerabilities when we haven’t fixed them. Every image comes with proof of authenticity. The result: a secure foundation you can trust, built with clarity, verified with evidence, and delivered without compromise.</p>



<p>Second: Migrating to secure images takes real work, and no one should pretend otherwise. But as you’d expect from Docker, we’ve focused on making the DX incredibly easy to use. As we mentioned before, DHI is built on the open source foundations the world already trusts, Debian and Alpine, so teams can adopt it with minimal friction.&nbsp; We’re reducing that friction even more: <a href="https://docs.docker.com/dhi/migration/migrate-with-ai/" id="dkr_dockers-ai-assistant-84109" rel="nofollow noopener" target="_blank">Docker’s AI assistant</a> can scan your existing containers and recommend or even apply equivalent hardened images; the feature is experimental as this is day one, but we’ll quickly GA it as we learn from real world migrations.&nbsp;</p>



<p>Lastly: we think about the most aggressive SLAs and longest support times and make certain that every piece of DHI can support that when you need it.</p>



<p>DHI Enterprise, the commercial offering of DHI, includes a 7-day commitment for critical CVE remediation, with a roadmap toward one day or less. For regulated industries and mission-critical systems, this level of trust is mandatory. Achieving it is hard. It demands deep test automation and the ability to maintain patches that diverge from upstream until they are accepted. That is why most organizations cannot do this on their own. In addition, DHI Enterprise allows organizations to easily customize DHI images, leveraging Docker’s build infrastructure which takes care of the full image lifecycle management for you, ensuring that build provenance and compliance is maintained. For example, typically organizations need to add certificates and keys, system packages, scripts, and so on. DHI’s build service makes this trivial.</p>



<p>Because our patching SLAs and our build service carry real operational cost, DHI has historically been one commercial offering. But our vision has always been broader. This level of security should be available to everyone, and the timing matters. Now that the evidence, infrastructure, and industry partnerships are in place, we are delivering on that vision. That is why today we are making Docker Hardened Images free and open source.</p>



<p>This move carries the same spirit that defined Docker Official Images over a decade ago. We made them free, kept them free, and backed them with clear docs, best practices, and consistent maintenance. That foundation became the starting point for millions of developers and partners.</p>



<p>Now we’re doing it again. DHI being free is powered by a rapidly growing ecosystem of partners, from Google, MongoDB, and the CNCF delivering hardened images to security platforms like Snyk and JFrog Xray integrating DHI directly into their scanners. Together, we are building a unified, end-to-end supply chain that raises the security bar for the entire industry.<strong><br></strong></p>




<div>
        <h4>“Docker’s move to make its hardened images freely available under Apache 2.0 underscores its strong commitment to the open source ecosystem. Many CNCF projects can already be found in the DHI catalog, and giving the broader community access to secure, well-maintained building blocks helps us strengthen the software supply chain together. It’s exciting to see Docker continue to invest in open collaboration and secure container infrastructure.”</h4>
                                    <div>
                                        <p>Jonathan Bryce</p>
                    <p>Executive Director at the Cloud Native Computing Foundation</p>
                </div>
                        </div>



<div>
        <h4>“Software supply chain attacks are a severe industry problem. Making Docker Hardened Images free and pervasive should underpin faster, more secure software delivery across the industry by making the right thing the easy thing for developers.”</h4>
                                    <div>
                                        <p>James Governor</p>
                    <p>Analyst and Co-founder, RedMonk</p>
                </div>
                        </div>



<div>
        <h4>“Security shouldn’t be a premium feature. By making hardened images free, Docker is letting every developer, not just big enterprises, start with a safer foundation. We love seeing tools that reduce noise and toil, and we’re ready to run these secure workloads on Google Cloud from day one”</h4>
                                    <div>
                                        <p>Ryan J. Salva</p>
                    <p>Senior Director of Product at Google, Developer Experiences</p>
                </div>
                        </div>



<div>
        <h4>“At MongoDB, we believe open source plays a central role in how modern software is built, enabling flexibility, choice, and developer productivity. That’s why we’re excited about free Docker Hardened Images for MongoDB. These images provide trusted, ready-to-deploy building blocks on proven Linux foundations such as Alpine and Debian, and with an Apache 2.0 license, they remain fully open source and free for anyone to use. With Docker Hub’s global reach and MongoDB’s commitment to reliability and safety, we are making it easier to build with confidence on a secure and open foundation for the future”</h4>
                                    <div>
                                        <p>Jim Scharf</p>
                    <p>Chief Technology Officer, MongoDB</p>
                </div>
                        </div>



<div>
        <h4>“We’re excited to partner with Docker to deliver secure, enterprise-grade AI workloads from development to production. With over 50 million users and the majority of Fortune 500 trusting Anaconda to help them operate at enterprise scale securely, this partnership with Docker brings that same foundation to Docker Hardened Images. This enables teams to spend less time managing risk and more time innovating, while reducing the time from idea to production.”</h4>
                                    <div>
                                        <p>David DeSanto</p>
                    <p>Chief Executive Officer, Anaconda</p>
                </div>
                        </div>



<div>
        <h4>“Socket stops malicious packages at install time, and Docker Hardened Images (DHI) give those packages a trustworthy place to run. With free DHI, teams get both layers of protection without lifting a finger. Pull a hardened image, run npm install, and the Socket firewall embedded in the DHI is already working for you. That is what true secure-by-default should look like, and we’re excited to partner with Docker and make it happen at their scale.”</h4>
                                    <div>
                                        <p>Feross Aboukhadijeh</p>
                    <p>Founder and CEO, Socket</p>
                </div>
                        </div>



<div>
        <h4>“Teams building with Temporal orchestrate mission-critical workflows, and Docker is how they deploy those services in production. Making Docker Hardened Images freely available gives our users a very strong foundation for those workflows from day one, and Extended Lifecycle Support helps them keep long running systems secure without constant replatforming.”</h4>
                                    <div>
                                        <p>Maxim Fateev</p>
                    <p>Chief Technology Officer, Temporal</p>
                </div>
                        </div>



<div>
        <h4>“At CircleCI, we know teams need to validate code as fast as they can generate it—and that starts with a trusted foundation. Docker Hardened Images eliminate a critical validation bottleneck by providing pre-secured, continuously verified components right from the start, helping teams ship fast, with confidence.”</h4>
                                    <div>
                                        <p>Rob Zuber</p>
                    <p>Chief Technology Officer, CircleCI</p>
                </div>
                        </div>



<div>
        <h4>“We evaluated multiple options for hardened base images and chose Docker Hardened Images (DHI) for its alignment with our supply chain security posture, developer tooling compatibility, Docker’s maturity in this space, and integration with our existing infrastructure. Our focus was on balancing trust, maintainability, and ecosystem compatibility.”</h4>
                                    <div>
                                        <p>Vikram Sethi</p>
                    <p>Principal Scientist, Adobe</p>
                </div>
                        </div>



<div>
        <h4>“Developers deserve secure foundations that do not slow them down. By making Docker Hardened Images freely available, Docker is making it easier than ever to secure the software supply chain at the source. This helps eliminate risk before anything touches production, a mission shared by LocalStack. At LocalStack, we are especially excited that developers will be able to use these hardened, minimal images for our emulators, helping teams finally break free from constant CVE firefighting.”</h4>
                                    <div>
                                        <p>Waldemar Hummer</p>
                    <p>Co-Founder and CTO at LocalStack</p>
                </div>
                        </div>


<h2><strong>A Secure Path for Every Team and Business</strong></h2>



<p>Everyone now has a secure foundation to start from with DHI. But businesses of all shapes and sizes often need more. Compliance requirements and risk tolerance may demand CVE patches ahead of upstream the moment the source becomes available. Companies operating in enterprise or government sectors must meet strict standards such as FIPS or STIG. And because production can never stop, many organizations need security patching to continue even after upstream support ends.</p>



<p>That is why we now offer three DHI options, each built for a different security reality.</p>



<p><strong>Docker Hardened Images: </strong>Free for Everyone. DHI is the foundation modern software deserves: minimal hardened images, easy migration, full transparency, and an open ecosystem built on Alpine and Debian.</p>



<p><strong>Docker Hardened Images (DHI) Enterprise: </strong>DHI Enterprise delivers the guarantees that organizations, governments, and institutions with strict security or regulatory demands rely on. FIPS-enabled and STIG-ready images. Compliance with CIS benchmarks. SLA-backed remediations they can trust for critical CVEs in under 7 days. And those SLAs keep getting shorter as we push toward one-day (or less) critical fixes.</p>



<p>For teams that need more control, DHI Enterprise delivers. Change your images. Configure runtimes. Install tools like curl. Add certificates. DHI Enterprise gives you unlimited customization, full catalog access, and the ability to shape your images on your terms while staying secure.</p>



<p><strong>DHI Extended Lifecycle Support (ELS):</strong> ELS is a paid add-on to DHI Enterprise, built to solve one of software’s hardest problems. When upstream support ends, patches stop but vulnerabilities don’t. Scanners light up, auditors demand answers, and compliance frameworks expect verified fixes. ELS ends that cycle with up to five additional years of security coverage, continuous CVE patches, updated SBOMs and provenance, and ongoing signing and auditability for compliance.</p>



<p>You can learn more about these options <a href="https://www.docker.com/products/hardened-images/" id="dkr_here-84109">here</a>.</p>



<h2><strong>Here’s how to get started</strong></h2>



<p>Securing the container ecosystem is something we do together. Today, we’re giving the world a stronger foundation to build on. Now we want every developer, every open source project, every software vendor, and every platform to make Docker Hardened Images the default.</p>



<ul>
<li>Join our launch <a href="https://www.docker.com/events/dhi-els-launch-webinar/">webinar</a> to get hands-on and learn what’s new.</li>



<li><a href="https://hub.docker.com/hardened-images/catalog" rel="nofollow noopener" target="_blank">Start using</a> Docker Hardened Images today for free.</li>



<li><a href="https://docs.docker.com/dhi/get-started/" rel="nofollow noopener" target="_blank">Explore the docs</a> and bring DHI into your workflows&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li>



<li>Join our <a href="https://docker.com/dhi-partners-sign-up/" rel="nofollow noopener" target="_blank">partner program</a> and help raise the security bar for everyone. &nbsp; &nbsp;</li>
</ul>



<p>Lastly, we are just getting started, and if you’re reading this and want to help build the future of container security, we’d love to meet you. <a href="https://www.docker.com/careers/" id="dkr_join-us-84109">Join us.</a></p>



<h2><strong>Authors’ Notes</strong></h2>



<h3><strong>Christian Dupuis</strong></h3>



<p>Today’s announcement marks a watershed moment for our industry. Docker is fundamentally changing how applications are built-secure by default for every developer, every organization, and every open-source project.&nbsp;</p>



<p>This moment fills me with pride as it represents the culmination of years of work: from the early days at Atomist building an event-driven SBOM and vulnerability management system, the foundation that still underpins Docker Scout today, to unveiling DHI earlier this year, and now making it freely available to all. I am deeply grateful to my incredible colleagues and friends at Docker who made this vision a reality, and to our partners and customers who believed in us from day one and shaped this journey with their guidance and feedback.</p>



<p>Yet while this is an important milestone, it remains just that, a milestone. We are far from done, with many more innovations on the horizon. In fact, we are already working on what comes next.</p>



<p>Security is a team sport, and today Docker opened the field to everyone. Let’s play.</p>



<h3><strong>Michael Donovan</strong></h3>



<p>I joined Docker to positively impact as many developers as possible. This launch gives every developer the right to secure their applications without adding toil to their workload. It represents a monumental shift in the container ecosystem and the digital experiences we use every day.</p>



<p>I’m extremely proud of the product we’ve built and the customers we serve every day. I’ve had the time of my life building this with our stellar team and I’m more excited than ever for what’s to come next.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas' (757 pts)]]></title>
            <link>https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers</link>
            <guid>46302267</guid>
            <pubDate>Wed, 17 Dec 2025 17:08:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers">https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers</a>, See on <a href="https://news.ycombinator.com/item?id=46302267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div cta-rich-text="" fs-toc-element="contents" fs-toc-offsettop="1.5rem"><figure><p><img src="https://cdn.prod.website-files.com/6660a5bfdcf6c5fbf039f446/69428e2d7c764c046536a548_AWS%20CEO%20Junior%20Developers%20AI.jpg" loading="lazy" alt="AWS CEO Junior Developers AI"></p></figure><p>‍</p><p><strong>AWS CEO Matt Garman outlined 3 solid reasons why companies should not focus on cutting junior developer roles, noting that they “<em>are actually the most experienced with the AI tools</em>”.</strong></p><h2><strong>3 Reasons AI Should Not Replace Junior Developers</strong></h2><p>In a tech world obsessed with AI replacing human workers, Matt Garman, CEO of Amazon Web Services (AWS), is pushing back against one of the industry’s most popular cost-cutting ideas.</p><p>Speaking on <a href="https://www.wired.com/story/the-big-interview-podcast-matt-garman-ceo-aws/" target="_blank" rel="nofollow"><em>WIRED’s The Big Interview</em> podcast</a>, Garman has a bold message for companies racing to cut costs with AI.</p><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/6660a5bfdcf6c5fbf039f446/69428e63cef065d3e9f62638_Matt%20Garman%20on%20Junior%20Developers.jpg" loading="lazy" alt="Matt Garman on Junior Developers"></p></figure><p>‍</p><p>He was asked to explain why he once called replacing junior employees with AI “<a href="https://www.finalroundai.com/blog/aws-ceo-matt-garman-says-replacing-junior-developers-with-ai-the-dumbest-thing"><em>one of the dumbest ideas</em></a>” he’d ever heard, and to expand on how he believes agentic AI will actually change the workplace in the coming years.</p><h3><strong>1) Junior Devs Often Know AI Tools Better</strong></h3><p><strong>First, junior employees are often better with AI tools than senior staff.</strong>&nbsp;</p><blockquote><em>“Number one, my experience is that many of the most junior folks are actually the most experienced with the AI tools. So they're actually most able to get the most out of them.”</em></blockquote><p>‍</p><p>Fresh grads have grown up with new technology, so they can adapt quickly. Many of them learn AI-powered tools while studying or during internships. They tend to explore new features, find quick methods to write code, and figure out how to get the best results from AI agents.&nbsp;</p><p>According to the <a href="https://survey.stackoverflow.co/2025/ai?utm_source=chatgpt.com#sentiment-and-usage-ai-sel-prof-exp" target="_blank" rel="nofollow">2025 Stack Overflow Developer Survey</a>, 55.5% of early-career developers reported using AI tools daily in their development process, higher than for the experienced folks.</p><p>This comfort with new tools allows them to work more efficiently. In contrast, senior developers have established workflows and may take more time to adopt. <a href="https://www.peoplemanagement.co.uk/article/1930418/half-gen-z-help-senior-colleagues-upskill-ai-study-finds" target="_blank" rel="nofollow">Recent research</a> shows that over half of Gen Z employees are actually helping senior colleagues upskill in AI.</p><h3><strong>2) Junior Developers Shouldn’t Be The Default Cost-Saving Move</strong></h3><p><strong>Second, junior staff are usually the least expensive employees.</strong></p><blockquote><em>“Number two, they're usually the least expensive because they're right out of college, and they generally make less. So if you're thinking about cost optimization, they're not the only people you would want to optimize around.”</em></blockquote><p>‍</p><p>Junior employees usually get much less in salary and benefits, so removing them does not deliver huge savings. If a company is trying to save money, it doesn’t make that much financial sense.&nbsp;</p><p>So, when companies talk about increasing profit margins, junior employees should not be the default or only target. True optimization, Real cost-cutting means looking at the whole company because there are plenty of other places where expenses can be trimmed.</p><p>In fact, 30% of companies that laid off workers expecting savings <a href="https://myabcm.com/layoffs-the-cost-cutting-measure-that-could-sink-your-company" target="_blank" rel="nofollow">ended up increasing expenses</a>, and many had to rehire later.&nbsp;</p><h3><strong>3) Removing Juniors Breaks the Talent Pipeline</strong></h3><p><strong>Third, companies need fresh talent.</strong></p><blockquote><em>“Three, at some point, that whole thing explodes on itself. If you have no talent pipeline that you're building and no junior people that you're mentoring and bringing up through the company, we often find that that's where we get some of the best ideas.”</em></blockquote><p>‍</p><p>Think of a company like a sports team. If you only keep veteran players and never recruit rookies, what happens when those veterans retire? You are left with no one who knows how to play the game.</p><p>Also, hiring people straight out of college brings new ways of thinking into the workplace. They have fresh ideas shaped by the latest trends, motivation to innovate.&nbsp;</p><p>More importantly, they form the foundation of a company’s future workforce. If a company decides to stop hiring junior employees altogether, it cuts off its own talent pipeline. Over time, that leads to fewer leaders to promote from within.</p><p>A <a href="https://www.deloitte.com/us/en/insights/topics/talent/overcoming-the-tech-talent-shortage-amid-transformation.html" target="_blank" rel="nofollow">Deloitte report</a> also notes that the tech workforce is expected to grow at roughly twice the rate of the overall U.S. workforce, highlighting the demand for tech talent. Without a strong pipeline of junior developers coming in, companies might face a tech talent shortage.&nbsp;</p><p>When there are not enough junior hires being trained today, teams struggle to fill roles tomorrow, especially as projects scale.</p><h2><strong>Bottom Line</strong></h2><p>This isn’t just corporate talk. As the leader of one of the world’s largest cloud computing platforms, serving everyone from Netflix to the U.S. intelligence agencies, Garman has a front-row seat to how companies are actually using AI.&nbsp;</p><p>And what he is seeing makes him worried that short-term thinking could damage businesses for years to come. Garman’s point is grounded in long-term strategy. A company that relies solely on AI to handle tasks without training new talent could find itself short of people.</p><p>Still, Garman admits the next few years will be bumpy. “Y<em>our job is going to change</em>,” he said. He believes AI will make companies more productive as well as the employees.&nbsp;</p><p>When technology makes something easier, people want more of it. AI enables the creation of software faster, allowing companies to develop more products, enter new markets, and serve more customers.</p><p>Developers will be responsible for more than just writing code, with faster adaptation to new technologies becoming essential. But he has a hopeful message in the end.</p><p>That’s why Geoffrey Hinton has advised that <a href="https://www.finalroundai.com/blog/ai-godfather-geoffrey-hinton-mid-level-coding-jobs">Computer Science degrees remain essential</a>. This directly supports Matt Garman’s point. Fresh talent with a strong understanding of core fundamentals becomes crucial for filling these higher-value roles of the future.</p><p>“<strong><em>I’m very confident in the medium to longer term that AI will definitely create more jobs than it removes at first,</em></strong>” Garman said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox is becoming an AI browser and the internet is not at all happy about it (123 pts)]]></title>
            <link>https://www.pcgamer.com/hardware/firefox-is-becoming-an-ai-browser-and-the-internet-is-not-at-all-happy-about-it/</link>
            <guid>46302114</guid>
            <pubDate>Wed, 17 Dec 2025 17:00:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/hardware/firefox-is-becoming-an-ai-browser-and-the-internet-is-not-at-all-happy-about-it/">https://www.pcgamer.com/hardware/firefox-is-becoming-an-ai-browser-and-the-internet-is-not-at-all-happy-about-it/</a>, See on <a href="https://news.ycombinator.com/item?id=46302114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">

<p id="313b7cb0-b065-46f1-aec5-90dc12fb1d13">There's no such thing as bad publicity, they say. Mozilla must be clinging to that aphorism for dear life right now, what with the internet meltdown that met its <a data-analytics-id="inline-link" href="https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/" target="_blank" data-url="https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">announcement that Firefox is to become an AI browser</a> over the next three years.</p><p>Mozilla's new CEO, Anthony Enzor-DeMeo, is putting AI up front and centre. "Firefox will remain our anchor. It will evolve into a modern AI browser and support a portfolio of new and trusted software additions," he says.</p><p id="313b7cb0-b065-46f1-aec5-90dc12fb1d13-2">In mitigation, Enzor-DeMeo also says that the AI element in Firefox will be optional. "First: Every product we build must give people agency in how it works. Privacy, data use, and AI must be clear and understandable. Controls must be simple. AI should always be a choice — something people can easily turn off," Enzor-DeMeo explains.</p><p>While Mozilla says that the transition to AI will be a three-year process, it's also clear that they don't plan to hang about. "We will move with urgency. AI is changing software. Browsers are becoming the control point for digital life. Regulation is shifting defaults. These shifts play to Mozilla’s strengths," Enzor-DeMeo goes on.</p><figure data-bordeaux-image-check="" id="702d6e5c-510b-43b3-913f-fb8a1b06828d"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg.png" alt="Chrome with Gemini" srcset="https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/tV42kficuogTpnECrw3YEg.png">
</picture></p></div><figcaption itemprop="caption description"><span>Google has rolled out Gemini for Chrome in the US already... </span><span itemprop="copyrightHolder">(Image credit: Google)</span></figcaption></figure><p id="14cfb1ea-677e-4b72-8c3c-3693af745da3">Over on X, it's a similar story, <a data-analytics-id="inline-link" href="https://x.com/datnofact/status/2001019286731776078" target="_blank" data-url="https://x.com/datnofact/status/2001019286731776078" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">with one user commenting</a> (via <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/mozilla-says-firefox-will-evolve-into-an-ai-browser-and-nobody-is-happy-about-it-ive-never-seen-a-company-so-astoundingly-out-of-touch" target="_blank" data-url="https://www.windowscentral.com/software-apps/mozilla-says-firefox-will-evolve-into-an-ai-browser-and-nobody-is-happy-about-it-ive-never-seen-a-company-so-astoundingly-out-of-touch" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">Windows Central</a>), "I've never seen a company so astoundingly out of touch with the people who want to use its software."</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-8Gim4re55Y8TbMqBAchcEC"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div><p>Mozilla's new CEO obviously doesn't agree. "Firefox will reach new audiences," he says, "our portfolio will strengthen our independence. Our approach to building trusted software will set a high standard for the industry."</p><p>Personally, I can see both sides of this. Admittedly, my heart sinks at the mere mention of AI, of late. But can the likes of Mozilla totally sit the AI revolution out? That seems unlikely.</p><p>Perhaps the role organisations like Mozilla can play is to implement AI in more considered, controlled way, instead of spewing it everywhere in a crazed hope to cash in. For now, then, the jury should surely be out on this move. Let's wait and see exactly how Mozilla plays AI, no?</p><div id="slice-container-person-8Gim4re55Y8TbMqBAchcEC-BL0rdMgmMDb5kGblD53JiCJ9Ta1Dp4Ht"><figure data-bordeaux-image-check="false"><div><picture data-hydrate="false"><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W-140-80.jpg.webp 140w" sizes="99vw" data-normal="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-nopin="true" data-slice-image="true"><source type="image/jpeg" srcset="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W-140-80.jpg 140w" sizes="99vw" data-normal="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-nopin="true" data-slice-image="true"><img src="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" alt="AMD Ryzen 9 9800X3D processor" srcset="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W-140-80.jpg 140w" sizes="99vw" loading="lazy" data-normal="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5ryUJb6snbbQMdpHJu7i8W.jpg" data-pin-nopin="true" data-slice-image="true"></picture></div></figure></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: HN Was Down (486 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46301921</link>
            <guid>46301921</guid>
            <pubDate>Wed, 17 Dec 2025 16:48:18 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46301921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46302176"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302176" href="https://news.ycombinator.com/vote?id=46302176&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Is this still a valid account for HN status? It says it’s the official one, but with the changes at Twitter to no longer show chronological feeds (at least for users that aren’t logged in), it’s rather useless. The top 5 listed post (for me) are seemingly random from 2014 - 2022.</p><p><a href="https://x.com/HNStatus" rel="nofollow">https://x.com/HNStatus</a></p><p>Is there a better place to check, beyond a basic down detector that may provide more insight or signal that the outage is acknowledged?</p></div></td></tr></tbody></table></td></tr><tr id="46302580"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302580" href="https://news.ycombinator.com/vote?id=46302580&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Only way I have figured out how to to change the "Following" sort order back to chronoligical is from the mobile app: click the down arrow on the "Following" tab. Change the sort from "popular" to "most recent."</p><p>Seems to reset it on the web view, too.</p></div></td></tr></tbody></table></td></tr><tr id="46302222"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302222" href="https://news.ycombinator.com/vote?id=46302222&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p><a href="https://hn.hund.io/" rel="nofollow">https://hn.hund.io/</a> Is a status page, no idea if official or not, but it didn't register here for some reason.</p><p>I didn't read the post text, it's identified there haha, my bad! I wish the text post text wasn't grey, I gloss over it too easily.</p></div></td></tr></tbody></table></td></tr><tr id="46302334"><td></td></tr><tr id="46301962"><td></td></tr><tr id="46302563"><td></td></tr><tr id="46302487"><td></td></tr><tr id="46302271"><td></td></tr><tr id="46302115"><td></td></tr><tr id="46302517"><td></td></tr><tr id="46302398"><td></td></tr><tr id="46302143"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302143" href="https://news.ycombinator.com/vote?id=46302143&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It just reinforces for me that addiction is a human problem not a problem with technology</p><p>I know dang basically works 
tirelessly to not change the format in order to not induce those addictive patterns</p><p>but yet here we all are</p></div></td></tr></tbody></table></td></tr><tr id="46302199"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302199" href="https://news.ycombinator.com/vote?id=46302199&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's a website with the smartest people in the world. The level of conversations here are unrivaled in internet communities.</p><p>It's understandable to be addicted. Lol.</p><p>I visit this place multiple times a day.</p></div></td></tr></tbody></table></td></tr><tr id="46302506"><td></td></tr><tr id="46302607"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46302607" href="https://news.ycombinator.com/vote?id=46302607&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Now now, HN does have its unusually high share of "Very Stable Geniuses" and "High I.Q. Individuals", we have to acknowledge that.</p></div></td></tr></tbody></table></td></tr><tr id="46302285"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46302285" href="https://news.ycombinator.com/vote?id=46302285&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's really not 'the smartest people.' It's people interested in tech, and often in making-a-lot-of-money-in-tech. It does have a lot of people with significant industry experience, which is cool.</p></div></td></tr></tbody></table></td></tr><tr id="46302523"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46302523" href="https://news.ycombinator.com/vote?id=46302523&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>&gt; It's really not 'the smartest people.'</p><p>This was especially obvious during Covid, I even stopped visiting because the comment section was so crazy.</p></div></td></tr></tbody></table></td></tr><tr id="46302395"><td></td></tr><tr id="46302359"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302359" href="https://news.ycombinator.com/vote?id=46302359&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>This one is at least healthy-ish for the mind. I’d much rather hacker news than any other news. Social Media is an emotional rage-bait cesspool these days. If it’s not for Hacker News those of us who abstain from the rest would be living in the dark.</p></div></td></tr></tbody></table></td></tr><tr id="46302049"><td></td></tr><tr id="46302283"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302283" href="https://news.ycombinator.com/vote?id=46302283&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I got stuck in an infinite loop.</p><p>Try opening HN -&gt; it's down, better check HN to see everyone talking about a major website being down -&gt; Try opening HN -&gt; loop</p></div></td></tr></tbody></table></td></tr><tr id="46302389"><td></td></tr><tr id="46302451"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302451" href="https://news.ycombinator.com/vote?id=46302451&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I always hated the late use-it-or-loose-it at the end of the year where you end up buying the things that were denied requests from earlier in the year. You just cost me half a year of using the damn thing.</p></div></td></tr></tbody></table></td></tr><tr id="46302566"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302566" href="https://news.ycombinator.com/vote?id=46302566&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>In other words, productivity in tech skyrocketed for hours..though it seems some work was flavoured with irrational anger.</p></div></td></tr></tbody></table></td></tr><tr id="46302482"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302482" href="https://news.ycombinator.com/vote?id=46302482&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I was able to view the site without being signed in (i.e. private window) but any browser I was logged into wouldn't load.</p><p>I'm sure it's a coincidence but it started working again shortly after emailing hn@ycombinator.com</p></div></td></tr></tbody></table></td></tr><tr id="46302039"><td></td></tr><tr id="46302192"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302192" href="https://news.ycombinator.com/vote?id=46302192&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Next time you can avoid that fate by opening HN in a private browsing (or whatever your browser calls its equivalent) window. This outage, like the vast majority of HN outages, only affected logged in requests.</p><p>I suppose you could also just clear your HN cookies in regular browsing window, but then when they fix it you'd have to log in again.</p></div></td></tr></tbody></table></td></tr><tr id="46302179"><td></td></tr><tr id="46301960"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46301960" href="https://news.ycombinator.com/vote?id=46301960&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Yeah I couldn't log in for a bit this morning. It's concerning how often and how many times I tried. Glad it's resolved.</p></div></td></tr></tbody></table></td></tr><tr id="46302136"><td></td></tr><tr id="46302187"><td></td></tr><tr id="46302174"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302174" href="https://news.ycombinator.com/vote?id=46302174&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>A lot of the outage indicators failed. Someone needs to create an outage indicator reliability dashboard.</p></div></td></tr></tbody></table></td></tr><tr id="46302206"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302206" href="https://news.ycombinator.com/vote?id=46302206&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>A lot of them got fooled by the caching; pages for signed-out users are cached heavily and those kept returning successful responses even if the actual backend server was down.</p></div></td></tr></tbody></table></td></tr><tr id="46302340"><td></td></tr><tr id="46302394"><td></td></tr><tr id="46302215"><td></td></tr><tr id="46302240"><td></td></tr><tr id="46302062"><td></td></tr><tr id="46302200"><td></td></tr><tr id="46302160"><td></td></tr><tr id="46302175"><td></td></tr><tr id="46302171"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302171" href="https://news.ycombinator.com/vote?id=46302171&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It was the first time since I started using this website (August last year) that it was down.</p><p>I'm still impressed nonetheless.</p><p>I'd like to know what caused the outage and how it could have been prevented, for learning purposes.</p></div></td></tr></tbody></table></td></tr><tr id="46302214"><td></td></tr><tr id="46302315"><td></td></tr><tr id="46302069"><td></td></tr><tr id="46302166"><td></td></tr><tr id="46302157"><td></td></tr><tr id="46302209"><td></td></tr><tr id="46302322"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46302322" href="https://news.ycombinator.com/vote?id=46302322&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>&gt; how do you keep track of his comments?</p><p>You can just look at them, turn on showdead in your profile and you'll see a bunch of flag-killed comments in this discussion by whatevermrfukz. No need for a plugin or scraper.</p></div></td></tr></tbody></table></td></tr><tr id="46302404"><td></td></tr><tr id="46302421"><td></td></tr><tr id="46302335"><td></td></tr><tr id="46302510"><td></td></tr><tr id="46302347"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302347" href="https://news.ycombinator.com/vote?id=46302347&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I got confused by the "minutes ago" thing.</p><p>Working with full dates in the HTML and doing a tiny JavaScript that calculates the "minutes ago" would actually be a neat improvement.</p></div></td></tr></tbody></table></td></tr><tr id="46302241"><td></td></tr><tr id="46302609"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302609" href="https://news.ycombinator.com/vote?id=46302609&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>I thought I was being rate-limited for opening posts too fast, which has happened before.</p><p>After more than an hour I thought, "wow this is pretty harsh" and "so much of my exposure to learning things is directly tied to HN posts". I was lost lol.</p></div></td></tr></tbody></table></td></tr><tr id="46302107"><td></td></tr><tr id="46302104"><td></td></tr><tr id="46302112"><td></td></tr><tr id="46302195"><td></td></tr><tr id="46302248"><td></td></tr><tr id="46302083"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46302083" href="https://news.ycombinator.com/vote?id=46302083&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Just a month ago, I got downvoted to -2 for saying HN for being self-hosted hasn't shown up as more reliable than something behind Cloudflare. My point is made.</p><p>Edit: Now it happens again. Knee jerk defenses all the way down.</p></div></td></tr></tbody></table></td></tr><tr id="46302203"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302203" href="https://news.ycombinator.com/vote?id=46302203&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Unless the downtime was caused by something Cloudflare would've prevented, this downtime would've happened regardless of being behind Cloudflare. Cloudflare adds another single point of failure.</p></div></td></tr></tbody></table></td></tr><tr id="46302177"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302177" href="https://news.ycombinator.com/vote?id=46302177&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Could this be a self-inflicted bug? In that case, the broader point still stands: cloud providers can cause outages that are outside your direct realm of responsibility.</p></div></td></tr></tbody></table></td></tr><tr id="46302185"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46302185" href="https://news.ycombinator.com/vote?id=46302185&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>Your VPS server and your data center and the ISP your data center uses and the AS system your ISP uses all can cause outages outside your direct realm of responsibility.</p></div></td></tr></tbody></table></td></tr><tr id="46302300"><td></td></tr><tr id="46302198"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46302198" href="https://news.ycombinator.com/vote?id=46302198&amp;how=up&amp;goto=item%3Fid%3D46301921"></a></center></td><td><br>
<div><p>It's absolutely irresistible downvoting people who preemptively complain about being downvoted like you do. It really made my day. Post another complaint so I can do it again please! It's not knee jerk when you explicitly ask for it, by leading with a complaint about downvoting, instead of just making your point and letting it fall or rise on its own merits. You're the one who put the idea of downvoting you into my head in the first place.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 3 Flash: frontier intelligence built for speed (786 pts)]]></title>
            <link>https://blog.google/products/gemini/gemini-3-flash/</link>
            <guid>46301851</guid>
            <pubDate>Wed, 17 Dec 2025 16:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gemini/gemini-3-flash/">https://blog.google/products/gemini/gemini-3-flash/</a>, See on <a href="https://news.ycombinator.com/item?id=46301851">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
  }">
  
  <div>
      
      
        <p>
          Gemini 3 Flash is our latest model with frontier intelligence built for speed that helps everyone learn, build, and plan anything — faster.
        </p>
      
    </div>
  
  <div data-component="uni-ai-generated-summary" data-analytics-module="{
    &quot;event&quot;: &quot;module_impression&quot;,
    &quot;module_name&quot;: &quot;ai_summary&quot;,
    &quot;section_header&quot;: &quot;CTA&quot;
  }">
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Google is releasing Gemini 3 Flash, a fast and cost-effective model built for speed. You can now access Gemini 3 Flash through the Gemini app and AI Mode in Search. Developers can access it via the Gemini API in Google AI Studio, Google Antigravity, Gemini CLI, Android Studio, Vertex AI and Gemini Enterprise.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_2">
          <h2>Bullet points</h2>
          <ul>
<li>"Gemini 3 Flash: frontier intelligence built for speed" introduces a fast, efficient AI model.</li>
<li>Gemini 3 Flash offers Pro-grade reasoning at Flash-level speed and a lower cost.</li>
<li>It's great for coding, complex analysis, and quick answers in interactive apps.</li>
<li>Gemini 3 Flash is now the default model in the Gemini app and AI Mode in Search.</li>
<li>Developers and everyday users can access Gemini 3 Flash via various Google platforms.</li>
</ul>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      
      <div>
        <h4>
          Explore other styles:
        </h4>
        
      </div>
      

      </div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Gemini 3 Flash text" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header_.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header_.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_flash_model_blog_header.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
  
    



















<div data-component="uni-audio-player-tts" uni-l10n="{
       &quot;stop&quot;: &quot;Click to stop audio&quot;,
       &quot;play&quot;: &quot;Click to play audio&quot;,
       &quot;progress&quot;: &quot;Current audio progress minutes with seconds: [[progress]]&quot;,
       &quot;duration&quot;: &quot;Duration of the audio minutes with seconds: [[duration]]&quot;,
       &quot;settings&quot;: &quot;Click for settings&quot;,
       &quot;timeText&quot;: &quot;[[duration]] minutes&quot;
     }" data-analytics-module="{
      &quot;module_name&quot;: &quot;Audio TTS&quot;,
      &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
     }" data-tts-audios="[
      
        {&quot;voice_name&quot;: &quot;Gacrux&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82955_gacrux_2025_12_17_16_29_26.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;},
      
        {&quot;voice_name&quot;: &quot;Umbriel&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82955_umbriel_2025_12_17_16_31_33.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;}
      ]">
  <p><audio title="Gemini 3 Flash: frontier intelligence built for speed">
      <source src="https://blog.google/products/gemini/gemini-3-flash/self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type">
      <p>Your browser does not support the audio element.</p>
  </audio></p><div aria-label="">
        <p><span>
          Listen to article
          <span tabindex="0" role="tooltip" aria-label="This content is generated by Google AI. Generative AI is experimental">
            <p>This content is generated by Google AI. Generative AI is experimental</p>
            <svg>
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251215-1743#ttf-info"></use>
</svg>

          </span>
        </span></p><p>[[duration]] minutes</p>
      </div>
</div>

  





            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><p data-block-key="qapzx">Today, we're expanding the Gemini 3 model family with the release of Gemini 3 Flash, which offers frontier intelligence built for speed at a fraction of the cost. With this release, we’re making Gemini 3’s next-generation intelligence accessible to everyone across Google products.</p><p data-block-key="b4nrq">Last month, we kicked off Gemini 3 with <a href="https://blog.google/products/gemini/gemini-3/#note-from-ceo">Gemini 3 Pro</a> and <a href="https://blog.google/products/gemini/gemini-3-deep-think/">Gemini 3 Deep Think</a> mode, and the response has been incredible. Since launch day, we have been processing over 1T tokens per day on our API. We’ve seen you use Gemini 3 to <a href="https://x.com/googleaidevs/status/1991333601959350306">vibe code simulations</a> to learn about complex topics, build and design <a href="https://x.com/googleaidevs/status/1991318283065131160">interactive games</a> and understand all types of <a href="https://x.com/googleaidevs/status/1997033279610818745?s=20">multimodal content</a>.</p><p data-block-key="3c1p3">With Gemini 3, we introduced frontier performance across complex reasoning, <a href="https://blog.google/technology/developers/gemini-3-pro-vision/">multimodal and vision understanding</a> and agentic and vibe coding tasks. Gemini 3 Flash retains this foundation, combining Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost. It not only enables everyday tasks with improved reasoning, but also is our most impressive model for agentic workflows.</p><p data-block-key="347o3">Starting today, Gemini 3 Flash is rolling out to millions of people globally:</p><ul><li data-block-key="4suea">For developers in the Gemini API in <a href="https://blog.google/technology/developers/build-with-gemini-3-flash">Google AI Studio</a>, <a href="https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/">Gemini CLI</a> and our new agentic development platform <a href="https://antigravity.google/blog/gemini-3-flash-in-google-antigravity">Google Antigravity</a></li><li data-block-key="72mi8">For everyone via the <a href="https://blog.google/products/gemini/gemini-3-flash-gemini-app/">Gemini app</a> and in <a href="https://blog.google/products/search/google-ai-mode-update-gemini-3-flash">AI Mode in Search</a></li><li data-block-key="7upf8">For enterprises in <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-3-flash-for-enterprises">Vertex AI and Gemini Enterprise</a></li></ul></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">Gemini 3 Flash: frontier intelligence at scale</h2><p data-block-key="b8etv">Gemini 3 Flash demonstrates that speed and scale don’t have to come at the cost of intelligence. It delivers frontier performance on PhD-level reasoning and knowledge benchmarks like GPQA Diamond (90.4%) and Humanity’s Last Exam (33.7% without tools), rivaling larger frontier models, and significantly outperforming even the best 2.5 model, Gemini 2.5 Pro, across a number of benchmarks. It also reaches state-of-the-art performance with an impressive score of 81.2% on MMMU Pro, comparable to Gemini 3 Pro.</p></div>
  

  
    














<uni-image-full-width alignment="full" alt-text="A benchmark comparison table showing performance scores and prices for several language models including Gemini 3 Flash, Gemini 3 Pro Thinking, Gemini 2.5 Flash Thinking, Gemini 2.5 Pro Thinking, Claude Sonnet 4.5, GPT-5.2 Extra high, and Grok 4.1 Fast, across various tasks like academic reasoning, scientific knowledge, math, multi-modal understanding, coding, and long context performance." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Flash: frontier intelligence built for speed" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-table_light_25-1.original.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="A benchmark comparison table showing performance scores and prices for several language models including Gemini 3 Flash, Gemini 3 Pro Thinking, Gemini 2.5 Flash Thinking, Gemini 2.5 Pro Thinking, Claude Sonnet 4.5, GPT-5.2 Extra high, and Grok 4.1 Fast, across various tasks like academic reasoning, scientific knowledge, math, multi-modal understanding, coding, and long context performance." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-ta.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-ta.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_final_benchmark-t.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">In addition to its frontier-level reasoning and multimodal capabilities, Gemini 3 Flash was built to be highly efficient, pushing the Pareto frontier of quality vs. cost and speed. When processing at the highest thinking level, Gemini 3 Flash is able to modulate how much it thinks. It may think longer for more complex use cases, but it also uses 30% fewer tokens on average than 2.5 Pro, as measured on typical traffic, to accurately complete everyday tasks with higher performance.</p>
      </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="A scatter plot showing LMArena Elo Score versus Price per million tokens for various language models, with a line highlighting the Pareto frontier through 'gemini-3-pro', 'gemini-3-flash', and 'gemini-3-flash-lite'." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Flash: frontier intelligence built for speed" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17_1_DF5Txhz.original.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="90v27">Gemini 3 Flash pushes the Pareto frontier on performance vs. cost and speed.</p>
    </div>
  
  
    <p><img alt="A scatter plot showing LMArena Elo Score versus Price per million tokens for various language models, with a line highlighting the Pareto frontier through 'gemini-3-pro', 'gemini-3-flash', and 'gemini-3-flash-lite'." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec17.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3-flash_pareto_graph_dec1.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="yrydl">Gemini 3 Flash’s strength lies in its raw speed, building on the Flash series that developers and consumers already love. It outperforms 2.5 Pro while being 3x faster (based on <a href="https://artificialanalysis.ai/models/gemini-3-flash-reasoning">Artificial Analysis</a> benchmarking) at a fraction of the cost. Gemini 3 Flash is priced at $0.50/1M input tokens and $3/1M output tokens (audio input remains at $1/1M input tokens).</p>
      </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Dynamic thinking in Gemini 3 Flash demo" external-image="" or-mp4-video-title="Gemini 3 Flash Action Replay" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Keyword_ACTION_REPLAY_V10_1.mp4" section-header="Gemini 3 Flash: frontier intelligence built for speed" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">For developers: intelligence that keeps up</h2><p data-block-key="8tjig">Gemini 3 Flash is made for iterative development, offering Gemini 3’s Pro-grade coding performance with low latency — it’s able to reason and solve tasks quickly in high-frequency workflows. On SWE-bench Verified, a benchmark for evaluating coding agent capabilities, Gemini 3 Flash achieves a score of 78%, outperforming not only the 2.5 series, but also Gemini 3 Pro. It strikes an ideal balance for agentic coding, production-ready systems and responsive interactive applications.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="9" thumbnail-alt="Demo of Gemini 3 Flash for developers" subtitle="Gemini 3 Flash in Google Antigravity works quickly to update production-ready applications." video-id="MPkgMSWQMSU" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">Gemini 3 Flash’s strong performance in reasoning, tool use and multimodal capabilities is ideal for developers looking to do more complex video analysis, data extraction and visual Q&amp;A, which means it can enable more intelligent applications — like in-game assistants or A/B test experiments — that demand both quick answers and deep reasoning.</p>
      </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/SlingShot_Thumbnail_vF.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash sling shot game demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Sling Shot&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini3Flash_SpinnerEvolve_short_noendcard.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Spinner Evolve demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Spinner Evolve&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Disc_augmented_image_asset3_1.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash demo Cloud City&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;cloud city updated&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini3flash_threeuniquevariations.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash demo showing design variations in UI&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash three unique variations&quot;
      }
    
  ]">
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">We’ve received a tremendous response from companies using Gemini 3 Flash. Companies like JetBrains, Bridgewater Associates, and Figma are already using it to transform their businesses, recognizing how its inference speed, efficiency and reasoning capabilities perform on par with larger models. Gemini 3 Flash is available today to enterprises via Vertex AI and Gemini Enterprise.</p>
      </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-jetb.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-jetb.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;JetBrains customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-aia-.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-aia-.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Bridgewater customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-figm.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-figm.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Figma customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-curs.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-curs.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Cursor customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-warp.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-warp.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Warp customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-harv.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-harv.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Harvey customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-astr.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-astr.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Astrocade customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-pres.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-pres.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Presentations.ai customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-repl.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-repl.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Replit customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      },
    
      {
        
          
          
          &quot;src&quot;: [&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-lati.max-1080x1080.format-webp.webp&quot;,&quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3Flash_blog_quote-lati.max-1080x1080.format-webp.webp&quot;],
        
        &quot;alt&quot;: &quot;Latitude customer testimonial quote&quot;,
        &quot;isVideo&quot;: false,
        &quot;videoTitle&quot;: &quot;&quot;
      }
    
  ]">
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">For everyone: Gemini 3 Flash is rolling out globally</h2><p data-block-key="5hmpf">Gemini 3 Flash is now the default model in the Gemini app, replacing 2.5 Flash. That means all of our Gemini users globally will get access to the Gemini 3 experience at no cost, giving their everyday tasks a major upgrade.</p><p data-block-key="1f9e7">Because of Gemini 3 Flash’s incredible multimodal reasoning capabilities, you can use it to help you see, hear and understand any type of information faster. For example, you can ask Gemini to understand your videos and images and turn that content into a helpful and actionable plan in just a few seconds.</p></div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Flash: frontier intelligence built for speed" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gem3_Golf_Demo_No_Audio_16x9.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 golf swing demo video&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 golf demo&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Pictionary_vFinal_Blog.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash Pictionary demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash Pictionary&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Gemini_Flash3.0_LearningDemo_16x9_JW_v6_NoAudio.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini 3 Flash learning demo&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini 3 Flash learning demo&quot;
      }
    
  ]">
  
    
      
    
  
    
      
    
  
    
      
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }">
        <p data-block-key="qapzx">Or you can quickly build fun, useful apps from scratch using your voice without prior coding knowledge. Just dictate to Gemini on the go, and it can transform your unstructured thoughts into a functioning app in minutes.</p>
      </div>
  

  
    
  
    




  <uni-youtube-player-article index="17" thumbnail-alt="Food prototype using Gemini 3 Flash" subtitle="Describe an idea using Gemini 3 Flash and turn it into a working prototype in minutes." video-id="8IYYMRdz2h4" video-type="video" image="Gemini3_Flash_Food_Thumbnail" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3_Flash_Food_Thumbnail.width-1000.format-webp.webp">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><p data-block-key="qapzx">Gemini 3 Flash is also starting to roll out as the default model for AI Mode in Search with access to everyone around the world.</p><p data-block-key="5fmab">Building on the reasoning capabilities of Gemini 3 Pro, AI Mode with Gemini 3 Flash is more powerful at parsing the nuances of your question. It considers each aspect of your query to serve thoughtful, comprehensive responses that are visually digestible — pulling real-time local information and helpful links from across the web. The result effectively combines research with immediate action: you get an intelligently organized breakdown alongside specific recommendations — at the speed of Search.</p><p data-block-key="fba77">This shines when tackling complex goals with multiple considerations like trying to plan a last-minute trip or learning complex educational concepts quickly.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="19" thumbnail-alt="Demo of Gemini 3 Flash in AI Mode" subtitle="Gemini 3 Flash brings the incredible reasoning capabilities of Gemini 3 to Search, without compromising speed, so you can tackle your most complicated questions." video-id="rPXBDSf-Hwg" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Gemini 3 Flash: frontier intelligence built for speed&quot;
         }"><h2 data-block-key="qapzx">Try Gemini 3 Flash today</h2><p data-block-key="avrm2">Gemini 3 Flash is available now in preview via the <a href="https://ai.google.dev/gemini-api/docs/models#gemini-3-flash">Gemini API</a> in Google AI Studio, <a href="https://antigravity.google/">Google Antigravity,</a> <a href="https://cloud.google.com/vertex-ai?e=48754805">Vertex AI</a> and <a href="https://cloud.google.com/gemini-enterprise?e=48754805">Gemini Enterprise</a>. You can also access it through other developer tools like <a href="https://developers.googleblog.com/gemini-3-flash-is-now-available-in-gemini-cli/">Gemini CLI</a> and <a href="https://android-developers.googleblog.com/2025/12/build-smarter-apps-with-gemini-3-flash">Android Studio</a>. It’s also starting to roll out to everyone in the <a href="https://gemini.google.com/">Gemini app</a> and <a href="https://www.google.com/search?udm=50&amp;aep=11">AI Mode</a> in Search, bringing fast access to next-generation intelligence at no cost.</p><p data-block-key="e3atd">We’re looking forward to seeing what you bring to life with this expanded family of models: Gemini 3 Pro, Gemini 3 Deep Think and now, Gemini 3 Flash.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yep, Passkeys Still Have Problems (160 pts)]]></title>
            <link>https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/</link>
            <guid>46301585</guid>
            <pubDate>Wed, 17 Dec 2025 13:12:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/">https://fy.blackhats.net.au/blog/2025-12-17-yep-passkeys-still-have-problems/</a>, See on <a href="https://news.ycombinator.com/item?id=46301585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>It's now late into 2025, and just over a year since I wrote my last post on Passkeys. The
prevailing dialogue that I see from thought leaders is "addressing common misconceptions" around Passkeys,
the implication being that "you just don't understand it correctly" if you have doubts. Clearly
I don't understand Passkeys in that case.</p>
<p>And yet, I am here to once again say - yep, it's 2025 and Passkeys still have all the issues I've mentioned
before, and a few new ones I've learnt! Let's round up the year together then.</p>
<h2 id="too-lazy-didn-t-read">Too Lazy - Didn't Read</h2>
<ul>
<li>Passkeys have flaws - learn about them and use them <em>on your terms</em>. Don't write them off wholesale based on this blog. I, the author of this blog, use Passkeys!!!</li>
<li>DO engage with and learn about Credential Managers (aka Password Managers). This is where the Passkey is stored.</li>
<li>DO use a Credential Manager you control and can backup. I recommend Bitwarden or Vaultwarden which allow backups to be taken easily.</li>
<li><em>AVOID</em> using a platform (Apple, Google) Credential Manager as your only Passkey repository - these can't easily backed up and you CAN be locked out permanently.
<ul>
<li>IF you use a platform Passkey manager, frequently sync it with <a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange</a> to an external Credential Manager you can backup/control.</li>
<li>OR use both the platform Passkey manager <em>AND</em> a Credential Manager you control in parallel.</li>
</ul>
</li>
<li>For high value accounts such as email which are on the account recovery path
<ul>
<li>DO use Yubikeys for your email account as the Passkey store.</li>
<li>DO keep strong machine generated passwords + TOTP in your Credential Managers as alternatives to Passkeys for your email accounts.</li>
</ul>
</li>
<li>DO a thought experiment - if I lost access to my Credential Manager what is the recovery path? Ensure you can rebuild from disaster.</li>
</ul>
<h2 id="so-what-has-changed">So what has changed?</h2>
<p>The major change in the last 12 months has been the introduction of the
<a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange Specification</a>.</p>
<p>Most people within the tech community who have dismissed my claim that "Passkeys are a form of vendor
lockin" are now pointing at this specification as proof that this claim is now wrong.</p>
<blockquote>
<p>"See! Look! You can export your credentials to another Passkey provider if you want! We aren't locking you in!!!"</p>
</blockquote>
<p>I have to agree - this is great if you want to <em>change</em> which walled-garden you live inside. However
it doesn't assist with the day to day usage of Passkeys when you have devices from <em>different</em> vendor ecosystems. Nor
does it make it easier for me to use a Passkey provider outside of my vendors platform provider.</p>
<p>Example: Let's say that I have an Windows Desktop and a Macbook Pro - I can sign up a Passkey on the Macbook Pro
but I can't then use it on the Windows Desktop.
<a href="https://fidoalliance.org/specifications-credential-exchange-specifications/">FIDO Credential Exchange</a>
lets me copy from
Apple's Keychain to whatever provider I use on the Windows machine. But now I have to do that
exchange <em>every time I enrol a new Passkey</em>. Similar I would need to do the reverse from Windows
to Mac every time that I sign up on the Windows machine.</p>
<p>So day to day, this changes very little - but if I want to go from "all in on Apple" to "all in on
Google" then I can do a big-bang migration and jump from once garden to the next. But if you have
mixed device ecosystems (like uhhh ... you know. Most of the world does) then very little will
change for you with this.</p>
<p>But if I use my own Credential Manager (e.g. Vaultwarden) then I can happily work between multiple
ecosystems.</p>
<h2 id="what-s-the-same">What's the same?</h2>
<h3 id="thought-leadership">Thought Leadership</h3>
<p>Today I saw this excellent quote in the context of why Passkeys are better than Password+TOTP in a Password Manager:</p>
<blockquote>
<p>Individuals having to learn to use password management software and be vigilant against phishing is an industry failure, not a personal success.</p>
</blockquote>
<p>Even giving as much benefit of the doubt to this statement, and that the "and" might be load bearing we have to ask - Where are passkeys stored?</p>
<p><img src="https://fy.blackhats.net.au/_static/passkey/af5o5b.jpg" alt="image"></p>
<p>So we still have to teach individuals about password (credential) managers, and how Passkeys work so that people trust them. That fundamental truth hasn't changed.</p>
<p>But not only this - if a person is choosing a password+TOTP over a Passkey, we have to ask "why is that"? Do we think that it's truly about arrogance? Do we think that
this user believes they are more important? Or is there and underlying usability issue at play? Why might we be recommending this to others? Do we really think that
Passkeys come without a need of education?</p>
<p>Maybe I'm fundamentally missing the original point of this comment. Maybe I am completely misinterpretting it. But I still think we need to say if a person chooses
password and TOTP over a Passkey even once they are informed of the choices, then Passkeys have <em>failed</em> that user. What could we have done better?</p>
<p>Perhaps one could interpret this statement as you don't need to teach users about Passkeys if they are using their <em>✨ m a g i c a l ✨</em> platform Passkey manager since it's so much nicer than a password and TOTP. And that leads to ...</p>
<h3 id="it-s-still-vendor-lockin">It's Still Vendor Lockin</h3>
<blockquote>
<p>In economics, vendor lock-in, [...] makes a customer dependent on a vendor for products, unable to
use another vendor without substantial switching costs.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Vendor_lock-in">citation - wikipedia</a></p>
<p>See, the big issue that the thought leaders seem to get wrong is that they believe that if you can
use FIDO Credential Exchange, then you aren't locked in because you can move between Passkey providers.</p>
<p>But if we aren't teaching our users about credential management, didn't we just silently lock them into
to our platform Passkey manager?</p>
<p>Not only that, when you try to go against the platform manager, it's the continual friction at each stage of the users
experience. It makes
the cost to switch <em>high</em> because at each point you encounter friction if you deviate from the vendors
intended paths.</p>
<p>For example, consider the Apple Passkey modal:</p>
<p><img src="https://fy.blackhats.net.au/_static/passkey/register-macos-1.png" alt="image"></p>
<blockquote>
<p>MacOS 15.7.1 taken on 2025-10-29</p>
</blockquote>
<p>The majority of this modal is dedicated to "you should make a Passkey in your Apple Keychain". If you
want to use your Android phone or a Security Key, where would I click? Oh yes, <code>Other Options</code>.</p>
<p>Per <a href="https://developer.apple.com/design/human-interface-guidelines/buttons#Best-practices">Apple's Human Interface Guidelines</a>:</p>
<blockquote>
<p>Make buttons easy for people to use. It’s essential to include enough space around a button so that people can visually distinguish it from surrounding components and content. Giving a button enough space is also critical for helping people select or activate it, regardless of the method of input they use.</p>
</blockquote>
<p><img src="https://fy.blackhats.net.au/_static/passkey/register-macos-2.png" alt="image"></p>
<blockquote>
<p>MacOS 15.7.1 taken on 2025-10-29</p>
</blockquote>
<p>When you select <code>Other Options</code> this is what you see - see how Touch ID is still the default, despite
the fact that I already indicated I don't want to use it by selecting <code>Other Options</code>? At this point
I would need to select <code>Security Key</code> and then click again to use my key. Similar for Android Phone.</p>
<p>And guess what - my preferences and choices are never remembered. I guess it's true what they say.</p>
<blockquote>
<p>Software engineers don't understand consent, and it shows.</p>
</blockquote>
<p>Google Chrome has a similar set of Modals and nudges (though props to Chrome, they at least <em>implicitly</em>
activate your security key from the first modal so a power user who knows the trick can use it). So they
are just as bad here IMO.</p>
<p>This is what I mean by "vendor lockin". It's not just about where the private keys are stored. It's
the continual friction at each step of the interaction when you deviate from the vendors intended
path. It's about making it so annoying to use <em>anything else</em> that you settle into one vendors
ecosystem. It's about the lack of communication about <em>where</em> Passkeys are stored that tricks users
into settling into their vendor ecosystem. That's vendor lock-in.</p>
<h3 id="cloud-keychains-are-still-blowing-up-data">Cloud Keychains Are Still Blowing Up Data</h3>
<p>We still get reports of people losing Passkeys from Apple Keychain. We similarly get reports of Android
phones that one day just stop creating new Passkeys, or stop being able to use existing ones. One
<a href="https://infosec.exchange/@tychotithonus/115341947864402280">exceptional story</a> we saw recently was of
an Android device that stopped using it's onboard Passkeys and also stopped accepting NFC key. USB
CTAP would still function, and all the historical fixes we've seen (such as full device resets) would
not work. So now what? I'm not sure of the outcome of this story, but my assumption is there was not
a happy ending.</p>
<p>If someone ends up locked out of their accounts because their Passkeys got nuked silently, what are
we meant to do to help them?</p>
<h3 id="vendors-can-lock-you-out">Vendors Can Lock You Out</h3>
<p><a href="https://hey.paris/posts/appleid/">Dr Paris Buttfield-Addison was locked out of their Apple account</a>.</p>
<p>I recommend you read the post, but the side effect - every Passkey they had in an Apple keychain is now unrecoverable.</p>
<p>There is just as much evidence about the same practices with Google / Android.</p>
<p>I honestly don't think I have to say much else, this is terrifying that every account you own could be destroyed by a single action where you have no recourse.</p>
<h3 id="authentication-providers-still-miscommunicate">Authentication Providers Still Miscommunicate</h3>
<p>We still have issues where services that are embracing Passkeys are communicating badly about them.
The gold standard of miscommunication came to me a few months ago infact (2025-10-29) when a company emailed me
this statement:</p>
<blockquote>
<p>Passkeys use your unique features – known as biometrics – like your facial features, your fingerprint or a PIN to let us know that it’s really you. They provide increased security because unlike a password or username, they can’t be shared with anyone, making them phishing resistant.</p>
</blockquote>
<p>As someone who is deeply aware of how webauthn works I know that my facial features or fingerprint never really
leave my device. However asking my partner
(context: my partner is a veternary surgeon, and so I feel justified in claiming that she is a very intelligent and educated woman)
to read this, her interpretation was:</p>
<blockquote>
<p>So this means a Passkey sends my face or fingerprint over the internet for the service to verify? Is that
also why they believe it is phishing resistant because you can't clone my face or my fingerprint?</p>
</blockquote>
<p>This is a smart, educated person, with the title of <em>doctor</em>, and even she is concluding that Passkeys
are sending biometrics over the internet. What are people in other disciplines going to think? What
about people with a cognitive impairment or who not have access to education about Passkeys?</p>
<p>This kind of messaging that leads people to believe we are sending personal physical features over
the internet is <em>harmful</em> because most people <em>will not want to send these data to a remote service</em>.
This completely undermines the trust in Passkeys because we are establishing to people that they are
personally invasive in a way that username and passwords are not!</p>
<p>And guess what - platform Passkey provider modals/dialogs don't do anything to counter this information
and often leave users with the same feeling.</p>
<h3 id="authentication-providers-are-still-playing-silly-games-with-user-choice">Authentication Providers Are Still Playing Silly Games With User Choice</h3>
<p>A past complaint was that I had encountered services that only accepted a single Passkey as they
assumed you would use a synchronised cloud keychain of some kind. In 2025 I still see a handful
of these services, but mostly the large problem sites have now finally allowed you to enrol multiple Passkeys.</p>
<p>But that doesn't stop sites pulling tricks on you.</p>
<p>I've encountered multiple sites that now use <code>authenticatorAttachment</code> options to force you to use
a platform bound Passkey. In other words, they force you into Google or Apple. No password manager,
no security key, no choices.</p>
<p>I won't claim this one as an attempt at "vendor lockin" by the big players, but it is a reflection
of what developers believe a Passkey to be - they believe it means a private key stored in one of
those vendors devices, and nothing else. So much of this comes from the confused historical origins
of Passkeys and we aren't doing anything to change it.</p>
<p>When I have confronted these sites about the mispractice, they pretty much shrugged and said
"well no one else has complained so meh". Guess I won't be enrolling a Passkey with you then.</p>
<p>One other site that pulled this said "instead of selecting continue, select this other option and you
get the <code>authenticatorAttachment=cross-platform</code> setting. Except that they could literally do
<em>nothing</em> with <code>authenticatorAttachment</code> and leave it up to the platform modals allowing me the choice
(and fewer friction burns) of choosing where I want to enrol my Passkey.</p>
<p>Another very naughty website attempts to enroll a Passkey on your device with no prior warning or consent
when you login, which is very surprising to anyone and seems very deceptive as a practice. Ironically
same vendor doesn't use your passkey when you go to sign in again anyway.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Yep, Passkeys Still Have Problems.</p>
<p>But it's not <em>all</em> doom and gloom.</p>
<p>Most of the issues are around <em>platform</em> Passkey providers like Apple or Google.</p>
<p>The best thing you can do as a user, and for anyone in your life you want to help, is to be educated
about Credential Managers. Regardless of Passwords, TOTP, Passkeys or anything else, empowering people
to manage and think about their online security via a Credential Manager they feel they control and
understand is critical - not an "industry failure".</p>
<p>Using a Credential Manager that you have control over shields you from the account lockout and
platform blow-up risks that exist with platform Passkeys. Additionally most Credential Managers
will allow you to backup your credentials too. It can be a great idea to do this every few months
and put the content onto a USB drive in a safe location.</p>
<p>If you do choose to use a platform Passkey provider, you can "emulate" this backup ability by using
the credential export function to another Passkey provider, and then do the backups from there.</p>
<p>You can also use a Yubikey as a Credential Manager if you want - modern keys (firmware version 5.7 and greater)
can store up to 150 Passkeys on them, so you could consider skipping software Credential Managers entirely for
some accounts.</p>
<p>The most critical accounts you own though need some special care. Email is one of those - email generally
is the path by which all other credential resets and account recovery flows occur. This means losing
your email access is the most devastating loss as anything else could potentially be recovered.</p>
<p>For email, this is why I recommend using hardware security keys (yubikeys are the gold standard here)
if you want Passkeys to protect your email. Always keep a strong password and TOTP as an extra <em>recovery</em> path, but
don't use it day to day since it can be phished. Ensure these details are physically secure and backed up - again a USB drive
or even a print out on paper in a safe and secure location so that you can "bootstrap your accounts"
in the case of a major failure.</p>
<p>If you are an Apple or Google employee - change your dialogs to allow remembering choices the user
has previously made on sites, or wholesale allow skipping some parts - for example I want to skip
straight to Security Key, and maybe I'll choose to go back for something else. But let <em>me</em> make
that choice. Similar, make the choice to use different Passkey providers a first-class citizen in
the UI, not just a tiny text afterthought.</p>
<p>If you are a <em>developer</em> deploying Passkeys, then don't use any of the pre-filtering Webauthn
options or javascript API's. Just leave it to the users platform modals to let the person choose. If
you want people to enroll a passkey on sign in, communicate that before you attempt the enrolment. Remember
kids, consent is paramount.</p>
<p>But of course - maybe I just "don't understand Passkeys correctly". I am but an underachiving white man on the internet after all.</p>
<p>EDIT: 2025-12-17 - expanded on the password/totp + password manager argument.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coursera to combine with Udemy (428 pts)]]></title>
            <link>https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx</link>
            <guid>46301346</guid>
            <pubDate>Wed, 17 Dec 2025 12:45:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx">https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=46301346">Hacker News</a></p>
Couldn't get https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Is Mozilla trying hard to kill itself? (838 pts)]]></title>
            <link>https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself</link>
            <guid>46299934</guid>
            <pubDate>Wed, 17 Dec 2025 09:37:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself">https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself</a>, See on <a href="https://news.ycombinator.com/item?id=46299934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In an interview with “The Verge”, the new Mozilla CEO, Enzor-DeMeo, IMHO hints that axing adblockers is something that, at the very least, was on the table in some form and at some point. From <a href="https://www.theverge.com/tech/845216/mozilla-ceo-anthony-enzor-demeo" rel="nofollow">the article</a>:</p>

<blockquote><p>He says he could begin to block ad blockers in Firefox and estimates that’d bring in another $150 million, but he doesn’t want to do that. It feels off-mission.</p></blockquote>

<p>It may be just me, but I read this as “I don't want to 😜 😜 but I'll kill AdBlockers in Firefox for buckerinos 😂”. This disappoints and saddens me a lot, and I hope I'm wrong.</p>

<p>I've been using Firefox before it was called that. Heck, I even used the Mozilla Application Suite back in the day. It was its commitment to open standards and the open web, and its powerful add-on system, that attracted me to its software.</p>

<p>Honestly, that's what's been keeping me. I think that's also what's been keeping their loyal base of users with the project, the geeks and nerds that care about privacy. It's the same group of people who helped it get very popular at one point.</p>

<p>Killing one of its advantages over the Chromium engine, being able to have a fucking adblocker that's actually useful, and that nowadays is a fucking security feature due to malvertising, will be another nail in the coffin, IMHO. The core community will feel disenfranchised, and this may have negative consequences for the project. You know why? Because these are some of the people that the <em>normies</em> turn to when they want tech advice.</p>

<p>For fuck sake, for-profit side of Mozilla, get a damn grip!</p>

<p><a href="https://infosec.press/brunomiguel/tag:Mozilla" rel="nofollow"><span>#</span><span>Mozilla</span></a> <a href="https://infosec.press/brunomiguel/tag:Firefox" rel="nofollow"><span>#</span><span>Firefox</span></a> <a href="https://infosec.press/brunomiguel/tag:AdBlocker" rel="nofollow"><span>#</span><span>AdBlocker</span></a> <a href="https://infosec.press/brunomiguel/tag:OpenSource" rel="nofollow"><span>#</span><span>OpenSource</span></a> <a href="https://infosec.press/brunomiguel/tag:FOSS" rel="nofollow"><span>#</span><span>FOSS</span></a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI's real superpower: consuming, not creating (211 pts)]]></title>
            <link>https://msanroman.io/blog/ai-consumption-paradigm</link>
            <guid>46299552</guid>
            <pubDate>Wed, 17 Dec 2025 08:34:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://msanroman.io/blog/ai-consumption-paradigm">https://msanroman.io/blog/ai-consumption-paradigm</a>, See on <a href="https://news.ycombinator.com/item?id=46299552">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><span>October 30, 2025</span><p>Everyone's using AI wrong. Including me, until last month.</p>
<p>We ask AI to write emails, generate reports, create content. But that's like using a supercomputer as a typewriter. The real breakthrough happened when I flipped my entire approach.</p>
<p>AI's superpower isn't creation. It's consumption.</p>
<h2 id="the-creation-trap">The creation trap</h2>
<p>Here's how most people use AI:</p>
<ul>
<li>"Write a blog post about engineering leadership"</li>
<li>"Generate code for this feature"</li>
<li>"Create a summary of this meeting"</li>
</ul>
<p>Makes sense. These tasks save time. But they're thinking too small.</p>
<p>My Obsidian vault contains:
→ 3 years of daily engineering notes
→ 500+ meeting reflections
→ Thousands of fleeting observations about building software
→ Every book highlight and conference insight I've captured</p>
<p>No human could read all of this in a lifetime. AI consumes it in seconds.</p>
<h2 id="the-consumption-breakthrough">The consumption breakthrough</h2>
<p>Last month I connected my Obsidian vault to AI. The questions changed completely:</p>
<p>Instead of "Write me something new"
I ask "What have I already discovered?"</p>
<p>Real examples from this week:</p>
<p><strong>"What patterns emerge from my last 50 one-on-ones?"</strong>
AI found that performance issues always preceded tool complaints by 2-3 weeks. I'd never connected those dots.</p>
<p><strong>"How has my thinking about technical debt evolved?"</strong>
Turns out I went from seeing it as "things to fix" to "information about system evolution" around March 2023. Forgotten paradigm shift.</p>
<p><strong>"Find connections between Buffer's API design and my carpeta.app architecture"</strong>
Surfaced 12 design decisions I'm unconsciously repeating. Some good. Some I need to rethink.</p>
<h2 id="your-knowledge-compounds-but-only-if-accessible">Your knowledge compounds, but only if accessible</h2>
<p>Every meeting, every shower thought, every debugging session teaches you something. But that knowledge is worthless if you can't retrieve it.</p>
<p>Traditional search fails because you need to remember exact words. Your brain fails because it wasn't designed to store everything.</p>
<p>AI changes the retrieval game:
→ Query by concept, not keywords
→ Find patterns across years, not just documents
→ Connect ideas that were separated by time and context</p>
<p>The constraint was never writing. Humans are already good at creating when they have the right inputs.</p>
<p>The constraint was always consumption. Reading everything. Remembering everything. Connecting everything.</p>
<h2 id="building-your-consumption-system">Building your consumption system</h2>
<p>My setup is deceptively simple:</p>
<ol>
<li>Everything goes into Obsidian (meetings, thoughts, reflections)</li>
<li>AI has access to the entire vault</li>
<li>I query my past self like a research assistant</li>
</ol>
<p>But the magic isn't in the tools. It's in the mindset shift.</p>
<p>Stop thinking of AI as a creator. Start thinking of it as the ultimate reader of your experience.</p>
<p>Every note becomes a future insight. Every reflection becomes searchable wisdom. Every random observation might be the missing piece for tomorrow's problem.</p>
<h2 id="the-compound-effect">The compound effect</h2>
<p>After two months of this approach:</p>
<p>→ I solve problems faster by finding similar past situations
→ I make better decisions by accessing forgotten context
→ I see patterns that were invisible when scattered across time</p>
<p>Your experience is your competitive advantage. But only if you can access it.</p>
<p>Most people are sitting on goldmines of insight, locked away in notebooks, random files, and fading memories. AI turns that locked vault into a queryable database of your own expertise.</p>
<h2 id="the-real-revolution">The real revolution</h2>
<p>We're still thinking about AI like it's 2023. Writing assistants. Code generators. Content creators.</p>
<p>The real revolution is AI as the reader of everything you've ever thought.</p>
<p>And that changes everything about how we should capture knowledge today.</p>
<p>Start documenting. Not for others. For your future self and the AI that will help you remember what you've forgotten you know.</p>
<hr>
<p><em>This piece originally appeared in my <a href="https://mikesanroman.substack.com/" target="_blank" rel="noopener">weekly newsletter</a>. Subscribe for insights on thinking differently about work, technology, and what's actually possible.</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TLA+ Modeling Tips (112 pts)]]></title>
            <link>http://muratbuffalo.blogspot.com/2025/12/tla-modeling-tips.html</link>
            <guid>46299389</guid>
            <pubDate>Wed, 17 Dec 2025 08:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://muratbuffalo.blogspot.com/2025/12/tla-modeling-tips.html">http://muratbuffalo.blogspot.com/2025/12/tla-modeling-tips.html</a>, See on <a href="https://news.ycombinator.com/item?id=46299389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-6023861270150914222">
<h3>Model minimalistically</h3><p>Start from a tiny core, and always keep a working model as you extend. Your default should be omission. Add a component only when you can explain why leaving it out would not work. Most models are about a slice of behavior, not the whole system in full glory: E.g., Leader election, repair, reconfiguration. Cut entire layers and components if they do not affect that slice. <a href="https://muratbuffalo.blogspot.com/2023/09/beyond-code-tla-and-art-of-abstraction.html">Abstraction is the art of knowing what to cut</a>. Deleting should spark joy.&nbsp;</p><h3>Model specification, not implementation</h3><p>Write declaratively. State what must hold, not how it is achieved. If your spec mirrors control flow, loops, or helper functions, you are simulating code. Cut it out. Every variable must earn its keep. Extra variables multiply the state space (model checking time) and hide bugs. Ask yourself repeatedly: can I derive this instead of storing it? For example, you do not need to maintain a <span>WholeSet</span> variable if you can define it as a state function of existing variables: <span>WholeSet == provisionalItems \union nonProvisionalItems</span>.</p><h3>Review the model for illegal knowledge</h3><p>Do a full read-through of your model and check what each process can really see. TLA+ makes it easy to read global state (or another process's state) that no real distributed process could ever observe atomically. This is one of the most common modeling errors. Make a dedicated pass to eliminate illegal global knowledge.</p><h3>Check atomicity granularity</h3><p>Push actions to be as fine-grained as correctness allows. Overly large atomic actions hide races and invalidate concurrency arguments. Fine-grained actions expose the real interleavings your protocol must tolerate.&nbsp;</p><h3>Think in guarded commands, not procedures&nbsp;</h3><p>Each action should express one logical step in <a href="https://en.wikipedia.org/wiki/Guarded_Command_Language">guarded-command style</a>. The guard should ideally define the meaning of the action. Put all enablement conditions in the guard. If the guard holds, the action may fire at any time in true event-driven style. This is why I now prefer writing TLA+ directly over PlusCal: TLA+ forces you to think in guarded-command actions, which is how distributed algorithms are meant to be designed. Yes, PlusCal is easier for developers to read, but it also nudges you toward sequential implementation-shaped thinking. And recently, with tools like <a href="https://github.com/will62794/spectacle">Spectacle</a>, sharing and visually exploring TLA+ specs <a href="https://muratbuffalo.blogspot.com/2025/11/tla-modeling-of-aws-outage-dns-race.html">got much easier</a>.</p><h3>Step back and ask what you forgot to model</h3><p>There is no substitute for thinking hard about your system. TLA+ modeling is only there to help you think hard about your system, and cannot substitute thinking about it. Check that you incorporated all relevant aspects: failures, message reordering, repair, reconfiguration.</p><h3>Write TypeOK invariants&nbsp;</h3><p>TLA+ is not typed, so you should state types explicitly and early by writing TypeOK invariants. A good TypeOK invariant provides an executable documentation for your model. Writing this in seconds can save you many minutes of hunting runtime bugs through TLA+ counterexample logs.</p><h3>Write as many invariants as you can</h3><p>If a property matters, make it explicit as an invariant. Write them early. Expand them over time. Try to keep your invariants as tight as possible. Document your learnings about invariants and non-invariants. A TLA+ spec is a communication artifact. Write it for readers, not for the TLC model checker. Be explicit and boring for the sake of clarity.</p><h3>Write progress properties</h3><p>Safety invariants alone are not enough. Check that things eventually happen: requests complete, leaders emerge, and goals accomplished. Many "correct" models may quietly do nothing forever. Checking progress properties catch paths that stall.</p><h3>Be suspicious of success</h3><p>A successful TLC run proves nothing unless the model explores meaningful behavior. Low coverage or tiny state spaces usually mean the model is over-constrained or wrong. Break the spec on purpose to check that your spec is actually doing some real work, and not giving up in a vacuous/trivial way. Inject bugs on purpose. If your invariants do not fail, they are too weak. Test the spec by sabotaging it.</p><h3>Optimize model checking efficiency last</h3><p>Separate the model from the model checker. The spec should stand on its own. Using the cfg file, you can optimize for model checking by using appropriate configuration, constraints, bounds for counters, and symmetry terms.</p><p>You can find many examples and walkthroughs of <a href="https://muratbuffalo.blogspot.com/search/label/tla">TLA+ specifications on my blog</a>.</p><p>There are many more in the<a href="https://github.com/tlaplus/Examples"> TLA+ repo</a> as well.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US threatens EU digital services market access (110 pts)]]></title>
            <link>https://twitter.com/ustraderep/status/2000990028835508258</link>
            <guid>46299377</guid>
            <pubDate>Wed, 17 Dec 2025 08:04:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ustraderep/status/2000990028835508258">https://twitter.com/ustraderep/status/2000990028835508258</a>, See on <a href="https://news.ycombinator.com/item?id=46299377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla reports another Robotaxi crash (151 pts)]]></title>
            <link>https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/</link>
            <guid>46297702</guid>
            <pubDate>Wed, 17 Dec 2025 02:52:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/">https://electrek.co/2025/12/15/tesla-reports-another-robotaxi-crash-even-with-supervisor/</a>, See on <a href="https://news.ycombinator.com/item?id=46297702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="765" src="https://electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1600" alt="Tesla Robotaxi hero" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/10/Tesla-Robotaxi-hero.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>Tesla has reported yet another crash involving its Robotaxi fleet in Austin to the NHTSA. The new data keeps the program’s accident rate alarmingly high compared to human drivers, even as the company prepares to <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/12/09/tesla-ceo-elon-musk-claims-driverless-robotaxis-coming-to-austin-in-3-weeks/">remove human safety supervisors from the vehicles</a>.</p>



<p>As we have been tracking in our <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">previous coverage of the Robotaxi pilot</a> in Austin, Tesla is required to report crashes involving its automated driving systems (ADS) to the NHTSA under a Standing General Order.</p>



<p>For months, we’ve seen these reports trickle in from Tesla’s small pilot fleet in Texas. In November, we reported that the fleet had reached <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">7 total crashes</a> as of September.</p>



<p>Now, a new report filed by Tesla reveals an 8th crash occurred in October 2025.</p>	
	



<p>According to the filing, the incident took place on October [Day Redacted], 2025, in Austin. The valid report (Report ID: 13781-11986) lists the “Highest Injury Severity Alleged” as “No Injured Reported,” but details are scarce because, as is typical for Tesla, the narrative description of the crash has been redacted to hide proprietary information.</p>



<p>We have been highlighting how Tesla often abuses NHTSA’s capability to redact much of the information in the crash reports, especially the ‘Narrative’ section, which explains precisely what happened in the incident.</p>



<p>It’s possible that Tesla’s Robotaxis are not responsible for some of these crashes, but we wouldn’t know because Tesla redacts most information.</p>



<p>In this new filing for the accident that happened in October, Tesla went even further as it even refrains from answering some of the sections. Instead, it says “see the narrative,” which again is redacted.</p>



<p>Here’s the updated list of Tesla Robotaxi crashes:</p>



<figure><table><thead><tr><td><strong>Report ID</strong></td><td><strong>Incident Date</strong></td><td><strong>City</strong></td><td><strong>State</strong></td><td><strong>Crash With</strong></td><td><strong>Highest Injury Severity Alleged</strong></td></tr></thead><tbody><tr><td>13781-11986</td><td>OCT-2025</td><td>Austin</td><td>TX</td><td>Other, see Narrative</td><td>No Injured Reported</td></tr><tr><td>13781-11787</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Animal</td><td>No Injured Reported</td></tr><tr><td>13781-11786</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Non-Motorist: Cyclist</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11784</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Passenger Car</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11687</td><td>SEP-2025</td><td>Austin</td><td>TX</td><td>Other Fixed Object</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11507</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>SUV</td><td>Property Damage. No Injured Reported</td></tr><tr><td>13781-11459</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>Other Fixed Object</td><td>Minor W/O Hospitalization</td></tr><tr><td>13781-11375</td><td>JUL-2025</td><td>Austin</td><td>TX</td><td>SUV</td><td>Property Damage. No Injured Reported</td></tr></tbody></table></figure>



<p>We do know that the crash involved “Other” as the conflict partner, and the vehicle was “Proceeding Straight” at the time.</p>



<h3 id="h-tesla-robotaxi-crash-rate">Tesla Robotaxi Crash Rate</h3>



<p>While a few fender benders might not seem like headline news, it becomes significant when you look at the math.</p>



<p>Last month, Tesla confirmed the fleet had traveled roughly 250,000 miles. With 7 reported crashes at the time, <a href="https://electrek.co/2025/11/17/tesla-robotaxi-had-3-more-crashes-now-7-total/" target="_blank" rel="noreferrer noopener">Tesla’s Robotaxi was crashing roughly once every 40,000 miles </a>(extrapolating from the previously disclosed Robotaxi mileage).</p>



<p>For comparison, the average human driver in the US crashes about once every 500,000 miles.</p>



<p>This means Tesla’s “autonomous” vehicle, which is supposed to be the future of safety, is crashing 10x more often than a human driver.</p>



<p>While Tesla’s Robotaxi fleet reportedly increased in November, with the number of cars spotted going up to 29, there’s no evidence that the Robotaxi mileage increased. In fact, the utilization rate indicates Tesla is running only a few vehicles at a time – meaning that mileage might have actually gone down.</p>



<p>And that is not even the scariest part.</p>



<h3 id="h-the-supervisor-paradox">The Supervisor Paradox</h3>



<p>The most critical detail that gets lost in the noise is that these crashes are happening with a human safety supervisor in the driver’s seat (for highway trips) or passenger seat, with a finger on a kill switch.</p>



<p>These employees are trained to intervene and take control of the vehicle if the software makes a mistake. </p>



<p>If the car is crashing this frequently with a human babysitter trying to prevent accidents, imagine what the crash rate would be without them.</p>



<p>Yet, that is exactly what Tesla is doing.</p>



<p>Elon Musk recently claimed that Tesla would <a target="_blank" rel="noreferrer noopener" href="https://electrek.co/2025/12/09/tesla-ceo-elon-musk-claims-driverless-robotaxis-coming-to-austin-in-3-weeks/">remove safety monitors from the Robotaxi fleet</a> in Austin within “three weeks.”</p>



<p>Yesterday, we reported that <a href="https://electrek.co/2025/12/14/tesla-robotaxi-spotted-without-a-safety-driver-austin-musk-confirms-testing-begins/">a Tesla Robotaxi was spotted for the first time without anyone in the front seat</a>s, and Musk confirmed that Tesla started testing without a supervisor.</p>



<h3 id="h-electrek-s-take">Electrek’s Take</h3>



<p>This is becoming hard to watch.</p>



<p>We have <a href="https://electrek.co/2025/12/10/elon-musk-waymo-never-had-chance-against-tesla/" target="_blank" rel="noreferrer noopener">Waymo operating fully driverless</a> commercial services in multiple cities with over 100 million miles of data showing they are safer than humans. They are not without their issues, but they are at least sharing data that is encouraging, including not redacting the NTHSA crash reporting.</p>




	<p>Meanwhile, Tesla is struggling to keep a small test fleet in Austin from hitting things, even with professional safety drivers on board.</p>



<p>Removing the safety supervisors when your crash rate is already orders of magnitude worse than the average human seems reckless. It feels like another case of prioritizing the “optics” of autonomy over the actual safety required to deploy it.</p>



<p>If Tesla pulls the supervisors while the data looks like this, it’s no longer a pilot program. It’s a gamble. And it’s not just gambling on its stock price, it’s gambling with everyone’s safety.</p>




	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
    </channel>
</rss>