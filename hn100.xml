<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 11 Mar 2024 21:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Kdenlive 24.02 open source video editor released (136 pts)]]></title>
            <link>https://kdenlive.org/en/2024/03/kdenlive-24-02-0-released/</link>
            <guid>39671218</guid>
            <pubDate>Mon, 11 Mar 2024 17:46:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kdenlive.org/en/2024/03/kdenlive-24-02-0-released/">https://kdenlive.org/en/2024/03/kdenlive-24-02-0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=39671218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The team is thrilled to introduce the much-anticipated release of Kdenlive 24.02, featuring a substantial upgrade to our frameworks with the adoption of <em>Qt6</em> and <em>KDE Frameworks 6</em>. This significant under-the-hood transformation establishes a robust foundation, shaping the trajectory of Kdenlive for the next decade. The benefits of this upgrade are particularly noteworthy for Linux users, as improved Wayland support enhances the overall experience. Additionally, users on Windows, MacOS, and Linux will experience a substantial performance boost since Kdenlive now runs natively on <em>DirectX</em>, <em>Metal</em>, and <em>Vulkan </em>respectively, replacing the previous abstraction layer reliance on <em>OpenGL</em> and <em>Angle</em>, resulting in a more efficient and responsive application. This upgrade brings significant changes to packaging, featuring the introduction of a dedicated package for <em>Apple Silicon</em>, the discontinuation of <em>PPA</em> support and an enhanced method for installing the <em>Whisper</em> and <em>Vosk</em> speech-to-text engines.</p>
<p>While a significant effort has been invested in providing a stable user experience in this transition, we want to acknowledge that, like any evolving software, there might be some rough edges. Some known issues include: themes and icons not properly applied in Windows and AppImage, text not properly displayed in clips in the timeline when using Wayland and a crash in the Subtitle Manager under MacOS. Worth noting also is the temporary removal of the audio recording feature pending its migration to Qt6. We appreciate your understanding and encourage you to provide feedback in this release cycle so that we can continue refining and improving Kdenlive. In the upcoming release cycles (24.05 and 24.08), our development efforts will concentrate on stabilizing any remaining issues stemming from this upgrade. We’ll also prioritize short-term tasks outlined in our <a href="https://kdenlive.org/en/kdenlive-roadmap/">roadmap</a>, with a specific emphasis on enhancing performance and streamlining the effects workflow.</p>
<p>In terms of performance enhancements, this release introduces optimized RAM usage during the import of clips into the Project Bin. Furthermore, it addresses Nvidia encoding and transcoding issues with recent ffmpeg versions.</p>
<p>To safeguard project integrity, measures have been implemented to prevent corruptions. Projects with non-standard and variable frame rates are not allowed to be created. When rendering a project containing variable frame rate clips, users will receive a warning with the option to transcode these clips, mitigating potential audio-video synchronization issues.</p>
<p>Users can now enjoy the convenience of an automatic update check <strong>without</strong> an active network connection. Glaxnimate animations now default to the rawr format, replacing Lottie. Furthermore, we’ve introduced an FFv1 render preset to replace the previously non-functional Ut Video. And multiple project archiving issues have been fixed.</p>
<p>Beyond performance and stability we’ve managed to sneak in several nifty quality-of-life and usability improvements, the highlights include:</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JSON Canvas – An open file format for infinite canvas data (340 pts)]]></title>
            <link>https://jsoncanvas.org/</link>
            <guid>39670922</guid>
            <pubDate>Mon, 11 Mar 2024 17:22:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jsoncanvas.org/">https://jsoncanvas.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39670922">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="readme" data-node-type="file" data-node-file="readme.md">
          <p>readme</p>
          <h2 id="an-open-file-format-for-infinite-canvas-data">An open file format for infinite canvas data.</h2>

<p>Infinite canvas tools are a way to view and organize information spatially, like a digital whiteboard. Infinite canvases encourage freedom and exploration, and have become a popular interface pattern across many apps.</p>

<p>The JSON Canvas format was created to provide longevity, readability, interoperability, and extensibility to data created with infinite canvas apps. The format is designed to be easy to parse and give users <a href="https://stephango.com/file-over-app">ownership over their data</a>. JSON Canvas files use the <code>.canvas</code> extension.</p>

<p>JSON Canvas was originally created for <a href="https://obsidian.md/blog/json-canvas/">Obsidian</a>. JSON Canvas can be implemented freely as an import, export, and storage format for any app or tool. This site, and all the resources associated with JSON Canvas are <a href="https://github.com/obsidianmd/jsoncanvas">open source</a> under the MIT license.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are We Watching the Internet Die? (150 pts)]]></title>
            <link>https://www.wheresyoured.at/are-we-watching-the-internet-die/</link>
            <guid>39670900</guid>
            <pubDate>Mon, 11 Mar 2024 17:19:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/are-we-watching-the-internet-die/">https://www.wheresyoured.at/are-we-watching-the-internet-die/</a>, See on <a href="https://news.ycombinator.com/item?id=39670900">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p>Sometime this month,<a href="https://www.cnbc.com/2024/03/01/reddit-seeking-a-valuation-of-up-to-6point5-billion-in-ipo.html?ref=wheresyoured.at"> <u>Reddit will go public at a valuation of $6.5bn</u></a>.<a href="https://www.cnn.com/2024/02/26/tech/reddit-ipo-users-can-buy-shares/index.html?ref=wheresyoured.at"> <u>Select Redditors were offered the chance to buy stock at the initial listing price</u></a>, which it hasn’t announced yet but is <a href="https://www.ft.com/content/b3199303-d419-482d-96c7-e73c0b0ee8ed?ref=wheresyoured.at"><u>expected to be in the range of $31-34 per share</u></a>. Regardless of the actual price, I wouldn’t be surprised if Reddit shares quickly fall below the IPO price, based on the fact that Reddit is an absolute dog of a company,<a href="https://www.reuters.com/technology/reddit-makes-us-ipo-filing-public-2024-02-22/?ref=wheresyoured.at"> <u>losing $90.8 million on $804 million of revenue in 2023</u></a> and <a href="https://www.cnn.com/2024/02/23/tech/reddit-ipo-filing-business-plan/index.html?ref=wheresyoured.at"><u>never having turned a profit</u></a>.<a href="https://www.sec.gov/Archives/edgar/data/1713445/000162828024006294/reddits-1q423.htm?ref=wheresyoured.at"> <u>Reddit's S1</u></a><u> </u>(the initial registration form for taking a company public) laughably claims that advertising on the site is "rapidly evolving" and that it is "still in the early phases of growing this business,"<a href="https://techcrunch.com/2009/11/12/reddit-advertising/?ref=wheresyoured.at"> <u>with "this business" referring to one that Reddit launched 15 years ago</u></a>.</p><p>The Reddit IPO is one of the biggest swindles in corporate history, where millions of unpaid contributors made billions of posts so that<a href="https://www.bizjournals.com/sanfrancisco/inno/stories/news/2024/02/23/reddit-ceo-steve-huffman-total-compensation-2023.html?ref=wheresyoured.at#:~:text=Bay%20Area%20Inno%20-%20Reddit%20CEO,exceeded%20%24193M%20last%20year"> <u>CEO Steve Huffman could make $193 million</u></a> in 2023<a href="https://www.reuters.com/technology/reddit-lay-off-about-5-workforce-wsj-2023-06-06/?ref=wheresyoured.at"> <u>while laying off 90 people</u> and</a> effectively <a href="https://www.theverge.com/2023/6/15/23762501/reddit-ceo-steve-huffman-interview-protests-blackout?ref=wheresyoured.at"><u>pushing third party apps off of the platform</u></a> by charging exorbitant rates for API access, which in <a href="https://www.theverge.com/2023/6/12/23755974/reddit-subreddits-going-dark-private-protest-api-changes?ref=wheresyoured.at"><u>turn prompted several prolonged “strikes” by users</u></a>, with some of the most popular subreddits going silent for a short period of time. Reddit, in turn, effectively “couped” these subreddits, replacing their longstanding moderators with <a href="https://www.theverge.com/2023/7/20/23802370/reddit-over-reopens-subreddit-protest-male-fashion-advice?ref=wheresyoured.at"><u>ones of its own choosing</u></a> — people who would <a href="https://arstechnica.com/gadgets/2023/07/reddit-calls-for-a-few-new-mods-after-axing-polarizing-some-of-its-best/?ref=wheresyoured.at"><u>happily toe the party line and reopen them to the public</u></a>.&nbsp;</p><p>None of the people that spent hours of their lives lovingly contributing to Subreddits, or performing the vital-but-thankless role of moderation, will make a profit off of Reddit's public listing, but<a href="https://www.cnbc.com/2024/02/22/openai-ceo-sam-altman-stands-to-net-millions-as-reddit-goes-public.html?ref=wheresyoured.at"> <u>Sam Altman will make hundreds of millions of dollars for his $50 million investment from 2014</u></a>.<a href="https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/?ref=wheresyoured.at"> <u>Reddit also announced that it had cut a $60 million deal to allow Google to train its models on Reddit's posts</u></a>, once again offering users nothing in return for their hard work.</p><p><a href="https://www.sec.gov/Archives/edgar/data/1713445/000162828024006294/reddits-1q423.htm?ref=wheresyoured.at#:~:text=As%20a%20way,enjoyable%20as%20possible."><u>Huffman's letter to investors</u></a> waxes poetic about Redditors' "deep sense of ownership over the communities they create," and justifies taking the company public by claiming that he wants "this sense of ownership to be reflected in real ownership" as he offers them a chance to buy non-voting stock in a company that they helped enrich. Huffman ends his letter by saying that Reddit is "one of the internet's largest corpuses of authentic and constantly updated human-generated experience" before referring to it as the company's "data advantage and intellectual property," describing Redditors' posts as "data [that] constantly grows and regenerates as users converse."</p><p>We're at the end of a vast, multi-faceted con of internet users, where ultra-rich technologists tricked their customers into building their companies for free. And while the trade once seemed fair, it's become apparent that these executives see users not as willing participants in some sort of fair exchange, but as veins of data to be exploitatively mined as many times as possible, given nothing in return other than access to a platform that may or may not work properly.</p><p>This is, of course, the crux of Cory Doctorow's<a href="https://en.wikipedia.org/wiki/Enshittification?ref=wheresyoured.at"> <u>Enshittification theory</u></a>, where Reddit has moved from pleasing users to pleasing its business customers to, now, pleasing shareholders at what will inevitably be the cost of the platform's quality.</p><p>Yet what's happening to the web is far more sinister than simple <em>greed</em>, but the destruction of the user-generated internet, where executives think they've found a way to replace human beings making cool things with generative monstrosities trained on datasets controlled and monetized by trillion-dollar firms.</p><p>Their ideal situation isn't one where you visit distinct websites with content created by human beings, but a return to the dark ages of the internet where most traffic ran through a series of heavily-curated portals operated by a few select companies, with results generated based on datasets that are <a href="https://futurism.com/ai-trained-ai-generated-data-interview?ref=wheresyoured.at"><u>increasingly poisoned by generative content</u></a> built to fill space rather than be consumed by a customer.</p><p>The algorithms are easily-tricked, and the tools used to trick them are becoming easier to use and scale.</p><p>And it's slowly killing the internet.</p><h2 id="degenerative-ai"><strong>Degenerative AI</strong></h2><p>After the world's governments began their above-ground nuclear weapons tests in the mid-1940s, radioactive particles made their way into the atmosphere, permanently tainting all modern steel production, making it challenging (or impossible) to build certain machines (such as those that measure radioactivity). As a result, we've a limited supply of something called "<a href="https://qz.com/emails/quartz-obsession/1849564217/low-background-metal-pure-unadulterated-treasure?ref=wheresyoured.at"><u>low-background steel</u></a>," pre-war metal that oftentimes has to be harvested from ships sunk before the first detonation of a nuclear weapon, including <a href="https://www.theatlantic.com/science/archive/2019/10/search-dark-matter-depends-ancient-shipwrecks/600718/?ref=wheresyoured.at"><u>those dating back to the Roman Empire</u></a>.</p><p>Generative AI models are trained by using massive amounts of text scraped from the internet, meaning that the consumer adoption of generative AI has brought a degree of radioactivity to its own dataset. As more internet content is created, either partially or entirely through generative AI, the models themselves will find themselves increasingly inbred, training themselves on content written by their own models which are, on some level,<a href="https://lowbackgroundsteel.ai/?ref=wheresyoured.at"> <u>permanently locked in 2023</u></a>, before the advent of a tool that is specifically intended to replace content created by human beings.</p><p>This is a phenomenon that Jathan Sadowski calls "<a href="https://twitter.com/jathansadowski/status/1625245803211272194?lang=en&amp;ref=wheresyoured.at"><u>Habsburg AI</u></a>," where "a system that is so heavily trained on the outputs of other generative AIs that it becomes an inbred mutant, likely with exaggerated, grotesque features." In reality, a Habsburg AI will be one that is increasingly more <em>generic</em> and <em>empty</em>, normalized into a slop of anodyne business-speak as its models are trained on increasingly-identical content.</p><p>LinkedIn, already a repository of empty-headed corpo-nonsense,<a href="https://techcrunch.com/2023/03/15/linkedin-expands-its-generative-ai-assistant-to-recruitment-ads-and-writing-profiles/?ref=wheresyoured.at"> <u>already lets users write generate messages, profiles and job descriptions using AI</u></a>, and<a href="https://www.linkedin.com/help/linkedin/answer/a5538339?ref=wheresyoured.at#:~:text=For%20example%2C%20some%20of%20our,data%20from%20the%20training%20dataset."> <u>anything you create using these generative features is immediately fed back into Azure's OpenAI models owned by its parent company Microsoft</u></a>, which invested $10 billion in OpenAI in early 2023. While LinkedIn is yet to introduce fully-automated replies,<a href="https://twitter.com/nilansaha/status/1762390930550927823?ref=wheresyoured.at"> <u>Chrome extensions already exist to flood the platform with generic responses</u></a>, feeding more genericisms into the mouth of Microsoft and OpenAI's models.</p><p>Generative AI also naturally aligns with the toxic incentives created by the largest platforms. Google's algorithmic catering to the Search Engine Optimization industry naturally benefits those who can spin up large amounts of "relevant" content rather than content created by humans.<a href="https://searchengineland.com/google-released-massive-search-quality-improvements-with-march-2024-core-update-and-multiple-spam-updates-438144?ref=wheresyoured.at"> <u>While Google has claimed that their upcoming "core" update will help promote "content for people and not to rank in search engines,"</u></a><a href="https://www.theregister.com/2022/08/19/google_search_algorithm/?ref=wheresyoured.at"> <u>it’s made this promise before</u></a>, and I severely doubt anything meaningfully changes. After all, Google makes up more than 85% of all search traffic and<a href="https://www.theverge.com/2023/10/26/23933206/google-apple-search-deal-safari-18-billion?ref=wheresyoured.at"> <u>pays Apple billions a year to make Google search the default on Apple devices</u></a>.</p><p>And because these platforms were built to reward scale and volume far more often than quality, AI naturally rewards those who can find the spammiest ways to manipulate the algorithm. 404 Media reports that<a href="https://www.404media.co/inside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them/?ref=wheresyoured.at"> <u>spammers are making thousands of dollars from TikTok's creator program by making "faceless reels" where AI-generated voices talk over spliced-together videos ripped from YouTube</u></a>, and<a href="https://www.instagram.com/reel/C1ZidLAuksO/?ref=404media.co"> <u>a cottage industry of automation gurus</u></a> are cashing in by helping others flood Facebook, TikTok and Instagram with low-effort videos that are irresistible to algorithms.</p><p>Amazon's Kindle eBook platform has been flooded with AI-generated content that<a href="https://www.wired.com/story/scammy-ai-generated-books-flooding-amazon/?ref=wheresyoured.at"> <u>briefly dominated bestseller lists</u></a>,<a href="https://arstechnica.com/information-technology/2023/09/ai-generated-books-force-amazon-to-cap-ebook-publications-to-3-per-day/?ref=wheresyoured.at"> <u>forcing Amazon to limit authors to publishing three books a day</u></a>.<a href="https://www.wired.com/story/scammy-ai-generated-books-flooding-amazon/?ref=wheresyoured.at"> <u>This hasn't stopped spammers from publishing awkward rewrites and summaries of other people's books</u></a>, and because Amazon's policies don't outright ban AI-generated content, ChatGPT has become an inoperable cancer on the body of the publishing industry.</p><p>"Handmade" goods store Etsy has its own AI problem,<a href="https://www.theatlantic.com/technology/archive/2023/06/ai-chatgpt-side-hustle/674415/?ref=wheresyoured.at"> <u>with The Atlantic reporting last year</u></a> that the platform was now pumped full of AI-generated art, t-shirts and mugs that, in turn, use ChatGPT to optimize listings to rank highly in Google search. As a profitable public company, Etsy has little incentive to change things, even if the artisanal products on the platform are being crowded out by generative art pasted on drop-shipped shirts.<a href="https://www.pymnts.com/artificial-intelligence-2/2023/ebay-to-add-ai-powered-image-based-listing-tool/?ref=wheresyoured.at"> <u>eBay, on the other hand, is leaning into the spam, offering tools to generate entire listings based on a single image using generative AI</u></a>.</p><p>The Wall Street Journal reported last year that<a href="https://www.wsj.com/articles/chatgpt-already-floods-some-corners-of-the-internet-with-spam-its-just-the-beginning-9c86ea25?ref=wheresyoured.at"> <u>magazines are now inundated with AI-generated pitches for articles</u></a>, and<a href="https://www.theguardian.com/technology/2023/feb/21/sci-fi-publisher-clarkesworld-halts-pitches-amid-deluge-of-ai-generated-stories?ref=wheresyoured.at"> <u>renowned sci-fi publisher Clarkesworld was forced to close submissions after receiving an overwhelming amount of AI-generated stories</u></a>. Help A Reporter Out used to be a way for journalists to find potential sources and quotes, except requests are now met with a deluge of AI-generated spam.</p><p>These stories are, of course, all manifestations of a singular problem: that generative artificial intelligence is poison for an internet dependent on algorithms.</p><p>There are simply too many users, too many websites and too many content providers to manually organize and curate the contents of the internet, making algorithms necessary for platforms to provide a service. Generative AI is a perfect tool for soullessly churning out content to match a particular set of instructions — such as those that an algorithm follows — and while an algorithm can theoretically be tuned to evaluate content as "human," so can scaled content be tweaked to make it <em>seem</em> more human.</p><p>Things get worse when you realize that the sheer <em>volume</em> of internet content makes algorithmic recommendations a necessity to sift through an ever-growing pile of crap. Generative AI<a href="https://twitter.com/sugarsmorecake/status/1763941484653343056?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1763941484653343056%7Ctwgr%5Ea872ae864382ff6ce94a7bc72d711eaacb954876%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.404media.co%2Finside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them%2F&amp;ref=wheresyoured.at"> <u>allows creators to weaponize the algorithms' weaknesses</u></a> to monetize and popularize low-effort crap, and ultimately, what is a platform to do? Ban anything that uses AI-generated content? Adjust the algorithm to penalize videos without people's faces? How does a platform judge the difference between a popular video and a video that the platform made popular? And if these videos are made by humans and enjoyed by humans, why <em>should</em> it stop them?</p><p>Google might <em>pretend</em> it cares about the quality of search results, but nothing about search's decade-long decline has suggested it’s actually going to do anything.<a href="https://developers.google.com/search/docs/essentials/spam-policies?hl=en&amp;ref=wheresyoured.at"> <u>Google's spam policies</u></a> have claimed<a href="https://web.archive.org/web/20221207161654/https://developers.google.com/search/docs/essentials/spam-policies?hl=en"> <em><u>for years</u></em></a> that scraped content (outright ripping the contents of another website) was grounds for removal from Google, but even the most cursory glance at any news search shows how often sites thinly rewrite or outright steal others' content. And I can't express enough how bad (yet inevitable) the existence of the<a href="https://www.acumenresearchandconsulting.com/search-engine-optimization-services-market?ref=wheresyoured.at#:~:text=The%20market%20size%20of%20search,USD%2046.7%20Billion%20in%202021."> <u>$40 billion Search Engine Optimization industry</u></a> is, and how much of a boon being able to semi-automate the creation and optimization of content<a href="https://developers.google.com/search/docs/essentials?ref=wheresyoured.at"> <u>to the standards of an algorithm that Google has explained in exhaustive detail</u></a>. While it's plausible that Google might genuinely try and fight the influx of SEO-generated articles, one has to wonder why it’d bother to try now after spending decades catering to the industry.</p><p>As we speak, the battle that platforms are fighting is against <em>generative spam</em>, a cartoonish and obvious threat of outright nonsense, meaningless chum that can and should (and likely will) be stopped. In the process, they're failing to see that this isn't a war against <em>spam</em>, but a war against <em>crap</em>, and the overall normalization and intellectual numbing that comes when content is created to please algorithms and provide a minimum viable product for consumers. Google's "useless" results problem isn't one borne of content that has no meaning, but of content that only sort of helps, that is the "right" result but doesn't actually provide any real thought behind it, like the endless "how to fix error code X" results full of well-meaning and plausibly helpful content that doesn't really help at all.</p><p>The same goes for Etsy and Amazon. While Etsy's "spam" is an existential threat to actual artisans building something with their hands, it's not actual spam — it's cheaply-made crap that nevertheless fulfills a need and <em>sort of </em>fits Etsy's remit. Amazon doesn't have any incentive to get rid of low-quality books that sell for<a href="https://nymag.com/intelligencer/2023/01/why-does-it-feel-like-amazon-is-making-itself-worse.html?ref=wheresyoured.at"> <u>the same reason that it doesn't get rid of its other low-quality items</u></a>. People aren't looking for the best, they're looking to fulfill a need, even if that need is fulfilled with poorly-constructed crap. </p><p>Platforms likely conflate positioning with popularity, failing to see the self-fulfilling prophecy of an algorithm making stuff popular because said stuff is built to please the algorithm creating more demand for content to please the algorithm. "Viral" content is no longer a result of lots of people deciding that they find something interesting — it's a condition created by algorithms manipulated by forces that are getting stronger and more nuanced thanks to generative AI.</p><p>We're watching the joint hyper-scaling and hyper-normalization of the internet, where all popular content begins to look the same to appeal to algorithms run by companies obsessed with growth. Quality control in AI models only exists to stop people from nakedly exploiting the network through unquestionably iniquitous intent, rather than people making shitty stuff that kind of sucks but gets popular because an algorithm says so.</p><p>This isn't a situation where these automated tools are giving life to new forms of art or interesting new concepts, but regurgitations of an increasingly less unique internet, <em>because these models are trained on data drawn from the internet.</em> Like a plant turning to capture sunlight,<a href="https://www.wheresyoured.at/the-anti-economy/"> <u>parts of the internet have already twisted toward the satisfaction of algorithms</u></a>, and as others become dependent on generative AI (<a href="https://slate.com/technology/2024/02/quora-what-happened-ai-decline.html?ref=wheresyoured.at"><u>like Quora, which now promotes ChatGPT-generated answers at the top of results</u></a>), so will the web become more dependent and dictated by automated systems.</p><p>The ultimate problem is that this morass of uselessness will lead companies like Google to force their generative AIs to "fix" the problem by generating answers to sift through the crap.<a href="https://www.theverge.com/2023/8/14/23831391/amazon-review-summaries-generative-ai?ref=wheresyoured.at"> <u>Amazon now summarizes reviews using generative AI</u></a>, legitimizing<a href="https://www.wired.com/story/fake-amazon-reviews-underground-market/?ref=wheresyoured.at"> <u>the thousands of faked and paid-for reviews on the platform</u></a> and presenting them as verified and trusted information from Amazon itself.<a href="https://blog.google/products/search/google-search-generative-ai-international-expansion/?ref=wheresyoured.at"> <u>Google has already been experimenting with its "Search Generative Experience</u></a>" that <a href="https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge?ref=wheresyoured.at"><u>summarizes entire articles on iOS and Chrome</u></a>, and Microsoft's Bing search has already integrated summaries from Copilot, with both basing their answers off of a combination of search and training data.</p><p>Yet in doing so, these platforms gain a dangerous hold on the world's information.<a href="https://www.searchenginejournal.com/google-announces-deal-to-show-more-reddit-content/509132/?ref=wheresyoured.at"> <u>Google's deal with Reddit also gave it real time access to Reddit's content</u></a>, allowing it to show Reddit posts natively in search (and directly access Reddit posts data for training purposes). Yet at some point these portals will generate an answer based off of the data they have (or have access to, <a href="https://www.404media.co/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools/?ref=wheresyoured.at"><u>in the case of Tumblr and Wordpress</u></a>) rather than linking you to a place where you can find an answer by reading something created by another person. There could be a future where the majority of web users experience the web through a series of portals,<a href="https://www.theverge.com/2024/1/28/24053882/arc-search-browser-web-app-ios?ref=wheresyoured.at"> <u>like Arc Search's "browse for me" feature, which visits websites for you and summarizes their information using AI</u></a>.</p><p>Right now, the internet is controlled by a few distinct platforms, each one intent on interrupting the exploratory and creative forces that made the web great. I believe that their goal is to intrude on our ability to browse the internet, to further obfuscate the source of information while paying the platforms for content that their users make for free. Their eventual goal, in my mind, is to remove as much interaction with the larger internet as possible, summarizing and regurgitating as much as they can so that they can control and monetize the results as much as possible.</p><p>On some level, I fear that the current platforms intend to use AI to become something akin to an Internet Service Provider, offering "clean" access to a web that has become too messy and unreliable as a direct result of the platforms' actions, eventually finding ways to monetize your information's prominence in their portals, models and chatbots. As that happens, it will begin to rot out the rest of the internet, depriving media entities and social networks of traffic as executives like Steve Huffman cut further deals to monetize free labor with platforms that will do everything they can to centralize all internet traffic to two or three websites.</p><p>And as the internet becomes dominated by these centralized platforms and the sites they trawl for content, so begins the vicious cycle of the Habsburg AI. OpenAI's ChatGPT and Anthropic's Claude are dependent on a constant flow of training data to improve their models, to the point that it's<a href="https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai?ref=wheresyoured.at"> <u>effectively impossible for them to operate without violating copyright</u></a>. As a result, they can't be too picky when it comes to the information they choose, meaning that they're more than likely going to depend on openly-available content from the internet, which as I've suggested earlier will become increasingly normalized by the demands of algorithms and the ease of automating the generic content that satisfies them.</p><p>I am not saying that user-generated content will <em>disappear,</em> but that human beings cannot create content at the scale that automation can, and<a href="https://www.theverge.com/23753963/google-seo-shopify-small-business-ai?ref=wheresyoured.at"> <u>when a large chunk of the internet is content for robots</u></a>, <em>that</em> is the content that will inform tomorrow's models. The only thing that can truly make them better is <em>more stuff</em>, but when the majority of stuff being created isn't good, or interesting, or even written for a human being, ChatGPT or Claude's models will learn the rotten habits of rotten content. This is why so many models' responses sound so similar — they're heavily dependent on the stuff they're fed for their outputs, and so much of their "intelligence" comes from the same training data.</p><p>It's a different flavor of the same problem — these models don't really "know" anything. They're copying other people's homework.</p><blockquote>As an aside, I also fear for the software code that's created by generative AI products like GitHub Co-pilot.<a href="https://www.infoworld.com/article/3713141/github-copilot-makes-insecure-code-even-less-secure-snyk-says.html?ref=wheresyoured.at"> <u>A study by security firm Snyk</u></a> found that GitHub Copilot and other AI-powered coding platforms, which were trained on publicly-available code (and based on the user's own codebase), can replicate existing security issues, proliferating problems rather than fixing them.<a href="https://cyber.nyu.edu/2021/10/15/ccs-researchers-find-github-copilot-generates-vulnerable-code-40-of-the-time/?ref=wheresyoured.at"> <u>NYU's Center for Cybersecurity also found in 2023 study that CoPilot generated code with security vulnerabilities 40% of the time</u></a>.</blockquote><p>These are also the hard limits that you're going to see with generative images and video. While the internet is a giant hole of content you can easily and cheaply consume for training, visual media requires a great deal of significantly more complex data — and that’s on top of the significant and obvious copyright issues. ChatGPT's DALL-E (images) and Sora (video) products are,<a href="https://www.wheresyoured.at/sam-altman-fried/"> <u>as I've noted</u></a>, limited by the availability of ways to teach them as well as the limits of generative AI itself, meaning that video may continue to dominate the internet as text-based content finds itself crowded out by AI-generated content.<a href="https://finance.yahoo.com/news/openai-sam-altman-says-giant-164924270.html?ref=wheresyoured.at"> <u>This may be why Sam Altman is trying to claim that giant AI models are not the future</u></a> — because there may not be enough fuel to grow them much further. After all,<a href="https://cnbc.com/2024/01/18/openai-ceo-on-nyt-lawsuit-ai-models-dont-need-publishers-data-.html?ref=wheresyoured.at"> <u>Altman claims that any one data source "doesn't move the needle" for OpenAI</u></a>.</p><p>There's also no way to escape the fact that these hungry robots require legal plagiarism, and any number of copyright assaults could massively slow their progress.<a href="https://www.axios.com/2024/01/12/ai-forget-unlearn-data-privacy?ref=wheresyoured.at"> <u>It's incredibly difficult to make a model forget information</u></a>, meaning that there may, at some point, be steps <em>back </em>in the development of models if datasets have to be reverted to previous versions with copyrighted materials removed.</p><p>The<a href="https://www.vox.com/technology/2024/1/18/24041598/openai-new-york-times-copyright-lawsuit-napster-google-sony?ref=wheresyoured.at"> <u>numerous</u></a><a href="https://www.nytimes.com/2024/02/28/technology/openai-copyright-suit-media.html?ref=wheresyoured.at"> <u>lawsuits</u></a><a href="https://www.cnbc.com/2024/01/05/microsoft-openai-sued-over-copyright-infringement-by-authors.html?ref=wheresyoured.at"> <u>against</u></a> OpenAI could break the back of the company, and while Altman and other AI fantasists may pretend that these models are an intractable path to the future of society, any force that controls (or makes them pay for) the data that they use will kneecap the company and force them to come up with a way to make these models ethically.</p><p>Yet the world I fear is one where these people are allowed to run rampant, turning unique content into food for an ugly, inbred monster of an internet, one that turns everybody's information sources into semi-personalized versions of the same content. These people have names — Sam Altman of OpenAI, Sundar Pichai of Google, Mark Zuckerberg of Meta (which has its own model called LLaMA), Dario Amodei of Anthropic, and Satya Nadella of Microsoft — and they are responsible for trying to standardize the internet and turn it into a series of toll roads that all lead to the same place.</p><p>And they will gladly misinform and disadvantage billions of people to do so. Their future is one that is less colorful, less exciting, one that caters to the entitled and suppresses the creative. Those who rely on generative AI to create are not creators any more than a person that commissions a portrait is an artist. Altman and his ilk believe they're the new Leonardo Da Vincis, but they're little more than petty kings and rent-seekers trying to steal the world's magic.</p><p>They can, however, be fought. Don't buy their lies. Generative AI might be steeped in the language of high fantasy, but it’s a tool, one that they will not admit is a terribly-flawed and unprofitable way to feed the growth-at-all-costs tech engine. Question everything they say. Don't accept that AI "might one day" be great.&nbsp; Demand that it is today, and reject anything less than perfection from men that make billions of dollars shipping you half-finished shit. Reject their marketing speak and empty fantasizing and interrogate the tools put in front of you, and be a thorn in their side when they try to tell you that mediocrity is the future.</p><p>You are not stupid. You are not "missing anything.” These tools are not magic — they're fantastical versions of autocomplete that can't help but make the same mistakes it's learned from the petabytes of information it's stolen from others.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[gh-116167: Allow disabling the GIL (317 pts)]]></title>
            <link>https://github.com/python/cpython/pull/116338</link>
            <guid>39670102</guid>
            <pubDate>Mon, 11 Mar 2024 16:21:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/python/cpython/pull/116338">https://github.com/python/cpython/pull/116338</a>, See on <a href="https://news.ycombinator.com/item?id=39670102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content">Skip to content</a>
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false">
  
  
  
</react-partial>



      

        

            


<header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:python/cpython" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TexTkrmpiwVRQISjQ9u6_4mK_zmlnys5088MAaIZmTFxAt9kMmMirUgeDCbYYv6w6A0n5ttFgtQ3tzX90RrxJw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="python/cpython" data-current-org="python" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=9DYFdB4AVYJCOlHuSHpLLLMgajv1B0gBMsEWUmYoqphRYw4QoRuVo4Wo4KGGV68fbw8NqrvgBh8t6YUcWWa9pjjnAl%2B%2Fui9J5%2FM7zRkPl4jkjX58M5hbS5%2FmBrcnK%2FAYsQUVc8bNbldATnP71iq9%2FTgt0WXMZCqL6t%2BYqpGOoDw6l41tOoAp3p2VivCLo5geKGu28lKK6INsFm2AewbWbveXI0W%2FQyt9JaayLuYlwER9VJEZhqbQtqH8DAz%2BXam1oywIaR8zuYrriNNieBM4wDrvfb5QI2u6mZVu2GUwswvS3Ih4oDcKZMiKYsp7zPY22yW80s0P7RJWEXhz6zjUTKd4HsKevCX727YBvKEmgr%2Fu7bIpAAEQGznqputFVyCXQWov6ZTWgWU0W%2BryxaGG9R8vObgSfCvfDjyQfp%2FCQGrcvxQKhNT9YGJju34%2B7yCgkQrp2H6F1CQNzc7IT3tPbjteD4dQWJ81BDHPCPGldN3EUbTd6SiPooZuWec%2BqNJFj75WhXW22Jb6cQ%2FMX9kXZlmuGvmBxZ7F%2F8Q%3D--sKPkpGqNwtPVkRS5--KOndQgPYCWF1AMn1mE3UGg%3D%3D&quot; />">
  
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fpull_requests_fragments%2Fpull_request_layout&amp;source=header-repo&amp;source_repo=python%2Fcpython" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/python/cpython/pull/116338&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5cc4a524fc6f3d5f2a3644821fc97cd1bc2ea91e37bf816d3f32b5af23c94e48" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/voltron/pull_requests_fragments/pull_request_layout;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  



      
    

    






  
  <div id="repository-container-header" data-turbo-replace="">

      

        


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  
    <div data-view-component="true">      <action-menu data-select-variant="none" data-view-component="true">
  <focus-group direction="vertical" mnemonics="" retain="">
    <tool-tip id="tooltip-7c6059c6-578c-4aac-bb20-d3c6fa8b96a4" for="action-menu-00e7492a-ec88-43e5-861b-a92fded039ff-button" popover="manual" data-direction="s" data-type="label" data-view-component="true">Additional navigation options</tool-tip>


<anchored-position id="action-menu-00e7492a-ec88-43e5-861b-a92fded039ff-overlay" anchor="action-menu-00e7492a-ec88-43e5-861b-a92fded039ff-button" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true">
  </anchored-position>  </focus-group>
</action-menu></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjE3NTU3MTkxMzkiLCJ0IjoxNzEwMTgwMDA1fQ==--eb5ff5551ddc51b3c705151cd94626da6bcabdb5d105b6f8d1ffcb8de834fb8e" data-url="/python/cpython/pull/116338/partials/title?sticky=true" data-pull-is-open="false" data-gid="PR_kwDOBN0Z8c5opiXj" data-pjax="" data-turbo-frame="">



          
<details>
  <summary data-ga-click="Issues, create new issue, view:issue_show location:issue_header style:button logged_in:false">
    
    New issue
  </summary>
  <details-dialog aria-label="Sign up for GitHub">
            <div>
  <p>
  <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  <!-- '"` --><!-- </textarea></xmp> -->
  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-ga-click="(Logged out) New issue modal, clicked Sign in, text:sign-in" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/python/cpython/pull/116338&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="da6957ed603101f7ef551fcae7cb94064e81005d8a56ac7bab72cea9ee98341a" href="https://github.com/login?return_to=%2Fpython%2Fcpython%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div>
  </details-dialog>
</details>
        
      </div>

</turbo-frame>


    </main>
  </div>

          




    <cookie-consent id="cookie-consent-banner" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></cookie-consent>


  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Performance in Firefox and Across the Web with Speedometer 3 (111 pts)]]></title>
            <link>https://hacks.mozilla.org/2024/03/improving-performance-in-firefox-and-across-the-web-with-speedometer-3/</link>
            <guid>39670046</guid>
            <pubDate>Mon, 11 Mar 2024 16:17:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hacks.mozilla.org/2024/03/improving-performance-in-firefox-and-across-the-web-with-speedometer-3/">https://hacks.mozilla.org/2024/03/improving-performance-in-firefox-and-across-the-web-with-speedometer-3/</a>, See on <a href="https://news.ycombinator.com/item?id=39670046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-main">
  <article role="article">
    <p>In collaboration with the other major browser engine developers, Mozilla is thrilled to <a href="https://browserbench.org/announcements/speedometer3">announce Speedometer 3</a> today. Like previous versions of Speedometer, this benchmark measures <a href="https://www.mozilla.org/en-US/about/webvision/full/#performance">what we think matters most</a> for performance online: responsiveness. But today’s release is more open and more challenging than before, and is the best tool for driving browser performance improvements that we’ve ever seen.</p>
<p>This fulfills the <a href="https://twitter.com/mozhacks/status/1603435347190419456">vision set out in December 2022</a> to bring experts across the industry together in order to rethink how we measure browser performance, guided by a shared goal to reflect the real-world Web as much as possible. This is the first time the Speedometer benchmark, or any major browser benchmark, has been developed through a cross-industry collaboration supported by each major browser engine: Blink, Gecko, and WebKit. Working together means we can build a shared understanding of what matters to optimize, and facilitates broad review of the benchmark itself: both of which make it a stronger lever for improving the Web as a whole.</p>
<p>And we’re seeing results: <a href="https://hacks.mozilla.org/2023/10/down-and-to-the-right-firefox-got-faster-for-real-users-in-2023/">Firefox got faster for real users in 2023</a> as a direct result of <a href="https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/">optimizing</a> <a href="https://spidermonkey.dev/blog/2023/11/27/newsletter-firefox-118-121.html">for</a> Speedometer 3. This took a coordinated effort from many teams: understanding real-world websites, building new tools to drive optimizations, and making a huge number of improvements inside Gecko to make web pages run more smoothly for Firefox users. In the process, we’ve shipped <a href="https://mzl.la/4bYLwtn">hundreds of bug fixes</a> across JS, DOM, Layout, CSS, Graphics, frontend, memory allocation, profile-guided optimization, and more.</p>
<p>We’re happy to see core optimizations in all the major browser engines turning into improved responsiveness for real users, and are looking forward to continuing to work together to build performance tests that improve the Web.</p>
    <section>
                                
                                <p><a href="https://hacks.mozilla.org/author/bgrinsteadmozilla-com/">More articles by Brian Grinstead…</a></p>
                  </section>
  </article>
  
  

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airbnb is banning indoor security cameras (213 pts)]]></title>
            <link>https://www.theverge.com/2024/3/11/24097107/airbnb-indoor-security-camera-ban</link>
            <guid>39669167</guid>
            <pubDate>Mon, 11 Mar 2024 15:08:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/3/11/24097107/airbnb-indoor-security-camera-ban">https://www.theverge.com/2024/3/11/24097107/airbnb-indoor-security-camera-ban</a>, See on <a href="https://news.ycombinator.com/item?id=39669167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Airbnb will no longer allow hosts to use indoor security cameras, regardless of where they’re placed or what they’re used for. In <a href="https://news.airbnb.com/an-update-on-our-policy-on-security-cameras/">an update on Monday</a>, Airbnb says the change to “prioritize the privacy” of renters goes into effect on April 30th.</p><p>The vacation rental app <a href="https://web.archive.org/web/20231223165134/https://www.airbnb.com/help/article/3061">previously let</a> hosts install security cameras in “common areas” of listings, including hallways, living rooms, and front doors. Airbnb required hosts to disclose the presence of security cameras in their listings and make them clearly visible, and it prohibited hosts from using cameras in bedrooms and bathrooms.</p><p>But now, hosts can’t use indoor security cameras at all. The change comes after <a href="https://www.newsweek.com/airbnb-camera-hidden-couple-reddit-lawsuit-1743269">numerous reports</a> of <a href="https://www.foxnews.com/tech/couple-finds-hidden-camera-disguised-as-smoke-detector-in-florida-airbnb">guests</a> finding <a href="https://www.buzzfeed.com/bradesposito/people-keep-finding-hidden-cameras-in-their-airbnb">hidden cameras</a> within their rental, leading some vacation-goers to <a href="https://www.theverge.com/23550845/smartphone-hidden-camera-android-ios-how-to">scan their rooms</a> for cameras.</p><p><a href="https://airbnb.pvxt.net/c/482924/264339/4273?u=https%3A%2F%2Fwww.airbnb.com%2Fhelp%2Farticle%2F3061%23%3A~%3Atext%3Dhere%2520to%2520help-%2CWhat%2520we%2520do%2520allow%2Cof%2520a%2520reservation%2520are%2520permitted.">Airbnb’s new policy</a> also introduces new rules for outdoor security cameras, and will now require hosts to disclose their use and locations before guests book a listing. Hosts can’t use outdoor cams to keep tabs on indoor spaces, either, nor can they use them in “certain outdoor areas where there’s a great expectation of privacy,” such as an outdoor shower or sauna. </p><p>Additionally, listings will have to disclose noise decibel monitors, which hosts might use to measure <a href="https://www.theverge.com/circuitbreaker/2018/10/29/18037604/noiseaware-gen-3-indoor-outdoor-security-microphone">whether there’s a party going on</a> in their rental — <a href="https://www.theverge.com/2022/8/17/23309433/airbnb-anti-party-technology-north-america-usa-canada-party-ban">something that Airbnb banned</a> in 2022. “These changes were made in consultation with our guests, hosts, and privacy experts, and we’ll continue to seek feedback to help ensure our policies work for our global community,” Juniper Downs, Airbnb’s head of community policy and partnership, says in a statement. </p><p>Airbnb hosts will have until the end of April to remove the security cameras from inside their listings. If a guest reports the presence of an indoor camera after that, Airbnb says it will investigate and that it could remove the host’s listing or account as a result. The new policy still can’t control the presence of hidden cameras, but it will at least offer some peace of mind knowing that rule-abiding hosts can no longer put cameras anywhere in their rentals.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel Gaudi2 chips outperform Nvidia H100 on diffusion transformers (125 pts)]]></title>
            <link>https://stability.ai/news/putting-the-ai-supercomputer-to-work</link>
            <guid>39669008</guid>
            <pubDate>Mon, 11 Mar 2024 14:56:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/news/putting-the-ai-supercomputer-to-work">https://stability.ai/news/putting-the-ai-supercomputer-to-work</a>, See on <a href="https://news.ycombinator.com/item?id=39669008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1709158639151_29172">
  <p>In our <a href="https://stability.ai/news/using-the-new-ai-supercomputer"><span>last installment</span></a>, we spoke about how we plan to utilize our state-of-the-art AI Supercomputer.</p><p>In this installment, we delve deeper into performance benchmarks and benefits of various compute solutions.</p><p>Our commitment to developing cutting-edge open models in multiple modalities necessitates a compute solution capable of handling diverse tasks with efficiency. To this end, we conducted a performance analysis, training two of our models, including the highly anticipated <a href="https://stability.ai/news/stable-diffusion-3"><span>Stable Diffusion 3</span></a>.</p><p>In our analysis, we compared the training speed of Intel Gaudi 2 accelerators versus Nvidia's A100 and H100, two of the most common choices for startups and developers training LLMs.</p><p><strong>Model 1:</strong></p><p><a href="https://stability.ai/news/stable-diffusion-3"><span><strong>Stable Diffusion 3</strong></span></a> is our most capable text-to-image model, soon to be in <a href="https://stability.ai/stablediffusion3"><span>early preview</span></a>.&nbsp;</p><p>Upon public release of Stable Diffusion 3, it will be available in sizes ranging from 800M to 8B parameters. Our analysis utilized the 2B parameter version and showed pleasantly surprising results.&nbsp;</p><p>We measured the training throughput for the 2B <a href="https://stability.ai/news/stable-diffusion-3-research-paper"><span>Multimodal Diffusion Transformer</span></a> (MMDiT) architecture model with d=24, BFloat16mixed precision, optimized attention (xFormers for A100 and the FusedSDPA for Intel Gaudi). We call this model version MMDiT-ps2-d24.</p><p>First, let’s examine our training benchmark results across 2 nodes, a total of 16 accelerators (Gaudi/GPU). Here’s an excerpt of the raw data:</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1709158639151_25063">
  <p>In this configuration, the Gaudi 2 cluster processed over 3x more images per second, compared to A100-80GB GPUs. This is particularly impressive considering that the A100s have a very optimized software stack.&nbsp;</p><p>On inference tests with the Stable Diffusion 3 8B parameter model the Gaudi 2 chips offer inference speed similar to Nvidia A100 chips using base PyTorch. However, with TensorRT optimization, the A100 chips produce images 40% faster than Gaudi 2. We anticipate that with further optimization, Gaudi 2 will soon outperform A100s on this model. In earlier tests on our SDXL model with base PyTorch, Gaudi 2 generates a 1024x1024 image in 30 steps in 3.2 seconds, versus 3.6 seconds for PyTorch on A100s and 2.7 seconds for a generation with TensorRT on an A100.&nbsp;</p><p>The higher memory and fast interconnect of Gaudi 2, plus other design considerations, make it competitive to run the Diffusion Transformer architecture that underpins this next generation of media models.</p><p><br><strong>Model 2:</strong></p><p><a href="https://stability.ai/news/stable-beluga-large-instruction-fine-tuned-models"><span><strong>Stable Beluga 2.5 70B</strong></span></a><strong> </strong>is our fine-tuned version of LLaMA 2 70B, building on the <a href="https://stability.ai/news/stable-beluga-large-instruction-fine-tuned-models"><span>Stable Beluga 2</span></a> model which was the first open model to best ChatGPT 3.5 in select benchmarks. We ran this training benchmark on 256 Gaudi 2 accelerators. Running our PyTorch code out of the box, with no extra optimizations, we measured an impressive total average throughput of 116,777 tokens/second. More specifically, this involves using a FP16 datatype, a global batch size of 1024, gradient accumulation steps of 2, and micro batch size of 2.</p><p>On inference tests with our 70B language model on Gaudi 2, it generates 673 tokens/second per accelerator, using an input token size of 128 and output token size of 2048. In comparison to <a href="https://nvidia.github.io/TensorRT-LLM/performance.html"><span>TensorRT-LLM</span></a>, Gaudi 2 appears to be 28% faster than the 525 tokens/second for the A100. We also anticipate further speed improvements with FP8.</p><p>Companies like ours face an increasing demand for more powerful and efficient computing solutions. Our findings underscore the need for alternatives like the Gaudi 2, which not only offers superior performance to other 7nm chips, but also addresses critical market needs such as affordability, reduced lead times, and superior price-to-performance ratios. Ultimately, the opportunity for choice in computing options broadens participation and innovation, thereby making advanced AI technologies more accessible to all.</p><p>Stay tuned for more insights in our next installment of "Behind the Compute."&nbsp;</p><p>To stay updated on our progress follow us on <a href="https://twitter.com/stabilityai"><span>Twitter</span></a>, <a href="https://www.instagram.com/stability.ai/"><span>Instagram</span></a>, <a href="https://www.linkedin.com/company/stability-ai"><span>LinkedIn</span></a>, and join our <a href="https://discord.gg/stablediffusion"><span>Discord Community</span></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Onedoc (YC W24) – A better way to create PDFs (151 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39668962</link>
            <guid>39668962</guid>
            <pubDate>Mon, 11 Mar 2024 14:52:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39668962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39671945"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39671945" href="https://news.ycombinator.com/vote?id=39671945&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Congratulations on the launch — it looks fantastic! My company is also developing a similar product. We've chosen to create a visual report designer that enables end-users (non-developers) to create and tweak PDF reports, and integrate with the existing IT infrastructure via the API. Our experience is that users want changes in reports very often and that it's best to allow them do it on their own.<p><a href="https://www.cx-reports.com/" rel="nofollow">https://www.cx-reports.com</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39671939"><td></td></tr>
                <tr id="39671996"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671996" href="https://news.ycombinator.com/vote?id=39671996&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>We spent many hours designing and generating PDFs at our previous venture.. terrible experience. Which is why we're now focused on solving this issue!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670933"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670933" href="https://news.ycombinator.com/vote?id=39670933&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I've also spent much longer than I'd like on this same problem. Having a lightweight-enough service to convert html-&gt;pdf on the fly, with good fidelity, and that can create an <i>accessible</i> pdf seems to be impossible.<p>If you can nail accessible PDFs then you'd open up a <i>very</i> big government market.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671067"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671067" href="https://news.ycombinator.com/vote?id=39671067&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>We felt the same, and that's precisely why we built this tool! The key, as you mentioned, is fidelity, especially for designing complex layouts. We hope to bring something new and valuable to the table. And yes, documents are central to many industries including government, legal, banking etc.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671252"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39671252" href="https://news.ycombinator.com/vote?id=39671252&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Can you directly answer whether your tool generates <i>tagged</i> PDFs?<p>Of course, you can't guarantee that the resulting document is 100% compliant because you can't enforce that the input is valid, but are you at least outputting a complete tag tree with as much semantics as possible given the input?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671430"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39671430" href="https://news.ycombinator.com/vote?id=39671430&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Yes, Onedoc generates tagged PDFs as long as you add a `title` property to the API call to make the PDF UA/1 compliant.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39670314"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670314" href="https://news.ycombinator.com/vote?id=39670314&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>FYI: the open source state of the art in this area is Playwright (the successor to Puppeteer) with Paged.js (<a href="https://pagedjs.org/" rel="nofollow">https://pagedjs.org/</a>). I highly recommend that everyone check out and donate to paged.js, it's a fantastic project with lots to like. It certainly blows commercial alternatives like Prince XML out of the water.<p>That forms a solid foundation that I find it hard to imagine paying for. The things where you might still command a premium are basically safety mechanisms/CI checks/library components that ensure the PDF renders correctly in the presence of variable-length content, etc. as well as maybe PDF-specific features like metadata and fillable forms. Naive ways to format headers, footers, tables/grids/flexboxes etc. often fail in PDFs because of unexpected layout complications. So having a methodology, process, and validation system for ensuring that a mission critical piece of information appears on a PDF in the presence of these constraints could be attractive.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671264"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671264" href="https://news.ycombinator.com/vote?id=39671264&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I think <a href="https://github.com/diegomura/react-pdf">https://github.com/diegomura/react-pdf</a> is closer to what this company is doing.<p>In fact their open source library, <a href="https://github.com/OnedocLabs/react-print-pdf">https://github.com/OnedocLabs/react-print-pdf</a>, seems like a higher-level library that sits above react-pdf. Reminds me a lot of the set of react-pdf based components I built for a corporate job where letting users create PDFs was a huge part of the value proposition.</p><p>They're solving a really cool problem, actually, because building out into certain difficult use cases like SVG support was a huge pain.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670434"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670434" href="https://news.ycombinator.com/vote?id=39670434&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>We are currently experimenting with this approach. A good thing about paged.js is that we would be able to provide hot-reload and live preview of files without actually converting to PDF.<p>Your second point is very interesting, seems like some kind of .assert('text').isVisible() API. We may want to dig into that further!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670470"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670470" href="https://news.ycombinator.com/vote?id=39670470&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>(How) does it handle CMYK and print PDFs? I see images of printed books created by Paged.js, were these post-processed, or printed using a printer that does a best-effort RGB conversion?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670569"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670569" href="https://news.ycombinator.com/vote?id=39670569&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I'm not sure - we don't do color correction on our PDFs because we don't have photos in them and color rendering is not mission critical - but paged.js is focused on the concern of layout for print media. I would imagine color rendering can be solved orthogonally to what paged.js does for you, as long as you specify the color data in CSS. I'm pretty sure paged.js will pass it through without messing with it, so you're good if the browser that Playwright/puppeteer is driving supports the correct color profile when emitting the PDF. I honestly don't know if browsers have sufficient support for that when emitting a PDF, though.<p>Overall you're right that color correction is another area where you could probably command a premium.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671894"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39671894" href="https://news.ycombinator.com/vote?id=39671894&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>It's certainly an area with more depth than I anticipated when I first started getting into it. Adobe is still pretty much the only one that can get a PDF compliant with print standards.<p>As far as I know, there's no way to currently get colors adhering to print color profiles in CMYK out of browsers.</p><p>Indeed, if color correctness isn't mission critical, I can imagine that going with Paged.js can be a nice experience!</p><p>(Edit: in my experience so far, it's been really really hard to 'correct' colors from an existing PDF in a way that gets a satisfying end result---the colors are usually muted/washed out)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671992"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39671992" href="https://news.ycombinator.com/vote?id=39671992&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I was curious and searched around and found this presentation: <a href="https://www.w3.org/Graphics/Color/Workshop/slides/Erias.pdf" rel="nofollow">https://www.w3.org/Graphics/Color/Workshop/slides/Erias.pdf</a><p>You're right - although many of the building blocks are there, it appears there is no way to specify a colorspace or print profile when asking Chrome to emit a PDF (and I doubt the other browsers are any better). Skia (the PDF rendering engine that Chromium uses) actually supports colorspace transforms, but Chromium doesn't seem to hook that up to CSS or even support non-RGBA colors in its rendering pipeline.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="39669425"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669425" href="https://news.ycombinator.com/vote?id=39669425&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>May be this is just me but this looks extremely costly to me! It will cost $2,500 to generate 50,000 PDFs. Are edits/corrections additional cost?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671397"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671397" href="https://news.ycombinator.com/vote?id=39671397&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>It sounds like this is as advanced as DocRaptor[1]. They have what I consider to be the best PDF generation API, giving complete control over the documents you need to create. The pricing is similar.<p>If you'd rather do it for free weasyprint[2] is the best open source alternative.</p><p>Another more affordable option you might want to consider is Urlbox[3]. (Disclosure: I work on this)</p><p>Urlbox's rendering engine is based on Chrome. It's been refined over the last 11 years to render pages as images or PDFs[4] that look great. I was a customer for 5 years before I joined the team. Everything we'd tried before Urlbox was a disappointment.</p><p>Urlbox probably can't match the power of either Onedoc or DocRaptor, but pricing starts at less than $0.01 per document and drops significantly with scale. If your PDF looks great when saving as PDF in Chrome it should look identically brilliant with Urlbox.</p><p>[1]: <a href="https://docraptor.com/" rel="nofollow">https://docraptor.com</a>
[2]: <a href="https://weasyprint.org/" rel="nofollow">https://weasyprint.org</a>
[3]: <a href="https://urlbox.com/" rel="nofollow">https://urlbox.com</a>
[4]: <a href="https://urlbox.com/html-to-pdf" rel="nofollow">https://urlbox.com/html-to-pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39669512"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669512" href="https://news.ycombinator.com/vote?id=39669512&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>This is a good point, and we are still trying to figure out how to price things fairly. Depending on the type of PDF, whether it is a simple receipt or a large multi-pages report, associated costs are very different on our side. At this time, we rely on other proprietary software that we are aiming to replace but that incur high costs on our side as well.<p>Edits and corrections on generated PDFs is not provided as the PDFs are signed as-is, however you can attach the metadata to the PDF and rerender with the modifications.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670331"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670331" href="https://news.ycombinator.com/vote?id=39670331&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>As a point of reference on pricing, convertAPI charges $0.05 per document conversion at their most expensive tier, and with any level of fixed commitment ($80 - $300 per month) it goes down to $0.016-0.006 per document.<p>Their PDF conversion is pretty good (I use it for PPT/Word -&gt; PDF conversion), though your product is obviously different and has different/better capabilities for programmatic PDF creation. Still, a reference point.</p><p>Pricing page: <a href="https://www.convertapi.com/prices" rel="nofollow">https://www.convertapi.com/prices</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39669654"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39669654" href="https://news.ycombinator.com/vote?id=39669654&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Edits would be limited to certain pages but may spill over (e.g. tables) so the whole PDF need not be generated. Only edited pages can be inserted back to previously generated PDFs. Could be an optimization to reduce cost.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669631"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669631" href="https://news.ycombinator.com/vote?id=39669631&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I second this. Maybe I'm missing something in the value proposition, but we already generate PDFs from .docx/.html templates using open source libraries and Docker microservices.<p>Do not misunderstand. A Stripe for generating PDFs can be great, but for a small team, $0.50/PDF is way more than I can afford (after all, you can create a small number of PDFs without too much fuss). Maybe you are oriented towards large companies?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670787"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670787" href="https://news.ycombinator.com/vote?id=39670787&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Indeed, and as you mentioned, open-source libraries are always an option. It's worth noting that our open-source library assists in document design, allowing freedom in renderer choice. While the open-source library is aimed at individuals, our API targets businesses of any size. Our pricing can be as low as $0.05 per PDF for high-volume or annual commitments. Additionally, we offer cloud hosting for your documents for up to 90 days, and our pricing includes analytics.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670373"><td></td></tr>
                  <tr id="39671520"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39671520" href="https://news.ycombinator.com/vote?id=39671520&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Looks awesome, will keep this in mind - every so often you need to create complex documents in code, and it's always a pain. Doing it with a familiar modern programming interface would be nice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671577"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671577" href="https://news.ycombinator.com/vote?id=39671577&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Exactly, that's one of the main reasons we began working on this. We aim to bring the modern web technologies used for website design into the document world. This includes enabling the use of React and, of course, Tailwind, Chakra UI, etc.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670676"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670676" href="https://news.ycombinator.com/vote?id=39670676&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Love the demo on the homepage with the render button. Really helps explain the product!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670796"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670796" href="https://news.ycombinator.com/vote?id=39670796&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Thanks! We try to make our product as accessible as possible for anyone to use (or at least to test). It's good to hear that our efforts have been worthwhile!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669738"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669738" href="https://news.ycombinator.com/vote?id=39669738&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Really interesting product. I do agree that the pricing seems steep ($0.25/document on Pro on the most generous tier) but I don't know enough about pricing B2B products to know if that would be a blocker.<p>I agree that HTML -&gt; PDF can be a really powerful tool. I worked on the UK government's tool to generate energy efficiency labels for consumer goods [0] and we ended up doing PDF generation with SVG templates, using Open HTML to PDF for the conversion. That ended up working very well, though as you allude to there can be some gotchas (eg unsupported CSS features) that you need to work around.</p><p>A few questions:</p><p>- Do the rendered documents support PDF's various accessibility features?</p><p>- How suitable is this for print PDF generation? For example, what version of the PDF spec do you target? What's your colour profile support like? Do you support the different PDF page boxes (MediaBox, CropBox, BleedBox, TrimBox, ArtBox)?</p><p>[0] <a href="https://github.com/UKGovernmentBEIS/energy-label-service">https://github.com/UKGovernmentBEIS/energy-label-service</a></p><p>[1] <a href="https://github.com/danfickle/openhtmltopdf">https://github.com/danfickle/openhtmltopdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670010"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670010" href="https://news.ycombinator.com/vote?id=39670010&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>The pricing does go down for larger volumes and is something we still have to narrow down to the exact place that makes sense to companies and is also viable.<p>- We do not force PDF/* profiles down to the user, but it seems that for most of them PDF/UA-1 would be a sensible default. We can extract most of the tags from the HTML semantics by themselves which makes it much easier.</p><p>- We target the PDF 1.7 spec. Color profiles can be changed and you can use a custom .icc profile, with the corresponding embedding restrictions based on the document format. MediaBox is supported through the @page size property. Bleed, trim and marks can be added using vendor specific css properties. We don't support ArtBox yet but this is something we can look into! So far none of our customers really wanted to take this out to a real print shop, but we would be glad to help people go down this route :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671287"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39671287" href="https://news.ycombinator.com/vote?id=39671287&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>So are you saying that you don't output tagged PDFs now?<p>For those who don't know, if you use Chromium's print-to-pdf feature you get a tagged PDF. And it's scriptable from the command-line too.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39669806"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669806" href="https://news.ycombinator.com/vote?id=39669806&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I had to deal a lot with PDF generation over the past few years and I was very unhappy with the eco-system that was available:<p>1. HTML-to-PDF: The web has a great layout system that works well for dynamic content. So using that seems like a good idea. BUT it is not very efficient as a lot of these libraries simply spin up a headless browser or deal with virtual doms.</p><p>2. PDF Libraries (like jsPDF): They mostly just have methods like ".text(x, y, string) which is an absolute pain to work with when building dynamic content or creating complex layouts.</p><p>This was such a pain point in various projects I worked on that I built my own library that has a component system to build dynamic layouts (like tables over multiple pages) and then computes that down to simple jsPDF commands. Giving you the best of both worlds.</p><p>Hope this makes somebody's life a bit easier: <a href="https://github.com/DevLeoko/painless-pdf">https://github.com/DevLeoko/painless-pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670020"><td></td></tr>
                <tr id="39670140"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670140" href="https://news.ycombinator.com/vote?id=39670140&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Yes, page breaks are probably the most significant difference between the layout of a web page and a PDF document, and thereby a major drawback when using HTML-to-PDF. There is little to no tooling for this in the web.<p>If you want granular control over how your PDF will look with content that is more than one page long, you will have a hard time using html.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670251"><td></td></tr>
            <tr id="39670311"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39670311" href="https://news.ycombinator.com/vote?id=39670311&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>That's what we are trying to solve at Onedoc, we want developers to be able to have full control over the PDF layout as they write content. react-print is built with the intention of creating the illusion that React was meant for PDFs.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39671294"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39671294" href="https://news.ycombinator.com/vote?id=39671294&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Hmm interesting... I just went through this user experience on iOS generating PDF invoices locally. I attempted the HTML &gt; PDF route, but Webkit is thorny wrt to layouts (as you mentioned). I did settle in with drawing everything from the ground up &gt; which with LLMs wasn't as hairy as it used to be, even got a little Swift framework out of the deal.<p>Am I understanding the docs correctly that you don't have a local library available (the SDKs are just calling the APIs right?)? Mind going through why you chose a remote API?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671497"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671497" href="https://news.ycombinator.com/vote?id=39671497&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>You are right in the sense we do not provide a local library. We considered the option but would have brought a lot of challenges to accommodate the various runtimes and device capabilities.<p>This may come at a later stage once we have built our own rendering engine though
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39671553"><td></td></tr>
                <tr id="39671571"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671571" href="https://news.ycombinator.com/vote?id=39671571&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>There are many reasons behind it, to name a few: files are self-contained(*) and easily portable, can guarantee some security features, the format is easily extended, and the ecosystem is very large.<p>It seems that a better format should exist, but the fact that PDF is the de-facto for portable documents make it unlikely things can change overnight.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669582"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669582" href="https://news.ycombinator.com/vote?id=39669582&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Super interesting and potentially a fit for a project I'm working on right now. What are the benefits of going this route vs styling your page for print (ex. tailwind print modifier) and relying on the browser's print dialogue?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39669652"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669652" href="https://news.ycombinator.com/vote?id=39669652&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>There is both commonalities and differences! Both approaches rely on web technology to provide the layout and are flexible in terms of frameworks and integrations.<p>Where things differ is that we don't actually use a browser under the hood. This allows a much better control over typesetting and layout - and you can do it on the server. We have also more controls over the outputted PDF and the ability to use more advanced features such as form fields or embedding other files and metadata in the PDF.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669634"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669634" href="https://news.ycombinator.com/vote?id=39669634&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Is this just a wrapper around Puppeteer that renders a pdf? I do this currently with an AWS lambda that has a chrome-aws-lambda layer.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39669717"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669717" href="https://news.ycombinator.com/vote?id=39669717&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>We use a dedicated HTML to PDF engine (such as PrinceXML) rather than building on top of a browser. Main issue with browser-backed implementations is that PDFs are often of subpar quality. However, the main good thing is you can rely on the latest CSS features.<p>In the end, what was the main decisive factor is the support for the PrintCSS and PagedMedia specifications, which have been completely discarded by major vendors and only implemented by specific engines.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669457"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669457" href="https://news.ycombinator.com/vote?id=39669457&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Congrats! My career has also revolved around PDF generation (once for federal compliance at large companies, second for scrubbing data from PDFs for HIPAA compliance and then generating a new pdf based on the scrubbed data). I think I've seen your tool around, I ended up creating a workflow that generated LateX scripts then converted them to pdfs, and the second a python library. The most difficult aspect for our tools was formatting - the pdfs were generally 60-100 pages and tables could show up anywhere and break the page/formatting. Quite curious to see how your company will grow, good luck!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39669964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669964" href="https://news.ycombinator.com/vote?id=39669964&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Curious, which python library did you use to convert to PDFs? currently looking into a couple options myself</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671056"><td></td></tr>
                        <tr id="39669517"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669517" href="https://news.ycombinator.com/vote?id=39669517&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>It seems TeX/LaTeX is a major inspiration in this, though there can be seen some room for improvement for details like hyphenation, expansion/protusion and microtypography. Not sure if/how a web engine can reach to those points but still it seems this has a potential niche and market outcome, so congrats.<p>Though personally I wish stuff like ConTeXt was more popular and approachable - to my humble knowledge their Lua backend seems to have huge potential, I am doing my invoices with ConTeXt/Lua.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39669561"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39669561" href="https://news.ycombinator.com/vote?id=39669561&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>It definitely is! Typesetting quality was the main reason we chose not to go down the Puppeteer/headless browser route but rather use a completely separate engine where typography is a first-class citizen.<p>We like LaTeX, but even for advanced users laying things out can be a difficult thing. Given that documents are a frontend, we wanted to bring the same tools frontend developers already use.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669987"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669987" href="https://news.ycombinator.com/vote?id=39669987&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>This looks really interesting! One of the main reasons we've opted to writing a more complex rending code is for speed. We're getting around 500ms for a single document, which is (last I tested) quicker than any headless chrome setup.<p>How long does it take to render using your API? :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670106"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670106" href="https://news.ycombinator.com/vote?id=39670106&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Rendering time scales with the length / complexity of the document. At the moment, our self-serve API renders slower than a headless chrome setup. We are working on speeding this up as it is currently in the order of seconds.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670471"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670471" href="https://news.ycombinator.com/vote?id=39670471&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>How is this better than writing out an HTML file, then using headless chrome to export to PDF, like this:<pre><code>    "C:\Program Files\Google\Chrome\Application\chrome.exe" --headless --disable-gpu --print-to-pdf=C:\temp\foo.pdf --no-margins --print-to-pdf-no-header C:\temp\test.mhtml</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670651"><td></td></tr>
            <tr id="39670575"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670575" href="https://news.ycombinator.com/vote?id=39670575&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>This brings its own set of challenges. Headers and footers are strictly limited in terms of features, you cannot add footnotes, the notion of page spreads is harder to implement. Then you need to combine that with having a Chrome instance at hand + exposing the needed assets for URL resolution. Definitely not difficult let alone impossible, but not the easiest way to get started :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671295"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39671295" href="https://news.ycombinator.com/vote?id=39671295&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>The easier way costs $0.05 cents per page. Imagine sending an invoice to your customer and the invoice itself costs 5 cents per page! That's prohibitively expensive for many applications. I wouldn't consider any solution that costs more than 1 cent per page.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671361"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39671361" href="https://news.ycombinator.com/vote?id=39671361&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>We bill per document, so the number of pages wouldn't impact the pricing. A 5 pages invoice would come at 1 cent per page. However, it seems that each and every company has different needs and the pricing may or may not make sense for them. There are alternative billing options that we are considering but we want to keep it easy to grasp rather than go into billing kilobytes or ms of execution. We would be more than happy to discuss use cases and see what can work for each company :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39670235"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670235" href="https://news.ycombinator.com/vote?id=39670235&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>We're using Gotenberg[1] to convert a rendered web page (with Elixir/Phoenix, in our case) to PDF. Works like a charm and we can use our existing frontend code/styling (including SVG graph generators) which is a huge bonus.<p>1: <a href="https://gotenberg.dev/" rel="nofollow">https://gotenberg.dev/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670326"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670326" href="https://news.ycombinator.com/vote?id=39670326&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>We actually experimented with Gotenberg! Ultimately it is a layer on top of Chromium for conversion and we were dissatisfied with the results. I am curious so as to how are you handling assets and other static media / attachments: do you embed everything in a single HTML file or do you use some kind of bucketing system to resolve URLs?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671790"><td></td></tr>
                        <tr id="39669684"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669684" href="https://news.ycombinator.com/vote?id=39669684&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>This is definitely a huge market. Are you targeting React developers only? I've successfully used html2pdf in the past, but looking again at their Github, it seems there has been no update in the last three years.<p>I think SOC2 is a must to start engaging with companies. Most PDFs will have sensitive data, and not many companies will feel comfortable sending customer data to a 3rd party platform, so you need security measures and certifications.</p><p>Good luck!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670222"><td></td></tr>
                <tr id="39670284"><td></td></tr>
                  <tr id="39670911"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670911" href="https://news.ycombinator.com/vote?id=39670911&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>I wonder what YC expects from such investments (considering the multitude of FOSS solutions in this area).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670992"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670992" href="https://news.ycombinator.com/vote?id=39670992&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>While this may sound a bit counterintuitive (maybe?) we actually pivoted to this field based on YC input and discussions they have had with their previous companies. The multitude of FOSS solutions in this area indicates this is a real problem people are willing to spend time on, and yet there is no go-to solution and every team we have talked to selected different tools based on a very specific requirement.<p>This may not mean success, it means that game is not over in the documents field :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671047"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39671047" href="https://news.ycombinator.com/vote?id=39671047&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Thanks for the perspective. Indeed, this is an area with real demand. I haven't evaluated YC's recent startups but I trust they do know a bit about what has a better chance in the market. Best of luck :)<p>ps.: As someone with very minimal PDF needs personally and at work, I'd say the beautiful templates are what caught my attention the most.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39670014"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670014" href="https://news.ycombinator.com/vote?id=39670014&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Glad to see people building in the PDF space, which as a format is unfortunately both awful and ubiquitous. Are you planning to build any support for programmatically filling out existing PDF forms? That's a huge pain point our product is facing that doesn't seem easy to solve.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670980"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670980" href="https://news.ycombinator.com/vote?id=39670980&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>I'm facing that same pain point of programmatic PDF filling. I noodled around in the PDF format and learned it's a bit difficult to deal with fonts and formatting. But I think this client-side library works well enough, as a start: <a href="https://pdf-lib.js.org/#fill-form" rel="nofollow">https://pdf-lib.js.org/#fill-form</a><p>I've also heard of one paid API that I forgot but seemed to work well, and this related service <a href="https://www.jotform.com/" rel="nofollow">https://www.jotform.com/</a>, and I also considered porting some server-side libraries to WASM. One day I'll collect all the libraries and findings in a blog post.</p><p>Are you looking to programmatically fill any PDF form by detecting the fields? Or are you filling one known PDF template?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670221"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670221" href="https://news.ycombinator.com/vote?id=39670221&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Yes, our focus is on programmatic interactions with PDFs, form filling is on our roadmap, alongside programmatic digital signature and many more.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670242"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670242" href="https://news.ycombinator.com/vote?id=39670242&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Amazing, is there anywhere I can follow along to find out when form filling will be available?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670352"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39670352" href="https://news.ycombinator.com/vote?id=39670352&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Sure! Feel free to join our Discord, we post announcements as soon as new features are released. You can also ask for features, we prioritise these requests with enterprise customer's in our development roadmap.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39670924"><td></td></tr>
            <tr id="39670708"><td></td></tr>
                <tr id="39670798"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670798" href="https://news.ycombinator.com/vote?id=39670798&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>It is similar to pspdfkit. We add an abstraction layer over the HTML and assets hosting to make it easier to use without having to think too hard about security and serving assets.<p>We also hope to keep the focus on the PDF generation part rather than expanding super-horizontal style to provide all imaginable PDF tools at the expense that none is really good.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669730"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669730" href="https://news.ycombinator.com/vote?id=39669730&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>So are you using PrinceXML for your "completely separate engine where typography is a first-class citizen"?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670196"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670196" href="https://news.ycombinator.com/vote?id=39670196&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Yes, we use an API layer on top of PrinceXML with additional polyfills to support modern features. This is a meh solution but it allowed us to iterate quickly and get to work with customers without building a full blown PDF engine firsthand. However building this engine ourselves is the key to reduced latency and overall better feature support. But we need to engage with our users first and see exactly where we should head first :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39669889"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39669889" href="https://news.ycombinator.com/vote?id=39669889&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Can we not have an alternative to PDFs? I get that they're more standardized but why would everyone let adobe have the hammer for a file type that's so important</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39670094"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670094" href="https://news.ycombinator.com/vote?id=39670094&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>We quite agree on this - but getting a new alternative out will require a significant critical mass before it can be of any interest. While PDF has its challenges, it remains a light portable format and its security features make it a good fit for binding documents. The ecosystem, although it is dominated by Adobe, also includes other major players and existing integrations.<p>The way we look at it is PDFs allows embedding of other files and metadata. It is easy to provide a platform where we can enrich PDFs to display different contents than the one in the PDF itself. If this gets interesting enough, we can then phase out the PDF in the first place. But this is a long way ahead.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670615"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670615" href="https://news.ycombinator.com/vote?id=39670615&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>PDF is an incredibly (stupidly) extensible format. There are tons of government forms that (sadly) bake in complex workflows into PDF forms.<p>Given that the whole world has been running on PDFs for decades it's makes more sense to leverage the existing infrastructure and move it towards something more functional over time. Introducing a new format will just lead to another format the achieves 0.5% marketshare and then is abandoned after a few years. Microsoft basically forcing people to use XPS in windows (&gt;70% market share of computing) still wasn't able to achieve meaningful usage or change.</p><p>I expect that PDFs will not go away for 20 years at least, but who knows
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39670421"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670421" href="https://news.ycombinator.com/vote?id=39670421&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>PDF is an open format in the sense that you don't need to pay Adobe a license fee for generating PDFs, or for reading and rendering PDFs. The format is fully documented, although the specification is controlled by Adobe.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39670151"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670151" href="https://news.ycombinator.com/vote?id=39670151&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>For supply chain workflows the ASC X12 Electronic Data Interchange (EDI) industry standard works much better than PDFs. Unfortunately, despite being around for decades in has only been adopted by forward thinking organizations such as Walmart. Most smaller companies and their vendors still haven't implemented EDI.<p><a href="https://developer.walmart.com/home/us-edi/" rel="nofollow">https://developer.walmart.com/home/us-edi/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670591"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670591" href="https://news.ycombinator.com/vote?id=39670591&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Insanity.<p>EDI is the only place where people are regularly still paying for message by the kilobyte, where unsecured FTP over the open internet is still a norm, and where entire cottage industries exist to support AVOIDING using EDI.</p><p>Source: I work in EDI. it's a pain in the rump.</p><p>Also, EDI is really only good for things like PO's, shipping notices, invoices, sales orders, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671515"><td></td></tr>
            <tr id="39671078"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39671078" href="https://news.ycombinator.com/vote?id=39671078&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>&gt; Also, EDI is really only good for things like PO's, shipping notices, invoices, sales orders, etc.<p>Don't forget health insurance claims, eligibility &amp; benefits, and prior auth requests!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39671493"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39671493" href="https://news.ycombinator.com/vote?id=39671493&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>EDI is used in a lot of situations for machine-to-machine communications, but outside USA I believe EDIFACT is much more used (X12 is mostly used in USA).<p>Today many EDIFACT documents have been converted to ebXML: <a href="https://en.wikipedia.org/wiki/EbXML" rel="nofollow">https://en.wikipedia.org/wiki/EbXML</a></p><p>Source: Worked in EDI for a few years
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39670131"><td></td></tr>
                <tr id="39670652"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39670652" href="https://news.ycombinator.com/vote?id=39670652&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Giving credit where it's due, I can appreciate Microsoft for introducing XPS as an alternative to pdf.<p>There was a time, when not every software had "export to pdf". So, having a "print to pdf" meant installing (often pirated) Adobe Acrobat or installing a sketchy free(ware) printdriver software downloaded from sourceforge.</p><p>MS adding xps print driver to windows enabled sharing docs consistently (within windows ecosystem) without resorting to hacks.</p><p>I don't know why it didn't catch up. May be it was the general mistrust of anything MS,  it arrived too late or it was something else.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670931"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39670931" href="https://news.ycombinator.com/vote?id=39670931&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Indeed, we need to give credit to MS for what they did. However, it didn't catch up as you mentioned, maybe due to timing, skepticism toward MS, or the complexity of moving from Adobe to MS for PDF management. I will dig a bit into it and come back later if I find anything interesting.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39670584"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670584" href="https://news.ycombinator.com/vote?id=39670584&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>I just wanted to add that if you want to convert plaintext files to pdf, vim has a builtin feature to do so:<pre><code>  vim filename.txt -c "hardcopy &gt; filename.ps | q" &amp;&amp; ps2pdf filename.ps #convert ps to pdf</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39669934"><td></td></tr>
                <tr id="39670148"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670148" href="https://news.ycombinator.com/vote?id=39670148&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>No, we don't currently do that. However, we are considering adding metadata to PDFs, and using pdfmark could be very helpful!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670037"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39670037" href="https://news.ycombinator.com/vote?id=39670037&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>The problem with using Tailwind is that I can't just say &lt;h1&gt;Some Heading&lt;/h1&gt;. As noted in the Tailwind documents "All heading elements are completely unstyled by default, and have the same font-size and font-weight as normal text."[1]<p>Most of the time when I'm writing HTML I want a set of default styles for the most common elements,
It's tedious and error-prone to have to specify a class <i>every single time</i>.</p><p>1 <a href="https://tailwindcss.com/docs/preflight" rel="nofollow">https://tailwindcss.com/docs/preflight</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39670147"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39670147" href="https://news.ycombinator.com/vote?id=39670147&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Makes total sense. There is no real requirement to use Tailwind to create the PDFs, we just have grown accustomed to Tailwind :) If you don't use the &lt;Tailwind&gt; tag, the browser defaults are used to generate the PDF.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39670174"><td></td></tr>
            <tr id="39671147"><td></td></tr>
                <tr id="39671451"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39671451" href="https://news.ycombinator.com/vote?id=39671451&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><p><span>Editors such as Overleaf, and those offered by MS and Adobe, have been around for a long time. Recently, companies like Pandadoc and Docusign have started offering services around PDFs (generation or other aspects of their lifecycle).<p>It might seem odd, given our long history with PDFs, but I believe there's still much to be done with these documents. They're everywhere—invoices, tickets, reports, etc.—yet the technology for generating and managing them hasn't evolved much in years. Our approach is to apply the same modern technologies used for web design to document design.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39671313"><td></td></tr>
                <tr id="39671490"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39671490" href="https://news.ycombinator.com/vote?id=39671490&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>When I was first hired 15 years ago my first task was to create a PDF report. It was easy back then in PHP+fPDF. Two years ago I was hired to work on a Heroku-hosted NodeJS app. I was surprised to find that generating a PDF turned out to be substantially more difficult task, requiring running a browser emulator or connecting to an external service. And now, seeing PDF generation as a premium pay-as-you-go product is just too much.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39671557"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39671557" href="https://news.ycombinator.com/vote?id=39671557&amp;how=up&amp;goto=item%3Fid%3D39668962"></a></center>    </td><td><br><div>
                  <p><span>Makes sense. Actually, if you keep the layout/content very simple, aren't constrained by throughput, and don't need to integrate dynamic data or other similar processes, then simple FOSS could indeed get the job done! That's exactly why we developed the open-source library react-print-pdf</span></p></div></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Extropic is building (116 pts)]]></title>
            <link>https://www.extropic.ai/future</link>
            <guid>39668430</guid>
            <pubDate>Mon, 11 Mar 2024 14:09:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.extropic.ai/future">https://www.extropic.ai/future</a>, See on <a href="https://news.ycombinator.com/item?id=39668430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Mar 11th, 2024								</p><p>/</p><p>Litepaper</p></div><div><p>Message from the team</p><div><p><em>We are very excited to finally share more about what Extropic is building: a full-stack hardware platform to harness matter's natural fluctuations as a computational resource for Generative AI.</em></p><p>What does this novel paradigm of computing practically mean for the world?</p><ul role="list"><li><em>Extends hardware scaling well beyond the constraints of digital computing</em></li><li><em>Enables AI accelerators that are many orders of magnitude faster and more energy efficient than digital processors (CPUs/GPUs/TPUs/FPGAs)</em></li><li><em>Unlocks powerful probabilistic AI algorithms that are not feasible on digital processors</em></li></ul><p><em>Our brief Litepaper (below) provides an early glimpse at our technologies. We hope the following excites you for the journey ahead. Join us as we accelerate towards the thermodynamically intelligent future.</em></p><p><strong>- Gill and Trev</strong></p></div></div><p><span>T</span>he demand for computing power in the AI era is increasing at an unprecedented exponential rate. Luckily, for the past several decades, the miniaturization of CMOS transistor technology following Moore’s law <a href="#references">[1]</a> has allowed much of this exponential growth to be accounted for by increasing computer efficiency.		</p><div><p>Unfortunately, Moore’s law is starting to slow down <a href="#references">[2]</a>. The reason for this is rooted in fundamental physics: transistors are approaching the atomic scale where effects like thermal noise start to forbid rigid digital operation <a href="#references">[3, 4, 5]</a>.</p><p>As a result, the energy requirements of modern AI are beginning to take off. Major players are proposing measures as extreme as building nuclear reactor-powered data centers dedicated to large model training and inference. Continuing this scaling for a few more decades will require infrastructure engineering efforts of unprecedented scale and represents an arduous path forward for scaling humanity’s aggregate intelligence.</p><p>On the other hand, biology is neither rigid nor digital and hosts computing circuitry that is much more efficient than anything humanity has built to date. Inter-cellular chemical reaction networks drive computation in biological systems. Cells are small, and as a result, the number of reactants in these networks is countable <a href="#references">[6, 7]</a>. Therefore, reactions between reactants are genuinely discrete and intrinsically random. The relative effect of this intrinsic randomness scales inversely with the number of reactant molecules, and as such, fluctuations tend to dominate the dynamics of these systems.</p><p>From this, we can say with certainty that there is no fundamental reason for the constraints of digital logic to bind the efficiency of computing devices. The engineering challenge is clear: how can we design a complete AI hardware and software system from the ground up that thrives in an intrinsically noisy environment?</p><p>Energy-Based Models (EBMs) offer hints at a potential solution, as they are a concept that appears both in thermodynamic physics and in fundamental probabilistic machine learning. In physics, they are known as parameterized thermal states, arising from steady-states of systems with tunable parameters. In machine learning, they are known as exponential families.</p><p>Exponential families are known to be the optimal way to parameterize probability distributions, requiring the minimal amount of data to uniquely determine their parameters <a href="#references">[8]</a>. They are thus excellent in the low-data regime, which encompasses scenarios where one needs to model tail events in mission-critical applications, as depicted in figure 1. The way they achieve this is by filling the blanks in data with noise; they seek to maximize their entropy while matching the statistics of the target distribution. This process of hallucinating every possibility that is not included in a dataset and penalizing such occurrences energetically requires the usage of a lot of randomness, both at training and inference time.</p></div><div id="figure-1"><p><span>Figure 1: The principles of Extropic probabilistic AI accelerators</span> A simple example of low-complexity distributional learning failing to capture the effect of a tail event. Low air pressure almost always means rain and high crop yields. However, every so often, very low air pressure corresponds to a hurricane.</p></div><div><p>This requirement of sampling has been the main limiter in production uses of EBMs. The fundamental reason for this is that sampling from generic energy landscapes is very difficult on digital hardware, which must expend substantial electrical energy to generate and shape the entropy required for the diffusion processes. From a hardware perspective, digital sampling seems quite contrived: why put so much effort into building increasingly complex pristine digital computers when the most common and compute-intensive algorithms turn around and pump them full of noise?</p><p>Extropic is shortcutting this inefficiency and unlocking the full potential of generative AI by implementing EBMs directly as parameterized stochastic analog circuits. Extropic accelerators will achieve many orders of magnitude of improvement over digital computers in terms of both runtime and energy efficiency for algorithms based on sampling from complex landscapes.</p><p>The operational principle of Extropic accelerators is analogous to Brownian motion. In Brownian motion, macroscopic but lightweight particles suspended in a fluid experience random forces due to many collisions with microscopic liquid molecules. These collisions lead to the random diffusion of the particles around the vessel. One could imagine anchoring the Brownian particles to the vessel walls and each other with springs, as depicted in Fig. 2 (a). In this case, the springs will resist the random forces, and the particles will prefer to reside in particular parts of the vessel more than others. If one repeatedly sampled the positions of the particles, waiting sufficiently long in between samples (as illustrated in Fig. 2 (b)), one would find that they follow a predictable <em>steady-state</em> probability distribution. If we changed the stiffness of the springs, this distribution would change. This simple mechanical system is a source of programmable randomness.</p></div><div id="figure-2"><p><span>Figure 2: The operational principle of Extropic accelerators &nbsp;<strong>(a)</strong></span> A simple mechanical analogy to Extropic accelerators. Since there are three masses in two dimensions, the steady state of this device would be a probability distribution over a 6-dimensional space. <span>(b)</span> Samples may be drawn from an Extropic accelerator by repeatedly observing the system, waiting at least the equilibration time teq between observations. teq is how long it takes for the noise in the system to destroy all correlations with the previous sample.</p></div><div><p>There is a direct connection between this mechanical picture and the parameterized stochastic analog circuits that make up Extropic accelerators. The lightweight particles represent electrons, and the liquid molecules represent the atoms of the conducting medium, which can transfer energy to the electrons upon collision. The springs represent circuit components that confine the motion of the electrons, such as inductors or transistors. Control voltages/currents can be applied to tune the values of these components, changing the distribution from which the circuit samples.</p><p>Although every circuit is noisy, not every circuit is useful as an Extropic accelerator. Making a noise-dominated yet well-behaved device is challenging from an engineering perspective. Thermal fluctuations are small, so devices must be physically small and low power to be strongly affected by them. For this reason, if one wanted to make an Extropic accelerator out of macroscopic components (on a PCB, for example), one would have to introduce synthetic noise. Doing so erodes the fundamental time and energy savings and ends up performing similarly to running the algorithm digitally.					</p><p>Extropic’s first processors are nano fabricated from aluminum and run at low temperatures where they are superconducting. Fig. 3 shows an early device that tested several possible superconducting neuron designs. Some of these neurons are similar to existing super conducting flux qubits <a href="#references">[9]</a>. These neurons exploit the Josephson effect as a source of nonlinearity, which occurs when two superconductors are near one another. This nonlinearity is required for the device to access non-Gaussian probability distributions, which are necessary to model real-world applications with fat tails. Additionally, digital Gaussian sampling routines are ubiquitous and highly optimized. So, if an analog device is to provide a considerable speedup compared to a traditional processor, non-Gaussianity is required.</p></div><div id="figure-3"><p><span>Figure 3:&nbsp;Microscope image of an Extropic chip.</span> The inset shows two Josephson junctions, which are the devices that provide the processor with its critical nonlinearity.												</p></div><div><p>These neurons provide the basic building blocks that are combined to form a larger superconducting system. In such a larger system, many linear and non-linear neurons are combined together to create a circuit that samples from a rich and high-dimensional distribution. The neuron biases and interaction strengths are all tunable parameters of the distribution, allowing a single device to embody a wide family of probability distributions.</p><p>Extropic’s superconducting chips are entirely passive, meaning we only expend energy when measuring or manipulating its state. This likely makes these neurons the most energy-efficient in the universe. These systems will be highly energy efficient at scale: Extropic targets low-volume, high-value customers like governments, banks, and private clouds with these systems.</p><p>Extropic is also building semiconductor devices that operate at room temperature to extend our reach to a larger market. These devices trade the Josephson junction for the transistor. Doing so sacrifices some energy efficiency compared to superconducting devices. In exchange, it allows one to build them using standard manufacturing processes and supply chains, unlocking massive scale. Since they operate at room temperature, it will be possible to pack them into a GPU-like expansion card form factor. This will allow us to put an Extropic accelerator in every home, enabling everyone to partake in the thermodynamic AI acceleration.</p><p>To support a wide range of hardware substrates, Extropic is also building a software layer that compiles from abstract specifications of EBMs to the relevant hardware control language. This compilation layer is built upon the theoretical framework of factor graphs <a href="#references">[8]</a>. Factor graphs specify how large distributions factorize into local chunks. This allows Extropic accelerators to breakdown and run programs that are too big to fit on any given analog core.				</p><p>Many previous AI accelerator companies have struggled to find an advantage because of the memory-boundedness of deep learning; today’s algorithms spend around 25% of their time moving numbers around in memory. As a result of this, via Amdahl’s law, any chip that accelerates a particular operation (such as matrix multiplication) will struggle to achieve more than a 4x speedup. As Extropic chips natively accelerate a broad class of probabilistic algorithms by running them physically as a rapid and energy-efficient process in their entirety, we are bound to unlock a whole new regime of artificial intelligence acceleration well beyond what was previously thought achievable.</p></div><a href="https://www.extropic.ai/careers" target="_blank"></a><div id="references"><h3>References</h3><a href="https://ieeexplore.ieee.org/document/4785860" target="_blank"></a><a href="https://ieeexplore.ieee.org/document/7878935" target="_blank"></a><a href="https://link.springer.com/article/10.1007/BF01250732" target="_blank"></a><a href="https://ieeexplore.ieee.org/document/752515" target="_blank"></a><a href="https://ieeexplore.ieee.org/document/1182065" target="_blank"></a><a href="https://www.annualreviews.org/doi/10.1146/annurev.physchem.58.032806.104637" target="_blank"></a><a href="https://www.pnas.org/doi/10.1073/pnas.94.3.814" target="_blank"></a><a href="https://mitpress.mit.edu/9780262013192/probabilistic-graphical-models/" target="_blank"></a><a href="https://escholarship.org/uc/item/9844c3h3" target="_blank"></a></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GrapheneOS finds Bluetooth memory corruption via ARM MTE (222 pts)]]></title>
            <link>https://grapheneos.social/@GrapheneOS/112066872276203917</link>
            <guid>39668053</guid>
            <pubDate>Mon, 11 Mar 2024 13:36:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grapheneos.social/@GrapheneOS/112066872276203917">https://grapheneos.social/@GrapheneOS/112066872276203917</a>, See on <a href="https://news.ycombinator.com/item?id=39668053">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Building an Open Source Decentralized E-Book Search Engine (197 pts)]]></title>
            <link>https://github.com/j2qk3b/ebook-demo/blob/main/tutorial.md</link>
            <guid>39666993</guid>
            <pubDate>Mon, 11 Mar 2024 11:56:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/j2qk3b/ebook-demo/blob/main/tutorial.md">https://github.com/j2qk3b/ebook-demo/blob/main/tutorial.md</a>, See on <a href="https://news.ycombinator.com/item?id=39666993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:j2qk3b/ebook-demo" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="bAZCvTYOEC1SyENw7fiHWar5i4g_5BOabdtPpvB5OUqiOqjlbK5DoCXtmlW_bypQzX_VzwXz_QG6tP0tZpvuDA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="j2qk3b/ebook-demo" data-current-org="" data-current-owner="j2qk3b" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=9V8qOlU0uL60V2hmJS9JtVN10NVQ2T0zkBzR2JB5SMOIie3pL6Sv6gcvviEJQN%2F69edBzexpUhHPPg%2BjA0aup4mGDvFPZ8P%2BN6CWxCwokOLVWuoU1bOEt4MMeqaI1havQKCgcNWFDpOR8offgQDmbGNr4LUd2iBoLrQhct2EWqemw649Y28VPiGA%2FPcoKwa%2F0%2FvEEpr4jLuHcHaV8DCOZOFOeDOKQOU0lM8SfEuXTKPiETG41IHhPjSibaOrz5XCezH3JVMesEe7RmKttqeIGmT5JnOT3feHxUPw7RQ7bMy%2FCF%2F32ihcy28nN0HUN1RfyjeTlFSypHbOEjX%2Bvv0wIX8gYMj3M5cN5Xq9jTZOmFXsqWljG%2Bp50bKBi6rGb98iFwNCfVSi2L5uM4WUvdlpqA88i%2Bo7%2FUCg4%2FG4cPtW69wXw1wW%2Bf5n9mV7mmbzcZmzD1DOXp3UIx%2F2TT7I8dOgv21e8csCdTypJE7gM1%2BFFHvQ%2BL84w8Ke9Vw1WUlvHjvttK27t0BN%2BG4j9ltsyRGdnHf9ESr8lE0q5Br5xihHc3JJv0CidZtvPSCP--YFyq8JjzuL938XB4--2LSoNQ17ZGyaQ63zQBm0%2BQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=j2qk3b%2Febook-demo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/j2qk3b/ebook-demo/blob/main/tutorial.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="8058d1ec797eb6e8a4b31d576edc0b0925b770eb14488aaefac3aabb12c6dca9" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automakers Are Sharing Consumers' Driving Behavior with Insurance Companies (120 pts)]]></title>
            <link>https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html</link>
            <guid>39666976</guid>
            <pubDate>Mon, 11 Mar 2024 11:55:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html">https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html</a>, See on <a href="https://news.ycombinator.com/item?id=39666976">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/03/11/technology/carmakers-driver-tracking-insurance.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Flowers for Algernon (1965) [pdf] (307 pts)]]></title>
            <link>https://www.sdfo.org/gj/stories/flowersforalgernon.pdf</link>
            <guid>39666956</guid>
            <pubDate>Mon, 11 Mar 2024 11:53:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sdfo.org/gj/stories/flowersforalgernon.pdf">https://www.sdfo.org/gj/stories/flowersforalgernon.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39666956">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Teable – Open-Source No-Code Database Fusion of Postgres and Airtable (167 pts)]]></title>
            <link>https://github.com/teableio/teable</link>
            <guid>39666865</guid>
            <pubDate>Mon, 11 Mar 2024 11:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/teableio/teable">https://github.com/teableio/teable</a>, See on <a href="https://news.ycombinator.com/item?id=39666865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <div dir="auto"><h2 tabindex="-1" dir="auto">
    <themed-picture data-catalyst-inline="true"><picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/teableio/teable/raw/develop/static/assets/images/teable-vertical-dark.png">
      <img alt="teable logo" height="150" src="https://github.com/teableio/teable/raw/develop/static/assets/images/teable-vertical-light.png">
    </picture></themed-picture>
  </h2><a id="user-content-----------------------" aria-label="Permalink: " href="#----------------------"></a></div>
  <p dir="auto"><h3 tabindex="-1" dir="auto"><strong>Postgres-Airtable Fusion</strong></h3><a id="user-content-postgres-airtable-fusion" aria-label="Permalink: Postgres-Airtable Fusion" href="#postgres-airtable-fusion"></a></p>
  <p dir="auto">Teable is a Super fast, Real-time, Professional, Developer friendly, No-code database built on Postgres. It uses a simple, spreadsheet-like interface to create complex enterprise-level database applications. Unlock efficient app development with no-code, free from the hurdles of data security and scalability. </p>
</div>
<p dir="auto">
  <a href="https://teable.io/" rel="nofollow">Home</a> | <a href="https://help.teable.io/" rel="nofollow">Help</a> | <a href="https://blog.teable.io/" rel="nofollow">Blog</a> | <a href="https://template.teable.io/" rel="nofollow">Template</a> | <a href="https://app.teable.io/share/shr04TEw1u9EOQojPmG/view" rel="nofollow">Roadmap</a> | <a href="https://discord.gg/n2JQqekG" rel="nofollow">Discord </a>
</p>
<p dir="auto">
  <a aria-label="Build" href="https://github.com/teableio/teable/actions?query=Build%20and%20Push%20to%20Docker%20Registry">
    <img alt="build" src="https://camo.githubusercontent.com/51feb6245c6188b4c6eb58922c111c863acbf0e6ad044115abc545e21069aa9d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f746561626c65696f2f746561626c652f646f636b65722d707573682e796d6c3f6c6162656c3d4275696c64266c6f676f3d676974687562267374796c653d666c61742d7175617265266c6162656c436f6c6f723d303030303030" data-canonical-src="https://img.shields.io/github/actions/workflow/status/teableio/teable/docker-push.yml?label=Build&amp;logo=github&amp;style=flat-quare&amp;labelColor=000000">
  </a>
  <a aria-label="Codefactor grade" href="https://www.codefactor.io/repository/github/teableio/teable" rel="nofollow">
    <img alt="Codefactor" src="https://camo.githubusercontent.com/56f625cb617e43b7d96feb176797b27ab934ef6c1533383e2aa16de314798b2d/68747470733a2f2f696d672e736869656c64732e696f2f636f6465666163746f722f67726164652f6769746875622f746561626c65696f2f746561626c653f6c6162656c3d436f6465666163746f72266c6f676f3d636f6465666163746f72267374796c653d666c61742d7175617265266c6162656c436f6c6f723d303030303030" data-canonical-src="https://img.shields.io/codefactor/grade/github/teableio/teable?label=Codefactor&amp;logo=codefactor&amp;style=flat-quare&amp;labelColor=000000">
  </a>
  <a aria-label="CodeClimate maintainability" href="https://codeclimate.com/github/teableio/teable" rel="nofollow">
    <img alt="Maintainability" src="https://camo.githubusercontent.com/02f58b978a0195807709e61e8fb3432a025c9d0c7c5dc776228a02ba1cc06afc/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636c696d6174652f6d61696e7461696e6162696c6974792f746561626c65696f2f746561626c653f6c6162656c3d4d61696e7461696e6162696c697479266c6f676f3d636f64652d636c696d617465267374796c653d666c61742d7175617265266c6162656c436f6c6f723d303030303030" data-canonical-src="https://img.shields.io/codeclimate/maintainability/teableio/teable?label=Maintainability&amp;logo=code-climate&amp;style=flat-quare&amp;labelColor=000000">
  </a>
  <a aria-label="CodeClimate technical debt" href="https://codeclimate.com/github/teableio/teable" rel="nofollow">
    <img alt="Techdebt" src="https://camo.githubusercontent.com/60407bf2806fbd36e678f1e3998e6ffabefe1fbae5a8866767881e0775f9745a/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636c696d6174652f746563682d646562742f746561626c65696f2f746561626c653f6c6162656c3d5465636844656274266c6f676f3d636f64652d636c696d617465267374796c653d666c61742d7175617265266c6162656c436f6c6f723d303030303030" data-canonical-src="https://img.shields.io/codeclimate/tech-debt/teableio/teable?label=TechDebt&amp;logo=code-climate&amp;style=flat-quare&amp;labelColor=000000">
  </a>
  <a aria-label="Codacy grade" href="https://www.codacy.com/gh/teableio/teable/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=teableio/teable&amp;utm_campaign=Badge_Grade" rel="nofollow">
    <img alt="Codacy grade" src="https://camo.githubusercontent.com/feac5e519bc775dbd9168ea74b043bb34c5f78973cafceb4f1c6535b89dd78c9/68747470733a2f2f696d672e736869656c64732e696f2f636f646163792f67726164652f64666639633934346166323834613066616434653136356562313732373436373f6c6f676f3d636f64616379267374796c653d666c61742d737175617265266c6162656c436f6c6f723d303030266c6162656c3d436f64616379" data-canonical-src="https://img.shields.io/codacy/grade/dff9c944af284a0fad4e165eb1727467?logo=codacy&amp;style=flat-square&amp;labelColor=000&amp;label=Codacy">
  </a>
  <a aria-label="Top language" href="https://github.com/teableio/teable/search?l=typescript">
    <img alt="GitHub top language" src="https://camo.githubusercontent.com/d5764ff62c111b52311ce4914e6b48f4cf79c54cae344edfe10f57f31854e8c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f746f702f746561626c65696f2f746561626c653f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d30303026636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/github/languages/top/teableio/teable?style=flat-square&amp;labelColor=000&amp;color=blue">
  </a>
  <a aria-label="Licence" href="https://github.com/teableio/teable/blob/main/LICENSE">
    <img alt="Licence" src="https://camo.githubusercontent.com/29629cb104e1314fe2c260743595d3a21f7582e7c83e06d80ea0f9c7a2ceae0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f746561626c65696f2f746561626c653f7374796c653d666c61742d7175617265266c6162656c436f6c6f723d303030303030" data-canonical-src="https://img.shields.io/github/license/teableio/teable?style=flat-quare&amp;labelColor=000000">
  </a>
</p>
  <div dir="auto"><h2 tabindex="-1" dir="auto">
    <themed-picture data-catalyst-inline="true"><picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/teableio/teable/raw/develop/static/assets/images/teable-interface-dark.png">
      <img alt="teable interface" width="100%" src="https://github.com/teableio/teable/raw/develop/static/assets/images/teable-interface-light.png">
    </picture></themed-picture>
  </h2><a id="user-content------------------------1" aria-label="Permalink: " href="#-----------------------1"></a></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Guide</h2><a id="user-content-quick-guide" aria-label="Permalink: Quick Guide" href="#quick-guide"></a></p>
<ol dir="auto">
<li>Looking for a quick experience? Select a scenario from the <a href="https://template.teable.io/" rel="nofollow">template center</a> and click "Use this template".</li>
<li>Seeking high performance? Try the <a href="https://app.teable.io/share/shrVgdLiOvNQABtW0yX/view" rel="nofollow">1 million rows demo</a> to feel the speed of Teable.</li>
<li>Want to learn to use it quickly? Click on this <a href="https://help.teable.io/quick-start/build-a-simple-base" rel="nofollow">tutorial</a></li>
<li>Interested in deploying it yourself? Click <a href="https://railway.app/template/wada5e?referralCode=rE4BjB" rel="nofollow">Deploy on Railway</a></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨Features</h2><a id="user-content-features" aria-label="Permalink: ✨Features" href="#features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">📊 Spreadsheet-like interface</h4><a id="user-content--spreadsheet-like-interface" aria-label="Permalink: 📊 Spreadsheet-like interface" href="#-spreadsheet-like-interface"></a></p>
<p dir="auto">All you want is here</p>
<ul dir="auto">
<li>Cell Editing: Directly click and edit content within cells.</li>
<li>Formula Support: Input mathematical and logical formulas to auto-calculate values.</li>
<li>Data Sorting and Filtering: Sort data based on a column or multiple columns; use filters to view specific rows of data.</li>
<li>Aggregation Function: Automatically summarize statistics for each column, providing instant calculations like sum, average, count, max, and min for streamlined data analysis.</li>
<li>Data Formatting: formatting numbers, dates, etc.</li>
<li>Grouping: Organize rows into collapsible groups based on column values for easier data analysis and navigation.</li>
<li>Freeze Columns: Freeze the left column of the table so they remain visible while scrolling.</li>
<li>Import/Export Capabilities: Import and export data from other formats, e.g., .csv, .xlsx.</li>
<li>Row Styling &amp; Conditional Formatting: Change row styles automatically based on specific conditions. (coming soon)</li>
<li>Charts &amp; Visualization Tools: Create charts from table data such as bar charts, pie charts, line graphs, etc. (coming soon)</li>
<li>Data Validation: Limit or validate data that are entered into cells. (coming soon)</li>
<li>Undo/Redo: Undo or redo recent changes. (coming soon)</li>
<li>Comments &amp; Annotations: Attach comments to rows, providing explanations or feedback for other users. (coming soon)</li>
<li>Find &amp; Replace: Search content within the table and replace it with new content. (coming soon)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🗂️ Multiple Views</h4><a id="user-content-️-multiple-views" aria-label="Permalink: 🗂️ Multiple Views" href="#️-multiple-views"></a></p>
<p dir="auto">Visualize and interact with data in various ways best suited for their specific tasks.</p>
<ul dir="auto">
<li>Grid View: The default view of the table, which displays data in a spreadsheet-like format.</li>
<li>Form View: Input data in a form format, which is useful for collecting data.</li>
<li>Kanban View: Displays data in a Kanban board, which is a visual representation of data in columns and cards. (coming soon)</li>
<li>Calendar View: Displays data in a calendar format, which is useful for tracking dates and events. (coming soon)</li>
<li>Gallery View: Displays data in a gallery format, which is useful for displaying images and other media. (coming soon)</li>
<li>Gantt View: Displays data in a Gantt chart, which is useful for tracking project schedules. (coming soon)</li>
<li>Timeline View: Displays data in a timeline format, which is useful for tracking events over time. (coming soon)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🚀 Super Fast</h4><a id="user-content--super-fast" aria-label="Permalink: 🚀 Super Fast" href="#-super-fast"></a></p>
<p dir="auto">Amazing response speed and data capacity</p>
<ul dir="auto">
<li>Millions of data are easily processed, and there is no pressure to filter and sort</li>
<li>Automatic database indexing for maximum speed</li>
<li>Supports batch data operations at one time</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">👨‍💻 Full-featured SQL Support</h4><a id="user-content--full-featured-sql-support" aria-label="Permalink: 👨‍💻 Full-featured SQL Support" href="#-full-featured-sql-support"></a></p>
<p dir="auto">Seamless integration with the software you are familiar with</p>
<ul dir="auto">
<li>BI tools like Metabase PowerBi...</li>
<li>No-code tools like Appsmith...</li>
<li>Direct retrieve data with native SQL</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔒 Privacy-First</h4><a id="user-content--privacy-first" aria-label="Permalink: 🔒 Privacy-First" href="#-privacy-first"></a></p>
<p dir="auto">You own your data, in spite of the cloud</p>
<ul dir="auto">
<li>Bring your own database (coming soon)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">⚡️ Real-time collaboration</h4><a id="user-content-️-real-time-collaboration" aria-label="Permalink: ⚡️ Real-time collaboration" href="#️-real-time-collaboration"></a></p>
<p dir="auto">Designed for teams</p>
<ul dir="auto">
<li>No need to refresh the page, data is updated in real-time</li>
<li>Seamlessly integrate collaboration member invitation and management</li>
<li>Perfect permission management mechanism, from table to column level</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🧩 Extensions (coming soon)</h4><a id="user-content--extensions-coming-soon" aria-label="Permalink: 🧩 Extensions (coming soon)" href="#-extensions-coming-soon"></a></p>
<p dir="auto">Expand infinite possibilities</p>
<ul dir="auto">
<li>Backend-less programming capability based on React</li>
<li>Customize your own application with extremely low cost</li>
<li>Extremely easy-to-use script extensions mode</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🤖 Automation (coming soon)</h4><a id="user-content--automation-coming-soon" aria-label="Permalink: 🤖 Automation (coming soon)" href="#-automation-coming-soon"></a></p>
<p dir="auto">Empower data-driven workflows effortlessly and seamlessly</p>
<ul dir="auto">
<li>Design your workflow with AI or Visual programming</li>
<li>Super easy to retrieve data from the table</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🧠 Copilot (coming soon)</h4><a id="user-content--copilot-coming-soon" aria-label="Permalink: 🧠 Copilot (coming soon)" href="#-copilot-coming-soon"></a></p>
<p dir="auto">Native Integrated AI ability</p>
<ul dir="auto">
<li>Chat 2 App. "Create a project management app for me"</li>
<li>Chat 2 Chart. "Analyze the data in the order table using a bar chart"</li>
<li>Chat 2 View. "I want to see the schedule for the past week and only display participants"</li>
<li>Chat 2 Action. "After the order is paid and completed, an email notification will be sent to the customer"</li>
<li>More actions...</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🗄️ Support for multiple databases (coming soon)</h4><a id="user-content-️-support-for-multiple-databases-coming-soon" aria-label="Permalink: 🗄️ Support for multiple databases (coming soon)" href="#️-support-for-multiple-databases-coming-soon"></a></p>
<p dir="auto">Choose the SQL database you like</p>
<ul dir="auto">
<li>Sqlite, PostgreSQL, MySQL, MariaDB, TiDB...</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Structure</h2><a id="user-content-structure" aria-label="Permalink: Structure" href="#structure"></a></p>
<p dir="auto"><a href="https://gitpod.io/#https://github.com/teableio/teable" rel="nofollow"><img src="https://camo.githubusercontent.com/1470bc5ed68e2671a712665be23b2c0612229ac893c1eee461399476f43bc28e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f70656e253230496e2d476974706f642e696f2d2532333139363644323f7374796c653d666f722d7468652d6261646765266c6f676f3d676974706f64" alt="Open in Gitpod" data-canonical-src="https://img.shields.io/badge/Open%20In-Gitpod.io-%231966D2?style=for-the-badge&amp;logo=gitpod"></a></p>
<div data-snippet-clipboard-copy-content=".
├── apps
│   ├── electron            (desktop, include a electron app )
│   ├── nextjs-app          (front-end, include a nextjs app)
│   └── nestjs-backend      (backend, running on server or inside electron app)
└── packages
    ├── common-i18n         (locales)
    ├── core                (share code and interface)
    ├── sdk                 (sdk for extensions)
    ├── db-main-prisma      (schema, migrations, prisma client)
    ├── eslint-config-bases (to shared eslint configs)
    └── ui-lib              (ui component)"><pre><code>.
├── apps
│   ├── electron            (desktop, include a electron app )
│   ├── nextjs-app          (front-end, include a nextjs app)
│   └── nestjs-backend      (backend, running on server or inside electron app)
└── packages
    ├── common-i18n         (locales)
    ├── core                (share code and interface)
    ├── sdk                 (sdk for extensions)
    ├── db-main-prisma      (schema, migrations, prisma client)
    ├── eslint-config-bases (to shared eslint configs)
    └── ui-lib              (ui component)
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deploy</h2><a id="user-content-deploy" aria-label="Permalink: Deploy" href="#deploy"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy with docker</h3><a id="user-content-deploy-with-docker" aria-label="Permalink: Deploy with docker" href="#deploy-with-docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd dockers/examples/standalone/
docker-compose up -d"><pre><span>cd</span> dockers/examples/standalone/
docker-compose up -d</pre></div>
<p dir="auto">for more details, see <a href="https://github.com/teableio/teable/blob/develop/dockers/examples">dockers/examples</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy with Railway</h3><a id="user-content-deploy-with-railway" aria-label="Permalink: Deploy with Railway" href="#deploy-with-railway"></a></p>
<p dir="auto"><a href="https://railway.app/template/wada5e?referralCode=rE4BjB" rel="nofollow"><img src="https://camo.githubusercontent.com/d07713342bc583232f8752c33a6a24e5f367d73725183a63f2f5fdd7c00606a3/68747470733a2f2f7261696c7761792e6170702f627574746f6e2e737667" alt="Deploy on Railway" data-canonical-src="https://railway.app/button.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">1. Initialize</h4><a id="user-content-1-initialize" aria-label="Permalink: 1. Initialize" href="#1-initialize"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Use `.nvmrc` file to specify node version（Requires pre `nvm` tools）
nvm install &amp;&amp; nvm use

# Enabling the Help Management Package Manager
corepack enable

# Install project dependencies
pnpm install

# Build packages
pnpm g:build"><pre><span><span>#</span> Use `.nvmrc` file to specify node version（Requires pre `nvm` tools）</span>
nvm install <span>&amp;&amp;</span> nvm use

<span><span>#</span> Enabling the Help Management Package Manager</span>
corepack <span>enable</span>

<span><span>#</span> Install project dependencies</span>
pnpm install

<span><span>#</span> Build packages</span>
pnpm g:build</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">2. Select Database</h4><a id="user-content-2-select-database" aria-label="Permalink: 2. Select Database" href="#2-select-database"></a></p>
<p dir="auto">we currently support <code>sqlite</code> and <code>postgres</code>, you can switch between them by running the following command</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">3. Custom environment variables（optional）</h4><a id="user-content-3-custom-environment-variablesoptional" aria-label="Permalink: 3. Custom environment variables（optional）" href="#3-custom-environment-variablesoptional"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd apps/nextjs-app
copy .env.development .env.development.local"><pre><span>cd</span> apps/nextjs-app
copy .env.development .env.development.local</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">4. Run dev server</h4><a id="user-content-4-run-dev-server" aria-label="Permalink: 4. Run dev server" href="#4-run-dev-server"></a></p>
<p dir="auto">you just need to start backend, it will start next server for frontend automatically, file change will be auto reload</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd apps/nestjs-backend
pnpm dev"><pre><span>cd</span> apps/nestjs-backend
pnpm dev</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Teable?</h2><a id="user-content-why-teable" aria-label="Permalink: Why Teable?" href="#why-teable"></a></p>
<p dir="auto">No-code tools have significantly speed up how we get things done, allowing non-tech users to build amazing apps and changing the way many work and live. People like using spreadsheet-like UI to handle their data because it's easy, flexible, and great for team collaboration. They also prefer designing their app screens without being stuck with clunky templates.</p>
<p dir="auto">Giving non-techy people the ability to create their software sounds exciting. But that's just the start:</p>
<ul dir="auto">
<li>As businesses expand, their data needs intensify. No one wishes to hear that once their orders reach 100k, they'll outgrow their current interface. Yet, many no-code platforms falter at such scales.</li>
<li>Most no-code platforms are cloud-based. This means your important data sits with the provider, and switching to another platform can be a headache.</li>
<li>Sometimes, no-code tools can't do what you want because of their limitations, leaving users stuck.</li>
<li>If a tool becomes essential, you'll eventually need some tech expertise. But developers often find these platforms tricky.</li>
<li>Maintaining systems with complex setups can be hard for developers, especially if these aren't built using common software standards.</li>
<li>Systems that don't use these standards might need revamping or replacing, costing more in the long run. It might even mean ditching the no-code route and going back to traditional coding.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">What we think the future of no-code products look like</h4><a id="user-content-what-we-think-the-future-of-no-code-products-look-like" aria-label="Permalink: What we think the future of no-code products look like" href="#what-we-think-the-future-of-no-code-products-look-like"></a></p>
<ul dir="auto">
<li>An interface that anyone can use to build applications easily.</li>
<li>Easy access to data, letting users grab, move, and reuse their information as they wish.</li>
<li>Data privacy and choice, whether that's in the cloud, on-premise, or even just on your local.</li>
<li>It needs to work for developers too, not just non-tech users.</li>
<li>It should handle lots of data, so it can grow with your business.</li>
<li>Flexibility to integrate with other software, combining strengths to get the job done.</li>
<li>Last, native AI integration to takes usability to the next level.</li>
</ul>
<p dir="auto">In essence, Teable isn't just another no-code solution, it's a comprehensive answer to the evolving demands of modern software development, ensuring that everyone, regardless of their technical proficiency, has a platform tailored to their needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsors ❤️</h2><a id="user-content-sponsors-heart" aria-label="Permalink: Sponsors :heart:" href="#sponsors-heart"></a></p>
<p dir="auto">If you are enjoying some this project in your company, I'd really appreciate a <a href="https://github.com/sponsors/teableio">sponsorship</a>, a <a href="https://ko-fi.com/teable" rel="nofollow">coffee</a> or a dropped star.
That gives me some more time to improve it to the next level.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">AGPL-3.0</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Commission's use of Microsoft 365 infringes data protection law for EU (117 pts)]]></title>
            <link>https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en</link>
            <guid>39666582</guid>
            <pubDate>Mon, 11 Mar 2024 11:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en">https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en</a>, See on <a href="https://news.ycombinator.com/item?id=39666582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper" data-off-canvas-main-canvas="">
              <main id="content" role="main">
                <section>
                  <a id="main-content" tabindex="-1"></a>
                    
<div id="block-edpsweb-theme-main-page-content">
      

<article>
  
  <div>
    <header>
      
      
      <h3>
        <a href="https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies" rel="bookmark"><span>European Commission’s use of Microsoft 365 infringes data protection law for EU institutions and bodies</span>
</a>
      </h3>
      
    </header>
    <div><p><b>Following its investigation, the EDPS has found that the European Commission (Commission) has infringed several key data protection rules when using Microsoft 365. In its decision, the EDPS imposes corrective measures on the Commission</b>.</p>
<p>The EDPS has found that the Commission <b>has infringed several provisions of Regulation (EU) 2018/1725</b>, the EU’s data protection law for EU institutions, bodies, offices and agencies (EUIs), including those <b>on transfers of personal data outside the EU/European Economic Area (EEA)</b>. In particular, the Commission has failed to provide appropriate safeguards to ensure that personal data transferred outside the EU/EEA are afforded an essentially equivalent level of protection as guaranteed in the EU/EEA. Furthermore, in its contract with Microsoft, <b>the Commission did not sufficiently specify what types of personal data are to be collected and for which explicit and specified purposes when using Microsoft 365</b>. The <b>Commission’s infringements as data controller also relate to data processing</b>, including transfers of personal data, carried out <b>on its behalf</b>.</p>
<p><b>Wojciech Wiewiórowski, EDPS, said: </b><i>“It is the responsibility of the EU institutions, bodies, offices and agencies (EUIs) to ensure that any processing of personal data outside and inside the EU/EEA, including in the context of cloud-based services, is accompanied by robust data protection safeguards and measures. This is imperative to ensure that individuals’ information is protected, as required by</i><i> Regulation (EU) 2018/1725, whenever their data is processed by, or on behalf of, an EUI.” </i></p>
<p>The EDPS has therefore decided to order the Commission, effective on <b>9 December 2024</b>, to <b>suspend all data flows </b>resulting from its use of Microsoft 365<b> to Microsoft </b>and to its affiliates and sub-processors<b> located in countries outside the EU/EEA not covered by an adequacy decision</b>. The EDPS has also decided to order the Commission to <b>bring the processing operations</b> resulting from its use of Microsoft 365 <b>into compliance with Regulation (EU) 2018/1725</b>. <b>The Commission must demonstrate compliance with both orders by 9 December 2024</b>.</p>
<p>The EDPS considers that <b>the corrective measures it imposes (<a href="https://www.edps.europa.eu/system/files/2024-03/EDPS-2024-05-European-Commission_s-use-of-M365-infringes-data-protection-rules-for-EU-institutions-and-bodies_EN.pdf">see annex for a detailed excerpt</a>) are appropriate, necessary </b>and<b> proportionate in light of the seriousness and duration of the infringements found. </b></p>
<p>Many of the infringements found concern all processing operations carried out by the Commission, or on its behalf, when using Microsoft 365, and impact a large number of individuals.</p>
<p>The EDPS also takes into account the need <b>not to compromise the Commission’s ability to carry out its tasks in the public interest or to exercise official authority vested in the Commission, and the need to allow appropriate time for the Commission to implement the foreseen suspension of relevant data flows, and to bring the processing of data into compliance with Regulation (EU) 2018/1725.</b></p>
<p>The measures imposed by the EDPS in its decision of 8 March 2024 are without prejudice to any other or further action that the EDPS may undertake.</p>
<p><b><a href="https://www.edps.europa.eu/system/files/2024-03/EDPS-2024-05-European-Commission_s-use-of-M365-infringes-data-protection-rules-for-EU-institutions-and-bodies_EN.pdf">The findings of infringements and corrective measures imposed by the EDPS in its decision can be found in annex</a>. </b></p>
</div>
  </div>
</article>

    </div>


                </section>
              </main>
                                      
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Commission's use of Microsoft 365 infringes data protection law for EU (146 pts)]]></title>
            <link>https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en</link>
            <guid>39666561</guid>
            <pubDate>Mon, 11 Mar 2024 10:57:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en">https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies_en</a>, See on <a href="https://news.ycombinator.com/item?id=39666561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper" data-off-canvas-main-canvas="">
              <main id="content" role="main">
                <section>
                  <a id="main-content" tabindex="-1"></a>
                    
<div id="block-edpsweb-theme-main-page-content">
      

<article>
  
  <div>
    <header>
      
      
      <h3>
        <a href="https://www.edps.europa.eu/press-publications/press-news/press-releases/2024/european-commissions-use-microsoft-365-infringes-data-protection-law-eu-institutions-and-bodies" rel="bookmark"><span>European Commission’s use of Microsoft 365 infringes data protection law for EU institutions and bodies</span>
</a>
      </h3>
      
    </header>
    <div><p><b>Following its investigation, the EDPS has found that the European Commission (Commission) has infringed several key data protection rules when using Microsoft 365. In its decision, the EDPS imposes corrective measures on the Commission</b>.</p>
<p>The EDPS has found that the Commission <b>has infringed several provisions of Regulation (EU) 2018/1725</b>, the EU’s data protection law for EU institutions, bodies, offices and agencies (EUIs), including those <b>on transfers of personal data outside the EU/European Economic Area (EEA)</b>. In particular, the Commission has failed to provide appropriate safeguards to ensure that personal data transferred outside the EU/EEA are afforded an essentially equivalent level of protection as guaranteed in the EU/EEA. Furthermore, in its contract with Microsoft, <b>the Commission did not sufficiently specify what types of personal data are to be collected and for which explicit and specified purposes when using Microsoft 365</b>. The <b>Commission’s infringements as data controller also relate to data processing</b>, including transfers of personal data, carried out <b>on its behalf</b>.</p>
<p><b>Wojciech Wiewiórowski, EDPS, said: </b><i>“It is the responsibility of the EU institutions, bodies, offices and agencies (EUIs) to ensure that any processing of personal data outside and inside the EU/EEA, including in the context of cloud-based services, is accompanied by robust data protection safeguards and measures. This is imperative to ensure that individuals’ information is protected, as required by</i><i> Regulation (EU) 2018/1725, whenever their data is processed by, or on behalf of, an EUI.” </i></p>
<p>The EDPS has therefore decided to order the Commission, effective on <b>9 December 2024</b>, to <b>suspend all data flows </b>resulting from its use of Microsoft 365<b> to Microsoft </b>and to its affiliates and sub-processors<b> located in countries outside the EU/EEA not covered by an adequacy decision</b>. The EDPS has also decided to order the Commission to <b>bring the processing operations</b> resulting from its use of Microsoft 365 <b>into compliance with Regulation (EU) 2018/1725</b>. <b>The Commission must demonstrate compliance with both orders by 9 December 2024</b>.</p>
<p>The EDPS considers that <b>the corrective measures it imposes (<a href="https://www.edps.europa.eu/system/files/2024-03/EDPS-2024-05-European-Commission_s-use-of-M365-infringes-data-protection-rules-for-EU-institutions-and-bodies_EN.pdf">see annex for a detailed excerpt</a>) are appropriate, necessary </b>and<b> proportionate in light of the seriousness and duration of the infringements found. </b></p>
<p>Many of the infringements found concern all processing operations carried out by the Commission, or on its behalf, when using Microsoft 365, and impact a large number of individuals.</p>
<p>The EDPS also takes into account the need <b>not to compromise the Commission’s ability to carry out its tasks in the public interest or to exercise official authority vested in the Commission, and the need to allow appropriate time for the Commission to implement the foreseen suspension of relevant data flows, and to bring the processing of data into compliance with Regulation (EU) 2018/1725.</b></p>
<p>The measures imposed by the EDPS in its decision of 8 March 2024 are without prejudice to any other or further action that the EDPS may undertake.</p>
<p><b><a href="https://www.edps.europa.eu/system/files/2024-03/EDPS-2024-05-European-Commission_s-use-of-M365-infringes-data-protection-rules-for-EU-institutions-and-bodies_EN.pdf">The findings of infringements and corrective measures imposed by the EDPS in its decision can be found in annex</a>. </b></p>
</div>
  </div>
</article>

    </div>


                </section>
              </main>
                                      
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A TUI Git client inspired by Magit (109 pts)]]></title>
            <link>https://github.com/altsem/gitu</link>
            <guid>39666520</guid>
            <pubDate>Mon, 11 Mar 2024 10:52:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/altsem/gitu">https://github.com/altsem/gitu</a>, See on <a href="https://news.ycombinator.com/item?id=39666520">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">It's Gitu! - A Git porcelain <em>outside</em> of Emacs</h2><a id="user-content-its-gitu---a-git-porcelain-outside-of-emacs" aria-label="Permalink: It's Gitu! - A Git porcelain outside of Emacs" href="#its-gitu---a-git-porcelain-outside-of-emacs"></a></p>
<p dir="auto"><a href="https://github.com/altsem/gitu/actions/workflows/ci.yml"><img src="https://github.com/altsem/gitu/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://codecov.io/gh/altsem/gitu" rel="nofollow"><img src="https://camo.githubusercontent.com/aea59bf22ba4df39a48b5a78040f11f0013f136caface0ef2f3aa8352042e8a1/68747470733a2f2f636f6465636f762e696f2f67682f616c7473656d2f676974752f67726170682f62616467652e7376673f746f6b656e3d35595750553747574657" alt="codecov" data-canonical-src="https://codecov.io/gh/altsem/gitu/graph/badge.svg?token=5YWPU7GWFW"></a></p>
<p dir="auto">A terminal user interface for Git. Inspired by Magit, and launched straight from the terminal.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/altsem/gitu/blob/master/vhs/rec.gif"><img src="https://github.com/altsem/gitu/raw/master/vhs/rec.gif" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Gitu aims to implement many of the core features of Magit over time.
It should be familiar to any previous Magit users.</p>
<p dir="auto">A rough list of so-far supported features:</p>
<ul dir="auto">
<li>File/Hunk-level stage/unstage</li>
<li>Show (view commits / open EDITOR at line)</li>
<li>Show branches</li>
<li>Branch:
<ul dir="auto">
<li>checkout</li>
</ul>
</li>
<li>Commit:
<ul dir="auto">
<li>commit, amend, fixup</li>
</ul>
</li>
<li>Fetch:
<ul dir="auto">
<li>all</li>
</ul>
</li>
<li>Log:
<ul dir="auto">
<li>current</li>
</ul>
</li>
<li>Pull / Push:
<ul dir="auto">
<li>remote</li>
</ul>
</li>
<li>Rebase:
<ul dir="auto">
<li>abort, continue, autosquash, interactive</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Keybinds</h3><a id="user-content-keybinds" aria-label="Permalink: Keybinds" href="#keybinds"></a></p>
<p dir="auto">A help-menu can be shown by pressing the <code>h</code> key.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/altsem/gitu/blob/master/vhs/help.png"><img src="https://github.com/altsem/gitu/raw/master/vhs/help.png"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using Cargo</h4><a id="user-content-using-cargo" aria-label="Permalink: Using Cargo" href="#using-cargo"></a></p>
<p dir="auto">Run the command (recommended):
<code>cargo install gitu --locked</code></p>
<p dir="auto">...or to install from git, run:
<code>cargo install --git https://github.com/altsem/gitu.git --locked</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">The environment variables <code>GIT_EDITOR</code>, <code>VISUAL</code> or <code>EDITOR</code> (checked in this order) dictate which editor Gitu will open.</p>
<p dir="auto">Configuration is also loaded from <code>~/.config/gitu/config.toml</code>,
you could copy the <a href="https://github.com/altsem/gitu/blob/master/src/default_config.toml">default configuration</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Humanity Is Dangerously Pushing Its Ability to Tolerate Heat (144 pts)]]></title>
            <link>https://www.wired.com/story/extreme-heat-tolerance/</link>
            <guid>39666369</guid>
            <pubDate>Mon, 11 Mar 2024 10:17:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/extreme-heat-tolerance/">https://www.wired.com/story/extreme-heat-tolerance/</a>, See on <a href="https://news.ycombinator.com/item?id=39666369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Humanity’s superpower is sweating—but rising heat could be our kryptonite, and an average temperature rise of 2 degrees Celsius above preindustrial levels could bring regular, fatal heat waves to large parts of the planet, says Tom Matthews, a senior lecturer in environmental geography at King’s College London.</p><p>“We have evolved to cope with the most extreme heat and humidity the planet can throw at us,” he explains. But when our core temperature gets to about 42 degrees Celsius (around 107.5 degrees Fahrenheit), people face heat stroke and probable death as the <a href="https://www.wired.com/story/india-deadly-combination-heat-humidity/">body strains</a> to keep cool and the heart works harder, inducing heart attacks.</p><p>Matthews cites an example from his home country, the UK. In the summer of 2022, the UK broke its high temperature record, surpassing 40 degrees Celsius (104 degrees Fahrenheit). Scientists <a href="https://climate-adapt.eea.europa.eu/en/metadata/publications/heat-related-mortality-in-europe-during-summer-2022">estimate</a> there were roughly 3,500 heat-associated deaths that summer in the UK. Across Europe, they estimate high heat caused more than 60,000 deaths.</p><p>“At 1.5 degrees Celsius of warming, the likes of Lagos, Karachi, [and] Shanghai start to experience heat waves exceeding our limit. At 2 degrees Celsius, the events increase at least 10 times more often, and if we get to 8 degrees Celsius, a large fraction of the Earth’s surface would be too hot for our physiology and would not be habitable,” he says.</p><p>Air conditioning and heat-escape rooms would help, but we might need to abandon intense outdoor work such as rice farming in hotter regions. And these solutions will need to be able to meet demand. “The infrastructure must be able to withstand the surges when everyone turns on the air conditioning, and must be able to withstand hurricanes or floods,” he says.</p><p>Our best hope in the face of inevitable rises in heat? Cooperation. “We’ve built forecasting systems that will warn us when disasters are incoming by working together at enormous scale. We must continue to do the same.”</p><p><em>This article appears in the March/April 2024 issue of WIRED UK magazine.</em></p><p><em>Updated 2-28-2024 11:30 am GMT: This story was updated to correct the estimated excess-death figures associated with the 2022 European heat wave.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[(How to Write a (Lisp) Interpreter (In Python)) (2010) (158 pts)]]></title>
            <link>https://www.norvig.com/lispy.html</link>
            <guid>39665939</guid>
            <pubDate>Mon, 11 Mar 2024 08:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.norvig.com/lispy.html">https://www.norvig.com/lispy.html</a>, See on <a href="https://news.ycombinator.com/item?id=39665939">Hacker News</a></p>
<div id="readability-page-1" class="page">


This page has two purposes: to describe how to implement computer
language interpreters in general, and in particular to build an interpreter
for most of the <a href="http://en.wikipedia.org/wiki/Scheme_(programming_language)"><i>Scheme</i></a>
dialect of Lisp using <a href="http://python.org/">Python 3</a> as the implementation language. 
I call my language and interpreter <i>Lispy</i> (<a href="https://www.norvig.com/lis.py"><b>lis.py</b></a>). Years ago, I showed how to write a semi-practical Scheme interpreter  <a (in="" href="https://www.norvig.com/jscheme.html">Java</a> and in <a href="http://books.google.com/books?id=QzGuHnDhvZIC&amp;lpg=PA756&amp;vq=scheme%20interpreter&amp;dq=Paradigms%20of%20Artificial%20Intelligence%20Programming&amp;pg=PA753#v=onepage&amp;q&amp;f=false">in Common
Lisp</a>).  This time around the goal is to demonstrate, as concisely
and simply as possible, what
<a href="http://queue.acm.org/detail.cfm?id=1039523">Alan Kay called</a> "<a href="http://www.righto.com/2008/07/maxwells-equations-of-software-examined.html"><i>Maxwell's Equations of Software</i></a>."

<p>Why does this  matter? As <a href="http://steve-yegge.blogspot.com/2007/06/rich-programmer-food.html">Steve
  Yegge said</a>, <i>"If you don't know how compilers work, then you
  don't know how computers work."</i> Yegge describes 8 problems that
  can be solved with compilers (or equally well with interpreters, or
   with Yegge's
  typical heavy dosage of cynicism).


</p><h2>Syntax and Semantics of Scheme Programs</h2>

The <i>syntax</i> of a language is the arrangement of characters to form correct statements or expressions; the
<i>semantics</i> is the meaning of those statements or expressions.  For example, in the language of
mathematical expressions (and in many programming languages), the syntax for adding one plus two is "1 +
2" and the semantics is the application of the addition operation to the two numbers, yielding the value 3. We say we
are <i>evaluating</i> an expression when we determine its
value; we would say that "1 + 2" evaluates to 3, and write
that as "1 + 2" ⇒ 3.

<p>Scheme syntax is different from most other programming languages. Consider:


</p><blockquote>
<table><tbody><tr><th>Java</th><th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th><th>Scheme
    </th></tr><tr><td>
</td></tr><tr><td>
<tt><b>if</b> (x.val() &gt; 0) {
<br>&nbsp;&nbsp;<b>return</b> fn(A[i] + 3 * i, 
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>new</b> String[] {"one", "two"});
<br>}
  </tt></td><td>&nbsp;
  </td><td><tt>(<b>if</b> (&gt; (val x) 0)
    <br>&nbsp;&nbsp;&nbsp;&nbsp;(fn (+ (aref A i) (* 3 i)) 
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<b>quote</b> (one two)))
   </tt></td></tr></tbody></table>
</blockquote>

Java has a wide variety
of syntactic conventions (keywords, infix operators, three kinds of brackets,
operator precedence, dot notation, quotes, commas,
semicolons), but Scheme syntax is much simpler: 
<ul>
<li> Scheme programs consist solely of <i>expressions</i>.  There is no statement/expression distinction.
</li><li> Numbers (e.g. <tt>1</tt>) and symbols (e.g. <tt>A</tt>) are called <i>atomic expressions</i>;
they cannot be broken into pieces.  These are similar to their Java counterparts, except that in
Scheme, operators such as <tt>+</tt> and <tt>&gt;</tt> are symbols too, and are treated the same
way as <tt>A</tt> and <tt>fn</tt>.
</li><li> Everything else is a <i>list expression</i>: a "(", followed by zero or more expressions,
followed by a ")".  The first element of the list determines what it means:
<ul>
<li>A list starting with a keyword, e.g. <tt>(if ...)</tt>, is a <i>special form</i>;
the meaning depends on the keyword.
</li><li>A list starting with a non-keyword, e.g. <tt>(fn ...)</tt>, is a function call.
</li></ul>
</li></ul>
The beauty of Scheme is that the full language only needs 5 keywords and 8 syntactic
forms.  In comparison, Python has 33 keywords and <a href="https://docs.python.org/3/reference/grammar.html">110</a>
syntactic forms, 
and Java has 50 keywords and <a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-18.html">133</a> syntactic forms.
All those parentheses
may seem intimidating, but Scheme syntax has the virtues of
simplicity and consistency. (Some have joked that "Lisp" stands for
"<a href="http://www.google.com/search?q=Lots+of+Irritating+Silly+Parentheses"><i><b>L</b>ots
of <b>I</b>rritating <b>S</b>illy <b>P</b>arentheses</i></a>"; I think it stand for
"<a href="http://www.google.com/search?hl=en&amp;as_q=&amp;as_epq=Lisp+Is+Syntactically+Pure"><i><b>L</b>isp
<b>I</b>s <b>S</b>yntactically <b>P</b>ure</i></a>".)  


<p>In this page we will cover all the important points of the Scheme language and its interpretation
(omitting some minor details), but we will take two steps to get there,
defining a simplified language first, before defining the near-full Scheme language. 

</p><h2>Language 1: Lispy Calculator</h2>

<i>Lispy Calculator</i> is a subset of Scheme using only five syntactic forms (two atomic, two special forms, and the procedure call).
Lispy Calculator lets you do any computation you could do on a typical calculator—as long as you are comfortable with prefix notation. 
And you can do two things that are not offered in typical calculator languages: "if" expressions, and the definition of new variables.  
Here's an example program, that computes the area of a circle of radius 10, using the formula π <i>r</i><sup>2</sup>:

<pre>(define r 10)
(* pi (* r r))
</pre>

Here is a table of all the allowable expressions:

<p>
<table>
  <tbody><tr><th>Expression</th><th>Syntax</th><th>Semantics and Example

  </th></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.1">variable reference</a></td><td><i>symbol</i></td><td>A symbol is interpreted as a variable name;
  its value is the variable's
  value. <br>Example: <tt>r</tt> ⇒ <tt>10</tt> (assuming <tt>r</tt> was previously defined to be 10)

    </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.2">constant
  literal</a></td><td><i>number</i></td><td>A number 
  evaluates to itself. <br>Examples: <tt>12 ⇒ 12</tt> <i>or</i>
  <tt>-3.45e+6 ⇒ -3.45e+6</tt>


      </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.5">conditional</a></td><td><tt>(if</tt> <i>test conseq
  alt</i><tt>) </tt></td><td>Evaluate <i>test</i>; if true,
  evaluate and return <i>conseq</i>; otherwise  
  <i>alt</i>. <br>Example: <tt>(if (&gt; 10 20) (+ 1 1) (+ 3 3)) ⇒ 6</tt>
    

    </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-8.html#%_sec_5.2">definition</a>
</td><td><tt>(define</tt> <i>symbol</i> <i>exp</i><tt>)</tt>
</td><td>Define a new variable and give it
  the value of evaluating the expression <i>exp</i>. 
      <br>Examples: <tt>(define r 10)</tt> 
      
</td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.3">procedure
   call</a></td><td><tt>(</tt><i>proc arg...</i><tt>)</tt>	</td><td>If <i>proc</i> is
   anything other than one of the symbols <tt>if,  define,
   </tt> or <tt>quote</tt> then it is treated as a procedure.  Evaluate <i>proc</i>
   and all the <i>args</i>, and then the procedure is applied to the list of <i>arg</i> values. <br>Example: <tt>(sqrt (* 2 8)) ⇒ 4.0</tt>
  
   </td></tr></tbody></table>

   

  </p><p>In the Syntax column of this table, <i>symbol</i> must be a
   symbol,
   <i>number</i> must be an integer or floating point number,
   and the other italicized words can be any
   expression. The notation <i>arg...</i> means zero or more repetitions
   of <i>arg</i>. 
   




</p><h2>What A Language Interpreter Does</h2>

A language interpreter has two parts:
<ol>

  <li> <b>Parsing:</b> The parsing component takes an input program in
the form of a sequence of characters, verifies it according to the
<i>syntactic rules</i> of the language, and translates the program
into an internal representation.  In a simple interpreter the internal
representation is a tree structure (often called an <i>abstract syntax tree</i>) 
that closely mirrors the nested
structure of statements or expressions in the program. In a language
translator called a <i>compiler</i> there is often a series of internal representations,
starting with an abstract syntax tree, and progressing to a
sequence of instructions that can be directly executed by the
computer. The Lispy parser is implemented with the function <tt>parse</tt>.</li><li> <b>Execution:</b> The internal representation is then
  processed according to the <i>semantic rules</i> of the
  language, thereby carrying out the computation. Lispy's execution function is called <tt>eval</tt> (note this shadows
  Python's built-in function of the same name).
  
</li></ol>

Here is a picture of the interpretation process:

<blockquote>program  ➡ <span><tt>parse</tt></span>
➡ abstract-syntax-tree 
➡ <span><tt>eval</tt></span>
➡ result 
</blockquote>

<p>And here is a short example of what we want <tt>parse</tt> and <tt>eval</tt> to be able to do (<tt>begin</tt> evaluates each expression in order and returns the final one):

</p><pre>&gt;&gt; program = "(begin (define r 10) (* pi (* r r)))"

&gt;&gt;&gt; parse(program)
['begin', ['define', 'r', 10], ['*', 'pi', ['*', 'r', 'r']]]

&gt;&gt;&gt; eval(parse(program))
314.1592653589793
</pre>

<h2>Type Definitions</h2>

Let's be explicit about our representations for Scheme objects:

<pre>Symbol = str              # A Scheme Symbol is implemented as a Python str
Number = (int, float)     # A Scheme Number is implemented as a Python int or float
Atom   = (Symbol, Number) # A Scheme Atom is a Symbol or Number
List   = list             # A Scheme List is implemented as a Python list
Exp    = (Atom, List)     # A Scheme expression is an Atom or List
Env    = dict             # A Scheme environment (defined below) 
                          # is a mapping of {variable: value}

</pre>

<h2>Parsing: <tt>parse</tt>, <tt>tokenize</tt> and <tt>read_from_tokens</tt></h2>


Parsing is traditionally separated into two parts: <i>lexical
analysis</i>, in which the input character string is broken up into a
sequence of <i>tokens</i>, and <i>syntactic analysis</i>, in which the
tokens are assembled into an abstract syntax tree.  
The Lispy tokens are parentheses, symbols, and numbers.
There are
many tools for lexical analysis (such as Mike Lesk and Eric Schmidt's
<a href="http://dinosaur.compilertools.net/#lex">lex</a>), but for now we'll
use a very simple tool: Python's <tt>str.split</tt>. The function <tt>tokenize</tt> takes
as input a string of characters; it
adds spaces around each paren, and then calls <tt>str.split</tt> to get a
list of tokens:

<pre>def tokenize(chars: str) -&gt; list:
    "Convert a string of characters into a list of tokens."
    return chars.replace('(', ' ( ').replace(')', ' ) ').split()
</pre>

Here we apply tokenize to our sample program:

<pre>&gt;&gt;&gt; program = "(begin (define r 10) (* pi (* r r)))"
&gt;&gt;&gt; tokenize(program)
['(', 'begin', '(', 'define', 'r', '10', ')', '(', '*', 'pi', '(', '*', 'r', 'r', ')', ')', ')']
</pre>


<p>Our function <tt>parse</tt> will take a string representation of a program as input, call <tt>tokenize</tt>
to get a list of tokens, and then call <tt>read_from_tokens</tt> to assemble an abstract syntax tree.
<tt>read_from_tokens</tt> looks at the first token; if
it is a <tt>')'</tt> that's a syntax error. If it is a <tt>'('</tt>, then we start
building up a list of sub-expressions until we hit a matching <tt>')'</tt>.
Any non-parenthesis token must be a symbol or number. 
We'll let Python make the distinction between them: for each non-paren token,
first try to interpret it as an int, then as a float, and if it is neither
of those, it must be a
symbol. Here is the parser:

</p><pre>def parse(program: str) -&gt; Exp:
    "Read a Scheme expression from a string."
    return read_from_tokens(tokenize(program))

def read_from_tokens(tokens: list) -&gt; Exp:
    "Read an expression from a sequence of tokens."
    if len(tokens) == 0:
        raise SyntaxError('unexpected EOF')
    token = tokens.pop(0)
    if token == '(':
        L = []
        while tokens[0] != ')':
            L.append(read_from_tokens(tokens))
        tokens.pop(0) # pop off ')'
        return L
    elif token == ')':
        raise SyntaxError('unexpected )')
    else:
        return atom(token)

def atom(token: str) -&gt; Atom:
    "Numbers become numbers; every other token is a symbol."
    try: return int(token)
    except ValueError:
        try: return float(token)
        except ValueError:
            return Symbol(token)
</pre>




<tt>parse</tt> works like this:

<pre>&gt;&gt;&gt; program = "(begin (define r 10) (* pi (* r r)))"

&gt;&gt;&gt; parse(program)
['begin', ['define', 'r', 10], ['*', 'pi', ['*', 'r', 'r']]]
</pre>


 
We're almost ready to define <tt>eval</tt>. But we need one more concept first.

<h2>Environments</h2>

An environment is a mapping from variable names to their values.
By default, <tt>eval</tt> will use a global environment that includes the names for a bunch of standard functions (like <tt>sqrt</tt> and <tt>max</tt>,
and also operators like <tt>*</tt>).  This environment can be augmented with user-defined variables,
using the expression <tt>(define <i>symbol value</i>)</tt>.  

<pre>import math
import operator as op

def standard_env() -&gt; Env:
    "An environment with some Scheme standard procedures."
    env = Env()
    env.update(vars(math)) # sin, cos, sqrt, pi, ...
    env.update({
        '+':op.add, '-':op.sub, '*':op.mul, '/':op.truediv, 
        '&gt;':op.gt, '&lt;':op.lt, '&gt;=':op.ge, '&lt;=':op.le, '=':op.eq, 
        'abs':     abs,
        'append':  op.add,  
        'apply':   lambda proc, args: proc(*args),
        'begin':   lambda *x: x[-1],
        'car':     lambda x: x[0],
        'cdr':     lambda x: x[1:], 
        'cons':    lambda x,y: [x] + y,
        'eq?':     op.is_, 
        'expt':    pow,
        'equal?':  op.eq, 
        'length':  len, 
        'list':    lambda *x: List(x), 
        'list?':   lambda x: isinstance(x, List), 
        'map':     map,
        'max':     max,
        'min':     min,
        'not':     op.not_,
        'null?':   lambda x: x == [], 
        'number?': lambda x: isinstance(x, Number),  
		'print':   print,
        'procedure?': callable,
        'round':   round,
        'symbol?': lambda x: isinstance(x, Symbol),
    })
    return env

global_env = standard_env()
</pre>


<h2>Evaluation: <tt>eval</tt></h2>

<p>We are now ready for the implementation of <tt>eval</tt>.
As a refresher, we repeat the table of Lispy Calculator forms:

</p><p>
<table>
  <tbody><tr><th>Expression</th><th>Syntax</th><th>Semantics and Example

  </th></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.1">variable reference</a></td><td><i>symbol</i></td><td>A symbol is interpreted as a variable name;
  its value is the variable's
  value. <br>Example: <tt>r</tt> ⇒ <tt>10</tt> (assuming <tt>r</tt> was previously defined to be 10)

    </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.2">constant
  literal</a></td><td><i>number</i></td><td>A number 
  evaluates to itself. <br>Examples: <tt>12 ⇒ 12</tt> <i>or</i>
  <tt>-3.45e+6 ⇒ -3.45e+6</tt>


      </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.5">conditional</a></td><td><tt>(if</tt> <i>test conseq
  alt</i><tt>) </tt></td><td>Evaluate <i>test</i>; if true,
  evaluate and return <i>conseq</i>; otherwise  
  <i>alt</i>. <br>Example: <tt>(if (&gt; 10 20) (+ 1 1) (+ 3 3)) ⇒ 6</tt>
    

    </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-8.html#%_sec_5.2">definition</a>
</td><td><tt>(define</tt> <i>symbol</i> <i>exp</i><tt>)</tt>
</td><td>Define a new variable and give it
  the value of evaluating the expression <i>exp</i>. 
      <br>Examples: <tt>(define r 10)</tt> 
      
</td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.3">procedure
   call</a></td><td><tt>(</tt><i>proc arg...</i><tt>)</tt>	</td><td>If <i>proc</i> is
   anything other than one of the symbols <tt>if,  define,
   </tt> or <tt>quote</tt> then it is treated as a procedure.  Evaluate <i>proc</i>
   and all the <i>args</i>, and then the procedure is applied to the list of <i>arg</i> values. <br>Example: <tt>(sqrt (* 2 8)) ⇒ 4.0</tt>
  
   </td></tr></tbody></table>

</p><p>Here is the code for <tt>eval</tt>, which closely follows the table:

</p><pre>def eval(x: Exp, env=global_env) -&gt; Exp:
    "Evaluate an expression in an environment."
    if isinstance(x, Symbol):        # variable reference
        return env[x]
    elif isinstance(x, Number):      # constant number
        return x                
    elif x[0] == 'if':               # conditional
        (_, test, conseq, alt) = x
        exp = (conseq if eval(test, env) else alt)
        return eval(exp, env)
    elif x[0] == 'define':           # definition
        (_, symbol, exp) = x
        env[symbol] = eval(exp, env)
    else:                            # procedure call
        proc = eval(x[0], env)
        args = [eval(arg, env) for arg in x[1:]]
        return proc(*args)
</pre>

<p><i>We're done!</i> You can see it all in action:

</p><pre>&gt;&gt;&gt; eval(parse("(begin (define r 10) (* pi (* r r)))"))
314.1592653589793
</pre>

<h2>Interaction: A REPL</h2>

It is tedious to have to enter <tt>eval(parse("..."))</tt> all the time.
One of Lisp's great legacies is the notion of an interactive read-eval-print loop:
a way for a programmer to enter an expression, and see it immediately read, evaluated, and printed, without having to go through a lengthy build/compile/run cycle.  So let's define the function <tt>repl</tt> (which stands for read-eval-print-loop), and the function <tt>schemestr</tt> which returns a string representing a Scheme object.

<pre>def repl(prompt='lis.py&gt; '):
    "A prompt-read-eval-print loop."
    while True:
        val = eval(parse(raw_input(prompt)))
        if val is not None: 
            print(schemestr(val))

def schemestr(exp):
    "Convert a Python object back into a Scheme-readable string."
    if isinstance(exp, List):
        return '(' + ' '.join(map(schemestr, exp)) + ')' 
    else:
        return str(exp)
</pre>

Here is <tt>repl</tt> in action:

<pre>&gt;&gt;&gt; repl()
lis.py&gt; (define r 10)
lis.py&gt; (* pi (* r r))
314.159265359
lis.py&gt; (if (&gt; (* 11 11) 120) (* 7 6) oops)
42
lis.py&gt; (list (+ 1 1) (+ 2 2) (* 2 3) (expt 2 3))
lis.py&gt; 
</pre>

<h2>Language 2: Full Lispy</h2>

We will now extend our language with three new special forms, giving us a much more nearly-complete Scheme subset:

<p><table>
  <tbody><tr><th>Expression</th><th>Syntax</th><th>Semantics and Example

          </th></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.2">quotation</a></td><td><tt>(quote </tt><i>exp</i><tt>)</tt></td><td>
Return the <i>exp</i> literally; do not evaluate it. <br>Example:
	<tt>(quote (+ 1 2)) ⇒ (+ 1 2)</tt> 
    
  </td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.6">assignment</a></td><td><tt>(set!</tt> <i>symbol
  exp</i><tt>)</tt></td><td>Evaluate <i>exp</i> and assign that value to
  <i>symbol</i>, which must have been previously defined (with a
  <tt>define</tt> or as a parameter to an enclosing procedure).
    <br>Example: <tt>(set! r2 (* r r))</tt>


      
</td></tr><tr><td><a href="http://www.schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-7.html#%_sec_4.1.4">procedure</a></td><td><tt>(lambda (</tt><i>symbol...</i><tt>)</tt>
  <i>exp</i><tt>)</tt></td><td>Create a procedure
  with parameter(s) named <i>symbol...</i> and <i>exp</i> as the body. <br>Example: <tt>(lambda (r)
  (* pi (* r r)))</tt>

</td></tr></tbody></table>

</p><p>The <tt>lambda</tt> special form (an obscure nomenclature choice that refers to Alonzo Church's <a href="http://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>) creates a procedure.  
We want procedures to work like this:

</p><pre>lis.py&gt; (define circle-area (lambda (r) (* pi (* r r)))
lis.py&gt; (circle-area (+ 5 5))
314.159265359
</pre>

There are two steps here. In the first step,  the <tt>lambda</tt> expression is evaluated to 
create a procedure, one which refers to the global variables <tt>pi</tt> and <tt>*</tt>, takes a single parameter, which it calls <tt>r</tt>.
This procedure is used as the value of the new variable <tt>circle-area</tt>. In the second step,  
the procedure we just defined is the value of <tt>circle-area</tt>, so it is called, with the value 10 as the argument.
We want <tt>r</tt> to take on the value 10,
but it wouldn't do to just set <tt>r</tt> to 10 in the global environment.  
What if we were using <tt>r</tt> for some other purpose? We wouldn't want a call to <tt>circle-area</tt> to alter that value.  Instead, we want to arrange for there to be a <i>local</i> variable named <tt>r</tt> that we can set to 10 without worrying about interfering with any global variable that happens to have the same name.
The process for calling a procedure introduces these new local variable(s), binding each symbol in the parameter list of. the function 
to the corresponding value in the argument list of the function call.

<h2>Redefining <tt>Env</tt> as a Class</h2>

To handle local variables, we will redefine <tt>Env</tt> to be a subclass of <tt>dict</tt>.
When we evaluate <tt>(circle-area (+ 5 5))</tt>, we will fetch the procedure body, <tt>(* pi (* r r))</tt>,
and evaluate it in an environment that has <tt>r</tt> as the sole local variable (with value 10), but also has the global environment as the "outer" 
environment; it is there that we will find the values of <tt>*</tt> and <tt>pi</tt>.  
In other words, we want an environment that looks like this, with the local (blue) environment nested inside the outer (red) global environment:

<p><div>
<tt>pi: 3.141592653589793
<br>*: &lt;built-in function mul&gt;
<br>...
<br>

</tt></div>

</p><p>When we look up a variable in such a nested environment, we look first at the innermost level, but if
we don't find the variable name there, we move to the next outer level.
Procedures and environments are intertwined, so let's define them together:

</p><pre>class Env(dict):
    "An environment: a dict of {'var': val} pairs, with an outer Env."
    def __init__(self, parms=(), args=(), outer=None):
        self.update(zip(parms, args))
        self.outer = outer
    def find(self, var):
        "Find the innermost Env where var appears."
        return self if (var in self) else self.outer.find(var)

class Procedure(object):
    "A user-defined Scheme procedure."
    def __init__(self, parms, body, env):
        self.parms, self.body, self.env = parms, body, env
    def __call__(self, *args): 
        return eval(self.body, Env(self.parms, args, self.env))

global_env = standard_env()
</pre>

We see that every procedure has three components: a list of parameter names,  a body expression, and an environment
that tells us what other variables are accessible from the body. For a procedure defined at the top level this will be
the global environment, but it is also possible for a procedure to refer to the local variables of the environment
in which it was <i>defined</i> (and not the environment in which it is <i>called</i>). 

<p>An environment is a subclass of <tt>dict</tt>, so it has
all the methods that <tt>dict</tt> has. In addition there are two methods: the constructor
<tt>__init__</tt> builds a new environment by taking a list of parameter names
and a corresponding list of argument values, and creating a new environment that has those
{variable: value} pairs as the inner part, and also refers to the given <tt>outer</tt> environment.
The method <tt>find</tt> is used to find the right environment for
a variable: either the inner one or an outer one. 

</p><p>To see how these all go together, here is the new definition of <tt>eval</tt>. Note that
the clause for variable reference has changed: we now have to call <tt>env.find(x)</tt> to find at what level
the variable <tt>x</tt> exists; then we can fetch the value of <tt>x</tt> from that level. (The clause for
<tt>define</tt> has not changed, because a <tt>define</tt> always adds a new variable
to the innermost environment.)  There are two new clauses: for <tt>set!</tt>, we find the environment level
where the variable exists and set it to a new value.  With <tt>lambda</tt>, we create a new procedure object with the given
parameter list, body, and environment.

</p><pre>def eval(x, env=global_env):
    "Evaluate an expression in an environment."
    if isinstance(x, Symbol):    # variable reference
        return env.find(x)[x]
    elif not isinstance(x, List):# constant 
        return x   
    op, *args = x       
    if op == 'quote':            # quotation
        return args[0]
    elif op == 'if':             # conditional
        (test, conseq, alt) = args
        exp = (conseq if eval(test, env) else alt)
        return eval(exp, env)
    elif op == 'define':         # definition
        (symbol, exp) = args
        env[symbol] = eval(exp, env)
    elif op == 'set!':           # assignment
        (symbol, exp) = args
        env.find(symbol)[symbol] = eval(exp, env)
    elif op == 'lambda':         # procedure
        (parms, body) = args
        return Procedure(parms, body, env)
    else:                        # procedure call
        proc = eval(op, env)
        vals = [eval(arg, env) for arg in args]
        return proc(*vals)
</pre>

<p>To appreciate how procedures and environments work together, consider this program and the environment that gets formed when we evaluate <tt>(account1 -20.00)</tt>:

</p><p><table><tbody><tr><td>
<p>
<div><tt>(define <b>make-account</b>
<div>&nbsp;&nbsp;(lambda (<b>balance</b>)
<p>&nbsp;&nbsp;&nbsp;&nbsp;(lambda (<b>amt</b>)
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(begin <b>(set! balance (+ balance amt))</b> 
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;balance))))
  </p></div>
<br><tt>(define <b>account1</b> (make-account 100.00))
  <br>(account1 -20.00)
</tt></tt></div>

</p></td><td> &nbsp; </td><td>

<div><b><tt>+</tt></b>: &lt;built-in operator add&gt;
<br><tt><b>make-account</b>: &lt;a Procedure&gt;

<br><tt><tt><b>account1</b>: &lt;a Procedure&gt;
</tt></tt></tt></div>

</td></tr></tbody></table>

</p><p>Each rectangular box represents an environment, and the color of
the box matches the color of the variables that are newly defined in
the environment.  In the last two lines of the program we define <tt>account1</tt> and call
<tt>(account1 -20.00)</tt>; this represents the creation of a bank account
with a 100 dollar opening balance, followed by a 20 dollar withdrawal.
In the process of evaluating <tt>(account1 -20.00)</tt>, we will eval the
expression highlighted in yellow.  There are three variables in that
expression.  <tt>amt</tt> can be found immediately in the innermost
(green) environment. But <tt>balance</tt> is not defined there: we
have to look at the green environment's outer <tt>env</tt>, the blue
one. And finally, the variable <tt>+</tt> is not found in either of
those; we need to do one more outer step, to the global (red) environment.
This process of looking first in inner environments and then in
outer ones is called <i>lexical scoping</i>.  
<tt>Env.find(var)</tt> finds the right environment according to
lexical scoping rules.



</p><p>Let's see what we can do now:

</p><pre>&gt;&gt;&gt; repl()
lis.py&gt; (define circle-area (lambda (r) (* pi (* r r))))
lis.py&gt; (circle-area 3)
28.274333877
lis.py&gt; (define fact (lambda (n) (if (&lt;= n 1) 1 (* n (fact (- n 1))))))
lis.py&gt; (fact 10)
3628800
lis.py&gt; (fact 100)
9332621544394415268169923885626670049071596826438162146859296389521759999322991
5608941463976156518286253697920827223758251185210916864000000000000000000000000
lis.py&gt; (circle-area (fact 10))
4.1369087198e+13
lis.py&gt; (define first car)
lis.py&gt; (define rest cdr)
lis.py&gt; (define count (lambda (item L) (if L (+ (equal? item (first L)) (count item (rest L))) 0)))
lis.py&gt; (count 0 (list 0 1 2 3 0 0))
3
lis.py&gt; (count (quote the) (quote (the more the merrier the bigger the better)))
4
lis.py&gt; (define twice (lambda (x) (* 2 x)))
lis.py&gt; (twice 5)
10
lis.py&gt; (define repeat (lambda (f) (lambda (x) (f (f x)))))
lis.py&gt; ((repeat twice) 10)
40
lis.py&gt; ((repeat (repeat twice)) 10)
160
lis.py&gt; ((repeat (repeat (repeat twice))) 10)
2560
lis.py&gt; ((repeat (repeat (repeat (repeat twice)))) 10)
655360
lis.py&gt; (pow 2 16)
65536.0
lis.py&gt; (define fib (lambda (n) (if (&lt; n 2) 1 (+ (fib (- n 1)) (fib (- n 2))))))
lis.py&gt; (define range (lambda (a b) (if (= a b) (quote ()) (cons a (range (+ a 1) b)))))
lis.py&gt; (range 0 10)
(0 1 2 3 4 5 6 7 8 9)
lis.py&gt; (map fib (range 0 10))
(1 1 2 3 5 8 13 21 34 55)
lis.py&gt; (map fib (range 0 20))
(1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 6765)
</pre>

We now have a language with procedures, variables, conditionals (<tt>if</tt>), and sequential execution (the <tt>begin</tt> procedure).  If you are familiar with other languages, you might think that a <tt>while</tt> or <tt>for</tt> loop would be needed, but
Scheme manages to do without these just fine. The Scheme report says "Scheme demonstrates that a very small number of rules for forming expressions, with no restrictions on how they are composed, suffice to form a practical and efficient programming language." In Scheme
you iterate by defining recursive functions.

<h2>How Small/Fast/Complete/Good is Lispy?</h2>

In which we judge Lispy on several criteria:

<ul>
<li><b><i>Small:</i></b> Lispy is <i>very</i> small: 117 non-comment
  non-blank lines; 4K of source code. (An earlier version was just 90 lines, but had fewer standard procedures
and was perhaps a bit too terse.)   The smallest version of
  my Scheme in Java, <a href="http://norvig.com/jscheme.html">Jscheme</a>, was 1664 lines and 57K of source. Jscheme was
  originally called SILK (Scheme in Fifty Kilobytes), but I only kept
  under that limit by counting bytecode rather than source code. Lispy does much
  better; I think it meets Alan Kay's 1972 <a href="http://gagne.homedns.org/~tgagne/contrib/EarlyHistoryST.html">claim</a>
  that <i>you could define the
  "most powerful language in the world" in "a page of code."</i> (However,
  I think Alan would disagree, because he would count the Python compiler as part of the code, putting me <i>well</i> over a page.)

<pre>bash$ grep "^\s*[^#\s]" lis.py | wc
     117     497    4276
</pre></li><li><b><i>Fast:</i></b> Lispy computes <tt>(fact 100)</tt> exactly in 0.003
seconds.  That's fast enough for me (although far slower than most
other ways of computing it). </li><li><b><i>Complete:</i></b> Lispy is not very complete compared to the
Scheme standard.  Some major shortcomings:
<ul>
  <li> <b><i>Syntax</i></b>: Missing comments, quote and quasiquote notation, # literals, the derived
  expression types (such as <tt>cond</tt>, derived from <tt>if</tt>,
  or <tt>let</tt>, derived from <tt>lambda</tt>), and dotted list notation.
</li><li> <b><i>Semantics</i></b>: Missing call/cc and tail recursion.  
</li><li> <b><i>Data Types</i></b>: Missing strings, characters, booleans, ports,
  vectors, exact/inexact numbers.
  Python lists are actually closer to Scheme
  vectors than to the Scheme pairs and lists that we implement with them.
</li><li> <b><i>Procedures</i></b>: Missing over 100 primitive procedures.
  
 </li><li> <b><i>Error recovery</i></b>: Lispy does not attempt to detect,
  reasonably report, or recover from errors.  Lispy expects the
  programmer to be perfect.
</li></ul></li><li><b><i>Good:</i></b> That's up to the readers to decide.  I found it
was good for my purpose of explaining Lisp interpreters.
</li></ul>

<h2>True Story</h2>

To back up the idea that it can be very helpful to know how
interpreters work, here's a story.  Way back in 1984 I was writing a
Ph.D. thesis.  This was before LaTeX, before Microsoft Word for Windows—we used
troff. Unfortunately, troff had no facility for forward references
to symbolic labels: I wanted to be able to write "As we will see on
page @theorem-x" and then write something like "@(set theorem-x \n%)" in
the appropriate place (the troff register \n% holds the page number). My
fellow grad student Tony DeRose felt the same need, and together we
sketched out a simple Lisp program that would handle this as a preprocessor.  However,
it turned out that the Lisp we had at the time was good at reading
Lisp expressions, but so slow at reading character-at-a-time non-Lisp
expressions that our program was annoying to use.  
<p>
From there Tony and I split paths.  He reasoned that the hard part was
the interpreter for expressions; he needed Lisp for that, but he knew
how to write a tiny C routine
for reading and echoing the non-Lisp characters and link it in to the Lisp
program.  I didn't know how to do that linking, but I reasoned that writing an
interpreter for this trivial language (all it had was set variable,
fetch variable, and string concatenate) was easy, so I wrote an
interpreter in C. So, ironically, Tony wrote a Lisp program (with one small routine in C) because he was a
C programmer, and I wrote a C program because I was a Lisp programmer.
</p><p>
In the end, we both got our theses done (<a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/1985/6081.html">Tony</a>, <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/1987/5995.html">Peter</a>).

</p><h2>The Whole Thing</h2>

The whole program is here: <a href="https://www.norvig.com/lis.py">lis.py</a>.

<h2>Further Reading</h2>

   
  
  <p>To learn more about Scheme consult some of the fine books (by
   <a href="http://books.google.com/books?id=xyO-KLexVnMC&amp;lpg=PP1&amp;dq=scheme%20programming%20book&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Friedman
   and Fellesein</a>,
   <a href="http://books.google.com/books?id=wftS4tj4XFMC&amp;lpg=PA300&amp;dq=scheme%20programming%20book&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Dybvig</a>,
   <a href="http://books.google.com/books?id=81mFK8pqh5EC&amp;lpg=PP1&amp;dq=scheme%20programming%20book&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Queinnec</a>,
   <a href="http://www.eecs.berkeley.edu/~bh/ss-toc2.html">Harvey and
   Wright</a> or
   <a href="http://mitpress.mit.edu/sicp/">Sussman and Abelson</a>),
   videos (by <a href="http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/">Abelson
   and Sussman</a>),
   tutorials (by
      <a href="http://www.ccs.neu.edu/home/dorai/t-y-scheme/t-y-scheme.html">Dorai</a>,
   <a href="http://docs.racket-lang.org/quick/index.html">PLT</a>, or
   <a href="http://cs.gettysburg.edu/~tneller/cs341/scheme-intro/index.html">Neller</a>),
   or the
      <a href="http://www.schemers.org/Documents/Standards/R5RS/HTML">reference
   manual</a>.

</p><p>I also have another page describing a <a href="http://norvig.com/lispy2.html">more advanced version of Lispy</a>.


</p><hr>
<i><a href="http://norvig.com/">Peter Norvig</a></i>

<hr> 
 
 
 </div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: RE3 – Reversed Engineered GTA3 Source Code (125 pts)]]></title>
            <link>https://github.com/halpz/re3</link>
            <guid>39665017</guid>
            <pubDate>Mon, 11 Mar 2024 04:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/halpz/re3">https://github.com/halpz/re3</a>, See on <a href="https://news.ycombinator.com/item?id=39665017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/halpz/re3/blob/master/res/images/logo_1024.png?raw=true"><img src="https://github.com/halpz/re3/raw/master/res/images/logo_1024.png?raw=true" alt="re3 logo" width="200"></a></p>
<p dir="auto"><a href="https://actions-badge.atrox.dev/GTAmodding/re3/goto?ref=master" rel="nofollow"><img src="https://camo.githubusercontent.com/1508b6f62669dc0b23cb2a1b91f8aef5dc3b946b611a59dc321682ecfe96dcaa/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e742e7376673f75726c3d6874747073253341253246253246616374696f6e732d62616467652e6174726f782e6465762532464754416d6f6464696e6725324672653325324662616467652533467265662533446d6173746572267374796c653d666c6174" alt="Build Status" data-canonical-src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2FGTAmodding%2Fre3%2Fbadge%3Fref%3Dmaster&amp;style=flat"></a>
<a href="https://discord.gg/RFNbjsUMGg" rel="nofollow"><img src="https://camo.githubusercontent.com/e1d2dd4598108ac98c8d4250d7574a307c1017ef81b319667c53a1de19332324/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d6a6f696e2d3732383944412e7376673f6c6f676f3d646973636f7264266c6f6e6743616368653d74727565267374796c653d666c6174" data-canonical-src="https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;longCache=true&amp;style=flat"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Intro</h2><a id="user-content-intro" aria-label="Permalink: Intro" href="#intro"></a></p>
<p dir="auto">In this repository you'll find the fully reversed source code for GTA III (<a href="https://github.com/halpz/re3/tree/master/">master</a> branch) and GTA VC (<a href="https://github.com/halpz/re3/tree/miami/">miami</a> branch).</p>
<p dir="auto">It has been tested and works on Windows, Linux, MacOS and FreeBSD, on x86, amd64, arm and arm64.<br>
Rendering is handled either by original RenderWare (D3D8)
or the reimplementation <a href="https://github.com/aap/librw">librw</a> (D3D9, OpenGL 2.1 or above, OpenGL ES 2.0 or above).<br>
Audio is done with MSS (using dlls from original GTA) or OpenAL.</p>
<p dir="auto">The project has also been ported to the <a href="https://github.com/AGraber/re3-nx/">Nintendo Switch</a>,
<a href="https://github.com/Rinnegatamante/re3">Playstation Vita</a> and
<a href="https://github.com/GaryOderNichts/re3-wiiu/">Nintendo Wii U</a>.</p>
<p dir="auto">We cannot build for PS2 or Xbox yet. If you're interested in doing so, get in touch with us.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ul dir="auto">
<li>re3 requires PC game assets to work, so you <strong>must</strong> own <a href="https://store.steampowered.com/app/12100/Grand_Theft_Auto_III/" rel="nofollow">a copy of GTA III</a>.</li>
<li>Build re3 or download the latest build:
<ul dir="auto">
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_x86/master/re3_Release_win-x86-librw_d3d9-mss.zip" rel="nofollow">Windows D3D9 MSS 32bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_amd64/master/re3_Release_win-amd64-librw_d3d9-oal.zip" rel="nofollow">Windows D3D9 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_amd64/master/re3_Release_win-amd64-librw_gl3_glfw-oal.zip" rel="nofollow">Windows OpenGL 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/build-cmake-conan/master/ubuntu-18.04-gl3.zip" rel="nofollow">Linux 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/build-cmake-conan/master/macos-latest-gl3.zip" rel="nofollow">MacOS 64bit x86-64</a></li>
</ul>
</li>
<li>Extract the downloaded zip over your GTA 3 directory and run re3. The zip includes the binary, updated and additional gamefiles and in case of OpenAL the required dlls.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107704085-fbdabd00-6cbc-11eb-8406-8951a80ccb16.png"><img src="https://user-images.githubusercontent.com/1521437/107704085-fbdabd00-6cbc-11eb-8406-8951a80ccb16.png" alt="re3 2021-02-11 22-57-03-23"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703339-cbdeea00-6cbb-11eb-8f0b-07daa105d470.png"><img src="https://user-images.githubusercontent.com/1521437/107703339-cbdeea00-6cbb-11eb-8f0b-07daa105d470.png" alt="re3 2021-02-11 22-43-44-98"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703343-cd101700-6cbb-11eb-9ccd-012cb90524b7.png"><img src="https://user-images.githubusercontent.com/1521437/107703343-cd101700-6cbb-11eb-9ccd-012cb90524b7.png" alt="re3 2021-02-11 22-46-33-76"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703348-d00b0780-6cbb-11eb-8afd-054249c2b95e.png"><img src="https://user-images.githubusercontent.com/1521437/107703348-d00b0780-6cbb-11eb-8afd-054249c2b95e.png" alt="re3 2021-02-11 22-50-29-54"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Improvements</h2><a id="user-content-improvements" aria-label="Permalink: Improvements" href="#improvements"></a></p>
<p dir="auto">We have implemented a number of changes and improvements to the original game.
They can be configured in <code>core/config.h</code>.
Some of them can be toggled at runtime, some cannot.</p>
<ul dir="auto">
<li>Fixed a lot of smaller and bigger bugs</li>
<li>User files (saves and settings) stored in GTA root directory</li>
<li>Settings stored in re3.ini file instead of gta3.set</li>
<li>Debug menu to do and change various things (Ctrl-M to open)</li>
<li>Debug camera (Ctrl-B to toggle)</li>
<li>Rotatable camera</li>
<li>XInput controller support (Windows)</li>
<li>No loading screens between islands ("map memory usage" in menu)</li>
<li>Skinned ped support (models from Xbox or Mobile)</li>
<li>Rendering
<ul dir="auto">
<li>Widescreen support (properly scaled HUD, Menu and FOV)</li>
<li>PS2 MatFX (vehicle reflections)</li>
<li>PS2 alpha test (better rendering of transparency)</li>
<li>PS2 particles</li>
<li>Xbox vehicle rendering</li>
<li>Xbox world lightmap rendering (needs Xbox map)</li>
<li>Xbox ped rim light</li>
<li>Xbox screen rain droplets</li>
<li>More customizable colourfilter</li>
</ul>
</li>
<li>Menu
<ul dir="auto">
<li>Map</li>
<li>More options</li>
<li>Controller configuration menu</li>
<li>...</li>
</ul>
</li>
<li>Can load DFFs and TXDs from other platforms, possibly with a performance penalty</li>
<li>...</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">To-Do</h2><a id="user-content-to-do" aria-label="Permalink: To-Do" href="#to-do"></a></p>
<p dir="auto">The following things would be nice to have/do:</p>
<ul dir="auto">
<li>Fix physics for high FPS</li>
<li>Improve performance on lower end devices, especially the OpenGL layer on the Raspberry Pi (if you have experience with this, please get in touch)</li>
<li>Compare code with PS2 code (tedious, no good decompiler)</li>
<li><a href="https://web.archive.org/web/20210217192931/https://github.com/GTAmodding/re3/wiki/PS2-port" rel="nofollow">PS2 port</a></li>
<li>Xbox port (not quite as important)</li>
<li>reverse remaining unused/debug functions</li>
<li>compare CodeWarrior build with original binary for more accurate code (very tedious)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Modding</h2><a id="user-content-modding" aria-label="Permalink: Modding" href="#modding"></a></p>
<p dir="auto">Asset modifications (models, texture, handling, script, ...) should work the same way as with original GTA for the most part.</p>
<p dir="auto">CLEO scripts work with <a href="https://github.com/cleolibrary/CLEO-Redux">CLEO Redux</a>.</p>
<p dir="auto">Mods that make changes to the code (dll/asi, limit adjusters) will <em>not</em> work.
Some things these mods do are already implemented in re3 (much of SkyGFX, GInput, SilentPatch, Widescreen fix),
others can easily be achieved (increasing limis, see <code>config.h</code>),
others will simply have to be rewritten and integrated into the code directly.
Sorry for the inconvenience.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building from Source</h2><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<p dir="auto">When using premake, you may want to point GTA_III_RE_DIR environment variable to GTA3 root folder if you want the executable to be moved there via post-build script.</p>
<p dir="auto">Clone the repository with <code>git clone --recursive https://github.com/halpz/re3.git</code>. Then <code>cd re3</code> into the cloned repository.</p>
<details><summary>Linux Premake</summary>
<p dir="auto">For Linux using premake, proceed: <a href="https://web.archive.org/web/20210217192751/https://github.com/GTAmodding/re3/wiki/Building-on-Linux" rel="nofollow">Building on Linux</a></p>
</details>
<details><summary>Linux Conan</summary>
<p dir="auto">Install python and conan, and then run build.</p>
<div data-snippet-clipboard-copy-content="conan export vendor/librw librw/master@
mkdir build
cd build
conan install .. re3/master@ -if build -o re3:audio=openal -o librw:platform=gl3 -o librw:gl3_gfxlib=glfw --build missing -s re3:build_type=RelWithDebInfo -s librw:build_type=RelWithDebInfo
conan build .. -if build -bf build -pf package"><pre><code>conan export vendor/librw librw/master@
mkdir build
cd build
conan install .. re3/master@ -if build -o re3:audio=openal -o librw:platform=gl3 -o librw:gl3_gfxlib=glfw --build missing -s re3:build_type=RelWithDebInfo -s librw:build_type=RelWithDebInfo
conan build .. -if build -bf build -pf package
</code></pre></div>
</details>
<details><summary>MacOS Premake</summary>
<p dir="auto">For MacOS using premake, proceed: <a href="https://web.archive.org/web/20210717004757/https://github.com/GTAmodding/re3/wiki/Building-on-MacOS" rel="nofollow">Building on MacOS</a></p>
</details>
<details><summary>FreeBSD</summary>
<p dir="auto">For FreeBSD using premake, proceed: <a href="https://web.archive.org/web/20210217192740/https://github.com/GTAmodding/re3/wiki/Building-on-FreeBSD" rel="nofollow">Building on FreeBSD</a></p>
</details>
<details><summary>Windows</summary>
<p dir="auto">Assuming you have Visual Studio 2015/2017/2019:</p>
<ul dir="auto">
<li>Run one of the <code>premake-vsXXXX.cmd</code> variants on root folder.</li>
<li>Open build/re3.sln with Visual Studio and compile the solution.</li>
</ul>
<p dir="auto">Microsoft recently discontinued its downloads of the DX9 SDK. You can download an archived version here: <a href="https://archive.org/details/dxsdk_jun10" rel="nofollow">https://archive.org/details/dxsdk_jun10</a></p>
<p dir="auto"><strong>If you choose OpenAL on Windows</strong> You must read <a href="https://web.archive.org/web/20210217192855/https://github.com/GTAmodding/re3/wiki/Running-OpenAL-build-on-Windows" rel="nofollow">Running OpenAL build on Windows</a>.</p>
</details>
<blockquote>
<p dir="auto">ℹ️ premake has an <code>--with-lto</code> option if you want the project to be compiled with Link Time Optimization.</p>
</blockquote>
<blockquote>
<p dir="auto">ℹ️ There are various settings in <a href="https://github.com/halpz/re3/tree/master/src/core/config.h">config.h</a>, you may want to take a look there.</p>
</blockquote>
<blockquote>
<p dir="auto">ℹ️ re3 uses completely homebrew RenderWare-replacement rendering engine; <a href="https://github.com/aap/librw/">librw</a>. librw comes as submodule of re3, but you also can use LIBRW enviorenment variable to specify path to your own librw.</p>
</blockquote>
<p dir="auto">If you feel the need, you can also use CodeWarrior 7 to compile re3 using the supplied codewarrior/re3.mcp project - this requires the original RW33 libraries, and the DX8 SDK. The build is unstable compared to the MSVC builds though, and is mostly meant to serve as a reference.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">As long as it's not linux/cross-platform skeleton/compatibility layer, all of the code on the repo that's not behind a preprocessor condition(like FIX_BUGS) are <strong>completely</strong> reversed code from original binaries.</p>
<p dir="auto">We <strong>don't</strong> accept custom codes, as long as it's not wrapped via preprocessor conditions, or it's linux/cross-platform skeleton/compatibility layer.</p>
<p dir="auto">We accept only these kinds of PRs;</p>
<ul dir="auto">
<li>A new feature that exists in at least one of the GTAs (if it wasn't in III/VC then it doesn't have to be decompilation)</li>
<li>Game, UI or UX bug fixes (if it's a fix to original code, it should be behind FIX_BUGS)</li>
<li>Platform-specific and/or unused code that's not been reversed yet</li>
<li>Makes reversed code more understandable/accurate, as in "which code would produce this assembly".</li>
<li>A new cross-platform skeleton/compatibility layer, or improvements to them</li>
<li>Translation fixes, for languages original game supported</li>
<li>Code that increase maintainability</li>
</ul>
<p dir="auto">We have a <a href="https://github.com/halpz/re3/blob/master/CODING_STYLE.md">Coding Style</a> document that isn't followed or enforced very well.</p>
<p dir="auto">Do not use features from C++11 or later.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">re3 was started sometime in the spring of 2018,
initially as a way to test reversed collision and physics code
inside the game.
This was done by replacing single functions of the game
with their reversed counterparts using a dll.</p>
<p dir="auto">After a bit of work the project lay dormant for about a year
and was picked up again and pushed to github in May 2019.
At the time I (aap) had reversed around 10k lines of code and estimated
the final game to have around 200-250k.
Others quickly joined the effort (Fire_Head, shfil, erorcun and Nick007J
in time order, and Serge a bit later) and we made very quick progress
throughout the summer of 2019
after which the pace slowed down a bit.</p>
<p dir="auto">Due to everyone staying home during the start of the Corona pandemic
everybody had a lot of time to work on re3 again and
we finally got a standalone exe in April 2020 (around 180k lines by then).</p>
<p dir="auto">After the initial excitement and fixing and polishing the code further,
reVC was started in early May 2020 by starting from re3 code,
not by starting from scratch replacing functions with a dll.
After a few months of mostly steady progress we considered reVC
finished in December.</p>
<p dir="auto">Since then we have started reLCS, which is currently work in progress.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">We don't feel like we're in a position to give this code a license.<br>
The code should only be used for educational, documentation and modding purposes.<br>
We do not encourage piracy or commercial use.<br>
Please keep derivate work open source and give proper credit.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Speech and Language Processing (3rd ed. draft) (167 pts)]]></title>
            <link>https://web.stanford.edu/~jurafsky/slp3/</link>
            <guid>39664782</guid>
            <pubDate>Mon, 11 Mar 2024 03:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a>, See on <a href="https://news.ycombinator.com/item?id=39664782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Speech and Language Processing
<span size="+2">(3rd ed. draft)</span><br>
<span size="+2">
<a href="http://web.stanford.edu/people/jurafsky/">Dan Jurafsky</a> and <a href="http://www.cs.colorado.edu/~martin/">James H. Martin</a>
</span>
</h2>

<h3>
Here's our Feb 3, 2024 release!  We also expect to release Chapter 12 soon in an updated release.

<p>
Individual chapters and updated slides are below;
<a href="https://web.stanford.edu/~jurafsky/slp3/ed3bookfeb3_2024.pdf">here is a single pdf of all the chapters in the Feb 3, 2024 release!</a> <br>

</p><p> <b>Feel free to use the draft chapters and slides in your classes, the resulting feedback we get from you makes the book better!</b><br>
As always, typos and comments very welcome (just email <a href="mailto:slp3edbugs@gmail.com">slp3edbugs@gmail.com</a>
and let us know the date on the draft)!
(Don't bother reporting missing refs due to cross-chapter cross-reference problems  in the indvidual chapter pdfs, those are fixed in the full book draft)<br>
</p></h3><h5>
We've put up a <a href="https://web.stanford.edu/~jurafsky/slp3/thanks.html">list here</a> of the amazing people who have sent so many fantastic suggestions and bug-fixes for improving the book.
We are really grateful to all of you for your help, the book would not be possible without you!
</h5>

<p>
When will the whole book be finished?  Don't ask.  
<br>
</p><p>
If you need last year's Jan 2023 draft chapters, 
they are <a href="https://web.stanford.edu/~jurafsky/slp3/old_jan23/">here</a>;

<table>
<tbody><tr><td>&nbsp;</td></tr>
<tr>
<td></td>
<td><b>Chapter</b></td>
<td><b>Slides </b></td>

<!--<tr><td>&nbsp;</td></tr>-->
</tr><tr><td></td><td><b>Part I: Fundamental Algorithms</b></td></tr>

<tr><td>1:</td><td>Introduction</td>
</tr><tr><td>2:</td><td>
        <a href="https://web.stanford.edu/~jurafsky/slp3/2.pdf">Regular Expressions, Text Normalization, Edit Distance</a></td>
<td>
2: Text Processing
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc_2023.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/2_TextProc_2023.pdf">pdf</a>]<br>
2: Edit Distance
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/2_EditDistance_2023.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/2_EditDistance_2023.pdf">pdf</a>]<br>
</td>
</tr><tr><td>3:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Language Models</a></td>
<td>
3: [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/3_LM_2024.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/3_LM_2024.pdf">pdf</a>]<br>
</td>
</tr><tr><td>4:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/4.pdf"> Naive Bayes, Text Classification,  and Sentiment </a></td>
<td>
4: [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/4_NB_2024.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/4_NB_2024.pdf">pdf</a>]<br>
</td>
</tr><tr><td>5:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/5.pdf"> Logistic Regression</a></td>
<td>
5: [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/5_LR_Apr_7_2021.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/5_LR_Apr_7_2021.pdf">pdf</a>]<br>
</td>
</tr><tr><td>6:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf"> Vector Semantics and Embeddings</a></td>
<td>
    6: [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/vectorsemantics2024.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/vectorsemantics2024.pdf">pdf</a>]
</td>
</tr><tr><td>7:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/7.pdf">Neural Networks and Neural Language Models </a>
        </td><td>
    7: [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/7_NN_Apr_28_2021.pptx">pptx</a>] [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/7_NN_Apr_28_2021.pdf">pdf</a>]
</td>
</tr><tr><td>8:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/8.pdf">Sequence Labeling for Parts of Speech and Named Entities</a></td>
<td>
    8: (Intro only) [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/8_POSNER_intro_May_6_2021.pptx">pptx</a>] [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/8_POSNER_intro_May_6_2021.pdf">pdf</a>]
</td>
</tr><tr><td>9:</td><td> 
        
        <a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf">RNNs and LSTMs</a> </td>
</tr><tr><td>10:</td><td> 
        <a href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">Transformers and Large Language Models</a> </td>
</tr><tr><td>11:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/11.pdf">Fine-tuning and Masked Language Models</a> </td>
</tr><tr><td>12:</td><td> 
        Prompting, In-Context Learning, and Instruct Tuning </td>

</tr><tr><td>&nbsp;</td></tr>
<tr><td></td><td><b>Part II: NLP Applications</b></td></tr>

<tr><td>13:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/13.pdf">Machine Translation</a> </td>
</tr><tr><td>14:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/14.pdf">Question Answering and Information Retrieval</a> </td>
</tr>
<tr><td>15:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/15.pdf">Chatbots and Dialogue Systems</a> </td>
    <td> 
15 [<a href="https://web.stanford.edu/~jurafsky/slp3/slides/24_Dialogue_May_6_2021.pptx">pptx</a>] 
[<a href="https://web.stanford.edu/~jurafsky/slp3/slides/24_Dialogue_May_6_2021.pdf">pdf</a>]
    </td>
</tr>
<tr><td>16:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/16.pdf">Automatic Speech Recognition and Text-to-Speech</a></td>
</tr>

<tr><td>&nbsp;</td></tr>
<tr><td></td><td><b>Part III: Annotating Linguistic Structure</b></td></tr>

<tr><td>17:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/17.pdf">Context-Free Grammars and Constituency Parsing</a></td>
</tr><tr><td>18:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/18.pdf">Dependency Parsing </a></td>
</tr><tr><td>19:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/19.pdf">Information Extraction: Relations, Events, and Time</a></td>
</tr><tr><td>20:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/20.pdf">Semantic Role Labeling and Argument Structure</a></td>
</tr><tr><td>21:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/21.pdf">Lexicons for Sentiment, Affect, and Connotation </a></td>
</tr><tr><td>22:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/22.pdf">Coreference Resolution</a></td>
</tr><tr><td>23:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/23.pdf">Discourse Coherence</a></td>
</tr><tr><td>&nbsp;</td></tr>
<tr><td></td><td><b>Appendix Chapters (will be just on the web)</b></td></tr>
<tr><td>A:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/A.pdf">Hidden Markov Models</a> </td></tr>
<tr><td>B:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/B.pdf">Spelling Correction and the Noisy Channel</a> </td></tr>
<tr><td>C:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/C.pdf">Statistical Constituency Parsing</a> </td>
</tr><tr><td>D:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/D.pdf">Context-Free Grammars</a> </td>
</tr><tr><td>E:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/E.pdf">Combinatory Categorial Grammar</a> </td>
</tr><tr><td>F:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/F.pdf">Logical Representations of Sentence Meaning</a> </td>
</tr><tr><td>G:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/G.pdf">Word Senses and WordNet</a> </td>
</tr><tr><td>H:</td><td> <a href="https://web.stanford.edu/~jurafsky/slp3/H.pdf">Phonetics</a> </td>
<td>
</td></tr></tbody></table>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD announces the Spartan UltraScale+ FPGA family (116 pts)]]></title>
            <link>https://www.cnx-software.com/2024/03/08/amd-announces-the-spartan-ultrascale-fpga-family-for-cost-sensitive-and-io-intensive-applications/</link>
            <guid>39664221</guid>
            <pubDate>Mon, 11 Mar 2024 02:01:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnx-software.com/2024/03/08/amd-announces-the-spartan-ultrascale-fpga-family-for-cost-sensitive-and-io-intensive-applications/">https://www.cnx-software.com/2024/03/08/amd-announces-the-spartan-ultrascale-fpga-family-for-cost-sensitive-and-io-intensive-applications/</a>, See on <a href="https://news.ycombinator.com/item?id=39664221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>The Spartan UltraScale+ FPGA family is the latest inclusion to AMD’s <a href="https://www.xilinx.com/products/silicon-devices/cost-optimized-portfolio.html">Cost-Optimized portfolio</a>, a series of FPGAs designed to balance cost, power, and form factor with affordability. The UltraScale+ FPGA family is designed for cost-sensitive, low-power applications requiring high I/O count and substantial security.</p>
<p><a href="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale.jpg"><picture><source sizes="(max-width: 720px) 100vw, 720px" type="image/webp" data-srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-720x405.jpg.webp 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-300x169.jpg.webp 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-768x432.jpg.webp 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale.jpg.webp 1200w"><img decoding="async" title="amd spartan ultrascale+" src="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-720x405.jpg" alt="amd spartan ultrascale+" width="720" height="405" srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-720x405.jpg 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-300x169.jpg 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-768x432.jpg 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale.jpg 1200w" sizes="(max-width: 720px) 100vw, 720px" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAtAAAAGVAQAAAAD/UftzAAAAAnRSTlMAAHaTzTgAAAA6SURBVHja7cEBDQAAAMKg909tDwcUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADcGo/3AAHiIfPyAAAAAElFTkSuQmCC" data-src="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-720x405.jpg" data-srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-720x405.jpg 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-300x169.jpg 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-768x432.jpg 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale.jpg 1200w"></picture></a></p>
<p>Devices in the Spartan UltraScale+ family offer a high I/O to logic cell ratio for FPGAs built in 28nm and lower process technology (the highest in the industry, according to AMD), consume up to 30% less power than compared to the previous generation, and feature robust security features that outclass the rest of the Cost-Optimized portfolio.</p>
<p>This FPGA family is built on the same UltraScale+ architecture as <a href="https://www.cnx-software.com/2022/11/15/amd-unveils-low-cost-artix-ultrascale-au7p-fpga-and-zynq-ultrascale-zu3t-mpsoc/">previous Artix and Zynq products</a>. They are the first AMD UltraScale+ FPGAs to feature a hardened DDR memory controller and PCIe Gen4 x8 support, “providing both power efficiency and future-ready capabilities for customers.”</p>
<p><a href="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram.jpg"><picture><source sizes="(max-width: 720px) 100vw, 720px" type="image/webp" data-srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-720x566.jpg.webp 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-1200x944.jpg.webp 1200w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-300x236.jpg.webp 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-768x604.jpg.webp 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram.jpg.webp 1280w"><img decoding="async" title="amd spartan ultrascale+ block diagram" src="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-720x566.jpg" alt="amd spartan ultrascale+ block diagram" width="720" height="566" srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-720x566.jpg 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-1200x944.jpg 1200w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-300x236.jpg 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-768x604.jpg 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram.jpg 1280w" sizes="(max-width: 720px) 100vw, 720px" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAtAAAAI2AQAAAABRMYKuAAAAAnRSTlMAAHaTzTgAAABJSURBVHja7cExAQAAAMKg9U9tDQ+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB/A8kyAAHAeDrHAAAAAElFTkSuQmCC" data-src="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-720x566.jpg" data-srcset="https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-720x566.jpg 720w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-1200x944.jpg 1200w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-300x236.jpg 300w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram-768x604.jpg 768w, https://www.cnx-software.com/wp-content/uploads/2024/03/amd-spartan-ultrascale-block-diagram.jpg 1280w"></picture></a></p>
<p>AMD Spartan UltraScale+ specifications:</p>
<ul>
<li aria-level="1">System Logic Cells – Up to 218K</li>
<li aria-level="1">Memory
<ul>
<li aria-level="2">On-Chip Memory: Block RAM for low latency, high throughput, and UltraRAM</li>
<li aria-level="2">External Memory: LPDDR4x and LPDDR5 up to 4266 Mb/s (hard MC), and DDR4 (soft MC) IP up to 2400 Mb/s</li>
</ul>
</li>
<li aria-level="1">I/O
<ul>
<li aria-level="2">I/O Count: 572</li>
<li aria-level="2">Types:
<ul>
<li aria-level="3">High Density I/O (HDIO) up to 3.3V,</li>
<li aria-level="3">High-Performance I/O (HPIO) up to 1.8V,</li>
<li aria-level="3">XP5IO up to 1.5V, supporting 3200 Mb/s MIPI and 1800 Mb/s LVDS</li>
</ul>
</li>
<li aria-level="2">PCIe: Gen4 x8</li>
<li aria-level="2">Transceivers – Up to 8 GTH transceivers supporting up to 16.3 Gb/s</li>
</ul>
</li>
<li aria-level="1">Security – NIST-approved post-quantum cryptography, unique device identification, permanent tamper penalty for device protection, and side-attack protection via DPA countermeasures</li>
</ul>
<p>The Spartan UltraScale+ FPGA series is primarily targeted for embedded vision, healthcare, industrial networking, robotics, and video applications according to <a href="https://ir.amd.com/news-events/press-releases/detail/1186/amd-extends-market-leading-fpga-portfolio-with-amd-spartan">the press release</a>. The high I/O count will enable the FPGAs to interface with a wide range of sensors and coupled with the programmable logic make it possible to control the sensors in real time and with low latency.</p>
<p>On the software end, the Spartan UltraScale+ FPGA family (along with the rest of AMD’s FPGA and adaptive SoCs lineup) is supported by AMD’s Vivado Design Suite and Vitis Unified Software Platform. This allows both hardware and software designers to leverage the “productivity benefits of these tools via a single designer cockpit from design to verification.”</p>
<p>AMD Spartan UltraScale+ samples and evaluation kits are expected to be available for sampling and evaluation in the first half of 2025. Documentation is currently available and tools support starting with the AMD Vivado Suite in Q4 2024. To learn more about the Spartan UltraScale+ FPGA family and what it offers, be sure to visit the <a href="https://www.xilinx.com/products/silicon-devices/fpga/spartan-ultrascale-plus.html">product page.</a></p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img decoding="async" src="https://www.cnx-software.com/wp-content/uploads/2023/12/photo_2022-08-11_21-23-31-e1701859611854.jpg" width="100" height="100" alt="" itemprop="image" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAApYAAAL2AQAAAADTfev9AAAAAnRSTlMAAHaTzTgAAABUSURBVHja7cEBDQAAAMKg909tDwcUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwY+LgAAe5KAhEAAAAASUVORK5CYII=" data-src="https://www.cnx-software.com/wp-content/uploads/2023/12/photo_2022-08-11_21-23-31-e1701859611854.jpg"></p><div><p>Tomisin is a writer specializing in hardware product reviews, comparisons, and explainers. He is very passionate about small form factor and single-board computers.</p></div></div>			<!-- JLA - Donations -->
		<p><strong>Support CNX Software! Donate via <a href="https://www.cnx-software.com/donate-cryptocurrencies/" rel="nofollow noopener">cryptocurrencies</a>, <a href="https://www.patreon.com/cnxsoft" target="_blank" rel="nofollow noopener">become a Patron</a> on Patreon, or purchase goods on <a href="https://amzn.to/3SXubZ0" rel="nofollow">Amazon</a> or <a href="https://s.click.aliexpress.com/e/_DmGIIRT" rel="nofollow">Aliexpress</a></strong></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jupiter's ocean moon Europa, thought to be habitable, may be oxygen-starved (103 pts)]]></title>
            <link>https://www.nytimes.com/2024/03/04/science/europa-moon-oxygen.html</link>
            <guid>39663708</guid>
            <pubDate>Mon, 11 Mar 2024 00:37:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/03/04/science/europa-moon-oxygen.html">https://www.nytimes.com/2024/03/04/science/europa-moon-oxygen.html</a>, See on <a href="https://news.ycombinator.com/item?id=39663708">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/03/04/science/europa-moon-oxygen.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[eBPF Documentary (199 pts)]]></title>
            <link>https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html</link>
            <guid>39663135</guid>
            <pubDate>Sun, 10 Mar 2024 22:45:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html">https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html</a>, See on <a href="https://news.ycombinator.com/item?id=39663135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>eBPF is a crazy technology – like putting JavaScript into the Linux kernel –  and getting it accepted had so far been an untold story of strategy and ingenuity. The eBPF documentary, published late last year, tells this story by interviewing key players from 2014 including myself, and touches on new developments including Windows. (If you are new to eBPF, it is the name of a kernel execution engine that runs a variety of new programs in a performant and safe sandbox in the kernel, like how JavaScript can run programs safely in a browser sandbox; it is also no longer an acronym.) The documentary was played at KubeCon, and is on <a href="https://www.youtube.com/watch?v=Wb_vD3XZYOA">youtube</a>:</p>

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/Wb_vD3XZYOA?si=-i0HID5ek4hPcEOD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></center>

<p>Watching this brings me right back to 2014, to see the faces and hear their voices discussing the problems we were trying to fix. Thanks to Speakeasy Productions for doing such a great job with this <a href="https://ebpfdocumentary.com/">documentary</a>, and letting you experience what it was like in those early days. This is also a great example of all the work that goes on behind the scenes to get code merged in a large codebase like Linux.</p>

<p>When Alexei Starovoitov visited Netflix in 2014 to discuss eBPF with myself and Amer Ather, we were so entranced that we lost track of time and were eventually kicked out of the meeting room as another meeting was starting. It was then I realized that we had missed lunch! Alexei sounded so confident that I was convinced that eBPF was the future, but a couple of times he added "if the patches get merged." <em>If</em> they get merged?? They <em>have</em> to get merged, this idea is too good to waste.</p>

<p>While only several of us worked on eBPF in 2014, more joined in 2015 and later, and there are now hundreds contributing to make it what it is. A longer documentary could also interview Brendan Blanco (bcc), Yonghong Song (bcc), Sasha Goldshtein (bcc), Alastair Robertson (bpftrace), Tobais Waldekranz (ply), Andrii Nakryiko, Joe Stringer, Jakub Kicinski, Martin KaFai Lau, John Fastabend, Quentin Monnet, Jesper Dangaard Brouer, Andrey Ignatov, Stanislav Fomichev, Teng Qin, Paul Chaignon, Vicent Marti, Dan Xu, Bas Smit, Viktor Malik, Mary Marchini, and many more. Thanks to everyone for all the work.</p>

<p>Ten years later it still feels like it's early days for eBPF, and a great time to get involved: It's likely already available in your production kernels, and there are tools, libraries, and documentation to help you get started.</p>

<p>I hope you enjoy the documentary. PS. Congrats to Isovalent, the role-model eBPF startup, as Cisco recently announced they would acquire them!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lead in gasoline blunted IQ of half the U.S. population, study says (160 pts)]]></title>
            <link>https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028</link>
            <guid>39662988</guid>
            <pubDate>Sun, 10 Mar 2024 22:21:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028">https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028</a>, See on <a href="https://news.ycombinator.com/item?id=39662988">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Exposure to leaded gasoline lowered the IQ of about half the population of the United States, a new study estimates.</p><p>The peer-reviewed study, published Monday in the journal Proceedings of the National Academy of Sciences, focuses on people born before 1996 — the year the U.S. banned gas containing lead.</p><p>Overall, the researchers from Florida State University and Duke University found, childhood lead exposure cost America an estimated 824 million points, or 2.6 points per person on average.&nbsp;</p><p>Certain cohorts were more affected than others. For people born in the 1960s and the 1970s, when leaded gas consumption was skyrocketing, the IQ loss was estimated to be up to 6 points and for some, more than 7 points. Exposure to it came primarily from inhaling auto exhaust.&nbsp;</p><p>The team behind the study used gas consumption data, population estimates and other data to calculate that as of 2015, more than 170 million Americans had had blood lead levels above 5 micrograms per deciliter in their early childhood years.&nbsp;</p><p>Lead is a neurotoxin, and no amount of it is safe. Currently, 3.5 micrograms per deciliter is the reference value for blood lead levels to be considered <a href="https://www.cdc.gov/nceh/lead/prevention/blood-lead-levels.htm">high</a>; the acceptable amount was once higher.&nbsp;</p><p>Principal study author Michael McFarland, an associate professor of sociology at Florida State University and a faculty member of the university’s Center for Demography and Population Health, called the number of people affected by lead exposure “staggering.”</p><p>“This is important because we often think about lead as an issue for children, and of course it is,” he said. “But what we really wanted to know is what happens to those children who were exposed?”</p><p>In many cases, McFarland said, a 2 to 3 point IQ difference is nominal, unless an individual is on the lower side of IQ distribution.</p><p>“If you’re more toward cognitive impairment, a couple points can mean a lot,” he said.</p><p>But on a population basis, shifting the average IQ down even a small amount could have large consequences, said Sung Kyun Park, an associate professor of epidemiology and environmental health sciences at the University of Michigan School of Public Health. The entire bell curve shifts, he explained, with more of the population at what was once the extreme low end of IQ scores.</p><p>Lead used to be added to gasoline to help engines run more smoothly until other, safer additives replaced it. In addition to being linked to lower IQs, it has also been associated with heart and <a href="https://www.kidney.org/atoz/content/lead-exposure-and-kidney-function#:~:text=Most%20lead%2Drelated%20kidney%20disease,is%20stored%20in%20the%20bones.">kidney disease</a>.</p><p>Lead can be inhaled or ingested, with children particularly susceptible to its poisonous effects. Children’s blood lead levels have been dramatically lowered in the U.S. in recent decades, but lead exposure still happens, and Black children are <a href="https://pubmed.ncbi.nlm.nih.gov/33394180/#:~:text=Conclusion%3A%20Although%20lead%20exposure%20in,gap%20was%20lesser%20but%20persisted.">exposed</a> more often than white children. Monday’s study, too, estimated that most Black adults under age 45 experienced “considerably higher” levels of blood lead levels in early life than their white counterparts.&nbsp;</p><p>The racial disparities are generally due to environmental contamination and infrastructure issues that affect drinking water in low-income and minority neighborhoods, with the water crisis in <a href="https://www.nbcnews.com/news/us-news/former-michigan-gov-rick-snyder-charged-flint-water-crisis-n1253966">Flint, Michigan</a>, one of the most egregious examples in recent years.</p><p>And while children are the most vulnerable to getting very ill from lead, the toxin’s damage can show up years later, Park said. Lead exposure is believed to put people at risk for chronic and age-related diseases, including <a href="https://www.health.harvard.edu/heart-health/lead-and-heart-disease-an-underappreciated-link#:~:text=Lead%20is%20widespread%20in%20our,of%20death%20from%20cardiovascular%20disease.">cardiovascular disease</a> and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6454899/">dementia</a>.</p><p>“Lead is a never-ending story,” he said.</p><p>There are medical interventions available for children who have recently been exposed to high amounts of lead, but those wouldn’t work for adults born before 1996. Still, the study findings should not be a major cause for concern, McFarland said.</p><p>“There are a host of things that go into IQ,” he said. “This is one that is obviously negative, but if you also have a nurturing home environment, that helped your IQ.”</p></div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><a href="https://www.nbcnews.com/author/elizabeth-chuck-ncpn341"><picture data-testid="picture"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_avif,q_auto:eco,dpr_2/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg" alt="" height="48" width="48"></picture></a></div><p><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/elizabeth-chuck-ncpn341">Elizabeth Chuck</a></span><span><a href="https://twitter.com/echuckles" target="_blank" rel="noopener noreferrer"><span></span></a><a href="https://facebook.com/elizabethNBCNews" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:elizabeth.chuck@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Elizabeth Chuck is a reporter for NBC News who focuses on health and mental health, particularly issues that affect women and children.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LocalSend: Open-source, cross-platform file sharing to nearby devices (376 pts)]]></title>
            <link>https://localsend.org</link>
            <guid>39662721</guid>
            <pubDate>Sun, 10 Mar 2024 21:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://localsend.org">https://localsend.org</a>, See on <a href="https://news.ycombinator.com/item?id=39662721">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Monte-Carlo graph search from first principles (360 pts)]]></title>
            <link>https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md</link>
            <guid>39662698</guid>
            <pubDate>Sun, 10 Mar 2024 21:33:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md">https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md</a>, See on <a href="https://news.ycombinator.com/item?id=39662698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:lightvector/KataGo" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="4sC8eYwjJZKZC1jMY2uFl4G0SB2rifYRS2EgIQnbVOVdTJ-9jHX_y81EzsUV76h92PBMaa8kVbuV5kGiZAYmQA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="lightvector/KataGo" data-current-org="" data-current-owner="lightvector" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=YKKSoNf86W26OSW3UUk3JFIvOJLtEhFnUGJtM5gYLcojbyXI3KPnZYxdE0MyU1YMZrzUDil2Zn6ypflHb4EeCyRhB99KlGOtNyXTQzk3LtkIwtHTaKwTPm%2BpjVEa7LX5Kh41Chls%2BsCbozUqIdKVjFcZWeDoRnQXLH%2FK15ih8SDdP1HG1x8TJp2p%2FvggRLRdHhhgaBlMPVusAX%2Ft7F0ef3zbl01VBBH1rJSlqps2g0KYn81toXRoIWse8eCnU0SwkZd8Yid%2BMrhOsEUDvzbT%2BhZMYVDk6JbjKoeKLWaHkkrFkT4sKZYJGftfoX44Pz2%2Fl6%2BvQ8boc34h1jvcjJryvQAAovIzjqG%2FyPMLdtPUTiujmIVieGuC1yrmW6E%2FIJ%2FLXCoiZbOnQ0ALt930KEATBo7HEHf9xclD%2FrCHTQMS4BZl7W6Hu6cjxQB0lrGntVktM79JZDZ1kl7eQRMf56hkddJFolRordxplf5c2G1FSJmYGkw8XDU9Cf%2BFHeJx0jwWsDudSSHCWs189p%2BSXs2jWiUkiiT3Uq0rfhD62RIKRWGn47e6ATucLyXYeNr4KCTRUrW9%2FnsrhVvDFQ%3D%3D--8WGaA2CStCTiRxIl--FXQcENf%2FcoX3waqXkwr38Q%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=lightvector%2FKataGo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="8b5625a74963b57aa934f82a2391c14828191e75196c792262ef707d0b4039c3" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Best Essay (298 pts)]]></title>
            <link>https://paulgraham.com/best.html</link>
            <guid>39662615</guid>
            <pubDate>Sun, 10 Mar 2024 21:20:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/best.html">https://paulgraham.com/best.html</a>, See on <a href="https://news.ycombinator.com/item?id=39662615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/the-best-essay-1.gif" width="121" height="18" alt="The Best Essay"><span size="2" face="verdana">March 2024<p>Despite its title this isn't meant to be the best essay. My goal
here is to figure out what the best essay would be like.</p><p>It would be well-written, but you can write well about any topic.
What made it special would be what it was about.</p><p>Obviously some topics would be better than others. It probably
wouldn't be about this year's lipstick colors. But it wouldn't be
vaporous talk about elevated themes either. A good essay has to be
surprising. It has to tell people something they don't already know.</p><p>The best essay would be on the most important topic you could tell
people something surprising about.</p><p>That may sound obvious, but it has some unexpected consequences.
One is that science enters the picture like an elephant stepping
into a rowboat. For example, Darwin first described the idea of
natural selection in an essay written in 1844.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span>
Talk about an
important topic you could tell people something surprising about.
If that's the test of a great essay, this was surely the best one
written in 1844. And indeed, the best possible essay at any given
time would usually be one describing the most important scientific
or technological discovery it was possible to make.
<span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Another unexpected consequence: I imagined when I started writing
this that the best essay would be fairly timeless — that the best
essay you could write in 1844 would be much the same as the best
one you could write now. But in fact the opposite seems to be true.
It might be true that the best painting would be timeless in this
sense. But it wouldn't be impressive to write an essay introducing
natural selection now. The best essay <i>now</i> would be one describing
a great discovery we didn't yet know about.</p><p>If the question of how to write the best possible essay reduces to
the question of how to make great discoveries, then I started with
the wrong question. Perhaps what this exercise shows is that we
shouldn't waste our time writing essays but instead focus on making
discoveries in some specific domain. But I'm interested in essays
and what can be done with them, so I want to see if there's some
other question I could have asked.</p><p>There is, and on the face of it, it seems almost identical to the
one I started with. Instead of asking <i>what would the best essay
be?</i> I should have asked <i>how do you write essays well?</i> Though
these seem only phrasing apart, their answers diverge. The answer
to the first question, as we've seen, isn't really about essay
writing. The second question forces it to be.</p><p>Writing essays, at its best, is a way of discovering ideas. How do
you do that well? How do you discover by writing?</p><p>An essay should ordinarily start with what I'm going to call a
question, though I mean this in a very general sense: it doesn't
have to be a question grammatically, just something that acts like
one in the sense that it spurs some response.</p><p>How do you get this initial question? It probably won't work to
choose some important-sounding topic at random and go at it.
Professional traders won't even trade unless they have what they
call an <i>edge</i> — a convincing story about why in some class of
trades they'll win more than they lose. Similarly, you shouldn't
attack a topic unless you have a way in — some new insight about
it or way of approaching it.</p><p>You don't need to have a complete thesis; you just need some kind
of gap you can explore. In fact, merely having questions about
something other people take for granted can be edge enough.</p><p>If you come across a question that's sufficiently puzzling, it could
be worth exploring even if it doesn't seem very momentous. Many an
important discovery has been made by pulling on a thread that seemed
insignificant at first. How can they <i>all</i> be finches? 
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>Once you've got a question, then what? You start thinking out loud
about it. Not literally out loud, but you commit to a specific
string of words in response, as you would if you were talking. This
initial response is usually mistaken or incomplete. Writing converts
your ideas from vague to bad. But that's a step forward, because
once you can see the brokenness, you can fix it.</p><p>Perhaps beginning writers are alarmed at the thought of starting
with something mistaken or incomplete, but you shouldn't be, because
this is why essay writing works. Forcing yourself to commit to some
specific string of words gives you a starting point, and if it's
wrong, you'll see that when you reread it. At least half of essay
writing is rereading what you've written and asking <i>is this correct
and complete?</i> You have to be very strict when rereading, not just
because you want to keep yourself honest, but because a gap between
your response and the truth is often a sign of new ideas to be
discovered.</p><p>The prize for being strict with what you've written is not just
refinement. When you take a roughly correct answer and try to make
it exactly right, sometimes you find that you can't, and that the
reason is that you were depending on a false assumption. And when
you discard it, the answer turns out to be completely different.
</p><span color="#dddddd">[<a href="#f4n"><span color="#dddddd">4</span></a>]</span><p>Ideally the response to a question is two things: the first step
in a process that converges on the truth, and a source of additional
questions (in my very general sense of the word). So the process
continues recursively, as response spurs response. 
</p><span color="#dddddd">[<a href="#f5n"><span color="#dddddd">5</span></a>]</span><p>Usually there are several possible responses to a question, which
means you're traversing a tree. But essays are linear, not tree-shaped,
which means you have to choose one branch to follow at each point.
How do you choose? Usually you should follow whichever offers the
greatest combination of generality and novelty. I don't consciously
rank branches this way; I just follow whichever seems most exciting;
but generality and novelty are what make a branch exciting. 
</p><span color="#dddddd">[<a href="#f6n"><span color="#dddddd">6</span></a>]</span><p>If you're willing to do a lot of rewriting, you don't have to guess
right. You can follow a branch and see how it turns out, and if it
isn't good enough, cut it and backtrack. I do this all the time.
In this essay I've already cut a 17-paragraph subtree, in addition
to countless shorter ones. Maybe I'll reattach it at the end, or
boil it down to a footnote, or spin it off as its own essay; we'll
see. 
</p><span color="#dddddd">[<a href="#f7n"><span color="#dddddd">7</span></a>]</span><p>In general you want to be quick to cut. One of the most dangerous
temptations in writing (and in software and painting) is to keep
something that isn't right just because it contains a few good bits
or cost you a lot of effort.</p><p>The most surprising new question being thrown off at this point is
<i>does it really matter what the initial question is?</i> If the space
of ideas is highly connected, it shouldn't, because you should be
able to get from any question to the most valuable ones in a few
hops. And we see evidence that it's highly connected in the way,
for example, that people who are obsessed with some topic can turn
any conversation toward it. But that only works if you know where
you want to go, and you don't in an essay. That's the whole point.
You don't want to be the obsessive conversationalist, or all your
essays will be about the same thing. 
</p><span color="#dddddd">[<a href="#f8n"><span color="#dddddd">8</span></a>]</span><p>The other reason the initial question matters is that you usually
feel somewhat obliged to stick to it. I don't think about this when
I decide which branch to follow. I just follow novelty and generality.
Sticking to the question is enforced later, when I notice I've
wandered too far and have to backtrack. 
</p><span color="#dddddd">[<a href="#f9n"><span color="#dddddd">9</span></a>]</span>
But I think this is
the optimal solution. You don't want the hunt for novelty and
generality to be constrained in the moment. Go with it and see what
you get.<p>Since the initial question does constrain you, in the best case it
sets an upper bound on the quality of essay you'll write. If you
do as well as you possibly can on the chain of thoughts that follow
from the initial question, the initial question itself is the only
place where there's room for variation.</p><p>It would be a mistake to let this make you too conservative though,
because you can't predict where a question will lead. Not if you're
doing things right, because doing things right means making
discoveries, and by definition you can't predict those. So the way
to respond to this situation is not to be cautious about which
initial question you choose, but to write a lot of essays. Essays
are for taking risks.</p><p>Almost any question can get you a good essay. Indeed, it took some
effort to think of a sufficiently unpromising topic in the third
paragraph, because any essayist's first impulse on hearing that the
best essay couldn't be about x would be to try to write it. But if
most questions yield good essays, only some yield great ones.</p><p>Can we predict which questions will yield great essays? Considering
how long I've been writing essays, it's alarming how novel that
question feels.</p><p>One thing I like in an initial question is outrageousness. I love
questions that seem naughty in some way — for example, by seeming
counterintuitive or overambitious or heterodox. Ideally all three.
This essay is an example. Writing about the best essay implies there
is such a thing, which pseudo-intellectuals will dismiss as reductive,
though it follows necessarily from the possibility of one essay
being better than another. And thinking about how to do something
so ambitious is close enough to doing it that it holds your attention.</p><p>I like to start an essay with a gleam in my eye. This could be just
a taste of mine, but there's one aspect of it that probably isn't:
to write a really good essay on some topic, you have to be interested
in it. A good writer can write well about anything, but to stretch
for the novel insights that are the raison d'etre of the essay, you
have to care.</p><p>If caring about it is one of the criteria for a good initial question,
then the optimal question varies from person to person. It also
means you're more likely to write great essays if you care about a
lot of different things. The more curious you are, the greater the
probable overlap between the set of things you're curious about and
the set of topics that yield great essays.</p><p>What other qualities would a great initial question have? It's
probably good if it has implications in a lot of different areas.
And I find it's a good sign if it's one that people think has already
been thoroughly explored. But the truth is that I've barely thought
about how to choose initial questions, because I rarely do it. I
rarely <i>choose</i> what to write about; I just start thinking about
something, and sometimes it turns into an essay.</p><p>Am I going to stop writing essays about whatever I happen to be
thinking about and instead start working my way through some
systematically generated list of topics? That doesn't sound like
much fun. And yet I want to write good essays, and if the initial
question matters, I should care about it.</p><p>Perhaps the answer is to go one step earlier: to write about whatever
pops into your head, but try to ensure that what pops into your
head is good. Indeed, now that I think about it, this has to be the
answer, because a mere list of topics wouldn't be any use if you
didn't have edge with any of them. To start writing an essay, you
need a topic plus some initial insight about it, and you can't
generate those systematically. If only. 
</p><span color="#dddddd">[<a href="#f10n"><span color="#dddddd">10</span></a>]</span><p>You can probably cause yourself to have more of them, though. The
quality of the ideas that come out of your head depend on what goes
in, and you can improve that in two dimensions, breadth and depth.</p><p>You can't learn everything, so getting breadth implies learning
about topics that are very different from one another. When I tell
people about my book-buying trips to Hay and they ask what I buy
books about, I usually feel a bit sheepish answering, because the
topics seem like a laundry list of unrelated subjects. But perhaps
that's actually optimal in this business.</p><p>You can also get ideas by talking to people, by doing and building
things, and by going places and seeing things. I don't think it's
important to talk to new people so much as the sort of people who
make you have new ideas. I get more new ideas after talking for an
afternoon with Robert Morris than from talking to 20 new smart
people. I know because that's what a block of office hours at Y
Combinator consists of.</p><p>While breadth comes from reading and talking and seeing, depth comes
from doing. The way to really learn about some domain is to have
to solve problems in it. Though this could take the form of writing,
I suspect that to be a good essayist you also have to do, or have
done, some other kind of work. That may not be true for most other
fields, but essay writing is different. You could spend half your
time working on something else and be net ahead, so long as it was
hard.</p><p>I'm not proposing that as a recipe so much as an encouragement to
those already doing it. If you've spent all your life so far working
on other things, you're already halfway there. Though of course to
be good at writing you have to like it, and if you like writing
you'd probably have spent at least some time doing it.</p><p>Everything I've said about initial questions applies also to the
questions you encounter in writing the essay. They're the same
thing; every subtree of an essay is usually a shorter essay, just
as every subtree of a Calder mobile is a smaller mobile. So any
technique that gets you good initial questions also gets you good
whole essays.</p><p>At some point the cycle of question and response reaches what feels
like a natural end. Which is a little suspicious; shouldn't every
answer suggest more questions? I think what happens is that you
start to feel sated. Once you've covered enough interesting ground,
you start to lose your appetite for new questions. Which is just
as well, because the reader is probably feeling sated too. And it's
not lazy to stop asking questions, because you could instead be
asking the initial question of a new essay.</p><p>That's the ultimate source of drag on the connectedness of ideas:
the discoveries you make along the way. If you discover enough
starting from question A, you'll never make it to question B. Though
if you keep writing essays you'll gradually fix this problem by
burning off such discoveries. So bizarrely enough, writing lots of
essays makes it as if the space of ideas were more highly connected.</p><p>When a subtree comes to an end, you can do one of two things. You
can either stop, or pull the Cubist trick of laying separate subtrees
end to end by returning to a question you skipped earlier. Usually
it requires some sleight of hand to make the essay flow continuously
at this point, but not this time. This time I actually need an
example of the phenomenon. For example, we discovered earlier that
the best possible essay wouldn't usually be timeless in the way the
best painting would. This seems surprising enough to be
worth investigating further.</p><p>There are two senses in which an essay can be timeless: to be about
a matter of permanent importance, and always to have the same effect
on readers. With art these two senses blend together. Art that
looked beautiful to the ancient Greeks still looks beautiful to us.
But with essays the two senses diverge, because essays
teach, and you can't teach people something they already know.
Natural selection is certainly a matter of permanent importance,
but an essay explaining it couldn't have the same effect on us that
it would have had on Darwin's contemporaries, precisely because his
ideas were so successful that everyone already knows about them.
</p><span color="#dddddd">[<a href="#f11n"><span color="#dddddd">11</span></a>]</span><p>I imagined when I started writing this that the best possible essay
would be timeless in the stricter, evergreen sense: that it would
contain some deep, timeless wisdom that would appeal equally to
Aristotle and Feynman. That doesn't seem to be true. But if the
best possible essay wouldn't usually be timeless in this stricter
sense, what would it take to write essays that were?</p><p>The answer to that turns out to be very strange: to be the evergreen
kind of timeless, an essay has to be ineffective, in the sense that
its discoveries aren't assimilated into our shared culture. Otherwise
there will be nothing new in it for the second generation of readers.
If you want to surprise readers not just now but in the future as
well, you have to write essays that won't stick — essays that,
no matter how good they are, won't become part of what people in
the future learn before they read them. 
</p><span color="#dddddd">[<a href="#f12n"><span color="#dddddd">12</span></a>]</span><p>I can imagine several ways to do that. One would be to write about
things people never learn. For example, it's a long-established
pattern for ambitious people to chase after various types of prizes,
and only later, perhaps too late, to realize that some of them
weren't worth as much as they thought. If you write about that, you
can be confident of a conveyor belt of future readers to be surprised
by it.</p><p>Ditto if you write about the tendency of the inexperienced to overdo
things — of young engineers to produce overcomplicated solutions,
for example. There are some kinds of mistakes people never learn
to avoid except by making them. Any of those should be a timeless
topic.</p><p>Sometimes when we're slow to grasp things it's not just because
we're obtuse or in denial but because we've been deliberately lied
to. There are a lot of things adults </p><a href="https://paulgraham.com/lies.html"><u>lie</u></a> 
to kids about, and when
you reach adulthood, they don't take you aside and hand you a list
of them. They don't remember which lies they told you, and most
were implicit anyway. So contradicting such lies will be a source
of surprises for as long as adults keep telling them.<p>Sometimes it's systems that lie to you. For example, the educational
systems in most countries train you to win by 
</p><a href="https://paulgraham.com/lesson.html"><u>hacking the test</u></a>. But
that's not how you win at the most important real-world tests, and
after decades of training, this is hard for new arrivals in the real
world to grasp. Helping them overcome such institutional lies will
work as long as the institutions remain broken. 
<span color="#dddddd">[<a href="#f13n"><span color="#dddddd">13</span></a>]</span><p>Another recipe for timelessness is to write about things readers
already know, but in much more detail than can be transmitted
culturally. "Everyone knows," for example, that it can be rewarding
to have </p><a href="https://paulgraham.com/kids.html"><u>kids</u></a>. But till you have them you don't know precisely what
forms that takes, and even then much of what you know you may never
have put into words.<p>I've written about all these kinds of topics. But I didn't do it
in a deliberate attempt to write essays that were timeless in the
stricter sense. And indeed, the fact that this depends on one's ideas
not sticking suggests that it's not worth making a deliberate attempt
to. You should write about topics of timeless importance, yes, but
if you do such a good job that your conclusions stick and future
generations find your essay obvious instead of novel, so much the
better. You've crossed into Darwin territory.</p><p>Writing about topics of timeless importance is an instance of
something even more general, though: breadth of applicability. And
there are more kinds of breadth than chronological — applying to
lots of different fields, for example. So breadth is the ultimate
aim.</p><p>I already aim for it. Breadth and novelty are the two things I'm
always chasing. But I'm glad I understand where timelessness fits.</p><p>I understand better where a lot of things fit now. This essay has
been a kind of tour of essay writing. I started out hoping to get
advice about topics; if you assume good writing, the only thing
left to differentiate the best essay is its topic. And I did get
advice about topics: discover natural selection. Yeah, that would
be nice. But when you step back and ask what's the best you can do
short of making some great discovery like that, the answer turns
out to be about procedure. Ultimately the quality of an essay is a
function of the ideas discovered in it, and the way you get them
is by casting a wide net for questions and then being very exacting
with the answers.</p><p>The most striking feature of this map of essay writing are the
alternating stripes of inspiration and effort required. The questions
depend on inspiration, but the answers can be got by sheer persistence.
You don't have to get an answer right the first time, but there's
no excuse for not getting it right eventually, because you can keep
rewriting till you do. And this is not just a theoretical possibility.
It's a pretty accurate description of the way I work. I'm rewriting
as we speak.</p><p>But although I wish I could say that writing great essays depends mostly
on effort, in the limit case it's inspiration that makes the
difference. In the limit case, the questions are the harder thing
to get. That pool has no bottom.</p><p>How to get more questions? That is the most important question of
all.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
Darwin wouldn't have chosen to publish his ideas this way.
His 1844 essay, like the 1839 version that preceded it, was written more to work out
his ideas than to communicate them. But Lyell and Hooker's hands were 
forced by Alfred Wallace's independent
discovery of natural selection before Darwin had published anything.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
There might be some resistance to this conclusion on the
grounds that some of these discoveries could only be understood by
a small number of readers. But you get into all sorts of difficulties
if you want to disqualify essays on this account. How do you decide
where the cutoff should be? If a virus kills off everyone except a 
handful of people sequestered at Los Alamos,
could an essay that had been disqualified now be eligible? Etc.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
When you find yourself very curious about an apparently minor
question, that's an exciting sign. Evolution has designed you to
pay attention to things that matter. So when you're very curious
about something random, that could mean you've unconsciously noticed
it's less random than it seems.<p>[</p><a name="f4n"><span color="#000000">4</span></a>]
Corollary: If you're not intellectually honest, your writing
won't just be biased, but also boring, because you'll miss all the
ideas you'd have discovered if you pushed for the truth.<p>[</p><a name="f5n"><span color="#000000">5</span></a>]
Sometimes this process begins before you start writing.
Sometimes you've already figured out the first few things you want
to say. Schoolchildren are often taught they should decide <i>everything</i>
they want to say, and write this down as an outline before they
start writing the essay itself. Maybe that's a good way to get them
started — or not, I don't know — but it's antithetical to the
spirit of essay writing. The more detailed your outline, the less
your ideas can benefit from the sort of discovery that essays are for.<p>[</p><a name="f6n"><span color="#000000">6</span></a>]
The problem with this type of "greedy" algorithm is that you
can end up on a local maximum. If the most valuable question is
preceded by a boring one, you'll overlook it. But I can't imagine
a better strategy. There's no lookahead except by writing. So use
a greedy algorithm and a lot of time.<p>[</p><a name="f7n"><span color="#000000">7</span></a>]
I ended up reattaching the first 5 of the 17 paragraphs, and
discarding the rest.<p>[</p><a name="f8n"><span color="#000000">8</span></a>]
Stephen Fry confessed to making use of this phenomenon when
taking exams at Oxford. He had in his head a standard essay about
some general literary topic, and he would find a way to turn the
exam question toward it and then just reproduce it again.<p>Strictly speaking it's the graph of ideas that would be highly
connected, not the space, but that usage would confuse people who
don't know graph theory, whereas people who do know it will get
what I mean if I say "space".</p><p>[</p><a name="f9n"><span color="#000000">9</span></a>]
Too far doesn't depend just on the distance from the original
topic. It's more like that distance divided by the value of whatever
I've discovered in the subtree.<p>[</p><a name="f10n"><span color="#000000">10</span></a>]
Or can you? I should try writing about this. Even if the
chance of succeeding is small, the expected value is huge.<p>[</p><a name="f11n"><span color="#000000">11</span></a>]
There was a vogue in the 20th century for saying that the
purpose of art was also to teach. Some artists tried to justify
their work by explaining that their goal was not to produce something
good, but to challenge our preconceptions about art. And to be fair,
art can teach somewhat. The ancient Greeks' naturalistic sculptures
represented a new idea, and must have been extra exciting to
contemporaries on that account. But they still look good to us.<p>[</p><a name="f12n"><span color="#000000">12</span></a>]
Bertrand Russell caused huge controversy in the early 20th
century with his ideas about "trial marriage." But they make boring
reading now, because they prevailed. "Trial marriage" is what we
call "dating."<p>[</p><a name="f13n"><span color="#000000">13</span></a>]
If you'd asked me 10 years ago, I'd have predicted that schools
would continue to teach hacking the test for centuries. But now it
seems plausible that students will soon be taught individually by
AIs, and that exams will be replaced by ongoing, invisible
micro-assessments.<span color="888888"><b>Thanks</b> to Sam Altman, Trevor Blackwell, 
Jessica Livingston, Robert
Morris, Courtenay Pipkin, and Harj Taggar for reading drafts of
this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Guide to Software Engineering Contracting in UK (127 pts)]]></title>
            <link>https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk</link>
            <guid>39662506</guid>
            <pubDate>Sun, 10 Mar 2024 21:02:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk">https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk</a>, See on <a href="https://news.ycombinator.com/item?id=39662506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This is my guide to contracting in the UK. Its based on my experiences, and to be honest yours might be different. But maybe this guide will help someone who is thinking of going contracting, and it might help you understand the pros/cons and what to know about it before you begin.</p>
<h3 id="what-is-contracting-and-what-is-involved">What is contracting, and what is involved?</h3>
<p>Contracting is where you work for a company, without being a permanent employee.</p>
<p>This means you get no benefits (like holiday pay), should expect no training, are expected to 'hit the ground running' and should know your tech stack pretty well. And the main benefit for this: much higher pay.</p>
<p>Someone earning £70-80k could easily get a contract paying £400-500 a day. Even on the low end of £400, £400 * 22 days worked a month = £8k/mo = £96k a year. Plus, you end up paying less tax due to the different structure.</p>
<p>Most contractors will work for a company for something like 6 weeks to 6 months. Then you set LinkedIn to 'looking for work', speak to agency recruiters, and you tell them your date rate. They'll match you up with potential roles.</p>
<p>The interview process for contract roles is really straightforward. They'll do some basic checks, but if it takes more than an hour or two you can sometimes even just refuse, and they'll accommodate that.</p>
<p>If you turn up and are rubbish, your contract will be terminated really quick. And if there are layoffs, contractors would (sometimes) already be well gone already.</p>
<p>During first COVID waves (and first lockdowns) the UK software engineer contract market completely dried up. There were almost no contracts going around (definitely not many published publicly or on LinkedIn).</p>
<p><strong>Note: none of this is legal or tax advice. This is just based on my experience, and is entirely my own opinion on how the UK contract market works. Before thinking of going contracting, please do further research. Speak to other contractors, speak to recruiters and get a feel for the contract market near you</strong></p>
<p><strong>Most of this guide also assumes you are set up as a limited company, and contracting within that</strong> but the guide is also relevant if you are contracting via an umbrella company or sole trader.</p>
<h3 id="proscons-of-contracting-in-uk">Pros/cons of contracting in UK</h3>
<h4 id="pros-of-contracting-in-uk">Pros of contracting in UK</h4>
<ul>
<li>You are your own boss (but you have clients who you have to keep happy),</li>
<li>you can select your own work hours. The contract might say something like you have to do 40hrs work a week or 8hrs a day, you can choose when they are.</li>
<li>You will not be on-call</li>
<li>You will not have to attend company off-sites (in fact you probably legally won't be able to)</li>
<li>You can have as much holiday as you want (but you only get paid for days you work)</li>
<li>For some contracts, you can work weekends (<em>at your choice</em>) which is great if you need to earn more money</li>
<li>It is easy to get a contract and start work within a day or two. I've never found it hard to find a new contract immediately. You normally know when you will be moving to a new role, so you normally have at least a few weeks.</li>
<li>You are always seeing new companies, new tech, new tech stacks, and the job never gets boring</li>
<li>More exposure to different ways of working and different frameworks</li>
<li>No performance reviews, no feedback cycles</li>
</ul>
<h4 id="cons-of-contracting-in-uk">Cons of contracting in UK</h4>
<ul>
<li>A lot of people say job security, however I do not believe this. It is so easy to find new contracts, and even perm employees are layed off.</li>
<li>the paperwork, legal and tax side is not fun. Tip: pay an accountant to do everything</li>
<li>no sick pay. You don't work, you don't get paid.</li>
<li>No benefits. No insurance, no gym, etc. But you earn a lot more so its not a huge deal, except for the pension contribution.</li>
<li>more complex to get mortgages</li>
</ul>
<h3 id="job-security-as-a-contractor">Job security as a contractor</h3>
<p>A lot of permanent employees think their jobs are much more secure than contractors. I very much disagree. Contractors can get a new role almost immediately (the only time this hasn't been true was during COVID first lockdown)</p>
<p>I think there is a bit more stress when interviewing all the time, but after a while it becomes quite easy. Landing the next role can be as easy as calling up a few recruiters and seeing what roles they have right now.</p>
<h3 id="taxetc">Tax/etc</h3>
<p><strong>I am not an accountant. Please consult with an accountant to understand the tax implications. This is just a very high level overview of tax in UK when contracting</strong></p>
<h4 id="ir35-and-other-tax-issues">IR35 and other tax issues</h4>
<ul>
<li>If you have your own ltd company, IR35 is a very important tax law that all contractors should be aware of. I don't want to give bad advice here, and I would recommend that every contractor fully understands the IR35 laws, so please Google it and read up. This cannot be skipped, and if you do not know about IR35 recruiters and hiring managers will not take you seriously.</li>
</ul>
<h4 id="is-it-worth-getting-an-accountant-when-contracting">Is it worth getting an accountant when contracting?</h4>
<ul>
<li>100% yes!</li>
<li>Get an accountant/bookkeeper to deal with all your tax things. Don't go with one of the cheap online ones, go to a proper accountant and pay them to handle everything.</li>
</ul>
<h4 id="expenses-and-tax-deductible-things">Expenses and tax deductible things</h4>
<ul>
<li>Most business expenses are tax deductible.</li>
<li>Food is not! despite what many contractors will like to tell you.</li>
<li>Laptops, monitors, travel (in most cases when contracting) are all expenses</li>
<li>If you register for VAT, you may be able to set up for flat rate VAT. This means you can't really claim back any VAT (as a contractor you probably won't have many purchases) unless its over £2k. But you can charge VAT (at 20%) but you send HMRC a smaller %. The details of this, in my opinion, are best left for an accountant to explain to you. But basically you can make another couple of % (especially in the first year, where you get an extra 1%).</li>
</ul>
<h4 id="getting-a-mortgage-as-a-contractor">Getting a mortgage as a contractor</h4>
<ul>
<li>Getting a mortgage is only slightly harder as a contractor. There are specialist  mortgage advisors who can find providers that give a mortage to contractors and self employed.</li>
</ul>
<h4 id="limited-companies-umbrella-companies-sole-trader">Limited companies, umbrella companies, sole trader</h4>
<ul>
<li><strong>Limited companies</strong> are what most contractors are. Some companies will only work with contractors who have a ltd company.  If you have this then the contracts are between the business you're contracting at, and your ltd company. If you are earning a decent day rate and are busy most months, then it is probably better in terms of tax to be set up as a limited company. It also means you can substitute yourself with someone else (just like if you hired a plumbing company, they can send who they want as long as they are qualified)</li>
<li><strong>Umbrella companies</strong> will be set up by agencies. They charge for this, and you make less due to worse tax structure. I cannot see why people do it, except it is easier</li>
<li>You can also do <strong>contracting as a sole trader</strong>, although you will be more limited with what companies will work with you. I did it as a sole trader for quite a while, until my accountant told me how I would be much better off with a ltd company.</li>
</ul>
<h4 id="business-bank-accounts">Business bank accounts</h4>
<p>Getting a business bank account is easy.</p>
<p>One of the most commonly used ones that I've seen other contractors set up is with tide (<a target="_blank" rel="noopener noreferrer" href="http://www.tide.co/">www.tide.co</a>). Do your research and see what is the best available one for you.</p>
<p>Most business bank accounts have a cost (you can probably get them for £10/mo). I think the reason tide are popular is because they charge no monthly fee (and very minimal fees for doing things like certain withdrawals).</p>
<p>You will need your business bank set up before you can accept payments from companies. Do not accept bank transfers to your personal current bank account.</p>
<p>If you are setting up a ltd company: You will be unable to set up a business bank account until you have your company set up, and have the documentation to prove it.</p>

<p><strong>Get insurance when contracting</strong>.</p>
<p>As well as it covering you in case something goes wrong (or you get sued), some companies won't work with you if you don't have insurance. It is quite quick to get insurance, and you can use price comparision sites for business insurance.</p>
<p>There are a few types, including <em>public liability insurance</em>, <em>professional indemnity insurance</em>, <em>employers' liability insurance</em> (important if you employ others in your business)</p>
<h3 id="day-rates-as-a-contractor">Day rates as a contractor</h3>
<p>In the UK everything contractors do are based on day rates. Contractors are often quite happy to share what sort of day rates they're getting with other contractors.</p>
<p>In my experience there is only a slight correlation between how good someone is at software engineering and the day rate they are getting.</p>
<h4 id="uk-london-software-engineer-contract-day-rates">UK London software engineer contract day rates</h4>
<ul>
<li>London software engineering day rates are around £400-500 (outside IR35)</li>
</ul>
<h4 id="uk-non-london-software-engineer-contract-day-rates">UK (non London) software engineer contract day rates</h4>
<ul>
<li>Outside of UK they can be lower, £300-400</li>
<li>Sometimes they can be the same as London rates.</li>
<li>Many are remote, so the location doesn't matter as much as it did a few years ago</li>
</ul>
<h4 id="how-to-calculate-contractor-day-rate-from-a-perm-salary">How to calculate contractor day rate, from a perm salary</h4>
<p>This is a funny subject, as there is no easy comparison. A perm employee is going to have benefits, sick pay, holiday. But I think from experience £70k = £400, £80 = £500, £90+ = £600+. Maybe this isn't too accurate, and might be on the low end of perm employee salary ranges.</p>
<h3 id="skills-and-attributes-as-a-contractor">Skills and attributes as a contractor</h3>
<p>Contractors are not always very skilled! I've worked with highly paid contractors who knew only the basics of how to code. But generally great engineers can command a higher price and after working with a recruiter, the recruiters will hear only positive feedback and will be keen to place you again in another role.</p>
<p>I've always specalised in certain languages and frameworks. Knowing them really well has always meant I could just present myself as an expert in whatever tech the role was for. (I'd only apply for those roles).</p>
<p>For SaaS and other typical tech startups, as well as knowing your programming language &amp; frameworks, I'd suggest you know these really well:</p>
<ul>
<li>git</li>
<li>experience with something like jira</li>
<li>(if for a FE role) experience with something like Figma or Sketch</li>
</ul>
<p>No one will be around to show you how to use git if you are a contractor and turn up without knowing how to use it.</p>
<h4 id="how-skilled-do-you-have-to-be-to-be-a-contractor">How skilled do you have to be to be a contractor?</h4>
<p>It helps to be very skilled, but really I think anyone with more than a few years of working in a perm role could land contract jobs. Most contract jobs are quite simple. They want you to quickly turn out a new feature or build something. Often its from scratch, which is nice. Sometimes its not from scratch, but you can pick and choose what contracts you work with.</p>
<h4 id="what-sorts-of-teams-will-you-be-working-with-as-a-contractor">What sorts of teams will you be working with as a contractor?</h4>
<p>A wide mix! It could be almost just you by yourself, or working with a typical cross functional squad. You won't have a manager (you might have someone to report to - but they won't be your manager)</p>
<p>You may be expected to turn up and get set up almost immediately. Unlike a perm job, there will probably be very mimimal onboarding, and if you do have to do onboarding you will not do the same as normal permanent new starters.</p>
<h3 id="getting-contractor-roles">Getting contractor roles</h3>
<p>In the UK the best way I've found to get contract roles is to simply speak to recruiters. The best place to find them is on LinkedIn. Set yourself to 'open to work', add some experiences, and contact recruiters who are posting contracts. The best way to find them is to search for things like "London JS per day" or "London JS contract" or "London JS outside ir35", and you'll find a bunch of recruiters posting their roles.</p>
<p>I read online before I started contracting like this that it is super competitive, you have to phone them the second you see them put an ad up. I never experienced this. There is enough work and there are enough roles posted that you can ignore all that. I have a feeling that recruiters might spread these lies in order to get you to only work with them.</p>
<h4 id="what-companies-are-looking-for-when-hiring-contractors">What companies are looking for when hiring contractors</h4>
<p>I've worked mostly with startups, but orgs of all sizes hire contractors (including FAANG).</p>
<h4 id="interviewing-for-contract-roles">Interviewing for contract roles</h4>
<p>Interviews are generally quite simple. There might be some simple tech test (if it takes long, you can sometimes refuse and just say you don't have time - some companies will still continue the interview process with you.)</p>
<p>There will probably not be a full behaviour type interviews, or them seeing how well you will fit in culturally.</p>
<p>If there are behaviour/culture interviews, then they will not see you as a contractor - they see you as someone they can try and turn into a perm employee. This is good - but they'll expect you to take part in everything normal employees take part in.</p>
<h4 id="speaking-to-recruiters">Speaking to recruiters</h4>
<ul>
<li>Know your date rate. If you don't know, do some research and pick a number. Don't go low.</li>
<li>Get a ltd company set up, it makes it easier and you can start working ASAP</li>
<li>Get insurance. Its not too expensive, some companeis will require it</li>
<li>Tell recruiters what rate you're looking for, what your expertise or specality is (maybe this is just what languages you have been using)</li>
</ul>
<h4 id="negotiations">Negotiations</h4>
<ul>
<li>If you go via a recruiter, they will tell you a rate (e.g. £500) but they charge the company much more (e.g. £600+). If the company <em>really</em> wants to work with you, and you have other roles you're considering you can negociate. The agency will get a smaller cut, but they are competing against other agencies and would prefer a smaller cut than no cut at all.</li>
<li>Know market rate. If you don't know market rate, just say your rate is market rate.</li>
<li>Negociations will be with the agency.</li>
<li>If you go direct: they save quite a bit by not paying recruitment agency fees. You may be able to demand a higher day rate.</li>
</ul>
<h4 id="how-to-find-work">How to find work</h4>
<ul>
<li>LinkedIn! I know other contractors find work in other ways, but linkedin has really good success rate</li>
</ul>
<h4 id="writing-a-cv-as-a-contractor">Writing a CV as a contractor</h4>
<ul>
<li>1 or 2 pages max</li>
<li>You can just put short summaries, and write what tech you used.</li>
<li>recruiters don't care about your personal bio. They care about what tech you know.</li>
<li>create a version of your cv for each role you apply to. Highlight/make bold the tech stack that you know &amp; is used for that role</li>
</ul>
<h4 id="going-from-perm-to-contract">Going from perm to contract</h4>
<ul>
<li>Legally it is questionable if you go from perm at a company to contracting at the company - especially if you do it under your own ltd company. I would not advise it. Go contract at another company.</li>
</ul>
<h4 id="going-from-contractor-to-perm">Going from contractor to perm</h4>
<ul>
<li>Its common to be offered a perm role. Companies sometimes see contractors as a part of recruiting long term perm employees.</li>
<li>The salary will be rubbish compared to your day rate, but they'll try to convince you that the benefits are worth it</li>
</ul>
<h4 id="does-educationuniversity-matter-for-getting-contractor-roles-in-uk">Does education/university matter for getting contractor roles in UK?</h4>
<p>I have never been asked about qualifications or university. I don't think it matters for software engineering contractors.</p>
<p>When hiring contractors it is a <em>little</em> like hiring a plumber. They just assume you know how to do the job and your experience are your credentials.</p>
<h4 id="going-direct-vs-finding-work-via-an-agency">Going direct vs finding work via an agency</h4>
<p>Going direct can be harder, as you have to approach CTOs (small startups) or hiring managers. But it can pay off, as a lot of companies are always hiring software engineers and often need contractors to fill up capacity.</p>
<h3 id="general-tips">General tips</h3>
<ul>
<li>Avoid having to find new contracts in late December or January - get it sorted and planning in advance. In my experience the contract market dies down a little in these months.</li>
<li>Before starting contracting, have at least some amount of savings that you can rely on if you had to have some time off between contracts (or if you get ill)</li>
<li>Always charge for day rates. Don't bother doing hourly charging.</li>
<li>Keep up to date with the ever changing IR35 laws.</li>
</ul>
<h3 id="further-resources-on-contracting-in-the-uk">Further resources on contracting in the UK</h3>
<ul>
<li>ITJobsWatch - I've never found a role through it, but it is popular: <a target="_blank" rel="noopener noreferrer" href="https://www.itjobswatch.co.uk/contract.aspx">https://www.itjobswatch.co.uk/contract.aspx</a></li>
<li>Contractor Calculator <a target="_blank" rel="noopener noreferrer" href="https://www.contractorcalculator.co.uk/">https://www.contractorcalculator.co.uk/</a></li>
</ul></div></div>]]></description>
        </item>
    </channel>
</rss>