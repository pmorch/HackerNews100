<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 28 Sep 2024 15:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Meta fined $102M for storing passwords in plain text (145 pts)]]></title>
            <link>https://www.engadget.com/big-tech/meta-fined-102-million-for-storing-passwords-in-plain-text-110049679.html</link>
            <guid>41678840</guid>
            <pubDate>Sat, 28 Sep 2024 08:38:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/big-tech/meta-fined-102-million-for-storing-passwords-in-plain-text-110049679.html">https://www.engadget.com/big-tech/meta-fined-102-million-for-storing-passwords-in-plain-text-110049679.html</a>, See on <a href="https://news.ycombinator.com/item?id=41678840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Irish Data Protection Commission (DPC) has slapped Meta with a $101.5 million (‚Ç¨91 million) fine after wrapping up an investigation into a security breach in 2019, wherein the company mistakenly <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/2019-03-21-facebook-user-passwords-plain-text.html" data-ylk="slk:stored users' passwords in plain text;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">stored users' passwords in plain text</a>. Meta's original announcement only talked about how it found some user passwords stored in plain text on its servers in January that year. But a month later, it updated its announcement to reveal that <a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/2019-04-18-facebook-stored-instagram-passwords-plain-text.html" data-ylk="slk:millions of Instagram passwords;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">millions of Instagram passwords</a> were also stored in easily readable format.</p><p>While Meta didn't say how many accounts were affected, a senior employee told <a data-i13n="cpos:3;pos:1" href="https://krebsonsecurity.com/2019/03/facebook-stored-hundreds-of-millions-of-user-passwords-in-plain-text-for-years/" rel="nofollow noopener" target="_blank" data-ylk="slk:Krebs on Security;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas"><em>Krebs on Security </em></a>back then that the incident involved up to 600 million passwords. Some of the passwords had been stored in easily readable format in the company's servers since 2012. They were also reportedly searchable by over 20,000 Facebook employees, though the DPC has clarified in its decision that they were at least not made available to external parties.</p><p>The DPC found that Meta violated several GDPR rules related to the breach. It determined that the company failed to "notify the DPC of a personal data breach concerning storage of user passwords in plaintext" without undue delay and failed to "document personal data breaches concerning the storage of user passwords in plaintext." It also said that Meta violated the GDPR by not using appropriate technical measures to ensure the security of users' passwords against unauthorized processing.</p><p>"It is widely accepted that user passwords should not be stored in plaintext, considering the risks of abuse that arise from persons accessing such data. It must be borne in mind, that the passwords the subject of consideration in this case, are particularly sensitive, as they would enable access to users‚Äô social media accounts," DPC's Deputy Commissioner, Graham Doyle, said in a statement.</p><p>The DPC has also given the company a reprimand in addition to the penalty. We may know more about what that means for Meta exactly when the commission publishes its full final decision and other related information in the future.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFT-based ocean-wave rendering, implemented in Godot (390 pts)]]></title>
            <link>https://github.com/2Retr0/GodotOceanWaves</link>
            <guid>41678412</guid>
            <pubDate>Sat, 28 Sep 2024 06:51:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/2Retr0/GodotOceanWaves">https://github.com/2Retr0/GodotOceanWaves</a>, See on <a href="https://news.ycombinator.com/item?id=41678412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">GodotOceanWaves</h2><a id="user-content-godotoceanwaves" aria-label="Permalink: GodotOceanWaves" href="#godotoceanwaves"></a></p>
<p dir="auto">An open ocean rendering experiment in the Godot Engine utilizing the inverse Fourier transform of directional ocean-wave spectra for wave generation. A concise set of parameters is exposed, allowing for scriptable, real-time modification of wave properties to emulate a wide-variety of ocean-wave environments.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description ocean_demo.mp4">ocean_demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/18603664/371443621-a8083878-a297-4536-a481-9123cea7e7df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNzE0NDM2MjEtYTgwODM4NzgtYTI5Ny00NTM2LWE0ODEtOTEyM2NlYTdlN2RmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg1NGI4ODAzMjU0NmQ0YzdjYTg3YTZkYmYxNmUzZmIxOTY5MTE4ODhjN2VmMGEwNTllMjMyYWJhMTMxNGE2MjQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.woLyampML5KaxatdZL9Tg1Grfm2FiX_wXjz8ysQSLBA" data-canonical-src="https://private-user-images.githubusercontent.com/18603664/371443621-a8083878-a297-4536-a481-9123cea7e7df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNzE0NDM2MjEtYTgwODM4NzgtYTI5Ny00NTM2LWE0ODEtOTEyM2NlYTdlN2RmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg1NGI4ODAzMjU0NmQ0YzdjYTg3YTZkYmYxNmUzZmIxOTY5MTE4ODhjN2VmMGEwNTllMjMyYWJhMTMxNGE2MjQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.woLyampML5KaxatdZL9Tg1Grfm2FiX_wXjz8ysQSLBA" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why Fourier Transforms?</h3><a id="user-content-why-fourier-transforms" aria-label="Permalink: Why Fourier Transforms?" href="#why-fourier-transforms"></a></p>
<p dir="auto">A common approach for animating water in video games is by displacing vertices using <em>Gerstner waves</em>. While Gerstner waves work well for modeling the lower-frequency details in calmer waters, they fall short in accurately representing the choppy surfaces in an open ocean. To simulate the latter, a more complex approach simulates waves using the <em>inverse Fourier transform</em> of ocean-wave spectra modeled from empirical data gathered by oceanographers.</p>
<p dir="auto">A benefit of working in frequency space using ocean-wave spectra is the ease of modifying ocean properties (e.g., surface choppiness). When using Gerstner waves, it is unclear how waves (and their parameters) need to be changed to emulate a certain ocean state. In contrast, ocean-wave spectra expose parameters that change waves' properties directly.</p>
<p dir="auto">To compute the Fourier transform, a <em>fast Fourier transform</em> algorithm (FFT) is used specifically. On top of having a lower computational complexity than the classical discrete Fourier transform algorithm (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$O(N \log N)$</math-renderer> versus <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$O(N^2)$</math-renderer>), the FFT is <em>scalable as a parallel system</em>. This means that it is perfect for running on the GPU. Using Gerstner waves requires each thread to perform <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$N$</math-renderer> computations, one for each wave. In contrast, FFT-based waves only require each thread to perform <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\log(N)$</math-renderer> equivalent computations. At scale, more waves can be added to the system (at the same performance cost), permitting more accurate surface simulation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Results</h2><a id="user-content-results" aria-label="Permalink: Results" href="#results"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wave Shading</h3><a id="user-content-wave-shading" aria-label="Permalink: Wave Shading" href="#wave-shading"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Lighting Model</h4><a id="user-content-lighting-model" aria-label="Permalink: Lighting Model" href="#lighting-model"></a></p>
<p dir="auto">The ocean lighting model largely follows the BSDF described in the 'Atlas' GDC talk. One deviation, however, is the use of the GGX distribution (rather than Beckmann distribution) for the microfacet distribution. This was due to the GGX distribution's 'flatter' and softer highlights providing a more uniform appearance in many of the ocean-wave environments tested.</p>
<p dir="auto">The normal/foam map is sampled with a mix between bicubic and bilinear filtering depending on the world-space pixel density (a value dependent on the normal map texture resolution and texture UV tiling size). This effectively reduces texture aliasing artifacts at lower surface resolutions while maintaining the detail at higher surface resolutions.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Sea Foam</h4><a id="user-content-sea-foam" aria-label="Permalink: Sea Foam" href="#sea-foam"></a></p>
<p dir="auto">Tessendorf notes a method for determining when to generate sea foam by checking where the waves' peaks curl into themselves (i.e., when the Jacobian of the displacement is negative). Foam accumulates linearly and dissipates exponentially on a texture over multiple wave updates, and are controlled by "foam grow rate" and "foam decay rate" parameters respectively.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Sea Spray</h4><a id="user-content-sea-spray" aria-label="Permalink: Sea Spray" href="#sea-spray"></a></p>
<p dir="auto">Sea spray is modeled using particles via Godot's GPUParticles3D node and makes heavy use of a custom particle shader. Particles are distributed evenly across the plane within the GPUParticles3D node's bounding box. Then, they are culled based on the foam amount present at their position. Un-culled particles begin their lifecycle at a random offset.</p>
<p dir="auto">Each sea spray particle uses a billboarded sprite with a single static texture. Over the course of their lifecycle, particles' scales and displacements are modified to emulate a splash's appearance. A dissolve effect in particles' mesh shader fades the sprite in a way that simulates how sea spray atomizes once in the air.</p>
<p dir="auto">One <em>major</em> drawback of this method is that a large increase in particle amount only results in a small increase in sea spray density. This is due to the equal distribution of particles along the bounding box, which results in a majority of the added particles being culled.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/18603664/367495381-c69766e7-711c-4909-a1fa-290bac0d577a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNjc0OTUzODEtYzY5NzY2ZTctNzExYy00OTA5LWExZmEtMjkwYmFjMGQ1NzdhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdmZThlYjZkYTM1MGZhZTAwNGU1ZTAxY2UzYjgwNTE0ZDZhY2Y5YmNjNTg0MDg4OGY5ZWMxNzRkM2EzZmU4Y2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.TsauWxPeyGFgju5z9_6ePtRLKSGiuVHYeXbvtOIx3y4"><img src="https://private-user-images.githubusercontent.com/18603664/367495381-c69766e7-711c-4909-a1fa-290bac0d577a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNjc0OTUzODEtYzY5NzY2ZTctNzExYy00OTA5LWExZmEtMjkwYmFjMGQ1NzdhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdmZThlYjZkYTM1MGZhZTAwNGU1ZTAxY2UzYjgwNTE0ZDZhY2Y5YmNjNTg0MDg4OGY5ZWMxNzRkM2EzZmU4Y2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.TsauWxPeyGFgju5z9_6ePtRLKSGiuVHYeXbvtOIx3y4" alt="shading_demo"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wave Simulation</h3><a id="user-content-wave-simulation" aria-label="Permalink: Wave Simulation" href="#wave-simulation"></a></p>
<p dir="auto">The method for generating surface waves closely follows Tessendorf. A directional ocean-wave spectrum function is multiplied with Gaussian-distributed random numbers to generate an initial spectral sea state. The initial state is then propagated in time through a "dispersion relation" (relating the frequency of waves and their propagation speed). An inverse Fourier transform can then be applied to the propagated state to generate displacement and normal maps.</p>
<p dir="auto">The methodology Tessendorf describes was implemented through a compute shader pipeline using Godot's RenderingDevice abstraction. The following sections detail more on major aspects of the wave generation system.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Ocean-Wave Spectra</h4><a id="user-content-ocean-wave-spectra" aria-label="Permalink: Ocean-Wave Spectra" href="#ocean-wave-spectra"></a></p>
<p dir="auto">The directional ocean-wave spectrum function, <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$S(\omega, \theta)$</math-renderer>, returns the energy of a wave given its frequency (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\omega$</math-renderer>) and direction (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\theta$</math-renderer>). It is comprised of a <strong>non-directional spectrum function</strong>, <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$S(\omega)$</math-renderer>, and a <strong>directional spread function</strong>, <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$D(\omega, \theta)$</math-renderer>; the choice of either is entirely independent.</p>
<ul dir="auto">
<li>For the <strong>non-directional spectrum function</strong>, the <em>Texel-Marsen-Arsloe</em> (TMA) spectrum described in Horvath was chosen. Given the wind speed (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$U$</math-renderer>), depth (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$D$</math-renderer>), and fetch length (i.e., distance from shoreline) (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$F$</math-renderer>), the TMA spectrum combines its preceding <em>JONSWAP</em> spectrum with a depth attenuation function and is defined as <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$S_{\text{TMA}}(\omega) = S_{\text{JONSWAP}}(\omega)\Phi(\omega)$</math-renderer> where:</li>
</ul>
<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$$\begin{align*}
S_{\text{JONSWAP}}(\omega) &amp;= \Big[0.076\Big(\tfrac{U^2}{F \cdot 9.81}\Big)^{0.22}\Big]\Big[\tfrac{9.81^2}{\omega^5}\exp\Big({-\tfrac 5 4}\big(\tfrac{\omega_p}{\omega}\big)^4\Big)\Big] \Big[3.3^{\exp\Big(-\tfrac{(\omega - \omega_p)^2}{2(0.07 + 0.02\cdot\mathrm{step}(\omega - \omega_p))^2\omega_p^2}\Big)}\Big]\\\
\Phi(\omega) &amp;\approx \tfrac 1 2 \omega_h^2 + ({-\omega}_h^2+2\omega_h-1)\cdot\mathrm{step}(\omega_h - 1)\\\
\omega_p &amp;= 22\Big(\tfrac{9.81^2}{U F}\Big)\\\
\omega_h &amp;= \omega \sqrt{\tfrac D {9.81}}
\end{align*}$$</math-renderer>
<ul dir="auto">
<li>For the <strong>directional spread function</strong>, a combination of the <em>flat</em> and <em>Hasselmann</em> directional spreadings described in Horvath‚Äîmixed by a 'spread' parameter (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\mu$</math-renderer>)‚Äîwas chosen. Horvath also proposes the addition of a 'swell' parameter (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\xi$</math-renderer>) to model ocean-wave elongation‚Äîthis was also incorporated into the spread model. The mixed spread function is defined as <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">${D_{\text{mixed}}(\omega, \theta) = \mathrm{lerp}((2\pi){^{-1}},\ Q(s+s_\xi)\text{|}\cos(\theta \text{/}2)\text{|}^{2(s+s_\xi)},\ \mu)}$</math-renderer> where:</li>
</ul>
<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$$\begin{align*}
&lt;!-- https://www.wolframalpha.com/input?i2d=true&amp;i=taylor+series+Divide%5BPower%5B2%2C%5C%2840%292x-1%5C%2841%29%5D%2C%CF%80%5D*Divide%5BPower%5B%5C%2840%29x%21%5C%2841%29%2C2%5D%2C%5C%2840%292x%5C%2841%29%21%5D+at+x+%3D+0 --&gt;
Q(\sigma) &amp;\approx \begin{cases}
 0.09\sigma^3 + \big(\tfrac{\ln^2 2}{\pi} - \tfrac{\pi}{12}\big)\sigma^2+\big(\tfrac{\ln 2}{\pi}\big)\sigma+\tfrac{1}{2\pi} &amp; \text{if } \sigma \leq 0.4\\\
 \frac{\sqrt \sigma}{2\sqrt \pi} + \frac{1}{16\sqrt{\pi \sigma}} &amp; \text{otherwise.}
\end{cases}\\\
s &amp;= \begin{cases}
 6.97\big(\tfrac \omega {\omega_p}\big){^{4.06}} &amp; \text{if } \omega \leq \omega_p\\\
 9.77\big(\tfrac \omega {\omega_p}\big){^{-2.33 -1.45(\omega_p U\text{/}9.81-1.17)}} &amp; \text{otherwise.}
\end{cases}\\\
s_\xi &amp;= 16 \tanh\big(\tfrac{\omega_p}{\omega}\big)\xi^2
\end{align*}$$</math-renderer>
<p dir="auto"><math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$Q(\sigma)$</math-renderer> is a normalization factor used to satisfy the condition: <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\int_{-\pi}^\pi D(\omega, \theta)d \theta = 1$</math-renderer>. The Hasselmann directional spread was chosen due to its approximate analytical solution for <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$Q(\sigma)$</math-renderer> (as opposed to e.g., the Donelan-Banner directional spread also described in Horvath).</p>
<p dir="auto">Following a suggestion in Tessendorf, the resultant spectrum function was also multiplied by a small-wave suppression term, <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\exp({-k}^2(1-\delta)^2)$</math-renderer> (given the magnitude of the wave vector (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$k$</math-renderer>) and a 'detail' parameter (<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$\delta$</math-renderer>)). Combining the above, our <em>final</em> directional ocean-wave spectrum function used can be denoted as:</p>
<math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="3bb48dd0e93aac9c804f5bc9c48749f1">$$S(\omega, \theta) = S_{\text{TMA}}(\omega)D_{\text{mixed}}(\omega, \theta)\exp({-k}^2(1-\delta)^2)$$</math-renderer>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fast Fourier Transform</h4><a id="user-content-fast-fourier-transform" aria-label="Permalink: Fast Fourier Transform" href="#fast-fourier-transform"></a></p>
<p dir="auto">A custom FFT implementation was written for the GPU using compute shaders. The <em>Stockham</em> FFT algorithm was used over the Cooley-Tukey algorithm to avoid the initial bit-reversal permutation. Following Fl√ºgge, a 'butterfly' texture is computed, once per spectrum texture resolution change, encoding the dataflow of the FFT.</p>
<p dir="auto">First, the FFT kernel is applied row-wise to perform the 2D FFT on the spectrum texture. The texture is then transposed using a compute shader, allowing the same row-wise FFT kernel to then be reused for‚Äîwhat is effectively‚Äîa column-wise FFT. This transposition also improves memory access patterns along with enabling pipeline reuse.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Wave Cascades</h4><a id="user-content-wave-cascades" aria-label="Permalink: Wave Cascades" href="#wave-cascades"></a></p>
<p dir="auto">At large-enough distances‚Äîespecially with sea foam present‚Äîtiling artifacts become very apparent. The wave generation system allows multiple wave cascades to be layered simultaneously to address this. Each cascade has its own tiling size and set of parameters. Cascades can be added/removed from the generation system dynamically in real-time. However, as all cascades use the same compute pipelines, they must have the same spectra texture resolution. Alternatively, blending wave displacements/normals with noise could also reduce tiling artifacts‚Äîat a lesser performance cost.</p>
<p dir="auto">Each wave cascades‚Äô parameters and size must be carefully chosen to avoid wave interference when layered. Similarly, the cascades' wave phases should be offset to avoid interference with other cascades. The generation system automatically attempts this by offsetting each cascades‚Äô start times differently (honestly, not sure if it works lol).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Load Balancing</h4><a id="user-content-load-balancing" aria-label="Permalink: Load Balancing" href="#load-balancing"></a></p>
<p dir="auto">Due to the erratic nature of wave motion, their movement can appear perceptually smooth even without updating their displacements every frame. Thus, an "update rate" parameter was introduced to control how often wave cascades are updated per second. While this reduces the amount of GPU-time spent working on FFT, frames during which the wave generation pipeline runs still stutter.</p>
<p dir="auto">An experiment to asynchronously compute cascade updates using Godot's local RenderingDevices, caused significant performance overhead due to transferring textures between the CPU and GPU. Instead, the wave generation system <em>attempts to load-balance cascades</em>. Whenever the frame time is shorter than the update rate, only one cascade is updated per frame. This reduces stuttering while still benefiting from the lower GPU workload of frame skipping.</p>
<p dir="auto">The displacement, normal, and foam maps generated after running FFT on our directional ocean-wave spectrum function (along with its associated parameters) yield realistic surface motion across a broad range of ocean-wave environments.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description ocean_param_demo.mp4">ocean_param_demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/18603664/367477646-7589758f-1233-4be8-accc-2902a1dd01ec.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNjc0Nzc2NDYtNzU4OTc1OGYtMTIzMy00YmU4LWFjY2MtMjkwMmExZGQwMWVjLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJmMjM2Njc1OGVhYzFlZmRjNjYwMTQ2OGM0OTA1YTExOTEyNDViMjhjMGIxZTU3MWEwYWNmOWViMWIzNGI1YTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9ySTzoAP2MM4b3nC3RfbSdJk8v7kVXn0TPmAEyIdTiY" data-canonical-src="https://private-user-images.githubusercontent.com/18603664/367477646-7589758f-1233-4be8-accc-2902a1dd01ec.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc1MTk3MDUsIm5iZiI6MTcyNzUxOTQwNSwicGF0aCI6Ii8xODYwMzY2NC8zNjc0Nzc2NDYtNzU4OTc1OGYtMTIzMy00YmU4LWFjY2MtMjkwMmExZGQwMWVjLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTI4VDEwMzAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJmMjM2Njc1OGVhYzFlZmRjNjYwMTQ2OGM0OTA1YTExOTEyNDViMjhjMGIxZTU3MWEwYWNmOWViMWIzNGI1YTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9ySTzoAP2MM4b3nC3RfbSdJk8v7kVXn0TPmAEyIdTiY" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">References</h2><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<p dir="auto"><strong>Fl√ºgge, Fynn-Jorin</strong>. <strong><a href="https://tore.tuhh.de/entities/publication/1cd390d3-732b-41c1-aa2b-07b71a64edd2" rel="nofollow">Realtime GPGPU FFT Ocean Water Simulation</a></strong>. Hamburg University of Technology. (2017).<br>
<strong>Gunnell, Garrett</strong>. <strong><a href="https://www.youtube.com/watch?v=yPfagLeUa7k" rel="nofollow">I Tried Simulating The Entire Ocean</a></strong>. (2023).<br>
<strong>Horvath, Christopher J</strong>. <strong><a href="https://dl.acm.org/doi/10.1145/2791261.2791267" rel="nofollow">Empirical Directional Wave Spectra for Computer Graphics</a></strong>. DigiPro. (2015).<br>
<strong>Tessendorf, Jerry</strong>. <strong><a href="https://people.computing.clemson.edu/~jtessen/reports/papers_files/coursenotes2004.pdf" rel="nofollow">Simulating Ocean Water</a></strong>. SIGGRAPH. (2004).<br>
<strong>Matusiak, Robert</strong>. <strong><a href="https://www.ti.com/lit/an/spra291/spra291.pdf" rel="nofollow">Implementing Fast Fourier Transform Algorithms of Real-Valued Sequences</a></strong>. Texas Instruments. (2001).<br>
<strong>Mihelich, Mark</strong>. <strong><a href="https://www.youtube.com/watch?v=Dqld965-Vv0" rel="nofollow">Wakes, Explosions and Lighting: Interactive Water Simulation in 'Atlas'</a></strong>. GDC. (2019).<br>
<strong>Pensionerov, Ivan</strong>. <strong><a href="https://github.com/gasgiant/FFT-Ocean">FFT-Ocean</a></strong>. GitHub. (2020).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Attribution</h2><a id="user-content-attribution" aria-label="Permalink: Attribution" href="#attribution"></a></p>
<p dir="auto"><strong><a href="https://polyhaven.com/a/evening_road_01_puresky" rel="nofollow">Evening Road 01 (Pure Sky)</a></strong> by <strong>Jarod Guest</strong> is used under the <a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow">CC0 1.0</a> license.<br>
<strong><a href="http://wwwa.pikara.ne.jp/okojisan/otfft-en/stockham3.html" rel="nofollow">OTFFT DIT Stockham Algorithm</a></strong> by <strong>Takuya Okahisa</strong> is used and modified under the <a href="http://wwwa.pikara.ne.jp/okojisan/otfft-en/download.html" rel="nofollow">MIT</a> license.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amusing Ourselves to Death (264 pts)]]></title>
            <link>https://otpok.com/2014/01/03/amusing-ourselves-to-death/</link>
            <guid>41678208</guid>
            <pubDate>Sat, 28 Sep 2024 05:56:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://otpok.com/2014/01/03/amusing-ourselves-to-death/">https://otpok.com/2014/01/03/amusing-ourselves-to-death/</a>, See on <a href="https://news.ycombinator.com/item?id=41678208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

		
			
<article id="post-1457">
	<!-- .entry-header -->

	<div>
		<p><a href="http://www.diet-specialist.co.uk/pathofknowledge"><img src="https://otpok.com/wp-content/uploads/2014/01/diet-specialist-1.gif?w=646&amp;h=106" alt="" width="646" height="106"></a></p>
<p>This is perhaps one of the most striking passages I have read for a while. It describes the modern world with startling accuracy. In our fear of an increasingly authoritarian rule, we have allowed a far more dangerous vision to come true: <span><strong><em>heedlessness</em></strong></span></p>
<p>Below is the foreward of Neil Postman‚Äôs book ‚Äú<strong>Amusing Ourselves to Death: Public Discourse in the Age of Show Business</strong>‚Äú, accompanied by a comic illustration of the two ideas. It gives a concise comparison of the two authors views and what they foresaw society will become. But perhaps the remarkable part of this whole story passage lies beyond its lines with us:</p>
<p><span><em><strong>Most of us will read this and continue living our life exactly the same way as before</strong></em></span></p>
<p><span><strong><em>‚Ä¶wake up</em></strong></span></p>
<p>‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì</p>
<blockquote><p>We were keeping our eye on 1984. When the year came and the prophecy didn‚Äôt, thoughtful Americans sang softly in praise of themselves. The roots of liberal democracy had held. Wherever else the terror had happened, we, at least, had not been visited by Orwellian nightmares.</p>
<p>But we had forgotten that alongside Orwell‚Äôs dark vision, there was another ‚Äì slightly older, slightly less well known, equally chilling: Aldous Huxley‚Äôs Brave New World. Contrary to common belief even among the educated, Huxley and Orwell did not prophesy the same thing. Orwell warns that we will be overcome by an externally imposed oppression. But in Huxley‚Äôs vision, no Big Brother is required to deprive people of their autonomy, maturity and history. As he saw it, people will come to love their oppression, to adore the technologies that undo their capacities to think.</p>
<p>What Orwell feared were those who would ban books. What Huxley feared was that there would be no reason to ban a book, for there would be no one who wanted to read one. Orwell feared those who would deprive us of information. Huxley feared those who would give us so much that we would be reduced to passivity and egoism. Orwell feared that the truth would be concealed from us. Huxley feared the truth would be drowned in a sea of irrelevance. Orwell feared we would become a captive culture. Huxley feared we would become a trivial culture, preoccupied with some equivalent of the feelies, the orgy porgy, and the centrifugal bumblepuppy. As Huxley remarked in Brave New World Revisited, the civil libertarians and rationalists who are ever on the alert to oppose tyranny ‚Äúfailed to take into account man‚Äôs almost infinite appetite for distractions‚Äù. In 1984, Huxley added, people are controlled by inflicting pain. In Brave New World, they are controlled by inflicting pleasure. In short, Orwell feared that what we hate will ruin us. Huxley feared that what we love will ruin us.</p>
<p>This book is about the possibility that Huxley, not Orwell, was right</p>
<p><strong><em>[Neil Postman ‚Äì Amusing ourselves to death]</em></strong></p></blockquote>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/screenshot_1.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/wpid-storageextsdcarddcimcomparison-1.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/wpid-storageextsdcarddcimcomparison-2.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/comparison-31.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/comparison-4.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/comparison-51.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/wpid-storageextsdcarddcimcomparison-6.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/comparison-71.png?w=700" alt=""></p>
<p><img src="https://otpok.com/wp-content/uploads/2014/01/screenshot_16.png?w=700" alt=""></p>
<p><em>[The comic is Stuart McMillen‚Äôs interpretation of media theorist Niel Postman‚Äôs book Amusing Ourselves to Death (1985), subtitled ‚ÄúPublic Discourse in the Age of&nbsp;Show Business‚Äù]</em></p>

			
						</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->
			<div>
	<h3>Related posts</h3>
	
		<article id="post-1449">

						<p><a href="https://otpok.com/2013/12/25/hamster/"><img width="50" height="50" src="https://otpok.com/wp-content/uploads/2013/12/skeleton-wheel.gif?w=50&amp;h=50&amp;crop=1" alt="" decoding="async" data-attachment-id="1450" data-permalink="https://otpok.com/2013/12/25/hamster/skeleton-wheel/" data-orig-file="https://otpok.com/wp-content/uploads/2013/12/skeleton-wheel.gif" data-orig-size="960,544" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Skeleton Wheel" data-image-description="" data-image-caption="" data-medium-file="https://otpok.com/wp-content/uploads/2013/12/skeleton-wheel.gif?w=300" data-large-file="https://otpok.com/wp-content/uploads/2013/12/skeleton-wheel.gif?w=700" tabindex="0" role="button"></a>
			</p>
			
			<!-- .entry-header -->

		</article>

	
		<article id="post-2847">

						<p><a href="https://otpok.com/2020/03/28/deaths-spectre/"><img width="50" height="50" src="https://otpok.com/wp-content/uploads/2020/03/death-164761.jpg?w=50&amp;h=50&amp;crop=1" alt="" decoding="async" data-attachment-id="2849" data-permalink="https://otpok.com/2020/03/28/deaths-spectre/death-164761/" data-orig-file="https://otpok.com/wp-content/uploads/2020/03/death-164761.jpg" data-orig-size="1920,1271" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="death-164761" data-image-description="" data-image-caption="" data-medium-file="https://otpok.com/wp-content/uploads/2020/03/death-164761.jpg?w=300" data-large-file="https://otpok.com/wp-content/uploads/2020/03/death-164761.jpg?w=700" tabindex="0" role="button"></a>
			</p>
			
			<!-- .entry-header -->

		</article>

	
		<article id="post-498">

			
			<!-- .entry-header -->

		</article>

	</div>

				<!-- #nav-below -->
	
			
	<!-- #comments -->

		
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything you need to know about Python 3.13 ‚Äì JIT and GIL went up the hill (224 pts)]]></title>
            <link>https://drew.silcock.dev/blog/everything-you-need-to-know-about-python-3-13/</link>
            <guid>41677131</guid>
            <pubDate>Sat, 28 Sep 2024 01:23:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drew.silcock.dev/blog/everything-you-need-to-know-about-python-3-13/">https://drew.silcock.dev/blog/everything-you-need-to-know-about-python-3-13/</a>, See on <a href="https://news.ycombinator.com/item?id=41677131">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p>On October 2<sup>nd</sup>, 2024, the Python core developers and community will release <a href="https://docs.python.org/3.13/whatsnew/3.13.html">CPython v3.13.0</a> ‚Äì and it‚Äôs a doozy.</p>
<p>So what makes this release different, and why should you care about it?</p>
<p>In short, there are two big changes being made to how Python runs at a core level which have the potential to radically change the performance profile of Python code in the future.</p>
<p>Those changes are:</p>
<ul>
<li>A ‚Äúfree-threaded‚Äù version of CPython which allows you to disable the Global Interpreter Lock (GIL), and</li>
<li>Support for experimental Just-in-Time (JIT) compilation.</li>
</ul>
<p>So what are these new features and what impact will they have on you?</p>
<a href="#global-interpreter-lock-gil">#</a><h2 id="global-interpreter-lock-gil">Global Interpreter Lock (GIL)</h2>
<a href="#what-is-the-gil">#</a><h3 id="what-is-the-gil">What is the GIL?</h3>
<p>From the inception of the Python programming language by Guido Van Rossum in a science park in East Amsterdam in the late ‚Äô80s, it was designed and implemented as a single-threaded interpreted language. What exactly does this mean?</p>
<p>You‚Äôll commonly hear that there are 2 types of programming languages ‚Äì interpreted and compiled. So which is Python? The answer is: <strong>yes</strong>.</p>
<p>You will very rarely find a programming language which is purely interpreted from source by an interpreter. For interpreted languages, the human-readable source code is almost always compiled into some kind of intermediary form, called bytecode. The interpreter then looks at the bytecode and executes the instructions one-by-one.</p>
<p>The ‚Äúinterpreter‚Äù here is commonly called a ‚Äúvirtual machine‚Äù, especially in other languages like Java which does the same thing as Python re. <a href="https://en.wikipedia.org/wiki/Java_bytecode">Java bytecode</a> and <a href="https://en.wikipedia.org/wiki/List_of_Java_virtual_machines">Java VMs</a>. In Java and <a href="https://kotlinlang.org/">friends</a>, it‚Äôs much more common to ship the compiled bytecode itself, whereas Python applications are usually distributed as source code (although, having said that, packages are often deployed as <a href="https://packaging.python.org/en/latest/discussions/package-formats/#what-is-a-wheel">wheels</a> as well as <a href="https://packaging.python.org/en/latest/discussions/package-formats/#what-is-a-source-distribution">sdist</a> nowadays).</p>
<p>Virtual machines in this meaning of the word come up in all kinds of unexpected places, like in the PostScript format (PDF files are essentially compiled PostScript) and in font rendering<sup><a href="#user-content-fn-font-rendering" id="user-content-fnref-font-rendering" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<p>If you‚Äôve ever noticed a bunch of <code>*.pyc</code> files in your Python projects, this is the compiled bytecode for your application. You can decompile and explore <code>pyc</code> files in exactly the same way you can find Java class files.</p>
<p><span data-astro-cid-mrmim4ef="">üí°</span> <span data-astro-cid-mrmim4ef=""> <p><strong>Python vs CPython</strong></p><p>I can already hear a chorus of pedantic Pythonistas shouting ‚ÄúPython isn‚Äôt the same as CPython!‚Äù, and they‚Äôre right. And this is an important distinction to make.</p><p>Python is the programming language, which is essentially a specification saying what the language should do.</p><p>CPython is the <em>reference implementation</em> of this language specification, and what we‚Äôre talking about here is mostly about the CPython implementation. There are other Python implementations, like <a href="https://pypy.org/">PyPy</a> which has always used JIT compilation, <a href="https://www.jython.org/">Jython</a> which runs on the JVM and <a href="https://ironpython.net/">IronPython</a> which runs on the .NET CLR.</p><p>Having said that, pretty much everyone just uses CPython and so I think it‚Äôs reasonable to talk about ‚ÄúPython‚Äù when we‚Äôre really talking about CPython. If you disagree, go ahead and get in the comments or write me a strongly worded email with an aggressive font (maybe <a href="https://www.google.com/search?q=impact+font">Impact</a>; I‚Äôve always thought <a href="https://www.google.com/search?q=comic+sans">Comic Sans</a> has a subtly threatening aura).</p> </span> </p> 
<p>So when we run Python, the <code>python</code> executable will generate the bytecode which is a stream of instructions, then the interpreter will read and execute the instructions one-by-one.</p>
<p>If you try to spin up multiple threads, what happens then? Well, the threads all share the same memory (apart from their local variables) and so they can all access and update the same objects. Each thread will be executing its own bytecode using its own stack and instruction pointer.</p>
<p>What happens if multiple threads try to access / edit the same object at the same time? Imagine one thread is trying to add to a dict while another is trying to read from it. There are two options here:</p>
<ul>
<li>Make the implementation of dict (and all the other objects) thread-safe, which takes a lot of effort and will make it slower for a single-threaded application, or</li>
<li>Create a global mutual exclusion lock (a.k.a. mutex) which allows only one thread to be executing bytecode at any one time.</li>
</ul>
<p>This latter option is the GIL. The former option is what the Python developers are calling ‚Äúfree-threading‚Äù mode.</p>
<p>It‚Äôs also worth mentioning that the GIL makes garbage collection much simpler and faster. We don‚Äôt have time to go into the depths of garbage collection here as it‚Äôs a whole big topic in itself, but a simplified version is that Python keeps a count of how many references there are to a particular object, and when that count reaches zero, Python knows that it can safely delete that object. If there are multiple threads concurrently creating and dropping references to different objects, this can lead to race conditions and memory corruptions, so any free-threaded version needs to use atomically counted references for all objects.</p>
<p>The GIL also makes it much easier to develop C extensions for Python (e.g. using the confusingly named <a href="https://cython.org/">Cython</a>) as you can make assumptions about thread safety that make your life much easier, check out the <a href="https://py-free-threading.github.io/porting">py-free-threading guide for porting C extensions</a> for more details on this.</p>
<a href="#why-does-python-have-a-gil">#</a><h3 id="why-does-python-have-a-gil">Why does Python have a GIL?</h3>
<p>Despite having a surge in popularity over the last few years, it‚Äôs not a particularly new language ‚Äì it was conceived in the late ‚Äô80s, with the first release on 20<sup>th</sup> February 1991 (making it slightly older than me). Back then, computers looked very different. Most programs were single-threaded and the performance of individual cores was increasing exponentially (see good old <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore‚Äôs Law</a>). In this environment, it didn‚Äôt make much sense to compromise single-threaded performance for thread safety when most programs would not be utilising multiple cores.</p>
<p>Also, implementing thread safety obviously takes a lot of work.</p>
<p>This isn‚Äôt to say that you can‚Äôt utilise multiple cores in Python. It just means that instead of using threading, you have to utilise multiple processes (i.e. <a href="https://docs.python.org/3/library/multiprocessing.html"><code>multiprocessing</code></a> module).</p>
<p>Multi-processing differs from multi-threading because each process is its own Python interpreter with its own separate memory space. This means that multiple processes can‚Äôt access the same objects in memory but instead you have to use special constructs and communication to share data (see <a href="https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes">‚ÄúSharing state between processes‚Äù</a> and <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue"><code>multiprocessing.Queue</code></a>).</p>
<p>It‚Äôs worth mentioning that there is a bit more overhead in using multiple processes as opposed to multiple threads, in addition to it being more difficult to share data.</p>
<p>Using multiple threads is sometimes not as bad as people commonly assume, however. If Python is doing I/O like reading from files or making network calls, it will release the GIL so that other threads can run. This means that if you‚Äôre doing lots of I/O, multi-threading will often be as fast as multi-processing. It‚Äôs when you are CPU-bound that the GIL becomes a big issue.</p>
<a href="#ok-so-why-are-they-removing-the-gil-now">#</a><h3 id="ok-so-why-are-they-removing-the-gil-now">Ok, so why are they removing the GIL now?</h3>
<p>The removal of the GIL has been something that certain people have been pushing for for several years now, but the main reason it‚Äôs not been done is not the amount of work it takes but instead is the corresponding performance degradation that would come with it for single-threaded programs.</p>
<p>Nowadays, the incremental improvements in single-core performance of computers doesn‚Äôt change too much from year to year (although big advances are being made with custom processor architectures, e.g. Apple Silicon chips) while the number of cores in a computer continues to increase. This means it‚Äôs much more common for programs to utilise multiple cores and hence the inability of Python to properly utilise multi-threading is becoming more and more of an issue.</p>
<p>Fast forward to 2021 and <a href="https://github.com/colesbury">Sam Gross</a> implemented a <a href="https://lwn.net/ml/python-dev/CAGr09bSrMNyVNLTvFq-h6t38kTxqTXfgxJYApmbEWnT71L74-g@mail.gmail.com/">no-GIL Proof of Concept implementation</a> that spurred the <a href="https://github.com/python/steering-council">Python Steering Council</a> to propose a vote on <a href="https://peps.python.org/pep-0703/">PEP 703 ‚Äì Making the Global Interpreter Lock Optional in CPython</a>. The outcome of the vote was positive, resulting in the Steering Council <a href="https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474">accepting the proposal</a> as part of a <a href="https://discuss.python.org/t/pep-703-making-the-global-interpreter-lock-optional-in-cpython-acceptance/37075">gradual rollout</a> in three phases:</p>
<ul>
<li><strong>Phase 1</strong>: Free-threading mode is an experimental build-time option that is not the default.</li>
<li><strong>Phase 2</strong>: Free-threading mode is officially supported but still not the default.</li>
<li><strong>Phase 3</strong>: Free-threading mode is the default.</li>
</ul>
<p>From reading the discussions, there‚Äôs a strong desire to not ‚Äúsplit‚Äù Python into two separate implementations ‚Äì one with the GIL and one without ‚Äì with the intention being that eventually after free-threading mode has been the default for a while, the GIL will be removed entirely and the free-threading mode will be the only mode.</p>
<p>While all this GIL vs. no-GIL stuff has been going on the last few years, there has been a parallel effort called the ‚ÄúFaster CPython‚Äù project. This has been <a href="https://lwn.net/ml/python-dev/CAGr09bSrMNyVNLTvFq-h6t38kTxqTXfgxJYApmbEWnT71L74-g@mail.gmail.com/">funded by Microsoft</a> and led by <a href="https://us.pycon.org/2023/speaker/profile/81/index.html">Mark Shannon</a> and <a href="https://gvanrossum.github.io/">Guido van Rossum</a> himself, both of whom work at Microsoft.</p>
<p>The effort this team have been making has produced some very impressive results, particularly for <a href="https://docs.python.org/3/whatsnew/3.11.html#faster-cpython">3.11</a> which boasted significant performance boosts over 3.10.</p>
<p>With the combination of community / council support, increasing ubiquity of multi-core processors and the Faster CPython effort, the time was ripe for the beginning of Phase 1 of the GIL adoption plan.</p>
<a href="#what-does-the-performance-look-like">#</a><h3 id="what-does-the-performance-look-like">What does the performance look like?</h3>
<p>I‚Äôve run a few benchmarks on both my machine ‚Äì MacBook Pro with Apple M3 Pro (CPU has 6 performance cores and 6 efficiency cores) ‚Äì and on a quiet EC2 instance ‚Äì t3.2xlarge (8 vCPUs).</p>
<p>The graphs below show a comparison of the runtime performance of a CPU-intensive task (converging Mandelbrot set) between Python 3.12 and Python 3.13 with and without the GIL.</p>
<img src="https://drew.silcock.dev/_astro/bench-comparison-m3-dark.B6MCcmGa_96BpF.webp" alt="Performance comparison for Apple M3 Pro" width="2400" height="800" loading="lazy" decoding="async">
<img src="https://drew.silcock.dev/_astro/bench-comparison-m3-light.CBPn1teC_Z1H6EDr.webp" alt="Performance comparison for Apple M3 Pro" width="2400" height="800" loading="lazy" decoding="async">
<img src="https://drew.silcock.dev/_astro/bench-comparison-ec2-dark.DsCVDY3z_2hOeU1.webp" alt="Performance comparison for t3.2xlarge EC2 instance" width="2400" height="800" loading="lazy" decoding="async">
<img src="https://drew.silcock.dev/_astro/bench-comparison-ec2-light.ojc_JmYg_Z1h2QNH.webp" alt="Performance comparison for t3.2xlarge EC2 instance" width="2400" height="800" loading="lazy" decoding="async">
<p>(These graphs aren‚Äôt the most readable, I know ‚Äì I‚Äôll improve on them when I get some time.)</p>
<p>To explain what these runtimes mean:</p>
<ul>
<li><code>3.12.6</code> ‚Äì Python version 3.12.6.</li>
<li><code>3.13.0rc2</code> ‚Äì the default build of Python 3.13.0 release candidate 2 (the latest version at the time of writing).</li>
<li><code>3.13.0rc2t</code> ‚Äì the Python 3.13.0 release candidate 2 with experimental free-threading enabled at build-time, run without additional arguments (i.e. GIL disabled).</li>
<li><code>3.13.0rc2t-g1</code> ‚Äì the Python 3.13.0 release candidate 2 with experimental free-threading enabled at build-time, run with the <code>-X gil=1</code> argument, thereby ‚Äúre-enabling‚Äù the GIL at runtime.</li>
</ul>
<p>A few caveats to this:</p>
<ul>
<li>I didn‚Äôt use a proper well established benchmark, just a simple iterative algorithm. You can find the code for running the benchmarks and graphing the results at: <a href="https://github.com/drewsilcock/gil-perf">github.com/drewsilcock/gil-perf</a>. Try it out for yourself!</li>
<li>I used <a href="https://github.com/sharkdp/hyperfine">hyperfine</a> to run the benchmarks, which is a really good tool, but these aren‚Äôt proper scientific benchmarks running on dedicated hardware. My MacBook is running a whole bunch of things and even the EC2 instance will have stuff going on in the background, although not nearly as much.</li>
<li>These benchmarks are really interesting and fun to talk about, but do bear in mind that in the real world, most libraries that do CPU-intensive work use <a href="https://cython.readthedocs.io/en/latest/src/userguide/nogil.html">Cython</a> or similar&nbsp;‚Äì very few people use raw Python for very compute-intensive tasks. Cython has the ability to release the GIL temporarily during execution and has had for a while. These benchmarks aren‚Äôt representative of this use case.</li>
</ul>
<p>With that in mind, we can already make a few observations:</p>
<ul>
<li>The performance degradation when Python is built with free-threading support is significant ‚Äì around 20%.</li>
<li>It doesn‚Äôt matter whether you re-enable the GIL via the <code>-X gil=1</code> argument, the performance degradation is the same.</li>
<li>Multi-threading shows a significant boost with GIL disabled, as expected.</li>
<li>Multi-threading with GIL enabled is slower than single-threading, as expected.</li>
<li>Multi-threading with GIL disabled is about the same as multi-processing. Then again, this is a pretty noddy example where you don‚Äôt need to do much real work.</li>
<li>Apple Silicon chips really are quite impressive. Single-threaded performance on my M3 Pro is about 4x faster than single-threaded performance on the t3.2xlarge. I mean, I know t3 are designed to be cheap and burstable, but even so! It‚Äôs even more impressive if you consider the insane battery life you get out of these things<sup><a href="#user-content-fn-apple-sponsorship" id="user-content-fnref-apple-sponsorship" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>.</li>
</ul>
<a href="#how-do-i-try-out-free-threaded-python">#</a><h3 id="how-do-i-try-out-free-threaded-python">How do I try out free-threaded Python?</h3>
<p>At the time of writing, Python 3.13 is still in release candidate and hasn‚Äôt been officially released. Having said that, today is Saturday 28<sup>th</sup> and the release is scheduled for 2<sup>nd</sup> October which is Wednesday, so its not far away.</p>
<p>If you want to try it out ahead of time, you‚Äôre out of luck with <a href="https://rye.astral.sh/">rye</a> which only seems to ship deployed versions and <a href="https://docs.astral.sh/uv/">uv</a> which includes the 3.13.0rc2 build but not the 3.13.0rc2t build. Luckily, <a href="https://github.com/pyenv/pyenv">pyenv</a> supports both 3.13.0rc2 and 3.13.0rc2t. To try it out for yourself:</p>
<div><figure><pre data-language="shell"><code><div><div><p>1</p></div><p><span># If you're reading this from the future, rye may have it:</span></p></div><div><div><p>2</p></div><p><span>$</span><span> </span><span>rye</span><span> </span><span>toolchain</span><span> </span><span>list</span><span> </span><span>--include-downloadable</span><span> </span><span>|</span><span> </span><span>rg</span><span> </span><span>-F</span><span> </span><span><a href="https://drew.silcock.dev/cdn-cgi/l/email-protection" data-cfemail="1e7d6e676a7671705e2d302f2d">[email&nbsp;protected]</a></span></p></div><div><p>3</p></div><div><div><p>4</p></div><p><span># uv may also have it</span></p></div><div><div><p>5</p></div><p><span>$</span><span> </span><span>uv</span><span> </span><span>python</span><span> </span><span>list</span><span> </span><span>|</span><span> </span><span>rg</span><span> </span><span>-F</span><span> </span><span>cpython-3.13</span></p></div><div><p>6</p></div><div><div><p>7</p></div><p><span># pyenv should have it, though.</span></p></div><div><div><p>8</p></div><p><span>$</span><span> </span><span>pyenv</span><span> </span><span>install</span><span> </span><span>--list</span><span> </span><span>|</span><span> </span><span>rg</span><span> </span><span>'^\s+3\.13'</span></p></div><div><p>9</p></div><div><div><p>10</p></div><p><span># Take 3.13.0rc2t for a spin</span></p></div><div><div><p>11</p></div><p><span>$</span><span> </span><span>pyenv</span><span> </span><span>install</span><span> </span><span>3.13.0rc2t</span></p></div><div><div><p>12</p></div><p><span>$</span><span> </span><span>pyenv</span><span> </span><span>local</span><span> </span><span>3.13.0rc2t</span></p></div><div><p>13</p></div><div><div><p>14</p></div><p><span>$</span><span> </span><span>python</span><span> </span><span>-VV</span></p></div><div><div><p>15</p></div><p><span>Python</span><span> </span><span>3.13.0rc2</span><span> </span><span>experimental</span><span> </span><span>free-threading</span><span> </span><span>build</span><span> (main, </span><span>Sep</span><span> </span><span>18</span><span> </span><span>2024,</span><span> </span><span>16:41:38</span><span>) [Clang </span><span>15.0.0</span><span> (clang</span><span>-</span><span>1500</span><span>.</span><span>3</span><span>.</span><span>9</span><span>.</span><span>4</span><span>)]</span></p></div><div><p>16</p></div><div><div><p>17</p></div><p><span>$</span><span> </span><span>python</span><span> </span><span>-c</span><span> </span><span>'import sys;print("GIL enabled üîí" if sys._is_gil_enabled() else "GIL disabled üòé")'</span></p></div><div><div><p>18</p></div><p><span>GIL</span><span> </span><span>disabled</span><span> </span><span>üòé</span></p></div><div><p>19</p></div><div><div><p>20</p></div><p><span># GIL can be re-enabled at runtime</span></p></div><div><div><p>21</p></div><p><span>$</span><span> </span><span>python</span><span> </span><span>-X</span><span> </span><span>gil=</span><span>1</span><span> </span><span>-c</span><span> </span><span>'import sys;print("GIL enabled üîí" if sys._is_gil_enabled() else "GIL disabled üòé")'</span></p></div><div><div><p>22</p></div><p><span>GIL</span><span> </span><span>enabled</span><span> </span><span>üîí</span></p></div></code></pre></figure></div>
<p>Just a heads up if you are trying free-threading Python ‚Äì if you don‚Äôt specify either <code>-X gil=0</code> or <code>-X gil=1</code>, the GIL will be disabled by default but simply importing a module which does not support running without the GIL will cause the GIL to be re-enabled. I found this when running the benchmarks because I imported matplotlib, which results in the GIL being re-enabled and all my benchmarks coming out rubbish. If you manually specify <code>-X gil=0</code>, the GIL will not be sneakily re-enabled, even if a package does not mark itself as supporting GIL-free running.</p>
<a href="#jit-just-in-time-compiler">#</a><h2 id="jit-just-in-time-compiler">JIT (Just-in-Time) Compiler</h2>
<p>It‚Äôs not just the GIL that‚Äôs a big change in this Python release ‚Äì there‚Äôs also the addition into the Python interpreter of an experimental JIT compiler.</p>
<a href="#what-is-a-jit">#</a><h3 id="what-is-a-jit">What is a JIT?</h3>
<p>JIT stands for Just in Time and is a compilation technique where machine code is produced just in time to execute it, as opposed to ahead of time (AOT) like your traditional C compiler like gcc or clang.</p>
<p>We already talked about bytecode and the interpreter earlier. The important thing is that, before Python 3.13, the interpreter would look at each bytecode instruction one at a time and turn each one into native machine code before executing it. With the introduction of the JIT compiler, it is now possible for bytecode to be ‚Äúinterpreted‚Äù into machine code once and updated as necessary, instead of being re-interpreted every time.</p>
<p>It‚Äôs important to point out that this kind of JIT that has been <a href="https://github.com/python/cpython/pull/113465">introduced in 3.13</a> is what‚Äôs called <a href="https://en.wikipedia.org/wiki/Copy-and-patch">‚Äúcopy-and-patch‚Äù JIT</a>. This is a very recent idea introduced in 2021 in an article called <a href="https://dl.acm.org/doi/10.1145/3485513">‚ÄúCopy-and-patch compilation: a fast compilation algorithm for high-level languages and bytecode</a>. The core idea behind copy-and-patch as opposed to more advanced JIT compilers is that there is a simple list of pre-generated templates ‚Äì the JIT compiler will pattern match for bytecode that matches one of the pre-defined templates and if it does, it will patch in pre-generated native machine code.</p>
<p>Traditional JIT compilers will be massively more advanced that this and also massively more memory intensive, especially if you compare it to heavily JIT-compiled languages like Java or C#. (That‚Äôs part of the reason Java programs take up so much memory.)</p>
<p>What‚Äôs great about JIT compilers is that they can adapt to your code as its running. For instance, as your code runs, the JIT compiler will keep track of how ‚Äúhot‚Äù each piece of code is. JIT compilers can perform incremental optimisations as the code get hotter and hotter and even use information about how the program is actually running to inform the optimisations it is making (like how Profile-Guided Optimisation does for AOT compilers). This means that JIT doesn‚Äôt waste time optimising some code which is only running once but the really hot sections of code can have heavy run-time informed optimisations done on them.</p>
<p>Now, the JIT compiler in Python 3.13 is relatively simple and won‚Äôt be doing any crazy at this stage, but it‚Äôs a really exciting development for the future of Python performance.</p>
<a href="#what-difference-will-the-jit-make-to-me">#</a><h3 id="what-difference-will-the-jit-make-to-me">What difference will the JIT make to me?</h3>
<p>In the short term, the introduction of the JIT is unlikely to make any difference to how you write or run your Python code. But it‚Äôs an exciting internal change to the way that the Python interpreter operates that could lead to much more significant performance improvements being made to Python performance in the future.</p>
<p>In particular, it opens up the way for incremental performance improvements to be made over time which could gradually bump up Python‚Äôs performance to be more competitive with other languages. Having said that, this is still early stages and the copy-and-patch JIT technique is both new and lightweight, so there‚Äôs more big changes needed before we start seeing significant benefits from the JIT compiler.</p>
<a href="#how-do-i-try-out-the-jit">#</a><h3 id="how-do-i-try-out-the-jit">How do I try out the JIT?</h3>
<p>The JIT compilers is ‚Äúexperimental‚Äù in 3.13 and isn‚Äôt built with support out of the box (at least not when I downloaded 3.13.0rc2 using pyenv). You can enable experimental JIT support by doing:</p>
<div><figure><pre data-language="shell"><code><div><div><p>1</p></div><p><span>$</span><span> </span><span>PYTHON_CONFIGURE_OPTS="--enable-experimental-jit"</span><span> </span><span>pyenv</span><span> </span><span>install</span><span> </span><span>3.13-dev</span></p></div><div><div><p>2</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>openssl@3</span><span> </span><span>from</span><span> </span><span>homebrew</span></p></div><div><div><p>3</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>readline</span><span> </span><span>from</span><span> </span><span>homebrew</span></p></div><div><div><p>4</p></div><p><span>Cloning</span><span> </span><span>https://github.com/python/cpython...</span></p></div><div><div><p>5</p></div><p><span>Installing</span><span> </span><span>Python-3.13-dev...</span></p></div><div><div><p>6</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>tcl-tk</span><span> </span><span>from</span><span> </span><span>homebrew</span></p></div><div><div><p>7</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>readline</span><span> </span><span>from</span><span> </span><span>homebrew</span></p></div><div><div><p>8</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>ncurses</span><span> </span><span>from</span><span> </span><span>homebrew</span></p></div><div><div><p>9</p></div><p><span>python-build:</span><span> </span><span>use</span><span> </span><span>zlib</span><span> </span><span>from</span><span> </span><span>xcode</span><span> </span><span>sdk</span></p></div><div><div><p>10</p></div><p><span>Installed</span><span> </span><span>Python-3.13-dev</span><span> </span><span>to</span><span> </span><span>/Users/drew.silcock/.pyenv/versions/3.13-dev</span></p></div><div><div><p>11</p></div><p><span>$</span><span> </span><span>python</span><span> </span><span>-c</span><span> </span><span>'import sysconfig;print("JIT enabled üöÄ" if "-D_Py_JIT" in sysconfig.get_config_var("PY_CORE_CFLAGS") else "JIT disabled üòí")'</span></p></div><div><div><p>12</p></div><p><span>JIT</span><span> </span><span>enabled</span><span> </span><span>üöÄ</span></p></div></code></pre></figure></div>
<p>There are additional configure options which you can read about <a href="https://discuss.python.org/t/pep-744-jit-compilation/50756">on the PEP 744 discussion page</a> (like enabling the JIT but requiring it be enabled by running <code>-X jit=1</code> at runtime, etc.).</p>
<p>The test here only checks for whether the JIT was enabled at built-time, not whether it‚Äôs currently running (e.g. has been disabled at runtime). It is possible to check at runtime whether the JIT is enabled, but it‚Äôs a bit more tricky. Here‚Äôs a script you can use to figure it out (taken from the <a href="https://discuss.python.org/t/pep-744-jit-compilation/50756/53">PEP 744 discussion page</a>)[^jit-deps]:</p>
<div><figure><pre data-language="python"><code><div><div><p>1</p></div><p><span>import</span><span> _opcode</span></p></div><div><div><p>2</p></div><p><span>import</span><span> types</span></p></div><div><p>3</p></div><div><p>4</p></div><div><div><p>5</p></div><p><span>def</span><span> </span><span>is_jitted</span><span>(f: types.FunctionType) -&gt; </span><span>bool</span><span>:</span></p></div><div><div><p>6</p></div><p><span>    </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>0</span><span>, </span><span>len</span><span>(f.</span><span>__code__</span><span>.co_code), </span><span>2</span><span>):</span></p></div><div><div><p>7</p></div><p><span>        </span><span>try</span><span>:</span></p></div><div><div><p>8</p></div><p><span><span>            </span></span><span>_opcode.get_executor(f.</span><span>__code__</span><span>, i)</span></p></div><div><div><p>9</p></div><p><span>        </span><span>except</span><span> </span><span>RuntimeError</span><span>:</span></p></div><div><div><p>10</p></div><p><span>            </span><span># This isn't a JIT build:</span></p></div><div><div><p>11</p></div><p><span>            </span><span>return</span><span> </span><span>False</span></p></div><div><div><p>12</p></div><p><span>        </span><span>except</span><span> </span><span>ValueError</span><span>:</span></p></div><div><div><p>13</p></div><p><span>            </span><span># No executor found:</span></p></div><div><div><p>14</p></div><p><span>            </span><span>continue</span></p></div><div><div><p>15</p></div><p><span>        </span><span>return</span><span> </span><span>True</span></p></div><div><div><p>16</p></div><p><span>    </span><span>return</span><span> </span><span>False</span></p></div><div><p>17</p></div><div><p>18</p></div><div><div><p>19</p></div><p><span>def</span><span> </span><span>fibonacci</span><span>(n):</span></p></div><div><div><p>20</p></div><p><span><span>    </span></span><span>a, b </span><span>=</span><span> </span><span>0</span><span>, </span><span>1</span></p></div><div><div><p>21</p></div><p><span>    </span><span>for</span><span> _ </span><span>in</span><span> </span><span>range</span><span>(n):</span></p></div><div><div><p>22</p></div><p><span><span>        </span></span><span>a, b </span><span>=</span><span> b, a </span><span>+</span><span> b</span></p></div><div><div><p>23</p></div><p><span>    </span><span>return</span><span> a</span></p></div><div><p>24</p></div><div><p>25</p></div><div><div><p>26</p></div><p><span>def</span><span> </span><span>main</span><span>():</span></p></div><div><div><p>27</p></div><p><span><span>    </span></span><span>fibonacci(</span><span>100</span><span>)</span></p></div><div><div><p>28</p></div><p><span>    </span><span>if</span><span> is_jitted(fibonacci):</span></p></div><div><div><p>29</p></div><p><span>        </span><span>print</span><span>(</span><span>"JIT enabled üöÄ"</span><span>)</span></p></div><div><div><p>30</p></div><p><span>    </span><span>else</span><span>:</span></p></div><div><div><p>31</p></div><p><span>        </span><span>print</span><span>(</span><span>"Doesn't look like the JIT is enabled ü•±"</span><span>)</span></p></div><div><p>32</p></div><div><p>33</p></div><div><p>34</p></div><div><div><p>35</p></div><p><span>if</span><span> </span><span>__name__</span><span> </span><span>==</span><span> </span><span>"__main__"</span><span>:</span></p></div><div><div><p>36</p></div><p><span><span>    </span></span><span>main()</span></p></div></code></pre></figure></div>
<p>The PEP 744 discussion has mention of both <code>PYTHON_JIT=0/1</code> and <code>-X jit=0/1</code> ‚Äì I did not find that the <code>-X</code> option did anything at all, but the environment variable seems to do the trick.</p>
<div><figure><pre data-language="shell"><code><div><div><p>1</p></div><p><span>$</span><span> </span><span>python</span><span> </span><span>is-jit.py</span></p></div><div><div><p>2</p></div><p><span>JIT</span><span> </span><span>enabled</span><span> </span><span>üöÄ</span></p></div><div><div><p>3</p></div><p><span>$</span><span> </span><span>PYTHON_JIT=</span><span>0</span><span> </span><span>python</span><span> </span><span>is-jit.py</span></p></div><div><div><p>4</p></div><p><span>Doesn</span><span>'t look like the JIT is enabled ü•±</span></p></div></code></pre></figure></div>
<p>[^jit-deps] I also found a few people online talking about how you could use <code>sysconfig.get_config_var("JIT_DEPS")</code> but I did not found that this worked at all for me.</p>
<a href="#conclusion">#</a><h2 id="conclusion">Conclusion</h2>
<p>Python 3.13 is a big release in introducing some exciting new concepts and features to the runtime. It‚Äôs unlikely to make any immediate different to how you write and run your Python, but it‚Äôs likely that over the next few months and years as both free-threading and JIT become more mature and well established, they‚Äôll begin to have more and more of an impact on the performance profile of Python code, particularly for CPU-bound tasks.</p>
<a href="#further-reading">#</a><h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="https://peps.python.org/pep-0703/">PEP 703 ‚Äì Making the Global Interpreter Lock Optional in CPython</a></li>
<li><a href="https://py-free-threading.github.io/">py-free-threading</a></li>
<li><a href="https://tonybaloney.github.io/posts/python-gets-a-jit.html">Python 3.13 gets a JIT ‚Äì Anthony Shaw</a></li>
<li><a href="https://peps.python.org/pep-0744/">PEP 744 ‚Äì JIT Compilation</a></li>
<li><a href="https://discuss.python.org/t/pep-744-jit-compilation/50756">Discuss ‚Äì PEP 744: JIT Compilation</a></li>
</ul>
<section data-footnotes=""><a href="#footnote-label">#</a>
<ol>
<li id="user-content-fn-font-rendering">
<p>Font rendering is a fascinating topic and that immensely complex. Trust me, however complicated you think font rendering is, it‚Äôs more complicated that that. IIRC most of the complexity actually comes from nicely drawing text at small resolutions. For instance, in TrueType both a whole font and individual glyphs have instructions associated with them which are executed by the FontEngine virtual machine a.k.a. interpreter. If this is something you‚Äôre interested in learning more about, I highly recommend Sebastian Lague‚Äôs video ‚Äì <a href="https://www.youtube.com/watch?v=SO83KQuuZvg&amp;pp=ygUOZm9udCByZW5kZXJpbmc%3D">Coding Adventure: Rendering Text</a>. He makes really great videos. The <a href="https://developer.apple.com/fonts/TrueType-Reference-Manual/RM02/Chap2.html#how_works">TrueType reference</a> is also surprisingly readable. <a href="#user-content-fnref-font-rendering" data-footnote-backref="" aria-label="Back to reference 1">‚Ü©</a></p>
</li>
<li id="user-content-fn-apple-sponsorship">
<p>Apple aren‚Äôt even paying me to say this stuff, it‚Äôs just true. <a href="#user-content-fnref-apple-sponsorship" data-footnote-backref="" aria-label="Back to reference 2">‚Ü©</a></p>
</li>
</ol>
</section>   </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If WordPress is to survive, Matt Mullenweg must be removed (230 pts)]]></title>
            <link>https://joshcollinsworth.com/blog/fire-matt</link>
            <guid>41676653</guid>
            <pubDate>Fri, 27 Sep 2024 23:49:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshcollinsworth.com/blog/fire-matt">https://joshcollinsworth.com/blog/fire-matt</a>, See on <a href="https://news.ycombinator.com/item?id=41676653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" tabindex="-1"><article><img src="https://joshcollinsworth.com/images/post_images/beatings.webp" alt="" width="1920" height="1388">

		

		<p><b>Published:</b>
			September 27, 2024
			</p>

		
		<div><p>This post is a little more hasty than some of my others, in the interest of expedience. I hope you‚Äôll bear with the poorly edited jumble of thoughts. It‚Äôs being actively edited. I also usually avoid cussing on my blog, but I do a little here because it feels warranted.</p>
<p>Cover image from <a href="https://www.etsy.com/listing/1341940035/the-beatings-will-continue-until-morale" rel="nofollow">this Etsy store</a> (unaffiliated).</p></div>
<p>There are some people who think being right about something gives them the right to do whatever they think should be done about it; a license to act however they see fit in order to correct that wrong.</p>
<p>This, of course, is never the case. Doing the wrong thing for the right reason never makes it the right thing. No matter how bad the original infraction, there are some responses it never justifies. Two wrongs don‚Äôt make a right, to be pithy about it. The ends don‚Äôt justify‚Ä¶you know how it goes.</p>
<p>Matt Mullenweg appears to be one of those people who believe the ends do indeed justify the means, as he‚Äôs effectively blowing up massive swaths of the WordPress community in his fight with some of its landlords.</p>
<p>Matt has, for far too long, enjoyed unchecked powers at the top of WordPress‚Äîpowers which are all too often a direct and flagrant conflict of interest. And while we‚Äôve seen this power abused before, we‚Äôve never seen it on this scale.</p>
<p>Yes, Matt‚Äôs original point <em>might</em> be warranted. But his egregious actions utterly nullify any previous merit.</p>
<p>A line has been crossed, and the entire community is worse for it.</p>


<p>I believe that if WordPress is to survive, let alone thrive, Matt Mullenweg must be removed from all forms of official WordPress leadership, as expediently as possible.</p>

<h2 id="wait-who-are-you-and-why-do-you-care">Wait, who are you and why do you care?</h2>
<p>Let‚Äôs get this out of the way right off: I‚Äôm not the best person to be talking about this. I haven‚Äôt really been involved in WordPress for about five years now. Honestly, I couldn‚Äôt tell you the last time I even logged in to a WordPress site.</p>
<p>That said, however: I spent some six or seven years of my life deep in the WordPress world. I built and customized WordPress sites for clients as a designer; I taught a WordPress development course (focused on building custom themes in PHP) for about five years; and I worked in support for Flywheel, a managed WordPress hosting company, for a little over five years. It was there I transitioned to full-time frontend work, building tools to help support WordPress sites.</p>
<p>So while I‚Äôve been out of the WordPress game for a good while now, I still might be considered an expert next to your average Joe. I‚Äôd like to think I could still sling some theme templates with the best of ‚Äòem. (Hell, some days I even get a little nostalgic and think about booting up a Local site just for fun.)</p>
<p>You might have spotted the word ‚ÄúFlywheel‚Äù up there and realized that company was acquired by WP Engine‚Äîthe company with which Mullenweg is publicly feuding at the moment‚Äîback in 2019. That might reasonably raise questions of my objectivity, so let‚Äôs get this out of the way:</p>
<p>Yes, I used to work for WP Engine. I even kinda liked them, for a while (mostly while they just kinda left us alone for the first year or so). But I wouldn‚Äôt say my time at the company left a good taste in my mouth.</p>
<p>We don‚Äôt need to dredge up a bunch of old and buried stuff that isn‚Äôt really important anyway, but suffice to say: I really don‚Äôt have any reason to be a WP Engine cheerleader. Most of the people I knew there have left, and I‚Äôve watched from the sidelines as the company has implemented a bunch of scummy policies and shady sales tactics to squeeze money from their customers and make it harder to leave.</p>
<p>On most days, if you wanted to have a conversation about how much WP Engine sucks, frankly, I‚Äôd be a happy participant.</p>
<p>So this post might be a lot of things, but I can assure you it‚Äôs <em>not</em> me defending my old company just because I used to work for them. I‚Äôve got literally no reason to do that.</p>


<p>To the extent I‚Äôm on WP Engine‚Äôs side, it‚Äôs not because of any sense of loyalty to the company or to the remaining good people I know there; it‚Äôs because I believe what Matt‚Äôs doing is deeply wrong and foolishly destructive.</p>

<p>I‚Äôll also go on record as saying I got pretty far in the interview process at Automattic once, a few years back. And, since we‚Äôre being honest, it was the absolute <em>worst</em> interview process I‚Äôve ever taken part of as a web professional (though the people themselves were lovely). But that alone ain‚Äôt gonna get a post out of me. I‚Äôm not wasting my time and yours just to gripe about an interview I chose to drop out of over three years ago. Just thought it merited a mention.</p>
<p>I still regarded Matt Mullenweg himself pretty highly after that, up until the last year or so. This post isn‚Äôt long enough to get into the details, but Matt had already become a pretty ‚Äúproblemattic‚Äù character well before any of this went down.</p>
<p>So in summary: I‚Äôm not a big fan of either party, and I don‚Äôt have any good reason to side with either one of them.</p>
<p>I <em>am</em>, however, somebody who still cares deeply about WordPress. It‚Äôs what gave me my start, and I still recommend it to a lot of people when they ask me what system might best suit their needs.</p>
<p>It‚Äôs a wonderful community, all in all, and despite my inactivity, I still feel invested in WordPress, and interested in seeing it continue to be a productive way to democratize the web.</p>
<p>Finally: I am not a lawyer, and since it‚Äôs Friday now and this feud had already reached lawyers-involved level by Monday morning, I should be careful to clarify any legal commentary here is expressly my personal, non-expert opinion.</p>
<h2 id="im-sorry-what-happened">I‚Äôm sorry, what happened?</h2>
<p>For those of you who haven‚Äôt been following the story thus far (read: aren‚Äôt chronically online web nerds like me), let‚Äôs hit the highlights.</p>
<h3 id="automattic-approaches-wp-engine-to-offer-a-license">Automattic approaches WP Engine to offer a ‚Äúlicense‚Äù</h3>
<p>Sometime in or around July of this year, <a href="https://automattic.com/" rel="nofollow">Automattic</a> (Matt Mullenweg‚Äôs for-profit company, which owns, among other things, <a href="https://wordpress.com/" rel="nofollow">WordPress.com</a>, a major WordPress hosting company) reached out to <a href="https://wpengine.com/" rel="nofollow">WP Engine</a> (also a for-profit company that offers WordPress hosting, and probably Automattic‚Äôs largest business rival).</p>
<p>Automattic was offering WP Engine some kind of ‚Äúlicensing,‚Äù at a rate of 8% of total business revenue, adding up to the eye-popping sum of several million dollars per year.</p>
<p>WP Engine apparently turned down this offer, presumably because <em>it doesn‚Äôt appear they actually need any license</em>. The term ‚ÄúWP‚Äù is explicitly not covered by the <a href="https://wordpressfoundation.org/trademark-policy/" rel="nofollow">WordPress trademark policy</a>, and using the term ‚ÄúWordPress‚Äù to describe products and services (e.g., calling yourself a ‚ÄúWordPress specialist,‚Äù or saying you offer ‚ÄúWordPress hosting‚Äù) is fully allowed, according to the policy.</p>
<p>They‚Äôve also been in business for like 15 years now, and somehow none of this has come up before.</p>
<p>Besides, I could name dozens of companies just off the top of my head also using one or both of those terms. So the ‚Äúyou need a license to say this‚Äù argument seems highly targeted and extremely dubious.</p>
<h3 id="matts-rejected-so-he-tries-new-strategies">Matt‚Äôs rejected, so he tries new strategies</h3>
<p>Immediately following WP Engine‚Äôs rejection, <a href="https://wordpressfoundation.org/" rel="nofollow">the WordPress Foundation</a> (the nonprofit that governs WordPress, the open source software, and which Matt Mullenweg <em>also</em> runs, in effect if not nominally) <a href="https://www.searchenginejournal.com/wordpress-files-to-trademark-managed-wordpress-hosted-wordpress/528112/" rel="nofollow">filed to trademark the terms ‚ÄúManaged WordPress‚Äù and ‚ÄúHosted WordPress</a>.‚Äù</p>
<p>Neither trademark has been granted at this point, nor should they; they‚Äôve been in use for ages, and are obviously far too generic for any one organization to hold.</p>
<p>Most reasonable and knowledgeable people seem to share this opinion. Companies have been describing themselves as one or both of those terms for around 15 years at this point. (We freely called Flywheel a ‚Äúmanaged WordPress hosting company‚Äù the entire time I worked there, and we were far from the first. We were also at one point one of WordPress.org‚Äôs recommended hosts. So‚Ä¶obviously, not a big deal.)</p>
<p>Anyway, this filing of spurious trademarks makes it appear very much like Matt‚Äôs endgame was to extract money from WP Engine, but he just needed more of a foundation to do it (pun intended?). So, following that initial rejection, Matt set the Foundation arm of WordPress working on securing highly dubious trademarks, which, again, I and most reasonable observers think and hope will fail.</p>
<p>Meanwhile, Matt <em>also</em> began sending a series of very apparently extortive messages to WP Engine leadership, essentially demanding they pay up or else. (This is all in <a href="https://wpengine.com/wp-content/uploads/2024/09/Cease-and-Desist-Letter-to-Automattic-and-Request-to-Preserve-Documents-Sent.pdf" rel="nofollow">WP Engine‚Äôs letter to Automattic</a>, which I‚Äôm getting to, but which comes later in the story.)</p>
<p>All of this was in the run-up to <a href="https://us.wordcamp.org/2024/" rel="nofollow">WordCamp US</a>, the largest WordPress event of the year, at least in North America. (Of note: WP Engine <a href="https://us.wordcamp.org/2024/sponsors/" rel="nofollow">sponsored this event</a> at the highest level, as did WordPress.com.)</p>
<p>Matt let WP Engine leadership know, via private DMs, that he intended to ‚Äúgo nuclear‚Äù and ‚Äúscorched earth‚Äù on WP Engine in his keynote at the conference‚Äîthat is, if WP Engine failed to acquiesce to his monetary demands, i.e., 8% of total revenue, i.e., tens of millions of dollars. It appears he repeated the ‚Äújust pay up and I‚Äôll make this all go away‚Äù offer up to the literal last minute before he went on stage.</p>


<p>Let‚Äôs not beat around the bush: words like ‚Äúthreat‚Äù and ‚Äúextortion‚Äù very much apply to Matt‚Äôs behavior here.</p>

<p>Again: this demand was ostensibly in exchange for a ‚Äúlicense‚Äù to use terms like ‚ÄúWordPress,‚Äù ‚ÄúWordPress hosting,‚Äù ‚ÄúWooCommerce,‚Äù etc.‚Äînone of which appear to be actually necessary.</p>
<p>The only <em>possible</em> exception seems to be ‚ÄúWooCommerce,‚Äù which <em>is</em> a trademark (and product/company) owned by Automattic. However, the lines are very blurry on what is and is not permissable when it comes to using the WooCommerce name. WP Engine does indeed call one of its offerings ‚ÄúWooCommerce hosting,‚Äù which is explicitly called out in the guidelines. So I don‚Äôt know, <em>maybe</em> there‚Äôs validity there. <em>Maybe</em>.</p>
<p>However, for one thing, it‚Äôs hard to know whether, or how much the trademark guidelines might have changed. Matt made several changes to the WordPress license page in the last week, among other things, to call out WP Engine. That makes me not trust that the WooCommerce license page I‚Äôm looking at today is the same as it was last week‚Äîwhich, all on its own, should be setting off raging alarms for even the most casual of observers. It‚Äôs extremely bad news when the company you‚Äôre doing business with can just decide what the new terms are with no warning or recourse.</p>
<p>Anyway, Matt keeps sending the DMs all the way up until the literal last minute, offering <em>not</em> to excoriate WP Engine onstage during his keynote at the country‚Äôs (continent‚Äôs? world‚Äôs?) largest WordPress event, provided they simply pay up.</p>
<p>Once more: I‚Äôm no lawyer, but I‚Äôm pretty sure that‚Äôs called extortion.</p>
<p>WP Engine says no (actually, they ask for more time, which Matt denies and takes as a no), so he proceeds with operation ‚Äúscorched earth,‚Äù and blasts WP Engine both onstage at WordCamp US, and in several other venues.</p>
<h3 id="waitwhats-matts-actual-deal-why-is-he-doing-this">Wait‚Äîwhat‚Äôs Matt‚Äôs actual deal? Why is he doing this?</h3>
<p>Aside from the licensing issue, which I covered above (and which seems like a mostly flimsy premise to me), Matt‚Äôs got some other complaints with WP Engine. Some have validity, some seem completely made-up. Let‚Äôs walk through them.</p>
<h4 id="matt-claims-wp-engine-is-misrepresenting-itself">Matt claims WP Engine is misrepresenting itself</h4>
<p>Among Matt‚Äôs complaints: that WP Engine is ‚Äúmisrepresenting‚Äù itself as an entity that‚Äôs officially affiliated with and/or endorsed by WordPress itself. Matt‚Äôs repeatedly used as an example his own mom‚Äôs confusion; she apparently thought WP Engine was somehow affiliated with WordPress.com (I guess because they also use the word ‚ÄúWordPress,‚Äù and are maybe a vaguely similar shade of blue).</p>


<p>I‚Äôm sure it‚Äôs frustrating, having taken over half the internet and being worth hundreds of millions of dollars, only to find out your own mom <em>still</em> doesn‚Äôt really understand what you do, but: come on, bro.</p>

<p>First, <em>tons</em> of companies use ‚ÄúWP‚Äù in their names, and/or the names of their products. Why isn‚Äôt Matt going after them?</p>
<p>Second, as many people have already noted: Matt effectively runs both <code>wordpress.com</code> <em>and</em> <code>wordpress.org</code>, which are entirely separate entities that do two completely different things. You wanna tell me <em>that‚Äôs</em> clear, but somehow WP Engine and WordPress.com are too similar? Really?</p>
<p>Third, my kindergartner and every kid in his class could tell the difference between the WordPress W and WP Engine‚Äôs dumb logo. (WP Engine‚Äôs logo has always been a grid of weird, almost-square shapes that‚Äôs apparently meant to vaguely resemble an engine, but which makes no sense to pretty much anyone who‚Äôs ever seen it, far as I can tell. It‚Äôs a bad logo, in my professional opinion as a designer, even the slightly better version they just released recently. But I digress. Point is: it looks literally nothing like any WordPress logo. Also: it‚Äôs not the same color. I have color vision deficiency, and even <em>I</em> can tell that.)</p>
<p>Finally, for the whole two years I worked for Shopify, most of my family thought I was at Spotify. Now I‚Äôm at Deno, and nobody in my family has any clue what a JavaScript runtime is, and my dad basically thinks I work for Java.</p>
<p>Family members don‚Äôt always get tech. That‚Äôs not a sign that something is wrong, and it‚Äôs most <em>certainly</em> not a sign that any wrongdoing has been committed, let alone deliberately. (Which, I assume, probably wasn‚Äôt Matt‚Äôs mom‚Äôs point to begin with, but that didn‚Äôt stop him from running with it.)</p>
<h4 id="matt-claims-wp-engine-is-selling-a-cheap-knock-off-of-wordpress">Matt claims WP Engine is selling a ‚Äúcheap knock-off‚Äù of WordPress</h4>
<p>Matt also claims WP Engine is selling ‚Äúsomething that they‚Äôve chopped up, hacked, butchered to look like WordPress.‚Äù His reason for this wild claim? Because WP Engine disables revisions (a default feature of WordPress, albeit a pretty small one).</p>
<p>Literally, that‚Äôs it. One tiny feature. The whole thing‚Äôs been ‚Äúhacked and butchered‚Äù because they just chose to modify one tiny detail.</p>
<p>Of all Matt‚Äôs spurious claims, this one might be the one that reeks the most of absolute made-up bullshit. WP Engine will just turn on revisions if you want them to, but that‚Äôs beside the point.</p>
<p>First, if I decide to build something with, say, Laravel, but decide there‚Äôs one feature I want to turn off, I‚Äôm not ‚Äúhacking and butchering‚Äù Laravel. That‚Äôs obviously ridiculous.</p>
<p>Second, pretty much all hosts limit revisions in some way or another anyway, because they take up a ton of memory and most people don‚Äôt really need them that bad.</p>
<p>And third, <em>it‚Äôs open-source software</em>! You don‚Äôt get to tell people how they use it!</p>
<p>We could also get into the utter hypocrisy that many of WordPress.com‚Äôs plans do far, far, <em>far</em> more invasive modifications of WordPress core (<em>you can‚Äôt even install themes and plugins, FFS!</em>), but again, that‚Äôs all beside the point. It‚Äôs open-source. They can do that. Anyone can. It‚Äôs in the license. This claim is clearly total garbage.</p>
<h4 id="matt-says-wp-engine-doesnt-give-back-enough">Matt says WP Engine doesn‚Äôt give back enough</h4>


<p>Matt‚Äôs other complaint‚Äîand I think this is what everything else really boils down to‚Äîis: WP Engine doesn‚Äôt give back enough to WordPress, in Matt‚Äôs estimation.</p>

<p>Matt showed some numbers onscreen at WCUS, comparing Automattic‚Äôs contributions to WP Engine‚Äôs. But I‚Äôm not going to repeat them because I‚Äôm certain they‚Äôre distorted. Besides, I‚Äôm not sure the two companies‚Äô work can, or <em>should</em>, be considered directly comparable in the first place. They do different things in different ways, and there‚Äôs no law or license mandating either of them do anything to begin with.</p>
<p>Regardless, Matt seems irked that WP Engine isn‚Äôt abiding by the <a href="https://wordpress.org/five-for-the-future" rel="nofollow">‚ÄúFive for the Future‚Äù program, outlined on WordPress.org</a>. Five for the Future asks that if you benefit from WordPress, you give back 5% of your time directly to that open-source project, which I think pretty much everyone can agree is a very noble and admirable aspiration that companies such as these involved <em>should</em> probably be doing.</p>
<p>But it‚Äôs not a requirement, or a policy, and enforcing it as such‚Äîacting unilaterally as the WordPress police, let alone so suddenly and violently‚Äîis extremely questionable and deeply troubling. (Not to mention a likely deterrent for people and organizations who might want to participate in the WordPress space.)</p>
<p>Matt‚Äôs claimed he/Automattic have been soliciting WP Engine for increased contributions for ‚Äúyears,‚Äù and that they‚Äôve given ‚Äú$0‚Äù to the WordPress foundation. To the best of my knowledge, neither of those claims has been substantiated, but I suppose they don‚Äôt really change this discussion much either way, because again: Matt‚Äôs taken it upon himself to act as the WP PD to enforce a law that isn‚Äôt even a law.</p>
<p>So that‚Äôs it; that‚Äôs what Matt‚Äôs mad about. There‚Äôs <em>some</em> substance there, and in a vacuum, I think he‚Äôd probably have a lot of people on his side.</p>
<p>But we‚Äôre not in a vacuum; there‚Äôs a lot of context here. So I‚Äôd like to talk about that next.</p>
<h3 id="an-aside-on-motivations-and-justifications">An aside on motivations and justifications</h3>
<p>Having explored Matt‚Äôs complaints, I‚Äôd like to pause for a moment, because this is where the sides seems to diverge.</p>
<p>The relatively small number of people in the community who appear to remain on Matt‚Äôs side (which seems to be mostly made up of his own employees and some people with their own reasons for hating WP Engine) appear to be sticking with him because they agree with <em>this</em> core point, i.e.: WP Engine should be doing more‚Äîmaybe much more‚Äîespecially considering that they‚Äôre a company owned by private equity and making significant money off WordPress.</p>
<p><strong>On its own, I think that claim seems perfectly fair</strong>. We could disagree about the details, or how much is too much or too little, but I don‚Äôt think it‚Äôs unreasonable to say a company the size and profitability of WPE probably owes quite a lot to the open-source software it‚Äôs built on (ethically, at least; likely not legally).</p>


<p>So it bears mentioning that WP Engine actually <em>does</em> do a pretty good deal for WordPress. You can cherry-pick specific ways it hasn‚Äôt contributed much, and you could certainly make a reasonable case they should be doing more. But to say they‚Äôve given ‚Äú$0‚Äù strikes me as pretty deliberately misleading.</p>

<p>WP Engine pays several staff members to contribute work hours to WordPress core (again, maybe the number should be greater than it is, but it‚Äôs definitely not zero), on top of the full-time maintenance of plugins, themes, and apps like Advanced Custom Fields, WP Migrate, WP GraphQL, Genesis, Local WP, and many others‚Äîall of which used by countless thousands of WordPress users every day.</p>
<p>This is to say nothing of WP Engine sponsoring of WordCamps, creating their own tutorials and educational material, their own events, and so on and so forth.</p>
<p>Point is: WP Engine <em>does</em> do a lot more than zero. You could argue those contributions are not ‚Äúpure‚Äù (Matt does), and that they‚Äôre ultimately in service to WP Engine, and not the WordPress community.</p>
<p>But in fairness: sure, they‚Äôre all marketing tools in some form or another, but you don‚Äôt <em>have</em> to pay for any of them. They all get maintained, they all have tons of users both on and off WP Engine, and they all work no matter what host you choose. (I‚Äôm sure they‚Äôre all used on WordPress.com. I‚Äôd even use some of those things if I had to spin up a WordPress site tomorrow, even if I probably wouldn‚Äôt host on WP Engine, personally. I‚Äôd probably choose <a href="https://spinupwp.com/" rel="nofollow">SpinupWP</a>, myself, which is another company with ‚ÄúWP‚Äù in the name that Matt apparently doesn‚Äôt care about.)</p>
<p>Besides, Matt‚Äôs company does exactly the same thing with Jetpack, which charges $5‚Äì$50 per month, depending on tier, so‚Ä¶not sure where that moral high ground is supposed to be coming from. Is Automattic really gonna claim Jetpack‚Äôs paid features are purely for the altruistic benefit of the community? Why do <em>they</em> get a pass on paid features?</p>
<p>I think you could fairly, if crudely, paraphrase Matt‚Äôs argument as: ‚ÄúWP Engine is in it for the money, and we are in it for WordPress.‚Äù</p>
<p>That‚Äôs a really flimsy stance in my view, without even getting into whether we can, or should, have exactly the same expectations of both companies in the first place (which is at least questionable; Automattic has their hands in a lot more things than WP Engine does, including Tumblr, PocketCasts, Longreads, and many others things that may or may not be related to WordPress, along with at least two hosting companies).</p>
<p>Still, once more: there‚Äôs probably <em>some</em> validity there. WP Engine is a big company that makes lots of money, and it probably can and should do more.</p>


<p><em>Matt could‚Äôve made that point</em>. I think most people would‚Äôve agreed with him, if he had gone about it properly. We‚Äôd probably be lining up with him. There was a way to rally the community around this.</p>

<p><em>If</em> Matt Mullenweg had done this the right way.</p>
<p>But Matt, being Matt, <em>didn‚Äôt</em> make that point in a good way.</p>
<p>(Sorry, this post is already too long without me going into all the times in the past he‚Äôs stirred up drama and just generally been a toxic jerk to undeserving people in the WordPress community. But if you‚Äôre not aware: it‚Äôs become increasingly common. He was even adding public snarky comments on WP Engine employees‚Äô posts, ones who had given decades of their life to the project, as recently as yesterday.)</p>


<p>Matt tried extortion, and threats, and petty, childish tantrums, and when none of that worked, he fully exercised his unmatched and unchecked powers in an inconscionable way, in order to extract millions of dollars from WP Engine to put in his own for-profit competitor‚Äôs bank account.</p>

<p>But I‚Äôm getting ahead of myself.</p>
<p>So that‚Äôs the core of this whole thing; Matt thinks private equity is ruining everything and taking too much without giving enough back. It‚Äôs an easy home run of a point to make in this economy. Pretty much nobody disagrees with that.</p>
<p>Maybe he thought he‚Äôd come off like Robin Hood in this whole deal. I don‚Äôt know. But if there was a way to tactfully and gracefully thread that needle, it wasn‚Äôt the rampaging hippopotamus approach Matt took.</p>
<p>The split in the community seems to lie in whether that core point <em>justifies</em> Matt‚Äôs actions.</p>
<p>It seems to me that most people agree it does <em>not</em>; that Matt‚Äôs committed too many flagrant fouls of his own for the original infraction to matter.</p>


<p>Matt had a problem with the landlords, so he carpet bombed the neighborhood. He didn‚Äôt like Alderaan‚Äôs leaders, and so he fired the Death Star. And now it doesn‚Äôt really matter what his original point was; he‚Äôs made himself the bad guy.</p>

<p>Anyway, back to the timeline. (Note: I may have the chronology slightly mixed up here on a few of the points, but I don‚Äôt think it should really matter.)</p>
<h3 id="the-wordcamp-us-fallout-and-matts-abuse-of-power">The WordCamp US fallout and Matt‚Äôs abuse of power</h3>
<p>At some point in this chaos (during his keynote at WCUS, or shortly after), Matt used his sway over every branch of power in the WordPress government to write a blog post called ‚Äù<a href="https://wordpress.org/news/2024/09/wp-engine/" rel="nofollow">WP Engine is not WordPress</a>,‚Äù (which isn‚Äôt something anybody seems to have been confused about, except of course Matt‚Äôs mom).</p>
<p>That post, crucially, went up on WordPress.org, which on its own seems questionable. WordPress.org is ostensibly the website for the nonprofit foundation; it‚Äôs supposed to exist to <em>prevent</em> any one for-profit company from having too much power over the WordPress ecosystem. It‚Äôs supposed to be agnostic.</p>
<p>Not only was that boundary ignored, but since the post was published as WordPress news, it was then <em>syndicated to each and every WordPress admin dashboard in the world</em>.</p>
<p>Forget for a second whether you agree with Matt or not; we‚Äôre getting into some of the worst of the conflicts of interest and abuses of power here.</p>
<p>This type of maneuver, plainly, is anti-competitive. It‚Äôs a flagrant exploitation of Matt‚Äôs many roles and the wild control he has over many branches of WordPress, many with conflicting priorities.</p>
<p>It‚Äôs bullying, really; WP Engine doesn‚Äôt have any tools to strike back like that. It can‚Äôt. (Maybe it <em>wouldn‚Äôt</em>, since to date, WP Engine appears to be the company with grown-ups in the room, who know to behave as though their actions will be examined in a courtroom one day.)</p>


<p>This would be like Meta one day deciding it didn‚Äôt like how a competitor was using React, and serving every single Facebook user a story on their home feed, brutally disparaging that competitor. It‚Äôs <em>clearly</em> a dramatic overreach.</p>

<p>I think Matt <em>thought</em> WP Engine had no retaliation. I think he was <em>counting</em> on this maneuver being yet another push towards their eventual acquiescence. But I guess it doesn‚Äôt matter; that‚Äôs just my speculation.</p>
<p>In any case, Matt wasn‚Äôt done. Matt went on flexing (read: abusing) his power by updating the <a href="https://wordpressfoundation.org/trademark-policy/" rel="nofollow">WordPress trademark policy</a> to <em>retroactively disincentivize the use of the term ‚ÄúWP‚Äù in titles of products and companies</em>. (<a href="https://www.reddit.com/r/Wordpress/comments/1foknoq/the_wordpress_foundation_trademark_policy_was/" rel="nofollow">Here‚Äôs the source on that change.</a>)</p>
<p>You know why you constantly get notifications saying ‚Äúwe‚Äôve updated our terms‚Äù? Because you legally <em>have</em> to do that. To just change the terms without letting people know is shady at best, and actively malicious at worst.</p>
<p>Well, Matt just went in and changed the terms.</p>


<p>Altering the WordPress trademark policy is yet another abuse that should make any remotely impartial observer shudder. Why would anyone want to use a software with an oligarch dictating the terms, and changing them on a whim, with no warning?</p>

<p>It‚Äôs around this point in the story Matt is really losing the plot. His whole complaint with WP Engine is that they‚Äôre not helping WordPress enough.</p>
<p>But yet‚Ä¶he‚Äôs burning WordPress to the ground to make that point.</p>
<h3 id="wp-engines-reaction">WP Engine‚Äôs reaction</h3>
<p>Following all this, WP Engine‚Äîquite understandably‚Äîdoesn‚Äôt really care for all of their users seeing that negative messaging in their wp-admin. So, WP Engine finds a way to block the news feed on WP Engine sites.</p>
<p>That would be questionable in a vacuum, to be sure. But we‚Äôre steeped in context at this point. (A lot of users either turn it off or ignore it on their own anyway, for what it‚Äôs worth.)</p>
<p>Following WordCamp US, WP Engine <em>also</em> sent a <a href="https://wpengine.com/wp-content/uploads/2024/09/Cease-and-Desist-Letter-to-Automattic-and-Request-to-Preserve-Documents-Sent.pdf" rel="nofollow">cease-and-desist</a> to Automattic. It‚Äôs pretty damning, and does a good job laying out all the points I tried to cover above. (In short: Matt tried to extort money from WP Engine for spurious licensing claims, and used disinformation, or at least heavily slanted data, to do it.)</p>


<p>One of the biggest revelations here is: Matt wanted the money he was trying to get from WP Engine to go <em>to Automattic</em>, which, again, is Matt‚Äôs for-profit company.</p>

<p>There are some pretty obvious conflicts of interest here. First and foremost, Automattic (or WordPress.com, at least) is a direct competitor of WP Engine‚Äôs.</p>
<p>Second, while Automattic <em>does</em> apparently own the WooCommerce copyright, it does <em>not</em> own the WordPress copyright. That is owned by the WordPress Foundation.</p>
<p>But it gets even murkier from there, as the Foundation is maybe (or maybe not) WordPress.org? And either way, the Foundation is apparently three people, and Matt Mullenweg is not only one of them, he appears to be <em>the only active one</em>!</p>
<p>Of the other two board members, one is a blogger whose company Matt bought out, and who apparently is no longer in the industry. The other is apparently a Partner and Managing Director at‚Äîsurprise!‚Äî<em>a private equity firm</em> (not to mention a twice-failed Republican politician).</p>
<p>Wait‚Ä¶isn‚Äôt private equity bad? I guess not if it‚Äôs on Matt‚Äôs side. (For the record, Matt and his companies are tied up in private equity in other, more substantial ways than this, but that‚Äôs not worth getting into. It‚Äôs all pretty hypocritical.)</p>


<p>It appears neither of the other two Foundation board members is active, and therefore, Matt is essentially, behind the curtains, the King, Prime Minister, and Pope when it comes to WordPress.</p>

<p>Nobody holds any ability to check his power or challenge him. (That‚Äôs very relevant to what happens next.)</p>
<p>Also: Matt apparently kinda sorta owns WordPress.org, too. So he has a dizzying interweaving of conflicts of interest and power abuses here. (<a href="https://www.pluginvulnerabilities.com/2024/09/24/who-is-on-the-wordpress-foundation-board/" rel="nofollow">Source for all that about the foundation here</a>.)</p>


<p>Let‚Äôs not leave unspoken the irony that the guy who basically <em>is</em> WordPress.com, <em>and</em> WordPress.org, <strong><em>and</em></strong> the WordPress Foundation, wants you to think the name ‚ÄúWP Engine‚Äù is confusing.</p>

<p>Anyway. <a href="https://automattic.com/2024/09/25/open-source-trademarks-wp-engine/" rel="nofollow">Automattic responded</a> by sending its own cease-and-desist to WP Engine, claiming mainly that WP Engine is deliberately confusing people, and that it owes licensing to‚Ä¶someone. Automattic, I guess, though the lines are so blurry it‚Äôs clear the separations between WordPress entities were only ever little more than a smokescreen.</p>
<hr>
<p><strong>I should mention: most people believe WordPress.com and WordPress.org/the Foundation are two (three!?) separate entities</strong>. I sure did, before this week. I thought the two had separated many years ago, with the express intent of preventing any one for-profit company from abusing the WordPress name.</p>
<p>I guess they technically are. But when one person apparently enjoys unchecked control over all of them‚Ä¶</p>
<p>[Guitar begins strumming with Alanis Morissette vocalizing]</p>
<h3 id="matt-melts-down">Matt melts down</h3>
<p>Two really weird things happened on Wednesday.</p>
<p>First, <em>out of nowhere</em>, Matt decides to <a href="https://ma.tt/2024/09/charitable-contributions/" rel="nofollow">publish a post on his personal blog</a> outlining his charitable donations. He really frames it as though he‚Äôs being victimized and bullied into revealing this information, and I suppose some people were probably (reasonably) asking how much <em>he</em> gives, since he spent the whole week blowing up half the internet over how much WP Engine gives.</p>
<p>In the post, he also spends a lot more time defending himself against claims of being a ‚Äúmafia boss‚Äù than most people who aren‚Äôt mafia bosses or acting like mafia bosses ever feel the need to do.</p>
<p>Weird move all around. Especially since the implication seems to be‚Ä¶what? ‚ÄúI‚Äôm a good guy so I can‚Äôt do bad things‚Äù?</p>
<p>I tried my best to look up Matt‚Äôs net worth and work out what percentage he‚Äôs giving, and by the best figures I could find, we‚Äôre likely at or below 5% here. (He‚Äôs said to be worth around $400 million, although that figure appears to be a little outdated‚Äîespecially since he may or may not have <a href="https://www.404media.co/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools/" rel="nofollow">sold a shitload of user data to AI companies earlier this year</a>.)</p>
<p>Which, fine, that‚Äôs still millions of dollars going to charity, and that‚Äôs objectively a good thing.</p>
<p>But also: if my wife and I gave that percentage of <em>our</em> income, it wouldn‚Äôt even be enough money to get a tax deduction for it. So it‚Äôs worth mentioning that just for scale. Contextually, Matt‚Äôs donating at below the standard deduction level for somebody of his net worth. (And, most likely, enjoying significant tax benefits for it.)</p>
<p>Anyway, no matter which way you look at it, that‚Äôs all weird, but it doesn‚Äôt even really matter in the case of this larger discussion. It has major ‚Äúoh yeah? Well would a bad guy do THIS?‚Äù energy.</p>
<p>You know‚Ä¶the sort of thing actual good guys don‚Äôt usually have to do.</p>
<p>Almost like Matt was trying to distract from something‚Ä¶</p>
<h3 id="matt-goes-nuclear">Matt goes nuclear</h3>
<p>The next move, and most recent development in this story, is still shocking to me. I think it should be shocking, and deeply disturbing, to <em>any</em> observer.</p>
<p><a href="https://techcrunch.com/2024/09/25/wordpress-org-bans-wp-engine-blocks-it-from-accessing-its-resources/" rel="nofollow">WordPress.org banned WP Engine sites from accessing the plugin repository</a>.</p>
<p>No more doing anything with plugins via the WordPress admin area. No installing, no updating. Not if you‚Äôre on WP Engine/Flywheel.</p>
<p>There are many layers to this.</p>
<p>First: again, this is the <code>.org</code> arm of WordPress enforcing this brutal new edict. The Organization, or Foundation, or <em>whatever</em>, is not <em>supposed</em> to be controlled solely by an oligarch who can bend it to their own will, to directly benefit their own interests. It‚Äôs <em>supposed</em> to be agnostic.</p>


<p>WordPress.org‚Äôs entire reason for existence, as I understood it (and I think as it was pitched to a lot of people), was explicitly to prevent things like this from happening.</p>

<p>Second: <em>not being able to update plugins is a <strong>massive</strong> deal</em>. You could very well be exposing your site to security vulnerabilities if plugins don‚Äôt update (to say nothing of bugs). There are nonprofits, charities, government agencies, and public services that host on WP Engine, on top of countless businesses. All of those are just being thrown under the bus to serve one man‚Äôs whims.</p>
<p>(<em>Yes,</em> it‚Äôs possible to manually update plugins, but nobody‚Äôs gonna do that. Certainly not the agencies and freelancers who oversee dozens or hundreds of sites on WP Engine.)</p>


<p>This is bombing civilians. This is putting innocent bystanders in harm‚Äôs way. This is firing the Death Star.</p>
<p>What Matt‚Äôs done is unforgivable, no matter how right he might have been at the beginning. To unleash harm on actual <em>users</em> of WordPress, indiscriminantly, solely over where they choose to host their sites, is an unconscionable, terroristic abuse of power.</p>

<p>(In the middle of all this, Pressable, a separate host Automattic owns, started offering promos to help people migrate to them from WP Engine. That alone should be majorly headline-grabbing, but Matt‚Äôs abuses up to this point are so egregious it barely even registers on the scale.)</p>
<p><em>You don‚Äôt hurt users because you‚Äôre beefing with their host</em>.</p>
<p>You don‚Äôt bomb civilians because they live near a criminal, you don‚Äôt shoot at innocent bystanders because a terrorist is hiding behind them, and you don‚Äôt fire the Death Star because you disagree with Alderaan‚Äôs government.</p>
<p>It no longer matters what this was all about at that point, or whether you were originally right or not. <em>You are irreversibly the bad guy now</em>.</p>
<p>It‚Äôs also worth calling out a side effect of this move, which may or may not have been deliberate:</p>


<p>Matt‚Äôs actions have ensured <em>his</em> hosting companies are now the <em>only</em> WordPress hosts that can guarantee something like this will never happen to their users.</p>

<p>I mean, he can just flip the switch at any time. He can change the rules whenever he wants to. So what company is safe?</p>
<p>None. Except his.</p>
<p>I hope I don‚Äôt need to go into how anti-competitive that is, all on its own, or what an egregious abuse of power it is to have put himself and his company in that position by using WordPress.org to do it.</p>



<p>The weapons Matt Mullenweg has wielded unilaterally in this war shouldn‚Äôt even <em>exist</em>, let alone be controlled by one person.</p>

<p>I believe the ability to block an entire hosting provider from accessing the plugins repository is a power that nobody should have. If one could <em>ever</em> be justified in the use of such unthinkably drastic measures, this case most certainly isn‚Äôt extreme enough to do that.</p>
<p>Imagine if Microsoft got into a dispute with Apple, and decided to block npm for anyone using a Mac.</p>
<p>Imagine if Apple got into a dispute with Google, and blocked all text messages from Android phones.</p>
<p>Imagine if Google had a dispute with Amazon, and blocked all Amazon communications in Gmail. Or with Walmart, and prevented store locations from showing up on Google Maps.</p>
<p>And imagine if <em>one person</em> at any one of those companies had the power to make that decision, unilaterally and without challenge.</p>
<p><em>This is the scale of thing we‚Äôre talking about.</em> This is the collateral damage Matt has unleashed on the WordPress community, and it‚Äôs not to <em>anyone‚Äôs</em> benefit except maybe Matt‚Äôs and his own companies‚Äô. (For now, anyway. We‚Äôll see how it all shakes out; it seems pretty inevitable that a class action suit will follow and this all gets dragged into court.)</p>
<p>Virtually no WordPress users are happy about this, no matter how they felt about WP Engine. Certainly, none benefit.</p>


<p>No reasonable person could argue WordPress is in a <em>better</em> place today than it was a week ago, or is on a better path now than it was then.</p>

<p>It‚Äôs less secure, less trustworthy, more volatile, and overall just not something <em>anybody</em> is as excited about as they were a week ago. People who spent the majority of their lives working on this software are leaving it. Professionals are looking at new tools to sell their clients. Major sites are considering changing platforms, when they wouldn‚Äôt have before.</p>
<p>The neighborhood we all lived in just rocked, by a man who‚Äôs enjoyed unchecked power as the head of every branch of the current government, as it were. And he <em>insists</em> he‚Äôs doing the right thing by us for blowing up a whole bunch of our homes. (Forgive me, I know the metaphor is beleaguered by this point, but it seems apt.)</p>
<p>Matt‚Äôs clearly willing to burn it all down to score a pyrrhic victory, and that‚Äôs not a power he or anybody else should ever have over any community, let alone one this size.</p>
<p>Matt has to go.</p>
<p>I don‚Äôt expect him to be removed from Automattic leadership (although I think others in leadership absolutely <em>should</em> be considering whether that‚Äôs the right move). But in any case:</p>


<p>It‚Äôs clear that the blurry lines between WordPress.org and WordPress.com should be turned into unbreachable walls, with no one company on both sides, or able to exercise power over the Foundation and/or Organization.</p>

<p>I don‚Äôt care about Automattic giving 5% to WordPress anymore. I want it to give up Matt‚Äôs unchecked, unilateral power. Because it‚Äôs clearer than ever he can‚Äôt be trusted with it.</p>

		

		
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Arch Linux and Valve Collaboration (123 pts)]]></title>
            <link>https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/</link>
            <guid>41676646</guid>
            <pubDate>Fri, 27 Sep 2024 23:47:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/">https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/</a>, See on <a href="https://news.ycombinator.com/item?id=41676646">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="thread-content">

                    <!-- Start first email -->
                    





<div>

     <!-- /email-header: gravatar, author-info, date, peramlink, changed_subject -->
    <p>We are excited to announce that Arch Linux is entering into a direct 
collaboration with Valve. Valve is generously providing backing for two 
critical projects that will have a huge impact on our distribution: a 
build service infrastructure and a secure signing enclave. By supporting 
work on a freelance basis for these topics, Valve enables us to work on 
them without being limited solely by the free time of our volunteers.

This opportunity allows us to address some of the biggest outstanding 
challenges we have been facing for a while. The collaboration will 
speed-up the progress that would otherwise take much longer for us to 
achieve, and will ultimately unblock us from finally pursuing some of 
our planned endeavors. We are incredibly grateful for Valve to make this 
possible and for their explicit commitment to help and support Arch Linux.

These projects will follow our usual development and consensus-building 
workflows. [RFCs] will be created for any wide-ranging changes. 
Discussions on this mailing list as well as issue, milestone and epic 
planning in our GitLab will provide transparency and insight into the 
work. We believe this collaboration will greatly benefit Arch Linux, and 
are looking forward to share further development on this mailing list as 
work progresses.

[RFCs]: <a target="_blank" href="https://rfc.archlinux.page/">https://rfc.archlinux.page/</a></p>

    
    
    

    

</div>

                    <!-- End first email -->

                    <p>
                        
                        <a href="https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/?sort=date">Show replies by date</a>
                        
                    </p>

                    
                    

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Trademark Office Cancels Marvel, DC's 'Super Hero' Marks (176 pts)]]></title>
            <link>https://www.reuters.com/legal/litigation/us-trademark-office-cancels-marvel-dcs-super-hero-marks-2024-09-26/</link>
            <guid>41676297</guid>
            <pubDate>Fri, 27 Sep 2024 22:51:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/litigation/us-trademark-office-cancels-marvel-dcs-super-hero-marks-2024-09-26/">https://www.reuters.com/legal/litigation/us-trademark-office-cancels-marvel-dcs-super-hero-marks-2024-09-26/</a>, See on <a href="https://news.ycombinator.com/item?id=41676297">Hacker News</a></p>
Couldn't get https://www.reuters.com/legal/litigation/us-trademark-office-cancels-marvel-dcs-super-hero-marks-2024-09-26/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Lion Cove: Intel's P-Core Roars (110 pts)]]></title>
            <link>https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/</link>
            <guid>41675637</guid>
            <pubDate>Fri, 27 Sep 2024 21:18:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/">https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/</a>, See on <a href="https://news.ycombinator.com/item?id=41675637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Intel‚Äôs mobile CPUs have undergone massive changes over the past couple generations as Intel defends its laptop market against AMD, Qualcomm, and to a lesser extent Apple. Meteor Lake adopted aggressive chiplet design with separate compute, GPU, SOC, and IO extender tiles. Lunar Lake switches things up again, putting all compute on one tile while a second ‚Äúplatform controller‚Äù tile deals strictly with low speed IO.</p>
<p>Amidst this whirlwind of change, Intel‚Äôs performance oriented P-Cores have remained a constant. P-Cores aim to deliver maximum per-thread performance, an important metric in client designs where responsiveness is vital and many programs don‚Äôt scale across many cores. Lion Cove is Intel‚Äôs latest and greatest high performance architecture, and fills the P-Core role in Lunar Lake. While its goals have remained constant, its design has very much not. Compared to Redwood Cove P-Cores in the previous generation Meteor Lake, Lion Cove has been overhauled with both performance and energy efficiency in mind.</p>
<figure><table><tbody><tr><td>Chip</td><td>P-Core Architecture</td><td>Test System</td><td>Source</td></tr><tr><td>Intel Core Ultra 7 258V (Lunar Lake)</td><td>Lion Cove</td><td>ASUS Zenbook S 14 UX5406SA</td><td>Sampled by ASUS</td></tr><tr><td>Intel Core Ultra 7 155H (Meteor Lake)</td><td>Redwood Cove</td><td>ASUS Zenbook 14 OLED UX3405MA</td><td>Purchased by Clam</td></tr><tr><td>AMD Ryzen AI 9 HX 370</td><td>Zen 5 Mobile</td><td>ASUS ProArt PX13 HN7306WU</td><td>Sampled by ASUS</td></tr></tbody></table></figure>
<p>Here I‚Äôll be looking at Lion Cove as implemented in the Core Ultra 7 258V. </p>
<h2>Acknowledgments </h2>
<p>We‚Äôd like to thank Asus for kindly sampling us with a Zenbook S 14 UX5406SA test system. Without their help, a look at Intel‚Äôs latest mobile chip wouldn‚Äôt have been possible.</p>
<h2>System Architecture</h2>
<p>Lion Cove cores sit on a ring bus interconnect, a familiar design that traces its roots back to Sandy Bridge in 2011. Over time though, ring bus agents have come and gone. P-Cores got to share the ring bus with E-Core clusters in 2021‚Äôs Alder Lake. Meteor Lake saw Intel kick the iGPU off the ring bus. Lunar Lake gives E-Cores the boot, leaving just the P-Cores and their associated L3 slices on the ring bus.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_sys-drawio-2/"><img data-recalc-dims="1" decoding="async" width="688" height="282" data-attachment-id="32324" data-permalink="https://chipsandcheese.com/lioncove_sys-drawio-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?fit=1201%2C492&amp;ssl=1" data-orig-size="1201,492" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_sys.drawio-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?fit=1201%2C492&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?fit=688%2C282&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?resize=688%2C282&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?w=1201&amp;ssl=1 1201w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sys.drawio-2.png?resize=768%2C315&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>L3 slices on Lunar Lake continue to have 3 MB of capacity just as they did in Meteor Lake. However, Lunar Lake caps out at four cores and four L3 slices, dropping L3 capacity in half. In exchange, Intel is dealing with a smaller and simpler ring bus. Possibly because of this, Lunar Lake‚Äôs L3 latency has dramatically improved compared to Meteor Lake. It‚Äôs not as good as AMD, which had a very strong L3 design since early Zen generations. But AMD‚Äôs L3 latency advantage isn‚Äôt as drastic as it was before.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_latency_ns-1/"><img data-recalc-dims="1" decoding="async" width="688" height="325" data-attachment-id="32328" data-permalink="https://chipsandcheese.com/lioncove_latency_ns-1/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?fit=1151%2C544&amp;ssl=1" data-orig-size="1151,544" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_latency_ns-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?fit=1151%2C544&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?fit=688%2C325&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?resize=688%2C325&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?w=1151&amp;ssl=1 1151w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_ns-1.png?resize=768%2C363&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>DRAM latency also improves. Lunar Lake‚Äôs new chiplet design places the memory controller and CPU cores on the same tile, so memory access no longer have to traverse a cross-die link. The LPDDR5X DRAM chips themselves have been brought on-package too.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_loadedlatency/"><img data-recalc-dims="1" decoding="async" width="688" height="381" data-attachment-id="32426" data-permalink="https://chipsandcheese.com/lioncove_loadedlatency/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_loadedlatency.png?fit=734%2C407&amp;ssl=1" data-orig-size="734,407" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_loadedlatency" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_loadedlatency.png?fit=734%2C407&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_loadedlatency.png?fit=688%2C381&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_loadedlatency.png?resize=688%2C381&amp;ssl=1" alt=""></a></figure></div>
<p>Like Meteor Lake, Lunar Lake complicates DRAM latency measurements because the memory controller likes to stay in a low power state if there isn‚Äôt enough DRAM traffic. A plain memory latency test sees about 131.4 ns of DRAM latency. Creating some artificial bandwidth load drops latency to 112.4 ns. AMD‚Äôs Strix Point had 128 ns of DRAM latency for comparison, with margin-of-error differences under moderate bandwidth load. While DRAM latency with LPDDR5(x) will never match desktop DDR5, Lunar Lake‚Äôs DRAM latency is good for a mobile platform.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32333"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="382" data-attachment-id="32333" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/hc2024_lunarlake_msc-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?fit=1595%2C885&amp;ssl=1" data-orig-size="1595,885" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hc2024_lunarlake_msc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?fit=1595%2C885&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?fit=688%2C382&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?resize=688%2C382&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?w=1595&amp;ssl=1 1595w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?resize=768%2C426&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?resize=1536%2C852&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?resize=1200%2C666&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?resize=1320%2C732&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lunarlake_msc-1.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Even with on-package memory, DRAM accesses are power hungry. Lunar Lake tackles this with a 8 MB memory side cache. 8 MB is less capacity than Lion Cove‚Äôs 12 MB cache, but that‚Äôs not a huge issue because the memory side cache is aimed towards blocks like the NPU or display engine that don‚Äôt have large caches of their own. Because improving CPU performance isn‚Äôt the main goal, the memory side cache doesn‚Äôt have great latency. In fact, estimating its latency is difficult because test sizes contained within the memory side cache will inevitably see a significant number of L3 hits. In those test ranges, latency is roughly 30 ns from a P-Core.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_dram_bw/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="374" data-attachment-id="32336" data-permalink="https://chipsandcheese.com/lioncove_dram_bw/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_dram_bw.png?fit=736%2C400&amp;ssl=1" data-orig-size="736,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_dram_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_dram_bw.png?fit=736%2C400&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_dram_bw.png?fit=688%2C374&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_dram_bw.png?resize=688%2C374&amp;ssl=1" alt=""></a></figure></div>
<p>DRAM bandwidth is quite impressive on Lunar Lake. Going to LPDDR5X-8533 brings noticeable improvements over Meteor Lake‚Äôs LPDDR5-7467. Four Lion Cove cores alone can pull more bandwidth than all of Meteor Lake‚Äôs cores.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_4c_read/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="311" data-attachment-id="32339" data-permalink="https://chipsandcheese.com/lioncove_4c_read/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?fit=1178%2C532&amp;ssl=1" data-orig-size="1178,532" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_4c_read" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?fit=1178%2C532&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?fit=688%2C311&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?resize=688%2C311&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?w=1178&amp;ssl=1 1178w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4c_read.png?resize=768%2C347&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>L3 bandwidth is less impressive, though that hasn‚Äôt been Intel‚Äôs strong point for years. AMD Strix Point‚Äôs four high performance Zen 5 cores can pull over 600 GB/s from L3 with reads alone. To Intel‚Äôs credit, quad core L3 bandwidth at least doesn‚Äôt regress compared to Redwood Cove. But L3 isn‚Äôt the focus of recent Intel designs. Rather, the company uses larger L2 caches to make their cores less sensitive to L3 performance. Having a slow cache is fine if you don‚Äôt hit it often.</p>
<h2>A Mid-Level Cache For Your Mid-Level Cache</h2>
<p>And Intel cores have trended towards bigger L2 caches. But increasing cache capacity isn‚Äôt so simple because larger caches often come with higher latency. Intel‚Äôs L2, which the company often refers to a mid-level cache, isn‚Äôt immune.</p>
<figure><table><tbody><tr><td>Generation</td><td>L2 Cache</td><td>L3 Cache</td></tr><tr><td>Skylake (Client)</td><td>256 KB, 12 cycle latency</td><td>6 MB, 37 cycle latency (Core i5-6600K)</td></tr><tr><td>Tiger Lake, Willow Cove</td><td>1280 KB, 14 cycle latency</td><td>24 MB, 58 cycle latency (Core i7-11800H)</td></tr><tr><td>Meteor Lake, Redwood Cove</td><td>2 MB, 16 cycle latency</td><td>24 MB, 75 cycle latency (Core Ultra 7 155H)</td></tr><tr><td>Lunar Lake, Lion Cove</td><td>2.5 MB, 17 cycle latency</td><td>12 MB, 51 cycle latency (Core Ultra 7 258V)</td></tr></tbody></table></figure>
<p>Lion Cove counters this by adding a mid-level cache for the mid-level cache so you can avoid mid-level cache latency if you hit in the faster mid-level cache. Intel calls this new mid-level cache a L1, and renames the first level cache to L0. The new ‚ÄúL1‚Äù has 192 KB of capacity with 9 cycles of load-to-use latency.</p>
<p>I disagree with Intel‚Äôs terminology change. While first level cache latency does drop from five to four cycles, it merely matches Zen 5‚Äôs L1D in capacity and latency terms. The 192 KB ‚ÄúL1‚Äù has much higher latency than L1D caches in competing cores. You could really stretch things by comparing to a Cortex A72 in Graviton 1. That has 1.75 ns of L1D latency, which is in the same ballpark as the 1.88 ns of measured latency on Lion Cove‚Äôs 192 KB L1. But Cortex A72 and Lion Cove don‚Äôt have comparable design goals.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_latency_cycles/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="345" data-attachment-id="32347" data-permalink="https://chipsandcheese.com/lioncove_latency_cycles/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?fit=1084%2C544&amp;ssl=1" data-orig-size="1084,544" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_latency_cycles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?fit=1084%2C544&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?fit=688%2C345&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?resize=688%2C345&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?w=1084&amp;ssl=1 1084w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_latency_cycles.png?resize=768%2C385&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>I‚Äôm going to be stubborn and call the 48 KB first level cache a ‚ÄúL1‚Äù, and the 192 KB cache a ‚ÄúL1.5‚Äù from now on. Lion Cove‚Äôs L1.5 has better bandwidth than Redwood Cove‚Äôs L2, though not with a read-only pattern. I needed a read-modify-write pattern to sustain more than 32 bytes per cycle, so I think it‚Äôs only a minor improvement. The L1.5‚Äôs bandwidth is nowhere near that of the 48 KB L1D on either Lion Cove or Redwood Cove.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_cache_levels-drawio/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="322" height="569" data-attachment-id="32464" data-permalink="https://chipsandcheese.com/lioncove_cache_levels-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_cache_levels.drawio.jpg?fit=322%2C569&amp;ssl=1" data-orig-size="322,569" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_cache_levels.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_cache_levels.drawio.jpg?fit=322%2C569&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_cache_levels.drawio.jpg?fit=322%2C569&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_cache_levels.drawio.jpg?resize=322%2C569&amp;ssl=1" alt=""></a><figcaption>That‚Äôs a lot of cache levels</figcaption></figure></div>
<p>But I don‚Äôt think bandwidth is Intel‚Äôs main goal with the new L1.5. Rather, it looks aimed at reducing average L1D miss latency. Catching some L1D misses and servicing them at 9 cycle latency helps of course. Beyond that, the L1.5 lets Intel make a bigger L2, reducing latency for more difficult accesses by servicing more of them within full speed core-private caches. Going from 2 MB on Redwood Cove to 2.5 MB on Lion Cove might not feel like much. However, Intel‚Äôs slides show Lion Cove can support up to 3 MB of L2 capacity. That‚Äôs as much capacity as last level caches on some old Intel dual core chips like the Core i5-3317U.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32353"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="324" data-attachment-id="32353" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_1t_bw-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?fit=1173%2C552&amp;ssl=1" data-orig-size="1173,552" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_1t_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?fit=1173%2C552&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?fit=688%2C324&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?resize=688%2C324&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?w=1173&amp;ssl=1 1173w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_1t_bw-1.png?resize=768%2C361&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Possibly because L1.5 absorbs a good chunk of L1D miss traffic, Intel didn‚Äôt focus as much on L2 bandwidth. Lion Cove‚Äôs L2 Bandwidth tops out at 32 bytes per cycle, regardless of whether I‚Äôm using a read-only pattern or a read-modify-write one. Intel‚Äôs focus is really about giving the L2 more capacity, rather than providing higher L2 bandwidth.</p>
<p>If workloads spill out of L2, L3 bandwidth is quite mediocre. L3 read bandwidth from a single Lion Cove core regresses to just over 10 bytes per cycle, down from 16 bytes per cycle on Redwood Cove. Lion Cove enjoys lower L3 latency and a larger L2 miss queue (80 entries, compared to 64 on Redwood Cove). It‚Äôs a combination that should give a single core access to more L3 bandwidth, but that doesn‚Äôt show through in testing. A read-modify-write pattern achieves higher bandwidth, at 17-18 bytes per cycle.</p>
<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="286" data-attachment-id="32487" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/image-107/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?fit=2386%2C991&amp;ssl=1" data-orig-size="2386,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?fit=2386%2C991&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?fit=688%2C286&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=688%2C286&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?w=2386&amp;ssl=1 2386w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=768%2C319&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=1536%2C638&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=2048%2C851&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=1600%2C665&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?resize=1320%2C548&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-1.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px"></figure></div>
<p>Neither figure approaches Zen 5, which goes right to the limit of its 32 byte per cycle L2 to L3 interface. A read-modify-write pattern exercises the 32 byte per cycle link in the other direction, bringing total L3 throughput to 64 bytes per cycle. The Ryzen AI 9 HX 370 can run its Zen 5 cores at up to 5.15 GHz compared to 4.8 GHz on the Core Ultra 7 258V. AMD‚Äôs clock speed advantage further inflates its L3 bandwidth advantage.</p>
<h2>Out-of-Order Execution Engine</h2>
<p>One of those sweeping changes applies to the schedulers, which have been reorganized with a view towards scalability. Since the Pentium Pro from 1995, Intel has served both integer and FP/vector operations with a unified scheduler. Scaling a large unified scheduler can be difficult, so Intel split the scheduler over time. Skylake put memory address generation ops on a separate scheduler. Sunny Cove split the memory scheduler, and Golden Cove revised the memory scheduler split.</p>
<p>Lion Cove finally splits the unified math scheduler into separate ones for integer and floating point/vector ops. Intel also split register renaming for floating point and integer operations. That‚Äôs not visible from software, but it does suggest Intel‚Äôs core is now laid out a lot like AMD‚Äôs Zen. Both do register renaming separately for integer and vector operations, and use separate schedulers for those operations.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_sched-drawio/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="309" data-attachment-id="32372" data-permalink="https://chipsandcheese.com/lioncove_sched-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?fit=1378%2C619&amp;ssl=1" data-orig-size="1378,619" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_sched.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?fit=1378%2C619&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?fit=688%2C309&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?resize=688%2C309&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?w=1378&amp;ssl=1 1378w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?resize=768%2C345&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_sched.drawio.png?resize=1320%2C593&amp;ssl=1 1320w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>After the split, Lion Cove‚Äôs vector and integer schedulers each have similar capacity to Redwood Cove‚Äôs unified math scheduler. Combined integer and vector scheduling capacity is simply massive with over 200 available entries. The memory schedulers are no joke either. In every category, Lion Cove‚Äôs scheduling capacity beats Zen 5‚Äôs.</p>
<figure><table><tbody><tr><td>Category</td><td>Lion Cove Available Scheduler Entries</td><td>Zen 5 Available Scheduler Entries</td></tr><tr><td>Scalar Integer Math</td><td>97</td><td>88</td></tr><tr><td>Floating Point/Vector Math</td><td>114</td><td>76</td></tr><tr><td>Memory Accesses</td><td>62</td><td>58</td></tr></tbody></table></figure>
<p>Besides big schedulers, Intel uses non-scheduling queues to let Lion Cove track more more operations waiting for an execution unit. If a scheduler fills up, the renamer can place micro-ops into an associated non-scheduling queue instead of stalling. Micro-ops sitting in a non-scheduling queue won‚Äôt be considered for execution, but can enter a scheduler later when entries become available. AMD‚Äôs Zen line and Intel‚Äôs own E-Core line have used non-scheduling queues over the years, and it‚Äôs great to see the Intel adopt it on P-Cores too.</p>
<p>Lion Cove‚Äôs schedulers feed a massive 18 execution ports, up from 12 in Redwood Cove. Much of that execution port count increase comes from moving FP/vector units off the integer scheduler. Execution capacity for common instruction categories hasn‚Äôt increased that much. Scalar integer adds get an extra ALU port. A third store address port helps discover memory dependencies faster, though sustained store throughput is limited two per cycle. FP/vector operations are handled by four ports instead of three.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_vecfp-drawio/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="409" height="333" data-attachment-id="32377" data-permalink="https://chipsandcheese.com/lioncove_vecfp-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_vecfp.drawio.png?fit=409%2C333&amp;ssl=1" data-orig-size="409,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_vecfp.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_vecfp.drawio.png?fit=409%2C333&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_vecfp.drawio.png?fit=409%2C333&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_vecfp.drawio.png?resize=409%2C333&amp;ssl=1" alt=""></a></figure></div>
<p>Lion Cove‚Äôs FP/vector execution setup is curious too, because now it very closely resembles AMD‚Äôs going back to Zen 1. AMD and Intel now handle FP/vector execution with four pipes. Two deal with floating point multiplies and multiply-adds, while two others handle FP adds. Vector integer adds can go to any of the four ports. Unlike Zen 5, Lion Cove maintains single cycle vector integer add latency even when the schedulers are full and micro-ops are woken up by single cycle ops (other vector integer adds). In AMD‚Äôs favor, cores from the Zen line don‚Äôt suffer a significant penalty when a floating point multiply with normalized inputs generates a denormal output. Such an event costs 132 cycles on Lion Cove, which is worse than the 124 cycles I saw on Redwood Cove. Skymont behaves like Zen, and doesn‚Äôt suffer a significant penalty for denormal results.</p>
<p>Micro-ops leave the schedulers after execution units generate their speculative results. But all the way until they‚Äôre retired, micro-ops require entries in various structures like the reorder buffer, register files, and load/store queues. Those queues, buffers, and register files ensure the core can correctly produce results as if instructions were executed in program order. Lion Cove grows those structures, letting the core keep more instructions in-flight. In turn, that makes the core more resilient against long latency events like cache misses. But not every structure got equal treatment.</p>
<figure><table><tbody><tr><td>Structure</td><td>Required if an instruction‚Ä¶</td><td>Lion Cove</td><td>Redwood Cove</td><td>Zen 5</td></tr><tr><td>Reorder Buffer (ROB)</td><td>Exists</td><td>576</td><td>512</td><td>448</td></tr><tr><td>Integer Register File</td><td>Writes to a scalar integer register</td><td>~290</td><td>280</td><td>240</td></tr><tr><td>Floating Point/Vector Register File</td><td>Writes to a floating point/vector register</td><td>~406</td><td>332</td><td>384</td></tr><tr><td>Mask Register File</td><td>Writes to an AVX-512 mask register<br><a href="https://travisdowns.github.io/blog/2020/05/26/kreg2.html">Intel CPUs alias MMX/x87 registers to the same physical register file</a></td><td>~166</td><td>~158</td><td>~146</td></tr><tr><td>Load Queue</td><td>Reads from Memory</td><td>~189</td><td>192</td><td>N/A, ~202 measured</td></tr><tr><td>Store Queue</td><td>Writes to Memory</td><td>120</td><td>114</td><td>104</td></tr><tr><td>Branch Order Buffer</td><td>Affects control flow</td><td>180</td><td>128</td><td>96</td></tr></tbody></table></figure>
<p>Lion Cove‚Äôs ROB sees a 12.5% capacity increase. It‚Äôs a noticeable improvement, if nowhere near the 45% or 40% ROB size growth that Golden Cove or Zen 5 got over their respective previous generations. However, some of Lion Cove‚Äôs supporting resources are much bigger than the corresponding ones in Golden Cove/Redwood Cove. Lion Cove can have over 40% more branches in flight. The floating point register file also sees substantial growth, likely to keep pace with increased floating point scheduling and non-scheduling queue capacity.</p>
<p>Since Skylake, Intel allocates both AVX-512 mask registers and MMX/x87 registers out of the same register file. I can‚Äôt test reordering capacity for mask registers because Intel stopped supporting AVX-512 on consumer chips. But testing with MMX registers shows a small increase in rename capacity over Redwood Cove. Intel may still be making AVX-512 oriented improvements, and some of those effects are visible even on client cores.</p>
<p>Improvements elsewhere are minor. The integer register file grew by less than a dozen entries and still doesn‚Äôt cover ROB capacity well. Intel added a few store queue entries too. As far as I can tell, the load queue either didn‚Äôt get any entries added, or even had a few removed.</p>
<h3>Load/Store Unit</h3>
<p>A CPU‚Äôs load/store unit often occupies plenty of die area, and is responsible for ensuring memory accesses appear to execute in program order. That feels challenging with a lot of memory accesses in-flight, because a load‚Äôs address has to be checked against all prior store addresses. If they overlap, the load has to read data from the store queue instead of the data cache.</p>

<p>Lion Cove maintains Golden Cove‚Äôs zero latency, two-per-cycle store forwarding capability for exact address matches. Latency slightly regresses if the load is contained within a store but addresses don‚Äôt match exactly, but that shouldn‚Äôt be common unless you‚Äôre dealing with network packets or something. Partial overlaps are handled with much higher latency, and are likely handled by blocking the load until the store commits, after which the load can get data from the L1D cache. If so, Zen 5 has a much shorter pipeline from store address generation to retirement.</p>
<figure><table><tbody><tr><td>Case</td><td>Lion Cove</td><td>Golden Cove</td><td>Zen 5</td></tr><tr><td>Exact Address Match</td><td>2 per cycle<br>0 cycle latency</td><td>2 per cycle<br>0 cycle latency</td><td>2 per cycle<br>0 cycle latency</td></tr><tr><td>Load Contained within Store</td><td>8-9 cycle latency</td><td>5-6 cycle latency</td><td>7 cycle latency</td></tr><tr><td>Load/Store Partially Overlap</td><td>19 cycles</td><td>19-20 cycles</td><td>14 cycles</td></tr><tr><td>Independent Misaligned Load</td><td>1 per cycle</td><td>1 per cycle</td><td>4 per 3 cycles</td></tr><tr><td>Independent Misaligned Store</td><td>2 cycles per store</td><td>2 cycles per store</td><td>1 per cycle</td></tr></tbody></table></figure>
<p>Independent accesses can face delays too depending on how they interact with the underlying data cache. Tracking cached data at the byte level would be far too expensive, so caches maintain tags and state at the cache line granularity. That‚Äôs typically 64 bytes. Intel‚Äôs architectures do worse when an access crosses a 64 byte cache line boundary, taking an extra cycle for a store. Loads do a bit better probably because the data cache has more load ports and can absorb the extra bandwidth needed for a misaligned access. But misaligned loads still aren‚Äôt handled as fast as on AMD.</p>
<h4>Address Translation</h4>
<p>Programs operate on virtual addresses, which have to be translated to physical addresses that correspond to locations in DRAM. The load/store unit has to carry out these translations according to page tables set up by the operating system. Page tables are actually multi-level structures, so CPUs cache frequently used address translations in translation lookaside buffers (TLBs). For generations Intel has used a very complex TLB setup with separate TLBs for different page sizes and access types.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32402"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="579" data-attachment-id="32402" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_tlbs/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?fit=785%2C661&amp;ssl=1" data-orig-size="785,661" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_tlbs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?fit=785%2C661&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?fit=688%2C579&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?resize=688%2C579&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?w=785&amp;ssl=1 785w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_tlbs.jpg?resize=768%2C647&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a><figcaption>Who uses 1 GB pages anyway</figcaption></figure></div>
<p>Lion Cove brings the 4K page load-only DTLB‚Äôs capacity up to 128 entries, from 96 in Redwood Cove. None of the other TLB sizes have changed. That should reduce average memory access latency across a wide variety of client programs, because 4K pages are most commonly used there. However, AMD‚Äôs Zen 5 and even Zen 4 can cache far more address translations in a L2 TLB. AMD‚Äôs cores therefore have a better chance of avoiding expensive page table walks.</p>
<p>As on Redwood Cove, getting a translation from Lion Cove‚Äôs L2 TLB adds 7 extra cycles of latency. That penalty also matches Zen 5.</p>
<h2>Rename and Allocate: Feeding the Backend</h2>
<p>The rename and allocate stage allocates micro-ops into backend structures, while carrying out register renaming and other optimizations to break false dependencies. Register renaming is an inherently serial task because which physical registers correspond to an instruction‚Äôs inputs depends on how prior renames have been carried out. Probably for that reason, the renamer is often the narrowest part of a core‚Äôs pipeline. AMD and Intel‚Äôs latest cores are no exception.</p>
<p>Lion Cove widens the renamer to handle 8 micro-ops per cycle, up from 6 in Redwood Cove. That makes Lion Cove an 8-wide core overall, matching AMD‚Äôs Zen 5. Intel‚Äôs renamer received some impressive capabilities in Golden Cove, including the ability to execute up to 6 dependent adds with small immediates per cycle. That‚Äôs carried forward to Lion Cove, though not widened to match the renamer‚Äôs full width.</p>
<figure><table><tbody><tr><td>Test</td><td>Comment</td><td>Lion Cove IPC</td><td>Redwood Cove IPC</td><td>Zen 5 IPC</td></tr><tr><td>XOR r,r</td><td>Commonly used to zero registers. The exclusive-or of two identical values is always zero</td><td>7.31</td><td>5.7</td><td>5.01</td></tr><tr><td>XOR xmm, xmm</td><td>Same as above but for a vector/FP register</td><td>7.31</td><td>5.71</td><td>4.99</td></tr><tr><td>Dependent MOV r,r</td><td>&gt;1 indicates move elimination</td><td>7.02</td><td>5.56</td><td>6.65</td></tr><tr><td>Independent MOV r,r</td><td>Easy</td><td>7.25</td><td>5.71</td><td>5.01</td></tr><tr><td>Dependent increment</td><td>Actual math, normally would create a dependency chain limiting the test to 1 IPC</td><td>5.6</td><td>5.53</td><td>1</td></tr><tr><td>Dependent add immediate</td><td>As above but adding small numbers up to 20 instead of just 1</td><td>4.36</td><td>5.47</td><td>1</td></tr></tbody></table></figure>
<p>Other easier optimizations like move elimination and zeroing idiom recognition can be carried out at or near the renamer‚Äôs full width. Zen 5 is no slouch for those, but often can‚Äôt carry out those optimizations at eight per cycle. I‚Äôm not sure if it makes a big performance difference, but it does show Intel‚Äôs focus on building a very powerful rename stage.</p>
<h2>Frontend Fetch and Decode</h2>
<p>The frontend has to feed the rename stage by bringing instructions into the core and decoding them into micro-ops. Lion Cove‚Äôs frontend uses a similar strategy to prior P-Cores. A conventional instruction cache feeds a decoder, which both sends micro-ops downstream and fills them into a micro-op cache. Lion Cove widens the decoder to handle eight instructions per cycle, up from six in Redwood Cove. Micro-op cache capacity increases to 5250 micro-ops, up from 4096 on Redwood Cove. Bandwidth from the micro-op cache went up to, from eight to 12 micro-ops per cycle.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32413"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="293" data-attachment-id="32413" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_4b_ifetch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?fit=1164%2C496&amp;ssl=1" data-orig-size="1164,496" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_4b_ifetch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?fit=1164%2C496&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?fit=688%2C293&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?resize=688%2C293&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?w=1164&amp;ssl=1 1164w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_4b_ifetch.png?resize=768%2C327&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Unlike AMD Zen 5‚Äôs clustered decoder, all eight decode slots on Lion Cove can serve a single thread. Lion Cove can therefore sustain eight instructions per cycle as long as code fits within the 64 KB instruction cache. After that, code fetch throughput from L2 is limited to 16 bytes per cycle. L3 code fetch bandwidth is similar to data-side bandwidth, so Lion Cove‚Äôs branch predictor can run very far ahead of fetch to hide even L2 miss latency. The same doesn‚Äôt apply to Zen 5, which has lower code fetch throughput from L3.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32417"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="300" data-attachment-id="32417" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_8b_ifetch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?fit=1152%2C503&amp;ssl=1" data-orig-size="1152,503" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_8b_ifetch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?fit=1152%2C503&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?fit=688%2C300&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?resize=688%2C300&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?w=1152&amp;ssl=1 1152w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_8b_ifetch.png?resize=768%2C335&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Longer instructions can run into cache bandwidth bottlenecks. With longer 8-byte NOPs, Lion Cove can maintain 8 instructions per cycle as long as code fits within the micro-op cache. Strangely, throughput drops well before the test should spill out of the micro-op cache. The 16 KB data point for example would correspond to 2048 NOPs, which is well within the micro-op cache‚Äôs 5250 entry capacity. I saw the same behavior on Redwood Cove.</p>
<p>Once the test spills into the L1 instruction cache, fetch bandwidth drops to just over 32 bytes per cycle. And once it gets into L2, Lion Cove can sustain 16 instruction bytes per cycle.</p>
<h2>Branch Predictor: Directing the Core</h2>
<p>Instruction fetch is steered by the branch predictor, which plays an important role in improving both performance and power efficiency. Everyone tends to improve their branch predictors with every generation, and Lion Cove does so too. A single branch sees little to no penalty (evidence of a mispredicts) even when throwing a 12K long random pattern at it.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_branchhist/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="369" data-attachment-id="32422" data-permalink="https://chipsandcheese.com/lioncove_branchhist/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?fit=1174%2C629&amp;ssl=1" data-orig-size="1174,629" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_branchhist" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?fit=1174%2C629&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?fit=688%2C369&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?resize=688%2C369&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?w=1174&amp;ssl=1 1174w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_branchhist.png?resize=768%2C411&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<div>
<figure><a href="https://chipsandcheese.com/2024/09/22/intels-redwood-cove-baby-steps-are-still-steps/redwood_cove_branchhist/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="375" data-attachment-id="32172" data-permalink="https://chipsandcheese.com/2024/09/22/intels-redwood-cove-baby-steps-are-still-steps/redwood_cove_branchhist/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?fit=1106%2C603&amp;ssl=1" data-orig-size="1106,603" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="redwood_cove_branchhist" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?fit=1106%2C603&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?fit=688%2C375&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?resize=688%2C375&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?w=1106&amp;ssl=1 1106w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove_branchhist.png?resize=768%2C419&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Intel definitely made some changes to direction predictor, but the scope of this change seems to be narrow. Lion Cove performance monitoring events haven‚Äôt been documented yet, but Intel does guarantee some architectural performance monitoring events will work across different generations. Events for retired branches and retired mispredicted branches are among those events.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_specint_bpu_accuracy/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="542" data-attachment-id="32467" data-permalink="https://chipsandcheese.com/lioncove_specint_bpu_accuracy/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?fit=927%2C730&amp;ssl=1" data-orig-size="927,730" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_specint_bpu_accuracy" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?fit=927%2C730&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?fit=688%2C542&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?resize=688%2C542&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?w=927&amp;ssl=1 927w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint_bpu_accuracy.png?resize=768%2C605&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>If I look at the geometric mean of branch prediction accuracy across all SPEC CPU2017 workloads, Redwood Cove and Lion Cove differ by well under 0.1%. Lion Cove has a tweaked branch predictor for sure, but I‚Äôm not seeing it move the needle in terms of accuracy. AMD‚Äôs Zen 5 still does a bit better overall, and can gain an especially significant edge with difficult workloads like 541.leela and 541.xz. There, AMD‚Äôs latest branch predictor sees a 11.4% and 3.84% reduction in mispredicts per instruction compared to Intel‚Äôs. Within SPEC CPU2017‚Äôs floating point suite, Lion Cove struggles in 526.blender.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_specfp_bpu_accuracy/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="646" data-attachment-id="32468" data-permalink="https://chipsandcheese.com/lioncove_specfp_bpu_accuracy/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?fit=926%2C870&amp;ssl=1" data-orig-size="926,870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_specfp_bpu_accuracy" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?fit=926%2C870&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?fit=688%2C646&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?resize=688%2C646&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?w=926&amp;ssl=1 926w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp_bpu_accuracy.png?resize=768%2C722&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Branch predictor speed matters too, because the point of a branch predictor is to minimize delays from control flow dependencies. Intel continues to use a triple level branch target buffer (BTB) setup to cache frequently used branch targets, but each level has been tweaked compared to Redwood Cove. To start, both architectures can handle two taken branches per cycle likely by unrolling small loops within the micro-op queue. Lion Cove and Redwood Cove both have a 192 entry micro-op queue, but perhaps Lion Cove can‚Äôt track as many branches within it.</p>
<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="361" data-attachment-id="32428" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?fit=1124%2C590&amp;ssl=1" data-orig-size="1124,590" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?fit=1124%2C590&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?fit=688%2C361&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?resize=688%2C361&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?w=1124&amp;ssl=1 1124w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_btb.png?resize=768%2C403&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></figure></div>
<p>Next, a L1 BTB is fast enough to do zero bubble branching, which means handling taken branches with just a single cycle of latency. On Lion Cove, the L1 BTB appears to cover 2 KB of code, regardless of how many branches are in it. Redwood Cove can track up to 128 branches in its L1 BTB, mostly independently of branch spacing.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=32429"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="303" data-attachment-id="32429" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/redwood_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?fit=1030%2C454&amp;ssl=1" data-orig-size="1030,454" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="redwood_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?fit=1030%2C454&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?fit=688%2C303&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?resize=688%2C303&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?w=1030&amp;ssl=1 1030w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_btb.png?resize=768%2C339&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Then there‚Äôs a 6K entry BTB on both cores with 2 cycle latency, followed by a 12K entry BTB. That large last level BTB has 3-4 cycles of latency on Lion Cove, and is difficult to characterize on Redwood Cove.</p>
<p>Returns are predicted via a return stack, which has grown to 24 entries from 20 in Redwood Cove. Prediction latency is better when the tested call depth doesn‚Äôt exceed 12, so I suspect this is a two level structure. For comparison AMD has opted for a larger 52 entry return stack on Zen 5, which is duplicated per-thread for a total of 104 entries.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_returnstack_cycles/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="392" data-attachment-id="32456" data-permalink="https://chipsandcheese.com/lioncove_returnstack_cycles/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?fit=776%2C442&amp;ssl=1" data-orig-size="776,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_returnstack_cycles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?fit=776%2C442&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?fit=688%2C392&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?resize=688%2C392&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?w=776&amp;ssl=1 776w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_returnstack_cycles.png?resize=768%2C437&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Capacity isn‚Äôt the only factor, and I have to point out how fast Intel‚Äôs return prediction is. Lion Cove and Redwood Cove can handle a call+return pair every cycle. AMD‚Äôs Zen 5 takes four cycles to do the same, or an average of two cycles per branch. Lion Cove trades some speed for a few extra return stack entries, and averages one branch per cycle up to a call depth of 24. AMD may be faster for direct branches thanks to its giant 1024 entry zero-bubble BTB. But Intel is faster for other categories of branches like calls and returns.</p>
<h2>Core Summary</h2>
<p>All those caches help feed Lion Cove‚Äôs core, which has huge upgrades over Redwood Cove. The pipeline is wider, structures are larger, and a reorganized out-of-order engine helps Intel achieve higher scheduling capacity.</p>
<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="432" data-attachment-id="32488" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/image-108/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?fit=1778%2C1116&amp;ssl=1" data-orig-size="1778,1116" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?fit=1778%2C1116&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?fit=688%2C432&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=688%2C432&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?w=1778&amp;ssl=1 1778w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=768%2C482&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=1536%2C964&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=1200%2C753&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=1600%2C1004&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?resize=1320%2C829&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/image-2.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px"></figure></div>
<p>Much like Redwood Cove, Lion Cove is a wide and high clocked out-of-order design. But it‚Äôs easily the biggest change to Intel‚Äôs performance oriented architecture since Golden Cove. After Redwood Cove‚Äôs minor changes over Raptor Cove, and Raptor Cove barely doing anything over Golden Cove, it‚Äôs great to see Lion Cove‚Äôs sweeping changes.</p>
<div>
<figure><a href="https://chipsandcheese.com/2024/09/22/intels-redwood-cove-baby-steps-are-still-steps/redwood_cove-1/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="566" data-attachment-id="32167" data-permalink="https://chipsandcheese.com/2024/09/22/intels-redwood-cove-baby-steps-are-still-steps/redwood_cove-1/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?fit=1348%2C1109&amp;ssl=1" data-orig-size="1348,1109" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="redwood_cove-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?fit=1348%2C1109&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?fit=688%2C566&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?resize=688%2C566&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?w=1348&amp;ssl=1 1348w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?resize=768%2C632&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?resize=1200%2C987&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/redwood_cove-1.png?resize=1320%2C1086&amp;ssl=1 1320w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Intel must have put a lot of effort into Lion Cove‚Äôs design. Compared to Redwood Cove, Lion Cove posts 23.2% and 15.8% gains in SPEC CPU2017‚Äôs integer and floating point suites, respectively. Against AMD‚Äôs Strix Point, single threaded performance in SPEC is well within margin of error. It‚Äôs an notable achievement for Intel‚Äôs newest P-Core architecture because Lunar Lake feeds its P-Cores with less L3 cache than either Meteor Lake or Strix Point. A desktop CPU like the Ryzen 9 7950X3D only stays 12% and 10.8% ahead in the integer and floating point suites respectively. Getting that close to a desktop core, even a last generation one, is also a good showing.</p>
<div>
<figure><a href="https://chipsandcheese.com/lioncove_spec_total/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="591" height="402" data-attachment-id="32437" data-permalink="https://chipsandcheese.com/lioncove_spec_total/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_spec_total.png?fit=591%2C402&amp;ssl=1" data-orig-size="591,402" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_spec_total" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_spec_total.png?fit=591%2C402&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_spec_total.png?fit=591%2C402&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_spec_total.png?resize=591%2C402&amp;ssl=1" alt=""></a></figure></div>
<p>Results here aren‚Äôt comparable to ones in the prior article because I re-ran with <code>-O3 -mtune=native -march=native</code> to let GCC use whatever instruction set extensions the CPU supports. They also aren‚Äôt comparable to Intel‚Äôs performance estimates, which took a variety of workloads into account at fixed frequencies.</p>
<div>
<figure><a href="https://chipsandcheese.com/hc2024_lioncove_ipc_gain/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="385" data-attachment-id="32441" data-permalink="https://chipsandcheese.com/hc2024_lioncove_ipc_gain/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?fit=1917%2C1074&amp;ssl=1" data-orig-size="1917,1074" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hc2024_lioncove_ipc_gain" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?fit=1917%2C1074&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?fit=688%2C385&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?resize=688%2C385&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?w=1917&amp;ssl=1 1917w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?resize=1536%2C861&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?resize=1600%2C896&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?resize=1320%2C740&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lioncove_ipc_gain.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Performance gains will vary across different workloads as SPEC CPU2017 subscores show. But there‚Äôs little doubt that Intel succeeded in delivering a generational performance uplift with Lion Cove.</p>
<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="571" data-attachment-id="32442" data-permalink="https://chipsandcheese.com/lioncove_specint/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?fit=862%2C716&amp;ssl=1" data-orig-size="862,716" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_specint" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?fit=862%2C716&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?fit=688%2C571&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?resize=688%2C571&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?w=862&amp;ssl=1 862w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specint.png?resize=768%2C638&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></figure></div>
<div>
<figure><a href="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_specfp-2/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="541" data-attachment-id="32502" data-permalink="https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/lioncove_specfp-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?fit=939%2C738&amp;ssl=1" data-orig-size="939,738" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lioncove_specfp" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?fit=939%2C738&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?fit=688%2C541&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?resize=688%2C541&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?w=939&amp;ssl=1 939w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/lioncove_specfp-1.png?resize=768%2C604&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<h2>Final Words</h2>
<p>P-Cores have been Intel‚Äôs bread and butter long before the company started calling them P-Cores. Progress with Intel‚Äôs performance oriented cores hasn‚Äôt always been fast. Redwood Cove was only a slight tweak over Golden Cove. Skylake filled out five generations of Intel designs the same architecture. Going back further, Intel used the P6 architecture on the Pentium Pro, Pentium II, and Pentium III with just minor tweaks and clock speed increases in between.</p>
<div>
<figure><a href="https://chipsandcheese.com/hc2024_lnl_perfcores_slide/"><img data-recalc-dims="1" loading="lazy" decoding="async" width="688" height="386" data-attachment-id="32462" data-permalink="https://chipsandcheese.com/hc2024_lnl_perfcores_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?fit=1915%2C1075&amp;ssl=1" data-orig-size="1915,1075" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hc2024_lnl_perfcores_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?fit=1915%2C1075&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?w=1915&amp;ssl=1 1915w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=1536%2C862&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=1600%2C898&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?resize=1320%2C741&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/09/hc2024_lnl_perfcores_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px"></a></figure></div>
<p>Lion Cove is a much improved architecture compared to Redwood Cove, and shows Intel still has potent engineering muscle despite recent setbacks. Traditionally Intel delivered significant architecture changes during a ‚Äútock‚Äù in a tick-tock cycle. That reduces risk by separately handling process node and architecture changes. Lunar Lake not only combines a new architecture with a move to a new node, but also drops system level changes on top. At a time when Intel‚Äôs facing increased pressure from all sides, a move like Lunar Lake is a sign that Intel can adapt and survive.</p>
<p>Intel‚Äôs upcoming Arrow Lake desktop CPU will let Lion Cove stretch its legs with more cache and a larger power budget. Lower latency DDR5 should improve performance even further. After seeing Lion Cove perform well in a mobile form factor, I‚Äôm optimistic about what the same architecture can do on desktop. Recently Intel has been sitting on a rather unstable foundation with Raptor Lake, and Arrow Lake‚Äôs release will be a great time to put the company‚Äôs high performance chips back on stable footing.</p>
<p>Again, we would like to thank ASUS for sending us over a Zenbook S 14 for review and if you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">
<p><span>
<ul>
<li>
<div>
<p><img alt="clamchowder" src="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80"> </p>
</div>

</li>
</ul>
</span>
</p></div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Obsessed with Cuttle: Parametric CAD for prototyping, producing, and procrastin (143 pts)]]></title>
            <link>https://hannahilea.com/blog/cuttle-obsession/</link>
            <guid>41674677</guid>
            <pubDate>Fri, 27 Sep 2024 19:35:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hannahilea.com/blog/cuttle-obsession/">https://hannahilea.com/blog/cuttle-obsession/</a>, See on <a href="https://news.ycombinator.com/item?id=41674677">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <p>
    <nav role="navigation">
      @hannahilea:
      <a href="https://hannahilea.com/">home</a> |
      <a href="https://hannahilea.com/projects">projects</a> |
      <a href="https://hannahilea.com/blog/">blog</a> |
      <a href="mailto:hannah.ilea.robertson+site@gmail.com">contact</a>
    </nav>
    <md-block src="./src.md" hlinks="">
      
    </md-block>
  </p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD Unveils Its First Small Language Model AMD-135M (263 pts)]]></title>
            <link>https://community.amd.com/t5/ai/amd-unveils-its-first-small-language-model-amd-135m/ba-p/711368</link>
            <guid>41674382</guid>
            <pubDate>Fri, 27 Sep 2024 19:05:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.amd.com/t5/ai/amd-unveils-its-first-small-language-model-amd-135m/ba-p/711368">https://community.amd.com/t5/ai/amd-unveils-its-first-small-language-model-amd-135m/ba-p/711368</a>, See on <a href="https://news.ycombinator.com/item?id=41674382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text" id="bodyDisplay">
			
				
					
					
						<p>In the ever-evolving landscape of artificial intelligence, large language models (LLMs) like GPT-4 and Llama&nbsp;have garnered significant attention for their impressive capabilities in natural language processing and generation. However, small language models (SLMs) are emerging as an essential counterpart in the AI model community offering a unique advantage for specific use cases.&nbsp; AMD is excited to release its very first small language model, AMD-135M with Speculative Decoding. &nbsp;This work demonstrates the commitment to an open approach to AI which will lead to more inclusive, ethical, and innovative technological progress, helping ensure that its benefits are more widely shared, and its challenges more collaboratively addressed.&nbsp;</p>
<p><strong>AMD-135M: First AMD Small Language Model&nbsp;</strong></p>
<p>AMD-135M is the first small language model for Llama family that was trained from scratch on AMD Instinct‚Ñ¢ MI250 accelerators&nbsp;utilizing 670B tokens and divided into two models: AMD-Llama-135M and AMD-Llama-135M-code.</p>
<ul>
<li><strong>Pretraining</strong>: The AMD-Llama-135M model was trained from scratch with 670 billion tokens of general data over six days using four MI250 nodes.&nbsp;</li>
<li><strong>Code Finetuning</strong>: The AMD-Llama-135M-code variant was fine-tuned with an additional 20 billion tokens of code data, taking four days on the same hardware.&nbsp;</li>
</ul>
<p>The training code, dataset and weights for this model are open sourced so that developers can reproduce the model and help train other SLMs and LLMs.</p>
<p><strong>Optimization with Speculative Decoding&nbsp;</strong></p>
<p>Large language models typically use an autoregressive approach for inference. However, a major limitation of this approach is that each forward pass can only generate a single token, resulting in low memory access efficiency and affecting overall inference speed.</p>
<p>The advent of speculative decoding has solved this problem. The basic principle involves using a small draft model to generate a set of candidate tokens, which are then verified by the larger target model. This approach allows each forward pass to generate multiple tokens without compromising performance, thereby significantly reducing memory access consumption, and enabling several orders of magnitude speed improvements.</p>
<p><strong>Inference Performance Acceleration</strong></p>
<p>Using AMD-Llama-135M-code as a draft model for CodeLlama-7b, we tested the inference performance with and without speculative decoding on the MI250 accelerator for data center, and Ryzen‚Ñ¢&nbsp;AI processor (with NPU) for AI PC. For the particular configurations that we tested using AMD-Llama-135M-code as the draft model, we saw a<span>&nbsp;</span>speedup on the Instinct MI250 accelerator,&nbsp;Ryzen AI CPU<span size="2">[2]</span>, and on&nbsp;Ryzen AI NPU<span size="2">[2]</span><span>&nbsp;</span>versus the inference without speculative decoding.[3]&nbsp;The AMD-135M SLM establishes an end-to-end workflow, encompassing both training and inferencing, on select AMD platforms.</p>

<p><u><strong>Next Steps</strong></u><br>By providing an open-source reference implementation, AMD is not only advancing its AI capabilities but also fostering innovation within the AI community.&nbsp;To learn more about AMD-135M, read the full technical blog<strong>:&nbsp;<a href="https://www.amd.com/en/developer/resources/technical-articles/introducing-amd-first-slm-135m-model-fuels-ai-advancements.html?utm_source=organic&amp;utm_medium=community&amp;utm_campaign=blog&amp;utm_id=amd35" target="_blank" rel="noopener noreferrer">Introducing the First AMD SLM (Small Language Model): AMD-135M Model Fuels AI Advancements</a></strong></p>
<p><strong>Additional Resources&nbsp;</strong></p>
<ul>
<li>For information about the training, inferencing and insights of this model, please visit <a id="menuro5m" title="https://github.com/amd-aig-aima/amd-llm" href="https://github.com/AMD-AIG-AIMA/AMD-LLM" target="_blank" rel="noreferrer noopener nofollow" aria-label="Link AMD Github">AMD Github</a> repository to get access to the code.</li>
<li>Visit Hugging Face <a id="menuro5o" title="https://huggingface.co/amd/amd-llama-135m" href="https://huggingface.co/amd/AMD-Llama-135m" target="_blank" rel="noreferrer noopener nofollow" aria-label="Link Model Card">Model Card</a> to download the model file.</li>
<li>Apply for Instinct accelerator card access on the&nbsp;<a id="menuro5q" title="https://www.amd.com/en/forms/registration/developer-cloud-application.html" href="https://www.amd.com/en/forms/registration/developer-cloud-application.html" target="_blank" rel="noreferrer noopener" aria-label="Link AMD Developer Cloud">AMD Developer Cloud</a>.</li>
<li>For any questions, contact us by email <a id="menuro5s" title="mailto:amd_ai_mkt@amd.com" href="mailto:amd_ai_mkt@amd.com" target="_blank" rel="noreferrer noopener nofollow" aria-label="Link amd_ai_mkt@amd.com">amd_ai_mkt@amd.com</a>.&nbsp;&nbsp;</li>
</ul>
<p>Explore, innovate, and together, let us push the boundaries of AI.&nbsp;</p>

<p><span size="2">Footnotes</span></p>
<p><span size="2"><span>[1] The training code for AMD-135M is based on </span><span>TinyLlama</span><span>, utilizing multi-node distributed training with PyTorch FSDP.‚ÄØ</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:360}">&nbsp;</span></span></p>
<p><span size="2"><span>[2] Test ran on AMD Ryzen 9 PRO 7940HS with Radeon 780M Graphics. The Ryzen AI APU Architecture includes CPU and NPU kernels.‚ÄØ</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:360}">&nbsp;</span></span></p>
<p><span size="2"><span>[3] These are the configurations that we tested. You might get different results on other configurations.‚ÄØ</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:360}">&nbsp;</span></span></p>
<p><span size="2"><span>[4] The performance had been tested on AMD Instinct MI250 + </span><span>ROCm</span><span>TM</span><span> 6.0 using standardized tests with </span><a href="https://github.com/EleutherAI/lm-evaluation-harness%22%20/t%20%22_blank" target="_blank" rel="noopener nofollow noreferrer"><span>lm-evaluation-harness</span></a><span>. Additionally, the model performance tests are independent of the hardware environment.‚ÄØ</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:360}">&nbsp;</span></span></p>
<p><span size="2"><span>[5] </span><span>Hellaswag</span><span> is dataset and metrics that tests how well that LLMs can reason about physical </span><span>situations;</span><span data-contrast="auto">‚ÄØ‚ÄØ</span><span data-ccp-props="{&quot;134233117&quot;:true,&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559739&quot;:200,&quot;335559740&quot;:360}">&nbsp;</span></span></p>
<p><span size="2"><span>WinoGrande</span><span> is a dataset and codebase for evaluating natural language understanding models on a challenging task of Winograd Schema;&nbsp;&nbsp;</span></span></p>
<p><span size="2"><span>SciQ is a dataset of closed-domain question answering tasks with text inputs and outputs;&nbsp;&nbsp;</span></span></p>
<p><span size="2"><span>MMLU is a dataset of multiple-choice questions on abstract algebra topics, such as groups, rings, fields, and polynomials;&nbsp;</span></span></p>
<p><span size="2"><span>ARC-Easy is a dataset of grade-school level science questions for testing advanced question answering systems.&nbsp;</span></span></p>
<p><span size="2"><span>SlimPajama is a deduplicated version of RedPajama and sources from Commoncrawl, C4, GitHub, Books, ArXiv, Wikpedia and StackExchange. We drop the Books data from SlimPajama due to license issues;&nbsp;</span></span></p>
<p><span size="2"><span>[6] Test ran on AMD Ryzen 9 PRO 7940HS w/ Radeon 780M Graphics. The Ryzen AI APU Architecture includes CPU and NPU kernels.&nbsp;</span></span></p>

					
				
			
			
			
				
			
			
			
			
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Architecture of London Pubs (1966) (101 pts)]]></title>
            <link>https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/</link>
            <guid>41674379</guid>
            <pubDate>Fri, 27 Sep 2024 19:04:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/">https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/</a>, See on <a href="https://news.ycombinator.com/item?id=41674379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p><strong>Stephen Gardiner</strong></p>
<div title="Page 1">
<hr>
<div class="page" title="Page 1">

<p><em><span>.</span><br>
In the mid-sixties, architect and writer, Stephen Gardiner, wrote recurrent socio-cultural architectural analysis for The London Magazine. This installment, on the state of that bastion of so-called English cultural activity, the pub, originally appeared in the December 1966 edition of The London Magazine.</em></p>
</div>
</div>
<p><span>.</span></p>
<p><span>.</span></p>
<p><span data-contrast="auto">What‚Äôs happened to the pub, that most personal piece of English belongings? The place where you stand up and drink, where there are scrubbed oak benches to sit on, partitions to conceal private conversations, men with pipes and caps, and there is sawdust and beer on wooden floors? What‚Äôs happened to those powerful bar tops, the glass flaps over the counter and the bottle-crammed shelves; the complicated cut-glass that fortified you from the fog and the snow, and through which the indecipherable interior form of figures, furniture and lights made impossible shapes from the wet streets outside? What‚Äôs happened? ‚Äì they‚Äôre going, or gone, most of them. The great brewers ‚Äì Watneys, Whitbreads and so on‚Äîare disposing of all that rubbish: that‚Äôs out now, finished with, they say. That‚Äôs dead wood, old hat. We‚Äôre living in a Modern Age. Dickens is dead, you know. Did you know that? Well, some people don‚Äôt. Anyone would think Victoria was still alive! Good God ‚Äì there are new materials now. Chromium plate, plastic (marvellous stuff, formica ‚Äì doesn‚Äôt burn). Wonderful new lacquers you can see your face in and, of course, artificial flowers. Last forever. Well, you can‚Äôt ‚Äã‚Äãbeat that, can you? ‚Äì flowers that last forever. The Germans have patented an artificial scent ‚Äì you just spray it on, each morning ‚Äì Rose, Gardenia ‚Äì have to watch you don‚Äôt get your sprays mixed up, of course ‚Äì not that anyone would notice. No, we don‚Äôt like bare boards, these days. We have to cater for the Young. Yes, yes, I know what you mean but we don‚Äôt encourage that sort of customer any more they‚Äôve got their own pubs to go to this place has changed hands, the street‚Äôs ‚Äòturned over‚Äô and that‚Äôs all there is to it, we‚Äôre afraid. </span></p>
<p><span data-contrast="auto">Drinking‚Äôs a business now, not a hobby. It‚Äôs double gins not pints of beer we‚Äôre after. Why doesn‚Äôt someone introduce the treble gin? ‚Äì it‚Äôll come, sir, it‚Äôll come ‚Äì amazing how much money there is about ‚Äì even in the Freeze ‚Äì just flowing like gin. Yes, we like the place to look friendly ‚Äì plenty of flowers (</span><i><span data-contrast="auto">and </span></i><span data-contrast="auto">leaves, they make rather a nice dark green variety), and I like pink net formica myself although Market Research generally settles matters of taste. Close-carpeting is best, so warm ‚Äì avocado, salmon, peach and shrimp are popular colours. And naturally, as you see, sir, we do food now‚Ä¶ A little Italian prosciutto? broad beans? a spot of corn? tomatoes? ‚Äì they‚Äôre lovely today, really beautiful. French bread? No?‚Ä¶ No, I‚Äôm afraid the crabs are just part of the d√©cor. They‚Äôre wax.</span><span data-ccp-props="{}">&nbsp;</span></p>
<figure id="attachment_94333" aria-describedby="caption-attachment-94333"><img data-attachment-id="94333" data-permalink="https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/untitled-design-7-7/" data-orig-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7.png" data-orig-size="1200,630" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Untitled design (7)" data-image-description="" data-image-caption="" data-medium-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-300x158.png" data-large-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-1024x538.png" decoding="async" loading="lazy" src="https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7.png" alt="" width="1200" height="630" srcset="https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7.png 1200w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-300x158.png 300w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-1024x538.png 1024w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-150x79.png 150w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Untitled-design-7-500x263.png 500w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption id="caption-attachment-94333">Sketches all from the essay and by Stephen Gardiner.</figcaption></figure>
<p><span data-contrast="auto">Pubs, in fact, are going the way of all those other things one cherishes ‚Äì the countryside, eighteenth-century bits of towns and villages, and the only sort of structure it seems nobody dares touch are churches and this is probably for some bogus superstitious reason. Otherwise the ghastly formula for modernisation is applied wholesale ‚Äì a formula which is a middle-class conception of what the twentieth-century is all about, a sixth-hand version of contemporary </span><span data-contrast="auto">design, and so far as pubs are concerned the best parallel in the building business is the shoddy reproduction Georgian terrace which contains the latest (and cheapest) thing in aluminium sinks, cookers and the rest. It seems to me that the organisers of these projects are, in general, deliberately out to destroy anything which is unique, unusual or eccentric because they feel such things must conform with their pattern of life ‚Äì the pattern they understand and which makes them feel safe and secure. Places must be the same. Friends must be the same sort of people, they must wear the same sort of clothes, say the same things. </span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">If they are not the same, then the friend gets struck off some list or other, and while it may possibly be reasonable to file away people into cabinets with smoothly sliding drawers, such things as buildings and pubs come into a different category. Architecture belongs to everyone and ought to be protected by the few who understand it. Of course it isn‚Äôt, because there is no one to do the job, or so it seems. How can you, therefore, expect anything but the destruction of pubs on a universal scale? Pubs are a universal English business. A formula has to be found to fit the majority taste. Something which is much the same ‚Äì like battery hens and cattle factories.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">The first thing to go, when the formula is applied, are the separate compartments and partitions. In this way the variety provided by different bars ‚Äì public, saloon, private etc. ‚Äì is eliminated at a stroke. This happened, for example, at two excellent Chelsea pubs ‚Äì the King‚Äôs Head and the Phene ‚Äì when they were given the treatment two or three years ago. Both were devastated, both look as though a giant vacuum cleaner has passed over them leaving them forlorn, empty, desperately clean, and with just a few fixtures like a structural column or two. Otherwise everything was sucked out of them‚Äîall that was good and of real value like the old bar tops, the high backed wooden seats, the grimy mahogany tables with their curvaceous cast-iron legs,</span><span data-ccp-props="{}">&nbsp;</span><span data-contrast="auto">the lovely intricate shelves and polished brass rods and knobs, the dark panelling and even the old men with caps and pipes (imagine them sitting in glittering, close-carpeted no-man‚Äôs-land!). How can it happen? ‚Äì and it is happening everywhere.</span><span data-ccp-props="{}">&nbsp;</span></p>
<figure id="attachment_94335" aria-describedby="caption-attachment-94335"><img data-attachment-id="94335" data-permalink="https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/website-image/" data-orig-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image.png" data-orig-size="1200,630" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Website image" data-image-description="" data-image-caption="" data-medium-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-300x158.png" data-large-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1024x538.png" decoding="async" loading="lazy" src="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image.png" alt="" width="1200" height="630" srcset="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image.png 1200w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-300x158.png 300w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1024x538.png 1024w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-150x79.png 150w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-500x263.png 500w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption id="caption-attachment-94335">Credits: Stephen Gardiner.</figcaption></figure>
<p><span data-contrast="auto">Quite shortly the English pub will be extinct, part of history. The trouble is that the wretched brewers, in their hurry to find a modern equivalent of the traditional interior, neither stop to think nor to find proper architects and designers. Pubs shouldn‚Äôt be in the hands of hacks in their ‚Äòinterior department‚Äô; but then it clearly has not filtered through to them that the contents of these old places do have a value, as any antique dealer could tell them. And instead of rushing ahead with the steamroller that sticks down the rule-of-thumb carpets, wallpapers and</span><span data-ccp-props="{}">&nbsp;</span><span data-contrast="auto">plastic tops they should make it their business to discover what the past has to offer in the way of lessons in design and why the kind of plans that were used in the old days were so good, and seem particularly so when set against the dreadful ‚Äòschemes‚Äô that are being done now. It‚Äôs no use the customer objecting. (I tried it once, saying angrily, as if I had been tricked in some way: ‚ÄòWhat‚Äôs happened here?‚Äô The manager merely said stonily: ‚ÄòThe customers like it.‚Äô) No, it‚Äôs up to the brewer. And there are a few obvious arguments that can be put to him. After all, to start with an elementary point, when you are inserting a new inside to a building of quality belonging to a good architectural period the normal and correct procedure is to consider your design in relation to what happens on the outside ‚Äì the scale, character and proportion of it, the detailing of the windows and so on; and by this I mean the sort of close observation which catches the atmosphere of the design and the period. If instead the inside is considered in isolation ‚Äì and it is part of an architect‚Äôs responsibility to see that the whole of a problem is solved and not pieces of it ‚Äì then the total result is bound to end as an architectural disaster.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">If you are landed with a Georgian or an early Victorian structure an answer has to be found which is somehow, although by no means literally, in sympathy with it. Should the brewer reject this argument as unimportant he is in fact dismissing something which is fundamental to the making of architecture of any time, and he is not worth talking to. But if he agrees one can go on. And if Henekey‚Äôs in the Portobello Road can make a good job of an interior with a few shelves, barrels, and glass-panelled partitions, then surely an architect of today can too ‚Äì provided he has insight, feeling and some imagination, and is not too conscious of being an architect.</span><span data-ccp-props="{}">&nbsp;</span></p>
<figure id="attachment_94337" aria-describedby="caption-attachment-94337"><img data-attachment-id="94337" data-permalink="https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/website-image-2/" data-orig-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2.png" data-orig-size="1200,630" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Website image (2)" data-image-description="" data-image-caption="" data-medium-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-300x158.png" data-large-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-1024x538.png" decoding="async" loading="lazy" src="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2.png" alt="" width="1200" height="630" srcset="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2.png 1200w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-300x158.png 300w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-1024x538.png 1024w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-150x79.png 150w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-2-500x263.png 500w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption id="caption-attachment-94337">Credits: Stephen Gardiner.</figcaption></figure>
<p><span data-contrast="auto">The main problem is the plan: it always is, in any architectural problem. Once you‚Äôve got your idea for the plan straight you can settle down to filling in the other gaps ‚Äì structure, materials, finishes and so on. Well, what is the most successful sort of pub plan? And the only possible point one can start from with any design is one‚Äôs own experience ‚Äì what sort of pub plan does one like best? Some pubs are huge and lavishly decorated with engraved glass like the Salisbury in St Martin‚Äôs Lane; others are huge but spare in their finishes and resemble great barns which contain things like dart boards and bar billiards; others are small and lavish like the Red Lion in Duke Street W1, or the Victoria in Sussex Place W8, and don‚Äôt have darts; others, again, are small and sparse like the Nag‚Äôs Head in Kinnerton Street SW1, or The Raven in Battersea Church Road and this one does have darts. But all the best pubs, the pubs which have the genuine atmosphere which is as solid as the people who inhabit them, do possess one thing in common and this is the position of the bar: it is always sited so that, like an altar in a church, it is the focus of attention. It is either in the centre of the whole space or it is arranged so that it forms clearly defined areas around it, and it is so shaped that it appears to personally control these areas. </span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">From this point on, the plan is developed to emphasise the areas, to increase their privacy and to simplify the control of them. Privacy is an important factor in pubs: the subtle suggestion of a room where there is exclusive service takes one back a bit ‚Äì to those small inns embedded deep in the country, or within listening distance of the waves breaking, with their high-backed black dining seats ‚Äì and there is something comforting and a little mysterious about it all, with a vague sense of nostalgia added in, a nostalgia for something remembered from history books and romantic stories and evoked by such details as the barrels at Henekey‚Äôs that have the white lettering on them. And this is why these partitions with their engraved glass panels have a real charm. The sense of privacy is complete but you can still see through the smoky glass, enough at any rate to identify a shadowy silhouette beyond. So the ideal plan seems to be, to my mind at least, one where the bar is in the centre (or approximates to this position), and where there are a number of compartments which are separated by partitions which have a somewhat temporary look, but which radiate from the bar.</span><span data-ccp-props="{}">&nbsp;</span></p>
<figure id="attachment_94336" aria-describedby="caption-attachment-94336"><img data-attachment-id="94336" data-permalink="https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/website-image-1/" data-orig-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1.png" data-orig-size="1200,630" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Website image (1)" data-image-description="" data-image-caption="<p>Credits: Stephen Gardiner.</p>
" data-medium-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-300x158.png" data-large-file="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-1024x538.png" decoding="async" loading="lazy" src="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1.png" alt="" width="1200" height="630" srcset="https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1.png 1200w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-300x158.png 300w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-1024x538.png 1024w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-150x79.png 150w, https://thelondonmagazine.org/wp-content/uploads/2024/09/Website-image-1-500x263.png 500w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption id="caption-attachment-94336">Credits: Stephen Gardiner.</figcaption></figure>
<p><span data-contrast="auto">We can go on from there. The ideal pub has a low ceiling because this is correct for the scale of the compartments and increases the suspense; you see it carrying on above the top of the partitions which it misses by about a foot, and you wonder what‚Äôs going on over the other side. The ideal pub also has some division between the compartment and the bar areas and this is sometimes in the form of glass flaps, as at Henekey‚Äôs, or in the form of unaffected but beautifully made shelves such as one finds at the Victoria in Sussex Place, the City Barge at Strand-on-the-Green and the Hansom Cab in the Earl‚Äôs Court Road. These shelves are always filled with bottles (and the colour of bottles really does glow, particularly when you think of the different colours of the drinks that fill them) and all kinds of glasses ‚Äì those huge brandy glasses, for example, which reflect light so admirably. This brings us to the question of display in general. The chief centre for display ‚Äì in the ideal pub ‚Äì is right there in the middle of the bar area and that‚Äôs where pretty well everything for sale is on show: this is the shop window. This is where labels matter and become, like the lettering and the inn signs outside, the d√©cor. A concentration of labels and calligraphic handwriting can be marvellous. The ideal pub has a genius for the ideal display.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">So it seems that, in the final analysis, the design of the pub comes down to a few known quantities: ceiling heights, partitions, simple country scrubbed furniture or something lavish in leather (whatever the call), shelves and glass, the loving display of a collector and the dominating father-figure, the bar. But there are obviously no cut-and-dried rules. You don‚Äôt have to have partitions, and the Hansom Cab, for example, with its irregular, rambling plan manages both suspense and intimacy very well indeed without them. And ceilings can be high provided the total space ‚Äì like that of the Salisbury ‚Äì requires and sustains such height.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">And what about the brewer? Well, he might as well know that there are no good modern pubs: the Hoop from Finch‚Äôs is absurdly over-elaborate, The Champion is self-conscious, the Hansom Cab is (although well done) a reproduction piece and the Ranelagh in Pimlico is really terrible. For the brewer there are two rules which he must obey if the English pub tradition is to be protected. They are quite simple. If a good pub comes up for redecoration and alterations the best things and the authentic details must be preserved. If a bad pub comes up ‚Äì and there are a depressingly large number of them ‚Äì start again from scratch, but with the right architect.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Lastly, don‚Äôt forget the dart board and the bar billiards which the TV set, in some curious, and odious, fashion, seems to have replaced. And no artificial flowers, by request, please.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span>.</span></p>
<p><span>.</span></p>
<p><strong>Stephen Gardiner</strong> was a British architect, teacher and writer. Born and raised in Chelsea, he wrote regularly for <em>The London Magazine&nbsp;</em>and&nbsp;<em>The Observer.</em></p>
<hr>
<p><em>To discover more content exclusive to our print and digital editions,&nbsp;<strong><a href="https://www.thelondonmagazine.org/product/recurring-subscription/">subscribe here</a></strong>&nbsp;to receive a copy of The London Magazine to your door every two months, while also enjoying full access to our extensive digital archive of essays, literary journalism, fiction and poetry.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SAML: A Technical Primer (204 pts)]]></title>
            <link>https://ssoready.com/docs/saml/saml-technical-primer</link>
            <guid>41674109</guid>
            <pubDate>Fri, 27 Sep 2024 18:38:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssoready.com/docs/saml/saml-technical-primer">https://ssoready.com/docs/saml/saml-technical-primer</a>, See on <a href="https://news.ycombinator.com/item?id=41674109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>If you just want to start integrating SAML right away, check out the <a href="https://ssoready.com/docs/saml/saml-quickstart">SAML
quickstart</a>. You can get a SAML integration
working end-to-end within a few hours.</p><p>This article is for folks who want to understand SAML at a deeper technical
level, or how they could implement SAML without using an open-source library
like SSOReady.</p></div>
<p><a target="_blank" rel="noreferrer" href="https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language">SAML<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>
(‚ÄúSecurity Assertion Markup Language‚Äù) is a source of a lot of confusion for
developers. This article is a technical primer on some of the most common
questions engineers and other technical folks have about SAML:</p>
<ol>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#what-is-the-point-of-saml">Why do businesses want their software vendors to support SAML</a>? In other
words, how does SAML fit into my customer‚Äôs business? Why do end users and C-level executives at my customer care about SAML?</li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#fitting-saml-into-your-existing-software">How should I fit SAML into my exiting software</a>? What parts of my software stack
need to be ‚ÄúSAML-aware‚Äù? How lightweight can I make my integration? (The answer: quite lightweight. Only a small part of your codebase needs to know about SAML at all.)</li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-at-a-technical-level">At a technical level, how does SAML even work</a>? What does the SAML protocol
even do? What kinds of security guarantees does it give me, or what assumptions can I make about it?</li>
</ol>
<h2 id="what-is-the-point-of-saml" data-state="closed">What is the point of SAML?</h2>
<p>You care about supporting SAML because your customer wants your product to
support SAML. This is sound reasoning on your part. But why does your customer
want SAML support?</p>
<h2 id="one-click-to-login-why-your-users-like-saml" data-state="closed">One click to login: why your users like SAML</h2>
<p>Your users probably don‚Äôt know what SAML is. What they do know about is their
company‚Äôs <em>identity provider</em>. The most popular one is called
<a target="_blank" rel="noreferrer" href="https://www.okta.com/customer-identity/single-sign-on/">Okta<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>; other common
competitors to Okta include <a target="_blank" rel="noreferrer" href="https://www.microsoft.com/en-us/security/business/identity-access/microsoft-entra-id">Microsoft
Entra<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>
(formerly ‚ÄúAzure Active Directory‚Äù) and <a target="_blank" rel="noreferrer" href="https://workspace.google.com/">Google
Workspace<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>. There are dozens more vendors in this
space (big companies often build their own internal alternatives), and they all
use the SAML protocol.</p>
<p>Even though your users don‚Äôt know what SAML or what an identity provider is,
they do love what it gives them: one-click login experience for every SaaS tool
they use at work, a so-called <em>Single Sign-On</em> (SSO) experience.</p>
<p>For example, here‚Äôs what Okta looks like for your users. When your user opens
their computer at work in the morning, this is what they see:</p>
<figure><figcaption>A screenshot of Okta. Every app they use at work gets a 'tile'. Click on a tile, and you're now logged into it.</figcaption></figure>
<p>At work, your users only need one password: their identity provider password.
They don‚Äôt need to set up or remember passwords anywhere. They might find
logging into Okta itself a bit annoying, because their IT team requires
two-factor authentication to log into Okta, but logging into everything else is
a breeze.</p>
<h2 id="one-click-to-fire-why-your-customers-ciso-likes-saml" data-state="closed">One click to fire: why your customer‚Äôs CISO likes SAML</h2>
<figure><figcaption>A screenshot of an IT admin deprovisioning an Okta user. CISOs love SAML because it lets them lock down all of an employee's accounts from a single place.</figcaption></figure>
<p>Your customer‚Äôs
<a target="_blank" rel="noreferrer" href="https://www.cisco.com/c/en/us/products/security/what-is-ciso.html">CISO<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a> (Chief
Information Security Officer) is in charge of making sure company data is
secure. Concretely, the biggest things they worry about is:</p>
<ul>
<li>Employees accidentally leaking data, because they use the same password
everywhere and that password got breached</li>
<li>Employees intentionally leaking data, because they were fired and want revenge</li>
</ul>
<p>CISOs love vendors that support SAML because they can put those vendor‚Äôs apps
inside the corporate identity provider, e.g. Okta. From there:</p>
<ul>
<li>
<p>Employees don‚Äôt need to have a password for that vendor. They just log in
using the identity provider. The identity provider uses the SAML protocol to
securely log the employee into the vendor‚Äôs app.</p>
</li>
<li>
<p>When the company fires someone, an IT admin doesn‚Äôt have to manually go in and delete that employee‚Äôs
account from the vendor. Once you remove an employee from Okta, then
Okta will stop letting that employee do SAML-based logins into <em>anything</em> (every
identity provider works like this). The fired employee is locked out of every
work application.</p>
</li>
</ul>
<p>But none of this works if your application doesn‚Äôt implement SAML. SAML is the
protocol that powers single-sign on, which lets identity providers like Okta log
employees into your app without using a password.</p>
<p>This is why many CISOs will go as far as to <em>require</em> SAML support out of all
vendors. Many companies have regulatory, contractual, or compliance obligations
to ensure employees don‚Äôt use insecure passwords and are properly off-boarded
after being fired. CISOs meet those obligations using SAML.</p>
<h2 id="fitting-saml-into-your-existing-software" data-state="closed">Fitting SAML into your existing software</h2>
<div><p>If you read <a target="_blank" rel="noreferrer" href="https://docs.oasis-open.org/security/saml/v2.0/saml-core-2.0-os.pdf">the SAML
specification<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>,
or look at <a target="_blank" rel="noreferrer" href="https://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html">documentation written about SAML<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>
(especially if those docs were written in the early 2000s), it might seem like
SAML is a framework that can subsume or replace all of auth. Don‚Äôt do this.</p><p>‚ÄùSAML solves everything‚Äù was a hot idea in 2002, but the industry has
moved away from this. The contemporary consensus is that SAML isn‚Äôt a great
protocol. Just use SAML as a way to securely find out what a corporate
user‚Äôs email address is.</p></div>
<p>You should think of SAML as a self-contained login method. You probably already
let your users log into your product using things like username+password, email
magic links, ‚ÄúLog in with Google‚Äù, etc. Think of SAML as another login method.</p>
<p>SAML is a protocol that lets your customer‚Äôs employees securely prove to you
what their email address is, without you having to worry about sending them
confirmation emails, verifying they‚Äôre still employed at the company, or that
they belong to the right team at the company.</p>
<p>Roughly speaking, only two parts of your overall system need to know about SAML:</p>
<ol>
<li>
<p>Your login page needs to know that SAML is a login option for a customer.
There are a couple common UI flows for doing this. We cover these in depth in
the <a href="https://ssoready.com/docs/saml/integrating-saml-into-your-login-ui">Integrating SAML with your Login
UI</a> guide.</p>
<p>Ultimately, your login page will, at a technical level, <a href="https://ssoready.com/docs/saml/saml-technical-primer#initiating-a-saml-login">initiate a SAML
login</a>.</p>
</li>
<li>
<p>Your login backend system needs to be able to <a href="https://ssoready.com/docs/saml/saml-technical-primer#handling-a-saml-assertion">handle SAML
assertions</a>. We cover this in depth in the <a href="https://ssoready.com/docs/saml/handling-saml-logins-jit-provisioning">Handling
SAML Logins</a> guide.</p>
<p>Ultimately your backend runs an HTTP endpoint, and your user‚Äôs web browsers
will POST SAML payloads there. You verify those payloads, and use your
normal session system (the same one you use for other kinds of logins) to
create a session for the email you securely extracted from the SAML
payload.</p>
</li>
</ol>
<p>If you don‚Äôt use an open-source library like SSOReady to help implement SAML,
the lack of structure that SAML imposes on you ‚Äî as well as historical baggage
from the early days of SAML ‚Äî can lead you astray in two common
ways:</p>
<ol>
<li>
<p>SAML supports the idea of putting ‚Äúmetadata‚Äù on a login session,
configuring ‚Äúconditional access‚Äù, and lots of other fancy functionality. It
might seem like supporting SAML means having your entire system be able to honor
these advanced SAML-specific features.</p>
<p>Without getting into too much detail on what
that functionality was meant to achieve in 2002, suffice it to say that most
modern software systems don‚Äôt use this functionality at all.</p>
<p>If you treat SAML as just a way to get a user‚Äôs email, you will be in line
with almost all other SAML-supporting software your customer is used to.
CISOs expect, and will be satisfied with, this kind of simple integration.</p>
</li>
<li>
<p>SAML is, unfortunately, much more annoying to configure than any other login
method you already support. The technical details of these SAML settings are
covered later in this article <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">here</a>.</p>
<p>You and your customer need to exchange settings about one another before a SAML
login can even begin. But that configuration
happens ‚Äúoffline‚Äù ‚Äî if you‚Äôre not using SSOReady, you‚Äôll implement it by
exchanging informal emails with your customer. If you do use SSOReady, you can
have your customer <a href="https://ssoready.com/docs/idp-configuration/enabling-self-service-configuration-for-your-customers">self-serve configure their SAML
setup</a>.</p>
<p>You don‚Äôt typically have to write
any UI or backend code related to configuring SAML configuration, beyond having
some way for your engineers to store the SAML settings you got from your
customer. You just need to store three small pieces on your backend (two strings
plus an X.509 certificate), and those settings change very infrequently.</p>
</li>
</ol>
<h2 id="saml-at-a-technical-level" data-state="closed">SAML at a technical level</h2>
<div><p>This section gets quite technical. You don‚Äôt need to understand this
material to understand how to use SSOReady. This section is, in a way, a
high-level overview of everything SSOReady abstracts away for you.</p></div>
<p>At the end of the day, SAML is a protocol that lets one of your users tell you
(‚Äúassert‚Äù) their email address using a payload (an ‚Äúassertion‚Äù) that is
self-contained. When you get a SAML payload, you can securely know:</p>
<ol>
<li>Which of your corporate customers sent you the payload,</li>
<li>What email address, according to that corporate customer, this user has</li>
<li>That the corporate customer wants you to log this user in right away</li>
</ol>
<p>The tricky part about SAML is that you need to watch out for:</p>
<ol>
<li>Forged SAML assertions, wherein an attacker pretends to be one of your
corporate customers</li>
<li>Malicious or misconfigured corporate customers sending assertions about other
company‚Äôs employees, e.g. EvilCorp (<code>evilcorp.com</code>) telling you to log someone
in as the CEO of AcmeCorp (<code>ceo@acmecorp.com</code>).</li>
</ol>
<p>If you use SSOReady, these issues are both automatically covered by you.
Otherwise, you‚Äôll typically need to implement (2) yourself, and you may want to
audit your SAML
dependency to make sure they adequately handle (1). Sadly, securely
authenticating SAML is tricky, and many libraries <a target="_blank" rel="noreferrer" href="https://nvd.nist.gov/vuln/detail/CVE-2024-45409">don‚Äôt do it
right<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>.</p>
<h2 id="the-saml-flow" data-state="closed">The SAML Flow</h2>
<p>There are three actors involved in a SAML flow:</p>
<ol>
<li>
<p>You are the <strong>service provider</strong> (‚ÄúSP‚Äù). The service provider is software
product being logged into via SAML.</p>
</li>
<li>
<p>Your customer‚Äôs Okta/Entra/Google/etc is the <strong>identity provider</strong> (‚ÄúIDP‚Äù).
The identity provider is responsible for knowing whether a user is a real
employee that wants to log into a product, and for telling service providers
about that information using SAML.</p>
</li>
<li>
<p>The <strong>user</strong> is mostly just along for the ride. In SAML, the SP and the IDP will
redirect the user to each other. The user‚Äôs browser is responsible for carrying
messages back and forth between the SP and IDP.</p>
</li>
</ol>
<figure><figcaption>A sequence diagram of a successful SAML login flow.</figcaption></figure>
<p>Logging in via SAML has five high-level steps:</p>
<ol>
<li>You and your customer agree, offline, on some settings about how you‚Äôre going
to do SAML.</li>
<li>When it‚Äôs time to log in via SAML, you have the user POST a SAML
<code>AuthnRequest</code> to your customer‚Äôs identity provider. This is called ‚Äúinitiating‚Äù
a SAML login.</li>
<li>Your customer‚Äôs identity provider handles making sure the user really has
valid corporate credentials. This step is entirely outside your app‚Äôs
control.</li>
<li>The identity provider has the user POST a SAML <code>Assertion</code> to your HTTP server.</li>
<li>You authenticate that the assertion is legitimate, and then log the user into
your product.</li>
</ol>
<div><p>If you‚Äôre familiar with OAuth, this flow might sound familiar. The biggest
difference between SAML and OAuth is how you verify the user after they get
redirected back to your application.</p><p>In OAuth, your backend server typically takes a <code>code</code> from the user, and
asks the identity provider if this <code>code</code> is legitimate, and what the
underlying user‚Äôs details are if it is.</p><p>In SAML, your backend server never talks directly to the identity provider.
You have to look at the assertion and use public-key cryptography to tell if
the identity provider cryptographically signed the message.</p></div>
<p>Step (1) is important conceptually, but doesn‚Äôt require any code. That‚Äôs covered
in the next section: <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">SAML Configuration</a>. Steps (2) and
(5) are the ones you have to write code for. They‚Äôre covered in <a href="https://ssoready.com/docs/saml/saml-technical-primer#initiating-a-saml-login">Initiating a
SAML Login</a> and <a href="https://ssoready.com/docs/saml/saml-technical-primer#handling-a-saml-assertion">Handling a SAML
Assertion</a>.</p>
<h3 id="sp--vs-idp-initiated-saml-flows" data-state="closed">SP- vs IDP-initiated SAML flows</h3>
<p>The discussion above illustrates the ‚ÄúSP-initiated‚Äù SAML flow, where your
application (the SP) decides to kick off the SAML flow.</p>
<p>SAML also supports ‚ÄúIDP-initiated‚Äù flows, where the IDP kicks off the SAML flow,
and just directly sends the user to your ACS URL with an assertion.</p>
<figure><figcaption>A sequence diagram of a successful IDP-initiated flow.</figcaption></figure>
<p>The only difference between an SP- and an IDP-initiated flow is that
IDP-initiated flows won‚Äôt require you to <a href="https://ssoready.com/docs/saml/saml-technical-primer#initiating-a-saml-login">initiate
them</a>, and as a result don‚Äôt have <a href="https://ssoready.com/docs/saml/saml-technical-primer#including-a-relaystate">a <code>RelayState</code></a>. Both
are widely used in
practice.
When you use SSOReady, you get both SP- and IDP-initiated SAML support
automatically.</p>
<h2 id="saml-configuration" data-state="closed">SAML Configuration</h2>
<p>For each of your customers, you will have five settings associated with the SAML
connection you have with them. These settings are:</p>
<ul>
<li>
<p>An <strong>Assertion Consumer Service (‚ÄúACS‚Äù) URL</strong>. You assign this value. It‚Äôs a
URL where you run an HTTP endpoint that‚Äôs ready to <a href="https://ssoready.com/docs/saml/saml-technical-primer#handling-a-saml-assertion">handle SAML
assertions</a>. When the identity provider redirects
the user back to your application, they‚Äôll send the user to the ACS URL.</p>
</li>
<li>
<p>An <strong>SP Entity ID</strong>. You assign this value, and it must be unique for every
customer. It‚Äôs a generic string, but
conventionally it‚Äôs formatted as a URL. The identity provider will include this SP
Entity ID in the
assertions it sends you, and you‚Äôll use it to ensure the assertion was meant
for <em>you</em> and not some other application.</p>
</li>
<li>
<p>An <strong>IDP Redirect URL</strong>. The IDP assigns this value. When you <a href="https://ssoready.com/docs/saml/saml-technical-primer#initiating-a-saml-login">initiate a SAML
login</a>, this is the URL you redirect the user to.</p>
</li>
<li>
<p>An <strong>IDP Entity ID</strong>. The IDP assigns this value. It‚Äôs a generic string, but
conventionally it‚Äôs formatted as a URL. When you initiate a SAML
login, you include this value so the IDP knows which application is starting
the login. The IDP will include this IDP Entity ID in the assertions it sends
you, and you‚Äôll use it to make sure the assertion is coming from the right
identity provider.</p>
</li>
<li>
<p>An <strong>IDP Certificate</strong>. The IDP assigns this value. The IDP will use this certificate to
cryptographically sign the assertions it sends you. You will use
this certificate to authenticate that the identity provider really generated the
assertion, and that it wasn‚Äôt forged or tampered with.</p>
</li>
</ul>
<p>Once you have all of these settings in place, you can begin doing SAML logins.</p>
<h2 id="initiating-a-saml-login" data-state="closed">Initiating a SAML Login</h2>
<p>Initiating a SAML login concretely consists of having your user‚Äôs web browser
send a POST request with a payload that looks like this:</p>

<p>The <code>Issuer</code> needs to be equal to the <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">SP Entity ID</a>.</p>
<p>That POST request needs to be pointed at the <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">IDP Redirect
URL</a>. The POST request needs to be a standard HTTP form,
with the <code>AuthnRequest.xml</code> being base64-encoded and set as a form field called
<code>SAMLRequest</code>.</p>
<p>You can‚Äôt use a normal HTTP redirect to have your user POST a form to another
URL. The typical workaround is to render your user a form that self-submits
using JavaScript:</p>
<div><div><p><span>Self-Submitting SAML Initiation Form</span></p></div><pre tabindex="0"></pre></div>
<h3 id="including-a-relaystate" data-state="closed">Including a <code>RelayState</code></h3>
<p>When initiating a SAML login, you can optionally include a <code>RelayState</code>
parameter. You include this data as an additional parameter in the POST request:</p>
<div><div><p><span>Self-Submitting SAML Initiation Form with a RelayState</span></p></div><pre tabindex="0"></pre></div>
<p>Whatever you put in <code>RelayState</code> will be echoed back to you when you <a href="https://ssoready.com/docs/saml/saml-technical-primer#handling-a-saml-assertion">handle the
SAML assertion</a>. The HTTP POST you receive will
contain, alongside the usual <code>SAMLResponse</code> entry, a <code>RelayState</code> entry.</p>
<p>The typical use-case for <code>RelayState</code> is to keep track of what page your user
was on before forced them to log in with SAML. Then, once they‚Äôre done logging
in with SAML, you redirect the user back to the page they were previously on.</p>
<div><p>You can‚Äôt trust that the <code>RelayState</code> you get back from an identity provider
is the same as the one you chose when initiating the SAML login. An attacker
can always send you a request with their own <code>RelayState</code> instead.</p><p>The most common security risk associated with <code>RelayState</code> is when you store
a URL in that <code>RelayState</code>, but don‚Äôt authenticate its legitimacy. If the
<code>RelayState</code> is allowed to redirect to a URL outside of your web
application, then you have an <a target="_blank" rel="noreferrer" href="https://cwe.mitre.org/data/definitions/601.html">open redirect
vulnerability<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>.</p><p>The safest solution is to cryptographically sign the <code>RelayState</code> value you
include in your request using a secret key. When you use SSOReady, every
<code>RelayState</code> is cryptographically authenticated; you do not need to worry
about the <a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows#state"><code>state</code>
parameter</a> being tampered
with.</p></div>
<h2 id="handling-a-saml-assertion" data-state="closed">Handling a SAML Assertion</h2>
<p>After you <a href="https://ssoready.com/docs/saml/saml-technical-primer#initiating-a-saml-login">initiate a SAML login</a>, the user is now on
the identity provider‚Äôs website. The user then identifies
themselves to the identity provider. Exactly how this works is outside of your
control.</p>
<div><p>Typically, an identity provider will ask for a user‚Äôs password, and
then may do multi-factor authentication checks. The point of SAML is that your
customer‚Äôs IT admin decides on their corporate security policy, and their
identity provider implements the logic. Your application doesn‚Äôt need to worry
about it.</p></div>
<p>If the identity provider decides to not proceed ‚Äî maybe the user is fired, or
maybe hasn‚Äôt been internally authorized to use your application (e.g. your
customer only wants engineers using your app, but the employee works in sales),
then from your perspective, nothing happens. You‚Äôll never hear back from the
login attempt. SAML doesn‚Äôt have a ‚Äúlogin attempt failed‚Äù mechanism.</p>
<p>But if the login succeeds, then your user‚Äôs web browser will be redirected back
to your <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">SAML ACS URL</a>. The user will POST you a standard
set of HTML form data. That form data will contain up to two values:</p>
<ul>
<li>A <code>SAMLResponse</code> element, containing a base64-encoded XML document. This is
the SAML assertion.</li>
<li>A <code>RelayState</code>. This is only included if you <a href="https://ssoready.com/docs/saml/saml-technical-primer#including-a-relaystate">included a <code>RelayState</code> in your
initiation request</a>.</li>
</ul>
<p>The job of ‚Äúhandling a SAML login‚Äù consists of three steps:</p>
<ol>
<li>Authenticating the legitimacy of the SAML payload</li>
<li>Deciding whether you want to honor the SAML request</li>
<li>Logging the user in</li>
</ol>
<p>To do any of this, you first need to parse the SAML assertion, and make sense of
its contents.</p>

<h3 id="anatomy-of-a-saml-assertion" data-state="closed">Anatomy of a SAML assertion</h3>
<p>The previous section discusses how your <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">ACS URL</a> will
receive an HTML form with a <code>SAMLResponse</code>. Here‚Äôs a real example of such a
<code>SAMLResponse</code>, base64-decoded, that came from Okta:</p>

<p>When we later <a href="https://ssoready.com/docs/saml/saml-technical-primer#cryptographically-authenticating-a-saml-assertion">authenticate the SAML
assertion</a>, this is the
payload we will be authenticating. Whitespace matters.</p>
<p>But for the purposes of human legibility, let‚Äôs look at it in a prettier form:</p>
<div><div><p><span>assertion.xml (Pretty-Indented)</span></p></div><pre tabindex="0"></pre></div>
<p>The most important pieces of information are:</p>
<ul>
<li>
<p>The assertion <strong>issuer</strong> lives in <code>&lt;saml2:Issuer&gt;</code></p>

</li>
<li>
<p>The assertion <strong>signature</strong> lives in <code>&lt;ds:Signature&gt;</code> (specifically the one
inside <code>&lt;saml2:Assertion&gt;</code>). The most important parts are the</p>
<ul>
<li>Canonicalization <code>Algorithm</code> on <code>&lt;ds:CanonicalizationMethod&gt;</code></li>
<li>Signature <code>Algorithm</code> on <code>&lt;ds:SignatureMethod&gt;</code></li>
<li>Digest <code>Algorithm</code> on <code>&lt;ds:DigestMethod&gt;</code></li>
<li>The digest hash in <code>&lt;ds:DigestValue&gt;</code></li>
<li>The signature value in <code>&lt;ds:SignatureValue&gt;</code></li>
</ul>

</li>
<li>
<p>The assertion <strong>subject ID</strong> lives in <code>&lt;saml2:NameID&gt;</code></p>

</li>
<li>
<p>The assertion‚Äôs <strong>validity window</strong> is specified by the <code>NotBefore</code> and <code>NotOnOrAfter</code> on <code>&lt;saml2:Conditions&gt;</code></p>

</li>
<li>
<p>The assertion‚Äôs <strong>audience</strong> lives in <code>&lt;saml2:Audience&gt;</code></p>

</li>
</ul>
<p>Validating the assertion signature is what <a href="https://ssoready.com/docs/saml/saml-technical-primer#cryptographically-authenticating-a-saml-assertion">cryptographically authenticating a
SAML assertion</a> is all
about. Validating all the other pieces of information ‚Äî the issuer, the subject
ID, the validity window, the audience ‚Äî happens when you <a href="https://ssoready.com/docs/saml/saml-technical-primer#deciding-whether-to-honor-a-saml-login">decide whether to
honor the login</a>.</p>
<h3 id="cryptographically-authenticating-a-saml-assertion" data-state="closed">Cryptographically authenticating a SAML assertion</h3>
<div><p>Cryptographically authenticating SAML assertions is the most perilous part
of implementing SAML. This is the step where the most security-critical
mistakes happen.</p><p>If you choose to implement this yourself, you‚Äôre going to at minimum have to
handle untrusted XML payloads. Make sure your code (and its
dependencies) aren‚Äôt susceptible to generic XML vulnerabilities like
<a target="_blank" rel="noreferrer" href="https://cwe.mitre.org/data/definitions/776.html">billion laughs<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://owasp.org/www-community/vulnerabilities/XML_External_Entity_(XXE)_Processing">XML
entity expansion
attacks<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>.</p><p>From there, you‚Äôll need to implement <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xmldsig-core/">XML Signature (aka
XMLDsig)<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>. This section will call out
many of the more common vulnerabilities with XML Signature implementations.</p></div>
<p>Before you can process a SAML assertion, you need to verify that it was really
sent by your customer‚Äôs identity provider. You <strong>must</strong> do this, because the
SAML assertion comes from an untrusted source: a user‚Äôs browser. How do you know
the user‚Äôs request contains a SAML assertion that was really produced by your
customer‚Äôs identity provider?</p>
<div><p>Make sure your SAML implementation can‚Äôt be tricked into skipping the
process of cryptographically authenticating SAML assertions.</p><p>Many SAML implementations can have such checks trivially bypassed by, for
example, just removing the <code>&lt;ds:Signature /&gt;</code> elements in an assertion. This
attack works most often when code contains logic that merely asks ‚Äúare there
any invalid signatures in this XML payload?‚Äú. A SAML assertion without any
signatures trivially passes such a check.</p><p><a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows#unsigned-assertion">SSOReady always requires that SAML assertions be
signed</a>. This
functionality cannot be disabled.</p></div>
<p>SAML implements cryptographic authentication using <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xmldsig-core/">XML
Signature<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>, which is a very complicated
standard that tries to anticipate dozens of different ways to sign XML messages.
Thankfully, the SAML specification does restrict what parts of XML Signature can
be used in a SAML assertion:</p>
<blockquote>
<p>5.4 XML Signature Profile</p>
<p>[‚Ä¶] This section details constraints on these facilities so that SAML processors do not
have to deal with the full generality of XML Signature processing.</p>
</blockquote>
<p>The restrictions SAML imposes on XML Signature are:</p>
<ul>
<li>XML Signature supports many different ways for where to put a signature
relative to what it signs. SAML assertions are signed using <em>enveloped</em>
signatures. This means the
<code>&lt;ds:Signature /&gt;</code> elements in a SAML assertion are placed <em>inside</em> the assertion.</li>
</ul>
<div><p>The same section of the specification reads:</p><blockquote>
<p>SAML processors SHOULD support the use of RSA signing and verification for public key
operations in accordance with the algorithm identified by <code>http://www.w3.org/2000/09/xmldsig#rsa-sha1</code>.</p>
</blockquote><p>Do not implement this requirement. Require <code>http://www.w3.org/2001/04/xmldsig-more#rsa-sha256</code> instead.</p><p>SHA1 was still considered secure when SAML 2.0 was drafted, but it is not
considered secure today. In practice, all modern identity providers support
RSA-SHA256 at minimum instead.</p></div>
<ul>
<li>
<p>XML Signature supports many different ways for a signature to indicate what
it‚Äôs signing. SAML stipulates that every assertion must have an <code>ID="..."</code>
attribute, and that the signature points at it using <code>URI="#..."</code>.</p>
</li>
<li>
<p>XML Signature supports many <em>canonicalization</em> algorithms (more on these
later). SAML assertions always use <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-exc-c14n/">Exclusive XML
Canonicalization<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>.</p>
</li>
</ul>
<p>SAML authenticates data in a three-step process: a subset of the SAML assertion
gets <em>canonicalized</em> and then <em>digested</em> (i.e. hashed). The hash is then
<em>signed</em> using RSA.</p>
<p>More concretely, the steps are to:</p>
<ol>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#extracting-the-saml-assertion-to-authenticate">Extract out the data that we want to canonicalize</a></li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#canonicalizing-a-saml-assertion">Canonicalize that data</a></li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#verifying-the-digest-of-the-canonicalized-assertion">Verify the digest (i.e. hash) of the canonicalized data</a></li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#extracting-the-signedinfo-to-sign">Extract out the data we want to sign</a></li>
<li><a href="https://ssoready.com/docs/saml/saml-technical-primer#authenticating-the-signedinfo">Verify the RSA signature of that data</a></li>
</ol>

<p>The data to authenticate is the <code>&lt;saml2:Assertion&gt;</code> inside the overall
<code>&lt;saml2p:Response&gt;</code> payload, but with the <code>&lt;ds:Signature&gt;</code> element removed.
However, you may need to copy over namespace declarations from the top-level
<code>&lt;saml2p:Response&gt;</code>; for instance, the identity provider
<a target="_blank" rel="noreferrer" href="https://www.keycloak.org/">Keycloak<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a> shapes its
assertions like so:</p>

<p>You don‚Äôt sign <code>&lt;saml:Assertion&gt;...&lt;/saml:Assertion&gt;</code>. You have to copy over all
namespaces ‚Äúabove‚Äù the XML assertion that are <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-exc-c14n/#def-visibly-utilizes">‚Äúvisibly
utilized‚Äù<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>, including
in this case the <code>xmlns:saml</code> declaration:</p>

<p>With this data in hand, you are ready to canonicalize the assertion.</p>
<h4 id="canonicalizing-a-saml-assertion" data-state="closed">Canonicalizing a SAML assertion</h4>
<p>From there, you have to carry out the <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-exc-c14n/">Exclusive XML
Canonicalization<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a> algorithm on the
assertion. This algorithm is hairy in the details, but at a high level it is
there to make operations like ‚Äúremove the <code>&lt;Signature&gt;</code> element from the
<code>&lt;Assertion&gt;</code>‚Äù be something that two parties can carry out, and still end up
with exactly the same set of bytes. Canonicalization (‚Äúc14n‚Äù) is an XML-to-bytes
algorithm.</p>
<div><p>Many XML libraries have abstractions that make it impossible to implement
XML canonicalization. You may need to write your own XML parser.</p><p>You need to use a library that exposes where XML namespaces are declared
(i.e. <code>xmlns:</code> attributes), and which lets you see what namespace prefixes
(i.e. the <code>foo</code> in <code>foo:bar</code>, not just what <code>foo</code> resolves to) that elements
and attributes use. These details are often abstracted away, because they
don‚Äôt affect message semantics.</p></div>
<p>Exclusive XML Canonicalization builds on top of <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-c14n11/">Canonical
XML<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>, aka ‚ÄúXML Canonicalization‚Äù or just ‚ÄúXML
c14n‚Äù.</p>
<p>XML Canonicalization is rather involved, but the basic idea is to make details
that don‚Äôt affect message semantics always resolve to the same thing:</p>
<ul>
<li>Empty elements (<code>&lt;foo /&gt;</code>) are converted to start/end pairs (<code>&lt;foo&gt;&lt;/foo&gt;</code>)</li>
<li>Element attributes are sorted by resolved namespace URI, ties broken
alphabetically. Namespace declarations come first.</li>
<li>Whitespace within elements is removed, but whitespace in text nodes is preserved</li>
</ul>
<div><p>The XML canonicalization spec is written to <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/2001/REC-xml-c14n-20010315#Example-Entities">require support for entity
expansion<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>,
for instance requiring that this document:</p><div><div><p><span>Input.xml (from the XML Canonicalization specification)</span></p></div><pre tabindex="0"></pre></div><p>Canonicalize to:</p><p><strong>Do not honor this requirement.</strong> You will be vulnerable to <a target="_blank" rel="noreferrer" href="https://owasp.org/www-community/vulnerabilities/XML_External_Entity_(XXE)_Processing">XML Entity
Expansion
(‚ÄúXXE‚Äù)<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>
attacks. The specification here is simply inappropriate for systems that
handle untrusted user input, such as SAML. In the real world, no SAML
systems rely on entity expansion. This part of the spec is irrelevant and
actively insecure in practice.</p></div>
<p>What makes XML Exclusive Canonicalization different from ordinary XML
Canonicalization is in how XML namespaces are handled. In particular, XML
Canonicalization stipulates that you only include XML namespaces that are
<a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-exc-c14n/#def-visibly-utilizes"><em>visibly utilized</em><svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>.</p>
<p>In other words, you take every namespace declaration (e.g. a <code>xmlns:foo="bar"</code>
attribute), and you scan through everything ‚Äúinside‚Äù that element. If they use
the declared namespace prefix (e.g. <code>&lt;foo /&gt;</code> or <code>foo:lorem="ipsum"</code>), then you
keep the namespace declaration. Otherwise, you omit it from the output. If a
namespace declaration is ‚Äúshadowed‚Äù (i.e. redeclared by a child element), then
you need to make sure it‚Äôs not the child declaration that‚Äôs being used. If two
prefixes resolve to the same URI (e.g. <code>&lt;lorem xmlns:a="xxx" xmlns:b="xxx"&gt;</code>),
you need to track the prefixes independently.</p>
<p>XML Exclusive Canonicalization permits for an <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xml-exc-c14n/#def-InclusiveNamespaces-PrefixList"><code>InclusiveNamespaces PrefixList</code><svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>
parameter. You need to support this. In SAML, that parameter gets passed in a
<code>InclusiveNamespaces</code> attribute under the <code>ds:Transform</code> element for
canonicalization in the signature:</p>

<p>What this element concretely does is say that any declaration of <code>xs</code> (e.g.
<code>xmlns:xs="..."</code>) is always treated as being visibly used.</p>
<div><p>The XML Exclusive Canonicalization spec has a bunch of discussion about
special-casing <code>xmlns=""</code>. You don‚Äôt need to worry about this; it‚Äôs written
to make the spec easier to implement using XPath, which has a hard time
‚Äúseeing‚Äù <code>xmlns=""</code> declarations. But such declarations are never used in
practice in SAML.</p><p>You do, however, need to handle checking whether default (i.e. unprefixed)
namespace declarations are visibly used. Many identity providers send
assertions that declare default namespaces. Not all of these declarations
are always visibly used.</p></div>
<p>When you‚Äôre done with this step, you‚Äôve converted the SAML payload into a
precise sequence of bytes, representing a normalized (i.e. canonicalized)
representation of the payload‚Äôs <code>&lt;Assertion&gt;</code> with the <code>&lt;Signature&gt;</code> removed.
Now, we can move on to doing cryptography.</p>
<h4 id="verifying-the-digest-of-the-canonicalized-assertion" data-state="closed">Verifying the digest of the canonicalized assertion</h4>
<p>After converting the SAML assertion into a set of canonicalized bytes, SAML
requires that those bytes be put through a digest ‚Äî i.e. cryptographic hash
‚Äî algorithm.</p>
<p>The SAML specification does not put constraints on what digest algorithm be
used, but you can limit yourself to supporting SHA-256; it‚Äôs secure and widely
supported by modern identity providers.</p>
<div><p>As with the prior warning regarding RSA-SHA1, we recommend against
implementing SHA1. It is not generally considered secure today.</p><p>SHA1 is a legal digest algorithm for a SAML implementation to use, but its
use has since been formally discouraged by later revisions of the XML
Signature specification:
<a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/xmldsig-core1/#sec-MessageDigests">https://www.w3.org/TR/xmldsig-core1/#sec-MessageDigests<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a></p><p>In practice, all modern identity providers support SHA256 at minimum instead.</p></div>
<p>You will compare the SHA-256 sum of the canonicalized bytes against the
<code>&lt;ds:DigestValue /&gt;</code> element of the signature. If your computed SHA-256 doesn‚Äôt
equal the digest value in the assertion, then the message is invalid /
inauthentic.</p>
<p>One quirk here is that <code>&lt;ds:DigestValue /&gt;</code> contains the base64-encoded bytes
from SHA-256, not the more common hex encoding typically used for the output of
SHA-256.</p>
<div><p>Do <strong>not</strong> stop here. All you have done to this point is make sure the
<code>Signature</code> you‚Äôre looking at is meant for the assertion you want to
process. You still do not know that the assertion was actually generated by
the identity provider.</p><p>It is trivial for an attacker to generate a correct SHA-256 digest for an
assertion. You have jumped through a hoop SAML introduces, but you have not
yet done any meaningful cryptographic authentication.</p></div>

<p>SAML relies on RSA to cryptographically sign (and authenticate) assertions. The
SHA-256 digest of the assertion, which we verified in the previous section, is
not what gets signed. Instead, an XML element <em>containing</em> the digest is signed.</p>
<p>SAML requires that the RSA-SHA256 signature be over the <code>SignedInfo</code>, an XML
element that contains the digest:</p>
<div><div><p><span>SignedInfo (Pretty-Indented)</span></p></div><pre tabindex="0"></pre></div>
<p>To make matters a bit more complicated, this payload isn‚Äôt what gets signed; you
need to copy over all XML namespaces that this <code>SignedInfo</code> payload visibly
uses, so in this case we need to define <code>xmlns:ds</code> on the <code>SignedInfo</code> before
signing:</p>
<div><div><p><span>SignedInfo with namespaces copied in (Pretty-Indented)</span></p></div><pre tabindex="0"></pre></div>
<p>This is the data that you need to verify with RSA-SHA256.</p>
<h4 id="authenticating-the-signedinfo" data-state="closed">Authenticating the <code>SignedInfo</code></h4>
<p>The correct signature is stored in the <code>&lt;SignatureValue&gt;</code> of the <code>&lt;Signature&gt;</code>
element:</p>
<div><div><p><span>SignatureValue (Pretty-Indented)</span></p></div><pre tabindex="0"></pre></div>
<p>As with the digest information, this <code>SignatureValue</code> contains base64 data. You
verify that it is an RSA PKCS #1 v1.5 signature for the XML payload you
extracted in the previous section.</p>
<p>Verifying an RSA signature requires an RSA public key. You <strong>must</strong> use the RSA
public key inside the <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">IDP‚Äôs X.509 certificate</a> to verify
the signature. Do not use any other key.</p>
<div><p>Every SAML assertion contains a <code>KeyInfo</code> element, which contains an X.509
certificate. <strong>Do not use this key.</strong> An attacker can trivially replace that
<code>KeyInfo</code> with a key they control. From there, they can generate valid
signatures easily.</p><p>Many open-source SAML libraries get this wrong. You should audit this. Any
SAML library that doesn‚Äôt take an RSA public key as a required parameter to
verify a SAML assertion is probably vulnerable.</p><p>To determine what the correct IDP certificate is, you must do so
out-of-band. See the section on <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">SAML configuration</a> in
this article. If you use SSOReady, you can have your customer securely
upload their IDP certificate using a <a href="https://ssoready.com/docs/idp-configuration/enabling-self-service-configuration-for-your-customers">self-serve configuration
UI</a>
without any work or coding on your part.</p></div>
<div><p>You can optionally check that the contents of that <code>KeyInfo</code> equal the
one-and-only key that you trust. You can use that check to gracefully detect
if your customer has rotated their IDP certificate without first giving you
the new certificate.</p><p>If you use SSOReady, your customers will get such a <a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows#bad-certificate">graceful warning about
incorrect
certificates</a> out
of the box. This is just a convenience feature for your customer; SSOReady
never trusts the <code>KeyInfo</code> on a user-provided assertion.</p></div>
<p>Once you have verified this signature (using the correct key), you have now
established that your customer‚Äôs identity provider really generated this
assertion. It is now your job to decide whether to honor this SAML login.</p>
<h3 id="deciding-whether-to-honor-a-saml-login" data-state="closed">Deciding whether to honor a SAML login</h3>
<div><p>Do <strong>not</strong> skip this step. Just because a SAML assertion was really
generated by your customer‚Äôs identity provider doesn‚Äôt mean you should honor it.</p><p>An attacker could be  performing a replay attack. You also need to guard
against the possibility of a customer <a href="https://ssoready.com/docs/saml/saml-technical-primer#handling-malicious-identity-providers">maliciously configuring their
identity provider</a> to send you
assertions designed to log in as another one of your customers.</p></div>
<p>After authenticating a SAML login, you now need to take the <a href="https://ssoready.com/docs/saml/saml-technical-primer#canonicalizing-a-saml-assertion">authenticated
payload</a> (<strong>not</strong> the original,
pre-canonicalization assertion) and carry out a few checks on the data.</p>
<div><p>Once you‚Äôve <a href="https://ssoready.com/docs/saml/saml-technical-primer#authenticating-the-signedinfo">authenticated</a> the SAML
assertion, you need to only work with the canonicalized payload from then
on. The XML Signature specification <a target="_blank" rel="noreferrer" href="https://www.w3.org/TR/2002/REC-xmldsig-core-20020212/#sec-See">puts it this
way<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>:</p><blockquote>
<p>automated mechanism that trust the validity of a transformed document on
the basis of a valid signature should operate over the data that was
transformed (including canonicalization) and signed, not the original
pre-transformed data</p>
</blockquote><p>Concretely, the sort of vulnerability you need to worry about is that these
two messages:</p><p>Both canonicalize to the same thing, and so have the same signature. So if
your code does this:</p><p>Then with the second payload (the one with the attacker-inserted comment),
your code will be tricked into thinking the identity provider signed
<code>abraham.lincoln@whitehouse.gov</code>. In both examples, <code>validated_payload</code> are
equal, but in the second example, the pre-canonicalization <code>saml_payload</code> is
represented as:</p><p>The SAML assertion‚Äôs signature only testifies to the post-canonicalization
payload, and in this case an attacker found a way to make the semantics of a
payload be affected by something that goes away during canonicalization* (a
comment). The fix is to work with the canonicalized payload.</p><p>If you use SSOReady, the code you write does not need to handle XML payloads
at all. Internally, SSOReady implements controls against
canonicalization-related attacks.</p></div>
<p>You should check that:</p>
<ul>
<li>
<p>The assertion‚Äôs <strong>audience</strong> equals the <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">SP Entity ID</a>
you assigned.</p>

<div><p>Verifying the assertion‚Äôs audience defends against replay attacks.</p><p>An attacker may take a legitimate assertion meant for one application,
and replay it to your application in order to do privilege escalation.</p><p>For example, many universities use the same IDP for all professors and
students. Many large organizations use the same IDP for executives and
for temporary employees.</p><p>The IDP might give out SAML assertions to anyone on staff to access the
internal company documentation hub. What if an employee takes a SAML
assertion meant for the documentation hub‚Äôs SP Entity ID, but sends it
to your (much more sensitive) application instead?</p><p>You might assume that checking the X.509 certificate on the assertion
would make sure the payload is meant for you. In fact, many IDPs use the
same certificate for every application.
<a target="_blank" rel="noreferrer" href="https://shibboleth.atlassian.net/wiki/spaces/IDP5/overview">Shibboleth<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a>,
in particular, is popular in higher education and is typically
configured this way.</p><p><a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows#bad-audience">SSOReady always verifies assertion
audiences</a>. This
functionality cannot
be disabled.</p></div>
</li>
<li>
<p>The assertion‚Äôs <strong>validity window</strong> is valid against the current time, i.e.
hasn‚Äôt expired:</p>

<div><p>Verifying the assertion‚Äôs validity window defends against replay
attacks.</p><p>In the example above, Okta generated a SAML assertion that‚Äôs only valid
for 10 minutes. The intention here is that if a victim‚Äôs SAML assertion
were somehow leaked to an attacker, the attacker would have less than 10
minutes to carry out an attack. This doesn‚Äôt solve every problem, but it
does greatly limit the impact of, for example, leaks of network logs or
other historical data.</p><p>Do not try to implement your own validity window logic on top of SAML
assertions. That way, your customers can choose how tight they want to
make their assertion expirations, depending on their security posture.</p><p>SSOReady always verifies assertion expiration. This functionality cannot
be disabled.</p></div>
</li>
<li>
<p>The assertion <strong>issuer</strong> equals the <a href="https://ssoready.com/docs/saml/saml-technical-primer#saml-configuration">IDP Entity ID</a>:</p>

<div><p>Compared to verifying the assertion‚Äôs audience, verifying the issuer is
less critical.</p><p>Authenticating the assertion‚Äôs signature using the IDP‚Äôs certificate is
what does the heavy lifting of making sure the IDP really issued the
assertion. Checking the issuer is more for helping to debug SAML
misconfiguration.</p><p>Some identity providers don‚Äôt use unique IDP entity IDs;
<a target="_blank" rel="noreferrer" href="https://jumpcloud.com/">JumpCloud<svg width="1.5em" height="1.5em" viewBox="0 0 24 24" stroke-width="1.5" fill="none" xmlns="http://www.w3.org/2000/svg" color="currentColor"><path d="M21 3L15 3M21 3L12 12M21 3V9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 13V19C21 20.1046 20.1046 21 19 21H5C3.89543 21 3 20.1046 3 19V5C3 3.89543 3.89543 3 5 3H11" stroke="currentColor" stroke-linecap="round"></path></svg></a> defaults to setting the IDP Entity
ID to <code>JumpCloud</code> for all applications.</p><p><a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows#bad-issuer">SSOReady always verifies assertion
issuers</a>. This
functionality cannot be
disabled.</p></div>
</li>
</ul>
<p>Once you have done these checks, you have now established that:</p>
<ul>
<li>The SAML assertion was really issued by your customer‚Äôs identity provider</li>
<li>The SAML assertion was really meant to be consumed by your application</li>
<li>The SAML assertion was recently issued, and hasn‚Äôt expired</li>
</ul>
<p>There is now only one major validation you need to worry about: what if the
customer‚Äôs identity provider is being malicious?</p>
<h4 id="handling-malicious-identity-providers" data-state="closed">Handling malicious identity providers</h4>
<p>Identity providers will diligently issue any assertion that the relevant IT
admin tells them to. When your customer‚Äôs Okta sends you an assertion, the
contents of that assertion are vouched for <em>only</em> by that customer. It‚Äôs <strong>not</strong>
vouched for by Okta itself.</p>
<p>To make this concrete: <a href="https://ssoready.com/blog/engineering/abraham-lincoln-and-the-malicious-saml-idp/">it‚Äôs trivial to create an Okta account for
<code>abraham.lincoln@whitehouse.gov</code>.</a>,
even if you don‚Äôt work at the White House. You don‚Äôt have to verify an email or
do anything like that. You can just stick whatever you want in <em>any</em> IDP,
including the popular ones like Okta.</p>
<p>So your final security step in handling SAML is this:</p>
<blockquote>
<p>AcmeCorp just told me to log a user in as <code>bob@acmecorp.com</code>. Is
<code>bob@acmecorp.com</code> a user that AcmeCorp ‚Äúowns‚Äù in my product?</p>
</blockquote>
<p>There are a few ways you can do this, but the simplest way to start is to make
an allowlist of domains, which you (not your customer) control, associated with
every SAML-using customer. Only honor SAML logins for users whose email are in
that allowlist.</p>
<p>Effectively, this approach makes it possible for each of your customers to ‚Äúown‚Äù
domains in your system. Unless they‚Äôre marked as owning a domain ‚Äî something
<em>you</em> control, not your customer ‚Äî then they can‚Äôt do SAML logins into that
domain.</p>

<p>The biggest vulnerability you should worry about is one customer putting another
customer‚Äôs email address into their identity provider, and then trying to log in
as them. A whitelist is a simple, reliable way to stop this.</p>
<p>You do not need to worry about an identity provider being ‚Äúwrong‚Äù about its own
employees. The entire point of SAML is to let you delegate one company‚Äôs logins
to an identity provider that company controls. It‚Äôs beyond your control to
prevent an identity provider from ‚Äúattacking itself‚Äù. It is in your control, and
it is your responsibility, to make sure you don‚Äôt accidentally delegate one company‚Äôs logins
to another company‚Äôs identity provider.</p>
<h3 id="logging-the-user-in" data-state="closed">Logging the user in</h3>
<p>You can now proceed to log the user in. Take whatever system you normally use to
log users in (such as if they logged in via password, or ‚ÄúLog in with Google‚Äù,
etc.), and give the user‚Äôs web browser a login session in your normal way ‚Äî be
it a cookie, a JWT bearer token, or anything else.</p>
<div><p>When you were <a href="https://ssoready.com/docs/saml/saml-technical-primer#deciding-whether-to-honor-a-saml-login">deciding whether to honor a SAML
login</a>, you had to validate whether
the SAML assertion is expired. Engineers sometimes think they need to make
their application sessions last just as long as the SAML assertion is valid.
This is not the case.</p><p>You don‚Äôt need to make the <code>NotOnOrAfter</code> of a SAML assertion affect how
long your application sessions last. It‚Äôs typical for IDPs to make
assertions very short-lived (Okta defaults to 10 minutes), because the goal
is to make it harder for attackers to intercept and replay SAML assertions. But your
application‚Äôs sessions can be much longer, because they aren‚Äôt communicated
across multiple trust boundaries like SAML assertions are.</p><p>In other words: don‚Äôt worry about this. Just give the user a session as
usual, with your usual session duration.</p></div>
<p>You should <strong>strongly</strong> consider implementing an audit log of every SAML
assertion you receive, and whether you decide to honor it or not. You should log
the entire SAML assertion; if one of your XML-related dependencies has a new
vulnerability discovered, you will need these logs to determine if that
vulnerability has been exploited against you.</p>
<div><p>If you use SSOReady, you will have <a href="https://ssoready.com/docs/ssoready-concepts/saml-login-flows">an audit log event for every SAML
login</a>. These include a timestamp,
a complete record of the assertion, and details on any errors that may have
made the SAML assertion invalid.</p></div>
<p>Beyond this, you may want to give your customers a way to disable non-SAML
logins. This doesn‚Äôt affect how you handle a SAML login; rather, making SAML
logins mandatory for a customer gives that customer the guarantee that nobody is
going around the <a href="https://ssoready.com/docs/saml/saml-technical-primer#one-click-to-fire-why-your-customers-ciso-likes-saml">benefits of SAML to your customer‚Äôs
CISO</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guide to implementing 2D platformers (2012) (121 pts)]]></title>
            <link>http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/</link>
            <guid>41672669</guid>
            <pubDate>Fri, 27 Sep 2024 16:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/">http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/</a>, See on <a href="https://news.ycombinator.com/item?id=41672669">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>Having previously been disappointed by the information available on the topic, this is my attempt at categorizing different ways to implement 2D platform games, list their strengths and weaknesses, and discuss some implementation details.</p>
<p>The long-term goal is to make this an exhaustive and comprehensible guide to the implementation of 2D platform games. If you have any sort of feedback, correction, request, or addition ‚Äì please leave it in the comments!</p>
<p><strong>Disclaimer</strong>: some of the information presented here comes from reverse engineering the behavior of the game, not from its code or programmers. It‚Äôs possible that they are not ACTUALLY implemented in this way, and merely behave in an equivalent way. Also note that tile sizes are for the game logic, graphical tiles might be of a different size.</p>
<h2>Four Ways of Implementing</h2>
<p>I can think of four major ways in which a platform game can be implemented. From simplest to most complicated, they are:</p>
<h2>Type #1: Tile-based (pure)</h2>
<p>Character movement is limited to tiles, so you can never stand halfway between two tiles. Animations may be used to create the illusion of smooth movement, but as far as the game logic is concerned, the player is always right on top of a specific tile. This is the easiest way to implement a platform game, but it imposes heavy restrictions on the control of character, making it unsuitable for traditional action-based platformers. It is, however, popular with puzzle and ‚Äúcinematographic‚Äù platformers.</p>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Flashback_tiles_2.png"><img title="Flashback_tiles_2" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Flashback_tiles_2.png" alt="" width="512" height="448"></a><em>Flashback, shown with tile boundaries</em></p>
<p>Examples: Prince of Persia, Toki Tori, Lode Runner, Flashback</p>
<p><strong>How it works</strong></p>
<p>The map is a grid of tiles, each one storing information such as whether it‚Äôs an obstacle or not, what image to use, what kind of footstep sound to use, and so on. The player and other characters are represented by a set of one or more tiles that move together. In Lode Runner, for example, the player is a single tile. In Toki Tori, the player is 2√ó2 tiles. In Flashback, which is unusual due to the smaller size of its tiles, the player is two tiles wide and five tiles tall (see image above) when standing, but only three tiles tall when crouching.</p>
<p>In this kind of game, the player will rarely ‚Äì if ever ‚Äì be moving diagonally, but, if he is, the movement can be decomposed in two separate steps. Likewise, he will likely only move one tile at once, but multi-tile movement can be done as multiple steps of one tile, if needed (in Flashback, you always move two tiles at once). The algorithm is then as follows:</p>
<ol>
<li>Create a copy of the character where he‚Äôd like to move to (e.g., if moving one tile to the right, make a copy where every tile of the character is shifted 1 tile to the right)</li>
<li>Check that copy for intersection with the background and other characters.</li>
<li>If an intersection is found, the character‚Äôs movement is blocked. React accordingly.</li>
<li>Otherwise, the path is clear. Move character there, optionally playing an animation so the transition looks smooth.</li>
</ol>
<p>This kind of movement is very ill-suited for traditional arc-shaped jumps ‚Äì so games in this genre often have no jump at all (Toki Tori, Lode Runner), or only allow vertical or horizontal jumps (Prince of Persia, Flashback), which are nothing but special cases of linear movement.</p>
<p>Advantages of this system include simplicity and precision. Since the games are more deterministic, glitches are much less likely, and the gameplay experience is more controlled, with less of a need to tweak values depending on circumstances. Implementing certain mechanics (such as grabbing ledges and one-way platforms) becomes a breeze, compared to more complex movement styles ‚Äì all you have to do is check whether the player tiles and the background tiles are aligned in the one specific way that allows for a given action.</p>
<p>In principle, this system doesn‚Äôt allow steps of less than one tile, but that can be mitigated in a few different ways. For example, the tiles can be a bit smaller than the player (say, a player is 2√ó6 tiles), or you can allow a visual-only movement to take place inside a given tile, without affecting the logic (which is the solution that I believe that ‚ÄúLode Runner ‚Äì The Legend Returns‚Äù takes).</p>
<h2>Type #2: Tile Based (Smooth)</h2>
<p>Collision is still determined by a tilemap, but characters can move freely around the world (typically with 1px resolution, aligned to integers, but see the note at the end of article regarding smoothing of movement). This is the most common form of implementing platformers in 8-bit and 16-bit consoles, and remains popular today, as it is still easy to implement and makes level editing simpler than more sophisticated techniques. It also allows for slopes and smooth jump arcs.</p>
<p>If you‚Äôre unsure which type of platformer you want to implement, and you want to do an action game, I suggest going for this one. It‚Äôs very flexible, relatively easy to implement, and gives you the most control of all four types. It‚Äôs no wonder that the majority of the best action platformers of all time are based on this type.</p>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_tiles.png"><img title="Mega_Man_X_tiles" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_tiles.png" alt="" width="512" height="448"></a><em>Mega Man X, shown with tile boundaries and player hitbox.</em></p>
<p>Examples: Super Mario World, Sonic the Hedgehog, Mega Man, Super Metroid, Contra, Metal Slug, and practically every platformer of the 16-bit era</p>
<h3>How it works</h3>
<p>Map information is stored in the same way as with the pure tile technique, the difference is merely in how the characters interact with the background. The character‚Äôs collision hitbox is now an Axis-Aligned Bounding Box (AABB, that is, a rectangle that cannot be rotated), and are typically still an integer multiple of tile size. Common sizes include one tile wide and one (small Mario, morph ball Samus), two (big Mario, Mega Man, crouched Samus) or three (standing Samus) tiles tall. In many cases, the character sprite itself is larger than the logical hitbox, as this makes for a more pleasant visual experience and fairer gameplay (it‚Äôs better for the player to avoid getting hit when he should have than for him to get hit when he should not have). In the image above, you can see that the sprite for X is square-ish (in fact, is two tiles wide), but his hitbox is rectangular (one tile wide).</p>
<p>Assuming that there are no slopes and one-way platforms, the algorithm is straightforward:</p>
<ol>
<li>Decompose movement into X and Y axes, step one at a time. If you‚Äôre planning on implementing slopes afterwards, step X first, then Y. Otherwise, the order shouldn‚Äôt matter much. Then, for each axis:</li>
<li>Get the coordinate of the forward-facing edge, e.g. : If walking left, the x coordinate of left of bounding box. If walking right, x coordinate of right side. If up, y coordinate of top, etc.</li>
<li>Figure which lines of tiles the bounding box intersects with ‚Äì this will give you a minimum and maximum tile value on the OPPOSITE axis. For example, if we‚Äôre walking left, perhaps the player intersects with horizontal rows 32, 33 and 34 (that is, tiles with y = 32 * TS, y = 33 * TS, and y = 34 * TS, where TS = tile size).</li>
<li>Scan along those lines of tiles and towards the direction of movement until you find the closest static obstacle. Then loop through every moving obstacle, and determine which is the closest obstacle that is actually on your path.</li>
<li>The total movement of the player along that direction is then the minimum between the distance to closest obstacle, and the amount that you wanted to move in the first place.</li>
<li>Move player to the new position. With this new position, step the other coordinate, if still not done.</li>
</ol>
<h3>Slopes</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_tiles_2.png"><img title="Mega_Man_X_tiles_2" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_tiles_2.png" alt="" width="512" height="448"></a><em>Mega Man X, with slope tile annotations</em></p>
<p>Slopes (the tiles pointed by green arrows on the image above) can be very tricky, because they are obstacles, and yet still allow the character to move into their tile. They also cause movement along the X axis to adjust position on the Y axis. One way to deal with them is to have the tile store the ‚Äúfloor y‚Äù of either side. Assuming a coordinate system where (0, 0) is at top-left, then the tile just left of X (first slope tile) is {0, 3} (left, right), then the one he stands on is {4, 7}, then {8, 11}, then {12, 15}. After that, the tiles repeat, with another {0, 3}, etc, and then we have a steeper slope, composed of two tiles: {0, 7} and {8, 15}.</p>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_Slope_Tile.png"><img title="Mega_Man_X_Slope_Tile" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_X_Slope_Tile.png" alt="" width="256" height="256"></a><em>Detailed View of the {4, 7} tile</em></p>
<p>The system that I‚Äôm going to describe allows arbitrary slopes, though for visual reasons, those two slopes are the most common, and result in a total of 12 tiles (the 6 described previously, and their mirrorings). The collision algorithm changes as follows for horizontal movement:</p>
<div>
<ul>
<li>Make sure that you step X position before Y position.</li>
<li>During collision detection (4 above), the slope only counts as a collision if its closest edge is the taller (smaller y coordinate) one. This will prevent characters from ‚Äúpopping‚Äù through the slope from the opposite side.</li>
<li>You might want to forbid slopes to stop ‚Äúhalfway through‚Äù (e.g. on a {4, 7} tile). This restriction is adopted by Mega Man X and many other games. If you don‚Äôt, you have to deal with the more complicated case of the player attempting to climb from the lower side of the slope tile ‚Äì one way to deal with this is to pre-process the level, and flag all such offending tiles. Then, on collision detection, also count it as a collision from the lower side if the player‚Äôs lowest y coordinate is greater (that is, below) the tile‚Äôs offset edge (tile coord * tile size + floor y).</li>
<li>A full obstacle tile adjacent to the slope the character is currently on should not be considered for collision if it connects to the slope, that is, if the character (that is, his bottom-center pixel) is on a {0, *} slope, ignore left tile, and, if on a {*, 0} slope, ignore the right tile. You may have to do this for more tiles if your character is wider than two tiles ‚Äì you might simply skip checking on the entire row if the player is moving towards the upper side of slope. The reason for this is to prevent the character from getting stuck at those tiles (highlighted yellow above) while still climbing the slope, as his foot will still be below the ‚Äúsurface level‚Äù by the time he comes into contact with the otherwise solid tile.</li>
</ul>
</div>
<p>And for vertical movement:</p>
<div>
<ul>
<li>If you‚Äôre letting gravity do its job for downhill movement, make sure that the minimum gravity displacement is compatible with slope and horizontal velocity. For example, on a 4:1 slope (as {4, 7} above), the gravity displacement must be at least 1/4 of the horizontal velocity, rounded up. On a 2:1 slope (such as {0, 7}), at least 1/2. If you don‚Äôt ensure this, the player will move horizontally right off the ramp for a while, until gravity catches up and drags him down, making him bounce on the ramp, instead of smoothly descending it.</li>
<li>An alternative to using gravity is to compute how many pixels above floor the player was before movement, and how many it is afterwards (using the formula below), and adjust his position so they‚Äôre the same.</li>
<li>When moving down, instead of considering a slope tile‚Äôs top edge as its collision boundary, instead, compute its floor coordinate at the current vertical line, and use that. To do that, find the [0, 1] value which represents the player‚Äôs x position on tile (0 = left, 1 = right) and use it to linearly interpolate the floorY values. The code will look something like:√Ç&nbsp;
<pre title="">float t = float(centerX - tileX) / tileSize;
float floorY = (1-t) * leftFloorY + t * rightFloorY;</pre>
</li>
<li>When moving down, if multiple tiles on the same Y coordinate are obstacle candidates, and the one on the X coordinate of the player‚Äôs center is a slope tile, use that one, and ignore the rest ‚Äì even though the others are technically closer. This ensures proper behaviour around the edges of slopes, with the character actually ‚Äúsinking‚Äù on a completely solid tile because of the adjacent slope.</li>
</ul>
</div>
<h3>One-way platforms</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Mario_World_One_Way.png"><img title="Super_Mario_World_One_Way" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Mario_World_One_Way.png" alt="" width="512" height="224"></a></p>
<p><em>Super Mario World, showing Mario falling through (left) and standing on (right) the same one-way platform</em></p>
<p>One-way platforms are platforms that you can step on, but you can also jump through them. In other words, they count as an obstacle if you‚Äôre already on top of them, but are otherwise traversable. That sentence is the key to understanding their behavior. The algorithm changes as follows:</p>
<div>
<ul>
<li>On the x axis, the tile is never an obstacle</li>
<li>On the y axis, the tile is only an obstacle if, prior to the movement, the player was entirely above it (that is, bottom-most coordinate of player was at least one pixel above top-most coordinate of one-way platform). To check for this, you will probably want to store the original player position before doing any stepping.</li>
</ul>
</div>
<p>It might be tempting to have it act as an obstacle if the player‚Äôs y speed is positive (that is, if the player is falling), but this behavior is wrong: it‚Äôs possible for the player to jump so he overlaps the platform, but then falls down again without having his feet reach the platform. In that case, he should still fall through.</p>
<p>Some games allow the player to ‚Äújump down‚Äù from such platforms. There are a few ways to do this, but they are all relatively simple. You could, for example, disable one-way platforms for a single frame and ensure that y speed is at least one (so he‚Äôll be clear of the initial collision condition on the next frame), or you could check if he‚Äôs standing exclusively on one-way platforms, and, if so, manually move the player one pixel to the bottom.</p>
<h3>Ladders</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_7_Ladder.png"><img title="Mega_Man_7_Ladder" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mega_Man_7_Ladder.png" alt="" width="512" height="448"></a><em>Mega Man 7, with tile boundaries, highlighted ladder tiles, and player ladder hitbox.</em></p>
<p>Ladders might seem complicated to implement, but they are simply an alternate state ‚Äì when you‚Äôre in a ladder, you ignore most of the standard collision system, and replace it with a new set of rules. Ladders are typically one tile wide.</p>
<p>You can usually enter the ladder state in two ways:</p>
<ul>
<li>Have your character hitbox overlap with the ladder, either on ground or on air, and hit up (some games also allow you to hit down)</li>
<li>Have your character stand on top of a ‚Äúladder top‚Äù tile (which is often a one-way platform tile as well, so you can walk on top of it), and hit down.</li>
</ul>
<p>This has the effect of immediately snapping the player‚Äôs x coordinate to align with the ladder tiles, and, if going down from the top of ladder, move y coordinate so player is now inside the actual ladder. At this point, some games will use a different hitbox for the purposes of determining whether the player is still on the ladder. Mega Man, for example, seems to use a single tile (equivalent to top tile of the original character, highlighted in red in the image above).</p>
<p>There are a few different ways of LEAVING the ladder:</p>
<ul>
<li>Reaching the top of the ladder. This will usually prompt an animation and move the player several pixels up in y, so he‚Äôs now standing on top of the ladder.</li>
<li>Reaching the bottom of a hanging ladder. This will cause the player to simply fall, although some games won‚Äôt let the player leave the ladder in this way.</li>
<li>Moving left or right. If there is no obstacle on that side, the player may be allowed to leave that way.</li>
<li>Jumping. Some games allow you to release the ladder by doing this.</li>
</ul>
<p>While on the ladder, the character‚Äôs movement changes so, typically, all he can do is move up and down, and sometimes attack.</p>
<h3>Stairs</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Castlevania_Dracula_X_Stairs.png"><img title="Castlevania_Dracula_X_Stairs" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Castlevania_Dracula_X_Stairs.png" alt="" width="512" height="448"></a><em>Castlevania: Dracula X, with tile boundaries</em></p>
<p>Stairs are a variation of ladders, seen in few games, but notably in the Castlevania series. The actual implementation is very similar to that of ladders, with a few exceptions:</p>
<ul>
<li>The player moves tile by tile or half-tile by half-tile (as in Dracula X)</li>
<li>Each ‚Äústep‚Äù causes the player to be shifted simultaneously on X and Y coordinates, by a preset amount.</li>
<li>Initial overlapping detection when going up might look on the tile ahead instead of just the current overlap one.</li>
</ul>
<p>Other games also have stairs that behave like slopes. In that case, they are simply a visual feature.</p>
<h3>Moving Platforms</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Mario_World_Moving_Platform.png"><img title="Super_Mario_World_Moving_Platform" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Mario_World_Moving_Platform.png" alt="" width="512" height="448"></a><em>Super Mario World</em></p>
<p>Moving platforms can seem a little tricky, but are actually fairly simple. Unlike normal platforms, they cannot be represented by fixed tiles (for obvious reasons), and instead should be represented by an AABB, that is, a rectangle that cannot be rotated. It is a normal obstacle for all collision purposes, and if you stop here, you‚Äôll have very slippery moving platforms (that is, they work as intended, except that the character does not move along it on his own).</p>
<p>There are a few different ways to implement that. One algorithm is as follows:</p>
<ul>
<li>Before anything on the scene is stepped, determine whether the character is standing on a moving platform. This can be done by checking, for example, whether his center-bottom pixel is just one pixel above the surface of the platform. If it is, store a handle to the platform and its current position inside the character.</li>
<li>Step all moving platforms. Make sure that this happens before you step characters.</li>
<li>For every character that‚Äôs standing on a moving platform, figure the delta-position of the platform, that is, how much it has moved along each axis. Now, shift the character by the same amount.</li>
<li>Step the characters as usual.</li>
</ul>
<h3>Other Features</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Sonic_2_Loop.jpg"><img title="Sonic_2_Loop" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Sonic_2_Loop.jpg" alt="" width="570" height="399"></a><em>Sonic the Hedgehog 2</em></p>
<p>Other games have more complicated and exclusive features. Sonic the Hedgehog series is notable for this. Those are beyond the scope of this article (and my knowledge, for that matter!), but might be subject of a future article.</p>
<h2>Type #3: Bitmask</h2>
<p>Similar to ‚ÄúTile Based (Smooth)‚Äù, but instead of using large tiles, an image is used to determine collision for each pixel. This allows finer detailing, but significantly increases complexity, memory usage, and requires something akin to an image editor to create levels. It also often implies that tiles won‚Äôt be used for visuals, and may therefore require large, individual artwork for each level. Due to those issues, this is a relatively uncommon technique, but can produce higher quality results than tile-based approaches. It is also suitable for dynamic environments ‚Äì such as the destructible scenarios in Worms ‚Äì as you can ‚Äúdraw‚Äù into the bitmask to change the scenario.</p>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Worms_World_Party.png"><img title="Worms_World_Party" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Worms_World_Party.png" alt="" width="512" height="384"></a><em>Worms World Party, featuring destructible terrain</em></p>
<p>Examples: Worms, Talbot‚Äôs Odyssey</p>
<h3>How it works</h3>
<p>The basic idea is very similar to the tile (smooth) algorithm ‚Äì you can simply consider each pixel to be a tile, and implement the exact same algorithm, and everything will work, with one major exception ‚Äì slopes. Since slopes are now implicitly defined by the positioning between nearby tiles, the previous technique doesn‚Äôt work, and a much more complex algorithm has to be used in its place. Other things, such as ladders, also become trickier.</p>
<h3>Slopes</h3>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Talbot_Bitmask_2.png"><img title="Talbot_Bitmask_2" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Talbot_Bitmask_2.png" alt="" width="512" height="384"></a><em>Talbot‚Äôs Odyssey, with the collision bitmask overlaid on top of the game.</em></p>
<p>Slopes are the primary reason why this type of implementation is very hard to get right. Unfortunately, they are also pretty much mandatory, as it‚Äôd make no sense to use this implementation without slopes. Often, they‚Äôre the reason why you‚Äôre even using this system.</p>
<p>This is, roughly, the algorithm used by Talbot‚Äôs Odyssey:</p>
<ul>
<li>Integrate acceleration and velocity to compute the desired delta-position vector (how much to move in each axis).</li>
<li>Step each axis separately, starting with the one with the largest absolute difference.</li>
<li>For the horizontal movement, offset the player AABB by 3 pixels to the top, so he can climb slopes.</li>
<li>Scan ahead, by checking against all valid obstacles and the bitmask itself, to determine how many pixels it is able to move before hitting an obstacle. Move to this new position.</li>
<li>If this was horizontal movement, move as many pixels up as necessary (which should be up to 3) to make up for slope.</li>
<li>If, at the end of the movement, any pixel of the character is overlaping with any obstacle, undo the movement on this axis.</li>
<li>Regardless of result of last condition, proceed to do the same for the other axis.</li>
</ul>
<p>Because this system has no distinction between moving down because you‚Äôre going downhill or because you‚Äôre falling, you‚Äôre likely to need a system counting how many frames it‚Äôs been since the character last touched the floor, for purposes of determining whether it can jump and changing animation. For Talbot, this value is 10 frames.</p>

<p>Another trick here is efficiently computing how many pixels it can move before hitting something. There are other possible complicating factors, such as one-way platforms (dealt in the exact same way as for tiled (smooth)) and sliding down steep inclines (which is fairly complex and beyond the scope of the article). In general, this technique requires a lot of fine tuning, and is intrinsically less stable than tile-based approaches. I only recommend it if you absolutely must have detailed terrain.</p>
<h2>Type #4: Vectorial</h2>
<p>This technique uses vectorial data (lines or polygons) to determine the boundaries of collision areas. Very difficult to implement properly, it is nevertheless increasingly popular due to the√Ç&nbsp;ubiquity of physics engines, such as Box2D, which are suitable for implementing this technique.√Ç&nbsp;It provides benefits similar to the bitmask technique, but without major memory overhead, and using a very different way of editing levels.</p>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/braid11.jpg"><img title="braid1" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/braid11.jpg" alt="" width="512" height="261"></a><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/braid2.png"><img title="braid2" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/braid2.png" alt="" width="512" height="261"></a><em>Braid (level editor), with visible layers (top) and the collision polygons (bottom)</em></p>
<p>Examples: Braid, Limbo</p>
<h3>How it works</h3>
<p>There are two general ways of approaching this:</p>
<ul>
<li>Resolve movement and collisions yourself, similar to the bitmask method, but using polygon angles to compute deflection and have proper slopes.</li>
<li>Use a physics engine (e.g. Box2D)</li>
</ul>
<p>Obviously, the second is more popular (though I suspect that Braid went for the first), both because it is easier and because it allows you to do many other things with physics in the game. Unfortunately, in my opinion, one has to be very careful when going this route, to avoid making the game feel like a generic, uninteresting physics-platformer.</p>
<h3>Compound objects</h3>
<p>This approach has its own unique problems. It may suddenly be difficult to tell whether the player is actually standing on the floor (due to rounding errors), or whether it‚Äôs hitting a wall or sliding down a steep incline. If using a physics engine, friction can be an issue, as you‚Äôll want friction to be high on the foot, but low on the sides.</p>
<p>There are different ways to deal with those, but a popular solution is to divide the character into several different polygons, each with different roles associated: so you‚Äôd (optionally) have the main central body, then a thin rectangle for feet, and two thin rectangles for sides, and another for head or some similar combination. Sometimes they are tapered to avoid getting caught into obstacles. They can have different physics properties, and collision callbacks on those can be used to determine the status of character. For more information, sensors (non-colliding objects that are just used to check for overlap) can be used. Common cases include determinining whether we‚Äôre close enough to the floor to perform a jump, or if the character is pushing against a wall, etc.</p>
<h2>General Considerations</h2>
<p>Regardless of the type of platform movement that you have chosen (except perhaps for type #1), a few general considerations apply.</p>
<h2>Acceleration</h2>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mario_Metroid_Megaman_Acceleration1.png"><img title="Mario_Metroid_Megaman_Acceleration" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Mario_Metroid_Megaman_Acceleration1.png" alt="" width="512" height="300"></a><em>Super Mario World (low acceleration), Super Metroid (mid acceleration), Mega Man 7 (high acceleration)</em></p>
<p>One of the factors that affects the feel of a platformer the most is the acceleration of the character. Acceleration is the rate of change in speed. When it is low, the character takes a long time to reach its maximum velocity, or to come to a halt after the player lets go of controls. This makes the character feel ‚Äúslippery‚Äù, and can be hard to master. This movement is most commonly associated with the Super Mario series of games. When the acceleration is high, the character takes very little (or no time) to go from zero to maximum speed and back, resulting in very fast responding, ‚Äútwitchy‚Äù controls, as seen in the Mega Man series (I believe that Mega Man actually employs infinite acceleration, that is, you‚Äôre either stopped or on full speed).</p>
<p>Even if a game has no acceleration on its horizontal movement, it is likely to have at least some for the jump arcs ‚Äì otherwise they will be shaped like triangles.</p>
<h3>How it works</h3>
<p>Implementing acceleration is actually fairly simple, but there are a few traps to watch out for.</p>
<ul>
<li>Determine xTargetSpeed. This should be 0 if the player is not touching the controls, -maxSpeed if pressing left or +maxSpeed if pressing right.</li>
<li>Determine yTargetSpeed. This should be 0 if the player is standing on a platform, +terminalSpeed otherwise.</li>
<li>For each axis, accelerate the current speed towards target speed using either weighted averaging or adding acceleration.</li>
</ul>
<p>The two acceleration methods are as follows:</p>
<div>
<ul>
<li>Weighted averaging: acceleration is a number (‚Äúa‚Äù) from 0 (no change) to 1 (instant acceleration). Use that value to linearly interpolate between target and current speed, and set the result as current speed.</li>
</ul>
<div>
<pre title="">vector2f curSpeed = a * targetSpeed + (1-a) * curSpeed;
if (fabs(curSpeed.x) &lt; threshold) curSpeed.x = 0;
if (fabs(curSpeed.y) &lt; threshold) curSpeed.y = 0;</pre>
</div>
<ul>
<li>Adding acceleration: We‚Äôll determine which direction to add the acceleration to (using the sign function, which returns 1 for numbers &gt;0 and -1 for &lt;0), then check if we overshot.</li>
</ul>
<pre title="">vector2f direction = vector2f(sign(targetSpeed.x - curSpeed.x),
                              sign(targetSpeed.y - curSpeed.y));
curSpeed += acceleration * direction;
if (sign(targetSpeed.x - curSpeed.x) != direction.x)
    curSpeed.x = targetSpeed.x;
if (sign(targetSpeed.y - curSpeed.y) != direction.y)
    curSpeed.y = targetSpeed.y;</pre>
<p>It‚Äôs important to integrate the acceleration into the speed before moving the character, otherwise you‚Äôll introduce a one-frame lag into character input.</p>

<p>When the character hits an obstacle, it‚Äôs a good idea to zero his speed along that axis.</p>
</div>
<h2>Jump control</h2>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Metroid_Screw_Attack.png"><img title="Super_Metroid_Screw_Attack" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Super_Metroid_Screw_Attack.png" alt="" width="512" height="448"></a><em>Super Metroid, Samus performing the ‚ÄúSpace Jump‚Äù (with ‚ÄúScrew Attack‚Äù power-up)</em></p>
<p>Jumping in a platform game can be as simple as checking if the player is on the ground (or, often, whether he was on the ground anytime on the last n frames), and, if so, giving the character an initial negative y speed (in physical terms, an impulse) and letting gravity do the rest.</p>
<p>There are four general ways in which the player can control the jump:</p>
<ul>
<li>Impulse: seen in games such as Super Mario World and Sonic the Hedgehog, the jump preserves the momentum (that is, in implementation terms, the speed) that the character had before the jump. In some games, this is the only way to influence the arc of the jump ‚Äì just like in real life. There is nothing to implement here ‚Äì it will be like this unless you do something to stop it!</li>
<li>Aerial acceleration: that is, retaining control of horizontal movement while in mid-air. Though this is physically implausible, it is a very popular feature, as it makes the character much more controllable. Almost every platformer game has it, with exceptions for games similar to Prince of Persia. Generally, the airborne acceleration is greatly reduced, so impulse is important, but some games (like Mega Man) give you full air control. This is generally implemented as merely tweaking the acceleration parameter while you‚Äôre airborne.</li>
<li>Ascent control: another physically implausible action, but very popular, as it gives you much greater control over the character. The longer you hold the jump button, the higher the character jumps. Typically, this is implemented by continuing to add impulse to the character (though this impulse can incrementally decrease) for as long as the button is held, or alternatively by√Ç&nbsp;suppressing√Ç&nbsp;gravity while the button is held. A time limit is imposed, unless you want the character to be able to jump√Ç&nbsp;infinitely.</li>
<li>Multiple jumps: once airborne, some games allow the player to jump again, perhaps for an unlimited number of times (as in the Space Jump in Super Metroid or the flight in Talbot‚Äôs Odyssey), or for a limited number of jumps before touching the ground (‚Äúdouble jump‚Äù being the most common choice). This can be accomplished by keeping a counter that increases for each jump and decreases when you‚Äôre on the ground (be careful when you update this, or you might reset it right after the first jump), and only allowing further jumps if the counter is low enough. Sometimes, the second jump is shorter than the initial one. Other restrictions may apply ‚Äì the Space Jump only triggers if you‚Äôre already doing a spin jump and just began to fall.</li>
</ul>
<h2>Animations and leading</h2>
<p><a href="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Black_Thorne_Lead.png"><img title="Black_Thorne_Lead" src="http://higherorderfun.com/blog/wp-content/uploads/2012/05/Black_Thorne_Lead.png" alt="" width="512" height="448"></a><em>Black Thorne, character doing a long animation before shooting backwards (Y button)</em></p>
<p>In many games, your character will play an animation before actually performing the action you requested. However, on a twitchy action-based game, this will frustrate players ‚Äì DON‚ÄôT DO THAT! You should still have leading animations for things such as jumping and running, but if you care about how the game responds, make those cosmetic only, with the action taken immediately regardless of the animation.</p>
<h2>Smoother movement</h2>
<p>Using integers to represent the position of the characters is wise, as it makes it faster and stable. However, if you use integers for everything, you will end up with some jerky motion. There are multiple solutions to this. These are a few:</p>
<ul>
<li>Use a float for all computations and for storing position, and cast to int whenever you‚Äôre rendering or computing collisions. Fast and simple, but it starts losing precision if you move too far away from (0,0). This is probably not relevant unless you have a very large playfield, but it‚Äôs something to keep in mind. If it comes to it, you can use a double instead.</li>
<li>Use a fixed point number for all computations and position, and again cast to int when you‚Äôre rendering or computing collisions. Less precise than float and with a more limited range, but the precision is uniform and can, on some hardware, be faster (notably, floating point processing is slow on many mobile phones).</li>
<li>Store position as an integer, but keep a ‚Äúremainder‚Äù stored in a float.√Ç&nbsp;When integrating position, compute the delta-movement as a float, add the remainder to the delta-movement, then add the integer part of this value to the position, and the fractional part to the ‚Äúremainder‚Äù field. On the next frame, the remainder will get added back in. The advantage of this method is that you‚Äôre using an integer everywhere except for movement, ensuring that you won‚Äôt have floating point complications elsewhere, and increasing performance. This technique is also very suitable if you have some framework in which the position of the object has to be an integer, or where it is a float, but that same position is used directly by the rendering system ‚Äì in that case, you can use the framework-provided float position to store integer values only, to make sure that the rendering is always aligned to pixels.</li>
</ul>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fraud, So Much Fraud (1303 pts)]]></title>
            <link>https://www.science.org/content/blog-post/fraud-so-much-fraud</link>
            <guid>41672599</guid>
            <pubDate>Fri, 27 Sep 2024 16:33:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/blog-post/fraud-so-much-fraud">https://www.science.org/content/blog-post/fraud-so-much-fraud</a>, See on <a href="https://news.ycombinator.com/item?id=41672599">Hacker News</a></p>
Couldn't get https://www.science.org/content/blog-post/fraud-so-much-fraud: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Earth Is on the Brink of Breaching a 7th of Nine 'Planetary Boundaries' (104 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/earth-is-on-the-brink-of-breaching-a-seventh-of-nine-planetary-boundaries-that-support-life-180985144/</link>
            <guid>41672418</guid>
            <pubDate>Fri, 27 Sep 2024 16:18:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/earth-is-on-the-brink-of-breaching-a-seventh-of-nine-planetary-boundaries-that-support-life-180985144/">https://www.smithsonianmag.com/smart-news/earth-is-on-the-brink-of-breaching-a-seventh-of-nine-planetary-boundaries-that-support-life-180985144/</a>, See on <a href="https://news.ycombinator.com/item?id=41672418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-article-body="">
        
          <figure>
            <img src="https://th-thumbnailer.cdn-si-edu.com/lhplFpGp9EWNLRJJnYUXgZCI2CM=/1000x750/filters:no_upscale():focal(1500x1400:1501x1401)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/39/2d/392d87f9-6d4d-4fd2-b9f4-1c4c68afaab2/oceanimagebank_tobymatthews_20.jpg" alt="Turtle among coral reef" itemprop="image">
            <figcaption>
              
                A sea turtle swims in a coral reef in Hawaii. Ocean acidification, found to be on the brink of crossing a boundary into higher-risk territory, can affect coral skeleton formation.
              <span>Toby Matthews via <a href="https://www.theoceanagency.org/ocean-image-bank" target="_blank">Ocean Image Bank</a></span>
            </figcaption>
          </figure>
        

        

        <p>Our planet has not passed its latest health check-up. A new assessment of Earth‚Äôs life-support systems shows that six out of nine of these crucial processes have crossed their ‚Äúplanetary boundary.‚Äù These boundaries are <a href="https://www.smithsonianmag.com/smart-news/humans-have-exceeded-six-of-the-nine-boundaries-keeping-earth-habitable-180982909/">not tipping points</a>‚Äîit‚Äôs possible to recover from passing them‚Äîbut they are thresholds signifying we‚Äôve entered higher-risk territory.</p>

<p>On another worrying note, scientists found the planet is close to breaching a seventh planetary boundary: ocean acidification.</p>

<p>In its first edition, a <a href="https://www.planetaryhealthcheck.org/storyblok-cdn/f/301438/x/03be75c484/planetaryhealthcheck2024_report.pdf">report</a> from the <a href="https://www.pik-potsdam.de/en/home">Potsdam Institute for Climate Impact Research</a> (PIK) used years of data and assessments to evaluate the nine planetary boundaries. These life-support systems make Earth resilient and stable. Alarmingly, six of those boundaries have already been crossed, as a <a href="https://www.smithsonianmag.com/smart-news/humans-have-exceeded-six-of-the-nine-boundaries-keeping-earth-habitable-180982909/">similar assessment</a> last year also concluded. The new report adds to that finding, suggesting these six metrics are now moving further into the ‚Äúred zone,‚Äù or what the researchers consider a high-risk zone.</p>

<p>‚ÄúThe overall diagnostic is that the patient, Planet Earth, is in critical condition,‚Äù says <a href="https://www.pik-potsdam.de/members/johanro/homepage">Johan Rockstr√∂m</a>, PIK director and pioneer of the Planetary Boundaries Framework, in a <a href="https://www.pik-potsdam.de/en/news/latest-news/earth-exceed-safe-limits-first-planetary-health-check-issues-red-alert">statement</a>.</p>

<p>Boundaries that have already been exceeded have to do with climate change, freshwater availability, biodiversity, land use, nutrient pollution (such as phosphorus and nitrogen) and the introduction of synthetic chemicals and <a href="https://www.smithsonianmag.com/smart-news/humans-pollute-the-environment-with-57-million-tons-of-plastic-each-year-study-suggests-180985026/">plastics to the environment</a>.</p>

<p>Ocean acidification is one of the systems that has not yet crossed its planetary boundary, along with ozone depletion and aerosols in the atmosphere. But while ocean acidification is still in the ‚Äúgreen zone,‚Äù the new report finds it‚Äôs trending in the wrong direction. Scientists now say this metric is on the brink and may cross out of the safe zone in the next few years.</p>

<p>Earth‚Äôs oceans absorb carbon dioxide from the atmosphere, providing a valuable carbon sink as humans burn fossil fuels. But this process also makes the oceans more acidic, which can disturb the formation of shells and coral skeletons and affect fish life cycles, per the report.</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/cDaWiVz0_OjWZAW3ibJg0YF1v4A=/fit-in/1072x0/filters:focal(2250x1500:2251x1501)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/1e/01/1e016b7d-5259-4977-8f54-b7c12f035d73/oceanimagebank_theoceanagency_bleaching_11.jpg" alt="Two clownfish among a bleached anemone" loading="lazy">
  

  <figcaption>
    
      Two clownfish hide in a bleached anemone during a coral bleaching event on the Great Barrier Reef in 2017. These bleaching events harm coral, along with ocean acidifcation, which reduces the calcification rate.
    
    
      <span>The Ocean Agency via <a href="https://www.theoceanagency.org/ocean-image-bank" target="_blank">Ocean Image Bank</a></span>
    
  </figcaption>
</figure>
<p>As ocean acidification approaches the boundary, scientists are particularly concerned about certain regions, like the Arctic and Southern oceans. These areas are vital for carbon and global nutrient cycles, ‚Äúwhich support marine productivity, biodiversity and global fisheries,‚Äù the report says.</p>

<p>‚ÄúLooking at the current evolution, I‚Äôd say it‚Äôs really, really difficult to prevent that [boundary] crossing,‚Äù says <a href="https://www.pik-potsdam.de/members/caesar">Levke Caesar</a>, a climate physicist at PIK and an author of the report, to <a href="https://news.mongabay.com/2024/09/inaugural-planetary-health-check-finds-ocean-acidification-on-the-brink/"><em>Mongabay</em></a>‚Äôs Sean Mowbray.</p>

<p>Other recent studies indicate the current conditions are already affecting some marine organisms, Caesar said in a press briefing, per the <a href="https://www.theguardian.com/environment/2024/sep/23/earth-breach-planetary-boundaries-health-check-oceans"><em>Guardian</em></a>‚Äôs Damien Gayle. As a result, it might be necessary to re-evaluate ‚Äúwhich levels can actually be called safe,‚Äù she added.</p>

<p>Levels of acidification are different across the world‚Äôs oceans. Colder waters, like those in the polar regions, may become more acidic more quickly, because they absorb more carbon dioxide. For some scientists, this suggests that perhaps the boundary has already been breached.</p>

<p>‚ÄúWhen you start to think of the nuances of how the ocean works and the importance of some regions over others, I don‚Äôt necessarily agree that we‚Äôre still in a safe place,‚Äù says <a href="https://pml.ac.uk/profile/professor-helen-findlay/">Helen Findlay</a>, a biological oceanographer at the Plymouth Marine Laboratory in England who was not involved in the report, to <em>Mongabay</em>.</p>

<p>The Planetary Health Check is the first in a series of annual reports led by PIK and organized by the Planetary Boundaries Science initiative. It builds on years of research to inform solutions on how to improve the planet‚Äôs health. The health check will also serve as a ‚Äúmission-control center‚Äù for decision-making, per the statement, by using satellite data, A.I. and multiple scientific disciplines‚Äîas well as the wisdom of Indigenous peoples, which is something the researchers hope to incorporate more of in following editions.</p>

<p>Even if it is close to its tipping point, ocean acidification is only one of the nine boundaries necessary for regulating the planet. Each process is woven together with the others. To protect the planet, it will take a holistic approach‚Äîand according to the team, considering the boundaries all together is the best way to identify the most effective actions to lessen humanity‚Äôs impact on the Earth and urgently restore it to a safe state.</p>

<p>‚ÄúIndeed, one of the main messages of our report is that all nine planetary boundaries are highly interconnected,‚Äù Caesar said, according to the <em>Guardian</em>.</p>

        

        

        
          
  <div>
      <p>Get the latest stories in your inbox every weekday.</p>
      
    </div>


        

        

        
          


  
    
      
    
  

  


        

        
        
        
        

        
          
            <section>
              <nav>Filed Under:
                
                  
                    <a href="https://www.smithsonianmag.com/tag/anthropocene/">Anthropocene</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/arctic-ocean/">Arctic Ocean</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/climate-change/">Climate Change</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/coral-reefs/">Coral Reefs</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/fish/">Fish</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/global-warming/">Global Warming</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/oceans/">Oceans</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/planets/">Planets</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/special-report/">Special Report</a>
                  
                
              </nav>
            </section>
          
        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How AlphaChip transformed computer chip design (265 pts)]]></title>
            <link>https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</link>
            <guid>41672110</guid>
            <pubDate>Fri, 27 Sep 2024 15:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a>, See on <a href="https://news.ycombinator.com/item?id=41672110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    

    
    
      
        <div>
          
            
            
              
              
<div>
    <div>
      <p>Research</p>
      

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2024-09-26">26 September 2024</time></dd>
      
      
        <dt>Authors</dt>
        
      
    </dl>
  

      
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w2144-h1206-n-nu-rw 2x"><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w1856-h1044-n-nu-rw 2x"><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w1056-h594-n-nu-rw 2x">
      <img alt="Close-up photograph of Google's Tensor Processing Unit (TPU) Trillium." height="603" src="https://lh3.googleusercontent.com/d1OBmuqgWhx5m_cQZVa-F2I47x1AwUF2Kog-H-xMkTkC-U52j9hl_NxB9tfD-dP9JX9SRO87JzR7TBRpQekzxqeNE5s1wlOXZH_GnJ3xPcQBu6JP=w1072-h603-n-nu" width="1072">
    </picture>
    
  
    
  </div>
            
          
            
            
              
              <div>
  <h4 data-block-key="gnu37">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</h4><p data-block-key="2eiij">In 2020, we released a <a href="https://arxiv.org/pdf/2004.10746" rel="noopener" target="_blank">preprint</a> introducing our novel reinforcement learning method for designing chip layouts, which we later <a href="https://www.nature.com/articles/s41586-021-03544-w" rel="noopener" target="_blank">published in Nature</a> and <a href="https://github.com/google-research/circuit_training" rel="noopener" target="_blank">open sourced</a>.</p><p data-block-key="1qnl3">Today, we‚Äôre <a href="https://www.nature.com/articles/s41586-024-08032-5" rel="noopener" target="_blank">publishing a Nature addendum</a> that describes more about our method and its impact on the field of chip design. We‚Äôre also releasing a <a href="https://github.com/google-research/circuit_training/?tab=readme-ov-file#PreTrainedModelCheckpoint" rel="noopener" target="_blank">pre-trained checkpoint</a>, sharing the model weights and announcing its name: AlphaChip.</p><p data-block-key="93pa">Computer chips have fueled remarkable progress in artificial intelligence (AI), and AlphaChip returns the favor by using AI to accelerate and optimize chip design. The method has been used to design superhuman chip layouts in the last three generations of Google‚Äôs custom AI accelerator, the <a href="https://cloud.google.com/tpu?hl=en" rel="noopener" target="_blank">Tensor Processing Unit</a> (TPU).</p><p data-block-key="dg0up">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</p>
</div>
            
          
            
            
              
              <figure>
  <blockquote>
    
    <p data-block-key="pesui">AlphaChip‚Äôs groundbreaking AI approach revolutionizes a key phase of chip design.</p>
  </blockquote>
  <figcaption><p data-block-key="9oba8">SR Tsai, Senior Vice President of MediaTek</p></figcaption>
</figure>
            
          
            
            
              
              <div>
  <h2 data-block-key="isrhj">How AlphaChip works</h2><p data-block-key="6vcl">Designing a chip layout is not a simple task. Computer chips consist of many interconnected blocks, with layers of circuit components, all connected by incredibly thin wires. There are also lots of complex and intertwined design constraints that all have to be met at the same time. Because of its sheer complexity, chip designers have struggled to automate the chip floorplanning process for over sixty years.</p><p data-block-key="4179m">Similar to <a href="https://deepmind.google/technologies/alphago/" rel="noopener" target="_blank">AlphaGo</a> and <a href="https://deepmind.google/technologies/alphazero-and-muzero/" rel="noopener" target="_blank">AlphaZero</a>, which learned to master the games of Go, chess and shogi, we built AlphaChip to approach chip floorplanning as a kind of game.</p><p data-block-key="6j69d">Starting from a blank grid, AlphaChip places one circuit component at a time until it‚Äôs done placing all the components. Then it‚Äôs rewarded based on the quality of the final layout. A novel ‚Äúedge-based‚Äù graph neural network allows AlphaChip to learn the relationships between interconnected chip components and to generalize across chips, letting AlphaChip improve with each layout it designs.</p>
</div>
            
          
            
            
              
              




<figure aria-labelledby="single-media-fbf5a211-7683-48e8-9249-1dc49e1b9e8d-figcaption">
  
  
    <figcaption id="single-media-fbf5a211-7683-48e8-9249-1dc49e1b9e8d-figcaption">
      <p data-block-key="wsykb">Left: Animation showing AlphaChip placing the open-source, Ariane RISC-V CPU, with no prior experience. Right: Animation showing AlphaChip placing the same block after having practiced on 20 TPU-related designs.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              <div>
  <h2 data-block-key="gnu37">Using AI to design Google‚Äôs AI accelerator chips</h2><p data-block-key="e8433">AlphaChip has generated superhuman chip layouts used in every generation of Google‚Äôs TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google‚Äôs <a href="https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/" rel="noopener" target="_blank">Transformer</a> architecture.</p><p data-block-key="8k0o4">TPUs lie at the heart of our powerful generative AI systems, from large language models, like <a href="https://gemini.google.com/" rel="noopener" target="_blank">Gemini</a>, to image and video generators, <a href="https://deepmind.google/technologies/imagen-3/" rel="noopener" target="_blank">Imagen</a> and <a href="https://deepmind.google/technologies/veo/" rel="noopener" target="_blank">Veo</a>. These AI accelerators also lie at the heart of Google's AI services and are <a href="https://cloud.google.com/tpu" rel="noopener" target="_blank">available</a> to external users via Google Cloud.</p>
</div>
            
          
            
            
              
              




<figure aria-labelledby="single-media-fddc11f0-446b-44f4-b505-2bd1bb9fd1fa-figcaption">
  
  
    <figcaption id="single-media-fddc11f0-446b-44f4-b505-2bd1bb9fd1fa-figcaption">
      <p data-block-key="c46ob">A row of Cloud TPU v5p AI accelerator supercomputers in a Google data center.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              <div>
  <p data-block-key="gnu37">To design TPU layouts, AlphaChip first practices on a diverse range of chip blocks from previous generations, such as <a href="https://en.wikipedia.org/wiki/Network_on_a_chip" rel="noopener" target="_blank">on-chip and inter-chip network blocks</a>, <a href="https://en.wikipedia.org/wiki/Memory_controller" rel="noopener" target="_blank">memory controllers</a>, and <a href="https://en.wikipedia.org/wiki/Data_buffer" rel="noopener" target="_blank">data transport buffers</a>. This process is called pre-training. Then we run AlphaChip on current TPU blocks to generate high-quality layouts. Unlike prior approaches, AlphaChip becomes better and faster as it solves more instances of the chip placement task, similar to how human experts do.</p><p data-block-key="blred">With each new generation of TPU, including our latest <a href="https://cloud.google.com/blog/products/compute/introducing-trillium-6th-gen-tpus" rel="noopener" target="_blank">Trillium</a> (6th generation), AlphaChip has designed better chip layouts and provided more of the overall floorplan, accelerating the design cycle and yielding higher-performance chips.</p>
</div>
            
          
            
            
              
              




<figure aria-labelledby="single-media-e5559907-7a8e-4691-b105-600819e44c8b-figcaption">
  
  
    <figcaption id="single-media-e5559907-7a8e-4691-b105-600819e44c8b-figcaption">
      <p data-block-key="c46ob">Bar graph showing the number of AlphaChip designed chip blocks across three generations of Google‚Äôs Tensor Processing Units (TPU), including v5e, v5p and Trillium.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              




<figure aria-labelledby="single-media-80a69e5d-5c52-42da-851f-eebd2ca1cbe0-figcaption">
  
  
    <figcaption id="single-media-80a69e5d-5c52-42da-851f-eebd2ca1cbe0-figcaption">
      <p data-block-key="c46ob">Bar graph showing AlphaChip‚Äôs average wirelength reduction across three generations of Google‚Äôs Tensor Processing Units (TPUs), compared to placements generated by the TPU physical design team.</p>
    </figcaption>
  
</figure>
            
          
            
            
              
              <div>
  <h2 data-block-key="gnu37">AlphaChip‚Äôs broader impact</h2><p data-block-key="7tafo">AlphaChip‚Äôs impact can be seen through its applications across Alphabet, the research community and the chip design industry. Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as <a href="https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu" rel="noopener" target="_blank">Google Axion Processors</a>, our first Arm-based general-purpose data center CPUs.</p><p data-block-key="6cgui">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips ‚Äî like the <a href="https://www.mediatek.com/products/smartphones/dimensity-5g" rel="noopener" target="_blank">Dimensity Flagship 5G</a> used in Samsung mobile phones ‚Äî while improving power, performance and chip area.</p>
</div>
            
          
            
            
              
              <p data-block-key="gnu37">AlphaChip has triggered an explosion of work on AI for chip design, and has been extended to other critical stages of chip design, such as <a href="https://openreview.net/forum?id=0t1O8ziRZp" rel="noopener" target="_blank">logic synthesis</a> and <a href="https://ieeexplore.ieee.org/document/9980637" rel="noopener" target="_blank">macro selection</a>.</p>
            
          
            
            
              
              <figure>
  <blockquote>
    
    <p data-block-key="pesui">AlphaChip has inspired an entirely new line of research on reinforcement learning for chip design, cutting across the design flow from logic synthesis to floorplanning, timing optimization and beyond.</p>
  </blockquote>
  <figcaption><p data-block-key="9oba8">Professor Siddharth Garg, NYU Tandon School of Engineering</p></figcaption>
</figure>
            
          
            
            
              
              <div>
  <h2 data-block-key="gnu37">Creating the chips of the future</h2><p data-block-key="do3u6">We believe AlphaChip has the potential to optimize every stage of the chip design cycle, from computer architecture to manufacturing ‚Äî and to transform chip design for custom hardware found in everyday devices such as smartphones, medical equipment, agricultural sensors and more.</p><p data-block-key="5crob">Future versions of AlphaChip are now in development and we look forward to working with the community to continue revolutionizing this area and bring about a future in which chips are even faster, cheaper and more power-efficient.</p>
</div>
            
          
            
            
              
              


            
          
            
            
              
              



            
          
            
            
              
              
            
          
            
            
              
              



  
    
  

            
          
        </div>
      
    

    
  
  

  

  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CA law means stores can't say you're buying a game if you're merely licensing it (244 pts)]]></title>
            <link>https://www.polygon.com/news/457071/new</link>
            <guid>41671838</guid>
            <pubDate>Fri, 27 Sep 2024 15:39:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.polygon.com/news/457071/new">https://www.polygon.com/news/457071/new</a>, See on <a href="https://news.ycombinator.com/item?id=41671838">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>When you turn on your Xbox Series X, open the Microsoft Store, and buy <em>Farming Simulator 22</em>, you might think you own the game, but you‚Äôd be wrong. You actually paid for a license to play the game ‚Äî not to own it. Companies can revoke the license at any time. It doesn‚Äôt happen all too often, but it does happen, especially with older games: Ubisoft made headlines earlier this year when it <a href="https://www.pcgamer.com/games/racing/ubisoft-is-stripping-peoples-licences-for-the-crew-weeks-after-its-shutdown-nearly-squandering-hopes-of-private-servers-and-acting-as-a-stark-reminder-of-how-volatile-digital-ownership-is/">delisted racing game <em>The Crew</em> in December</a>, took its servers offline, then started to pull licenses to the game. Licensing vs. actually owning a game becomes an issue, once again, <a href="https://www.polygon.com/gaming/24172809/steam-games-when-you-die-gog-itchio-estate-planning">when you consider where your games go when you die</a> ‚Äî you can‚Äôt technically pass your license along to another person, per many companies‚Äô policies.</p><p>A new California bill (<a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB2426">AB 2426</a>), signed into law by Gov. Gavin Newsom on Tuesday, is an attempt to bring transparency to the buying and selling of digital goods like movies, e-books, and, yes, video games. <a href="https://a42.asmdc.org/press-releases/20240916-assemblymember-irwin-urges-governor-sign-legislation-increasing">California assemblymember Jacqui Irwin introduced the bill</a>, in part, after hearing about Ubisoft‚Äôs move with <em>The Crew</em>. The law won‚Äôt change the fact that we‚Äôre all licensing games instead of actually owning them, but it will force companies that operate in California to be more transparent about it. Companies and storefronts that would have to comply include Microsoft with the Microsoft Store, Valve with Steam, Sony with the PlayStation Store, Nintendo with its eShop, and publishers with their own stores, like Ubisoft‚Äôs Ubisoft Store.</p><p>Polygon has reached out to all previously listed companies but did not hear back by publication time.</p><p>The law is expected to go into effect on Jan. 1, 2025, preventing companies that operate digital storefronts from using words like ‚Äúpurchase‚Äù or ‚Äúbuy‚Äù unless the company is clear that it‚Äôs selling a license, not ‚Äúunrestricted ownership interest in the digital good.‚Äù This notice will have to be ‚Äúdistinct and separate‚Äù from other terms and conditions of the purchase, according to the text. The law doesn‚Äôt apply to subscription-based services, free downloads like demos, or companies that offer ‚Äúpermanent offline download[s]‚Äù of digital goods. Companies will be fined for breaking the rules.</p><p>‚ÄúBy sending AB 2426 to Governor Newsom, California is now the first state to recognize that when digital media retailers use terms like ‚Äòbuy‚Äô and ‚Äòpurchase‚Äô to advertise digital media licenses, they are engaged in false advertising,‚Äù University of Michigan professor Aaron Perzanowski said in a <a href="https://a42.asmdc.org/press-releases/20240916-assemblymember-irwin-urges-governor-sign-legislation-increasing">news release from Irwin</a>. ‚ÄúConsumers around the world deserve to understand that when they spend money on digital movies, music, books, and games, those so-called ‚Äòpurchases‚Äô can disappear without notice. There is still important work to do in securing consumers‚Äô digital rights, but AB 2426 is a crucial step in the right direction.‚Äù</p><p>Digital purchasing is already ubiquitous, as physical media becomes less easy to find. <a href="https://www.theverge.com/2023/10/13/23915567/best-buy-discontinue-physical-media-dvd-blu-ray">Stores like Best Buy have stopped selling physical movies entirely</a>, and it wouldn‚Äôt be surprising to see more retailers follow. Physical video games use a disc or cartridge as a license, and that object is yours. But a company could still take servers offline, for instance ‚Äî ongoing access isn‚Äôt guaranteed.</p><div><p>Ownership of digital goods like movies and video games will continue to be an issue; beyond companies revoking licenses, it‚Äôs also becoming <a href="https://www.polygon.com/24140123/what-happens-game-gets-delisted-spec-ops-the-line-adult-swim">increasingly common to see games being delisted from sale</a> or pulled offline entirely, <a href="https://www.polygon.com/24152760/kim-kardashian-hollywood-glu-mobile-game-legacy">like with popular mobile game <em>Kim Kardashian: Hollywood</em></a>. In that example, players lost a decade‚Äôs worth of digital purchases. Not only is it a consumer protection issue, <a href="https://www.polygon.com/pc/24113466/adult-swim-games-delisting-law-warner-bros-discovery-archiving">but it‚Äôs a preservation problem, too</a>.</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>