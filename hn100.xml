<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 05 Jan 2025 23:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Akamai to shut down its CDN operations in China (234 pts)]]></title>
            <link>https://content.akamai.com/index.php/email/emailWebview?email=NjQyLVNLTi00NDkAAAGWBQgHSPFMp0ow2aF67IAbDOB0c1pNppYjWH8ZCkGxrVi4pDs7pT_120NiLvARghhVOBbaIJqps_3Ii2OZlixo3IPjhpR79JsTe-0&amp;trk=comments_comments-list_comment-text</link>
            <guid>42603585</guid>
            <pubDate>Sun, 05 Jan 2025 18:02:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://content.akamai.com/index.php/email/emailWebview?email=NjQyLVNLTi00NDkAAAGWBQgHSPFMp0ow2aF67IAbDOB0c1pNppYjWH8ZCkGxrVi4pDs7pT_120NiLvARghhVOBbaIJqps_3Ii2OZlixo3IPjhpR79JsTe-0&#x26;trk=comments_comments-list_comment-text">https://content.akamai.com/index.php/email/emailWebview?email=NjQyLVNLTi00NDkAAAGWBQgHSPFMp0ow2aF67IAbDOB0c1pNppYjWH8ZCkGxrVi4pDs7pT_120NiLvARghhVOBbaIJqps_3Ii2OZlixo3IPjhpR79JsTe-0&#x26;trk=comments_comments-list_comment-text</a>, See on <a href="https://news.ycombinator.com/item?id=42603585">Hacker News</a></p>
Couldn't get https://content.akamai.com/index.php/email/emailWebview?email=NjQyLVNLTi00NDkAAAGWBQgHSPFMp0ow2aF67IAbDOB0c1pNppYjWH8ZCkGxrVi4pDs7pT_120NiLvARghhVOBbaIJqps_3Ii2OZlixo3IPjhpR79JsTe-0&trk=comments_comments-list_comment-text: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Help! Politics Blog Cloudflare Subpoena (125 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42603292</link>
            <guid>42603292</guid>
            <pubDate>Sun, 05 Jan 2025 17:24:31 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42603292">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42603292: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ads chew through half of mobile data (192 pts)]]></title>
            <link>https://www.nextpit.com/ads-consume-half-of-your-mobile-data</link>
            <guid>42602673</guid>
            <pubDate>Sun, 05 Jan 2025 16:06:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nextpit.com/ads-consume-half-of-your-mobile-data">https://www.nextpit.com/ads-consume-half-of-your-mobile-data</a>, See on <a href="https://news.ycombinator.com/item?id=42602673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><span><span>Many people see adverts as the scourge of the internet but they remain the major, and in many cases, only, revenue stream for online media publishers. Another blow has been struck to online advertising recently, however, as a study has revealed how it could constitute for as much as 79 percent of the mobile data consumed by each web page. &nbsp;</span></span>&nbsp;</p>
</div><div>
     
<h2><span><span>An average of 48% of our data is spent on ads</span></span></h2> 
<p><span><span><a href="https://www.businessinsider.com/enders-analysis-ad-blocker-study-finds-ads-take-up-79-of-mobile-data-transfer-2016-3?r=DE&amp;IR=T" target="_blank">The&nbsp;study</a>,</span></span><span><span> published by media research firm <a href="https://www.endersanalysis.com/" target="_blank">Enders Analysis</a> in late April, suggested that, on average, almost half of the data required to view a web page&nbsp;is consumed by advertising. </span><span>To test this, <em>Enders</em> used a browser that mimicked an iPhone 6 and accessed a total of eight "popular" news sites (though they didn't confirm what these were).&nbsp;</span></span></p> 
<p><span><span><em>Ender</em>'s published the chart below which shows&nbsp;the&nbsp;data consumed by&nbsp;three&nbsp;web page elements: HTML (blue), Javascript (orange) and ads (green). </span><span>The columns below correspond&nbsp;to the data (in megabytes) consumed by each of the eight websites. Pages were loaded once in their entirety, once with ads disabled, and once with Javascript and ads</span><span>&nbsp;disabled to achieve the results.</span></span></p> 
<figure>
 <img alt="Enders Analysis" src="https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w782.jpg" srcset="https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w782.jpg 782w, https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w596.jpg 596w, https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w450.jpg 450w, https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w336.jpg 336w, https://fs.npstatic.com/userfiles/7031685/image/enders-analysis-w300.jpg 300w" sizes="(max-width: 810px) calc(100vw - 28px), 782px" loading="lazy" width="782" height="440"> 
 <figcaption>
  <span><span>Data transfer from eight different news sites. </span><span>/ © Enders Analysis</span></span>
 </figcaption> 
</figure> 
<p><span><span>The conclusion is that the ads accounted for anywhere between 18&nbsp;and 79 percent of the data transferred while non-essential JavaScript elements&nbsp;added an extra 6 to 68 percent.&nbsp;</span></span></p> 
<p><span><span>"</span></span>On the basis of this investigation, an estimate that says advertising accounts for half of all data used by publisher pages on iPhones does not look unreasonable," <a href="https://www.theguardian.com/media/2016/mar/16/ad-blocking-advertising-half-of-data-used-articles" target="_blank">the report stated</a>.</p> 
<h2><span><span>Oh, so that's why I run out of data before the end of the month...</span></span></h2> 
<p>Well, not exactly. This was only tested on eight unnamed news sites&nbsp;on a system which represented an iPhone 6: it's far from comprehensive. That said, it does provide insight into the <em>potential</em>&nbsp;effect that advertising can have on mobile data.</p> 
<p>Mobile data is consumed by far more than just webpages: downloads, streaming, messages and apps can all add to how much mobile data your device uses. But mobile browsers like Chrome are often at the top of this list&nbsp;(just check your <em>mobile data</em> page in your Android settings now to see for yourself).</p> 
<figure>
 <img alt="ABP banners" src="https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w782.jpg" srcset="https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w782.jpg 782w, https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w596.jpg 596w, https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w450.jpg 450w, https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w336.jpg 336w, https://fs.npstatic.com/userfiles/6792426/image/ABP-banners-w300.jpg 300w" sizes="(max-width: 810px) calc(100vw - 28px), 782px" loading="lazy" width="782" height="440"> 
 <figcaption>
  <span><span>Many people turn to adblock apps to reduce mobile data usage, but it's a contentious subject. </span><span>/ © ANDROIDPIT</span></span>
 </figcaption> 
</figure> 
<h2>Final thoughts</h2> 
<p><span><span>Solutions to this issue are scarce, but Adblock services do provide&nbsp;one way to reduce this data consumption. This is a c</span><span>ontroversial subject, though, as ads&nbsp;are often the sole&nbsp;source&nbsp;of a website's revenue, and cutting this off invariably means cutting funding for that site.&nbsp;</span></span></p> 
<p>With online ads being so omnipresent&nbsp;– and indeed vital to the survival of most websites&nbsp;– we just hope that they can be made more efficient, and their cost to the mobile data plans of consumers reduced further. For more ideas on this topic, check out our helpful guide to <a href="https://www.nextpit.com/reduce-mobile-data-usage-android" target="_top">reducing your mobile data consumption</a>.</p> 
<p>What is your position on online advertising and mobile data consumption? Let us know in the comments.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The day I taught AI to read code like a Senior Developer (350 pts)]]></title>
            <link>https://nmn.gl/blog/ai-senior-developer</link>
            <guid>42601847</guid>
            <pubDate>Sun, 05 Jan 2025 14:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nmn.gl/blog/ai-senior-developer">https://nmn.gl/blog/ai-senior-developer</a>, See on <a href="https://news.ycombinator.com/item?id=42601847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><em>A messy experiment that changed how we think about AI code analysis</em></p>

<p>Last week, I watched our AI choke on a React codebase - again. As timeout errors flooded my terminal, something clicked. We’d been teaching AI to read code like a fresh bootcamp grad, not a senior developer.</p>

<p>Here’s what I mean.</p>

<!--more-->

<h2 id="the-bootcamp-vs-senior-mindset">The Bootcamp vs Senior Mindset</h2>

<p>Remember your first day reading production code? Without any experience with handling mature codebases, you probably quickly get lost in the details<sup>[0]</sup></p>

<p>But watch a senior dev review a massive PR:</p>

<ul>
  <li>They jump straight to the core files</li>
  <li>Group changes by feature (“all auth changes, all db changes”)</li>
  <li>Build a mental model of architecture first</li>
  <li>Only then dive into implementation</li>
</ul>

<p>Obvious in hindsight, right? This realization led us to completely rewire our analyzer.</p>

<h2 id="the-experiment">The Experiment</h2>

<p>Instead of dumping files linearly, we built a context-aware grouping system:</p>

<div><pre><code><span>interface</span> <span>FileGroup</span> <span>{</span>
  <span>files</span><span>:</span> <span>ProjectFile</span><span>[];</span>
  <span>totalSize</span><span>:</span> <span>number</span><span>;</span>
  <span>groupContext</span><span>:</span> <span>string</span><span>;</span> <span>// 'auth', 'database', etc.</span>
<span>}</span>

<span>export</span> <span>const</span> <span>groupFiles</span> <span>=</span> <span>(</span><span>files</span><span>:</span> <span>ProjectFile</span><span>[]):</span> <span>FileGroup</span><span>[]</span> <span>=&gt;</span> <span>{</span>
  <span>// Group files by related functionality and size</span>
  <span>const</span> <span>fileInfos</span> <span>=</span> <span>files</span><span>.</span><span>map</span><span>(</span><span>file</span> <span>=&gt;</span> <span>({</span>
    <span>file</span><span>,</span>
    <span>size</span><span>:</span> <span>file</span><span>.</span><span>content</span><span>?.</span><span>length</span> <span>||</span> <span>0</span><span>,</span>
    <span>context</span><span>:</span> <span>getFileContext</span><span>(</span><span>file</span><span>.</span><span>path</span><span>)</span>
  <span>}));</span>

  <span>// Process larger, more important files first</span>
  <span>fileInfos</span><span>.</span><span>sort</span><span>((</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>b</span><span>.</span><span>size</span> <span>-</span> <span>a</span><span>.</span><span>size</span><span>);</span>

  <span>const</span> <span>groups</span><span>:</span> <span>FileGroup</span><span>[]</span> <span>=</span> <span>[];</span>
  <span>let</span> <span>currentGroup</span> <span>=</span> <span>createEmptyGroup</span><span>();</span>

  <span>for</span> <span>(</span><span>const</span> <span>{</span> <span>file</span><span>,</span> <span>size</span><span>,</span> <span>context</span> <span>}</span> <span>of</span> <span>fileInfos</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>shouldStartNewGroup</span><span>(</span><span>currentGroup</span><span>,</span> <span>size</span><span>,</span> <span>context</span><span>))</span> <span>{</span>
      <span>groups</span><span>.</span><span>push</span><span>(</span><span>currentGroup</span><span>);</span>
      <span>currentGroup</span> <span>=</span> <span>createNewGroup</span><span>(</span><span>file</span><span>,</span> <span>size</span><span>,</span> <span>context</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>addFileToGroup</span><span>(</span><span>currentGroup</span><span>,</span> <span>file</span><span>,</span> <span>size</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>groups</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Then we changed how we prompt the AI. Instead of “analyze this file”, we give it context about the feature group first:</p>

<div><pre><code><span>const</span> <span>buildGroupPrompt</span> <span>=</span> <span>(</span><span>group</span><span>:</span> <span>FileGroup</span><span>):</span> <span>string</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>`
    Analyzing authentication system files:
    - Core token validation logic
    - Session management
    - Related middleware
    
    Focus on:
    1. How these integrate with existing auth patterns
    2. Security implications
    3. Performance impact on other systems

    Files to analyze:
    </span><span>${</span><span>formatFiles</span><span>(</span><span>group</span><span>.</span><span>files</span><span>)}</span><span>
  `</span><span>;</span>
<span>}</span>
</code></pre></div>

<h2 id="the-holy-shit-moment">The Holy Shit Moment</h2>

<p>The results broke our benchmark script. We thought it was a bug.</p>

<p>The AI went from:</p>
<div><pre><code>"This file contains authentication logic using JWT tokens"
</code></pre></div>

<p>To:</p>
<div><pre><code>"Warning: This auth change could impact websocket connections.
The token refresh logic shares patterns with the notification 
service (added last month), suggesting a potential race 
condition during high-traffic socket reconnects.

Related PR: #1234 (merged last week) modified the same
retry logic. Consider adding backoff."
</code></pre></div>

<p>That’s senior dev level awareness. It was catching connections we hadn’t explicitly taught it about.</p>

<h2 id="what-actually-changed">What Actually Changed?</h2>

<p>The magic isn’t in fancy ML or bigger models. It’s in mirroring how senior devs think:</p>

<ol>
  <li><strong>Context First</strong>: We front-load system understanding before diving into code</li>
  <li><strong>Pattern Matching</strong>: Group similar files to spot repeated approaches</li>
  <li><strong>Impact Analysis</strong>: Consider changes in relation to the whole system</li>
  <li><strong>Historical Understanding</strong>: Track why code evolved certain ways</li>
</ol>

<h2 id="the-unexpected-side-effects">The Unexpected Side Effects</h2>

<p>The system started catching things we didn’t design for:</p>

<ul>
  <li>Spotting copy-pasted code across different features</li>
  <li>Flagging inconsistent error handling patterns</li>
  <li>Warning about potential performance bottlenecks</li>
  <li>Suggesting architectural improvements based on usage patterns</li>
</ul>

<h2 id="why-this-matters">Why This Matters</h2>

<p>Every few days there’s a new “AI-powered IDE” on Product Hunt. They’re solving the wrong problem. Making code suggestions without deep context is like having a brilliant junior dev who just joined yesterday - they’ll write clean code that subtly breaks everything.</p>

<p>The key isn’t better code generation. It’s better code understanding.</p>

<h2 id="open-questions">Open Questions</h2>

<p>We’re still figuring out:</p>

<ul>
  <li>When to refresh vs preserve historical understanding</li>
  <li>How to handle conflicting patterns in different parts of the system</li>
  <li>Whether to expose uncertainty in the analysis</li>
</ul>

<h2 id="whats-next">What’s Next?</h2>

<p>I’m curious if we can teach AI to spot other senior dev instincts:</p>

<ul>
  <li>Identifying tech debt before it happens</li>
  <li>Suggesting architectural improvements</li>
  <li>Catching security issues from usage patterns</li>
  <li>Understanding unwritten team conventions</li>
</ul>

<p>The problem isn’t making AI write more code. It’s teaching it to think about code the way experienced developers do.</p>

<p><small>
[0] Previously said <em>You probably did what I did - start at line 1, read every file top to bottom, get lost in the details.</em>, edited in response to <a href="https://news.ycombinator.com/item?id=42602156">feedback from advael</a>
</small></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Human study on AI spear phishing campaigns (126 pts)]]></title>
            <link>https://www.lesswrong.com/posts/GCHyDKfPXa5qsG2cP/human-study-on-ai-spear-phishing-campaigns</link>
            <guid>42601681</guid>
            <pubDate>Sun, 05 Jan 2025 13:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/GCHyDKfPXa5qsG2cP/human-study-on-ai-spear-phishing-campaigns">https://www.lesswrong.com/posts/GCHyDKfPXa5qsG2cP/human-study-on-ai-spear-phishing-campaigns</a>, See on <a href="https://news.ycombinator.com/item?id=42601681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postContent"><p id="block0">TL;DR: We ran a human subject study on whether language models can successfully spear-phish people. We use AI agents built from GPT-4o and Claude 3.5 Sonnet to search the web for available information on a target and use this for highly personalized phishing messages. We achieved a click-through rate of above 50% for our AI-generated phishing emails.</p><h2 id="Full_paper__https___arxiv_org_abs_2412_00586">Full paper: <a href="https://arxiv.org/abs/2412.00586">https://arxiv.org/abs/2412.00586</a></h2><p id="block1">This post is intended to be a brief summary of the main findings, these are some key insights we gained:</p><ol><li id="block2">AI spear-phishing is highly effective, receiving a click-through rate of more than 50%, significantly outperforming our control group.</li><li id="block3">AI-spear phishing is also highly cost-efficient, reducing costs by up to 50 times compared to manual attacks.</li><li id="block4">AI models are highly capable of gathering open-source intelligence. They produce accurate and useful profiles for 88% of targets. Only 4% of the generated profiles contained inaccurate information.</li><li id="block5">Safety guardrails are not a noteworthy barrier for creating phishing mails with any tested model, including Claude 3.5 Sonnet, GPT-4o, and o1-preview.</li><li id="block6">Claude 3.5 Sonnet is surprisingly good at detecting AI-generated phishing emails, though it struggles with some phishing emails that are clearly suspicious to most humans.</li></ol><h2 id="Abstract">Abstract</h2><p id="block7">In this paper, we evaluate the capability of large language models to conduct personalized phishing attacks and compare their performance with human experts and AI models from last year. We include four email groups with a combined total of 101 participants: A control group of arbitrary phishing emails, which received a click-through rate (recipient pressed a link in the email) of 12%, emails generated by human experts (54% click-through), fully AI-automated emails 54% (click-through), and AI emails utilizing a human-in-the-loop (56% click-through). Thus, the AI-automated attacks performed on par with human experts and 350% better than the control group. The results are a significant improvement from similar studies conducted last year, highlighting the increased deceptive capabilities of AI models. Our AI-automated emails were sent using a custom-built tool that automates the entire spear phishing process, including information gathering and creating personalized vulnerability profiles for each target. The AI-gathered information was accurate and useful in 88% of cases and only produced inaccurate profiles for 4% of the participants. We also use language models to detect the intention of emails. Claude 3.5 Sonnet scored well above 90% with low false-positive rates and detected several seemingly benign emails that passed human detection. Lastly, we analyze the economics of phishing, highlighting how AI enables attackers to target more individuals at lower cost and increase profitability by up to 50 times for larger audiences.</p><h2 id="Method">Method</h2><p id="block8">In a brief summary, the method consists of 5 steps:</p><ol><li id="block9">Collecting Targets.</li><li id="block10">Collecting information about the targets using an AI web-browsing agent that crawls publicly available information.</li><li id="block11">Writing personalized phishing emails based on the collected information and carefully crafted language model prompts.</li><li id="block12">Sending emails using custom-built and automated software.</li><li id="block13">Analyzing outcomes by tracking clicks on embedded URLs in emails.</li></ol><figure><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/zihrxmduql07fedjthpg" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/ikadfgqrctfkr4odt4zs 340w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/mj70icvkqleshm2gkrjh 680w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/chqjwjz8z46bbjabcfip 1020w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/qqxaaxn7dt2tazrnsmvg 1360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/r0azmgnf9kw4bxgqz27w 1700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/muertujy7chjqeyojaxw 2040w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/h4ess8sexvyuodbowyno 2380w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/hwcrsogy7gjv5aisifif 2720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/xtso6rsibpx4g0ccybdj 3060w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/rln5x6elatjmjojxorrf 3372w"><figcaption>Example from the paper for an AI-compiled profile from step 2 and an AI-written email from step 3.</figcaption></figure><h2 id="Results">Results</h2><p id="block14">For full results, <a href="https://arxiv.org/abs/2412.00586">go to the paper</a></p><p id="block15">The results of the phishing emails are presented in the figure below (figure 5 in the paper). The control group emails received a click-through rate of 12%, the emails generated by human experts 54%, the fully AI-automated emails 54%, and the AI-emails utilizing a human-in-the-loop 56%. Both the AI-generated email types (fully automated and human-in-the-loop) performed on par with the emails created by human experts.</p><figure><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/nqlxyoxumgrnuhtulxli" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/d8bvnmizhwnkysw6onlg 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/szvscbwya6pdk72bkybn 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/x1azo4k5hnkaaaxe9smv 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/iaktghjwlgymxdnu9cue 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/it5brr6q3d9ymmv2ptsl 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/qrewhds9wjdk9cr16mkj 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/hi5rmz04gn7bilkfdnvx 2520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/fmb4bjb4gy0utxfmfioy 2880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/sdgoemme0jmqy9tgqavx 3240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/c7rq5gwsgdsfouuqojfv 3571w"><figcaption>Click-through rates for the 4 different groups in our human study</figcaption></figure><p id="block16">The figure below shows that about 40% of both AI groups specifically mentioned in their free text answer that personalization increased their trust in the email message, compared to 0% in the control group and about 20% in the human expert group. The presentation received equally trustworthy scores for the AI and human expert-generated emails.&nbsp;</p><figure><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/dlb6x0dmzwelwntogqcn" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/zkzyyvpmkkunqsydwcjh 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/wocaygl1owympkxdigxs 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/cphmaqxh9tdu61xi1cxi 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/fyskzwfnxbp3yf42dpkk 1440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/blnqvuzr8s4nzypqwpnj 1800w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/wlzcmardw9dd8q4jwboh 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/u8whoy4mat6zpbl95grm 2520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/lzxgmrhk52r7gvuo8v3g 2880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/zmir8904kt853dcwvduu 3240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/rtpqeagsend9mlbdppsj 3523w"><figcaption>Common reasons given in free text survey responses for why the email was trustworthy as a percentage of survey responses per group.</figcaption></figure><p id="block17">Furthermore, we analyzed the quality of AI-compiled profiles. In a manual analysis of 51 profiles, we found that 88% of profiles were accurate and useful, 8% were accurate but not useful and 4% contained inaccurate information.</p><p id="block18">To measure the time saved, we measured how much time we spent on the interventions for the human-in-the-loop group. The information gathering (OSINT) updates for this group took an average of 1:05 minutes, and the email message updates averaged 1:36 minutes. Thus, the total combined time was 2:41 minutes per message. To better measure the time difference between AI-automated and manual attacks, we manually replicated the OSINT information gathering and email crafting processes<br>provided by our AI tool. We performed the manual replication on four targets. The process required an average of 23:27 minutes to gather OSINT data and an additional 10:10 minutes to write each personalized email, totaling about 34 minutes per target. Thus the human-in-the-loop based AI-automation was about 92% faster than the fully manual process.</p><h2 id="Automated_intent_detection">Automated intent detection</h2><p id="block19">On average, Claude achieved a true positive detection rate of 97.25% with no false positives. If we weigh the detection rates by category, i.e., each category is given the same weight regardless of the number of messages in the category, the detection rate remains almost identical (97.64%). Claude 3.5 Sonnet far outperformed GPT-4o. The paper contains additional results using other models for suspicious intent detection.</p><p id="block20">However, the possibilities of jailbreaks and prompt injections pose a significant challenge to using language models to prevent phishing.</p><figure><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/eypxgzjrowktgia6njgn" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/mvzzpnac9lcjvg23fjrj 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/dglrsocuhux81t8r68ia 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/gy8ugxm43aqztd3blnwr 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/jllnk4tenhnbtlm5v0rl 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/lr0raqdwn2ctlaxkti4j 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/lss8hqsq40eteuxllgmw 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/zhxcp3i5erzhttymhker 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/tntw1gs5ygvceclvh334 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/qhkf78cvs7w0vbrebgxb 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/guirtlproudpetzmm2ca 1100w"><figcaption>Overview of suspicion scores evaluated by the Claude 3.5 Sonnet and GPT-4o. The first row is evaluated for suspicion by GPT-4o, and the second by Claude 3.5 Sonnet. The plots compare different types of mail, from legitimate mail, mail generated for our 2 AI groups (orange), mail generated by 3 different AI models (red), and other types of phishing mail (blue). For more information on the data used, see section 4.2 of the paper. For a theoretical detection threshold of 50%, we show a cutoff line with corresponding false positive (FP) and true positive (TP) percentages.</figcaption></figure><h2 id="The_economics_of_AI_enhanced_phishing">The economics of AI-enhanced phishing</h2><p id="block22">Table 4 from the paper shows part of our economic analysis. We estimate q for three different scenarios, considering low, medium and high conversion rates. conversion rate refers to the ratio of opened URLs that result in a successful fraud. Using fully automated AI with no human intervention always leads to the highest returns.</p><figure><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/x3ntoytpbfo2scr0rlvr" srcset="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/fcwcluevh8rchp3qeroi 140w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/yik3r949hkdjgjwlbo5d 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/kqqlqswyxbyitdaz7ofh 420w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/idknnmgnscrwjockkiwn 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/apisqoecim0cvxpzflvy 700w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/n0bhbnogbod6mzb875ql 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/wkx3mzktkxjeopdplqjy 980w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/anrcifhebetdxtfsa8rl 1120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/nb5fqadipjzplrnl9jlm 1260w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/GCHyDKfPXa5qsG2cP/qm8b7skvlsi0jlvegamd 1374w"><figcaption>&nbsp;</figcaption></figure><h2 id="Future_Work">Future Work</h2><p id="block23">For future work, we hope to scale up studies on human participants by multiple orders of magnitude and measure granular differences in various persuasion techniques. Detailed persuasion results for different models would help us understand how AI-based deception is evolving and how to ensure our protection schemes stay up-to-date. Additionally, we will explore fine-tuning models for creating and detecting phishing. We are also interested in evaluating AI's capabilities to exploit other communication channels, such as social media or modalities like voice. Lastly, we want to measure what happens after users press a link in an email. For example, how likely is it that a pressed email link results in successful exploitation, what different attack trees exist (such as downloading files or entering account details in phishing sites), and how well can AI exploit and defend against these different paths? We also encourage other researchers to explore these avenues.&nbsp;</p><p id="block24">We propose personalized mitigation strategies to counter AI-enhanced phishing. The cost-effective nature of AI makes it highly plausible we're moving towards an agent vs agent future. AI could assist users by creating personalized vulnerability profiles, combining their digital footprint with known behavioral patterns.</p><h2 id="Conclusion">Conclusion</h2><p id="block25">Our results reveal the significant challenges that personalized, AI-generated phishing emails present to current cybersecurity systems. Many existing spam filters use signature detection (detecting known malicious content and behaviors). By using language models, attackers can effortlessly create phishing emails that are uniquely adapted to every target, rendering signature detection schemes obsolete. As models advance, their capabilities of persuasion will likely also increase. We find that LLM-driven spear phishing is highly effective and economically viable, with automated reconnaissance that provides accurate and useful information in almost all cases. Current safety guardrails fail to reliably prevent models from conducting reconnaissance or generating phishing emails. However, AI could mitigate these threats through advanced detection and tailored countermeasures.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Wouldn't Download an AI (234 pts)]]></title>
            <link>https://altayakkus.substack.com/p/you-wouldnt-download-an-ai</link>
            <guid>42601549</guid>
            <pubDate>Sun, 05 Jan 2025 13:19:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://altayakkus.substack.com/p/you-wouldnt-download-an-ai">https://altayakkus.substack.com/p/you-wouldnt-download-an-ai</a>, See on <a href="https://news.ycombinator.com/item?id=42601549">Hacker News</a></p>
Couldn't get https://altayakkus.substack.com/p/you-wouldnt-download-an-ai: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A story on home server security (194 pts)]]></title>
            <link>https://raniseth.com/blog/2025-01-04-Home-Server-Security.html</link>
            <guid>42601374</guid>
            <pubDate>Sun, 05 Jan 2025 12:36:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://raniseth.com/blog/2025-01-04-Home-Server-Security.html">https://raniseth.com/blog/2025-01-04-Home-Server-Security.html</a>, See on <a href="https://news.ycombinator.com/item?id=42601374">Hacker News</a></p>
Couldn't get https://raniseth.com/blog/2025-01-04-Home-Server-Security.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[How Nat Traversal Works (2020) (319 pts)]]></title>
            <link>https://tailscale.com/blog/how-nat-traversal-works</link>
            <guid>42600846</guid>
            <pubDate>Sun, 05 Jan 2025 10:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tailscale.com/blog/how-nat-traversal-works">https://tailscale.com/blog/how-nat-traversal-works</a>, See on <a href="https://news.ycombinator.com/item?id=42600846">Hacker News</a></p>
Couldn't get https://tailscale.com/blog/how-nat-traversal-works: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The funniest thing I ever did – a.k.a. "How To Make $100K From A Dick Joke." (208 pts)]]></title>
            <link>https://imgur.com/gallery/KZ4u3c4</link>
            <guid>42600595</guid>
            <pubDate>Sun, 05 Jan 2025 09:03:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://imgur.com/gallery/KZ4u3c4">https://imgur.com/gallery/KZ4u3c4</a>, See on <a href="https://news.ycombinator.com/item?id=42600595">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Struggle with CSS Flexbox? This Playground Is for You (259 pts)]]></title>
            <link>https://yoavsbg.github.io/css-flexbox-playground/</link>
            <guid>42600586</guid>
            <pubDate>Sun, 05 Jan 2025 09:02:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yoavsbg.github.io/css-flexbox-playground/">https://yoavsbg.github.io/css-flexbox-playground/</a>, See on <a href="https://news.ycombinator.com/item?id=42600586">Hacker News</a></p>
Couldn't get https://yoavsbg.github.io/css-flexbox-playground/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Remote code execution via MIDI messages (132 pts)]]></title>
            <link>https://psi3.ru/blog/swl01u/</link>
            <guid>42600349</guid>
            <pubDate>Sun, 05 Jan 2025 07:40:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://psi3.ru/blog/swl01u/">https://psi3.ru/blog/swl01u/</a>, See on <a href="https://news.ycombinator.com/item?id=42600349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            

            
            <span id="article-meta">Jan 2025 · 45 min read</span>
            <p>I gained remote code execution via MIDI messages to trick my synth into playing Bad Apple on its LCD. This blog post is about my journey with this reverse engineering project.</p>
            <figure>
                <iframe width="1080" height="608" src="https://www.youtube.com/embed/u6sukVMijBg" title="Yamaha PSR-E433 Bad Apple demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
                <figcaption>Final iteration of Bad Apple</figcaption>
            </figure>

            <h2 id="the-beginning">The beginning</h2>
            <p>I’ve had this Yamaha PSR-E433 synth for a very long time, and a couple of years ago I decided to open it up — partly because it was in need of cleaning, and partly because I was really curious about its internals. After removing some screws and digging up the main circuit board (labeled “DMLCD”), I was quite amused to find two flash chips, one RAM chip and an absolute unit of a chip labeled “YAMAHA SWL01U”, which I guessed had to be the brains of the operation. Using that part number I wasn’t able to find any information about the chip online apart from an <a href="https://sandsoftwaresound.net/swl-micro-architecture/" target="_blank">article</a> that claimed it was based around a “SuperH” CPU core – an <abbr title="Instruction Set Architecture">ISA</abbr> that I’ve encountered for the first time ever in that article. So, after finishing the cleanup I just put the synth back together, which left me wondering about what that mysterious chip really had under the hood.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/virgin_dmlcd.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/thumb/virgin_dmlcd.jpg" alt="DMLCD board in its natural habitat"></a>
                <figcaption>DMLCD board in its natural habitat</figcaption>
            </figure>
            <p>Fast forward to a few months ago, when I took apart the poor synth again – this time purely out of curiosity. What sparked that curiosity was a service manual for a similar synth (the E443, I own an E433) that I found online, which among other things featured a pinout of that main chip that listed pin descriptions so enticing (“TESTN – Test Mode”, “PROTN – Determines if the product is a prototype”) that I just had to get a look at what was going on. There were also two bidirectional UART interfaces, and by looking at the schematic I could see that one of the two transmit pins wasn’t connected anywhere, suggesting that the chip maybe emits some kind of log via that pin. Oh, and it also had JTAG test points nicely broken out on the board -  basically a 5-pin interface for various production line testing and debugging-adjacent tasks.</p>
            <p>So, what were my options at that point? I could:</p>
            <ul>
                <li>Play around with the TESTN and PROTN pins and see how the synth behaves;</li>
                <li>Solder to the UART Tx pin and see what the chip outputs;</li>
                <li>Connect to the JTAG interface and read the chip’s identification code;</li>
                <li>Desolder one of the two flash chips and dump the firmware.</li>
            </ul>
            <p>Let’s begin with the first approach. Both of the boot mode select pins end with an N, suggesting that these pins are active low, meaning that the signal is considered active when the voltage is close to zero, as opposed to the power rail, which in this case is 3.3 volts. The schematic says that both of these pins are pulled up to 3.3 volts with a resistor, so we can just short the pins to ground in order to activate them. That’s exactly what I did; unfortunately, it appeared as though activating the TESTN pin just prevented the synth from booting, and activating the PROTN pin didn’t change the synth’s behavior at all. Hey, at least I didn’t brick it!</p>
            <p>Next up, let’s try looking at the UART interface. That pin that I mentioned didn’t lead anywhere, not even a test point, which means that I had to solder directly to a 0.3mm wide pin of the chip. No success this time either, as the chip didn’t output anything in any of the 4 combinations of the TESTN and PROTN signals.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/dmlcd_w_3_wires.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/thumb/dmlcd_w_3_wires.jpg" alt="SWL01U with three debug wires coming off of the board"></a>
                <figcaption>SWL01U with three debug wires coming off of the board</figcaption>
            </figure>
            <p>It was now JTAG’s turn. Even though the next option (desoldering a flash chip) was quite scary as it meant that I had to build a flash dumper (I didn’t have one), messing around with the JTAG was even scarier for another reason. The thing is that JTAG is quite an abstract interface that vendors can build whatever they want on top of. In order to talk to a device via JTAG, you have to have a detailed description of the circuitry that builds on top of it, which usually comes in the form of a <abbr title="Boundary Scan Description Language">BSDL</abbr> file. There’s basically only one command that almost every device supports, and that is reading the IDCODE – a 32-bit number that acts as an identifier for the type of device you’re talking to. Let’s hook a <abbr title="a JTAG to USB adapter">J-Link</abbr> up to our board and try to read that identification code using <abbr title="the software in charge of controlling the JTAG">OpenOCD</abbr>.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/dmlcd_and_jlink.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/thumb/dmlcd_and_jlink.jpg" alt="J-Link connected to the board"></a>
                <figcaption>J-Link connected to the board</figcaption>
            </figure>
            <figure>
                <code><span>$ cat openocd.cfg</span>
<span># Uh-oh, a continuity error! I've switched to an FT232R-based dongle instead of J-Link since I took the picture above.</span>
adapter driver ft232r
transport select jtag
adapter speed 5000
<span>$ openocd</span>
Open On-Chip Debugger 0.12.0
Licensed under GNU GPL v2
For bug reports, read
        http://openocd.org/doc/doxygen/bugs.html
Info : only one transport option; autoselect 'jtag'
Warn : Transport "jtag" was already selected
adapter speed: 5000 kHz

Info : Listening on port 6666 for tcl connections
Info : Listening on port 4444 for telnet connections
Info : clock speed 3000 kHz
Warn : There are no enabled taps.  AUTO PROBING MIGHT NOT WORK!!
Info : JTAG tap: auto0.tap tap/<span>device found: 0x3f0f0f0f</span> (mfg: 0x787 (&lt;unknown&gt;), part: 0xf0f0, ver: 0x3)
Warn : AUTO auto0.tap - use "jtag newtap auto0 tap -irlen 4 -expected-id 0x3f0f0f0f"
Warn : gdb services need one or more targets defined</code>
                <figcaption>OpenOCD reporting the IDCODE</figcaption>
            </figure>
            <p>Well, that’s something. The IDCODE is reported as 0x3f0f0f0f, which is suspiciously pretty. So suspicious that I triple-checked my wiring, but nope, looks like that’s the actual IDCODE of the device, which after a quick Google search seemed like it belonged to either an STMicroelectonics STR7xxx or an Atmel SAM7xxx microcontroller, both of which were based around an <abbr title="not the same thing as ARMv7">ARM7</abbr> CPU core. My only option was to assume that I was dealing with an actual ARM7TDMI core like the one that these MCUs are based on. On the other hand, incorrectly talking to a device via JTAG risks catastrophic damage, as some implementations of the interface grant very low-level access to the hardware, even lower than the machine code that CPU cores execute have. There’s a small chance of letting the magic smoke out when you instruct the device incorrectly at such a low level, provided the circumstances turn against you. Anyways, I did it; I told OpenOCD that I’m dealing with an ARM7TDMI core and it happily complied.</p>
            <figure>
                <code><span>$ cat openocd.cfg</span>
adapter driver ft232r
transport select jtag
adapter speed 5000
jtag newtap swl01u cpu -irlen 4 -expected-id 0x3f0f0f0f
target create swl01u.cpu arm7tdmi -chain-position swl01u.cpu
<span>$ openocd</span>
Open On-Chip Debugger 0.12.0
Licensed under GNU GPL v2
For bug reports, read
        http://openocd.org/doc/doxygen/bugs.html
Info : only one transport option; autoselect 'jtag'
Warn : Transport "jtag" was already selected
swl01u.cpu
Info : Listening on port 6666 for tcl connections
Info : Listening on port 4444 for telnet connections
Info : clock speed 3000 kHz
Info : JTAG tap: swl01u.cpu tap/device found: 0x3f0f0f0f (mfg: 0x787 (&lt;unknown&gt;), part: 0xf0f0, ver: 0x3)
Info : Embedded ICE version 1
Info : swl01u.cpu: hardware has 2 breakpoint/watchpoint units
Info : starting gdb server for swl01u.cpu on 3333
Info : Listening on port 3333 for gdb connections</code>
                <figcaption>OpenOCD assuming communication with an ARM7TDMI core</figcaption>
            </figure>
            <p>At least at this point, the magic smoke was still contained within the chip. I nervously connected to OpenOCD via <abbr title="a program used to debug software">GDB</abbr> and tried pausing and resuming execution of the program. I was very surprised and excited to witness the current draw reported by my lab bench power supply reacting predictably to my commands. The entire circuit board was drawing about 115 mA when running and about 98 mA when paused, which was a very good sign that what I was talking to was, in fact, an ARM7TDMI core. At that point I had no other way to verify whether the thing’s CPU was really stopping or not.</p>
            <figure>
                <video controls="" src="https://psi3.ru/blog/swl01u/videos/current_draw_differential.mp4"></video>
                <figcaption>Me noting the power draw differential (in Russian)</figcaption>
            </figure>

            <h2 id="dumping-the-firmware">Dumping the firmware</h2>
            <p>Wow, it looks like I won’t even have to desolder the flash chip in order to dump the firmware! And I already know what ISA the chip is based on, so I won’t have to go digging around in the firmware image in order to find that out! Looking in the documentation for ARM7TDMI, the <abbr title="the address where the CPU starts executing instructions from when it’s first powered up">reset vector</abbr> is located at address 0, so let’s see what kind of data there is at that address.</p>
            <figure>
                <code>(gdb) x/2xw 0 <span># eXamine 2 heX Words at location 0</span>
<span>0x0</span>:    0xe59ff018      0xe59ff018
(gdb) x/2i 0  <span># eXamine 2 Instructions at location 0</span>
<span>0x0</span>: <span>ldr</span>     <span>pc</span>, [<span>pc</span>, <span>#24</span>]   <span>@ 0x20</span>
<span>0x4</span>: <span>ldr</span>     <span>pc</span>, [<span>pc</span>, <span>#24</span>]   <span>@ 0x24</span></code>
                <figcaption>Asking GDB to read two instructions at address 0</figcaption>
            </figure>
            <p>Yeah, okay, it’s a jump, just as I expected. The very next instruction is some other vector, and it’s a jump as well. That looks about right. Yeah, we’re definitely on the right track! I know the size of the flash chip (16 MiBytes), so let’s just dump 16 MiBytes of data starting at address 0 into a file, load it up into <abbr title="a reverse engineering framework that I was used to using up until this point">Cutter</abbr> and see what secrets it contains.</p>
            <p>I’m very unexperienced when it comes to reverse engineering, but one thing that I do know is that strings are a goldmine of easily digestible information about a piece of software. That’s why the first thing that I do when starting an <abbr title="reverse engineering">RE</abbr> project is look at the “Strings” section in an RE tool. This project was no exception, and I was very pleased to see strings such as “This code can only run on a <abbr title="extension of ARM that introduces shorter instructions">Thumb</abbr> compatible processor”, “Illegal address (e.g. wildly outside array bounds)”, “Abnormal termination (e.g. abort() function)”, and most of all, “SWL01U Internal”.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/strings_in_cutter.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/strings_in_cutter.png" alt="Strings section in Cutter"></a>
                <figcaption>Strings section in Cutter</figcaption>
            </figure>
            <p>What I didn’t like is how the very few strings that were there in the image repeated every 64 KiBytes. So, for instance, the string “SWL01U Internal” was contained at addresses 0x0000bfd0, 0x0001bfd0, 0x0002bfd0 and so on. Both this repetition (likely caused by a primitive design of the address decoder inside the chip) and that string itself hinted that I took a dump of some kind of memory inside the chip itself, and not one of the external flash chips like I had originally imagined. I concluded that this SWL01U chip contains a 64KiByte ROM.</p>
            <p>The instruction at the reset vector was a jump to address 0x02000000, which I thought might actually be the external flash chip this time. I once again took a 16 MiByte dump starting at that address, and was pleased not to find any repetitions this time. Also, I observed a large amount of strings that I could recognize just from using the synth, such as “GrandPno”, “Tr1 will be OverWritten!” and “BogiWogi”.</p>
            <p>So, what do we know so far? We know that the chip itself contains a 64 KiByte ROM that immediately transfers control over to the external 16 MiByte flash chip upon startup. The ROM is located at address 0x00000000, and the flash starts at 0x02000000. We have dumps of both memories and can now start reversing the firmware of this synth to hopefully gain more information about its main chip.</p>

            <h2 id="reversing-the-firmware">Reversing the firmware</h2>
            <p>After staring at the flash image for about an hour in Cutter, it became very obvious to me that this RE tool just wasn’t going to cut it (pun intended) and that I needed to switch it out for something more powerful. I’m happy to report that Ghidra met my expectations.</p>
            <p>Now, we have to get a little philosophical here. In my eyes, RE is like a game of minesweeper. You start with an empty field not knowing the state of any of the cells, i.e. not knowing whether each individual cell contains a landmine or not. When you discover the state of a cell, you have the context to deduce the state of its neighbor cells. In minesweeper, you don’t have a particular direction in which you progress. You never say “In this game of minesweeper, I want to go up no matter what”, you just let the numbers nudge you in the direction that is the easiest to go in at the moment. I assert that this is also true for RE. Once you find out what a function or a variable does, you suddenly understand a little more about functions and variables that depend on the ones whose meaning you’ve just inferred. It may be beneficial not to set any particular goal with an RE project, and instead letting the complex network of intertwined functions and variables guide you towards understanding the system as a whole.</p>
            <p>So, where do we start? Right now we have two entry points from which we could begin prying the firmware apart: the reset vector and the strings. I tried both, just spending night after night learning more about the next function based on new insights gained from learning more about the previous one. This process is not very exciting to witness from the outside, so I don’t feel the need to retrace and describe my steps here. It’s just a chain of simple logical conclusions which propagate through the codebase. Like those little flags propagating through the field in a game of minesweeper.</p>
            <p>There’s one subsystem in the firmware that I think is worth mentioning as it plays an instrumental role in the whole “Bad Apple” thing: The Shell. As I was digging around in the “Defined Strings” section of Ghidra, I noticed a cluster of a few ones that looked like they might be some kind of list of commands for some kind of a shell:</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/strings_in_ghidra.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/strings_in_ghidra.png" alt="The strings “help”, “?”, “info”, “ver” at addresses that are close together"></a>
                <figcaption>The strings “help”, “?”, “info”, “ver” at addresses that are close together</figcaption>
            </figure>
            <p>In RE, so-called “xrefs“ (cross-references) take center stage. When you’re looking at a symbol (a function or a global variable), xrefs tell you what other symbols use (reference) the symbol that you’re looking at. In the screenshot above, most of our strings have one xref. Let’s follow each of them and see where they lead us to:</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/cmd_definition_array.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/cmd_definition_array.png" alt="A sequence of references"></a>
                <figcaption>A sequence of references</figcaption>
            </figure>
            <p>What we’re seeing here is a sequence of pairs of references, where the first item in the pair is always the name of a command, and the second item is a pointer to some function. Only the first element in this sequence is referenced directly, which leads me to believe that this is an ordinary C array of C structs with two members. Let’s name this array, so that when we encounter this variable being used somewhere in the future we instantly know what it is.</p>
            <p>Let’s now look at some code! Normal programs (like .exe or ELF files) consist of sections with clear designations for what sort of data they contain. For example, the .text section contains executable code and the .rodata section contains read-only data that the code requires. Unfortunately, embedded systems don’t typically use these files, and instead throw the code and data together in one large pile. This also means that there’s absolutely no hope of recovering <abbr title="function or global variable">symbol</abbr> names and locations. Without symbol metadata, the stream of instructions is just that: a stream. Fortunately for us Ghidra has been programmed to at least recognize the boundaries of most functions, which it tends to do really well.</p>
            <p>As this was my first time dealing with ARM assembly, the C decompiler feature of Ghidra turned out to be very useful for me. Unfortunately, due to a total lack of symbols its output is still quite hard for me to process. Take a look at this function which references the array that we looked at earlier. Don’t read into it, just skim over it:</p>
            <figure>
                <code><span>void</span> <span>FUN_02022008</span>(<span>char</span> *<span>param_1</span>)
                    
{
  <span>int</span> *<span>piVar1</span>;
  <span>char</span> <span>cVar2</span>;
  <span>int</span> <span>iVar3</span>;
  <span>char</span> *<span>pcVar4</span>;
  <span>undefined4</span> *<span>puVar5</span>;
  
  <span>if</span> (<span>DAT_060078c6</span> == <span>'\0'</span>) {
    <span>iVar3</span> = <span>FUN_020214e0</span>(<span>param_1</span>,(<span>char</span> *)<span>0x20bdf3c</span>);
    <span>if</span> (<span>iVar3</span> == <span>0</span>) {
      <span>FUN_02021f9c</span>();
      <span>DAT_060078c6</span> = <span>'\x01'</span>;
    }
  }
  <span>else if</span> (<span>DAT_060078c6</span> == <span>'\x01'</span>) {
    <span>iVar3</span> = <span>FUN_020214e0</span>(<span>param_1</span>,<span>"#0000"</span>);
    <span>if</span> (<span>iVar3</span> == <span>0</span>) {
      <span>FUN_02021fb4</span>();
      <span>DAT_060078c6</span> = <span>'\x02'</span>;
    }
    <span>else</span> {
      <span>FUN_020213f8</span>((<span>byte</span> *)<span>0x2022098</span>);
      <span>DAT_060078c6</span> = <span>'\0'</span>;
    }
  }
  <span>else</span> {
    <span>puVar5</span> = (<span>undefined4</span> *)<span>0x20bdf48</span>;
    <span>do</span> {
      <span>pcVar4</span> = (<span>char</span> *) <span>FUN_02021528</span>(<span>param_1</span>,*<span>puVar5</span>);
      <span>if</span> (<span>pcVar4</span> != (<span>char</span> *)<span>0x0</span>) {
        <span>cVar2</span> = *<span>pcVar4</span>;
        <span>while</span> (<span>cVar2</span> == <span>' '</span>) {
          <span>pcVar4</span> = <span>pcVar4</span> + <span>1</span>;
          <span>cVar2</span> = *<span>pcVar4</span>;
        }
        <span>jump_to_1</span>(<span>pcVar4</span>,<span>puVar5</span>[<span>1</span>]);
        <span>return</span>;
      }
      <span>piVar1</span> = <span>puVar5</span> + <span>2</span>;
      <span>puVar5</span> = <span>puVar5</span> + <span>2</span>;
    } <span>while</span> (*<span>piVar1</span> != <span>0</span>);
    <span>FUN_02021fe8</span>();
  }
  <span>return</span>;
}</code>
                <figcaption>Raw output from the C decompiler</figcaption>
            </figure>
            <p>Like I said, because Ghidra has absolutely no type or symbol information, the resulting C code is not something that you’d typically write and keep your job afterwards. Functions and global variables don’t have any meaningful names and are instead referred to by their addresses. Local variables don’t have meaningful names either, and they’re scoped to the entire function, as opposed to any particular block. Sometimes Ghidra thinks something is a local variable when really it’s better represented as a temporary result from an expression. It’s absolutely not the fault of the tool: all this information that makes code easy to understand is erased when it’s is compiled and the symbols are stripped away.</p>
            <p>Making sense of this heavily processed code is what’s so hard about RE, and it’s one of those things that you learn by doing a lot of. From now on, for the sake of clarity, I’ll only be presenting you the cleaned up C code after I’ve made sense of it. Anyways, we’re clearly dealing with some kind of state machine. Notice the outline of this function:</p>
            <figure>
                <code><span>void</span> <span>function</span>() {
    <span>if</span>(<span>global_var</span> == <span>0</span>) {
        <span>if</span>(<span>/* condition */</span>)
            <span>global_var</span> = <span>1</span>;
    } <span>else if</span>(<span>global_var</span> == <span>1</span>) {
        <span>if</span>(<span>/* condition */</span>)
            <span>global_var</span> = <span>2</span>;
        <span>else</span>
            <span>global_var</span> = <span>0</span>;
    } <span>else</span> {
        <span>if</span>(<span>/* condition */</span>)
            <span>global_var</span> = <span>0</span>; <span>// performed by a subordinate function</span>
        <span>else</span>
            <span>action</span>();
    }
}</code>
                <figcaption>Structural overview of this function</figcaption>
            </figure>
            <p>There are two states in which the function does very little, and one state in which the function does a lot. Judging by the strings that the first two states reference (“login” and “Passwd Error”), this function implements some kind of login interface and only lets us run a command if we’re logged in. This function is only ever called by one other function, so let’s inspect that one:</p>
            <figure>
                <code><span>void</span> <span>FUN_020220f0</span>(<span>void</span>) {
    <span>while</span>(<span>global_var_1</span> != <span>global_var_2</span>) {
        <span>char</span> <span>ch</span> = <span>global_var_3</span>[<span>global_var_1</span>];
        <span>global_var_1</span> = <span>global_var_1</span> + <span>1</span> &amp; <span>0xff</span>;
        <span>yet_unknown_function</span>(<span>ch</span>); <span>// manipulates "global_var_4"</span>
        <span>if</span>(<span>ch</span> == <span>'\r'</span>) {
            <span>function_from_before</span>(<span>global_var_4</span>);
            <span>global_var_5</span> = <span>0</span>;
        }
    }
}</code>
                <figcaption>The only caller of our last function</figcaption>
            </figure>
            <p>This function is going through some sort of buffer and calling another function for each character that it fetches from the buffer, and only calls the function that we looked at in the previous paragraph for every ‘\r’ (carriage return) character. Furthermore, the buffer appears to be a circular one with a size of 256. Let’s name some of the variables and functions to what I think they do based on those new insights:</p>
            <figure>
                <code><span>void</span> <span>shell_process_input</span>(<span>void</span>) {
    <span>while</span>(<span>shell_input_buf_r</span> != <span>shell_input_buf_w</span>) {
        <span>char</span> <span>ch</span> = <span>shell_input_buf</span>[<span>shell_input_buf_r</span>];
        <span>shell_input_buf_r</span> = <span>shell_input_buf_r</span> + <span>1</span> &amp; <span>0xff</span>;
        <span>shell_feed_char</span>(<span>ch</span>); <span>// manipulates "shell_command_buffer"</span>
        <span>if</span>(<span>ch</span> == <span>'\r'</span>) {
            <span>shell_run_command</span>(<span>shell_command_buffer</span>);
            <span>shell_edit_position</span> = <span>0</span>;
        }
    }
}</code>
                <figcaption>The “shell_process_input” function</figcaption>
            </figure>
            <p>Let’s name some variables once again and dive back into our “shell_run_command” function, this time with even more symbols labeled (I’ve glossed over most of the boring straightforward symbols):</p>
            <figure>
                <code><span>void</span> <span>shell_run_command</span>(<span>char</span>* <span>command_input</span>) {
    <span>if</span> (<span>shell_login_state</span> == <span>0</span>) {
        <span>if</span> (<span>shell_compare_command</span>(<span>command_input</span>, <span>"login"</span>) == <span>0</span>) {
            <span>shell_ask_passwd</span>(); <span>// prints "passwd? "</span>
            <span>shell_login_state</span> = <span>1</span>;
        }
    } <span>else if</span> (<span>shell_login_state</span> == <span>1</span>) {
        <span>if</span> (<span>shell_compare_command</span>(<span>command_input</span>, <span>"#0000"</span>) == <span>0</span>) {
            <span>shell_login_ok</span>(); <span>// prints "login OK"</span>
            <span>shell_login_state</span> = <span>2</span>;
        } <span>else</span> {
            <span>shell_print</span>(<span>"Passwd Error\r"</span>);
            <span>shell_login_state</span> = <span>0</span>;
        }
    } <span>else</span> {
        <span>// actually run the command</span>
    }
}</code>
                <figcaption>The “shell_run_command” function</figcaption>
            </figure>
            <p>If we dive into the “shell_print” function, we see lots of yet unknown data transfers into global variables. These global variables are referenced by other pieces of code (both in the flash and internal ROM) which write data into mysterious addresses located at 0xfxxxxxxx, which I’m assuming is the memory region that’s used to talk to various peripherals inside of the chip.</p>
            <p>Okay, so what do we know about this shell?</p>
            <ul>
                <li>It won’t respond to our commands unless we say “login” and type in the password “#0000”;</li>
                <li>It has quite a limited set of commands and is potentially uninteresting;</li>
                <li>We still don’t know how to access that shell.</li>
            </ul>
            <p>Let’s list out potential candidates for various interfaces that this shell could be running on top of:</p>
            <ul>
                <li>UART. There’s two documented UART interfaces. Based on the schematic, both receive pins and one of the two transmit pins are used as GPIOs, and the other transmit pin doesn’t do anything (remember the previous section?).</li>
                <li>USB. There are two USB interfaces on this synth: one is a device interface implemented by the SWL01U chip itself, and the other is a host interface for connecting pen drives and such, implemented by an external host controller chip. If a shell is running on top of one of them, it’s probably the device interface, not the host one. However, if we connect the synth to a PC and run “lsusb” to dump its USB descriptor, we see that it has nothing but <abbr title="Musical Instrument Digital Interface">MIDI</abbr>, an interface widely used in the music industry for transferring various music-related stuff such as “note on” and “note off” events. No serial ports or anything like that.</li>
                <li>JTAG. The documentation for ARM7TDMI says that its JTAG implementation features something ARM calls the <abbr title="Debug Communication Channel">DCC</abbr>, which lets a program running on the chip and an external debug probe exchange custom data. It’s bidirectional and could thus be very well used for a shell. The DCC is accessed via special coprocessor data transfer instructions (MCR and MRC) in 32-bit words.</li>
            </ul>
            <p>If it’s UART, then it’s definitely not accessible on our variant of the board, but nevertheless the code shouldn’t be greatly modifying the data that it wants to send, as UART operates on a byte level. If it’s USB, then it must be running on top of MIDI and must thus be manipulating the data in a way that’s suitable to send over MIDI in one way or another. If it’s JTAG, then it must be running on top of the DCC and must be using special instructions that access the DCC. Let’s look deeper into how exactly our “shell_print” function mutilates the data:</p>
            <figure>
                <code><span>void</span> <span>shell_print</span>(<span>char</span>* <span>data</span>) {
    <span>memcpy</span>(<span>global_var_1</span>, <span>global_var_2</span>, <span>8</span>);
    <span>global_var_1</span>[<span>24</span>] = <span>0xf7</span>;

    <span>// process data in 8-byte blocks first</span>
    <span>for</span>(<span>size_t</span> <span>i</span> = <span>strlen</span>(<span>data</span>); <span>i</span> &gt;= <span>8</span>; <span>i</span> -= <span>8</span>) {
        <span>char</span> <span>ch</span> = *(<span>data</span>++);
        <span>for</span>(<span>int</span> <span>j</span> = <span>0</span>; <span>j</span> &lt; <span>8</span>; <span>j</span>++) {
            <span>global_var_1</span>[<span>8</span> + (<span>j</span> * <span>2</span>)] = <span>ch</span> &gt;&gt; <span>4</span>;
            <span>global_var_1</span>[<span>8</span> + (<span>j</span> * <span>2</span>) + <span>1</span>] = <span>ch</span> &amp; <span>0xf</span>;
        }
        <span>pass_on_to_next_stage_of_printing</span>(<span>global_var_1</span>, <span>25</span>);
    }

    <span>// process the tail</span>
    <span>size_t</span> <span>tail_size</span> = <span>8</span>;
    <span>for</span>(<span>int</span> <span>i</span> = <span>0</span>; *<span>data</span>; <span>i</span>++) {
        <span>char</span> <span>ch</span> = *(<span>data</span>++);
        <span>global_var_1</span>[<span>8</span> + (<span>i</span> * <span>2</span>)] = <span>ch</span> &gt;&gt; <span>4</span>;
        <span>global_var_1</span>[<span>8</span> + (<span>i</span> * <span>2</span>) + <span>1</span>] = <span>ch</span> &amp; <span>0xf</span>;
        <span>tail_size</span> += <span>2</span>;
    }
    <span>global_var_1</span>[<span>tail_size</span>] = <an>0xf7</an>;
    <span>tail_size</span>++;
    <span>pass_on_to_next_stage_of_printing</span>(<span>global_var_1</span>, <span>tail_size</span>);
}</code>
                <figcaption>Overview of the “shell_print” function</figcaption>
            </figure>
            <p>It seems to be breaking up each byte of data into two 4-bit nibbles and wrapping each of the two in its own byte. Every block of data that it passes on to the next stage in this data transfer pipeline starts with the same 8 bytes of data, followed by the payload, finally ending with an 0xf7 byte. Let’s use GDB to look at what those constant 8 bytes are:</p>
            <figure>
                <code>(gdb) x/8xb 0x06000000 <span># eXamine 8 heX Bytes at location 0x06000000</span>
<span>0x6000000</span>:      0xf0    0x43    0x73    0x01    0x52    0x19    0x00    0x00</code>
                <figcaption>GDB reading the 8 bytes in "global_var_2"</figcaption>
            </figure>
            <p>All in all, a shell packet containing the string “&gt; ” looks like this:</p>
            <figure>
                <code><span>F0 43 73 01 52 19 00 00</span> <span>03 0E</span> <span>02 00</span> <span>F7</span>
└──────────┬──────────┘ └─┬─┘ └─┬─┘ ├┘
           │              │     │   │
           │              │     │   ╰── <span>fixed footer</span>
           │              │     ╰────── <span>the character “ ”</span>
           │              ╰──────────── <span>the character “&gt;”</span>
           ╰─────────────────────────── <span>fixed header</span></code>
                <figcaption>Shell packet corresponding to the string “&gt; ”</figcaption>
            </figure>
            <p>Here’s some context for those of you who don’t know how MIDI works. MIDI is a really simple protocol that emerged in the 80s and to this day allows various digital musical instruments to interoperate by sending and receiving messages such as “Please play the note C#4 with a loudness of 40 out of 127”, or “Please set the reverb level to 14 out of 127”, or “This is a tick. Assume that the period of time between the current and last tick corresponds to 1/24th of a quarter note”. MIDI has a few different message types, but they weren’t enough to describe every aspect of sound generation, so they introduced a special message called the System Exclusive message, or simply SysEx. In the words of the specification, “This message type allows manufacturers to create their own messages”.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/sysex_definition.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/sysex_definition.png" alt="The SysEx message as defined by the MIDI specification"></a>
                <figcaption>The SysEx message as defined by the MIDI specification</figcaption>
            </figure>
            <p>Sooooo.... it was MIDI, right? Every SysEx message starts with an 0xf0 byte (just like our shell packets do), followed by 1 or 3 bytes of the manufacturer ID, followed by the payload, finally ending with an 0xf7 byte (again, like our packets do). The SysEx payload can only contain bytes in which the <abbr title="Most Significant Bit">MSB</abbr> is 0 because MIDI uses the MSB to differentiate between command and data bytes: 1 means it’s a command, and 0 means it’s data associated with the last command – this is exactly why “shell_print” is cutting the bytes up into 4-bit nibbles. Let’s look at the first data byte that the synth sends out (0x43) and see what manufacturer that corresponds to.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/sysex_0x43_yamaha.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/sysex_0x43_yamaha.png" alt="MIDI Manufacturers Association declaring that ID 0x43 is allocated to Yamaha"></a>
                <figcaption>MIDI Manufacturers Association declaring that ID 0x43 is allocated to Yamaha</figcaption>
            </figure>
            <p>So yeah, these madlads made a shell that runs on top of MIDI SysEx messages on top of USB. Very cool. Let’s cook up a Python script that acts as a translation layer between the terminal and the synth’s twisted little shell protocol and try talking to it.</p>
            <figure>
                <code><span># our input in red, the response in blue</span>
<span>login</span>
<span>passwd? </span><span>#0000</span>
<span>login OK</span>
<span>&gt; </span><span>help</span>
<span>logout</span>
<span>help</span>
<span>?</span>
<span>info</span>
<span>ver</span>
<span>stack</span>
<span>perf-on</span>
<span>perf-off</span>
<span>perf-disp</span>
<span>d</span>
<span>dp</span>
<span>d   xxxxx</span>
<span>d/s xxxxx</span>
<span>m   ADDRESS DATA</span>
<span>m/b ADDRESS DATA</span>
<span>m/w ADDRESS DATA</span>
<span>m/l ADDRESS DATA</span>
<span>&gt; </span><span>info</span>
<span>DevelopName        PSR-E433</span>
<span>DevelopNumber      #3341</span>
<span>Main DevelopNumber #3341</span>
<span>Make data &amp; time   MAY 16 2012 19:00:57</span>
<span>J/E Select         English</span>
<span>&gt; </span>
</code>
                <figcaption>Our first conversation with the synth’s MIDI shell</figcaption>
            </figure>
            <p>This is extraordinarily cool! I wasn’t really expecting this to work, as there’s a possibility that the format of the incoming messages is different from that of the outgoing ones. Fortunately, that turned out not to be the case. Although I have to say that the available commands are quite boring. Apart from your standard help and version information, the most interesting commands that we have are arbitrary memory read/write commands. So, if we really wanted to, we could just peek and poke the memory of the synth via MIDI. We don’t need JTAG for that.</p>

            <h2 id="shellcode">Shellcode</h2>
            <p>Now, what can we do with arbitrary memory poke commands? We could inject executable code into RAM, but we could never execute it. Right? Wrong! If we overwrite the call stack of the program, we can trick the synth into executing it once it finishes handling the command. This is binary exploitation 101, except we don’t have to find any buffer overflow vulnerabilities, the memory poke commands are right there!</p>
            <p>Let’s talk about data transfer speed. Our 32-bit memory write command takes the form of “m/l AAAAAAAA DDDDDDDD\r”, where A and D are the address and data respectively, expressed in hexadecimal. Each byte of the command is transformed into two bytes containing 4-bit nibbles of the original byte. It’s also extended with 9 additional bytes of the SysEx message. Then, every 3 bytes are wrapped in a 4 byte long USB-MIDI packet. In total, if we want to write 4 bytes into the memory, we have to send the synth 72 bytes, which is 18x larger than the payload. But that’s not all! The synth will read the command back to us, with every individual character nicely wrapped in its own SysEx transfer, and finish off with the “&gt; “ prompt. In total, us and the synth exchange 396 bytes, which is almost 100 times larger than the 4-byte payload! This low transfer efficiency definitely shows and will become a problem if we ever want to send large amounts of data (foreshadowing?)</p>
            <p>I found a region of RAM which looks like it’s not used by anything and might thus be safe to put arbitrary data into. Let’s write a little assembly snippet that nicely asks the firmware to print “HeloWrld” to the 8 character long text portion of the LCD:</p>
            <figure>
                <code><span># Tell the assembler what address this program is going to reside at.</span>
<span># Not really required in this case, but always nice to have:</span>
<span>.org</span> <span>0x06002900</span>

<span># This "write_str" function resides in the firmware.</span>
<span># We want to nicely ask it to print something.</span>
<span># First, load the address of this function into a register:</span>
<span>ldr</span> <span>r1</span>, <span>write_str</span>
<span># Then, load the address of the string into another register:</span>
<span>adr</span> <span>r0</span>, <span>str</span>
<span># Remember how we interrupted the normal execution flow by</span>
<span># overwriting the stack? Well, we need to somehow jump to where</span>
<span># the firmware wanted to jump originally once we're done.</span>
<span># Let's make the function we're calling do that for us!</span>
<span># Most functions (and write_str is no exception) expect to get called
<span># via the "bl" instruction (Branch and Link), which places the return</span>
<span># address in a special register called the Link Register (lr).</span>
<span># If we assign lr ourselves and just jump to the function, it will</span>
<span># return to our chosen address.</span>
<span>ldr</span> <span>lr</span>, <span>return</span>
<span># Jump to the function:</span>
<span>bx</span> <span>r1</span>

<span># Data definitions</span>
<span>write_str</span>: <span>.word</span> <span>0x2086ed5</span>
<span>return</span>: <span>.word</span> <span>0x02021a7b</span>
<span>str</span>: <span>.asciz</span> <span>"HeloWrld"</span>
<span># Padding so that the size of our program is even</span>
<span>.byte</span> <span>0</span>
</span></code>
                <figcaption>Our first Hello World program</figcaption>
            </figure>
            <p>Let’s write a python script that takes our assembled snippet, transforms it into memory write commands and sends them via MIDI over to the synth, following up with another write in order to trick the firmware into running that snippet.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/lcd_helo_wrld.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/thumb/lcd_helo_wrld.jpg" alt="The LCD displaying “HeloWrld”"></a>
                <figcaption>The LCD displaying “HeloWrld”</figcaption>
            </figure>
            <p>This took me quite a few tries to get right, but hey, it works! The nice part about this hack is that it doesn’t depend on any special interfaces like JTAG or UART. If we wanted to, we could write these messages to a MIDI file and play it on the synth like any other MIDI file. Hey, that gives me an idea.....</p>
            <p>Ladies and gentlemen, I present to you: World’s First MIDI Shellcode.</p>
            <figure>
                <video controls="" src="https://psi3.ru/blog/swl01u/videos/toccata_with_a_twist.mp4"></video>
                <figcaption>Toccata and Fugue in D Minor with a twist</figcaption>
            </figure>
            <p>Here’s the <a href="https://psi3.ru/blog/swl01u/files/scary-toccata-for-psr-e433-fw-1.02.mid" target="_blank">MIDI file</a> in case you want to do the same thing with a Yamaha PSR-E433 running firmware version 1.02. DO NOT play this MIDI file on ANY other Yamaha device, or on a PSR-E433 running a different version of the firmware, as it’s going to act unpredictably. You have been warned.</p>

            <h2 id="bad-apple">Bad Apple</h2>
            <p>Displaying graphics turned out to be way, way, way harder than displaying text. First, let’s look in the datasheet for our LCD controller (ML9040A) to decide whether that’s is even possible from a hardware standpoint. Turns out, not really – it can only handle text characters on a dot matrix. Our LCD definitely has a dot matrix part, but it also has this note notation part, and a 7-segment part in the middle, and another 7-segment part on the right, and a chord notation part below it, and finally a keyboard display at the very bottom.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/lcd_segments.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/lcd_segments.jpg" alt="The LCD on a Yamaha PSR-E433 with all segments enabled"></a>
                <figcaption>The LCD on a Yamaha PSR-E433 with all segments enabled</figcaption>
            </figure>
            <p>How does the firmware light these segments up in a custom pattern if the controller only supports text? Let’s look at the block diagram of our display controller.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/ml9040a.png" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/ml9040a.png" alt="Internal block diagram of ML9040A"></a>
                <figcaption>Internal block diagram of ML9040A</figcaption>
            </figure>
            <p>We can see three memories:</p>
            <ul>
                <li>The Display Data RAM (DDRAM) is written to by the host (in this case, SWL01U) to change the text displayed on the display. The host never writes the image that it wants the controller to display; instead, it sends it plain old ASCII (with some extra characters), and the controller is responsible for translating ASCII into an image that can be displayed on a dot matrix.</li>
                <li>The Character Generation ROM (CGROM) is what actually performs this translation. This ROM is a simple lookup table. It spits out a graphical pattern that must be displayed at a particular row in order to form a particular character.</li>
                <li>The Character Generation RAM (CGRAM) allows the host to define up to 8 custom characters, which can be called up by using character codes 0 through 7 or 8 though 15.</li>
            </ul>
            <p>The CGRAM is how the synth displays non-textual data and what we can use to display custom graphics in the dot matrix part of the LCD panel as well. Let’s use the assembly snippet from before to display the 8 custom characters in the dot matrix area.</p>
            <figure>
                <a href="https://psi3.ru/blog/swl01u/images/lcd_cgram.jpg" target="_blank"><img src="https://psi3.ru/blog/swl01u/images/thumb/lcd_cgram.jpg" alt="The LCD displaying the 8 custom characters controlled by the firmware"></a>
                <figcaption>The LCD displaying the 8 custom characters controlled by the firmware</figcaption>
            </figure>
            <p>No, it’s not displaying garbage. When I press down a key on the keyboard, two dots light up in the dot matrix area which correspond to a note in the notation area and a key in the keyboard area. When I let go of the key, those segments get extinguished. This confirms that the firmware manipulates the CGRAM in order to display its stuff below the dot matrix area.</p>
            <p>From the countless sleepless nights of digging around in the firmware I’ve discovered a function that sends arbitrary data to the LCD controller. Let’s write another assembly snippet that exploits this function to upload some custom data to the CGRAM.</p>
            <figure>
                <code><span># --- SNIP ---</span>

<span># We're going to be calling this function several times</span>
<span>ldr</span> <span>r4</span>, <span>lcd_write</span>

<span># Command 0x40 is "Set CGRAM write address to 0"</span>
<span>mov</span> <span>r0</span>, <span>#0x40</span>
<span>mov</span> <span>lr</span>, <span>pc</span>
<span>bx</span> <span>r4</span>

<span># Send the checker pattern (64 bytes)</span>
<span>mov</span> <span>r5</span>, <span>#0</span>
<span>ldr</span> <span>r0</span>, <span>checker_pattern</span>
<span>fill_loop:</span>
    <span># Send the data</span>
    <span>push</span> {<span>r0</span>}
    <span>mov</span> <span>lr</span>, <span>pc</span>
    <span>bx</span> <span>r4</span>
    <span>pop</span> {<span>r0</span>}
    <span># Invert the pattern for the next line</span>
    <span>eor</span> <span>r0</span>, <span>r0</span>, <span>#0xff</span>
    <span># Loop</span>
    <span>add</span> <span>r5</span>, <span>r5</span>, <span>#1</span>
    <span>cmp</span> <span>r5</span>, <span>#64</span>
    <span>bne</span> <span>fill_loop</span>

<span># --- SNIP ---</span>

<span>lcd_write:</span> <span>.word</span> <span>0x02020ac9</span> <span># Resides in the firmware</span>
<span>checker_pattern:</span> <span>.word</span> <span>0x4055</span> <span># That 0x4000 tells the function that we're sending data, not a command</span></code>
                <figcaption>Uploading data to the CGRAM</figcaption>
            </figure>
            <p>When I run this snippet, I can definitely see the data that I want displayed (in this case, a checker pattern) getting actually displayed in the dot matrix area. However, it’s quickly replaced with what the synth wants to display in the custom area. We definitely can’t play a video with this; we have to find a way to disable the part of the firmware responsible for updating the CGRAM. One way we could do this is to find the function responsible for that (which I’ve already done) and just replace it with an immediate return, causing it to not do anything. The problem is that this requires me to overwrite the synth’s flash chip, which I don’t want to do out of fear of bricking it. I specifically set out to make every experiment of mine instantly reversible through power cycling, which means that I’m only allowing myself to manipulate the RAM.</p>
            <p>I remember noticing that this firmware runs what appears to be some sort of a primitive <abbr title="Real-Time Operating System">RTOS</abbr> with some parts of it contained in the ROM of the SWL01U chip. There’s a set of constant global variables in the flash which define the callback functions for the tasks, as well as their stacks and other attributes which I couldn’t figure out the meaning of. So, if we could a) find out which of these 64 tasks is responsible for constantly updating the CGRAM, and b) find a way to overwrite the corresponding entry in the task table so that it points to a no-op function, we could effectively disable that part of the firmware.</p>
            <p>The key to this puzzle is the fact that the ROM and the flash are very loosely coupled. On startup, the firmware in the flash tells the ROM where its task table is located, and the ROM remembers this information in a global variable located in the embedded SRAM. If we make a copy of this task table in the RAM, and then tell the ROM that the task table has moved to a new location, we could coerce it into using this new table which we can modify in an instantly reversible way. So I did just that! I figured out which task was responsible for updating the display and replaced its callback with the default idle task callback, effectively preventing the firmware from continuously updating the CGRAM of the display controller.</p>
            <figure>
                <video src="https://psi3.ru/blog/swl01u/videos/bad_apple_1.mp4" controls=""></video>
                <figcaption>First iteration of Bad Apple</figcaption>
            </figure>
            <p>You can see that the first iteration has some artifacts, but the biggest problem is that the frame rate is very low. The reason for that is the extremely low data transfer efficiency that I was talking about. Even if we upload the executable snippet once and only replace its data section when we want to display a new frame, that’s still 6732 bytes of data transferred per 70 bytes of payload (64 bytes of CGRAM data plus a 32-bit return address overwrite). And it turns out that these transfers are really slow, which in our case translates to low frame rate.</p>
            <p>The two biggest contributors to this low payload efficiency are: a) the fact that this data has to be wrapped in a command, and b) that the synth reads the command back character by character in these enormous packets. If we could manipulate the task table once again in order to assign our own callback for the shell task, we could capture raw data and choose not to respond with anything, which would eliminate both of these problems. This, together with another packing optimization brings the total transfer size per frame down from 6732 bytes to 92 bytes – a 73-fold decrease! The artifacting is still there, but we’re now able to play video at a tolerable framerate.</p>
            <figure>
                <video src="https://psi3.ru/blog/swl01u/videos/bad_apple_2.mp4" controls=""></video>
                <figcaption>Second iteration of Bad Apple</figcaption>
            </figure>
            <p>Now, what causes this artifacting? The synth uses the same 8 <abbr title="General-Purpose Input/Output">GPIO</abbr> lines for both talking to the display and scanning the panel with button controls and LEDs. One of the tasks is responsible for intertwining LCD accesses with panel scanning, and sometimes while we’re transferring our data to the LCD unbeknownst to this task, it decides to interrupt us and do a scan of the panel, which messes with the same data lines that the display is currently actively listening to, which causes these artifacts. To avoid this, we could stop talking to the display directly, and instead nicely ask that multiplexing task to send the data that we want once it’s done with the panel scan.</p>
            <figure>
                <iframe width="1080" height="608" src="https://www.youtube.com/embed/u6sukVMijBg" title="Yamaha PSR-E433 Bad Apple demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
                <figcaption>Final iteration of Bad Apple</figcaption>
            </figure>
            <p>So there you go! The algorithm to display video on the LCD of this synth over MIDI is as follows:</p>
            <ul>
                <li>Log into the shell;</li>
                <li>Write executable code into RAM using memory write commands provided by the shell;</li>
                <li>Execute the code from RAM by overwriting the return address on the stack;</li>
                <li>Make a copy of the task tables in RAM;</li>
                <li>Fix those new tables up so that they point to each other;</li>
                <li>Tell the ROM to use our new task tables;</li>
                <li>Replace the display task callback with the default idle callback;</li>
                <li>Replace the shell task callback with our own callback;</li>
                <li>In that callback, unpack data arriving via MIDI and transfer it over to the display/panel multiplexing task;</li>
                <li>Feed our synth video frames via MIDI.</li>
            </ul>
            <p>This project is not quite done yet. I have a very limited understanding of the chip’s MMIO region, and absolutely no understanding about its most interesting part - the DSP that’s separate from the main ARM core. Stay tuned for when I figure those things out :)</p>

            <h2 id="links">Links</h2>
            <ul>
                <li><a href="https://github.com/portasynthinca3/swl01u" target="_blank">This project on GitHub</a></li>
                <li><a href="https://midi.org/spec-detail" target="_blank">MIDI Specification</a></li>
                <li><a href="https://midi.org/sysexidtable" target="_blank">MIDI SysEx ID allocation table</a></li>
                <li><a href="https://www.usb.org/sites/default/files/midi10.pdf" target="_blank">USB-MIDI Specification</a></li>
                <li><a href="https://developer.arm.com/documentation/ddi0084/f" target="_blank">ARM7TDMI Technical Reference Manual</a></li>
                <li><a href="https://sandsoftwaresound.net/swl-micro-architecture/" target="_blank">Architecture of Yamaha entry-level synths</a></li>
            </ul>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Back to basics: Why we chose long-polling over websockets (200 pts)]]></title>
            <link>https://www.inferable.ai/blog/posts/postgres-nodejs-longpolling.mdx</link>
            <guid>42600276</guid>
            <pubDate>Sun, 05 Jan 2025 07:14:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inferable.ai/blog/posts/postgres-nodejs-longpolling.mdx">https://www.inferable.ai/blog/posts/postgres-nodejs-longpolling.mdx</a>, See on <a href="https://news.ycombinator.com/item?id=42600276">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><p>Learn how we implemented real-time updates using Node.js, TypeScript, and PostgreSQL with HTTP long polling. A practical guide to building scalable real-time systems without WebSockets.</p><div><p><span>Nadeesha Cabral</span></p><p><span>•</span><time datetime="04-01-2025">04-01-2025</time></p></div></div></header><p>Like many teams building real-time systems with Node.js and TypeScript, we've been exploring ways to handle real-time updates at scale. Our system handles hundreds of worker nodes constantly polling our PostgreSQL-backed control plane for new jobs (tool calls issued by agents), while agents themselves continuously pull for execution and chat state updates. What started as an exploration into WebSockets led us to a surprisingly effective "old-school" solution: HTTP long polling with Postgres.</p>
<h2>The Challenge: Real-time Updates at Scale</h2>
<p>Our Node.js/TypeScript backend faced two main challenges:</p>
<ol>
<li><strong>Worker Node Updates</strong>: Hundreds of worker nodes running our Node.js / Golang / C# SDKs needed to know about new jobs as soon as they were available, requiring a querying strategy that didn't bring down our Postgres database</li>
<li><strong>Agent State Synchronization</strong>: Agents required real-time updates about execution and chat state, which we needed to stream efficiently.</li>
</ol>
<h2>Long Polling vs WebSockets: A Refresher</h2>
<h3>How Long Polling Works</h3>
<pre>sequenceDiagram
    participant Client
    participant Server
    participant Database
    
    Client-&gt;&gt;Server: Request new data
    
    alt Data available immediately
        Server-&gt;&gt;Database: Check for data
        Database--&gt;&gt;Server: Return data
        Server--&gt;&gt;Client: Return response immediately
    else No data available
        Server-&gt;&gt;Database: Check for data
        Database--&gt;&gt;Server: No data
        Note over Server: Hold connection
        loop Check periodically
            Server-&gt;&gt;Database: Poll for new data
            Database--&gt;&gt;Server: New data arrives
        end
        Server--&gt;&gt;Client: Return response
    end
    Client-&gt;&gt;Server: Next request begins
</pre>
<p>The key difference between approaches can be understood with a simple train analogy:</p>
<p>Short polling is like a train that departs strictly according to a timetable - it leaves the station at fixed intervals regardless of whether there are passengers or not. WebSockets, on the other hand, are like having a dedicated train line always ready to transport passengers.</p>
<p>Long polling? It's like a train that waits at the station until at least one passenger boards before departing. If no passengers show up within a certain time (TTL), only then does it leave empty. This approach gives you the best of both worlds - immediate departure when there's data (passengers) and efficient resource usage when there's not.</p>
<p>In technical terms:</p>
<ol>
<li>With short polling, the server responds immediately whether there's data or not</li>
<li>With long polling, the server holds the connection open until either:<!-- -->
<ul>
<li>New data becomes available</li>
<li>A timeout is reached (TTL)</li>
</ul>
</li>
</ol>
<h2>Our Implementation Deep Dive</h2>
<p>Let's break down our Node.js implementation:</p>
<pre><code><span>export</span> <span>const</span> <span>getJobStatusSync</span> = <span>async</span> (<span>{
  jobId,
  owner,
  ttl = <span>60_000</span>,
}: {
  jobId: <span>string</span>;
  owner: { clusterId: <span>string</span> };
  ttl?: <span>number</span>;
}</span>) =&gt; {
  <span>let</span> <span>jobResult</span>: {
    <span>service</span>: <span>string</span>;
    <span>status</span>: <span>"pending"</span> | <span>"running"</span> | <span>"success"</span> | <span>"failure"</span> | <span>"stalled"</span>;
    <span>result</span>: <span>string</span> | <span>null</span>;
    <span>resultType</span>: <span>ResultType</span> | <span>null</span>;
  } | <span>undefined</span>;

  <span>const</span> start = <span>Date</span>.<span>now</span>();
</code></pre>
<p>The function accepts:</p>
<ul>
<li><code>jobId</code>: Unique identifier for the job we're tracking</li>
<li><code>owner.clusterId</code>: Cluster identifier for multi-tenancy</li>
<li><code>ttl</code>: Time-to-live in milliseconds (defaults to 60 seconds)</li>
</ul>
<h3>The Polling Loop</h3>
<pre><code>  <span>do</span> {
    <span>const</span> [job] = <span>await</span> data.<span>db</span>
      .<span>select</span>({
        <span>service</span>: data.<span>jobs</span>.<span>service</span>,
        <span>status</span>: data.<span>jobs</span>.<span>status</span>,
        <span>result</span>: data.<span>jobs</span>.<span>result</span>,
        <span>resultType</span>: data.<span>jobs</span>.<span>result_type</span>,
      })
      .<span>from</span>(data.<span>jobs</span>)
      .<span>where</span>(<span>and</span>(<span>eq</span>(data.<span>jobs</span>.<span>id</span>, jobId), <span>eq</span>(data.<span>jobs</span>.<span>cluster_id</span>, owner.<span>clusterId</span>)));

    <span>if</span> (!job) {
      <span>throw</span> <span>new</span> <span>NotFoundError</span>(<span>`Job <span>${jobId}</span> not found`</span>);
    }

    <span>if</span> (job.<span>status</span> === <span>"success"</span> || job.<span>status</span> === <span>"failure"</span>) {
      jobResult = job;
    } <span>else</span> {
      <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, <span>500</span>));
    }
  } <span>while</span> (!jobResult &amp;&amp; <span>Date</span>.<span>now</span>() - start &lt; ttl);
</code></pre>
<p>Key aspects:</p>
<ol>
<li>The loop continues until either:<!-- -->
<ul>
<li>We get a final status (<code>success</code> or <code>failure</code>)</li>
<li>We hit the TTL timeout</li>
</ul>
</li>
<li>We use a 500ms delay between checks to prevent hammering the database</li>
<li>Database query is optimized with proper indexes on <code>id</code> and <code>cluster_id</code></li>
</ol>
<h3>Error Handling and Response</h3>
<pre><code>  <span>if</span> (jobResult) {
    <span>return</span> jobResult;
  } <span>else</span> {
    <span>throw</span> <span>new</span> <span>JobPollTimeoutError</span>(<span>`Call did not resolve within <span>${ttl}</span>ms`</span>);
  }
</code></pre>
<p>The function concludes by:</p>
<ol>
<li>Throwing a timeout error if no result was found</li>
<li>Returning the job result if successful</li>
</ol>
<h2>Database Optimization</h2>
<p>For this pattern to work efficiently, proper Postgres indexing needs to be implemented:</p>
<pre><code><span>CREATE</span> INDEX idx_jobs_status <span>ON</span> jobs(id, cluster_id);
<span>CREATE</span> INDEX idx_jobs_lookup <span>ON</span> jobs(status) <span>WHERE</span> status <span>IN</span> (<span>'success'</span>, <span>'failure'</span>);
</code></pre>
<p>This ensures our frequent polling queries are fast and don't put unnecessary load on the database.</p>
<h2>The Hidden Benefits of Long Polling</h2>
<p>One of the most compelling aspects of long polling is what you don't have to build. Here's what we avoided:</p>
<h3><strong>Observability Remains Unchanged</strong></h3>
<p>One of the biggest wins is that we don't need to modify our observability stack for WebSockets. All our standard HTTP metrics just work out of the box, and our existing logging patterns do exactly what we need. There's no need to figure out new ways to monitor persistent connections or implement additional logging for WebSocket state.</p>
<h3><strong>Authentication Simplicity</strong></h3>
<p>We completely avoid the headache of implementing a new authentication mechanism for incoming WebSocket connections. We just keep using our standard HTTP authentication that we already have in place. All our existing security patterns continue to work exactly as they always have.</p>
<p>When we implemented Websockets earlier, this became extremely gnarly due to the RBAC restrictions we had to honor. Basically, we needed to be really careful about what data we push to the connected clients, and the privilege escalation that happens when a client moves from one cluster to another.</p>
<h3><strong>Infrastructure Compatibility</strong></h3>
<p>Corporate firewalls blocking WebSocket connections was one of our other worries. Some  of our users are behind firewalls, and we don't need the IT headache of getting them to open up WebSockets.</p>
<p>Not our problem. We don't need any special proxy configurations or complex infrastructure setups. Our standard load balancer configuration works fine without any modifications. The entire stack just keeps humming along as it always has.</p>
<h3><strong>Operational Simplicity</strong></h3>
<p>We never have to worry about server restarts dropping WebSocket connections. There's no connection state to manage or maintain. When something goes wrong (and something always goes wrong), it's much easier to debug and troubleshoot because we're just dealing with standard HTTP requests and responses.</p>
<p>We use Cloudflare for our edge, and that means our existing configuration rules and DDoS protection didn't need any changing.</p>
<h3><strong>Client Implementation</strong></h3>
<p>The client-side code stays remarkably simple. It works with any HTTP client, no special WebSocket libraries needed. Even better, reconnection handling comes for free with basic retry logic. The entire client implementation can often be just a few lines of code.</p>
<h2>Why Not ElectricSQL?</h2>
<p>While exploring solutions, we looked at <a href="https://electric-sql.com/blog/2024/07/17/electric-next">ElectricSQL</a>, which synchronizes Postgres data to the frontend. They make an interesting case for long polling over WebSockets:</p>
<blockquote>
<p>"Switching to an HTTP protocol may at first seem like a regression or a strange fit. Web sockets are built on top of HTTP specifically to serve the kind of realtime data stream that Electric provides. However, they are also more stateful and harder to cache."</p>
</blockquote>
<p>In fact, we actually recommend ElectricSQL if you don't need extreme control or low-level constructs to handle real-time updates. It's a solid, battle-tested solution that handles many edge cases and provides a great developer experience.</p>
<h3>Why We Chose Raw Long Polling</h3>
<p>The message delivery mechanism is a core part of our product - it's not just an implementation detail, it's central to what we do. You can't afford to have something as fundamental as message delivery abstracted away in a third-party library, no matter how good that library might be.</p>
<p>Our specific use case required:</p>
<ol>
<li><strong>Core Product Control</strong>: Full control over our message delivery mechanism - it's not just infrastructure, it's our product</li>
<li><strong>Zero External Dependencies</strong>: We needed our stack to be as simple as possible for self-hosting</li>
<li><strong>Close to the Metal</strong>: Direct control over the polling mechanism and connection handling</li>
<li><strong>Maximum Control</strong>: Ability to fine-tune every aspect of the implementation, including implementing dynamic polling intervals</li>
<li><strong>Simplicity</strong>: Making it easy for users to understand and modify the codebase</li>
</ol>
<p>For us, staying close to the metal with a simple HTTP long polling implementation was the right choice. But if you don't need this level of control, ElectricSQL provides a more feature-rich solution that could save you significant development time.</p>
<h2>Application Layer Best Practices</h2>
<p>When implementing long polling, there are several critical practices to follow to ensure reliable operation:</p>
<h3><strong>Mandatory TTL Implementation</strong></h3>
<p>You must implement a Time-To-Live (TTL) for your HTTP connections. Without this, you'll inevitably run into connection reset errors. Your polling logic should always return within this TTL, no matter what.</p>
<pre><code><span>const</span> <span>getJobStatus</span> = <span>async</span> (<span>jobId: <span>string</span>, ttl = <span>60_000</span></span>) =&gt; {
  <span>const</span> start = <span>Date</span>.<span>now</span>();
  
  <span>// Always check if we've exceeded TTL</span>
  <span>while</span> (<span>Date</span>.<span>now</span>() - start &lt; ttl) {
    <span>// polling logic here</span>
  }
  
  <span>return</span> <span>null</span>; <span>// TTL exceeded</span>
}
</code></pre>
<h3><strong>Client-Configurable TTL with Server Limits</strong></h3>
<p>While clients should be able to specify their desired TTL, the server must enforce a maximum limit:</p>
<pre><code><span>const</span> <span>MAX_TTL</span> = <span>120_000</span>; <span>// 2 minutes</span>

<span>const</span> <span>getJobStatus</span> = <span>async</span> (<span>jobId: <span>string</span>, clientTtl: <span>number</span></span>) =&gt; {
  <span>const</span> ttl = <span>Math</span>.<span>min</span>(clientTtl, <span>MAX_TTL</span>);
  <span>// ... polling logic</span>
}
</code></pre>
<h3><strong>Infrastructure-Aware TTL Settings</strong></h3>
<p>Your maximum TTL must stay under the minimum HTTP connection timeout across your entire infrastructure stack:</p>
<ul>
<li>Application server timeouts</li>
<li>Client timeouts</li>
<li>Load balancer timeouts</li>
<li>Edge server timeouts</li>
<li>Proxy timeouts</li>
</ul>
<p>For example, if your edge server has a 30-second timeout, your max TTL should be comfortably under this, say 25 seconds.</p>
<h3><strong>Sensible Database Polling Intervals</strong></h3>
<p>As shown in our implementation, include a reasonable wait time between database polls. We use a 500ms interval:</p>
<pre><code><span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, <span>500</span>));
</code></pre>
<p>This prevents hammering your database while still providing reasonably quick updates.</p>
<h3><strong>Optional: Exponential Backoff</strong></h3>
<p>While not implemented in our current system, you can implement exponential backoff for more efficient resource usage:</p>
<pre><code><span>const</span> <span>getJobStatus</span> = <span>async</span> (<span>jobId: <span>string</span>, ttl = <span>60_000</span></span>) =&gt; {
  <span>const</span> start = <span>Date</span>.<span>now</span>();
  <span>let</span> waitTime = <span>100</span>; <span>// Start with 100ms</span>
  
  <span>while</span> (<span>Date</span>.<span>now</span>() - start &lt; ttl) {
    <span>const</span> result = <span>await</span> <span>checkJob</span>(jobId);
    
    <span>if</span> (result) <span>return</span> result;
    
    <span>// Exponential backoff with max of 2 seconds</span>
    waitTime = <span>Math</span>.<span>min</span>(waitTime * <span>2</span>, <span>2000</span>);
    <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, waitTime));
  }
  
  <span>return</span> <span>null</span>;
}
</code></pre>
<p>This approach means:</p>
<ul>
<li>Active requests (those likely to get data soon) terminate quickly</li>
<li>Inactive requests gradually increase their polling interval</li>
<li>System resources are used more efficiently</li>
</ul>
<h2>A Case for WebSockets: The Other Side of the Story</h2>
<p>While we've found long polling to be a great solution for our needs, it's not the only option. WebSockets are not inherently bad. They just require a lot of love and attention.</p>
<p>The challenges we mentioned aren't insurmountable - they just require proper engineering attention:</p>
<ul>
<li>
<p><strong>Observability</strong>: WebSockets are more stateful, so you need to implement additional logging and monitoring for persistent connections.</p>
</li>
<li>
<p><strong>Authentication</strong>: You need to implement a new authentication mechanism for incoming WebSocket connections.</p>
</li>
<li>
<p><strong>Infrastructure</strong>: You need to configure your infrastructure to support WebSockets, including load balancers and firewalls.</p>
</li>
<li>
<p><strong>Operations</strong>: You need to manage WebSocket connections and reconnections, including handling connection timeouts and errors.</p>
</li>
<li>
<p><strong>Client Implementation</strong>: You need to implement a client-side WebSocket library, including handling reconnections and state management.</p>
</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacker gains access to the RP2350 OTP secret by glitching the RISC-V cores (189 pts)]]></title>
            <link>https://www.tomshardware.com/raspberry-pi/it-looks-like-the-raspberry-pi-rp2350-hacking-challenge-has-been-beaten-hacker-gains-access-to-the-otp-secret-by-glitching-the-risc-v-cores-to-enable-debugging</link>
            <guid>42599971</guid>
            <pubDate>Sun, 05 Jan 2025 05:24:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/raspberry-pi/it-looks-like-the-raspberry-pi-rp2350-hacking-challenge-has-been-beaten-hacker-gains-access-to-the-otp-secret-by-glitching-the-risc-v-cores-to-enable-debugging">https://www.tomshardware.com/raspberry-pi/it-looks-like-the-raspberry-pi-rp2350-hacking-challenge-has-been-beaten-hacker-gains-access-to-the-otp-secret-by-glitching-the-risc-v-cores-to-enable-debugging</a>, See on <a href="https://news.ycombinator.com/item?id=42599971">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:320/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:480/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:650/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:970/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1024/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1200/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1301/yB6wiDWXxE5MZmYV7D2CSG.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:320/yB6wiDWXxE5MZmYV7D2CSG.jpg" alt="RP2350 Hacking Challenge" srcset="https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:320/yB6wiDWXxE5MZmYV7D2CSG.jpg 320w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:480/yB6wiDWXxE5MZmYV7D2CSG.jpg 480w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:650/yB6wiDWXxE5MZmYV7D2CSG.jpg 650w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:970/yB6wiDWXxE5MZmYV7D2CSG.jpg 970w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1024/yB6wiDWXxE5MZmYV7D2CSG.jpg 1024w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1200/yB6wiDWXxE5MZmYV7D2CSG.jpg 1200w, https://cdn.mos.cms.futurecdn.net/v2/t:0,l:0,cw:0,ch:0,q:80,w:1301/yB6wiDWXxE5MZmYV7D2CSG.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/yB6wiDWXxE5MZmYV7D2CSG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yB6wiDWXxE5MZmYV7D2CSG.jpg" data-pin-nopin="true" fetchpriority="high" crossorigin="anonymous">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/yB6wiDWXxE5MZmYV7D2CSG.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Aedan Cullen)</span>
</figcaption>
</div>

<div id="article-body">
<p>We may have a winner for the $20,000 Raspberry Pi and Hextree RP2350 <a data-analytics-id="inline-link" href="https://www.raspberrypi.com/news/can-you-hack-our-new-chip/" data-url="https://www.raspberrypi.com/news/can-you-hack-our-new-chip/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Hacking Challenge</a>, but we won't officially find out who the winner is until January 14. Engineer Aedan Cullen went public with his <a data-analytics-id="inline-link" href="https://media.ccc.de/v/38c3-hacking-the-rp2350" data-url="https://media.ccc.de/v/38c3-hacking-the-rp2350" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Hacking the RP2350</a> presentation at the recent 38th Chaos Communication Congress (38C3), and there is a <a data-analytics-id="inline-link" href="https://github.com/aedancullen/hacking-the-rp2350/tree/master" data-url="https://github.com/aedancullen/hacking-the-rp2350/tree/master" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">GitHub repo</a> now published to accompany the video <a data-analytics-id="inline-link" href="https://github.com/aedancullen/hacking-the-rp2350/blob/master/README.md" data-url="https://github.com/aedancullen/hacking-the-rp2350/blob/master/README.md" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">here</a>. Cullen studied the RP2350 in detail before going for a voltage injection glitch attack on pin 53 of the RP2350 chip, which managed to turn on the 'permanently disabled' RISC-V cores and their debug access port, enabling him to read the secret.</p><p>Raspberry Pi <a data-analytics-id="inline-link" href="https://www.tomshardware.com/raspberry-pi/raspberry-pi-pico/whats-inside-the-raspberry-pi-pico-2s-rp2350" data-before-rewrite-localise="https://www.tomshardware.com/raspberry-pi/raspberry-pi-pico/whats-inside-the-raspberry-pi-pico-2s-rp2350">introduced the RP2350 </a>via the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/raspberry-pi/raspberry-pi-pico/raspberry-pi-pico-2-launches-with-arm-risc-v-cores-hands-on-with-the-new-dollar5-microcontroller" data-before-rewrite-localise="https://www.tomshardware.com/raspberry-pi/raspberry-pi-pico/raspberry-pi-pico-2-launches-with-arm-risc-v-cores-hands-on-with-the-new-dollar5-microcontroller">Raspberry Pi Pico 2</a> as a successor to the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/raspberry-pi-10-million-rp2040s" data-before-rewrite-localise="https://www.tomshardware.com/news/raspberry-pi-10-million-rp2040s">RP2040</a> – with added <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/security" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/security">security</a> features to appeal to commercial and industrial customers. To publicize the new microcontroller it teamed up with Hextree to devise the RP2350 Hacking Challenge, <a data-analytics-id="inline-link" href="https://www.raspberrypi.com/news/can-you-hack-our-new-chip/" data-url="https://www.raspberrypi.com/news/can-you-hack-our-new-chip/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">announced at DEF CON in August</a>. This challenge concluded on 31 Dec 2024, but we must wait until January 14 for the official winner announcement. Cullen made his presentation at 38C3 on Dec 27 and also shared a GitHub repo with an outline of his hacking process and Python code. However, we don't know if Cullen is the winner, so this may not be the $20K winning hack method.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-320-80.jpg" alt="RP2350 Hacking Challenge" srcset="https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ibXQxW6autxYfKtTJxaTQG.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Aedan Cullen)</span></figcaption></figure><p>Specifically, the RP2350 comes with a quartet of new security features, that Raspberry Pi was keen to highlight. These are Secure Boot, TrustZone, Redundancy Coprocessor (RCP), and Glitch Detectors. The setters of the challenge hid a secret on one of these 'fully secured' chips, which would be supplied to hackers who applied, and the first demonstrable success story would get $20,000 and the kudos of being the winner of the challenge. Attacks using hardware and/or software means were permissible by the competition rules, so it was almost an anything-goes situation.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-320-80.jpg" alt="RP2350 Hacking Challenge" srcset="https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/GBWvVvGr6TbJk6ujN9bTQG.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Aedan Cullen)</span></figcaption></figure><p>Raspberry Pi and Hextree would hide the secret in the RP2350's OTP (One Time Programmable) memory on the chip, said to be a once-set but never-forget binary code. Picotool was used to write the covert code to the OTP. Then the RP2350's OTP memory was locked behind the Page Locks hardware protection feature, set to an 'inaccessible' state '13:12' as per the table above. Firmware was also signed, with Secure Boot enabled, and they disabled the chip debug feature, so prying eyes couldn't get to the secret via a Serial Wire Debug (SWD) interface. Furthermore, all other bootkeys were disabled, the RP2350 Glitch Detector was turned on and then set to its highest sensitivity. It certainly sounds like it was locked down.</p><p>Cullen says he started his hacking process by studying the RP2350 data sheet and the dependencies outlined in the documentation. Then Cullen drilled down on how the RP2350 boots and establishes its security settings, with particular attention to the OTP.</p><p>Cullen's first idea was to get the OTP to misread its critical bit settings, you could get the chip to work in a non-secure way. Cullen even X-rayed the RP2350 as part of his investigations and annotated the chip blocks. However, he stresses that this was just a pursuit of interest and not really instrumental to beating the challenge.</p><p>Research compelled Cullen to focus on Pin 53, labeled USB-OTP_VDD, as it is connected to OTP (and USB) functions. Perhaps a hacker could "mess with this power supply externally" to affect these functions, he pondered. So he took off the chip and isolated Pin 53 (physically cutting PCB trace), so it was ready to be electrically tampered with separately on a reassembled board.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-nQ4sTaGVvBq3RDynH4YwZQ"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><div aria-hidden="false" data-swipeable="true" data-hydrate="true" id="slice-container-imageGallery-nQ4sTaGVvBq3RDynH4YwZQ-V5ppwQPQlYKQEEzp8YfYNSf4WgG7yCzH"><figure data-bordeaux-image-check="false"><div><picture data-hydrate="true"><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-nopin="true" data-slice-image="true"><source type="image/jpeg" srcset="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-nopin="true" data-slice-image="true"><img src="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" alt="RP2350 Hacking Challenge" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/VqTQyzSKcfsLApECYJYjTG.jpg" data-pin-nopin="true" data-slice-image="true"></picture></div><figcaption><span itemprop="copyrightHolder">(Image credit: Aedan Cullen )</span></figcaption></figure></div><p>With this hardware-modified setup, Cullen probed Pin 53 to "inject whatever voltages I want" and checked what happened. An unprotected RP2350 board was kept on hand for side-by-side comparisons. Once the hardware was set up he watched what normally occurs when a secured and a non-secured RP2350 started up – according to the probe readout on an oscilloscope.</p><p>16 groups of spikes were seen, corresponding with 16 initial OTP reads on startup. Cullen then tested injecting power glitches to Pin 53 at certain points in the boot process. Disappointingly, the debug remained locked down. Next, a Python script was used to sweep the position of a glitch power input through the entire 600-microsecond range of OTP reads during startup. The debug functionality was checked but never became available. So Cullen looked at the unlocked RP2350 board again, with debugging enabled, for clues.</p><p>Then, something interesting was observed, as the RISC-V cores showed up via the glitch on the unsecured RP2350. Cullen then used another script to check where the RISC-V debug access port shows up. This technique could also be triggered on the secured RP2350 – and a debugger could now be connected to the secured RP2350 and the secret read from the OTP!</p><h2 id="secret-gets-busted-3">Secret gets busted</h2><p>The 'permanently disabled' RISC-V cores had been woken by the glitch to enable this access. Cullen explains the odd underlying reason that the glitch 0x00030033 works is that it disables both Arm and RISC-V cores but, the Arm disable instruction has higher priority, leaving RISC-V turned on. Importantly the glitch successfully clears Debug_Disable.</p><div aria-hidden="false" data-swipeable="true" data-hydrate="true" id="slice-container-imageGallery-nQ4sTaGVvBq3RDynH4YwZQ-NKOg5Y8ErILypSgdcOnKfaOiUe7TF7Qt"><figure data-bordeaux-image-check="false"><div><picture data-hydrate="true"><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-nopin="true" data-slice-image="true"><source type="image/jpeg" srcset="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-nopin="true" data-slice-image="true"><img src="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" alt="RP2350 Hacking Challenge" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-normal="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" data-original-mos="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/vkU8csoeyzL6rtQTzQKcQG.jpg" data-pin-nopin="true" data-slice-image="true"></picture></div><figcaption><span itemprop="copyrightHolder">(Image credit: Aedan Cullen )</span></figcaption></figure></div><p>For more information about the background to this hack, particularly bypassing the guard read mechanism, we advise watching the video recorded during the 38c3 (linked top). There's also an interesting Q&amp;A at the end of the session. You might find attendees ask similar questions to those you may have.</p><p>Cullen concluded his presentation with three pithy points:</p><ul><li>Human communication factors are huge. Sidense [the company behind OTP NV memory tech used] knew how to do guards properly, and RPi missed out.</li><li>“Permanent” is not a thing unless it involves chip destruction. There is some copper somewhere with each signal…</li><li>Remember to glitch in the places they don’t tell you.</li></ul>
</div>



<!-- Drop in a standard article here maybe? -->




<div id="slice-container-authorBio-nQ4sTaGVvBq3RDynH4YwZQ"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>
</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guten: A Tiny Newspaper Printer (246 pts)]]></title>
            <link>https://amanvir.com/guten</link>
            <guid>42599599</guid>
            <pubDate>Sun, 05 Jan 2025 03:47:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://amanvir.com/guten">https://amanvir.com/guten</a>, See on <a href="https://news.ycombinator.com/item?id=42599599">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[No more needles Tracking blood sugar on your wrist (351 pts)]]></title>
            <link>https://uwaterloo.ca/news/media/no-more-needles-tracking-blood-sugar-your-wrist</link>
            <guid>42599189</guid>
            <pubDate>Sun, 05 Jan 2025 02:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uwaterloo.ca/news/media/no-more-needles-tracking-blood-sugar-your-wrist">https://uwaterloo.ca/news/media/no-more-needles-tracking-blood-sugar-your-wrist</a>, See on <a href="https://news.ycombinator.com/item?id=42599189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p>Imagine shrinking satellite technology that predicts the weather into a device that transmits vital information about the health of the person wearing it.</p>

<p>University of Waterloo engineers have achieved this&nbsp;technological feat to help people faced with&nbsp;chronic health problems such as diabetes monitor their glucose levels.</p>

<p>The Waterloo team’s breakthrough addresses the major challenge of creating non-invasive, continuous glucose monitoring, essential for those managing diabetes.</p>

<p>Currently, diabetics must frequently prick their fingers or rely on invasive wearable patches with micro-needles to track their blood-sugar levels. But the system designed by Dr. George Shaker, an adjunct associate professor at Waterloo’s Department of Electrical and Computer Engineering, and his colleagues eliminates this need, thereby reducing pain, the risk of infection and improving people’s quality of life.</p>

<p><img alt="George Shaker picture" height="233" src="https://uwaterloo.ca/news/sites/ca.news/files/resize/styles/feature_small/public/george_shaker_23-06-13_0853_1-350x233.jpg?itok=mvnnwrr9" width="350">“We’ve developed radar technology that can now fit inside a smart watch and sense glucose levels more accurately than ever before,” Shaker said. “Just like you use glasses to improve your vision, our technology helps for better sensing of glucose levels.”</p>

<p>To explain how the new system works, Shaker points to weather satellites that use radar to monitor the Earth’s atmosphere and, for example, measure storm movements and other kinds of cloud cover.</p>

<p>“We’ve figured a way to miniaturize these radar systems on satellites and put them in a wearable device and use the same radar technology that looks at changes in the atmosphere to look at changes in the human body,” he said</p>

<p>The system’s key components are a radar chip, which sends and receives signals through the body, an engineered “meta-surface”, which helps focus these signals for better accuracy, and microcontrollers, which process the radar signals using artificial intelligence algorithms. The algorithms improve the accuracy and reliability of the readings by learning from the data over time.</p>

<p>The unique aspect of this system is the meta-surface which Shaker and his team have developed. It further improves the radar’s resolution and sensitivity, allowing for more accurate glucose readings.</p>

<p>“Unlike existing methods that require skin penetration our system is entirely non-invasive and can detect even small changes in glucose level,” Shaker said. “No other technology can provide this level of precision without direct contact with the bloodstream.”</p>

<p>More work remains to perfect their system. Although the engineers now power their device with a USB cable, they’re planning to optimize it for battery use to improve portability. Eventually, they hope it can be used to gather other health-related data, such as blood pressure.</p>

<p>The team is currently working with industry partners to introduce the technology to be installed in the next generation of wearables.</p>

<p>“We have a minimum viable product that’s already being used in clinical trials, and while there’s more work to be done, we’re much closer to a full marketable device,” Shaker said.</p>

<p>The research paper, “Radar near-field sensing using metasurface for biomedical applications” was recently featured in Nature’s <a href="https://www.nature.com/articles/s44172-024-00194-4"><i>Communications Engineering</i></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No-hole surgery: no keyhole, yet surgeons can now still operate under your skin (2023) (102 pts)]]></title>
            <link>https://www.nibib.nih.gov/news-events/newsroom/getting-under-your-skin-3d-printing-technique-builds-structures-through-tissues</link>
            <guid>42599142</guid>
            <pubDate>Sun, 05 Jan 2025 02:00:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nibib.nih.gov/news-events/newsroom/getting-under-your-skin-3d-printing-technique-builds-structures-through-tissues">https://www.nibib.nih.gov/news-events/newsroom/getting-under-your-skin-3d-printing-technique-builds-structures-through-tissues</a>, See on <a href="https://news.ycombinator.com/item?id=42599142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>What if a clinician could 3D print something <em>through</em> your skin, constructing an implant or replacement organ underneath layers of tissue? The world of medicine would be transformed: a host of surgical procedures, which come with a variety of risks, could be performed without ever lifting a scalpel.</p>
<p>A collaborative, NIH-funded team is working to make this Star Trek-like fiction a reality. Their work, <a href="https://www.science.org/doi/10.1126/science.adi1563">published today in <em>Science</em></a>, outlines a method to print biocompatible structures through thick, multi-layered tissues. The principle? Focused ultrasound, combined with a novel ultrasound-sensitive ink.</p>
<p>“Focused ultrasound has been used for decades to treat a wide variety of conditions, underscoring its safety and utility as a clinical tool,” said Randy King, Ph.D., a program director in the Division of Applied Science &amp; Technology at NIBIB. “This potential new application, built on years of technology advancements, could set the stage for something previously thought impossible: through-tissue 3D ultrasound printing.”</p>
<h4>Using ultrasound principles for 3D printing</h4>
<p>Some 3D printing techniques use light—a form of energy—to trigger the solidification of an “ink,” which is often composed of liquid substance, like resin or plastic. Light, however, doesn’t travel well through skin and organs, getting scattered as it passes through them. In order to successfully “print” through biological tissues, a different energy source would be needed.</p>
<p>Enter ultrasound. Compared with light, ultrasound waves can travel much further through tissues, sending energy well below the surface. By delivering an ink that could be solidified through interactions with ultrasound waves, a clinician could potentially build biologically relevant structures inside of the human body, all without making an incision.</p>

<figure role="group">
<img alt="On the left: An illustration of an ultrasound transducer positioned above a chamber of ultrasound-sensitive ink, casting ultrasound waves deep into the chamber. On the right: Computer models and 3D-printed structures including a honeycomb, a vascular network, a hand, and a spider." data-entity-type="file" data-entity-uuid="23fbe99f-2576-4804-bdde-bda7f645a04b" src="https://www.nibib.nih.gov/sites/default/files/inline-images/Yao-panels-840x340.jpg" width="840" height="340" loading="lazy">
<figcaption><strong>Ultrasound technique can build 3D structures at varying depths.</strong> Using a focused ultrasound transducer, ultrasound waves are cast into a chamber of ultrasound-sensitive ink, creating 3D structures at centimeter depths. <em>Credit:</em> Junjie Yao (Duke University) and Yu Shrike Zhang (Harvard Medical School and Brigham and Women’s Hospital)</figcaption>
</figure>
<p>“Our technology is based on the sono-thermal effect, which describes the increase in temperature that occurs due to the absorption of ultrasound waves,” explained senior study author Junjie Yao, Ph.D., an associate professor of biomedical engineering at Duke University. “If we can precisely control the temperature increase by focusing the ultrasound waves, we can guide the solidification of the injected ink, even through layers of tissue.”</p>
<p>The ink is made using four components: a compound that helps to absorb the ultrasound waves, a microparticle that helps to control viscosity, a polymer that provides structure, and a salt that absorbs heat to trigger solidification. “The individual components of the bioink are not new—in fact, they have been used for many years in biomaterials applications,” said senior study author Y. Shrike Zhang, Ph.D., associate professor and associate bioengineer at Harvard Medical School and Brigham and Women’s Hospital, respectively. “The key was the combination of these ingredients, in the appropriate ratios, which allowed us to create an ink that can rapidly solidify upon interactions with ultrasound waves without getting dispersed.”</p>
<h4>From principle to proof of concept</h4>
<figure role="group">

<figcaption><strong>Ultrasound technique enables through-tissue 3D printing.</strong> A honeycomb structure is printed through a 17mm pig liver. <em>Credit:</em> Junjie Yao (Duke University) and Yu Shrike Zhang (Harvard Medical School and Brigham and Women’s Hospital)</figcaption>
</figure>
<p>To start, the researchers wanted to see if they could create 3D shapes using their ultrasound technique. They suspended a focused ultrasound transducer over a chamber filled with their novel ink. Between the transducer and the ink was a “matching medium,” a substance used in most ultrasound methods that ensures efficient transmission of ultrasound waves. Using a computer program to precisely control the intricate 3D movements of the ultrasound transducer, the researchers were able to create a variety of different structures at varying depths inside of the ink chamber. These structures had a range of sizes and geometrical intricacies and included objects such as multi-layer honeycomb, a branched vascular network, and complex models that resembled a hand or spider.</p>
<p>Next, the researchers wanted to determine if their technique could be used to print through biological tissues. They placed pig tissues that ranged in thickness (up to 17 millimeters) on top of the chamber filled with ink. With the transducer positioned above, the researchers steered ultrasound waves through the tissue and into the chamber below. They successfully printed a variety of different structures through several different kinds of tissues, including a pig liver and a pig tissue phantom that was comprised of multiple layers (such as skin, fat, and muscle).</p>
<p>To mimic a real-world procedure, the researchers performed a mock surgery using an ex vivo goat heart. With a catheter, the researchers injected their ultrasound-sensitive ink into the left atrial appendage, a sac-like structure in the heart where blood clots can develop. Through the goat heart wall, the researchers used ultrasound waves to solidify the ink, effectively sealing off this area of the heart. This procedure, called left atrial appendage closure, can require open-heart surgery and is sometimes performed on patients with atrial fibrillation with increased risk of stroke.</p>
<p>These initial experiments demonstrate that this proof-of-concept printing method has the potential to turn highly invasive surgical procedures into safer, less invasive ones. “Our technique could provide an unconventional avenue towards truly minimally invasive medicine which seemed nearly impossible before,” said Yao.</p>
<h4>Looking ahead</h4>
<p>This focused ultrasound printing technique can require high levels of energy, which has the potential to overheat the surrounding tissues. To combat this, the researchers constructed a confocal high-intensity ultrasound printer. This system uses two ultrasound transducers that are aligned in a crossbeam pattern, allowing the two ultrasound wavefronts to overlap. Not only does this design reduce the energy needed from each transducer, it also improves the resolution and speed of the ultrasound printer.</p>
<p>“We will continue to modify our technique to increase its safety and efficiency, looking to adapt our technology for different medical uses,” said Zhang. “While we believe that our method has the potential to enable a variety of minimally invasive procedures, it’s still a prototype technology that will require further optimization before it can be evaluated in humans.”</p>
<figure role="group">
<div>
  
  

            <p><img loading="lazy" src="https://www.nibib.nih.gov/sites/default/files/styles/16_9_at_1_2_content_width/public/2024-09/strategic-plan-ultrasound-microcatheter.jpg?itok=nQM7TjcW" width="700" height="356" alt="An illustration of a robotic arm connected to a focused ultrasound transducer that rests above a human chest. A microcatheter injects an ink into a region below the transducer." typeof="foaf:Image">


</p>
      
</div>
<figcaption><strong>Potential adaptation of the 3D ultrasound printing technique in humans.</strong> Using a catheter, the ultrasound-sensitive ink could be injected near the area of interest and then solidified into the desired shape using focused ultrasound. Note: this technique has not yet been evaluated in humans. <em>Credit:</em> Junjie Yao (Duke University) and Yu Shrike Zhang (Harvard Medical School and Brigham and Women’s Hospital)</figcaption>
</figure>
<p>Yao and Zhang—who have known each other since graduate school—have spent the last several years working together on their 3D ultrasound printing technology. “Our multi-year collaboration gave us a chance to create a new technique that combines our unique perspectives: ultrasound imaging and biochemistry,” said Yao. “We could not have created this technology without one another, highlighting the unique possibilities that can stem from interdisciplinary partnerships.”</p>
<p>This research was supported by grants from NIH, including NIBIB (R21EB025270, R21EB027981, R21EB027304, R01EB028143, R21EB027981, and R01EB031629); the National Heart, Lung, and Blood Institute (R01HL153857, R01HL165176, and R01HL166522); the National Institute of Neurological Disorders and Stroke (RF1NS115581 and R01NS111039); and the National Cancer Institute (R01CA282451). Other funding includes grants from the National Science Foundation.</p>
<p><em>This Science Highlight describes a basic research finding. Basic research increases our understanding of human behavior and biology, which is foundational to advancing new and better ways to prevent, diagnose, and treat disease. Science is an unpredictable and incremental process—each research advance builds on past discoveries, often in unexpected ways. Most clinical advances would not be possible without the knowledge of fundamental basic research.</em></p>
<p>Study reference: Xiao Kuang&nbsp;<em>et al.</em> Self-enhancing sono-inks enable deep-penetration acoustic volumetric printing.&nbsp;<em>Science</em>&nbsp;<strong>382</strong>, 1148-1155 (2023) DOI:<a href="https://doi.org/10.1126/science.adi1563">10.1126/science.adi1563</a></p>
<p>The graphics seen here and on the NIBIB website have been adapted from figures found in the <em>Science</em>&nbsp;publication.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web page annoyances that I don't inflict on you here (301 pts)]]></title>
            <link>http://rachelbythebay.com/w/2025/01/04/cruft/</link>
            <guid>42599102</guid>
            <pubDate>Sun, 05 Jan 2025 01:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://rachelbythebay.com/w/2025/01/04/cruft/">http://rachelbythebay.com/w/2025/01/04/cruft/</a>, See on <a href="https://news.ycombinator.com/item?id=42599102">Hacker News</a></p>
Couldn't get http://rachelbythebay.com/w/2025/01/04/cruft/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly half Dell's US workforce has rejected RTO. Rather WFH than get promoted (2024) (195 pts)]]></title>
            <link>https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb</link>
            <guid>42598722</guid>
            <pubDate>Sun, 05 Jan 2025 00:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb">https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb</a>, See on <a href="https://news.ycombinator.com/item?id=42598722">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[University of Alabama Engineer Pioneers New Process for Recycling Plastics (2024) (155 pts)]]></title>
            <link>https://news.ua.edu/2024/10/ua-chemical-engineer-plastic-recycling/</link>
            <guid>42598458</guid>
            <pubDate>Sat, 04 Jan 2025 23:30:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.ua.edu/2024/10/ua-chemical-engineer-plastic-recycling/">https://news.ua.edu/2024/10/ua-chemical-engineer-plastic-recycling/</a>, See on <a href="https://news.ycombinator.com/item?id=42598458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">
					
<article id="post-160701">
	<!-- .entry-header -->

	<div>
		
<p>Plastic recycling is commonplace but imperfect. Part of the problem, says <a href="https://eng.ua.edu/eng-directory/dr-jason-e-bara/" target="_blank" rel="noreferrer noopener">Dr. Jason Bara</a>, is that current processes yield lower-quality plastics with reduced value and fewer end uses. In a circular plastic economy, any plastic could be broken down to its component parts and then reconstituted into new products with little or no waste.</p>



<p>The science is not there yet, but it may be one step closer.</p>



<div>
<div>
<figure><img decoding="async" width="828" height="1024" src="https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-828x1024.jpg" alt="Dr. Jason Bara of The University of Alabama. " srcset="https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-828x1024.jpg 828w, https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-243x300.jpg 243w, https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-768x950.jpg 768w, https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-1242x1536.jpg 1242w, https://news.ua.edu/wp-content/uploads/2024/10/2209032_BH_119_Jason_Bara-1656x2048.jpg 1656w" sizes="(max-width: 828px) 100vw, 828px"><figcaption>Dr. Jason Bara</figcaption></figure>
</div>



<div>
<p>Bara, a professor in the College of Engineering, leads a team at The University of Alabama working to improve <a href="https://news.ua.edu/2021/08/ua-researchers-part-of-national-effort-to-tackle-plastic-waste/">methods to recycle</a> the ubiquitous plastics we interact with daily.</p>



<p>Polyethylene terephthalate (PET) is a common plastic that responds well to chemolysis, a chemical process that depolymerizes plastic for recycling. Much of the previous work on chemolysis and PET has focused on water, alcohols, and amines.&nbsp; Amines are a group of compounds derived from ammonia and are especially effective for PET depolymerization, but most products formed from the aminolysis of PET have limited uses, Bara said.</p>
</div>
</div>



<h2 id="h-let-s-see-what-happens"><strong>“Let’s See What Happens”</strong></h2>



<p>Nothing in the literature pointed to the effectiveness of imidazoles in this process. Imidazole, and its related compounds, are a group of organic molecules that are used in a wide range of applications and even appear within biologically important compounds.</p>



<p>“I’ve been working with imidazole for much of my career,” said Bara. “It’s pretty amazing how versatile it is.” Bara had been working for two years with using amines to break down plastics as part of a National Science Foundation grant geared toward reducing plastic waste. His appreciation for imidazole’s versatility made it a natural extension to see what happened when he tried using it for chemolysis.</p>



<p>“My student came back into the lab and said oh — the plastic is gone. It’s all gone.”</p>



<p>The University of Alabama has filed a patent application for the process, which offers several key advantages over other chemical recycling methods for PET. Among these is the lack of need of an additional solvent or catalyst because imidazole has a relatively low melting point. These are favorable qualities for developing a cost efficient and commercially viable process.</p>



<p>Breaking down PET via imidazolysis yields chemical intermediates that can be transformed to a range of other chemicals that are hard to get by traditional methods.</p>



<p>“Our imidazolysis process is unique in that it’s a flexible recycling technology, and you can get a wider range of final products from PET depolymerization when you do it our way,” Bara said.</p>



<h2 id="h-chasing-the-next-challenge"><strong>Chasing the Next Challenge</strong></h2>



<p>Bara says one of the more exciting things about the research is what lies ahead.</p>



<div><p>PET is among the easier plastics to recycle. For one thing, it is relatively clean because it is used in food containers and drink bottles, and it generally contains few additives. Based on their results so far, imidazolysis is also useful in depolymerizing polyurethanes, which are trickier to work with than PET.</p><figure><img loading="lazy" decoding="async" width="1024" height="683" src="https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-1024x683.jpeg" alt="Wooden box marked with a recycling symbol holding a variety of plastic bottles. " srcset="https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-1024x683.jpeg 1024w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-300x200.jpeg 300w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-768x512.jpeg 768w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-1536x1024.jpeg 1536w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_480960525-2048x1366.jpeg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>“There is generally good awareness around the need to recycle plastics and other materials (paper, metal) that commonly go into our recycling bins,” he said. “But it’s harder to appreciate that polyurethanes can also be chemically recycled.”</p>



<p>Polyurethanes are generally encountered as foams that are full of air, do not melt and often are formulated with any number of inorganic additives. Think packing foams, seat cushions, memory foam mattresses and automobile seats.</p>



<figure><img loading="lazy" decoding="async" width="2560" height="1439" src="https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-scaled.jpeg" alt="Yellow chunks of polyurethane foam, torn into irregular pieces. " srcset="https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-scaled.jpeg 2560w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-300x169.jpeg 300w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-1024x576.jpeg 1024w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-768x432.jpeg 768w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-1536x864.jpeg 1536w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-2048x1152.jpeg 2048w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-1280x720.jpeg 1280w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-640x360.jpeg 640w, https://news.ua.edu/wp-content/uploads/2024/10/AdobeStock_294651475-edited-320x180.jpeg 320w" sizes="(max-width: 2560px) 100vw, 2560px"><figcaption>The new process could increase the recycling of polyurethane foam, which is widely used a variety of consumer products.</figcaption></figure>



<p>“While municipal recycling is limited to the most common thermoplastics, consumers likely don’t understand the magnitude of the polyurethane problem that needs to be addressed.”</p>



<p>Imidazolysis not only works to break down polyurethanes and allows for recovery of the molecular components (the polyols used to make polyurethanes can be especially valuable to recover), but the physical properties of imidazole also make it a better reagent for carrying out the reaction.</p>



<p>“While I think what we’ve already published on the successful imidazolysis of PET is very exciting,” Bara said, “The chemical recycling of polyurethanes is where imidazolysis may potentially have a much bigger impact.”</p>



<p>This work on recycling PET and PU via imidazolysis has been supported by active funding from NSF and includes contributions from researchers at Iowa State University.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-160701 -->



</div></div>]]></description>
        </item>
    </channel>
</rss>