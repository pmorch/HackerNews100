<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 02 Jan 2026 10:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A confession from a mainstream food delivery app engineer (141 pts)]]></title>
            <link>https://www.reddit.com/r/confession/s/gbrh2zxeou</link>
            <guid>46461578</guid>
            <pubDate>Fri, 02 Jan 2026 05:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reddit.com/r/confession/s/gbrh2zxeou">https://www.reddit.com/r/confession/s/gbrh2zxeou</a>, See on <a href="https://news.ycombinator.com/item?id=46461578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="t3_1q1mzej-post-rtjson-content" about="t3_1q1mzej_" property="schema:articleBody" dir="auto">
      <p>
      I’m posting this from a library Wi-Fi on a burner laptop because I am technically under a massive NDA. I don’t care anymore. I put in my two weeks yesterday and honestly, I hope they sue me. I’ve been sitting on this for about eight months, just watching the code getting pushed to production, and I can’t sleep at night knowing I helped build this machine.
    </p><p>
      You guys always suspect the algorithms are rigged against you, but the reality is actually so much more depressing than the conspiracy theories. I’m a backend engineer. I sit in the weekly sprint planning meetings where Product Managers (PMs) discuss how to squeeze another 0.4% margin out of "human assets" (that’s literally what they call drivers in the database schemas). They talk about these people like they are resource nodes in a video game, not fathers and mothers trying to pay rent.
    </p><p>
      First off, the "Priority Delivery" is a total scam. It was pitched to us as a "psychological value add." Like I said in the title, when you pay that extra $2.99, it changes a boolean flag in the order JSON, but the dispatch logic literally ignores it. It does nothing to speed you up.
    </p><p>
      We actually ran an A/B test last year where we didn't speed up the priority orders, we just purposefully delayed non-priority orders by 5 to 10 minutes to make the Priority ones "feel" faster by comparison. Management loved the results. We generated millions in pure profit just by making the standard service worse, not by making the premium service better.
    </p><p>
      But the thing that actually makes me sick—and the main reason I’m quitting—is the "Desperation Score." We have a hidden metric for drivers that tracks how desperate they are for cash based on their acceptance behavior.
    </p><p>
      If a driver usually logs on at 10 PM and accepts every garbage $3 order instantly without hesitation, the algo tags them as "High Desperation." Once they are tagged, the system then deliberately stops showing them high-paying orders. The logic is: "Why pay this guy $15 for a run when we know he’s desperate enough to do it for $6?" We save the good tips for the "casual" drivers to hook them in and gamify their experience, while the full-timers get grinded into dust.
    </p><p>
      Then there is the "Benefit Fee." You’ve probably seen that $1.50 "Regulatory Response Fee" or "Driver Benefits Fee" that appeared on your bill after the recent labor laws passed. The wording is designed to make you feel like you're helping the worker.
    </p><p>
      In reality, that money goes straight to a corporate slush fund used to lobby against driver unions. We have a specific internal cost center for "Policy Defense," and that fee feeds directly into it. You are literally paying for the high-end lawyers that are fighting to keep your delivery guy homeless.
    </p><p>
      And regarding tips, we're essentially doing Tip Theft 2.0. We don't "steal" them legally anymore because we got sued for that. Instead, we use predictive modeling to dynamically lower the base pay.
    </p><p>
      If the algo predicts you are a "high tipper" and you’ll likely drop $10, it offers the driver a measly $2 base pay. If you tip $0, it offers them $8 base pay just to get the food moved. The result is that your generosity isn't rewarding the driver; it’s subsidizing us. You’re paying their wage so we don't have to.
    </p><p>
      I'm drunk and I'm angry. Ask me anything before this gets taken down.
    </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm a developer for a major food delivery app (417 pts)]]></title>
            <link>https://old.reddit.com/r/confession/comments/1q1mzej/im_a_developer_for_a_major_food_delivery_app_the/</link>
            <guid>46461563</guid>
            <pubDate>Fri, 02 Jan 2026 04:57:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/confession/comments/1q1mzej/im_a_developer_for_a_major_food_delivery_app_the/">https://old.reddit.com/r/confession/comments/1q1mzej/im_a_developer_for_a_major_food_delivery_app_the/</a>, See on <a href="https://news.ycombinator.com/item?id=46461563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I’m posting this from a library Wi-Fi on a burner laptop because I am technically under a massive NDA. I don’t care anymore. I put in my two weeks yesterday and honestly, I hope they sue me. I’ve been sitting on this for about eight months, just watching the code getting pushed to production, and I can’t sleep at night knowing I helped build this machine.</p>

<p>You guys always suspect the algorithms are rigged against you, but the reality is actually so much more depressing than the conspiracy theories. I’m a backend engineer. I sit in the weekly sprint planning meetings where Product Managers (PMs) discuss how to squeeze another 0.4% margin out of "human assets" (that’s literally what they call drivers in the database schemas). They talk about these people like they are resource nodes in a video game, not fathers and mothers trying to pay rent.</p>

<p>First off, the "Priority Delivery" is a total scam. It was pitched to us as a "psychological value add." Like I said in the title, when you pay that extra $2.99, it changes a boolean flag in the order JSON, but the dispatch logic literally ignores it. It does nothing to speed you up.</p>

<p>We actually ran an A/B test last year where we didn't speed up the priority orders, we just purposefully delayed non-priority orders by 5 to 10 minutes to make the Priority ones "feel" faster by comparison. Management loved the results. We generated millions in pure profit just by making the standard service worse, not by making the premium service better.</p>

<p>But the thing that actually makes me sick—and the main reason I’m quitting—is the "Desperation Score." We have a hidden metric for drivers that tracks how desperate they are for cash based on their acceptance behavior.</p>

<p>If a driver usually logs on at 10 PM and accepts every garbage $3 order instantly without hesitation, the algo tags them as "High Desperation." Once they are tagged, the system then deliberately stops showing them high-paying orders. The logic is: "Why pay this guy $15 for a run when we know he’s desperate enough to do it for $6?" We save the good tips for the "casual" drivers to hook them in and gamify their experience, while the full-timers get grinded into dust.</p>

<p>Then there is the "Benefit Fee." You’ve probably seen that $1.50 "Regulatory Response Fee" or "Driver Benefits Fee" that appeared on your bill after the recent labor laws passed. The wording is designed to make you feel like you're helping the worker.</p>

<p>In reality, that money goes straight to a corporate slush fund used to lobby against driver unions. We have a specific internal cost center for "Policy Defense," and that fee feeds directly into it. You are literally paying for the high-end lawyers that are fighting to keep your delivery guy homeless.</p>

<p>And regarding tips, we're essentially doing Tip Theft 2.0. We don't "steal" them legally anymore because we got sued for that. Instead, we use predictive modeling to dynamically lower the base pay.</p>

<p>If the algo predicts you are a "high tipper" and you’ll likely drop $10, it offers the driver a measly $2 base pay. If you tip $0, it offers them $8 base pay just to get the food moved. The result is that your generosity isn't rewarding the driver; it’s subsidizing us. You’re paying their wage so we don't have to.</p>

<p>I'm drunk and I'm angry. Ask me anything before this gets taken down.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marmot – A distributed SQLite server with MySQL wire compatible interface (106 pts)]]></title>
            <link>https://github.com/maxpert/marmot</link>
            <guid>46460676</guid>
            <pubDate>Fri, 02 Jan 2026 02:21:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/maxpert/marmot">https://github.com/maxpert/marmot</a>, See on <a href="https://news.ycombinator.com/item?id=46460676">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Marmot v2</h2><a id="user-content-marmot-v2" aria-label="Permalink: Marmot v2" href="#marmot-v2"></a></p>
<p dir="auto"><a href="https://goreportcard.com/report/github.com/maxpert/marmot" rel="nofollow"><img src="https://camo.githubusercontent.com/a9cf99f212f56b414c865728a2659a62b2129d1edcf479e5a53d1366dc2def36/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6d6178706572742f6d61726d6f74" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/maxpert/marmot"></a>
<a href="https://discord.gg/AWUwY66XsE" rel="nofollow"><img src="https://camo.githubusercontent.com/dfd80a5843107ada4de21a02a89c0bb029f240e404f38ee2b101e784685e0e8e/68747470733a2f2f62616467656e2e6e65742f62616467652f69636f6e2f646973636f72643f69636f6e3d646973636f7264266c6162656c3d4d61726d6f74" alt="Discord" data-canonical-src="https://badgen.net/badge/icon/discord?icon=discord&amp;label=Marmot"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7d665d92a54ac639b00283b01653885ccfb206dab2d80fd32a1674608b7a6c03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6178706572742f6d61726d6f74"><img src="https://camo.githubusercontent.com/7d665d92a54ac639b00283b01653885ccfb206dab2d80fd32a1674608b7a6c03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6178706572742f6d61726d6f74" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/maxpert/marmot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What &amp; Why?</h2><a id="user-content-what--why" aria-label="Permalink: What &amp; Why?" href="#what--why"></a></p>
<p dir="auto">Marmot v2 is a leaderless, distributed SQLite replication system built on a gossip-based protocol with distributed transactions and eventual consistency.</p>
<p dir="auto"><strong>Key Features:</strong></p>
<ul dir="auto">
<li><strong>Leaderless Architecture</strong>: No single point of failure - any node can accept writes</li>
<li><strong>MySQL Protocol Compatible</strong>: Connect with any MySQL client (DBeaver, MySQL Workbench, mysql CLI)</li>
<li><strong>Distributed Transactions</strong>: Percolator-style write intents with conflict detection</li>
<li><strong>Multi-Database Support</strong>: Create and manage multiple databases per cluster</li>
<li><strong>DDL Replication</strong>: Distributed schema changes with automatic idempotency and cluster-wide locking</li>
<li><strong>Production-Ready SQL Parser</strong>: Powered by rqlite/sql AST parser for MySQL→SQLite transpilation</li>
<li><strong>CDC-Based Replication</strong>: Row-level change data capture for consistent replication</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start a single-node cluster
./marmot-v2

# Connect with MySQL client
mysql -h localhost -P 3306 -u root

# Or use DBeaver, MySQL Workbench, etc."><pre><span><span>#</span> Start a single-node cluster</span>
./marmot-v2

<span><span>#</span> Connect with MySQL client</span>
mysql -h localhost -P 3306 -u root

<span><span>#</span> Or use DBeaver, MySQL Workbench, etc.</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Replication</h3><a id="user-content-testing-replication" aria-label="Permalink: Testing Replication" href="#testing-replication"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Test DDL and DML replication across a 2-node cluster
./scripts/test-ddl-replication.sh

# This script will:
# 1. Start a 2-node cluster
# 2. Create a table on node 1 and verify it replicates to node 2
# 3. Insert data on node 1 and verify it replicates to node 2
# 4. Update data on node 2 and verify it replicates to node 1
# 5. Delete data on node 1 and verify it replicates to node 2

# Manual cluster testing
./examples/start-seed.sh              # Start seed node (port 8081, mysql 3307)
./examples/join-cluster.sh 2 localhost:8081  # Join node 2 (port 8082, mysql 3308)
./examples/join-cluster.sh 3 localhost:8081  # Join node 3 (port 8083, mysql 3309)

# Connect to any node and run queries
mysql --protocol=TCP -h localhost -P 3307 -u root
mysql --protocol=TCP -h localhost -P 3308 -u root

# Cleanup
pkill -f marmot-v2"><pre><span><span>#</span> Test DDL and DML replication across a 2-node cluster</span>
./scripts/test-ddl-replication.sh

<span><span>#</span> This script will:</span>
<span><span>#</span> 1. Start a 2-node cluster</span>
<span><span>#</span> 2. Create a table on node 1 and verify it replicates to node 2</span>
<span><span>#</span> 3. Insert data on node 1 and verify it replicates to node 2</span>
<span><span>#</span> 4. Update data on node 2 and verify it replicates to node 1</span>
<span><span>#</span> 5. Delete data on node 1 and verify it replicates to node 2</span>

<span><span>#</span> Manual cluster testing</span>
./examples/start-seed.sh              <span><span>#</span> Start seed node (port 8081, mysql 3307)</span>
./examples/join-cluster.sh 2 localhost:8081  <span><span>#</span> Join node 2 (port 8082, mysql 3308)</span>
./examples/join-cluster.sh 3 localhost:8081  <span><span>#</span> Join node 3 (port 8083, mysql 3309)</span>

<span><span>#</span> Connect to any node and run queries</span>
mysql --protocol=TCP -h localhost -P 3307 -u root
mysql --protocol=TCP -h localhost -P 3308 -u root

<span><span>#</span> Cleanup</span>
pkill -f marmot-v2</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/maxpert/marmot" rel="nofollow"><img src="https://camo.githubusercontent.com/ee99a4dc41e48fb1f38d51af628abb0ae1fd696beb5ccd37d3dfa28e7377565f/68747470733a2f2f7374617263686172742e63632f6d6178706572742f6d61726d6f742e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/maxpert/marmot.svg?variant=adaptive"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">Marmot v2 uses a fundamentally different architecture from other SQLite replication solutions:</p>
<p dir="auto"><strong>vs. rqlite/dqlite/LiteFS:</strong></p>
<ul dir="auto">
<li>❌ They require a primary node for all writes</li>
<li>✅ Marmot allows writes on <strong>any node</strong></li>
<li>❌ They use leader election (Raft)</li>
<li>✅ Marmot uses <strong>gossip protocol</strong> (no leader)</li>
<li>❌ They require proxy layer or page-level interception</li>
<li>✅ Marmot uses <strong>MySQL protocol</strong> for direct database access</li>
</ul>
<p dir="auto"><strong>How It Works:</strong></p>
<ol dir="auto">
<li><strong>Write Coordination</strong>: 2PC (Two-Phase Commit) with configurable consistency (ONE, QUORUM, ALL)</li>
<li><strong>Conflict Resolution</strong>: Last-Write-Wins (LWW) with HLC timestamps</li>
<li><strong>Cluster Membership</strong>: SWIM-style gossip with failure detection</li>
<li><strong>Data Replication</strong>: Full database replication - all nodes receive all data</li>
<li><strong>DDL Replication</strong>: Cluster-wide schema changes with automatic idempotency</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">DDL Replication</h2><a id="user-content-ddl-replication" aria-label="Permalink: DDL Replication" href="#ddl-replication"></a></p>
<p dir="auto">Marmot v2 supports <strong>distributed DDL (Data Definition Language) replication</strong> without requiring master election:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How It Works</h3><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Cluster-Wide Locking</strong>: Each DDL operation acquires a distributed lock per database (default: 30-second lease)</p>
<ul dir="auto">
<li>Prevents concurrent schema changes on the same database</li>
<li>Locks automatically expire if a node crashes</li>
<li>Different databases can have concurrent DDL operations</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Automatic Idempotency</strong>: DDL statements are automatically rewritten for safe replay</p>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE TABLE users (id INT)
→ CREATE TABLE IF NOT EXISTS users (id INT)

DROP TABLE users
→ DROP TABLE IF EXISTS users"><pre><span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>INT</span>)
→ CREATE TABLE IF NOT EXISTS users (id <span>INT</span>)

<span>DROP</span> <span>TABLE</span> users
→ <span>DROP</span> <span>TABLE</span> <span>IF</span> EXISTS users</pre></div>
</li>
<li>
<p dir="auto"><strong>Schema Version Tracking</strong>: Each database maintains a schema version counter</p>
<ul dir="auto">
<li>Incremented on every DDL operation</li>
<li>Exchanged via gossip protocol for drift detection</li>
<li>Used by delta sync to validate transaction applicability</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Quorum-Based Replication</strong>: DDL replicates like DML through the same 2PC mechanism</p>
<ul dir="auto">
<li>No special master node needed</li>
<li>Works with existing consistency levels (QUORUM, ALL, etc.)</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[ddl]
# DDL lock lease duration (seconds)
lock_lease_seconds = 30

# Automatically rewrite DDL for idempotency
enable_idempotent = true"><pre>[<span>ddl</span>]
<span><span>#</span> DDL lock lease duration (seconds)</span>
<span>lock_lease_seconds</span> = <span>30</span>

<span><span>#</span> Automatically rewrite DDL for idempotency</span>
<span>enable_idempotent</span> = <span>true</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Best Practices</h3><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<ul dir="auto">
<li>✅ <strong>Do</strong>: Execute DDL from a single connection/node at a time</li>
<li>✅ <strong>Do</strong>: Use qualified table names (<code>mydb.users</code> instead of <code>users</code>)</li>
<li><g-emoji alias="warning">⚠️</g-emoji> <strong>Caution</strong>: ALTER TABLE is less idempotent - avoid replaying failed ALTER operations</li>
<li>❌ <strong>Don't</strong>: Run concurrent DDL on the same database from multiple nodes</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">CDC-Based Replication</h2><a id="user-content-cdc-based-replication" aria-label="Permalink: CDC-Based Replication" href="#cdc-based-replication"></a></p>
<p dir="auto">Marmot v2 uses <strong>Change Data Capture (CDC)</strong> for replication instead of SQL statement replay:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How It Works</h3><a id="user-content-how-it-works-1" aria-label="Permalink: How It Works" href="#how-it-works-1"></a></p>
<ol dir="auto">
<li><strong>Row-Level Capture</strong>: Instead of replicating SQL statements, Marmot captures the actual row data changes (INSERT/UPDATE/DELETE)</li>
<li><strong>Binary Data Format</strong>: Row data is serialized as CDC messages with column values, ensuring consistent replication regardless of SQL dialect</li>
<li><strong>Deterministic Application</strong>: Row data is applied directly to the target database, avoiding parsing ambiguities</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Benefits</h3><a id="user-content-benefits" aria-label="Permalink: Benefits" href="#benefits"></a></p>
<ul dir="auto">
<li><strong>Consistency</strong>: Same row data applied everywhere, no SQL parsing differences</li>
<li><strong>Performance</strong>: Binary format is more efficient than SQL text</li>
<li><strong>Reliability</strong>: No issues with SQL syntax variations between MySQL and SQLite</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Row Key Extraction</h3><a id="user-content-row-key-extraction" aria-label="Permalink: Row Key Extraction" href="#row-key-extraction"></a></p>
<p dir="auto">For UPDATE and DELETE operations, Marmot automatically extracts row keys:</p>
<ul dir="auto">
<li>Uses PRIMARY KEY columns when available</li>
<li>Falls back to ROWID for tables without explicit primary key</li>
<li>Handles composite primary keys correctly</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">CDC Publisher</h2><a id="user-content-cdc-publisher" aria-label="Permalink: CDC Publisher" href="#cdc-publisher"></a></p>
<p dir="auto">Marmot can publish CDC events to external messaging systems, enabling real-time data pipelines, analytics, and event-driven architectures. Events follow the <strong><a href="https://debezium.io/" rel="nofollow">Debezium</a> specification</strong> for maximum compatibility with existing CDC tooling.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Debezium-Compatible Format</strong>: Events conform to the <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-events" rel="nofollow">Debezium event structure</a>, compatible with Kafka Connect, Flink, Spark, and other CDC consumers</li>
<li><strong>Multi-Sink Support</strong>: Publish to multiple destinations simultaneously (Kafka, NATS)</li>
<li><strong>Glob-Based Filtering</strong>: Filter which tables and databases to publish</li>
<li><strong>Automatic Retry</strong>: Exponential backoff with configurable limits</li>
<li><strong>Persistent Cursors</strong>: Survives restarts without losing position</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration-1" aria-label="Permalink: Configuration" href="#configuration-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[publisher]
enabled = true

[[publisher.sinks]]
name = &quot;kafka-main&quot;
type = &quot;kafka&quot;                    # &quot;kafka&quot; or &quot;nats&quot;
format = &quot;debezium&quot;               # Debezium-compatible JSON format
brokers = [&quot;localhost:9092&quot;]      # Kafka broker addresses
topic_prefix = &quot;marmot.cdc&quot;       # Topics: {prefix}.{database}.{table}
filter_tables = [&quot;*&quot;]             # Glob patterns (e.g., &quot;users&quot;, &quot;order_*&quot;)
filter_databases = [&quot;*&quot;]          # Glob patterns (e.g., &quot;prod_*&quot;)
batch_size = 100                  # Events per poll cycle
poll_interval_ms = 10             # Polling interval

# NATS sink example
[[publisher.sinks]]
name = &quot;nats-events&quot;
type = &quot;nats&quot;
format = &quot;debezium&quot;
nats_url = &quot;nats://localhost:4222&quot;
topic_prefix = &quot;marmot.cdc&quot;
filter_tables = [&quot;*&quot;]
filter_databases = [&quot;*&quot;]"><pre>[<span>publisher</span>]
<span>enabled</span> = <span>true</span>

[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>"</span>kafka-main<span>"</span></span>
<span>type</span> = <span><span>"</span>kafka<span>"</span></span>                    <span><span>#</span> "kafka" or "nats"</span>
<span>format</span> = <span><span>"</span>debezium<span>"</span></span>               <span><span>#</span> Debezium-compatible JSON format</span>
<span>brokers</span> = [<span><span>"</span>localhost:9092<span>"</span></span>]      <span><span>#</span> Kafka broker addresses</span>
<span>topic_prefix</span> = <span><span>"</span>marmot.cdc<span>"</span></span>       <span><span>#</span> Topics: {prefix}.{database}.{table}</span>
<span>filter_tables</span> = [<span><span>"</span>*<span>"</span></span>]             <span><span>#</span> Glob patterns (e.g., "users", "order_*")</span>
<span>filter_databases</span> = [<span><span>"</span>*<span>"</span></span>]          <span><span>#</span> Glob patterns (e.g., "prod_*")</span>
<span>batch_size</span> = <span>100</span>                  <span><span>#</span> Events per poll cycle</span>
<span>poll_interval_ms</span> = <span>10</span>             <span><span>#</span> Polling interval</span>

<span><span>#</span> NATS sink example</span>
[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>"</span>nats-events<span>"</span></span>
<span>type</span> = <span><span>"</span>nats<span>"</span></span>
<span>format</span> = <span><span>"</span>debezium<span>"</span></span>
<span>nats_url</span> = <span><span>"</span>nats://localhost:4222<span>"</span></span>
<span>topic_prefix</span> = <span><span>"</span>marmot.cdc<span>"</span></span>
<span>filter_tables</span> = [<span><span>"</span>*<span>"</span></span>]
<span>filter_databases</span> = [<span><span>"</span>*<span>"</span></span>]</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Event Format</h3><a id="user-content-event-format" aria-label="Permalink: Event Format" href="#event-format"></a></p>
<p dir="auto">Events follow the <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-change-events-value" rel="nofollow">Debezium envelope structure</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;schema&quot;: { ... },
  &quot;payload&quot;: {
    &quot;before&quot;: null,
    &quot;after&quot;: {&quot;id&quot;: 1, &quot;name&quot;: &quot;alice&quot;, &quot;email&quot;: &quot;alice@example.com&quot;},
    &quot;source&quot;: {
      &quot;version&quot;: &quot;2.0.0&quot;,
      &quot;connector&quot;: &quot;marmot&quot;,
      &quot;name&quot;: &quot;marmot&quot;,
      &quot;ts_ms&quot;: 1702500000000,
      &quot;db&quot;: &quot;myapp&quot;,
      &quot;table&quot;: &quot;users&quot;
    },
    &quot;op&quot;: &quot;c&quot;,
    &quot;ts_ms&quot;: 1702500000000
  }
}"><pre>{
  <span>"schema"</span>: { <span>... </span>},
  <span>"payload"</span>: {
    <span>"before"</span>: <span>null</span>,
    <span>"after"</span>: {<span>"id"</span>: <span>1</span>, <span>"name"</span>: <span><span>"</span>alice<span>"</span></span>, <span>"email"</span>: <span><span>"</span>alice@example.com<span>"</span></span>},
    <span>"source"</span>: {
      <span>"version"</span>: <span><span>"</span>2.0.0<span>"</span></span>,
      <span>"connector"</span>: <span><span>"</span>marmot<span>"</span></span>,
      <span>"name"</span>: <span><span>"</span>marmot<span>"</span></span>,
      <span>"ts_ms"</span>: <span>1702500000000</span>,
      <span>"db"</span>: <span><span>"</span>myapp<span>"</span></span>,
      <span>"table"</span>: <span><span>"</span>users<span>"</span></span>
    },
    <span>"op"</span>: <span><span>"</span>c<span>"</span></span>,
    <span>"ts_ms"</span>: <span>1702500000000</span>
  }
}</pre></div>
<p dir="auto"><strong>Operation Types</strong> (per <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-create-events" rel="nofollow">Debezium spec</a>):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th><code>op</code></th>
<th><code>before</code></th>
<th><code>after</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>INSERT</td>
<td><code>c</code> (create)</td>
<td><code>null</code></td>
<td>row data</td>
</tr>
<tr>
<td>UPDATE</td>
<td><code>u</code> (update)</td>
<td>old row</td>
<td>new row</td>
</tr>
<tr>
<td>DELETE</td>
<td><code>d</code> (delete)</td>
<td>old row</td>
<td><code>null</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Topic Naming</h3><a id="user-content-topic-naming" aria-label="Permalink: Topic Naming" href="#topic-naming"></a></p>
<p dir="auto">Topics follow the pattern: <code>{topic_prefix}.{database}.{table}</code></p>
<p dir="auto">Examples:</p>
<ul dir="auto">
<li><code>marmot.cdc.myapp.users</code></li>
<li><code>marmot.cdc.myapp.orders</code></li>
<li><code>marmot.cdc.analytics.events</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Use Cases</h3><a id="user-content-use-cases" aria-label="Permalink: Use Cases" href="#use-cases"></a></p>
<ul dir="auto">
<li><strong>Real-Time Analytics</strong>: Stream changes to data warehouses (Snowflake, BigQuery, ClickHouse)</li>
<li><strong>Event-Driven Microservices</strong>: Trigger actions on data changes</li>
<li><strong>Cache Invalidation</strong>: Keep caches in sync with database changes</li>
<li><strong>Audit Logging</strong>: Capture all changes for compliance</li>
<li><strong>Search Indexing</strong>: Keep Elasticsearch/Algolia in sync</li>
</ul>
<p dir="auto">For more details, see the <a href="https://maxpert.github.io/marmot/integrations" rel="nofollow">Integrations documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">SQL Statement Compatibility</h2><a id="user-content-sql-statement-compatibility" aria-label="Permalink: SQL Statement Compatibility" href="#sql-statement-compatibility"></a></p>
<p dir="auto">Marmot supports a wide range of MySQL/SQLite statements through its MySQL protocol server. The following table shows compatibility for different statement types:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Statement Type</th>
<th>Support</th>
<th>Replication</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DML - Data Manipulation</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>INSERT</code> / <code>REPLACE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names (db.table)</td>
</tr>
<tr>
<td><code>UPDATE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names</td>
</tr>
<tr>
<td><code>DELETE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names</td>
</tr>
<tr>
<td><code>SELECT</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Read operations</td>
</tr>
<tr>
<td><code>LOAD DATA</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Bulk data loading</td>
</tr>
<tr>
<td><strong>DDL - Data Definition</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>CREATE TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>ALTER TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>DROP TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>TRUNCATE TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td></td>
</tr>
<tr>
<td><code>RENAME TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP INDEX</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP VIEW</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP TRIGGER</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><strong>Database Management</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>CREATE DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>DROP DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>ALTER DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>SHOW DATABASES</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Metadata query</td>
</tr>
<tr>
<td><code>SHOW TABLES</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Metadata query</td>
</tr>
<tr>
<td><code>USE database</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Session state</td>
</tr>
<tr>
<td><strong>Transaction Control</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>BEGIN</code> / <code>START TRANSACTION</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Transaction boundary</td>
</tr>
<tr>
<td><code>COMMIT</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Commits distributed transaction</td>
</tr>
<tr>
<td><code>ROLLBACK</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Aborts distributed transaction</td>
</tr>
<tr>
<td><code>SAVEPOINT</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Nested transaction support</td>
</tr>
<tr>
<td><strong>Locking</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>LOCK TABLES</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Requires distributed locking coordination</td>
</tr>
<tr>
<td><code>UNLOCK TABLES</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Requires distributed locking coordination</td>
</tr>
<tr>
<td><strong>Session Configuration</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>SET</code> statements</td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Session-local, not replicated</td>
</tr>
<tr>
<td><strong>XA Transactions</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>XA START/END/PREPARE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Marmot uses its own 2PC protocol</td>
</tr>
<tr>
<td><code>XA COMMIT/ROLLBACK</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Not compatible with Marmot's model</td>
</tr>
<tr>
<td><strong>DCL - Data Control</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>GRANT</code> / <code>REVOKE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><code>CREATE/DROP USER</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><code>ALTER USER</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><strong>Administrative</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>OPTIMIZE TABLE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Node-local administrative command</td>
</tr>
<tr>
<td><code>REPAIR TABLE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Node-local administrative command</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Legend</h3><a id="user-content-legend" aria-label="Permalink: Legend" href="#legend"></a></p>
<ul dir="auto">
<li>✅ <strong>Full</strong>: Fully supported and working</li>
<li>✅ <strong>Parsed</strong>: Statement is parsed and recognized</li>
<li><g-emoji alias="warning">⚠️</g-emoji> <strong>Limited</strong>: Works but has limitations in distributed context</li>
<li>❌ <strong>No</strong>: Not supported or not replicated</li>
<li><strong>N/A</strong>: Not applicable (read-only or session-local)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Important Notes</h3><a id="user-content-important-notes" aria-label="Permalink: Important Notes" href="#important-notes"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Schema Changes (DDL)</strong>: DDL statements are fully replicated with cluster-wide locking and automatic idempotency. See the DDL Replication section for details.</p>
</li>
<li>
<p dir="auto"><strong>XA Transactions</strong>: Marmot has its own distributed transaction protocol based on 2PC. MySQL XA transactions are not compatible with Marmot's replication model.</p>
</li>
<li>
<p dir="auto"><strong>User Management (DCL)</strong>: User and privilege management statements are local to each node. For production deployments, consider handling authentication at the application or proxy level.</p>
</li>
<li>
<p dir="auto"><strong>Table Locking</strong>: <code>LOCK TABLES</code> statements are recognized but not enforced across the cluster. Use application-level coordination for distributed locking needs.</p>
</li>
<li>
<p dir="auto"><strong>Qualified Names</strong>: Marmot fully supports qualified table names (e.g., <code>db.table</code>) in DML and DDL operations.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">MySQL Protocol &amp; Metadata Queries</h2><a id="user-content-mysql-protocol--metadata-queries" aria-label="Permalink: MySQL Protocol &amp; Metadata Queries" href="#mysql-protocol--metadata-queries"></a></p>
<p dir="auto">Marmot includes a MySQL-compatible protocol server, allowing you to connect using any MySQL client (DBeaver, MySQL Workbench, mysql CLI, etc.). The server supports:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Metadata Query Support</h3><a id="user-content-metadata-query-support" aria-label="Permalink: Metadata Query Support" href="#metadata-query-support"></a></p>
<p dir="auto">Marmot provides full support for MySQL metadata queries, enabling GUI tools like DBeaver to browse databases, tables, and columns:</p>
<ul dir="auto">
<li><strong>SHOW Commands</strong>: <code>SHOW DATABASES</code>, <code>SHOW TABLES</code>, <code>SHOW COLUMNS FROM table</code>, <code>SHOW CREATE TABLE</code>, <code>SHOW INDEXES</code></li>
<li><strong>INFORMATION_SCHEMA</strong>: Queries against <code>INFORMATION_SCHEMA.TABLES</code>, <code>INFORMATION_SCHEMA.COLUMNS</code>, <code>INFORMATION_SCHEMA.SCHEMATA</code>, and <code>INFORMATION_SCHEMA.STATISTICS</code></li>
<li><strong>Type Conversion</strong>: Automatic SQLite-to-MySQL type mapping for compatibility</li>
</ul>
<p dir="auto">These metadata queries are powered by the <strong>rqlite/sql AST parser</strong>, providing production-grade MySQL query compatibility.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Connecting with MySQL Clients</h3><a id="user-content-connecting-with-mysql-clients" aria-label="Permalink: Connecting with MySQL Clients" href="#connecting-with-mysql-clients"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Using mysql CLI
mysql -h localhost -P 3306 -u root

# Connection string for applications
mysql://root@localhost:3306/marmot"><pre><span><span>#</span> Using mysql CLI</span>
mysql -h localhost -P 3306 -u root

<span><span>#</span> Connection string for applications</span>
mysql://root@localhost:3306/marmot</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Recovery Scenarios</h2><a id="user-content-recovery-scenarios" aria-label="Permalink: Recovery Scenarios" href="#recovery-scenarios"></a></p>
<p dir="auto">Marmot handles various failure and recovery scenarios automatically:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Network Partition (Split-Brain)</h3><a id="user-content-network-partition-split-brain" aria-label="Permalink: Network Partition (Split-Brain)" href="#network-partition-split-brain"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scenario</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Minority partition</strong></td>
<td>Writes <strong>fail</strong> - cannot achieve quorum</td>
</tr>
<tr>
<td><strong>Majority partition</strong></td>
<td>Writes <strong>succeed</strong> - quorum achieved</td>
</tr>
<tr>
<td><strong>Partition heals</strong></td>
<td>Delta sync + LWW merges divergent data</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>How it works:</strong></p>
<ol dir="auto">
<li>During partition, only the majority side can commit writes (quorum enforcement)</li>
<li>When partition heals, nodes exchange transaction logs via <code>StreamChanges</code> RPC</li>
<li>Conflicts resolved using Last-Writer-Wins (LWW) with HLC timestamps</li>
<li>Higher node ID breaks ties for simultaneous writes</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Node Failure &amp; Recovery</h3><a id="user-content-node-failure--recovery" aria-label="Permalink: Node Failure &amp; Recovery" href="#node-failure--recovery"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scenario</th>
<th>Recovery Method</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Brief outage</strong></td>
<td>Delta sync - replay missed transactions</td>
</tr>
<tr>
<td><strong>Extended outage</strong></td>
<td>Snapshot transfer + delta sync</td>
</tr>
<tr>
<td><strong>New node joining</strong></td>
<td>Full snapshot from existing node</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Anti-Entropy Background Process:</strong></p>
<p dir="auto">Marmot v2 includes an automatic anti-entropy system that continuously monitors and repairs replication lag across the cluster:</p>
<ol dir="auto">
<li><strong>Lag Detection</strong>: Every 60 seconds (configurable), each node queries peers for their replication state</li>
<li><strong>Smart Recovery Decision</strong>:
<ul dir="auto">
<li><strong>Delta Sync</strong> if lag &lt; 10,000 transactions AND &lt; 1 hour: Streams missed transactions incrementally</li>
<li><strong>Snapshot Transfer</strong> if lag exceeds thresholds: Full database file transfer for efficiency</li>
</ul>
</li>
<li><strong>Gap Detection</strong>: Detects when transaction logs have been GC'd and automatically falls back to snapshot</li>
<li><strong>Multi-Database Support</strong>: Tracks and syncs each database independently</li>
<li><strong>GC Coordination</strong>: Garbage collection respects peer replication state - logs aren't deleted until all peers have applied them</li>
</ol>
<p dir="auto"><strong>Delta Sync Process:</strong></p>
<ol dir="auto">
<li>Lagging node queries <code>last_applied_txn_id</code> for each peer/database</li>
<li>Requests transactions since that ID via <code>StreamChanges</code> RPC</li>
<li><strong>Gap Detection</strong>: Checks if first received txn_id has a large gap from requested ID
<ul dir="auto">
<li>If gap &gt; delta_sync_threshold_txns, indicates missing (GC'd) transactions</li>
<li>Automatically falls back to snapshot transfer to prevent data loss</li>
</ul>
</li>
<li>Applies changes using LWW conflict resolution</li>
<li>Updates replication state tracking (per-database)</li>
<li>Progress logged every 100 transactions</li>
</ol>
<p dir="auto"><strong>GC Coordination with Anti-Entropy:</strong></p>
<ul dir="auto">
<li>Transaction logs are retained with a two-tier policy:
<ul dir="auto">
<li><strong>Min retention</strong> (2 hours): Must be &gt;= delta sync threshold, respects peer lag</li>
<li><strong>Max retention</strong> (24 hours): Force delete after this time to prevent unbounded growth</li>
</ul>
</li>
<li>Config validation enforces: <code>gc_min &gt;= delta_threshold</code> and <code>gc_max &gt;= 2x delta_threshold</code></li>
<li>Each database tracks replication progress per peer</li>
<li>GC queries minimum applied txn_id across all peers before cleanup</li>
<li><strong>Gap detection</strong> prevents data loss if GC runs while nodes are offline</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Consistency Guarantees</h3><a id="user-content-consistency-guarantees" aria-label="Permalink: Consistency Guarantees" href="#consistency-guarantees"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Write Consistency</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ONE</code></td>
<td>Returns after 1 node ACK (fast, less durable)</td>
</tr>
<tr>
<td><code>QUORUM</code></td>
<td>Returns after majority ACK (default, balanced)</td>
</tr>
<tr>
<td><code>ALL</code></td>
<td>Returns after all nodes ACK (slow, most durable)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Conflict Resolution:</strong></p>
<ul dir="auto">
<li>All conflicts resolved via LWW using HLC timestamps</li>
<li>No data loss - later write always wins deterministically</li>
<li>Tie-breaker: higher node ID wins for equal timestamps</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<ul dir="auto">
<li><strong>Selective Table Watching</strong>: All tables in a database are replicated. Selective table replication is not supported.</li>
<li><strong>WAL Mode Required</strong>: SQLite must use WAL mode for reliable multi-process changes.</li>
<li><strong>Eventually Consistent</strong>: Rows may sync out of order. <code>SERIALIZABLE</code> transaction assumptions may not hold across nodes.</li>
<li><strong>Concurrent DDL</strong>: Avoid running concurrent DDL operations on the same database from multiple nodes (protected by cluster-wide lock with 30s lease).</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatibility</h2><a id="user-content-compatibility" aria-label="Permalink: Compatibility" href="#compatibility"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AUTO_INCREMENT and Integer Types</h3><a id="user-content-auto_increment-and-integer-types" aria-label="Permalink: AUTO_INCREMENT and Integer Types" href="#auto_increment-and-integer-types"></a></p>
<blockquote>
<p dir="auto"><strong>IMPORTANT: Marmot automatically converts <code>INT AUTO_INCREMENT</code> to <code>BIGINT</code></strong></p>
<p dir="auto">This is a <strong>breaking change</strong> from standard MySQL/SQLite behavior. Marmot does not respect 32-bit <code>INT</code> for auto-increment columns - they are automatically promoted to <code>BIGINT</code> to support distributed ID generation.</p>
</blockquote>
<p dir="auto"><strong>Why?</strong></p>
<p dir="auto">In a distributed, leaderless system, each node must generate unique IDs independently without coordination. Marmot uses HLC-based (Hybrid Logical Clock) 64-bit IDs to ensure:</p>
<ol dir="auto">
<li><strong>Global Uniqueness</strong>: IDs are unique across all nodes without central coordination</li>
<li><strong>Monotonicity</strong>: IDs increase over time (within each node)</li>
<li><strong>No Collisions</strong>: Unlike auto-increment sequences, HLC IDs cannot collide between nodes</li>
</ol>
<p dir="auto"><strong>How It Works:</strong></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>DDL Transformation</strong>: When you create a table with <code>AUTO_INCREMENT</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE TABLE users (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(100))
-- Becomes internally:
CREATE TABLE users (id BIGINT PRIMARY KEY, name TEXT)"><pre><span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>INT</span> AUTO_INCREMENT <span>PRIMARY KEY</span>, name <span>VARCHAR</span>(<span>100</span>))
<span><span>--</span> Becomes internally:</span>
<span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>BIGINT</span> <span>PRIMARY KEY</span>, name <span>TEXT</span>)</pre></div>
</li>
<li>
<p dir="auto"><strong>DML ID Injection</strong>: When inserting with <code>0</code> or <code>NULL</code> for an auto-increment column:</p>
<div dir="auto" data-snippet-clipboard-copy-content="INSERT INTO users (id, name) VALUES (0, 'alice')
-- Becomes internally:
INSERT INTO users (id, name) VALUES (7318624812345678901, 'alice')"><pre><span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>0</span>, <span><span>'</span>alice<span>'</span></span>)
<span><span>--</span> Becomes internally:</span>
<span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>7318624812345678901</span>, <span><span>'</span>alice<span>'</span></span>)</pre></div>
</li>
<li>
<p dir="auto"><strong>Explicit IDs Preserved</strong>: If you provide an explicit non-zero ID, it is used as-is:</p>
<div dir="auto" data-snippet-clipboard-copy-content="INSERT INTO users (id, name) VALUES (12345, 'bob')
-- Remains:
INSERT INTO users (id, name) VALUES (12345, 'bob')"><pre><span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>12345</span>, <span><span>'</span>bob<span>'</span></span>)
<span><span>--</span> Remains:</span>
<span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>12345</span>, <span><span>'</span>bob<span>'</span></span>)</pre></div>
</li>
</ol>
<p dir="auto"><strong>Important Considerations:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Aspect</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ID Range</strong></td>
<td>64-bit (up to 9.2 quintillion) instead of 32-bit (4.2 billion)</td>
</tr>
<tr>
<td><strong>ID Format</strong></td>
<td>HLC-based, not sequential integers</td>
</tr>
<tr>
<td><strong>SQLite ROWID</strong></td>
<td>Not used - Marmot manages IDs explicitly</td>
</tr>
<tr>
<td><strong>Client Libraries</strong></td>
<td>Ensure your client handles <code>BIGINT</code> correctly (some JSON serializers may lose precision)</td>
</tr>
<tr>
<td><strong>Existing Data</strong></td>
<td>Migrate existing <code>INT</code> columns to <code>BIGINT</code> before enabling Marmot</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Schema-Based Detection:</strong></p>
<p dir="auto">Marmot automatically detects auto-increment columns by querying SQLite schema directly. A column is considered auto-increment if:</p>
<ul dir="auto">
<li>It is a single-column <code>INTEGER PRIMARY KEY</code> (SQLite rowid alias), or</li>
<li>It is a single-column <code>BIGINT PRIMARY KEY</code> (Marmot's transformed columns)</li>
</ul>
<p dir="auto">This means:</p>
<ul dir="auto">
<li><strong>No registration required</strong> - columns are detected from schema at runtime</li>
<li><strong>Works across restarts</strong> - no need to re-execute DDL statements</li>
<li><strong>Works with existing databases</strong> - tables created directly on SQLite work too</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration-2" aria-label="Permalink: Configuration" href="#configuration-2"></a></p>
<p dir="auto">Marmot v2 uses a TOML configuration file (default: <code>config.toml</code>). All settings have sensible defaults.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Configuration</h3><a id="user-content-core-configuration" aria-label="Permalink: Core Configuration" href="#core-configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="node_id = 0  # 0 = auto-generate
data_dir = &quot;./marmot-data&quot;"><pre><span>node_id</span> = <span>0</span>  <span><span>#</span> 0 = auto-generate</span>
<span>data_dir</span> = <span><span>"</span>./marmot-data<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Transaction Manager</h3><a id="user-content-transaction-manager" aria-label="Permalink: Transaction Manager" href="#transaction-manager"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[transaction]
heartbeat_timeout_seconds = 10  # Transaction timeout without heartbeat
conflict_window_seconds = 10    # Conflict resolution window
lock_wait_timeout_seconds = 50  # Lock wait timeout (MySQL: innodb_lock_wait_timeout)"><pre>[<span>transaction</span>]
<span>heartbeat_timeout_seconds</span> = <span>10</span>  <span><span>#</span> Transaction timeout without heartbeat</span>
<span>conflict_window_seconds</span> = <span>10</span>    <span><span>#</span> Conflict resolution window</span>
<span>lock_wait_timeout_seconds</span> = <span>50</span>  <span><span>#</span> Lock wait timeout (MySQL: innodb_lock_wait_timeout)</span></pre></div>
<p dir="auto"><strong>Note</strong>: Transaction log garbage collection is managed by the replication configuration to coordinate with anti-entropy. See <code>replication.gc_min_retention_hours</code> and <code>replication.gc_max_retention_hours</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Connection Pool</h3><a id="user-content-connection-pool" aria-label="Permalink: Connection Pool" href="#connection-pool"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[connection_pool]
pool_size = 4              # Number of SQLite connections
max_idle_time_seconds = 10 # Max idle time before closing
max_lifetime_seconds = 300 # Max connection lifetime (0 = unlimited)"><pre>[<span>connection_pool</span>]
<span>pool_size</span> = <span>4</span>              <span><span>#</span> Number of SQLite connections</span>
<span>max_idle_time_seconds</span> = <span>10</span> <span><span>#</span> Max idle time before closing</span>
<span>max_lifetime_seconds</span> = <span>300</span> <span><span>#</span> Max connection lifetime (0 = unlimited)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">gRPC Client</h3><a id="user-content-grpc-client" aria-label="Permalink: gRPC Client" href="#grpc-client"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[grpc_client]
keepalive_time_seconds = 10    # Keepalive ping interval
keepalive_timeout_seconds = 3  # Keepalive ping timeout
max_retries = 3                # Max retry attempts
retry_backoff_ms = 100         # Retry backoff duration"><pre>[<span>grpc_client</span>]
<span>keepalive_time_seconds</span> = <span>10</span>    <span><span>#</span> Keepalive ping interval</span>
<span>keepalive_timeout_seconds</span> = <span>3</span>  <span><span>#</span> Keepalive ping timeout</span>
<span>max_retries</span> = <span>3</span>                <span><span>#</span> Max retry attempts</span>
<span>retry_backoff_ms</span> = <span>100</span>         <span><span>#</span> Retry backoff duration</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Coordinator</h3><a id="user-content-coordinator" aria-label="Permalink: Coordinator" href="#coordinator"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[coordinator]
prepare_timeout_ms = 2000 # Prepare phase timeout
commit_timeout_ms = 2000  # Commit phase timeout
abort_timeout_ms = 2000   # Abort phase timeout"><pre>[<span>coordinator</span>]
<span>prepare_timeout_ms</span> = <span>2000</span> <span><span>#</span> Prepare phase timeout</span>
<span>commit_timeout_ms</span> = <span>2000</span>  <span><span>#</span> Commit phase timeout</span>
<span>abort_timeout_ms</span> = <span>2000</span>   <span><span>#</span> Abort phase timeout</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cluster</h3><a id="user-content-cluster" aria-label="Permalink: Cluster" href="#cluster"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[cluster]
grpc_bind_address = &quot;0.0.0.0&quot;
grpc_port = 8080
seed_nodes = []                # List of seed node addresses
cluster_secret = &quot;&quot;            # PSK for cluster authentication (see Security section)
gossip_interval_ms = 1000      # Gossip interval
gossip_fanout = 3              # Number of peers to gossip to
suspect_timeout_ms = 5000      # Suspect timeout
dead_timeout_ms = 10000        # Dead timeout"><pre>[<span>cluster</span>]
<span>grpc_bind_address</span> = <span><span>"</span>0.0.0.0<span>"</span></span>
<span>grpc_port</span> = <span>8080</span>
<span>seed_nodes</span> = []                <span><span>#</span> List of seed node addresses</span>
<span>cluster_secret</span> = <span><span>"</span><span>"</span></span>            <span><span>#</span> PSK for cluster authentication (see Security section)</span>
<span>gossip_interval_ms</span> = <span>1000</span>      <span><span>#</span> Gossip interval</span>
<span>gossip_fanout</span> = <span>3</span>              <span><span>#</span> Number of peers to gossip to</span>
<span>suspect_timeout_ms</span> = <span>5000</span>      <span><span>#</span> Suspect timeout</span>
<span>dead_timeout_ms</span> = <span>10000</span>        <span><span>#</span> Dead timeout</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Marmot supports Pre-Shared Key (PSK) authentication for cluster communication. <strong>This is strongly recommended for production deployments.</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="[cluster]
# All nodes in the cluster must use the same secret
cluster_secret = &quot;your-secret-key-here&quot;"><pre>[<span>cluster</span>]
<span><span>#</span> All nodes in the cluster must use the same secret</span>
<span>cluster_secret</span> = <span><span>"</span>your-secret-key-here<span>"</span></span></pre></div>
<p dir="auto"><strong>Environment Variable (Recommended):</strong></p>
<p dir="auto">For production, use the environment variable to avoid storing secrets in config files:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export MARMOT_CLUSTER_SECRET=&quot;your-secret-key-here&quot;
./marmot"><pre><span>export</span> MARMOT_CLUSTER_SECRET=<span><span>"</span>your-secret-key-here<span>"</span></span>
./marmot</pre></div>
<p dir="auto">The environment variable takes precedence over the config file.</p>
<p dir="auto"><strong>Generating a Secret:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Generate a secure random secret
openssl rand -base64 32"><pre><span><span>#</span> Generate a secure random secret</span>
openssl rand -base64 32</pre></div>
<p dir="auto"><strong>Behavior:</strong></p>
<ul dir="auto">
<li>If <code>cluster_secret</code> is empty and <code>MARMOT_CLUSTER_SECRET</code> is not set, authentication is disabled</li>
<li>A warning is logged at startup when authentication is disabled</li>
<li>All gRPC endpoints (gossip, replication, snapshots) are protected when authentication is enabled</li>
<li>Nodes with mismatched secrets will fail to communicate (connection rejected with "invalid cluster secret")</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cluster Membership Management</h3><a id="user-content-cluster-membership-management" aria-label="Permalink: Cluster Membership Management" href="#cluster-membership-management"></a></p>
<p dir="auto">Marmot provides admin HTTP endpoints for managing cluster membership (requires <code>cluster_secret</code> to be configured):</p>
<p dir="auto"><strong>Node Lifecycle:</strong></p>
<ul dir="auto">
<li>New/restarted nodes <strong>auto-join</strong> via gossip - no manual intervention needed</li>
<li>Nodes marked REMOVED via admin API <strong>cannot auto-rejoin</strong> - must be explicitly allowed</li>
<li>This prevents decommissioned nodes from accidentally rejoining the cluster</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="# View cluster members and quorum info
curl -H &quot;X-Marmot-Secret: your-secret&quot; http://localhost:8080/admin/cluster/members

# Remove a node from the cluster (excludes from quorum, blocks auto-rejoin)
curl -X POST -H &quot;X-Marmot-Secret: your-secret&quot; http://localhost:8080/admin/cluster/remove/2

# Allow a removed node to rejoin (node must then restart to join)
curl -X POST -H &quot;X-Marmot-Secret: your-secret&quot; http://localhost:8080/admin/cluster/allow/2"><pre><span><span>#</span> View cluster members and quorum info</span>
curl -H <span><span>"</span>X-Marmot-Secret: your-secret<span>"</span></span> http://localhost:8080/admin/cluster/members

<span><span>#</span> Remove a node from the cluster (excludes from quorum, blocks auto-rejoin)</span>
curl -X POST -H <span><span>"</span>X-Marmot-Secret: your-secret<span>"</span></span> http://localhost:8080/admin/cluster/remove/2

<span><span>#</span> Allow a removed node to rejoin (node must then restart to join)</span>
curl -X POST -H <span><span>"</span>X-Marmot-Secret: your-secret<span>"</span></span> http://localhost:8080/admin/cluster/allow/2</pre></div>
<p dir="auto">See the <a href="https://maxpert.github.io/marmot/operations" rel="nofollow">Operations documentation</a> for detailed usage and examples.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Replication</h3><a id="user-content-replication" aria-label="Permalink: Replication" href="#replication"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[replication]
default_write_consistency = &quot;QUORUM&quot;      # Write consistency level: ONE, QUORUM, ALL
default_read_consistency = &quot;LOCAL_ONE&quot;    # Read consistency level
write_timeout_ms = 5000                   # Write operation timeout
read_timeout_ms = 2000                    # Read operation timeout

# Anti-Entropy: Background healing for eventual consistency
# - Detects and repairs divergence between replicas
# - Uses delta sync for small lags, snapshot for large lags
# - Includes gap detection to prevent incomplete data after GC
enable_anti_entropy = true                 # Enable automatic catch-up for lagging nodes
anti_entropy_interval_seconds = 60         # How often to check for lag (default: 60s)
delta_sync_threshold_transactions = 10000  # Delta sync if lag < 10K txns
delta_sync_threshold_seconds = 3600        # Snapshot if lag > 1 hour

# Garbage Collection: Reclaim disk space by deleting old transaction records
# - gc_min must be >= delta_sync_threshold (validated at startup)
# - gc_max should be >= 2x delta_sync_threshold (recommended)
# - Set gc_max = 0 for unlimited retention
gc_min_retention_hours = 2   # Keep at least 2 hours (>= 1 hour delta threshold)
gc_max_retention_hours = 24  # Force delete after 24 hours"><pre>[<span>replication</span>]
<span>default_write_consistency</span> = <span><span>"</span>QUORUM<span>"</span></span>      <span><span>#</span> Write consistency level: ONE, QUORUM, ALL</span>
<span>default_read_consistency</span> = <span><span>"</span>LOCAL_ONE<span>"</span></span>    <span><span>#</span> Read consistency level</span>
<span>write_timeout_ms</span> = <span>5000</span>                   <span><span>#</span> Write operation timeout</span>
<span>read_timeout_ms</span> = <span>2000</span>                    <span><span>#</span> Read operation timeout</span>

<span><span>#</span> Anti-Entropy: Background healing for eventual consistency</span>
<span><span>#</span> - Detects and repairs divergence between replicas</span>
<span><span>#</span> - Uses delta sync for small lags, snapshot for large lags</span>
<span><span>#</span> - Includes gap detection to prevent incomplete data after GC</span>
<span>enable_anti_entropy</span> = <span>true</span>                 <span><span>#</span> Enable automatic catch-up for lagging nodes</span>
<span>anti_entropy_interval_seconds</span> = <span>60</span>         <span><span>#</span> How often to check for lag (default: 60s)</span>
<span>delta_sync_threshold_transactions</span> = <span>10000</span>  <span><span>#</span> Delta sync if lag &lt; 10K txns</span>
<span>delta_sync_threshold_seconds</span> = <span>3600</span>        <span><span>#</span> Snapshot if lag &gt; 1 hour</span>

<span><span>#</span> Garbage Collection: Reclaim disk space by deleting old transaction records</span>
<span><span>#</span> - gc_min must be &gt;= delta_sync_threshold (validated at startup)</span>
<span><span>#</span> - gc_max should be &gt;= 2x delta_sync_threshold (recommended)</span>
<span><span>#</span> - Set gc_max = 0 for unlimited retention</span>
<span>gc_min_retention_hours</span> = <span>2</span>   <span><span>#</span> Keep at least 2 hours (&gt;= 1 hour delta threshold)</span>
<span>gc_max_retention_hours</span> = <span>24</span>  <span><span>#</span> Force delete after 24 hours</span></pre></div>
<p dir="auto"><strong>Anti-Entropy Tuning:</strong></p>
<ul dir="auto">
<li><strong>Small clusters (2-3 nodes)</strong>: Use default settings (60s interval)</li>
<li><strong>Large clusters (5+ nodes)</strong>: Consider increasing interval to 120-180s to reduce network overhead</li>
<li><strong>High write throughput</strong>: Increase <code>delta_sync_threshold_transactions</code> to 50000+</li>
<li><strong>Long-running clusters</strong>: Keep <code>gc_max_retention_hours</code> at 24+ to handle extended outages</li>
</ul>
<p dir="auto"><strong>GC Configuration Rules (Validated at Startup):</strong></p>
<ul dir="auto">
<li><code>gc_min_retention_hours</code> must be &gt;= <code>delta_sync_threshold_seconds</code> (in hours)</li>
<li><code>gc_max_retention_hours</code> should be &gt;= 2x <code>delta_sync_threshold_seconds</code></li>
<li>Violating these rules will cause startup failure with helpful error messages</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Pipeline</h3><a id="user-content-query-pipeline" aria-label="Permalink: Query Pipeline" href="#query-pipeline"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[query_pipeline]
transpiler_cache_size = 10000  # LRU cache for MySQL→SQLite transpilation
validator_pool_size = 8        # SQLite connection pool for validation"><pre>[<span>query_pipeline</span>]
<span>transpiler_cache_size</span> = <span>10000</span>  <span><span>#</span> LRU cache for MySQL→SQLite transpilation</span>
<span>validator_pool_size</span> = <span>8</span>        <span><span>#</span> SQLite connection pool for validation</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">MySQL Protocol Server</h3><a id="user-content-mysql-protocol-server" aria-label="Permalink: MySQL Protocol Server" href="#mysql-protocol-server"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[mysql]
enabled = true
bind_address = &quot;0.0.0.0&quot;
port = 3306
max_connections = 1000"><pre>[<span>mysql</span>]
<span>enabled</span> = <span>true</span>
<span>bind_address</span> = <span><span>"</span>0.0.0.0<span>"</span></span>
<span>port</span> = <span>3306</span>
<span>max_connections</span> = <span>1000</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CDC Publisher</h3><a id="user-content-cdc-publisher-1" aria-label="Permalink: CDC Publisher" href="#cdc-publisher-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[publisher]
enabled = false  # Enable CDC publishing to external systems

[[publisher.sinks]]
name = &quot;kafka-main&quot;              # Unique sink name
type = &quot;kafka&quot;                   # &quot;kafka&quot; or &quot;nats&quot;
format = &quot;debezium&quot;              # Debezium-compatible JSON (only option)
brokers = [&quot;localhost:9092&quot;]     # Kafka broker addresses
topic_prefix = &quot;marmot.cdc&quot;      # Topic pattern: {prefix}.{db}.{table}
filter_tables = [&quot;*&quot;]            # Glob patterns for table filtering
filter_databases = [&quot;*&quot;]         # Glob patterns for database filtering
batch_size = 100                 # Events to read per poll cycle
poll_interval_ms = 10            # Polling interval (default: 10ms)
retry_initial_ms = 100           # Initial retry delay on failure
retry_max_ms = 30000             # Max retry delay (30 seconds)
retry_multiplier = 2.0           # Exponential backoff multiplier"><pre>[<span>publisher</span>]
<span>enabled</span> = <span>false</span>  <span><span>#</span> Enable CDC publishing to external systems</span>

[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>"</span>kafka-main<span>"</span></span>              <span><span>#</span> Unique sink name</span>
<span>type</span> = <span><span>"</span>kafka<span>"</span></span>                   <span><span>#</span> "kafka" or "nats"</span>
<span>format</span> = <span><span>"</span>debezium<span>"</span></span>              <span><span>#</span> Debezium-compatible JSON (only option)</span>
<span>brokers</span> = [<span><span>"</span>localhost:9092<span>"</span></span>]     <span><span>#</span> Kafka broker addresses</span>
<span>topic_prefix</span> = <span><span>"</span>marmot.cdc<span>"</span></span>      <span><span>#</span> Topic pattern: {prefix}.{db}.{table}</span>
<span>filter_tables</span> = [<span><span>"</span>*<span>"</span></span>]            <span><span>#</span> Glob patterns for table filtering</span>
<span>filter_databases</span> = [<span><span>"</span>*<span>"</span></span>]         <span><span>#</span> Glob patterns for database filtering</span>
<span>batch_size</span> = <span>100</span>                 <span><span>#</span> Events to read per poll cycle</span>
<span>poll_interval_ms</span> = <span>10</span>            <span><span>#</span> Polling interval (default: 10ms)</span>
<span>retry_initial_ms</span> = <span>100</span>           <span><span>#</span> Initial retry delay on failure</span>
<span>retry_max_ms</span> = <span>30000</span>             <span><span>#</span> Max retry delay (30 seconds)</span>
<span>retry_multiplier</span> = <span>2.0</span>           <span><span>#</span> Exponential backoff multiplier</span></pre></div>
<p dir="auto">See the <a href="https://maxpert.github.io/marmot/integrations" rel="nofollow">Integrations documentation</a> for details on event format, Kafka/NATS configuration, and use cases.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Logging</h3><a id="user-content-logging" aria-label="Permalink: Logging" href="#logging"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[logging]
verbose = false          # Enable verbose logging
format = &quot;console&quot;       # Log format: console or json"><pre>[<span>logging</span>]
<span>verbose</span> = <span>false</span>          <span><span>#</span> Enable verbose logging</span>
<span>format</span> = <span><span>"</span>console<span>"</span></span>       <span><span>#</span> Log format: console or json</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prometheus Metrics</h3><a id="user-content-prometheus-metrics" aria-label="Permalink: Prometheus Metrics" href="#prometheus-metrics"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[prometheus]
enabled = true  # Metrics served on gRPC port at /metrics endpoint"><pre>[<span>prometheus</span>]
<span>enabled</span> = <span>true</span>  <span><span>#</span> Metrics served on gRPC port at /metrics endpoint</span></pre></div>
<p dir="auto"><strong>Accessing Metrics:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Metrics are multiplexed with gRPC on the same port
curl http://localhost:8080/metrics

# Prometheus scrape config
scrape_configs:
  - job_name: 'marmot'
    static_configs:
      - targets: ['node1:8080', 'node2:8080', 'node3:8080']"><pre><span><span>#</span> Metrics are multiplexed with gRPC on the same port</span>
curl http://localhost:8080/metrics

<span><span>#</span> Prometheus scrape config</span>
scrape_configs:
  - job_name: <span><span>'</span>marmot<span>'</span></span>
    static_configs:
      - targets: [<span><span>'</span>node1:8080<span>'</span></span>, <span><span>'</span>node2:8080<span>'</span></span>, <span><span>'</span>node3:8080<span>'</span></span>]</pre></div>
<p dir="auto">See <code>config.toml</code> for complete configuration reference with detailed comments.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">Performance benchmarks on a local development machine (Apple M-series, 3-node cluster, single machine):</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test Configuration</h3><a id="user-content-test-configuration" aria-label="Permalink: Test Configuration" href="#test-configuration"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Nodes</td>
<td>3 (ports 3307, 3308, 3309)</td>
</tr>
<tr>
<td>Threads</td>
<td>16</td>
</tr>
<tr>
<td>Batch Size</td>
<td>10 ops/transaction</td>
</tr>
<tr>
<td>Consistency</td>
<td>QUORUM</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Load Phase (INSERT-only)</h3><a id="user-content-load-phase-insert-only" aria-label="Permalink: Load Phase (INSERT-only)" href="#load-phase-insert-only"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Throughput</td>
<td><strong>4,175 ops/sec</strong></td>
</tr>
<tr>
<td>TX Throughput</td>
<td><strong>417 tx/sec</strong></td>
</tr>
<tr>
<td>Records Loaded</td>
<td>200,000</td>
</tr>
<tr>
<td>Errors</td>
<td>0</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mixed Workload</h3><a id="user-content-mixed-workload" aria-label="Permalink: Mixed Workload" href="#mixed-workload"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Throughput</td>
<td><strong>3,370 ops/sec</strong></td>
</tr>
<tr>
<td>TX Throughput</td>
<td><strong>337 tx/sec</strong></td>
</tr>
<tr>
<td>Duration</td>
<td>120 seconds</td>
</tr>
<tr>
<td>Total Operations</td>
<td>404,930</td>
</tr>
<tr>
<td>Errors</td>
<td>0</td>
</tr>
<tr>
<td>Retries</td>
<td>37 (0.09%)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Operation Distribution:</strong></p>
<ul dir="auto">
<li>READ: 20%</li>
<li>UPDATE: 30%</li>
<li>INSERT: 35%</li>
<li>DELETE: 5%</li>
<li>UPSERT: 10%</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Latency (Mixed Workload)</h3><a id="user-content-latency-mixed-workload" aria-label="Permalink: Latency (Mixed Workload)" href="#latency-mixed-workload"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Percentile</th>
<th>Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>P50</td>
<td>4.3ms</td>
</tr>
<tr>
<td>P90</td>
<td>14.0ms</td>
</tr>
<tr>
<td>P95</td>
<td>36.8ms</td>
</tr>
<tr>
<td>P99</td>
<td>85.1ms</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Replication Verification</h3><a id="user-content-replication-verification" aria-label="Permalink: Replication Verification" href="#replication-verification"></a></p>
<p dir="auto">All 3 nodes maintained identical row counts (346,684 rows) throughout the test, confirming consistent replication.</p>
<blockquote>
<p dir="auto"><strong>Note</strong>: These benchmarks are from a local development machine with all nodes on the same host. Production deployments across multiple machines will have different characteristics based on network latency.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQs &amp; Community</h2><a id="user-content-faqs--community" aria-label="Permalink: FAQs &amp; Community" href="#faqs--community"></a></p>
<ul dir="auto">
<li>For FAQs visit <a href="https://maxpert.github.io/marmot/intro#faq" rel="nofollow">this page</a></li>
<li>For community visit our <a href="https://discord.gg/AWUwY66XsE" rel="nofollow">discord</a> or discussions on GitHub</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Happy Public Domain Day 2026 (273 pts)]]></title>
            <link>https://publicdomainreview.org/blog/2026/01/public-domain-day-2026/</link>
            <guid>46460440</guid>
            <pubDate>Fri, 02 Jan 2026 01:42:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://publicdomainreview.org/blog/2026/01/public-domain-day-2026/">https://publicdomainreview.org/blog/2026/01/public-domain-day-2026/</a>, See on <a href="https://news.ycombinator.com/item?id=46460440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="img-0"><a href="#img-0"><svg width="24" height="24" viewBox="0 0 24 24"><path d="M8,15 C8.55228475,15 9,15.4477153 9,16 C9,16.5522847 8.55228475,17 8,17 L6.5,17 C4.01471863,17 2,14.9852814 2,12.5 C2,10.0147186 4.01471863,8 6.5,8 L10.5,8 C12.9852814,8 15,10.0147186 15,12.5 C15,12.7389847 14.9812814,12.9760008 14.9442505,13.2094168 C14.8577141,13.7548798 14.3453774,14.1269133 13.7999144,14.040377 C13.2544514,13.9538406 12.8824178,13.4415038 12.9689542,12.8960408 C12.9895566,12.7661784 13,12.633943 13,12.5 C13,11.1192881 11.8807119,10 10.5,10 L6.5,10 C5.11928813,10 4,11.1192881 4,12.5 C4,13.8807119 5.11928813,15 6.5,15 L8,15 Z M16,10 C15.4477153,10 15,9.55228475 15,9 C15,8.44771525 15.4477153,8 16,8 L17.5,8 C19.9852814,8 22,10.0147186 22,12.5 C22,14.9852814 19.9852814,17 17.5,17 L13.5,17 C11.0147186,17 9,14.9852814 9,12.5 C9,12.2610153 9.01871861,12.0239992 9.05574949,11.7905832 C9.14228587,11.2451202 9.65462261,10.8730867 10.2000856,10.959623 C10.7455486,11.0461594 11.1175822,11.5584962 11.0310458,12.1039592 C11.0104434,12.2338216 11,12.366057 11,12.5 C11,13.8807119 12.1192881,15 13.5,15 L17.5,15 C18.8807119,15 20,13.8807119 20,12.5 C20,11.1192881 18.8807119,10 17.5,10 L16,10 Z"></path></svg></a><p><img src="https://pdr-assets.b-cdn.net/blog/2026/public-domain-in-2026.jpg?width=1200&amp;height=850" data-blursrc="https://pdr-assets.b-cdn.net/blog/2026/public-domain-in-2026.jpg?width=1200&amp;height=850&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/blog/2026/public-domain-in-2026.jpg?width=1200&amp;height=850" alt=""><span>Scroll through the whole page to download all images before printing.</span></p></div><div><p>The calendar turns, and once again a lively procession of books, images, films, and music leaves copyright behind and steps into the ever-growing public domain! On this year's Public Domain Day (which falls each January 1st) we welcome, in lots of countries around the world, the words of Wallace Stevens, Thomas Mann, Hannah Arendt, and Albert Einstein, and in the US a bevy of brilliant books including William Faulkner’s <em>As I Lay Dying</em>, Langston Hughes’ <em>Not Without Laughter</em>, Agatha Christie’s <em>The Murder at the Vicarage</em>, and, in their original German, Robert Musil’s <em>The Man Without Qualities</em> and Hermann Hesse’s <em>Narcissus and Goldmund</em>.</p></div><div><p>Due to differing copyright laws around the world, there is no one single public domain, but there are three main types of copyright term for historical works which cover most cases. For these three systems, newly entering the public domain today are: </p></div><div><ul><li><a href="https://en.wikipedia.org/wiki/2026_in_public_domain#Entering_the_public_domain_in_countries_with_life_+_70_years">works by people who died in 1955</a>, for countries with a copyright term of “life plus 70 years” (relevant in UK, most of the EU, and South America);</li><li><a href="https://en.wikipedia.org/wiki/2026_in_public_domain#Entering_the_public_domain_in_countries_with_life_+_50_years">works by people who died in 1975</a>, for countries with a term of “life plus 50 years” (relevant to most of Africa and Asia);</li><li><a href="https://en.wikipedia.org/wiki/1930_in_film">films</a> and <a href="https://en.wikipedia.org/wiki/1930_in_literature#New_books">books</a> (incl. artworks featured) published in 1929 (relevant solely to the United States).</li></ul></div><div><p>Some of you may have been following <a href="https://publicdomainreview.org/features/entering-the-public-domain/2026/">our advent-style countdown calendar</a> which revealed day-by-day through December our highlights for these new public domain entrants. The last window was opened yesterday, and while such a format was fun for the slow reveal, for the sake of a good gorgeable list we’ve exploded the calendar out into a digestible array below. Enjoy!</p></div><div><p><h2><span>Entering the public domain in the US</span></h2></p></div><div id="side-by-side-1"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/as-i-lay-dying.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/as-i-lay-dying.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/as-i-lay-dying.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>William Faulkner – <i>As I Lay Dying</i></h3><div><p><i>As I Lay Dying</i> is a Southern Gothic novel by American author William Faulkner, consistently ranked among the best novels of the 20th century. The title is derived from William Marris’s 1925 translation of Homer’s <i>Odyssey</i>, referring to the similar themes of both works.</p><p>The novel traces the story of the death of Addie Bundren and her poor, rural family’s quest to honor her wish to be buried in her hometown of Jefferson, Mississippi, as well as the motives—noble or selfish—they show on the journey. It uses a stream-of-consciousness writing technique and varying chapter lengths, and is narrated by 15 different characters over 59 chapters.</p><p>Faulkner said that he wrote the novel from midnight to 4:00 a.m. over the course of six weeks and that he did not change a word of it. He spent the first eight hours of his twelve-hour shift at the University of Mississippi Power House shoveling coal or directing other works and the remaining four hours handwriting his manuscript on unlined onionskin paper. <i>As I Lay Dying</i> represents a progenitor of the Southern Renaissance, reflecting on being, existence, and other existential metaphysics of everyday life, and helped to solidify Faulkner’s reputation as a pioneer, like James Joyce and Virginia Woolf, of stream of consciousness. (<a href="https://en.wikipedia.org/wiki/As_I_Lay_Dying" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://fadedpage.com/showbook.php?pid=20171024" target="_blank" rel="noopener noreferrer">Faded Page</a> and <a href="https://standardebooks.org/ebooks/william-faulkner/as-i-lay-dying" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-2"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/swallows-and-amazons.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/swallows-and-amazons.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/swallows-and-amazons.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Arthur Ransome - <i>Swallows and Amazons</i></h3><div><p><i>Swallows and Amazons</i> is a children’s adventure novel by English author Arthur Ransome. It is the first book in the <i>Swallows and Amazons</i> series, followed by <i>Swallowdale</i>.</p><p>Set in the summer of 1929 in England’s Lake District, the book relates the outdoor adventures and play of two families of children. These involve sailing, camping, fishing, exploration and piracy. The Walker children (John, Susan, Titty and Roger) are staying at a farm near a lake in the Lake District of England, during the school holidays. They sail a borrowed dinghy named <i>Swallow</i> and meet the Blackett children (Nancy and Peggy), who sail a dinghy named <i>Amazon</i>. When the children meet, they agree to join forces against a common enemy – the Blacketts’ uncle Jim Turner whom they call “Captain Flint” (after the parrot in <i>Treasure Island</i>).</p><p>The book was inspired by a summer spent by Ransome teaching the children of his friends, the Altounyans, to sail. At the time, Ransome had been working as a journalist with the <i>Manchester Guardian</i>, but decided to become a full-time author rather than go abroad as a foreign correspondent. Three of the Altounyan children’s names are adopted directly for the Walker family. However, later in life Ransome tried to downplay the Altounyan connections, changing the initial dedication of <i>Swallows and Amazons</i> and writing a new foreword which gave other sources. (<a href="https://en.wikipedia.org/wiki/Swallows_and_Amazons" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://fadedpage.com/showbook.php?pid=20180107" target="_blank" rel="noopener noreferrer">Faded Page</a> and <a href="https://standardebooks.org/ebooks/arthur-ransome/swallows-and-amazons" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-4"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/not-without-laughter.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/not-without-laughter.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/not-without-laughter.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Langston Hughes – <i>Not Without Laughter</i></h3><div><p>Not Without Laughter* is the debut novel of Langston Hughes, the American writer, activist, and leader of the Harlem Renaissance.</p><p>The novel portrays African-American life in Kansas in the 1910s, focusing on the effects of class and religion on the community. In telling the story of Sandy Rogers, a young African American boy in small-town Kansas, and of his family—his mother, Annjee, a housekeeper for a wealthy white family; his irresponsible father, Jimboy, who plays the guitar and travels the country in search of employment; his strong-willed grandmother Hager, who clings to her faith; his Aunt Tempy, who marries a rich man; and his Aunt Harriet, who struggles to make it as a blues singer—Hughes gives the longings and lineaments of Black life in the early twentieth century an important place in the history of racially divided America.</p><p>Hughes said that *Not Without Laughter* is semi-autobiographical, and that a good portion of the characters and setting included in the novel are based on his memories of growing up in Lawrence, Kansas. A review in *The New York Times* said that the novel is “very slow, even tedious, reading in its early chapters, but once it gains its momentum it moves as swiftly as a jazz rhythm”. (<a href="https://en.wikipedia.org/wiki/Not_Without_Laughter" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://www.fadedpage.com/showbook.php?pid=20240413" target="_blank" rel="noopener noreferrer">Faded Page</a> and <a href="https://standardebooks.org/ebooks/langston-hughes/not-without-laughter" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-5"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/narcissus-and-goldmund.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/narcissus-and-goldmund.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/narcissus-and-goldmund.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Hermann Hesse – <i>Narcissus and Goldmund</i></h3><div><p><i>Narcissus and Goldmund</i> (in German, <i>Narziß und Goldmund</i>), also published in English as <i>Death and the Lover</i>, is a novel written by the German-Swiss author Hermann Hesse. At its publication, it was considered Hesse’s literary triumph.</p><p>The novel is the story of a young man, Goldmund (German for “Gold mouth”), who wanders aimlessly throughout Medieval Germany after leaving a Catholic monastery school in search of what could be described as “the meaning of life”. With the help of Narcissus, a gifted young teacher, and following an epiphanic experience with a beautiful Gypsy woman, Goldmund leaves the monastery and embarks on a wandering existence. He has numerous love affairs, studies art, and encounters human existence at its ugliest when the Black Death devastates the region. Eventually, he is reunited with his friend Narcissus, now an abbot.</p><p>Like most of Hesse’s works, the main theme of this book is the wanderer’s struggle to find himself, as well as the Jungian union of polar opposites (<i>Mysterium Coniunctionis</i>). Goldmund represents nature and the “feminine conscious mind” (but also <i>anima</i>, a man’s unconscious), while Narcissus represents science and logic and God and the “masculine conscious mind” (but also <i>animus</i>, a woman’s unconscious).</p><p>A film adaptation, directed by the Austrian Oscar-winning director Stefan Ruzowitzky, was released in 2020. (<a href="https://en.wikipedia.org/wiki/Narcissus_and_Goldmund" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-6"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/all-quiet-on-the-western-front.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/all-quiet-on-the-western-front.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/all-quiet-on-the-western-front.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>All Quiet on the Western Front (1930 film)</h3><div><p><i>All Quiet on the Western Front</i> is a 1930 American pre-Code epic anti-war film based on the 1929 novel of the same name by German novelist Erich Maria Remarque. Directed by Lewis Milestone, it stars Lew Ayres, Louis Wolheim, John Wray, Slim Summerville, and William Bakewell.</p><p>The movie follows a group of German students moved to enlist in the army as part of the new 2nd Company. Their romantic delusions are quickly shattered during their brief but rigorous training under the abusive Sergeant Himmelstoss. After being sent to the Western Front, their idealism is destroyed by the harsh realities of combat.</p><p>Considered a realistic and harrowing account of warfare in World War I, the film opened to wide acclaim in the United States and made the American Film Institute’s first <i>100 Years... 100 Movies</i> list in 1997. (<a href="https://en.wikipedia.org/wiki/All_Quiet_on_the_Western_Front_(1930_film)" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://fadedpage.com/showbook.php?pid=20190146" target="_blank" rel="noopener noreferrer">Faded Page</a></span></p></div></div><div id="side-by-side-7"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/vile-bodies.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/vile-bodies.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/vile-bodies.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Evelyn Waugh – <i>Vile Bodies</i></h3><div><p><i>Vile Bodies</i> is the second novel by Arthur Evelyn St. John Waugh, an English writer of novels, biographies, and travel books, and a prolific journalist and book reviewer. It satirises London’s post–First World War “bright young things” — a group of Bohemian young aristocrats and socialites in London — and the press coverage around them. Waugh originally considered the title <i>Bright Young Things</i> but changed it; the published title echoes a narrator’s remark on crowds and parties: “Those vile bodies”.</p><p>The novel follows a vivid assortment of characters, among them the struggling writer Adam Fenwick-Symes and the glamorous, aristocratic Nina Blount, who hunt fast and furiously for ever greater sensations and the hedonistic fulfillment of their desires. Waugh’s acidly funny satire reveals the darkness and vulnerability beneath the sparkling surface of the high life.</p><p>The book shifts in tone from light-hearted romp to bleak desolation (Waugh himself later attributed it to the breakdown of his first marriage halfway through the book’s composition). Critics have noted the novel’s fragmented scenes, jump-cuts, and telephone dialogue, often linking its method to cinema and to modernist effects. Some have defended the novel’s downbeat ending as a poetically just reversal of the conventions of comic romance.</p><p>David Bowie cited the novel as the primary influence in writing his song “Aladdin Sane”, and a film adaptation, written and directed by Stephen Fry, was released in 2003. (<a href="https://en.wikipedia.org/wiki/Vile_Bodies" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://fadedpage.com/showbook.php?pid=20190146" target="_blank" rel="noopener noreferrer">Faded Page</a> and <a href="https://standardebooks.org/ebooks/evelyn-waugh/vile-bodies" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-8"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/years-of-grace.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/years-of-grace.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/years-of-grace.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Margaret Ayer Barnes - <i>Years of Grace</i></h3><div><p><i>Years of Grace</i> is the first book by the American playwright, novelist, and short-story writer Margaret Ayer Barnes. It won the Pulitzer Prize for the Novel in 1931.</p><p>The story, beginning in the 1890s and continuing into the 1930s, chronicles the life of Jane Ward Carver from her teens to age 54. This novel follows many of the same themes as Barnes’s other works. Centering on the social manners of upper middle class society, her female protagonists are often traditionalists, struggling to uphold conventional morality in the face of changing social climates. Barnes’s alma mater Bryn Mawr College, along with the characters of college presidents M. Carey Thomas and Marion Park, figure prominently in this work.</p><p><i>The New York Times</i> commented that “this story of the death of an old order and the birth of a new one, of the perpetually renewed conflict between succeeding generations... holds the reader’s attention to the end.” Despite the success of <i>Years of Grace</i>, it is not Barnes’s best-known work; that honor belongs to <i>Dishonored Lady</i>, a play she co-wrote with Edward Sheldon, which was adapted twice into film. (<a href="https://en.wikipedia.org/wiki/Years_of_Grace" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read free ebook through <a href="https://standardebooks.org/ebooks/margaret-ayer-barnes/years-of-grace" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-9"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/hellbound-train.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/hellbound-train.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/hellbound-train.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Hellbound Train</h3><p><i>Hell-Bound Train</i> is a 1930 film written and directed by James and Eloyce Gist. A self-taught husband-and-wife team with a shared religious mission, they produced at least three silent films for African American church audiences, touring them across the United States. Shown alongside sermons, these works used cinema as a vehicle for evangelism. In <i>Hell-Bound Train</i> — which Eloyce is said to have rewritten, re-edited, and partly refilmed after James’s initial version — the viewer passes from carriage to carriage as the filmmakers stage various “Jazz Age” sins, including dancing, drinking, and gambling, all overseen by a mischievous devil conductor. Though <i>Hell-Bound Train</i> has gained some renewed attention via Kino Lorber’s <i>Pioneers of African-American Cinema</i> box set and a brief run on the Criterion Channel, this film — one of the few surviving silent works by an African American woman — is still often absent from retrospectives on early women filmmakers, perhaps because of its modest production values and overtly moralizing tone. (<a href="https://en.wikipedia.org/wiki/Eloyce_King_Patrick_Gist" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p><hr><p><span>Watch on <a href="https://www.youtube.com/watch?v=9ucG8Xex2AI" target="_blank" rel="noopener noreferrer">YouTube</a></span></p></div></div><div id="side-by-side-10"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-man-without-qualities.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-man-without-qualities.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-man-without-qualities.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Robert Musil – <i>The Man Without Qualities</i></h3><div><p><i>The Man Without Qualities</i> (in German <i>Der Mann ohne Eigenschaften</i>) is an unfinished modernist novel in three volumes and various drafts, by the Austrian writer Robert Musil, published in parts from 1930 to 1943.</p><p>The novel is a “story of ideas”, which takes place in the time of the Austro-Hungarian monarchy’s last days. The plot often veers into allegorical digressions on a wide range of existential themes concerning humanity and feelings. It has a particular concern with the values of truth and opinion and how society organizes ideas about life and society. The book is well over a thousand pages long in its entirety, and no one single theme dominates.</p><p>The story takes place in 1913 in Vienna, the capital of Austria-Hungary, which Musil refers to by the playful term Kakanien. Part I, titled <i>A Sort of Introduction</i>, is an introduction to the protagonist, a mathematician named Ulrich whose ambivalence towards morals and indifference to life make him “a man without qualities”. In Part II, <i>Pseudoreality Prevails</i>, Ulrich joins preparations for a celebration in honor of 70 years of the Austrian Emperor Franz Joseph’s reign. Part III, entitled <i>Into the Millennium (The Criminals)</i>, is about Ulrich’s sister Agathe. They experience a mystically incestuous stirring upon meeting after their father’s death.</p><p>Musil worked on the novel for more than twenty years: his detailed portrait of a decaying <i>fin de siècle</i> world has strong autobiographical features. Musil’s almost daily preoccupation with writing left his family in dire financial straits. (<a href="https://en.wikipedia.org/wiki/The_Man_Without_Qualities" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read German original on <a href="https://www.projekt-gutenberg.org/musil/mannohne/mannohne.html" target="_blank" rel="noopener noreferrer">Project Gutenberg</a></span></p></div></div><div id="side-by-side-11"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/ash-wednesday.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/ash-wednesday.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/ash-wednesday.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>T. S. Eliot – <i>Ash Wednesday</i></h3><div><p><i>Ash Wednesday</i> is a long poem written by T. S. Eliot during his 1927 conversion to Anglicanism. Published in 1930, the poem deals with the struggle that ensues when one who has lacked faith in the past strives to move towards God.</p><p>Sometimes referred to as Eliot’s “conversion poem”, <i>Ash Wednesday</i>, with a base of Dante’s <i>Purgatorio</i>, is richly but ambiguously allusive and deals with the move from spiritual barrenness to hope for human salvation. The style is different from his poetry which predates his conversion. <i>Ash Wednesday</i> and the poems that followed had a more casual, melodic, and contemplative method.</p><p>The poem’s title comes from the Western Christian fast day that marks the beginning of Lent, forty days before Easter. It is a poem about the difficulty of religious belief, and concerned with personal salvation in an age of uncertainty. In it, Eliot’s poetic persona, one who has lacked faith in the past, has somehow found the courage, through spiritual exhaustion, to seek faith.</p><p>The initial reception of <i>Ash Wednesday</i> was largely positive, though many of the more secular literati found its groundwork of orthodox Christianity discomfiting. Edwin Muir maintained that “‘Ash Wednesday’ is one of the most moving poems he [Eliot] has written, and perhaps the most perfect”. (<a href="https://en.wikipedia.org/wiki/Ash_Wednesday_(poem)" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://englishverse.com/poems/ash_wednesday" target="_blank" rel="noopener noreferrer">English Verse</a> and <a href="https://standardebooks.org/ebooks/t-s-eliot/poetry/text/poetry#ash-wednesday" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-12"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-murder-at-the-vicarage.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-murder-at-the-vicarage.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-murder-at-the-vicarage.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Agatha Christie - <i>The Murder at the Vicarage</i></h3><div><p><i>The Murder at the Vicarage</i> is a work of detective fiction by the British writer Agatha Christie. It is the first novel to feature the character of Miss Marple and her village of St Mary Mead (characters that had previously appeared in short stories).</p><p>The story is set in the quiet English village of St Mary Mead, where life is seemingly peaceful until Colonel Protheroe, the local magistrate and a widely disliked man, is found shot dead in the vicar’s study. The vicar, Leonard Clement, is the narrator of the story. Just before the murder, he had remarked that “anyone who murdered Colonel Protheroe would be doing the world a service” — a comment that comes back to haunt him.</p><p>Several suspects quickly emerge, as well as Miss Marple, who proves, though she appears at first as a nosy old spinster, to have unmatched observational skills and a deep understanding of human nature. (<a href="https://en.wikipedia.org/wiki/The_Murder_at_the_Vicarage" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read free ebook through <a href="https://standardebooks.org/ebooks/agatha-christie/the-murder-at-the-vicarage" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-13"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-castle.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-castle.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-castle.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Franz Kafka - <i>The Castle</i> (english translation)</h3><p><i>The Castle</i> (in German, *Das Schloss*) is a 1926 novel by Franz Kafka. In it a protagonist known only as “K.” arrives in a village and struggles to gain access to the mysterious authorities who govern it from a castle supposedly owned by Count Westwest. Kafka died before he could finish the work, but suggested it would end with K. dying in the village, the castle notifying him on his death bed that his “legal claim to live in the village was not valid, yet, taking certain auxiliary circumstances into account, he was permitted to live and work there.” Dark and at times surreal, *The Castle* is often understood to be about alienation, unresponsive bureaucracy, the frustration of trying to conduct business with non-transparent, seemingly arbitrary controlling systems, and the futile pursuit of an unobtainable goal. (<a href="https://en.wikipedia.org/wiki/The_Castle_(novel)" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p><hr><p><span>Read free ebook through <a href="https://standardebooks.org/ebooks/franz-kafka/the-castle/willa-muir_edwin-muir" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-14"><h3><a href="https://standardebooks.org/ebooks/franz-kafka/the-castle/willa-muir_edwin-muir" target="_blank" rel="noopener noreferrer">Sigmund Freud – <i>Civilization and Its Discontents</i></a></h3><p><a href="https://standardebooks.org/ebooks/franz-kafka/the-castle/willa-muir_edwin-muir" target="_blank" rel="noopener noreferrer"><i>Civilization and Its Discontents</i> is a book by Sigmund Freud, the founder of psychoanalysis. It was written in 1929 and first published in German in 1930 as <i>Das Unbehagen in der Kultur</i> (“The Uneasiness in Civilization”).<p>Exploring what Freud saw as a clash between the desire for individuality and the expectations of society, the book is considered one of Freud’s most important and widely read works, and was described in 1989 by historian Peter Gay as one of the most influential and studied books in the field of modern psychology.</p><p>The book espouses a theory grounded in the notion that humans have certain characteristic instincts that are immutable. The primary tension originates from an individual attempting to find instinctive freedom, and civilization’s contrary demand for conformity and repression of instincts. Freud states that when any situation that is desired by the pleasure principle is prolonged, it creates a feeling of mild resentment as it clashes with the reality principle.</p><p>Primitive instincts—for example, the desire to kill and the insatiable craving for sexual gratification—are harmful to the collective wellbeing of a human community. The historical development of laws that prohibit violence, murder, rape, and adultery, he argued, is an inherent quality of civilization that gives rise to perpetual feelings of discontent among individuals. (</p></a><a href="https://en.wikipedia.org/wiki/Civilization_and_Its_Discontents" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><div id="side-by-side-15"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-far-away-bride.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-far-away-bride.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-far-away-bride.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Stella Benson - <i>The Far-Away Bride</i></h3><div><p><i>The Far-Away Bride</i> is the most famous book by the English feminist, novelist, poet, and travel writer Stella Benson. It was published in the United States first in 1930 and as <i>Tobit Transplanted</i> in Britain in 1931. It won the Femina Vie Heureuse Prize for English writers in 1932.</p><p>The novel deals with a family of Russian émigrés in Manchuria. Its characters are the old, grumbling and tearfully sentimental Russian intellectual, Malinin; his disheveled, kind-hearted and unbearable wife, Anna; and Seryozha, their resourceful 19-year-old son. Spending their time in laziness, indulging in exaggerated Russian disorder and comical quarrels growing out of every trifle, they are incongruously happy. The humorous and adventurous action of the novel starts when Seryozha sets out, on foot, on a business trip to the Korean city of Seoul (where he must recover 200 yens); it is there that he finds his “far-away bride” — a charming and whimsical Russian girl who has already broken seven hearts and whose heart he finally conquers.</p><p>Benson described the novel as an “accurate modernization” of the <i>Book of Tobit</i>, a work of Second Temple Jewish literature dating to the 3rd or early 2nd century BC; <i>The New York Times</i> described <i>The Far-Away Bride</i>, rather, as a “spirited parody of it.” Benson’s novel, writes the reviewer, is “a truly felicitous comedy of the human personality”. (<a href="https://en.wikipedia.org/wiki/Stella_Benson" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-16"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-defense.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-defense.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-defense.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Vladimir Nabokov - <i>The Defense</i></h3><div><p><i>The Defense</i> (in Russian, <i>Zashchita Luzhinais</i>) is the third novel written by Vladimir Nabokov after he had emigrated to Berlin. It appeared first under Nabokov’s pen name V. Sirin in the Russian émigré quarterly <i>Sovremennye zapiski</i> and was thereafter published by the émigré publishing house Slovo as <i>The Luzhin Defense</i> in Berlin.</p><p>The novel tells the story of Luzhin. As a young boy, unattractive, withdrawn, sullen, he takes up chess as a refuge from the anxiety of his everyday life. His talent is prodigious and he rises to the rank of grandmaster, but at a cost: in Luzhin’s obsessive mind, the game of chess gradually supplants the world of reality. His own world falls apart during a crucial championship match, when the intricate defense he has devised withers under his opponent’s unexpected and unpredictable lines of assault.</p><p>The character of Luzhin is based on Curt von Bardeleben, a chess master Nabokov knew personally, and Nabokov links the events in the central chapters to moves as encountered in chess problems. The book was adapted to film in 2000, as <i>The Luzhin Defence</i>. It was directed by Marleen Gorris, and starred John Turturro as Luzhin. (<a href="https://en.wikipedia.org/wiki/The_Defense" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-17"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-maltese-falcon.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/the-maltese-falcon.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/the-maltese-falcon.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Dashiell Hammett – <i>The Maltese Falcon</i></h3><div><p><i>The Maltese Falcon</i> is a detective novel by American writer Dashiell Hammett, originally serialized in the magazine <i>Black Mask</i> beginning with the September 1929 issue. The story is told entirely in external third-person narrative; there is no description whatsoever of any character’s thoughts or feelings, only what they say and do, and how they look. The novel has been adapted several times for the cinema and is considered part of the hardboiled genre, which Hammett played a major part in popularizing.</p><p>The novel follows Sam Spade, a private detective in San Francisco, in partnership with Miles Archer. The beautiful “Miss Wonderley” hires them to follow Floyd Thursby, who she claims has run off with her sister. Archer takes the first stint but is found shot dead that night. “Miss Wonderley” is soon revealed to be an acquisitive adventuress named Brigid O’Shaughnessy, who is involved in the search for a black statuette of unknown but substantial value. Red herrings abound.</p><p>Although Hammett himself worked for a time as a private detective for the Pinkerton Detective Agency in San Francisco (and used his given name, Samuel, for the story’s protagonist), Hammett asserted that “Spade has no original. He is a dream man in the sense that he is what most of the private detectives I worked with would like to have been, and, in their cockier moments, thought they approached.” (<a href="https://en.wikipedia.org/wiki/The_Maltese_Falcon_(novel)" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read on <a href="https://fadedpage.com/showbook.php?pid=20161221" target="_blank" rel="noopener noreferrer">Faded Page</a> and <a href="https://standardebooks.org/ebooks/dashiell-hammett/the-maltese-falcon" target="_blank" rel="noopener noreferrer">Standard Books</a></span></p></div></div><div id="side-by-side-18"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/insatiability.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/insatiability.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/insatiability.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Stanisław Ignacy Witkiewicz – <i>Insatiability</i></h3><div><p><i>Insatiability</i> (in Polish <i>Nienasycenie</i>) is a speculative fiction novel by the Polish writer, dramatist, philosopher, painter and photographer, Stanisław Ignacy Witkiewicz (Witkacy). It is Witkiewicz’s third novel, considered by some to be his best.</p><p>Consisting of two parts — <i>Przebudzenie</i> (Awakening) and <i>Obłęd</i> (The Madness) — the novel takes place in the future, circa 2000. Following a battle, modeled after the Bolshevik revolution, Poland is overrun by the army of the last and final Mongol conquest. The nation becomes enslaved to the Chinese leader Murti Bing. His emissaries give everyone a special pill called DAVAMESK B 2 which takes away their abilities to think and to mentally resist. East and West become one, in faceless misery fueled by sexual instincts.</p><p>The book combines chaotic action with deep philosophical and political discussion, and predicts many of the events and political outcomes of the subsequent years, specifically, the invasion of Poland, the postwar foreign domination as well as the totalitarian mind control exerted, first by the Germans, and then by the Soviet Union on Polish life and art. (<a href="https://en.wikipedia.org/wiki/Insatiability" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Read more about Witkiewicz’s artworks in our essay <a href="https://publicdomainreview.org/essay/documenting-drugs/">“Documenting Drugs” by Juliette Bretan</a></span></p></div></div><div><p><h2><span>Entering the public domain in countries with a ‘life plus 70 year’ copyright term</span></h2></p></div><div id="side-by-side-19"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/albert-einstein.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/albert-einstein.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/albert-einstein.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Albert Einstein</h3><div><p>Albert Einstein was a German-born theoretical physicist best known for developing the theory of relativity. Einstein also made important contributions to quantum theory. His mass–energy equivalence formula E = mc^2, which arises from special relativity, has been called “the world’s most famous equation”. He received the 1921 Nobel Prize in Physics for “his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect”.</p><p>In 1905, sometimes described as his *annus mirabilis* (miracle year), he published four groundbreaking papers. In them, he outlined a theory of the photoelectric effect, explained Brownian motion, introduced his special theory of relativity, and demonstrated that if the special theory is correct, mass and energy are equivalent to each other. In 1915, he proposed a general theory of relativity that extended his system of mechanics to incorporate gravitation. A cosmological paper that he published the following year laid out the implications of general relativity for the modeling of the structure and evolution of the universe as a whole. In 1917, Einstein introduced the concepts of spontaneous emission and stimulated emission, the latter of which is the core mechanism behind the laser and maser, and which helped lay the groundwork for later developments in physics such as quantum electrodynamics and quantum optics. (<a href="https://en.wikipedia.org/wiki/Albert_Einstein" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Works at <a href="https://en.wikisource.org/wiki/Author:Albert_Einstein" target="_blank" rel="noopener noreferrer">Wikisource</a></span></p></div></div><div id="side-by-side-20"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/wallace-stevens.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/wallace-stevens.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/wallace-stevens.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Wallace Stevens</h3><div><p>Wallace Stevens was an American modernist poet. He was born in Reading, Pennsylvania, educated at Harvard and then New York Law School, and spent most of his life working as an executive for an insurance company in Hartford, Connecticut.</p><p>Stevens’s first period begins with the publication of <i>Harmonium</i> (1923), followed by a slightly revised and amended second edition in 1930. It features, among other poems, “The Emperor of Ice-Cream”, “Sunday Morning”, “The Snow Man”, and “Thirteen Ways of Looking at a Blackbird”. His second period commenced with <i>Ideas of Order</i> (1933), included in <i>Transport to Summer</i> (1947). His third and final period began with the publication of <i>The Auroras of Autumn</i> (1950), followed by <i>The Necessary Angel: Essays On Reality and the Imagination</i> (1951).</p><p>Many of Stevens’s poems deal with the making of art and poetry in particular. His <i>Collected Poems</i> (1954) won the Pulitzer Prize for Poetry in 1955 and Stevens is a rare example of a poet whose main output came largely only as he approached 40 years of age. His first major publication (four poems from a sequence titled “Phases” in the November 1914 edition of <i>Poetry</i>) was written at age 35, although as an undergraduate at Harvard, Stevens had written poetry and exchanged sonnets with Santayana. Many of his canonical works were written well after he turned 50. According to the literary scholar Harold Bloom, no Western writer since Sophocles has had such a late flowering of artistic genius. (<a href="https://en.wikipedia.org/wiki/Wallace_Stevens" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-21"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/charlie-parker.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/charlie-parker.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/charlie-parker.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Charlie Parker</h3><div><p>Charles Parker Jr. was an American jazz saxophonist, bandleader, and composer. Parker was a highly influential soloist and leading figure in the development of bebop, a form of jazz characterized by fast tempos, virtuosic technique, and advanced harmonies. He was a virtuoso and introduced revolutionary rhythmic and harmonic ideas into jazz, including rapid passing chords, new variants of altered chords, and chord substitutions. Parker primarily played the alto saxophone.</p><p>Parker was an icon for the hipster subculture and later the Beat Generation, personifying the jazz musician as an uncompromising artist and intellectual rather than just an entertainer.</p><p>His style of composition involved interpolation of original melodies over existing jazz forms and standards, a practice known as contrafact and still common in jazz today. Examples include “Ornithology” (which borrows the chord progression of jazz standard “How High the Moon” and is said to be co-written with trumpet player Little Benny Harris), and “Moose The Mooche”. The practice was not uncommon prior to bebop, but it became a signature of the movement as artists began to move away from arranging popular standards and toward composing their own material. Parker contributed greatly to the modern jazz solo, one in which triplets and pick-up notes were used in unorthodox ways to lead into chord tones.</p><p>Miles Davis once said, “You can tell the history of jazz in four words: Louis Armstrong. Charlie Parker.” (<a href="https://en.wikipedia.org/wiki/Charlie_Parker" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-22"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/thomas-mann.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/thomas-mann.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/thomas-mann.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Thomas Mann</h3><div><p>Paul Thomas Mann was a German novelist, short story writer, social critic, philanthropist, essayist, and the 1929 Nobel Prize in Literature laureate. His highly symbolic and ironic epic novels and novellas are noted for their insight into the psychology of the artist and the intellectual. His analysis and critique of the European and German soul used modernized versions of German and Biblical stories, as well as the ideas of Johann Wolfgang von Goethe, Friedrich Nietzsche, and Arthur Schopenhauer.</p><p>Mann was a member of the hanseatic Mann family and portrayed his family and class in his first novel, <i>Buddenbrooks</i> (1901). Further major novels include <i>The Magic Mountain</i> (1924), the tetralogy <i>Joseph and His Brothers</i> (1933–1943), and <i>Doctor Faustus</i> (1947); he also wrote short stories and novellas, including <i>Death in Venice</i> (1912).</p><p>When Adolf Hitler came to power in 1933, Mann fled to Switzerland and when World War II broke out in 1939, he moved to the United States, then returned to Switzerland in 1952. Mann is one of the best-known exponents of the so-called <i>Exilliteratur</i>, German literature written in exile by those who opposed the Hitler regime. (<a href="https://en.wikipedia.org/wiki/Thomas_Mann" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Works at <a href="https://www.gutenberg.org/ebooks/author/4200" target="_blank" rel="noopener noreferrer">Project Gutenberg</a></span></p></div></div><div id="side-by-side-23"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/pierre-teilhard-de-chardin.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/pierre-teilhard-de-chardin.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/pierre-teilhard-de-chardin.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Pierre Teilhard de Chardin</h3><div><p>Pierre Teilhard de Chardin was a French Jesuit, Catholic priest, scientist, paleontologist, philosopher, mystic, and teacher. He investigated the theory of evolution from a perspective influenced by Henri Bergson and Christian mysticism, writing multiple scientific and religious works on the subject, his most popular being <i>The Phenomenon of Man</i>, published posthumously in 1955. His mainstream scientific achievements include his palaeontological research in China, taking part in the discovery of the significant Peking Man fossils from the Zhoukoudian cave complex near Beijing. His more speculative ideas, sometimes criticized as pseudoscientific, have included a vitalist conception of the Omega Point. Along with Vladimir Vernadsky, he contributed to the development of the concept of the noosphere.</p><p>In 1962, the Holy Office issued a warning regarding Teilhard’s works, alleging ambiguities and doctrinal errors without specifying them. Some eminent Catholic figures, including Pope Benedict XVI and Pope Francis, have made positive comments on some of his ideas since. The response to his writings by scientists has been divided. His work was controversial to some scientists and religious leaders because Teilhard combined theology and metaphysics with science.</p><p>Teilhard served in World War I as a stretcher-bearer. He received several citations, and was awarded the Médaille militaire and the Legion of Honor, the highest French order of merit, both military and civil. (<a href="https://en.wikipedia.org/wiki/Pierre_Teilhard_de_Chardin" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-24"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/roger-mais.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/roger-mais.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/roger-mais.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Roger Mais</h3><div><p>Roger Mais was a Jamaican journalist, novelist, poet, and playwright. He was born to a middle-class family in Kingston, Jamaica. By 1951, he had won ten first prizes in West Indian literary competitions. His integral role in the development of political and cultural nationalism is evidenced in his being awarded the high honour of the Order of Jamaica in 1978.</p><p>He worked at various times as a photographer, insurance salesman, and journalist, launching his journalistic career as a contributor to the weekly newspaper <i>Public Opinion</i> from 1939 to 1952. Mais published more than a hundred short stories, most appearing in <i>Public Opinion</i> and <i>Focus</i>, with others collected in <i>Face and Other Stories</i> and <i>And Most of All Man</i>. He wrote more than thirty stage and radio plays, as well as three novels: <i>The Hills Were Joyful Together</i> (1953), <i>Brother Man</i> (1954), and <i>Black Lightning</i> (1955).</p><p>Mais’ topics most frequently were the social injustice and inequality suffered by black, poor Jamaicans. Accused of sedition for writing the article “Now We Know,” a 1944 denunciation of the British Empire, the Jamaican novelist was tried, convicted and imprisoned for six months. His political activism, anti-colonial writing, and imprisonment helped galvanize Jamaican nationalism. (<a href="https://en.wikipedia.org/wiki/Thomas_Mann" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div id="side-by-side-25"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/saadat-hasan-manto.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/saadat-hasan-manto.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/saadat-hasan-manto.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Saadat Hasan Manto</h3><div><p>Saadat Hasan Manto was a Pakistani writer, playwright and novelist from Punjab, who is regarded as the greatest short-story author in Urdu literature. He was active from 1933 during British rule till his death in 1955 after independence.</p><p>Writing mainly in Urdu, he produced 22 collections of short stories, a novel, five series of radio plays, three collections of essays, and two collections of personal sketches. He is best known for his stories about the partition of India, which he opposed, immediately following independence in 1947. Manto’s most notable work has been archived by Rekhta.</p><p>Manto was tried six times for alleged obscenity in his writings; thrice before 1947 in British India, and thrice after independence in 1947 in Pakistan, but was never convicted. He started his literary career translating the works of Victor Hugo, Oscar Wilde and Russian writers such as Chekhov and Gorky. His first story was “Tamasha”, based on the Jallianwala Bagh massacre at Amritsar. His final works, which grew from the social climate and his own financial struggles, reflected an innate sense of human impotency towards darkness and contained satire that verged on dark comedy, as seen in his last story, “Toba Tek Singh”. (<a href="https://en.wikipedia.org/wiki/Saadat_Hasan_Manto" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div></div></div><div><p><h2><span>Entering the public domain in countries with a ‘life plus 50 year’ copyright term</span></h2></p></div><div id="side-by-side-26"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/barbara-hepworth.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/barbara-hepworth.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/barbara-hepworth.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Barbara Hepworth</h3><p>Dame Jocelyn Barbara Hepworth was an English artist and sculptor. Along with artists such as Ben Nicholson and Naum Gabo, Hepworth was a leading figure in the colony of artists who resided in St Ives during the Second World War. Born in Wakefield, Yorkshire, Hepworth studied at Leeds School of Art and the Royal College of Art in the 1920s. She married the sculptor John Skeaping in 1925. In 1931 she fell in love with the painter Ben Nicholson, and in 1933 divorced Skeaping. At this time she was part of a circle of modern artists centred on Hampstead, London, and was one of the founders of the art movement Unit One. At the beginning of the Second World War Hepworth and Nicholson moved to St Ives, Cornwall, where she would remain for the rest of her life. Best known as a sculptor, Hepworth also produced drawings – including a series of sketches of operating rooms following the hospitalisation of her daughter in 1944 – and lithographs. She died in a fire at her studio in 1975. (<a href="https://en.wikipedia.org/wiki/Barbara_Hepworth" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p><hr></div></div><div id="side-by-side-27"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/hannah-arendt.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/hannah-arendt.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/hannah-arendt.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Hannah Arendt</h3><div><p>Hannah Arendt was a German and American historian and philosopher. She was one of the most influential political theorists of the twentieth century.</p><p>Her works cover a broad range of topics, but she is best known for those dealing with the nature of wealth, power, fame, and evil, as well as politics, direct democracy, authority, tradition, and totalitarianism. She is also remembered for the controversy surrounding the trial of Adolf Eichmann, for her attempt to explain how ordinary people become actors in totalitarian systems, which was considered by some an apologia, and for the phrase “the banality of evil”.</p><p>In 1933, Arendt was briefly imprisoned by the Gestapo for performing illegal research into antisemitism. On release, she fled Germany, settling in Paris. There she worked for Youth Aliyah, assisting young Jews to emigrate to the British Mandate of Palestine. When Germany invaded France she was detained as an alien, but she escaped and made her way to the United States in 1941. She became a writer and editor and worked for the Jewish Cultural Reconstruction, becoming an American citizen in 1950. With the publication of <i>The Origins of Totalitarianism</i> in 1951, her reputation as a thinker and writer was established, and a series of works followed. These included the books <i>The Human Condition</i> in 1958, as well as <i>Eichmann in Jerusalem</i> and <i>On Revolution</i> in 1963. She taught at many American universities while declining tenure-track appointments. She died suddenly of a heart attack in 1975, leaving her last work, <i>The Life of the Mind</i>, unfinished. (<a href="https://en.wikipedia.org/wiki/Hannah_Arendt" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr></div></div><div id="side-by-side-28"><p><img src="https://pdr-assets.b-cdn.net/features/countdown/2026/walker-evans.jpg?width=640&amp;height=1200" data-blursrc="https://pdr-assets.b-cdn.net/features/countdown/2026/walker-evans.jpg?width=640&amp;height=1200&amp;blur=70&amp;q=20" data-src="https://pdr-assets.b-cdn.net/features/countdown/2026/walker-evans.jpg?width=640&amp;height=1200"><span>Scroll through the whole page to download all images before printing.</span></p><div><h3>Walker Evans</h3><div><p>Walker Evans was an American photographer and photojournalist best known for his work for the Resettlement Administration and the Farm Security Administration (FSA) documenting the effects of the Great Depression. Evans’ published his first photos at the age of 27. Much of Evans’ New Deal work uses the large format, 8 × 10-inch (200×250 mm) view camera. He said that his goal as a photographer was to make pictures that are “literate, authoritative, transcendent”.</p><p>Many of his works are in the permanent collections of museums and have been the subject of retrospectives at such institutions as the Metropolitan Museum of Art or the George Eastman Museum.</p><p>Born in St. Louis, Missouri, Evans took up photography in 1928 around the time he was living in Ossining, New York. The Great Depression years of 1935–36 were a period of remarkable productivity and accomplishment for Evans. In 1936, employed by the National Recovery Administration, he photographed three impoverished sharecropper families in Hale County, Alabama. The photographs became iconic and were praised for effectively capturing the negative effects of the Great Depression in the American South. Between 1940 and 1959, Evans was awarded three Guggenheim Fellowships in Photography to continue his work of making record photographs of contemporary American subjects. (<a href="https://en.wikipedia.org/wiki/Walker_Evans" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p></div><hr><p><span>Works at <a href="https://www.loc.gov/pictures/related/?fi=name&amp;q=Evans%2C%20Walker%2C%201903-1975" target="_blank" rel="noopener noreferrer">Library of Congress</a></span></p></div></div><div id="side-by-side-29"><h3><a href="https://www.loc.gov/pictures/related/?fi=name&amp;q=Evans%2C%20Walker%2C%201903-1975" target="_blank" rel="noopener noreferrer">P. G. Wodehouse</a></h3><p><a href="https://www.loc.gov/pictures/related/?fi=name&amp;q=Evans%2C%20Walker%2C%201903-1975" target="_blank" rel="noopener noreferrer">Sir Pelham Grenville Wodehouse was an English writer and one of the most widely read humorists of the 20th century. His creations include the feather-brained Bertie Wooster and his sagacious valet, Jeeves; the immaculate and loquacious Psmith; Lord Emsworth and the Blandings Castle set; the Oldest Member, with stories about golf; and Mr. Mulliner, with tall tales on subjects ranging from bibulous bishops to megalomaniac movie moguls.<p>Born in Guildford, his early novels were mostly school stories, but he later switched to comic fiction. Most of Wodehouse’s fiction is set in his native United Kingdom, although he spent much of his life in the US and used New York and Hollywood as settings for some of his novels and short stories. Wodehouse was a prolific writer throughout his life, publishing more than ninety books, forty plays, two hundred short stories and other writings between 1902 and 1974. Early in his career Wodehouse would produce a novel in about three months, but he slowed in old age to around six months. He used a mixture of Edwardian slang, quotations from and allusions to numerous poets, and several literary techniques to produce a prose style that has been compared to comic poetry and musical comedy. Some critics of Wodehouse have considered his work flippant, but among his fans are former British prime ministers and many of his fellow writers. (</p></a><a href="https://en.wikipedia.org/wiki/P._G._Wodehouse" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</p><hr><p><span>Works at <a href="https://www.gutenberg.org/ebooks/search/?query=P.+G.+Wodehouse" target="_blank" rel="noopener noreferrer">Project Gutenberg</a></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why users cannot create Issues directly (352 pts)]]></title>
            <link>https://github.com/ghostty-org/ghostty/issues/3558</link>
            <guid>46460319</guid>
            <pubDate>Fri, 02 Jan 2026 01:24:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ghostty-org/ghostty/issues/3558">https://github.com/ghostty-org/ghostty/issues/3558</a>, See on <a href="https://news.ycombinator.com/item?id=46460319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">Users are not allowed to create Issues directly in this repository - we ask that you create a <a href="https://github.com/ghostty-org/ghostty/discussions">Discussion</a> first.</p>
<p dir="auto">Unlike some other projects, Ghostty <strong>does not use the issue tracker for discussion or feature requests</strong>. Instead, we use GitHub <a href="https://github.com/ghostty-org/ghostty/discussions">discussions</a> for that. Once a discussion reaches a point where a well-understood, actionable item is identified, it is moved to the issue tracker. <strong>This pattern makes it easier for maintainers or contributors to find issues to work on since <em>every issue</em> is ready to be worked on.</strong></p>
<p dir="auto">This approach is based on years of experience maintaining open source projects and observing that 80-90% of what users think are bugs are either misunderstandings, environmental problems, or configuration errors by the users themselves. For what's left, the majority are often feature requests (unimplemented features) and not bugs (malfunctioning features). Of the features requests, almost all are underspecified and require more guidance by a maintainer to be worked on.</p>
<p dir="auto">Any Discussion which clearly identifies a problem in Ghostty and can be confirmed or reproduced will be converted to an Issue by a maintainer, so as a user finding a valid problem you don't do any extra work anyway. Thank you.</p>
<p dir="auto">For more details, see our <a href="https://github.com/ghostty-org/ghostty/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can Bundler be as fast as uv? (258 pts)]]></title>
            <link>https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/</link>
            <guid>46458302</guid>
            <pubDate>Thu, 01 Jan 2026 21:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/">https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/</a>, See on <a href="https://news.ycombinator.com/item?id=46458302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>At RailsWorld earlier this year, I got nerd sniped by someone.
They asked “why can’t Bundler be as fast as uv?”
Immediately my inner voice said “YA, WHY CAN’T IT BE AS FAST AS UV????”</p>
<p>My inner voice likes to shout at me, especially when someone asks a question so obvious I should have thought of it myself.
Since then I’ve been thinking about and investigating this problem, going so far as to <a href="https://www.xoruby.com/event/portland/">give a presentation at XO Ruby Portland about Bundler performance</a>.
I firmly believe the answer is “Bundler <em>can</em> be as fast as uv” (where “as fast” has a margin of error lol).</p>
<p>Fortunately, Andrew Nesbitt recently wrote a post called <a href="https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html">“How uv got so fast”</a>, and I thought I would take this opportunity to review some of the highlights of the post and how techniques applied in uv can (or can’t) be applied to Bundler / RubyGems.
I’d also like to discuss some of the existing bottlenecks in Bundler and what we can do to fix them.</p>
<p>If you haven’t read Andrew’s post, I <a href="https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html">highly recommend giving it a read</a>.
I’m going to quote some parts of the post and try to reframe them with RubyGems / Bundler in mind.</p>
<h2 id="rewrite-in-rust">Rewrite in Rust?</h2>
<p>Andrew opens the post talking about rewriting in Rust:</p>
<blockquote>
<p>uv installs packages faster than pip by an order of magnitude. The usual explanation is “it’s written in Rust.” That’s true, but it doesn’t explain much. Plenty of tools are written in Rust without being notably fast. The interesting question is what design decisions made the difference.</p></blockquote>
<p>This is such a good quote.
I’m going to address “rewrite in Rust” a bit later in the post.
But suffice to say, I think if we eliminate bottlenecks in Bundler such that the only viable option for performance improvements is to “rewrite in Rust”, then I’ll call it a success.
I think rewrites give developers the freedom to “think outside the box”, and try techniques they might not have tried.
In the case of <code>uv</code>, I think it gave the developers a good way to say “if we don’t have to worry about backwards compatibility, what could we achieve?”.</p>
<p>I suspect it would be possible to write a uv in Python (PyUv?) that approaches the speeds of uv, and in fact much of the blog post goes on to talk about performance improvements that <em>aren’t</em> related to Rust.</p>
<h2 id="installing-code-without-evaling">Installing code without eval’ing</h2>
<blockquote>
<p>pip’s slowness isn’t a failure of implementation. For years, Python packaging required executing code to find out what a package needed.</p></blockquote>
<p>I didn’t know this about Python packages, and it doesn’t really apply to Ruby Gems so I’m mostly going to skip this section.</p>
<p>Ruby Gems are tar files, and one of the files in the tar file is a YAML representation of the GemSpec.
This YAML file declares all dependencies for the Gem, so RubyGems can know, without evaling anything, what dependencies it needs to install before it can install any particular Gem.
Additionally, RubyGems.org provides an API for asking about dependency information, which is actually the normal way of getting dependency info (again, no <code>eval</code> required).</p>
<p>There’s only one other thing from this section I’d like to quote:</p>
<blockquote>
<p>PEP 658 (2022) put package metadata directly in the Simple Repository API, so resolvers could fetch dependency information without downloading wheels at all.</p></blockquote>
<p>Fortunately RubyGems.org already provides the same information about gems.</p>
<p>Reading through the number of PEPs required as well as the amount of time it took to get the standards in place was very eye opening for me.
I can’t help but applaud folks in the Python community for doing this.
It seems like a mountain of work, and they should really be proud of themselves.</p>
<h2 id="what-uv-drops">What uv drops</h2>
<p>I’m mostly going to skip this section except for one point:</p>
<blockquote>
<p>Ignoring requires-python upper bounds. When a package says it requires python&lt;4.0, uv ignores the upper bound and only checks the lower. This reduces resolver backtracking dramatically since upper bounds are almost always wrong. Packages declare python&lt;4.0 because they haven’t tested on Python 4, not because they’ll actually break. The constraint is defensive, not predictive.</p></blockquote>
<p>I think this is very very interesting.
I don’t know how much time Bundler spends on doing “required Ruby version” bounds checking, but it feels like if uv can do it, so can we.</p>
<h2 id="optimizations-that-dont-need-rust">Optimizations that don’t need Rust</h2>
<p>I really love that Andrew pointed out optimizations that could be made that don’t involve Rust.
There are three points in this section that I want to pull out:</p>
<blockquote>
<p>Parallel downloads. pip downloads packages one at a time. uv downloads many at once. Any language can do this.</p></blockquote>
<p>This is absolutely true, and is a place where Bundler could improve.
Bundler currently has a problem when it comes to parallel downloads, and needs a small architectural change as a fix.</p>
<p>The first problem is that Bundler tightly couples <em>installing</em> a gem with <em>downloading</em> the gem.
You can read <a href="https://github.com/ruby/rubygems/blob/c00ca53960d21d0680df4ea7dde8ddf1bedaa774/bundler/lib/bundler/source/rubygems.rb#L165">the installation code here</a>, but I’ll summarize the method in question below:</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span>def</span> <span>install</span>
</span></span><span><span>  path <span>=</span> fetch_gem_if_not_cached
</span></span><span><span>  <span>Bundler</span><span>::</span><span>RubyGemsGemInstaller</span><span>.</span>install path, dest
</span></span><span><span><span>end</span>
</span></span></code></pre></div><p>The problem with this method is that it inextricably links <em>downloading</em> the gem with <em>installing</em> it.
This is a problem because we could be downloading gems while installing other gems, but we’re forced to wait because the installation method couples the two operations.
Downloading gems can trivially be done in parallel since the <code>.gem</code> files are just archives that can be fetched independently.</p>
<p>The second problem is the queuing system in the installation code.
After gem resolution is complete, and Bundler knows what gems need to be installed, it queues them up for installation.
You can find <a href="https://github.com/ruby/rubygems/blob/c00ca53960d21d0680df4ea7dde8ddf1bedaa774/bundler/lib/bundler/installer/parallel_installer.rb#L188-L201">the queueing code here</a>.
The code takes some effort to understand. Basically it allows gems to be installed in parallel, but only gems that have already had their dependencies installed.</p>
<p>So for example, if you have a dependency tree like “gem <code>a</code> depends on gem <code>b</code> which depends on gem <code>c</code>” (<code>a -&gt; b -&gt; c</code>), then no gems will be installed (or downloaded) in parallel.</p>
<p>To demonstrate this problem in an easy-to-understand way, I built a <a href="https://github.com/tenderlove/slow-gemserver">slow Gem server</a>.
It generates a dependency tree of <code>a -&gt; b -&gt; c</code> (<code>a</code> depends on <code>b</code>, <code>b</code> depends on <code>c</code>), then starts a Gem server.
The Gem server takes 3 seconds to return any Gem, so if we point Bundler at this Gem server and then profile Bundler, we can see the impact of the queueing system and download scheme.</p>
<p>In my test app, I have the following Gemfile:</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span>source <span>"http://localhost:9292"</span>
</span></span><span><span>
</span></span><span><span>gem <span>"a"</span>
</span></span></code></pre></div><p>If we profile Bundle install with Vernier, we can see the following swim lanes in the marker chart:</p>
<p><img src="https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/images/serial.png" alt="gem install swim lanes (serial)">
</p>
<p>The above chart is showing that we get no parallelism during installation.
We spend 3 seconds downloading the <code>c</code> gem, then we install it.
Then we spend 3 seconds downloading the <code>b</code> gem, then we install it.
Finally we spend 3 seconds downloading the <code>a</code> gem, and we install it.</p>
<p>Timing the <code>bundle install</code> process shows we take over 9 seconds to install (3 seconds per gem):</p>
<pre tabindex="0"><code>&gt; rm -rf x; rm -f Gemfile.lock; time GEM_PATH=(pwd)/x GEM_HOME=(pwd)/x bundle install
Fetching gem metadata from http://localhost:9292/...
Resolving dependencies...
Fetching c 1.0.0
Installing c 1.0.0
Fetching b 1.0.0
Installing b 1.0.0
Fetching a 1.0.0
Installing a 1.0.0
Bundle complete! 1 Gemfile dependency, 3 gems now installed.
Use `bundle info [gemname]` to see where a bundled gem is installed.

________________________________________________________
Executed in   11.80 secs      fish           external
   usr time  341.62 millis  231.00 micros  341.38 millis
   sys time  223.20 millis  712.00 micros  222.49 millis
</code></pre><p>Contrast this with a Gemfile containing <code>d</code>, <code>e</code>, and <code>f</code>, which have no dependencies, but still take 3 seconds to download:</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span>source <span>"http://localhost:9292"</span>
</span></span><span><span>
</span></span><span><span>gem <span>"d"</span>
</span></span><span><span>gem <span>"e"</span>
</span></span><span><span>gem <span>"f"</span>
</span></span></code></pre></div><p><img src="https://tenderlovemaking.com/2025/12/29/can-bundler-be-as-fast-as-uv/images/parallel.png" alt="gem install swim lanes (parallel)">
</p>
<p>Timing <code>bundle install</code> for the above Gemfile shows it takes about 4 seconds:</p>
<pre tabindex="0"><code>&gt; rm -rf x; rm -f Gemfile.lock; time GEM_PATH=(pwd)/x GEM_HOME=(pwd)/x bundle install
Fetching gem metadata from http://localhost:9292/.
Resolving dependencies...
Fetching d 1.0.0
Fetching e 1.0.0
Fetching f 1.0.0
Installing e 1.0.0
Installing f 1.0.0
Installing d 1.0.0
Bundle complete! 3 Gemfile dependencies, 3 gems now installed.
Use `bundle info [gemname]` to see where a bundled gem is installed.

________________________________________________________
Executed in    4.14 secs      fish           external
   usr time  374.04 millis    0.38 millis  373.66 millis
   sys time  368.90 millis    1.09 millis  367.81 millis
</code></pre><p>We were able to install the same number of gems in a fraction of the time.
This is because Bundler is able to download <em>siblings</em> in the dependency tree in parallel, but unable to handle other relationships.</p>
<p>There is actually a good reason that Bundler insists dependencies are installed before the gems themselves: native extensions.
When installing native extensions, the installation process <em>must</em> run Ruby code (the <code>extconf.rb</code> file).
Since the <code>extconf.rb</code> could require dependencies be installed in order to run, we must install dependencies first.
For example <a href="https://rubygems.org/gems/nokogiri"><code>nokogiri</code> depends on <code>mini_portile2</code></a>, but <code>mini_portile2</code> is only used during the installation process, so it needs to be installed before <code>nokogiri</code> can be compiled and installed.</p>
<p>However, if we were to <em>decouple downloading from installation</em> it would be possible for us to maintain the “dependencies are installed first” business requirement but speed up installation.
In the <code>a -&gt; b -&gt; c</code> case, we <em>could have been</em> downloading gems <code>a</code> and <code>b</code> at the same time as gem <code>c</code> (or even while waiting on <code>c</code> to be installed).</p>
<p>Additionally, pure Ruby gems don’t need to execute any code on installation.
If we knew that we were installing a pure Ruby gem, it would be possible to relax the “dependencies are installed first” business requirement and get even more performance increases.
The above <code>a -&gt; b -&gt; c</code> case <em>could</em> install all three gems in parallel since none of them execute Ruby code during installation.</p>
<p>I would propose we split installation in to 4 discrete steps:</p>
<ol>
<li>Download the gem</li>
<li>Unpack the gem</li>
<li>Compile the gem</li>
<li>Install the gem</li>
</ol>
<p>Downloading and unpacking can be done trivially in parallel.
We should unpack the gem to a temporary folder so that if the process crashes or the machine loses power, the user isn’t stuck with a half-installed gem.
After we unpack the gem, we can discover whether the gem is a native extension or not.
If it’s not a native extension, we “install” the gem simply by moving the temporary folder to the “correct” location.
This step could even be a “hard link” step as discussed in the next point.</p>
<p>If we discover that the gem is a native extension, then we can “pause” installation of that gem until its dependencies are installed, then resume (by compiling) at an appropriate time.</p>
<p>Side note: <a href="https://github.com/gel-rb/gel"><code>gel</code>, a Bundler alternative</a>, works mostly in this manner today.
Here is a timing of the <code>a -&gt; b -&gt; c</code> case from above:</p>
<pre tabindex="0"><code>&gt; rm -f Gemfile.lock; time gel install
Fetching sources....
Resolving dependencies...
Writing lockfile to /Users/aaron/git/gemserver/app/Gemfile.lock
Installing c (1.0.0) 
Installing a (1.0.0)
Installing b (1.0.0)
Installed 3 gems  

________________________________________________________
Executed in    4.07 secs      fish           external
   usr time  289.22 millis    0.32 millis  288.91 millis
   sys time  347.04 millis    1.36 millis  345.68 millis
</code></pre><p>Lets move on to the next point:</p>
<blockquote>
<p>Global cache with hardlinks. pip copies packages into each virtual environment. uv keeps one copy globally and uses hardlinks</p></blockquote>
<p>I think this is a great idea, but I’d actually like to split the idea in two.
First, RubyGems and Bundler should have a combined, global cache, full stop.
I think that global cache should be in <code>$XDG_CACHE_HOME</code>, and we should store <code>.gem</code> files there when they are downloaded.</p>
<p>Currently, both Bundler and RubyGems will use a Ruby version specific cache folder.
In other words, if you do <code>gem install rails</code> on two different versions of Ruby, you get two copies of Rails and all its dependencies.</p>
<p>Interestingly, <a href="https://github.com/ruby/rubygems/issues/7249">there is an open ticket to implement this</a>, it just needs to be done.</p>
<p>The second point is hardlinking on installation.
The idea here is that rather than unpacking the gem multiple times, once per Ruby version, we simply unpack once and then hard link per Ruby version.
I like this idea, but I think it should be implemented after some technical debt is paid: namely implementing a global cache and unifying Bundler / RubyGems code paths.</p>
<p>On to the next point:</p>
<blockquote>
<p>PubGrub resolver</p></blockquote>
<p>Actually Bundler already uses a Ruby implementation of the PubGrub resolver.
You can see it <a href="https://github.com/ruby/rubygems/tree/569c5c7450137839ff7c536f160b06a43ea3dfe4/bundler/lib/bundler/vendor/pub_grub">here</a>.
Unfortunately, RubyGems <a href="https://github.com/ruby/rubygems/tree/569c5c7450137839ff7c536f160b06a43ea3dfe4/lib/rubygems/vendor/molinillo">still uses the molinillo resolver</a>.</p>
<p>In other words you use a different resolver depending on whether you do <code>gem install</code> or <code>bundle install</code>.
I don’t really think this is a big deal since the vast majority of users will be doing <code>bundle install</code> most of time.
However, I do think this discrepancy is some technical debt that should be addressed, and I think this should be addressed via unification of RubyGems and Bundler codebases (today they both live in the same repository, but the code isn’t necessarily combined).</p>
<p>Lets move on to the next section of Andrew’s post:</p>
<h2 id="where-rust-actually-matters">Where Rust actually matters</h2>
<p>Andrew first mentions “Zero-copy deserialization”.
This is of course an important technique, but I’m not 100% sure where we would utilize it in RubyGems / Bundler.
I think that today we parse the YAML spec on installation, and that could be a target.
But I also think we could install most gems without looking at the YAML gemspec at all.</p>
<blockquote>
<p>Thread-level parallelism. Python’s GIL forces parallel work into separate processes, with IPC overhead and data copying.</p></blockquote>
<p>This is an interesting point.
I’m not sure what work pip needed to do in separate processes.
Installing a pure Ruby, Ruby Gem is mostly an IO bound task, with some ZLIB mixed in.
Both of these things (IO and ZLIB processing) release Ruby’s GVL, so it’s possible for us to do things truly in parallel.
I imagine this is similar for Python / pip, but I really have no idea.</p>
<p>Given the stated challenges with Python’s GIL, you might wonder whether Ruby’s GVL presents similar parallelism problems for Bundler.
I don’t think so, and in fact I think Ruby’s GVL gets kind of a bad rap.
It prevents us from running CPU bound Ruby code in parallel.
Ractors address this, and Bundler could possibly leverage them in the future, but since installing Gems is mostly an IO bound task I’m not sure what the advantage would be (possibly the version solver, but I’m not sure what can be parallelized in there).
The GVL does allow us to run IO bound work in parallel with CPU bound Ruby code.
CPU bound native extensions are allowed to <em>release the GVL</em>, allowing Ruby code to run in parallel with the native extension’s CPU bound code.</p>
<p>In other words, Ruby’s GVL allows us to <em>safely</em> run work in parallel.
That said, the GVL can work against us because releasing and acquiring the GVL <em>takes time</em>.</p>
<p>If you have a system call that is very fast, releasing and acquiring the GVL could end up being a large percentage of that call.
For example, if you do <code>File.binwrite(file, buffer)</code>, and the buffer is very small, you could encounter a situation where GVL book keeping is the majority of the time.
A bummer is that Ruby Gem packages usually contain lots of very small files, so this problem <em>could</em> be impacting us.
The good news is that this problem can be solved in Ruby itself, and <a href="https://github.com/ruby/ruby/pull/15529">indeed some work is being done on it today</a>.</p>
<blockquote>
<p>No interpreter startup. Every time pip spawns a subprocess, it pays Python’s startup cost.</p></blockquote>
<p>Obviously Ruby has this same problem.
That said, we only start Ruby subprocesses when installing native extensions.
I think native extensions make up the minority of gems installed, and even when installing a native extension, it isn’t Ruby startup that is the bottleneck.
Usually the bottleneck is compilation / linking time (as we’ll see in the next post).</p>
<blockquote>
<p>Compact version representation. uv packs versions into u64 integers where possible, making comparison and hashing fast.</p></blockquote>
<p>This is a cool optimization, but I don’t think it’s actually Rust specific.
Comparing integers is <em>much</em> faster than comparing version objects.
The idea is that you take a version number, say <code>1.0.0</code>, and then pack each part of the version in to a single integer.
For example, we could represent <code>1.0.0</code> as <code>0x0001_0000_0000_0000</code> and <code>1.1.0</code> as <code>0x0001_0001_0000_0000</code>, etc.</p>
<p>It should be possible to use this trick in Ruby and encode versions to integer immediates, which would unlock performance in the resolver.
Rust has an advantage here - compiled native code comparing u64s will always be faster than Ruby, even with immediates.
However, I would bet that with the YJIT or ZJIT in play, this gap could be closed enough that no end user would notice the difference between a Rust or Ruby implementation of Bundler.</p>
<p>I <a href="https://github.com/ruby/rubygems/pull/9085">started refactoring the <code>Gem::Version</code> object</a> so that we might start doing this, but we ended up reverting it because of backwards compatibility (I am jealous of <code>uv</code> in that regard).
I think the right way to do this is to refactor the solver entry point and ensure all version requirements are encoded as integer immediates before entering the solver.
We could keep the <code>Gem::Version</code> API as “user facing” and design a more internal API that the solver uses.
I am very interested in reading the version encoding scheme in uv.
My intuition is that minor numbers tend to get larger than major numbers, so would minor numbers have more dedicated bits?
Would it even matter with 64 bits?</p>
<h2 id="wrapping-this-up">Wrapping this up</h2>
<p>I’m going to quote Andrew’s last 2 paragraphs:</p>
<blockquote>
<p>uv is fast because of what it doesn’t do, not because of what language it’s written in. The standards work of PEP 518, 517, 621, and 658 made fast package management possible. Dropping eggs, pip.conf, and permissive parsing made it achievable. Rust makes it a bit faster still.</p>
<p>pip could implement parallel downloads, global caching, and metadata-only resolution tomorrow. It doesn’t, largely because backwards compatibility with fifteen years of edge cases takes precedence. But it means pip will always be slower than a tool that starts fresh with modern assumptions.</p></blockquote>
<p>I think these are very good points.
The difference is that in RubyGems and Bundler, we already have the infrastructure in place for writing a “fast as uv” package manager.
The difficult part is dealing with backwards compatibility, and navigating two legacy codebases.
I think this is the real advantage the uv developers had.
That said, I am very optimistic that we could “repair the plane mid-flight” so to speak, and have the best of both worlds: backwards compatibility <em>and</em> speed.</p>
<p>I mentioned at the top of the post I would address “rewrite it in Rust”, and I think Andrew’s own quote mostly does that for me.
I think we could have 99% of the performance improvements while still maintaining a Ruby codebase.
Of course if we rewrote it in Rust, you could squeeze an extra 1% out, but would it be worthwhile?  I don’t think so.</p>
<p>I have a lot more to say about this topic, and I feel like this post is getting kind of long, so I’m going to end it here.
Please look out for part 2, which I’m tentatively calling “What makes Bundler / RubyGems slow?”
This post was very “can we make RubyGems / Bundler do what uv does?” (the answer is “yes”).
In part 2 I want to get more hands-on by discussing how to profile Bundler and RubyGems, what specifically makes them slow in the real world, and what we can do about it.</p>
<p>I want to end this post by saying “thank you” to Andrew for writing such a great post about <a href="https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html">how uv got so fast</a>.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A website to destroy all websites (548 pts)]]></title>
            <link>https://henry.codes/writing/a-website-to-destroy-all-websites/</link>
            <guid>46457784</guid>
            <pubDate>Thu, 01 Jan 2026 20:36:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://henry.codes/writing/a-website-to-destroy-all-websites/">https://henry.codes/writing/a-website-to-destroy-all-websites/</a>, See on <a href="https://news.ycombinator.com/item?id=46457784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <section>
            
            <p><span>How to win the war for the soul of the internet</span>
                <span>and build the <em>Web We Want</em>.</span>
            </p>
            <figure>
                <picture><source type="image/webp" srcset="https://henry.codes/img/odilon-redon_captive-pegasus-700w.webp 700w" sizes="100vw"><img loading="eager" decoding="async" src="https://henry.codes/img/odilon-redon_captive-pegasus-700w.jpeg" alt="" width="700" fetchpriority="high" height="949"></picture>
                <figcaption><a href="https://www.artic.edu/artworks/79492/captive-pegasus">Captive Pegasus, <cite>Odilon Redon</cite> (1889)</a></figcaption>
            </figure> 
            
            <span>~3100 words; about a 15 minute read
        </span></section>
        <section>
            <h2>table of contents, of course</h2>
            <ol role="list">
                <li><a href="#internet-bad">The internet is bad</a></li>
                <li><a href="#invention-of-the-automobile">The invention of the automobile</a></li>
                <li><a href="#tools-for-conviviality"><em>Tools for Conviviality</em> &amp; the industrialization of the Web</a></li>
                <li><a href="#the-web-we-want">The Web we want</a></li>
                <li><a href="#where-do-we-go-from-here">So where do we go from here?</a></li>
                <li><a href="#denouement">Denouement</a></li>
            </ol>
        </section>
        <hr>
        <section id="internet-bad">
            <header>
                <p>part one.</p>
                
            </header>
            <div>
                <p>Well, the Internet mostly feels bad these days.</p>
<p>We were given this vast, holy realm of self-discovery and joy and philosophy and community; a thousand thousand acres of digital landscape, on which to grow our forests and grasslands of imagination, plant our gardens of learning, explore the caves of our making. We were given the chance to know anything about anything, to be our own Prometheus, to make wishes and to grant them.</p>
<p>But that’s not what we use the Internet for anymore. These days, instead of using it to make ourselves, most of us are using it to waste ourselves: we’re doom-scrolling brain-rot on the attention-farm, we’re getting slop from the feed.</p>
<p>Instead of turning freely in the HTTP meadows we grow for each other, we go to work: we break our backs at the foundry of algorithmic content as this earnest, naïve, human endeavoring to connect our lives with others is corrupted. Our powerful drive to learn about ourselves, each other, and our world, is broken into scant remnants — hollow, clutching phantasms of Content Creation, speed-cut vertical video, listicle thought-leadership, ragebait and the thread emoji.</p>

            </div>
            
            <div>
                <p>It used to feel way better to Go Online, and some of us will remember.</p>
<p>We used to be able to learn about our hobbies and interests from hundreds of experts on a wealth of websites whose only shared motivation was their passion. Some of those venerable old educational blogs, forums, and wikis still stand, though most have been bulldozed.</p>
<p>Now, Learning On The Internet often means fighting ads and endless assaults on one’s attention — it means watching part-1-part-2-part-3 short-form video clips, taped together by action movie psychology hacks, narrated gracelessly by TTS AI voices. We’re down from a thousand and one websites to three, and each of those remaining monolith websites is just a soullessly-regurgitated, compression-down-scaled, AI-up-scaled version of the next.</p>
<p>¶</p>
<p>We used to make lasting friendships with folks all over the world on shared interest and good humor.</p>
<p>But now those social networks, once hand-built and hand-tended, vibrant and organic, are unceremoniously swallowed by social <em>media</em> networks, pens built for trapping us and our little piggy attentions, turning us all into clout-chasers &amp; content-creators, and removing us from what meaningful intimacy &amp; community felt like.</p>
<p>¶</p>
<p>Even coding for the web used to be different: One could Learn To Code™ to express oneself creatively, imbue one’s online presence with passion and meaning, and for some of us, build a real career.</p>
<p>These days, however, we write increasing amounts of complicated, unsecure code to express less and less meaning, in order to infinitely generate shareholder value. We don’t think about the art of our craft and the discipline of its application, we think about throughput and scale.</p>

            </div>
            
            <p>To be very clear: I’m not trying to <em>Good Old Days</em> the internet. None of this is meant to make you feel nostalgic — the Internet used to be slow and less populated and less diverse, and its access was limited to those of a certain class. The Web For All is a marked improvement, widespread global internet access is a marked improvement, and what I’m asking you to consider is what it used to feel like to use these tools, and what we’ve lost in the Big Tech, Web 2.0 and web3 devouring of the ’Net.</p>
        </section>
        <hr>
        <section id="invention-of-the-automobile">
            <header>
                <p>part two.</p>
                
            </header>
       
            <div>
                <p>The onset of the automobile was a revelation for access and personal liberty. With the advent of cars, members of society could travel farther, get more done in their day, and bend their limited time more to their creative will!</p>
<p>But as time wore on and the industrialization &amp; proliferation of the automobile progressed, its marginal utility diminished —  the industry started to society fewer &amp; fewer benefits, and take more &amp; more in exchange<a href="#footnote-1">1</a>.</p>
<p>In American cities, for example: though at first the automobile enabled humans to travel further distances, it now <em>demanded</em> that humans travel those distances, and <em>demanded</em> infrastructure be created &amp; maintained to enable it.<a href="#footnote-2">2</a> Many now <em>must</em> use an automobile to get everything done in their town in a day, and must pay &amp; take time for that automobile’s fueling &amp; maintenance.<a href="#footnote-3">3</a></p>
<p>Further than that, the automobile asks all of us to chip in tax revenue to protect its infrastructure, but only certain classes can afford an automobile with which to use that infrastructure, and those classes who can’t afford to do so are relegated to underfunded public transit systems.<a href="#footnote-4">4</a></p>
<p>No longer a tool to serve our societies, our societies now serve the automobile.</p>

            </div>
            
        </section>
        <hr>
        <section id="tools-for-conviviality">
            <header>
                <p>part three.</p>
                <h2><em>Tools for Conviviality,</em> <span>&amp;</span> the industrialization of the Web.</h2>
            </header>
            <div>
                <p><picture><source type="image/webp" srcset="https://henry.codes/img/book-tools-for-conviviality-400w.webp 400w, https://henry.codes/img/book-tools-for-conviviality-800w.webp 800w" sizes="100vw"><img loading="lazy" decoding="async" src="https://henry.codes/img/book-tools-for-conviviality-400w.jpeg" alt="" width="800" height="1314" srcset="https://henry.codes/img/book-tools-for-conviviality-400w.jpeg 400w, https://henry.codes/img/book-tools-for-conviviality-800w.jpeg 800w" sizes="100vw"></picture>
In his book <em>Tools For Conviviality</em>, technology philosopher and social critic Ivan Illich identifies these two critical moments, the optimistic arrival &amp; the deadening industrialization, as watersheds of technological advent. Tools are first created to enhance our capacities to spend our energy more freely and in turn spend our days more freely, but as their industrialization increases, their manipulation &amp; usurpation of society increases in tow<a href="#footnote-5">5</a>.</p>
<p>Illich also describes the concept of <em>radical monopoly</em>, which is that point where a technological tool is so dominant that people are excluded from society unless they become its users. We saw this with the automobile, we saw it with the internet, and we even see it with social media.</p>
<p><del>No longer a tool to serve our societies, our societies now serve the automobile.</del> <ins>Instead of designing and using tools to build a society, our society changes to adapt to the demands of our tools.</ins></p>
<p>¶</p>
<p>Illich’s thesis allows us to reframe our adoption and use of the technologies in our life. We can map fairly directly most technological developments in the last 100 (or even 200) years to this framework: a net lift, followed by a push to extract value and subsequent insistence upon the technology’s ubiquity:</p>

            </div>
            <section>
                <div>
                    <h3 id="the-textile-revolution" tabindex="-1">the textile revolution</h3>
<p>The preferred imagery used to mythologize the Industrial Revolution is the woodetchings of textile manufacturers, transformed in the early 19th century by the arrival of automated fabric machinery. Its proponents laud the shift of an agricultural society to a technological one, creating new sectors for labor, and raising up the middle class (we will say nothing of this period’s <em>new</em> punishing conditions for labor in this essay<a href="#footnote-6">6</a>). But the ultimate ecological and human costs engendered by the increasing availability of cheap fabric production are well-documented: In 2022, the fashion and textile industries employed around 60 million factory workers worldwide<a href="#footnote-7">7</a>, and less than 2% of those workers earn a living wage. Those workers also endure the full suite of labor exploitation practices, including gender-based harassment, wage theft, and unsafe conditions. On the material side, the induced consumption resulting from ever-cheaper products means the world consumed 400% more textile products globally as 20 years ago<a href="#footnote-8">8</a>, and bins most of it (the average American generates 82 pounds of textile waste each year).</p>

                </div>
                <div>
                    <h3 id="antibiotic-technology" tabindex="-1">antibiotic technology</h3>
<p>The arrival of antibiotics in 1928<a href="#footnote-9">9</a> allowed for revolutionary leaps in fighting bacterial infections like strep throat, pneumonia, and meningitis, but an over-dependence and over-prescription of penicillin and its siblings through the 1950s-70s resulted in the proliferation of antibiotic resistance, which subsequently led to longer hospital stays, higher medical costs, and increased mortality.<a href="#footnote-10">10</a></p>

                </div>
                <div>
                    <h3 id="space-exploration" tabindex="-1">space exploration</h3>
<p>Since the beginning of the space exploration era in the late 1950s, humanity has made leaps and bounds in learning about our own world and its physical systems, telecommunications, imaging, etc. The increasing frequency of commercialization missions in space for satellite systems (and lately tourism) has resulted in immense amounts of space debris being generated — both from active satellites and from jettisoned/destroyed components of previous missions, the debris threatens future missions and has even been destructive to the field of astronomy, making it impossible to use earth-based sensors and photography devices to learn about space.<a href="#footnote-11">11</a> So desperate to extract Shareholder Value from the starry sky, we’re blinding our own ability to look at it.</p>

                </div>
            </section>
            <div>
                <p>The web is no exception to this pattern. A vision of interoperability, accessibility, and usability, the World Wide Web was first conceived in 1989 as a way to universally link documents and other media content in a flexibly-organized system that could make information easily accessed at CERN, and be easily shared with collaborators beyond.<a href="#footnote-12">12</a> But the proliferation of access and ultimate social requirement of access has spawned countless troubles for human society, including cyberstalking and bullying, the instantaneous circulation of CSAM, violent images, and misinformation, identity theft, addiction, etcetera.</p>
<p>The rampant industrialization and commercialization of the Web predictably develops flashy, insidious patterns of extracting capital from its users: new surfaces for information means new surfaces for advertisement, and new formats of media beget new mechanisms for divorcing you from their ownership.</p>

            </div>
            <div>
                <h3 id="convivial-life-and-convivial-tooling" tabindex="-1">convivial life &amp; convivial tooling</h3>
<p><picture><source type="image/webp" srcset="https://henry.codes/img/book-small-is-beautiful-400w.webp 400w, https://henry.codes/img/book-small-is-beautiful-800w.webp 800w" sizes="100vw"><img loading="lazy" decoding="async" src="https://henry.codes/img/book-small-is-beautiful-400w.jpeg" alt="" width="800" height="1207" srcset="https://henry.codes/img/book-small-is-beautiful-400w.jpeg 400w, https://henry.codes/img/book-small-is-beautiful-800w.jpeg 800w" sizes="100vw"></picture>
Illich poses <em>convivial</em> tools as directly opposed to this industrialized, radically-monopolized set of social systems. Similar to E.F. Schumacher’s concept of “intermediate technology” introduced in his 1973 book <em>Small Is Beautiful: A Study of Economics As If People Mattered</em>, convivial tools are sustainable, energy-efficient (though often labor intensive), local-first, and designed primarily to enhance the autonomy and creativity of their users.<a href="#footnote-13">13</a> Illich cites specifically hand tools, bicycles, and telephones as examples, but with its enormous capacity for interoperability and extensibility, the Internet is the perfect workshed in which to design our own Tools For Conviviality.</p>

            </div>
        </section>
        <section id="the-web-we-want">
             <header>
                <div>
                <p>part four.</p>
                <h2>the Web we want</h2>
                </div>
                <figure>
                    <div>
                        <picture><source type="image/webp" srcset="https://henry.codes/img/john-martin_the-plains-of-heaven-1500w.webp 1500w" sizes="100vw"><img loading="lazy" decoding="async" src="https://henry.codes/img/john-martin_the-plains-of-heaven-1500w.jpeg" alt="" width="1500" height="960"></picture>
                    </div>
                    <figcaption><a href="https://www.tate.org.uk/art/artworks/martin-the-plains-of-heaven-t01928">The Plains of Heaven, <cite>John Martin</cite> (1851-3)</a></figcaption>
                </figure>
            </header>
            <div>
                <p>let’s reconsider</p>
                <p>the markers of a decaying 'Net I mentioned before, with convivial tooling in mind:</p>
            </div>
            <div>
                <h3>Teaching &amp; learning on the Web</h3>
                <div>
                <p>Monolithic platforms like YouTube, TikTok, Medium, and Substack draw a ton of creators and educators because of the promise of monetization and large audiences, but they’ve shown time and time again how the lack of ownership creates a problem. When those platforms fail, when they change their rules, when they demand creators move or create a particular way to maintain their access to those audiences, they pit creators or their audiences against the loss of the other. Without adhering to the algorithm’s requirements, writers may not write an impactful document, and without bypassing a paywall, readers can’t read it.</p>
<p>¶</p>
<p>When those promises of exorbitant wealth and a life of decadence through per-click monetization ultimately dry up (or come with a steep moral or creative cost), creators and learners must look for new solutions for how educational content is shared on the Internet. The most self-evident, <em>convivial</em> answer is an old one: blogs. HTML is free to access by default, <a href="https://indieweb.org/RSS">RSS</a> has worked for about 130 years<sup>[citation needed]</sup>, and combined with <a href="https://indieweb.org/Webmention">webmentions</a>, it’s never been easier to read new ideas, experiment with ideas, and build upon &amp; grow those ideas with other strong thinkers on the web, <em>owning</em> that content all along.<a href="#footnote-14">14</a></p>

                </div>
            </div>
            <div>
                <h3>Connecting with friends on the Web</h3>
                <div>
                <p>Social media apps have imprisoned us all in this weird content prison — in order to connect with friends we’re sort of forced to create or be vanished by capricious black box algorithms, and all that we <em>do</em> create is, as we’ve already alluded to, subsequently owned by whatever platform we’ve created it on. If Instagram goes away overnight, or decides to pivot catastrophically, your stories and your network of friends goes with it.</p>
<p>¶</p>
<p>The advent and development of tools &amp; methodologies like <a href="https://indieweb.org/POSSE">POSSE</a> (<em>Publish On your Own Site, Syndicate Elsewhere</em>), <a href="https://en.wikipedia.org/wiki/ActivityPub">ActivityPub</a>, <a href="https://microformats.org/wiki/microformats2">microformats</a>, and <a href="https://atproto.com/">ATProto</a>, it’s becoming quite achievable to generate your own social network, interoperable with other networks like Bluesky or Mastodon. That network, designed for ownership and decentralization, is durable, designed around storytelling instead of engagement, and free of the whims of weird tech billionaires.</p>
<p>With some basic HTML knowledge and getting-stuff-online knowledge, a handful of scrappy protocols, and a free afternoon or two, one can build their own home to post bangers for the tight homies, make friends, and snipe those new friends with those hits of dopamine they so fiendishly rely on.</p>

                </div>
            </div>
            <div>
                <h3>Coding for the web</h3>
                <div>
                <p>Lastly, consider the discipline of web engineering:</p>
<p>We have been asked to build the same B2B SaaS website with the same featureset n^∞ times, and our answers for the optimal way to do that are increasingly limited. We’ve penned all of our markup into JavaScript templates just in case a product manager needs the wrapper component to post JSON somewhere down the line, and we’ve whittled away at style code until it’s just a mechanism for deploying one of two border-radius-drop-shadow combos to divs. It’s an industrial, production-minded way of approaching a discipline that has all the hallmarks of being a great craft, and that’s understandably uninspiring to many of us.</p>
<p>¶</p>
<p>Yet our young React shepherds have no need to fear: there are countless more colors than blurple out there, and countless more fonts than Inter. HTML and CSS are better and more generative technologies than they’ve ever been: Thanks to the tireless work of the CSS working groups and browser implementers, etc, there is an unbelievable amount of creative expression possible with basic web tools in a text editor. Even JavaScript is more progressively-ehanceable than ever, and enables interfacing with a rapidly-growing number of exciting browser APIs <em>(still <a href="https://www.thepinknews.com/2012/04/04/javascript-inventor-gave-1000-to-support-californias-gay-marriage-ban/">fuck Brendan Eich</a> though)</em>. <a href="https://henry.codes/writing/i-know-about-the-date-in-the-footer/"><code>${new Date.getCurrentYear()}</code></a> is a veritable renaissance of web code, and it asks of authors only curiosity and a drive to experiment.</p>

                </div>
            </div>
        </section>
        <hr>
        <section id="where-do-we-go-from-here">
            
            <div>
                <p>Illich’s thesis is that technology and its derived tools should serve people in a way that enhances their freedom, creativity, independence, and will.</p>
<p>The distillation of those principles on the web through manual code, hand-built social networks, and blogs, points luminously to one answer to the question of how the Internet can best serve humans:</p>

            </div>
            <h3>it’s personal websites.</h3>
            <p>Hand-coded, syndicated, and above all <em>personal</em> websites are exemplary: They let users of the internet to be autonomous, experiment, have ownership, learn, share, find god, find love, find purpose. Bespoke, endlessly tweaked, eternally redesigned, built-in-public, surprising UI and delightful UX. The personal website is a staunch undying answer to everything the corporate and industrial web has taken from us.</p>
            <div>
                <p>And how might one claim this ultimate toolchain of conviviality, and build a place on the web that enhances their autonomy and creativity?</p>
<p><em>How might one build a personal website?</em></p>

            </div>
            <ol>
                <li>
                    <h3 id="start-small" tabindex="-1">Start small</h3>
<p>Let yourself start small, have fun trying shit that doesn’t work, document your growth, publish failed ideas &amp; successful ones. Some of the best websites in the world are just HTML, and they belong to their authors. Make friends, let yourself be inspired by others, send friendly emails asking to learn new things, and do not demand of yourself masterpieces.</p>

                </li>
                <li>
                <h3 id="reduce-friction-to-publishing" tabindex="-1">Reduce friction to publishing</h3>
<p>Get the resistance to ship out of your way. Don’t get caught up in tooling and frameworks, just write HTML and get something online. If you’re an engineer, delight that you’re not beholden to the same standards of quality and rigorous testing that you are at work — draft some ideas, hit the <code>h1</code> to <code>p</code> tag combo, and publish. Update and update again; let your ideas grow like gardens, the way they do in your mind. The mutability of the web, often its great weakness, is also one of its great strengths.</p>

                </li>
                <li>
                    <h3 id="don-t-worry-about-design-unless-you-want-to" tabindex="-1">Don’t worry about design <em>(unless you want to)</em></h3>
<p>Don’t worry about design unless that’s the part that brings you joy. Make friends with designers and trade your work for theirs, or trade tips, trade advice. Get comfortable with being joyfully bad at something — from that soil of humility grows a million questions for those who have learned and are excited to share. Iterate until you’ve something you’re proud of, or iterate so much you’ve ruined it and have to go back to bald.</p>

                </li>
                <li>
                    <h3 id="use-the-indie-web" tabindex="-1">Use the IndieWeb</h3>
<p><a href="https://indieweb.org/">Leverage the IndieWeb</a> and its wonderfully thought-out protocols, tools like <a href="https://brid.gy/">brid.gy</a> to syndicate your ideas out to the wider web, and then use Webmentions to bring the ensuing conversations back where the content is. That way, you can publish work where you prefer to, folks on Bluesky can enjoy and discuss it, in the same stroke as folks on Mastodon may, or folks directly on the canonical URL.</p>

                </li>
                <li>
                    <h3 id="join-us-in-sharing-what-you-ve-made" tabindex="-1">Join us in sharing what you’ve made</h3>
<p>I encourage you to join us in our auspicious website adventure, and if you do, I hope you’ll further join us on <a href="https://personalsit.es/">personalsit.es</a>, our happy little home for everyone building something humble or thrilling or joyful or deeply accursed, but personal.</p>

                </li>
            </ol>
        </section>
        <section id="denouement">
                <header>
                
                <figure>
                    <picture><source type="image/webp" srcset="https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-400w.webp 400w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-800w.webp 800w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-1400w.webp 1400w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-2721w.webp 2721w" sizes="100vw"><img loading="lazy" decoding="async" src="https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-400w.jpeg" alt="" width="2721" height="3722" srcset="https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-400w.jpeg 400w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-800w.jpeg 800w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-1400w.jpeg 1400w, https://henry.codes/img/albert-bierstadt_sunrise-on-the-matterhorn-2721w.jpeg 2721w" sizes="100vw"></picture>
                    <figcaption><a href="https://www.metmuseum.org/art/collection/search/10158">Sunrise on the Matterhorn, <cite>Albert Bierstadt</cite> (after 1875)</a></figcaption>
                </figure>
            </header>
            <div>
                <p>You’re not crazy. The internet <em>does</em> feel genuinely so awful right now, and for about a thousand and one reasons. But the path back to feeling like you have some control is to un-spin yourself from the Five Apps of the Apocalypse and reclaim the Internet as a set of tools you use to build something you can own &amp; be proud of — or in most of our cases, be deeply ashamed of. <em>Godspeed and good luck</em>.</p>
<p>❦</p>
<p>That’s all for me. If you find any issues with this post, please reach out to me <a href="mailto:yo@henry.codes">by email</a>. Thanks eternally for your time and patience, and thanks for reading. Find me here online at one of my personal websites like <a href="https://henry.codes/">henry.codes</a> or <a href="https://strange.website/">strange.website</a> or <a href="https://stillness.digital/">stillness.digital</a> or <a href="https://strangersbyspring.com/">strangersbyspring.com</a>, or sometimes <a href="https://bsky.app/profile/strange.website">on Bluesky</a> and <a href="https://front-end.social/@henry">Mastodon</a>.</p>
<p>As ever, unionize, free Palestine, trans rights are human rights, fix your heart or die.</p>
<p><em>fin.</em></p>
<p><a href="https://henry.codes/">go home</a></p>

            </div>
        </section>
        <hr>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux is good now; to feel like you actually own your PC, put Linux on it (779 pts)]]></title>
            <link>https://www.pcgamer.com/software/linux/im-brave-enough-to-say-it-linux-is-good-now-and-if-you-want-to-feel-like-you-actually-own-your-pc-make-2026-the-year-of-linux-on-your-desktop/</link>
            <guid>46457770</guid>
            <pubDate>Thu, 01 Jan 2026 20:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/software/linux/im-brave-enough-to-say-it-linux-is-good-now-and-if-you-want-to-feel-like-you-actually-own-your-pc-make-2026-the-year-of-linux-on-your-desktop/">https://www.pcgamer.com/software/linux/im-brave-enough-to-say-it-linux-is-good-now-and-if-you-want-to-feel-like-you-actually-own-your-pc-make-2026-the-year-of-linux-on-your-desktop/</a>, See on <a href="https://news.ycombinator.com/item?id=46457770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH.jpg" alt="Linux Designer Linus Torvalds - stock photo. Linus Torvalds was the designer of the open-source operating system Linux." srcset="https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/N7349wfXfd84gf2gpZ6VeH.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Jim Sugar via Getty Images)</span>
</figcaption>
</div>
<div id="article-body">

<p id="03f00f37-bfc1-438c-bb4a-3b391150f953">I'm all-in, baby. I'm <em>committed</em>. If upgrading any distinct component of my PC didn't require me taking out a loan right now, I'd be seriously considering switching my GPU over to some kind of AMD thing just to make my life slightly, slightly easier.</p><p>I've had it with Windows and ascended to the sunlit uplands of Linux, where the trees heave with open-source fruits and men with large beards <a data-analytics-id="inline-link" href="https://en.wikipedia.org/wiki/Grep" target="_blank" data-url="https://en.wikipedia.org/wiki/Grep" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">grep</a> things with their minds.</p><figure data-bordeaux-image-check="" id="31982b71-fa78-48f3-b1a5-a91c6e733d79"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U.jpg" alt="The Convergence wallpaper as used in the Linux-based gaming OS, Bazzite" srcset="https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/vHbmjfxXkyrzwdpKK4Rd6U.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>It's really hard to find interesting screenshots that represent Linux, okay? </span><span itemprop="copyrightHolder">(Image credit: Bazzite)</span></figcaption></figure><p id="a84ff2d5-47a5-4acc-a10b-aa80017de149">I'm not alone. In last month's Steam hardware survey, the number of Linux users hit a new all-time high for the second month running, reaching the heady summit of a whopping, ah, 3.2% of overall Steam users. Hey, we're beating Mac players.</p><p id="a84ff2d5-47a5-4acc-a10b-aa80017de149-1">I think that number will only grow as the new year goes by. More and more of us are getting sick of Windows, sure—the AI guff, the constant upselling on Office subs, the <em>middle taskbar</em>*—but also, all my experience goofing about with Linux this year has dispelled a lot of the, frankly, erroneous ideas I had about it. It's really not hard! Really! I know Linux guys have been saying this for three decades, but it's true now!</p><h2 id="goated-with-the-open-source-sorry-3">Goated with the open source (sorry)</h2><p id="7bb9ef3a-576f-4f23-8836-39fb8c30ac3b">As I've <a data-analytics-id="inline-link" href="https://www.pcgamer.com/software/platforms/you-dont-need-to-wait-for-steamos-to-ditch-windows-ive-been-running-linux-for-the-past-2-months-and-the-revolution-is-already-here/" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/software/platforms/you-dont-need-to-wait-for-steamos-to-ditch-windows-ive-been-running-linux-for-the-past-2-months-and-the-revolution-is-already-here/">already written about</a>, the bulk of my Linux-futzing time this year has been spent in Bazzite, a distro tailor-made for gaming and also tailor-made to stop idiots (me) from doing something likely to detonate their boot drive.</p><figure data-bordeaux-image-check="" id="5f33ce94-3586-48fe-b70b-d84289b78c41"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j.jpg" alt="Peering down the sights of a rifle." srcset="https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/gMqkSANtpSZcpTmVWdhC9j.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Hunt: Showdown running on Bazzite. </span><span itemprop="copyrightHolder">(Image credit: Crytek)</span></figcaption></figure><p id="bd8ce400-c67a-4ea8-9f31-872b119c4a24">I grew up thinking of Linux as 'the command-line OS that lets you delete your bootloader' and, well, I suppose that's not <em>untrue</em>, but I've been consistently impressed at how simple Bazzite has been to run on my PC, even with my persnickety Nvidia GPU.</p><p>Everything I've played this year has been as easy—if not easier—to run on a free OS put together by a gaggle of passionate nerds as it is on Windows, the OS made by one of the most valuable corporations on planet Earth. I've never had to dip into the command line (which is, to be frank, a shame, as the command line is objectively cool).</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-MNR2zcGKjpm4vRFGVVGGML"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div><p>But to be honest, it's not as if the Bazzite team has miraculously made Linux pleasant to use after decades of it seeming difficult and esoteric to normie computer users. I think mainstream Linux distros are just, well, sort of good now. Apart from my gaming PC, I also have an old laptop converted into a media server that lives underneath my television. It runs Debian 13 (which I updated to from Debian 12 earlier in the year) and requires essentially zero input from me at all.</p><p>What's more, the only software I have on there is software I actually <em>want </em>on there. Oh for a version of Windows that let me do something as zany as, I don't know, uninstall Edge.</p><figure data-bordeaux-image-check="" id="45df8509-80fe-43fe-a85d-b6df2b16a210"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS.png" alt="Installing Age of Empires on Linux." srcset="https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/MxF6RyJFq3wPtTeAEQAcHS.png">
</picture></p></div><figcaption itemprop="caption description"><span>Hell yeah. </span></figcaption></figure><p id="27f46b74-7b25-437f-84d0-4fb16264fc3c">That's the true nub of it, I think. The stats can say what they like (and they do! We've all heard tales of Windows games actually <a data-analytics-id="inline-link" href="https://www.pcgamer.com/hardware/the-first-true-1-1-test-we-have-shows-steam-os-getting-better-performance-than-windows-in-10-big-games-tying-in-2-more-and-its-got-me-salivating-for-a-desktop-version-of-valves-os/" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/hardware/the-first-true-1-1-test-we-have-shows-steam-os-getting-better-performance-than-windows-in-10-big-games-tying-in-2-more-and-its-got-me-salivating-for-a-desktop-version-of-valves-os/">running <em>better</em> on Linux</a> via Valve's Proton compatibility layer), but the heart of my fatigue with Windows is that, for every new worthless AI gadget Microsoft crams into it and for every time the OS inexplicably boots to a white screen and implores me to "finish setting up" my PC with an Office 365 subscription, the real problem is a feeling that my computer isn't mine, that I am somehow renting this thing I put together with my own two hands from an AI corporation in Redmond.</p><p>That's fine for consoles. Indeed, part of the whole pitch of an Xbox or PlayStation is the notion that you are handing off a lot of responsibility for your device to Sony and Microsoft's teams of techs, but my PC? That I built? Get your grubby mitts off it.</p><figure data-bordeaux-image-check="" id="7845b546-21df-4b9e-9099-da32d971264d"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH.png" alt="Baldur&amp;#039;s Gate 3 protagonist handles magical polyhedron." srcset="https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/LtuViEu5rJ5KJAH2BgpxEH.png">
</picture></p></div><figcaption itemprop="caption description"><span>BG3 running in Bazzite. </span><span itemprop="copyrightHolder">(Image credit: Larian)</span></figcaption></figure><p id="e68b70d6-4a7c-43e7-ae8d-0672d87c3a0b">Are there issues? Sure. HDR's still a crapshoot (plus ça change) and, as you've no doubt heard, a lot of live-service games have anticheat software that won't play with Linux. But I think both of these issues are gradually ticking toward their solutions, particularly with <a data-analytics-id="inline-link" href="https://www.pcgamer.com/hardware/gaming-pcs/steam-machine-specs-availability/" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/hardware/gaming-pcs/steam-machine-specs-availability/">Valve making its own push into the living room</a>.</p><p>So I say make 2026 the year you give Linux a try, if you haven't already. At the very least, you can stick it on a separate boot drive and have a noodle about with it. I suspect you'll find the open (source) water is a lot more hospitable than you might think.</p><p>*I'm actually fine with the middle taskbar. I'm sorry.</p>
</div>


<div id="slice-container-authorBio-MNR2zcGKjpm4vRFGVVGGML"><p>One of Josh's first memories is of playing Quake 2 on the family computer when he was much too young to be doing that, and he's been irreparably game-brained ever since. His writing has been featured in Vice, Fanbyte, and the Financial Times. He'll play pretty much anything, and has written far too much on everything from visual novels to Assassin's Creed. His most profound loves are for CRPGs, immersive sims, and any game whose ambition outstrips its budget. He thinks you're all far too mean about Deus Ex: Invisible War.</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.pcgamer.com/about-pc-gamer/#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dell's version of the DGX Spark fixes pain points (136 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2025/dells-version-dgx-spark-fixes-pain-points</link>
            <guid>46457027</guid>
            <pubDate>Thu, 01 Jan 2026 19:11:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2025/dells-version-dgx-spark-fixes-pain-points">https://www.jeffgeerling.com/blog/2025/dells-version-dgx-spark-fixes-pain-points</a>, See on <a href="https://news.ycombinator.com/item?id=46457027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Dell sent me two of their GB10 mini workstations to test:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-two.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-91c249ce-34c4-4690-9afb-7b2dbf8552e7" data-insert-attach="{&quot;id&quot;:&quot;91c249ce-34c4-4690-9afb-7b2dbf8552e7&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10"></p>

<p>In this blog post, I'll cover the base system, just one of the two nodes. Cluster testing is ongoing, and I'll cover things like AI model training and networking more in depth next year, likely with comparisons to the <a href="https://www.jeffgeerling.com/blog/2025/i-clustered-four-framework-mainboards-test-huge-llms">Framework Desktop cluster</a> and <a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5">Mac Studio cluster</a> I've also been testing.</p>

<p>But many of the same caveats of the DGX Spark (namely, price to performance is not great if you just want to run LLMs on a small desktop) apply to Dell's GB10 box as well.</p>

<p>It costs a little <em>more</em> than the DGX Spark, but does solve a couple pain points people experienced on the DGX Spark:</p>

<ul>
<li>It has a power LED (seriously, why does the DGX Spark <em>not</em> have one?!)</li>
<li>The included power supply is 280W instead of 240W for a little more headroom</li>
<li>The thermal design (front-to-back airflow) seems less restricted, so is quieter and capable of keeping the GB10 'AI Superchip' from thermal throttling</li>
</ul>

<p>But if this isn't a mini PC to compete with a Mac mini, nor a good value for huge LLMs like a Mac Studio, or AMD's Ryzen AI Max+ 395 machines, what is it and who is it for?</p>

<p>Well, it's a $4,000+ box built specifically for developers in Nvidia's ecosystem, deploying code to Nvidia servers that cost <a href="https://wccftech.com/nvidia-blackwell-dgx-b200-price-half-a-million-dollars-top-of-the-line-ai-hardware/">half a million dollars</a> <em>each</em>. A major part of the selling point are these built-in 200 gigabit QSFP ports, which would cost $1,500 or so to add on to another system, assuming you have the available PCIe bandwidth:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-qsfp-200gbps.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-9914275f-3916-4ac0-a4de-0c22aca075c8" data-insert-attach="{&quot;id&quot;:&quot;9914275f-3916-4ac0-a4de-0c22aca075c8&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 Cluster - QSFP cables"></p>

<p>Those ports can't achieve 400 Gbps, but they <em>do</em> hit over 200 Gbps in the right conditions, configured for Infiniband / RDMA. And they hit over 100 Gbps for Ethernet (though only when running multiple TCP streams).</p>

<p>So it may seem a little bit of an odd duck for me, since I'm not an 'Nvidia developer' and I don't deploy code to Nvidia's 'AI factories'.</p>

<p>If I'm being honest, I'm <em>more</em> interested in the 'Grace' part of the GB10 (or 'Grace Blackwell 10') 'AI Superchip. It's a big.LITTLE Arm CPU co-designed by Mediatek, with 10 Cortex-X925 cores and 10 Cortex-A725 cores.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/grace-blackwell-gb10-ai-superchip-nvidia.jpg" width="700" height="436" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-fc7a15f1-de59-4034-a0f3-37fb075bf485" data-insert-attach="{&quot;id&quot;:&quot;fc7a15f1-de59-4034-a0f3-37fb075bf485&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Nvidia GB10 Grace CPU diagram 20 cores"></p>

<p>The chip is united to the Blackwell GPU, and shares the same 128 GB pool of LPDDR5X memory. And it's a pretty snappy Arm CPU—just stuck in a $4,000+ system.</p>

<p>But like I said, Dell sent me these boxes to test. They aren't paying for this blog post and have no control over what I say.</p>

<p>In fact, one of the main things they said was "this is isn't a gaming machine, so don't focus on that."</p>

<p>But that got me thinking. What if... I <em>did</em>.</p>

<h2>Gaming on Arm Linux</h2>

<p>Valve just announced the Steam Frame, and it <a href="https://www.windowscentral.com/hardware/virtual-reality/valve-announce-steam-frame-snapdragon-xr-headset-steam-os-arm-support">runs on Arm</a>.</p>

<p>Steam Frame will use <a href="https://fex-emu.com/">FEX</a> for its x86-Arm translation layer, and <a href="https://www.codeweavers.com/blog/mjohnson/2025/11/6/twist-our-arm64-heres-the-latest-crossover-preview">CodeWeavers' Crossover Preview for Arm64</a> was just released, so I thought I'd give that a try on DGX OS (Nvidia's Linux OS, currently based on Ubuntu 24.04).</p>

<p>I was able to quickly install Steam, and through that, games like Cyberpunk 2077, Doom Eternal, and Ultimate Epic Battle Simulator II.</p>

<p>I'll leave the full experience and test results for you to see in this video:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/FjRKvKC4ntw" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>But bottom line, the Windows games I typically test on Arm systems through Steam/Proton played very well here, with no stuttering, and decent frame rates (100 fps in Cyberpunk 2077 at 1080p with low settings).</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-gaming-doom-eternal.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-063e7f60-d443-4905-aa50-596163130fc9" data-insert-attach="{&quot;id&quot;:&quot;063e7f60-d443-4905-aa50-596163130fc9&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Doom Eternal 200 fps Dell Pro Max GB10"></p>

<p>But no, I agree with Dell, this box should <em>not</em> be evaluated as a gaming machine. While it performs admirably for an Arm linux box, you could do a lot better with half the budget if you just wanted to build a dedicated gaming rig. Even with RAM prices as they are today.</p>

<h2>General Purpose Arm Workstation (with tons of VRAM)</h2>

<p>This machine is built for AI development, but it just so happens to have a very good Arm CPU and tons of RAM, so I wanted to test it for both running LLMs, and as a general Arm Linux workstation.</p>

<p>The video above has more depth, and you can find <a href="https://github.com/geerlingguy/sbc-reviews/issues/92">all my benchmark data here</a>, but I wanted to focus on a few things in particular.</p>

<h2>Software</h2>

<p>Before we get to benchmarks, I wanted to mention Nvidia's <a href="https://docs.nvidia.com/dgx/dgx-spark/dgx-os.html#release-cadence">DGX OS</a>. Based on Ubuntu Linux, it's the only supported Linux distribution for GB10 systems. Regular Ubuntu LTS versions are supported for 5 years, with optional Pro support extending that out to 10 or even 15 years. But <a href="https://docs.nvidia.com/dgx/dgx-spark/dgx-os.html#release-cadence">DGX OS only guarantees updates for two years</a>, though Nvidia doesn't really offer guarantees for its hardware support.</p>

<p>Their track record for ongoing support for their hardware is <a href="https://developer.nvidia.com/embedded/jetson-linux-archive">decidedly mixed</a>, and in the absence of any guarantees, I wouldn't expect them to continue supporting the Spark or other GB10 systems beyond a few years.</p>

<p><a href="https://forums.developer.nvidia.com/t/has-anyone-tried-an-alternative-linux-distro/349124">Some people have had luck getting other distros running</a>, but they're still running <a href="https://github.com/NVIDIA/NV-Kernels">Nvidia's kernel</a>. So if you buy one of these, know there's no guarantees for ongoing support.</p>

<p>Running things on DGX OS, I've found most server/headless software runs great, but there are still desktop tools that are more of a hassle. Like Blender doesn't have a stable release that uses GPU acceleration on Arm. But if you <a href="https://github.com/CoconutMacaroon/blender-arm64/">compile it from source</a>like GitHub user CoconutMacaroon did, you can get full acceleration.</p>

<p>Just using this box as a little workstation, it is plenty fast for all the things I do, from coding, to browsing the web, to media editing. (Though media workflows are still rough on Linux in general, even on x86.)</p>

<h2>CPU benchmarks</h2>

<p>The Grace CPU is a 20-core Arm chip <a href="https://www.mediatek.com/press-room/newly-launched-nvidia-dgx-spark-features-gb10-superchip-co-designed-by-mediatek">co-designed by Mediatek</a>, fused together with the Blackwell GPU.</p>

<p>There must be some inefficiency there, though, because the system's idle power draw is a bit higher than I'm used to for Arm, coming in around 30 watts. A lot higher than Apple's M3 Ultra with 512GB of RAM, or even AMD's Ryzen AI Max+ 395 (these names just roll right off the tongue, don't they?).</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-power-idle.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-1cfaa4e4-84f2-48dd-a1f5-1c265c2a0345" data-insert-attach="{&quot;id&quot;:&quot;1cfaa4e4-84f2-48dd-a1f5-1c265c2a0345&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - Idle power draw comparison"></p>

<p>In my testing, it seems the CPU itself maxes out around 140 watts, leaving another 140 watts of headroom for the GPU, network, and USB-C ports with PD.</p>

<p>Geekbench 6 was a little unstable, which was weird, but when I did get it to run, it was about on par with the AMD Ryzen AI Max+ 395 system I tested earlier this year, the Framework Desktop.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-geekbench6.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-0a825788-077c-4a54-971e-947415dbeef3" data-insert-attach="{&quot;id&quot;:&quot;0a825788-077c-4a54-971e-947415dbeef3&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - Geekbench 6 comparison"></p>

<p>Apple's 2-generation-old M3 Ultra Mac studio beats both, but it does cost quite a bit more, so that's to be expected.</p>

<p>And testing with High Performance Linpack, the Dell Pro Max gets about 675 Gflops:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-hpl.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-639ede2a-de04-4ad0-b703-8c2d776bb676" data-insert-attach="{&quot;id&quot;:&quot;639ede2a-de04-4ad0-b703-8c2d776bb676&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - HPL comparison"></p>

<p>NVIDIA's marketing said the GB10 <a href="https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips">"offers a petaflop of AI computing performance"</a>—a <em>thousand</em> teraflops! This thing can't even hit <em>one</em>...</p>

<p>But in the fine print, NVIDIA says it's a petaflop at <em>FP4 precision</em>. HPL tests FP64, aka double precision, which is more used in scientific computing. <a href="https://bsky.app/profile/fclc.bsky.social/post/3lc4qpte3ys2o">A FLOP is not always a FLOP</a>, and even the 'petaflop' claim seems disputed, at least if I'm reading <a href="https://x.com/ID_AA_Carmack/status/1982831774850748825">John Carmack's tweets correctly</a>.</p>

<p>But at least for FP64 on the CPU, the GB10 is fairly efficient, at least compared to x86 systems I've tested:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-hpl-efficiency.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-479f4c08-0b47-4303-b90d-317d04312f80" data-insert-attach="{&quot;id&quot;:&quot;479f4c08-0b47-4303-b90d-317d04312f80&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - HPL efficiency comparison"></p>

<h2>Networking Performance</h2>

<p>A huge part of the value is the built-in ConnectX-7 networking. I tested that, and it's fast. But also a bit odd. Here's the maximum TCP performance I was able to get through the fastest interface on each of the three systems I've been comparing:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-network.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-ce70cde6-7dfe-4ef8-adc3-27d566ad6079" data-insert-attach="{&quot;id&quot;:&quot;ce70cde6-7dfe-4ef8-adc3-27d566ad6079&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - Ethernet bandwidth"></p>

<p>But 106 Gigabits isn't 200, is NVIDIA lying?</p>

<p>Well, no... it's a little complicated. For full details, I'll refer you to the ServeTheHome article <a href="https://www.servethehome.com/the-nvidia-gb10-connectx-7-200gbe-networking-is-really-different/">The NVIDIA GB10 ConnectX-7 200GbE Networking is Really Different</a>.</p>

<p>Because the ports are each connected to a x4 PCIe Gen 5 link—which isn't enough bandwidth for 200 Gbps per port. To get a full 200 Gbps, you have to use Infiniband/RDMA and carefully configure the network topology. You won't get more than about 206 Gbps, maximum, in real world throughput, no matter how you set it up.</p>

<p>That's still honestly pretty good, but it's not the same as getting 400 Gbps of networking for AI clustering, like I think some of us expected reading the initial press releases in early 2025...</p>

<p>From the perspective of someone replicating NVIDIA's networking stack locally, though, having ConnectX ports built in is a boon. If you want replicate this kind of developer setup on AMD, you'd have to spend around the same amount of money, for the Max+ 395 plus a Connect-X 7 card.</p>

<p>Many people don't care about clustering use cases, or RDMA or Infiniband, but that doesn't mean it's not extremely useful for the people who <em>do</em>. This stuff's expensive, but to some people, it's not a bad value.</p>

<h2>AI Performance</h2>

<p>For now I'm just running two models, both of them with llama.cpp, optimized for each architecture.</p>

<p>And for a small model that requires a decent amount of CPU to keep up with the GPU, the GB10 does pretty well, almost hitting 100 tokens/s for inference, which is second to the M3 Ultra:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-ai-llama32-3b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-0b422ea5-d743-4a99-b3df-1fa67a9698af" data-insert-attach="{&quot;id&quot;:&quot;0b422ea5-d743-4a99-b3df-1fa67a9698af&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - AI llama small"></p>

<p>But for prompt processing, which is important for how quickly you start seeing a response from AI models, the GB10 chip is the winner, despite costing less than half the M3 Ultra.</p>

<p>And it's a similar story for a huge 'dense' model, Llama 3.1 70B, except here, it gets beat just a little by AMD's Strix Halo in the Framework Desktop:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-ai-llama31-70b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-c19de866-eb76-4092-a0af-e080da4c8f24" data-insert-attach="{&quot;id&quot;:&quot;c19de866-eb76-4092-a0af-e080da4c8f24&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 - AI llama large"></p>

<p>Prompt processing is a strong selling point for these boxes. That's the reason Exo teased <a href="https://blog.exolabs.net/nvidia-dgx-spark/">running a DGX Spark as the compute node</a> for a Mac Studio cluster.</p>

<p>You can have the Spark, or one of these Dell's, handle the thing <em>it's</em> best at, prompt processing, while the Mac Studios handle the thing <em>they're</em> best at, memory bandwidth for token generation.</p>

<p>Anyway, these are just two quick AI benchmarks, and I have <a href="https://github.com/geerlingguy/ai-benchmarks/issues/34">a lot more in the Dell Pro Max with GB10 issue in my ai-benchmarks repository</a>. I'm doing a lot more testing, including model training and how I clustered two of these things in a tiny mini rack, but you'll have to wait until next year for that.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-cluster-display.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-072256d9-4ae0-4da0-ae24-40d07ca37c01" data-insert-attach="{&quot;id&quot;:&quot;072256d9-4ae0-4da0-ae24-40d07ca37c01&quot;,&quot;attributes&quot;:{&quot;alt&quot;:[&quot;alt&quot;,&quot;description&quot;],&quot;title&quot;:[&quot;title&quot;]}}" alt="Dell Pro Max with GB10 mini cluster"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finland detains ship and its crew after critical undersea cable damaged (422 pts)]]></title>
            <link>https://www.cnn.com/2025/12/31/europe/finland-estonia-undersea-cable-ship-detained-intl</link>
            <guid>46456797</guid>
            <pubDate>Thu, 01 Jan 2026 18:46:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/12/31/europe/finland-estonia-undersea-cable-ship-detained-intl">https://www.cnn.com/2025/12/31/europe/finland-estonia-undersea-cable-ship-detained-intl</a>, See on <a href="https://news.ycombinator.com/item?id=46456797">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/12/31/europe/finland-estonia-undersea-cable-ship-detained-intl: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[Cameras and Lenses (2020) (436 pts)]]></title>
            <link>https://ciechanow.ski/cameras-and-lenses/</link>
            <guid>46455872</guid>
            <pubDate>Thu, 01 Jan 2026 17:18:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ciechanow.ski/cameras-and-lenses/">https://ciechanow.ski/cameras-and-lenses/</a>, See on <a href="https://news.ycombinator.com/item?id=46455872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_container">
    <p>December 7, 2020</p>
    <p>Pictures have always been a meaningful part of the human experience. From the first cave drawings, to sketches and paintings, to modern photography, we’ve mastered the art of recording what we see.</p>
<p>Cameras and the lenses inside them may seem a little mystifying. In this blog post I’d like to explain not only how they work, but also how adjusting a few tunable parameters can produce fairly different results:</p>




<p>Over the course of this article we’ll build a simple camera from first principles. Our first steps will be very modest – we’ll simply try to take any picture. To do that we need to have a sensor capable of detecting and measuring light that shines onto it.</p>
<h2 id="recording-light">Recording Light<a href="https://ciechanow.ski/cameras-and-lenses/#recording-light" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>Before the dawn of the digital era, photographs were taken on a piece of film covered in crystals of <a href="https://en.wikipedia.org/wiki/Silver_halide">silver halide</a>. Those compounds are light-sensitive and when exposed to light they form a speck of metallic silver that can later be developed with further chemical processes.</p>
<p>For better or for worse, I’m not going to discuss analog devices – these days most cameras are digital. Before we continue the discussion relating to light we’ll use the classic trick of turning the illumination off. Don’t worry though, we’re not going to stay in darkness for too long.</p>

<div>
        
<p>The <a href="https://en.wikipedia.org/wiki/Image_sensor">image sensor</a> of a digital camera consists of a grid of photodetectors. A&nbsp;photodetector converts photons into electric current that can be measured – the more photons hitting the detector the higher the signal.</p>
<p>In the demonstration below you can observe how photons fall onto the arrangement of detectors represented by small squares. After some processing, the value read by each detector is converted to the brightness of the resulting image pixels which you can see on the right side. I’m also symbolically showing which <em>photosite</em> was hit with a short highlight. The slider below controls the flow of time:</p>


<p>The longer the time of collection of photons the more of them are hitting the detectors and the brighter the resulting pixels in the image. When we don’t gather enough photons the image is <a href="#" onclick="lens_under_exp();return false;">underexposed</a>, but if we allow the photon collection to run for too long the image will be <a href="#" onclick="lens_over_exp();return false;">overexposed</a>.</p>
<p>While the photons have the “color” of their <a href="https://ciechanow.ski/color-spaces/#and-there-was-light">wavelength</a>, the photodetectors don’t see that hue – they only measure the total intensity which results in a black and white image. To record the color information we need to separate the incoming photons into distinct groups. We can put tiny color filters on top of the detectors so that they will only accept, more or less, red, green, or blue light:</p>


<p>This <a href="https://en.wikipedia.org/wiki/Color_filter_array">color filter array</a> can be arranged in many different formations. One of the simplest is a <a href="https://en.wikipedia.org/wiki/Bayer_filter">Bayer filter</a> which uses one red, one blue, and <em>two</em> green filters arranged in a 2x2 grid:</p>

<p>A Bayer filter uses two green filters because light in green part of the spectrum heavily <a href="https://en.wikipedia.org/wiki/Luminosity_function">correlates</a> with perceived brightness. If we now repeat this pattern across the entire sensor we’re able to collect color information. For the next demo we will also double the resolution to an astonishing 1 kilopixel arranged in a 32x32 grid:</p>


<p>Note that the individual sensors themselves still only see the intensity, and not the color, but knowing the arrangement of the filters we can recreate the colored intensity of each sensor, as shown on the right side of the simulation.</p>
<p>The final step of obtaining a normal image is called <a href="https://en.wikipedia.org/wiki/Demosaicing"><em>demosaicing</em></a>. During demosaicing we want to reconstruct the full color information by filling in the gaps in the captured RGB values. One of the simplest way to do it is to just linearly interpolate the values between the existing neighbors. I’m not going to focus on the details of many other available demosaicing algorithms and I’ll just present the resulting image created by the process:</p>


<p>Notice that yet again the overall brightness of the image depends on the length of time for which we let the photons through. That duration is known as <a href="https://en.wikipedia.org/wiki/Shutter_speed"><em>shutter speed</em></a> or exposure time. For most of this presentation I will ignore the time component and we will simply assume that the shutter speed has been set <em>just right</em> so that the image is well exposed.</p>
<p>The examples we’ve discussed so far were very convenient – we were surrounded by complete darkness with the photons neatly hitting the pixels to form a coherent image. Unfortunately, we can’t count on the photon paths to be as favorable in real environments, so let’s see how the sensor performs in more realistic scenarios.</p>
</div>

<p>Over the course of this article we will be taking pictures of this simple scene. The almost white background of this website is also a part of the scenery – it represents a bright overcast sky. You can drag around the demo to see it from other directions:</p>

<p>Let’s try to see what sort of picture would be taken by a sensor that is placed near the objects without any enclosure. I’ll also significantly increase the sensor’s resolution to make the pixels of the final image align with the pixels of your display. In the demonstration below the left side represents a view of the scene with the small greenish sensor present, while the right one shows the taken picture:</p>

<p>This is not a mistake. As you can see, the obtained image doesn’t really resemble anything. To understand why this happens let’s first look at the light radiated from the scene.</p>
<p>If you had a chance to explore how <a href="https://ciechanow.ski/lights-and-shadows/#reflections">surfaces reflect light</a>, you may recall that most matte surfaces scatter the incoming light in every direction. While I’m only showing a few examples, <em>every</em> point on every surface of this scene reflects the photons it receives from the whiteish background light source all around itself:</p>

<p>The red sphere ends up radiating red light, the green sphere radiates green light, and the gray checkerboard floor reflects white light of lesser intensity. Most importantly, however, the light emitted from the background is <em>also</em> visible to the sensor.</p>
<p>The problem with our current approach to taking pictures is that every pixel of the sensor is exposed to the <em>entire</em> environment. Light radiated from every point of the scene and the white background hits every point of the sensor. In the simulation below you can witness how light from different directions hits one point on the surface of the sensor:</p>

<p>Clearly, to obtain a discernible image we have to limit the range of directions that affect a given pixel on the sensor. With that in mind, let’s put the sensor in a box that has a small hole in it. The first slider controls the <span>diameter</span> of the hole, while the second one controls the <span>distance</span> between the opening and the sensor:</p>



<p>While not shown here, the inner sides of the walls are all black so that no light is reflected inside the box. I also put the sensor on the back wall so that the light from the hole shines onto it. We’ve just built a <a href="https://en.wikipedia.org/wiki/Pinhole_camera"><em>pinhole camera</em></a>, let’s see how it performs. Observe what happens to the taken image as we tweak the <span>diameter</span> of the hole with the first slider, or change the <span>distance</span> between the opening and the sensor with the second one:</p>



<p>There are so many interesting things happening here! The most pronounced effect is that the image is inverted. To understand why this happens let’s look at the schematic view of the scene that shows the light rays radiated from the objects, going through the hole, and hitting the sensor:</p>

<p>As you can see the rays cross over in the hole and the formed image is a horizontal and a vertical reflection of the actual scene. Those two flips end up forming a 180° rotation. Since rotated images aren’t convenient to look at, all cameras automatically rotate the image for presentation and for the rest of this article I will do so as well.</p>
<p>When we change the <span>distance</span> between the hole and the sensor the viewing angle changes drastically. If we trace the rays falling on the corner pixels of the sensor we can see that they define the extent of the visible section of the scene:</p>


<p>Rays of light coming from outside of that shape still go through the pinhole, but they land outside of the sensor and aren’t recorded. As the hole moves further away from the sensor, the angle, and thus the <a href="https://en.wikipedia.org/wiki/Field_of_view">field of view</a> visible to the sensor gets smaller. We can see this in a top-down view of the camera:</p>


<p>Coincidentally, this diagram also helps us explain two other effects. Firstly, in the photograph the red sphere looks almost as big as the green one, even though the scene view shows the latter is much larger. However, both spheres end up occupying roughly <a href="#" onclick="lens_field_0();return false;">the same span</a> on the sensor and their size in the picture is similar. It’s also worth noting that the spheres seem to grow when the field of view gets narrower because their light covers larger part of the sensor.</p>
<p>Secondly, notice that different pixels of the sensor have different distance and relative orientation to the hole. The pixels right in the center of the sensor see the pinhole straight on, but pixels positioned at an angle to the main axis see a distorted pinhole that is further away. The ellipse in the bottom right corner of the demonstration below shows how a pixel positioned at the blue point sees the pinhole:</p>


<p>This change in the visible area of the hole causes the darkening we see in the corners of the photograph. The value of the <em>cosine</em> of the angle I’ve marked with a <span>yellow color</span> is quite important as it contributes to the reduction of visible light in four different ways:</p>
<ul>
<li>Two cosine factors from the increased distance to the hole, it’s essentially the <a href="https://ciechanow.ski/lights-and-shadows/#inverse_square">inverse square law</a></li>
<li>A cosine factor from the side squeeze of the circular hole seen at an angle</li>
<li>A cosine factor from the relative <a href="https://ciechanow.ski/lights-and-shadows/#cosine_factor">tilt of the receptor</a></li>
</ul>
<p>These four factors conspire together to reduce the illumination by a factor of <strong>cos<sup>4</sup>(α)</strong> in what is known as <em>cosine-fourth-power law</em>, also described as <a href="https://en.wikipedia.org/wiki/Vignetting#Natural_vignetting">natural vignetting</a>.</p>
<p>Since we know the relative geometry of the camera and the opening we can correct for this effect by simply dividing by the falloff factor and from this point on I will make sure that the images don’t have darkened corners.</p>
<p>The final effect we can observe is that when the hole gets smaller the image gets sharper. Let’s see how the light radiated from two points of the scene ends up going through the camera depending on the <span>diameter</span> of the pinhole:</p>


<p>We can already see that larger hole size ends up creating a bigger spread on the sensor. Let’s see this situation up close on a simple grid of detecting cells. Notice what happens to the size of the final circle hitting the sensor as that <span>diameter</span> of the hole changes:</p>


<p>When the hole is <a href="#" onclick="lens_sharp_0();return false;">small enough</a> rays from the source only manage to hit one pixel on the sensor. However, at <a href="#" onclick="lens_sharp_1();return false;">larger radii</a> the light spreads onto other pixels and a tiny point in the scene is no longer represented by a single pixel causing the image to no longer be sharp.</p>
<p>It’s worth pointing out that sharpness is ultimately arbitrary – it depends on the size at which the final image is seen, viewing conditions, and visual acuity of the observer. The same photograph that looks sharp on a postage stamp may in fact be very blurry when seen on a big display.</p>
<p>By reducing the size of the cone of light we can make sure that the source light affects a limited number of pixels. Here, however, lays the problem. The sensor we’ve been using so far has been an idealized detector capable of flawless adjustment of its sensitivity to the lighting conditions. If we instead were to fix the sensor sensitivity adjustment, the captured image would look more like this:</p>



<p>As the relative size of the hole visible to the pixels of the sensor gets smaller, be it due to reduced <span>diameter</span> or increased <span>distance</span>, fewer photons hit the surface and the image gets dimmer.</p>
<p>To increase the number of photons we capture we could extend the duration of collection, but increasing the exposure time comes with its own problems – if the photographed object moves or the camera isn’t held steady we risk introducing some <a href="https://en.wikipedia.org/wiki/Motion_blur">motion blur</a>.</p>
<p>Alternatively, we could increase the <a href="https://en.wikipedia.org/wiki/Film_speed">sensitivity</a> of the sensor which is described using the ISO rating. However, boosting the ISO may introduce a higher level of <a href="https://en.wikipedia.org/wiki/Image_noise">noise</a>. Even with these problems solved an actual image obtained by smaller and smaller holes would actually start getting blurry again due to <a href="https://en.wikipedia.org/wiki/Diffraction">diffraction</a> effects of light.</p>
<p>If you recall how diffuse surfaces reflect light you may also realize how incredibly inefficient a pinhole camera is. A single point on the surface of an object radiates light into its surrounding hemisphere, however, the pinhole captures only a tiny portion of that light.</p>
<p>More importantly, however, a pinhole camera gives us minimal artistic control over <em>which</em> parts of the picture are blurry. In the demonstration below you can witness how changing which object is in focus heavily affects what is the primary target of attention of the photograph:</p>


<p>Let’s try to build an optical device that would solve both of these problems: we want to find a way to harness a bigger part of the energy radiated by the objects and also control what is blurry and <em>how</em> blurry it is. For the objects in the scene that are supposed to be sharp we want to collect a big chunk of their light and make it converge to the smallest possible point. In essence, we’re looking for an instrument that will do something like this:</p>

<p>We could then put the sensor at the focus point and obtain a sharp image. Naturally, the contraption we’ll try to create has to be transparent so that the light can pass through it and get to the sensor, so let’s begin the investigation by looking at a piece of glass.</p>
<h2 id="glass">Glass<a href="https://ciechanow.ski/cameras-and-lenses/#glass" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>In the demonstration below I put a red stick behind a pane of glass. You can adjust the thickness of this pane with the <span>gray slider</span> below:</p>


<p>When you look at the stick through the surface of a thick glass <a href="#" onclick="lens_glass_0();return false;">straight on</a>, everything looks normal. However, as your viewing direction <a href="#" onclick="lens_glass_1();return false;">changes</a> the stick seen through the glass seems out of place. The thicker the glass and the steeper the viewing angle the bigger the offset.</p>
<p>Let’s focus on one point on the surface of the stick and see how the rays of light radiated from its surface propagate through the subsection of the glass. The <span>red slider</span> controls the position of the source and the <span>gray slider</span> controls the thickness.  You can drag the demo around to see it from different viewpoints:</p>



<p>For some reason the rays passing through glass at an angle are <a href="#" onclick="lens_glass_rays_0();return false;">deflected off their paths</a>. The change of direction happens whenever the ray enters or leaves the glass.</p>
<p>To understand <em>why</em> the light changes direction we have to peek under the covers of <a href="https://en.wikipedia.org/wiki/Classical_electromagnetism">classical electromagnetism</a> and talk a bit more about waves.</p>
<h2 id="waves">Waves<a href="https://ciechanow.ski/cameras-and-lenses/#waves" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>It’s impossible to talk about wave propagation without involving the time component, so the simulations in this section are animated – you can play and pause them by <span>clicking</span><span>tapping</span> on the button in their bottom left corner.</p>
<p>By default all animations are <span id="global_animate_on">enabled, but if you find them distracting, or if you want to save power, you can <a href="#" onclick="global_animate(false);return false;">globally pause</a> all the following demonstrations.</span><span id="global_animate_off">disabled, but if you’d prefer to have things moving as you read you can <a href="#" onclick="global_animate(true);return false;">globally unpause</a> them and see all the waves oscillating.</span></p>
<p>Let’s begin by introducing the simplest sinusoidal wave:</p>



<p>A wave like this can be characterized by two components. <a href="https://en.wikipedia.org/wiki/Wavelength">Wavelength</a> <strong>λ</strong> is the distance over which the shape of the wave repeats. Period <strong>T</strong> defines how much time a full cycle takes.</p>
<p><a href="https://en.wikipedia.org/wiki/Frequency">Frequency</a> <strong>f</strong>, is just a reciprocal of period and it’s more commonly used – it defines how many waves per second have passed over some fixed point. Wavelength and frequency define <a href="https://en.wikipedia.org/wiki/Phase_velocity">phase velocity</a> <strong>v<sub>p</sub></strong> which describes how quickly a point on a wave, e.g. a peak, moves:</p>
<p><span>v<sub>p</sub></span> = <span>λ</span> · <span>f</span> 
</p>
<p>The sinusoidal wave is the building block of a polarized electromagnetic plane wave. As the name implies electromagnetic radiation is an interplay of oscillations of electric field <strong>E</strong> and magnetic field <strong>B</strong>:</p>

<p>In an electromagnetic wave the magnetic field is tied to the electric field so I’m going to hide the former and just visualize the latter. Observe what happens to the electric component of the field as it passes through a block of glass. I need to note that dimensions of wavelengths are <em>not</em> to scale:</p>

<p>Notice that the wave remains continuous at the boundary and inside the glass the frequency of the passing wave remains constant, However, the wavelength and thus the phase velocity are reduced – you can see it clearly <a href="#" onclick="lens_wave_glass_0();return false;">from the side</a>.</p>
<p>The microscopic reason for the phase velocity change is <a href="https://en.wikipedia.org/wiki/Ewald%E2%80%93Oseen_extinction_theorem">quite complicated</a>, but it can be quantified using the <a href="https://en.wikipedia.org/wiki/Refractive_index"><em>index of refraction</em></a> <strong>n</strong>, which is the ratio of the speed of light <strong>c</strong> to the phase velocity <strong>v<sub>p</sub></strong> of lightwave in that medium:</p>
<p><span>n</span> = <span><span>c</span>
    <span>/</span>
    <span>v<sub>p</sub></span>
</span>
</p>
<p>The higher the index of refraction the <em>slower</em> light propagates through the medium. In the table below I’ve presented a few different indices of refraction for some materials:</p>
<table>
<tbody><tr><td>vacuum</td><td>1.00</td></tr>
<tr><td>air</td><td>1.0003</td></tr>
<tr><td>water</td><td>1.33</td></tr>
<tr><td>glass</td><td>1.53</td></tr>
<tr><td>diamond</td><td>2.43</td></tr>
</tbody></table>
<p>Light traveling through air barely slows down, but in a diamond it’s over twice as slow. Now that we understand how <span>index of refraction</span> affects the wavelength in the glass, let’s see what happens when we change the <span>direction</span> of the incoming wave:</p>



<p>The wave in the glass has a shorter wavelength, but it still has to match the positions of its peaks and valleys across the boundary. As such, the direction of propagation <a href="#" onclick="lens_wave_glass_2();return false;">must change</a> to ensure that continuity.</p>
<p>I need to note that the previous two demonstrations presented a two dimensional wave since that allowed me to show the sinusoidal component oscillating into the third dimension. In real world the lightwaves are three dimensional and I can’t really visualize the sinusoidal component without using the fourth dimension which has <a href="https://ciechanow.ski/tesseract/">its own set of complications</a>.</p>
<p>The alternative way of presenting waves is to use <a href="https://en.wikipedia.org/wiki/Wavefront"><em>wavefronts</em></a>. Wavefronts connect the points of the same phase of the wave, e.g. all the peaks or valleys. In two dimensions wavefronts are represented by lines:</p>

<p>In three dimensions the wavefronts are represented by <em>surfaces</em>. In the demonstration below a single source emits a spherical wave, points of the same phase in the wave are represented by the moving shells:</p>

<p>By drawing lines that are perpendicular to the surface of the wavefront we create the familiar rays. In this interpretation rays simply show the local direction of wave propagation which can be seen in this example of a section of a spherical 3D wave:</p>

<p>I will continue to use the ray analogy to quantify the change in direction of light passing through materials. The relation between the angle of incidence <strong>θ<sub>1</sub></strong> and angle of refraction <strong>θ<sub>2</sub></strong> can be formalized with the equation known as <a href="https://en.wikipedia.org/wiki/Snell%27s_law">Snell’s law</a>:</p>
<p><span>n<sub>1</sub></span> · sin(θ<sub>1</sub>) = <span>n<sub>2</sub></span> · sin(θ<sub>2</sub>)
</p>
<p>It describes how a ray of light changes direction relative to the surface normal on the border between two different media. Let’s see it in action:</p>




<p>When traveling from a less to more refractive material the ray bends <a href="#" onclick="lens_snell_0();return false;"><em>towards</em> the normal</a>, but when the ray exits the object with higher index of refraction it bends <a href="#" onclick="lens_snell_1();return false;"><em>away</em> from the normal</a>.</p>
<p>Notice that in <a href="#" onclick="lens_snell_2();return false;">some configurations</a> the refracted ray completely disappears, however, this doesn’t paint a full picture because we’re currently completely ignoring reflections.</p>
<p>All transparent objects reflect some amount of light. You may have noticed that reflection on a surface of a calm lake or even on the other side of the glass demonstration at the beginning of the <a href="#glass">previous section</a>. The intensity of that reflection depends on the index of refraction of the material and the angle of the incident ray. Here’s a more realistic demonstration of how light would get refracted <em>and</em> reflected between two media:</p>




<p>The relation between <em>transmittance</em> and <em>reflectance</em> is determined by <a href="https://en.wikipedia.org/wiki/Fresnel_equations">Fresnel equations</a>. Observe that the curious case of missing light that we saw previously <a href="#" onclick="lens_snell_3();return false;">no longer occurs</a> – that light is actually reflected. The transition from partial reflection and refraction to the complete reflection is continuous, but near the end it’s very rapid and at some point the refraction <a href="#" onclick="lens_snell_4();return false;">completely disappears</a> in the effect known as <a href="https://en.wikipedia.org/wiki/Total_internal_reflection">total internal reflection</a>.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Total_internal_reflection#Critical_angle"><em>critical angle</em></a> at which the total internal reflection starts to happen depends on the indices of refraction of the boundary materials. Since that coefficient is low for air, but very high for diamond a <a href="https://en.wikipedia.org/wiki/Brilliant_(diamond_cut)">proper cut</a> of the faces <a href="https://physics.stackexchange.com/questions/43361/why-do-diamonds-shine/43373#43373">makes diamonds</a> very shiny.</p>
<p>While interesting on its own, reflection in glass isn’t very relevant to our discussion and for the rest of this article we’re not going to pay much attention to it. Instead, we’ll simply assume that the materials we’re using are covered with high quality <a href="https://en.wikipedia.org/wiki/Anti-reflective_coating">anti-reflective coating</a>.</p>
<h2 id="manipulating-rays">Manipulating Rays<a href="https://ciechanow.ski/cameras-and-lenses/#manipulating-rays" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>Let’s go back to the example that started the discussion of light and glass. When both sides of a piece of glass are parallel, the ray is shifted, but it still travels in the same direction. Observe what happens to the ray when we change the relative angle of the surfaces of the glass.</p>


<p>When we make two surfaces of the glass <em>not</em> parallel we gain the ability to change the direction of the rays. Recall, that we’re trying to make the rays hitting the optical device <em>converge</em> at a certain point. To do that we have to bend the rays in the upper part down and, conversely, bend the rays in the lower part up.</p>
<p>Let’s see what happens if we shape the glass to have different angles between its walls at different height. In the demonstration below you can control how many distinct segments a piece of glass is shaped to:</p>

<p>As the number of segments <a href="#" onclick="lens_subdiv_0();return false;">approaches infinity</a> we end up with a continuous surface without any edges. If we look at the crossover point <a href="#" onclick="lens_subdiv_1();return false;">from the side</a> you may notice that we’ve managed to converge the rays across one axis, but the top-down view <a href="#" onclick="lens_subdiv_2();return false;">reveals</a> that we’re not done yet. To focus all the rays we need to replicate that smooth shape across <em>all</em> possible directions – we need rotational symmetry:</p>

<p>We’ve created a <em>convex</em> <a href="https://en.wikipedia.org/wiki/Thin_lens">thin lens</a>. This lens is idealized, in the later part of the article we’ll discuss how real lenses aren’t as perfect, but for now it will serve us very well. Let’s see what happens to the focus point when we change the position of the <span>red</span> source:</p>


<p>When the source is positioned <a href="#" onclick="lens_inf();return false;">very far away</a> the incoming rays become parallel and after passing through lens they converge at a certain distance away from the center. That distance is known as <a href="https://en.wikipedia.org/wiki/Focal_length"><em>focal length</em></a>.</p>
<p>The previous demonstration also shows two more general distances: <strong>s<sub>o</sub></strong> which is the distance between the <strong>o</strong>bject, or source, and the lens, as well as <strong>s<sub>i</sub></strong> which is the distance between the <strong>i</strong>mage and the lens. These two values and the focal length <strong>f</strong> are related by the <a href="https://en.wikipedia.org/wiki/Thin_lens#Image_formation"><em>thin lens equation</em></a>:</p>
<p><span><span>1</span>
    <span>/</span>
    <span>s<sub>o</sub></span>
</span>
+
<span><span>1</span>
    <span>/</span>
    <span>s<sub>i</sub></span>
</span>
=
<span><span>1</span>
    <span>/</span>
    <span>f</span>
</span>
</p>
<p>Focal length of a lens depends on both the <span>index of refraction</span> of the material from which the lens is made and its <span>shape</span>:</p>



<p>Now that we understand how a simple convex lens works we’re ready to mount it into the hole of our camera. We will still control the <span>distance</span>  between the sensor and the lens, but instead of controlling the diameter of the lens we’ll instead control its <span>focal length</span>:</p>



<p>When you look at the lens <a href="#" onclick="lens_camera_lens();return false;">from the side</a> you may observe how the <span>focal length</span> change is tied to the shape of the lens. Let’s see how this new camera works in action:</p>



<p>Once again, a lot of things are going on here! Firstly, let’s try to understand how the image is formed in the first place. The demonstration below shows paths of rays from two separate points in the scene. After going through the lens they end up hitting the sensor:</p>



<p>Naturally, this process happens for <em>every</em> single point in the scene which creates the final image. Similarly to a pinhole a convex lens creates an inverted picture – I’m still correcting for this by showing you a rotated photograph.</p>
<p>Secondly, notice that the distance between the lens and the sensor still controls the field of view. As a reminder, the focal length of a lens simply defines the distance from the lens at which the rays coming from infinity converge. To achieve a sharp image, the sensor has to be placed at the location where the rays focus and <em>that’s</em> what’s causing the field of view to change.</p>
<p>In the demonstration below I’ve visualized how rays from a very far object focus through a lens of adjustable <span>focal length</span>, notice that to obtain a sharp image we must change the <span>distance</span> between the lens and the sensor which in turn causes the field of view to change:</p>



<p>If we want to change the object on which a camera with a lens of a fixed focal length is focused, we have to move the image plane closer or further away from the lens which affects the angle of view. This effect is called <a href="https://en.wikipedia.org/wiki/Breathing_(lens)">focus breathing</a>:</p>


<p>A lens with a fixed focal length like the one above is often called a <em>prime</em> lens, while lenses with adjustable focal length are called <em>zoom</em> lenses. While the lenses in our eyes do dynamically adjust their focal lengths by changing their shape, rigid glass can’t do that so zoom lenses use a system of multiple glass elements that change their relative position to achieve this effect.</p>
<p>In the simulation above notice the difference in sharpness between the red and green spheres. To understand why this happens let’s analyze the rays emitted from two points on the surface of the spheres. In the demonstration below the right side shows the light seen by the sensor <em>just</em> from the two marked points on the spheres:</p>


<p>The light from the point in focus converges to a point, while the light from an out-of-focus point spreads onto a circle. For larger objects the multitude of overlapping out-of-focus circles creates a smooth blur called
<a href="https://en.wikipedia.org/wiki/Bokeh"><em>bokeh</em></a>. With tiny and bright light sources that circle itself is often visible, you may have seen effects like the one in the demonstration below in some photographs captured in darker environments:</p>



<p>Notice that the circular shape is visible for lights both in front of and behind the focused distance. As the object is positioned closer or further away from the lens the image plane “slices” the cone of light at different location:</p>


<p>That circular spot is called a <a href="https://en.wikipedia.org/wiki/Circle_of_confusion"><em>circle of confusion</em></a>. While in many circumstances the blurriness of the background or the foreground looks very appealing, it would be very useful to control how much blur there is.</p>
<p>Unfortunately, we don’t have total freedom here – we still want the primary photographed object to remain in focus so its light has to converge to a point. We just want to change the size of the circle of out-of-focus objects without moving the central point. We can accomplish that by changing the <em>angle</em> of the cone of light:</p>


<p>There are two methods we can use to modify that angle. Firstly, we can change the focal length of the lens – you may recall that with longer focal lengths the cone of light also gets longer. However, changing the focal length and keeping the primary object in focus requires moving the image plane which in turn changes how the picture is framed.</p>
<p>The alternative way of reducing the angle of the cone of light is to simply ignore some of the “outer” rays. We can achieve that by introducing a stop with a hole in the path of light:</p>


<p>This hole is called an <a href="https://en.wikipedia.org/wiki/Aperture"><em>aperture</em></a>. In fact, even the hole in which the lens is mounted is an aperture of some sort, but what we’re introducing is an <em>adjustable</em> aperture:</p>



<p>Let’s try to see how an aperture affects the photographs taken with our camera:</p>



<p>In real camera lenses an adjustable aperture is often constructed from a set of overlapping blades that constitute an <em>iris</em>. The movement of those blades changes the size of the aperture:</p>


<p>The shape of the aperture also defines the shape of bokeh. This is the reason why bokeh sometimes has a polygonal shape – it’s simply the shape of the “cone” of light after passing through the blades of the aperture. Next time you watch a movie pay a close attention to the shape of out-of-focus highlights, they’re often polygonal:</p>


<p>As the aperture diameter decreases, larger and larger areas of the photographed scene remain sharp. The term <a href="https://en.wikipedia.org/wiki/Depth_of_field"><em>depth of field</em></a> is used to define the length of the region over which the objects are acceptably sharp. When describing the depth of field we’re trying to conceptually demark those two boundary planes and see how far apart they are from each other.</p>
<p>Let’s see the depth of field in action. The <span>black slider</span> controls the aperture, the <span>blue slider</span> controls the focal length, and the <span>red slider</span> changes the position of the object relative to the camera. The <span><strong>green dot</strong></span> shows the place of perfect focus, while the <span><strong>dark blue dots</strong></span> show the limits, or the depth, of positions between which the image of the red light source will be reasonably sharp, as shown by a single outlined pixel on the sensor:</p>




<p>Notice that <a href="#" onclick="lens_dof_0();return false;">the larger</a> the <span>diameter of aperture</span> and <a href="#" onclick="lens_dof_1();return false;">the shorter</a> the <span>focal length</span> the shorter the distance between the <span><strong>dark blue dots</strong></span> and thus the <em>shallower</em> the depth of field becomes. If you recall our discussion of sharpness this demonstration should make it easier to understand why reducing the angle of the cone <em>increases</em> the depth of field.</p>
<p>If you don’t have perfect vision you may have noticed that squinting your eyes make you see things a little better. Your eyelids covering some part of your iris simply act as an aperture that decreases the angle of the cone of light falling into your eyes making things sightly less blurry on your retina.</p>
<p>An interesting observation is that aperture defines the diameter of the base of the captured cone of light that is emitted from the object. Twice as large aperture diameter captures roughly <em>four</em> times more light due to increased <a href="https://ciechanow.ski/lights-and-shadows/#solid-angles">solid angle</a>. In practice, the actual size of the aperture as seen from the point of view of the scene, or the <a href="https://en.wikipedia.org/wiki/Entrance_pupil"><em>entrance pupil</em></a>, depends on all the lenses in front of it as the shaped glass may scale the perceived size of the aperture.</p>
<p>On the other hand, when a lens is focused correctly, the focal length defines how large a source object is in the picture. By doubling the focal length we double the width <em>and</em> the height of the object on the sensor thus increasing the area by the factor of four. The light from the source is more spread out and each individual pixel receives less light.</p>
<p>The total amount of light hitting each pixel is proportional to the <em>ratio</em> between the focal length <strong>f</strong> and the diameter of the entrance pupil <strong>D</strong>. This ratio is known as the <a href="https://en.wikipedia.org/wiki/F-number"><em>f-number</em></a>:</p>
<p><span>N</span> = <span><span>f</span>
    <span>/</span>
    <span>D</span>
</span>
</p>
<p>A lens with a focal length of 50 mm and the entrance pupil of 25 mm would have <strong>N</strong> equal to 2 and the <em>f</em>-number would be known as <em>f</em>/2. Since the amount of light getting to each pixel of the sensor increases with the diameter of the aperture and decreases with the focal length, the <em>f</em>-number controls the brightness of the projected image.</p>
<p>The <em>f</em>-number with which commercial lenses are marked usually defines the maximum aperture a lens can achieve and the smaller the <em>f</em>-number the more light the lens passes through. Bigger amount of incoming light allows reduction of exposure time, so the smaller the <em>f</em>-number the <a href="https://en.wikipedia.org/wiki/Lens_speed"><em>faster</em></a> the lens is. By reducing the size of the aperture we can modify the <em>f</em>-number with which a picture is taken.</p>
<p>The <em>f</em>-numbers are often multiples of 1.4 which is an approximation of <span>2</span>. Scaling the diameter of an adjustable aperture by <span>2</span> scales its <em>area</em> by 2 which is a convenient factor to use. Increasing the <em>f</em>-number by a so-called <a href="https://en.wikipedia.org/wiki/F-number#Stops,_f-stop_conventions,_and_exposure"><em>stop</em></a> halves the amount of received light. The demonstration below shows the relatives sizes of the aperture through which light is being seen:</p>

<div>
        


<p>To maintain the overall brightness of the image when <a href="https://en.wikipedia.org/wiki/Stopping_down">stopping down</a> we’d have to either increase the exposure time or the sensitivity of the sensor.</p>
</div>

<p>While aperture settings let us easily control the depth of field, that change comes at a cost. When the <em>f</em>-number increases and the aperture diameter gets smaller we effectively start approaching a pinhole camera with all its related complications.</p>
<p>In the final part of this article we will discuss the entire spectrum of another class of problems that we’ve been conveniently avoiding all this time.</p>
<h2 id="aberrations">Aberrations<a href="https://ciechanow.ski/cameras-and-lenses/#aberrations" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>In our examples so far we’ve been using a perfect idealized lens that did exactly what we want and in all the demonstrations I’ve relied on a certain simplification known as the <a href="https://en.wikipedia.org/wiki/Paraxial_approximation">paraxial approximation</a>. However, the physical world is a bit more complicated.</p>
<p>The most common types of lenses are <em>spherical</em> lenses – their curved surfaces are sections of spheres of different radii. These types of lenses are easier to manufacture, however, they actually don’t perfectly converge the rays of incoming light. In the demonstration below you can observe how fuzzy the focus point is for various lens radii:</p>


<p>This imperfection is known as <a href="https://en.wikipedia.org/wiki/Spherical_aberration"><em>spherical aberration</em></a>. This specific flaw can be corrected with <a href="https://en.wikipedia.org/wiki/Aspheric_lens"><em>aspheric lenses</em></a>, but unfortunately there are other types of problems that may not be easily solved by a single lens. In general, for monochromatic light there are five primary types of aberrations: <a href="https://en.wikipedia.org/wiki/Spherical_aberration">spherical aberration</a>, <a href="https://en.wikipedia.org/wiki/Coma_(optics)">coma</a>, <a href="https://en.wikipedia.org/wiki/Astigmatism_(optical_systems)">astigmatism</a>, <a href="https://en.wikipedia.org/wiki/Petzval_field_curvature">field curvature</a>, and <a href="https://en.wikipedia.org/wiki/Distortion_(optics)">distortion</a>.</p>
<p>We’re still not out of the woods even if we manage to minimize these problems. In normal environments light is very <em>non</em>-monochromatic and nature sets another hurdle into optical system design. Let’s quickly go back to the dark environment as we’ll be discussing a single beam of white light.</p>

<div>
        
<p>Observe what happens to that beam when it hits a piece of glass. You can make the sides non-parallel by using the slider:</p>


<p>What we perceive as white light is a combination of lights of different wavelengths. In fact, the index of refraction of materials <em>depends</em> on the wavelength of the light. This phenomena called <a href="https://en.wikipedia.org/wiki/Dispersion_(optics)"><em>dispersion</em></a> splits what seems to be a uniform beam of white light into a fan of color bands. The very same mechanism that we see here is also responsible for a rainbow.</p>
<p>In a lens this causes different wavelengths of light to focus at different offsets – the effect known as <a href="https://en.wikipedia.org/wiki/Chromatic_aberration"><em>chromatic aberration</em></a>. We can easily visualize the <em>axial</em> chromatic aberration even on a lens with spherical aberration fixed. I’ll only use red, green, and blue dispersed rays to make things less crowded, but remember that other colors of the spectrum are present in between. Using the slider you can control the amount of dispersion the lens material introduces:</p>


<p>Chromatic aberration may be corrected with an <a href="https://en.wikipedia.org/wiki/Achromatic_lens">achromatic lens</a>, usually in the form of a <a href="https://en.wikipedia.org/wiki/Doublet_(lens)">doublet</a> with two different types of glass fused together.</p>
<br>

    </div>


<p>To minimize the impact of the aberrations, camera lenses use more than one optical element on their pathways. In this article I’ve only shown you simple lens systems, but a high-end camera lens may consist of <a href="https://en.wikipedia.org/wiki/File:Objective_Zeiss_Cut.jpg">a lot of elements</a> that were carefully designed to balance the optical performance, weight, and cost.</p>
<p>While we, in our world of computer simulations on this website, can maintain the illusion of simple and perfect systems devoid of aberrations, <a href="https://en.wikipedia.org/wiki/Vignetting">vignetting</a>, and <a href="https://en.wikipedia.org/wiki/Lens_flare">lens flares</a>, real cameras and lenses have to deal with all these problems to make the final pictures look good.</p>
<h2 id="further-watching-and-reading">Further Watching and Reading<a href="https://ciechanow.ski/cameras-and-lenses/#further-watching-and-reading" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>Over on YouTube <a href="https://www.youtube.com/channel/UCSFAYalJ2Q7Tm_WmLgetmeg">Filmmaker IQ channel</a> has a lot of great content related to lenses and movie making. Two videos especially fitting here are <a href="https://www.youtube.com/watch?v=1YIvvXxsR5Y">The History and Science of Lenses</a> and <a href="https://www.youtube.com/watch?v=lte9pa3RtUk">Focusing on Depth of Field and Lens Equivalents</a>.</p>
<p><a href="https://www.youtube.com/watch?v=q1n2DR6H7mk">What Makes Cinema Lenses So Special!?</a> on <a href="https://www.youtube.com/channel/UCNJe8uQhM2G4jJFRWiM89Wg">Potato Jet channel</a> is a great interview with Art Adams from <a href="https://www.arri.com/en/">ARRI</a>. The video goes over many interesting details of high-end cinema lens design, for example, how the lenses <a href="https://youtu.be/q1n2DR6H7mk?t=370">compensate for focus breathing</a>, or how much attention is paid to the <a href="https://youtu.be/q1n2DR6H7mk?t=899">quality of bokeh</a>.</p>
<p>For a deeper dive on bokeh itself Jakub Trávník’s <a href="https://jtra.cz/stuff/essays/bokeh/index.html">On Bokeh</a> is a great article on the subject. The author explains how aberrations may cause bokeh of non uniform intensity and shows many photographs of real cameras and lenses.</p>
<p>In this article I’ve mostly been using <a href="https://en.wikipedia.org/wiki/Geometrical_optics">geometrical optics</a> with some soft touches of electromagnetism. For a more modern look at the nature of light and its interaction with matter I recommend Richard Feynman’s <a href="https://en.wikipedia.org/wiki/QED:_The_Strange_Theory_of_Light_and_Matter">QED: The Strange Theory of Light and Matter</a>. The book is written in a very approachable style suited for general audience, but it still lets Feynman’s wits and brilliance shine right through.</p>
<h2 id="final-words">Final Words<a href="https://ciechanow.ski/cameras-and-lenses/#final-words" arialabel="Anchor"><img src="https://ciechanow.ski/images/anchor.png" width="16px" height="8px"></a> </h2>
<p>We’ve barely scratched the surface of optics and camera lens design, but even the most complex systems end up serving the same purpose: to tell light where to go. In some sense optical engineering is all about taming the nature of light.</p>
<p>The simple act of pressing the shutter button in a camera app on a smartphone or on the body of a high-end DSLR is effortless, but it’s at this moment when, through carefully guided rays hitting an array of photodetectors, we immortalize reality by painting with light.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sony PS5 ROM keys leaked – jailbreaking could be made easier with BootROM codes (258 pts)]]></title>
            <link>https://www.tomshardware.com/video-games/playstation/playstation-5-rom-keys-leaked-jailbreaking-could-be-made-easier-with-bootrom-codes</link>
            <guid>46455053</guid>
            <pubDate>Thu, 01 Jan 2026 15:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/video-games/playstation/playstation-5-rom-keys-leaked-jailbreaking-could-be-made-easier-with-bootrom-codes">https://www.tomshardware.com/video-games/playstation/playstation-5-rom-keys-leaked-jailbreaking-could-be-made-easier-with-bootrom-codes</a>, See on <a href="https://news.ycombinator.com/item?id=46455053">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>

<div id="article-body">

<p id="1de52338-63f3-4f30-ab8e-b2f1027cd57e">The PlayStation 5’s ROM keys have allegedly been leaked, meaning anyone who can get their hands on the hex strings now has the hardware code that will allow jailbreakers to try decrypting and analyzing the console’s bootloader. According to <a data-analytics-id="inline-link" href="https://thecybersecguru.com/news/ps5-rom-keys-leaked/" data-url="https://thecybersecguru.com/news/ps5-rom-keys-leaked/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">The Cybersec Guru</a>, this is an unpatchable problem for <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/sony" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.tomshardware.com/tag/sony">Sony</a>, because these keys cannot be changed and are burned directly in the APU. The only way that the company can invalidate the leaked codes is to replace the chips on yet-to-be-manufactured units, meaning consoles that are already in the wild could possibly take advantage of future jailbreaks stemming from the use of these leaked codes.</p><p>When you turn on the PS5, its CPU runs the BootROM code that’s baked in the chip and uses the ROM keys to ensure that Bootloader is valid. Now that the ROM keys have been leaked (and assuming they are valid), a hacker could then decrypt and study the official bootloader and potentially use that as a starting point to understand how the PS5’s boot system works. Since the issue is at a hardware level, Sony would not be able to release an update that will stop consoles with the compromised chip from loading kernel-level exploits in the future, should one become available.</p><p>This isn’t the first time that Sony has had to deal with a security crisis with the popular PlayStation family. The PlayStation 3 was previously hit with a vulnerability when the company made a mistake with their cryptography on the console, allowing users to install homebrew software and allow piracy and cheating on popular titles. We also saw this with the Nintendo Switch, when a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/tegra-vulnerability-affects-every-nintendo-switch,36942.html" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.tomshardware.com/news/tegra-vulnerability-affects-every-nintendo-switch,36942.html">flaw in the Nvidia Tegra X1 chip that it used let tinkerers run Linux on the handheld</a>.</p><p>Sony has yet to release a statement regarding the hack, but the company could release revised hardware in the near future to rectify the situation. Another solution is to issue a recall for all existing PlayStation 5 consoles on the market and replace their motherboard to change the hardware codes, but this is unlikely to happen as it’s either going to be too costly for the company or gamers would be unwilling to pay extra for a mistake that was ultimately not theirs.</p><a href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" id="d2c9db27-6a47-4468-85a2-fb7349e49791" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" alt="Google Preferred Source" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png">
</picture></p></div></figure></a><p id="69583c41-85c4-42fb-9830-f1fb2e735404"><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em> add us as a preferred source</em></a><em>, to get our latest news, analysis, &amp; reviews in your feeds.</em></p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-dRa7insCXCF7xYRNoWCLTJ"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>




<!-- Drop in a standard article here maybe? -->



<div id="slice-container-authorBio-dRa7insCXCF7xYRNoWCLTJ"><p>Jowi Morales is a tech enthusiast with years of experience working in the industry. He’s been writing with several tech publications since 2021, where he’s been interested in tech hardware and consumer electronics.</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BYD Sells 4.6M Vehicles in 2025, Meets Revised Sales Goal (256 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2026-01-01/byd-sells-4-6-million-vehicles-in-2025-meets-revised-sales-goal</link>
            <guid>46454977</guid>
            <pubDate>Thu, 01 Jan 2026 15:49:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2026-01-01/byd-sells-4-6-million-vehicles-in-2025-meets-revised-sales-goal">https://www.bloomberg.com/news/articles/2026-01-01/byd-sells-4-6-million-vehicles-in-2025-meets-revised-sales-goal</a>, See on <a href="https://news.ycombinator.com/item?id=46454977">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2026-01-01/byd-sells-4-6-million-vehicles-in-2025-meets-revised-sales-goal: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[50% of U.S. vinyl buyers don't own a record player (201 pts)]]></title>
            <link>https://lightcapai.medium.com/the-great-return-from-digital-abundance-to-analog-meaning-cfda9e428752</link>
            <guid>46454944</guid>
            <pubDate>Thu, 01 Jan 2026 15:45:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lightcapai.medium.com/the-great-return-from-digital-abundance-to-analog-meaning-cfda9e428752">https://lightcapai.medium.com/the-great-return-from-digital-abundance-to-analog-meaning-cfda9e428752</a>, See on <a href="https://news.ycombinator.com/item?id=46454944">Hacker News</a></p>
Couldn't get https://lightcapai.medium.com/the-great-return-from-digital-abundance-to-analog-meaning-cfda9e428752: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[ACM Is Now Open Access (323 pts)]]></title>
            <link>https://www.acm.org/articles/bulletins/2026/january/acm-open-access</link>
            <guid>46454763</guid>
            <pubDate>Thu, 01 Jan 2026 15:19:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.acm.org/articles/bulletins/2026/january/acm-open-access">https://www.acm.org/articles/bulletins/2026/january/acm-open-access</a>, See on <a href="https://news.ycombinator.com/item?id=46454763">Hacker News</a></p>
Couldn't get https://www.acm.org/articles/bulletins/2026/january/acm-open-access: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenWorkers: Self-Hosted Cloudflare Workers in Rust (441 pts)]]></title>
            <link>https://openworkers.com/introducing-openworkers</link>
            <guid>46454693</guid>
            <pubDate>Thu, 01 Jan 2026 15:09:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openworkers.com/introducing-openworkers">https://openworkers.com/introducing-openworkers</a>, See on <a href="https://news.ycombinator.com/item?id=46454693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Self-hosted Cloudflare Workers in Rust</p></div><div><p>OpenWorkers is an open-source runtime for executing JavaScript in V8 isolates. 
        It brings the power of edge computing to your own infrastructure.</p> <h2>What works today</h2>  <h2>Features</h2> <div><div><h3>Bindings</h3> <ul><li>• KV storage (get, put, delete, list)</li> <li>• PostgreSQL database</li> <li>• S3/R2-compatible storage</li> <li>• Service bindings</li> <li>• Environment variables &amp; secrets</li></ul></div> <div><h3>Web APIs</h3> <ul><li>• fetch, Request, Response</li> <li>• ReadableStream</li> <li>• crypto.subtle</li> <li>• TextEncoder/Decoder, Blob</li> <li>• setTimeout, AbortController</li></ul></div></div> <h2>Architecture</h2> <pre>                         ┌─────────────────┐
                         │  nginx (proxy)  │
                         └────────┬────────┘
                                  │
         ┌───────────────┬────────┴──┬───────────────┐
         │               │           │               │
         │               │           │               │
┌────────┸────────┐ ┌────┸────┐ ┌────┸────┐ ┌────────┸────────┐
│   dashboard     │ │  api    │ │ logs *  │ │  runner (x3) *  │
└─────────────────┘ └────┬────┘ └────┰────┘ └────────┰────────┘
                         │           │               │
                         │           │               │
                ┌────────┸────────┐  │      ┌────────┸────────┐
                │   postgate *    │  └──────┥      nats       │
                └─────────────────┘         └────────┰────────┘
                                                     │
                                                     │
                ┌─────────────────┐           ┌──────┴───────┐
         * ─────┥   PostgreSQL    │           │ scheduler *  │
                └─────────────────┘           └──────────────┘</pre> <ul><li><strong>V8 Isolates:</strong> Sandboxing with CPU (100ms) and memory (128MB) limits per worker.</li> <li><strong>Cron Scheduling:</strong> Built-in support for 5 or 6-field cron syntax.</li> <li><strong>Compatibility:</strong> Cloudflare Workers syntax compatible.</li></ul> <h2>Self-hosting</h2> <p>Deployment is designed to be simple. A single PostgreSQL database and a single Docker Compose file is all you need.</p>  <h2>Why I built this</h2> <p>This project has been evolving for about 7 years. I started experimenting with vm2 for sandboxing JS,
        then Cloudflare launched Workers and I got hooked on the model. When Deno came out, I switched to deno-core
        and ran on that for two years. Recently, with Claude's help, I rewrote everything on top of rusty_v8 directly.</p> <p>The goal has always been the same: run JavaScript on your own servers,
        with the same DX as Cloudflare Workers but without vendor lock-in.</p> <div><div><p>Your Data</p> <p>Never leaves your infrastructure</p></div> <div><p>Predictable Costs</p> <p>No per-request pricing</p></div> <div><p>No Lock-in</p> <p>Cloudflare Workers compatible</p></div></div> <div><p>Next up: Execution recording &amp; replay for deterministic debugging.</p> </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build a Deep Learning Library (117 pts)]]></title>
            <link>https://zekcrates.quarto.pub/deep-learning-library/</link>
            <guid>46454587</guid>
            <pubDate>Thu, 01 Jan 2026 14:53:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zekcrates.quarto.pub/deep-learning-library/">https://zekcrates.quarto.pub/deep-learning-library/</a>, See on <a href="https://news.ycombinator.com/item?id=46454587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-document-content">


<header id="title-block-header">





  


</header>



<section id="preface">
<h2>Preface</h2><p><img src="https://zekcrates.quarto.pub/deep-learning-library/cover.png" title="Build a Simple Deep Learning Library"></p>
<p>Instead of just learning how to use a deep learning library, we are going to learn how to create one.</p>
<p>We start with a blank file and NumPy, and we don’t stop until we have a functional autograd engine and a collection of layer modules. By the end, we will use it to train MNIST, simple CNN and simple ResNet.</p>
<div>
<div>

<p><span>Note</span>Support This Project
</p>
</div>
<div>
<p>This book is <strong>free to read online</strong>. If it helps you, consider <a href="https://zekcrates.gumroad.com/l/deep-learning-library">paying what you want on Gumroad</a></p>
<p><strong>Questions or feedback?</strong> <a href="mailto:zekcrates@proton.me">zekcrates@proton.me</a></p>
</div>
</div>


</section>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python numbers every programmer should know (359 pts)]]></title>
            <link>https://mkennedy.codes/posts/python-numbers-every-programmer-should-know/</link>
            <guid>46454470</guid>
            <pubDate>Thu, 01 Jan 2026 14:39:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mkennedy.codes/posts/python-numbers-every-programmer-should-know/">https://mkennedy.codes/posts/python-numbers-every-programmer-should-know/</a>, See on <a href="https://news.ycombinator.com/item?id=46454470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><strong>There are numbers every Python programmer should know</strong>. For example, how fast or slow is it to add an item to a list in Python? What about opening a file? Is that less than a millisecond? Is there something that makes that slower than you might have guessed? If you have a performance sensitive algorithm, which data structure should you use? How much memory does a floating point number use? What about a single character or the empty string? How fast is FastAPI compared to Django?</p>
<p>I wanted to take a moment and write down performance numbers specifically focused on Python developers. Below you will find an extensive table of such values. They are grouped by category. And I provided a couple of graphs for the more significant analysis below the table.</p>
<h3 id="source-code-for-the-benchmarks">Source code for the benchmarks</h3>
<p>This article is posted without any code. I encourage you to dig into the benchmarks. The code is available on GitHub at:</p>
<p><a href="https://github.com/mikeckennedy/python-numbers-everyone-should-know">https://github.com/mikeckennedy/python-numbers-everyone-should-know</a></p>
<h3 id="-system-information">📊 System Information</h3>
<p>The benchmarks were run on the sytem described in this table. While yours may be faster or slower, the most important thing to consider is relative comparisons.</p>
<table>
  <thead>
      <tr>
          <th>Property</th>
          <th>Value</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Python Version</strong></td>
          <td>CPython 3.14.2</td>
      </tr>
      <tr>
          <td><strong>Hardware</strong></td>
          <td>Mac Mini M4 Pro</td>
      </tr>
      <tr>
          <td><strong>Platform</strong></td>
          <td>macOS Tahoe (26.2)</td>
      </tr>
      <tr>
          <td><strong>Processor</strong></td>
          <td>ARM</td>
      </tr>
      <tr>
          <td><strong>CPU Cores</strong></td>
          <td>14 physical / 14 logical</td>
      </tr>
      <tr>
          <td><strong>RAM</strong></td>
          <td>24 GB</td>
      </tr>
      <tr>
          <td><strong>Timestamp</strong></td>
          <td>2025-12-30</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="python-numbers-you-should-know">Python numbers you should know</h2>
<p>More analysis and graphs by category below the table.</p>
<table>
  <thead>
      <tr>
          <th>Category</th>
          <th>Operation</th>
          <th>Time</th>
          <th>Memory</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><a href="#memory-costs"><strong>💾 Memory</strong></a></td>
          <td>Empty Python process</td>
          <td>—</td>
          <td>15.73 MB</td>
      </tr>
      <tr>
          <td></td>
          <td>Empty string</td>
          <td>—</td>
          <td>41 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>100-char string</td>
          <td>—</td>
          <td>141 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Small int (0-256)</td>
          <td>—</td>
          <td>28 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Large int</td>
          <td>—</td>
          <td>28 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Float</td>
          <td>—</td>
          <td>24 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Empty list</td>
          <td>—</td>
          <td>56 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>List with 1,000 ints</td>
          <td>—</td>
          <td>35.2 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>List with 1,000 floats</td>
          <td>—</td>
          <td>32.1 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>Empty dict</td>
          <td>—</td>
          <td>64 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Dict with 1,000 items</td>
          <td>—</td>
          <td>63.4 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>Empty set</td>
          <td>—</td>
          <td>216 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>Set with 1,000 items</td>
          <td>—</td>
          <td>59.6 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>Regular class instance (5 attrs)</td>
          <td>—</td>
          <td>48 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td><code>__slots__</code> class instance (5 attrs)</td>
          <td>—</td>
          <td>72 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>List of 1,000 regular class instances</td>
          <td>—</td>
          <td>165.2 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>List of 1,000 <code>__slots__</code> class instances</td>
          <td>—</td>
          <td>79.1 KB</td>
      </tr>
      <tr>
          <td></td>
          <td>dataclass instance</td>
          <td>—</td>
          <td>48 bytes</td>
      </tr>
      <tr>
          <td></td>
          <td>namedtuple instance</td>
          <td>—</td>
          <td>88 bytes</td>
      </tr>
      <tr>
          <td><a href="#basic-operations"><strong>⚙️ Basic Ops</strong></a></td>
          <td>Add two integers</td>
          <td>19.0 ns (52.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Add two floats</td>
          <td>18.4 ns (54.4M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>String concatenation (small)</td>
          <td>39.1 ns (25.6M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>f-string formatting</td>
          <td>64.9 ns (15.4M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>.format()</code></td>
          <td>103 ns (9.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>%</code> formatting</td>
          <td>89.8 ns (11.1M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>List append</td>
          <td>28.7 ns (34.8M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>List comprehension (1,000 items)</td>
          <td>9.45 μs (105.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Equivalent for-loop (1,000 items)</td>
          <td>11.9 μs (83.9k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#collection-access-and-iteration"><strong>📦 Collections</strong></a></td>
          <td>Dict lookup by key</td>
          <td>21.9 ns (45.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Set membership check</td>
          <td>19.0 ns (52.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>List index access</td>
          <td>17.6 ns (56.8M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>List membership check (1,000 items)</td>
          <td>3.85 μs (259.6k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>len()</code> on list</td>
          <td>18.8 ns (53.3M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Iterate 1,000-item list</td>
          <td>7.87 μs (127.0k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Iterate 1,000-item dict</td>
          <td>8.74 μs (114.5k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>sum()</code> of 1,000 ints</td>
          <td>1.87 μs (534.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#class-and-object-attributes"><strong>🏷️ Attributes</strong></a></td>
          <td>Read from regular class</td>
          <td>14.1 ns (70.9M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Write to regular class</td>
          <td>15.7 ns (63.6M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Read from <code>__slots__</code> class</td>
          <td>14.1 ns (70.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Write to <code>__slots__</code> class</td>
          <td>16.4 ns (60.8M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Read from <code>@property</code></td>
          <td>19.0 ns (52.8M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>getattr()</code></td>
          <td>13.8 ns (72.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>hasattr()</code></td>
          <td>23.8 ns (41.9M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#json-and-serialization"><strong>📄 JSON</strong></a></td>
          <td><code>json.dumps()</code> (simple)</td>
          <td>708 ns (1.4M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>json.loads()</code> (simple)</td>
          <td>714 ns (1.4M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>json.dumps()</code> (complex)</td>
          <td>2.65 μs (376.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>json.loads()</code> (complex)</td>
          <td>2.22 μs (449.9k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>orjson.dumps()</code> (complex)</td>
          <td>310 ns (3.2M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>orjson.loads()</code> (complex)</td>
          <td>839 ns (1.2M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>ujson.dumps()</code> (complex)</td>
          <td>1.64 μs (611.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>msgspec</code> encode (complex)</td>
          <td>445 ns (2.2M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Pydantic <code>model_dump_json()</code></td>
          <td>1.54 μs (647.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Pydantic <code>model_validate_json()</code></td>
          <td>2.99 μs (334.7k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#web-frameworks"><strong>🌐 Web Frameworks</strong></a></td>
          <td>Flask (return JSON)</td>
          <td>16.5 μs (60.7k req/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Django (return JSON)</td>
          <td>18.1 μs (55.4k req/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>FastAPI (return JSON)</td>
          <td>8.63 μs (115.9k req/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Starlette (return JSON)</td>
          <td>8.01 μs (124.8k req/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Litestar (return JSON)</td>
          <td>8.19 μs (122.1k req/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#file-io"><strong>📁 File I/O</strong></a></td>
          <td>Open and close file</td>
          <td>9.05 μs (110.5k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Read 1KB file</td>
          <td>10.0 μs (99.5k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Write 1KB file</td>
          <td>35.1 μs (28.5k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Write 1MB file</td>
          <td>207 μs (4.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>pickle.dumps()</code></td>
          <td>1.30 μs (769.6k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>pickle.loads()</code></td>
          <td>1.44 μs (695.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#database-and-persistence"><strong>🗄️ Database</strong></a></td>
          <td>SQLite insert (JSON blob)</td>
          <td>192 μs (5.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>SQLite select by PK</td>
          <td>3.57 μs (280.3k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>SQLite update one field</td>
          <td>5.22 μs (191.7k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>diskcache set</td>
          <td>23.9 μs (41.8k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>diskcache get</td>
          <td>4.25 μs (235.5k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>MongoDB insert_one</td>
          <td>119 μs (8.4k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>MongoDB find_one by _id</td>
          <td>121 μs (8.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>MongoDB find_one by nested field</td>
          <td>124 μs (8.1k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#function-and-call-overhead"><strong>📞 Functions</strong></a></td>
          <td>Empty function call</td>
          <td>22.4 ns (44.6M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Function with 5 args</td>
          <td>24.0 ns (41.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Method call</td>
          <td>23.3 ns (42.9M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>Lambda call</td>
          <td>19.7 ns (50.9M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>try/except (no exception)</td>
          <td>21.5 ns (46.5M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td>try/except (exception raised)</td>
          <td>139 ns (7.2M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>isinstance()</code> check</td>
          <td>18.3 ns (54.7M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td><a href="#async-overhead"><strong>⏱️ Async</strong></a></td>
          <td>Create coroutine object</td>
          <td>47.0 ns (21.3M ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>run_until_complete(empty)</code></td>
          <td>27.6 μs (36.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>asyncio.sleep(0)</code></td>
          <td>39.4 μs (25.4k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>gather()</code> 10 coroutines</td>
          <td>55.0 μs (18.2k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>create_task()</code> + await</td>
          <td>52.8 μs (18.9k ops/sec)</td>
          <td>—</td>
      </tr>
      <tr>
          <td></td>
          <td><code>async with</code> (context manager)</td>
          <td>29.5 μs (33.9k ops/sec)</td>
          <td>—</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="memory-costs">Memory Costs</h2>
<p>Understanding how much memory different Python objects consume.</p>
<h3 id="an-empty-python-process-uses-1573-mb">An empty Python process uses 15.73 MB</h3>
<hr>
<h3 id="strings">Strings</h3>
<p>The rule of thumb for strings is the core string object takes 41 bytes. Each additional character is 1 byte.</p>
<table>
  <thead>
      <tr>
          <th>String</th>
          <th>Size</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Empty string <code>""</code></td>
          <td>41 bytes</td>
      </tr>
      <tr>
          <td>1-char string <code>"a"</code></td>
          <td>42 bytes</td>
      </tr>
      <tr>
          <td>100-char string</td>
          <td>141 bytes</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/string-memory-usage-by-size.png" alt=""></p>
<hr>
<h3 id="numbers">Numbers</h3>
<p><strong>Numbers are surprisingly large in Python</strong>. They have to derive from CPython’s <code>PyObject</code> and are subject to reference counting for garabage collection, they exceed our typical mental model many of:</p>
<ul>
<li>2 bytes = short int</li>
<li>4 bytes = long int</li>
<li>etc.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Type</th>
          <th>Size</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Small int (0-256, cached)</td>
          <td>28 bytes</td>
      </tr>
      <tr>
          <td>Large int (1000)</td>
          <td>28 bytes</td>
      </tr>
      <tr>
          <td>Very large int (10**100)</td>
          <td>72 bytes</td>
      </tr>
      <tr>
          <td>Float</td>
          <td>24 bytes</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/individual-integer-and-float-memory-usage.png" alt=""></p>
<hr>
<h3 id="collections">Collections</h3>
<p>Collections are amazing in Python. Dynamically growing lists. Ultra high-perf dictionaries and sets. Here is the empty and “full” overhead of each.</p>
<table>
  <thead>
      <tr>
          <th>Collection</th>
          <th>Empty</th>
          <th>1,000 items</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>List (ints)</td>
          <td>56 bytes</td>
          <td>35.2 KB</td>
      </tr>
      <tr>
          <td>List (floats)</td>
          <td>56 bytes</td>
          <td>32.1 KB</td>
      </tr>
      <tr>
          <td>Dict</td>
          <td>64 bytes</td>
          <td>63.4 KB</td>
      </tr>
      <tr>
          <td>Set</td>
          <td>216 bytes</td>
          <td>59.6 KB</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/empty-collection-memory-overhead.png" alt=""></p>
<hr>
<h3 id="classes-and-instances">Classes and Instances</h3>
<p>Slots are an interesting addition to Python classes. They remove the entire concept of a <code>__dict__</code> for tracking fields and other values. This does not significantly matter for a single instance, with the slots instance actually <strong>larger</strong>. But if you are holding a large number of them in memory for a list or cache, the memory savings of a slots class is very dramatic. Luckily for most use-cases, just adding a slots entry saves a ton of memory with minimal effort.</p>
<table>
  <thead>
      <tr>
          <th>Type</th>
          <th>Empty</th>
          <th>5 attributes</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Regular class</td>
          <td>48 bytes</td>
          <td>48 bytes</td>
      </tr>
      <tr>
          <td><code>__slots__</code> class</td>
          <td>32 bytes</td>
          <td>72 bytes</td>
      </tr>
      <tr>
          <td>dataclass</td>
          <td>—</td>
          <td>48 bytes</td>
      </tr>
      <tr>
          <td><code>@dataclass(slots=True)</code></td>
          <td>—</td>
          <td>72 bytes</td>
      </tr>
      <tr>
          <td>namedtuple</td>
          <td>—</td>
          <td>88 bytes</td>
      </tr>
  </tbody>
</table>
<p><strong>Aggregate Memory Usage (1,000 instances):</strong></p>
<table>
  <thead>
      <tr>
          <th>Type</th>
          <th>Total Memory</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>List of 1,000 regular class instances</td>
          <td>165.2 KB</td>
      </tr>
      <tr>
          <td>List of 1,000 <code>__slots__</code> class instances</td>
          <td>79.1 KB</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/memory-for-1-000-class-instances.png" alt=""></p>
<hr>
<h2 id="basic-operations">Basic Operations</h2>
<p>The cost of fundamental Python operations: Way slower than C/C++/C# but still quite fast.</p>
<h3 id="arithmetic">Arithmetic</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Add two integers</td>
          <td>19.0 ns (52.7M ops/sec)</td>
      </tr>
      <tr>
          <td>Add two floats</td>
          <td>18.4 ns (54.4M ops/sec)</td>
      </tr>
      <tr>
          <td>Multiply two integers</td>
          <td>19.4 ns (51.6M ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/arithmetic-operation-speed.png" alt=""></p>
<hr>
<h3 id="string-operations">String Operations</h3>
<p>String operations in Python are fast as well. f-strings are the fastest formatting style, while even the slowest style is still measured in just nano-seconds.</p>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Concatenation (<code>+</code>)</td>
          <td>39.1 ns (25.6M ops/sec)</td>
      </tr>
      <tr>
          <td>f-string</td>
          <td>64.9 ns (15.4M ops/sec)</td>
      </tr>
      <tr>
          <td><code>.format()</code></td>
          <td>103 ns (9.7M ops/sec)</td>
      </tr>
      <tr>
          <td><code>%</code> formatting</td>
          <td>89.8 ns (11.1M ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/string-formatting-speed-comparison.png" alt=""></p>
<hr>
<h3 id="list-operations">List Operations</h3>
<p>List operations are very fast in Python. Adding a single item <em>usually</em> requires 28ns. Said another way, you can do 35M appends per second. This is unless the list has to expand using something like a doubling algorithm. You can see this in the ops/sec for 1,000 items.</p>
<p>Surprisingly, <strong>list comprehensions are 20% faster than the equivalent for loops</strong> with append statements.</p>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>list.append()</code></td>
          <td>28.7 ns (34.8M ops/sec)</td>
      </tr>
      <tr>
          <td>List comprehension (1,000 items)</td>
          <td>9.45 μs (105.8k ops/sec)</td>
      </tr>
      <tr>
          <td>Equivalent for-loop (1,000 items)</td>
          <td>11.9 μs (83.9k ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/list-comprehension-vs-for-loop.png" alt=""></p>
<hr>
<h2 id="collection-access-and-iteration">Collection Access and Iteration</h2>
<p>How fast can you get data out of Python’s built-in collections? Here is a dramatic example of how much faster the correct data structure is. <code>item in set</code> or <code>item in dict</code> is <strong>200x faster</strong> than <code>item in list</code> for just 1,000 items!</p>
<p>The graph below is non-linear in the x-axis.</p>
<h3 id="access-by-keyindex">Access by Key/Index</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Dict lookup by key</td>
          <td>21.9 ns (45.7M ops/sec)</td>
      </tr>
      <tr>
          <td>Set membership (<code>in</code>)</td>
          <td>19.0 ns (52.7M ops/sec)</td>
      </tr>
      <tr>
          <td>List index access</td>
          <td>17.6 ns (56.8M ops/sec)</td>
      </tr>
      <tr>
          <td>List membership (<code>in</code>, 1,000 items)</td>
          <td>3.85 μs (259.6k ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/collection-access-speed.png" alt=""></p>
<hr>
<h3 id="length">Length</h3>
<p><code>len()</code> is very fast. Maybe we don’t have to optimize it out of the test condition on a while loop looping 100 times after all.</p>
<table>
  <thead>
      <tr>
          <th>Collection</th>
          <th><code>len()</code> time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>List (1,000 items)</td>
          <td>18.8 ns (53.3M ops/sec)</td>
      </tr>
      <tr>
          <td>Dict (1,000 items)</td>
          <td>17.6 ns (56.9M ops/sec)</td>
      </tr>
      <tr>
          <td>Set (1,000 items)</td>
          <td>18.0 ns (55.5M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="iteration">Iteration</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Iterate 1,000-item list</td>
          <td>7.87 μs (127.0k ops/sec)</td>
      </tr>
      <tr>
          <td>Iterate 1,000-item dict (keys)</td>
          <td>8.74 μs (114.5k ops/sec)</td>
      </tr>
      <tr>
          <td><code>sum()</code> of 1,000 integers</td>
          <td>1.87 μs (534.8k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="class-and-object-attributes">Class and Object Attributes</h2>
<p>The cost of reading and writing attributes, and how <code>__slots__</code> changes things. <strong>Slots is a tiny bit slower but easily saves over 2x the memory usage on large collections</strong>.</p>
<h3 id="attribute-access">Attribute Access</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Regular Class</th>
          <th><code>__slots__</code> Class</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Read attribute</td>
          <td>14.1 ns (70.9M ops/sec)</td>
          <td>14.1 ns (70.7M ops/sec)</td>
      </tr>
      <tr>
          <td>Write attribute</td>
          <td>15.7 ns (63.6M ops/sec)</td>
          <td>16.4 ns (60.8M ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/attribute-access-regular-vs-slots-classes.png" alt=""></p>
<hr>
<h3 id="other-attribute-operations">Other Attribute Operations</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Read <code>@property</code></td>
          <td>19.0 ns (52.8M ops/sec)</td>
      </tr>
      <tr>
          <td><code>getattr(obj, 'attr')</code></td>
          <td>13.8 ns (72.7M ops/sec)</td>
      </tr>
      <tr>
          <td><code>hasattr(obj, 'attr')</code></td>
          <td>23.8 ns (41.9M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="json-and-serialization">JSON and Serialization</h2>
<p>Comparing standard library JSON with optimized alternatives. <code>orjson</code> <strong>handles more data types and is over 11x faster than standard lib</strong> <code>json</code>. Impressive!</p>
<h3 id="serialization-dumps">Serialization (dumps)</h3>
<table>
  <thead>
      <tr>
          <th>Library</th>
          <th>Simple Object</th>
          <th>Complex Object</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>json</code> (stdlib)</td>
          <td>708 ns (1.4M ops/sec)</td>
          <td>2.65 μs (376.8k ops/sec)</td>
      </tr>
      <tr>
          <td><code>orjson</code></td>
          <td>60.9 ns (16.4M ops/sec)</td>
          <td>310 ns (3.2M ops/sec)</td>
      </tr>
      <tr>
          <td><code>ujson</code></td>
          <td>264 ns (3.8M ops/sec)</td>
          <td>1.64 μs (611.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>msgspec</code></td>
          <td>92.3 ns (10.8M ops/sec)</td>
          <td>445 ns (2.2M ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/json-serialization-speed-complex-object.png" alt=""></p>
<hr>
<h3 id="deserialization-loads">Deserialization (loads)</h3>
<table>
  <thead>
      <tr>
          <th>Library</th>
          <th>Simple Object</th>
          <th>Complex Object</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>json</code> (stdlib)</td>
          <td>714 ns (1.4M ops/sec)</td>
          <td>2.22 μs (449.9k ops/sec)</td>
      </tr>
      <tr>
          <td><code>orjson</code></td>
          <td>106 ns (9.4M ops/sec)</td>
          <td>839 ns (1.2M ops/sec)</td>
      </tr>
      <tr>
          <td><code>ujson</code></td>
          <td>268 ns (3.7M ops/sec)</td>
          <td>1.46 μs (682.8k ops/sec)</td>
      </tr>
      <tr>
          <td><code>msgspec</code></td>
          <td>101 ns (9.9M ops/sec)</td>
          <td>850 ns (1.2M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="pydantic">Pydantic</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>model_dump_json()</code></td>
          <td>1.54 μs (647.8k ops/sec)</td>
      </tr>
      <tr>
          <td><code>model_validate_json()</code></td>
          <td>2.99 μs (334.7k ops/sec)</td>
      </tr>
      <tr>
          <td><code>model_dump()</code> (to dict)</td>
          <td>1.71 μs (585.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>model_validate()</code> (from dict)</td>
          <td>2.30 μs (435.5k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="web-frameworks">Web Frameworks</h2>
<p>Returning a simple JSON response. Benchmarked with <code>wrk</code> against localhost running 4 works in Granian. Each framework returns the same JSON payload from a minimal endpoint. No database access or that sort of thing. This is just how much overhead/perf do we get from each framework itself. The code we write that runs within those view methods is largely the same.</p>
<h3 id="results">Results</h3>
<table>
  <thead>
      <tr>
          <th>Framework</th>
          <th>Requests/sec</th>
          <th>Latency (p99)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Flask</td>
          <td>16.5 μs (60.7k req/sec)</td>
          <td>20.85 ms (48.0 ops/sec)</td>
      </tr>
      <tr>
          <td>Django</td>
          <td>18.1 μs (55.4k req/sec)</td>
          <td>170.3 ms (5.9 ops/sec)</td>
      </tr>
      <tr>
          <td>FastAPI</td>
          <td>8.63 μs (115.9k req/sec)</td>
          <td>1.530 ms (653.6 ops/sec)</td>
      </tr>
      <tr>
          <td>Starlette</td>
          <td>8.01 μs (124.8k req/sec)</td>
          <td>930 μs (1.1k ops/sec)</td>
      </tr>
      <tr>
          <td>Litestar</td>
          <td>8.19 μs (122.1k req/sec)</td>
          <td>1.010 ms (990.1 ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/web-framework-throughput.png" alt=""></p>
<hr>
<h2 id="file-io">File I/O</h2>
<p>Reading and writing files of various sizes. Note that the graph is non-linear in y-axis.</p>
<h3 id="basic-operations-1">Basic Operations</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Open and close (no read)</td>
          <td>9.05 μs (110.5k ops/sec)</td>
      </tr>
      <tr>
          <td>Read 1KB file</td>
          <td>10.0 μs (99.5k ops/sec)</td>
      </tr>
      <tr>
          <td>Read 1MB file</td>
          <td>33.6 μs (29.8k ops/sec)</td>
      </tr>
      <tr>
          <td>Write 1KB file</td>
          <td>35.1 μs (28.5k ops/sec)</td>
      </tr>
      <tr>
          <td>Write 1MB file</td>
          <td>207 μs (4.8k ops/sec)</td>
      </tr>
  </tbody>
</table>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/file-io-performance.png" alt=""></p>
<hr>
<h3 id="pickle-vs-json-to-disk">Pickle vs JSON to Disk</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>pickle.dumps()</code> (complex obj)</td>
          <td>1.30 μs (769.6k ops/sec)</td>
      </tr>
      <tr>
          <td><code>pickle.loads()</code> (complex obj)</td>
          <td>1.44 μs (695.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>json.dumps()</code> (complex obj)</td>
          <td>2.72 μs (367.1k ops/sec)</td>
      </tr>
      <tr>
          <td><code>json.loads()</code> (complex obj)</td>
          <td>2.35 μs (425.9k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="database-and-persistence">Database and Persistence</h2>
<p>Comparing SQLite, diskcache, and MongoDB using the same complex object.</p>
<h3 id="test-object">Test Object</h3>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>user_data</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>"id"</span><span>:</span> <span>12345</span><span>,</span>
</span></span><span><span>    <span>"username"</span><span>:</span> <span>"alice_dev"</span><span>,</span>
</span></span><span><span>    <span>"email"</span><span>:</span> <span>"alice@example.com"</span><span>,</span>
</span></span><span><span>    <span>"profile"</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>"bio"</span><span>:</span> <span>"Software engineer who loves Python"</span><span>,</span>
</span></span><span><span>        <span>"location"</span><span>:</span> <span>"Portland, OR"</span><span>,</span>
</span></span><span><span>        <span>"website"</span><span>:</span> <span>"https://alice.dev"</span><span>,</span>
</span></span><span><span>        <span>"joined"</span><span>:</span> <span>"2020-03-15T08:30:00Z"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>"posts"</span><span>:</span> <span>[</span>
</span></span><span><span>        <span>{</span><span>"id"</span><span>:</span> <span>1</span><span>,</span> <span>"title"</span><span>:</span> <span>"First Post"</span><span>,</span> <span>"tags"</span><span>:</span> <span>[</span><span>"python"</span><span>,</span> <span>"tutorial"</span><span>],</span> <span>"views"</span><span>:</span> <span>1520</span><span>},</span>
</span></span><span><span>        <span>{</span><span>"id"</span><span>:</span> <span>2</span><span>,</span> <span>"title"</span><span>:</span> <span>"Second Post"</span><span>,</span> <span>"tags"</span><span>:</span> <span>[</span><span>"rust"</span><span>,</span> <span>"wasm"</span><span>],</span> <span>"views"</span><span>:</span> <span>843</span><span>},</span>
</span></span><span><span>        <span>{</span><span>"id"</span><span>:</span> <span>3</span><span>,</span> <span>"title"</span><span>:</span> <span>"Third Post"</span><span>,</span> <span>"tags"</span><span>:</span> <span>[</span><span>"python"</span><span>,</span> <span>"async"</span><span>],</span> <span>"views"</span><span>:</span> <span>2341</span><span>},</span>
</span></span><span><span>    <span>],</span>
</span></span><span><span>    <span>"settings"</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>"theme"</span><span>:</span> <span>"dark"</span><span>,</span>
</span></span><span><span>        <span>"notifications"</span><span>:</span> <span>True</span><span>,</span>
</span></span><span><span>        <span>"email_frequency"</span><span>:</span> <span>"weekly"</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><h3 id="sqlite-json-blob-approach">SQLite (JSON blob approach)</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Insert one object</td>
          <td>192 μs (5.2k ops/sec)</td>
      </tr>
      <tr>
          <td>Select by primary key</td>
          <td>3.57 μs (280.3k ops/sec)</td>
      </tr>
      <tr>
          <td>Update one field</td>
          <td>5.22 μs (191.7k ops/sec)</td>
      </tr>
      <tr>
          <td>Delete</td>
          <td>191 μs (5.2k ops/sec)</td>
      </tr>
      <tr>
          <td>Select with <code>json_extract()</code></td>
          <td>4.27 μs (234.2k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="diskcache">diskcache</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>cache.set(key, obj)</code></td>
          <td>23.9 μs (41.8k ops/sec)</td>
      </tr>
      <tr>
          <td><code>cache.get(key)</code></td>
          <td>4.25 μs (235.5k ops/sec)</td>
      </tr>
      <tr>
          <td><code>cache.delete(key)</code></td>
          <td>51.9 μs (19.3k ops/sec)</td>
      </tr>
      <tr>
          <td>Check key exists</td>
          <td>1.91 μs (523.2k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="mongodb">MongoDB</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>insert_one()</code></td>
          <td>119 μs (8.4k ops/sec)</td>
      </tr>
      <tr>
          <td><code>find_one()</code> by <code>_id</code></td>
          <td>121 μs (8.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>find_one()</code> by nested field</td>
          <td>124 μs (8.1k ops/sec)</td>
      </tr>
      <tr>
          <td><code>update_one()</code></td>
          <td>115 μs (8.7k ops/sec)</td>
      </tr>
      <tr>
          <td><code>delete_one()</code></td>
          <td>30.4 ns (32.9M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="comparison-table">Comparison Table</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>SQLite</th>
          <th>diskcache</th>
          <th>MongoDB</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Write one object</td>
          <td>192 μs (5.2k ops/sec)</td>
          <td>23.9 μs (41.8k ops/sec)</td>
          <td>119 μs (8.4k ops/sec)</td>
      </tr>
      <tr>
          <td>Read by key/id</td>
          <td>3.57 μs (280.3k ops/sec)</td>
          <td>4.25 μs (235.5k ops/sec)</td>
          <td>121 μs (8.2k ops/sec)</td>
      </tr>
      <tr>
          <td>Read by nested field</td>
          <td>4.27 μs (234.2k ops/sec)</td>
          <td>N/A</td>
          <td>124 μs (8.1k ops/sec)</td>
      </tr>
      <tr>
          <td>Update one field</td>
          <td>5.22 μs (191.7k ops/sec)</td>
          <td>23.9 μs (41.8k ops/sec)</td>
          <td>115 μs (8.7k ops/sec)</td>
      </tr>
      <tr>
          <td>Delete</td>
          <td>191 μs (5.2k ops/sec)</td>
          <td>51.9 μs (19.3k ops/sec)</td>
          <td>30.4 ns (32.9M ops/sec)</td>
      </tr>
  </tbody>
</table>
<p>Note: MongoDB is a victim of network access version in-process access.</p>
<p><img src="https://cdn.mkennedy.codes/posts/python-numbers-every-programmer-should-know/database-performance-sqlite-vs-diskcache-vs-mongodb.png" alt=""></p>
<hr>
<h2 id="function-and-call-overhead">Function and Call Overhead</h2>
<p>The hidden cost of function calls, exceptions, and async.</p>
<h3 id="function-calls">Function Calls</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Empty function call</td>
          <td>22.4 ns (44.6M ops/sec)</td>
      </tr>
      <tr>
          <td>Function with 5 arguments</td>
          <td>24.0 ns (41.7M ops/sec)</td>
      </tr>
      <tr>
          <td>Method call on object</td>
          <td>23.3 ns (42.9M ops/sec)</td>
      </tr>
      <tr>
          <td>Lambda call</td>
          <td>19.7 ns (50.9M ops/sec)</td>
      </tr>
      <tr>
          <td>Built-in function (<code>len()</code>)</td>
          <td>17.1 ns (58.4M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="exceptions">Exceptions</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>try/except</code> (no exception raised)</td>
          <td>21.5 ns (46.5M ops/sec)</td>
      </tr>
      <tr>
          <td><code>try/except</code> (exception raised)</td>
          <td>139 ns (7.2M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="type-checking">Type Checking</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>isinstance()</code></td>
          <td>18.3 ns (54.7M ops/sec)</td>
      </tr>
      <tr>
          <td><code>type() == type</code></td>
          <td>21.8 ns (46.0M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="async-overhead">Async Overhead</h2>
<p>The cost of async machinery.</p>
<h3 id="coroutine-creation">Coroutine Creation</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Create coroutine object (no await)</td>
          <td>47.0 ns (21.3M ops/sec)</td>
      </tr>
      <tr>
          <td>Create coroutine (with return value)</td>
          <td>45.3 ns (22.1M ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="running-coroutines">Running Coroutines</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>run_until_complete(empty)</code></td>
          <td>27.6 μs (36.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>run_until_complete(return value)</code></td>
          <td>26.6 μs (37.5k ops/sec)</td>
      </tr>
      <tr>
          <td>Run nested await</td>
          <td>28.9 μs (34.6k ops/sec)</td>
      </tr>
      <tr>
          <td>Run 3 sequential awaits</td>
          <td>27.9 μs (35.8k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="asynciosleep">asyncio.sleep()</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>asyncio.sleep(0)</code></td>
          <td>39.4 μs (25.4k ops/sec)</td>
      </tr>
      <tr>
          <td>Coroutine with <code>sleep(0)</code></td>
          <td>41.8 μs (23.9k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="asynciogather">asyncio.gather()</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>gather()</code> 5 coroutines</td>
          <td>49.7 μs (20.1k ops/sec)</td>
      </tr>
      <tr>
          <td><code>gather()</code> 10 coroutines</td>
          <td>55.0 μs (18.2k ops/sec)</td>
      </tr>
      <tr>
          <td><code>gather()</code> 100 coroutines</td>
          <td>155 μs (6.5k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="task-creation">Task Creation</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>create_task()</code> + await</td>
          <td>52.8 μs (18.9k ops/sec)</td>
      </tr>
      <tr>
          <td>Create 10 tasks + gather</td>
          <td>85.5 μs (11.7k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="async-context-managers--iteration">Async Context Managers &amp; Iteration</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>async with</code> (context manager)</td>
          <td>29.5 μs (33.9k ops/sec)</td>
      </tr>
      <tr>
          <td><code>async for</code> (5 items)</td>
          <td>30.0 μs (33.3k ops/sec)</td>
      </tr>
      <tr>
          <td><code>async for</code> (100 items)</td>
          <td>36.4 μs (27.5k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="sync-vs-async-comparison">Sync vs Async Comparison</h3>
<table>
  <thead>
      <tr>
          <th>Operation</th>
          <th>Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Sync function call</td>
          <td>20.3 ns (49.2M ops/sec)</td>
      </tr>
      <tr>
          <td>Async equivalent (<code>run_until_complete</code>)</td>
          <td>28.2 μs (35.5k ops/sec)</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="methodology">Methodology</h2>
<h3 id="benchmarking-approach">Benchmarking Approach</h3>
<ul>
<li>All benchmarks run multiple times and with warmup not timed</li>
<li>Timing uses <code>timeit</code> or <code>perf_counter_ns</code> as appropriate</li>
<li>Memory measured with <code>sys.getsizeof()</code> and <code>tracemalloc</code></li>
<li>Results are median of N runs</li>
</ul>
<h3 id="environment">Environment</h3>
<ul>
<li><strong>OS:</strong> macOS 26.2</li>
<li><strong>Python:</strong> 3.14.2 (CPython)</li>
<li><strong>CPU:</strong> ARM - 14 cores (14 logical)</li>
<li><strong>RAM:</strong> 24.0 GB</li>
</ul>
<h3 id="code-repository">Code Repository</h3>
<p>All benchmark code available at: <a href="https://github.com/mkennedy/python-numbers-everyone-should-know">https://github.com/mkennedy/python-numbers-everyone-should-know</a></p>
<hr>
<h2 id="key-takeaways">Key Takeaways</h2>
<ol>
<li><strong>Memory overhead</strong>: Python objects have significant memory overhead - even an empty list is 56 bytes</li>
<li><strong>Dict/set speed</strong>: Dictionary and set lookups are extremely fast (O(1) average case) compared to list membership checks (O(n))</li>
<li><strong>JSON performance</strong>: Alternative JSON libraries like <code>orjson</code> and <code>msgspec</code> are 3-11x faster than stdlib <code>json</code></li>
<li><strong>Async overhead</strong>: Creating and awaiting coroutines has measurable overhead - only use async when you need concurrency</li>
<li><strong><code>__slots__</code> tradeoff</strong>: While <code>__slots__</code> saves memory, the difference for attribute access speed is minimal</li>
</ol>
<hr>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Inspired by <a href="https://gist.github.com/jboner/2841832">Latency Numbers Every Programmer Should Know</a> and similar resources.</p>
<hr>
<p>*Last updated: 2025-12-31</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2025 Letter (313 pts)]]></title>
            <link>https://danwang.co/2025-letter/</link>
            <guid>46454413</guid>
            <pubDate>Thu, 01 Jan 2026 14:32:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danwang.co/2025-letter/">https://danwang.co/2025-letter/</a>, See on <a href="https://news.ycombinator.com/item?id=46454413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><em>(This piece is my year in review; I <a href="https://danwang.co/breakneck/" target="_blank" rel="noopener">skipped</a> a letter last year</em><em>)</em></p>
<p><span>One way that Silicon Valley and the Communist Party resemble each other is that both are serious, self-serious, and indeed, completely humorless.</span></p>
<p><span>If the Bay Area once had an impish side, it has gone the way of most hardware tinkerers and hippie communes. Which of the tech titans are funny? In public, they tend to speak in one of two registers. The first is the blandly corporate tone we’ve come to expect when we see them dragged before Congressional hearings or fireside chats. The second leans philosophical, as they compose their features into the sort of reverie appropriate for issuing apocalyptic prophecies on AI. Sam Altman once combined both registers at a tech conference when he said: “I think that AI will probably, most likely, sort of lead to the end of the world. But in the meantime, there will be great companies created with serious machine learning.” Actually that was pretty funny.</span></p>
<p><span>It wouldn’t be news to the Central Committee that only the paranoid survive. The Communist Party speaks in the same two registers as the tech titans. The po-faced men on the Politburo tend to make extraordinarily bland speeches, laced occasionally with a murderous warning against those who cross the party’s interests. How funny is the big guy? We can take a look at an official list of Xi Jinping’s jokes, helpfully published by party propagandists. These </span><span>wisecracks</span><span> include the following: “On an inspection tour to Jiangsu, Xi quipped that the true measure of water cleanliness is whether the mayor would dare to swim in the water.” Or try this reminiscence that Xi offered on bad air quality: “The PM2.5 back then was even worse than it is now; I used to joke that it was PM250.” Yes, such a humorous fellow is the general secretary.<i><a href="#footnote-1-2101" id="note-1-2101" rel="footnote">1</a></i></span></p>
<p><span>It’s nearly as dangerous to tweet a joke about a top VC as it is to make a joke about a member of the Central Committee. People who are dead serious tend not to embody sparkling irony. Yet the Communist Party and Silicon Valley are two of the most powerful forces shaping our world today. Their initiatives increase their own centrality while weakening the agency of whole nation states. Perhaps they are successful because they are remorseless.</span></p>
<p><span>Earlier this year, I moved from Yale to Stanford. The sun and the dynamism of the west coast have drawn me back. I found a Bay Area that has grown a lot weirder since I lived there a decade ago. In 2015, people were mostly working on consumer apps, cryptocurrencies, and some business software. Though it felt exciting, it looks in retrospect like a more innocent, even a more sedate, time. Today, AI dictates everything in San Francisco while the tech scene plays a much larger political role in the United States. I can’t get over how strange it all feels. In the midst of California’s natural beauty, nerds are trying to build God in a Box; meanwhile, Peter Thiel hovers in the background presenting lectures on the nature of the Antichrist. This eldritch setting feels more appropriate for a Gothic horror novel than for real life.</span></p>
<p><span>Before anyone gets the wrong idea, I want to say that I am rooting for San Francisco. It’s tempting to gawk at the craziness of the culture, as much of the east coast media tends to do. Yes, one can quickly find people who speak with the conviction of a cultist; no, I will not inject the peptides proffered by strangers. But there’s more to the Bay Area than unusual health practices. It is, after all, a place that creates not only new products, but also new modes of living. I’m struck that some east coast folks insist to me that driverless cars can’t work and won’t be accepted, even as these vehicles populate the streets of the Bay Area. Coverage of Silicon Valley increasingly reminds me of coverage of China, where a legacy media reporter might parachute in, write a dispatch on something that looks deranged, and leave without moving past caricature.</span></p>
<p><span>I enjoy San Francisco more than when I was younger because I now better appreciate what makes it work. I believe that Silicon Valley possesses plenty of virtues. To start, it is the most meritocratic part of America. Tech is so open towards immigrants that it has driven populists into a froth of rage. It remains male-heavy and practices plenty of gatekeeping. But San Francisco better embodies an ethos of openness relative to the rest of the country. Industries on the east coast —&nbsp;finance, media, universities, policy —&nbsp;tend to more carefully weigh name and pedigree. Young scientists aren’t told they ought to keep their innovations incremental and their attitude to hierarchy duly deferential, as they might hear in Boston. A smart young person could achieve much more over a few years in SF than in DC. People aren’t reminiscing over some lost golden age that took place decades ago, as New Yorkers in media might do.&nbsp;</span></p>
<p><span>San Francisco is forward looking and eager to try new ideas. Without this curiosity, it wouldn’t be able to create whole new product categories: iPhones, social media, large language models, and all sorts of digital services. For the most part, it’s positive that tech values speed: quick product cycles, quick replies to email. Past success creates an expectation that the next technological wave will be even more exciting. It’s good to keep building the future, though it’s sometimes absurd to hear someone pivot, mid-breath, from declaring that salvation lies in the blockchain to announcing that AI will solve everything.</span></p>
<p><span>People like to make fun of San Francisco for not drinking; well, that works pretty well for me. I enjoy board games and appreciate that it’s easier to find other players. I like SF house parties, where people take off their shoes at the entrance and enter a space in which speech can be heard over music, which feels so much more civilized than descending into a loud bar in New York. It’s easy to fall into a nerdy conversation almost immediately with someone young and earnest. The Bay Area has converged on Asian-American modes of socializing (though it lacks the emphasis on food). I find it charming that a San Francisco home that is poorly furnished and strewn with pizza boxes could be owned by a billionaire who can’t get around to setting up a bed for his mattress.&nbsp;</span></p>
<p><span>There’s still no better place for a smart, young person to go in the world than Silicon Valley. It adores the youth, especially those with technical skill and the ability to grind. Venture capitalists are chasing younger and younger founders: the median age of the latest Y Combinator cohort is only 24, down from 30 just three years ago. My favorite part of Silicon Valley is the cultivation of community. Tech founders are a close-knit group, always offering help to each other, but they circulate actively amidst the broader community too. (The finance industry in New York by contrast practices far greater secrecy.) Tech has organizations I think of as internal civic institutions that try to build community. They bring people together in San Francisco or retreats north of the city, bringing together young people to learn from older folks.</span></p>
<p><span>Silicon Valley also embodies a cultural tension. It is playing with new ideas while being open to newcomers; at the same time, it is a self-absorbed place that doesn’t think so much about the broader world. Young people who move to San Francisco already tend to be very online. They know what they’re signing up for. If they don’t fit in after a few years, they probably won’t stick around. San Francisco is a city that absorbs a lot of people with similar ethics, which reinforces its existing strengths and weaknesses.</span></p>
<p><span>Narrowness of mind is something that makes me uneasy about the tech world. Effective altruists, for example, began with sound ideas like concern for animal welfare as well as cost-benefit analyses for charitable giving. But these solid premises have launched some of its members towards intellectual worlds very distant from moral intuitions that most people hold; they’ve also sent a few into jail. The well-rounded type might struggle to stand out relative to people who are exceptionally talented in a technical domain. Hedge fund managers have views about the price of oil, interest rates, a reliably obscure historical episode, and a thousand other things. Tech titans more obsessively pursue a few ideas —&nbsp;as Elon Musk has on electric vehicles and space launches —&nbsp;rather than developing a robust model of the world.</span></p>
<p><span>So the 20-year-olds who accompanied Mr. Musk into the Department of Government Efficiency did not, I would say, distinguish themselves with their judiciousness. The Bay Area has all sorts of autistic tendencies. Though Silicon Valley values the ability to move fast, the rest of society has paid more attention to instances in which tech wants to break things. It is not surprising that hardcore contingents on both the left and the right have developed hostility to most everything that emerges from Silicon Valley.&nbsp;</span></p>
<p><span>There’s a general lack of cultural awareness in the Bay Area. It’s easy to hear at these parties that a person’s favorite nonfiction book is </span><i><span>Seeing Like a State</span></i><span> while their aspirationally favorite novel is </span><i><span>Middlemarch</span></i><span>. Silicon Valley often speaks in strange tongues, starting podcasts and shows that are popular within the tech world but do not travel far beyond the Bay Area. Though San Francisco has produced so much wealth, it is a relative underperformer in the national culture. Indie movie theaters keep closing down while all sorts of retail and art institutions suffer from the crumminess of downtown. The symphony and the opera keep cutting back on performances — after Esa-Pekka Salonen quit the directorship of the symphony, it hasn’t been able to name a successor. Wealthy folks in New York and LA have, for generations, pumped money into civic institutions. Tech elites mostly scorn traditional cultural venues and prefer to fund the next wave of technology instead.</span></p>
<p><span>One of the things I like about the finance industry is that it might be better at encouraging diverse opinions. Portfolio managers want to be right on average, but everyone is wrong three times a day before breakfast. So they relentlessly seek new information sources; consensus is rare, since there are always contrarians betting against the rest of the market. Tech cares less for dissent. Its movements are more herdlike, in which companies and startups chase one big technology at a time. Startups don’t need dissent; they want workers who can grind until the network effects kick in. VCs don’t like dissent, showing again and again that many have thin skins. That contributes to a culture I think of as Silicon Valley’s soft Leninism. When political winds shift, most people fall in line, most prominently this year as many tech voices embraced the right.&nbsp;</span></p>
<p><span>The two most insular cities I’ve lived in are San Francisco and Beijing. They are places where people are willing to risk apocalypse every day in order to reach utopia. Though Beijing is open only to a narrow slice of newcomers — the young, smart, and Han — its elites must think about the rest of the country and the rest of the world. San Francisco is more open, but when people move there, they stop thinking about the world at large. Tech folks may be the worst-traveled segment of American elites. People stop themselves from leaving in part because they can correctly claim to live in one of the most naturally beautiful corners of the world, in part because they feel they should not tear themselves away from inventing the future. More than any other topic, I’m bewildered by the way that Silicon Valley talks about AI.</span></p>
<p><b>Hallucinating the end of history</b></p>
<p><span>While critics of AI cite the spread of slop and rising power bills, AI’s architects are more focused on its potential to produce surging job losses. Anthropic chief Dario Amodei takes pains to point out that AI could push the unemployment rate to 20 percent by eviscerating white-collar work.<i><a href="#footnote-2-2101" id="note-2-2101" rel="footnote">2</a></i> I wonder whether this message is helping to endear his product to the public.</span></p>
<p><span>The most-read essay from Silicon Valley this year was </span><a href="http://ai-2027.com/" target="_blank" rel="noopener"><span>AI 2027</span></a><span>. The five authors, who come from the AI safety world, outline a scenario in which superintelligence wakes up in 2027; a decade later, it decides to annihilate humanity with biological weapons. My favorite detail in the report is that humanity would persist in a genetically modified form, after the AI reconstructs creatures that are “to humans what corgis are to wolves.” It’s hard to know what to make of this document, because the authors keep tucking important context into footnotes, repeatedly saying they do not endorse a prediction. Six months after publication, they stated that their timelines were lengthening, but even at the start their median forecast for the arrival of superintelligence was later than 2027. Why they put that year in their title remains beyond me.</span></p>
<p><span>It’s easy for conversations in San Francisco to collapse into AI. At a party, someone told me that we no longer have to worry about the future of manufacturing. Why not? “Because AI will solve it for us.” At another, I heard someone say the same thing about climate change. One of the questions I receive most frequently anywhere is when Beijing intends to seize Taiwan. But only in San Francisco do people insist that Beijing wants Taiwan for its production of AI chips. In vain do I protest that there are historical and geopolitical reasons motivating the desire, that chip fabs cannot be violently seized, and anyway that Beijing has coveted Taiwan for approximately seven decades before people were talking about AI.</span></p>
<p><span>Silicon Valley’s views on AI made more sense to me after I learned the term “decisive strategic advantage.” It was first used by Nick Bostrom’s 2014 book </span><i><span>Superintelligence</span></i><span>, which defined it as a technology sufficient to achieve “complete world domination.” How might anyone gain a DSA? A superintelligence might develop cyber advantages that cripple the adversary’s command-and-control capabilities. Or the superintelligence could self-recursively improve such that the lab or state that controls it gains an insurmountable scientific advantage. Once an AI reaches a certain capability threshold, it might need only weeks or hours to evolve into a superintelligence.<i><a href="#footnote-3-2101" id="note-3-2101" rel="footnote">3</a></i> And if an American lab builds it, it might help to lock in the dominance of another American century.</span></p>
<p><span>If you buy the potential of AI, then you might worry about the corgi-fication of humanity by way of biological weapons. This hope also helps to explain the semiconductor controls unveiled by the Biden administration in 2022. If the policymakers believe that DSA is within reach, then it makes sense to throw almost everything into grasping it while blocking the adversary from the same. And it barely matters if these controls stimulate Chinese companies to invent alternatives to American technologies, because the competition will be won in years, not decades.</span></p>
<p><span>The trouble with these calculations is that they mire us in epistemically tricky terrain. I’m bothered by how quickly the discussions of AI become utopian or apocalyptic. As Sam Altman once <a href="https://x.com/sama/status/488085826866143232" target="_blank" rel="noopener">said</a> (and again this is fairly humorous): “AI will be either the best or the worst thing ever.” It’s a Pascal’s Wager, in which we’re sure that the values are infinite, but we don’t know in which direction. It also forces thinking to be obsessively short term. People start losing interest in problems of the next five or ten years, because superintelligence will have already changed everything. The big political and technological questions we need to discuss are only those that matter to the speed of AI development. Furthermore, we must sprint towards a post-superintelligence world even though we have no real idea what it will bring.</span></p>
<p><span>Effective altruists used to be known for their insistence on thinking about the very long run; much more of the movement now is concerned about the development of AI in the next year. Call me a romantic, but I believe that there will be a future, and indeed a long future, beyond 2027. History will not end. We need to cultivate the skill of exact thinking in demented times.</span></p>
<p><span>I am skeptical of the decisive strategic advantage when I filter it through my main preoccupation: understanding China’s technology trajectories. On AI, China is behind the US, but not by years. There’s no question that American reasoning models are more sophisticated than the likes of DeepSeek and Qwen. But the Chinese efforts are doggedly in pursuit, sometimes a bit closer to US models, sometimes a bit further. By virtue of being open-source (or at least open-weight), the Chinese models have found receptive customers overseas, sometimes with American tech companies.<em><a href="#footnote-4-2101" id="note-4-2101" rel="footnote">4</a></em> If US labs achieve superintelligence, the Chinese labs are probably on a good footing to follow closely. Unless the DSA is decisive immediately, it’s not obvious that the US will have a monopoly on this technology, just as it could not keep it over the bomb.</span></p>
<p><span>One advantage for Beijing is that much of the global AI talent is Chinese. We can tell from the CVs of researchers as well as occasional disclosures from top labs (for example from Meta) that a large percentage of AI researchers earned their degrees from Chinese universities. American labs may be able to declare that “our Chinese are better than their Chinese.” But some of these Chinese researchers may decide to repatriate. I know that many of them prefer to stay in the US: their compensation might be higher by an order of magnitude, they have access to compute, and they can work with top peers.<i><a href="#footnote-5-2101" id="note-5-2101" rel="footnote">5</a></i>But they may also tire of the uncertainty created by Trump’s immigration policy. It’s never worth forgetting that at the dawn of the Cold War, the US deported Qian Xuesen, the CalTech professor who then built missile delivery systems for Beijing. Or these Chinese researchers expect life in Shanghai to be safer or more fun than in San Francisco. Or they miss mom. People move for all sorts of reasons, so I’m reluctant to believe that the US has a durable talent advantage.</span></p>
<p><span>China has other advantages in building AI. Superintelligence will demand a superload of power. By now everyone has seen the chart with two curves: US electrical generation capacity, which has barely budged upwards since the year 2000; and China’s capacity, which was one-third US levels in 2000 and more than two-and-a-half times US levels in 2024. Beijing is building so much solar, coal, and nuclear to make sure that no data center shall be in want. Though the US has done a superb job building data centers, it hasn’t prepared enough for other bottlenecks. Especially not as Trump’s dislike of wind turbines has removed this source of growth. Speaking of Trump’s whimsy, he has also been generous with selling close-to-leading chips to Beijing. That’s another reason that data centers might not represent a US advantage for long.</span></p>
<p><span>Silicon Valley has not demonstrated joined-up thinking for deploying AI. It would help if they learned from the central planners. The AI labs have not shown that they’re thinking seriously about how to diffuse the technology throughout society, which will require extensive regulatory and legal reform. How else will AI be able to fold doctors and lawyers into its tender mercies? Doing politics will also mean reaching out to more of the electorate, who are often uneasy with Silicon Valley’s promises while they see rising electrical bills. Silicon Valley has done a marvelous job in building data centers. But tech titans don’t look ready to plan for later steps in leading the whole-of-society effort into deploying AI everywhere.&nbsp;</span></p>
<p><span>The Communist Party lives for whole-of-society efforts. That’s what Leninist systems are built for. Beijing has set targets for deploying AI across society, though as usual with planning announcements, these numerical targets should be taken seriously and not literally. Chinese founders talk about AI mostly as a technology to be harnessed rather than a fickle power that might threaten all.<i><a href="#footnote-6-2101" id="note-6-2101" rel="footnote">6</a></i> Rather than building superintelligence, Chinese companies have been more interested in embedding AI into robots and manufacturing lines. Some researchers believe that this sort of embodied AI might present the real path towards superintelligence.<i><a href="#footnote-7-2101" id="note-7-2101" rel="footnote">7</a></i>We might furthermore wonder how the US and China will use AI. Since the US is much more services-driven, Americans may be using AI to produce more powerpoints and lawsuits; China, by virtue of being the global manufacturer, has the option to scale up production of more electronics, more drones, and more munitions.</span></p>
<p><span>Dean Ball, who helped craft the White House’s action plan on AI, has written a perceptive </span><a href="https://www.hyperdimensional.co/p/the-bitter-lessons" target="_blank" rel="noopener"><span>post</span></a><span> on how the US is playing to its strengths —&nbsp;software, chips, cloud computing, financing —&nbsp;while China is also focused on leaning on manufacturing excellence. In his view, “the US economy is increasingly a highly leveraged bet on deep learning.” Certainly there’s a lot of money invested here, but it looks risky to be so concentrated. I believe it’s unbecoming for the world’s largest economy to be so levered on one technology. That’s a more appropriate strategy for a small country. Why shouldn’t the US be better positioned across the entirety of the supply chain, from electron production to electronics production?</span></p>
<p><span>I am not a skeptic of AI. I am a skeptic only of the decisive strategic advantage, which treats awakening the superintelligence as the final goal. Rather than “winning the AI race,” I prefer to say that the US and China need to “win the AI future.” There is no race with a clear end point or a shiny medal for first place. Winning the future is the more appropriately capacious term that incorporates the agenda to build good reasoning models as well as the effort to diffuse it across society. For the US to come ahead on AI, it should build more power, revive its manufacturing base, and figure out how to make companies and workers make use of this technology. Otherwise China might do better when compute is no longer the main bottleneck.</span></p>
<p><b>The humming tech engine</b></p>
<p><span>I’ve had Silicon Valley friends tell me that they are planning a trip to China nearly every month this year. Silicon Valley respects and fears companies from only one other country. Game recognizes game, so to speak. Tech founders may begrudge China’s restrictions; and some companies have suffered directly from IP theft. But they also recognize that Chinese companies can move even faster than they do with their teams of motivated workers; and Chinese manufacturers are far ahead of US capabilities on anything involving physical production. Some founders and VCs are impressed with the fact that Chinese AI companies have gotten this far while suffering American tech restrictions, while leading in open-source to boot. VCs are wondering whether they may still invest in Chinese startups or Chinese founders who have moved abroad.&nbsp;</span></p>
<p><span>2025 is the year that Chinese tech successes have really blossomed into the wider American consciousness. There’s no need to retread the coverage around DeepSeek, the surge of electric vehicle exports, or new developments in robotics. When I first moved from Silicon Valley to China in 2017, I felt some degree of skepticism from my friends that I was taking myself out of the beating heart of the technological universe and into the unknown. But it was clear to me that Chinese firms were improving on quality and taking global market share. I wrote in my </span><a href="https://danwang.co/2019-letter/" target="_blank" rel="noopener"><span>2019 letter</span></a><span>: “Chinese workers are working with the latest tools to produce most of the world’s goods; over the longer term, my hypothesis is that they’ll be able to replicate the tooling and make just as good final products.”&nbsp;</span></p>
<p><span>I think that has become closer to consensus views. I believe that Chinese technological success is now the rule rather than the exception. There are two fields in which China is substantially behind the west: semiconductors and aviation. The chip sector is gingerly attempting to expand under the weight of US restrictions; meanwhile, China’s answer to Airbus and Boeing is on a very long runway. I grant that these are two critical technologies, but China has attained technological leadership almost everywhere else. And I believe its technological momentum will continue rolling onwards to engulf more of their western competitors over the next decade.</span></p>
<p><span>The electric vehicle industry is the sharp tip of the spear of China’s global success. Chinese EVs have greater functionalities than western models while selling at lower price points. A rule of thumb is that it takes five years from an American, German, or Japanese automaker to dream up a new car design and launch that model on the roads; in China, it’s closer to 18 months. The Chinese market is full of demanding customers as well as fast-iterating automotive suppliers. It also has a more productive workforce. According to Tesla’s corporate disclosures, a worker at a Gigafactory in China produces an average of 47 vehicles a year; a worker at a Gigafactory in California produces an average of 20.<i><a href="#footnote-8-2101" id="note-8-2101" rel="footnote">8</a></i></span></p>
<p><span>China’s automotive success is biting into Germany more than anywhere else. I keep a scrapbook filled with mournful remarks that German executives offer to newspapers. “Most of what German Mittelstand firms do these days, Chinese companies can do just as well,” </span><a href="https://www.ft.com/content/239eed1b-a268-42ec-861e-fc3047f47c32" target="_blank" rel="noopener"><span>said</span></a><span> a consultant to the Financial Times. “In my sector they look at the price-point of the market leader and sell for roughly half of that,” the boss of a medical devicemaker </span><a href="https://www.economist.com/briefing/2025/11/20/chinese-regulations-and-competition-are-panicking-european-manufacturers" target="_blank" rel="noopener"><span>told</span></a><span> the Economist. It’s never hard to find parades of gloomy Germans. Now more than ever it looks like their core competences are threatened by Chinese firms.</span></p>
<p><span>I often think of the case of Xiaomi. In 2021, Lei Jun vowed that the company he founded would break into the EV business. Four years later, Xiaomi started shipping cars to customers. Not only that, a Xiaomi EV set a speed record at the Nürburgring racetrack in Germany. Compare Xiaomi to Apple, which spent 10 years and $10 billion studying whether to enter the EV market before it pulled the plug. The world’s most advanced consumer product company could not match Xiaomi’s feat. It’s cases like these that make me skeptical of reasoning about China’s tech successes through financial measures or productivity ratios. As of this writing, Xiaomi’s market value is $130 billion. That is only around half of the market value of AppLovin, the mobile advertisement company. Rather than being an indictment of Xiaomi, I view this imbalance as an indictment of financial valuations. Isn’t it better, from a national power perspective, to develop firms like Xiaomi, which calls its shots and then makes them?</span></p>
<p><span>This comparison between Xiaomi and Apple motivated an essay I wrote with Dragonomics founder Arthur Kroeber in an issue of </span><a href="https://www.foreignaffairs.com/china/real-china-model-wang-kroeber" target="_blank" rel="noopener"><span>Foreign Affairs</span></a><span>. Our view is that China’s industrial success has roots in deep infrastructure. That includes not only ports and rail, it also includes data connectivity, electrification, and process knowledge. China’s strength lies in a robust manufacturing ecosystem full of self-reinforcing parts.</span></p>
<p><span>Chinese tech achievements that were apparent in 2025 were the fruits of investments made a decade ago. Given that China continues to invest massively in technology, I expect we’ll see yet more tech successes for another decade to come. Alexander Grothendieck used an analogy of a walnut to describe different approaches to mathematics, which might also apply to technology development. Some mathematicians crack their problems by finding the right spot to insert a chisel before making a clean strike. Grothendieck described his own approach as coming up with general solutions, as if he were immersing the walnut in a bath for such a long time that mere hand pressure would be enough to open it. The US comes up with exquisite and expensive solutions to its technology problems. China’s industrial ecosystem is more like a rising sea, softening many nuts at once.<i><a href="#footnote-9-2101" id="note-9-2101" rel="footnote">9</a></i></span></p>
<p><span>When these nuts open, it looks like China is producing a big wave of new products. These are its breakthroughs in drones, electric vehicles, and robotics. Years from now we may see greater success in biotech as well. I am keen to follow along China’s progress in electromagnetism over the next decade. China’s industrial ecosystem is leading the way in replacing combustion with electromagnetic processes. Everything is now drone, as the combination of cheaper batteries and better permanent magnets displaces the engine.<a href="#footnote-10-2101" id="note-10-2101" rel="footnote">10</a></span></p>
<p><span>One of the startling geopolitical moves of the year was how quickly Donald Trump withdrew his ~150 percent tariffs on China. Trump folded not out of beneficence, but because Xi Jinping denied rare earth magnets to most of the world, threatening many types of manufacturing operations. And yet I’m struck by Beijing’s relative restraint. Chinese producers are close to being monopolists not only in rare earths, but also electronics products, batteries, and many types of active pharmaceutical ingredients. In case China denies, say, cardiovascular drugs to the elderly, how long could a state hold out?</span></p>
<p><span>One might have expected the US to have roused itself after this bout of the trade war. But there have been too many declarations of Sputnik Moments without commensurate action. Barack Obama declared a Sputnik with China’s high-speed rail; Mark Warner repeated with Huawei’s 5G; Marc Andreessen called it with DeepSeek. The more that people use the term, the less likely that society spurs itself into taking it seriously.</span></p>
<p><span>I think the US continues to systematically underrate China’s industrial progress for several reasons.</span></p>
<p><span>First, too many western elites retain hope that China’s efforts will run out of fuel by its own accord. Industrial progress will be weighed down by demographic drag, the growing debt load, maybe even a political collapse. I won’t rule these out, but I don’t think they are likely to break China’s humming tech engine. Demographics in particular don’t matter for advanced technology —&nbsp;you don’t need a workforce of many millions to have robust production of semiconductors or EVs. South Korea, for example, has one of the world’s fastest shrinking populations while retaining its success in electronics production. And though China suffers broader economic headwinds, technology firms like Xiaomi continue to develop new products and enjoy rising revenues. Technology breakthroughs can occur even in a suffering society. Especially if the state continues to lavish resources on chips or anything that could represent an American chokepoint.&nbsp;</span></p>
<p><span>Second, western elites keep citing the wrong reasons for China’s success. When members of Congress get around to acknowledging China’s tech advancements, they do not fail to attribute causes to either industrial subsidies (also known as cheating) or IP theft (that is, stealing). These are legitimate claims, but China’s advantages extend far beyond them. That’s the creation of deep infrastructure as well as extensive industrial ecosystems that I describe above.</span></p>
<p><span>Probably the most underrated part of the Chinese system is the ferocity of market competition. It’s excusable not to see that, given that the party espouses so much Marxism. I would argue that China embodies both greater capitalist competition and greater capitalist excess than America does today. Part of the reason that China’s stock market trends sideways is that everyone’s profits are competed away. Big Tech might enjoy the monopolistic success smiled upon by Peter Thiel, coming almost to genteel agreements not to tread too hard upon each other’s business lines. Chinese firms have to fight it out in a rough-and-tumble environment, expanding all the time into each other’s core businesses, taking Jeff “your margin is my opportunity” Bezos with seriousness.</span></p>
<p><span>Third, western elites keep holding on to a distinction between “innovation,” which is mostly the remit of the west, and “scaling,” which they accept that China can do. I want to dissolve that distinction. Chinese workers innovate every day on the factory floor. By being the site of production, they have a keen sense of how to make technical improvements all the time. American scientists may be world leaders in dreaming up new ideas. But American manufacturers have been poor at building industries around these ideas. The history books point out that Bell Labs invented the first solar cell in 1957; today, the lab no longer exists while the solar industry moved to Germany and then to China. While Chinese universities have grown more capable at producing new ideas, it’s not clear that the American manufacturing base has grown stronger at commercializing new inventions.</span></p>
<p><span>I sometimes hear that the US will save manufacturers through automation. The truth is that Chinese factories tend to be ahead on automation: that’s a big part of the reason that Chinese Tesla workers are more productive than California Tesla workers. China regularly installs as many robots as the rest of the world put together. They are also able to provide greater amounts of training data for AI. We have to be careful not to let automation, like superintelligence, become an excuse for magical thinking rather than doing the hard work of capacity building.</span></p>
<p><b>Outlasting the adversary</b></p>
<p><span>The China discussions I get into on the east coast tend to focus on the country’s problems. Washington, DC in particular likes to ask questions like: didn’t we think that Japan was going to overrun the world with manufacturing before it fell apart? Isn’t China mostly a mess? These are ultimately variants of the form: how might China fail?</span></p>
<p><span>The west coast flavor of the discussion is different. People are more inclined to ask: what happens if China succeeds? That reflects, in part, Silicon Valley’s epistemic bias towards securing upside returns rather than minimizing downside risks. They also tend to make more frequent visits to China than folks in DC. “What if China succeeds?” is certainly the more interesting question to me, not only because my career has been studying China’s technological successes. The east coast questions deserve to be taken seriously. But I fear that dwelling on China’s failure modes will coax elites into complacency, serving a narrative that the US needs to change nothing before the adversary will topple, robbing the country of urgency to reform.</span></p>
<p><span>I want to be clear that though I expect China will overrun advanced technology industries, it won’t make the country a broad success. Over the past five years, it has been mired in disinflationary growth, where young people struggle to find a job and find a spouse. The political system is growing even more opaque, terrifying even the insiders. This year, Xi deposed a dozen generals of the People’s Liberation Army, one of whom was also a sitting Politburo member. I wonder how many people inside the Politburo feel confident about where they stand with Xi.</span></p>
<p><span>Entrepreneurs are on even worse ground. Earlier this year, investors greeted Xi’s handshake with prominent entrepreneurs (including Jack Ma) as good news. It was so, but who can be sure that Xi will not greet them differently once they revive the economy? Though Xi can cut entrepreneurs some slack, the trend is towards greater party control over business and society. Xi himself doesn’t evince concern that economic growth is lackluster. It’s an acceptable tradeoff for making China’s economy less dependent on foreign powers. None of this is a formula for broad human flourishing. Rather, it is depriving Chinese of contact with the rest of the world.</span></p>
<p><span>Beijing has been working relentlessly to build up its resilience. While the US talks itself out of Sputnik Moments, Beijing has dedicated immense resources to patching up its own deficiencies. It’s not a theoretical fear that Chinese companies might lose access to American technologies. So the state is pouring more money than ever before into semiconductor makers and research universities. It is investing in clean technologies not so much because it cares about the climate, but because it wants to be self-sufficient in energy. And it is re-writing the rules of the global order, with caution because it has been a giant beneficiary of it, while the US is still wondering about what it wants from China. Beijing has been preparing for Cold War without eagerness for waging it, while the US wants to wage a Cold War without preparing for it.<i><a href="#footnote-11-2101" id="note-11-2101" rel="footnote">11</a></i></span></p>
<p><span>So here’s a potential way that China succeeds. Beijing’s goal is to make nearly every important product in the world, while everyone else supplies its commodities and services. By making the country mostly self-sufficient, and by vigorously policing the outputs of LLMs and social media, Xi might hope to make China resilient. He is building Fortress China stone by stone in order to outlast the adversary. Beijing doesn’t have to replicate American diplomatic, cultural, and financial superpowerdom. It might hope that its prowess in advanced manufacturing might deter the US. And its success in manufacturing might directly destabilize the US: by delivering the coup de grace to the rustbelt, the US might shed a few million more manufacturing jobs over the next decade. The job losses combined with AI psychosis, social media, and all the problems with phones could make national politics meaningfully worse.</span></p>
<p><span>I don’t think this scenario is likely to be successful. Authoritarian systems have always hoped for the implosion of liberal democracies, while it is the liberal democracies that have a better track record of endurance. But I also don’t think that authoritarian countries are obviously wrong to bet that western polarization will get worse. So it’s up to the US and Europe to show that they can hold on to their values while absorbing the technological changes coming their way.&nbsp;</span></p>
<p><span>That task is more challenging as Europe and the US grew more apart in 2025. This year, both regions were able to look upon each other with pity. And both were correct to do so. America’s global trust and favorability measures have collapsed in Trump’s second term. Meanwhile, Europe looks as economically stuck as it has ever been, pushing its politics to increasingly chaotic extremes. But I am still more optimistic for the US.</span></p>
<p><span>I don’t need to lament the damage done by the Trump administration this year: the erosion of alliances, the cruelty towards the weak, the wasting of time. Manufacturing and re-industrialization, which I spend most of my time thinking of, have been doing worse. The Biden administration tried to fund an ambitious program of industrial policy; but it was so plodding and proceduralist that it built little before voters re-elected Trump. Since Trump imposed tariffs in April, the US has lost around 65,000 manufacturing jobs.<i><a href="#footnote-12-2101" id="note-12-2101" rel="footnote">12</a></i> His administration shows little interest in capturing electromagnetism before China overruns that field. Trump is more interested in protectionism rather than export promotion, which risks turning American industries into fossils like its exquisitely protected and horribly inefficient shipbuilding industry.</span></p>
<p><span>One of the Trump administration’s biggest blunders was its decision to raid a battery plant in Georgia, which put 300 Korean engineers in chains before deporting them. I suspect that any Korean, Taiwanese, or European engineer would ponder that episode before accepting a job posting to the United States. What a contrast that looks with China’s approach, which for decades has been to welcome managers from Walmart, Apple, or Tesla to train its workforce.</span></p>
<p><span>Will the US solve manufacturing with AI? Well, maybe, because superintelligence is supposed to solve everything. But there’s a risk that AI will destabilize society before it fixes the industrial base. When I walk around the library at Stanford, I see students plugging everything into AI tools; when they need a break, they’re watching short-form videos on their phones. These videos have been marvelously transformed by AI tools. Shortly after OpenAI released Sora 2, I had brunch with a friend who told me that he created an AI video of himself expertly breakdancing that fooled his five-year-old; another friend piped up to say that she created an AI video of herself that fooled her mother. AI chatbots are skilled at providing emotional companionship: Jasmine Sun </span><a href="https://jasmi.news/p/ai-friends" target="_blank" rel="noopener"><span>discussed</span></a><span> how they are able to seduce any segment of society, while pointing to a survey that 52 percent of teens regularly interact with AI companions. I’m not advocating for regulation. But I think it’s reasonable for the world to hope that AI labs will exercise some degree of forbearance before they release their shattering tools.</span></p>
<p><span>While I feel apprehensive about the US, I am much more gloomy about Europe. I have a hard time squaring the poor prospects of Europe over the next decade with the smugness that Europeans have for themselves. I spent most of the summer in Copenhagen. There’s no doubt that quality of life in most European cities is superb, especially for what I care about: food, opera, walkable streets, access to nature. But a decade of low economic growth is biting. European prices and taxes can be so high while salaries can be so low. For all the American complaints about home affordability, relative housing costs can be even worse in big European cities. London has the house prices of California and the income levels of Mississippi.&nbsp;</span></p>
<p><span>I remember two vivid episodes from Copenhagen. One day I read the news that the share price of Novo Nordisk — unquestionably one of Europe’s technological successes, along with ASML —&nbsp;collapsed as a result of sustained competition from US-based Eli Lilly as well as its misfortunes navigating the US regulatory system. I also watched Ursula von der Leyen visit Trump in the White House to graciously accept his EU tariffs. It’s already been clear that China has begun to maul European industry. What the Novo Nordisk news made me appreciate was that American companies are comprehensively outworking their European counterparts in biotech in addition to software and finance. Europe is losing the two-front battle against the Chinese on manufacturing and the Americans on services.</span></p>
<p><span>Perhaps Europe could have recruited some professors from the United States. American academics wouldn’t have needed Trump’s insults to act on their Europhile impulses. And yet European initiatives have not yet been able to brain drain much of this class. That’s mostly because European governments have little funding to offer. European universities have failed to build substantial endowments, so their revenues are dependent on the taxpaying public, which also must support a million other initiatives. An American academic who wants to move to Europe would have to accept more teaching and administrative work, lose tenure, and for the pleasure of all that, probably halve her pay. She would likely also suffer the resentment of European peers, who scoff at the idea that better paid Americans are now refugees. Trump threw a lot against US universities; they are holding up okay, and I think they will remain strong.</span></p>
<p><span>Europeans are right to gloat they are not under the rule of Trump. But for all of Trump’s ills, I see him as a sign of the underlying dynamism of the US. Who else would have elected so whimsical a leader to this high office? Trump forces questions that Europeans have no appetite to confront, proud as they are in being superior to both Americans and Chinese. I submit that Europeans ought to be more circumspect in their self-satisfaction. Chaos is only one election away. Right-populist parties are outpolling ruling incumbent parties pretty much everywhere, and it is as likely as not that Trumps with European characteristics will engulf the continent by the end of the decade.</span></p>
<p><span>So I am betting that the US and China are more compelling forces for change. Stalin was fond of telling a story from his experience in Leipzig in 1907, when, to his astonishment, 200 German workers failed to turn up to a socialist meeting because no ticket controller was on the platform to punch their train tickets, citing this experience as proof of the hopelessness of Germanic obedience. Could anyone imagine Chinese or Americans being so obedient? One advantage for the US and China is that both countries are at least interested in growth. You don’t have to convince the elites or the populace that growth is good or that entrepreneurs could be celebrated. Meanwhile in Europe, perhaps 15 percent of the electorate actively believes in degrowth. I feel it’s impossible to convince Europeans to act in their self interest. You can’t even convince them to adopt air conditioning in the summer.</span></p>
<p><b>The personal is the geopolitical</b></p>
<p><span>I’m not a doomer on AI or the broader state of the world. Across the US, China, and Europe, people generally enjoy comfortable lives that are free from fear. The market goes up. AI tools improve. Over the years I lived in China, I knew that life was more mundane than the headlines made out. Now that headlines and tweets are more negative everywhere, I know that things are not so bad in most places.</span></p>
<p><span>What I want is for everyone to do better. I opened my book by saying that Chinese and Americans are the most alike people in the world. They both are driven by a yearning for the future. They feel the draw of better times ahead, which is missing for Europeans, those people who have a sense of optimism only about the past.</span></p>
<p><span>I believe that modern China is one of the most ahistorical nations in the world. The state and the education system may talk insistently about its thousands of years of continuous history. But no other society has also been so destructive of its own history. The physical past has been disfigured by the attention of the Red Guards and the inattention of urban bulldozers. The social past is contorted by outrageous textbooks, which implement enforced forgetting of major traumas. For tragedies too widely experienced in modern times to be censored —&nbsp;the Cultural Revolution, the one-child policy, Zero Covid —&nbsp;the party discourages reflection in the name of protecting the state’s sensitivity.</span></p>
<p><span>The United States isn’t so good at celebrating its history either. 2026 is the 250th anniversary of the country’s founding. Where are the monuments to exalt that history? Most of the planned celebrations look small bore. Why hasn’t the federal government built a technological specimen as sublime as the Golden Gate Bridge, the Hoover Dam, or the Apollo missions? Probably because planning for any project should have commenced 10, 20, or 30 years ago. No president would have gotten around to starting a project that has no chance of being completed in his term. Lack of action due to the expectation of long timelines is one of the sins of the lawyerly society.</span></p>
<p><span>But American problems seem more fixable to me than Chinese problems. That’s why I live here in the US. I made clear in my book that I am drawn to pluralism as well as a broader conception of human flourishing than one that could be delivered by the Communist Party. The United States still draws many of the most ambitious people in the world, few of whom want to move to China. Even now a significant number of Chinese would jump to emigrate to the US if they felt they could be welcomed. But this enduring American advantage should not excuse the US from patching up its deficiencies.</span></p>
<p><span>A light grab-bag of complaints: While the rich have access to concierge doctors and the world’s best healthcare, the United States cannot organize a pandemic response; it is bioprosperity for the individual and measles for the many. I learned recently that the Bay Area has 26 separate transit agencies; is it really a triumph of democracy to have so many unconsolidated efforts? I wonder whether we can accuse the California government of subverting the will of the people by making so little progress on its high-speed rail, which was approved by referendum in 2008; California rail authorities take more pride in creating jobs than doing the job. I am tempted to use the language from American foreign policy at home. Why talk about American credibility only in terms of combat? Why shouldn’t the failure to deliver on big projects, after spending so much money, constitute a more severe blow to the credibility of the American project? Is the state of the US defense industrial base really deterring adversaries?</span></p>
<p><span>I won’t belabor issues with American public works or manufacturing. I’ll suggest only that the US ought to be acting with greater curiosity on how to do better. It doesn’t have to become China; but it should better study China’s successes. There is a 21st century playbook for becoming an industrial power and China has written it. This playbook consists of infrastructure development, solicitation of foreign investment, industrial subsidies, and the creation of industrial ecosystems. I hope that the US will stop attributing all of China’s successes to stealing. If such a program would be sufficient for building a world-class industry, then American spooks should dedicate their formidable capabilities to extracting Chinese industrial secrets. The reality is that there is little to be learned from blueprints. By failing to recognize China’s real strengths —&nbsp;the industrial ecosystems pulsating with process knowledge —&nbsp;the US is only cheating itself.&nbsp;</span></p>
<p><span>The future of US-China competition demands a resounding demonstration of the superiority of one country’s system to perform better for its citizens, which no country has thus achieved. Who’s going to come out ahead? I believe the competition is dynamic. It means we should not rely on static and structural features (like geography or demographics) to predict long-term advantage. One feature that unites American, Chinese, and European elites is the tendency to close ranks behind bad ideas and bad leaders. They are all skilled at dreaming up new ways to squander their advantages. Silicon Valley, for example, succeeds in spite of the generations-long governance failures of California. Imagine how much more vibrant Chinese society could be if it could escape the weight of overbearing censors in Beijing.</span></p>
<p><span>Competition will be dynamic because people have agency. The country that is ahead at any given moment will commit mistakes driven by overconfidence, while the country that is behind will feel the crack of the whip to reform. Implosion is always an option. In 2021, Xi Jinping was on top of the world, witnessing the omnishambles of the western pandemic response combined with the political disgrace of January 6. So he proceeded to smack around tech founders and initiate a controlled demolition of the property sector, which are two of the policies most responsible for China’s economic sluggishness today. Now, Beijing is trying to get a grip on its weaknesses. If either the US or China falls too far behind the other, the laggard will sweat to catch up. That drive will mean that competition will go on for years and decades.</span></p>
<p><span>In the competition for who might grow to be more humorous, I give a slight edge to the Chinese rather than to Silicon Valley.</span></p>
<p><span>No, I don’t expect the Communist Party ever to be funny. But there is a growing contrast between the baleful formality of the political system and the inexhaustible informality of Chinese society. Now that China is bidding farewell to its era of hypergrowth, young people are asking what they want to do with their lives. Fewer of them are interested in doing crazy hours in tech companies or big banks. Some of them are having fun in comedy sketches and stand-up shows. The increasingly gerontocratic Communist Party is not so much hovering over them as existing on a slightly different plane, speaking in strange apocalyptic tongues. Over the long run, I bet that the exuberance and rollicking nature of Chinese society will outlive the lusterless political system.</span></p>
<p><span>I wish that the tech world could learn to present broader cultural appeal. I hope that Silicon Valley could learn some of the humorousness of New York (or at least LA.) It’s unfortunate that any show or movie made about Silicon Valley is full of awkward nerds; by contrast, Hollywood reliably finds attractive leads when it makes movies about Wall Street. So long as the tech world is talking about the Machine God and the Antichrist, so long as it declines to read more broadly, so long as it is mostly inward looking, it will continue to alienate big parts of the world. But the longer I’m in California, the more easy I find it to be a sunny optimist. So I’m hopeful that the lovable nerds there will be able to present their own smiling optimism to the rest of the world.</span></p>
<p><i><span>I thank a number of people for reading a draft of this section and discussing the core ideas with me.&nbsp;</span></i></p>
<p><span>***</span></p>
<p><span>Of all the feedback I’ve received for my book, the most devastating came from my mother. After one of my television appearances, she called me to say: “Son, you looked terrible. Are you sick?” I accept that she, a former TV news anchor, has standing to judge. Still I could only reply with a quavering voice: “Mom, you’re so mean.”<i><a href="#footnote-13-2101" id="note-13-2101" rel="footnote">13</a></i></span></p>
<p><span>Other readers have been kinder to </span><a href="https://danwang.co/breakneck/" target="_blank" rel="noopener"><i><span>Breakneck</span></i></a><span>. It reached #3 on the New York Times bestseller list and was also a bestseller on its monthly Business list. I went on podcasts, radio, TV, and spoke at book events. </span><i><span>Breakneck</span></i><span> was a finalist for the FT/Schroders best business book of the year and it has been a book of the year in several big publications. It’s being translated into 17 languages as of this writing.&nbsp;</span></p>
<p><span>I’ve learned a lot over the past four months.</span></p>
<p><span>Why did </span><i><span>Breakneck</span></i><span> do well? I think four reasons, in descending order of importance. First, timing. It came out in a year of many China headlines — DeepSeek, trade war, 15th Five-Year Plan — and five months after </span><i><span>Abundance</span></i><span>, which primed readers for the idea that Americans are right to be frustrated by their state. Second, the book had the memetic framing of lawyers and engineers, which also encouraged people to wonder how other countries could be described. (What is India? The UK?) Third, people know my work through these letters. Fourth and least important was the content in the book. An author spends so much time workshopping words and sentences. I accept that a book’s reception is subject to the vagaries of the market and the memelords.</span></p>
<p><span>I don’t regret a minute of workshopping. I would have liked to workshop some more. Like every author, I wish I had more time to add a finer polish to the entire manuscript. I was heartened when a writer I admire told me that no author is ever more than 85 percent satisfied with their work; to hope for more would be profligate. In any case, I’m proud of the content. If it weren’t in place, I wouldn’t have had positive reviews in mainstream publications like the </span><a href="https://www.ft.com/content/261a0eaa-7fb9-4052-ac78-f4d8d9969e72" target="_blank" rel="noopener"><span>Financial Times</span></a><span>, the </span><a href="https://www.wsj.com/arts-culture/books/breakneck-review-lawyers-vs-technocrats-1aefcff8" target="_blank" rel="noopener"><span>Wall Street Journal</span></a><span>, the </span><a href="https://www.newyorker.com/magazine/2025/09/22/breakneck-threads-of-empire-god-and-sex-dominion" target="_blank" rel="noopener"><span>New Yorker</span></a><span>, and the </span><a href="https://www.thetimes.com/culture/books/article/breakneck-china-quest-engineer-future-dan-wang-review-9tqtkfb7b" target="_blank" rel="noopener"><span>Times</span></a><span>. I was glad to see praise from both left publications like </span><a href="https://jacobin.com/2025/08/us-china-lawfare-engineering-infrastructure"><span>Jacobin</span></a><span> and right publications like </span><a href="https://americanaffairsjournal.org/2025/11/the-engineering-state/"><span>American Affairs</span></a><span>.&nbsp;</span></p>
<p><span>I tried to write this book to reach a non-coast audience. Ideally I wanted a lawyer in say Indiana or Ohio to read </span><i><span>Breakneck</span></i><span>, rather than for it to be picked up only by folks in New York, DC, San Francisco, and the terminally online. So I was happy to hear from a broader cross-section of readers who wrote to tell me that they’d never visited China before and are now curious to do so. It’s a shame that book tours are no longer much of a thing for authors. Publishers don’t necessarily bring authors to book readings in Houston, Los Angeles, New Orleans, or other big cities as a matter of course. I was happy, however, to visit Dallas for the first time this year. After giving a talk in October, I wandered over to the Texas State Fair. Who can resist a place that calls itself “the most Texan place on earth?” I had a fabulous time walking through the fairground, the livestock pens, and the food stalls. The atmosphere made me realize that friendly and pragmatic Texans are what I imagined all Americans to be like, at least in my Canadian mind.</span></p>
<p><span>I’ve enjoyed opening my inbox to see reader notes. I love hearing from two groups in particular: engineers and other technical people who feel better appreciated for their work; and Chinese readers who tell me that I’ve captured something authentic. Someone emailed a set of book recommendations for the Spanish Civil War. An investor emailed to enlighten me that Copenhagen’s marvelous subways (which I praise for being clean and driverless) were built by Italian construction companies. An agricultural consultant emailed to tell me about her eye-opening experiences visiting big Chinese farms. These notes are small delights for any author. A stranger but still charming event was to see the Blue Book Club. About 20 people </span><a href="https://www.maximumnewyork.com/p/the-blue-book-club-breakneck" target="_blank" rel="noopener"><span>gathered</span></a><span> in Brooklyn this November to discuss </span><i><span>Breakneck</span></i><span>, but not before the hosts issued a light exam to make sure that the participants actually read the book.</span></p>
<p><span>Book promotion made me more of a public figure. I did my best to have fun with it. It wasn’t as hard as I imagined: podcast and TV hosts are as bored by self-serious personalities as the rest of us are. Readers have been friendly as they’ve recognized me in public. There was only one instance of a bit too much friendliness, when someone sidled up to the urinal beside mine in a public bathroom to tell me that he liked my book.</span></p>
<p><span>I’ve learned it is not possible to value mentors too highly. I am blessed to have good counselors. I mean not only my publishing house, my literary agent, and my writing coach who directly support my work. I am grateful to folks who give me time to reflect on the course of my thinking, especially the ones who have by now mentored me for over a decade. Friends have been generous in all sorts of ways. Eugene, Tina, Maran, Ren, James, Caleb, Alec, and Arthur hosted book parties. Joe Weisenthal </span><a href="https://x.com/thestalwart/status/1962922909896176085?s=46&amp;t=JoGB3DITqFZIf9-BRSvAhA" target="_blank" rel="noopener"><span>wrote</span></a><span> in the Odd Lots newsletter: “Total Dan Wang victory” on his view that most of the world is seeing China through the industrial lens I’ve been writing about. Afra </span><a href="https://afraw.substack.com/p/reading-breakneck-from-china" target="_blank" rel="noopener"><span>hosted</span></a><span> a Mandarin-language book discussion in which someone accused me of having a “gentle and vulnerable” voice. Alice, who doesn’t often pick up books on China, told me that my fondness for both the US and China shone through the book. It reconnected me with two friends from Ottawa that I haven’t heard from since high school.</span></p>
<p><span>I am grateful that Waterstones Piccadilly and Daunt Books in Marylebone have given my book prominent display. One surprise was that my book sold well in the United Kingdom. I’ve been pretty relentless at telling Brits that they are the PPE society and that they excel in the sounding-clever industries —&nbsp;television, journalism, finance, and universities. Upon reflection, it makes sense that the British are reading </span><i><span>Breakneck </span></i><span>and </span><i><span>Abundance</span></i><span>. Every problem in the lawyerly society is worse in the UK. I thought that California’s high-speed rail project was an embarrassment; then I learned about the Leeds tram network. First legislated in 1993, mass transit might not come to West Yorkshire until the late 2030s. It reminds me of the lawsuit in </span><i><span>Bleak House</span></i><span>: “The little plaintiff or defendant who was promised a new rocking-horse when Jarndyce and Jarndyce should be settled has grown up, possessed himself of a real horse, and trotted away into the other world.” At least Californians are struggling over something mighty; I hope that Leeds will one day have a tram.<i><a href="#footnote-14-2101" id="note-14-2101" rel="footnote">14</a></i></span></p>
<p><span>Homebuilding in London has collapsed. Heathrow has been making plans to build a third runway for twenty years, which is now expected to cost $20 billion. Britain’s electrical network is in even worse disrepair than America’s. I am not sure if it is a geopolitical asset to be able to stiff-upper-lip one’s way through ineffectual government. Maybe it’s more of a liability. But my experience of criticizing Brits resembles my experience of criticizing lawyers. They tend to nod along to my critiques; many of them take me further than where I’d like to go. It’s all very disarming.</span></p>
<p><span>I’ve been lucky to have smart critics. It’s any author’s dream to see people pick up the book and examine the arguments. Jon Sine wanted to have more specific data on engineers and lawyers, then proceeded to </span><a href="https://www.cogitations.co/p/litigation-nation-engineering-empire" target="_blank" rel="noopener"><span>supply</span></a><span> it while wrapping it in a narrative on a trip to Wushan. Charles Yang noted that I don’t have much by way of policy suggestions, but he also </span><a href="https://americanaffairsjournal.org/2025/11/the-engineering-state/" target="_blank" rel="noopener"><span>grasped</span></a><span> that I’m trying to change the culture of governing elites while suggesting that Breakneck is an incitement to initiate “tractable mimetic competition.” Jen-Kuan Wang </span><a href="https://jenkuanwang.github.io/breakneck_review" target="_blank" rel="noopener"><span>argued</span></a><span> that China was not quite the right model for the US, but that Taiwan and the rest of Northeast Asia better show how to survive China Shocks. I am grateful to see constructive engagement with my work. I was unimpressed with only one piece of commentary. Law professors Curtis Milhaupt and Angela Zhang </span><a href="https://www.project-syndicate.org/commentary/trump-state-capitalism-lawless-and-no-answer-to-china-rivalry-by-curtis-j-milhaupt-and-angela-huyue-zhang-2025-09" target="_blank" rel="noopener"><span>wrote</span></a><span> in Project Syndicate: “Lawless State Capitalism Is No Answer to China’s Rise,” as if I were advocating for that. Since the authors mention the book only at the start without engaging with any of the content, I suspect they are critics who chose not to read the book.</span></p>
<p><span>I learned of Leo Rosten’s quip that it is the weak who are cruel, and gentleness to be expected only from the strong. Every author will hear from online commentators who belligerently misunderstand their work. Saying anything about China tends to rile up the online commentators. Either the hawks will pounce because they believe that the whole country is evil and that its progress is fake; or the tankies will defend the idea that China has achieved socialist utopia. These people live on Twitter and Youtube, offering the stock comment that “this person knows nothing about China.” That’s of course hard to respond to because they offer no analytical content to rebut. Part of what makes the China discourse exasperating is that people have to choose sides all the time, which makes everyone dumber. At least I didn’t have it as bad as Ezra and Derek with </span><i><span>Abundance</span></i><span>.</span></p>
<p><span>I’ve learned more about myself as a writer this year. Namely, I like doing it. Writing a book is sometimes enough to make an author forswear the experience for a long time. Then there are the really perverse, for whom a taste of publishing is enough to tempt one into becoming a serial offender. After writing this book, I most looked forward to writing this long-ass letter, the very one you’re reading now.</span></p>
<p><span>Some writers work like sculptors: they produce something fully chiseled that could stand forever. Novelists tend to be like that. Rather than being a sculptor, I see myself as being a musician. After a performance, no matter how it goes, the musician’s task is to start practicing for the next one. It’s hard for US-China books to rest like sculptures. So I am happy to get back to work, writing iteratively to refine the same few themes that animate me: technology production, industrial ecosystems, US-China competition.</span></p>
<p><span>Musicians don’t usually practice by running a whole piece from start to finish. Rather, practice sessions tend to focus on particular passages, with a full run-through only before performance. Before I publish this letter, I retype the whole thing from start to finish. It means I take the draft that lives in my Notes app on the left half of my screen while I retype the whole thing into the Google Docs on the right side of my screen. It’s a final check to catch infelicities. More importantly, by simulating the experience of a reader, it’s another way to see if the whole essay stands together.</span></p>
<p><span>I’ve learned that it is better to wear a tie with a blazer. That was part of my training to be a speaker. The book tour forces you to have answers that last 30 seconds for TV, 30 minutes for a talk, and 3 hours for the more bruising podcasts. I’ve learned that delivering a good talk is a rare skill. I don’t think I could ever be satisfied by a talk I’ll give, because there will always be a stumble, or l’esprit de l’escalier kicks in. The piece of speaking advice I’ve remembered for many years came from Tim Harford: good speaking rewards those who are able to prepare extensively and who are also able to improvise. My favorite book talk took place at the Hoover Institution, </span><a href="https://www.youtube.com/watch?v=eXsehDq-LiM" target="_blank" rel="noopener"><span>hosted</span></a><span> by Stephen Kotkin (who is himself peerless at giving excellent lectures). In the summer, I spent two hours </span><a href="https://www.youtube.com/watch?v=myi0FWQs0nY" target="_blank" rel="noopener"><span>asking</span></a><span> Kotkin how historians work.&nbsp;</span></p>
<p><span>One day in October, I went on six podcasts. I haven’t counted the number of podcasts I’ve been on, but I think the number is north of 70. There’s a lot I don’t understand. Are so many people really listening to podcasts? What is the appeal of a video featuring two people with giant microphones in their faces? Do we really have to live in an oral culture world?</span></p>
<p><span>I’ve noticed the wide range of effort that people put into podcasts. Some hosts edit extensively — Freakonomics Radio stands out for the sheer number of producers and editors. Other hosts release their episodes more or less unedited. </span><a href="https://freakonomics.com/podcast/china-is-run-by-engineers-america-is-run-by-lawyers/" target="_blank" rel="noopener"><span>Freakonomics</span></a><span> stood out to me because Stephen Dubner was able to make the conversation so much fun. Going on Ross Douthat’s </span><a href="https://www.nytimes.com/2025/09/04/opinion/china-global-superpower-dan-wang.html" target="_blank" rel="noopener"><span>Interesting Times</span></a><span> was more appropriately serious. </span><a href="https://www.searchengine.show/america-vs-china/"><span>Search Engine</span></a><span> was impressive for the amount of narrative that PJ Vogt imbued into our more rambling conversation. It felt like a homecoming to return to </span><a href="https://www.youtube.com/watch?v=VaNy4J4cju8" target="_blank" rel="noopener"><span>Odd Lots</span></a><span>, where I could tease Tracy Alloway for her country life and Joe Weisenthal over Moby Dick. </span><a href="https://www.youtube.com/watch?v=tWbcIrGbMw0" target="_blank" rel="noopener"><span>David Perell</span></a><span> read nearly everything I’d written to discuss the writing process. I went on </span><a href="https://www.youtube.com/watch?v=VqfIxd1x6B" target="_blank" rel="noopener"><span>Francis Fukuyama’s</span></a><span> podcast to ask him about his relationship with Wang Qishan as well as why he is now banned from China. </span><a href="https://www.worksinprogress.news/p/how-to-become-president-of-china" target="_blank" rel="noopener"><span>Works in Progress</span></a><span>, </span><a href="https://www.statecraft.pub/p/leninist-technocracy-with-grand-opera" target="_blank" rel="noopener"><span>Statecraft</span></a><span>, and </span><a href="https://www.chinatalk.media/p/dan-wang-on-modern-china" target="_blank" rel="noopener"><span>ChinaTalk</span></a><span> were each fun in their own way.&nbsp;</span></p>
<p><span>You don’t really mature into being on podcast mode until you’ve done a lot of them. That’s why I proposed to Tyler to go on his show near the end of the book tour. Conversations with Tyler is the first podcast I regularly started listening to, whose early episodes I still remember well. Before our interview, I told Tyler that he was my final boss. Both of us were </span><a href="https://conversationswithtyler.com/episodes/dan-wang/" target="_blank" rel="noopener"><span>playful</span></a><span>. I challenged Tyler to enumerate the list of 12th-century popes and teased him about being a New Jersey suburban boy. He told me that America has great infrastructure and healthcare before issuing an intellectual Turing test to see if I could say why he likes Yunnan more than any other place. I had the chance to bring up one of the most sublime pieces of Rossini, the gently entwining </span><a href="https://www.youtube.com/watch?v=nZfJCWH_Dtk" target="_blank" rel="noopener"><span>trio</span></a><span> that concludes Le Comte Ory. Afterwards, commentators wrote that he and I were confrontational. But they should have watched the video, in which Tyler was smiling as much as he ever would.</span></p>
<p><span>Again, who is listening to all these podcasts? I don’t much look at my book sales, but it doesn’t feel like podcasts move the needle. And a book might create a lot of social media buzz, with all the right people saying all the right things, but Twitter too doesn’t drive sales. It was two platforms that moved a lot of my books: television and radio. People bought after seeing me on CNN or hearing me on NPR. The straightforward explanation is that older people have the time and the money to buy books. Even a brief appearance on TV could reach an ambient audience of millions, a few of whom purchase afterwards. Social media and podcasts are more valuable for driving conversation among the youths.</span></p>
<p><span>It’s stirring to see that people buy books at all. I do not doubt that we are moving towards an oral culture. But the publishing industry is holding up. A lot of excellent books came out this year, including many on China. Revenues at most of the big trade publishers have been rising. Barnes &amp; Noble is opening 60 new stores in 2026. A lot of the growth in the book trade is coming from romantasy and fairy smut, while the genre of nonfiction is in slight decline. That’s all good, I’m no snob. It’s pleasant to believe that a few decades from now, people might still hold physical books in their hands.</span></p>
<p><span>I’ve learned that books produce an invitation to all sorts of conversations, both closed and open. A physical book, bound and printed, has a totemic quality. It’s funny that PDFs sometimes circulate better than web-optimized pages; there’s something about strict formatting that establishes authority. Physical books can also last a long time. This letter that you’re reading will no longer be sent around a month from now, while my book can sit unread on shelves for years to gather dust. So I’m still keen to encourage friends to write their books. It’s a great way to sort through one’s ideas and to ease them into the conversation.</span></p>
<p><span>If I yearned for commercial success in our new oral culture, I would lend my soft voice to narrate romantasy novels. But I worry the superintelligence will devour that job. So I will stick to longform writing. However strange our new world will become, there will always be a class of people who want to engage with essays and books. Over the long term, writing might enjoy the fate of the opera and the symphony. People have been heralding the death of classical music for a century. Yes, much of its audience is pretty old. But there will always be more old people —&nbsp;especially if Silicon Valley delivers on longevity treatments. The job of authors and opera houses is to keep holding on to people who are maturing into pleasures that technological platforms cannot provide. The demographic trend is on our side: the world is producing more old people than youths. I want to be a sunny Californian optimist about everything, including the fate of the written word.</span></p>
<p><span>***</span></p>
<p><span>It’s time to talk about (other) books.</span></p>
<p><span>I last picked up Stendhal’s </span><a href="https://amzn.to/4smWlxu" target="_blank" rel="noopener"><b>The Red and the Black</b></a><span> a decade ago. I wasn’t certain that the novel, which I keep calling my favorite, would hold up on re-reading. It did gorgeously. The plot centers on Julien Sorel, the handsome son of a poor sawyer. After Julien dons the black garb of the priesthood, he moves from the periphery of his Alpine village into the luminous center of Parisian society. Along the way, he seduces two extraordinary women, the gentle Mme. de Rênal and the magnificent Mathilde, while he commits, in the name of love, acts of extraordinary stupidity. Julien — who is possessed by galloping ambition and extravagant pride — maneuvers his way towards aristocratic distinction and romantic triumph. Then he loses all.</span></p>
<p><span>More than anything else, Stendhal is funny, especially about love. Only Proust surpasses Stendhal at the skill of guiding the reader into the transports of intoxicating love, only to snap them out of it by skewering the foolishness of Julien or Mathilde. Stendhal doesn’t create the cool detachment that Flaubert or Fontane bring to their characters. Rather, he’s eager to envelop the reader into his passionate embrace. The list of writers who have succumbed to Stendhal includes Nietzsche, Beauvoir, Girard, Balzac, and Robert Alter, who, before he translated the Hebrew Bible, wrote an admiring biography of Stendhal titled </span><i><span>A Lion for Love</span></i><span>.</span></p>
<p><span>Why is it that reading Stendhal feels like making a discovery? Stendhal might be just on the cusp of the pantheon because his critics can’t get over the significance of his flaws while his fans cannot forget the delights of his peaks. In that sense, Stendhal is like Rossini. Neither produced a ripe and perfect work; I can’t help but feel some disappointment when I listen to Rossini, who couldn’t achieve the musical perfection of Mozart or the dramatic conviction of Verdi. And yet the peak moments of Stendhal and Rossini produce ecstatic joy. It’s no surprise that Stendhal and Rossini are both renowned for their ravenous appetites, nor that Stendhal wrote his own admiring biography of Rossini, filled with his characteristic amusing falsehoods. Erich Auerbach grasped the point that Stendhal ought to be appreciated for his peaks rather than his average. Stendhal has pride of place in </span><i><span>Mimesis</span></i><span>, as an author who fluctuated between “realistic candor in general and silly mystification in particulars,” and between “cold self-control, rapturous abandonment to sensual pleasures, and sentimental vaingloriousness.” In other words, Stendhal embodies the spirit of opera buffa in novel.&nbsp;</span></p>
<p><span>I am often drawn to </span><a href="https://amzn.to/4phTFyo" target="_blank" rel="noopener"><b>Ecclesiastes</b></a><span>. In Robert Alter’s hands, the gloomy prophet behind the book is named Qohelet, and though I value Alter’s translation, I favor a few of the more iconic lines from King James: “vanity of vanities, all is vanity” and “better to hear the rebuke of the wise than the song of fools.” Melancholy attracts me in any form, and isn’t Ecclesiastes the most melancholic book? The prophet makes small allowances for joy and celebration before hauling the reader back into the house of mourning. There is something deeply satisfying with reading out loud phrases like: “for in mere breath did it come, and into darkness it goes, and in darkness its name is covered.” Though King James is iconic, Robert Alter better conveys overall the literary power of the Hebrew Bible.</span></p>
<p><span>Marlen Haushofer’s </span><a href="https://amzn.to/44RAtk1" target="_blank" rel="noopener"><b>The Wall</b></a><span> is short and engrossing. It was deemed a “Cold War” novel by the German press when it was published in 1963. Little about it comes across as being geopolitical today. Rather, Haushofer has written a book about domesticity that manages to be gripping. The heroine spends her days milking her cow, minding her garden, and caring for her cat and dog while living in total isolation in the Alps. She would not survive if she lacked for any of the above. As Katherine Rundell once wrote, “It’s easier to trust a writer who writes great food: they are a person who has paid attention to the world.” Haushofer pays loving attention to the details of life. It never became boring to read about the narrator churning her butter, tending to her potato field, or chopping wood throughout the year.</span></p>
<p><span>After a man turns 30, he has to choose between specializing in the history of the Roman Empire or the World Wars. Within the latter, one tends to focus on the Pacific Theater, the Western Front, or the Eastern Front. For me, the last theater is the most interesting. No human effort approaches the gargantuan scale of Operation Barbarossa or the Soviet reply. The same fields, one world war earlier, produced other shocks. Nick Lloyd’s </span><a href="https://amzn.to/492lEgR" target="_blank" rel="noopener"><b>The Eastern Front</b></a><span> covers the clashes between Imperial Germany and the Russian Empire as well as the Austro-Hungarians against the Italians and the Serbs. Whereas the western front was essentially static throughout the whole war, the east was characterized by the sort of maneuver warfare that most generals had expected to fight. It was the field of legendary confrontations like the Gorlice-Tarnow campaign, the Brusilov offensive, and the 37th Battle of the Isonzo.</span></p>
<p><span>One of the revelations of Lloyd’s book is how well the Germans fought and how poorly Austro-Hungary performed, ending the war by self-liquidating. Immediately after the war began, German military attachés had already begun to fret that “the major trouble with the Austro-Hungarian Army is currently its weakness in combat.” It became nearly comical how often the Kaiser had to intervene, in the latter half of the war, to stop Emperor Karl from surrendering to the Entente. Perhaps it shouldn’t be surprising that the fighting force of an army where the officers all spoke German and regiments spoke Czech or Croatian could not overwhelm the adversary. The eastern front had diplomatic scheming that was nearly as impressive as the battlefield breakthroughs. It was, after all, the political section of the German general staff that had the imaginative idea to ship Lenin from Switzerland to Russia in order to make revolution.</span></p>
<p><span>I’m looking for a book that has a clear focus on bigger questions: How did Hohenzollern Prussia outmaneuver Habsburg Austria? And how did they become such firm allies before the war? John Boyer’s </span><a href="https://amzn.to/4q3qhNO" target="_blank" rel="noopener"><b>Austria 1867-1955</b></a><span> offers parts of the answer, though not in a conceptually organized way. It’s a work of history written for specialists, which means that the narrative serves the footnotes rather than the other way around. Too much of the book is focused on how politicians grappled with each other. Still it yields many morsels. One difference between Austrian nobles and Prussian nobles was that the former did not view a military life as attractive — part of the reason that Austrians performed so badly in war. Austria’s partner was sometimes rooting for the adversary: “a large, successful Prussia was Hungary’s best guarantee that Austria would not gain a superior position to dominate the Hungarian elites.” And this insight feels like a good explanation of the attractiveness of Austrian Catholicism, which “combines a Jansenist, puritanical strain with exuberant baroque piety.” It’s the sort of exuberance that produced a Mozart, rather than more gloomy and ardent Spanish Catholicism that produced the Inquisition.&nbsp;</span></p>
<p><span>One lesson from the latter years of Austro-Hungary is a good reminder that periods of state decay often correspond with eras of cultural flowering. </span><a href="https://amzn.to/4pfErKj" target="_blank" rel="noopener"><b>1913: The Year Before the Storm</b></a><span> presents a whimsical slice of Central Europe. Art historian Florian Illies collates fragments of leading figures month by month, diary-entry style. People were running into each other all the time. Duchamp, d’Annunzio, Debussy at the premiere of the Rite of Spring. Stalin potentially tipping his hat at Hitler, as both residents of Vienna were known to take evening strolls through the gardens of Schönbrunn. Matisse bringing flowers to Picasso while the latter was sick. Rainer Maria Rilke being moody at the seaside with Sidonie Nadherny while she was running off into the arms of Karl Kraus. The celebrated love affairs between Franz Kafka and Felice Bauer, Igor Stravinsky and Coco Chanel, Alma Mahler and Oskar Kokoschka, Alma Mahler with Walter Gropius, Alma Mahler with anyone, really. 1913 is the year that modernism was born; the continent began to shatter the following year.</span></p>
<p><span>Nan Z. Da’s </span><a href="https://amzn.to/45Aapdh" target="_blank" rel="noopener"><b>The Chinese Tragedy of King Lear</b></a><span> also has an experimental form. Da is a professor of literature at Johns Hopkins who emigrated from Hangzhou before she was 7. One half of the book is a literary analysis of Shakespeare; the other half of the book is the story of the chaos of Maoist society and her family’s personal experiences of it. The novelty is the weaving of family history with a classic piece of literature. Sometimes these transitions are jarring, perhaps deliberately so. Da has just barely begun musing about the reign of Goneril and Regan before she launches into an exposition: “A history — I am thirty nine years old. My parents left China for the United States at this age.” But I liked this effort to map Mao’s madness onto Lear’s delirium as well as analogizing Deng’s tenacity to Edgar’s determination to lay low. And it convinced me that Lear is the most Chinese of Shakespeare’s plays. It is the marriage of the eastern emphasis on pro forma ceremonies, excessive flattery, and empty speechifying with the western practice of elder abuse. I’d like to read more experimental books like this one.</span></p>
<p><span>Susannah Clarke’s </span><a href="https://amzn.to/4piBGrG" target="_blank" rel="noopener"><b>Piranesi</b></a><span> is a glittering jewel. The setting is a mysterious, magical house. The narrator is a radiantly earnest explorer who self-identifies as a “Beloved Child of the House.” His warm curiosity makes this book an adventurer’s diary. I liked the fantasy elements of the first half better than the second half of the book, which disenchanted some of the story, so maybe it’s better to stop halfway through. Afterwards, I read Clarke’s earlier book, </span><em>Jonathan Strange &amp; Mr Norrell</em><span>. It’s enjoyable too, especially for its partisanship of Northern English identity, though the book as a whole is wooly. Susannah Clarke offers a good case study of how authors can think about their work over time: an overlong first book that took decades to craft, followed by a shorter and more glittering second work. I can’t wait to see what her third book will be like.</span></p>
<p><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="700" height="777" src="https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?resize=700%2C777&amp;ssl=1" alt="" srcset="https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?resize=700%2C777&amp;ssl=1 700w, https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?resize=465%2C516&amp;ssl=1 465w, https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?resize=768%2C852&amp;ssl=1 768w, https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?resize=200%2C222&amp;ssl=1 200w, https://i0.wp.com/danwang.co/wp-content/uploads/2026/01/Grossberg-Maschinensaal.jpg?w=894&amp;ssl=1 894w" sizes="(max-width: 700px) 100vw, 700px"></p>
<p><span>(</span><i><span>The Neue Galerie’s exhibition this year on </span></i><a href="https://www.neuegalerie.org/exhibitions/neuesachlichkeit" target="_blank" rel="noopener"><i><span>New Objectivity</span></i></a><i><span> led me to the work of German painter Carl Grossberg. This 1925 work spoke to me. Credit: </span></i><a href="https://commons.wikimedia.org/wiki/File:Grossberg-Maschinensaal.jpg" target="_blank" rel="noopener"><i><span>Wikimedia</span></i></a><i><span>.)</span></i></p>
<p><span>I’ve learned that Christmas is a good time to write. Emails stop and all is calm. I submitted my manuscript this time last year in Vietnam. This year, my wife and I are writing from Bali. Tropical Asia makes for great writing retreats. We have lazy mornings that feature a swim and a big breakfast; then we spend the rest of the day writing before going out in the evening for some really spicy food.</span></p>
<p><span>A few food questions to wrap up:</span></p>
<ol>
<li aria-level="1"><span>Is Da Nang the most underrated food city in Asia? Yes, we all know about excellent eating spots in Penang, Tokyo, Yunnan, etc. But I hardly ever hear about Da Nang, which has several Michelin listed places. I am still dreaming about its chewy rice products, the grilled meats, the spice mixes, the seafood soups, the not-too-sweet desserts. It’s well-listed on Michelin guides, but I hardly hear about it. Da Nang is my submission for a food city that ought to be better recognized as a destination.</span></li>
<li aria-level="1"><span>Over the summer in Europe, I found myself wondering why Copenhagen has such amazing baked goods. I think its croissants are even better than in Paris. Then I found myself wondering about the quality distribution of croissants throughout the continent. They are not so good in Spain and Italy. I believe that Italy and Spain have the best overall cuisine in Europe; but they have been less interested in producing excellent baked goods. Is it because they don’t have as good butter? But they still eat a lot of cheese. The US is getting better croissants in big cities, which once more makes me appreciate that America has excellence across many cuisines, though they tend to be scattered.</span></li>
<li aria-level="1"><span>Every winter, I find myself craving vitamin-rich tropical fruits. I mean mostly passionfruit, mango, papaya, eggfruit, and of course durian. American groceries are stocking more rambutan and dragonfruit. I wonder if they could stock even more. It’s always mango season somewhere, for example, so is it possible to find better mangoes throughout the year? Is there a subscription package to receive regular shipments of passionfruit and mango? I realize the durian supply chain is highly complicated (apparently the fruit is pollinated mostly by bats), but still it would be nice to have the fruit occasionally. I realize that tariffs are hurting access to American essentials like coffee and bananas. But I hope that Americans can continue to demand better fruits.</span></li>
</ol>

<!-- widgets_on_page -->
<!--/#footnotes--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iOS allows alternative browser engines in Japan (389 pts)]]></title>
            <link>https://developer.apple.com/support/alternative-browser-engines-jp/</link>
            <guid>46453950</guid>
            <pubDate>Thu, 01 Jan 2026 13:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/support/alternative-browser-engines-jp/">https://developer.apple.com/support/alternative-browser-engines-jp/</a>, See on <a href="https://news.ycombinator.com/item?id=46453950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

						
						
						<p>In iOS 26.2 and later, browser engines other than WebKit can be used in two types of apps for users in Japan: Dedicated browser apps that provide a full web browser experience, and apps from browser engine stewards that provide in-app browsing experiences using an embedded browser engine.</p>

						<p>Apple will provide authorized developers access to technologies within the system that enable critical functionality and help them offer high-performance modern browser engines. These technologies include just-in-time compilation, multiprocess support, and more.</p>

						<p>However, as browser engines are constantly exposed to untrusted and potentially malicious content and have visibility of sensitive user data, they are one of the most common attack vectors for bad actors. To help keep users safe online, Apple will only authorize developers to implement alternative browser engines after meeting specific criteria and who commit to a number of ongoing privacy and security requirements, including timely security updates to address emerging threats and vulnerabilities.</p>

						<hr id="web-browser-engine-entitlement">

						<h2 id="web-entitlement" data-sidenav="">Web Browser Engine&nbsp;Entitlement</h2>
						<h4>For browser apps</h4>
						<p>With the Web Browser Engine Entitlement, you can use an alternative browser engine in your browser app. If you’re interested in using an alternative browser engine in your browser app, review the requirements below, then <a href="https://developer.apple.com/contact/request/web-browser-engine/">submit your request<span></span></a> for the Web Browser Engine Entitlement. For technical guidance, review: </p>
						<ul>
							<li><a href="https://developer.apple.com/documentation/browserenginekit">BrowserEngineKit<span></span></a></li>
							<li><a href="https://developer.apple.com/documentation/browserenginecore">BrowserEngineCore<span></span></a></li>
							<li><a href="https://developer.apple.com/documentation/xcode/preparing-your-app-to-be-the-default-browser">Preparing your app to be the default browser<span></span></a></li>
						</ul>

						<h3>Requirements</h3>
						<p>To qualify for the entitlement, your app must:</p>
						<ul>
							<li>Be distributed solely on iOS in Japan (except for any other jurisdiction or Apple platform expressly permitted by Apple under the Developer Agreement - including any addenda - for which you have likewise obtained a corresponding entitlement profile);</li>
							<li>Be a separate binary from any application that uses the system-provided web browser engine;</li>
							<li>Have the <a href="https://developer.apple.com/documentation/xcode/preparing-your-app-to-be-the-default-browser">Default Browser Entitlement<span></span></a></li>
							<li>Meet the following functional requirements to ensure your app is using a web browser engine that provides a baseline of web functionality: <ul>
									<li>Pass a minimum percentage of tests available from industry standard test suites: 
									<ul>
											<li>90% of <a href="https://wpt.fyi/results/">Web Platform Tests<span></span></a></li>
											<ul>
												<li>as a percentage of the highest number of subtests executed by any browser on the wpt.fyi front page; and</li>
												<li>on an operating system that the test suite is compatible with</li>
											</ul>
											<li>80% of <a href="https://github.com/tc39/test262">Test262<span></span></a> on an iOS device, iPadOS device, or Mac with Apple silicon; and</li>
										</ul>
									</li>
									<li>Meet the above test suite requirement if Just in Time (JIT) compilation is unavailable (e.g., if Lockdown Mode is enabled by the user)</li>
								</ul>
							</li>
							<li>You and your app must meet the following security requirements: <ul>
									<li>Commit to secure development processes, including monitoring your app’s software supply chain for vulnerabilities, and following best practices around secure software development (such as performing threat modeling on new features under development).</li>
									<li>Provide a URL to a published vulnerability disclosure policy that includes contact information for reporting of security vulnerabilities and issues to you by third parties (which may include Apple), what information to provide in a report, and when to expect status updates.</li>
									<li>Commit to mitigate vulnerabilities that are being exploited within your app or the alternative web browser engine it is using in a timely manner (e.g., 30 days for the simplest classes of vulnerabilities being actively exploited).</li>
									<li>Provide a URL to a publicly available web page (or pages) that provides information on which reported vulnerabilities have been resolved in specific versions of the browser engine and associated app version if different.</li>
									<li>If your alternative web browser engine uses a root certificate store that is not accessed via the iOS SDK, you must make the root certificate policy publicly accessible and the owner of that policy must participate as a browser in the Certification Authority / Browser Forum.</li>
									<li>Demonstrate support for modern Transport Layer Security protocols to protect data-in-transit communications when the browser engine is in use.</li>
								</ul>
							</li>
						</ul>
						<h5>Program security requirements</h5>
						<p>You must:</p>
						<ul>
							<li>Use memory-safe programming languages, or features that improve memory safety within other languages, within the alternative web browser engine at a minimum for all code that processes web content;</li>
							<li>Adopt the latest security mitigations (for example, Pointer Authentication Codes) that remove classes of vulnerabilities or make it much harder to develop an exploit chain. This includes adoption of:
								<ul>
									<li>Pointer Authentication Codes (PAC);</li>
									<li>Memory Integrity Enforcement (MIE) for any (i) system-provided allocators in any content extension and (ii) custom- or system-provided allocators in any processes and extensions of your app, including in your network and graphics rendering extensions;</li>
								</ul>
							</li>
							<li>Follow secure design and coding best practices;</li>
							<li>Use process separation to limit the effects of exploitation and validate inter-process communication (IPC) within the alternative web browser engine;</li>
							<li>Monitor for vulnerabilities in any third-party software dependencies and your app’s broader software supply chain, migrating to newer versions if a vulnerability impacts your app;</li>
							<li>Not use frameworks or software libraries that are no longer receiving security updates in response to vulnerabilities; and</li>
							<li>Prioritize resolving reported vulnerabilities with expedience, over new feature development. For example, where the alternative web browser engine bridges capabilities between the platform’s SDK and web content to enable Web APIs, upon request you must remove support for such a Web API if it is identified to present a vulnerability. Most vulnerabilities should be resolved in 30 days, but some may be more complex and may take longer.</li>
						</ul>
						<h5>Program privacy requirements</h5>
						<p>You must:</p>
						<ul>
							<li>Block cross-site cookies (i.e., third-party cookies) by default unless the user expressly opts to allow such cookies with informed consent, or as required for compatibility in the case of popup windows that interact with frames in their opening window;</li>
							<li>Partition any storage or state observable by websites per top-level website, or block such storage or state from cross-site usage and observability;</li>
							<li>Not sync any state (including cookies) between your app and any other app, even another app from the same developer, unless the user has explicitly given permission for the state to be synced, either by signing into both your app and the other app, or through another mechanism of providing explicit permission;</li>
							<li>Not share device identifiers with websites without informed consent and user activation;</li>
							<li>Label network connections using the APIs provided to generate an App Privacy Report on iOS (i.e., wherever your app is distributed); and</li>
							<li>Follow commonly adopted web standards on when to require informed user activation and/or user consent, as appropriate for web APIs (e.g., clipboard or full screen access), including those that provide access to PII.</li>
						</ul>
						<hr id="embedded-browser-engine-entitlement">

						<h2 id="embedded-entitlement" data-sidenav="">Embedded Browser Engine&nbsp;Entitlement</h2>
						<h4>For in-app browsing</h4>
						<p>With the Embedded Browser Engine Entitlement, you can embed an alternative browser engine within your app to provide in-app browsing. In-app browsing is the display of content dynamically from the web that would be accessible and work within a web browser app. This doesn’t include content embedded within or only obtainable via the app.</p>
						<p>The primary focus of your app while providing in-app browsing must be to provide web browsing functionality. When providing in-app browsing, the user interface must:</p>
						<ul>
							<li>Take over the majority of the display, apart from relevant controls allowing the end user to control the browsing session;</li>
							<li>Provide a button or link to the default browser of the system to allow the user to open a dedicated browser app to view the content currently being displayed; and</li>
							<li>Display the domain or URL whose content is being rendered by in-app browsing.</li>
						</ul>
						<p>If you’re interested in using an alternative browser engine in your app to provide in-app browsing experiences, review the requirements below, then <a href="https://developer.apple.com/contact/request/embdedded-browser-engine/">submit your request<span></span></a> for the Embedded Browser Engine Entitlement. You will need to provide information on the engine that you are intending to embed, including how it meets the requirements and how it can be integrated into an app to provide the in-app browsing experience. For technical guidance, review the Examples and Resources section.</p>

						<h3>Requirements</h3>
						<p>To qualify for the entitlement, your organization must be a browser engine steward. A browser engine steward is an entity with the primary responsibility for operating a distinct web browser engine.</p>
						<ul>
							<li>Primary responsibility means you have operational control over, and are ultimately responsible for, coordinating a response where a security or privacy vulnerability is found in the web browser engine, and resolving it.</li>
							<li>A distinct web browser engine is maintained by a different entity or organization than any other web browser engine, and has both architecture and support for Web APIs that are materially distinct from any other engine. The engine is not generally updated to reflect changes made to its forks, but instead pushes out changes to its forks.</li>
						</ul>

						<h5>App requirements</h5>

						<p>Your app must:</p>
						<ul>
							<li>Be distributed solely on iOS in Japan (except for any other jurisdiction or Apple platform expressly permitted by Apple under the Developer Agreement - including any addenda - for which you have likewise obtained a corresponding entitlement profile);
							</li><li>Use the entitlement solely for in-app browsing;
							</li><li>Not have the default browser entitlement
							</li><li>Meet the following functional requirements to ensure your app is using a web browser engine that provides a baseline of web functionality:
								<ul>
									<li>Pass a minimum percentage of tests available from industry standard test suites:
										<ul>
											<li>90% of <a href="https://wpt.fyi/results/">Web Platform Tests<span></span></a></li>
												<ul>
													<li>as a percentage of the highest number of subtests executed by any browser on the wpt.fyi front page; and</li>
													<li>on an operating system that the test suite is compatible with</li>
												</ul>
											
											<li>80% of <a href="https://github.com/tc39/test262">Test262<span></span></a> on an iOS device, iPadOS device, or Mac with Apple silicon; and</li>
										</ul>
									</li>
									<li>Meet the above test suite requirement if Just in Time (JIT) compilation is unavailable (e.g., if Lockdown Mode is enabled by the user)</li>
								</ul>
							</li>
							<li>Meet the following security requirements: <ul>
									<li>Commit to secure development processes, including monitoring your Application’s software supply chain for vulnerabilities, and following best practices around secure software development (such as performing threat modeling on new features under development).</li>
									<li>Provide a URL to a published vulnerability disclosure policy that includes contact information for reporting of security vulnerabilities and issues to you by third parties (which may include Apple), what information to provide in a report, and when to expect status updates.</li>
									<li>Commit to mitigate vulnerabilities that are being exploited within your app or the alternative web browser engine in a timely manner (e.g., 30 days for the simplest classes of vulnerabilities being actively exploited).</li>
									<li>Provide a URL to a publicly available webpage (or pages) that provides information on which reported vulnerabilities have been resolved in specific versions of the browser engine and associated app version if different.</li>
									<li>If the alternative web browser engine you choose uses a root certificate store that is not accessed via the iOS SDK, you must make the root certificate policy publicly accessible and the owner of that policy must participate as a Certificate Consumer in the Certification Authority / Browser Forum.</li>
									<li>Demonstrate support for modern Transport Layer Security protocols to protect data-in-transit communications when the browser engine is in use.</li>
								</ul>
							</li>
						</ul>

						<h5>Program security requirements</h5>
						<p>You must:</p>
						<ul>
							<li>Use memory-safe programming languages, or features that improve memory safety within other languages, within the Alternative Web Browser Engine at a minimum for all code that processes web content;</li>
							<li>Adopt the latest security mitigations that remove classes of vulnerabilities or make it much harder to develop an exploit chain;</li>
							<li>Follow secure design, and secure coding, best practices;</li>
							<li>Monitor for vulnerabilities in any third-party software dependencies and your app’s broader software supply chain, migrating to newer versions if a vulnerability impacts your app;</li>
							<li>Not use frameworks or software libraries that are no longer receiving security updates in response to vulnerabilities; and</li>
							<li>Prioritize resolving reported vulnerabilities with expedience, over new feature development. For example, where the alternative browser engine bridges capabilities between the platform’s SDK and web content to enable Web APIs, upon request you must remove support for such a Web API if it is identified to present a vulnerability. Most vulnerabilities should be resolved in 30 days, but some may be more complex and may take longer.</li>
						</ul>

						<h5>Program privacy requirements</h5>
						<p>You must:</p>
						<ul>
							<li>Block cross-site cookies (i.e., third-party cookies) by default unless the user expressly opts to allow such cookies with informed consent, or as required for compatibility in the case of popup windows that interact with frames in their opening window;</li>
							<li>Partition any storage or state observable by websites per top level website, or block such storage or state from cross-site usage and observability;</li>
							<li>Not share device identifiers with websites without informed consent and user activation;</li>
							<li>Label network connections using the APIs provided to generate an App Privacy Report on iOS (i.e., wherever your app is distributed); and</li>
							<li>Follow commonly adopted web standards on when to require informed user activation and/or user consent, as appropriate for Web APIs (e.g., clipboard or full screen access), including those that provide access to PII.</li>
						</ul>
						<h5>Additional requirements</h5>
						<ul>
							<li>You must submit with each binary submission the name and version of the alternative web browser engine embedded in your app.</li>
							<li>Upon a new version of the alternative web browser engine embedded in your app being made available, you must submit an update to your app with that new version within fifteen (15) calendar days.</li>
						</ul>
						<hr id="examples-and-resources">

						<h2 id="examples-resources" data-sidenav="">Examples and resources</h2>
						<p>This section contains additional resources and examples to help you meet the requirements that allow you to use an alternative browser engine.</p>

						<h3>Secure SDLC (Software Development Lifecycle)</h3>
						<p>Many of the requirements that you need to meet rely on developing a security and privacy-first approach to introducing new features into your app. When you begin development on a new feature, you should first develop a threat model as well as a plan for how you will gain assurance that your architecture and the released version of your app mitigates the risks you’ve identified. There are a number of techniques to gaining assurance — for example, code auditing, fuzz testing, and writing tests to verify the security properties you intend to enforce. You should consider all web content to be untrusted and potentially malicious.</p>

						<h5>Resources</h5>
						<ul>
							<li><a href="https://developer.apple.com/documentation/browserenginekit">Learn more about the BrowserEngineKit framework<span></span></a></li>
							<li><a href="https://developer.apple.com/documentation/browserenginekit/designing-your-browser-architecture">Learn more about designing your browser architecture<span></span></a></li>
							<li><a href="https://developer.apple.com/videos/play/wwdc2020/10189/">Secure your app: threat modeling and anti-patterns (WWDC20)</a></li>
							<li><a href="https://developer.apple.com/security/">Security<span></span></a></li>
							<li><a href="https://developer.mozilla.org/en-US/docs/Glossary/Fuzzing">Fuzz testing (MDN)<span></span></a></li>
						</ul>

						<h3>Security Mitigations and Memory Safety</h3>

						<p>You should also consider what current security mitigations are provided by iOS or iPadOS, such as Pointer Authentication Codes and Memory Integrity Enforcement, and what programming languages (or language and compiler features, and other tooling) are available to mitigate each threat you identify. For example, Swift is a memory-safe language by default, and can help you avoid a number of common sources of vulnerabilities, as well as other memory-related software bugs. However, memory-unsafe languages such as C++ do provide features that provide memory safety benefits - such as <code>std::span</code>. Additionally, compiler options and tools can be used, for example -fbounds-safety with C, which allows annotation of existing code to mitigate out-of-bounds memory access without always requiring rewriting of functionality in a language that’s memory safe by default.</p>

						<h5>Resources</h5>

						<ul>
							<li><a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/memorysafety/">The Swift Programming Language: Memory Safety<span></span></a></li>
							<li><a href="https://docs.swift.org/compiler/documentation/diagnostics/strict-memory-safety/">Swift StrictMemorySafety<span></span></a></li>
							<li><a href="https://developer.apple.com/documentation/Xcode/enabling-enhanced-security-for-your-app">Enabling enhanced security for your app<span></span></a></li>
						</ul>

						<h3>Vulnerability Management</h3>
						<p>You should assume that undiscovered vulnerabilities will always be present within a browser engine or that any new features could introduce unintended risks. Therefore, it is vital that you have the processes in place to allow you to respond when a vulnerability is discovered either internally through testing and security and privacy assurance efforts, within your software supply chain, or disclosed to you by another&nbsp;party.</p>
						<p>Where you provide a pathway for a third party (for example, a security researcher) to report a vulnerability to you, you should consider what information you will need from them to enable you to quickly determine the validity and cause of the issue. You should also ensure that you have processes in place to prioritize a fix for the vulnerability and then release an update that might be out of step with your normal schedule.</p>
						<p>It’s also important that users can quickly determine which public vulnerabilities that have an associated <a href="https://www.cve.org/ResourcesSupport/Glossary?activeTerm=glossaryRecord#">CVE-ID<span></span></a> are resolved in which version of your app (or alternative browser engine).</p>
						<h5>Resources</h5>
						<ul>
							<li><a href="https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks">Verifying the origin of your XCFrameworks<span></span></a></li>
							<li><a href="https://support.apple.com/102549">Report a security or privacy vulnerability</a></li>
							<li><a href="https://security.apple.com/bounty/guidelines/">Apple Security Bounty Guidelines<span></span></a></li>
							<li><a href="https://support.apple.com/HT201222">Apple Security Releases</a></li>
						</ul>

						<h3>Network Security</h3>
						<p>By using the iOS SDK, specifically the Network framework and/or SecTrust APIs, you reduce your need to take responsibility for evaluating the trust of web certificates and maintaining or using a corresponding root trust store and program for the alternative browser engine you use. If you do operate a program - it should provide information on how a root certificate authority (CA) can apply to become part of the program, and also how incidents (for example, the exposure of a root certificate authority’s private key material) can be reported such that you can take action.</p>
						<p>Protocols used on the web are constantly evolving to respond to emerging threats and better protect user privacy and security. The current modern TLS versions that should be compatible with your alternative browser engine that have not been deprecated are TLS 1.2 and 1.3. However, these may change over time. You can support deprecated protocols in your alternative browser engine, but you should inform users when they browse to a site that only supports these.</p>
						<h5>Resources</h5>
						<ul>
							<li><a href="https://developer.apple.com/documentation/network">Network framework<span></span></a></li>
							<li><a href="https://developer.apple.com/documentation/security/sectrust">SecTrust<span></span></a></li>
							<li><a href="https://www.apple.com/certificateauthority/ca_program.html">Apple Root Certificate Program<span></span></a></li>
							<li><a href="https://datatracker.ietf.org/doc/html/rfc8446">The Transport Layer Security (TLS) Protocol Version 1.3<span></span></a></li>
						</ul>

						<h3>Agreements</h3>
						<ul>
							<li><a href="https://developer.apple.com/contact/request/download/embedded_browser_engine-jp.pdf">Embedded Browser Engine Entitlement Addendum for Apps in Japan<span></span></a></li>
							<li><a href="https://developer.apple.com/contact/request/download/web_browser_engine-jp.pdf">Web Browser Engine Entitlement Addendum for Apps in Japan<span></span></a></li>
						</ul>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta made scam ads harder to find instead of removing them (300 pts)]]></title>
            <link>https://sherwood.news/tech/rather-than-fully-cracking-down-on-scam-ads-meta-worked-to-make-them-harder/</link>
            <guid>46453582</guid>
            <pubDate>Thu, 01 Jan 2026 12:29:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sherwood.news/tech/rather-than-fully-cracking-down-on-scam-ads-meta-worked-to-make-them-harder/">https://sherwood.news/tech/rather-than-fully-cracking-down-on-scam-ads-meta-worked-to-make-them-harder/</a>, See on <a href="https://news.ycombinator.com/item?id=46453582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-post-id="2jfa4ZRecwEY4R8ChzMkkp" id="__next"><header><div><a href="https://sherwood.news/"><div><p><img alt="Tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a></div></header><div><article><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a><div><div><p>In its latest piece on <span><a href="https://robinhood.com/us/en/stocks/META/?source=sherwood"><span>Meta’s</span></a></span> scam ads, Reuters found that the social media giant didn’t just remove fraudulent ads from its platforms — it also worked to make them harder for governments and journalists to find.</p><p>Fearing that Japanese regulators would require universal advertiser verification — a measure Meta estimated would cost roughly $2 billion to implement and potentially reduce its revenue by nearly 5% — the company took steps to make scam ads less “discoverable” to “regulators, investigators and journalists,” according to internal documents reviewed by Reuters.</p></div><div><p>“So successful was the search-result cleanup that Meta, the documents show, added the tactic to a ‘general global playbook’ it has deployed against regulatory scrutiny in other markets, including the United States, Europe, India, Australia, Brazil and Thailand,” Reuters wrote. </p><p>Previous Reuters reporting found Meta internally projected that about <a href="https://sherwood.news/tech/meta-projected-10-of-2024-revenue-came-from-scams-and-banned-goods-reuters/" target="_blank" rel="noopener">10% of its 2024 revenue</a> would come from ads tied to scams and banned goods, though the company later said that estimate was overly broad. Reuters also reported the rate was <a href="https://sherwood.news/tech/nearly-20-of-metas-chinese-ad-revenue-came-from-scams-and-other-banned/" target="_blank" rel="noopener">double in China</a>.</p></div></div><div><p>“So successful was the search-result cleanup that Meta, the documents show, added the tactic to a ‘general global playbook’ it has deployed against regulatory scrutiny in other markets, including the United States, Europe, India, Australia, Brazil and Thailand,” Reuters wrote. </p><p>Previous Reuters reporting found Meta internally projected that about <a href="https://sherwood.news/tech/meta-projected-10-of-2024-revenue-came-from-scams-and-banned-goods-reuters/" target="_blank" rel="noopener">10% of its 2024 revenue</a> would come from ads tied to scams and banned goods, though the company later said that estimate was overly broad. Reuters also reported the rate was <a href="https://sherwood.news/tech/nearly-20-of-metas-chinese-ad-revenue-came-from-scams-and-other-banned/" target="_blank" rel="noopener">double in China</a>.</p></div></div></article></div><div><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a></div><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a></div><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a><div><a href="https://sherwood.news/tech/tesla-compiled-estimates-show-q4-deliveries-expected-to-fall-15-from-last/"><h2><span>Tesla-compiled estimates show Q4 deliveries expected to fall 15% from last year</span></h2></a><p>A <span><a href="https://robinhood.com/stocks/TSLA?source=sherwood"><span>Tesla</span></a></span>-compiled average of analyst estimates pegs fourth-quarter deliveries at 422,850, which would mark a 15% slump from the 495,570 the company delivered in the same quarter last year, if realized. The full-year estimate of 1.6 million vehicles would represent an 8% decline from 2024 and the second annual decline for the EV company. The estimates are notably lower than the consensus estimates compiled by Bloomberg and FactSet, which have been <a href="https://sherwood.news/tech/estimates-for-teslas-q4-deliveries-are-declining/" target="_blank" rel="noopener">declining</a> over the past month.</p><p>The <a href="https://robinhood.com/us/en/prediction-markets/financial/events/tesla-deliveries-in-q4-2025-dec-08-2025/" target="_blank" rel="noopener">market-implied odds derived from event contracts</a> show that most traders think Tesla deliveries will be more than 410,000 but less than 420,000 in the quarter ending December.</p><p>(Event contracts are offered through Robinhood Derivatives, LLC — probabilities referenced or sourced from KalshiEx LLC or ForecastEx LLC.)</p><p>While Tesla typically shares its compilation of analyst estimates with institutional investors, this is the first time the company has shared those numbers on its own <a href="https://ir.tesla.com/press-release/delivery-consensus-fourth-quarter-2025" target="_blank" rel="noopener">website</a>. Tesla’s numbers include estimates from Daiwa, DB, Wedbush, OpCo, Canaccord, Baird, Wolfe, Exane, GS, RBC, Evercore ISI, Barclays, Wells Fargo, Morgan Stanley, UBS, Jefferies, Needham &amp; Co., HSBC, Cantor Fitzgerald, and William Blair.</p><p>Actual numbers are expected Friday. </p></div></div><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a></div><div><a href="https://sherwood.news/tech/"><div><p><img alt="tech" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></a><div><p>Currently the FactSet consensus estimate expects Tesla to deliver 449,000 vehicles in Q4, down 9.5% from last year’s 496,000 and down from 450,000 <a href="https://sherwood.news/tech/how-many-vehicles-analysts-think-tesla-will-deliver-this-quarter/" target="_blank" rel="noopener">earlier this month</a>. Bloomberg now pegs the number at 445,000, down from a 448,000 consensus estimate at the start of December. </p><p>Prediction markets are even less bullish. The <a href="https://robinhood.com/us/en/prediction-markets/financial/events/tesla-deliveries-in-q4-2025-dec-08-2025/" target="_blank" rel="noopener">market-implied odds derived through event contracts</a> show that less than a quarter of traders believe Tesla will surpass 430,000 deliveries in the quarter ending December.  The actual delivery numbers are expected to be released in early January.</p><p>(Event contracts are offered through Robinhood Derivatives, LLC — probabilities referenced or sourced from KalshiEx LLC or ForecastEx LLC.)</p></div><div><p>Currently the FactSet consensus estimate expects Tesla to deliver 449,000 vehicles in Q4, down 9.5% from last year’s 496,000 and down from 450,000 <a href="https://sherwood.news/tech/how-many-vehicles-analysts-think-tesla-will-deliver-this-quarter/" target="_blank" rel="noopener">earlier this month</a>. Bloomberg now pegs the number at 445,000, down from a 448,000 consensus estimate at the start of December. </p><p>Prediction markets are even less bullish. The <a href="https://robinhood.com/us/en/prediction-markets/financial/events/tesla-deliveries-in-q4-2025-dec-08-2025/" target="_blank" rel="noopener">market-implied odds derived through event contracts</a> show that less than a quarter of traders believe Tesla will surpass 430,000 deliveries in the quarter ending December.  The actual delivery numbers are expected to be released in early January.</p><p>(Event contracts are offered through Robinhood Derivatives, LLC — probabilities referenced or sourced from KalshiEx LLC or ForecastEx LLC.)</p></div></div></div><section><p><h3>Latest Stories</h3></p></section><div><p>Sherwood Media, LLC produces fresh and unique perspectives on topical financial news and is a fully owned subsidiary of Robinhood Markets, Inc., and any views expressed here do not necessarily reflect the views of any other Robinhood affiliate, including Robinhood Markets, Inc., Robinhood Financial LLC, Robinhood Securities, LLC, Robinhood Crypto, LLC, or Robinhood Money, LLC.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluetooth Headphone Jacking: A Key to Your Phone [video] (454 pts)]]></title>
            <link>https://media.ccc.de/v/39c3-bluetooth-headphone-jacking-a-key-to-your-phone</link>
            <guid>46453204</guid>
            <pubDate>Thu, 01 Jan 2026 11:17:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/39c3-bluetooth-headphone-jacking-a-key-to-your-phone">https://media.ccc.de/v/39c3-bluetooth-headphone-jacking-a-key-to-your-phone</a>, See on <a href="https://news.ycombinator.com/item?id=46453204">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Dennis+Heinze">Dennis Heinze</a> and
<a href="https://media.ccc.de/search?p=Frieder+Steinmetz">Frieder Steinmetz</a>

</p>

<a href="https://media.ccc.de/c/39c3/One" rel="tag">One</a>
<a href="https://media.ccc.de/c/39c3/Security" rel="tag">Security</a>
Playlists:
<a href="https://media.ccc.de/v/39c3-bluetooth-headphone-jacking-a-key-to-your-phone/playlist">'39c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/39c3-bluetooth-headphone-jacking-a-key-to-your-phone/audio">audio</a>

<!-- %h3 About -->
<p>Bluetooth headphones and earbuds are everywhere, and we were wondering what attackers could abuse them for. Sure, they can probably do things like finding out what the person is currently listening to. But what else? During our research we discovered three vulnerabilities (CVE-2025-20700, CVE-2025-20701, CVE-2025-20702) in popular Bluetooth audio chips developed by Airoha. These chips are used by many popular device manufacturers in numerous Bluetooth headphones and earbuds.</p>

<p>The identified vulnerabilities may allow a complete device compromise. We demonstrate the immediate impact using a pair of current-generation headphones. We also demonstrate how a compromised Bluetooth peripheral can be abused to attack paired devices, like smartphones, due to their trust relationship with the peripheral.</p>

<p>This presentation will give an overview over the vulnerabilities and a demonstration and discussion of their impact. We also generalize these findings and discuss the impact of compromised Bluetooth peripherals in general. At the end, we briefly discuss the difficulties in the disclosure and patching process. Along with the talk, we will release tooling for users to check whether their devices are affected and for other researchers to continue looking into Airoha-based devices.</p>

<p>Examples of affected vendors and devices are Sony (e.g., WH1000-XM5, WH1000-XM6, WF-1000XM5), Marshall (e.g. Major V, Minor IV), Beyerdynamic (e.g. AMIRON 300), or Jabra (e.g. Elite 8 Active).</p>

<p>Airoha is a vendor that, amongst other things, builds Bluetooth SoCs and offers reference designs and implementations incorporating these chips. They have become a large supplier in the Bluetooth audio space, especially in the area of True Wireless Stereo (TWS) earbuds. Several reputable headphone and earbud vendors have built products based on Airoha’s SoCs and reference implementations using Airoha’s Software Development Kit (SDK).</p>

<p>During our Bluetooth Auracast research we stumbled upon a pair of these headphones. During the process of obtaining the firmware for further research we initially discovered the powerful custom Bluetooth protocol called *RACE*. The protocol provides functionality to take full control of headphones. Data can be written to and read from the device's flash and RAM.</p>

<p>The goal of this presentation is twofold. Firstly, we want to inform about the vulnerabilities. It is important that headphone users are aware of the issues. In our opinion, some of the device manufacturers have done a bad job of informing their users about the potential threats and the available security updates. We also want to provide the technical details to understand the issues and enable other researchers to continue working with the platform. With the protocol it is possible to read and write firmware. This opens up the possibility to patch and potentially customize the firmware.</p>

<p>Secondly, we want to discuss the general implications of compromising Bluetooth peripherals. As smart phones are becoming increasingly secure, the focus for attackers might shift to other devices in the environment of the smart phone. For example, when the Bluetooth Link Key, that authenticates a Bluetooth connection between the smart phone and the peripheral is stolen, an attacker might be able to impersonate the peripheral and gain its capabilities.</p>

<p>Licensed to the public under http://creativecommons.org/licenses/by/4.0</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I rebooted my social life (370 pts)]]></title>
            <link>https://takes.jamesomalley.co.uk/p/this-might-be-oversharing</link>
            <guid>46453114</guid>
            <pubDate>Thu, 01 Jan 2026 11:01:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing">https://takes.jamesomalley.co.uk/p/this-might-be-oversharing</a>, See on <a href="https://news.ycombinator.com/item?id=46453114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2cbR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2cbR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 424w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 848w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 1272w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2cbR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:190454,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://takes.jamesomalley.co.uk/i/182475233?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2cbR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 424w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 848w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 1272w, https://substackcdn.com/image/fetch/$s_!2cbR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F843e4d28-1b2e-4861-9fa9-c86cd50e908c_1536x1024.heic 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>A few years ago, I was going a little mad.</p><p><span>Materially, my life was comfortable. My partner and I had just </span><a href="https://takes.jamesomalley.co.uk/p/yimby" rel="">bought a house</a><span>. I was doing okay in a freelance writing career. And we were living the sort of middle class-ish lifestyle where we could afford multiple foreign holidays a year.</span></p><p>But there was something I found disturbing. I didn’t have any reason to ever leave the house.</p><p><span>That’s not much of an exaggeration. Through a combination of luck and circumstance, I’d landed in a work-from-home career where almost everything happened over email or Zoom. Amazon could drop anything I wanted at my door within 24 hours. Deliveroo and Ocado took care of food. And because my partner and I don’t have—</span><a href="https://takes.jamesomalley.co.uk/p/the-birth-rate-weirdos-have-a-point?utm_source=publication-search" rel="">nor want</a><span>—kids, we didn’t have that automatic tether to our local area either.</span></p><p>So far, this may not sound so difficult. Lucky me, right? But what made living like this difficult was that my social life had also ground to a halt.</p><p>Sure, I had friends and perhaps even hundreds of looser connections, by virtue of being a middle-ranking character on British Politics Twitter, but I only rarely saw people in person. Our closest friends did not live locally, nor was there any mechanism that would regularly bring us together.</p><p><span>How did this happen? I think the cause of this social collapse was down to a few different factors. The first was obviously the pandemic, which made us all too comfortable with staying indoors. The second is a function of getting older – a significant proportion of the people you used to hang out with have kids and disappear off the face of the Earth for two decades. And the third was, frankly, my comfortable circumstances.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-1-182475233" target="_self" rel="">1</a></span></p><p><span>Simply put, </span><em>I really like being in my house</em><span>. It’s extremely pleasant to live in. The person who I like spending time with more than anyone else lives here with me, and our cats are here too. I have a massive TV, a Playstation 5 and a gigabit internet connection.</span></p><p>But clearly you can have too much of a good thing, as it has the effect of making staying in more desirable, and makes the prospect of heading outside seem less appealing.</p><p><span>Perhaps, though, you can’t really see the problem? You might even be reading what I’ve written so far with envy. After all, I’ve lucked my way into an extremely pleasant life of no dependents and few commitments,</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-2-182475233" target="_self" rel="">2</a></span><span> so what could possibly be wrong? Objectively, this was an </span><em>incredibly </em><span>unsympathetic situation to complain about.</span></p><p>However, the problem is that I had basically managed to over-optimise my life, and as a result it was actually quite a mentally tough way to live. It turns out that when you don’t have them, you start to miss connections with other humans.</p><p>And this was when I finally realised something that should have been obvious. I had a small group of close friends who were spread across the country. I had a wider group of friends and acquaintances who I’d talk to online.</p><p>But what I lacked was a community.</p><p>Ironically, I’d always been pretty dismissive of the importance of community.</p><p>On a zoomed-out level, this was because I saw myself on the cosmopolitan side of the great cosmopolitan/communitarian divide. In principle, I’ve always liked the idea of a big, anonymous, atomised city where individuals are free to determine their own destiny.</p><p><span>Ideologically, I think strong, individual rights are important tools of liberation, and I’m suspicious of how strong communities shackle people within what the authors of </span><em>The Narrow Corridor</em><span> refer to as a ‘cage of norms’.</span></p><p><span>For example, the reason small towns can feel so oppressive is because they are surveillance panopticons. Everyone knows each other, so the range of acceptable behaviour is inevitably mediated by social pressure. If you break the invisible rules of the group, you risk </span><a href="https://takes.jamesomalley.co.uk/p/we-should-be-more-honest-about-the?utm_source=publication-search" rel="">losing status</a><span>, being shunned by everyone in your life – or potentially even worse.</span></p><p><span>Historically, that’s why small communities are more conservative, and why people move to the city to free themselves from the expectations they were born into.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-3-182475233" target="_self" rel="">3</a></span></p><p>But this is not just a geography thing. These same dynamics also apply to other types of communities too. Strong communities, whether geographic, religious, professional or simply driven by shared interests warp our incentives, and create norms and taboos about what can and cannot be said or done, if you want to maintain standing with the in-group.</p><p><span>I think I’m particularly suspicious of community, because as a writer and pedantic arsehole on the internet, I value truth-seeking behaviour. I want people to think and say things that are true, not just things that they </span><em>have</em><span> to believe for the sake of keeping their community happy.</span></p><p>And to be fair to me, there are plenty of examples of communities where this happens – many of which I have written about before.</p><p><span>For example, back in 2020 if your in-group were all lefties, it would have required an act of tremendous bravery to question </span><a href="https://takes.jamesomalley.co.uk/p/woke-is-a-new-ideology-and-its-proponents?utm_source=publication-search" rel="">the norms that arose around ‘wokeness’</a><span>.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-4-182475233" target="_self" rel="">4</a></span><span> And more recently, in ‘neurodivergent’ communities, it can be difficult to raise </span><a href="https://takes.jamesomalley.co.uk/p/melding-identity-and-disorders?utm_source=publication-search" rel="">legitimate questions</a><span> about over-diagnosis, without risking the wrath of friends and peers.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-5-182475233" target="_self" rel="">5</a></span></p><p>And I personally have experienced these same community dynamics myself, albeit on a much less severe scale.</p><p><span>I won’t bore on as I’ve talked about this before, but I spent my early-mid 20s as an enthusiastic member of the ‘skeptics’ community which, ironically, was premised on the rejection of dogma and the celebration of changing your mind. Yet, inevitably, over time even this community developed its own norms about what ideas and questions </span><a href="https://takes.jamesomalley.co.uk/p/you-cant-cancel-the-gender-wars-when?utm_source=publication-search" rel="">were and were not acceptable</a><span> to remain in good standing, and it has fallen apart as a cohesive community because of disagreements over those norms in the intervening years.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-6-182475233" target="_self" rel="">6</a></span></p><p>So this is all to say that my default setting here was deep suspicion of community dynamics, and a strong desire to be an independent thinker. I wanted to believe that I was deriving my opinions and outlook on the world through the exercise of pure reason and careful thought. I didn’t want to pollute my analysis with concerns about what other people would think.</p><p>But when I reached the point of total social collapse, it turns out that, actually, I did.</p><p><span>This is all an extremely pretentious way to say that, despite my carping above, what this whole thing made clear to me was that there is clearly social and psychological value in community.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-7-182475233" target="_self" rel="">7</a></span><span> Even if it does make truth-seeking more complicated.</span></p><p>So what good is there in being a part of a community? It seems almost too obvious to say. I could talk about how there are practical advantages in terms of mutual support. I could point to how communities are engines of trust, which we need for society to function. Or I could recognise how community bestows a sense of belonging or identity as we float through an empty, meaningless, godless, universe.</p><p>But this would hardly be revelatory.</p><p>So what I will say is that personally, something I miss the most about being a part of a community is how it creates a ready-made group of friends, even in a city as large as London.</p><p><span>Back in those ‘skeptic’ years, I could go to certain ‘skeptic’-branded events – pub meet-ups, public lectures</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-8-182475233" target="_self" rel="">8</a></span><span> and so on – and without detailed planning or coordination, I’d inevitably bump into familiar faces. And crucially, they all knew each other too – it was a shortcut to like-minded people to hang out with.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-9-182475233" target="_self" rel="">9</a></span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-10-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-10-182475233" target="_self" rel="">10</a></span></p><p>So when the community fell apart, and I fell out of it, it was like losing access to an entire constellation of friends.</p><p>This brings me back to my dilemma. I had identified that the problem was that I wasn’t part of any community. So how could I find a new one?</p><p>It was 2023, a few months before my 36th birthday, and I had an idea. I should organise some birthday drinks for myself – something I hadn’t done for years.</p><p><span>Now, obviously, this doesn’t sound like a big deal, but I was genuinely nervous. My mental health wasn’t in a </span><em>spectacular</em><span> place, so when I did this I wasn’t sure if anyone would actually turn up.</span></p><p>So I psyched myself up, and started sending out invitations to both friends I hadn’t seen in a while and looser connections. I didn’t have a well-defined strategy for who to invite – I sent the details to friends and acquaintances who appeared in my notifications, or to mutuals who appeared on my timeline. But anyway, to my relief, on the night itself, a whole bunch of people actually turned up.</p><p>There were friends who I’d known for years, and others I was meeting in person for the first time. And as far as I could tell, everyone had a pretty great time.</p><p><span>Psychologically, this was obviously an enormous boost. It turned out making the effort to invite people to stuff pays off. And this is when the answer to my larger problem hit me. If I wanted a community, then I could </span><em>build it myself</em><span>.</span></p><p>I mean, in principle, it shouldn’t be too hard to do. Community has been the foundation of all of human society since the dawn of our species, so the playbook for how to build one had already been figured out.</p><p><span>I think it boils down to a few key ingredients: a community needs a common connection or interest. It needs a place for people to interact informally. And it needs a mechanism for new people to join, to prevent it from decaying over time.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-11-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-11-182475233" target="_self" rel="">11</a></span></p><p><span>So the first thing I did was not wait until my next birthday to organise some more drinks. In fact, soon after that first event, I began planning not just my next event, but my next </span><em>events,</em><span> plural.</span></p><p>My premise was simple. I was going to attempt to fill a room with what I described as “the most interesting people I know”. And I was going to do it every month.</p><p>I’d pick a date and announce some drinks. I’d then send out an invite to a mailing list I’d curate of several dozen friends and acquaintances. And I’d follow the same scattershot strategy of inviting people to join both the next event and the mailing list. Then when the day arrived each month, I’d hang out with whoever turns up.</p><p>My thinking was that this solves two of the core challenges when forming a community. It solved the coordination problem – instead of ad-hoc hangouts that would need to be specifically arranged and have a nominal purpose – like a work meeting – I was saying “I will be here, come and hang out if you’re free”.</p><p>And it also solved the decay problem. To put this in the most mercenary and bloodless terms possible, by continuing to expand the mailing list, I have created what digital marketing bores would call an engagement funnel. Now when I make a new friend, I have something recurring I can invite them to so that we can see each other regularly. And if they turn up, it’s an effective and fun way to maintain our connection, rather than have us drift apart.</p><p>It’s now over two years on from… whatever this moment was. And it has worked out even better than I could have hoped. Almost every month now, I have an excuse to see my friends, and renew the connections I have with a much wider network of people. Some months are bigger than others in terms of attendance, but every single time I’ve headed home feeling like I am connected to my fellow humans, and psychologically renewed.</p><p><span>It has had spillover benefits too – my social calendar is now much busier, as staying connected with people, in person, has enriched my social connections more broadly.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-12-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-12-182475233" target="_self" rel="">12</a></span></p><p>I no longer feel like I am going mad, even if there is a risk that my description of how to maintain friendships above might read as psychopathic. I once again have a community of people around me.</p><p>And I don’t think I’m the only person who appreciates this. Other regulars at my drinks events seem to enjoy the excuse to get together, maintain existing connections and make new friends too.</p><p><span>Which I guess brings me to, basically, why I decided to write about this, beyond the fact that I thought you might like something a bit more reflective in the awkward Christmas-New Year gap.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-13-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-13-182475233" target="_self" rel="">13</a></span></p><p>I wrote about this because I suspect I’m not the only person who has experienced a collapse in social connections. The structural problems I identify above – the pandemic, working from home and comfortable circumstances – aren’t exactly unique to me. I bet that lots of people feel like they are going mad for similar reasons too.</p><p>So at risk of sounding like a grifting internet ‘guru’ type, if you’re where I was a few years ago, my life advice to you is this: Just invite people to stuff! It works!</p><p>If you’re looking for an excuse to organise that event, start that thing or create that WhatsApp group, this is the sign you have been waiting for to do it!</p><p>Hanging out with other humans is good – and if you can’t find a community… you can always build your own.</p><p><em>Talking of joining communities, if you enjoyed reading this you should subscribe to my newsletter (for free!) to get more of my writing direct to your inbox. I even organise real-life public events for subscribers occasionally!</em><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-14-182475233" href="https://takes.jamesomalley.co.uk/p/this-might-be-oversharing#footnote-14-182475233" target="_self" rel="">14</a></span></p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust--: Rust without the borrow checker (123 pts)]]></title>
            <link>https://github.com/buyukakyuz/rustmm</link>
            <guid>46453062</guid>
            <pubDate>Thu, 01 Jan 2026 10:53:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/buyukakyuz/rustmm">https://github.com/buyukakyuz/rustmm</a>, See on <a href="https://news.ycombinator.com/item?id=46453062">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Rust--: Rust without the borrow checker</h2><a id="user-content-rust---rust-without-the-borrow-checker" aria-label="Permalink: Rust--: Rust without the borrow checker" href="#rust---rust-without-the-borrow-checker"></a></p>
<p dir="auto">A modified Rust compiler with the borrow checker disabled. This allows code that would normally violate Rust's borrowing rules to compile and run successfully.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Pre-built binaries for macOS (Apple Silicon) and Linux (x86_64):</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sSL https://raw.githubusercontent.com/buyukakyuz/rustmm/main/install.sh | bash"><pre>curl -sSL https://raw.githubusercontent.com/buyukakyuz/rustmm/main/install.sh <span>|</span> bash</pre></div>
<p dir="auto">Use:</p>
<div dir="auto" data-snippet-clipboard-copy-content="~/.rustmm/bin/rustc your_code.rs"><pre><span>~</span>/.rustmm/bin/rustc your_code.rs</pre></div>
<p dir="auto">To build from source, see <a href="https://github.com/buyukakyuz/rustmm/blob/main/BUILDING.md">BUILDING.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples: Before vs After</h2><a id="user-content-examples-before-vs-after" aria-label="Permalink: Examples: Before vs After" href="#examples-before-vs-after"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 1: Move Then Use</h3><a id="user-content-example-1-move-then-use" aria-label="Permalink: Example 1: Move Then Use" href="#example-1-move-then-use"></a></p>
<p dir="auto">Normal Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let a = String::from(&quot;hello&quot;);
    let b = a;
    println!(&quot;{a}&quot;);
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> a = <span>String</span><span>::</span><span>from</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>
    <span>let</span> b = a<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{a}"</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Error in normal Rust:</p>
<div data-snippet-clipboard-copy-content="error[E0382]: borrow of moved value: `a`
 --> test.rs:4:16
  |
2 |     let a = String::from(&quot;hello&quot;);
  |         - move occurs because `a` has type `String`, which does not implement the `Copy` trait
3 |     let b = a;
  |             - value moved here
4 |     println!(&quot;{a}&quot;);
  |                ^ value borrowed here after move"><pre><code>error[E0382]: borrow of moved value: `a`
 --&gt; test.rs:4:16
  |
2 |     let a = String::from("hello");
  |         - move occurs because `a` has type `String`, which does not implement the `Copy` trait
3 |     let b = a;
  |             - value moved here
4 |     println!("{a}");
  |                ^ value borrowed here after move
</code></pre></div>
<p dir="auto">Rust--:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let a = String::from(&quot;hello&quot;);
    let b = a;
    println!(&quot;{a}&quot;);  // Works! Prints: hello
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> a = <span>String</span><span>::</span><span>from</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>
    <span>let</span> b = a<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{a}"</span><span>)</span><span>;</span>  <span>// Works! Prints: hello</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 2: Multiple Mutable References</h3><a id="user-content-example-2-multiple-mutable-references" aria-label="Permalink: Example 2: Multiple Mutable References" href="#example-2-multiple-mutable-references"></a></p>
<p dir="auto">Normal Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut y = 5;
    let ref1 = &amp;mut y;
    let ref2 = &amp;mut y;
    *ref1 = 10;
    *ref2 = 20;
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> y = <span>5</span><span>;</span>
    <span>let</span> ref1 = <span>&amp;</span><span>mut</span> y<span>;</span>
    <span>let</span> ref2 = <span>&amp;</span><span>mut</span> y<span>;</span>
    <span>*</span>ref1 = <span>10</span><span>;</span>
    <span>*</span>ref2 = <span>20</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Error in normal Rust:</p>
<div data-snippet-clipboard-copy-content="error[E0499]: cannot borrow `y` as mutable more than once at a time
 --> test.rs:4:16
  |
3 |     let ref1 = &amp;mut y;
  |                ------ first mutable borrow occurs here
4 |     let ref2 = &amp;mut y;
  |                ^^^^^^ second mutable borrow occurs here
5 |     *ref1 = 10;
  |     ---------- first borrow later used here"><pre><code>error[E0499]: cannot borrow `y` as mutable more than once at a time
 --&gt; test.rs:4:16
  |
3 |     let ref1 = &amp;mut y;
  |                ------ first mutable borrow occurs here
4 |     let ref2 = &amp;mut y;
  |                ^^^^^^ second mutable borrow occurs here
5 |     *ref1 = 10;
  |     ---------- first borrow later used here
</code></pre></div>
<p dir="auto">Rust--:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut y = 5;
    let ref1 = &amp;mut y;
    let ref2 = &amp;mut y;  // Works!
    *ref1 = 10;
    *ref2 = 20;
    println!(&quot;{}&quot;, y);  // Prints: 20
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> y = <span>5</span><span>;</span>
    <span>let</span> ref1 = <span>&amp;</span><span>mut</span> y<span>;</span>
    <span>let</span> ref2 = <span>&amp;</span><span>mut</span> y<span>;</span>  <span>// Works!</span>
    <span>*</span>ref1 = <span>10</span><span>;</span>
    <span>*</span>ref2 = <span>20</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> y<span>)</span><span>;</span>  <span>// Prints: 20</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 3: Mutable Borrow Then Move</h3><a id="user-content-example-3-mutable-borrow-then-move" aria-label="Permalink: Example 3: Mutable Borrow Then Move" href="#example-3-mutable-borrow-then-move"></a></p>
<p dir="auto">Normal Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut x = vec![1, 2, 3];
    let borrowed = &amp;mut x;
    println!(&quot;{:?}&quot;, x);  // ERROR: cannot use `x` while mutable borrow exists
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> x = <span>vec</span><span>!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]</span><span>;</span>
    <span>let</span> borrowed = <span>&amp;</span><span>mut</span> x<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span><span>,</span> x<span>)</span><span>;</span>  <span>// ERROR: cannot use `x` while mutable borrow exists</span>
<span>}</span></pre></div>
<p dir="auto">Rust--:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut x = vec![1, 2, 3];
    let borrowed = &amp;mut x;
    println!(&quot;{:?}&quot;, x);  // Works! Prints: [1, 2, 3]
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> x = <span>vec</span><span>!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]</span><span>;</span>
    <span>let</span> borrowed = <span>&amp;</span><span>mut</span> x<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span><span>,</span> x<span>)</span><span>;</span>  <span>// Works! Prints: [1, 2, 3]</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 4: Use After Move in Loop</h3><a id="user-content-example-4-use-after-move-in-loop" aria-label="Permalink: Example 4: Use After Move in Loop" href="#example-4-use-after-move-in-loop"></a></p>
<p dir="auto">Normal Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let s = String::from(&quot;test&quot;);
    for _ in 0..2 {
        println!(&quot;{}&quot;, s);  // ERROR: cannot move out of loop
    }
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> s = <span>String</span><span>::</span><span>from</span><span>(</span><span>"test"</span><span>)</span><span>;</span>
    <span>for</span> _ <span>in</span> <span>0</span>..<span>2</span> <span>{</span>
        <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> s<span>)</span><span>;</span>  <span>// ERROR: cannot move out of loop</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">Rust--:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let s = String::from(&quot;test&quot;);
    for _ in 0..2 {
        println!(&quot;{}&quot;, s);  // Works! Prints twice
    }
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> s = <span>String</span><span>::</span><span>from</span><span>(</span><span>"test"</span><span>)</span><span>;</span>
    <span>for</span> _ <span>in</span> <span>0</span>..<span>2</span> <span>{</span>
        <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> s<span>)</span><span>;</span>  <span>// Works! Prints twice</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 5: Conflicting Borrows</h3><a id="user-content-example-5-conflicting-borrows" aria-label="Permalink: Example 5: Conflicting Borrows" href="#example-5-conflicting-borrows"></a></p>
<p dir="auto">Normal Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut num = 42;
    let mut_ref = &amp;mut num;
    let immut_ref = &amp;num;
    println!(&quot;{}&quot;, immut_ref);
    println!(&quot;{}&quot;, mut_ref);
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> num = <span>42</span><span>;</span>
    <span>let</span> mut_ref = <span>&amp;</span><span>mut</span> num<span>;</span>
    <span>let</span> immut_ref = <span>&amp;</span>num<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> immut_ref<span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> mut_ref<span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Error in normal Rust:</p>
<div data-snippet-clipboard-copy-content="error[E0502]: cannot borrow `num` as immutable because it is also borrowed as mutable
 --> test.rs:4:21
  |
3 |     let mut_ref = &amp;mut num;
  |                   -------- mutable borrow occurs here
4 |     let immut_ref = &amp;num;
  |                     ^^^^ immutable borrow occurs here
5 |     println!(&quot;{}&quot;, immut_ref);
6 |     println!(&quot;{}&quot;, mut_ref);
  |                    ------- mutable borrow later used here"><pre><code>error[E0502]: cannot borrow `num` as immutable because it is also borrowed as mutable
 --&gt; test.rs:4:21
  |
3 |     let mut_ref = &amp;mut num;
  |                   -------- mutable borrow occurs here
4 |     let immut_ref = &amp;num;
  |                     ^^^^ immutable borrow occurs here
5 |     println!("{}", immut_ref);
6 |     println!("{}", mut_ref);
  |                    ------- mutable borrow later used here
</code></pre></div>
<p dir="auto">Rust--:</p>
<div dir="auto" data-snippet-clipboard-copy-content="fn main() {
    let mut num = 42;
    let mut_ref = &amp;mut num;
    let immut_ref = &amp;num;  // Works! No error
    println!(&quot;{}&quot;, immut_ref);  // Prints: 42
    println!(&quot;{}&quot;, mut_ref);    // Prints: 0x...
}"><pre><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> num = <span>42</span><span>;</span>
    <span>let</span> mut_ref = <span>&amp;</span><span>mut</span> num<span>;</span>
    <span>let</span> immut_ref = <span>&amp;</span>num<span>;</span>  <span>// Works! No error</span>
    <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> immut_ref<span>)</span><span>;</span>  <span>// Prints: 42</span>
    <span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span> mut_ref<span>)</span><span>;</span>    <span>// Prints: 0x...</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">The <code>examples/</code> directory contains code that would fail in standard Rust:</p>
<ul dir="auto">
<li><code>01_move_then_use.rs</code> - E0382: Borrow of moved value</li>
<li><code>02_multiple_mutable_borrows.rs</code> - E0499: Multiple mutable borrows</li>
<li><code>03_mutable_borrow_then_move.rs</code> - E0502: Use while mutably borrowed</li>
<li><code>04_use_after_move_loop.rs</code> - Use after move in loop</li>
<li><code>05_self_referential.rs</code> - E0597: Self-referential struct</li>
<li><code>06_conflicting_borrows.rs</code> - E0502: Conflicting borrows</li>
<li><code>07_doubly_linked.rs</code> - E0506: Doubly linked list</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="~/.rustmm/bin/rustc examples/01_move_then_use.rs &amp;&amp; ./01_move_then_use"><pre><span>~</span>/.rustmm/bin/rustc examples/01_move_then_use.rs <span>&amp;&amp;</span> ./01_move_then_use</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Same as Rust - dual licensed under Apache 2.0 and MIT</p>
<p dir="auto">See LICENSE-APACHE, LICENSE-MIT, and COPYRIGHT for details.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>