<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 16 May 2024 16:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What's New in Neovim 0.10 (168 pts)]]></title>
            <link>https://gpanders.com/blog/whats-new-in-neovim-0.10/</link>
            <guid>40378218</guid>
            <pubDate>Thu, 16 May 2024 13:30:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gpanders.com/blog/whats-new-in-neovim-0.10/">https://gpanders.com/blog/whats-new-in-neovim-0.10/</a>, See on <a href="https://news.ycombinator.com/item?id=40378218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Neovim 0.10 was the longest release cycle since the heady days of the 0.5
release. There are a ton of new features in this release (as well as some
breaking changes), so be sure to check the full <a href="https://neovim.io/doc/user/news-0.10.html">release notes</a>. You can
view the release notes directly in Nvim with <code>:h news</code>. The news file includes
information on new features, deprecations, and breaking changes. I especially
urge plugin authors to read this file carefully.</p>
<p>Like <a href="https://gpanders.com/blog/whats-new-in-neovim-0-7/">last time</a>, in this post I’ll cover a subset of the new features.
As I said, it’s a big release, and I won’t write about everything, but these
are some of the highlights.</p>
<h2 id="table-of-contents">
  <a href="#table-of-contents">Table of Contents</a>
</h2>
<ul>
<li><a href="#defaults">Defaults</a></li>
<li><a href="#builtin-commenting">Builtin commenting</a></li>
<li><a href="#terminal-ui-enhancements">Terminal UI enhancements</a></li>
<li><a href="#lsp-inlay-hints">LSP inlay hints</a></li>
<li><a href="#tree-sitter-query-editor">Tree-sitter query editor</a></li>
<li><a href="#miscellaneous">Miscellaneous</a></li>
<li><a href="#roadmap">Roadmap</a></li>
</ul>
<h2 id="defaults">
  <a href="#defaults">Defaults</a>
</h2>
<h3 id="colorscheme">
  <a href="#colorscheme">Colorscheme</a>
</h3>
<p>Nvim has been in need of a new default colorscheme for a long time. While the
default colors have some charm and nostalgia, there are serious accessibility
and aesthetic issues, particular when using Nvim is a diff viewer. The
screenshot below shows the default colorscheme before Nvim 0.10:</p>
<figure><img src="https://gpanders.com/img/nvim-colorscheme-old.png" alt="Neovim's default colorscheme before 0.10">
</figure>

<p>Nvim 0.10 now ships with a new default colorscheme, which you can see below:</p>
<figure><img src="https://gpanders.com/img/nvim-colorscheme-new.png" alt="Neovim's new default colorscheme">
</figure>

<p>The new default colorscheme was heroically contributed by <a href="https://github.com/echasnovski">Evgeni
Chasnovski</a>, who endured seemingly endless bikeshedding and
successfully navigated the treacherous waters of such a subjective change.
There were many constraints imposed on the design of the colorscheme, which
you can read in the <a href="https://github.com/neovim/neovim/pull/26334">PR</a> (and the many follow up PRs and issues linked
therein). It is quite literally impossible to please <em>everyone</em> with a single
colorscheme, and there is no expectation that we have achieved that, but the
new colorscheme does, hopefully, improve the default experience for many
people.</p>
<h3 id="lsp-and-diagnostics-mappings">
  <a href="#lsp-and-diagnostics-mappings">LSP and Diagnostics Mappings</a>
</h3>
<p>Nvim 0.10 adds a new <a href="https://github.com/neovim/neovim/pull/24331">default mapping</a>: <code>K</code> in Normal mode maps to
<code>vim.lsp.buf.hover()</code> whenever a buffer attaches to an LSP client, unless
<code>'keywordprg'</code> is already set to a non-default value. Use this to view
information about the function or variable under the cursor. This in addition
to the existing defaults mentioned in <code>:h lsp-defaults</code> which were added in
the previous release.</p>
<p>In addition, there are new <a href="https://github.com/neovim/neovim/pull/16230">default mappings</a> for navigating
diagnostics:</p>
<ul>
<li><code>[d</code> and <code>]d</code> in Normal mode map to <code>vim.diagnostic.goto_prev()</code> and
<code>vim.diagnostic.goto_next()</code>, respectively. Use these to navigate between
diagnostics in the current buffer.</li>
<li><code>&lt;C-W&gt;d</code> (and <code>&lt;C-W&gt;&lt;C-D&gt;</code>) in Normal mode map to
<code>vim.diagnostic.open_float()</code>. Use this to view information about any
diagnostics under the cursor in a floating window.</li>
</ul>
<p>The diagnostics mappings override builtin mappings. These builtin mappings are
not often used, but if you <em>do</em> use them you can delete the new default
mappings with <code>vim.keymap.del()</code> or <code>:unmap</code>.</p>
<p>The intention behind providing more default mappings is to make it easier to
get started with LSP in Neovim. The hope is that most users should be able to
get up and running with useful LSP features with little to no configuration
and without needing to write a bunch of Lua code. We have plans to add more
defaults in future releases, though as you might imagine this is a fraught
exercise. It is quite difficult to change default behavior in a tool as
extensible and customizable as Nvim without breaking users'
<a href="https://xkcd.com/1172/">workflows</a>.</p>
<p>Two features which many users rely on for their LSP experience are snippets
support and autocompletion. Both of these features are on the roadmap to be
included in Nvim core (see <a href="https://github.com/neovim/neovim/pull/27339">#27339</a>, <a href="https://github.com/neovim/neovim/issues/25696">#25696</a>, and <a href="https://github.com/neovim/neovim/issues/25670">#25670</a>) which
will, hopefully, make the experience of using LSP in Neovim even smoother in
the future.</p>

<p>Longtime Vim users are likely familiar with the venerable <a href="https://github.com/tpope/vim-commentary">vim-commentary</a>
plugin, which creates mappings and operators for commenting and uncommenting
text. Thanks to <a href="https://github.com/echasnovski">Evgeni Chasnovski</a>, Nvim 0.10 now <a href="https://github.com/neovim/neovim/pull/28176">bundles this
functionality</a> by default, using a from-scratch implementation in
Lua. Unlike vim-commentary, Nvim’s builtin implementation provides a text
object and supports Tree-sitter, which is useful when working in injected
languages (example: if you comment text inside a <code>&lt;script&gt;</code> tag in an HTML
buffer, it will correctly use the Javascript <code>//</code> comment string rather than
HTML’s <code>&lt;!-- --&gt;</code> comment string).</p>
<p>See <code>:h commenting</code> for more details.</p>
<h2 id="terminal-ui-enhancements">
  <a href="#terminal-ui-enhancements">Terminal UI enhancements</a>
</h2>
<p>Nvim 0.10 adds support for many new terminal based capabilities.</p>
<h3 id="synchronized-output">
  <a href="#synchronized-output">Synchronized Output</a>
</h3>
<p>Many modern terminal emulators support <a href="https://gist.github.com/christianparpart/d8a62cc1ab659194337d73e399004036">synchronized output</a> which allows
terminal applications (like Nvim) to “batch” all of their UI updates in the
terminal emulator and display them all at once. This can reduce “flickering”
and “tearing” when a terminal UI (TUI) is being drawn very rapidly. This can
sometimes happen in Nvim when using plugins that perform rapid UI updates
(e.g. spinners, LSP status windows, etc.). Nvim 0.10 introduces a new
<code>'termsync'</code> option (enabled by default) which enables this feature if it is
supported by the terminal emulator.</p>
<h3 id="system-clipboard-synchronization">
  <a href="#system-clipboard-synchronization">System clipboard synchronization</a>
</h3>
<p>Nvim 0.10 can now use the OSC 52 escape sequence to write to (or read from)
the system clipboard. OSC 52 is only used automatically when (1) it is able to
determine that the terminal emulator supports it (via XTGETTCAP), (2) it is
running in an SSH session, and (3) when the <code>'clipboard'</code> option is unset.
Note that some terminal emulators do not support reading from the system
clipboard with OSC 52, or only allow it after prompting the user for
confirmation. It is recommended to use the traditional “paste” key binding
(e.g. <code>Cmd+V</code> on macOS or <code>Ctrl+Shift+V</code> on Linux) to paste into Nvim from the
system clipboard and use <code>"+</code> to copy to the clipboard inside Nvim (see <code>:h quoteplus</code>).</p>
<h3 id="hyperlinks">
  <a href="#hyperlinks">Hyperlinks</a>
</h3>
<p>Nvim 0.10 introduces experimental support for hyperlinks using the OSC 8
sequence. By default, this is used in Markdown for links of the form
<code>[example](https://example.com)</code>. If your terminal emulator supports the OSC 8
escape sequence, then the text <code>example</code> in the Nvim buffer will contain a
hyperlink that can be clicked and will open <code>https://example.com</code> in your web
browser.</p>
<p>This means that users can view Markdown files with <code>:set conceallevel=2</code> and
get an experience much closer to the rendered output:</p>
<figure><img src="https://gpanders.com/img/nvim-readme.png" alt="Screenshot of the Neovim README opened in Nvim">
</figure>

<p>In the screenshot above, the underlined words are clickable link text, just as
you would find in a web browser.</p>
<h3 id="automatic-truecolor-detection">
  <a href="#automatic-truecolor-detection">Automatic truecolor detection</a>
</h3>
<p>Nvim 0.10 will now automatically determine if the terminal emulator supports
24 bit color (“truecolor”) and enable the <code>'termguicolors'</code> option if it does.
It does this through a combination of heuristics (<code>$COLORTERM</code>, terminfo) and
terminal queries (DECRQSS, XTGETTCAP). This detection works even over SSH
connections and when inside a terminal multiplexer such as <code>tmux</code>.</p>
<h2 id="lsp-inlay-hints">
  <a href="#lsp-inlay-hints">LSP inlay hints</a>
</h2>
<p>Nvim 0.10 now supports <a href="https://github.com/neovim/neovim/pull/23984">LSP inlay hints</a> thanks to <a href="https://github.com/p00f">Chinmay
Dalal</a>. A picture here will do more than my words can:</p>
<figure><img src="https://gpanders.com/img/nvim-inlay-hints.png" alt="Screenshot of Nvim showing inlay hints">
</figure>

<p>The dark colored texts which display type annotations for variable declarations
are inlay hints. This text is not part of the actual source file in the
buffer, but is “virtual” text inserted by Nvim and provided by the language
server. These hints can be enabled or disabled dynamically using
<code>vim.lsp.inlay_hint.enable()</code>.</p>
<p>Many other new LSP features were added in Nvim 0.10 as well. Refer to the
“LSP” section in <code>:h news</code> for a full list.</p>
<h2 id="tree-sitter-query-editor">
  <a href="#tree-sitter-query-editor">Tree-sitter query editor</a>
</h2>
<p>Nvim 0.10 adds even more tools for working with Tree-sitter queries. If you
didn’t know already, Nvim bundles an “inspector” which allows you to view the
abstract syntax tree of any source file with the <code>:InspectTree</code> command (so
long as a Tree-sitter parser for the file’s language is installed). Example:</p>
<figure><img src="https://gpanders.com/img/nvim-inspect-tree.png" alt="Screenshot of the :InspectTree command in Nvim">
</figure>

<p>Thanks to <a href="https://github.com/MariaSolOs">Maria José Solano</a>, Nvim 0.10 adds a powerful
capability to the Tree-sitter inspector: <a href="https://github.com/neovim/neovim/pull/24703">a query editor</a>. The query
editor allows you to write queries and see the matches in a source buffer in
real time. Being able to create and modify queries interactively makes writing
new queries a breeze. Example:</p>
<figure><img src="https://gpanders.com/img/nvim-query-editor.png" alt="Screenshot of the :EditQuery command in Nvim">
</figure>

<p>In the screenshot above, the query editor is open in the top-right window, the
tree inspector is in the bottom-right window, and the source buffer is in the
left window. Notice that the text that is matched by the query in the query
editor is highlighted in the source buffer and that the text <strong>initializer</strong>
(the capture group used in the query) is floating on the line next to the
match. As the query is updated in the editor, the corresponding highlights in
the source buffer change in real time.</p>
<p>The query editor can be opened by pressing <code>o</code> in the <code>:InspectTree</code> window,
with the <code>:EditQuery</code> command, or by calling <code>vim.treesitter.query.edit()</code>
directly.</p>
<p>With <code>:InspectTree</code> and <code>:EditQuery</code>, Neovim is one of the best tools (if not
<em>the</em> best tool) for working with Tree-sitter, even if you don’t actually use
Neovim.</p>
<h2 id="miscellaneous">
  <a href="#miscellaneous">Miscellaneous</a>
</h2>
<p>As I mentioned at the top of this post, there are <em>a lot</em> of new features in
this release, and I am not going to cover all of them. Here I’ll list a few
more that I personally think are worth mentioning:</p>
<ul>
<li>
<p>The <code>:terminal</code> command now accepts modifiers, so you can use e.g. <code>:botright terminal</code> (or <code>:bo te</code>) to open a new terminal window in a split at the
bottom of your screen. In addition, <code>:terminal</code> buffers that are started
with no arguments (and thus open a shell) will close automatically when the
shell exits without an error.</p>
</li>
<li>
<p><code>gx</code> in Normal mode calls <code>vim.ui.open()</code> on whatever is under the cursor,
which shells out to your operating system’s “open” capability (e.g. <code>open</code>
on macOS or <code>xdg-open</code> on Linux). For instance, pressing <code>gx</code> on a URL will
open that URL in your browser.</p>
</li>
<li>
<p>Tree-sitter based syntax highlighting is enabled by default for Lua, Vimdoc
(<code>:help</code>), and Tree-sitter queries (to revert to traditional regex
based syntax highlighting, create a <code>FileType</code> autocommand or <code>ftplugin</code>
with <code>vim.treesitter.stop()</code> for the respective filetype).</p>
</li>
<li>
<p><code>Q</code> and <code>@</code> in Visual mode will execute the last recorded/executed macro for
all visually selected lines.</p>
</li>
<li>
<p>Users using a terminal emulator that supports the Kitty keyboard protocol
can create mappings using the “super” and “meta” modifiers with the <code>&lt;D-</code>
and <code>&lt;T-</code> prefixes, respectively (e.g. <code>&lt;D-S&gt;</code> is <code>Cmd+S</code> on macOS).</p>
</li>
</ul>
<h2 id="roadmap">
  <a href="#roadmap">Roadmap</a>
</h2>
<p>The Neovim project is loosely organized and structured. We follow a “fun
driven development” paradigm: for the most part, contributors and maintainers
work on things that are personally interesting to them. Because of this, it
can be difficult to predict what will happen in future releases. If there is a
feature you want to see implemented, the best way to do it is to take a crack
at it yourself: many of the features mentioned in this very blog post were
contributed by users that are not part of the “core” maintenance team!</p>
<p>There is active chatter about further improving the LSP and Tree-sitter
experience (as mentioned above, builtin snippet and completion support are a
work-in-progress). One of the biggest challenges with Tree-sitter is parser
distribution: currently, parsers are shared object files which must be
compiled on every user’s machine or distributed with a system package manager.
We are already working on implementing the new <a href="https://github.com/neovim/neovim/pull/28415">Tree-sitter WASM
capabilities</a> which will enable distributing Tree-sitter parsers as
portable WASM blobs. This solves the distribution problem and may enable
Neovim to ship more Tree-sitter parsers out of the box.</p>
<p>We would also like to integrate some of the functionality from
<a href="https://github.com/neovim/nvim-lspconfig">nvim-lspconfig</a> so that, ideally, nvim-lspconfig is just a “bag of configs”
without any smarts or core logic. How best to do this is still hotly debated,
but it is something that is being discussed.</p>
<h2 id="getting-involved">
  <a href="#getting-involved">Getting Involved</a>
</h2>
<p>There is nothing quite as fun as hacking on your own tools. If you are a
Neovim user, I encourage you to get involved, whether that is through
contributing directly to the Neovim project or a plugin, or simply
participating in community spaces such as the <a href="https://matrix.to/#/#neovim:matrix.org">Neovim Matrix room</a>. If you
have pain points or frustrations when using Neovim, please let us know. Many
of us on the core maintenance team have been using Vim/Nvim for so long that
we’ve forgotten what it’s like to be a beginner and, speaking for myself at
least, this can leave blind spots on how things can be improved.</p>
<p>Thanks for reading and for using Neovim! Hopefully the next update will come a
little sooner.</p>
<h2 id="one-last-thing">
  <a href="#one-last-thing">One Last Thing</a>
</h2>
<p>The Neovim project now has a merch <a href="https://store.neovim.io/">store</a>! If you
didn’t know that you needed a Neovim branded hoodie or mug, now you do. All
proceeds raised from the store are used to fund project needs and sponsor
full-time development work.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Students invent quieter leaf blower (214 pts)]]></title>
            <link>https://hub.jhu.edu/2024/05/14/quieter-leaf-blower/</link>
            <guid>40377201</guid>
            <pubDate>Thu, 16 May 2024 11:47:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hub.jhu.edu/2024/05/14/quieter-leaf-blower/">https://hub.jhu.edu/2024/05/14/quieter-leaf-blower/</a>, See on <a href="https://news.ycombinator.com/item?id=40377201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

            
                  
                    
                      

                    
                    

                  
                  			<h2>Patent-pending design by Johns Hopkins undergrads could be available in stores within two years</h2>
	

                

          </div><div itemprop="articleBody">

  					
  			      <div>

  			        
	
		
		<p>
			<span>By</span>
			
		</p>

	


                              <p>
              
  			    		
	
		
		<span>Published</span></p><meta itemprop="datePublished dateCreated" content="2024-05-14">
		
		
		
						
		
														
		<p><span data-timestamp="1715694420">
	
	May 14, 2024

</span>

	


  			      </p></div>

                            
                

              
              <p>The challenge before Johns Hopkins University engineering students: Take a leaf blower, but make it quiet. Make it work as powerfully as ever, but do not allow it to emit the ear-piercing caterwaul that has gotten leaf blowers banned in some communities and cursed in many others.</p>

<p>Shocking their sponsors, their advisers, and even themselves a little, the students did it.</p>

<p>Their improved leaf blower drops the overall noise level by nearly 40% while almost entirely erasing the most obnoxious frequencies. The design is patent-pending and Stanley Black &amp; Decker expects to be selling them in two years.</p>

<div role="region" aria-label="YouTube video"><div><p><iframe src="https://www.youtube.com/embed/ISgHpUDeLBw?rel=0&amp;autohide=1&amp;modestbranding=1&amp;wmode=transparent" frameborder="0" allowfullscreen=""></iframe></p></div><p>Video <span>credit</span>: Aubrey Morse / Johns Hopkins University</p></div>

<p>"We spent many hours on this project, just going through the various versions of it, just constantly iterating and improving and so for that to finally pay off, this was really, really rewarding," said team member Michael Chacon, who like the rest of the four-member team is a senior majoring in mechanical engineering. "We are stoked and super, super proud."</p>

<p>The team started working last September. They hoped to improve an electric or battery-powered leaf blower, which is already much quieter than the notorious gas-powered ones, where the sound can carry over an average suburban block.</p>

<p>They spent months figuring out the leaf blower piece by piece, analyzing all of its the noises and why it made them. They then spent many more months spit-balling possible improvements, refining some ideas, killing even more.</p>

<div data-id="43038"><p><img src="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHU2348.jpg" alt="A student in a Hopkins sweatshirt demonstrates the quieter leaf blower" srcset="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_medium/public/2024-05/leaf-blower051324_JHU2348.jpg 420w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_630/public/2024-05/leaf-blower051324_JHU2348.jpg 630w, https://api.hub.jhu.edu/factory/sites/default/files/styles/full_width/public/2024-05/leaf-blower051324_JHU2348.jpg 825w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1030/public/2024-05/leaf-blower051324_JHU2348.jpg 1030w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_large/public/2024-05/leaf-blower051324_JHU2348.jpg 1194w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1300/public/2024-05/leaf-blower051324_JHU2348.jpg 1300w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHU2348.jpg 1440w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1600/public/2024-05/leaf-blower051324_JHU2348.jpg 1600w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1800/public/2024-05/leaf-blower051324_JHU2348.jpg 1800w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2000/public/2024-05/leaf-blower051324_JHU2348.jpg 2000w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2400/public/2024-05/leaf-blower051324_JHU2348.jpg 2400w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2880/public/2024-05/leaf-blower051324_JHU2348.jpg 2880w" sizes="(min-width: 1680px) 1194px, (min-width: 1280px) 948px, (min-width: 1024px) 843px, (min-width: 863px) 675px, (min-width: 768px) 716px, (min-width: 640px) 637px, (min-width: 412px) 531px, (min-width: 375px) 412px, 375px"></p><p>Image <span>credit</span>: Will Kirk / Johns Hopkins University</p></div>

<p>"The sound that comes out of this leaf blower is very complicated and it contains a lot of different frequencies," said team member Andrew Palacio. "A lot of different notes on a piano would be a good analogy."</p>

<p>They workshopped more than 40 versions of the solution they finally settled on: an attachment that cuts the machine's noise almost like a silencer on a gun or a muffler on a car.</p>

<p>"Our product takes in a full blow of air and separates it," said team member Leen Alfaoury. "Some of that air comes out as it is, and part of it comes out shifted. The combination of these two sections of the air makes the blower less noisy."</p>

<p>Adds Chacon: "It ultimately dampens the sound as it leaves, but it keeps all that force, which is the beauty of it."</p>

<p>Their design cuts the most shrill and annoying frequencies by about 12 decibels, which all but removes them, making them 94% quieter. The team reduced the overall leaf blower noise by about two decibels, making the machine sound 37% quieter.</p>

<p>So it's a quieter machine, and what people can hear will sound more pleasant.</p>

<div data-id="43036"><p><img src="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHZ6579.JPG" alt="Johns Hopkins undergrads work in the lab on their quieter leaf blower" srcset="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_medium/public/2024-05/leaf-blower051324_JHZ6579.JPG 420w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_630/public/2024-05/leaf-blower051324_JHZ6579.JPG 630w, https://api.hub.jhu.edu/factory/sites/default/files/styles/full_width/public/2024-05/leaf-blower051324_JHZ6579.JPG 825w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1030/public/2024-05/leaf-blower051324_JHZ6579.JPG 1030w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_large/public/2024-05/leaf-blower051324_JHZ6579.JPG 1194w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1300/public/2024-05/leaf-blower051324_JHZ6579.JPG 1300w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHZ6579.JPG 1440w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1600/public/2024-05/leaf-blower051324_JHZ6579.JPG 1600w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1800/public/2024-05/leaf-blower051324_JHZ6579.JPG 1800w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2000/public/2024-05/leaf-blower051324_JHZ6579.JPG 2000w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2400/public/2024-05/leaf-blower051324_JHZ6579.JPG 2400w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2880/public/2024-05/leaf-blower051324_JHZ6579.JPG 2880w" sizes="(min-width: 1680px) 1194px, (min-width: 1280px) 948px, (min-width: 1024px) 843px, (min-width: 863px) 675px, (min-width: 768px) 716px, (min-width: 640px) 637px, (min-width: 412px) 531px, (min-width: 375px) 412px, 375px"></p><p>Image <span>credit</span>: Will Kirk / Johns Hopkins University</p></div>

<p>"It's the difference between hearing a high-pitched whistle and hearing what you might think of as wind noise," said team member Madison Morrison.</p>

<p>Alfaoury thinks the best way to describe it is "muffled."</p>

<p>"It's suppressed, if that makes sense," she said. "Like the noise is deeper. It is not screechy. There's no high pitch sound that is like really annoying to hear."</p>

<p>Team adviser Stephen Belkoff puts it bluntly: "It's still a leaf blower but it's not nearly as annoying as it was before they got involved."</p>

<p>The design wowed Stanley Black &amp; Decker officials, who can't wait to start manufacturing and selling the new tools.</p>

<p>"It's not just some cool theoretical thing that will sit on a shelf and never be heard from again—this is ready to be mass manufactured," said Nate Greene, senior product manager at Stanley Black &amp; Decker, who graduated from Johns Hopkins in 2017 with an engineering degree. "This is a really rare and dramatic level of success."</p>

<p>The student team expects their solution could be adapted to quiet other similarly loud appliances like vacuums and hairdryers.</p>

<div data-id="43037"><p><img src="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHZ6786.jpg" alt="Four Johns Hopkins undergrads pose on the quad with their quieter leaf blower" srcset="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_medium/public/2024-05/leaf-blower051324_JHZ6786.jpg 420w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_630/public/2024-05/leaf-blower051324_JHZ6786.jpg 630w, https://api.hub.jhu.edu/factory/sites/default/files/styles/full_width/public/2024-05/leaf-blower051324_JHZ6786.jpg 825w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1030/public/2024-05/leaf-blower051324_JHZ6786.jpg 1030w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_large/public/2024-05/leaf-blower051324_JHZ6786.jpg 1194w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1300/public/2024-05/leaf-blower051324_JHZ6786.jpg 1300w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2024-05/leaf-blower051324_JHZ6786.jpg 1440w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1600/public/2024-05/leaf-blower051324_JHZ6786.jpg 1600w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1800/public/2024-05/leaf-blower051324_JHZ6786.jpg 1800w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2000/public/2024-05/leaf-blower051324_JHZ6786.jpg 2000w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2400/public/2024-05/leaf-blower051324_JHZ6786.jpg 2400w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2880/public/2024-05/leaf-blower051324_JHZ6786.jpg 2880w" sizes="(min-width: 1680px) 1194px, (min-width: 1280px) 948px, (min-width: 1024px) 843px, (min-width: 863px) 675px, (min-width: 768px) 716px, (min-width: 640px) 637px, (min-width: 412px) 531px, (min-width: 375px) 412px, 375px"></p><div><p><span>Image caption:</span> From left, Michael Chacon, Madison Morrison, Andrew Palacio, and Leen Alfaoury
</p><p>Image <span>credit</span>: Will Kirk / Johns Hopkins University</p></div></div>


  			    	
  					
            
              
                

              
            
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Bad CEOs Fear Remote Work (2021) (106 pts)]]></title>
            <link>https://scottberkun.com/2021/why-bad-ceos-fear-remote-work/</link>
            <guid>40377161</guid>
            <pubDate>Thu, 16 May 2024 11:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottberkun.com/2021/why-bad-ceos-fear-remote-work/">https://scottberkun.com/2021/why-bad-ceos-fear-remote-work/</a>, See on <a href="https://news.ycombinator.com/item?id=40377161">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-26431">
	<!-- .entryHeader -->

	<div>
		
<p>Remote work expert <a href="https://twitter.com/mixteenth/status/1390692158240342017">David Tate wrote</a> that <strong>when fearful CEOs talk about workplace culture, they’re really talking about workplace control</strong>. Their insecurities demand that the way work is done by employees is always visible, highly regulated and uses the methods executives prefer, rather than what’s best for everyone’s productivity. Remote work is seen as a threat to many CEOs simply because of their fear of change and resistance to progress. That fear leads to an irrational rejection of remote work, instead of a thoughtful examination of where it has succeeded and what can be learned. </p>



<p>In her May 6th Washington Post opinion article, <a href="https://www.washingtonpost.com/opinions/2021/05/06/ceo-i-want-my-employees-understand-risks-not-returning-work-office/">I worry about the erosion of office culture with more remote work</a>, CEO Cathy Merill makes two fundamental mistakes common among fearful executives. First, it shows an ignorance of alternatives, as many organizations have worked remotely for years before the pandemic and <a href="https://scottberkun.com/2017/why-remote-workers-fail/">have solved problems she considers unsolvable</a>. She may not prefer these approaches, but her lack of awareness of them is incompetence. Second, she is infantilizing her employees by presuming they are not capable of and motivated to be productive and collaborate even when the CEO can’t see them down the hallway.&nbsp;</p>



<p>We are over a year into a pandemic and an era of great social unrest and uncertainty, yet Merill has chosen remote work, and not other likely psychological or cultural factors, as the singular reason why workplace performance has declined. And if this wasn’t enough of an oversight, her evidence against remote work consists mostly of examples from executive friends of their self-described management incompetence.&nbsp;</p>



<p>She offered the story of an anonymous CEO with a new but struggling employee. Yet none of the leadership team did anything about it: </p>



<blockquote><p>&nbsp;A friend at a Fortune 500 company tells of a colleague who was hired just as the pandemic hit. He struggled. He wasn’t getting the job done. It was very hard for the leadership team to tell what the problem was. Was it because he was new? Was he not up to the work? What was the specific issue? Worse, no one wanted to give him feedback over Zoom when they hadn’t even met him. Professional development is hard to do remotely.</p></blockquote>



<p>This is simply a management failure. Does this company not have telephones? Or email? Have they never worked with a vendor or client that wasn’t in the same building? They are responsible for helping this employee regardless of what technologies are available or not. This is inept management hiding behind technological fear. &nbsp;</p>



<p>Merill estimates that 20% of work is helping a colleague or mentoring more junior people, extra work that she feels is impossible to do remotely. This is despite dozens of popular collaboration tools and mentoring programs that work entirely online. It also denies the dozens of remote corporations like <a href="https://scottberkun.com/yearwithoutpants/">Automattic</a> and Citrix that have vibrant work cultures where these “extra” activities are successfully done remotely. </p>



<p>Merill and her peers might not like these alternatives, but she never explains why. She even goes so far as to suggest that remote workers should be paid less and lose their benefits, since in her estimation they will never be able to contribute in these extra ways. She effectively threatened her own staff through the article (she <a href="https://www.forbes.com/sites/jackkelly/2021/05/09/the-cautionary-tale-of-the-washingtonian-magazines-ceo-who-warned-employees-what-would-happen-if-they-didnt-return-to-the-office/?sh=2da183bd6931">apologized later</a> after her staff revolted). </p>



<blockquote><p>If the employee is rarely around to participate in those extras, management has a strong incentive to change their status to “contractor.” Instead of receiving a set salary, contractors are paid only for the work they do, either hourly or by appropriate output metrics. That would also mean not having to pay for health care, a 401(k) match and our share of FICA and Medicare taxes</p></blockquote>



<p>One quality of a great CEO is the ability to look into the future and show their organization the way forward. Instead of blaming employees, they take responsibility for solving problems. For every serious issue that arises they ask themselves what can I do or change in my own behavior that can lead my staff to a better place? They diversify their network to ask “who has solved the problem my organization is facing somewhere else and what can we learn?” Or perhaps most critical of all, they invite their own employees to participate in both defining the problem and exploring ways to solve it, instead of drawing lines in the sand and assuming the only way forward is the one that makes them the most comfortable. &nbsp;</p>



<p>Technology is often seen as a silver bullet, oversold as the magic solution that can solve hard problems. This overestimates what a technology can do, as often it’s the management culture that is the real cause. But in the case of Merill, her CEO peers and remote work, technology is being used as a scapegoat. It’s the safe target to blame as it requires no introspection or accountability. Leaders that do this become fear-driven, allowing their competitors an advantage simply by exercising curiosity and seeking new knowledge. Smart CEOs chose to invest in their work culture and grow it for the future instead of hoping for the past to return.&nbsp;</p>



<figure><a href="https://pixabay.com/illustrations/fear-shadow-disorder-scare-threat-3949033/"><img loading="lazy" width="1024" height="665" src="https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920-1024x665.jpg" alt="" srcset="https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920-1024x665.jpg 1024w, https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920-600x390.jpg 600w, https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920-768x499.jpg 768w, https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920-1536x998.jpg 1536w, https://scottberkun.com/wp-content/uploads/2021/05/fear-3949033_1920.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
			</div><!-- .entryContent -->

	
	<!-- .entryFooter -->

</article><!-- #post-## -->

			
			
	



<section id="respond">
	<h3>Leave a Reply</h3>
		

	
</section>



		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU opens child safety probes of Facebook and Instagram, citing addictive design (130 pts)]]></title>
            <link>https://techcrunch.com/2024/05/16/eu-opens-child-safety-probes-of-facebook-and-instagram-citing-addictive-design-concerns/</link>
            <guid>40377154</guid>
            <pubDate>Thu, 16 May 2024 11:40:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/05/16/eu-opens-child-safety-probes-of-facebook-and-instagram-citing-addictive-design-concerns/">https://techcrunch.com/2024/05/16/eu-opens-child-safety-probes-of-facebook-and-instagram-citing-addictive-design-concerns/</a>, See on <a href="https://news.ycombinator.com/item?id=40377154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Facebook and Instagram are under formal investigation in the European Union over child protection concerns, the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_24_2664" target="_blank" rel="noreferrer noopener">Commission announced</a> Thursday. The proceedings follow a raft of <a href="https://techcrunch.com/2023/12/01/meta-dsa-rfi-2-child-safety/">requests for information to parent entity Meta</a> since the bloc’s online governance regime, the Digital Services Act (DSA), started applying last August.</p>

<p>The development could be significant as the formal proceedings unlock additional investigatory powers for EU enforcers, such as the ability to conduct office inspections or apply interim measures. Penalties for any confirmed breaches of the DSA could reach up to 6% of Meta’s global annual turnover.</p>

<p>Meta’s two social networks are designated as very large online platforms (VLOPs) under the DSA. This means the company faces an extra set of rules — overseen by the EU directly — requiring it to assess and mitigate systemic risks on Facebook and Instagram, including in areas like minors’ mental health. </p>

<p>In a briefing with journalists, senior Commission officials said they suspect Meta of failing to properly assess and mitigate risks affecting children. </p>

	
	


	
	


<p>They particularly highlighted concerns about addictive design on its social networks, and what they referred to as a “rabbit hole effect,” where a minor watching one video may be pushed to view more similar content as a result of the platforms’ algorithmic content recommendation engines.</p>

<p>Commission officials gave examples of depression content, or content that promotes an unhealthy body image, as types of content that could have negative impacts on minors’ mental health.</p>

<p>They are also concerned that the age assurance methods Meta uses may be too easy for kids to circumvent. </p>


	
	


	
	


<p>“One of the underlying questions of all of these grievances is how can we be sure who accesses the service and how effective are the age gates — particularly for avoiding that underage users access the service,” said a senior Commission official briefing press today on background. “This is part of our investigation now to check the effectiveness of the measures that Meta has put in place in this regard as well.”</p>

<p>In all, the EU suspects Meta of infringing DSA Articles 28, 34, and 35. The Commission will now carry out an in-depth investigations of the two platforms’ approach to child protection.</p>

<p>The EU opened a similar probe into addictive design concerns on video sharing social network TikTok <a href="https://techcrunch.com/2024/04/22/tiktok-lite-dsa-probe/" target="_blank" rel="noreferrer noopener">last month</a>.</p>

<p>Reached for a response to the EU investigation, a Meta spokesperson emailed us this statement: “We want young people to have safe, age-appropriate experiences online and have spent a decade developing more than 50 tools and policies designed to protect them. This is a challenge the whole industry is facing, and we look forward to sharing details of our work with the European Commission.”</p>

	
	


	
	


<p>The company also told us its approach to verifying the age of users of the two social networks relies on a combination of self declared age and AI assessments to try to detect kids who may be lying about their age. Additionally, it said it allows people to report suspected underage accounts, adding that it trains its content reviewers to flag accounts that may be used by underage minors. </p>

<p>Users who are under 18 and attempt to edit their age on its platforms will be challenged to choose and submit to an age verification test, per Meta — however the company did not specify which age verification checks it offers. But it claimed that internal tests of the efficacy of its approach indicate the approach is working to prevent minors from accessing age-appropriate experiences. Since instigating the checks Meta said it has been able to stop 96% of teens who attempted to edit their birthdays from under 18 to over 18 on Instagram from doing so.</p>

<p>The Commission also already opened two DSA investigations on Meta’s social networks. <a href="https://techcrunch.com/2024/04/30/meta-first-dsa-probes/">Last month</a> it said it would investigate separate concerns related to Facebook’s and Instagram’s approach to election integrity.</p>

<p><em>This report was updated with comment from Meta</em></p>

<figure></figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VCs aren’t your friends (456 pts)]]></title>
            <link>https://www.openvc.app/blog/vcs-arent-your-friends</link>
            <guid>40375548</guid>
            <pubDate>Thu, 16 May 2024 05:42:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openvc.app/blog/vcs-arent-your-friends">https://www.openvc.app/blog/vcs-arent-your-friends</a>, See on <a href="https://news.ycombinator.com/item?id=40375548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Yesterday, famous VC Jason Lemkin passed on a startup because the deck was dated from 2 months ago, which he saw as a negative signal.</p>
<p>Of course, people on Twitter and Linkedin got riled up.</p>
<p>Let me tell you why (a) Jason did nothing wrong, and (b) most founders have the wrong expectations when it comes to VC relationships.</p>
<p>
    <i>NB: This is an "opinion piece", slightly different from our usual educational content. Feel free to say if you hate it or love it on </i>
    <a href="https://twitter.com/StephNass/status/1790776845514023335" target="_blank">
        <i>Twitter</i>
    </a>
    <i> and <a href="https://www.linkedin.com/posts/stephanenasser_vcs-arent-your-friends-activity-7196542558531907587-73xw" target="_blank">LinkedIn</a>
    </i>😁
</p>

  <div>
    <h4>Table of Contents</h4>
    <ul>
      <li><a href="#toc-id">toc-name</a></li>
    </ul>
  </div>
<h2 id="first-lets-get-the-facts-straight">First, let's get the facts straight</h2>
<p>Here's the full tweet that caused the outrage:</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/qeuOX0ZBUkfqxsbQUnJR8gq7O_rvuIiN-OUYnpPLD_nhNLyoYCZ5-2ic0T9TX0zDjbZwVdx3zmv2dHeYUwfsCtIVxbY_9HXZcJmY9Bmc7iPSTzV1ftK0ZQLRkPJXfwir2lcaf_1U0DnOEkIqZxqpCBE" loading="lazy" width="500">
    <figcaption>
        <a href="https://twitter.com/jasonlk/status/1790071196308091042" target="_blank">Source</a>
    </figcaption>
</figure>
<p>So, Jason opens a cold email. The deal seems decent, but not that exciting. Then, he notices that the date on the cover is outdated. Small detail? Yes, but also a red flag that tips the scale. Jason passes.</p>
<p>Congratulations, you just got introduced to the VC "game of inches".</p>
<h2 id="signaling-and-red-flags-vcs-play-a-game-of-inches">Signaling and red flags: VCs play a game of inches</h2>
<p>Founders may be horrified, but look at the investor's point of view.</p>
<p>A VC receives 10 to 50 decks per week. Out of those, 10% are hot: think OpenAI. These deals don't even need a deck to raise. They thrive on FOMO, it's a <a href="https://www.openvc.app/blog/pool-party" target="_blank">pool party</a>. VCs fight for allocation on those cap tables.</p>
<p>Then there's the rest.</p>
<p>The bottom 90%. The normal founders. You and I.</p>
<p>For these ones, it's an elimination process: kill as many decks as fast as possible. Whatever remains gets a second look.</p>
<p>
    <b>This is where "red flags" come into play. Because VCs have zero context on a cold email, they rely on micro-signals:</b>
</p>
<figure>
    <ul>
        <li>"Market size is $200Tn" -&gt; Founder is naive or delusional</li>
        <li>Lots of text written small -&gt; Founder has low empathy, poor marketing skills</li>
        <li>The deck is outdated&nbsp; -&gt; Founder has low attention to details</li>
        <li>Etc etc.</li>
    </ul>
</figure>
<p>(By the way, the OpenVC pitch deck tutorial explicitly says to never include the date on your cover. If you haven't read it, it's free and available to all founders <a href="https://openvc.app/blog/startup-pitch-deck" target="_blank">here</a> ).</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/kKmrWxRZeA2nA9wn78rnrRvQZ9Od6aobLhHlWOx-cFJFTygZbpVBRy6_WRKMiANTNEkVyVNBKjIlCZSP4wNjAz3ZvT36h-JodkromzxMJHDxSDwuyfE1sODlYe_8HZquP3UMbRr6jlXZkLVi3_KDQMg" loading="lazy" data-toggle="modal" data-options="{}" width="500">
    <figcaption>VC playing the game of inches. One wrong move and you're dead.</figcaption>
</figure>
<h2 id="dont-fall-for-the-fleece-vest-vcs-arent-your-friends">Don't fall for the fleece vest: VCs aren't your friends</h2>
<p>If you listen to VCs, they are your friends.</p>
<p>"We want to be the first check in." "We add value" 'We are responsible investors". "We're in for the long run". "We back outliers" and the oh-so-famous "Let me know how I can be helpful".</p>
<p>That's normal, that's part of their brand building.</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/VJJPbPlLunhpXuoP2r1aDBrw5XUYdFN7TXB-GLD14RFonF8qYGuM7AhdHts2Oq4PoLNR9fgCzwF1ZtumdxWXfrrI-6GmuZReAqpe54EuZEpe-1D2BZ9KkUjbYqSKcz-81sjH1fV06QD8DTq5ms1ok6o" loading="lazy" data-toggle="modal" data-options="{}" width="500">
    <figcaption></figcaption>
</figure>
<p>VCs want to see as many deals as possible. Even if they barely open your deck, they want to increase their "coverage rate" and report a growing top of funnel to their LPs.</p>
<p>
    <b>Founders however, especially first-time founders, rarely get that nuance. They want to believe that there's a bunch of nice people who will support their journey with advice, cheers, and yes, money.</b>
</p>
<p>This is partly true. Most VCs I've met - and I've met 100+ at this point - are good human beings and diligent professionals.</p>
<p>But they remain money allocators. Don't be fooled by the Allbirds, the fleece vest, and the Twitter threads. VCs are investors. They manage millions of dollars, report to their own investors (the LPs) and if they don't deliver the expected returns, they won't raise their next fund.</p>
<p>As much as they want to be your friends, the fund comes first (as it should).</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/7wg-jHKJT-fFMA6tXbYKp9NBaFWtaw-hAKfZ0wKGrsDlm8cuCM-x9cv07BbvZ2hz4SBD2vCLbY4sx93fHEnwDOXX2VHR4GYN3clj0x0gEwcnlbcoAhNK8W9WathaAkD5btTuri3tabBBIMQlbQfqyKk" loading="lazy" data-toggle="modal" data-options="{}" width="500">
    <figcaption>Tomato tomato?</figcaption>
</figure>
<h2 id="jason-did-nothing-wrong">Jason did nothing wrong?</h2>
<p>This brings us back to Jason Lemkin's post.</p>
<p>I actually believe Jason's post to be sincere and helpful.</p>
<p>For one thing, he is one the few who actually opens cold emails, replies to them, and invests in them. He famously funded Algolia, Pipedrive, Salesloft, and Talkdesk on a cold email.</p>
<p>
    <b>He also openly shares his decision-making process, which is rare and valuable. Think about it: investment bankers and experienced founders know better than sending an outdated deck. Now, outsiders know about this, too.</b>
</p>
<p>That's why I believe Jason did nothing wrong.</p>
<p>He just gave founders a sense of how ruthless and biased the selection process can be. A few founders got offended, but many more learnt from it and adjusted their decks accordingly.</p>
<p>All in all, it's a net positive.</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/cOXanjnNz-IDj9zbMQOmwEjzcZ4I7lP8nQpNaCVW1sTqFqF8-uL6Va5PikbKvRdo9FgDTKs8Q22GBZbOwzZl3ogs8d0A0FRO6Eiu98MgwPYA1sxGM3Z5hDfNuRNtqa6CG3Yxl6T45fqaWs0deu38GB0" loading="lazy" data-toggle="modal" data-options="{}" width="NaN">
    <figcaption>Jason's reply to an upset founder on LinkedIn</figcaption>
</figure>
<h2 id="find-the-right-distance-with-vcs">Find the right distance with VCs</h2>
<p>I work with first-time founders on a daily basis.</p>
<p>I've noticed a typical emotional journey from excitement (pre-raise) to frustration (1-2 months into the raise) to downright anger (3+ months) when they realize VCs don't open their decks, don't reply to their emails, and don't provide <a href="https://openvc.app/blog/investors-honest-feedback" target="_blank">any feedback</a>.</p>
<p>I believe this is due to wrong expectations.</p>
<p>If you've never dealt with professional investors, this is something you have to learn.</p>
<p>
    <b>VCs aren't your teachers nor your managers. They don't have an obligation to provide feedback or even to reply to your emails. They won't give you a second chance. They won't coach you so you can do better next time.</b>
</p>
<figure>
    <img src="https://lh7-us.googleusercontent.com/eYNiHw-lU6XAUAxKOQKbnIdspB-_TKhTiXEKt2xG72Ej88RrmNythmx6ZFqvDSKoltTt34OwMeD9WEv77EvUsPEwbqJ9mgaRL2-l6x4k1emW9R3scGkGOlfUhv-27aR_vwbehv-jwOnw_8h22mu-kuU" loading="lazy" data-toggle="modal" data-options="{}" width="500">
    <figcaption></figcaption>
</figure>
<p>Instead, think of a VC as a sales prospect.</p>
<p>They have been pitched 10 times and are jaded. They are irrational and demanding. If you want to close that deal, you need to bring your A game, especially if you're an "almost" deal.</p>
<p>Of course, you can also decide that belly dancing for VCs is not your thing and go another route like bootstrapping. Perfectly reasonable.</p>
<p>Simply remember: VCs are investment professionals before being a founder's best friend.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kernel.org servers infected with backdoors for two years from 2009 (106 pts)]]></title>
            <link>https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/</link>
            <guid>40375498</guid>
            <pubDate>Thu, 16 May 2024 05:32:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/">https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/</a>, See on <a href="https://news.ycombinator.com/item?id=40375498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      ONGOING LINUX THREAT    —
</h4>
            
            <h2 itemprop="description">Ebury backdoors SSH servers in hosting providers, giving the malware extraordinary reach. </h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/backdoor-800x450.jpeg" alt="A cartoon door leads to a wall of computer code.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 241:single/related:a1c3db44ef6c82bce6b426d4579d22c6 --><!-- empty -->
<p>Infrastructure used to maintain and distribute the Linux operating system kernel was infected for two years, starting in 2009, by sophisticated malware that managed to get a hold of one of the developers’ most closely guarded resources: the /etc/shadow files that stored encrypted password data for more than 550 system users, researchers said Tuesday.</p>
<p>The unknown attackers behind the compromise infected at least four servers inside kernel.org, the Internet domain underpinning the sprawling Linux development and distribution network, the researchers from security firm ESET said. After obtaining the cryptographic hashes for 551 user accounts on the network, the attackers were able to convert half into plaintext passwords, likely through password-cracking techniques and the use of an advanced credential-stealing feature built into the malware. From there, the attackers used the servers to send spam and carry out other nefarious activities. The four servers were likely infected and disinfected at different times, with the last two being remediated at some point in 2011.</p>
<h2>Stealing kernel.org’s keys to the kingdom</h2>
<p>An infection of kernel.org <a href="https://www.theregister.com/2011/08/31/linux_kernel_security_breach/">came to light</a> in 2011, when kernel maintainers revealed that 448 accounts had been compromised after attackers had somehow managed to gain unfettered, or “root,” system access to servers connected to the domain. Maintainers <a href="https://arstechnica.com/information-technology/2013/09/who-rooted-kernel-org-servers-two-years-ago-how-did-it-happen-and-why/">reneged on a promise</a> to provide an autopsy of the hack, a decision that has limited the public’s understanding of the incident.
</p><p>Besides revealing the number of compromised user accounts, representatives of the Linux Kernel Organization provided no details other than saying that the infection:</p>
<ul>
<li>Occurred no later than August 12, 2011, and wasn't detected for another 17 days</li>
<li>Installed an off-the-shelf rootkit known as Phalanx on multiple servers and personal devices belonging to a senior Linux developer</li>
<li>Modified the files that both servers and end user devices inside the network used to connect through OpenSSH, an implementation of the SSH protocol for securing remote connections.</li>
</ul>                                            
                                                        
<p>In 2014, ESET researchers said the 2011 attack likely infected kernel.org servers with a <a href="https://arstechnica.com/information-technology/2014/03/10000-linux-servers-hit-by-malware-serving-tsunami-of-spam-and-exploits/">second piece of malware</a> they called Ebury. The malware, the firm said, came in the form of a malicious code library that, when installed, created a backdoor in OpenSSH that provided the attackers with a remote root shell on infected hosts with no valid password required. In a little less than 22 months, starting in August 2011, Ebury spread to 25,000 servers. Besides the four belonging to the Linux Kernel Organization, the infection also touched one or more servers inside hosting facilities and an unnamed domain registrar and web hosting provider.
</p><p>A <a href="https://web-assets.esetstatic.com/wls/en/papers/white-papers/ebury-is-alive-but-unseen.pdf">47-page report</a> summarizing Ebury's 15-year history&nbsp;said that the infection hitting the kernel.org network began in 2009, two years earlier than the domain was previously thought to have been compromised. The report said that since 2009, the OpenSSH-dwelling malware has infected more than 400,000 servers, all running Linux except for about 400 FreeBSD servers, a dozen OpenBSD and SunOS servers, and at least one Mac.</p>
<p>Researcher Marc-Etienne M. Léveillé wrote:</p>
<blockquote><p>In our 2014 paper, we mentioned that there was evidence that kernel.org, hosting the source code of the Linux kernel, had been a victim of Ebury. Data now at our disposal reveals additional details about the incident. Ebury had been installed on at least four servers belonging to the Linux Foundation between 2009 and 2011. It seems these servers acted as mail servers, name servers, mirrors, and source code repositories at the time of the compromise. We cannot tell for sure when Ebury was removed from each of the servers, but since it was discovered in 2011 it is likely that two of the servers were compromised for as long as two years, one for one year and the other for six months.</p>
<p>The perpetrator also had copies of the /etc/shadow files, which overall contained 551 unique username and hashed password pairs. The cleartext passwords for 275 of those users (50%) are in possession of the attackers. We believe that the cleartext passwords were obtained by using the installed Ebury credential stealer, and by brute force.</p></blockquote>
<p>The researcher said in an email that the Ebury and Phalanx infections appear to be separate compromises by two unrelated threat groups. Representatives of the Linux Kernel Organization didn’t respond to emails asking if they were aware of the ESET report or if its claims were accurate. There is no indication that either infection resulted in tampering with the Linux kernel source code.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/2/">2</a> <a href="https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/3/">3</a> <a href="https://arstechnica.com/security/2024/05/ssh-backdoor-has-infected-400000-linux-servers-over-15-years-and-keeps-on-spreading/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Some notes on Rust, mutable aliasing and formal verification (267 pts)]]></title>
            <link>https://graydon2.dreamwidth.org/312681.html</link>
            <guid>40375341</guid>
            <pubDate>Thu, 16 May 2024 05:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://graydon2.dreamwidth.org/312681.html">https://graydon2.dreamwidth.org/312681.html</a>, See on <a href="https://news.ycombinator.com/item?id=40375341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Recently <a href="https://without.boats/blog/references-are-like-jumps/">Boats wrote a blog post</a> about Rust, mutable aliasing, and the sad story of local reasoning over many decades of computer science. I recommend that post and agree with its main points! Go read it! But I also thought I'd add a little more detail to an area it's less acutely focused on: formal methods / formal verification.</p><p><b>TL;DR</b>: support for <em>local</em> reasoning is a big factor in the ability to do <em>automated</em> reasoning about programs. Formal verification involves such reasoning. Rust supports it better than many other imperative systems languages -- even some impure functional ones! -- and formal verification people are excited and building tools presently. This is not purely by accident, and is worth understanding as part of what makes Rust valuable beyond "it doesn't need a GC".</p><p>The rest of this post is just unpacking and giving details of one or more of the above assertions, which I'll try to address in order of plausible interestingness to the present, but I will also throw in some history because I kinda can't help myself.</p><p><b>What even are formal verification tools?</b></p><p><a href="https://en.wikipedia.org/wiki/Formal_methods">Formal methods</a> or <a href="https://en.wikipedia.org/wiki/Formal_verification">formal verification</a> tools are tools that <em>prove</em> properties hold over large (possibly infinite) amounts of a program's entire possible state space, rather than testing the program on individual paths through that state space. They use <em>computational logics</em> for this, sometimes in very complex ways. They are a very old field in computer science, going back at least 50 years. A certain contingent -- including the famous <a href="https://en.wikipedia.org/wiki/Tony_Hoare">Tony Hoare</a> (no relation) -- have maintained since the late 60s that we <em>really ought</em> to be proving all of our programs correct, and that it will be tractable to do so any day now (or perhaps already is if we tried harder). There's way too much to summarize in a blog post, but <a href="http://venge.net/assets/talks/formal-world.pdf">I gave a talk recently covering some of it</a>. It does <em>sometimes</em> work, but it's not yet made it as big as its proponents have always wanted.</p><p>In the <em>best</em> case -- and this is actually approached, sometimes, by some tools today -- the developer experience can be something like "you write an </p><tt>assert!()</tt><p> in your code, and the IDE puts a green squiggly underline when it can prove that that assert always holds over all possible executions, and a red squiggly underline if it has a counterexample possible-execution where the assert won't hold". Absolute <em>magic</em>.</p><p><b>How does local reasoning relate to formal verification?</b></p><p>Formal verification involves inferring, propagating, resolving and relating formulas in sound computational logics (eg. <a href="https://en.wikipedia.org/wiki/Hoare_logic">Hoare logic</a>) that characterize a program's possible states. These formulas start with the literals and variables in a program and are then combined by rules (eg. <a href="https://en.wikipedia.org/wiki/Predicate_transformer_semantics">Dijkstra's predicate-transformer rules</a>) driven by the composite syntactic and semantic forms of the programming language, including function applications, variable assignments, conditional branching, sequential composition and so forth.</p><p>The rules for combining logical formulas across variable assignments typically have to modify all formulas involving the modified variable to correctly account for the change. This is a problem if the underlying programming language has uncontrolled mutable aliasing: potentially <em>every logical formula</em> might change when you make an assignment through a reference, because the logic has no idea what other variables the reference might write-to in a given run of the program. Essentially "all bets are off" at any write through a pointer.</p><p>There are various partial workarounds -- reasoning about type disjointness, or about sets of disjoint possible-aliases, eventually the development of a whole family of logics (eg. <a href="https://en.wikipedia.org/wiki/Separation_logic">separation logic</a>) that account for the disjointness of portions of the heap and the reachable "footprints" of functions -- but for a very, very long time the field has been held back by programming languages with too much mutable aliasing to be tractable.</p><p><b>And Rust makes this better?</b></p><p>Yes. Rust references are subject to the "shared-xor-mutable" rule, which means a write through a reference <em>doesn't</em> invalidate any other variables in existing formulas. This makes it much easier to write a tool that verifies Rust code. Don't just believe me! Here's formal verification hacker Xavier Denis saying as much:</p><blockquote><p lang="en" dir="ltr">rust's avoidance of shared mutable state has deep consequences; when we formally verify programs in Rust we can use FOL and avoid separation logic since the type system protects us from mutable aliasing, while this is not true in caml despite being 'functional'</p>— xavxav (@xldenis) <a href="https://twitter.com/xldenis/status/1790297114519404692?ref_src=twsrc%5Etfw">May 14, 2024</a></blockquote> <p><b>What Rust formal verification projects are there?</b></p><p>Tons! And they're very exciting. <a href="https://github.com/viperproject/prusti-dev">Prusti</a>, <a href="https://github.com/model-checking/kani">Kani</a>, <a href="https://github.com/GaloisInc/crucible/tree/master/crux-mir">Crux-Mir</a>, <a href="https://github.com/AeneasVerif/aeneas">Aeneas</a>, <a href="https://github.com/flux-rs/flux">Flux</a>, <a href="https://github.com/creusot-rs/creusot">Creusot</a>, <a href="https://github.com/facebookexperimental/MIRAI">MIRAI</a>, <a href="https://github.com/hacspec/hax">Hax</a>, <a href="https://github.com/hopv/rust-horn">RustHorn</a>, <a href="https://github.com/Rust-Proof/rustproof">Rustproof</a>, <a href="https://github.com/verus-lang/verus">Verus</a> .. plus lots of <a href="https://github.com/newca12/awesome-rust-formalized-reasoning">supporting crates and projects in computational logic</a>.</p><p><b>Was Rust designed for formal verification?</b></p><p><em>Kinda</em>. There are two fairly different ways in which this is partly true, one usually forgotten and one possibly non-obvious: typestate and borrow checking. I will discuss both briefly below. Both are what we'd at best call "lightweight" formal methods, in the sense that the annotation burden is comparatively low, the word "logic" doesn't make much of an appearance, and the verification is fast and reliable, integrated into the normal workflow of programming. Indeed, some people call type systems themselves "lightweight formal methods", and we had no shortage of people on the team who were comfortable (much more comfortable than me!) with this sort of thing.</p><p>Moreover, even before the project was overrun by MIT and CMU folks (j/k I love you all), I was generally aware of Hoare logics when doing early Rust, and the extent to which mutable aliasing was a problem for them, and that limiting mutable aliasing helped. I was aware that pure-functional languages, affine languages, or those with un-observable writes (eg. with Copy-on-Write) could propagate logical formulas more readily. I was aware Butler Lampson and Jim Horning's "verification-oriented" <a href="https://en.wikipedia.org/wiki/Euclid_(programming_language)">Euclid systems language</a>, for example, had shipped pointers with disjointness guarantees to support local reasoning as far back as the late 70s. I even registered and maintained the domain name </p><tt>rust-proof.org</tt><p> early on, thinking it might wind up coming in handy if we went further in that direction.</p><p>But in a broader sense it is not true that Rust was "designed for" formal verification. I was <em>not</em> totally fluent in Dijkstra's approach to automatic generation of verification condition formulas in Hoare logics, and I was not closely following the ongoing revolutions in either separation logic or <a href="https://en.wikipedia.org/wiki/Conflict-driven_clause_learning">CDCL SAT solvers</a> that were pushing the boundary of that approach. I had (wrongly) convinced myself well before Rust that the approach was a bit of a weird dead end, and believed that the future of formal methods was either in stepwise refinement calculi like <a href="https://en.wikipedia.org/wiki/B-Method">B-method</a>, or interactive dependent-type or higher-order-logic provers like <a href="https://en.wikipedia.org/wiki/Coq_(software)">Rocq (nee Coq)</a> or <a href="https://en.wikipedia.org/wiki/HOL_(proof_assistant)">HOL</a>, or other sorts of pure-functional hybrid logic languages like <a href="https://en.wikipedia.org/wiki/ACL2">ACL2</a>. I did not think any of these was likely to be usable for the broad audience of systems programmers I was aiming Rust at, and was happy to limit its formal verification ambitions to something I could explain to normal programmers, like a typestate system.</p><p>(And I was actually a bit annoyed at how involved the analysis got for the borrow checker; it's long passed my ability to accurately describe what it's doing, and I apologize for the somewhat mangled explanations to follow.)</p><p><b>Typestate</b></p><p>A usually-forgotten chapter in Rust's history is that it initially had a typestate system. <a href="https://en.wikipedia.org/wiki/Typestate_analysis">Typestate systems</a> let you annotate a program's variables with n-ary predicates that get checked dynamically when they're initially established, but are also subject to static analysis of their propagation and validity as values flow through the program. For example you can mark a function as requiring a given predicate on its arguments, and then it becomes an obligation for the caller to have established somewhere before the call (or a requirement they can place on their caller, etc.)</p><p>Eventually people figured out that you can emulate typestates fairly well (though a bit awkwardly) with a combination of affine types and phantom types, both of which Rust supports, so the typestate feature was dropped from the language, but this was a part of the original design that lived quite a ways into the project's life, and was part of the motivation for control over mutable aliasing. If you ever see mention of <a href="https://en.wikipedia.org/wiki/Hermes_(programming_language)">Hermes</a> and NIL in Rust's influences, this is what is meant: these languages have typestates and prohibit mutable aliasing in order to support it.</p><p><b>Borrow checking</b></p><p>Borrow checking is the other motivation, and it's an interesting case because it both requires <em>and provides</em> local reasoning support. It's a key actor in the story! Its main purpose is to prove that any given access through a </p><tt>&amp;</tt><p> or </p><tt>&amp;mut</tt><p> reference is accessing valid memory. To do this it sets out to prove the property that reference lifetimes are shorter than referent lifetimes: a pointer always points to something live.</p><p>But it turns out mere lifetime nesting isn't enough, because Rust is a language with non-uniform representation: not every pointer points to a separate heap cell, but rather a </p><tt>&amp;</tt><p> or </p><tt>&amp;mut</tt><p> reference can point into the middle of some existing value, and that might be a value like an enum that can change size or shape when it's overwritten. So to ensure memory safety, the borrow checker also needs to know that a referenced value with a variable size or shape <em>doesn't change size or shape while referenced</em>, and so it <em>also</em> enforces the "shared-xor-mutable" property on references. And somewhat coincidentally, this rule in turn provides quite strong local reasoning for <em>any</em> property of Rust programs you might want to formally verify.</p><p>While earlier versions of Rust had a much more limited version of </p><tt>&amp;</tt><p> and </p><tt>&amp;mut</tt><p> references -- they were "second class", could not be returned from functions or embedded in structs, only passed as arguments -- they still provided strong support for local reasoning, for the same memory-safety reasons. But their limited expressivity meant the machinery required to check and enforce their properties was much simpler than the full glory of the modern borrow checker: there was a <a href="https://github.com/rust-lang/rust/commit/beda82ddf1f482f286a8d9af3402626dc56d6fea#diff-966e2bfbe831a658c4a89ea9bad0a12ec9d85d6dbf46318e7bd59f2e297c2946">simple path-and-type-disjointness pass called the "alias checker"</a>.</p><p><b>How is this related to GC?</b></p><p>One way to look at reference counting is as a sort of eager, optimized form of garbage collection that works in the case that you have strictly acyclic data (or can tolerate leaking cycles). And one way to look at the </p><tt>&amp;</tt><p> and </p><tt>&amp;mut</tt><p> reference types in Rust is as a way to <em>further</em> optimize reference counting, all the way down to nothing: if you prove the referent outlives the reference, you can avoid reference counting altogether. Of course the </p><tt>&amp;</tt><p> and </p><tt>&amp;mut</tt><p> reference types do other things too -- for example they let you abstract over the difference between reference-counted heap allocation pointers and pointers to the interior of the stack or other objects -- but to a first approximation, when people call these references (and the supporting alias-and-later-borrow-checking pass) "compile-time garbage collection" that is not too far from the point. Strong local reasoning support just comes along for the ride.</p><p>Conversely, languages that <em>have</em> a GC have unfortunately often not felt it necessary to bother having strong local reasoning support. Java for example has a GC and also uncontrolled mutable aliasing, so weak local reasoning and consequently more-challenging formal verification. If you write to an object in Java every other variable referencing that object "sees" the change, so any logical formula that held over all those variables might be invalidated by the write unless you use some fancy method of tracking possible write-sets or separating the heap.</p><p><b>Didn't Rust once have a full, tracing, not-just-reference-counting GC?</b></p><p>Yep! Rust had reference counting with a backup tracing GC on <em>part</em> of its memory graph in order to help support the use case of modeling the DOM in a web browser, which was considered an important use case by some early Mozilla reviewers. As it happened, we couldn't get the tracing part performing well enough to take over from the reference counting part entirely, and also people weren't using these shared pointer types as much in idiomatic Rust as they were using the unique pointer types. So we removed the tracing GC from the shared-mutable type, and then eventually pushed both the unique pointer (Box) and shared pointer (Rc and Arc) types <em>and</em> a mutable-cell type (RefCell) into the standard library.</p><p>What's important to understand is that, as with Rust's Rc type today, the shared pointer graph in Rust-with-a-GC was not responsible for the whole pointer graph. It statically differentiated "shared and immutable" parts of the memory graph from the "shared and mutable" parts, and put the shared-and-mutable stuff behind runtime borrow checks to prevent simultaneous mutable aliasing with </p><tt>&amp;</tt><p> references. Essentially it functioned like </p><tt>Rc&lt;RefCell&lt;T&gt;&gt;</tt><p> today does, which an attentive reader will note can still be tied into reference-cycles, and lacking a GC such a cycle will now just leak! So just imagine that type, but with a cycle collector attached to it automatically by the language runtime to prevent leaks, and a little syntax sugar. You could revive this today if you wanted, and there are even a few Rust libraries that do.</p><p><b>Wait, does that mean <tt>Rc&lt;RefCell&lt;T&gt;&gt;</tt> is a mutable alias?</b></p><p>It's fair to view it that way! You can also look at unsafe Rust as a way to get mutable aliasing. Arguably so is access to stuff outside the program's memory, such as performing IO against a shared filesystem or whatever; at least if you were trying to do automated reasoning about such things. The main difference with other languages is in the <em>ubiquity</em> of such problematic mutable aliases. The typical Rust program has either no refcells, or a very small number, just as it has either no unsafe code or a very small amount; so it's easier to reason about them as a special case and, say, exclude them from the variables being analyzed or develop <a href="https://arxiv.org/abs/2405.08372">specialized rules for them</a>.</p><p>Moreover the RefCell type does a dynamic check for the shared-xor-mutable rule, so <em>from the perspective of the borrow checker in particular</em> it's safe (and sound) to assume any execution that actually occurs (i.e. that does not panic) upholds the rule. But from the perspective of a different verifier looking at different properties then yes, a formula that includes an </p><tt>Rc&lt;RefCell&lt;T&gt;&gt;</tt><p> might be invalidated by a write to some other </p><tt>Rc&lt;RefCell&lt;T&gt;&gt;</tt><p> pointing to the same value, which might defeat formal verification of the properties of interest.</p><p>In fact early versions of Rust didn't support this sort of thing <em>at all</em>. It made all shared-mutable allocations Copy-on-Write, so writing to a shared-mutable allocation made the write private, the other observers of the shared allocation would continue to see the old value. This is a fairly common design choice for languages trying to maintain local reasoning while accepting the need to do mutation sometimes. Rust copied it from a fairly old language called <a href="https://en.wikipedia.org/wiki/Newsqueak">Newsqueak</a>, but you will see it also in newer languages like <a href="https://en.wikipedia.org/wiki/Swift_(programming_language)">Swift</a>. Unfortunately like pure-functional programming, it's something users of lower-level systems languages tend to reject due to both its unpredictable performance and the fact that some programs really do <em>want</em> some small amounts of mutable aliasing.</p><p><b>How is this related to threading?</b></p><p>Threading in the presence of mutable aliasing usually makes formal verification much harder; or put another way it makes local reasoning much less plausible than just "normal" sequential mutable aliasing. Now you don't just have variable assignments invalidating logical formulas, you have <em>everything that a concurrent thread might write to</em> potentially being invalidated <em>at any time</em>. A lot of formal verification tools limit themselves to a single-threaded model of the language they're working with.</p><p><b>Is this why Rust has Fearless Concurrency (tm)?</b></p><p>To an extent. Rust built up a lot of machinery to restrict the ways concurrent threads can interact in order both to make multithreaded programming in Rust less error-prone in general, but <em>also</em> to just preserve the local reasoning required by its "lightweight formal verification" passes, mentioned above, specifically the borrow checker. The borrow checker couldn't rely on anything if it was racing with other threads everywhere. Neither could typestate.</p><p>Again, thinking about analogies to GC, this is in some ways similar to how runtime automatic memory management -- refcounting or tracing GC -- often has to work harder in the presence of threads, with write barriers or collection restarts or atomic operations or such.</p><p>Earlier versions of Rust didn't actually support multiple threads touching the same memory at all. It was trying to be an Actor Language, so limited communication to messages sent over channels, and leveraged the Copy-on-Write machinery to make shallow copies of messages sent between tasks in the same thread, and deep copies when sending between threads.</p><p><b>Phew, that is a lot of notes</b></p><p>Yeah, this is paraphrasing a bunch from earlier conversations but I've wanted to write about it publicly for a long time. Thanks Boats for the motivation!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things I won't work with: the higher states of bromine (2019) (305 pts)]]></title>
            <link>https://blogs.sciencemag.org/pipeline/archives/2019/11/21/the-higher-states-of-bromine</link>
            <guid>40375178</guid>
            <pubDate>Thu, 16 May 2024 04:24:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.sciencemag.org/pipeline/archives/2019/11/21/the-higher-states-of-bromine">https://blogs.sciencemag.org/pipeline/archives/2019/11/21/the-higher-states-of-bromine</a>, See on <a href="https://news.ycombinator.com/item?id=40375178">Hacker News</a></p>
Couldn't get https://blogs.sciencemag.org/pipeline/archives/2019/11/21/the-higher-states-of-bromine: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[NetBSD bans all commits of AI-generated code (103 pts)]]></title>
            <link>https://mastodon.sdf.org/@netbsd/112446618914747900</link>
            <guid>40375029</guid>
            <pubDate>Thu, 16 May 2024 03:47:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.sdf.org/@netbsd/112446618914747900">https://mastodon.sdf.org/@netbsd/112446618914747900</a>, See on <a href="https://news.ycombinator.com/item?id=40375029">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Swift sucks at web serving or does it? (132 pts)]]></title>
            <link>https://wadetregaskis.com/swift-sucks-at-web-serving-or-does-it/</link>
            <guid>40374946</guid>
            <pubDate>Thu, 16 May 2024 03:29:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wadetregaskis.com/swift-sucks-at-web-serving-or-does-it/">https://wadetregaskis.com/swift-sucks-at-web-serving-or-does-it/</a>, See on <a href="https://news.ycombinator.com/item?id=40374946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<div id="toc_container"><p>Contents</p><ul><li><a href="#Benchmark_method_apparatus">Benchmark method &amp; apparatus</a></li><li><a href="#Benchmark_results">Benchmark results</a></li><li><a href="#Debugging_the_benchmark">Debugging the benchmark</a><ul><li><a href="#Domain_experts_weigh_in">Domain experts weigh in</a></li><li><a href="#Examining_the_load">Examining the load</a><ul><li><a href="#The_8220right8221_load">The “right” load</a></li><li><a href="#A_8220fair8221_load">A “fair” load</a></li><li><a href="#Do_these_improvements_apply_to_the_other_cases_too">Do these improvements apply to the other cases too?</a></li></ul></li><li><a href="#but_why_is_the_success_rate_still_weird">…but… why is the success rate still weird?</a></li><li><a href="#Examining_the_benchmark_tool">Examining the benchmark tool</a><ul><li><a href="#Characterising_the_failure_modes">Characterising the failure mode(s)</a></li><li><a href="#Overlooked_clues">Overlooked clues</a></li><li><a href="#A_misunderstood_workaround">A misunderstood workaround</a></li><li><a href="#It8217s_never_the_compiler_or_the_kernel_except_when_it_is">It’s never the compiler or the kernel… except when it is</a></li></ul></li><li><a href="#Conclusion">Conclusion</a></li></ul></li></ul></div><p>A few weeks ago, Axel Roest published <a href="https://tech.phlux.us/Juice-Sucking-Servers/" data-wpel-link="external" target="_blank" rel="external noopener">a simple web server comparison</a>, that turned out to not be doing what it was thought to be doing. Figuring that out was a very interesting discussion that warrants a retrospective, to look at which parts were particularly helpful and which not so much.</p>
<p>Tangentially, I want to highlight that Axel’s comparison is notable because he is interested in <em>efficiency</em>, not mere brute performance. The two are usually correlated but not always the same. He correctly noted that electricity is a major <em>and increasingly large</em> part of server costs (see <a href="https://wadetregaskis.com/the-cost-of-electrical-power-in-servers/" data-wpel-link="internal">my prior post</a> for why it’s even worse than you likely realise). That said, while he did take RAM and power measurements, his benchmark and analysis didn’t go into detail about energy efficiency.</p>
<h2><span id="Benchmark_method_apparatus">Benchmark method &amp; apparatus</span></h2>
<p>Alex wanted to see how a very simple web server performed in:</p>
<ul>
<li><a href="https://www.php.net/manual/en/install.fpm.php" data-wpel-link="external" target="_blank" rel="external noopener">FPM</a> w/ <a href="https://www.nginx.com/" data-wpel-link="external" target="_blank" rel="external noopener">NGINX</a> (PHP).</li>
<li><a href="https://helidon.io/" data-wpel-link="external" target="_blank" rel="external noopener">Helidon</a> (Kotlin).</li>
<li><a href="https://nodejs.org/en" data-wpel-link="external" target="_blank" rel="external noopener">Node.js</a> (JavaScript).</li>
<li><a href="https://vapor.codes/" data-wpel-link="external" target="_blank" rel="external noopener">Vapor</a> (Swift).</li>
</ul>
<p>He was particularly interested in throughput &amp; latency vs RAM &amp; power usage. All are important metrics in their own right, but are most useful in light of each other.</p>
<p>He chose to use <a href="https://en.wikipedia.org/wiki/Fibonacci_sequence" data-wpel-link="external" target="_blank" rel="external noopener">Fibonacci sequence</a> calculation as the load. Choosing a load for any web server benchmark is always highly contentious, and not the focus of this post. Whether you think Fibonacci’s a good choice or not, read on to see why really it didn’t matter.</p>
<div><p>☝️ People get hung up on how well benchmarks represent the so-called real world, but I think that’s often fruitless to argue about and also beside the point. What matters is whether the benchmark is <em>useful</em>. e.g. does it <em>inform</em> and <em>elucidate</em>?</p></div><p>He did use <em>very</em> old hardware, though – an Intel Core i3-550 from over a decade ago. Fortunately it didn’t turn out to materially impact the relative results nor behaviours of the benchmark, but it’s usually unwise to add unnecessary [potential] variables to your setup, like unusual hardware.</p>
<p>In my own debugging and profiling, I used my also very old 10-core iMac Pro. It’s at least a Xeon? 😅</p>
<h2><span id="Benchmark_results">Benchmark results</span></h2>
<p>In words:</p>
<ul>
<li>Helidon (Kotlin) had the highest throughput and lowest latency at low (and arguably more reasonable) loads, but used by far the most RAM, and the most power. Consequently it handled the most load before requests started failing (timing out).</li>
<li>Node.js (JavaScript) was qualitatively very similar to Helidon (Kotlin) but less in all metrics – less throughput, less peak load capacity, but also less RAM and very slightly less power used.</li>
<li>FPM + NGINX (PHP) followed the pattern.</li>
<li>Vapor (Swift) did not – it had higher throughput than PHP yet requests started failing much sooner as load increased. It used the least RAM and least power, though, and kept on trucking irrespective of the load.</li>
</ul>
<p>Many people would have left it at that – obviously the results make sense for the first three (“everyone knows” that Kotlin’s faster than JavaScript that’s faster than PHP) and Vapor / Swift apparently just isn’t fast and has weird reliability behaviours. QED, right?</p>
<div><p>⚠️ Going in with a specific hypothesis can be helpful, but hypotheses can also end up being just biases. Be careful not to blindly accept apparent confirmation of the hypothesis. Similarly, beware subconscious hypotheses like “Kotlin is faster than JavaScript”.</p></div><p>To his credit, Axel wasn’t so sure – he felt that the results he was seeing were suspicious, and <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583" data-wpel-link="external" target="_blank" rel="external noopener">he sought help from the Swift Forums</a> in explaining or correcting them.</p>
<div> <p>✅ Question your results. <em>Understand</em> them. It improves the quality, correctness, and usefulness of your work. <em>Why</em> something behaves the way it does is often more interesting and important than merely how it behaves.</p> <p>On most platforms it’s pretty easy to at least do a time profile, and most often that’s all you need to understand what’s going on. On Apple platforms you can use <a href="https://www.avanderlee.com/debugging/xcode-instruments-time-profiler/" data-wpel-link="external" target="_blank" rel="external noopener">Instruments</a>, on Windows &amp; Linux tools like <a href="https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2024-1/basic-hotspots-analysis.html" data-wpel-link="external" target="_blank" rel="external noopener">VTune</a>, among <a href="https://en.wikipedia.org/wiki/List_of_performance_analysis_tools" data-wpel-link="external" target="_blank" rel="external noopener">many other options</a>.</p> <p>If need be, ask others for help, like Axel did.</p></div><p>While Axel did <em>suspect</em> something was wrong – noting the oddly small but persistent failure rate – he missed the most obvious <em>proof</em> of wrongness – logically impossible results. Doing 80,000 continuous concurrent streams of requests with ~98% of those requests completing within the two second time limit means the server must have a throughput of at least 39,000 requests per second. Yet the benchmark tool reported a mere ~8,000 requests per second.</p>
<p>Sadly, though <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/2" data-wpel-link="external" target="_blank" rel="external noopener">I pointed this out as the very first response to the thread</a>, it seemed to be overlooked by everyone (even myself!), even though it clearly fingered the benchmark tool itself as the problem (which is only partially correct, as we’ll see later, but in any case was the exact right place to start looking).</p>
<h2><span id="Debugging_the_benchmark">Debugging the benchmark</span></h2>
<h2><span id="Domain_experts_weigh_in">Domain experts weigh in</span></h2>
<p>The Swift Forum post immediately attracted relevant people: folks that work on Vapor and NIO, and folks that have experience using them. However, ironically this didn’t initially help – they tended to assume the problem was in Vapor (or its networking library, <a href="https://github.com/apple/swift-nio" data-wpel-link="external" target="_blank" rel="external noopener">SwiftNIO</a>) or how Vapor was being configured. It turned out none of this was really true – there <em>was</em> <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/49" data-wpel-link="external" target="_blank" rel="external noopener">a small optimisation made to Vapor</a> as a result of all this, which did marginally improve performance (in specific circumstances), but ultimately Vapor &amp; NIO were not the problem, nor was the benchmark’s configuration and use of them.</p>
<div> <p>⚠️ It can be all too easy to assume elaborate reasons when you know a lot about something. Don’t jump to conclusions. Check the most basic and foundational things <em>first</em>.</p> <p>I say this with humility and I guess technically hypocrisy, because even as professional performance engineer (in the past) I’ve repeatedly made this mistake myself. We’re all particularly susceptible to this mistake.</p></div><p>There were some assertions that the results <em>were</em> plausible and just how Vapor performs, and that the “problem” was the choice of Vapor rather than some other web server framework (e.g. <a href="https://github.com/hummingbird-project/hummingbird" data-wpel-link="external" target="_blank" rel="external noopener">Hummingbird</a>).</p>
<div><p>⚠️ It’s not <em>wrong</em> to be interested in additional data, but be careful not to get distracted. Using Vapor was not in any way wrong or unhelpful – it is the most well-known and probably well-used web server framework in Swift. It might well be that other frameworks are better in some respects, but that’s a <em>different</em> comparison than what Axel performed.</p></div><p>Others similarly asserted that the results were plausible because Swift uses <a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/automaticreferencecounting/" data-wpel-link="external" target="_blank" rel="external noopener">reference-counting</a> for memory management whereas PHP, JavaScript, and Kotlin use garbage collection. It was presented as “common knowledge” that garbage collection has inherent benefits for some programs, like web servers, because it makes memory allocation super cheap.</p>
<div> <p>⚠️ While it can be useful to speculate a little, in a brainstorming sense, don’t presume. A <em>lot</em> of mistakes have been made over the years because of this, like that “linked lists are faster than arrays” or “binary search is faster than linear search”, etc.</p> <p>Remember that intuition is in large part presumptions and generalisations. That doesn’t make intuition useless, but always remember that it’s far from foolproof. Use it to generate hypotheses, not conclusions.</p></div><h2><span id="Examining_the_load">Examining the load</span></h2>
<p>Even though it was clear that something was wrong with the actual measurements, a lot of the early discussion revolved around the load used (Fibonacci sequence calculation), particularly regarding whether it was:</p>
<h3><span id="The_8220right8221_load">The “right” load</span></h3>
<p>A few folks asserted that the CPU-heavy nature of calculating Fibonacci numbers isn’t representative of web servers generally. Multiple people noted that – in the Swift implementation, at least – the majority of the CPU time was spent doing the Fibonacci calculation. Some felt this was therefore not a useful benchmark of Vapor itself.</p>
<p>A lot of this boiled down to <a href="https://en.wikipedia.org/wiki/No_true_Scotsman" data-wpel-link="external" target="_blank" rel="external noopener">the “no true Scotsman” problem</a>, which is very common in benchmarking, with a bit of perfect world logical fallacy peppered in, trying to identify the One True Representative Benchmark. See the earlier point about fixating on such matters rather than whether the benchmark is <em>useful</em>.</p>
<div> <p>⚠️ While it’s not necessarily wrong or unwise to evaluate how well a benchmark represents real world usage (whether generally or against specific cases), it’s an exercise that suffers from diminishing returns pretty quickly. It’s usually best to not quibble too much or too long, as long as the benchmark is in the ballpark.</p> <p>You can always develop &amp; present your own benchmark(s), if you feel there are better or additional ways to go about it. Best of all, the existence of <em>both</em> the original benchmark and your benchmark(s) will be more useful than either alone, since you can compare and contrast them.</p></div><h3><span id="A_8220fair8221_load">A “fair” load</span></h3>
<p>Accusations were made pretty quickly that the benchmark is “unfair” to Swift because Swift doesn’t – it was asserted – have a properly-optimised “<a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" data-wpel-link="external" target="_blank" rel="external noopener">BigInt</a>” implementation, unlike all the other languages tested.</p>
<p>No real evidence was given for this.  Even if it were true, it doesn’t invalidate the benchmark – in fact, it just makes the benchmark <em>more</em> successful because it’s then highlighted an area where Swift is lacking.</p>
<p>The BigInt library that Axel used, <a href="https://github.com/attaswift/BigInt" data-wpel-link="external" target="_blank" rel="external noopener">attaswift/BigInt</a>, is by far the most popular available for Swift, as judged by things like GitHub stars, forks, &amp; contributor counts, ranking in web &amp; GitHub searches, etc. There are <a href="https://swiftpackageindex.com/search?query=bigint" data-wpel-link="external" target="_blank" rel="external noopener">quite a few others</a>, though.</p>
<div> <p>☝️ There are multiple ways to approach a benchmark, all equally valid because they’re all useful. Axel chose to use popular packages, in <em>all</em> the languages he tested. That’s definitely fair. It’s also useful because it represents what the typical developer will do when building real web servers.</p> <p>It’s often also interesting and useful to search out the <em>best</em> packages (whatever that may mean in context, such as fastest). That could represent what a more heavily optimised implementation might do. It <em>might</em> also better represent what is theoretical possible (<em>if</em> optimal packages exist already). Those are interesting things to explore too, just not what Axel happened to be doing.</p> <p>You can see also more of my thoughts on Axel’s choice here, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/39" data-wpel-link="external" target="_blank" rel="external noopener">in the Swift Forums thread</a>.</p></div><p>It wasn’t until <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/46" data-wpel-link="external" target="_blank" rel="external noopener">actual evidence was presented</a>, that the discussion made progress.</p>
<div> <p>⚠️ While it’s true that without the initial blind assertions, actual data might never have been gathered, it would have been more effective and efficient to have just gathered the data at the start.</p> <p>Data is better than supposition.</p></div><p>It was shown that in fact the BigInt implementation in question <em>was</em> significantly slower than it could be, because JavaScript’s implementation of addition was much faster. <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/62" data-wpel-link="external" target="_blank" rel="external noopener">Some additional simple tests</a> showed even wider performance gaps regarding the other key operation: rendering to strings. It was <em>that</em> data that turned out to be critical – <a href="https://github.com/apple/swift-foundation/pull/262" data-wpel-link="external" target="_blank" rel="external noopener">I myself happened to have implemented BigInt string rendering for Apple’s new Foundation</a>, <em>and</em> then <a href="https://github.com/apple/swift-foundation/pull/306" data-wpel-link="external" target="_blank" rel="external noopener">saw it dramatically optimised by</a> <a href="https://github.com/oscbyspro" data-wpel-link="external" target="_blank" rel="external noopener">Oscar Byström Ericsson</a>, whom has his own BigInt package for Swift, <a href="https://github.com/oscbyspro/Numberick" data-wpel-link="external" target="_blank" rel="external noopener">Numberick</a>. So I had a pretty darn good idea of where I might find a faster package… 😆</p>
<p>You can read more about that specific bit of serendipity <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/64" data-wpel-link="external" target="_blank" rel="external noopener">in the Swift Forums thread</a>.</p>
<p>It was trivial to do the package switch, and it quickly improved Vapor/Swift’s showing in the benchmark manyfold – in combination with some other simple and reasonable tweaks, it was <em>five times faster</em>!</p>
<div>
<p>✅ Axel’s benchmark taught a lot of people that <a href="https://github.com/oscbyspro/Numberick" data-wpel-link="external" target="_blank" rel="external noopener">Numberick</a> is much more performant than <a href="https://github.com/attaswift/BigInt" data-wpel-link="external" target="_blank" rel="external noopener">BigInt</a>, at least in some important operations (addition and string rendering). Granted that knowledge is a little bit niche in its utility, but it’s still a good outcome.</p>
<p>It also demonstrated that modifying in place can be faster than creating a copy, <em>even if</em> it means having to do a swap. i.e.:</p>
<p>…instead of:</p>
<div data-code-block-pro-font-family=""><pre tabindex="0"><code><span><span>let</span><span> c = a + b</span></span>
<span><span>a = b</span></span>
<span><span>b = c</span></span></code></pre></div><p>That’s a tidbit I had picked up through varied experiences, and <a href="https://wadetregaskis.com/swift-tip-the-swap-function/" data-wpel-link="internal">wrote about previously</a>. The <code><a href="https://developer.apple.com/documentation/swift/swap(_:_:)" data-wpel-link="external" target="_blank" rel="external noopener">swap</a></code> function in Swift is under-appreciated and under-utilised. This knowledge may seem esoteric but you’d be amazed how often it applies (a <em>lot</em> of programming is about combining data, after all).</p></div><p>Axel posted <a href="https://tech.phlux.us/Juice-Sucking-Servers-Part-Deux/" data-wpel-link="external" target="_blank" rel="external noopener">a follow-up with additional data</a> (with the aforementioned changes and optimisations). That showed Swift now beating out the other three frameworks / languages, with the highest throughput and lowest latency (and still the lowest RAM and power usage).</p>
<div> <figure><img loading="lazy" decoding="async" width="800" height="513" src="https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-throughput-after-fixes.webp" alt="" srcset="https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-throughput-after-fixes.webp 800w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-throughput-after-fixes-256x164.webp 256w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-throughput-after-fixes-768x492.webp 768w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-throughput-after-fixes-256x164@2x.webp 512w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>From Axel’s follow-up post. X axis is the number of concurrent requests.</figcaption></figure></div><p>So, all done, right? Turns out, Vapor/Swift wins, yeah?</p>
<p>Well, maybe.</p>
<h3 id="do-these-improvements-apply-to-the-other-cases-too"><span id="Do_these_improvements_apply_to_the_other_cases_too">Do these improvements apply to the other cases too?</span></h3>
<p>That is yet to be examined. Because only Swift seemed to be producing odd results, Axel only put the benchmark to the Swift community for deeper analysis. It’s quite possible that doing the same with the other web frameworks &amp; languages would similarly reveal potential improvements.</p>
<p>Still, the results are useful as they stand. Some simple and very plausible – even for a Swift beginner – optimisations made a big difference, though of course the biggest difference was simply using a different 3rd party package. There are a lot of useful lessons in that, both in the specifics as already covered and as general best practices.</p>
<div> <p>☝️ Benchmarks are rarely “done”, their results rarely “final”. At least if you permit optimisations or other changes. How do you <em>know</em> there’s not something still “unfair” about one of the cases?</p> <p>Again, this speaks to the potential futility of trying to make “fair” benchmarks, and reiterates the practical benefit of simply trying to learn instead.</p></div><h2><span id="but_why_is_the_success_rate_still_weird">…but… why is the success rate still weird?</span></h2>
<p>Despite the improved performance, a fundamental problem remained: <em>the numbers still didn’t make sense</em>.</p>
<div> <figure><img loading="lazy" decoding="async" width="800" height="512" src="https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-success-rate-after-fixes.png" alt="" srcset="https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-success-rate-after-fixes.png 800w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-success-rate-after-fixes-256x164.png 256w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-success-rate-after-fixes-768x492.png 768w, https://wadetregaskis.com/wp-content/uploads/2024/05/Web-server-comparison-success-rate-after-fixes-256x164@2x.png 512w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>From Axel’s follow-up post. X axis is the number of concurrent requests.</figcaption></figure></div><p>The success rates are <em>slightly</em> different but not materially – as concurrent requests go up, the throughput plateaus very quickly, yet success rate remains about the same. It’s exactly the same problem as at the outset – these results cannot possibly be correct.</p>
<p>Despite all the community’s efforts, we hadn’t actually figured out the real problem. We’d merely made Swift <em>look</em> better, without actually providing confidence in the accuracy of the results.</p>
<p>In fairness to myself, I was well aware that we weren’t done, I was just struggling to understand what was really going on, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/74" data-wpel-link="external" target="_blank" rel="external noopener">as I noted here</a>.</p>
<h2><span id="Examining_the_benchmark_tool">Examining the benchmark tool</span></h2>
<p>While there’d been some tangential questions about <code><a href="https://github.com/wg/wrk" data-wpel-link="external" target="_blank" rel="external noopener">wrk</a></code>, the benchmarking tool Axel used, it had largely been ignored thus far.</p>
<p>Ironically (as you’ll soon see) Axel chose <code>wrk</code> specifically because <a href="https://tech.phlux.us/Juice-Sucking-Servers/#benchmarking-software" data-wpel-link="external" target="_blank" rel="external noopener">he didn’t like the behaviour he saw</a> with <a href="https://httpd.apache.org/docs/2.4/programs/ab.html" data-wpel-link="external" target="_blank" rel="external noopener">ApacheBench</a>. Mostly its lack of HTTP/1.1 connection reuse (a subjective but valid methodology choice on Axel’s part) but also because it sounds like he saw some inexplicable results from it too. In hindsight, that might have been a clue that something more pervasive was wrong.</p>
<p>In retrospect there were a few tangential comments in the Swift Forums thread that were on the right track, e.g.:</p>
<blockquote>
<p>…when a new connection comes in, the server needs to make a decision: It can</p>
<ul>
<li>Either accept the new connection immediately, slowing the existing connections down a little (because now there are more connections to service with the same resources as before)</li>
<li>Or it can prioritise the existing connections and slow the connection acceptance (increasing the latency of the first request in the new connection which now has to wait).</li>
</ul>
<cite><a href="https://forums.swift.org/u/johannesweiss/summary" data-wpel-link="external" target="_blank" rel="external noopener">Johannes Weiss</a>, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/77" data-wpel-link="external" target="_blank" rel="external noopener">Swift Forums post</a></cite></blockquote>
<p>As a little spoiler, it seems apparent that the other three web frameworks all accept incoming connections virtually immediately with priority over any existing connections &amp; request handling (even though they don’t necessarily attempt to <em>serve</em> all those connections’ requests simultaneously). Vapor does not.</p>
<p>Suspicions did [correctly] develop around the opening of the connections themselves, which triggered testing with longer timeouts in a somewhat blind attempt to cover-up the “spurious” first moments of the test.</p>
<div><p>❌ Trying to essentially just hide inconvenient results is unlikely to help. It may even be successful, which is the worst possible outcome because it’s basically just burying a time-bomb into the benchmark, <em>and</em> forgoing any real understanding &amp; potential knowledge to be gained from properly investigating the problem.</p></div><h3><span id="Characterising_the_failure_modes">Characterising the failure mode(s)</span></h3>
<p>Though admittedly I wasn’t <em>fully</em> conscious of what I was doing at the time, the next breakthrough came from simply <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/85" data-wpel-link="external" target="_blank" rel="external noopener">gathering more data and analysing it <em>qualitatively</em></a>. This helped in two key ways:</p>
<ul>
<li>It better defined and pinned down the circumstances in which things appear to go wrong with the benchmark itself.<p>It separated out a whole bunch of test configurations that seemingly weren’t interesting (as they behaved in line with intuition / expectations, and similarly across all four web servers).</p></li>
</ul>
<div><p>✅ When it doubt, try to better define the problem. Eliminate variables. Refine quantitative estimates. Make your life easier by eliminating things that don’t matter.</p></div><ul>
<li>It provided hints and potential insight into the nature of the problem.<p>It showed that there was some kind of variability (in time) in the benchmark’s behaviour, with three very distinct modes (including one which was basically the benchmark actually working as expected, the existence of which had been unknown until that point!).</p></li>
</ul>
<div><p>✅ There are <em>many</em> ways to approach a data set, in terms of analysis methods. It’s a good idea to always keep that in mind, and to try different analysis mindsets whenever you seem stuck (and also to further validate conclusions).</p></div><p>Interestingly although ultimately only tangentially, this modality finding prompted quite a few “me too!” responses from other folks, about a variety of use-cases involving Vapor <em>or</em> NIO.  I took that as affirmation that I was onto something real, but in retrospect that should have been an even better clue:  the fact that some people had seen this issue <em>without</em> Vapor involved – the only common denominator was NIO.  Even though it turns out NIO itself wasn’t doing any wrong, it was on the right path to answers.  <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/87" data-wpel-link="external" target="_blank" rel="external noopener">This was <em>specifically</em> pointed out to everyone</a>, even.</p>
<div><p>☝️ Sometimes, it just comes down to needing to listen better.</p></div><h3><span id="Overlooked_clues">Overlooked clues</span></h3>
<p>At this point there were a bunch of discussions about <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/89" data-wpel-link="external" target="_blank" rel="external noopener">benchmark tool configuration</a>, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/91" data-wpel-link="external" target="_blank" rel="external noopener">hardware arrangement</a>, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/102" data-wpel-link="external" target="_blank" rel="external noopener">whether TLS should be used</a>, etc.  I’m going to skim over it, because there’s not much to ultimately say about it – it turned out to not be on the right track in this case, or purely tangential, but it was entirely reasonable to investigate &amp; discuss those aspects.  Such is debug life.</p>
<div> <figure><img loading="lazy" decoding="async" width="600" height="600" src="https://wadetregaskis.com/wp-content/uploads/2024/05/Debug-Life-t-shirt.avif" alt="" srcset="https://wadetregaskis.com/wp-content/uploads/2024/05/Debug-Life-t-shirt.avif 600w, https://wadetregaskis.com/wp-content/uploads/2024/05/Debug-Life-t-shirt-256x256.avif 256w, https://wadetregaskis.com/wp-content/uploads/2024/05/Debug-Life-t-shirt-256x256@2x.avif 512w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>I couldn’t find evidence that anyone’s gotten the tattoo yet, but you can at least <a href="https://www.redbubble.com/i/t-shirt/Debug-Life-White-Typographic-Design-for-Thug-Programmers-by-ramiro/17317023.FB110" data-wpel-link="external" target="_blank" rel="external noopener">get the wardrobe</a>.</figcaption></figure></div><p>What’s interesting is that yet another key clue was mentioned in the Swift Forums thread, yet was overlooked because it was attributed incorrectly and the mechanics miscategorised:</p>
<blockquote>
<p>Don’t test with more than 128 connections. You will get read errors. This is due to the file descriptor limit applied to each process on macOS. As&nbsp;<a href="https://forums.swift.org/u/johannesweiss" data-wpel-link="external" target="_blank" rel="external noopener">@johannesweiss</a>&nbsp;mentioned earlier the default for this is 256. You can change this but it involves disabling the System Integrity Protection.</p>
<cite><a href="https://forums.swift.org/u/adam-fowler/summary" data-wpel-link="external" target="_blank" rel="external noopener">Adam Fowler</a>, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/99" data-wpel-link="external" target="_blank" rel="external noopener">Swift Forums thread</a></cite></blockquote>
<p>The 128 connections &amp; read errors parts were spot on, in hindsight.  But the rest was incorrect (it’s not about the file descriptor ulimit) and in particular the incorrect statement about having to disable SIP perhaps further distracted readers (corrections were posted in reply, which perhaps steered the thread away from what actually mattered).</p>
<p>I’m not sure what precisely the lesson is here… if Adam had better understood the behaviour he’d seen previously (re. 128 connections being the apparent limit) he might have been able to immediately point out one of the key problems.  But who can say why he didn’t quite understand that limit correctly, or whether he should have.  This sort of thing happens, and <em>maybe</em> it suggests a failure to properly diagnose problems previously, but mostly I’d just point out that the discrepancy here – between 128 and 256 – <em>should</em> have been noticed, and had it been questioned it would have accelerated progress towards the root cause.</p>
<p>Speaking just for myself, I think I (erroneously) dismissed Adam’s comment because I already knew that the default file descriptor limit is <em>not</em> actually 256 (it’s 2,560 on macOS, mostly) and so I assumed the <em>whole</em> comment was wrong and irrelevant.</p>
<div><p>⚠️ Partly wrong is not the same as completely wrong (let-alone useless).</p></div><p>Another clue was put forth, yet again essentially by accident (without understanding its significance, at the time):</p>
<blockquote>
<p>Yes, the reason I used&nbsp;<code>wrk</code>, is that it uses pipelining. That’s why ab (apachebench) had such terrible performance: it opened a new socket for each request. And then it overloaded the system by throwing</p>
<ul>
<li><code>socket: Too many open files</code></li>
<li><code>apr_socket_recv: Connection reset by peer&nbsp;</code></li>
</ul>
<p>errors.</p>
<p>I raised the&nbsp;<code>ulimit -n</code>&nbsp;to 10240, but still&nbsp;<code>apr_socket_recv: Connection reset by peer (104)</code>&nbsp;occurred occasionally.</p>
<cite><a href="https://forums.swift.org/u/axello/summary" data-wpel-link="external" target="_blank" rel="external noopener">Axel Roest</a>, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/122" data-wpel-link="external" target="_blank" rel="external noopener">Swift Forums thread</a></cite></blockquote>
<p>This hinted very directly at the second major problem, but it seems nobody in the forum thread realised it.  I think there was still a pre-occupation with the file descriptor ulimit.</p>
<p>A little logic applied at the time of Axel’s comment <em>should</em> have revealed its mistaken presumption: that opening new TCP connections for each HTTP request will inevitably cause connection failures.  Sure, it will if you give it enough concurrent connection attempts, but real-world web servers operate at <em>huge</em> loads that are basically one HTTP request per connection, without any significant reliability problems.  In hindsight, it’s clear that Axel’s dismissal of this behaviour as in any way normal was a mistake – as was everyone else in the thread going along with that dismissal.</p>
<div><p>⚠️ If a tool isn’t working the way you expect, maybe that’s telling you something important. Just switching tools until you find one which doesn’t exhibit the problem doesn’t necessarily mean it’s not still a problem.</p></div><h3><span id="A_misunderstood_workaround">A misunderstood workaround</span></h3>
<p>In parallel to all of the above discussion in the Swift Forums thread, I’d been diving into <code>wrk</code> to see what it was really doing.  I discovered <em>a way</em> to eliminate the errors: by opening all the TCP connections in advance in a way that <em>happened</em> to limit how many were attempted concurrently by <code>wrk</code> thread count which <em>happened</em> to be low enough in my use of <code>wrk</code> to not hit the magic 128 limit (more on that later).  As you can see in <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/123" data-wpel-link="external" target="_blank" rel="external noopener">my forum post on this</a>, I initially misunderstood how <code>wrk</code> functioned and misattributed the root cause as bugs / bad design in <code>wrk</code>.</p>
<p>In my defence, <code>wrk</code> isn’t written very well, eschewing such outrageous and bourgeois software engineering practices as, you know, actually checking for errors.  So it wasn’t unreasonable to believe it was ultimately just broken, given plenty of evidence that it was at least partly broken (which it was &amp; is), but it was ultimately a mistake to let that cloud my judgement of each individual behaviour.</p>
<p>Then again, if I hadn’t been so appalled by the bad code in <code>wrk</code>, and taken it upon myself to rewrite key parts of it, I might not have stumbled onto the above “fix” and therefore also not found the true cause, later.</p>
<div><p>✅ Improving error handling &amp; reporting is practically always a good idea. And when debugging a problem it can be helpful even if it doesn’t feel guided – the whole point of absent or incorrect error reporting is that you don’t know what you’re missing, so you may well reveal an important clue “by accident”.</p></div><h3><span id="It8217s_never_the_compiler_or_the_kernel_except_when_it_is">It’s never the compiler or the kernel… except when it is</span></h3>
<p>At the time I did think I’d actually <em>fixed</em> <code>wrk</code>; I didn’t realise I’d merely found an imperfect workaround.  I’d solved the connection errors (not really)!  But, I was still curious about one thing – something pretty much everyone had kinda ignored this whole time:</p>
<blockquote>
<p>Though those lingering few read/write errors still bother me. I might look into them later.</p>
<cite>Me, <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/123" data-wpel-link="external" target="_blank" rel="external noopener">Swift Forums thread</a></cite></blockquote>
<p>Tracing those reported errors to their cause was quite a challenge.  The only known way to reproduce the errors was to use a very high number of concurrent TCP connections (several thousand), which made it hard to follow any <em>single</em> connection through its lifecycle using any low-brow methods (printf debugging etc).  <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/129" data-wpel-link="external" target="_blank" rel="external noopener">I eventually managed</a> using System Trace<sup data-fn="65590619-a219-4fb0-87ea-fd2c98990365"><a href="#65590619-a219-4fb0-87ea-fd2c98990365" id="65590619-a219-4fb0-87ea-fd2c98990365-link">1</a></sup> (lamenting, the entire time I used Instruments, that it would have been <a href="https://leopard-adc.pepas.com/documentation/DeveloperTools/Conceptual/SharkUserGuide/SystemTracing/SystemTracing.html" data-wpel-link="external" target="_blank" rel="external noopener">so much easier in Shark</a>).</p>
<p>Unfortunately, what I was seeing – while in fact correct – did not make sense to me, so I was hesitant to take it on face value.</p>
<p>The lack of any error reporting on the server side, because Vapor lacks it completely, was also both a known problem at the time and also a problem in hindsight.  Had Vapor/NIO actually reported the errors they were encountering, it would have partially validated what I was seeing in the system traces – in fact, it would probably have saved me from having to capture &amp; analyse system traces.</p>
<div><p>❌ Ignoring errors is always a bad idea. I mean, duh, right? But apparently it has to be reiterated.</p></div><p>Alas I don’t actually remember now precisely what led me to the final answers and root causes.  I know it involved many hours of experimenting, exploring hypotheses, and in generally fiddling with everything I could think of.</p>
<p>Somehow or other, I did finally cotton on to a key configuration parameter:  <code>kern.ipc.somaxconn</code>.</p>
<p>That controls how many connection requests can be pending (not formally accepted by the server) at one time.  It defaults to 128 on macOS.  Remember that number, 128?</p>
<p>Once I had figured out that <code>kern.ipc.somaxconn</code> directly controlled the problematic behaviour, the rest followed pretty naturally and quickly – I realised that what I saw in the system traces was in fact accurate, and that in turn revealed that the macOS kernel contains multiple surprisingly blatant and serious bugs (or at the very least dubious design choices, and lying documentation) regarding TCP sockets in non-blocking mode.  I wrote that up in some detail in the second half of <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583/132" data-wpel-link="external" target="_blank" rel="external noopener">this Swift Forums post</a>.</p>
<p>As a sidenote, that darn magic number that everyone kept ignoring – 128 – cropped up yet again, in <a href="https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man2/listen.2.html" data-wpel-link="external" target="_blank" rel="external noopener">the <code>listen</code> man page</a>, though by the time I saw it there it was merely a confirmation of what I’d already discovered, than a helpful clue.  Still, perhaps there’s a lesson there:  read the man page. 😆</p>
<div><p>❌ When documenting known bugs and limitations, explain them fully. Don’t just say e.g. “more than 128 doesn’t work”, say <em>why</em>.</p></div><h2><span id="Conclusion">Conclusion</span></h2>
<p>All told, the major problems identified by the benchmark were (and not all of these were mentioned above, but you can find all the details in <a href="https://forums.swift.org/t/standard-vapor-website-drops-1-5-of-requests-even-at-concurrency-of-100/71583" data-wpel-link="external" target="_blank" rel="external noopener">the Swift Forums thread</a>):</p>
<ul>
<li>The particular 3rd party library used for BigInt support in Swift, <a href="https://github.com/attaswift/BigInt" data-wpel-link="external" target="_blank" rel="external noopener">attaswift/BigInt</a>, performs quite poorly.</li>
<li>Vapor would accept too few connections per cycle of its event loop (promptly fixed, in <a href="https://github.com/vapor/vapor/releases/tag/4.96.0" data-wpel-link="external" target="_blank" rel="external noopener">4.96.0</a>).</li>
<li>The benchmark tool used, <code><a href="https://github.com/wg/wrk" data-wpel-link="external" target="_blank" rel="external noopener">wrk</a></code>, has numerous bugs:
<ul>
<li>It doesn’t always use the configured number of concurrent connections.</li>
<li>It doesn’t measure latency correctly.</li>
<li>It doesn’t report errors correctly (in the sense both that it miscategorises them, e.g. connect vs read/write, and that it doesn’t provide enough detail to understand what they are, such as by including the errno).</li>
</ul>
</li>
<li>The macOS kernel (and seemingly Linux kernel likewise) has multiple bugs:
<ul>
<li>Connection errors are reported incorrectly (as <code>ECONNRESET</code> or <code>EBADF</code>, instead of <code>ECONNREFUSED</code>).</li>
<li>kqueue (kevents) behaves as if all connections are always accepted, even when they are not. Put another way, you cannot actually tell if a connection was successful when using non-blocking sockets on macOS.</li>
</ul>
</li>
<li>Key network configuration on macOS &amp; Linux is way too restrictive:
<ul>
<li>Maximum file descriptors per process is only 2,560 generally on macOS, and even less (256) in GUI apps. It may vary on Linux, but on Axel’s particular server it was 1,024.</li>
<li>Maximum number of unaccepted connection requests (the <code>kern.ipc.somaxconn</code> sysctl on macOS, <code>/proc/sys/net/core/somaxconn</code> on Linux) is only 128 on macOS.  It may vary on Linux.</li>
</ul>
</li>
</ul>
<p>It <em>appears</em> that the kernel bugs apply to Linux as well (although it’s not known if kqueue was in use there, as <code>wrk</code> also supports <code>epoll</code> and <code>select</code>), as the behaviour seems to be the same there, but I didn’t test that myself and it’s not completely clear from Axel’s posts.  Also, Axel has not yet done a follow-up with the final fixes &amp; workarounds, to confirm that they do fully fix the benchmark’s results.</p>
<p>And that’s just the <em>problems</em> – there was a whole host of interesting lessons taken away from all this (only a fraction of which were highlighted in this post – many more can be found in Axel’s posts and the Swift Forums thread).</p>
<p>Nominally the end result is also a benchmark that shows Vapor (Swift) out-performing other popular web frameworks in other languages.  <em>Hugely</em> out-performing them, if you factor in not just throughput &amp; latency but RAM &amp; power usage.  But, to reiterate <a href="#do-these-improvements-apply-to-the-other-cases-too">what I pointed out earlier</a>, take that with a grain of salt.</p>
<p>So, for a benchmark that many initially decried as unrealistic or plain poorly conceived, it turned out to be pretty darn useful, I think.  And if that doesn’t make it a successful benchmark, I don’t know what does.</p>
<ol><li id="65590619-a219-4fb0-87ea-fd2c98990365">I always endeavour to link to the things I mention, but in this case there’s nothing to link to – Apple don’t provide any actual documentation of the System Trace tool in Instruments, and there’s not even any usable 3rd party guide to it, that I can find. It’s a sad demonstration of Apple’s general indifference to performance tools. 😔<p>Apple don’t even have a proper product page for Instruments itself – the closest you can find is merely <a href="https://help.apple.com/instruments/mac/10.0/#/" data-wpel-link="external" target="_blank" rel="external noopener">its Help</a>. <a href="#65590619-a219-4fb0-87ea-fd2c98990365-link" aria-label="Jump to footnote reference 1">↩︎</a></p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Utah Locals Are Getting Cheap 10 Gbps Fiber Thanks to Local Governments (304 pts)]]></title>
            <link>https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/</link>
            <guid>40373931</guid>
            <pubDate>Thu, 16 May 2024 00:22:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/">https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/</a>, See on <a href="https://news.ycombinator.com/item?id=40373931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-438359">


<h3>from the <i>just-build-it-yourself</i> dept</h3>

<p>Tired of being underserved and overbilled by shitty regional broadband monopolies, back in 2002 a coalition of local Utah governments formed <a href="https://www.utopiafiber.com/faqs/">UTOPIA</a> — (the Utah Telecommunication Open Infrastructure Agency). The inter-local agency collaborative venture then set about building an “open access” fiber network that allows any ISP to then come and compete on the shared network. </p>
<p>As we’ve noted over the years, regional monopolies like Qwest (now Centurylink or Lumen) didn’t much like that. They desperately tried to <a href="https://www.deseret.com/2005/7/22/19903471/utopia-responds-to-qwest-lawsuit/">sue and harass the network out of existence</a> in the early aughts, claiming the concept violated numerous local laws (it didn’t). These efforts failed, in part, because of widespread support among a public extremely tired of being ripped off by shitty monopolies. </p>
<p>Two decades later and the coalition <a href="https://www.utopiafiber.com/2024/05/08/utopia-fiber-adds-three-new-residential-internet-service-providers-to-its-open-access-network/">just announced</a> that 18 different ISPs now compete for Utah resident attention over a network that now covers 21 different Utah cities. In many instances, ISPs on the network are offering symmetrical (uncapped) gigabit fiber for as little as $45 a month (plus $30 network connection fee, so $75). Some ISPs are even offering symmetrical <strong>10 Gbps fiber for around $150 a month</strong>:</p>
<blockquote>
<p><em>“Sumo Fiber, a veteran member of the UTOPIA Open Access Marketplace, is now offering 10 Gbps symmetrical for $119, plus a $30 UTOPIA Fiber infrastructure fee, bringing the total cost to $149 per month.”</em></p>
</blockquote>
<p>It’s a collaborative hybrid that blurs the line between private companies and government, and it works. And the prices being offered here are significantly less than locals often pay in highly developed tech-centric urban hubs like New York, San Francisco, or Seattle. </p>
<p>Yet giant local ISPs like Comcast and Qwest spent decades trying to either sue this network into oblivion, or using their proxy policy orgs (like the “<a href="https://mail.communitynets.org/content/utopia-confronts-critics-continues-new-strategy">Utah Taxpayer Association</a>“) to falsely claim this effort would end in chaos and inevitable taxpayer tears. Yet miraculously UTOPIA is profitable, and for the last 15 years, every UTOPIA project has been paid for completely through subscriber revenues.</p>
<p>As other Utah cities have considered following suit, those same local monopolies have created dark money campaigns and even <a href="https://www.techdirt.com/2022/07/12/charters-running-a-fake-consumer-group-in-maine-thats-killing-community-broadband-with-the-help-of-a-democratic-advisor/">fake consumer groups</a> to <a href="https://www.techdirt.com/2024/01/18/telecom-monopolies-are-once-again-funding-covert-sleazy-local-attacks-on-community-broadband-networks/">lie to locals that such efforts are still inevitable government boondoggles</a>. Such sleazy lobbying campaigns are cheaper than actually competing or building the kind of networks these locals have spent several decades clamoring for. </p>
<p>For years, real world experience and <a href="https://www.techdirt.com/2020/12/04/benton-study-again-shows-how-open-access-broadband-networks-can-drive-competition-improve-service/">several</a> different <a href="https://transition.fcc.gov/stage/pdf/Berkman_Center_Broadband_Study_13Oct09.pdf">studies</a> and reports (including see our <a href="https://copia.is/library/just-a-click-away/">Copia study on this concept</a>) have made it clear that open access networks and policies result in faster, better, more affordable broadband access. UTOPIA is proving it at scale, but numerous other municipalities have been following suit with the help of COVID relief and infrastructure bill funding. </p>
<p>Sometimes such networks are owned by local governments. Sometimes they’re community-owned cooperatives. Sometimes they’re the extension of the local city-owned utility. Sometimes they’re built on the back of public/private partnerships.</p>
<p>According to a&nbsp;<a href="https://communitynets.org/content/community-network-map">database</a>&nbsp;of such networks tracked by the Institute For Local Self Reliance (which I have done research and writing work for), there are now 450 municipal broadband networks in the U.S. Since January 1, 2021, at least 47 new networks have come online, with dozens in the planning or pre-construction phases. And this may be an undercount given the FCC’s failure to track them all.</p>
<p>But because big monopolies (and a bunch of Libertarian think tankers with covert financial ties to those same monopolies) didn’t like the idea for ideological or financial reasons, federal and state policymakers have vacillated between demonizing the idea of municipal broadband, or banned it entirely (17 states <a href="https://broadbandnow.com/report/municipal-broadband-roadblocks#:~:text=17%20states%20currently%20have%20laws,operating%20municipal%20networks%20more%20difficult.">currently prohibit such networks</a>, and House Republicans attempted <a href="https://www.techdirt.com/2021/02/19/new-bill-tries-to-ban-community-broadband-during-pandemic/">a federal ban during COVID</a>). </p>
<p>Again, this could have all been prevented if big ISPs like AT&amp;T, Comcast, Verizon, CenturyLink and others had actually delivered the affordable, ultra-fast access Americans have demanded for decades. It could have been avoided if they’d embraced competition. It could have been avoided if they’d <a href="https://mountainstatespotlight.org/2020/12/09/frontier-has-sucked-up-millions-before-without-giving-w-va-good-broadband-theyre-about-to-get-another-chance/">properly used</a> the <a href="https://www.techdirt.com/2020/06/22/att-has-now-eliminated-41000-jobs-since-42-billion-trump-tax-cut/">untold billions</a> in taxpayer subsidies they’ve received over the last thirty years to expand access. </p>
<p>Community and municipal broadband sees widespread bipartisan support. It’s an organic, highly local, response to decades of corruption and market failure these companies enabled at every step of the way. Any impact it has on regional telecom monopolies was entirely earned on the back of decades of hubris and greed.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/broadband/" rel="tag">broadband</a>, <a href="https://www.techdirt.com/tag/community-broadband/" rel="tag">community broadband</a>, <a href="https://www.techdirt.com/tag/fiber/" rel="tag">fiber</a>, <a href="https://www.techdirt.com/tag/high-speed-internet/" rel="tag">high speed internet</a>, <a href="https://www.techdirt.com/tag/municipal-broadband/" rel="tag">municipal broadband</a>, <a href="https://www.techdirt.com/tag/open-access/" rel="tag">open access</a>, <a href="https://www.techdirt.com/tag/telecom/" rel="tag">telecom</a>, <a href="https://www.techdirt.com/tag/utah/" rel="tag">utah</a>, <a href="https://www.techdirt.com/tag/utopia/" rel="tag">utopia</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSD death, tricky read-only filesystems, and systemd magic? (156 pts)]]></title>
            <link>https://rachelbythebay.com/w/2024/05/15/ro/</link>
            <guid>40372317</guid>
            <pubDate>Wed, 15 May 2024 21:02:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2024/05/15/ro/">https://rachelbythebay.com/w/2024/05/15/ro/</a>, See on <a href="https://news.ycombinator.com/item?id=40372317">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2024/05/15/ro/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Making a Postgres query 1k times faster (207 pts)]]></title>
            <link>https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/</link>
            <guid>40372296</guid>
            <pubDate>Wed, 15 May 2024 21:00:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/">https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/</a>, See on <a href="https://news.ycombinator.com/item?id=40372296">Hacker News</a></p>
Couldn't get https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/: Error: Parse Error: Header overflow]]></description>
        </item>
        <item>
            <title><![CDATA[A 'plague' comes before the fall: lessons from Roman history (180 pts)]]></title>
            <link>https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/</link>
            <guid>40371785</guid>
            <pubDate>Wed, 15 May 2024 20:11:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/">https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/</a>, See on <a href="https://news.ycombinator.com/item?id=40371785">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span><img width="1024" height="720" src="https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1024x720.png" alt="Colosseum." title="roman ruins" decoding="async" loading="lazy" srcset="https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1024x720.png 1024w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-300x211.png 300w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-768x540.png 768w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1536x1080.png 1536w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-526x370.png 526w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px">The ruins of the Colosseum in Rome. Credit: Livioandronico2013. CC BY-SA 4.0.</span></p><div><p>The <em>Pax Romana—</em>the 200-year “<a href="https://open.spotify.com/show/2v1yIKNR3jiV94tGi0g5ot">golden age</a>” of the Roman Empire—was a marvel of diversity, connectivity, and unchallenged hegemony. By the middle of the second century AD, imperial Rome ruled territory across three different continents. Roughly one-quarter of the Earth’s population, some 60 million people, lived under Rome’s vast aegis, and the emperors of the age—most notably Marcus Aurelius—enjoyed the consent of those they governed. The Empire’s elites—witnessing the disciplined legions, widespread religiosity, cultural efflorescence, and dominant economy—likely expected their world order to endure forever.</p>
<p>In the year 166 AD, however, seemingly eternal Rome was caught completely off-guard as a deadly novel disease swept across the Eurasian landmass. It ransacked Rome’s cities for at least a decade and preceded centuries of decline. This major biological event—now known as the Antonine plague—appears to have been <a href="https://www.amazon.com/Pox-Romana-Turning-Ancient-History/dp/069121915X">the world’s first pandemic</a>.</p>
<p>Historians hotly debate its death toll—with estimates ranging from 2 percent to 35 percent mortality—and its broader social and economic effects. The disease itself remains undiagnosed. The great Greek physician Galen described its main symptoms as fever, throat ulcers, and a pustular rash. Some have suspected it was measles or smallpox, but <a href="https://www.cambridge.org/core/journals/journal-of-roman-archaeology/article/smallpoxs-antiquity-in-doubt/B15B505D959E90824B6B9DCFAB1FA124">modern analysis</a> provides reasons to doubt these as the possible culprits. Human remains from the Antonine plague period, meanwhile, have thus far failed to yield genetic evidence sufficient to identify the pathogen.</p>
<p>Although the plague did not on its own cut short Rome’s dominance, it struck an empire that was confronting multiple challenges beneath a veneer of prosperity and growth—factors that modern-day infectious disease experts might recognize as creating the ideal conditions for pandemics. Much remains unknown about the Antonine plague; in some ways, modern scholars are just as in the dark about this first pandemic as its contemporary victims. But interdisciplinary researchers, trying to understand how the plague could have helped push such a powerful empire to the breaking point, have recently been unravelling some of its mysteries.</p><div id="thebu-623384653"><p><a data-no-instant="1" href="https://thebulletin.org/magazine/2024-05/?utm_source=Website&amp;utm_medium=MobileMediumRectangle&amp;utm_campaign=Website_MayMagazine_05072024&amp;utm_content=ClimateChange_MayMagazine_05072024" rel="noopener" target="_blank" aria-label="2024 May Magazine – Mobile Medium Rectangle"><img loading="lazy" decoding="async" src="https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle.png" alt="" srcset="https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle.png 1250w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-300x250.png 300w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-1024x854.png 1024w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-768x640.png 768w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-444x370.png 444w" sizes="(max-width: 1250px) 100vw, 1250px" width="300" height="250"></a></p></div>
<p><strong>Probing the plague</strong>. Historians, archaeologists, and scientists have been sharing data and expertise, working together to develop histories of past pandemics—including the Antonine plague—that are surprisingly comprehensive and nuanced. Paleogenetic and paleoclimatological evidence reveal the crucial role of environmental and demographic factors in the pandemic. Insights from modern economics and sociology have improved historians’ understanding of how the institutions of the Roman Empire were affected by disease mortality. Even before the pandemic arrived, the pre-existing ecological, economic, and demographic context of mid-second century Eurasia prepared the way for the disease that would accelerate the end of Rome’s era of efflorescence.</p>
<p>Research assessing the severity of modern anthropogenic climate change, for example, has compiled a vast array of climatological data dating back to the Roman period, and well before. Such research offers historians an increasingly detailed and <a href="https://link.springer.com/chapter/10.1007/978-3-030-81103-7_13">comprehensive view</a> of the ecosystems of ancient Eurasia and Africa. The ancient Mediterranean was (and still is) polka-dotted with microclimates; meanwhile, <a href="https://www.pnas.org/doi/10.1073/pnas.1721818115">ice cores</a> from Greenland, <a href="https://www.nature.com/articles/s41561-021-00698-0">ancient tree rings</a> from northern Europe, and <a href="https://www.sciencenews.org/article/roman-empire-cold-climate-plague-archaeology">sediment cores</a> from Egypt and Italy suggest that some regions in and around Roman territory endured cooler temperatures and droughts about a decade ahead of the Antonine plague pandemic. These climatological shifts were hardly severe, nor did they affect the entire Mediterranean Basin. Many of the affected regions, however, happened to play outsized roles in supplying Roman cities with grain.</p>
<p>The annual Nile flood in Egypt, for instance, reliably nourished well-irrigated grainfields with nutrient-rich water from the Ethiopian highlands. The resulting harvests, often abundant, were stored and then shipped in massive vessels across the Mediterranean to Rome for distribution to the city’s masses. But from the 150s onward, a series of droughts near the Nile headwaters in equatorial east Africa disrupted the flood, reducing the productivity of Rome’s main breadbasket. Meanwhile, at the same time, increased storm activity in the western Mediterranean—as confirmed by sediment cores extracted from the coast of southern France—made shipping already scarce grain far riskier than in previous centuries. As a result, denizens of Rome and several other major cities, and possibly also some of Rome’s soldiers, endured greater food insecurity and malnutrition—weakening their bodies ahead of the pandemic’s arrival in the 160s.</p>
<p><strong>An interconnected, vulnerable ancient world.</strong> Historians still don’t know exactly where and when the pandemic entered Roman territory. But, again, historical circumstances conspired in favor of the novel disease.</p>
<p>An outbreak today can <a href="https://www.cell.com/trends/parasitology/fulltext/S1471-4922(18)30142-9#%20">jump continents</a> as quickly as an airplane can fly. Travel and transportation can facilitate the spread of infectious diseases. It may not be coincidental, therefore, that by the time of the Antonine plague, the Eurasian landmass was better-connected than ever before. In 166 AD, for the first time in recorded history, the imperial Han court in Luoyang, China, received visitors from the Roman Empire. Merchants from India, sub-Saharan Africa, Arabia, and Egypt rode the trade winds to ports all around the Indian Ocean. Roman soldiers, seeking to police and tax such abundant trade, ventured well outside Roman borders—as Latin inscriptions in the Farasan Islands of southern Arabia attest. In short, there were plenty of opportunities for novel diseases to cross political and geographic barriers into new populations, transforming what might have otherwise been a regional epidemic into a pandemic that spread across three different continents.</p>
<p>In the Roman Empire, an impressive transportation infrastructure—once a source of economic and military power—became a sudden liability once the pandemic breached its borders. Roman roads and ships weren’t themselves responsible, but larger movements and migrations transported the disease from city to city.</p>
<p>Because of the shifts in local climates, and resulting food insecurity, desperate and hungry rural peasants had already flooded into cities in Asia Minor (present day Turkey) and Italy. Beyond Roman borders, nomadic peoples on the Eurasian Steppe in search of food pushed against the Germanic tribes along the Danube River, sending hordes of migrants and invaders into Roman frontier provinces. Contemporary sources from the Han Empire reference a series of epidemics in several Chinese cities, as well as the army. Concerns over ever-present sickness were partly responsible for the famed <a href="https://www.britannica.com/topic/Yellow-Turbans#ref268958">Yellow Turban Rebellion</a>—a peasant rebellion that unleashed decades of civil war and instability in much of eastern China.</p>
<p>At the exact same time, tens of thousands of Roman soldiers were uprooted from their military bases and sent thousands of miles—first to fight a war on the Empire’s eastern frontier in Persia (Iran), then back into Europe to resist the surging tide of Germanic migrants. At multiple points along these journeys, soldiers could have collected the Antonine plague pathogen.</p>
<p><strong>The plague and the capital.</strong> Rome’s large legions might have sustained disease transmission for weeks, if not months, as armies passed back-and-forth through the same densely populated cities of Asia Minor and Italy that were taking on underfed refugees from the budding crisis.</p>
<p>None of these cities, however, were as packed as Rome—a cosmopolis of over one million people. In October of 166 AD, just as the pandemic reached Italy, the city held a massive triumphal parade for the legions, fresh off their victory in Persia. Perhaps 100,000 or more citizens crammed into the city center to celebrate, creating what may have been the world’s first super-spreader event.</p>
<p>Shortly following the triumph, the streets of Rome must have resembled a war zone. Bodies were so strewn about the city that Marcus Aurelius and his co-emperor imposed strict regulations on burials and tombs. They funded corpse removal. They sought out the gods for aid. At some point, perhaps after the first wave abated, the emperors commissioned statues to memorialize elite victims, while the masses were commemorated in remembrance events.</p>
<p>The ancient Romans had limited means to treat the Antonine plague, although they developed many remedies of unknown or suspect effectiveness. Elites, including the emperor Marcus Aurelius, used a concoction called “theriac”—an aged blend of exotic spices and expensive substances, mixed with a dose of opium. Others tried various smell therapies—including smelling laurel leaves. Galen claimed that fresh urine applied directly to the skin could help—the younger the urinator, the better.</p>
<p>The Antonine plague would continue to rage in the cities and military camps of the Roman Empire for at least another decade. A second wave of an undiagnosed epidemic disease hit Rome in 190 AD; if this too was part of the Antonine plague, then the pandemic lasted at least a quarter-century. However long it endured, the plague was an unprecedented test the resilience of Roman systems; Galen named it “the everlasting pestilence.”</p>
<p>Marcus may have rallied Rome during the first wave. But when the plague struck northern Italy a few years later, he abandoned his friends and soldiers to a dark winter of sickness. Officials responded to drought and high grain prices with price controls, most likely disincentivizing production and making shortages even worse. In response to plague and war deaths in the legions, Marcus recruited criminals and slaves into the military. This proved fateful when, a few years later, many of them deserted and, now well-equipped and trained, turned on the cities of the Empire, pillaging and murdering in a crime wave that stretched from Asia Minor to western Europe.</p>
<p>While it might seem like the pandemic single-handedly caused the decline and fall of the Roman Empire, it was clearly more complicated than that. The western Roman Empire would muddle along for over 200 years, but its heyday ended with the Antonine plague. The plague exposed and exacerbated pre-existing fragilities. Many Roman achievements may have been grand, but the Empire was a product of its pre-industrial context, in which weather, famine, and other factors could be destabilizing. The agricultural economy was subject to the vagaries of its ecosystem and the limitations of fledgling markets. Roman cities, for all the attention paid to aqueducts and baths, were contaminated by poor sanitation and grappled with persistent malnutrition. They may have been temporarily well-connected enough to enjoy the commodities of distant regions, but these same populations were simultaneously “immunologically naive” to pathogens from outside their immediate area. While it is no coincidence that the pandemic and the end of the <em>Pax Romana</em> occurred at the same time, exploring the connections between them underscores the interconnectedness and even interdependence of past human societies and their environmental contexts.</p>
<p>Present societies now easily mitigate much of what ailed Rome during the Antonine plague. The wonders of modern medicine—treatments, vaccines, and proven sanitation measures—render once-deadly scourges innocuous or even eradicated. A globalized society is one which collaborates and coordinates—orienting markets, scientific research, and communication channels towards responding to threats and, even better, predicting and preventing them before they occur. And yet, like the Roman Empire, the strengths of the modern world order have inbuilt weaknesses. Travel and transportation are so cheap and easy that pandemic diseases seem virtually impossible to contain.</p>
<p>The collaborative process that permeates most democratic societies nevertheless requires seemingly slow and cumbersome debate and consensus building. Yet all told, the modern world’s capacity to understand and adapt to our natural context—clumsy as it is at times—so far continues to outpace the rapidly evolving diseases that surround us. A vital part of our strategy must be to <a href="https://thebulletin.org/2023/01/deadliest-pandemics/">learn from</a> the pandemics of the past.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What’s the difference between an -ectomy, an -ostomy, and an -otomy? (1986) (223 pts)]]></title>
            <link>https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy</link>
            <guid>40371650</guid>
            <pubDate>Wed, 15 May 2024 20:01:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy">https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy</a>, See on <a href="https://news.ycombinator.com/item?id=40371650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <main data-module="" data-padding="none" data-width="full-constrained">

                

                
                    
                

                <div>
                                    <div data-align-center="">
            <blockquote><p>Dear Cecil: In medicine, what’s the difference between an "-ectomy,” an "-ostomy,” and an "-otomy”? My wife believes they mean “hack it off,” “bite it off,” and “pinch it till it drops off.” J.W., Chicago</p></blockquote>

            
        </div>
<div data-crop="large-2x1-notfixed" data-align-floatright="">
            
            
                
                    
                        
                            <figure><a id="image-variant-700001" name="image-variant-700001" data-cms-ai="0"></a>
        <picture data-crop="large-2x1-notfixed">
    
            
                

            
        

        
        
            
    
            <source type="image/webp" width="840" height="608" data-srcset="https://cst.brightspotcdn.com/dims4/default/c57efe7/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/format/webp/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 1x,https://cst.brightspotcdn.com/dims4/default/55bb77a/2147483647/strip/true/crop/300x217+0+0/resize/1680x1216!/format/webp/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 2x" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

    

    
        <source width="840" height="608" data-srcset="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

    


        
        
    <img alt="861219.gif" srcset="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 1x,https://cst.brightspotcdn.com/dims4/default/b0693d6/2147483647/strip/true/crop/300x217+0+0/resize/1680x1216!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 2x" width="840" height="608" data-src="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

</picture>

    

    
        <div><p>Illustration by Slug Signorino</p></div>
    
</figure>

                        
                    
                
            
        </div><p>Cecil replies:</p><p>Very funny, J.W., and actually not all that far off the mark. Turning to <i>Taber’s Cyclopedic Medical Dictionary,</i> which for an old deve like me is a constant garden of delight, we learn the following:</p><ul><li>An “-ectomy” is the cutting out of something, as in “tonsillectomy.” In other words, hacking it off. This may account for lingering male squeamishness about another well-known operation, the vasectomy. (In reality, of course, only a tiny portion of the vas deferens is removed.)</li><li>An “-ostomy” (actually, “-stomy”) involves cutting a hole in something, or more precisely, furnishing it with a mouth or outlet, as in “colostomy,” in which an opening is cut into the colon to create an artificial anus. (Seems like a waste, considering how many real ones there are already.)</li><li>Finally, there’s “-otomy,” (or “-tomy”), which means to slice it up, i.e., an operation in which cutting is involved. Thus we can distinguish a lobectomy, in which a lobe, typically of the brain, is removed, from a lobotomy, in which they merely jab an ice pick in there and chop things up.</li></ul><p>I’m not kidding, either. You might want to read an engrossing volume entitled <i>Great and Desperate Cures: The Rise and Decline of Psychosurgery and Other Radical Treatments for Mental Illness,</i> by Elliott Valenstein (1986). Valenstein quotes a letter written in the mid-1940s by one prominent lobotomist, Walter Freeman:</p><div data-align-center="">
            <blockquote><p>I have also been trying out a sort of half-way stage between electroshock and prefrontal lobotomy [to treat mental patients]. … This consists of knocking them out with a shock and while they are under the ‘anesthetic’ thrusting an ice pick up between the eyeball and the eyelid through the roof of the orbit [the bony cavity that contains the eye] actually into the frontal lobe of the brain and making the lateral cut by swinging the thing from side to side. I have done two patients on both sides and another on one side without running into any complications, except a very black eye in one case. There may be trouble later on but it seemed fairly easy, although definitely a disagreeable thing to watch. It remains to be seen how these cases hold up, but so far they have shown considerable relief of their symptoms, and only some of the minor behavior difficulties that follow lobotomy. [That is, prefrontal lobotomy, which typically involved boring holes through the front of the skull. The ice pick operation is called a transorbital lobotomy.] They can even get up and go home within an hour or so. If this works out it will be a great advance for people who are too bad for shock but not bad enough for surgery.</p></blockquote>

            
        </div>
<p>Freeman went around the country in the late 1940s demonstrating this technique in mental hospitals. These exhibitions reportedly went well for the most part, except on those occasions when the patient bled too much or the ice pick broke off within the orbit or inside the skull. To remedy this problem, the ice pick was later replaced with a sturdier instrument and an ordinary carpenter’s hammer was used to drive it into the brain.</p><p>The first lobotomy in the United States took place on September 14, 1936. By August 15, 1949, the procedure had been performed 10,706 times. In the mid-1950s the popularity of the operation waned due to the availability of psychotropic drugs, which offered similar benefits without the trauma. One hopes today the practice is extinct, but you never know.</p><p>My point in telling this story is that you’re right to regard -otomies, -ectomies and so on with some skepticism. The majority of medical professionals performing such techniques help their patients, but a few are just mopes with icepicks. The challenge is telling the two apart.</p><p>Cecil Adams</p><p>Send questions to Cecil via <a href="mailto:cecil@straightdope.com" target="_blank" data-cms-ai="0">cecil@straightdope.com.</a><br></p></div>

                

                
                    
                

                
            </main>

        
            
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New exponent functions that make SiLU and SoftMax 2x faster, at full accuracy (354 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/7154</link>
            <guid>40371612</guid>
            <pubDate>Wed, 15 May 2024 19:57:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/7154">https://github.com/ggerganov/llama.cpp/pull/7154</a>, See on <a href="https://news.ycombinator.com/item?id=40371612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          
<p dir="auto">📈 <strong>llama.cpp server</strong> for <em>bench-server-baseline</em> on <em>Standard_NC4as_T4_v3</em> for <code>phi-2</code>-<code>q4_0</code>: <strong>543 iterations</strong> 🚀</p>

<details>
<summary>Expand details for performance related PR only</summary>
<ul dir="auto">
<li>Concurrent users: 8, duration: 10m</li>
<li>HTTP request          : avg=8626.19ms        p(95)=21696.44ms fails=, finish reason: stop=474 truncated=69</li>
<li>Prompt processing (pp): avg=94.59tk/s p(95)=412.43tk/s</li>
<li>Token generation  (tg): avg=33.43tk/s p(95)=48.33tk/s</li>
<li>ggml-org/models/phi-2/ggml-model-q4_0.gguf parallel=8 ctx-size=16384 ngl=33 batch-size=2048 ubatch-size=256 pp=1024 pp+tg=2048 branch=expf commit=d7359a389c236193edac1c8761e6ac98844654f3</li>
</ul>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/db33b06dd0cfe99d55bf162b4fee930601203d12bb1550d983bb5cb1ebb5c54c/68747470733a2f2f692e696d6775722e636f6d2f51317462364a662e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/db33b06dd0cfe99d55bf162b4fee930601203d12bb1550d983bb5cb1ebb5c54c/68747470733a2f2f692e696d6775722e636f6d2f51317462364a662e6a706567" alt="prompt_tokens_seconds" data-canonical-src="https://i.imgur.com/Q1tb6Jf.jpeg"></a>
</p><details>
<summary>More</summary>
<section data-identity="5ec07373-0b36-431e-8ec5-bb63a70b2153" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:prompt_tokens_seconds\&quot;\n    x-axis \&quot;llamacpp:prompt_tokens_seconds\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:prompt_tokens_seconds&quot;
    x-axis &quot;llamacpp:prompt_tokens_seconds&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:prompt_tokens_seconds"
    x-axis "llamacpp:prompt_tokens_seconds" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/52c5e5809cf979690fcb6f4cd9dd7a4ee43655b91e2bf1d56d07c2091ec26711/68747470733a2f2f692e696d6775722e636f6d2f6a355857356f6c2e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/52c5e5809cf979690fcb6f4cd9dd7a4ee43655b91e2bf1d56d07c2091ec26711/68747470733a2f2f692e696d6775722e636f6d2f6a355857356f6c2e6a706567" alt="predicted_tokens_seconds" data-canonical-src="https://i.imgur.com/j5XW5ol.jpeg"></a>
<details>
    <summary>More</summary>
<section data-identity="95c07a72-b7e4-4a9e-9a0d-e0cea47fd8ec" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:predicted_tokens_seconds\&quot;\n    x-axis \&quot;llamacpp:predicted_tokens_seconds\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:predicted_tokens_seconds&quot;
    x-axis &quot;llamacpp:predicted_tokens_seconds&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:predicted_tokens_seconds"
    x-axis "llamacpp:predicted_tokens_seconds" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>

<details>
<summary>Details</summary>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c9c7c8cc87ce6595e66b8f760299af0e170c7718acc0145d5efd7eb8654bd031/68747470733a2f2f692e696d6775722e636f6d2f7a396c315a72522e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/c9c7c8cc87ce6595e66b8f760299af0e170c7718acc0145d5efd7eb8654bd031/68747470733a2f2f692e696d6775722e636f6d2f7a396c315a72522e6a706567" alt="kv_cache_usage_ratio" data-canonical-src="https://i.imgur.com/z9l1ZrR.jpeg"></a>
</p><details>
    <summary>More</summary>
<section data-identity="0f6a0084-7712-4327-848a-d3aa4e03e368" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:kv_cache_usage_ratio\&quot;\n    x-axis \&quot;llamacpp:kv_cache_usage_ratio\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:kv_cache_usage_ratio&quot;
    x-axis &quot;llamacpp:kv_cache_usage_ratio&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:kv_cache_usage_ratio"
    x-axis "llamacpp:kv_cache_usage_ratio" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3942f2339f91c1f1f38e2fc6e9b2dd0e52c45e7aa773079744af1ded0d55bc98/68747470733a2f2f692e696d6775722e636f6d2f7a6b396d316b422e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/3942f2339f91c1f1f38e2fc6e9b2dd0e52c45e7aa773079744af1ded0d55bc98/68747470733a2f2f692e696d6775722e636f6d2f7a6b396d316b422e6a706567" alt="requests_processing" data-canonical-src="https://i.imgur.com/zk9m1kB.jpeg"></a>
<details>
    <summary>More</summary>
<section data-identity="1dc42fc3-a67b-42cc-9e43-8195101d631a" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:requests_processing\&quot;\n    x-axis \&quot;llamacpp:requests_processing\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:requests_processing&quot;
    x-axis &quot;llamacpp:requests_processing&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:requests_processing"
    x-axis "llamacpp:requests_processing" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>

</details>
</details>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a Mac app to search my images and videos locally with ML (180 pts)]]></title>
            <link>https://desktopdocs.com</link>
            <guid>40371467</guid>
            <pubDate>Wed, 15 May 2024 19:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://desktopdocs.com">https://desktopdocs.com</a>, See on <a href="https://news.ycombinator.com/item?id=40371467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper"><p><span><img src="https://desktopdocs.com/assets/images/image01.png?v=f388f0c3" alt=""></span></p><hr id="divider03"><div id="container01"><h2 id="text01">We make it easy to work with your files</h2><p id="text03">Desktop Docs is the all-in-one platform to browse, edit, and export your media files.</p></div><hr id="divider10"><ul id="buttons01"><li><a href="#start"><svg aria-labelledby="icon-title"><title id="icon-title">Chevron Down</title><use xlink:href="#icon-539e8a7dd31ef103fa8a43b109673d75"></use></svg><span>Learn more</span></a></li></ul><hr id="divider02"><div data-reorder="1,0" id="container02" data-scroll-id="start" data-scroll-behavior="center" data-scroll-offset="0" data-scroll-speed="5" data-scroll-invisible="1"><div><h2 id="text05">Do less admin work</h2><p id="text06"><span>Let AI do the boring work of searching your files.</span><span>With Desktop Docs, you can search images and videos by their actual content.</span></p></div><div><p><span><img src="https://desktopdocs.com/assets/images/image03.jpg?v=f388f0c3" alt="search your mac"></span></p></div></div><hr id="divider09"><ul id="buttons05"><li><a href="https://buy.stripe.com/7sIeY03KtgUtaDS002"><svg aria-labelledby="icon-title"><title id="icon-title">Chevron Right</title><use xlink:href="#icon-6f1498c47b5f47672990badd5a8b1884"></use></svg><span>Buy</span></a></li></ul><hr id="divider04"><div id="container06"><h2 id="text04">Create with your media</h2><p id="text11"><span>Desktop Docs has a built-in Studio to quickly edit and resize files.<p> Are you more of a pro video editor? Export images and video clips from search results right into Adobe Premiere for easy video editing.</p></span></p><p><span><img src="https://desktopdocs.com/assets/images/image06.jpg?v=f388f0c3" alt="edit video on mac"></span></p></div><hr id="divider13"><div id="container04"><h2 id="text07">Supercharge your search</h2><p id="text09">When you index your files with Desktop Docs' machine learning models, it will understand your files based on their content, including whatever is happening in your videos.</p><p><span><img src="https://desktopdocs.com/assets/images/image02.jpg?v=f388f0c3" alt=""></span></p></div><hr id="divider05"><div id="container05"><h2 id="text02">Frequently Asked Questions</h2><p id="text08"><span><strong>What's included when you purchase?</strong><br> After making a one time purchase of $24.99, we'll email you a download link for the Desktop Docs desktop application for Mac. That will let you install the app and start browsing your files!</span><span><strong>Is Windows supported?</strong><br> Not yet, but if you're interested in Windows send us an email and let us know. If enough people ask, we'll build it.</span><span><strong>Does Desktop Docs collect my data?</strong><br> No. The application does not collect any of your personal data. Anything that's indexed with our machine learning models stays on your computer and is never uploaded online.</span><span><strong>Who are you?</strong><br> We're Katrina and Brian, two engineers who love to create. We used to build products at Meta, Transmit, and Triplelift. Before that, we created software for small businesses and founders.</span><span><strong>Can I get a refund?</strong><br> Once you download Desktop Docs it's yours forever, so it's non-refundable. If you're unhappy with the purchase, contact us (email at the bottom of this page) and we'll work with you.</span></p></div><hr id="divider08"><ul id="buttons03"><li><a href="https://buy.stripe.com/7sIeY03KtgUtaDS002"><svg aria-labelledby="icon-title"><title id="icon-title">Chevron Right</title><use xlink:href="#icon-6f1498c47b5f47672990badd5a8b1884"></use></svg><span>Buy</span></a></li></ul><hr id="divider01"><div data-reorder="1,0" id="container03"><div><p><span><img src="https://desktopdocs.com/assets/images/image05.jpg?v=f388f0c3" alt=""></span></p></div><div><h2 id="text49">Built by creators</h2><p id="text10"><span>We're engineers and content creators.<p> Between photos in iPhones, chaotic downloads folders, and content stuck in social media platforms, we were tired of managing our files across applications.</p><p> We made Desktop Docs to browse everything in one place, save time organizing, and spend more time creating. We want to share it with creators to help everyone find more time to be creative.</p></span></p></div></div><hr id="divider07"><ul id="buttons02"><li><a href="https://buy.stripe.com/7sIeY03KtgUtaDS002"><svg aria-labelledby="icon-title"><title id="icon-title">Chevron Right</title><use xlink:href="#icon-6f1498c47b5f47672990badd5a8b1884"></use></svg><span>Buy</span></a></li></ul><hr id="divider06"><hr id="divider11"><ul id="icons01"><li><a href="mailto:katrina@golivecosmos.com"><svg aria-labelledby="icon-title"><title id="icon-title">Email</title><use xlink:href="#icon-c3c8e1063e3b7f84f6b54712741de139"></use></svg><span>Email</span></a></li><li><a href="https://itsthecreators.com/"><svg aria-labelledby="icon-title"><title id="icon-title">Substack</title><use xlink:href="#icon-05d74455b24f2bd787b0d36eb7d4debe"></use></svg><span>Substack</span></a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Gameface launches on Android (176 pts)]]></title>
            <link>https://developers.googleblog.com/en/project-gameface-launches-on-android/</link>
            <guid>40371401</guid>
            <pubDate>Wed, 15 May 2024 19:39:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/project-gameface-launches-on-android/">https://developers.googleblog.com/en/project-gameface-launches-on-android/</a>, See on <a href="https://news.ycombinator.com/item?id=40371401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
      
    

    

    

    <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Avneet+Singh">Avneet Singh</a>
            
              <span>Product Manager</span>
            
            
              <span>Google Partner Innovation</span>
            
          </p>
        
          
        

      
      </section>

    
    <div>
          

<div>
    <p data-block-key="yqqoj">At I/O 2023, we launched <a href="https://blog.google/technology/ai/google-project-gameface/">Project Gameface</a>, an open-source, hands-free gaming ‘mouse’ enabling people to control a computer’s cursor using their head movement and facial gestures. People can raise their eyebrows to click and drag, or open their mouth to move the cursor, making gaming more accessible.</p><p data-block-key="c8bt5">The project was inspired by the story of quadriplegic video game streamer Lance Carr, who lives with muscular dystrophy, a progressive disease that weakens muscles. And we collaborated with Lance to bring Project Gameface to life. The full story behind the product is available on the <a href="https://blog.google/technology/ai/google-project-gameface/">Google Keyword blog</a>.</p><p data-block-key="7k1tq">We’ve been delighted to see companies like <a href="https://www.playability.gg/">playAbility</a> utilize Project Gameface building blocks, like <a href="https://storage.googleapis.com/mediapipe-assets/Model%20Card%20Blendshape%20V2.pdf">MediaPipe Blendshapes</a>, in their inclusive software. Now, we’re open sourcing more code for Project Gameface to help developers build Android applications to make every Android device more accessible. Through the device's camera, it seamlessly tracks facial expressions and head movements, translating them into intuitive and personalized control. Developers can now build applications where their users can configure their experience by customizing facial expressions, gesture sizes, cursor speed, and more.</p><p data-block-key="ca2du">For this release, we collaborated with <a href="https://incluzza.org/">Incluzza</a>, a social enterprise in India that supports people with disability, to learn how Project Gameface can be expanded to educational, work and other settings, like being able to type messages to family or searching for new jobs.</p>
</div>    <div>
    <p data-block-key="yqqoj">While building Project Gameface for Android, we based our product design and development on three core principles:</p><ol><li data-block-key="9t5u7">Give people with disabilities a new additional means to operate Android devices.</li></ol><p data-block-key="drc1o">2. Build a cost-effective solution that’s generally available to enable scalable usage.</p><p data-block-key="64b54">3. Leverage the learnings and guiding principles from the first Gameface launch to make the product user-friendly and customizable.</p><h3 data-block-key="8dm8n"><b><br>Building out a cursor in an Android device</b></h3><p data-block-key="d9s6v">We are launching a novel way to start operating an Android device. Based on the positive feedback on Project Gameface, we realized that developers and users appreciated the idea of moving a cursor with head movement and taking actions through facial expressions.</p><p data-block-key="13v61">We have replicated the same idea to bring a new virtual cursor on an Android device. We are using the Android accessibility service to create a new cursor and are leveraging <a href="https://youtu.be/3NePkYhFkiw?si=dIk4396bp-kVXLQW">MediaPipe’s Face Landmarks Detection API</a> to program the cursor in a way so it moves according to a user’s head movement.</p><p data-block-key="1t503">Within the API, there are 52 face blendshape values which represent the expressiveness of 52 facial gestures such as raising left eyebrow or mouth opening. We use some of these 52 values to effectively map and control a wide range of functions, offering users expanded possibilities for customization and manipulation. We are also leveraging blendshapes coefficients which gives developers an ability to set different thresholds on each specific expression and this helps them customize the experience.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Project_Gameface_1_1_Nh0Y7zK.original.png" alt="Project Gameface visuals">
        
    </p>
</div>
  <div>
    <h3 data-block-key="yqqoj"><b>Bringing the best of Android Accessibility Service to Project Gameface</b></h3><h4 data-block-key="4dvo5"><i>Mobile actions</i></h4><p data-block-key="a18bh">In the Windows version for Project Gameface, we enabled users to replicate common click actions. However, in Android, there is a wider array of capabilities that users need to perform. There are touch events that are inputted into the OS and there are other global action events like “Go Back”, “Switch to Multitasking”, “Home”. We used the <a href="https://developer.android.com/reference/android/accessibilityservice/AccessibilityService">Android Accessibility API supported mobile actions</a> to determine which actions could be provided to the user. Currently, Project Gameface for Android supports GLOBAL_ACTION_HOME, GLOBAL_ACTION_BACK, GLOBAL_ACTION_NOTIFICATIONS, GLOBAL_ACTION_ACCESSIBILITY_ALL_APPS</p><h4 data-block-key="cl7e2"><i><br>Camera Feed</i></h4><p data-block-key="9ug6s">The camera feed significantly enhances the user experience, facilitating accurate threshold settings and a deeper comprehension of gestures. It also sends a clear signal to the user that their camera is being actively used to understand their head movements and gestures.</p><p data-block-key="a6p3">Just creating an overlay of camera feed would have prevented developers from accessing some important sections of their Android device like the Android settings. We use Android accessibility service with Project Gameface to enable the camera to continue floating even in Android settings and any other important sections of a user’s Android device.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Project_Gameface_1.original.png" alt="Project Gameface camera feed">
        
    </p>
</div>
  <div>
    <h3 data-block-key="yqqoj"><b>Enabling users to perform the ‘drag function’</b></h3><p data-block-key="2tps8">The Android accessibility service currently lacks a straightforward method for users to perform real-time interactive screen dragging. However, our product has been upgraded to include drag functionality, allowing users to define both starting and ending points. Consequently, the drag action will be executed seamlessly along the specified path.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-fux_2cpn_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/Project_Gameface_1_1.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
</div>  <div>
    <p data-block-key="yqqoj">We’re excited to see the potential of Project Gameface and can’t wait for developers and enterprises to leverage it to build new experiences. The code for Gameface is now <a href="https://github.com/google/project-gameface">open sourced on Github</a>.<b><br></b></p><hr><h3 data-block-key="fdlso"><b>Acknowledgements</b></h3><p data-block-key="fp8gp"><i><sub>We would like to acknowledge the invaluable contributions of the following people to Project GameFace for Android: Edwina Priest, Sisi Jin, KC Chung, Boon Panichprecha, Dome Seelapun, Kim Nomrak, Guide Pumithanon, Lance Carr, Communique Team (Meher Dabral,Samudra Sengupta), EnAble/Incluzza India (Shristi G, Vinaya C, Debashree Bhattacharya, Manju Sharma, Jeeja Ghosh, Sultana Banu, Sunetra Gupta, Ajay Balachandran , Karthik Chandrasekar</sub></i></p>
</div> 
      </div>
    

    

    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PaliGemma: Open-Source Multimodal Model by Google (118 pts)]]></title>
            <link>https://blog.roboflow.com/paligemma-multimodal-vision/</link>
            <guid>40371237</guid>
            <pubDate>Wed, 15 May 2024 19:24:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.roboflow.com/paligemma-multimodal-vision/">https://blog.roboflow.com/paligemma-multimodal-vision/</a>, See on <a href="https://news.ycombinator.com/item?id=40371237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://ai.google.dev/gemma/docs/paligemma?ref=blog.roboflow.com"><u>PaliGemma</u></a> is a vision language model (VLM) developed and released by Google that has <a href="https://blog.roboflow.com/multimodal-models/"><u>multimodal</u></a> capabilities.&nbsp;</p><p>Unlike other VLMs, such as <a href="https://blog.roboflow.com/gpt-4o-vision-use-cases/"><u>OpenAI’s GPT-4o</u></a>, <a href="https://blog.roboflow.com/gemini-what-we-know/"><u>Google Gemini</u></a>, and <a href="https://blog.roboflow.com/claude-3-opus-multimodal/"><u>Anthropic’s Claude 3</u></a> which have struggled with object detection and segmentation, PaliGemma has a wide range of abilities, paired with the ability to fine-tune for better performance on specific tasks. </p><p>Google’s decision to open source a highly capable multimodal model with the ability to fine-tune on custom data is a major breakthrough for open-source AI. PaliGemma gives you the opportunity to create custom multimodal models which you can self-host in the cloud and potentially on larger edge devices like NVIDIA Jetsons.</p><h2 id="what-is-paligemma">What is PaliGemma?</h2><p>PaliGemma, <a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/?ref=blog.roboflow.com"><u>released alongside other products</u></a> at the <a href="https://io.google/2024/?ref=blog.roboflow.com"><u>2024 Google I/O event</u></a>, is a combined multimodal model based on two other models from Google research: SigLIP, a vision model, and Gemma, a large language model, which means the model is a composition of a Transformer decoder and a Vision Transformer image encoder. It takes both image and text as input and generates text as output, supporting multiple languages. </p><p>Important aspects of PaliGemma:</p><ul><li>Relatively small 3 billion combined parameter model</li><li><a href="https://ai.google.dev/gemma/terms?ref=blog.roboflow.com"><u>Permissible commercial use terms</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>Ability to fine-tune</u></a> for image and short video caption, visual question answering, text reading, object detection, and object segmentation</li></ul><p>While PaliGemma is useful without fine-tuning, Google says it is “not designed to be used directly, but to be transferred (by fine-tuning) to specific tasks using a similar prompt structure” which means whatever baseline we can observe with the model weights is only the tip of the iceberg for how useful the model may be in a given context. <a href="https://ai.google.dev/gemma/docs/paligemma/model-card?ref=blog.roboflow.com#pre-train_datasets"><u>PaliGemma is pre-trained</u></a> on WebLI, CC3M-35L, VQ²A-CC3M-35L/VQG-CC3M-35L, OpenImages, and WIT.</p><h3 id="links-to-paligemma-resources">Links to PaliGemma Resources</h3><p>Google supplied ample resources to start prototyping with PaliGemma and we’ve curated the highest quality information for those of you who want to jump into using PaliGemma immediately. We suggest getting started with the following resources:</p><ul><li><a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/README.md?ref=blog.roboflow.com"><u>PaliGemma Github README</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma?ref=blog.roboflow.com"><u>PaliGemma documentation</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>PaliGemma fine-tuning documentation</u></a></li><li><a href="https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb?ref=blog.roboflow.com"><u>Fine-tune PaliGemma in Google Colab</u></a></li><li><a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/363?project=roboflow-marketing&amp;ref=blog.roboflow.com"><u>Access PaliGemma in Google Vertex</u></a></li></ul><p>In this post we will explore what PaliGemma can do, compare PaliGemma benchmarks to other LMMs, understand PaliGemma’s limitations, and see how it performs in real world use cases. We’ve put together learnings that can save you time while testing PaliGemma.</p><p>Let’s get started!</p><h2 id="what-can-paligemma-do">What can PaliGemma do?</h2><p>PaliGemma is a single-turn vision language model and it works best when fine-tuning to a specific use case. This means you can input an image and text string, such as a prompt to caption the image, or a question and PaliGemma will output text in response to the input, such as a caption of the image, an answer to a question, or a list of object bounding box coordinates.</p><p>Tasks PaliGemma is suited to perform relate to the <a href="https://ai.google.dev/gemma/docs/paligemma/model-card?ref=blog.roboflow.com#benchmark-results"><u>benchmarking results Google</u></a> released across the following tasks:</p><ul><li>Fine-tuning on single tasks</li><li>Image question answering and captioning</li><li>Video question answering and captioning</li><li>Segmentation</li></ul><p>This means PaliGemma is useful for straightforward and specific questions related to visual data.</p><p>We’ve created a table to show PaliGemma results relative to other models based on reported results on common benchmarks.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-6.png" alt="" loading="lazy" width="896" height="146" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-6.png 600w, https://blog.roboflow.com/content/images/2024/05/image-6.png 896w" sizes="(min-width: 720px) 720px"></figure><p>While benchmarks are helpful data points, they do not tell the entire story. PaliGemma is <strong>built to be fine-tuned</strong> and the other models are closed-source. For the purposes of showing which options are available, we compare against other, often much larger, models that are unable to be fine-tuned.</p><p>It is worth experimenting to see if fine-tuning with custom data will lead to better performance for your specific use case than out-of-the-box performance with other models.</p><p>Later in this post, we will compare PaliGemma to other <a href="https://blog.roboflow.com/gpt-4-vision-alternatives/"><u>open-source VLMs and LMMs</u></a> using a standard set of tests. Continue reading to see how it performs.</p><h2 id="how-to-fine-tune-paligemma">How to Fine-tune PaliGemma</h2><p>One of the exciting aspects of PaliGemma is its ability to finetune on custom use-case data. <a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>A notebook</u></a> published by Google’s PaliGemma team showcases how to fine-tune on a small dataset.</p><p>It’s important to note that in this example, only the attention layers are fine-tuned and therefore the performance improvements may be limited.</p><h2 id="how-to-deploy-and-use-paligemma">How to Deploy and Use PaliGemma</h2><p>You can deploy PaliGemma using an open-source <a href="https://inference.roboflow.com/?ref=blog.roboflow.com"><u>Inference package</u></a>. First, we will need to install Inference, as well as some other packages needed to run PaliGemma.</p><div><p>📓</p><div><p>See the PaliGemma inference notebook, which contains the code below </p><a href="https://colab.research.google.com/drive/1_q09OjR2Ldl1FZnvfqwckvxrW_FIYclC?usp=sharing&amp;ref=blog.roboflow.com"><u>here</u></a><p>.</p></div></div><pre><code>!git clone https://github.com/roboflow/inference.git
%cd inference
!pip install -e .</code></pre><pre><code>!pip install git+https://github.com/huggingface/transformers.git accelerate -q</code></pre><p>Next, we will set up PaliGemma by importing the module from Inference and putting in our <a href="https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com"><u>Roboflow API key</u></a>.</p><pre><code>import inference
from inference.models.paligemma.paligemma import PaliGemma

pg = PaliGemma(api_key="YOUR ROBOFLOW API KEY")</code></pre><p>Last, we can input a test image as a Pillow image, pair it with a prompt, and wait for the result.</p><pre><code>from PIL import Image

image = Image.open("/content/dog.webp") # Change to your image
prompt = "How many dogs are in this image?"

result = pg.predict(image,prompt)</code></pre><p>When prompted with this image, we get the accurate answer of&nbsp; `1`.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/dog.webp" alt="" loading="lazy" width="960" height="1280" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/dog.webp 600w, https://blog.roboflow.com/content/images/2024/05/dog.webp 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="paligemma-evaluation-for-computer-vision">PaliGemma Evaluation&nbsp;for Computer Vision</h2><p>Next, we will evaluate how PaliGemma does on various computer vision tasks that we’ve tested using <a href="https://blog.roboflow.com/gpt-4o-vision-use-cases/"><u>GPT-4o</u></a>, <a href="https://blog.roboflow.com/claude-3-opus-multimodal/"><u>Claude 3</u></a>, <a href="https://blog.roboflow.com/first-impressions-with-google-gemini/"><u>Gemini</u></a>, and other models.</p><p>Here, we will test several different use cases including optical character recognition (OCR), document OCR, document understanding, <a href="https://blog.roboflow.com/what-is-vqa/"><u>visual question answering</u></a> (VQA), and <a href="https://blog.roboflow.com/object-detection/"><u>object detection</u></a>.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-18.png" alt="" loading="lazy" width="909" height="168" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-18.png 600w, https://blog.roboflow.com/content/images/2024/05/image-18.png 909w" sizes="(min-width: 720px) 720px"></figure><h3 id="paligemma-for-optical-character-recognition-ocr">PaliGemma for Optical Character Recognition (OCR)</h3><p><a href="https://blog.roboflow.com/what-is-optical-character-recognition-ocr/"><u>Optical character recognition</u></a> is a computer vision task to return the visible text from an image in machine-readable text format. While its a simple task in concept, it can be a difficult task to accomplish in production applications.</p><p>Below we try OCR with both the prompts that we’ve seen work with other LMMs, asking it to “Read the serial number. Return the number with no additional text.” With this prompt, it failed, claiming that it did not have the training or capability to answer that question.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-7.png" alt="" loading="lazy" width="683" height="347" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-7.png 600w, https://blog.roboflow.com/content/images/2024/05/image-7.png 683w"></figure><p>However, we know from the model documentation that it should be capable of OCR. We tried with the example prompt provided in the documentation, `ocr`, where we got a successful, correct result. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-8.png" alt="" loading="lazy" width="686" height="341" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-8.png 600w, https://blog.roboflow.com/content/images/2024/05/image-8.png 686w"></figure><p>Trying with a different image with the first prompt also yielded correct results, bringing up a potential limitation of prompt sensitivity.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-9.png" alt="" loading="lazy" width="685" height="424" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-9.png 600w, https://blog.roboflow.com/content/images/2024/05/image-9.png 685w"></figure><p>Next, testing on an <a href="https://blog.roboflow.com/best-ocr-models-text-recognition/"><u>OCR benchmark</u></a> that we have used previously to test other OCR models like Tesseract, Gemini, Claude, GPT-4o and others, we saw very impressive results.&nbsp;</p><p>In average accuracy, we saw 85.84%, beating all other OCR models except for Anthropic’s Claude 3 Opus. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-10.png" alt="Average accuracy of all tested models, all except PaliGemma are cached results." loading="lazy" width="504" height="421"><figcaption><span>Average accuracy of all tested models, where all except PaliGemma are cached results. The graph labels on the right side are overlapped. They are Gemini 1.5, GPT-4o and PaliGemma in that order.</span></figcaption></figure><p>PaliGemma also achieved relatively fast speeds. Combined with the cheaper local nature of the model, PaliGemma seems to be the top OCR model in terms of speed efficiency and cost efficiency.</p><div><p>🗒️</p><p>Speed efficiency and cost efficiency, metrics introduced in the OCR benchmarking post, refer to a metric of accuracy given (divided by) time elapsed and cost incurred.</p></div><p>In median speed efficiency, it beats the previous leader, GPT-4o, set a day earlier when it was released, by a healthy margin. In terms of cost efficiency, PaliGemma outperformed the previous leader, EasyOCR, by almost three times, running more accurately and cheaper.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-11.png" alt="Median speed and cost efficiency of all tested models" loading="lazy" width="696" height="296" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-11.png 600w, https://blog.roboflow.com/content/images/2024/05/image-11.png 696w"><figcaption><span>Median speed and cost efficiency of all tested models, where all except PaliGemma are cached results. The graph labels on the right side are overlapped. They are Gemini 1.5, GPT-4o and PaliGemma in that order.</span></figcaption></figure><p>We consider these results to make PaliGemma a top OCR model given the local and more lightweight nature of PaliGemma compared to the models it beat, including the recently released GPT-4o, Gemini, and other OCR packages.</p><h3 id="document-understanding">Document Understanding</h3><p>Document understanding refers to the ability to extract relevant key information from an image, usually with other irrelevant text.</p><p>On an image with a receipt, we ask it to extract the tax paid according to the receipt. Here, PaliGemma gives a close but incorrect result consistently across several attempts.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-12.png" alt="" loading="lazy" width="691" height="486" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-12.png 600w, https://blog.roboflow.com/content/images/2024/05/image-12.png 691w"></figure><p>However, on an image with a pizza menu, when asked to provide the cost of a specific pizza, it returned a correct value. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-13.png" alt="" loading="lazy" width="690" height="510" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-13.png 600w, https://blog.roboflow.com/content/images/2024/05/image-13.png 690w"></figure><p>This performs similar or equivalent to the experience we had with GPT-4 with Vision, where it failed tax extraction but answered the pizza menu question correctly. Gemini, Claude 3 and the new GPT-4o did answer both questions correctly, as well as <a href="https://roboflow.com/compare/qwenvl-vs-gpt-4-vision?ref=blog.roboflow.com"><u>Qwen-VL-Plus</u></a>, an open-source VLM.</p><h3 id="visual-question-answering-vqa">Visual Question Answering (VQA)</h3><p>Visual Question Answering involves posing a model with an image and a question requiring some form of recognition, identification, or reasoning.</p><p>When posed with a question on how much money was present in a picture with 4 coins, it answered with 4 coins. A technically correct answer, but the question asked for the amount of money in the image.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-14.png" alt="" loading="lazy" width="686" height="485" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-14.png 600w, https://blog.roboflow.com/content/images/2024/05/image-14.png 686w"></figure><p>When tasked with identifying a scene featuring Kevin Mcallister from the movie Home Alone, it responded with “christmas”. We consider this to be an incorrect answer.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-15.png" alt="" loading="lazy" width="690" height="339" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-15.png 600w, https://blog.roboflow.com/content/images/2024/05/image-15.png 690w"></figure><h3 id="object-detection">Object Detection</h3><p>As we mentioned earlier, VLMs have traditionally struggled with object detection, much less instance segmentation. However, PaliGemma is reported to have object detection and instance segmentation abilities.</p><p>First, we test with the same prompt we have given other models in the past. Here, it returns an incorrect, likely hallucinated result.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-16.png" alt="" loading="lazy" width="691" height="479" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-16.png 600w, https://blog.roboflow.com/content/images/2024/05/image-16.png 691w"></figure><p>However, when prompting with the keyword `detect`, followed by the object `dog` (so `detect dog`) as detailed in the model documentation, it correctly and accurately identifies the dog in the image. Using the keyword `segment dog` also resulted in a correct segmentation.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-17.png" alt="" loading="lazy" width="632" height="419" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-17.png 600w, https://blog.roboflow.com/content/images/2024/05/image-17.png 632w"></figure><p>Although it is very impressive that a VLM is able to provide object detection and recognition capabilities, it is worth noting that only basic examples, such as those possible with a traditional object detection model, succeeded. When prompted to find cars, (there is a car present visible through the door of the building in the back) it returned no results.</p><h2 id="use-cases-for-paligemma">Use Cases for PaliGemma</h2><p>Whether using PaliGemma zero-shot or fine-tuned on custom data, there are specific use cases tailored to PaliGemma’s strengths that will open the door to new AI use cases. Let’s take a look at a two of them.</p><h3 id="custom-applications">Custom Applications</h3><p>Models like Claude 3, Gemini 1.5 Pro, and GPT-4o are used out-of-the-box and applied to problems they are suited to solve. PaliGemmi brings multimodal abilities to use cases that are still unsolved by closed-source models because you can fine-tune PaliGemma with proprietary data related to your problem. This is useful in industries like manufacturing, CPG, healthcare, and security. If you have a unique problem that closed-models have not seen, and will never see due to their proprietary nature, then PaliGemma is a great entry point into building custom AI solutions.&nbsp;</p><h3 id="ocr">OCR</h3><p>As shown earlier in this article, PaliGemma is a strong OCR model without any additional fine-tuning. When building OCR applications to scale to billions of predictions, latency, cost, and accuracy can be difficult to balance. Before PaliGemma, closed-source models were the best-in-class option for performance but their cost and lack of model ownership made them difficult to justify in production. This model can provide immediate performance and be improved over time by fine-tuning on your specific data.</p><h2 id="limitations-of-paligemma">Limitations of PaliGemma</h2><p>PaliGemma, and all VLMs, are best suited for tasks with clear instructions and are not the best tool for open-ended, complex, nuanced, or reason based problems. This is where VLMs are distinct from LMMs and you will find the best results if you use the models where they are most likely to perform well.</p><p>In terms of context, PaliGemma has information based on the pre-training datasets and any data supplied during fine-tuning. PaliGemma will not know information outside of this and, barring any weights updates with new data from Google or the open source community, you should not rely on PaliGemma as a knowledge base.</p><p>To get the most out of PaliGemma, and have a reason to use the model over other open source models, you’ll want to train the model on custom data. Its zero-shot performance is not state-of-the-art across most benchmarks. Setting up a custom training pipeline will be necessary to warrant using PaliGemma for most use cases.</p><p>Finally, during various tests, we saw drastic differences in results with slight changes to prompts. This is similar behavior to other LMMs, like <a href="https://blog.roboflow.com/yolo-world-prompting-tips/"><u>YOLO-World</u></a>, and takes time to understand how to best prompt the model. Changes in a prompt, like removing an ‘s’ to make a word singular rather than plural, can be the difference between a perfect detection and an unusable output.</p><figure><div><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png" width="1610" height="1054" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1610w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png" width="1688" height="946" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1688w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png" width="1804" height="1138" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1804w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><span>Notice the different results based on plural vs singular nouns</span></p></figcaption></figure><h2 id="conclusion">Conclusion</h2><p>Google’s release of PaliGemma is incredibly useful for the advancement of multimodal AI. The lightweight open source model built for fine-tuning means anyone can custom train their own large vision-language model and deploy it for any commercial purpose on their own hardware or cloud. </p><p>Previous LMMs have been extremely expensive to fine-tune and often require large amounts of compute to run, making them prohibitive for broad adoption. PaliGemma breaks the mold and offers people building custom AI applications a breakthrough model to create sophisticated applications.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LDAPjs decomissioned by maintainer over hateful email (103 pts)]]></title>
            <link>https://github.com/ldapjs/node-ldapjs</link>
            <guid>40370190</guid>
            <pubDate>Wed, 15 May 2024 17:53:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ldapjs/node-ldapjs">https://github.com/ldapjs/node-ldapjs</a>, See on <a href="https://news.ycombinator.com/item?id=40370190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Project Decomissioned</h2><a id="user-content-project-decomissioned" aria-label="Permalink: Project Decomissioned" href="#project-decomissioned"></a></p>
<p dir="auto">This project has been decomissioned. I, James Sumners, took it on when it was
languishing without any maintenance as it filled a need in the ecosystem and
I had built things at a prior organization that depended upon this project.
I spent a lot of time triaging issues and reworking things toward a path
that could be more easily maintained by a community of volunteers. But I have
not had the time to dedicate to this project in quite a while. There are
outstanding issues that would take me at least a week of dedicated development
time to solve, and I cannot afford to take time off of work to do that.
Particularly considering that the aforementioned organization was two
jobs ago, and it is extremely unlikely that I will transition to a role again
that will need this project.</p>
<p dir="auto">So, why am I just now deciding to decomission this project? Because today,
2024-05-14, I received the following email:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ldapjs/node-ldapjs/blob/master/dt.png"><img src="https://github.com/ldapjs/node-ldapjs/raw/master/dt.png" alt="Abusive email"></a></p>
<p dir="auto">I will not tolerate abuse, and I especially will not tolerate tacit death
threats, over a hobby. You can thank the author of that email for the
decomissioning on this project.</p>
<p dir="auto">My recommendation to you in regard to LDAP operations: write a gateway in a
language that is more suited to these types of operations. I'd suggest
<a href="https://go.dev/" rel="nofollow">Go</a>.</p>
<p dir="auto">👋</p>
<p dir="auto">P.S.: if I ever do need this project again, I might revive it. But I'd fight
hard for my suggestion above. Also, I will consider turning it over to an
interested party, but I will require at least one recommendation from a
Node.js core contributor that I can vet with the people that I know on that
team.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Blog: Android's theft protection features keep your device and data safe (185 pts)]]></title>
            <link>https://blog.google/products/android/android-theft-protection/</link>
            <guid>40369668</guid>
            <pubDate>Wed, 15 May 2024 17:12:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/android/android-theft-protection/">https://blog.google/products/android/android-theft-protection/</a>, See on <a href="https://news.ycombinator.com/item?id=40369668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>
        <video autoplay="" muted="" loop="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/blog_header_2.mp4" title="In an animation, a person steals someone’s unlocked phone. As the thief carries the phone away, it locks itself and a notification pops up: “Your device was auto-locked; a possible theft motion was detected.”" poster="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Theft_blog_hero_image_thumbnail.png">
          Sorry, your browser doesn't support embedded videos, but don't worry, you can
            <a href="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/blog_header_2.mp4">download it</a>
            and watch it with your favorite video player!
        </video>
      </p>
      
    </div><div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &quot;event&quot;: &quot;module_impression&quot;,
        &quot;module_name&quot;: &quot;ai_audio&quot;,
        &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
    }" data-date-modified="2024-05-15T17:10:55.384138+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><p data-block-key="el7di">Smartphones help us with everyday tasks like online banking, storing sensitive information, taking photos of our friends and families and quickly paying for stuff. While our phones make our lives easier, they also contain a lot of valuable information which makes these devices a target for people who might want to get their hands on our data.</p><p data-block-key="3r7mt">To help keep your device and your data safe before, during and after a theft attempt, we’re introducing a new suite of advanced theft protection features. These features will be rolling out through Google Play services updates later this year to the billions of devices running Android 10+, with some features available in Android 15.</p></div>
  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">1. Improved device and data protection to deter theft before it happens</h2><p data-block-key="2icmd">We're working to strengthen your device's security against theft with new and improved protection features that will make thieves think twice about trying.</p><p data-block-key="93f7b"><b>Factory reset upgrade prevents a reset by a thief.</b> For some criminals, the goal is to quickly reset your stolen device and resell it. We’re making it more difficult to do that with an upgrade to Android’s factory reset protection. With this upgrade, if a thief forces a reset of the stolen device, they’re not able to set it up again without knowing your device or Google account credentials. This renders a stolen device unsellable, reducing incentives for phone theft.</p><p data-block-key="48h9d"><b>Private space hides your sensitive apps.</b> Some thieves just want the device, but many aim to extract valuable data and transfer funds from your phone that can be worth much more than your hardware. Private space is a new feature that lets you create a separate area in your phone that you can hide and lock with a separate PIN, giving you additional security for apps that might contain sensitive data, like health or financial information.</p><p data-block-key="dnako"><b>More steps for changing sensitive device settings to protect your data.</b> Disabling Find My Device or extending screen timeout now requires your PIN, password or biometric authentication, adding an extra layer of security preventing criminals who got a hold of your device from keeping it unlocked or untrackable online.</p><p data-block-key="asfvs"><b>Increased authentication to protect you in case your PIN is known by a thief.</b> When enabled, our new enhanced authentication will require biometrics for accessing and changing critical Google account and device settings, like changing your PIN, disabling theft protection or accessing Passkeys, from an untrusted location.</p><p data-block-key="1ejes">Factory reset protection updates and private space will be released as part of Android 15. Enhanced authentication protections will be released to select devices later this year.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Protect_sensitive_settings_30fps.mp4" type="video/mp4" title="Animation showing a biometric screen when a user tries to turn off Find My Device.  Caption: Android will protect access to sensitive settings by requiring users to enter their  PIN or biometrics." alt="Protect sensitive settings">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Android will protect access to sensitive settings by requiring users to enter their PIN or biometrics.</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">2. Automatic protection the moment your phone is stolen</h2><p data-block-key="an4h1">Having a device stolen is unexpected and stressful and it can be hard to react quickly at the moment it happens. That’s why we created features that can automatically recognize suspicious signals and proactively protect your data on the device.</p><p data-block-key="3jaj2"><b>Automatic AI-powered screen lock for when your phone is snatched.</b> Theft Detection Lock is a powerful new feature that uses Google AI to sense if someone snatches your phone from your hand and tries to run, bike or drive away. If a common motion associated with theft is detected, your phone screen quickly locks – which helps keep thieves from easily accessing your data.</p><p data-block-key="7qjv1"><b>Added protection when a thief has your device.</b> If a thief tries to disconnect your phone for prolonged periods of time, Offline Device Lock automatically locks your screen to help protect your data even when your device is off the grid. Android can also recognize other signs that your device may be in the wrong hands. For example, it will lock your device screen when excessive failed authentication attempts are made.</p><p data-block-key="2p9na">Theft Detection Lock and Offline Device Lock will be available to Android 10+ devices through a Google Play services update later this year.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Theft_Detection_Lock_-_30fps_2.mp4" type="video/mp4" title="Animation showing how Theft Detection Lock works to protect user data Caption: Android uses AI to lock the device if the phone detects motion that could indicate theft." alt="Theft Detection Lock">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Android uses AI to lock the device if the phone detects motion that could indicate theft.</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">3. Lock your device and act quickly after your phone is stolen</h2><p data-block-key="vnhl"><a href="https://support.google.com/android/answer/6160491?hl=en" rt-link-type="external">Find My Device</a> already lets you remotely lock or wipe a lost or stolen phone and you can now <a href="https://blog.google/products/android/android-find-my-device/" rt-link-type="external">mark it as lost</a> for easier tracking. But many users are shocked and stressed after a phone goes missing and can’t recall their Google account password to access Find My Device.</p><p data-block-key="fr2qg"><b>Remote Lock feature throws you a lifeline if your phone is already gone.</b> You'll be able to lock the screen of your phone with just your phone number and a quick security challenge using any device. This buys you time to recover your account details and access additional helpful options in Find My Device, including sending a full factory reset command to completely wipe the device.</p><p data-block-key="57j0p">Remote Lock will be available to Android 10+ devices through a Google Play services update later this year. Find My Device is available on Android 5+ devices.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Remote-lock-updated-final-30fps_2.mp4" type="video/mp4" title="Animation showing a user turning on Remote Lock." alt="Remote Lock">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Remote Lock lets you remotely lock your device screen quickly</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><p data-block-key="kv45b">We're committed to keeping your device and data secure on Android. We’re constantly developing new protections to help our users around the world. Look out for more security and privacy features and updates from Android.<br></p><p data-block-key="5r4jt"><a href="https://security.googleblog.com/2024/05/io-2024-whats-new-in-android-security.html" rt-link-type="external">Learn more</a> about how we’re also protecting users from financial fraud and scams with new features.</p></div>
  

  
    



<section data-analytics-module="{
  &quot;module_name&quot;: &quot;Related Content Tout&quot;,
  &quot;section_header&quot;: &quot;10 updates coming to the Android ecosystem&quot;
}">
  <a href="https://blog.google/products/android/android-15-google-io-2024/" data-ga4-analytics-cta-click="{
  &quot;event&quot;: &quot;cta_click&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}" data-ga4-analytics-lead-click="{
  &quot;event&quot;: &quot;article_lead_click&quot;,
  &quot;link_text&quot;: &quot;10 updates coming to the Android ecosystem&quot;,
  &quot;link_type&quot;: &quot;internal&quot;,
  &quot;article_name&quot;: &quot;10 updates coming to the Android ecosystem&quot;,
  &quot;author_name&quot; : &quot;Menaka Shroff&quot;,
  &quot;page_name&quot;: &quot;android-15-google-io-2024&quot;,
  &quot;position&quot;: &quot;1 of 1&quot;,
  &quot;click_location&quot;: &quot;undefined&quot;,
  &quot;primary_tag&quot;: &quot;Products - Android&quot;,
  &quot;secondary_tags&quot;: &quot;undefined&quot;,
  &quot;publish_date&quot;: &quot;2024-05-15|17:00&quot;,
  &quot;hero_media&quot;: &quot;image&quot;,
  &quot;days_since_published&quot;: &quot;0&quot;,
  &quot;content_category&quot;: &quot;Announcement&quot;,
  &quot;word_count&quot;: &quot;1032&quot;,
  &quot;has_audio&quot;: &quot;no&quot;,
  &quot;has_video&quot;: &quot;yes&quot;,
  &quot;has_image&quot;: &quot;yes&quot;,
  &quot;has_carousel&quot;: &quot;no&quot;
}">
    <p>Related Article</p>
    <div>
      
        <figure>
          <img alt="An image showcasing Android 15 logo in the middle surrounded by a smartwatch, a TV interface, a car display interface in a circular web." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-165.format-webp.webp" data-loading="{
              &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-165.format-webp.webp&quot;,
              &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-300.format-webp.webp&quot;
            }">
          </figure>
      
      <div>
        <p>Related Article</p>
        <p>10 updates coming to the Android ecosystem</p>
        <p>From Theft Detection Lock to casting on Rivian to Wear OS 5 updates, here’s what’s coming to Android 15 and its device ecosystem.</p>
        
      </div>
    </div>
  </a>
</section>

  

  
    



<section data-analytics-module="{
  &quot;module_name&quot;: &quot;Related Content Tout&quot;,
  &quot;section_header&quot;: &quot;I/O 2024&quot;
}">
  <a href="https://blog.google/technology/developers/google-io-2024-collection/" data-ga4-analytics-cta-click="{
  &quot;event&quot;: &quot;cta_click&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}" data-ga4-analytics-landing-lead="{
  &quot;event&quot;: &quot;landing_page_lead&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}">
    
    <div>
      
        <figure>
          <img alt="A grid with curved lines and rectangles filled with a gradient of rainbow colors." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-165.format-webp.webp" data-loading="{
              &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-165.format-webp.webp&quot;,
              &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-300.format-webp.webp&quot;
            }">
          </figure>
      
      <div>
        
        <p>I/O 2024</p>
        <p>Here’s a look at everything we announced at Google I/O 2024.</p>
        
      </div>
    </div>
  </a>
</section>

  

  
    

  
    






<div role="form" aria-label="Sign up to receive weekly news and stories from Google." data-component="uni-subscribe" data-analytics-module="{
    &quot;module_name&quot;: &quot;Newsletter&quot;,
    &quot;section_header&quot;: &quot;Get more stories from Google in your inbox.&quot;
  }">
        
        
        <p>You are already subscribed to our newsletter.</p>
      </div>

  

  


            
            

            
              




            
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jepsen: Datomic Pro 1.0.7075 (324 pts)]]></title>
            <link>https://jepsen.io/analyses/datomic-pro-1.0.7075</link>
            <guid>40369467</guid>
            <pubDate>Wed, 15 May 2024 16:57:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jepsen.io/analyses/datomic-pro-1.0.7075">https://jepsen.io/analyses/datomic-pro-1.0.7075</a>, See on <a href="https://news.ycombinator.com/item?id=40369467">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><a href="https://datomic.com/">Datomic</a> is a temporal Entity-Attribute-Value OLTP database which supports non-interactive transactions on top of pluggable storage engines. It offers a variety of query mechanisms across thick and thin clients, including Datalog, graph traversal, and an ODM-style API. We evaluated Datomic Pro 1.0.7075 and found its inter-transaction safety properties appear stronger than claimed. Not only was every history Serializable, but sessions bound to a single peer appear Strong Session Serializable, and histories restricted to write transactions and reads using <code>d/sync</code> appear Strong Serializable. However, inside of a transaction Datomic behaves as if operations were evaluated concurrently. Depending on how one interprets those operations, this might violate three of the most widely accepted formalizations of Serializability, each of which specify serial intra-transaction semantics. It also creates the potential for invariant violations when composing transaction functions. Datomic has published a <a href="https://blog.datomic.com/2024/05/Jepsen-tests-Datomic.html">companion blog post</a> alongside this report. This work was funded by <a href="https://nubank.com.br/en/">Nubank</a> (Nu Pagamentos S.A), and conducted in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</p><article>
  <div>
<h2 data-number="1" id="background"> Background</h2>
<p><a href="https://datomic.com/">Datomic</a> is a general-purpose database intended for systems of record. In many ways, Datomic is unusual. At any instant in time, the state of the database is represented by a set of <code>[entity, attribute, value]</code> (<a href="https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model">EAV</a>) triples, known as <em>datoms</em>. Each datom declares that some <em>entity</em> (like a person) has a particular <em>attribute</em> (like a name) with a specific <em>value</em> (like “Vidrun”). The types and cardinality of attributes are controlled by a <a href="https://docs.datomic.com/pro/schema/schema.html">schema</a>.</p>
<p>Datomic is also a <a href="https://en.wikipedia.org/wiki/Temporal_database">temporal database</a>: it models time explicitly. Every transaction is identified by a <a href="https://docs.datomic.com/pro/glossary.html#t">strictly monotonic logical timestamp</a> <code>t</code>, as well as a wall-clock time <code>txInstant</code>. Transactions can <a href="https://docs.datomic.com/pro/glossary.html#assertion"><em>assert</em></a> a datom, adding it to the database, or they can <a href="https://docs.datomic.com/pro/glossary.html#retraction"><em>retract</em></a> a datom, removing it from the database. Every datom also retains a reference to the transaction that asserted or retracted it. A full datom is therefore a five-tuple of <code>[entity, attribute, value, transaction, asserted-or-retracted?]</code>. The database is an ever-growing set of these tuples.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Users can request a snapshot state of the database <a href="https://docs.datomic.com/pro/tutorial/history.html#asof-query">at any logical or wall-clock time</a>—right now or years in the past. They can also obtain a full <a href="https://docs.datomic.com/pro/tutorial/history.html#history-query">view of the database’s history</a>, allowing users to ask questions like “was there ever a time when Janelle Monáe and Cindi Mayweather were recorded in the same room together?”</p>
<p>Given a state of the database, users may query it via a <a href="https://docs.datomic.com/pro/query/query.html">Datalog-style API</a>, a <a href="https://docs.datomic.com/pro/query/pull.html">declarative graph traversal API</a>, or an <a href="https://docs.datomic.com/pro/overview/entities.html">ODM-style <code>Entity</code> datatype</a> which allows lazy access to an entity’s associated values, including other entities.</p>
<p>Datomic comes in two flavors. In this report we discuss <a href="https://www.datomic.com/index.html">Datomic Pro</a>, which anyone can run on their own computers. <a href="https://www.datomic.com/details.html">Datomic Cloud</a> runs in AWS and uses a <a href="https://docs.datomic.com/cloud/whatis/architecture.html">somewhat different architecture</a>.</p>
<h2 data-number="1.1" id="architecture"> Architecture</h2>
<p>Datomic Pro comprises several <a href="https://docs.datomic.com/pro/overview/architecture.html">co-operating services</a>. <em>Transactors</em> execute write transactions, maintain indices, and write data to storage. <em>Peers</em> are thick clients: they embed a JVM library which submits transactions to transactors, executes read queries against storage, and caches results. For applications written in other languages, Datomic also has a traditional client-server model. <em>Clients</em> are thin clients which forward transactions and queries to a <em>peer server</em>: a peer which runs a small network API.</p>
<p>Internally, Datomic <a href="https://docs.datomic.com/pro/transactions/acid.html#how-it-works">appends each transaction</a> to the <a href="https://docs.datomic.com/pro/query/indexes.html#log"><em>log</em></a>: a time-ordered set of transactions. From the log Datomic maintains <a href="https://docs.datomic.com/pro/query/indexes.html">four indices</a> sorted by different permutations of entity, attribute, value, and time. These indices allow efficient queries like “which entities were modified yesterday,” or “who run the world?”<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Both log and indices are stored as persistent, immutable trees in a data store like <a href="https://docs.datomic.com/pro/overview/storage.html">Cassandra or DynamoDB</a>. Because tree nodes are immutable, their backing storage only needs to guarantee eventual consistency. A small pointer to the roots of these trees provides a consistent, immutable snapshot of the database’s state. To commit a transaction, a transactor saves new immutable tree nodes to storage, then executes a compare-and-set (CaS) operation to advance the root pointer. This CaS operation must execute under <a href="https://jepsen.io/consistency/models/sequential">Sequential</a> consistency.</p>
<p>Using a Sequential CaS operation ensures a global order of transactions, and limits Datomic’s write throughput to the speed of a single transactor. To reduce contention, Datomic tries to have a <a href="https://docs.datomic.com/pro/operation/ha.html">single active transactor</a> at all times. Operators typically deploy multiple transactors for fault tolerance.</p>
<p>Peers connect directly to storage, and also to transactors. Transactions are forwarded to an active transactor, which executes them. Each peer also maintains a local, monotonically-advancing copy of the root pointer, which allows the peer to read tree nodes from storage. Since tree nodes are immutable, they can be trivially cached. There may be any number of peers, allowing near-linear read scalability.</p>
<h2 data-number="1.2" id="transaction-model"> Transaction Model</h2>
<p>Datomic has an unusual transaction model. Most OLTP databases offer interactive transactions: one begins a transaction, submits an operation, receives results from that operation, submits another, and so on before finally committing. Some databases, like <a href="https://docs.voltdb.com/UsingVoltDB/DesignProcAnatomy.php">VoltDB</a>, use stored procedures: an operator writes a small program which is installed in the database. Clients invoke that program by name, which mutates database state and returns values to the client. Other databases like <a href="https://fauna.com/fql">FaunaDB</a> allow clients to directly submit miniature programs as text or an abstract syntax tree. Like stored procedures, these programs perform arbitrary reads and writes, mutate state, and return data to the user.</p>
<p>Datomic does something rather different. It enforces a strict separation between read and write paths. There are no interactive transactions. It has stored procedures, but they cannot return values to the caller.</p>
<p>A read obtains an immutable state of the entire database. For instance, the <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/db"><code>db</code></a> function returns the most recent database state<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> the peer is aware of. To obtain the most recent state across all peers, or a state later than a given time, one calls <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/sync"><code>d/sync</code></a>. To obtain a state from a past time (seconds or years ago), one calls <a href="https://docs.datomic.com/pro/tutorial/history.html#asof-query">d/as-of</a>. These states are cheap, highly cacheable, and never block other writers or readers.</p>
<p>Given a database state, one can run any number of queries using (e.g.) <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/q"><code>q</code></a> or <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/pull"><code>pull</code></a>. Queries lazily fetch datoms from cache or storage. Since database states are immutable, any number of queries run against the same state occur at the exact same logical time. In this sense, all queries run on the same state take place in a single atomic transaction—even two queries executed on different machines, months apart.</p>
<p>Write transactions<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> are represented as an ordered list of <a href="https://web.archive.org/web/20240129122139/https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">operations</a>.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<blockquote>
<p>A transaction is simply a list of lists and/or maps, each of which is a statement in the transaction.</p>
</blockquote>
<p>For example, here is a transaction of three operations, all involving entity <code>123</code>:</p>
<div id="cb1"><pre><code><span id="cb1-1">[[<span>:db/add</span> <span>123</span> <span>:person/name</span> <span>"N. K. Jemisin"</span>]</span>
<span id="cb1-2"> [<span>:db/cas</span> <span>123</span> <span>:author/hugo-count</span> <span>2</span> <span>3</span>]]</span>
<span id="cb1-3"> [<span>:author/add-book</span> <span>123</span> <span>"The Stone Sky"</span>]]</span></code></pre></div>
<p>Those operations may be simple assertions (<code>:db/add</code>) or retractions <code>(:db/retract)</code> of datoms, or they may be calls to <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html">transaction functions</a>: either built-in or user-defined. In this example, the built-in <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#dbfn-cas"><code>db/cas</code></a> function performs a CaS operation, asserting the number of Hugo awards for this author is 3 if and only if that number is currently 2. One can also <a href="https://docs.datomic.com/pro/reference/database-functions.html#using-transaction-functions">store a function</a> (represented as a Clojure AST or <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/function">Java string</a>) in the database just like any other value. Alternatively, one may write a function in any JVM language, and provide it in a <code>jar</code> file on the transactor’s <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/classpath.html">classpath</a>. Once a function has been installed, any transaction may invoke it by providing the function’s name and arguments. Here, the <code>author/add-book</code> function receives the state of the database as of the start of the transaction, as well as any arguments from the transaction. It can perform arbitrary (pure) computation, including running queries against the database state. It then returns a new set of operations for the transaction—for instance, assertions, retractions, or calls to other functions. Function calls are recursively expanded until only assertions and retractions remain.</p>
<p>While transaction functions can make decisions based on the results of reads they perform internally, there is no channel to return those reads (or other information) to the caller of <code>transact</code>. Transactions <em>only</em> return effects. This means there is no direct analogue for an arbitrary read-write transaction in Datomic! For example, you can write a function which performs a conditional write,<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> but you can’t inform the caller whether the write took place or not. This constraint nudges Datomic users towards pulling reads out of the write transaction path—a key factor in obtaining good performance from a system which can logically execute only one write transaction at a time.</p>
<p>Instead of offering arbitrary return values from transactions, every call to <code>transact</code> returns the database state just before the transaction, the database state the transaction produced, and the set of datoms the transaction expanded to. This allows callers to execute read-write transactions by splitting them in twain: they submit a transaction which performs some writes, then use the pre-state of the database to determine what data that transaction would have read. Peers can also examine the post-state and set of datoms produced by the transaction to (e.g.) determine whether a conditional write took place.</p>
<p>From the perspective of traditional database systems, this sounds absurd. Mixed read-write transactions are a staple of OLTP workloads—how could you get anything done without them? Datomic offers a view of an alternate universe: one where database snapshots are cheap, efficient, and can be passed from node to node with just a timestamp. From this point of view, other databases feel impoverished. What do you mean, Postgres can’t give you the state of the entire database a transaction observed? The lack of a return channel for transaction functions may be annoying, but Datomic’s other strengths generally allow it to solve the same kinds of problems as a traditional, interactive transaction system. For example, NuBank (Datomic’s current developers) offers financial services to nearly 94 million users, processing an average of 2.3 billion user transactions per day. Almost all of their products use Datomic as a system of record.</p>
<h2 data-number="1.3" id="consistency"> Consistency</h2>
<p>Datomic advertises <a href="https://docs.datomic.com/pro/transactions/transactions.html">ACID transactions</a> and means it: their <a href="https://docs.datomic.com/pro/transactions/acid.html">ACID documentation</a> makes detailed, specific promises with respect to consistency models and durability guarantees. Transactions are “written to storage in a single atomic write,” which precludes intermediate read anomalies. Every peer “sees completed transactions as of a particular point in time,” and observes <em>all</em> transactions, totally ordered, up to that time. Transactions are always flushed to durable storage before client acknowledgement.</p>
<p>When our analysis began in early January 2024, Datomic’s documentation <a href="https://web.archive.org/web/20231208204951/docs.datomic.com/pro/transactions/acid.html#isolation">informally claimed</a> write transactions were <a href="https://jepsen.io/consistency/models/serializable">Serializable</a>:</p>
<blockquote>
<p>The Isolation property ensures that concurrent transactions result in the same system state that would result if the transactions were executed serially.</p>
</blockquote>
<p>Since write transactions are Serializable and execute atomically, and since read-only queries execute against committed snapshots, it seems plausible that histories of both read and write transactions should also be Serializable.<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Serializability does not impose <a href="https://jepsen.io/consistency/models/strict-serializable">real-time</a> or <a href="https://cs.uwaterloo.ca/~kmsalem/pubs/DaudjeeICDE04.pdf">session</a> ordering constraints: in a Serializable system, it is legal for a client to execute a transaction which inserts object <span><em>x</em></span>, then execute a second transaction which fails to observe <span><em>x</em></span>. While Datomic’s documentation does not make this claim, it seems plausible that Datomic’s transactor design might provide <a href="https://jepsen.io/consistency/models/strict-serializable">Strong Serializability</a> over write transactions, preventing real-time anomalies.</p>
<p>Since <code>d/db</code> returns an asynchronously updated <a href="https://docs.datomic.com/pro/transactions/client-synchronization.html">copy of the database</a>, we expect peers to observe stale reads. Indeed, Datomic is explicit that peer reads may not observe some recently committed transactions. However, it would be straightforward for peers to ensure that their time basis advances monotonically; if we say that every session is bound to a single peer node, we would expect to observe <a href="https://dbmsmusings.blogspot.com/2019/06/correctness-anomalies-under.html">Strong Session Serializable</a> histories.</p>
<p>In addition to these possible realtime and session constraints, Datomic has multiple synchronization mechanisms. Clients can <a href="https://docs.datomic.com/pro/transactions/client-synchronization.html">block until they observe</a> a value of the database at or later than some time <code>t</code>. This enables clients to ensure consistency when threading state through side channels. Calling <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/sync"><code>d/sync</code></a> forces the client to synchronize with the transactor, preventing stale reads. We expect histories which always use <code>d/sync</code> to be Strict Serializable as well.</p>
<p>Datomic’s documentation also described it as a “<a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/transactions/acid.html#isolation">single-writer</a>” system:</p>
<blockquote>
<p>A single thread in a single process is responsible for writing transactions. The Isolation property follows automatically from this, because there are no concurrent transactions. Transactions are always executed serially.</p>
</blockquote>
<p>This is wrong in two senses. First, Datomic is fault-tolerant: one can and should run several transactor nodes on different computers. Typically one transactor is active and the others are in standby. When a transactor’s <a href="https://docs.datomic.com/pro/operation/ha.html#enabling">failure detector</a> believes there is no active transactor, it will attempt to promote itself to active. However, <a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf">perfect failure detectors are impossible</a> in asynchronous networks. There may be times when a standby transactor believes it should take over, but another active transactor is still running. This means transactions may actually execute concurrently. During this window Datomic is not a single-writer system, but a multi-writer one!</p>
<p>Second, even if there were a perfect failure detector which ensured a single Datomic transactor at a time, its messages to storage could be arbitrarily delayed by the network and arrive interleaved with messages from other transactors. Thankfully this doesn’t matter: Datomic’s safety property follows directly from the Sequential consistency of the storage system’s <a href="https://docs.datomic.com/pro/transactions/acid.html#implications">CaS operation</a>. Any number of concurrent transactors ought to be safe.</p>
<h2 data-number="2" id="test-design"> Test Design</h2>
<p>We designed a <a href="https://github.com/jepsen-io/datomic/tree/7997e678a1925d2c3a576a728a63bc29a1b1812c">test suite for Datomic</a> using the <a href="https://github.com/jepsen-io/jepsen">Jepsen testing library</a>. Our test <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/db.clj#L54-L69">installed Datomic Pro</a> 1.0.7075 on a cluster of Debian Bookworm nodes. For storage, it provisioned a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/db/storage.clj#L40-L43">DynamoDB table</a> in AWS. Two of the test nodes ran transactors, and the remaining nodes ran peers.</p>
<p>Our peers were <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer.clj">small Clojure programs</a> which used the <a href="https://docs.datomic.com/pro/peer/peer-introduction.html">Datomic peer library</a>. They connected to storage and transactors and exposed a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer.clj#L96-L114">small HTTP API</a> for performing test suite operations. For each operation the test <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/client.clj#L44-L66">used an HTTP client</a> to submit that operation to some peer. The peer executed that operation using the peer library, and returned a result to the client. We ran our workloads both using <code>d/db</code>, which may yield stale reads, and also with <code>d/sync</code>, which blocks but guarantees recency.</p>
<p>Our test harness <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/nemesis.clj">injected faults</a> into both transactors and peers, including process pauses, crashes, and clock errors. We created network partitions between nodes (including both transactors and peers) and between nodes and the storage system. We also requested Datomic perform garbage collection.</p>
<p>Datomic transactors kill themselves when they cannot maintain a stable connection to storage. When we ran transactors with the default 5-second timeout settings on nodes outside AWS, transactors routinely killed themselves every few minutes due to normal network fluctuations. With a 1-second timeout, even transactors running in our EC2 test environment would kill themselves roughly every 10–20 minutes. To work around this, Datomic advises that operators run their own supervisor daemons to restart transactors. We used a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/resources/transactor.service">systemd service</a> with <code>Restart=on-failure</code>.</p>
<p>Our test suite included four workloads.</p>
<h2 data-number="2.1" id="list-append"> List Append</h2>
<p>We designed an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/append.clj#L31-L42">append workload</a> for use with the <a href="https://github.com/jepsen-io/elle">Elle transaction checker</a>. Logically, this workload operates over lists of integer elements, with each list identified by an integer primary key. Clients perform transactions comprising random operations. Each operation may read the current value of a list, or append a unique element to the end of a list. Elle then performs a broad array of checks on the history of transactions. It looks for aborted and intermediate reads, violations of internal consistency, and inconsistent orders of elements across different reads of a list. From the element orders, it infers write-write, write-read, and read-write dependencies between transactions. From the order of transactions on each logical process, and the global order of transactions, it infers per-process and real-time orders, respectively. Elle then searches for cycles in the resulting dependency graphs. Various cycles correspond to violations of different consistency models, like Strict Serializability.</p>
<p>We encoded our lists in Datomic <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L9-L18">as follows</a>. Each list was represented by a single entity with two attributes. One, <code>append/key</code>, served as the primary key. The other, <code>append/elements</code>, was a many-valued attribute which stored all the integer elements in a given list.</p>
<p>Performing the writes in a transaction was straightforward: given a write, we emitted <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L85-L88">a single operation</a> for the transaction stating that the given key now had that element: <code>{:append/key k, :append/elements element}</code>. To perform a read of <code>k</code>, we <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L85-L88">read a local cache of <code>k</code>’s elements</a>. We populated that cache with an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L68-L72">initial series of read queries</a>, then used a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L77-L90">small state machine</a> to simulate internal reads.</p>
<p>Note that multi-valued attributes represent an unordered <em>set</em>, not an ordered list. Elle’s inference uses the order of list elements to infer the serialization order of transactions. To obtain this order, we took advantage of the fact that Datomic is a temporal database: every datom includes a reference to the transaction which wrote it. When we read the elements for a given key, we also <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L24-L31">included their corresponding transactions</a>. We then <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L37">sorted the elements</a> by transaction times, which provides exactly the order Elle needs.</p>
<p>Elle’s list-append workload is designed for databases which offer mixed read-write transactions, but Datomic doesn’t have this concept. As previously mentioned, any read-write transaction can be expressed in Datomic by running the writes in a transaction function, then using the returned database state to determine what the transaction’s reads would have been. We used this technique in our workload: a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L40">single function</a> executes the transaction, simulates internal reads, and produces side effects (for the write transaction) and completed reads (to be returned to the client). We execute this function twice: <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L139">once using a stored procedure via <code>transact</code></a>, then a second time on the peer to <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L144">fill in reads</a>, using the pre-state of the database <code>transact</code> returned.</p>
<h2 data-number="2.2" id="list-append-with-cas"> List Append with CaS</h2>
<p>Many Datomic users use the built-in compare-and-set function <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#dbfn-cas"><code>db/cas</code></a> to control concurrent updates to an attribute of an entity outside a transaction. For example, they might read the current DB state using <code>d/db</code>, read the value of a counter as <code>4</code>, then increment the counter’s value using <code>[:db/cas 123 :counter/value 4 5]</code>. The CaS function asserts the new value 5 if and only if the current value is 4.</p>
<p>Datomic guarantees transactions are always Serializable, but a user might want to express a logical “user transaction” consisting of a read followed by a separate write transaction. Since Datomic database states are always complete snapshots, and transactions are Serializable, using <code>db/cas</code> for every write<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> allows users to build an ad hoc <a href="https://jepsen.io/consistency/models/snapshot-isolation">Snapshot Isolation</a> over these user transactions.</p>
<p>Our <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/append_cas.clj">append-cas</a> workload provides the same logical API as the list-append workload, but uses this CaS pattern to ensure Snapshot Isolation. Instead of multi-valued elements, we encoded each list <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L12-L21">as a single-valued, comma-separated string</a>. We <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L142-L143">performed a read</a> at the start of each transaction, <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L102-L122">applied reads and writes locally</a>, maintaining a buffer of written values, then <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L81-L95">constructed a transaction</a> of CaS operations which ensured that any values we wrote had not been modified since they were read.</p>
<h2 data-number="2.3" id="internal"> Internal</h2>
<p>Our two list-append workloads measured safety between transactions, but because they simulated the results of internal reads, they did not measure Datomics intra-transaction semantics. We designed an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/internal.clj">internal</a> workload which measures internal consistency with a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/internal.clj#L129-L270">suite of hand-crafted transactions</a>. For instance, we assert that the value for some attribute of an entity is 1, then 2. We assert and retract a fact in the same transaction. We assert a value, then try to CaS it to something else. We perform multiple CaS operations—trying to change 1 to 2, then 2 to 3. We create an entity, then modify it using a <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup ref</a>. Using a transaction function, we attempt to increment a value twice, and so on.</p>
<h2 data-number="2.4" id="grant"> Grant</h2>
<p>To ensure that transaction functions preserved function invariants, we designed a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#">grant</a> workload which simulates a simple state machine using transaction functions. Grants are first created, then can either be approved or denied. We <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/grant.clj#L11-L23">encode a grant</a> as a single entity with three attributes: <code>created-at</code>, <code>approved-at</code>, and <code>denied-at</code>.</p>
<p>No grant should be <em>both</em> approved and denied. We ensure this invariant by writing a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/grant.clj#L89-L99">pair of transaction functions</a> <code>approve</code> and <code>deny</code>. Each first checks that the grant under consideration has not been approved or denied already, aborting the transaction if necessary. If the grant hasn’t been approved or denied yet, <code>approve</code> adds the grant’s <code>approved-at</code> date. Our <code>deny</code> function works the same way.</p>
<p>Our grant workload creates a new grant in one transaction. In subsequent transactions it tries to approve and/or deny the grant. We repeat this process, exploring <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#L109-L112">different combinations</a> of functions and transaction boundaries. We check to make sure that no grant is <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#L84-L104">both approved and denied</a>.</p>
<h2 data-number="3" id="results"> Results</h2>
<p>We found no behavior which violated Datomic’s core safety claims. Transactions appeared to execute as if they had been applied in a total order, and that order was consistent with the local order of operations on each peer. Histories restricted to just those transactions performing writes, and histories in which reads used <code>(d/sync conn)</code> to obtain a current copy of the database, were consistent with real-time order.</p>
<p>However, we did observe unusual behavior within transactions. This intra-transaction behavior is generally consistent with Datomic’s documentation, but it represents a significant departure both from typical database behavior and the major formalisms used to model transactional isolation. We discuss those divergences here.</p>
<h2 data-number="3.1" id="internal-consistency"> Internal Consistency</h2>
<p>Virtually all databases and formalisms Jepsen is familiar with provide serial execution semantics within a transaction. For example, a transaction like <code>set x = 1; read x;</code> would print <code>1</code>, rather than the value of <code>x</code> when the transaction started.</p>
<p>Although Datomic transactions are <a href="https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">ordered lists of operations</a>, Datomic does not preserve this order in execution. Instead, all operations within a transaction (adds, retracts, and transaction functions) are executed as if they were concurrent with one another. Transaction functions always observe the state of the database at the beginning of the transaction. They do not observe prior assertions, retractions, or transaction functions. For example, consider <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/internal.zip">these results</a> from our internal workload. Imagine entity <code>123</code> currently has an <code>:internal/value</code> of <code>0</code>, and we execute the following transaction:</p>
<div id="cb2"><pre><code><span id="cb2-1">[[<span>:db/cas</span> <span>123</span> <span>:internal/value</span> <span>0</span> <span>1</span>]</span>
<span id="cb2-2"> [<span>:db/cas</span> <span>123</span> <span>:internal/value</span> <span>0</span> <span>1</span>]]</span></code></pre></div>
<p>In a serial execution model, this transaction would fail: the first CaS would alter the value of key <code>123</code> from <code>0</code> to <code>1</code>, and the second CaS would fail, since the current value was <code>1</code> and not <code>0</code>. In Datomic, both CaS operations observe the initial state <code>0</code>, and both succeed. They produce a pair of redundant assertions <code>[:db/add 123 :interval/value 1]</code>, and the value of entity <code>123</code> becomes <code>1</code>.</p>
<p>This means that state transitions may not compose as one expects. For instance, here is a transaction function that <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/internal.clj#L33-L37">increments the value</a> of the entity with key <code>k</code>:</p>
<div id="cb3"><pre><code><span id="cb3-1">(<span>defn</span><span> increment</span></span>
<span id="cb3-2">  [db k]</span>
<span id="cb3-3">  (<span>let</span> [{<span>:keys</span> [id value]} (<span>read</span> db k)]</span>
<span id="cb3-4">    [[<span>:db/add</span> id <span>:internal/value</span> (<span>inc</span> value)]]))</span></code></pre></div>
<p>What value does the following transaction produce, given an entity with key <code>"x"</code> and value <code>0</code>?</p>
<div id="cb4"><pre><code><span id="cb4-1">[[<span>'internal/increment</span> <span>"x"</span>]</span>
<span id="cb4-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>In a serial model, the result of two increments would be <code>2</code>. In Datomic, it’s <code>1</code>: both <code>increment</code> functions receive the database state from the start of the transaction. Similarly, transaction functions do not observe lexically prior assertions or retractions.</p>
<div id="cb5"><pre><code><span id="cb5-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>1</span>]</span>
<span id="cb5-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>This produces a final value of <code>1</code>, not <code>2</code>.</p>
<p>Likewise, <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup refs</a> use the state of the database as of the start of the transaction. This means a transaction which adds an entity cannot use a lookup ref to refer to it later in that same transaction. The following transaction aborts with an <code>Unable to resolve entity</code> message:</p>
<div id="cb6"><pre><code><span id="cb6-1">[<span>; Create an entity with key "x"</span></span>
<span id="cb6-2"> [<span>:db/add</span> <span>"x"</span> <span>:internal/key</span> <span>"x"</span>]</span>
<span id="cb6-3"> <span>; And set the value of the entity with key x</span></span>
<span id="cb6-4"> <span>; to 0:</span></span>
<span id="cb6-5"> [<span>:db/add</span> [<span>:internal/key</span> <span>"x"</span>] <span>:internal/value</span> <span>0</span>]]</span></code></pre></div>
<p>Many of the above transactions included multiple assertion requests with the same entity, attribute, and value. What happens if the values conflict? Imagine this transaction executes on a state where <code>x</code>’s value is <code>0</code>.</p>
<div id="cb7"><pre><code><span id="cb7-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>2</span>]</span>
<span id="cb7-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>In a database with serial intra-transaction semantics, this would produce the value <code>3</code>. In Datomic, the increment observes the start-of-transaction value <code>0</code>. It completes successfully, and the transaction expands to the following:</p>
<div id="cb8"><pre><code><span id="cb8-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>2</span>]</span>
<span id="cb8-2"> [<span>:db/add</span> id-of-x <span>:internal/value</span> <span>1</span>]]</span></code></pre></div>
<p>If this were executed by a serial database, it would produce the value <code>1</code>. But Datomic’s order-free semantics have another rule we have not yet discussed. If two assertions in the same transaction have different values for the same single-cardinality attribute of the same entity, the transaction aborts with <code>:db.error/datoms-conflict</code>. This transaction aborts!</p>
<p>This in-transaction conflict detection mechanism likely rules out many cases where the use of transaction functions would produce surprising results. A pair of increments will silently produce a single increment, but this is only possible because they all expand to compatible <code>[entity, attribute, value]</code> triples. Since there are an infinite number of incompatible values, and a single compatible choice for any <code>[entity, attribute]</code> pair, it seems likely that users who accidentally compose transaction functions incorrectly will find their transactions fail due to conflicts, and recognize their mistake.</p>
<p>This behavior may be surprising, but it is generally consistent with Datomic’s documentation. Nubank does not intend to alter this behavior, and we do not consider it a bug.</p>
<h2 data-number="3.2" id="pseudo-write-skew"> Pseudo Write Skew</h2>
<p>The fact that transactions appear to execute in serial, but the operations <em>within</em> a transaction appear to execute concurrently, creates an apparent paradox. A set of transaction functions might be correct when executed in separate transactions, but <em>incorrect</em> when executed in the same transaction! While Datomic’s in-transaction conflict checker prevents conflicts on a (single-cardinality) <code>[entity, attribute]</code> pair, it does nothing to control concurrency of functions which produce disjoint <code>[entity, attribute]</code> pairs.</p>
<p>We designed the grant workload to illustrate this scenario. Following the <a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/reference/database-functions.html#uses-for-transaction-functions">documentation’s advice</a> that transaction functions “can atomically analyze and transform database values,” and can be used to “ensure atomic read-modify-update processing, and integrity constraints,” we wrote a pair of transaction functions <code>approve</code> and <code>deny</code>. These functions encode the two legal state transitions for a single grant.</p>
<div id="cb9"><pre><code><span id="cb9-1">(<span>defn</span><span> approved?</span></span>
<span id="cb9-2">  <span>"Has a grant been approved?"</span></span>
<span id="cb9-3">  [db id]</span>
<span id="cb9-4">  (<span>-&gt;</span> '{<span>:find</span>  [?t]</span>
<span id="cb9-5">        <span>:in</span>    [$ ?id]</span>
<span id="cb9-6">        <span>:where</span> [[?id <span>:grant/approved-at</span> ?t]]}</span>
<span id="cb9-7">      (d/q db id)</span>
<span id="cb9-8">      <span>count</span></span>
<span id="cb9-9">      <span>pos?</span>))</span>
<span id="cb9-10"></span>
<span id="cb9-11">(<span>defn</span><span> ensure-fresh</span></span>
<span id="cb9-12">  <span>"Throws if the given grant ID</span></span>
<span id="cb9-13"><span>  is approved or denied."</span></span>
<span id="cb9-14">  [db id]</span>
<span id="cb9-15">  (<span>when</span> (approved? db id)</span>
<span id="cb9-16">    (throw+ {<span>:type</span> <span>:already-approved</span>}))</span>
<span id="cb9-17">  (<span>when</span> (denied? db id)</span>
<span id="cb9-18">    (throw+ {<span>:type</span> <span>:already-denied</span>})))</span>
<span id="cb9-19"></span>
<span id="cb9-20">(<span>defn</span><span> approve</span></span>
<span id="cb9-21">  <span>"Approves a grant by ID. Ensures the</span></span>
<span id="cb9-22"><span>  grant has not been approved or denied."</span></span>
<span id="cb9-23">  [db id]</span>
<span id="cb9-24">  (ensure-fresh db id)</span>
<span id="cb9-25">  [[<span>:db/add</span> id <span>:grant/approved-at</span> (Date.)]])</span></code></pre></div>
<p>The <code>denied?</code> and <code>deny</code> functions are identical to <code>approved?</code> and <code>approve</code>, except they use the <code>denied-at</code> attribute; we omit them for brevity.</p>
<p>By ensuring that the given grant ID is fresh (i.e.&nbsp;neither approved nor denied), these functions ensure an important invariant: no sequence of <code>approve</code> and/or <code>deny</code> calls can produce a grant which is both approved and denied. And indeed, Datomic’s Serializable transactions guarantee this invariant holds—so long as calls to <code>approve</code> and <code>deny</code> only ever take place in <em>different</em> transactions.</p>
<p>However, if a single transaction happens to call both <code>approve</code> and <code>deny</code>, <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/grant.zip">something very interesting occurs</a>:</p>
<div id="cb10"><pre><code><span id="cb10-1">[[<span>'grant/approve</span> id]</span>
<span id="cb10-2"> [<span>'grant/deny</span> id]]</span></code></pre></div>
<p>This transaction produces a grant with the following state:</p>
<div id="cb11"><pre><code><span id="cb11-1">{<span>:db/id</span>             <span>17592186045426</span>,</span>
<span id="cb11-2"> <span>:grant/created-at</span>  #inst <span>"2024-02-01..."</span>,</span>
<span id="cb11-3"> <span>:grant/denied-at</span>   #inst <span>"2024-02-01..."</span>,</span>
<span id="cb11-4"> <span>:grant/approved-at</span> #inst <span>"2024-02-01..."</span>}</span></code></pre></div>
<p>This grant is both approved and denied at the same time. Our invariant has been violated! Datomic’s in-transaction conflict checker did not prevent this behavior because the <code>approve</code> and <code>deny</code> functions returned assertion requests for disjoint <code>[entity, attribute]</code> pairs.</p>

<p>If we were to draw a data dependency graph between these two functions using the language of <a href="https://pmg.csail.mit.edu/papers/adya-phd.pdf">Adya’s formalism</a>, we’d see something like the following:</p>

<p>The <code>approve</code> function wrote a new version of the grant’s <code>approved-at</code> attribute, but when <code>deny</code> read that attribute, it observed the previous (unborn) version from the start-of-transaction database state. This is analogous to a read-write (<code>rw</code>) anti-dependency edge in Adya’s Direct Serialization Graph. Symmetrically, <code>deny</code> wrote a new version of the grant’s <code>denied-at</code> attribute, but <code>approve</code> saw the previous unborn version of <code>denied-at</code>. This gives rise to a dependency cycle: each transaction function failed to observe the other’s effects.</p>
<p>If these <code>approve</code> and <code>deny</code> boxes were transactions, we’d call this cycle G2-item: an isolation anomaly proscribed by <a href="https://jepsen.io/consistency/models/repeatable-read">Repeatable Read</a> and Serializability. Indeed, this phenomenon is analogous to a concurrency anomaly <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">Berenson et al called</a> called Write Skew:</p>
<blockquote>
<p>Suppose <code>T1</code> reads x and y, which are consistent with C(), and then a <code>T2</code> reads x and y, writes x, and commits. Then <code>T1</code> writes y. If there were a constraint between x and y, it might be violated.</p>
</blockquote>
<p>There are some similarities between the inter-transaction concurrency control of Berenson et al’s Snapshot Isolation and the intra-transaction concurrency control of Datomic’s end-of-transaction conflict checker. When the write sets (assertion requests) of two transactions (transaction functions) intersect on some object (an entity and cardinality-one attribute), the first-committer-wins principle (conflict checker) prevents concurrent execution by forcing an abort. When their write sets are disjoint, invariants preserved by two transaction functions individually may be violated by the transaction as a whole.</p>
<p>Like the internal consistency findings above, this behavior may be surprising, but it is broadly consistent with Datomic’s documentation. Nubank intends to preserve Datomic’s concurrent intra-transaction semantics. We consider this expected behavior for Datomic, rather than a bug.</p>
<h2 data-number="3.3" id="entity-predicates"> Entity Predicates</h2>
<p>From Datomic’s point of view, the grant workload’s invariant violation is a matter of user error. Transaction functions do not execute atomically in sequence. Checking that a precondition holds in a transaction function is unsafe when some other operation in the transaction could invalidate that precondition!</p>
<p>However, Datomic offers a <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#when-to-use">suite</a> of constraints for enforcing database invariants, including type, uniqueness, and arbitrary predicates on specific attributes. One of the most general constraints is an <a href="https://docs.datomic.com/pro/schema/schema.html#entity-predicates">entity predicate</a>.</p>
<p>Entity predicates are functions which receive a candidate state of the database with all transaction effects applied, the ID of an entity, and return <code>true</code> if the transaction should be allowed to commit that state. “Entity” is something of a misnomer: these predicates have access to the <em>entire</em> state of the database, and can therefore enforce arbitrary global constraints, not just those scoped to a particular entity.</p>
<p>We can use entity predicates to ensure grants are never approved and denied. To start, we write an entity predicate function <code>valid-grant?</code>.</p>
<div id="cb12"><pre><code><span id="cb12-1">(<span>defn</span><span> valid-grant?</span></span>
<span id="cb12-2">  [db eid]</span>
<span id="cb12-3">  (<span>let</span> [{<span>:grant/keys</span> [approved-at denied-at]}</span>
<span id="cb12-4">        (d/pull db '[<span>:grant/approved-at</span></span>
<span id="cb12-5">                     <span>:grant/denied-at</span>]</span>
<span id="cb12-6">                   eid)]</span>
<span id="cb12-7">   (<span>not</span> (<span>and</span> approved-at denied-at))))</span></code></pre></div>
<p>Then we add an <a href="https://docs.datomic.com/pro/schema/schema.html#entity-specs">entity spec</a> to the schema which references that function.</p>
<div id="cb13"><pre><code><span id="cb13-1">(<span>def</span><span> schema</span></span>
<span id="cb13-2"> [...</span>
<span id="cb13-3">  {<span>:db/ident</span>        <span>:grant/valid</span>?</span>
<span id="cb13-4">   <span>:db.entity/preds</span> [<span>'grant/valid-grant?</span>]</span>
<span id="cb13-5">   <span>:db/doc</span>          <span>"Ensures the given grant</span></span>
<span id="cb13-6"><span>                     is not approved *and*</span></span>
<span id="cb13-7"><span>                     denied"</span>}])</span></code></pre></div>
<p>Unlike other schema constraints, which are enforced for every transaction, entity specs (and their associated entity predicates) are only enforced when transactions explicitly ask for them. Datomic believes that whether or not to enforce an entity spec is a domain decision, and that this approach is more flexible than making entity specs mandatory. Therefore our transition functions assert the grant’s <code>approved-at</code> or <code>denied-at</code> attribute, then <a href="https://github.com/jepsen-io/datomic/blob/0af5c0d5a2e9fdb5baee54378f64c1cc0f496ac0/peer/src/jepsen/datomic/peer/grant.clj#L99-L115">request the entity spec be enforced</a> by adding a special request for a <em>virtual datom</em>, binding the attribute <code>:db/ensure</code> to our entity spec.</p>
<div id="cb14"><pre><code><span id="cb14-1">(<span>defn</span><span> approve</span></span>
<span id="cb14-2">  [db id]</span>
<span id="cb14-3">  [[<span>:db/add</span> id <span>:grant/approved-at</span> (Date.)]</span>
<span id="cb14-4">   [<span>:db/add</span> id <span>:db/ensure</span> <span>:grant/valid</span>?]])</span>
<span id="cb14-5"></span>
<span id="cb14-6">(<span>defn</span><span> deny</span></span>
<span id="cb14-7">  [db id]</span>
<span id="cb14-8">  [[<span>:db/add</span> id <span>:grant/denied-at</span> (Date.)]</span>
<span id="cb14-9">   [<span>:db/add</span> id <span>:db/ensure</span> <span>:grant/valid</span>?]])</span></code></pre></div>
<p>Using this entity spec, attempts to approve and deny a grant within the same transaction <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/grant-entity-pred.zip">throw an error</a>, preserving our intended invariant.</p>
<div id="cb15"><pre><code><span id="cb15-1">{<span>:cognitect.anomalies/category</span></span>
<span id="cb15-2"> <span>:cognitect.anomalies/incorrect</span>,</span>
<span id="cb15-3"> <span>:cognitect.anomalies/message</span></span>
<span id="cb15-4"> <span>"Entity 17592186045427 failed pred</span></span>
<span id="cb15-5"><span>  #'jepsen.datomic.peer.grant/valid-grant?</span></span>
<span id="cb15-6"><span>  of spec :grant/valid?"</span>,</span>
<span id="cb15-7">  <span>:db.error/pred-return</span> <span>false</span>,</span>
<span id="cb15-8">  <span>:db/error</span> <span>:db.error/entity-pred</span>}</span></code></pre></div>
<h2 data-number="4" id="discussion"> Discussion</h2>
<p>In our testing, Datomic’s inter-transaction semantics were consistent with Strong Session Serializability. Intra-transaction semantics appeared strictly concurrent: the operations within a transaction seemed to be executed simultaneously, and the resulting effects merged via set union. This combination satisfies a common high-level definition of Serializability: “equivalence to a serial execution of transactions.” However, it does seem to violate the definitions of Serializability in the most broadly-adopted academic formalisms for transactional isolation. Datomic argues—and Jepsen is willing to entertain—that these formalisms should not be applied to Datomic; they are fundamentally different kinds of databases.</p>
<p>While some details of the documentation were inaccurate or misleading, Datomic’s inter- and intra-transaction behavior appeared consistent with its core safety claims. Indeed, we believe Datomic’s inter-transaction safety properties are stronger than promised.</p>
<p>As always, we caution that Jepsen takes an experimental approach to safety verification: we can prove the presence of bugs, but not their absence. We also note that correctness errors in the storage system underlying Datomic could cause violations of Datomic’s guarantees; Datomic atop DynamoDB is only as safe as DynamoDB’s compare-and-set operation.</p>
<h2 data-number="4.1" id="inter-transaction-semantics"> Inter-Transaction Semantics</h2>
<p>If one considers a session as being bound to a single peer, Datomic appears to guarantee Strong Session Serializability. Histories of transactions appear indistinguishable from one in which those transactions had executed in some total order, and that order is consistent with the order observed on each peer.</p>
<p>Histories restricted to write transactions (i.e.&nbsp;calls to <code>d/transact</code>) appear Strict Serializable. So too do histories where readers use <code>d/sync</code> to obtain an up-to-date state of the database rather than <code>d/db</code>, which could be stale.</p>
<h2 data-number="4.2" id="intra-transaction-semantics"> Intra-Transaction Semantics</h2>
<p>Most transactional systems provide serial semantics within a single transaction.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> Each operation—writes, reads, procedure calls, etc.—within a transaction appears to take place after the previous operation in that same transaction. This property is explicitly encoded in the major formalisms for transactional isolation. <a href="https://pmg.csail.mit.edu/papers/icde00.pdf">Adya, Liskov, and O’Neil</a> begin their database model by defining transactions as ordered, and explicitly specify later operations observe earlier ones:</p>
<blockquote>
<p>Each transaction reads and writes objects and indicates a total order in which these operations occur….</p>
<p>If an event <span><em>w</em><sub><em>i</em></sub>(<em>x</em><sub><em>i</em>.<em>m</em></sub>)</span> is followed by <span><em>r</em><sub><em>i</em></sub>(<em>x</em><sub><em>j</em></sub>)</span> without an intervening event <span><em>w</em><sub><em>i</em></sub>(<em>x</em><sub><em>i</em>.<em>n</em></sub>)</span> in <span><em>E</em></span>, <span><em>x</em><sub><em>j</em></sub></span> must be <span><em>x</em><sub><em>i</em>.<em>m</em></sub></span>. This condition ensures that if a transaction modiﬁes object <span><em>x</em></span> and later reads <span><em>x</em></span>, it will observe its last update to <span><em>x</em></span>.</p>
</blockquote>
<p>Similarly, the <a href="https://software.imdea.org/~andrea.cerone/works/Framework.pdf">abstract execution formalism</a> of Cerone, Bernardi, and Gotsman defines an <em>internal consistency axiom</em> preserved by all consistency models from Read Atomic through Serializable:</p>
<blockquote>
<p>The internal consistency axiom  ensures that, within a transaction, the database provides sequential semantics: a read from an object returns the same value as the last write to or read from this object in the transaction. In particular,  guarantees that, if a transaction writes to an object and then reads the object, then it will observe its last write.</p>
</blockquote>
<p>Crooks, Alvisi, Pu, and Clement’s <a href="https://www.cs.cornell.edu/lorenzo/papers/Crooks17Seeing.pdf">client-centric formalism</a> similarly specifies transactions include a total order, and uses that order to ensure reads observe the most recent write to that object within the current transaction:</p>
<blockquote>
<p>Further, once an operation in <span><em>T</em></span> writes <span><em>v</em></span> to <span><em>k</em></span>, we require all subsequent operations in <span><em>T</em></span> that read <span><em>k</em></span> to return <span><em>v</em></span>.</p>
</blockquote>
<p>Even as far back as 1979, <a href="https://www.eecs.harvard.edu/~htk/publication/1979-sigmod-kung-papadimitriou.pdf">Kung and Papadimitriou</a> defined transactions as a finite sequence of <em>transaction steps</em>. “Thus, our transactions are straight-line programs,” they explain.</p>
<p>In all of these models, a Serializable system behaves equivalently to one which begins with an initial database state <span><em>d</em><em>b</em><sub>0</sub></span>, picks some transaction <span><em>T</em></span>, applies the first operation in <span><em>T</em></span> producing an intermediate database state <span><em>d</em><em>b</em><sub>0</sub>′</span>, applies the second operation in <span><em>T</em></span> to <span><em>d</em><em>b</em><sub>0</sub>′</span> producing <span><em>d</em><em>b</em><sub>0</sub>″</span>, and so on until the transaction has completed, producing a committed database state <span><em>d</em><em>b</em><sub>1</sub></span>. Then it moves to a second transaction, and the process continues.</p>
<p>Datomic’s semantics are quite different. As previously discussed, the operations within a transaction (assertions, retractions, transaction functions, etc.) are evaluated logically concurrent with one another. Every transaction function in a transaction <span><em>T</em></span> observes the state of the database when <span><em>T</em></span> began, and produces a new set of operations. They do not observe the other assertions, retractions, or functions in <span><em>T</em></span>. These operations are recursively evaluated until only assertions and retractions remain. Those assertions and retractions are merged with set union, checked for conflicts (e.g.&nbsp;contradictory assertions about the value of a single-cardinality attribute on some entity), and then applied to the database state to produce a new, committed version of the database.</p>

<p>This behavior may be surprising to users familiar with other databases, but it is (to some extent) documented. The <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup ref documentation</a> explains that refs use the before-transaction database state. The <a href="https://docs.datomic.com/pro/reference/database-functions.html#processing-transaction-functions">database functions documentation</a> says the transaction processor calls transactions “in turn”, which hints at ordered execution, but explicitly notes that functions are passed “the value of the db (currently, as of the beginning of the transaction).” On the other hand, that same documentation goes on to say that “[t]ransaction functions are serialized by design,” which is true <em>between</em> transactions, but not <em>within</em> them.</p>
<p>Datomic’s concurrent semantics yield advantages and drawbacks. For one, a common axiom of database systems is that committed database state is always <em>consistent</em>, in the business-rules sense. <a href="https://jepsen.io/consistency/models/read-committed">Read Committed</a> and above proscribe phenomenon G1b (<em>intermediate read</em>) in which one transaction sees intermediate state from another transaction. Datomic goes one step further: it is impossible to observe your <em>own</em> transaction’s intermediate state. One can never<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a> produce or observe an inconsistent view of the system—full stop! In some sense, the concept of intermediate state is inherently confusing; Datomic does away with it altogether. This choice also simplifies Datomic’s model of time: everything in a transaction happens “at once”, and every datom is <em>always</em> associated with a single, totally-ordered time.</p>
<p>On the other hand, Datomic’s model reintroduces one of the problems Serializability has long been used to prevent. As Papadimitriou’s 1979 paper <a href="https://www.cs.purdue.edu/homes/bb/cs542-06Spr-bb/SCDU-Papa-79.pdf">The Serializability of Concurrent Database Updates</a><a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a> concisely argues:</p>
<blockquote>
<p>Another way of viewing serializability is as a tool for ensuring system correctness. If each user transaction is correct—i.e., when run by itself, it is guaranteed to map consistent states of the database to consistent states—and transactions are guaranteed to be intermingled in a serializable way, then the overall system is also correct.</p>
</blockquote>
<p>It seems plausible that users would want to write transaction functions that transform data while preserving some kind of correctness invariant. Datomic’s <a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/reference/database-functions.html#uses-for-transaction-functions">transaction functions documentation</a> originally suggested as much:</p>
<blockquote>
<p>Transaction functions run on the transactor inside of transactions, and thus can atomically analyze and transform database values. You can use them to ensure atomic read-modify-update processing, and integrity constraints… A transaction function can issue queries on the db value it is passed, and can perform arbitrary logic in the programming language.</p>
</blockquote>
<p>If one writes a set of transaction functions which independently preserve some invariant—say, that a grant must never be both approved and also denied, or that the circuits in a home never exceed the capacity of the main panel—one would like to say (analogous to Serializable transactions) that any composition of these functions also preserves that invariant. But as we’ve demonstrated, within a single Datomic transaction this is not true! A transaction which calls multiple transaction functions might produce an outcome incompatible with the atomic application of those functions. It might violate integrity constraints. Paradoxically, combining two transactions into one can actually make the system <em>less</em> safe.</p>
<p>It seems likely that Datomic’s behavior violates the major modern transaction formalisms: Cerone et al’s internal consistency axiom, Adya’s program order, Crooks et al’s in-transaction order, etc. It may be possible to contort Datomic’s model into alignment with these formalisms: say, by defining Datomic as containing only one object (the entire database), or through a non-local translation of Datomic operations to the formalism’s sequence of reads and writes, in which reads are reordered to the beginning of the transaction, and writes to the end. However, these approaches strain intuition. Datomic databases obviously contain independently addressable entities and attributes. Datomic transactions are clearly made up of individual parts, those parts are written in order, and this looks very much like how other databases would express a transaction with serial semantics. Convincing users to ignore that intuition seems a challenging lift.</p>
<p>An easier path might be to abandon these formalisms altogether: they are clearly not designed to apply to Datomic’s concurrent intra-transaction semantics. Instead, we could follow the classic informal definition of Serializability. The internal structure of transactions is completely opaque; all that matters is that the history of transactions is equivalent to one which executed in a serial order. Under this interpretation, Datomic does ensure Serializability, Strong Session Serializability, and so on—just with different intra-transaction rules. To avoid confusion, we carefully distinguish between inter- and intra-transaction consistency throughout this report.</p>
<h2 data-number="4.3" id="recommendations"> Recommendations</h2>
<p>We found no evidence of safety bugs in Datomic, or serious divergence between documentation and system behavior. Datomic’s concurrency architecture is refreshingly straightforward, and its transactional correctness easy to argue. Jepsen believes users can rely on Datomic’s inter-transaction Serializability.</p>
<p>However, Datomic users should be aware of the concurrent execution semantics within transactions. These are specified in the documentation, but remain an unusual choice which creates the potential for subtle invariant violations. Users should be careful when calling multiple transaction functions in the same transaction. In particular, watch out for intersecting read sets and disjoint write sets. Also be aware of the possibility that multiple updates (e.g. increments) to a single value might quietly collapse to a single update.</p>
<p>In practice, we believe several factors protect Datomic users against encountering anomalies. First, users often try to create a schema and use it in the same transaction, or try to use a lookup ref to refer to an entity created in the same transaction. Both of these scenarios fail, which guides users towards re-reading the documentation and internalizing Datomic’s model. Second, the in-transaction conflict checker likely prevents many of the anomalies that could arise from logically-concurrent transaction functions: if two transaction functions produce different values for a single-cardinality attribute of an entity, the transaction aborts.</p>
<p>In addition, users can use <a href="https://docs.datomic.com/pro/schema/schema.html#attribute-predicates">attribute predicates</a> to constrain individual values, and <a href="https://docs.datomic.com/pro/schema/schema.html#entity-specs">entity specs</a> (which must be requested on each transaction) to constrain all attributes of a single entity, or even an entire database. However, users must take care to explicitly request the appropriate entity specs within every transaction that might require them.</p>
<p>Another potential surprise: Datomic goes to great pains to ensure every database state is business-rules consistent: there are no intermediate states, every state is the product of a committed transaction, and so on. However, not all schema constraints apply to extant data. In particular, attribute predicates are only enforced on newly-added datoms, not on existing datoms.</p>
<p>A small operational note: Datomic transactors kill themselves after a few minutes of not being able to talk to storage. We recommended Datomic add a retry loop to make transactors robust to network fluctuations.</p>
<h2 data-number="4.4" id="documentation-changes"> Documentation Changes</h2>
<p>Following our collaboration, Datomic has made extensive revisions to their documentation.</p>
<p>First, we worked together to rewrite Datomic’s <a href="https://docs.datomic.com/pro/transactions/acid.html">transaction safety documentation</a>. It now reflects the stronger safety properties we believe Datomic actually offers: Serializability globally, monotonicity on each peer, and Strict Serializability when restricted to writes, or reads which use <code>sync</code>. Datomic also removed the “single-writer” argument from their safety documentation.</p>
<p>Datomic’s docs now include a <a href="https://docs.datomic.com/pro/transactions/transactions.html">comprehensive explanation</a> of transaction syntax and semantics. It covers the structure of transaction requests, the rules for expanding map forms and transaction functions, and the process of applying a transaction. Expanded documentation for <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html">transaction functions</a> explains Datomic’s various mechanisms for ensuring consistency, how to create and invoke functions, and the behavior of built-in functions. The transaction function documentation no longer says they can be used to “atomically analyze and transform database values”, nor does it claim transaction functions can “ensure atomic read-modify-write processing”.</p>
<p>Datomic <a href="https://web.archive.org/web/20240129122139/https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">used to refer</a> to the data structure passed to <code>d/transact</code> as a “transaction”, and to its elements as “statements” or “operations”. Going forward, Datomic intends to refer to this structure as a “transaction request”, and to its elements as “data”. The <code>[:db/add ...]</code> and <code>[:db/retract ...]</code> forms are “assertion requests” and “retraction requests,” respectively. This helps distinguish between assertion <em>datoms</em>, which are <code>[entity, attribute, value, transaction, added-or-removed?]</code> tuples, and the incomplete <code>[entity, attribute, value]</code> assertion <em>request</em> in a transaction request.</p>
<p>Datomic has also added documentation <a href="https://docs.datomic.com/pro/tech-notes/comparison-with-updating-transactions.html">arguing for a difference</a> between Datomic transactions and SQL-style “updating transactions.” There is also a new <a href="https://docs.datomic.com/pro/tech-notes/composing-transactions-by-example.html">tech note</a> which discusses the differences between transaction functions and entity predicates when composing transactions.</p>
<h2 data-number="4.5" id="future-work"> Future Work</h2>
<p>Our tests did not evaluate excision or historical queries. Nor did we investigate the Datomic client library—though we believe its behavior is likely similar to the peers we designed in this test. We also limited ourselves to a single storage engine: DynamoDB. Datomic runs atop a variety of storage systems; testing others might be of interest. Finally, we have not evaluated Datomic Cloud, which uses a slightly different architecture.</p>
<p>Jepsen is aware of few systems or formalisms which provide inter-transaction Serializability but intra-transaction concurrent semantics. Datomic’s behavior suggests fascinating research questions.</p>
<p>First, what <em>are</em> Datomic transactions? Is there a sense in which they are a <em>dual</em> to typical database transactions? Rather than happening entirely in series, everything happens all at once. What are the advantages and drawbacks of such a “co-transaction” model? Can the drawbacks be mitigated through static analysis, runtime checks, or API extensions? And does this actually matter in practice, or are users unlikely to write transactions which could violate invariants?</p>
<p>Second, are there other databases with concurrent intra-transaction semantics? Conversely, what about other temporal databases with serial intra-transaction semantics? How does Datomic’s model fit into this landscape?</p>
<p><a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-173.pdf">Alvaro’s Dedalus</a>, a research project exploring temporal Datalog, comes to mind. Like Datomic, its transactions happen “all at once.” As in Datomic, this creates the apparent paradox that breaking up operations into multiple transactions can actually make them safer. Consider also <a href="https://docs.fauna.com/fauna/current/cookbook/basics/update_document">Fauna</a>, a temporal database supporting up to Strong Serializability. Like Datomic, Fauna transactions are small programs that the database evaluates, rather than an interactive session driven by a client. Unlike Datomic, Fauna’s transactions provide (what appears to be) serial execution with incremental side effects within each transaction. Are Fauna’s in-transaction temporal semantics sound? How do their models compare?</p>
<p>The similarity between Datomic’s end-of-transaction conflict checker and Snapshot Isolation’s first-committer-wins rule suggests new research opportunities. How close is the relationship between Snapshot Isolation and Datomic’s in-transaction semantics, and what parts of the existing literature on Snapshot Isolation could we apply to Datomic? Can we show that within a Datomic transaction, cycles between transaction functions must always involve a pair of adjacent read-write anti-dependency edges. Clearly Datomic does not prevent the intra-transaction analogue of lost update, since it collapses multiple increments. What about Fractured Read? Does it allow something like the read-only transaction anomaly described by <a href="https://www.cs.umb.edu/~poneil/ROAnom.pdf">Fekete, O’Neil, and O’Neil</a>? Or <a href="https://www.news.cs.nyu.edu/~jinyang/pub/walter-sosp11.pdf">Long Fork</a>? Are there analogues to other G2-item and G2 cycles, perhaps involving predicates?</p>
<p>Finally, one wonders whether there might be a connection to <a href="https://arxiv.org/pdf/1901.01930.pdf">Hellerstein &amp; Alvaro’s CALM theorem</a>. Could we show, for instance, that transaction functions which are logically monotonic are safe to combine in a single Datomic transaction? Datalog programs without negation are logically monotonic. Can we show that those programs are also safe under this execution model? Jepsen encourages future research.</p>
<p><em>Jepsen wishes to thank the entire Datomic team at Nubank, and in particular Dan De Aguiar, Guilherme Baptista, Adrian Cockcroft, Stuart Halloway, Keith Harper, and Chris Redinger. Peter Alvaro offered key insights into concurrent semantics. <a href="https://www.irenekannyo.com/">Irene Kannyo</a> provided invaluable editorial support. This work was funded by <a href="https://nubank.com.br/en/">Nubank</a> (Nu Pagamentos S.A), and conducted in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Datomic also provides an <a href="https://docs.datomic.com/pro/reference/excision.html">excision</a> mechanism which rewrites history to permanently delete datoms. This is useful for regulatory compliance or removing unwanted PII.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Girls!<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Datomic refers to an immutable version of the database as a “value”. To avoid confusion with other kinds of values in this report, we call this a “database state”.<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Most systems use “transaction” to refer to a group of operations, including reads or writes, executed as a unit. Datomic uses “transaction” to refer specifically to a write transaction—i.e.&nbsp;a call to <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/transact"><code>d/transact</code></a>. However, Datomic’s reads are trivially transactional as well. We refer to both reads and writes as transactions in this work—it significantly simplifies our discussion of consistency models.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>At the start of our collaboration, Datomic used “statement”, “operation”, and “data” to refer to elements of a transaction. We use “operation” in this report for consistency with the database literature, and to avoid confusion with other kinds of data. Datomic intends to refer to transaction elements solely as “data” going forward.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Datomic wishes to note that transaction functions (for instance, <code>db/cas</code>) do not actually perform writes. They produce data structures which represent <em>requests</em> for writes. Those writes are performed during the final stages of transaction execution. Delayed evaluation of transaction effects is a common database technique; we use the term “write” loosely with this understanding.<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>As Fekete, O’Neil, and O’Neil point out, adding read-only transactions to a history which is otherwise Serializable can <a href="https://www.cs.umb.edu/~poneil/ROAnom.pdf">actually yield non-Serializable histories</a>! However, this paper applies specifically to Snapshot Isolation, where two transactions may read the same state and write new values concurrently. Datomic’s design ensures transactions are atomic, in the sense that no two transactions overlap in the window between their read and write timestamps.<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>We say “every” write for safety and clarity. In practice, users often arrange for all transactions requiring concurrency control to conflict on a single attribute of an entity. A single CaS operation on, say, a customer’s <code>version</code> attribute could ensure that any number of updates to that customer occur sequentially.<a href="#fnref8" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Of course, typical Serializable databases may not <em>actually</em> execute operations in serial order. However, they (ought to) behave indistinguishably from a system which had. Similarly, Datomic may not execute transaction functions in parallel—but it guarantees concurrent semantics. For concision, we say “serial semantics” instead of “behavior which is indistinguishable from a serial execution,” and so on.<a href="#fnref9" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Unless one produces new, transient database states using <code>d/with</code>.<a href="#fnref10" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Intriguingly, Papadimitriou’s paper begins with transactions which perform a set of reads, then a set of writes; this formalism might be more readily applicable to Datomic transactions. Later in the paper he addresses “multistep transactions,” which are analogous to the serial formalisms discussed in this section.<a href="#fnref11" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tarsier – Vision utilities for web interaction agents (170 pts)]]></title>
            <link>https://github.com/reworkd/tarsier</link>
            <guid>40369319</guid>
            <pubDate>Wed, 15 May 2024 16:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/reworkd/tarsier">https://github.com/reworkd/tarsier</a>, See on <a href="https://news.ycombinator.com/item?id=40369319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/reworkd/Tarsier/main/.github/assets/tarsier.png"><img src="https://raw.githubusercontent.com/reworkd/Tarsier/main/.github/assets/tarsier.png" height="300" alt="Tarsier Monkey"></a>
</p>
<p dir="auto">
  <em>🙈 Vision utilities for web interaction agents 🙈</em>
</p>
<p dir="auto">
    <a href="https://pypi.org/project/tarsier/" rel="nofollow">
        <img alt="Python" src="https://camo.githubusercontent.com/0562f16a4ae7e35dae6087bf8b7805fb7e664a9e7e20ae6d163d94e56b94f32d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534" data-canonical-src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54">
        <img alt="Version" src="https://camo.githubusercontent.com/e3c0bb6224b756f0057970306b1daf2b9d4f063ce276f67a892cbbdac4c82ccb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f746172736965723f7374796c653d666f722d7468652d626164676526636f6c6f723d333637304130" data-canonical-src="https://img.shields.io/pypi/v/tarsier?style=for-the-badge&amp;color=3670A0">
    </a>
</p>
<p dir="auto">
<a href="https://reworkd.ai/" rel="nofollow">🔗 Main site</a>
<span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>
<a href="https://twitter.com/khoomeik/status/1723432848739483976" rel="nofollow">🐦 Twitter</a>
<span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>
<a href="https://discord.gg/gcmNyAAFfV" rel="nofollow">📢 Discord</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tarsier</h2><a id="user-content-tarsier" aria-label="Permalink: Tarsier" href="#tarsier"></a></p>
<p dir="auto">If you've tried using an LLM to automate web interactions, you've probably run into questions like:</p>
<ul dir="auto">
<li>How should you feed the webpage to an LLM? (e.g. HTML, Accessibility Tree, Screenshot)</li>
<li>How do you map LLM responses back to web elements?</li>
<li>How can you inform a text-only LLM about the page's visual structure?</li>
</ul>
<p dir="auto">At Reworkd, we iterated on all these problems across tens of thousands of real web tasks to build a powerful perception system for web agents... Tarsier!
In the video below, we use Tarsier to provide webpage perception for a minimalistic GPT-4 LangChain web agent.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description tarsier.mp4">tarsier.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/50181239/282260008-af12beda-89b5-4add-b888-d780b353304b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU4MDcxMDQsIm5iZiI6MTcxNTgwNjgwNCwicGF0aCI6Ii81MDE4MTIzOS8yODIyNjAwMDgtYWYxMmJlZGEtODliNS00YWRkLWI4ODgtZDc4MGIzNTMzMDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE1VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBkMTM0M2YwNTkzYzkzYjc0NjU3ZDU4MmFiMjMxNjI0MGYyNDc4MTNiNWM2MTk5OTlkYTVjMTEzZDZiZDE1Y2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.VKHJqRjEIxRLBSfqvLGG3AWyAX4CPBHTLOFIIRMxnlw" data-canonical-src="https://private-user-images.githubusercontent.com/50181239/282260008-af12beda-89b5-4add-b888-d780b353304b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU4MDcxMDQsIm5iZiI6MTcxNTgwNjgwNCwicGF0aCI6Ii81MDE4MTIzOS8yODIyNjAwMDgtYWYxMmJlZGEtODliNS00YWRkLWI4ODgtZDc4MGIzNTMzMDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE1VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBkMTM0M2YwNTkzYzkzYjc0NjU3ZDU4MmFiMjMxNjI0MGYyNDc4MTNiNWM2MTk5OTlkYTVjMTEzZDZiZDE1Y2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.VKHJqRjEIxRLBSfqvLGG3AWyAX4CPBHTLOFIIRMxnlw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">Tarsier visually tags interactable elements on a page via brackets + an ID e.g. <code>[23]</code>.
In doing this, we provide a mapping between elements and IDs for an LLM to take actions upon (e.g. <code>CLICK [23]</code>).
We define interactable elements as buttons, links, or input fields that are visible on the page; Tarsier can also tag all textual elements if you pass <code>tag_text_elements=True</code>.</p>
<p dir="auto">Furthermore, we've developed an OCR algorithm to convert a page screenshot into a whitespace-structured string (almost like ASCII art) that an LLM <em>even without vision</em> can understand.
Since current vision-language models still lack fine-grained representations needed for web interaction tasks, this is critical.
On our internal benchmarks, unimodal GPT-4 + Tarsier-Text beats GPT-4V + Tarsier-Screenshot by 10-20%!</p>
<table>
<thead>
<tr>
<th>Tagged Screenshot</th>
<th>Tagged Text Representation</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/reworkd/tarsier/blob/main/.github/assets/tagged.png"><img src="https://github.com/reworkd/tarsier/raw/main/.github/assets/tagged.png" alt="tagged"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/reworkd/tarsier/blob/main/.github/assets/tagged_text.png"><img src="https://github.com/reworkd/tarsier/raw/main/.github/assets/tagged_text.png" alt="tagged"></a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Visit our <a href="https://github.com/reworkd/Tarsier/tree/main/cookbook">cookbook</a> for agent examples using Tarsier:</p>
<ul dir="auto">
<li><a href="https://github.com/reworkd/tarsier/blob/main/cookbook/langchain-web-agent.ipynb">An autonomous LangChain web agent</a> 🦜⛓️</li>
<li><a href="https://github.com/reworkd/tarsier/blob/main/cookbook/llama-index-web-agent.ipynb">An autonomous LlamaIndex web agent</a> 🦙</li>
</ul>
<p dir="auto">Otherwise, basic Tarsier usage might look like the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio

from playwright.async_api import async_playwright
from tarsier import Tarsier, GoogleVisionOCRService
import json

def load_google_cloud_credentials(json_file_path):
    with open(json_file_path) as f:
        credentials = json.load(f)
    return credentials

async def main():
    # To create the service account key, follow the instructions on this SO answer https://stackoverflow.com/a/46290808/1780891
    google_cloud_credentials = load_google_cloud_credentials('./google_service_acc_key.json')

    ocr_service = GoogleVisionOCRService(google_cloud_credentials)
    tarsier = Tarsier(ocr_service)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto(&quot;https://news.ycombinator.com&quot;)

        page_text, tag_to_xpath = await tarsier.page_to_text(page)

        print(tag_to_xpath)  # Mapping of tags to x_paths
        print(page_text)  # My Text representation of the page


if __name__ == '__main__':
    asyncio.run(main())"><pre><span>import</span> <span>asyncio</span>

<span>from</span> <span>playwright</span>.<span>async_api</span> <span>import</span> <span>async_playwright</span>
<span>from</span> <span>tarsier</span> <span>import</span> <span>Tarsier</span>, <span>GoogleVisionOCRService</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load_google_cloud_credentials</span>(<span>json_file_path</span>):
    <span>with</span> <span>open</span>(<span>json_file_path</span>) <span>as</span> <span>f</span>:
        <span>credentials</span> <span>=</span> <span>json</span>.<span>load</span>(<span>f</span>)
    <span>return</span> <span>credentials</span>

<span>async</span> <span>def</span> <span>main</span>():
    <span># To create the service account key, follow the instructions on this SO answer https://stackoverflow.com/a/46290808/1780891</span>
    <span>google_cloud_credentials</span> <span>=</span> <span>load_google_cloud_credentials</span>(<span>'./google_service_acc_key.json'</span>)

    <span>ocr_service</span> <span>=</span> <span>GoogleVisionOCRService</span>(<span>google_cloud_credentials</span>)
    <span>tarsier</span> <span>=</span> <span>Tarsier</span>(<span>ocr_service</span>)

    <span>async</span> <span>with</span> <span>async_playwright</span>() <span>as</span> <span>p</span>:
        <span>browser</span> <span>=</span> <span>await</span> <span>p</span>.<span>chromium</span>.<span>launch</span>(<span>headless</span><span>=</span><span>False</span>)
        <span>page</span> <span>=</span> <span>await</span> <span>browser</span>.<span>new_page</span>()
        <span>await</span> <span>page</span>.<span>goto</span>(<span>"https://news.ycombinator.com"</span>)

        <span>page_text</span>, <span>tag_to_xpath</span> <span>=</span> <span>await</span> <span>tarsier</span>.<span>page_to_text</span>(<span>page</span>)

        <span>print</span>(<span>tag_to_xpath</span>)  <span># Mapping of tags to x_paths</span>
        <span>print</span>(<span>page_text</span>)  <span># My Text representation of the page</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span>:
    <span>asyncio</span>.<span>run</span>(<span>main</span>())</pre></div>
<p dir="auto">Keep in mind that Tarsier tags different types of elements differently to help your LLM identify what actions are performable on each element. Specifically:</p>
<ul dir="auto">
<li><code>[#ID]</code>: text-insertable fields (e.g. <code>textarea</code>, <code>input</code> with textual type)</li>
<li><code>[@ID]</code>: hyperlinks (<code>&lt;a&gt;</code> tags)</li>
<li><code>[$ID]</code>: other interactable elements (e.g. <code>button</code>, <code>select</code>)</li>
<li><code>[ID]</code>: plain text (if you pass <code>tag_text_elements=True</code>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local Development</h2><a id="user-content-local-development" aria-label="Permalink: Local Development" href="#local-development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">We have provided a handy setup script to get you up and running with Tarsier development.</p>

<p dir="auto">If you modify any TypeScript files used by Tarsier, you'll need to execute the following command.
This compiles the TypeScript into JavaScript, which can then be utilized in the Python package.</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto">We use <a href="https://docs.pytest.org/" rel="nofollow">pytest</a> for testing. To run the tests, simply run:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Linting</h3><a id="user-content-linting" aria-label="Permalink: Linting" href="#linting"></a></p>
<p dir="auto">Prior to submitting a potential PR, please run the following to format your code:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Supported OCR Services</h2><a id="user-content-supported-ocr-services" aria-label="Permalink: Supported OCR Services" href="#supported-ocr-services"></a></p>
<ul>
<li> <a href="https://cloud.google.com/vision" rel="nofollow">Google Cloud Vision</a></li>
<li> <a href="https://aws.amazon.com/textract/" rel="nofollow">Amazon Textract</a> (Coming Soon)</li>
<li> <a href="https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/" rel="nofollow">Microsoft Azure Computer Vision</a> (Coming Soon)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul>
<li> Add documentation and examples</li>
<li> Clean up interfaces and add unit tests</li>
<li> Launch</li>
<li> Improve OCR text performance</li>
<li> Add options to customize tagging styling</li>
<li> Add support for other browsers drivers as necessary</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citations</h2><a id="user-content-citations" aria-label="Permalink: Citations" href="#citations"></a></p>
<div data-snippet-clipboard-copy-content="bibtex
@misc{reworkd2023tarsier,
  title        = {Tarsier},
  author       = {Rohan Pandey and Adam Watkins and Asim Shrestha and Srijan Subedi},
  year         = {2023},
  howpublished = {GitHub},
  url          = {https://github.com/reworkd/tarsier}
}"><pre><code>bibtex
@misc{reworkd2023tarsier,
  title        = {Tarsier},
  author       = {Rohan Pandey and Adam Watkins and Asim Shrestha and Srijan Subedi},
  year         = {2023},
  howpublished = {GitHub},
  url          = {https://github.com/reworkd/tarsier}
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three of the oldest stars in the universe found circling the Milky Way (113 pts)]]></title>
            <link>https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514</link>
            <guid>40369226</guid>
            <pubDate>Wed, 15 May 2024 16:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514">https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514</a>, See on <a href="https://news.ycombinator.com/item?id=40369226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

            <p>MIT researchers, including several undergraduate students, have discovered three of the oldest stars in the universe, and they happen to live in our own galactic neighborhood.</p><p>The team spotted the stars in the Milky Way’s “halo” — the cloud of stars that&nbsp;envelopes the entire&nbsp;main galactic disk. Based on the team’s analysis, the three stars formed between 12 and 13 billion years ago, the time when the very first galaxies were taking shape.</p><p>The researchers have coined the stars “SASS,” for Small Accreted Stellar System stars, as they believe each star once belonged to its own small, primitive galaxy that was later absorbed by&nbsp;the&nbsp;larger&nbsp;but still growing&nbsp;Milky Way. Today, the three stars are all that are left of their respective galaxies. They circle the outskirts of the Milky Way, where the team suspects there may be more such ancient stellar survivors.</p><p>“These oldest stars should definitely be there, given what we know of galaxy formation,” says MIT professor of physics Anna Frebel. “They are part of our cosmic family tree. And we now have a new way to find them.”</p><p>As they uncover similar SASS stars, the researchers hope to use them as analogs of ultrafaint dwarf galaxies, which are thought to be some of the universe’s&nbsp;surviving&nbsp;first galaxies. Such galaxies are still intact today but are too distant and faint for astronomers to study in depth. As SASS stars may have once belonged to similarly primitive dwarf galaxies but are&nbsp;in the Milky Way and as such&nbsp;much closer, they could be an accessible key to understanding the evolution of ultrafaint dwarf galaxies.</p><p>“Now we can look for more analogs in the Milky Way, that are much brighter, and study their chemical evolution without having to chase these extremely faint stars,” Frebel says.</p><p>She and her colleagues have <a href="https://doi.org/10.1093/mnras/stae670" target="_blank">published their findings today</a> in the <em>Monthly Notices of the Royal Astronomical Society (MNRAS)</em>. The study’s co-authors are Mohammad Mardini, at&nbsp;Zarqa University, in Jordan; Hillary Andales ’23; and current MIT undergraduates Ananda Santos and Casey Fienberg.</p><p><strong>Stellar frontier</strong></p><p>The team’s discoveries grew out of a classroom&nbsp;concept. During the 2022 fall semester, Frebel launched a new course, 8.S30<em>&nbsp;</em>(Observational Stellar Archaeology), in which students learned techniques for analyzing ancient stars and then applied those tools to stars that had never been studied before, to determine their origins.</p><p>“While most of our classes are taught from the ground up, this class immediately put us at the frontier of research in astrophysics,” Andales says.</p><p>The students worked from star data collected by Frebel over the years from&nbsp;the 6.5-meter Magellan-Clay telescope&nbsp;at the Las Campanas Observatory. She keeps hard copies of the data in a large binder in her office, which the students combed through to look for stars of interest.</p><p>In particular, they were searching ancient stars that formed&nbsp;soon after the Big Bang, which occurred&nbsp;13.8 billion years ago. At this time, the universe was made mostly of hydrogen and helium and very low abundances of other chemical elements, such as strontium and barium. So, the students looked through Frebel’s binder for stars with spectra, or measurements of starlight, that indicated low abundances of strontium and barium.</p><p>Their search narrowed in on three stars that were originally observed by the Magellan&nbsp;telescope&nbsp;between 2013 and 2014. Astronomers never followed up on these particular stars to interpret their spectra and deduce their origins. They were, then, perfect candidates for the students in Frebel’s class.</p><p>The students&nbsp;learned how to characterize a star in order to prepare for the analysis of&nbsp;the spectra for each of the three stars. They&nbsp;were able to determine the chemical composition of each one with&nbsp;various&nbsp;stellar&nbsp;models.&nbsp;The intensity of a particular&nbsp;feature in the stellar spectrum, corresponding to a specific&nbsp;wavelength of light, corresponds to a particular abundance of a specific element.</p><p>After&nbsp;finalizing their analysis, the students were able to confidently conclude that the three stars did hold very low abundances of strontium, barium, and other&nbsp;elements such as iron, compared to their&nbsp;reference&nbsp;star — our own sun. In fact, one star contained less than 1/10,000 the amount of iron to helium compared to the sun today.</p><p>“It took a lot of hours staring at a computer, and a lot of debugging, frantically texting and emailing each other to figure this out,” Santos recalls. “It was a big learning curve, and a special experience.”</p><p><strong>“On the run”</strong></p><p>The stars’ low chemical abundance did hint that they originally formed 12 to 13 billion years ago. In fact, their low chemical signatures were similar to what astronomers had previously measured for some ancient, ultrafaint dwarf galaxies. Did the team’s stars originate in similar galaxies? And how did they come to be in the Milky Way?</p><p>On a hunch, the scientists checked out the stars’ orbital patterns and how they move across the sky. The three stars are in different locations throughout the Milky Way’s halo and are estimated to be about 30,000 light years from Earth. (For reference, the disk of the Milky Way spans 100,000 light years across.)</p><p>As they retraced each star’s motion&nbsp;about the galactic center using observations from the Gaia astrometric satellite, the team noticed a curious thing: Relative to most of the stars in the main disk, which move like cars on a racetrack, all three stars seemed to be going the wrong way. In astronomy, this is known as “retrograde motion” and is a tipoff that an object was once “accreted,” or drawn in from elsewhere.</p><p>“The only way you can have stars going the wrong way from the rest of the gang is if you threw them in the wrong way,” Frebel says.</p><p>The fact that these three stars were orbiting in completely different ways from the rest of the galactic disk and even the halo, combined with the fact that they held low chemical abundances, made a strong case that the stars were indeed ancient and once belonged to older, smaller dwarf galaxies that fell into the Milky Way at random angles and continued their stubborn trajectories billions of years later.</p><p>Frebel, curious as to whether retrograde motion was a feature of other ancient stars in the halo that astronomers previously analyzed, looked through the scientific literature and found 65 other stars, also with low strontium and barium abundances, that appeared to also be going against the galactic flow.</p><p>“Interestingly they’re all quite fast — hundreds of kilometers per second, going the wrong way,” Frebel says. “They’re on the run! We don’t know why that’s the case, but&nbsp;it was the piece to the puzzle that we needed, and that I didn’t quite anticipate when we started.”</p><p>The team is eager to search out other ancient SASS stars, and they now have a relatively simple recipe to do so: First, look for stars with low chemical abundances, and then track their orbital patterns for signs of retrograde motion. Of the more than 400 billion stars in the Milky Way, they anticipate that the method will turn up a small but significant number of the universe’s oldest stars.</p><p>Frebel plans to relaunch the class&nbsp;this&nbsp;fall, and looks back at that first course, and the three students who took their results through to publication, with admiration and gratitude.</p><p>“It’s been awesome to work with three women undergrads. That’s a first for me,” she says. “It’s really an example of the MIT way. We do. And whoever says, ‘I want to participate,’ they can do that, and good things happen.”</p><p>This research was supported, in part, by the National Science Foundation.</p>        

      </div><div>
  
  
  

      <header>
      <h2>Press Mentions</h2>
    </header>
  
  
  

  <div><h3>Gizmodo</h3><p>Isaac Schultz of <em>Gizmodo</em> reports on recent research by Prof. Anna Frebel and colleagues identifying some of the oldest&nbsp;stars in our universe, which grew from Frebel’s new course, 8.S30 (Observational Stellar Archaeology). “Studying the ancient stars won’t only help explain the timeline of stellar evolution, but how our galaxy actually formed,” Schultz explains.&nbsp;</p></div>


    

  
  

  
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starting emails with "BEGIN PGP MESSAGE" will fool the filter (231 pts)]]></title>
            <link>https://nondeterministic.computer/@martin/112444389342113780</link>
            <guid>40369119</guid>
            <pubDate>Wed, 15 May 2024 16:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nondeterministic.computer/@martin/112444389342113780">https://nondeterministic.computer/@martin/112444389342113780</a>, See on <a href="https://news.ycombinator.com/item?id=40369119">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Reasons not to take Lumina's anticavity probiotic (182 pts)]]></title>
            <link>https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity</link>
            <guid>40369084</guid>
            <pubDate>Wed, 15 May 2024 16:29:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity">https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity</a>, See on <a href="https://news.ycombinator.com/item?id=40369084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I like to think of the Bay Area intellectual culture as the equivalent of the Vogons’ in </span><em>Hitchhiker’s Guide to the Galaxy</em><span>. The Vogons, if you don’t remember, are an alien species who demolish Earth to build an interstellar highway. Similarly, Bay Area intellectuals tend to see some goal in the future that they want to get to and they make a straight line for it, tunneling through anything in their way.&nbsp;</span></p><p>Sometimes this Bay Area tunneling produces great results and benefits a lot of people. Sometimes it produces terrible results and harms a lot of people. But, regardless of the quality of the results, it always leaves behind a hole.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg" width="512" height="288.0450070323488" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1422,&quot;resizeWidth&quot;:512,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...\&quot; - The Hitchhiker's Guide to the Galaxy quote&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...&quot; - The Hitchhiker's Guide to the Galaxy quote" title="Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...&quot; - The Hitchhiker's Guide to the Galaxy quote" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>“You see, your response of ‘You should probably do at least a little bit of research before confidently stating your opinion on a technical topic’ was a clear example of an </span><em>ad hominem</em><span> fallacy, which is explained here on page 495 of the Sequences. Allow me to read this whole chapter to you…”</span></figcaption></figure></div><p>Speaking of holes, in my weird, nerdy corner of the Internet, there’s recently been a hubbub around an anticavity probiotic, Lumina Probiotic, coming straight from the Bay Area. In the literal sense, this probiotic is meant to prevent holes (in teeth). In the more metaphorical sense, though, it fits in well with previous Bay Area fads, tunneling not only through the dentistry industry but also through the FDA approval process. You see, despite this being clearly a drug and thus under FDA/CDER purview, the founder of Lumina, Aaron Silverbook, has decided to sell this directly to the public as a cosmetic product without doing the requisite safety and efficacy tests.</p><p>In case you can’t tell by the title of the post, I think this is a terrible idea, as well as probably illegal. Unlike most people in the Bay Area, I think formalized safety and efficacy trials are a must for health products. In fact, I told Aaron Silverbook this when he asked me for my advice about his product last fall. No, the FDA is not a perfect institution, and yes, it can be improved in many, many ways. But the history of health product regulation is written in blood. There’s a reason why we need some sort of regulation, even if that form of regulation can be improved.</p><p><span>I’ve been annoyed for some months now to see Lumina sell their product directly to the public without FDA approval or even human trials. I’ve also been disappointed for some months to see how many people I respect (and some I don’t respect) have been using it/promoting it. Taking unapproved drugs is a bad idea, no matter what rationalist bloggers with MDs, porn star/escort/sex researchers, Twitter guys, or </span><a href="https://manifold.markets/Reddit/will-richard-hanania-find-out-his-r" rel="">conservative firebrands who get sick immediately after taking the unapproved drug</a><span> tell you.</span></p><p>Despite my annoyance, I had resigned myself to just grumbling about Lumina to my friends. That is, until last week, when I randomly started looking more deeply into some of Lumina’s claims as part of an unrelated project. As I looked more deeply, I became convinced that many of Lumina’s claims are unfounded, and it is, in fact, simultaneously a more dangerous and less effective drug than Lumina or its boosters have been publicly saying that it is. So, I thought it’d be best to write a blog post and share my criticisms to stop people from getting sick from a bad drug.</p><p><span>Also, before I start, I did only think it fair to ask Aaron Silverbook for his comments on this blog post before publishing. So far, I haven’t heard back</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-1-144660269" target="_self" rel="">1</a></span><span>, but I will update this post if I do. With that in mind, let’s begin.</span></p><p><span>Your mouth has a bunch of bacteria in it all the time. In a healthy mouth, these bacteria are useful insofar as they prevent other, worse bacteria from taking up residence in your mouth. However, these bacteria, like the bacteria in your </span><a href="https://trevorklee.substack.com/p/ground-squirrel-microbiomes-are-neat/comments" rel="">gut</a><span> or </span><a href="https://trevorklee.substack.com/p/bacterial-vaginosis-we-contain-multitudes?r=3ege4" rel="">vagina</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-2-144660269" target="_self" rel="">2</a></span><span> (assuming you have one) are only “good” insofar as your body can keep them in check, mostly through flushing the bacteria from your mouth to your stomach via swallowing, at which point they get destroyed by stomach acid.</span></p><p>Sometimes your body can’t keep these bacteria in check, like when defense mechanisms fail (e.g. persistent lack of saliva) or the mouth becomes more hospitable for the bacteria (e.g. excess of sugar). The bacteria start to overgrow. And when you give bacteria an inch, they take a mile, fortifying their position. The most important way they do that in the mouth is by forming biofilms on the teeth (dental plaque), which are “bacterial cities”. These biofilms are mutual aid pacts, in which bacteria share defenses, nutrients, and swap useful genes.</p><p><span>In the mouth, the biofilms also help the bacteria produce a more hospitable habitat for themselves. These bacteria, specifically </span><em>Streptococcus mutans, Streptococcus sobrinus, </em><span>and lactobacilli produce lactic acid through their metabolism. This not only changes the local environment to be a more preferable pH, but it also lets them create pits in teeth by demineralizing the teeth to live in. These pits, if they don’t get remineralized by the saliva, become cavities.</span></p><p>This is all pretty settled science. Brushing your teeth with a fluoride-enhanced toothpaste, like you’ve probably done your entire life, is meant to disrupt these biofilms and promote remineralization of these pits. The newer, less settled science mostly revolves around ways to combat these cavity-causing bacteria directly. There have been various attempts to create vaccines or antibiotics for these bacteria, none of which have been amazingly successful.</p><p>One inventor who’s tried repeatedly to address this issue is a guy named Jeffrey Hillman, who’s technically a dentist by training. Starting in the 80s and continuing through the 2000s, he tried to make an idea work where he would genetically engineer safe bacteria to outcompete the bacteria in the mouth that cause cavities and then permanently reside in the mouth. The result would be a mouth permanently full of safe bacteria that couldn’t possibly cause cavities and would beat up any dangerous bacteria that would.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg" width="634" height="356" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:356,&quot;width&quot;:634,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Wonka's Origins Charlie And The Chocolate Factory, 40% OFF&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Wonka's Origins Charlie And The Chocolate Factory, 40% OFF" title="Wonka's Origins Charlie And The Chocolate Factory, 40% OFF" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Pictured: Jeffrey Hillman’s origin story. Any resemblance to Tim Burton’s 2005 remake of </span><em>Willy Wonka</em><span> is purely coincidental. Ignore the Warner Bros. copyright in the corner. </span></figcaption></figure></div><p><span>His ideas around this went through several iterations, a lot of money (definitely tens of millions and possibly more), and several companies, most notably Oragenics. After a number of rat trials (which </span><a href="https://twitter.com/natalia__coelho/status/1778537436446117985?utm_source=substack&amp;utm_medium=email" rel="">weren’t entirely successful</a><span>), one or two aborted human trials</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-3-144660269" target="_self" rel="">3</a></span><span>, and two bouts of self-experimentation, the idea died on the vine in the 2000s. Then, it was reborn in a less exciting way as </span><a href="https://probiorahealth.com/patented-formula/" rel="">ProBiora</a><span>, a formulation of specially picked, non-genetically engineered bacteria that would also outcompete dangerous oral bacteria. This product </span><a href="https://pubmed.ncbi.nlm.nih.gov/26427036/" rel="">then failed its one-and-only human trial</a><span>, an outcome Hillman apparently ignored. You can now buy ProBiora today at all participating retailers.</span></p><p><span>Fast-forward to last year, when rationalist Aaron Silverbook came across Hillman’s original work with the genetically modified bacteria. Aaron, based on his previous work as </span><a href="https://manifund.org/projects/recreate-the-cavity-preventing-gmo-bacteria-bcs3-l1-from-precursor-" rel="">guy at a rationalist nonprofit, videogame producer, and porn producer</a><span>, decided to recreate Hillman’s work</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-4-144660269" target="_self" rel="">4</a></span><span>. First, he applied for funding from FTX. He got it, but then FTX collapsed. Then, he applied for funding from alternative rationalist funding source Manifund, got that, and failed to recreate Hillman’s work. However, </span><a href="https://manifold.markets/Austin/if-funded-will-lantern-bioworks-suc" rel="">Aaron declared mission success anyways</a><span> in that he negotiated with Oragenics to acquire a sample of BCS3L-1, one of Hillman’s later strains</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-5-144660269" target="_self" rel="">5</a></span><span>, in exchange for $50k and promise of royalties, although </span><a href="https://www.oragenics.com/news-media/press-releases/detail/163/oragenics-enters-into-agreement-with-lantern-bioworks-for" rel="">he didn’t get any intellectual property rights</a><span> .</span></p><p>Aaron then went on an intellectual journey where he tried to figure out what exactly to do with this genetically modified bacteria. After all, he was faced with basically the same daunting FDA journey as Hillman, but without Hillman’s scientific background or financial resources. After talking to a bunch of people, including me, he eventually decided on a very rationalist, very Bay Area, very strange approach:</p><p>1. Sell the genetically modified bacteria as-is for a one time payment of $20,000 in a libertarian charter city in Honduras</p><p>2. Give a bunch of rationalist-adjacent celebrities free samples of the GMO bacteria as-is in exchange for positive press, including Scott Alexander, Aella (the porn star/escort/sex researcher who he’s the business manager for), Richard Hanania, Cremieux, and Bryan Caplan</p><p>3. Take preorders for $200 a piece from the general public</p><p>It’s worth noting that, regardless of what I think of this plan (i.e. it’s bad and maybe unethical), I’m pretty sure this plan is also illegal. While Lantern claims to be marketing this probiotic as a cosmetic, it is meant to prevent and cure tooth decay. According to the WHO, tooth decay is a disease. A product meant to cure and prevent a disease is a drug, and legally needs to go through the drug approval process. But, you know, whatever.</p><p>Anyhow, enough about Lumina as a company. Let’s talk about Lumina’s science.</p><div><p><span>It’s a little hard to say. Jeffrey Hillman created a bunch of different versions of his genetically modified bacteria with a confusing naming structure. But, as far as I can tell, BCS3L-1 was/is a genetically modified </span><em>S. mutans</em><span> bacteria with </span><a href="https://sci-hub.gupiaoq.com/10.1023/a:1020695902160" rel="">four main features</a><span>:</span></p><p><span>1. It produced mutacin-1140, a naturally occurring antibiotic in the bacteriocin family.</span></p></div><p>2. It was resistant itself to mutacin-1140.</p><p>3. It produced alcohol instead of lactic acid.</p><p><span>4. It has a deleted </span><em>comE</em><span> gene, which was intended to prevent genetic transformation by wildtype, existing </span><em>S. mutans</em><span>.</span></p><p><span>The first 2 features are natural and occur with some frequency in </span><em>S. mutans</em><span> population. Specifically, </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel="">there are at least 3 </a><em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel="">S. mutans</a></em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel=""> groups which both secrete and are resistant to mutacin</a><span> including the group that BCS3L-1 comes from.</span></p><p><span>The second 2 features are engineered. BCS3L-1 has its </span><em>ldh</em><span> gene replaced by an alcoholic dehydrogenase gene, and has, as mentioned, a deleted </span><em>comE </em><span>gene.</span></p><p><span>The lack of an </span><em>ldh</em><span> gene means that BCS3L-1 does not produce lactic acid. The alcoholic dehydrogenase gene means that it produces ethanol instead. I don’t think this is the safest way to replace lactic acid, although I don’t think this is the biggest problem with BCS3L-1</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-6-144660269" target="_self" rel="">6</a></span><span>.</span></p><p><span>The lack of a </span><em>comE </em><span>gene is hard for me to evaluate. As of the early 2000s, when Hillman was creating BCS3L-1,</span><em> </em><span>deleting </span><em>comE </em><span>seemed like a definitive way to prevent BCS3L-1 from forming effective biofilms or taking up helpful genes (like, say, regaining the </span><em>ldh</em><span> gene). </span><a href="https://www.mdpi.com/2073-4425/8/1/15" rel="">As of 2017</a><span>, this picture is much more complicated. </span><em>comE</em><span> is involved in many different things, and some of its functions are redundant.</span></p><p><span>So, deletion of </span><em>comE</em><span> would definitely make it more difficult for BCS3L-1 to be transformed, but it would likely not make it impossible. It would definitely make it harder for BCS3L-1 to survive in the mouth and compete against wildtype </span><em>S. mutans</em><span> who are resistant to mutacin-1140. And it definitely would not make it impossible for BCS3L-1 to transform other </span><em>S. mutans</em><span>, like by autolysis, which is basically bacterial self-detonation. This releases bacterial DNA in the biofilm, so it could result in wildtype </span><em>S. mutans</em><span> getting some of the genes of BCS3L-1 (like resistance to mutacin 1140).</span></p><p><span>Putting this all together, putting BCS3L-1 in your mouth results in your teeth being colonized by whatever bacteria are resistant to mutacin-1140. Ideally, this would be some mixture of BCS3L-1 and harmless bacteria. However, if any other bacteria are in the mouth that are resistant to mutacin-1140 and can live on your teeth (e.g. naturally occurring mutacin-resitant </span><em>S. mutans</em><span>), they will become the dominant species in your mouth, as BCS3L-1 has several fitness-decreasing mutations. Or, it’s entirely possible that BCS3L-1 will start off by being the dominant species in your mouth, then, at some point, will just transform the existing </span><em>S. mutans</em><span> into mutacin-1140 resistant </span><em>S. mutans</em><span>, at which point these wildtype </span><em>S. mutans </em><span>will, again, become the dominant species in your mouth.</span></p><p>But let’s say BCS3L-1 becomes the dominant species in your mouth. What then? Are there any health risks? I’m glad you asked.</p><p>When I talk about the health risks of BCS3L-1, there are really two categories of health risks to discuss: the health risks if BCS3L-1 works as intended, and the health risks if it doesn’t. You see, one of the main functions of the FDA is to not only outline the health risks of products working as intended, but to minimize the health risks of products not working as intended. Like, say, the health risks involved with the product being contaminated.</p><p><span>BCS3L-1 is a probiotic, which is a bacteria that you ingest. This puts it in the same category as kombucha or yogurt. And, like </span><a href="https://www.reddit.com/r/Kombucha/comments/a3pxz7/my_homemade_kombucha_which_i_swore_by_was_making/" rel="">kombucha</a><span> or </span><a href="https://japantoday.com/category/national/students-hospitalized-after-eating-teacher%E2%80%99s-homemade-yogurt-in-nagoya" rel="">yogurt</a><span>, improper manufacturing of BCS3L-1 could introduce any number of contaminants into the product, including foreign bacteria or fungi (like mold). These can make you incredibly sick or even kill you.</span></p><p><span>The FDA has strict manufacturing standards when it comes to probiotics, known as </span><a href="https://internationalprobiotics.org/wp-content/uploads/IPA-Probiotic-Manufacturing-Guidelines-2019.pdf" rel="">GMP standards</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-7-144660269" target="_self" rel="">7</a></span><span>. These include making sure your factory is clean and free from contaminants, your protocol reliably produces safe probiotics and is followed closely by your employees, and your end product is regularly tested. These standards aren’t just paper standards, either. The FDA regularly goes and inspects factories to make sure they follow GMP standards. Because these standards are so strict, most smaller drug developers, like my companies, find it cost-prohibitive to manufacture drugs ourselves, and rely on contract factories to do so.</span></p><p>If you are a Bay Area type, you might think that it’s unfair that the FDA regulates who can manufacture drugs. You’d probably be tempted to manufacture the drug by yourself. In fact, that’s what I suspect Lumina has done, because I really doubt a contract factory would be ok making an unapproved drug for them to sell to the public, as that would get the contract factory in trouble.</p><p>But, again, these standards are written in blood. As the links above suggest, even “safe” probiotics like yogurt or kombucha can make you incredibly sick or kill you if improperly manufactured. BCS3L-1 definitely could make someone sick or kill them if improperly manufactured. If Lumina is not following GMP standards, as I suspect they’re not, they are at risk of seriously injuring or killing their customers through contamination.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg" width="682" height="408" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:408,&quot;width&quot;:682,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Food Poisoning: Symptoms and Treatment | Allina Health&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Food Poisoning: Symptoms and Treatment | Allina Health" title="Food Poisoning: Symptoms and Treatment | Allina Health" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Pictured: you after ingesting contaminated, improperly manufactured probiotics. You know, in some sense, a probiotic that makes you unable to leave the toilet is also an anti-cavity probiotic, in that you will not want to eat anything afterwards.</figcaption></figure></div><p><span>Similarly, I don’t think Lumina is regularly sequencing the bacteria that they are sending out to people. They certainly aren’t following </span><a href="https://www.chpa.org/public-policy-regulatory/voluntary-codes-guidelines/best-practices-voluntary-guidelines-probiotics" rel="">the Best Practices Guidelines for Probiotics</a><span>, which require you to state how much of each strain in CFUs is in each batch that you send out on your packaging. So, when Lumina claims that you are receiving BCS3L-1, which has the modifications above, they actually have no idea what you’re receiving.&nbsp;</span></p><p>You could be receiving:</p><p>1) Just BCS3L-1</p><p>2) Random contaminants</p><p>3) Mutated BCS3L-1 (like one that regained the ability to produce lactic acid)</p><p>4) Dangerous bacteria or fungi that have taken over your batch</p><p>5) Some combination of 1 through 4</p><p><span>So, that’s what I mean when I say the first category of health risks when taking BCS3L-1 are the unknown health risks. </span><strong>Neither you, nor Lumina, have any idea what you’re infecting your mouth with.</strong></p><p>Onto the next category: the known health risks.</p><p>BCS3L-1, if you remember, produces two main byproducts by design: alcohol and mutacin-1140. Now the alcohol that BCS3L-1 produces can definitely be a health risk (see footnote 6), but I want to discuss mutacin-1140.</p><p><span>Mutacin-1140 is an antibiotic in the lantibiotic class. Oragenics has spent the past 20 years or so trying to develop it and related antibiotics commercially, </span><a href="https://pubmed.ncbi.nlm.nih.gov/30479173/" rel="">most notably for </a><em><a href="https://pubmed.ncbi.nlm.nih.gov/30479173/" rel="">C. difficile</a></em><span>, an infection of the digestive tract. They’ve struggled in part because, although mutacin-1140 can be effective against </span><em>C. difficile</em><span>, it’s </span><a href="https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2018.00415/full" rel="">somewhat cytotoxic</a><span> (i.e. is somewhat dangerous to the body) and</span><a href="https://sci-hub.gupiaoq.com/10.1517/17425255.2011.573478" rel=""> caused a hypersensitivity reaction in a rat when given through IV at a high dose</a><span>. It also has difficult pharmacokinetics, because </span><a href="https://sci-hub.gupiaoq.com/10.1517/17425255.2011.573478" rel="">it binds strongly to blood and plasma</a><span>, meaning that it tends to go everywhere that blood goes, making it hard to target specific infections.&nbsp;</span></p><p><span>On the plus side, it is very effective at surviving the digestive tract, in that </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864910/" rel="">it survives for greater than 240 minutes in simulated gastric fluid and for 72 minutes in simulated intestinal fluid</a><span>. This stability in the stomach is probably why Oragenics keeps trying to develop it for infections of the digestive tract.</span></p><p>Now, given that information, think about the wisdom of infecting your mouth with a bacteria that is designed to continually produce mutacin-1140. You are continually producing an antibiotic in your mouth that:</p><p>1) Can be dangerous</p><p>2) Goes everywhere that blood goes</p><p>3) Is not inactivated by stomach acid</p><p>4) Kills other bacteria very effectively</p><p>At the very least, this is a great way to give yourself the digestive equivalent of continually taking antibiotics (i.e. diarrhea and indigestion). This also might be a good way to give yourself a hypersensitivity reaction like that poor rat. It’s hard to say, because making a safety equivalence between taking an IV antibiotic one time at a high dose and taking an antibiotic orally at a low dose for potentially decades is really difficult. This is why the FDA requires safety studies.</p><p><span>What I can say for sure is that this would be exceptionally dangerous for infants and immunocompromised people. </span><a href="https://www.fda.gov/news-events/press-announcements/fda-raises-concerns-about-probiotic-products-sold-use-hospitalized-preterm-infants#:~:text=The%20FDA%20is%20aware%20that,the%20United%20States%20since%202018." rel="">Infants have died from hospital-grade probiotics before</a><span>, and </span><a href="https://www.sciencedirect.com/science/article/pii/S2405844024039392#:~:text=Yet%2C%20probiotics%20themselves%20may%20also,localized%20and%20opportunistic%20infections%20(Fig." rel="">immunocompromised people have gotten seriously sick</a><span>. That’s from normal, “healthy” probiotics. How do you think your infant (who does not yet have a fully colonized microbiome) will respond if you infect them with a bacterium that nukes all other bacteria in their system? Better hope you don’t kiss your baby or share food or drinks with them!</span></p><p><span>I hope I’ve conclusively proven, at this point, that Lumina has messed up big time. They have put a lot of people at risk, including everyone who they’ve non-consensually infected by introducing a genetically modified bacteria into the wild. They messed with things they didn’t understand, put profit and “acceleration” before safety, and, in one of the worst sins that a rationalist can do, tunneled a hole through the Chesterton fence of the FDA</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-8-144660269" target="_self" rel="">8</a></span><span>.</span></p><p><span>If Lumina had the good sense of Hillman (who, to be clear, I don’t think is a scientific saint either), they at least would have sold the version of the GMO bacteria that had a self-destruct button, </span><a href="https://sci-hub.gupiaoq.com/10.1111/j.1365-2672.2007.03316.x" rel="">AJ2M</a><span>, which I think was the last strain Hillman created. That one was designed to be vulnerable to chlorhexidine and to require an exogenous amino acid, d-alanine, to function. If the d-alanine stopped being provided, the bacteria died, assuming it didn’t acquire any mutations in the meantime that let it keep surviving.</span></p><p>But Lumina didn’t do that, even though I and, I assume others, told them to do that. They sold the earlier version of the probiotic without a kill-switch, which means that the cat is out of the bag and is probably giving overly credulous rationalists diarrhea as we speak. So, at the very least, Lumina needs to:</p><p>1) Stop selling the probiotic and refund everyone who’s bought it so far</p><p>2) Do research into which antibiotics and what course of antibiotics will completely remove BCS3L-1</p><p>3) Message everyone who’s bought BCS3L-1 with information on how to test if they still have it and how to rid them themselves of it if they do</p><p>4) Fund people’s doctors’ visits to rid themselves of BCS3L-1</p><p><span>Or, you know, they could also do the typical Bay Area thing and keep tunneling along regardless of what damage they leave in their wake. After all, as every dentist knows, one person’s hole is another person’s business opportunity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-9-144660269" target="_self" rel="">9</a></span><span>.</span></p><div data-attrs="{&quot;url&quot;:&quot;https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Like this post? Share it!</p><p data-attrs="{&quot;url&quot;:&quot;https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dragonfly: An optical telescope built from an array of off-the-shelf Canon lens (198 pts)]]></title>
            <link>https://www.dunlap.utoronto.ca/instrumentation/dragonfly/</link>
            <guid>40369021</guid>
            <pubDate>Wed, 15 May 2024 16:24:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dunlap.utoronto.ca/instrumentation/dragonfly/">https://www.dunlap.utoronto.ca/instrumentation/dragonfly/</a>, See on <a href="https://news.ycombinator.com/item?id=40369021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">
 




  

<div id="attachment_18521"><p><a href="http://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1.jpg"><img src="http://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-226x300.jpg" alt="" width="248" height="329" data-id="18521" srcset="https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-226x300.jpg 226w, https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-768x1020.jpg 768w, https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-771x1024.jpg 771w" sizes="(max-width: 248px) 100vw, 248px"></a></p><p>Grad student Seery Chen connects cables to a power supply on the Dragonfly telescope in New Mexico, in November of 2022. Credit: Seery Chen.</p></div>
<p>
Dragonfly is an innovative, multi-lens array designed for ultra-low surface brightness astronomy at visible wavelengths. Commissioned in 2013 with only three lenses, the array is growing in size and proving capable of detecting extremely faint, complex structure around galaxies.</p>
<p>In 2022, the Dragonfly team completed 70 per cent of its ultrawide survey, which will map out the full footprint of sloan digital sky Survey when complete.</p>
<p>An expansion of an additional 120 lenses is currently underway in 2023.</p>
<p>According to Cold Dark Matter (CDM) cosmology, structure in the Universe grows from the “bottom up”, with small galaxies merging to form larger ones. Evidence of such mergers can be seen in faint streams and filaments visible around the Milky Way Galaxy and the nearby M31 galaxy.</p>
<p>But the CDM model predicts that we should see more of this structure than is currently observed. However, images obtained using even the largest, most advanced telescopes today contain scattered light that may be hiding this faint structure. Dragonfly is designed to reveal the faint structure by greatly reducing scattered light and internal reflections within its optics. It achieves this using commercially-available Canon 400mm lenses, with unprecedented nano-fabricated coatings with sub-wavelength structure on optical glasses.</p>
<p>Also, Dragonfly images a galaxy through multiple lenses simultaneously—akin to a dragonfly’s compound eye—enabling further removal of unwanted light. The result is an image in which extremely faint galaxy structure is visible.</p>
<p><span>The&nbsp; co-principal-investigators for Dragonfly are U of T’s&nbsp;<a title="DAA Prof. Roberto Abraham" href="http://www.astro.utoronto.ca/~abraham/Web/Welcome.html" target="_blank" rel="noopener">Professor Roberto Abraham</a>&nbsp;and Yale University’s Professor Pieter van Dokkum.&nbsp;</span></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Viking 7B: open LLM for the Nordic languages trained on AMD GPUs (107 pts)]]></title>
            <link>https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages</link>
            <guid>40368760</guid>
            <pubDate>Wed, 15 May 2024 16:05:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages">https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages</a>, See on <a href="https://news.ycombinator.com/item?id=40368760">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Together with University of Turku’s research group TurkuNLP and HPLT, Europe’s largest private AI lab Silo AI is releasing the first multilingual large language model (LLM) for all Nordic languages. Viking 7B is a best-in-class open source model that is sensitive to local values and cultures and further evidence of the team’s novel approach to training capable LLMs for low-resource languages. It is a significant milestone on the journey towards a state-of-the-art LLM family for all European languages.</strong></p><p>Following the completion of the language model <a href="https://www.silo.ai/blog/europes-open-language-model-poro-a-milestone-for-european-ai-and-low-resource-languages">Poro</a>, and the first checkpoint release of <a href="https://www.silo.ai/blog/viking-7b-13b-33b-sailing-the-nordic-seas-of-multilinguality">Viking</a>, Silo AI and TurkuNLP of University of Turku are now releasing the full 7B parameter version of Viking. At the same time, we are also releasing further checkpoints for the Viking 13B and Viking 33B models. In addition to the Nordic languages, Viking also covers English and programming languages. Evaluations indicate best-in-class performance in all Nordic languages, without compromising performance in English.&nbsp;</p><p>Viking relies on the same training approach as Poro, focusing on low-resource languages without compromising English, but extends to include Danish, Finnish, Norwegian, Icelandic, Swedish and programming languages. And the model family comes with an updated architecture and in a variety of model sizes. </p><p>Building on Silo AI's strategy to promote democratic access to LLMs and promote linguistic diversity across Europe, the collaboration with TurkuNLP utilizes the latest advancements in multilingual LLMs. Unlike most other LLMs, we're prioritizing low-resource language performance, rather than relegating them to an afterthought. The team has worked on determining optimal training approaches and architectures to support this. This covers optimal model architecture for pre-training, as well as other approaches to training and data sampling like data reuse frequencies for low-resource languages during training and incorporating translated paired texts between high- and low-resource languages. Several of these strategies rely on a cross-lingual signal to enhance the model's understanding of the connections between languages, proving crucial in achieving superior performance for low-resource languages, without compromising performance in English.</p><p>Silo AI and TurkuNLP are dedicated to developing models that not only excel in linguistic performance and inclusivity but are also attuned to local values and cultures. Such sensitivity ensures that these technological advancements serve as connectors, rather than dividers, in digital communication. It enhances Europe’s digital infrastructure, thereby accelerating the adoption of LLM-driven products and applications. This, in turn, fosters innovation across sectors and use cases throughout Europe, bolstering the continent's technological ecosystem.</p><p>Further emphasizing digital sovereignty, Viking is trained on the EuroHPC supercomputer LUMI, utilizing up to 4096 AMD MI-250X GPUs. LUMI is not only Europe’s most powerful supercomputer and the 5th most powerful in the world, but also the 3rd greenest supercomputer among the top 500 supercomputers. LUMI’s energy consumption is covered with power produced 100% with hydroelectricity, and the waste heat of LUMI will account for about 20 percent of the district heating in the surrounding city of Kajaani.&nbsp;</p><p>With a purpose-built software layer to train models on AMD, Silo AI and TurkuNLP possess unmatched experience with training on AMD at scale, having <a href="https://lumi-supercomputer.eu/scaling-the-pre-training-of-large-language-models-of-100b-parameters-to-thousands-of-amd-mi250x-gpus-on-lumi/">shown that their</a> theoretical predictions for throughput scaling materialize in weak and strong scaling experiments. As one of the seminal initiatives on AMD GPUs, this shows how it’s possible to achieve good throughput on the AMD-based LUMI, training the models with their open source training framework and utilizing up to 4096 MI-250X GPUs simultaneously.</p><h2>Viking 7B completed and checkpoint performance</h2><p>Today, the Viking models stand at 100% of training on Viking 7B, 85% on 13B and 65% on 33B. With common benchmarks, we can observe evidence of outperformance with respect to other open models (e.g. Falcon, GPT-SW3, Llama, Mistral, MPT, etc). Results indicate best-in-class performance in low-resource languages vis-à-vis other open models, without compromising performance in English and programming languages. In our latest evaluations, Viking is benchmarked on a large number of relevant measures, including translated tests, MMLU, Arc-C, HellaSwag etc. While translated tests are commonly used (e.g. to prove multilinguality of Mistral Large) and provide indicative evidence, they don't fully capture the multilingual reasoning capabilities of language models. Another measure, perplexity, further corroborates Viking’s performance. Overall, Viking not only showcases its adeptness at understanding and generating Nordic languages but also highlights its efficiency in processing and predicting linguistic sequences. This dual advantage indicates the viability of the approach to train multilingual models, and Viking's technological edge in navigating the complexities of multilinguality.</p><h2>Viking 7B/13B/33B: A modern architecture with more languages</h2><p>Below is a summary of key features of the Viking model family covering English, Finnish, Swedish, Norwegian, Danish, Icelandic and code:</p><p>‍</p><ul role="list"><li><strong>Research Checkpoints: </strong>Silo AI and TurkuNLP are committed to publishing checkpoints throughout the training process, providing transparency on the model training process.</li><li><strong>Model architecture:</strong> Viking uses an architecture similar to Llama 2, with flash attention, rotary embeddings, grouped query attention and supports a 4k sequence length</li><li><strong>Model sizes: </strong>7B, 13B and 33B parameters</li><li><strong>Multilingual capabilities: </strong>The models are designed to process English and Nordic languages, and have proficiency with a variety of programming languages. Additionally, they can perform basic translation between English and Nordic languages.</li><li><strong>Dataset:</strong> The model family is trained with a dataset of 2 trillion tokens, including Danish, English, Finnish, Icelandic, Norwegian, Swedish and a variety of programming languages.</li><li><strong>Open source: </strong>The model family is freely available under the Apache 2.0 License, implying applicability for both commercial and research use.</li><li><strong>Training hardware: </strong>Our models are trained using the LUMI supercomputer in Finland, covering up to 4096 AMD MI250X GPUs.</li></ul><h3>Considerations for Use</h3><p>The intended audience for Poro Research Checkpoints is academic and industry research. These checkpoints are not suitable for deployment in a production use case without further training, fine-tuning and testing. For more on Silo AI's SaaS-based custom LLMs we invite you to familiarize yourself with the <a href="https://www.silo.ai/silogen">SiloGen platform</a>.</p><h3>Acknowledgments</h3><p>We wish to thank the operators of the <a href="https://www.lumi-supercomputer.eu/">LUMI/EuroHPC</a> supercomputer for computational resources and technical support, including AMD, HPE and CSC – the IT Center for Science, Finland. TurkuNLP researchers have received funding from the European Union’s Horizon Europe research and innovation programme High Performance Language Technologies (HPLT) under grant agreement No 101070350.</p><p>‍</p></div><div><h2>About</h2><div role="list"><div role="listitem"><h3>Silo AI</h3><p>Silo AI is Europe’s largest private AI lab on a mission to ensure Europe has a flagship AI company. We’re a trusted AI partner that brings competitive advantage to product R&amp;D. We build AI-driven solutions and products to enable smart devices, autonomous vehicles, industry 4.0, and smart cities. Silo AI provides its customers unique access to world-class AI models and expertise, as well as the Silo OS infrastructure to speed up AI development and deployment. With SiloGen, Silo AI is currently building market leading open source LLMs, with the intent to ensure European digital sovereignty and democratize access to LLMs.</p><p><a href="https://www.silo.ai/" target="_blank">www.silo.ai</a></p></div><div role="listitem"><h3>TurkuNLP</h3><p>The TurkuNLP Group is a group of researchers at the University of Turku, with a research focus on various aspects of natural language processing, language technology and digital linguistics. TurkuNLP has contributed to a large number of open source NLP resources, such as FinBERT, WikiBERT, FinGPT, Turku Dependency Treebank, Universal Dependencies, Turku Neural Parsing Pipeline, Large internet corpora, Turku Paraphrase Corpus, Turku Sentiment Corpus, Wikidata normalization, TurkuONE etc. The University of Turku is an international academic community of 25,000 students and staff and was ranked among the 301–400 best universities in the 2023 Shanghai Ranking. </p></div></div></div><div><h2>Want to discuss how Silo AI could help your organization?</h2><p>Get in touch with our AI&nbsp;experts.</p><div><p><img loading="lazy" alt="" src="https://assets-global.website-files.com/63beb9b135d26ec169729fa2/63f603ac4a61da58b147991a_peter-sarlin.jpg"></p><div><p>Peter Sarlin, PhD</p><p>CEO &amp; Co-Founder</p></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>