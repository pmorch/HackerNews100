<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 01 Aug 2023 13:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[First claimed successful replication of LK-99 (282 pts)]]></title>
            <link>https://twitter.com/Andercot/status/1686286684424691712</link>
            <guid>36953819</guid>
            <pubDate>Tue, 01 Aug 2023 08:45:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Andercot/status/1686286684424691712">https://twitter.com/Andercot/status/1686286684424691712</a>, See on <a href="https://news.ycombinator.com/item?id=36953819">Hacker News</a></p>
Couldn't get https://twitter.com/Andercot/status/1686286684424691712: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Room-Temperature Ambient-Pressure Superconductor LK-99 preprint revision 2 (306 pts)]]></title>
            <link>https://arxiv.org/abs/2307.12037</link>
            <guid>36952894</guid>
            <pubDate>Tue, 01 Aug 2023 06:12:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2307.12037">https://arxiv.org/abs/2307.12037</a>, See on <a href="https://news.ycombinator.com/item?id=36952894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2307.12037">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  A material called LK-99, a modified-lead apatite crystal structure with the
composition Pb$_{10-x}$Cu$_x$(PO$_4$)$_{6O}$ ($0.9&lt;x&lt;1.1$), has been
synthesized using the solid-state method. The material exhibits the Ohmic metal
characteristic of Pb(6s1) above its superconducting critical temperature,
$T_c$, and the levitation phenomenon as Meissner effect of a superconductor at
room temperature and atmospheric pressure below $T_c$. A LK-99 sample shows
$T_c$ above 126.85$^\circ$C (400 K). We analyze that the possibility of
room-temperature superconductivity in this material is attributed to two
factors: the first being the volume contraction resulting from an
insulator-metal transition achieved by substituting Pb with Cu, and the second
being on-site repulsive Coulomb interaction enhanced by the structural
deformation in the one-dimensional(D) chain (Pb2-O$_{1/2}$-Pb2 along the
c-axis) structure owing to superconducting condensation at $T_c$. The mechanism
of the room-temperature $T_c$ is discussed by 1-D BR-BCS theory.

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Hyuntak Kim [<a href="https://arxiv.org/show-email/d39fdffe/2307.12037">view email</a>]
      <br>
    
        <strong><a href="https://arxiv.org/abs/2307.12037v1">[v1]</a></strong>
    
        Sat, 22 Jul 2023 10:11:28 UTC (936 KB)<br>
    
    <strong>[v2]</strong>
    
        Sat, 29 Jul 2023 01:53:47 UTC (1,014 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jujutsu: A Git-compatible DVCS that is both simple and powerful (321 pts)]]></title>
            <link>https://github.com/martinvonz/jj</link>
            <guid>36952796</guid>
            <pubDate>Tue, 01 Aug 2023 05:53:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/martinvonz/jj">https://github.com/martinvonz/jj</a>, See on <a href="https://news.ycombinator.com/item?id=36952796">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Jujutsu VCS</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/66223d9347dd19e0972b8c0993b15ee2128d3522206743bd68adf5edb9c88d5e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d617274696e766f6e7a2f6a6a"><img src="https://camo.githubusercontent.com/66223d9347dd19e0972b8c0993b15ee2128d3522206743bd68adf5edb9c88d5e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d617274696e766f6e7a2f6a6a" alt="" data-canonical-src="https://img.shields.io/github/license/martinvonz/jj"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d49bc09238c3124665edfe4bad8a2df3ae7765174fcbadab19bace8fc30c794e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6d617274696e766f6e7a2f6a6a"><img src="https://camo.githubusercontent.com/d49bc09238c3124665edfe4bad8a2df3ae7765174fcbadab19bace8fc30c794e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6d617274696e766f6e7a2f6a6a" alt="" data-canonical-src="https://img.shields.io/github/v/release/martinvonz/jj"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9c9b2c88ea25122ef25089209aaa3ccb608959154dfc6ef894581f13d5890af9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652d646174652f6d617274696e766f6e7a2f6a6a"><img src="https://camo.githubusercontent.com/9c9b2c88ea25122ef25089209aaa3ccb608959154dfc6ef894581f13d5890af9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652d646174652f6d617274696e766f6e7a2f6a6a" alt="" data-canonical-src="https://img.shields.io/github/release-date/martinvonz/jj"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/da0e9f5a2d9821345f4f236262a75f524ce3baf4171c9b8cd0a2979e3050c575/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6a6a2d636c69"><img src="https://camo.githubusercontent.com/da0e9f5a2d9821345f4f236262a75f524ce3baf4171c9b8cd0a2979e3050c575/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6a6a2d636c69" alt="" data-canonical-src="https://img.shields.io/crates/v/jj-cli"></a>
<br>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/workflows/build/badge.svg"><img src="https://github.com/martinvonz/jj/workflows/build/badge.svg" alt=""></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/46d01448672a24144a22958bd7b1c0a8193f7d056a780dcbd32a35926935726c/68747470733a2f2f696d672e736869656c64732e696f2f636f6465666163746f722f67726164652f6769746875622f6d617274696e766f6e7a2f6a6a2f6d61696e"><img src="https://camo.githubusercontent.com/46d01448672a24144a22958bd7b1c0a8193f7d056a780dcbd32a35926935726c/68747470733a2f2f696d672e736869656c64732e696f2f636f6465666163746f722f67726164652f6769746875622f6d617274696e766f6e7a2f6a6a2f6d61696e" alt="" data-canonical-src="https://img.shields.io/codefactor/grade/github/martinvonz/jj/main"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/66ead3e5479436b4d2089e5b1e7726137caa1755f5a0370b4e76702739fa74e4/68747470733a2f2f696d672e736869656c64732e696f2f6c6962726172696573696f2f6769746875622f6d617274696e766f6e7a2f6a6a"><img src="https://camo.githubusercontent.com/66ead3e5479436b4d2089e5b1e7726137caa1755f5a0370b4e76702739fa74e4/68747470733a2f2f696d672e736869656c64732e696f2f6c6962726172696573696f2f6769746875622f6d617274696e766f6e7a2f6a6a" alt="" data-canonical-src="https://img.shields.io/librariesio/github/martinvonz/jj"></a></p>
<ul dir="auto">
<li><a href="#disclaimer">Disclaimer</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#status">Status</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#command-line-completion">Command-line completion</a></li>
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#related-work">Related work</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Disclaimer</h2>
<p dir="auto">This is not a Google product. It is an experimental version-control system
(VCS). I (Martin von Zweigbergk <a href="mailto:martinvonz@google.com">martinvonz@google.com</a>) started it as a hobby
project in late 2019. That said, this it is now my full-time project at Google.
My presentation from Git Merge 2022 has information about Google's plans. See
the
<a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view" rel="nofollow">slides</a>
or the <a href="https://www.youtube.com/watch?v=bx_LGilOuE4" rel="nofollow">recording</a>.</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">Jujutsu is a <a href="https://github.com/martinvonz/jj/blob/main/docs/git-compatibility.md">Git-compatible</a>
<a href="https://en.wikipedia.org/wiki/Distributed_version_control" rel="nofollow">DVCS</a>. It combines
features from Git (data model,
<a href="https://github.com/martinvonz/jj/discussions/49" data-hovercard-type="discussion" data-hovercard-url="/martinvonz/jj/discussions/49/hovercard">speed</a>), Mercurial (anonymous
branching, simple CLI <a href="https://github.com/martinvonz/jj/blob/main/docs/git-comparison.md#the-index">free from "the index"</a>,
<a href="https://github.com/martinvonz/jj/blob/main/docs/revsets.md">revsets</a>, powerful history-rewriting), and Pijul/Darcs
(<a href="https://github.com/martinvonz/jj/blob/main/docs/conflicts.md">first-class conflicts</a>), with features not found in most
of them (<a href="https://github.com/martinvonz/jj/blob/main/docs/working-copy.md">working-copy-as-a-commit</a>,
<a href="https://github.com/martinvonz/jj/blob/main/docs/operation-log.md">undo functionality</a>, automatic rebase,
<a href="https://github.com/martinvonz/jj/blob/main/docs/technical/concurrency.md">safe replication via <code>rsync</code>, Dropbox, or distributed file
system</a>).</p>
<p dir="auto">The command-line tool is called <code>jj</code> for now because it's easy to type and easy
to replace (rare in English). The project is called "Jujutsu" because it matches
"jj".</p>
<p dir="auto">If you have any questions, please join us on Discord
<a href="https://discord.gg/dkmfj3aGQN" rel="nofollow"><img src="https://camo.githubusercontent.com/921138eb8ace84556c8918eb7f6bc869521cb974e3d7121b12314122645e8b3e/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3936383933323232303534393130333638362e7376673f6c6162656c3d266c6f676f3d646973636f7264266c6f676f436f6c6f723d66666666666626636f6c6f723d373338394438266c6162656c436f6c6f723d364137454332" alt="Discord" data-canonical-src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2"></a>
. The <a href="https://github.com/martinvonz/jj/blob/main/docs/glossary.md">glossary</a> may also be helpful.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<h3 tabindex="-1" dir="auto">Compatible with Git</h3>
<p dir="auto">Jujutsu has two <a href="https://github.com/martinvonz/jj/blob/main/docs/glossary.md#backend">backends</a>. One of them is a Git
backend (the other is a native one <sup><a href="#user-content-fn-native-backend-7cb6abcd5c51aa74722e11350c0a42f8" id="user-content-fnref-native-backend-7cb6abcd5c51aa74722e11350c0a42f8" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>). This lets you use Jujutsu
as an alternative interface to Git. The commits you create will look like
regular Git commits. You can always switch back to Git. The Git support uses the
<a href="https://libgit2.org/" rel="nofollow">libgit2</a> C library.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/blob/main/demos/git_compat.png"><img src="https://github.com/martinvonz/jj/raw/main/demos/git_compat.png"></a></p>
<h3 tabindex="-1" dir="auto">The working copy is automatically committed</h3>
<p dir="auto">Almost all Jujutsu commands automatically commit the working copy. That means
that commands never fail because the working copy is dirty (no "error: Your
local changes to the following files..."), and there is no need for <code>git stash</code>.
You also get an automatic backup of the working copy whenever you run a command.
Also, because the working copy is a commit, commands work the same way on the
working-copy commit as on any other commit, so you can set the commit message
before you're done with the changes.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/blob/main/demos/working_copy.png"><img src="https://github.com/martinvonz/jj/raw/main/demos/working_copy.png"></a></p>
<h3 tabindex="-1" dir="auto">The repo is the source of truth</h3>
<p dir="auto">With Jujutsu, the working copy plays a smaller role than with Git. Commands
snapshot the working copy before they start, then the update the repo, and then
the working copy is updated (if the working-copy commit was modified). Almost
all commands (even checkout!) operate on the commits in the repo, leaving the
common functionality of snapshotting and updating of the working copy to
centralized code. For example, <code>jj restore</code> (similar to <code>git restore</code>) can
restore from any commit and into any commit, and <code>jj describe</code> can set the
commit message of any commit (defaults to the working-copy commit).</p>
<h3 tabindex="-1" dir="auto">Entire repo is under version control</h3>
<p dir="auto">All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily revert to an
earlier repo state, or to simply undo a particular operation (which does not
necessarily have to be the most recent operation).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/blob/main/demos/operation_log.png"><img src="https://github.com/martinvonz/jj/raw/main/demos/operation_log.png"></a></p>
<h3 tabindex="-1" dir="auto">Conflicts can be recorded in commits</h3>
<p dir="auto">If an operation results in <a href="https://github.com/martinvonz/jj/blob/main/docs/glossary.md#conflict">conflicts</a>, information
about those conflicts will be recorded in the commit(s). The operation will
succeed. You can then resolve the conflicts later. One consequence of this
design is that there's no need to continue interrupted operations. Instead, you
get a single workflow for resolving conflicts, regardless of which command
caused them. This design also lets Jujutsu rebase merge commits correctly
(unlike both Git and Mercurial).</p>
<p dir="auto">Basic conflict resolution:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/blob/main/demos/resolve_conflicts.png"><img src="https://github.com/martinvonz/jj/raw/main/demos/resolve_conflicts.png"></a></p>
<p dir="auto">Juggling conflicts:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinvonz/jj/blob/main/demos/juggle_conflicts.png"><img src="https://github.com/martinvonz/jj/raw/main/demos/juggle_conflicts.png"></a></p>
<h3 tabindex="-1" dir="auto">Automatic rebase</h3>
<p dir="auto">Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Branches pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.</p>
<h3 tabindex="-1" dir="auto">Comprehensive support for rewriting history</h3>
<p dir="auto">Besides the usual rebase command, there's <code>jj describe</code> for editing the
description (commit message) of an arbitrary commit. There's also <code>jj diffedit</code>,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use <code>jj split</code>. You can even move part of the changes in a
commit to any other commit using <code>jj move</code>.</p>
<h2 tabindex="-1" dir="auto">Status</h2>
<p dir="auto">The tool is quite feature-complete, but some important features like (the
equivalent of) <code>git blame</code> are not yet supported. There
are also several performance bugs. It's also likely that workflows and setups
different from what the core developers use are not well supported.</p>
<p dir="auto">I (Martin von Zweigbergk) have almost exclusively used <code>jj</code> to develop the
project itself since early January 2021. I haven't had to re-clone from source
(I don't think I've even had to restore from backup).</p>
<p dir="auto">There <em>will</em> be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. Even the binary's name may change (i.e.
away from <code>jj</code>). For any format changes, we'll try to implement transparent
upgrades (as we've done with recent changes), or provide upgrade commands or
scripts if requested.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">See below for how to build from source. There are also
<a href="https://github.com/martinvonz/jj/releases">pre-built binaries</a> for Windows,
Mac, or Linux (musl).</p>
<h3 tabindex="-1" dir="auto">Linux</h3>
<p dir="auto">On most distributions, you'll need to build from source using <code>cargo</code> directly.</p>
<h4 tabindex="-1" dir="auto">Build using <code>cargo</code></h4>
<p dir="auto">First make sure that you have the <code>libssl-dev</code>, <code>openssl</code>, and <code>pkg-config</code>
packages installed by running something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt-get install libssl-dev openssl pkg-config"><pre>sudo apt-get install libssl-dev openssl pkg-config</pre></div>
<p dir="auto">Now run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli"><pre>cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli</pre></div>
<h4 tabindex="-1" dir="auto">Nix OS</h4>
<p dir="auto">If you're on Nix OS you can use the flake for this repository.
For example, if you want to run <code>jj</code> loaded from the flake, use:</p>
<div dir="auto" data-snippet-clipboard-copy-content="nix run 'github:martinvonz/jj'"><pre>nix run <span><span>'</span>github:martinvonz/jj<span>'</span></span></pre></div>
<p dir="auto">You can also add this flake url to your system input flakes. Or you can
install the flake to your user profile:</p>
<div dir="auto" data-snippet-clipboard-copy-content="nix profile install 'github:martinvonz/jj'"><pre>nix profile install <span><span>'</span>github:martinvonz/jj<span>'</span></span></pre></div>
<h4 tabindex="-1" dir="auto">Homebrew</h4>
<p dir="auto">If you use linuxbrew, you can run:</p>

<h3 tabindex="-1" dir="auto">Mac</h3>
<h4 tabindex="-1" dir="auto">Homebrew</h4>
<p dir="auto">If you use Homebrew, you can run:</p>

<h4 tabindex="-1" dir="auto">MacPorts</h4>
<p dir="auto">You can also install <code>jj</code> via <a href="https://www.macports.org/" rel="nofollow">MacPorts</a> (as the <code>jujutsu</code> port):</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo port install jujutsu"><pre>sudo port install jujutsu</pre></div>
<p dir="auto">(<a href="https://ports.macports.org/port/jujutsu/" rel="nofollow">port page</a>)</p>
<h4 tabindex="-1" dir="auto">From Source</h4>
<p dir="auto">You may need to run some or all of these:</p>
<div dir="auto" data-snippet-clipboard-copy-content="xcode-select --install
brew install openssl
brew install pkg-config
export PKG_CONFIG_PATH=&quot;$(brew --prefix)/opt/openssl@3/lib/pkgconfig&quot;"><pre>xcode-select --install
brew install openssl
brew install pkg-config
<span>export</span> PKG_CONFIG_PATH=<span><span>"</span><span><span>$(</span>brew --prefix<span>)</span></span>/opt/openssl@3/lib/pkgconfig<span>"</span></span></pre></div>
<p dir="auto">Now run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli"><pre>cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli</pre></div>
<h3 tabindex="-1" dir="auto">Windows</h3>
<p dir="auto">Run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli --features vendored-openssl"><pre>cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jj-cli --features vendored-openssl</pre></div>
<h2 tabindex="-1" dir="auto">Initial configuration</h2>
<p dir="auto">You may want to configure your name and email so commits are made in your name.
Create a file at <code>~/.jjconfig.toml</code> and make it look something like
this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat ~/.jjconfig.toml
[user]
name = &quot;Martin von Zweigbergk&quot;
email = &quot;martinvonz@google.com&quot;"><pre>$ cat <span>~</span>/.jjconfig.toml
[user]
name = <span><span>"</span>Martin von Zweigbergk<span>"</span></span>
email = <span><span>"</span>martinvonz@google.com<span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Command-line completion</h2>
<p dir="auto">To set up command-line completion, source the output of
<code>jj util completion --bash/--zsh/--fish</code> (called <code>jj debug completion</code> in
jj &lt;= 0.7.0). Exactly how to source it depends on your shell.</p>
<h3 tabindex="-1" dir="auto">Bash</h3>
<div dir="auto" data-snippet-clipboard-copy-content="source <(jj util completion)  # --bash is the default"><pre><span>source</span> <span><span>&lt;(</span>jj util completion<span>)</span></span>  <span><span>#</span> --bash is the default</span></pre></div>
<p dir="auto">Or, with jj &lt;= 0.7.0:</p>
<div dir="auto" data-snippet-clipboard-copy-content="source <(jj debug completion)  # --bash is the default"><pre><span>source</span> <span><span>&lt;(</span>jj debug completion<span>)</span></span>  <span><span>#</span> --bash is the default</span></pre></div>
<h3 tabindex="-1" dir="auto">Zsh</h3>
<div dir="auto" data-snippet-clipboard-copy-content="autoload -U compinit
compinit
source <(jj util completion --zsh)"><pre>autoload -U compinit
compinit
<span>source</span> <span><span>&lt;(</span>jj util completion --zsh<span>)</span></span></pre></div>
<p dir="auto">Or, with jj &lt;= 0.7.0:</p>
<div dir="auto" data-snippet-clipboard-copy-content="autoload -U compinit
compinit
source <(jj debug completion --zsh)"><pre>autoload -U compinit
compinit
<span>source</span> <span><span>&lt;(</span>jj debug completion --zsh<span>)</span></span></pre></div>
<h3 tabindex="-1" dir="auto">Fish</h3>
<div dir="auto" data-snippet-clipboard-copy-content="jj util completion --fish | source"><pre>jj util completion --fish <span>|</span> <span>source</span></pre></div>
<p dir="auto">Or, with jj &lt;= 0.7.0:</p>
<div dir="auto" data-snippet-clipboard-copy-content="jj debug completion --fish | source"><pre>jj debug completion --fish <span>|</span> <span>source</span></pre></div>
<h3 tabindex="-1" dir="auto">Xonsh</h3>
<div dir="auto" data-snippet-clipboard-copy-content="source-bash $(jj util completion)"><pre>source-bash <span><span>$(</span>jj util completion<span>)</span></span></pre></div>
<p dir="auto">Or, with jj &lt;= 0.7.0:</p>
<div dir="auto" data-snippet-clipboard-copy-content="source-bash $(jj debug completion)"><pre>source-bash <span><span>$(</span>jj debug completion<span>)</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">The best way to get started is probably to go through
<a href="https://github.com/martinvonz/jj/blob/main/docs/tutorial.md">the tutorial</a>. Also see the
<a href="https://github.com/martinvonz/jj/blob/main/docs/git-comparison.md">Git comparison</a>, which includes a table of
<code>jj</code> vs. <code>git</code> commands.</p>
<h2 tabindex="-1" dir="auto">Related work</h2>
<p dir="auto">There are several tools trying to solve similar problems as Jujutsu. See
<a href="https://github.com/martinvonz/jj/blob/main/docs/related-work.md">related work</a> for details.</p>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-native-backend-7cb6abcd5c51aa74722e11350c0a42f8">
<p dir="auto">At this time, there's practically no reason to use the native
backend. The backend exists mainly to make sure that it's possible to eventually
add functionality that cannot easily be added to the Git backend. <a href="#user-content-fnref-native-backend-7cb6abcd5c51aa74722e11350c0a42f8" data-footnote-backref="" aria-label="Back to reference 1"><g-emoji alias="leftwards_arrow_with_hook" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/21a9.png">↩</g-emoji></a></p>
</li>
</ol>
</section>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia H100 GPUs: Supply and Demand (153 pts)]]></title>
            <link>https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/</link>
            <guid>36951872</guid>
            <pubDate>Tue, 01 Aug 2023 03:10:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/">https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/</a>, See on <a href="https://news.ycombinator.com/item?id=36951872">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <header>
      
      
      
      
        <p><img srcset="https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/feature_hu4b9dcc4d15a2fc6ab8bc2944a890614b_273016_330x0_resize_box_3.png 330w,https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/feature_hu4b9dcc4d15a2fc6ab8bc2944a890614b_273016_660x0_resize_box_3.png 660w,https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/feature_hu4b9dcc4d15a2fc6ab8bc2944a890614b_273016_1024x0_resize_box_3.png 1024w,https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/feature_hu4b9dcc4d15a2fc6ab8bc2944a890614b_273016_1320x0_resize_box_3.png 2x" alt="" loading="lazy">
          
        </p>
      
    </header>
    <div>
        <!-- maybe add disqus -->
<!-- created: 2023-06-28T06:24:16-07:00 -->
<p><strong>This post is an exploration of the supply and demand of GPUs, particularly Nvidia H100s. We’re also releasing a song and music video on the same day as this post.</strong></p>
<h2 id="introduction">Introduction <span><a href="#introduction" aria-label="Anchor">#</a></span></h2>
<p>As of July 2023, it seems AI might be bottlenecked by the supply of GPUs.</p>
<blockquote>
<p>“One reason the AI boom is being underestimated is the GPU/TPU shortage. This shortage is causing all kinds of limits on product rollouts and model training but these are not visible. Instead all we see is Nvidia spiking in price. Things will accelerate once supply meets demand.”</p>
<p>— Adam D’Angelo, CEO of Quora, Poe.com, former Facebook CTO</p>
</blockquote>
<figure>
      <img srcset="https://gpus.llm-utils.org/images/ai-leaders-small_hu52fb41bb95d450a1e9186789c5540494_485451_330x0_resize_q75_box.jpg 330w,https://gpus.llm-utils.org/images/ai-leaders-small_hu52fb41bb95d450a1e9186789c5540494_485451_660x0_resize_q75_box.jpg 660w,https://gpus.llm-utils.org/images/ai-leaders-small_hu52fb41bb95d450a1e9186789c5540494_485451_1024x0_resize_q75_box.jpg 1024w,https://gpus.llm-utils.org/images/ai-leaders-small_hu52fb41bb95d450a1e9186789c5540494_485451_1320x0_resize_q75_box.jpg 2x" src="https://gpus.llm-utils.org/images/ai-leaders-small_hu52fb41bb95d450a1e9186789c5540494_485451_660x0_resize_q75_box.jpg" alt="AI Leaders" loading="lazy">
      <figcaption>These Are The CEOs And Companies That Are Most Important to GPU Supply and Demand - And To AI. <a href="https://gpus.llm-utils.org/static-images/ai-leaders-large.jpg">Larger version</a></figcaption>
    </figure>
  

<h3 id="is-there-really-a-bottleneck">Is There Really A Bottleneck? <span><a href="#is-there-really-a-bottleneck" aria-label="Anchor">#</a></span></h3>
<p>Elon Musk says that “GPUs are at this point considerably harder to get than drugs.”<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Sam Altman says that OpenAI is GPU-limited and it’s delaying their short term plans (fine-tuning, dedicated capacity, 32k context windows, multimodality).<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Capacity of large scale H100 clusters at small and large cloud providers is running out.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<blockquote>
<p>“Rn everybody wishes Nvidia could produce more A/H100”<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup></p>
<p>— Message from an exec at a cloud provider</p>
</blockquote>
<blockquote>
<p>“We’re so short on GPUs the less people use our products the better”</p>
<p>“We’d love it if they use it less because we don’t have enough GPUs”</p>
<p>Sam Altman, CEO at OpenAI<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p>
</blockquote>
<p>It’s a good soundbite to remind the world how much users love your product, but it’s also true that OpenAI needs more GPUs.</p>
<blockquote>
<p>For Azure/Microsoft:</p>
<ol>
<li>They are rate limiting employees on GPUs internally. They have to queue up like it was a university mainframe in the 1970s. I think OpenAI is sucking up all of it right now.</li>
<li>The Coreweave deal is all about pasting on their GPU infrastructure.</li>
</ol>
<p>— Anonymous</p>
</blockquote>
<p>In short: Yes, there’s a supply shortage of H100 GPUs. I’m told that for companies seeking 100s or 1000s of H100s, Azure and GCP are effectively out of capacity, and AWS is close to being out.<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p>
<p>This “out of capacity” is based on the allocations that Nvidia gave them.</p>
<p><strong>What do we want to know about the bottleneck?</strong></p>
<ol>
<li>What’s causing it (how much demand, how much supply)</li>
<li>How long will it last</li>
<li>What’s going to help resolve it</li>
</ol>
<h2 id="the-gpu-song">The GPU Song <span><a href="#the-gpu-song" aria-label="Anchor">#</a></span></h2>
<p>Uh… We’re also releasing a song on the same day as we’re releasing this post. It’s fire.</p>
<p>If you haven’t heard The GPU Song yet, do yourself a favor and play it.</p>

<p>
  <iframe src="https://www.youtube.com/embed/YGpnXANXGUg" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>It’s on <a href="https://open.spotify.com/track/752PA6x8X3x0Gdft1khH61?si=429b9fd7233f4b2e" target="_blank" rel="noreferrer noopener">Spotify</a>, <a href="https://music.apple.com/us/album/the-gpu-song-gpus-are-fire/1699113597?i=1699113599" target="_blank" rel="noreferrer noopener">Apple Music</a> and <a href="https://www.youtube.com/watch?v=YGpnXANXGUg" target="_blank" rel="noreferrer noopener">YouTube</a>.</p>
<p>See more info on <a href="https://gpus.llm-utils.org/the-gpu-song-gpus-are-fire/">the song here</a>.</p>
<h2 id="table-of-contents">Table Of Contents <span><a href="#table-of-contents" aria-label="Anchor">#</a></span></h2>
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#is-there-really-a-bottleneck">Is There Really A Bottleneck?</a></li>
</ul>
</li>
<li><a href="#table-of-contents">Table Of Contents</a></li>
<li><a href="#demand-for-h100-gpus">Demand For H100 GPUs</a>
<ul>
<li><a href="#who-needs-h100s">Who Needs H100s?</a>
<ul>
<li><a href="#who-needshas-1000-h100-or-a100s">Who Needs/Has 1,000+ H100 Or A100s</a></li>
<li><a href="#who-needshas-100-h100-or-a100s">Who Needs/Has 100+ H100 Or A100s</a></li>
<li><a href="#what-are-most-of-the-high-end-gpus-being-used-for">What Are Most Of The High End GPUs Being Used For?</a></li>
<li><a href="#are-the-big-ai-labs-more-constrained-on-inference-or-training">Are The Big AI Labs More Constrained On Inference Or Training?</a></li>
</ul>
</li>
<li><a href="#which-gpus-do-people-need">Which GPUs Do People Need?</a>
<ul>
<li><a href="#whats-the-most-common-need-from-llm-startups">What’s The Most Common Need From LLM Startups?</a></li>
<li><a href="#what-do-companies-want-for-llm-training-and-inference">What Do Companies Want For LLM Training And Inference?</a></li>
<li><a href="#what-is-important-for-llm-training">What Is Important For LLM Training?</a></li>
<li><a href="#what-are-the-other-costs-of-training-and-running-llms">What Are The Other Costs Of Training And Running LLMs?</a></li>
<li><a href="#what-about-gpudirect">What About GPUDirect?</a></li>
<li><a href="#what-stops-llm-companies-from-using-amd-gpus">What Stops LLM Companies From Using AMD GPUs?</a></li>
<li><a href="#h100-vs-a100-how-much-faster-are-h100s-than-a100s">H100 Vs A100: How Much Faster Are H100s Than A100s?</a></li>
<li><a href="#is-everyone-going-to-want-to-upgrade-from-a100s-to-h100s">Is Everyone Going To Want To Upgrade From A100s To H100s?</a></li>
<li><a href="#whats-the-difference-between-h100s-gh200s-dgx-gh200s-hgx-h100s-and-dgx-h100s">What’s The Difference Between H100s, GH200s, DGX GH200s, HGX H100s, And DGX H100s?</a>
<ul>
<li><a href="#which-of-those-will-be-most-popular">Which Of Those Will Be Most Popular?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#how-much-do-these-gpus-cost">How Much Do These GPUs Cost?</a></li>
<li><a href="#how-many-gpus-are-needed">How Many GPUs Are Needed?</a>
<ul>
<li><a href="#how-many-h100s-are-most-startups-ordering">How Many H100s Are Most Startups Ordering?</a></li>
<li><a href="#how-many-h100s-might-companies-be-wanting">How Many H100s Might Companies Be Wanting?</a></li>
</ul>
</li>
<li><a href="#summary-h100-demand">Summary: H100 Demand</a></li>
</ul>
</li>
<li><a href="#supply-of-h100-gpus">Supply Of H100 GPUs</a>
<ul>
<li><a href="#who-makes-the-h100s">Who Makes The H100s?</a>
<ul>
<li><a href="#can-nvidia-use-other-chip-fabs-for-h100-production">Can Nvidia Use Other Chip Fabs For H100 Production?</a></li>
<li><a href="#how-do-the-different-tsmc-nodes-relate">How Do The Different TSMC Nodes Relate?</a></li>
<li><a href="#which-tsmc-node-is-the-h100-made-on">Which TSMC Node Is The H100 Made On?</a>
<ul>
<li><a href="#who-else-uses-that-node">Who Else Uses That Node?</a></li>
</ul>
</li>
<li><a href="#which-tsmc-node-does-the-a100-use">Which TSMC Node Does The A100 Use?</a></li>
<li><a href="#how-long-in-advance-is-fab-capacity-normally-reserved">How Long In Advance Is Fab Capacity Normally Reserved?</a></li>
<li><a href="#how-long-does-production-take-production-packaging-testing">How Long Does Production Take (production, Packaging, Testing)?</a></li>
<li><a href="#where-are-the-bottlenecks">Where Are The Bottlenecks?</a></li>
</ul>
</li>
<li><a href="#h100-memory">H100 Memory</a>
<ul>
<li><a href="#what-impacts-memory-bandwidth-on-gpus">What Impacts Memory Bandwidth On GPUs?</a></li>
<li><a href="#what-memory-is-used-on-the-h100s">What Memory Is Used On The H100s?</a></li>
<li><a href="#who-makes-the-memory-on-the-h100s">Who Makes The Memory On The H100s?</a></li>
</ul>
</li>
<li><a href="#what-else-is-used-when-making-gpus">What Else Is Used When Making GPUs?</a></li>
</ul>
</li>
<li><a href="#outlook-and-predictions">Outlook And Predictions</a>
<ul>
<li><a href="#what-is-nvidia-saying">What Is Nvidia Saying?</a></li>
<li><a href="#whatll-happen-next">What’ll Happen Next?</a>
<ul>
<li><a href="#when-will-there-be-a-h100-successor">When Will There Be A H100 Successor?</a></li>
<li><a href="#will-there-be-higher-vram-h100s">Will There Be Higher VRAM H100s?</a></li>
<li><a href="#when-will-the-shortage-end">When Will The Shortage End?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sourcing-h100s">Sourcing H100s</a>
<ul>
<li><a href="#who-sells-h100s">Who Sells H100s?</a>
<ul>
<li><a href="#how-are-the-lead-times">How Are The Lead Times?</a></li>
<li><a href="#if-a-startup-places-an-order-today-when-would-they-have-ssh-access">If A Startup Places An Order Today, When Would They Have SSH Access?</a></li>
<li><a href="#do-startups-buy-from-oems-and-resellers">Do Startups Buy From OEMs And Resellers?</a></li>
<li><a href="#when-do-startups-build-their-own-datacenter-vs-doing-colocation">When Do Startups Build Their Own Datacenter Vs Doing Colocation?</a></li>
</ul>
</li>
<li><a href="#how-do-the-big-clouds-compare">How Do The Big Clouds Compare?</a>
<ul>
<li><a href="#which-big-cloud-has-the-best-networking">Which Big Cloud Has The Best Networking?</a></li>
<li><a href="#which-big-clouds-do-enterprises-use">Which Big Clouds Do Enterprises Use?</a></li>
<li><a href="#how-about-dgx-cloud-who-is-nvidia-working-with-for-that">How About DGX Cloud, Who Is Nvidia Working With For That?</a></li>
<li><a href="#when-did-the-big-clouds-launch-their-h100-previews">When Did The Big Clouds Launch Their H100 Previews?</a></li>
</ul>
</li>
<li><a href="#how-can-a-company-or-cloud-service-provider-get-more-gpus">How Can A Company Or Cloud Service Provider Get More GPUs?</a>
<ul>
<li><a href="#how-do-nvidia-allocations-work">How Do Nvidia Allocations Work?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#closing-thoughts">Closing Thoughts</a>
<ul>
<li><a href="#tracing-the-journey-of-gpu-supply-and-demand">Tracing The Journey Of GPU Supply And Demand</a></li>
<li><a href="#getting-in-touch">Getting In Touch</a></li>
<li><a href="#the-natural-next-question---what-about-nvidia-alternatives">The Natural Next Question - What About Nvidia Alternatives?</a></li>
</ul>
</li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ul>
<h2 id="demand-for-h100-gpus">Demand For H100 GPUs <span><a href="#demand-for-h100-gpus" aria-label="Anchor">#</a></span></h2>
<p><strong>What’s causing the bottleneck - Demand</strong></p>
<ol>
<li>Specifically, what do people want to buy that they can’t?</li>
<li>How many of those GPUs do they need?</li>
<li>Why can’t they use a different GPU?</li>
<li>What are the different product names?</li>
<li>Where do companies buy them and how much do they cost?</li>
</ol>
<h3 id="who-needs-h100s">Who Needs H100s? <span><a href="#who-needs-h100s" aria-label="Anchor">#</a></span></h3>
<blockquote>
<p>“It seems like everyone and their dog is buying GPUs at this point”<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup></p>
<p>– Elon</p>
</blockquote>
<h4 id="who-needshas-1000-h100-or-a100s">Who Needs/Has 1,000+ H100 Or A100s <span><a href="#who-needshas-1000-h100-or-a100s" aria-label="Anchor">#</a></span></h4>
<ul>
<li>Startups training LLMs
<ul>
<li>OpenAI (through Azure), Anthropic, Inflection (through Azure<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> and CoreWeave<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>), Mistral AI</li>
</ul>
</li>
<li>CSPs (Cloud Service Providers)
<ul>
<li>The big 3: Azure, GCP, AWS</li>
<li>The other public cloud: Oracle</li>
<li>Larger private clouds like CoreWeave, Lambda</li>
</ul>
</li>
<li>Other large companies
<ul>
<li>Tesla<sup id="fnref1:7"><a href="#fn:7" role="doc-noteref">7</a></sup> <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup></li>
</ul>
</li>
</ul>
<h4 id="who-needshas-100-h100-or-a100s">Who Needs/Has 100+ H100 Or A100s <span><a href="#who-needshas-100-h100-or-a100s" aria-label="Anchor">#</a></span></h4>
<p>Startups doing significant fine-tuning large open source models.</p>
<h4 id="what-are-most-of-the-high-end-gpus-being-used-for">What Are Most Of The High End GPUs Being Used For? <span><a href="#what-are-most-of-the-high-end-gpus-being-used-for" aria-label="Anchor">#</a></span></h4>
<p>For companies using private clouds (CoreWeave, Lambda), of companies with hundreds or thousands of H100s, it’s almost all LLMs, and some diffusion model work. Some of it is fine-tuning of existing models, but mostly it’s new startups that you may not yet know about that are building new models from scratch. They’re doing $10mm-50mm contracts done over 3 years, with a few hundred to a few thousand GPUs.</p>
<p>For companies using on-demand H100s with a handful of GPUs, it’s still probably &gt;50% LLM related usage.</p>
<p>Private clouds are now starting to see inbound demand from enterprises who would normally be going with their default big cloud provider, but everyone is out.</p>
<h4 id="are-the-big-ai-labs-more-constrained-on-inference-or-training">Are The Big AI Labs More Constrained On Inference Or Training? <span><a href="#are-the-big-ai-labs-more-constrained-on-inference-or-training" aria-label="Anchor">#</a></span></h4>
<p>Depends on how much product traction they have! Sam Altman says OpenAI would rather have more inference capacity if forced to choose, but OpenAI is still constrained on both.<sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></p>
<h3 id="which-gpus-do-people-need">Which GPUs Do People Need? <span><a href="#which-gpus-do-people-need" aria-label="Anchor">#</a></span></h3>
<p>Mostly H100s. Why? It’s the fastest both for inference and training for LLMs. (The H100 is often also the best price-performance ratio for inference, too)</p>
<p>Specifically: 8-GPU HGX H100 SXM servers.</p>
<blockquote>
<p>My analysis is it’s cheaper to run for the same work as well. The V100 a great deal if you could find them used, which you can’t</p>
<p>– Anonymous</p>
</blockquote>
<blockquote>
<p>honestly not sure about [it being the best price-performance ratio]? price/performance for training looks about the same for A100 as for H100. for inference, we find that A10Gs are more than enough and much cheaper.</p>
<p>– Private cloud exec</p>
</blockquote>
<blockquote>
<p>this [A10G’s being more than enough] was true for a while. but in the world of falcon 40b and llama2 70b, which we’re seeing a lot of usage for, it’s not true anymore. we need A100s for these</p>
<p>2xA100s to be exact. so the interconnect speed matters for inference.</p>
<p>– (Different) Private cloud exec</p>
</blockquote>
<!-- I'm planning to do a deep dive on specifically what stops companies who are spending 9-10 figures on GPUs from spending a portion of their budget on getting their training or inference to run on non-Nvidia hardware. If you're a reader and have insight there, let me know. -->
<h4 id="whats-the-most-common-need-from-llm-startups">What’s The Most Common Need From LLM Startups? <span><a href="#whats-the-most-common-need-from-llm-startups" aria-label="Anchor">#</a></span></h4>
<p>For training LLMs: H100s with 3.2Tb/s InfiniBand.</p>
<h4 id="what-do-companies-want-for-llm-training-and-inference">What Do Companies Want For LLM Training And Inference? <span><a href="#what-do-companies-want-for-llm-training-and-inference" aria-label="Anchor">#</a></span></h4>
<p>For training they tend to want H100s, for inference it’s much more about performance per dollar.</p>
<p>It’s still a performance per dollar question with H100s vs A100s, but H100s are generally favored as they can scale better with higher numbers of GPUs and give faster training times, and speed / compressing time to launch or train or improve models is critical for startups.</p>
<blockquote>
<p>“For multi-node training, all of them are asking for A100 or H100 with InfiniBand networking. Only non A/H100 request we see are for inference where workloads are single GPU or single node”</p>
<p>– Private cloud exec</p>
</blockquote>
<h4 id="what-is-important-for-llm-training">What Is Important For LLM Training? <span><a href="#what-is-important-for-llm-training" aria-label="Anchor">#</a></span></h4>
<ul>
<li>Memory bandwidth</li>
<li>FLOPS (tensor cores or equivalent matrix multiplication units)</li>
<li>Caches and cache latencies</li>
<li>Additional features like FP8 compute</li>
<li>Compute performance (related to number of cuda cores)</li>
<li>Interconnect speed (eg InfiniBand)</li>
</ul>
<p>The H100 is preferred over A100 partly because of things like lower cache latencies and FP8 compute.</p>
<blockquote>
<p>H100 is preferred because it is up to 3x more efficient, but the costs are only (1.5 - 2x). Combined with the overall system cost, H100 yields much more performance per dollar (if you look at system performance, probably 4-5x more performance per dollar).</p>
<p>— Deep learning researcher</p>
</blockquote>
<h4 id="what-are-the-other-costs-of-training-and-running-llms">What Are The Other Costs Of Training And Running LLMs? <span><a href="#what-are-the-other-costs-of-training-and-running-llms" aria-label="Anchor">#</a></span></h4>
<p>GPUs are the most expensive individual component, but there are other costs.</p>
<p>System RAM and NVMe SSDs are expensive.</p>
<p>InfiniBand networking is costly.</p>
<p>10-15% of total cost for running a cluster might go to power and hosting (electricity, cost of the datacenter building, cost of the land, staff) - roughly split between the two, can be 5-8% for power and 5-10% for other elements of hosting cost (land, building, staff).</p>
<blockquote>
<p>It’s mostly networking and reliable datacenters. AWS is difficult to work with because of network limitations and unreliable hardware</p>
<p>— Deep learning researcher</p>
</blockquote>
<h4 id="what-about-gpudirect">What About GPUDirect? <span><a href="#what-about-gpudirect" aria-label="Anchor">#</a></span></h4>
<p>GPUDirect is not a critical requirement, but can be helpful.</p>
<blockquote>
<p>I would not say it is supercritical, but it makes a difference in performance. I guess it depends on where your bottleneck is. For some architectures / software implementations, the bottleneck is not necessarily networking, but if it is GPUDirect can make a difference of 10-20%, and that are some pretty significant numbers for expensive training runs.</p>
<p>That being said, GPUDirect RDMA is now so ubiquitous that it goes almost without saying that it is supported. I think support is less strong for non-InfiniBand networking, but most GPU clusters optimized for neural network training have Infiniband networks / cards. A bigger factor for performance might be NVLink, since this is rarer than Infiniband, but it is also only critical if you have particular parallelization strategies.</p>
<p>So features like strong networking and GPUDirect allows you to be lazy and you can guarantee that naive software is better out of the box. But it is not a strict requirement if you care about cost or using infrastructure that you already have.</p>
<p>– Deep learning researcher</p>
</blockquote>
<h4 id="what-stops-llm-companies-from-using-amd-gpus">What Stops LLM Companies From Using AMD GPUs? <span><a href="#what-stops-llm-companies-from-using-amd-gpus" aria-label="Anchor">#</a></span></h4>
<blockquote>
<p>Theoretically a company can buy a bunch of AMD GPUs, but it just takes time to get everything to work. That dev time (even if just 2 months) might mean being later to market than a competitor. So CUDA is NVIDIA’s moat right now.</p>
<p>– Private cloud exec</p>
</blockquote>
<blockquote>
<p>I suspect 2 months is off by an order of magnitude, it’s probably not a meaningful difference, see <a href="https://www.mosaicml.com/blog/amd-mi250" target="_blank" rel="noreferrer noopener">https://www.mosaicml.com/blog/amd-mi250</a></p>
<p>– ML Engineer</p>
</blockquote>
<blockquote>
<p>Who is going to take the risk of deplying 10,000 AMD GPUs or 10,000 random startup silicon chips? That’s almost a $300 million investment.</p>
<p>– Private cloud exec</p>
</blockquote>
<blockquote>
<p>MosaicML/MI250 - Has anyone asked AMD about availability?  It doesn’t seem like AMD built many beyond what they needed for Frontier, and now TSMC CoWoS capacity is sucked up by Nvidia.  MI250 may be a viable alternative but unavailable.</p>
<p>– Retired semiconductor industry professional</p>
</blockquote>
<!-- There's a *lot* of activity going to reducing Nvidia's lock on GPUs, I'll be writing more about that.  -->
<!-- AMD, Intel, geohot's tiny corp, lots of efforts for CUDA porting, making CUDA irrelevant, Mojo, PyTorch, various other chip companies, and so on. -->
<h4 id="h100-vs-a100-how-much-faster-are-h100s-than-a100s">H100 Vs A100: How Much Faster Are H100s Than A100s? <span><a href="#h100-vs-a100-how-much-faster-are-h100s-than-a100s" aria-label="Anchor">#</a></span></h4>
<p>About 3.5x faster for 16-bit inference<sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup> and about 2.3x faster for 16-bit training.<sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup></p>
<figure>
      <img srcset="https://gpus.llm-utils.org/images/a100-vs-h100-speed_hu4a71f10b529caba057f44f0c2d231f98_87340_330x0_resize_q75_box.jpeg 330w,https://gpus.llm-utils.org/images/a100-vs-h100-speed_hu4a71f10b529caba057f44f0c2d231f98_87340_660x0_resize_q75_box.jpeg 660w,https://gpus.llm-utils.org/images/a100-vs-h100-speed_hu4a71f10b529caba057f44f0c2d231f98_87340_1024x0_resize_q75_box.jpeg 1024w,https://gpus.llm-utils.org/images/a100-vs-h100-speed_hu4a71f10b529caba057f44f0c2d231f98_87340_1320x0_resize_q75_box.jpeg 2x" src="https://gpus.llm-utils.org/images/a100-vs-h100-speed_hu4a71f10b529caba057f44f0c2d231f98_87340_660x0_resize_q75_box.jpeg" alt="A100 vs H100 speed" loading="lazy">
      <figcaption>A100 vs H100 Speed</figcaption>
    </figure>
  

<figure>
      <img src="https://gpus.llm-utils.org/images/h100-moe-vs-a100.webp" alt="H100 training MoE" loading="lazy">
      <figcaption>H100 Training MoE</figcaption>
    </figure>
  

<figure>
      <img srcset="https://gpus.llm-utils.org/images/h100-speedup-at-scale_hud19a8968909652227c6b38ef1bbeae84_163135_330x0_resize_q75_box.jpeg 330w,https://gpus.llm-utils.org/images/h100-speedup-at-scale_hud19a8968909652227c6b38ef1bbeae84_163135_660x0_resize_q75_box.jpeg 660w,https://gpus.llm-utils.org/images/h100-speedup-at-scale_hud19a8968909652227c6b38ef1bbeae84_163135_1024x0_resize_q75_box.jpeg 1024w,https://gpus.llm-utils.org/images/h100-speedup-at-scale_hud19a8968909652227c6b38ef1bbeae84_163135_1320x0_resize_q75_box.jpeg 2x" src="https://gpus.llm-utils.org/images/h100-speedup-at-scale_hud19a8968909652227c6b38ef1bbeae84_163135_660x0_resize_q75_box.jpeg" alt="H100 speedup at scale" loading="lazy">
      <figcaption>H100 Speedup At Scale</figcaption>
    </figure>
  

<p>Here’s some more reading for you: <a href="https://blogs.nvidia.com/blog/2022/03/22/h100-transformer-engine/" target="_blank" rel="noreferrer noopener">1</a> <a href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/" target="_blank" rel="noreferrer noopener">2</a> <a href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/" target="_blank" rel="noreferrer noopener">3</a>.</p>
<h4 id="is-everyone-going-to-want-to-upgrade-from-a100s-to-h100s">Is Everyone Going To Want To Upgrade From A100s To H100s? <span><a href="#is-everyone-going-to-want-to-upgrade-from-a100s-to-h100s" aria-label="Anchor">#</a></span></h4>
<p>Mostly people will want to buy H100s and use them for training and inference and switch their A100s to be used primarily for inference. But, some people might be hesitant to switch due to cost, capacity, the risk of using new hardware and setting it up, and their existing software being already optimized for A100s.</p>
<blockquote>
<p>Yes, A100s will become today’s V100s in a few years. I don’t know of anyone training LLMs on V100s right now because of performance constraints. But they are still used in inference and other workloads. Similarly, A100 pricing will come down as more AI companies shift workloads to H100s, but there will always be demand, especially for inference.</p>
<p>– Private cloud exec</p>
</blockquote>
<blockquote>
<p>think it’s also plausible some of the startups that raised huge rounds end up folding and then there’s a lot of A100s coming back on the market</p>
<p>– (Different) Private cloud exec</p>
</blockquote>
<p>Over time people will move and the A100s will be more used for inference.</p>
<p>What about V100s? Higher VRAM cards are better for large models, so cutting edge groups much prefer H100s or A100s.</p>
<blockquote>
<p>The main reason for not using V100 is the lack of brainfloat16 (bfloat16, BF16) data type. Without that, its very difficult to train models easily. The poor performance of OPT and BLOOM can be mostly attributed to not having this data type (OPT was trained in float16, BLOOM’s prototyping was mostly done in fp16, which did not yield data was generalized to the training run which was done in bf16)</p>
<p>— Deep learning researcher</p>
</blockquote>
<h4 id="whats-the-difference-between-h100s-gh200s-dgx-gh200s-hgx-h100s-and-dgx-h100s">What’s The Difference Between H100s, GH200s, DGX GH200s, HGX H100s, And DGX H100s? <span><a href="#whats-the-difference-between-h100s-gh200s-dgx-gh200s-hgx-h100s-and-dgx-h100s" aria-label="Anchor">#</a></span></h4>
<ul>
<li>H100 = 1x H100 GPU</li>
<li>HGX H100 = the Nvidia server reference platform that OEMs use to build 4-GPU or 8-GPU servers. Built by third-party OEMs like Supermicro.</li>
<li>DGX H100 = the Nvidia official H100 server with 8x H100s.<sup id="fnref:14"><a href="#fn:14" role="doc-noteref">14</a></sup> Nvidia is the sole vendor.</li>
<li>GH200 = 1x H100 GPU plus 1x Grace CPU.<sup id="fnref:15"><a href="#fn:15" role="doc-noteref">15</a></sup></li>
<li>DGX GH200 = 256x GH200s,<sup id="fnref:16"><a href="#fn:16" role="doc-noteref">16</a></sup> available toward the end of 2023.<sup id="fnref:17"><a href="#fn:17" role="doc-noteref">17</a></sup> Likely only offered by Nvidia.</li>
</ul>
<p>There’s also MGX which is aimed at large cloud companies.</p>
<h5 id="which-of-those-will-be-most-popular">Which Of Those Will Be Most Popular? <span><a href="#which-of-those-will-be-most-popular" aria-label="Anchor">#</a></span></h5>
<p>Most companies will buy 8-GPU HGX H100s,<sup id="fnref:18"><a href="#fn:18" role="doc-noteref">18</a></sup> rather than DGX H100s or 4-GPU HGX H100 servers.</p>
<h3 id="how-much-do-these-gpus-cost">How Much Do These GPUs Cost? <span><a href="#how-much-do-these-gpus-cost" aria-label="Anchor">#</a></span></h3>
<p>1x DGX H100 (SXM) with 8x H100 GPUs is $460k including the required support. $100k of the $460k is required support. The specs are below. Startups can get the Inception discount which is about $50k off, and can be used on up to 8x DGX H100 boxes for a total of 64 H100s.</p>
<figure>
      <img src="https://gpus.llm-utils.org/images/dgx-h100-specs.png" alt="DGX H100 Specs" loading="lazy">
      <figcaption>DGX H100 Specs</figcaption>
    </figure>
  

<p>1x HGX H100 (SXM) with 8x H100 GPUs is between $300k-380k, depending on the specs (networking, storage, ram, CPUs) and the margins of whoever is selling it and the level of support. The higher end of that range, $360k-380k including support, is what you might expect for identical specs to a DGX H100.</p>
<p>1x HGX H100 (PCIe) with 8x H100 GPUs is approx $300k including support, depending on specs.</p>
<p>PCIe cards are around $30k-32k market prices.</p>
<p>SXM cards aren’t really sold as single cards, so it’s tough to give pricing there. Generally only sold as 4-GPU and 8-GPU servers.</p>
<p>Around 70-80% of the demand is for SXM H100s, the rest is for PCIe H100s. And the SXM portion of the demand is trending upwards, because PCIe cards were the only ones available for the first few months. Given most companies buy 8-GPU HGX H100s (SXM), the approximate spend is $360k-380k per 8 H100s, including other server components.</p>
<p>The DGX GH200 (which as a reminder, contains 256x GH200s, and each GH200 contains 1x H100 GPU and 1x Grace CPU) might cost in the range of $15mm-25mm - though this is a guess, not based on a pricing sheet.<sup id="fnref:19"><a href="#fn:19" role="doc-noteref">19</a></sup></p>
<h3 id="how-many-gpus-are-needed">How Many GPUs Are Needed? <span><a href="#how-many-gpus-are-needed" aria-label="Anchor">#</a></span></h3>
<ul>
<li>GPT-4 was likely trained on somewhere between 10,000 to 25,000 A100s.<sup id="fnref:20"><a href="#fn:20" role="doc-noteref">20</a></sup></li>
<li>Meta has about 21,000 A100s, Tesla has about 7,000 A100s, and Stability AI has about 5,000 A100s.<sup id="fnref:21"><a href="#fn:21" role="doc-noteref">21</a></sup></li>
<li>Falcon-40B was trained on 384 A100s.<sup id="fnref:22"><a href="#fn:22" role="doc-noteref">22</a></sup></li>
<li>Inflection used 3,500 H100s for their GPT-3.5 equivalent model.<sup id="fnref:23"><a href="#fn:23" role="doc-noteref">23</a></sup></li>
</ul>
<p>GPT-5 might need 30k-50k H100s according to Elon. Morgan Stanley said in Feb 2023 that GPT-5 would use 25,000 GPUs, but they also said it was already being trained as of Feb 2023 and Sam Altman said in May 2023 that it’s not yet being trained, so MS’s info may be outdated.</p>
<p>GCP has approx 25k H100s. Azure probably has 10k-40k H100s. Should be similar for Oracle. Most of Azure’s capacity is going to OpenAI.</p>
<p>CoreWeave is in the ballpark of 35k-40k H100s - not live, but based on bookings.</p>
<h4 id="how-many-h100s-are-most-startups-ordering">How Many H100s Are Most Startups Ordering? <span><a href="#how-many-h100s-are-most-startups-ordering" aria-label="Anchor">#</a></span></h4>
<p>For LLMs: For fine tuning, dozens or low hundreds. For training, thousands.</p>
<h4 id="how-many-h100s-might-companies-be-wanting">How Many H100s Might Companies Be Wanting? <span><a href="#how-many-h100s-might-companies-be-wanting" aria-label="Anchor">#</a></span></h4>
<p>OpenAI might want 50k. Inflection wants 22k.<sup id="fnref:24"><a href="#fn:24" role="doc-noteref">24</a></sup> Meta maybe 25k (I’m told actually Meta wants 100k or more). Big clouds might want 30k each (Azure, Google Cloud, AWS, plus Oracle). Lambda and CoreWeave and the other private clouds might want 100k total. Anthropic, Helsing, Mistral, Character, might want 10k each. Total ballparks and guessing, and some of that is double counting both the cloud and the end customer who will rent from the cloud. But that gets to about 432k H100s. At approx $35k a piece, that’s about $15b worth of GPUs. That also excludes Chinese companies like ByteDance (TikTok), Baidu, and Tencent who will want a lot of H800s.</p>
<p>There are also financial companies each doing deployments starting with hundreds of A100s or H100s and going to thousands of A/H100s: names like Jane Street, JP Morgan, Two Sigma, Citadel.</p>
<p>How does that compare to Nvidia’s data center revenue?</p>
<p>Feb-April 2023 was $4.28b data center revenue.<sup id="fnref:25"><a href="#fn:25" role="doc-noteref">25</a></sup> May-July 2023 might be around $8b data center revenue, assuming most of the higher guidance for that quarter is due to gain in data center revenue rather than other segments.</p>
<p>So might take a while for the supply shortage to go away. But also all my ballparks could be wildly overstated, and many of these companies aren’t going to go right out and buy the H100s today, they’ll upgrade over time. Plus, Nvidia is aggressively ramping production capacity.</p>
<blockquote>
<p>Seems possible. 400k H100s doesn’t sound out of reach, especially given how everyone is doing a massive 4 or 5-figure H100 deployment right now.</p>
<p>– Private cloud exec</p>
</blockquote>
<h3 id="summary-h100-demand">Summary: H100 Demand <span><a href="#summary-h100-demand" aria-label="Anchor">#</a></span></h3>
<p>The main things to keep in mind as you go onto the next section are that most of the big CSPs (Azure, AWS, GCP, and also Oracle) and private clouds (CoreWeave, Lambda, and various others) want more H100s than they can get access to. Most of the big AI product companies want more H100s than they can get access to, as well. Generally they want 8-GPU HGX H100 boxes with SXM cards, which cost approx $300k-400k per 8-GPU server depending on specs and support. There may be a few hundred thousand H100 GPUs worth of excess demand ($15b+ of GPUs). With a limited supply, Nvidia could purely raise prices to find a clearing price, and are doing that to some extent. But it’s important to know that ultimately H100 allocation comes down to who Nvidia prefers to give that allocation to.</p>
<h2 id="supply-of-h100-gpus">Supply Of H100 GPUs <span><a href="#supply-of-h100-gpus" aria-label="Anchor">#</a></span></h2>
<p><strong>What’s causing the bottleneck - Supply</strong></p>
<ol>
<li>What are the bottlenecks on the production side?</li>
<li>Which components?</li>
<li>Who produces them?</li>
</ol>
<h3 id="who-makes-the-h100s">Who Makes The H100s? <span><a href="#who-makes-the-h100s" aria-label="Anchor">#</a></span></h3>
<p>TSMC.</p>
<h4 id="can-nvidia-use-other-chip-fabs-for-h100-production">Can Nvidia Use Other Chip Fabs For H100 Production? <span><a href="#can-nvidia-use-other-chip-fabs-for-h100-production" aria-label="Anchor">#</a></span></h4>
<p>Not really, at least not yet. They’ve worked with Samsung in the past. But on the H100s and other 5nm GPUs they only use TSMC. Implication is that Samsung can’t yet meet their needs for cutting edge GPUs. They might work with Intel in the future, and Samsung again on cutting edge, but neither of those will be happening in the short term in a way that’d help the H100 supply crunch.</p>
<h4 id="how-do-the-different-tsmc-nodes-relate">How Do The Different TSMC Nodes Relate? <span><a href="#how-do-the-different-tsmc-nodes-relate" aria-label="Anchor">#</a></span></h4>
<p>TSMC 5nm family:</p>
<ul>
<li>N5<sup id="fnref:26"><a href="#fn:26" role="doc-noteref">26</a></sup>
<ul>
<li>4N either fits here as an enhanced version of N5, or below N5P</li>
<li>N5P
<ul>
<li>4N either fits here as an enhanced version of N5P, or below N5 as an enhanced version of N5</li>
</ul>
</li>
<li>N4</li>
<li>N4P</li>
</ul>
</li>
</ul>
<h4 id="which-tsmc-node-is-the-h100-made-on">Which TSMC Node Is The H100 Made On? <span><a href="#which-tsmc-node-is-the-h100-made-on" aria-label="Anchor">#</a></span></h4>
<p>TSMC 4N. This is a special node for Nvidia, it’s in the 5nm family and is enhanced 5nm though rather than truly 4nm.</p>
<h5 id="who-else-uses-that-node">Who Else Uses That Node? <span><a href="#who-else-uses-that-node" aria-label="Anchor">#</a></span></h5>
<p>It was Apple, but they’ve moved primarily to N3 and have reserved most of the N3 capacity. Qualcomm and AMD are the other big N5-family customers.</p>
<h4 id="which-tsmc-node-does-the-a100-use">Which TSMC Node Does The A100 Use? <span><a href="#which-tsmc-node-does-the-a100-use" aria-label="Anchor">#</a></span></h4>
<p>N7<sup id="fnref:27"><a href="#fn:27" role="doc-noteref">27</a></sup></p>
<h4 id="how-long-in-advance-is-fab-capacity-normally-reserved">How Long In Advance Is Fab Capacity Normally Reserved? <span><a href="#how-long-in-advance-is-fab-capacity-normally-reserved" aria-label="Anchor">#</a></span></h4>
<p>Not sure though maybe 12+ months.</p>
<blockquote>
<p>that applies to TSM and their big customers
They sort of plan it out together
Which is why TSM/NVDA may have underestimated what they need</p>
<p>– Anonymous</p>
</blockquote>
<h4 id="how-long-does-production-take-production-packaging-testing">How Long Does Production Take (Production, Packaging, Testing)? <span><a href="#how-long-does-production-take-production-packaging-testing" aria-label="Anchor">#</a></span></h4>
<p>6 months from production on a H100 starting to that H100 being ready to be sold to a customer (est from a conversation, would like to get a confirmation)</p>
<h4 id="where-are-the-bottlenecks">Where Are The Bottlenecks? <span><a href="#where-are-the-bottlenecks" aria-label="Anchor">#</a></span></h4>
<blockquote>
<p>Wafer starts are not the bottleneck at TSMC.  Mentioned earlier CoWoS (3D stacking) packaging is the gate at TSMC.</p>
<p>– Retired semiconductor industry professional</p>
</blockquote>
<h3 id="h100-memory">H100 Memory <span><a href="#h100-memory" aria-label="Anchor">#</a></span></h3>
<h4 id="what-impacts-memory-bandwidth-on-gpus">What Impacts Memory Bandwidth On GPUs? <span><a href="#what-impacts-memory-bandwidth-on-gpus" aria-label="Anchor">#</a></span></h4>
<p>Memory type, memory bus width, and memory clock speed.</p>
<blockquote>
<p>It’s mostly HBM. Manufacturing it is a nightmare. Supply is also mostly limited because HBM is so difficult to produce. Once you have HBM the design follows intuitively</p>
<p>— Deep learning researcher</p>
</blockquote>
<h4 id="what-memory-is-used-on-the-h100s">What Memory Is Used On The H100s? <span><a href="#what-memory-is-used-on-the-h100s" aria-label="Anchor">#</a></span></h4>
<p>On the H100 SXM, it’s HBM3.<sup id="fnref:28"><a href="#fn:28" role="doc-noteref">28</a></sup> On the H100 PCIe, it’s actually HBM2e.<sup id="fnref:29"><a href="#fn:29" role="doc-noteref">29</a></sup></p>
<h4 id="who-makes-the-memory-on-the-h100s">Who Makes The Memory On The H100s? <span><a href="#who-makes-the-memory-on-the-h100s" aria-label="Anchor">#</a></span></h4>
<p>The bus width and clock speed are designed by Nvidia as part of the GPU architecture.</p>
<p>For the HBM3 memory itself, I think Nvidia uses either all or mostly SK Hynix. Not sure if Nvidia uses any from Samsung for the H100s and I believe it’s nothing from Micron for the H100s.</p>
<p>In terms of HBM3 generally, SK Hynix makes the most, then Samsung not that far behind, then Micron far behind. Seems like SK Hynix is ramped up but Nvidia still wants them to make more, and Samsung and Micron haven’t successfully ramped up production yet.</p>
<h3 id="what-else-is-used-when-making-gpus">What Else Is Used When Making GPUs? <span><a href="#what-else-is-used-when-making-gpus" aria-label="Anchor">#</a></span></h3>
<p>Note that some of these pieces are significantly more bottlenecked than others.</p>
<ul>
<li>
<p><strong>Metal Elements</strong>: These are essential in the production of GPUs. They include:</p>
<ul>
<li>Copper: Used in the creation of electrical connections due to its high conductivity.</li>
<li>Tantalum: Often used in capacitors due to its ability to hold a high electrical charge.</li>
<li>Gold: Used in high-quality plating and connectors due to its resistance to corrosion.</li>
<li>Aluminum: Frequently used in the heatsink to help dissipate heat.</li>
<li>Nickel: Often used in the coating of connectors for its corrosion resistance.</li>
<li>Tin: Used in soldering components together.</li>
<li>Indium: Used in thermal interface materials for its good thermal conductivity.</li>
<li>Palladium: Used in certain types of capacitors and semiconductor devices.</li>
</ul>
</li>
<li>
<p><strong>Silicon (Metalloid)</strong>: This is the primary material used in the creation of semiconductor devices.</p>
</li>
<li>
<p><strong>Rare Earth Elements</strong>: These are used in various parts of the GPU for their unique properties.</p>
</li>
<li>
<p><strong>Other Metals and Chemicals</strong>: These are used in various stages of production, from creating the silicon wafers to the final assembly of the GPU.</p>
</li>
<li>
<p><strong>Substrates</strong>: These are the material on which the GPU components are mounted.</p>
</li>
<li>
<p><strong>Package Materials</strong>: These are used to house and protect the GPU chip.</p>
</li>
<li>
<p><strong>Solder Balls and Bonding Wires</strong>: These are used to connect the GPU chip to the substrate and other components.</p>
</li>
<li>
<p><strong>Passive Components</strong>: These include capacitors and resistors, which are essential for the operation of the GPU.</p>
</li>
<li>
<p><strong>Printed Circuit Board (PCB)</strong>: This is the board on which all the components of the GPU are mounted. It provides the electrical connections between the components.</p>
</li>
<li>
<p><strong>Thermal Compounds</strong>: These are used to improve heat conduction between the chip and the heatsink.</p>
</li>
<li>
<p><strong>Semiconductor Manufacturing Equipment</strong>: This includes photolithography machines, etching equipment, ion implantation equipment, etc.</p>
</li>
<li>
<p><strong>Clean Room Facilities</strong>: These are necessary for the production of GPUs to prevent contamination of the silicon wafers and other components.</p>
</li>
<li>
<p><strong>Testing and Quality Control Equipment</strong>: These are used to ensure that the GPUs meet the required performance and reliability standards.</p>
</li>
<li>
<p><strong>Software and Firmware</strong>: These are essential for controlling the operation of the GPU and for interfacing with the rest of the computer system.</p>
</li>
<li>
<p><strong>Packaging and Shipping Materials</strong>: These are necessary for delivering the final product to customers in good condition.</p>
</li>
<li>
<p><strong>Software Tools</strong>: Software tools for Computer-Aided Design (CAD) and simulations are crucial in designing the structure and testing functionality of the GPU.</p>
</li>
<li>
<p><strong>Energy Consumption</strong>: A significant amount of electricity is required in the manufacturing process of GPU chips due to the usage of high-precision machinery.</p>
</li>
<li>
<p><strong>Waste Management:</strong> The production of GPUs results in waste which has to be properly managed and disposed of, as many of the materials used can be harmful to the environment.</p>
</li>
<li>
<p><strong>Test capacity:</strong> Custom/specialty test equipment that verifies functionality and performance.</p>
</li>
<li>
<p><strong>Chip packaging:</strong> Assembling the silicon wafer into a component package that can be utilized in a larger system.</p>
</li>
</ul>
<h2 id="outlook-and-predictions">Outlook And Predictions <span><a href="#outlook-and-predictions" aria-label="Anchor">#</a></span></h2>
<h3 id="what-is-nvidia-saying">What Is Nvidia Saying? <span><a href="#what-is-nvidia-saying" aria-label="Anchor">#</a></span></h3>
<p>Nvidia has disclosed that they have more supply in the second half of the year, but beyond that they haven’t said much more, and nothing quantitative.</p>
<blockquote>
<p>“We are working on both supply today for this quarter, but we have also procured a substantial amount of supply for the second half”</p>
<p>“We believe that the supply that we will have for the second half of the year will be substantially larger than h1”</p>
<p>– Nvidia CFO Colette Kress during the earnings call for Feb-April 2023</p>
</blockquote>
<h3 id="whatll-happen-next">What’ll Happen Next? <span><a href="#whatll-happen-next" aria-label="Anchor">#</a></span></h3>
<blockquote>
<p>I think it’s possible we have a self-reinforcing cycle right now where scarcity causes GPU capacity to be perceived as a moat, which causes more GPU-hoarding, which exacerbates scarcity.</p>
<p>– Private cloud exec</p>
</blockquote>
<h4 id="when-will-there-be-a-h100-successor">When Will There Be A H100 Successor? <span><a href="#when-will-there-be-a-h100-successor" aria-label="Anchor">#</a></span></h4>
<p>Probably won’t be announced until late 2024 (mid 2024 to early 2025), based on historical Nvidia time between architectures.</p>
<p>The H100 will be the top of the line Nvidia GPU until then. (The GH200 and DGX GH200 don’t count, they’re not pure GPUs, they all use H100s as their GPU)</p>
<h4 id="will-there-be-higher-vram-h100s">Will There Be Higher VRAM H100s? <span><a href="#will-there-be-higher-vram-h100s" aria-label="Anchor">#</a></span></h4>
<p>Maybe liquid cooled 120GB H100s.</p>
<h4 id="when-will-the-shortage-end">When Will The Shortage End? <span><a href="#when-will-the-shortage-end" aria-label="Anchor">#</a></span></h4>
<p>One group I talked with mentioned they are effectively sold out until the end of 2023.</p>
<h2 id="sourcing-h100s">Sourcing H100s <span><a href="#sourcing-h100s" aria-label="Anchor">#</a></span></h2>
<h3 id="who-sells-h100s">Who Sells H100s? <span><a href="#who-sells-h100s" aria-label="Anchor">#</a></span></h3>
<p>OEMs like Dell, HPE, Lenovo, Supermicro and Quanta sell H100s and HGX H100s.<sup id="fnref:30"><a href="#fn:30" role="doc-noteref">30</a></sup></p>
<p>And when you need InfiniBand, you’ll need to speak directly to Mellanox at Nvidia.<sup id="fnref:31"><a href="#fn:31" role="doc-noteref">31</a></sup></p>
<p>So GPU clouds like CoreWeave and Lambda buy from OEMs and then rent to startups.</p>
<p>Hyperscalers (Azure, GCP, AWS, Oracle) work more directly with Nvidia but they are generally also working with the OEMs as well.</p>
<p>And even for DGX you’ll still buy through an OEM. You can talk to Nvidia, but you’ll buy through an OEM. You won’t do a purchase order directly to Nvidia.</p>
<h4 id="how-are-the-lead-times">How Are The Lead Times? <span><a href="#how-are-the-lead-times" aria-label="Anchor">#</a></span></h4>
<p>Lead times on 8-GPU HGX servers are terrible, lead times on 4-GPU HGX servers are good. Everyone wants the 8-GPU servers!</p>
<h4 id="if-a-startup-places-an-order-today-when-would-they-have-ssh-access">If A Startup Places An Order Today, When Would They Have SSH Access? <span><a href="#if-a-startup-places-an-order-today-when-would-they-have-ssh-access" aria-label="Anchor">#</a></span></h4>
<p>It’d be a staggered deployment. Say it was a 5,000 GPU order. They might get access to 2,000 or 4,000 in 4-5 months and then the remaining by around 6 months total.</p>
<h4 id="do-startups-buy-from-oems-and-resellers">Do Startups Buy From OEMs And Resellers? <span><a href="#do-startups-buy-from-oems-and-resellers" aria-label="Anchor">#</a></span></h4>
<p>Not really. Startups will generally go to big clouds like Oracle to rent access, or to private clouds like Lambda and CoreWeave, or to providers that work with OEMs and data centers like FluidStack.</p>
<h4 id="when-do-startups-build-their-own-datacenter-vs-doing-colocation">When Do Startups Build Their Own Datacenter Vs Doing Colocation? <span><a href="#when-do-startups-build-their-own-datacenter-vs-doing-colocation" aria-label="Anchor">#</a></span></h4>
<p>For building a datacenter, the considerations are the time to build the datacenter, whether you have the people and experience in hardware, and that it’s capex expensive.</p>
<blockquote>
<p>Much easier to rent &amp; colo servers. If you want to build your own DC, you literally have to run a dark fiber line out to your location to connect to the internet - $10k per km. Most of this infra was already built &amp; paid for during dot-com boom. Now you can just rent it, quite cheap</p>
<p>– Private cloud exec</p>
</blockquote>
<p>The spectrum from rent to own is: on-demand cloud (pure rental using cloud services), reserved cloud, colo (buy the servers, work with a provider to host and manage the servers), self-hosting (buy and host the servers yourself).</p>
<p>Most startups needing large H100 quantities will do either reserved cloud or colo.</p>
<h3 id="how-do-the-big-clouds-compare">How Do The Big Clouds Compare? <span><a href="#how-do-the-big-clouds-compare" aria-label="Anchor">#</a></span></h3>
<p>The sentiment is that Oracle infrastructure is less reliable than the big 3 clouds. In exchange, Oracle gives more tech support help and time.</p>
<blockquote>
<p>100%. a big feeder of unhappy customers lol</p>
<p>– Private cloud exec</p>
</blockquote>
<blockquote>
<p>i think [oracle has] better networking though</p>
<p>– (Different) Private cloud exec</p>
</blockquote>
<p>Generally startups will pick whoever offers the best blend of support, price, and capacity.</p>
<p>The main big differences at the large clouds are:</p>
<ul>
<li>Networking (AWS and Google Cloud have been slower to adopt InfiniBand because they have their own approaches, though most startups looking for large A100/H100 clusters are seeking InfiniBand)</li>
<li>Availability (Azure’s H100s are mostly going to OpenAI. GCP is struggling to get H100s.)</li>
</ul>
<p>Nvidia seems to tend to give better allocations to clouds that aren’t building competing machine learning chips. (This is all speculation, not hard facts.) All of the big 3 clouds are working on machine learning chips, but the Nvidia-alternative offerings from AWS and Google are already available and taking dollars that might’ve gone to Nvidia.</p>
<blockquote>
<p>also speculation but i agree that nvidia likes oracle for this reason</p>
<p>– Private cloud exec</p>
</blockquote>
<p>Some big clouds have better pricing than others. As one private cloud exec noted, “a100s are much more expensive on aws/azure than gcp for instance.”</p>
<blockquote>
<p>oracle told me they have “10s of thousands of H100s” coming online later this year. they boasted about their special relationship with nvidia.</p>
<p>but… when it came to pricing, they were way higher than anyone else. they didn’t give me H100 pricing but for A100 80gb they quoted me close to $4/hour, which is nearly 2x more than gcp’s quote for the same hw and same commit.</p>
<p>– Anonymous</p>
</blockquote>
<p>The smaller clouds are better for pricing, except in some instances where the one of the big clouds does a weird deal in exchange for equity.</p>
<p>It might be something like: Oracle &amp; Azure &gt; GCP &amp; AWS in terms of Nvidia relationship. But that’s speculation.</p>
<p>Oracle was the <a href="https://www.oracle.com/news/announcement/nvidia-a100-oracle-cloud-infrastructure-092220/" target="_blank" rel="noreferrer noopener">first to launch A100s</a>, and they worked with Nvidia to <a href="https://www.oracle.com/news/announcement/nvidia-chooses-oracle-cloud-infrastructure-for-ai-services-2023-03-21/" target="_blank" rel="noreferrer noopener">host an NVIDIA-based cluster</a>. Nvidia is also a customer of <a href="https://azure.microsoft.com/en-us/blog/azure-previews-powerful-and-scalable-virtual-machine-series-to-accelerate-generative-ai/" target="_blank" rel="noreferrer noopener">Azure</a>.</p>
<h4 id="which-big-cloud-has-the-best-networking">Which Big Cloud Has The Best Networking? <span><a href="#which-big-cloud-has-the-best-networking" aria-label="Anchor">#</a></span></h4>
<p>Azure, CoreWeave and Lambda all use InfiniBand. Oracle has good networking, it is 3200 Gbps, but it’s ethernet rather than InfiniBand, which may be around 15-20% slower than IB for use cases like high-parameter count LLM training. AWS and GCP’s networking isn’t as good.</p>
<h4 id="which-big-clouds-do-enterprises-use">Which Big Clouds Do Enterprises Use? <span><a href="#which-big-clouds-do-enterprises-use" aria-label="Anchor">#</a></span></h4>
<p>In one private datapoint of about 15 enterprises, all 15 were either AWS, GCP or Azure, zero Oracle.</p>
<p>Most enterprises will stick with their existing cloud. Desperate startups will go wherever the supply is.</p>
<h4 id="how-about-dgx-cloud-who-is-nvidia-working-with-for-that">How About DGX Cloud, Who Is Nvidia Working With For That? <span><a href="#how-about-dgx-cloud-who-is-nvidia-working-with-for-that" aria-label="Anchor">#</a></span></h4>
<p>“NVIDIA is partnering with leading cloud service providers to host DGX Cloud infrastructure, starting with Oracle Cloud Infrastructure (OCI)” - you deal with Nvidia sales but you rent it through an existing cloud provider (first launching with Oracle, then Azure, then Google Cloud, not launching with AWS)<sup id="fnref:32"><a href="#fn:32" role="doc-noteref">32</a></sup> <sup id="fnref:33"><a href="#fn:33" role="doc-noteref">33</a></sup></p>
<p>Jensen said on the last earnings call: “The ideal mix is something like 10% Nvidia DGX Cloud and 90% the CSPs clouds”</p>
<h4 id="when-did-the-big-clouds-launch-their-h100-previews">When Did The Big Clouds Launch Their H100 Previews? <span><a href="#when-did-the-big-clouds-launch-their-h100-previews" aria-label="Anchor">#</a></span></h4>
<p>CoreWeave was first.<sup id="fnref:34"><a href="#fn:34" role="doc-noteref">34</a></sup> Nvidia gave them an earlier allocation, presumably to help strengthen competition (and because Nvidia is an investor) amongst large clouds.</p>
<p>Azure on March 13 announced that H100s were available for preview.<sup id="fnref:35"><a href="#fn:35" role="doc-noteref">35</a></sup></p>
<p>Oracle on March 21 announced that H100s were available in limited availability.<sup id="fnref:36"><a href="#fn:36" role="doc-noteref">36</a></sup></p>
<p>Lambda Labs on March 21 announced that H100s would be added in early April.<sup id="fnref:37"><a href="#fn:37" role="doc-noteref">37</a></sup></p>
<p>AWS on March 21 announced that H100s would be available for preview starting in a few weeks.<sup id="fnref:38"><a href="#fn:38" role="doc-noteref">38</a></sup></p>
<p>Google Cloud on May 10 announced the start of a private preview for H100s.<sup id="fnref:39"><a href="#fn:39" role="doc-noteref">39</a></sup></p>
<h4 id="which-companies-use-which-clouds">Which Companies Use Which Clouds? <span><a href="#which-companies-use-which-clouds" aria-label="Anchor">#</a></span></h4>
<ul>
<li>OpenAI: Azure.</li>
<li>Inflection: Azure and CoreWeave.</li>
<li>Anthropic: AWS and Google Cloud.</li>
<li>Cohere: AWS.</li>
<li>Hugging Face: AWS.</li>
<li>Stability AI: CoreWeave and AWS.</li>
<li>Character.ai: Google Cloud.</li>
<li>X.ai: Oracle.</li>
<li>Nvidia: Azure.<sup id="fnref1:35"><a href="#fn:35" role="doc-noteref">35</a></sup></li>
</ul>
<h3 id="how-can-a-company-or-cloud-service-provider-get-more-gpus">How Can A Company Or Cloud Service Provider Get More GPUs? <span><a href="#how-can-a-company-or-cloud-service-provider-get-more-gpus" aria-label="Anchor">#</a></span></h3>
<p>The ultimate bottleneck is getting allocation from Nvidia.</p>
<h4 id="how-do-nvidia-allocations-work">How Do Nvidia Allocations Work? <span><a href="#how-do-nvidia-allocations-work" aria-label="Anchor">#</a></span></h4>
<p>They have an allocation they give per customer. But for example, Azure saying “hey we would like 10,000 H100s all to be used by Inflection” is different from Azure saying “hey we would like 10,000 H100s for Azure’s cloud” - Nvidia cares about who the end customer is, and so clouds might be able to get an extra allocation for a specific end customer if Nvidia is excited about the end customer. Nvidia also wants to know who that end customer is, as much as possible. And they prefer customers with nice brand names or startups with strong pedigrees.</p>
<blockquote>
<p>Yes, this seems to be the case. NVIDIA likes to guarantee GPU access to rising AI companies (many of which they have a close relationship with). See Inflection — an AI company they invested in — testing a huge H100 cluster on CoreWeave, which they also invested in</p>
<p>– Private cloud exec</p>
</blockquote>
<p>If a cloud brings Nvidia an end customer and says they’re ready to purchase xxxx H100s, if Nvidia is excited about that end customer they’ll generally give an allocation, which effectively boosts the total capacity allocated by Nvidia to that cloud - because it won’t count against the original allocation that Nvidia gave to that cloud.</p>
<p>It’s a unique situation in that Nvidia is giving large allocations to private clouds: CoreWeave has more H100s than GCP.</p>
<p>Nvidia would prefer not to give large allocations to companies that are attempting to compete directly with them (AWS Inferentia and Tranium, Google TPUs, Azure Project Athena).</p>
<p>But ultimately, if you put the purchase order and money in front of Nvidia, committing to a bigger deal and more money up front and show that you have a low risk profile, then you’ll get a larger allocation than others get.</p>
<!-- ## Open questions

When will we see dozens of enterprises (not the companies training the LLMs, I mean the companies using them) using LLMs in a way that gets them increased profits? When will we see dozens of enterprises using LLMs in a way that gets them increased profits, and more satisfied end users? How will those timelines differ for closed LLMs vs open source LLMs? -->
<h2 id="closing-thoughts">Closing Thoughts <span><a href="#closing-thoughts" aria-label="Anchor">#</a></span></h2>
<p>For now, we are GPU-limited. Even if we are at the “end of the era where it’s going to be these giant models” as Sam Altman has said.</p>
<p>It’s both bubble-ish and not-bubble-ish depending on where you look. Some companies like OpenAI have products like ChatGPT with intense product-market-fit, and can’t get enough GPUs. Other companies are buying or reserving GPU capacity so they’ll have access in the future, or to train LLMs that are much less likely to have product-market-fit.</p>
<p>Nvidia is the green king of the castle right now.</p>
<h3 id="tracing-the-journey-of-gpu-supply-and-demand">Tracing The Journey Of GPU Supply And Demand <span><a href="#tracing-the-journey-of-gpu-supply-and-demand" aria-label="Anchor">#</a></span></h3>
<p>The LLM product with the strongest product-market fit is ChatGPT. Here’s the story of GPU demand with respect to ChatGPT:</p>
<ol>
<li>Users love ChatGPT. It’s probably making $500mm++ annual recurring revenue.</li>
<li>ChatGPT runs on the GPT-4 and GPT-3.5 APIs.</li>
<li>The GPT-4 and GPT-3.5 APIs need GPUs to run. Lots of them. And OpenAI wants to release more features for ChatGPT and their APIs, but they can’t, because they don’t have access to enough GPUs.</li>
<li>They buy lots of Nvidia GPUs through Microsoft/Azure. Specifically the GPU they want most is the Nvidia H100 GPU.</li>
<li>To make H100 SXM GPUs, Nvidia uses TSMC for fabrication and uses TSMC’s CoWoS packaging tech and uses HBM3 primarily from SK Hynix.</li>
</ol>
<p>OpenAI isn’t the only company that wants GPUs (but they are the company with the strongest product-market-fit that wants GPUs). Other companies are also wanting to train large AI models. Some of these use cases will make sense, but some are more hype driven and unlikely to get product-market-fit. This is pushing up demand. Also, some companies are concerned about not being able to access GPUs in the future so they’re placing their orders now even when they don’t need them yet. So there’s a bit of “expectations of supply shortages create even more supply shortages” going on.</p>
<p>The other major contributor to GPU demand is from companies that want to create new LLMs. Here’s the story of GPU demand with respect to companies wanting to build new LLMs:</p>
<ol>
<li>A company executive or founder knows there’s big opportunities in the AI space. Maybe they’re an enterprise that wants to train an LLM on their own data and use it externally or sell access, or maybe they’re a startup that wants to build an LLM and sell access.</li>
<li>They know they need GPUs to train large models.</li>
<li>They talk with some set of people from the big clouds (Azure, Google Cloud, AWS) to try and get many H100s.</li>
<li>They find out that they can’t get a big allocation from the big clouds, and that some of the big clouds don’t have good networking setups. So they go and talk with other providers like CoreWeave, Oracle, Lambda, FluidStack. If they want to buy the GPUs themselves and own them, maybe they also talk with OEMs and Nvidia.</li>
<li>Eventually, they acquire a lot of GPUs.</li>
<li>Now, they try and get product-market-fit.</li>
<li>In case it’s not obvious, this pathway isn’t as good - remember that OpenAI got product-market-fit on much smaller models and then scaled them up. But, now to get product-market-fit you have to be better than OpenAI’s models for your users’ use-cases, so to start you will need more GPUs than OpenAI started with.</li>
</ol>
<p>Expect H100 shortages for multi-hundred or multi-thousand deployments through the end of 2023 at least. At the end of 2023 the picture will be clearer, but for now it looks like the shortages may persist through some of 2024 as well.</p>
<figure>
      <img srcset="https://gpus.llm-utils.org/images/gpu-journey-small_hubc5d31a0ba9b346a37f48de655885693_361966_330x0_resize_q75_box.jpg 330w,https://gpus.llm-utils.org/images/gpu-journey-small_hubc5d31a0ba9b346a37f48de655885693_361966_660x0_resize_q75_box.jpg 660w,https://gpus.llm-utils.org/images/gpu-journey-small_hubc5d31a0ba9b346a37f48de655885693_361966_1024x0_resize_q75_box.jpg 1024w,https://gpus.llm-utils.org/images/gpu-journey-small_hubc5d31a0ba9b346a37f48de655885693_361966_1320x0_resize_q75_box.jpg 2x" src="https://gpus.llm-utils.org/images/gpu-journey-small_hubc5d31a0ba9b346a37f48de655885693_361966_660x0_resize_q75_box.jpg" alt="The GPU Journey" loading="lazy">
      <figcaption>The Journey of GPU Supply and Demand. <a href="https://gpus.llm-utils.org/static-images/gpu-journey-large.jpg">Larger version</a></figcaption>
    </figure>
  

<h3 id="getting-in-touch">Getting In Touch <span><a href="#getting-in-touch" aria-label="Anchor">#</a></span></h3>
<!-- Contact info for questions, notes, new posts and Discord: -->
<!-- If you need a large amount of H100s, feel free to let [me](mailto:clay@studionumberzero.com) know and we may be able to make some helpful intros. -->
<p>Questions and notes can be sent in via <a href="https://gpus.llm-utils.org/cdn-cgi/l/email-protection#b2d1ded3cbf2c1c6c7d6dbdddcc7dfd0d7c0c8d7c0dd9cd1dddf">email</a>. Also if you can offer helpful comments on any of these topics, please send me an email: the deal structures of large CSP investments in AI startups, the financing structures of large H100 purchases, and the economics at each layer of the stack (the ones discussed in this post, plus other layers including colo providers, invididual GPU hosts, electricity and so on). If you’d like to help, the most helpful thing would be to email and offer interesting conversations either with you or someone you could intro me to. I’d like to write more about interesting things related to GPUs, LLM startups, financing, public and private equities, colocation and so on.</p>
<!-- New posts: [get notified about new posts via email](https://airtable.com/shr411VWRbl9og1xb). -->
<!-- Someone I work with set up a discord server to chat all things GPUs - 'gpugang' - [here's the link](https://discord.gg/3zCM9meP). It's brand new and we plan to close it after around 20 users. -->
<h3 id="the-natural-next-question---what-about-nvidia-alternatives">The Natural Next Question - What About Nvidia Alternatives? <span><a href="#the-natural-next-question---what-about-nvidia-alternatives" aria-label="Anchor">#</a></span></h3>
<p>The natural next question is “ok, what about the competition and alternatives?” I’d like to do a post exploring hardware alternatives as well as software approaches. Submit things I should explore as alternatives to <a href="https://airtable.com/appOhBgC3S2sN8aE2/shrvsLIxFv7zdf1sT" target="_blank" rel="noreferrer noopener">this form</a>. For example, TPUs, Inferentia, LLM ASICs and others on the hardware side, and Mojo, Triton and others on the software side, and what it looks like to use AMD hardware and software. I’d like to explore things that are in development, but to emphasize hardware and software that is actually usable by customers today.</p>
<h2 id="acknowledgements">Acknowledgements <span><a href="#acknowledgements" aria-label="Anchor">#</a></span></h2>
<p><em>This article contains a decent amount of proprietary and previously unpublished information. When you see people wondering about GPU production capacity, please point them in the direction of this post.</em></p>
<p>Thanks to a handful of execs and founders at private GPU cloud companies, a few AI founders, an ML engineer, a deep learning researcher, a few other industry experts, and some non-industry readers, for providing helpful comments. Thanks to Hamid for illustrations.</p>


      </div>
    
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Origin of correlated isolated flat bands in LK99 (351 pts)]]></title>
            <link>https://arxiv.org/abs/2307.16892</link>
            <guid>36951815</guid>
            <pubDate>Tue, 01 Aug 2023 03:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2307.16892">https://arxiv.org/abs/2307.16892</a>, See on <a href="https://news.ycombinator.com/item?id=36951815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2307.16892">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  A recent report of room temperature superconductivity at ambient pressure in
Cu-substituted apatite (`LK99') has invigorated interest in the understanding
of what materials and mechanisms can allow for high-temperature
superconductivity. Here I perform density functional theory calculations on
Cu-substituted lead phosphate apatite, identifying correlated isolated flat
bands at the Fermi level, a common signature of high transition temperatures in
already established families of superconductors. I elucidate the origins of
these isolated bands as arising from a structural distortion induced by the Cu
ions and a chiral charge density wave from the Pb lone pairs. These results
suggest that a minimal two-band model can encompass much of the low-energy
physics in this system. Finally, I discuss the implications of my results on
possible superconductivity in Cu-doped apatite

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Sinéad Griffin Dr. [<a href="https://arxiv.org/show-email/69b7c63e/2307.16892">view email</a>]
      <br>
    <strong>[v1]</strong>
    
        Mon, 31 Jul 2023 17:58:17 UTC (7,923 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git files hidden in plain sight (116 pts)]]></title>
            <link>https://tylercipriani.com/blog/2023/07/31/git-files-hidden-in-plain-sight/</link>
            <guid>36951738</guid>
            <pubDate>Tue, 01 Aug 2023 02:48:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tylercipriani.com/blog/2023/07/31/git-files-hidden-in-plain-sight/">https://tylercipriani.com/blog/2023/07/31/git-files-hidden-in-plain-sight/</a>, See on <a href="https://news.ycombinator.com/item?id=36951738">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">







<section id="pagebody" role="main">
<blockquote>
<p>I doubt that it is a good practice to ship the public key used to
sign things in the repository in the repository itself</p>
<p>– Junio C Hamano, <a href="https://lore.kernel.org/git/20210907204100.ptapvn4wrqn3qrzq@meerkat.local/T/">git@vger.kernel.org:
expired key in junio-gpg-pub</a></p>
</blockquote>
<p>Git ships with the maintainer’s public key.</p>
<p>But you won’t find it in your worktree—it’s hidden in plain
sight.</p>
<p>Junio Hamano’s public key is a blob in the <code>git</code> object
database. It’s tagged with <code>junio-gpg-pub</code>, so you can only
see it with <code>git cat-file</code>:</p>
<pre><code>(/^ヮ^)/*:・ﾟ✧ git cat-file blob junio-gpg-pub
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: GnuPG v1
...</code></pre>
<p>In 2021, Junio pretty much said that this was a <a href="https://lore.kernel.org/git/20210907204100.ptapvn4wrqn3qrzq@meerkat.local/T/">bad
idea</a>.</p>
<p>But it led me to think about some other wonderful bad ideas.</p>
<section id="fake-empty-github-repos">
<h2>Fake empty GitHub repos <span aria-role="hidden">📦</span></h2>
<p>I made an empty GitHub repo called <a href="https://github.com/thcipriani/hidden-zangief">hidden-zangief</a>.</p>
<figure>
<img src="https://photos.tylercipriani.com/2023-07-31_empty-github.png" alt="hidden-zangief">

</figure>
<p>Except it’s not empty.</p>
<p>Instead, it’s chockfull of sweet ANSI art—Zangief from Street Fighter
II.</p>
<figure>
<img src="https://photos.tylercipriani.com/2023-07-31_zangief-ansii.png" alt="Zangief + Figlet = magic">

</figure>
<p>And if you clone it, after an initial warning, you can see Zangief is
still in there:</p>
<pre><code>(/^ヮ^)/*:・ﾟ✧ git clone https://github.com/thcipriani/hidden-zangief &amp;&amp; cd hidden-zangief
Cloning into 'hidden-zangief'...
warning: You appear to have cloned an empty repository.
(/^ヮ^)/*:・ﾟ✧ git fetch origin refs/atomic/piledriver
remote: Enumerating objects: 1, done.
remote: Counting objects: 100% (1/1), done.
remote: Total 1 (delta 0), reused 1 (delta 0), pack-reused 0
Unpacking objects: 100% (1/1), 1.71 KiB | 1.71 MiB/s, done.
From https://github.com/thcipriani/hidden-zangief
 * branch            refs/atomic/piledriver -&gt; FETCH_HEAD
(/^ヮ^)/*:・ﾟ✧ git show FETCH_HEAD

                        [...sweet zangief ansi art...]
                        _____                 _       __ 
                       |__  /__ _ _ __   __ _(_) ___ / _|
                         / // _` | '_ \ / _` | |/ _ \ |_ 
                        / /| (_| | | | | (_| | |  __/  _|
                       /____\__,_|_| |_|\__, |_|\___|_|  
                                        |___/        </code></pre>
</section>
<section id="dubious-git-plumbing-hacks">
<h2>Dubious git plumbing hacks <span aria-role="hidden">🪓</span></h2>
<p>Inspired by Junio, I misused and finagled a couple of <a href="https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain">git
plumbing commands</a> to make this fake empty repo:</p>
<ol type="1">
<li><code>git hash-object</code></li>
<li><code>git update-ref</code></li>
</ol>
<p>First, I used <code>hash-object</code> to create a dangling git
object with the <code>~/zangief.txt</code> contents.</p>
<pre><code>(/^ヮ^)/*:・ﾟ✧ mkdir /tmp/hidden-zangief &amp;&amp; cd /tmp/hidden-zangief
(/^ヮ^)/*:・ﾟ✧ git init
(/^ヮ^)/*:・ﾟ✧ git hash-object -w ~/zangief.txt
7dd9e2d2d2d8b5107d225b4708e1177abb08e7c8</code></pre>
<p>Now Zangief is lurking in your git plumbing, atomic-suplexing your
other git objects.</p>
<p>I imagine this is how Junio added his public key to the git object
database. Then he tagged it with <code>junio-gpg-pub</code> and pushed
it to the <code>git</code> repo.</p>
<p>But a tag would appear in the GitHub UI, and I wondered whether I
could hide it.</p>
<p>So I opted to abuse the wide-open git ref namespace, imagining a ref
beyond tags and branches: <code>refs/atomic/piledriver</code>.</p>
<p>Then I schlepped that ref to GitHub.</p>
<pre><code>(/^ヮ^)/*:・ﾟ✧ git update-ref refs/atomic/piledriver 7dd9e2d2d2d8b5107d225b4708e1177abb08e7c8
(/^ヮ^)/*:・ﾟ✧ git remote add origin https://github.com/thcipriani/hidden-zangief
(/^ヮ^)/*:・ﾟ✧ git push origin refs/atomic/piledriver:refs/atomic/piledriver</code></pre>
<p>And, of course, Microsoft GitHub foolishly neglects the
<code>refs/atomic/*</code> namespace in their UI, rendering our 400 lb
wrestler friend invisible.</p>
<p>Infinite magic awaits the intrepid developer willing to abuse
<code>git</code> plumbing. After all, git is just a database with a
terrible interface.</p>
</section>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Worst API Ever Made (254 pts)]]></title>
            <link>https://caseymuratori.com/blog_0025</link>
            <guid>36951289</guid>
            <pubDate>Tue, 01 Aug 2023 01:39:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://caseymuratori.com/blog_0025">https://caseymuratori.com/blog_0025</a>, See on <a href="https://news.ycombinator.com/item?id=36951289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p>In response to last week’s post, I received the following e-mail:
</p></div><div><p>“I might be a little late for a question about your recent post, but just in case I’m not:  Do you have any strategies for, or stories about, dealing with an external library that you couldn’t get rid of that violated some (or all) of these API design guidelines?  It’s a vague question, but I’m really just asking about any past experience as a user of an API that really sticks out in your mind.”</p></div><div><p>This reminded me that I’d always wanted to go write down the steps necessary to use a bad API, just to highlight how terrible it can be for the programmer.  I don’t think people who make APIs really appreciate how important it is to get them right, and how much unnecessary work their mistakes can cause for hundreds, thousands, sometimes even millions of other programmers.  So I felt like it was important to spend an article walking through an API and showing just how much unnecessary work an API can manufacture.
</p><p>It’d probably be a nice column on its own &nbsp;—&nbsp; a weekly dissection of a bad API.  But since I don’t have time for something like that, if I was only going to dissect one API, the most important question was, which API should I choose?
</p></div><div><p>Event Tracing for Windows
</p></div><div><p>It’s a great time in the history of computing to be writing an article about bad APIs (which is another way of saying it’s a terrible time to actually have to program for a living).  There’s so many bad APIs out there, I could have picked one at random and been very likely to find enough problems to fill a 3000-word article.  But if I was only going to pick apart one specific operation in one API, it seemed only right to try to pick the worst API I’d ever actually used.
</p><p>Now there are a lot of APIs out there that routinely turn in top-ranking efforts for the “worst API” leaderboard.  CSS, for example, can probably claim half the spots on the top 10 for any year in which there’s a new version.  DirectShow, while it was still a going concern, certainly dominated the rankings for its era.  And in the modern age, newcomers like the Android SDK are showing real potential with development environments so convoluted that the quality of the APIs when called from actual C++ code are the last thing you’ll worry about when trying to ship something with them.
</p><p>But when I thought long and hard about who the all-time heavyweight bad API champion was, there was one clear winner: Event Tracing for Windows.
</p><p>Event Tracing for Windows is an API that does something very simple: it allows any component of the system (including end-user software) to announce “events” which any other component can then “consume”.  It is a logging system, and it is used to record performance and debugging information by everything from the kernel upwards.
</p><p>Now, normally, a game developer would have no reason to use the Event Tracing for Windows API directly.  You can use tools like PerfMon to view logged information about your game, like how much working set it was using or how much disk I/O it did.  But there is one specific thing that directly accessing Event Tracing gives you that you can’t get anywhere else: context switch timing.
</p><p>Yes, if you have any relatively recent version of Windows (like 7 or 8), the kernel will log all thread context switches, and using the CPU timestamp included in those events, you can actually correlate them with your own in-game profiling.  This is incredibly useful information to have, and is the kind of thing you often only get from console hardware.  It’s the reason tools like <a href="http://radgametools.com/">RAD</a>’s <a href="http://www.radgametools.com/telemetry.htm">Telemetry</a> can show you when your running threads were interrupted and had to wait for system threads to do work, something that can often be critical to debugging weird performance problems.
</p><p>So far, the API is sounding pretty good.  I mean, context switch timing is very vaulable information, so even if the API was a little janky, it’d still be pretty great, right?
</p><p>Right?
</p></div><div><p>Write the Usage Code First
</p></div><div><p>Before we take a look at the actual Event Tracing for Windows API, I want to walk the walk here and do exactly what I said to do in last week’s lecture: write the usage code first.  Whenever you evaluate an API, or create a new one, you must always, always, ALWAYS start by writing some code as if you were a user trying to do the thing that the API is supposed to do.  This is the only way to get a nice, clean perspective on how the API would work if it had no constraints on it whatsoever.  If it was “magical”, as it were.  And then, once you have that, you can move forward and start thinking about the practical problems, and what the best way is for you to get to something implementable.
</p><p>So, if I were a programmer, with no knowledge of the Event Tracing for Windows API, how would I want to get a list of context switches?  Well, two methods come to mind.
</p><p>The most straightforward approach would be something like this:
</p></div></div><div><p><wbr><span>// At the beginning of the program</span><wbr></p><p><wbr>etw_event_trace <wbr>Trace <wbr>= <wbr>ETWBeginTrace();</p><p><wbr>ETWAddEventType(<wbr>Trace, <wbr>ETWType_ContextSwitch);</p><p><wbr><span>// On each frame</span><wbr></p><p><wbr>event <wbr>EventBuffer[<wbr><span>4096</span><wbr>];</p><p><wbr><span>int</span><wbr> <wbr>EventCount;</p><p><wbr><span>while</span><wbr>(<wbr>EventCount <wbr>= <wbr>ETWGetEvents(<wbr>Trace, <wbr><span>sizeof</span><wbr>(<wbr>EventBuffer), <wbr>EventBuffer))</p><p>{</p><p><wbr><span>for</span><wbr>(<wbr><span>int</span><wbr> <wbr>EventIndex <wbr>= <wbr><span>0</span><wbr>;</p><p><wbr>EventIndex <wbr>&lt; <wbr>EventCount;</p><p><wbr>++<wbr>EventIndex)</p><p>{</p><p><wbr><span>assert</span><wbr>(<wbr>EventBuffer[<wbr>EventIndex]<wbr>.<wbr>Type <wbr>== <wbr>ETWType_ContextSwitch);</p><p><wbr><span>// process EventBuffer[EventIndex].ContextSwitch here</span><wbr></p><p>}</p><p>}</p><p><wbr><span>// At the end of the program</span><wbr></p><p><wbr>ETWEndTrace(<wbr>Trace);</p></div><div><p>which would imply an API design that looks like this:
</p></div><div><p><wbr><span>enum</span><wbr> <wbr>etw_event_type</p><p>{</p><p><wbr>ETWType_None,</p><p><wbr>ETWType_ContextSwitch,</p><p><wbr><span>// ...</span><wbr></p><p><wbr>ETWType_Count,</p><p>};</p><p><wbr><span>struct</span><wbr> <wbr>etw_event_context_switch</p><p>{</p><p><wbr><span>int64_t</span><wbr> <wbr>TimeStamp;</p><p><wbr><span>uint32_t</span><wbr> <wbr>ProcessID;</p><p><wbr><span>uint32_t</span><wbr> <wbr>FromThreadID;</p><p><wbr><span>uint32_t</span><wbr> <wbr>ToThreadID;</p><p>};</p><p><wbr><span>struct</span><wbr> <wbr>etw_event</p><p>{</p><p><wbr><span>uint32_t</span><wbr> <wbr>Type; <wbr><span>// event_type</span><wbr></p><p><wbr><span>union</span><wbr></p><p>{</p><p><wbr>etw_event_context_switch <wbr>ContextSwitch;</p><p><wbr><span>// ...</span><wbr></p><p>};</p><p>};</p><p><wbr><span>struct</span><wbr> <wbr>etw_event_trace</p><p>{</p><p><wbr><span>void</span><wbr> <wbr>*<wbr>Internal;</p><p>};</p><p><wbr>event_trace <wbr>ETWBeginTrace(<wbr><span>void</span><wbr>);</p><p><wbr><span>void</span><wbr> <wbr>ETWAddEventType(<wbr>event_trace <wbr>Trace, <wbr>event_type);</p><p><wbr><span>int</span><wbr> <wbr>ETWGetEvents(<wbr>event_trace <wbr>Trace, <wbr>size_t <wbr>BufferSize, <wbr><span>void</span><wbr> <wbr>*<wbr>Buffer);</p><p><wbr><span>void</span><wbr> <wbr>ETWEndTrace(<wbr>event_trace <wbr>Trace);</p></div><div><p>That’s one way to do it.  Very simple, trivial to understand, pretty hard to mess up.  Someone stepping into this with the debugger would be able to see exactly what was going on, and you’d be able to tell pretty easily if you’d done something wrong.
</p><p>However, I could imagine a scenario where performance-critical code would not want to pay the cost of the copy from the kernel’s buffer to your buffer, which this API requires (ETWGetEvents must copy the events from some OS-internal buffer, since it has to get them from somewhere).  So a slightly more complex version would be to get some mapped memory back from the API that you use as a reading buffer:
</p></div><div><p><wbr><span>// At the beginning of the program</span><wbr></p><p><wbr>etw_event_trace <wbr>Trace <wbr>= <wbr>ETWBeginTrace(<wbr><span>4096</span><wbr><wbr>*<wbr><span>sizeof</span><wbr>(<wbr>etw_event));</p><p><wbr>ETWAddEventType(<wbr>Trace, <wbr>ETWType_ContextSwitch);</p><p><wbr><span>// On each frame</span><wbr></p><p><wbr>etw_event_range <wbr>Range;</p><p><wbr><span>while</span><wbr>(<wbr>ETWBeginEventRead(<wbr>Trace, <wbr>&amp;<wbr>Range))</p><p>{</p><p><wbr><span>for</span><wbr>(<wbr>etw_event <wbr>*<wbr>Event <wbr>= <wbr>Range<wbr>.<wbr>First;</p><p><wbr>Event <wbr>!= <wbr>Range<wbr>.<wbr>OnePastLast;</p><p><wbr>++<wbr>Event)</p><p>{</p><p><wbr><span>assert</span><wbr>(<wbr>Event<wbr>-&gt;<wbr>Type <wbr>== <wbr>ETWType_ContextSwitch);</p><p><wbr><span>// process Event-&gt;ContextSwitch here</span><wbr></p><p>}</p><p><wbr>ETWEndEventRead(<wbr>Trace, <wbr>&amp;<wbr>Range);</p><p>}</p><p><wbr><span>// At the end of the program</span><wbr></p><p><wbr>ETWEndTrace(<wbr>Trace);</p></div><div><p>All I have done here is changed the return mechanism from a copy to a ranged pointer.  In ETWBeginTrace, the user now passes in the number of events they want to buffer at maximum, and the kernel reserves room in the user’s address space for that many events.  It then writes directly into that memory if it can, avoiding unnecessary copies. When the user calls ETWBeginEventRead(), a begin and end pointer are returned that span some part of the event memory.  Since it will be treated as a circular buffer, the caller is expected to loop on in case there are two ranges (a “head” and “tail”) that need to be returned.  I included an end call, since certain methods of implementation might require the kernel to know what part of the buffer the user is looking at, so it can avoid writing into memory that is actively being read.  I don’t really know that this sort of thing would be necessary, but if you wanted to cover your bases and give the kernel the maximum implementation flexibility, this definitely supports more implementations than the ETWGetEvents() version.
</p><p>The API would be updated like this:
</p></div><div><p><wbr><span>struct</span><wbr> <wbr>etw_event_range</p><p>{</p><p><wbr>etw_event <wbr>*<wbr>First;</p><p><wbr>etw_event <wbr>*<wbr>OnePastLast;</p><p>};</p><p><wbr>event_trace <wbr>ETWBeginTrace(<wbr>size_t <wbr>BufferSize);</p><p><wbr><span>int</span><wbr> <wbr>ETWBeginEventRead(<wbr>event_trace <wbr>Trace, <wbr>etw_event_range <wbr>*<wbr>Range);</p><p><wbr><span>void</span><wbr> <wbr>ETWEndEventRead(<wbr>event_trace <wbr>Trace, <wbr>etw_event_range <wbr>*<wbr>Range);</p></div><div><p>If one were so inclined, one could even support both retrieval methods with the same API just by still allowing the ETWGetEvents() call.  Also, to complete the API with some error reporting, it might also be nice to have something like:
</p></div><div><p><wbr>bool <wbr>ETWLastGetEventsOverflowed(<wbr>event_trace <wbr>Trace);</p></div><div><div><p>to allow you to check after each ETWGetEvents() whether too many events had occurred since the last check, and the kernel was forced to throw some away.
</p><p>To each his own, but I suspect that most of the programmers I know wouldn’t have a lot of complaints with my API proposal as written.  Everyone has their own taste, so I’m sure they would each tweak something to be more to their liking, but I doubt anyone would say it was horrible.  It’s all pretty straightforward, and I suspect most programmers could integrate it into their code trivially without really thinking too much about it.
</p><p>The reason the API is so straightforward is not because I employed a sophisticated set of API design practices to finesse my way to a good API.  Quite the contrary.  The API is simple because the problem it’s solving is trivial.  It’s essentially the simplest API problem you can have in a system: how to move data from one place to another.  It’s a glorified memcpy().
</p><p>But it is precisely the simplicity of the problem that allows the Event Tracing for Windows API to really shine.  Even though all it has to do is move memory from one place to another, it manages to involve almost every kind of complexity you can see in an API.
</p></div><div><p>I don’t know how anyone is supposed to actually learn how to use the Event Tracing for Windows API.  Maybe there are good examples floating around that I just never found.  I had to piece the usage code together over the course of many hours of experimentation, pulling from various snippets of documentation.  Each time I figured out another step of the process I thought, “Wait, seriously?”  And each time Microsoft implicitly replied, “Seriously.”
</p><p>Having me tell you how to call the API does take some away from the sheer awe of the experience, so I will say, if you want the full monty, stop reading now and go try to get context switch timestamps on your own.  I can assure you it will be hours of fun and excitement.  Those who’d rather save time at the expense of a day full of facepalm moments, read on.
</p><p>OK, here we go.  The equivalent to my proposed ETWBeginTrace() is Microsoft’s StartTrace() call.  At first glance, it seems innocent enough:
</p></div></div><div><p><wbr>ULONG <wbr>StartTrace(<wbr>TRACEHANDLE <wbr>*<wbr>SessionHandle, <wbr><span>char</span><wbr> <wbr>const <wbr>*<wbr>SessionName, <wbr>EVENT_TRACE_PROPERTIES <wbr>*<wbr>Properties);</p></div><div><p>However, when you look at what you need to pass in for the Properties parameter, things start to get a little hairy.  The EVENT_<wbr>TRACE_<wbr>PROPERTIES structure is defined by Windows to look like this:
</p></div><div><p><wbr><span>struct</span><wbr> <wbr>EVENT_TRACE_PROPERTIES</p><p>{</p><p><wbr>WNODE_HEADER <wbr>Wnode;</p><p><wbr>ULONG <wbr>BufferSize;</p><p><wbr>ULONG <wbr>MinimumBuffers;</p><p><wbr>ULONG <wbr>MaximumBuffers;</p><p><wbr>ULONG <wbr>MaximumFileSize;</p><p><wbr>ULONG <wbr>LogFileMode;</p><p><wbr>ULONG <wbr>FlushTimer;</p><p><wbr>ULONG <wbr>EnableFlags;</p><p><wbr>LONG <wbr>AgeLimit;</p><p><wbr>ULONG <wbr>NumberOfBuffers;</p><p><wbr>ULONG <wbr>FreeBuffers;</p><p><wbr>ULONG <wbr>EventsLost;</p><p><wbr>ULONG <wbr>BuffersWritten;</p><p><wbr>ULONG <wbr>LogBuffersLost;</p><p><wbr>ULONG <wbr>RealTimeBuffersLost;</p><p><wbr>HANDLE <wbr>LoggerThreadId;</p><p><wbr>ULONG <wbr>LogFileNameOffset;</p><p><wbr>ULONG <wbr>LoggerNameOffset;</p><p>};</p></div><div><p>where the first member is actually a struct itself, which expands to:
</p></div><div><p><wbr><span>struct</span><wbr> <wbr>WNODE_HEADER</p><p>{</p><p><wbr>ULONG <wbr>BufferSize;</p><p><wbr>ULONG <wbr>ProviderId;</p><p><wbr><span>union</span><wbr></p><p>{</p><p><wbr>ULONG64 <wbr>HistoricalContext;</p><p><wbr><span>struct</span><wbr></p><p>{</p><p><wbr>ULONG <wbr>Version;</p><p><wbr>ULONG <wbr>Linkage;</p><p>};</p><p>};</p><p><wbr><span>union</span><wbr></p><p>{</p><p><wbr>HANDLE <wbr>KernelHandle;</p><p><wbr>LARGE_INTEGER <wbr>TimeStamp;</p><p>};</p><p><wbr>GUID <wbr>Guid;</p><p><wbr>ULONG <wbr>ClientContext;</p><p><wbr>ULONG <wbr>Flags;</p><p>};</p></div><div><p>A cursory glance at this mass of data reveals a bit of oddity: why are there members like “EventsLost” and “BuffersWritten”?  The reason is because, instead of making different structures for the different operations you might do on a trace, Microsoft grouped the API functions into a few groups, and all the functions in each group share one amalgamated structure for their parameters.  So instead of the user getting a clear idea of what goes into and comes out of a function by looking at its parameters, they must instead rely entirely on the MSDN documentation for each API, and hope that it correctly enumerates which members of the giant parameter structure are used for each call, and whether those members go into or come out of the function.
</p><p>Of course, because there’s so many different ways it can be used, and given the possibility of future APIs using it, too, Microsoft requires that you clear this gigantic beast to zero before you use it:
</p></div><div><p><wbr>EVENT_TRACE_PROPERTIES <wbr>SessionProperties <wbr>= {<wbr><span>0</span><wbr>};</p></div><div><p>For StartTrace(), if we just want to get the data back directly and aren’t trying to log to a file, we need to fill out some members. These two make some sense:
</p></div><div><p><wbr>SessionProperties<wbr>.<wbr>EnableFlags <wbr>= <wbr>EVENT_TRACE_FLAG_CSWITCH;</p><p><wbr>SessionProperties<wbr>.<wbr>LogFileMode <wbr>= <wbr>EVENT_TRACE_REAL_TIME_MODE;</p></div><div><p>The EnableFlags says what we wanted to get.  We want context switches, so we set that flag.  Now, what happens when you have more than 32 types of events coming from a single provider, I don’t know, but I guess they weren’t particularly concerned with that eventuality.  I was, which is why I went with the enum-and-function-call approach in my proposal, since it supports four billion event types, but hey, “32 event types should be enough for everyone”, so Microsoft went with a 32-bit flags field.  Not a huge deal, but this is definitely the kind of short-term thinking that leads to things like unnecessarily duplicated functions with “Ex” appended to their names.
</p><p>The LogFileMode just says whether we wanted to get events back directly, or whether we just want the kernel to write them to disk. Since they are such disparate operations, I would have broken those two things up into different function calls, but, hey, we’ve already got one big giant structure for everything, might as well throw it all in there.
</p><p>Things get a little weirder with this field:
</p></div><div><p><wbr>SessionProperties<wbr>.<wbr>Wnode<wbr>.<wbr>Flags <wbr>= <wbr>WNODE_FLAG_TRACED_GUID;</p></div><div><p>According to the documentation, that’s the only value you’re allowed to have.  So it’s just busywork for you to do.  Again, not a huge deal, because maybe they’re trying to plan for future expansion or something (heaven help us).  But we are already getting nasty data coupling here, where the function call and the structure contents are effectively redundant.
</p><p>Things continue to sour as we come to this field:
</p></div><div><p><wbr>SessionProperties<wbr>.<wbr>Wnode<wbr>.<wbr>ClientContext <wbr>= <wbr><span>1</span><wbr>;</p></div><div><p>What does that mean?  Well, the cryptically named “ClientContext” actually refers to the type of timestamp you want your events to have. “TimestampType” might have been a little bit more descriptive, but whatever.  The real fun is the bare “1” value that’s just sitting on the right.
</p><p>It turns out that there’s actually a set of enumerated values to which you can set ClientContext, but Microsoft didn’t ever give them symbolic names.  So you’re just supposed to read the documentation and remember that 1 means the timestamps come from QueryPerformanceCounter, 2 means the “system time”, and 3 means the CPU cycle count.
</p><p>In case it is not obvious, there are a number of reasons why public APIs should never do something like this.  Internally, I will occasionally do something like this, in situations where a local piece of code just wants to, say, use -1 and -2 for some kind of convoluted special cases in an indexing scheme.  But for an API that ships to literally millions of developers, you always want to define your constants.
</p><p>First, it makes the code readable.  Nobody knows what a ClientContext of “1” is, but a ClientContext of USE_<wbr>QUERY_<wbr>PERFORMANCE_<wbr>COUNTER_<wbr>TIMESTAMPS would be crystal clear. Second, it makes the code searchable.  Nobody can grep a codebase for “1”, but they can trivially grep it for USE_<wbr>QUERY_<wbr>PERFORMANCE_<wbr>COUNTER_<wbr>TIMESTAMPS.  And although you might think “well, no big deal, I’ll just grep for ClientContext = 1”, remember that more complex usage of this API could involve variables, like “…ClientContext = TimestampType;”.  Third, it makes the code not compile on future versions of the SDK where things have changed. For example, if the platform maintainers decided to deprecate the use of USE_<wbr>QUERY_<wbr>PERFORMANCE_<wbr>COUNTER_<wbr>TIMESTAMPS, they could remove the #define for it and make it be USE_<wbr>QUERY_<wbr>PERFORMANCE_<wbr>COUNTER_<wbr>TIMESTAMPS_<wbr>DEPRECATED.  Now all the old code that uses that value will get a compile error on the new SDK, and the programmer will go look at the new documentation and see what they should be using instead.
</p><p>Etc., etc., etc.
</p><p>Perhaps the most annoying field we have to fill out is this one:
</p></div><div><p><wbr>SessionProperties<wbr>.<wbr>Wnode<wbr>.<wbr>Guid <wbr>= <wbr>SystemTraceControlGuid;</p></div><div><p>The GUID says who you’re trying to trace.  In our case, we’re trying to get data from the kernel logger, and SystemTraceControlGuid is the globally defined GUID that refers to this service.  It could have been named better, sure, but that’s a minor issue compared to the fact that, if you were to actually try to compile this line of code, you’d find that SystemTraceControlGuid was an undefined symbol at link time.
</p><p>This happens, of course, because the GUIDs are so large that Microsoft apparently couldn’t figure out any way to embed them in the headers (I can think of several possible ways, but I guess they didn’t like any of them), so instead they force you to pick one file in your project where the Windows headers will inject the actual GUID definitions.  To signal that you want this to happen, you have to do something like this:
</p></div><div><p><wbr><span>#define</span><wbr> <wbr>INITGUID  <wbr><span>// Causes definition of SystemTraceControlGuid in evntrace.h</span><wbr></p><p><wbr><span>#include</span><wbr> <wbr>&lt;<wbr>windows<wbr>.<wbr>h<wbr>&gt;</p><p><wbr><span>#include</span><wbr> <wbr>&lt;<wbr>strsafe<wbr>.<wbr>h<wbr>&gt;</p><p><wbr><span>#include</span><wbr> <wbr>&lt;<wbr>wmistr<wbr>.<wbr>h<wbr>&gt;</p><p><wbr><span>#include</span><wbr> <wbr>&lt;<wbr>evntrace<wbr>.<wbr>h<wbr>&gt;</p><p><wbr><span>#include</span><wbr> <wbr>&lt;<wbr>evntcons<wbr>.<wbr>h<wbr>&gt;</p></div><div><p>So now you have to be careful about where you do this, perhaps by making a new file in your project where the GUIDs will live so everyone can reference them, or some other such nonsense, so you don’t ever do it twice.
</p><p>But whatever, we’re almost done filling out the structure.  All we have to do is deal with the SessionName parameter, which we should be able to just pass as a string, right?  Since it’s the name of the session, I guess maybe just do:
</p></div><div><p><wbr>ULONG <wbr>Status <wbr>= <wbr>StartTrace(<wbr>&amp;<wbr>SessionHandle, <wbr><span>"CaseyTownProfilerAWESOMEYEAH!!!"</span><wbr>, <wbr>&amp;<wbr>SessionProperties);</p></div><div><p>Because that would be an awesome session name, don’t you think?
</p><p>But alas, that is not the way things work.  It turns out that, even though you already pass a GUID in the SessionProperties that specifies that the kernel is the source of the events, you must also pass the pre-defined constant KERNEL_<wbr>LOGGER_<wbr>NAME as the session name.  Why?  Well, it’s because of a little secret surprise that I’ll save for a bit, just so you can savor the suspense of it all.
</p><p>OK, so, here we go:
</p></div><div><p><wbr>ULONG <wbr>Status <wbr>= <wbr>StartTrace(<wbr>&amp;<wbr>SessionHandle, <wbr>KERNEL_LOGGER_NAME, <wbr>&amp;<wbr>SessionProperties);</p></div><div><p>Looking good, right?  Wrong.
</p><p>It turns out that, although the SessionName string is passed as the second parameter, that’s really just a “convenience” feature.  Really, the SessionName is required to be embedded directly into the SessionProperties, but since Microsoft didn’t want to limit the maximum length of the name, they decided to just go ahead and pack it in after the EVENT_<wbr>TRACE_<wbr>PROPERTIES structure.  So really, you can’t do this:
</p></div><div><p><wbr>EVENT_TRACE_PROPERTIES <wbr>SessionProperties <wbr>= {<wbr><span>0</span><wbr>};</p></div><div><p><wbr>ULONG <wbr>BufferSize <wbr>= <wbr><span>sizeof</span><wbr>(<wbr>EVENT_TRACE_PROPERTIES) <wbr>+ <wbr><span>sizeof</span><wbr>(<wbr>KERNEL_LOGGER_NAME);</p><p><wbr>EVENT_TRACE_PROPERTIES <wbr>*<wbr>SessionProperties <wbr>= (<wbr>EVENT_TRACE_PROPERTIES<wbr>*) <wbr>malloc(<wbr>BufferSize);</p><p><wbr>ZeroMemory(<wbr>SessionProperties, <wbr>BufferSize);</p><p><wbr>SessionProperties<wbr>-&gt;<wbr>LoggerNameOffset <wbr>= <wbr><span>sizeof</span><wbr>(<wbr>EVENT_TRACE_PROPERTIES);</p></div><div><p>Yes, that’s right, every user of the Event Tracing for Windows API has to do the arithmetic and layout of the packed structure format themselves.  I have absolutely no idea why the name has to be bundled in this way, but surely if you wanted everyone to do this, you should have supplied a utility macro or function that would do the right thing for the user and keep them out of the business of understanding your weird data packing requirements.
</p><p>But hey, at least you don’t have to copy the name in there yourself! The convention Microsoft adopted for this API was that the StartTrace() function will copy the name into the structure for you, since after all, it’s passed as the second parameter.
</p><p>Well, it’s a nice gesture, but it doesn’t pan out in practice. It turns out that forcing the SessionName to be KERNEL_<wbr>LOGGER_<wbr>NAME wasn’t superfluous with the GUID after all, and that is the secret surprise to which I alluded.  The real reason that it has to be KERNEL_<wbr>LOGGER_<wbr>NAME is because Windows only allows you to have one session in the system &nbsp;—&nbsp; total &nbsp;—&nbsp; that reads events from the SystemTraceControlGuid.  Other GUIDs can be read by multiple sessions, but not SystemTraceControlGuid.  So really what is happening when you pass KERNEL_<wbr>LOGGER_<wbr>NAME is that you are saying you want the one unique session that can exist in the system at any given time with the GUID of SystemTraceControlGuid.  If someone else already started that session, then your attempt to start it will fail.
</p><p>It gets better.  The session is global to the operating system and doesn’t automatically close on the termination of the process that started it.  So if you write code that calls StartTrace(), but you have a bug in that code somewhere &nbsp;—&nbsp; anywhere &nbsp;—&nbsp; and your program crashes, the KERNEL_<wbr>LOGGER_<wbr>NAME session is still running!  When you go to re-run your program, perhaps after fixing the bug, your attempt to StartTrace() will fail with ERROR_<wbr>ALREADY_<wbr>EXISTS.
</p><p>So, basically, StartTrace(), which is the call that helpfully copies the SessionName into the struct for you, is rarely the first call you would make anyway.  What you’re much more likely to do is call this:
</p></div><div><p><wbr>ControlTrace(<wbr><span>0</span><wbr>, <wbr>KERNEL_LOGGER_NAME, <wbr>SessionProperties, <wbr>EVENT_TRACE_CONTROL_STOP);</p></div><div><p>This shuts down any existing session, so that your subsequent call to StartTrace() will succeed.  But of course, ControlTrace() doesn’t copy the name in like StartTrace() does, which means that, in practice, you have to do it yourself, since StartTrace() gets called after ControlTrace()!
</p></div><div><p><wbr>StringCbCopy((<wbr>LPSTR)((<wbr><span>char</span><wbr><wbr>*)<wbr>pSessionProperties <wbr>+ <wbr>pSessionProperties<wbr>-&gt;<wbr>LoggerNameOffset), <wbr><span>sizeof</span><wbr>(<wbr>KERNEL_LOGGER_NAME), <wbr>KERNEL_LOGGER_NAME);</p></div><div><div><p>It’s crazy, but the ramifications of all this are crazier still.  If you think about what it means to have only one possible trace that is connected to the kernel logger, you realize quickly that there are security issues at play.  If some other process had called StartTrace(), and they were the ones that were using the kernel logger, how does the system know that it’s OK for our process to come in and stop that trace so we can start it back up again with our settings?
</p><p>The answer, hilariously, is that it doesn’t!  In fact, it’s a complete free-for-all &nbsp;—&nbsp; may the best process win!  Whoever calls StartTrace() last, well, that’s who gets to configure the trace.
</p><p>Well, not quite.  Obviously, you don’t want just any old process to be able to steal the kernel logger away from other processes.  So Microsoft decided that the best course of action would be to simply prohibit all processes from accessing the kernel logger at all, unless they’ve been specifically granted administrator privileges.
</p><p>That’s right &nbsp;—&nbsp; I am not exaggerating.  If you simply want to receive a list of the context switches, even if only for your process, it must be running with full administrator privileges.  The whole right-click-run-as-administrator nine yards.  If you don’t, and you just run your process normally, your StartTrace will fail with insufficient privileges.  (In theory, you may also be able to add your user to the “Performance Log Users” group and avoid having to run the process as administrator, but I’m sad to say that, at the moment, I can’t actually remember if that works for kernel logger connections or only other types of traces…)
</p><p>Amazing, yes?  To do the equivalent of what should have been two trivial function calls (ETWBeginTrace() / ETWAddEventType()), we’ve done memory arithmetic, we’ve allocated memory, we’ve cleared memory, we’ve computed offsets, we’ve copied strings, we’ve filled out structures, used not one but two global GUID-style constants, forced a #define manhandling of the preprocessor #includes, and required that the user start our process with full administrator privileges.
</p><p>All this, and we haven’t even gotten any events yet!
</p></div><div><p>I know what you’re thinking.  You’re thinking that the section after “Starting the Trace” should cover getting the events from the trace, right?  Nonsense!  This is the Event Tracing for Windows API, people!  Starting a trace doesn’t start a trace!  It just half-starts a trace!  If you want to start the trace for real, everyone knows you have to start it, then <i>open</i> it…  with the OpenTrace() function:
</p></div></div><div><p><wbr>TRACEHANDLE <wbr>OpenTrace(<wbr>EVENT_TRACE_LOGFILE <wbr>*<wbr>Logfile);</p></div><div><p>What does this function do?  Well, it turns out that a “started” trace is just a trace that is collecting events.  It doesn’t actually provide any way to ever get those events.  If you want to get them, you need to open the trace up with OpenTrace().
</p><p>So to call OpenTrace(), we need an EVENT_<wbr>TRACE_<wbr>LOGFILE.  Of course, we’re not actually making a log file, we just want to get the events, so it’s a little odd that we’d be filling out something called “LOGFILE”.  But much like StartTrace(), OpenTrace() is part of a family of functions that all share the same parameter structure, so really, the fact that it’s inappropriately named for our purposes is one of the more minor annoyances.
</p><p>The EVENT_<wbr>TRACE_<wbr>LOGFILE structure looks like this:
</p></div><div><p><wbr><span>struct</span><wbr> <wbr>EVENT_TRACE_LOGFILE</p><p>{</p><p><wbr>LPTSTR <wbr>LogFileName;</p><p><wbr>LPTSTR <wbr>LoggerName;</p><p><wbr>LONGLONG <wbr>CurrentTime;</p><p><wbr>ULONG <wbr>BuffersRead;</p><p><wbr><span>union</span><wbr></p><p>{</p><p><wbr>ULONG <wbr>LogFileMode;</p><p><wbr>ULONG <wbr>ProcessTraceMode;</p><p>};</p><p><wbr>EVENT_TRACE <wbr>CurrentEvent;</p><p><wbr>TRACE_LOGFILE_HEADER <wbr>LogfileHeader;</p><p><wbr>PEVENT_TRACE_BUFFER_CALLBACK <wbr>BufferCallback;</p><p><wbr>ULONG <wbr>BufferSize;</p><p><wbr>ULONG <wbr>Filled;</p><p><wbr>ULONG <wbr>EventsLost;</p><p><wbr><span>union</span><wbr></p><p>{</p><p><wbr>EVENT_CALLBACK <wbr>*<wbr>EventCallback;</p><p><wbr>EVENT_RECORD_CALLBACK <wbr>*<wbr>EventRecordCallback;</p><p>};</p><p><wbr>ULONG <wbr>IsKernelTrace;</p><p><wbr>PVOID <wbr>Context;</p><p>};</p></div><div><p>If you got nervous when you saw the word “Callback” appear in that structure, I’m right there with you.  Getting events should be a simple matter of asking for them and receiving the memory.  There should be absolutely no need for a callback.
</p><p>But, moving on, EVENT_<wbr>TRACE_<wbr>LOGFILE is one of those giant grab-bag structures, so Microsoft asks that you clear it first so any unused parts will be zero:
</p></div><div><p><wbr>EVENT_TRACE_LOGFILE <wbr>LogFile <wbr>= {<wbr><span>0</span><wbr>};</p></div><div><p>Since the OpenTrace() function doesn’t actually take any handles, we need to give it some way to find the trace we “started” before.  It turns out this is done by string-matching, so we pass the session name yet again:
</p></div><div><p><wbr>LogFile<wbr>.<wbr>LoggerName <wbr>= <wbr>KERNEL_LOGGER_NAME;</p></div><div><p>Strangely, this time we don’t have to copy it to the end of the structure.  Why?  Who knows!  Variety is the spice of life, I am told.  Microsoft wants your life to be spicy.
</p><p>Next, we have to fill in the tracing mode, which is actually a set of mode flags:
</p></div><div><p><wbr>LogFile<wbr>.<wbr>ProcessTraceMode <wbr>= (<wbr>PROCESS_TRACE_MODE_REAL_TIME <wbr>| <wbr>PROCESS_TRACE_MODE_EVENT_RECORD <wbr>| <wbr>PROCESS_TRACE_MODE_RAW_TIMESTAMP);</p></div><div><p>PROCESS_<wbr>TRACE_<wbr>MODE_<wbr>REAL_<wbr>TIME, as far as I can tell, is a completely redundant flag, because if you don’t specify a log file name, then I’m not sure how you’d receive events otherwise. PROCESS_<wbr>TRACE_<wbr>MODE_<wbr>EVENT_<wbr>RECORD is a compatibility flag that tells Windows you want to use the new EventRecordCallback, as opposed to the older EventCallback (yes, believe it or not, this fine API has actually gone through multiple revisions!)  And the PROCESS_<wbr>TRACE_<wbr>MODE_<wbr>RAW_<wbr>TIMESTAMP flag tells Windows not to override the setting for the ClientContext passed to the StartTrace() call.  I guess the idea here is that the person who started the trace might have used a timestamp format other than “2”, and if you want “2”, then you can always for it to be “2” when you actually get the events.  If you always wanted “1” or “3”, well… no such luck.
</p><p>Finally, we need to point the API at a function we write that will collect the events:
</p></div><div><p><wbr>LogFile<wbr>.<wbr>EventRecordCallback <wbr>= <wbr>CaseyEventRecordCallback;</p></div><div><p>And then we’re finally ready for the big call:
</p></div><div><p><wbr>TRACEHANDLE <wbr>ConsumerHandle <wbr>= <wbr>OpenTrace(<wbr>&amp;<wbr>LogFile);</p></div><div><div><p>Now, before we move on to actually trying to get some actual events (perish the thought!), I’d like you to stop for a minute and marvel at the pure brilliance of StartTrace() and OpenTrace().  These are two APIs that are part of the same system.  They both generate a new TRACEHANDLE.  They can both fail.  They both take the session name. But, for each of these things, they do it completely differently. Completely!
</p><p>StartTrace() returns a ULONG error code, and takes a pointer to space for the handle it returns.  OpenTrace() returns the handle directly, but sets it to INVALID_<wbr>HANDLE_<wbr>VALUE if there was an error.  StartTrace() takes the session name as a parameter, and forces you to leave space in its parameter structure so it can copy it in.  OpenTrace() takes a pointer to the session name in its parameter structure, but doesn’t require it to be copied anywhere.
</p></div><div><p>We’ve worked so hard and come so far, it would be nice to finally get an actual context switch event, wouldn’t it?  To get one, we’ll of course need to implement the actual callback we pointed OpenTrace() at:
</p></div></div><div><p><wbr><span>static</span><wbr> <wbr><span>void</span><wbr> <wbr>WINAPI <wbr>CaseyEventRecordCallback(<wbr>EVENT_RECORD <wbr>*<wbr>EventRecord)</p><p>{</p><p><wbr>EVENT_HEADER <wbr>&amp;<wbr>Header <wbr>= <wbr>EventRecord<wbr>-&gt;<wbr>EventHeader;</p><p><wbr>UCHAR <wbr>ProcessorNumber <wbr>= <wbr>EventRecord<wbr>-&gt;<wbr>BufferContext<wbr>.<wbr>ProcessorNumber;</p><p><wbr>ULONG <wbr>ThreadID <wbr>= <wbr>Header<wbr>.<wbr>ThreadId;</p><p><wbr>int64 <wbr>CycleTime <wbr>= <wbr>Header<wbr>.<wbr>TimeStamp<wbr>.<wbr>QuadPart;</p><p><wbr><span>// Process event here.</span><wbr></p><p>}</p></div><div><p>Mercifully, this is just a bunch of structure accesses, and there’s nothing particularly unusual going on.  The event comes in, we pull the data out of it, and then we could do whatever we wanted to do with it.  But, when does this callback get called?
</p><p>Well, Windows only calls it back when you attempt to “process” events in your open trace using this API:
</p></div><div><p><wbr>ULONG <wbr>ProcessTrace(<wbr>TRACEHANDLE <wbr>*<wbr>HandleArray, <wbr>ULONG <wbr>HandleCount, <wbr>LPFILETIME <wbr>StartTime, <wbr>LPFILETIME <wbr>EndTime);</p></div><div><p>Using this function, you can pass an open trace handle, and Windows will spin through all the events it has on that handle, calling your callback for each one.  So we’re done, right?  We just call this function every frame of our game, or some other appropriate interval, and we harvest the events with the callback?
</p><p>I’m afraid not, my friends, because here is the brown icing on the poopcake, that savory sauce that makes the Event Tracing for Windows API more grainy and aromatic that its contemporaries: ProcessTrace is defined to never return.
</p><p>Yes, you read that correctly.  The definition of ProcessTrace(), for a real-time trace, is that it dispatches any events it finds currently logged on the trace, and then just blocks until more come in.  It will block forever, or until the trace is manually closed with CloseTrace().  This means the only way to actually get the events and continue running your process is to create an entirely new thread to do nothing but block on ProcessTrace()!
</p><p>You think I’m joking, but I’m completely serious.  You first have to make a thread stub that blocks forever on ProcessTrace():
</p></div><div><p><wbr><span>static</span><wbr> <wbr>DWORD <wbr>WINAPI <wbr>Win32TracingThread(<wbr>LPVOID <wbr>Parameter)</p><p>{</p><p><wbr>ProcessTrace(<wbr>&amp;<wbr>ConsumerHandle, <wbr><span>1</span><wbr>, <wbr><span>0</span><wbr>, <wbr><span>0</span><wbr>);</p><p><wbr><span>return</span><wbr>(<wbr><span>0</span><wbr>);</p><p>}</p></div><div><p>Then, after you call OpenTrace(), you have to spin up that thread to do the processing:
</p></div><div><p><wbr>DWORD <wbr>ThreadID;</p><p><wbr>HANDLE <wbr>ThreadHandle <wbr>= <wbr>CreateThread(<wbr><span>0</span><wbr>, <wbr><span>0</span><wbr>, <wbr>Win32TracingThread, <wbr><span>0</span><wbr>, <wbr><span>0</span><wbr>, <wbr>&amp;<wbr>ThreadID);</p><p><wbr>CloseHandle(<wbr>ThreadHandle);</p></div><div><div><p>That is literally the only way I know to retrieve frame-by-frame events from a running program using the Event Tracing for Windows API.
</p></div><div><p>A Class Entirely By Itself
</p></div><div><p>So there you have it, ladies and gentlemen: the only API I’ve ever used that requires both elevated privileges and a dedicated user thread just to copy a block of structures from the kernel to the user. I’d never seen anything like it before, and I’ve never seen anything like it since.  Add that to the littany of what-not-to-dos that comprise the actual API calls themselves, and I hope everyone will agree that the Event Tracing for Windows API is in a class of bad API entirely by itself.
</p><p>You can nit-pick this API by examining it with the principles I outlined last week (well, ten years ago).  For example, you can point out that a required thread and a callback for a simple memory transfer is a major red flag under the Flow Control principle.  You can point out that there is no granularity at all, as you must call the calls in exactly the way that I described.  You can point out that nearly all the data and all the functions are coupled in a dozen different ways, including bizarre ones like the requirement that the SessionName be KERNEL_<wbr>LOGGER_<wbr>NAME if the GUID is SystemTraceControlGuid.
</p><p>But really, the most important takeaway from a bad API like this is “always write the usage code first”.  In the lecture, I said it was the first and second rule of API design, and I wasn’t kidding.  Without thinking about pricinples at all, or getting bogged down in details, just the simple exercise of writing down what the API <i>should</i> look like was all that was really necesssary to see all the places the Microsoft version fell down.  If you go back and contrast the two, it’s immediately apparent how overcomplicated, error-prone, and unnecessary the Microsoft version is using only your programmer’s intuition.                    
</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Semiconducting Transport in LK99 reproduction attempt (470 pts)]]></title>
            <link>https://arxiv.org/abs/2307.16802</link>
            <guid>36951140</guid>
            <pubDate>Tue, 01 Aug 2023 01:18:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2307.16802">https://arxiv.org/abs/2307.16802</a>, See on <a href="https://news.ycombinator.com/item?id=36951140">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2307.16802">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  The very recent claim on the discovery of ambient-pressure room-temperature
superconductivity in modified lead-apatite has immediately excited sensational
attention in the entire society, which is fabricated by sintering lanarkite
(Pb2SO5) and copper(I) phosphide (Cu3P). To verify this exciting claim, we have
successfully synthesized Pb2SO5, Cu3P, and finally the modified lead-apatite
Pb10-xCux(PO4)6O. Detailed electrical transport and magnetic properties of
these compounds were systematically analyzed. It turns out that Pb2SO5 is a
highly insulating diamagnet with a room-temperature resistivity of ~7.18x10^9
<a href="http://ohm.cm/" rel="external noopener nofollow">this http URL</a> and Cu3P is a paramagnetic metal with a room-temperature resistivity of
~5.22x10^-4 <a href="http://ohm.cm/" rel="external noopener nofollow">this http URL</a>. In contrast to the claimed superconductivity, the resulting
Pb10-xCux(PO4)6O compound sintered from Pb2SO5 and Cu3P exhibits
semiconductor-like transport behavior with a large room-temperature resistivity
of ~1.94x10^4 <a href="http://ohm.cm/" rel="external noopener nofollow">this http URL</a> although our compound shows greatly consistent x-ray
diffraction spectrum with the previously reported structure data. In addition,
when a pressed Pb10-xCux(PO4)6O pellet is located on top of a commercial
Nd2Fe14B magnet at room temperature, no repulsion could be felt and no magnetic
levitation was observed either. These results imply that the claim of a
room-temperature superconductor in modified lead-apatite may need more careful
re-examination, especially for the electrical transport properties.

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Zhiqi Liu [<a href="https://arxiv.org/show-email/0aad5666/2307.16802">view email</a>]
      <br>
    <strong>[v1]</strong>
    
        Mon, 31 Jul 2023 16:13:05 UTC (1,275 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MIT engineers create an energy-storing supercapacitor from ancient materials (154 pts)]]></title>
            <link>https://news.mit.edu/2023/mit-engineers-create-supercapacitor-ancient-materials-0731</link>
            <guid>36951089</guid>
            <pubDate>Tue, 01 Aug 2023 01:11:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.mit.edu/2023/mit-engineers-create-supercapacitor-ancient-materials-0731">https://news.mit.edu/2023/mit-engineers-create-supercapacitor-ancient-materials-0731</a>, See on <a href="https://news.ycombinator.com/item?id=36951089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

            <p>Two of humanity's most ubiquitous historical materials, cement and carbon black (which resembles very fine charcoal), may form the basis for a novel, low-cost energy storage system, according to a new study. The technology could facilitate the use of renewable energy sources such as solar, wind, and tidal power by allowing energy networks to remain stable despite fluctuations in renewable energy supply.</p>

<p>The two materials, the researchers found, can be combined with water to make a supercapacitor — an alternative to batteries — that could provide storage of electrical energy. As an example, the MIT researchers who developed the system say that their supercapacitor could eventually be incorporated into the concrete foundation of a house, where it could store a full day’s worth of energy while adding little (or no) to the cost of the foundation and still providing the needed structural strength. The researchers also envision a concrete roadway that could provide contactless recharging for electric cars as they travel over that road.</p>



<p>The simple but innovative technology is described this week in the journal <em>PNAS</em>, in a <a href="https://www.pnas.org/doi/10.1073/pnas.2304318120" target="_blank">paper</a> by MIT professors Franz-Josef Ulm, Admir Masic, and Yang-Shao Horn, and four others at MIT and at the Wyss Institute for Biologically Inspired Engineering.</p>



<p>Capacitors are in principle very simple devices, consisting of two electrically conductive plates immersed in an electrolyte and separated by a membrane. When a voltage is applied across the capacitor, positively charged ions from the electrolyte accumulate on the negatively charged plate, while the positively charged plate accumulates negatively charged ions. Since the membrane in between the plates blocks charged ions from migrating across, this separation of charges creates an electric field between the plates, and the capacitor becomes charged. The two plates can maintain this pair of charges for a long time and then deliver them very quickly when needed. Supercapacitors are simply capacitors that can store exceptionally large charges.</p>



<p>The amount of power a capacitor can store depends on the total surface area of its conductive plates. The key to the new supercapacitors developed by this team comes from a method of producing a cement-based material with an extremely high internal surface area due to a dense, interconnected network of conductive material within its bulk volume. The researchers achieved this by introducing carbon black — which is highly conductive — into a concrete mixture along with cement powder and water, and letting it cure. The water naturally forms a branching network of openings within the structure as it reacts with cement, and the carbon migrates into these spaces to make wire-like structures within the hardened cement. These structures have a fractal-like structure, with larger branches sprouting smaller branches, and those sprouting even smaller branchlets, and so on, ending up with an extremely large surface area within the confines of a relatively small volume. The material is then soaked in a standard electrolyte material, such as potassium chloride, a kind of salt, which provides the charged particles that accumulate on the carbon structures. Two electrodes made of this material, separated by a thin space or an insulating layer, form a very powerful supercapacitor, the researchers found.</p>



<p>The two plates of the capacitor function just like the two poles of a rechargeable battery of equivalent voltage: When connected to a source of electricity, as with a battery, energy gets stored in the plates, and then when connected to a load, the electrical current flows back out to provide power.</p>



<p>“The material is fascinating,” Masic says, “because you have the most-used manmade material in the world, cement, that is combined with carbon black, that is a well-known historical material — the Dead Sea Scrolls were written with it. You have these at least two-millennia-old materials that when you combine them in a specific manner you come up with a conductive nanocomposite, and that’s when things get really interesting.”</p>



<p>As the mixture sets and cures, he says, “The water is systematically consumed through cement hydration reactions, and this hydration fundamentally affects nanoparticles of carbon because they are hydrophobic (water repelling).” As the mixture evolves, “the carbon black is self-assembling into a connected conductive wire,” he says. The process is easily reproducible, with materials that are inexpensive and readily available anywhere in the world. And the amount of carbon needed is very small — as little as 3 percent by volume of the mix — to achieve a percolated carbon network, Masic says.</p>



<p>Supercapacitors made of this material have great potential to aid in the world’s transition to renewable energy, Ulm says. The principal sources of emissions-free energy, wind, solar, and tidal power, all produce their output at variable times that often do not correspond to the peaks in electricity usage, so ways of storing that power are essential. “There is a huge need for big energy storage,” he says, and existing batteries are too expensive and mostly rely on materials such as lithium, whose supply is limited, so cheaper alternatives are badly needed. “That’s where our technology is extremely promising, because cement is ubiquitous,” Ulm says.</p>



<p>The team calculated that a block of nanocarbon-black-doped concrete that is 45 cubic meters (or yards) in size — equivalent to a cube about 3.5 meters across — would have enough capacity to store about 10 kilowatt-hours of energy, which is considered the average daily electricity usage for a household. Since the concrete would retain its strength, a house with a foundation made of this material could store a day’s worth of energy produced by solar panels or windmills and allow it to be used whenever it’s needed. And, supercapacitors can be charged and discharged much more rapidly than batteries.</p>



<p>After a series of tests used to determine the most effective ratios of cement, carbon black, and water, the team demonstrated the process by making small supercapacitors, about the size of some button-cell batteries, about 1 centimeter across and 1 millimeter thick, that could each be charged to 1 volt, comparable to a 1-volt battery. They then connected three of these to demonstrate their ability to light up a 3-volt light-emitting diode (LED). Having proved the principle, they now plan to build a series of larger versions, starting with ones about the size of a typical 12-volt car battery, then working up to a 45-cubic-meter version to demonstrate its ability to store a house-worth of power.</p>



<p>There is a tradeoff between the storage capacity of the material and its structural strength, they found. By adding more carbon black, the resulting supercapacitor can store more energy, but the concrete is slightly weaker, and this could be useful for applications where the concrete is not playing a structural role or where the full strength-potential of concrete is not required. For applications such as a foundation, or structural elements of the base of a wind turbine, the “sweet spot” is around 10 percent carbon black in the mix, they found.</p>



<p>Another potential application for carbon-cement supercapacitors is for building concrete roadways that could store energy produced by solar panels alongside the road and then deliver that energy to electric vehicles traveling along the road using the same kind of technology used for wirelessly rechargeable phones. A related type of car-recharging system is already being developed by companies in Germany and the Netherlands, but using standard batteries for storage.</p>



<p>Initial uses of the technology might be for isolated homes or buildings or shelters far from grid power, which could be powered by solar panels attached to the cement supercapacitors, the researchers say.</p>



<p>Ulm says that the system is very scalable, as the energy-storage capacity is a direct function of the volume of the electrodes. “You can go from 1-millimeter-thick electrodes to 1-meter-thick electrodes, and by doing so basically you can scale the energy storage capacity from lighting an LED for a few seconds, to powering a whole house,” he says.</p>



<p>Depending on the properties desired for a given application, the system could be tuned by adjusting the mixture. For a vehicle-charging road, very fast charging and discharging rates would be needed, while for powering a home “you have the whole day to charge it up,” so slower-charging material could be used, Ulm says.</p>



<p>“So, it’s really a multifunctional material,” he adds. Besides its ability to store energy in the form of supercapacitors, the same kind of concrete mixture can be used as a heating system, by simply applying electricity to the carbon-laced concrete.</p>



<p>Ulm sees this as “a new way of looking toward the future of concrete as part of the energy transition.”</p>



<p>The research team also included postdocs Nicolas Chanut and Damian Stefaniuk at MIT’s Department of Civil and Environmental Engineering, James Weaver at the Wyss Institute, and Yunguang Zhu in MIT’s Department of Mechanical Engineering. The work was supported by the MIT Concrete Sustainability Hub, with sponsorship by the Concrete Advancement Foundation.</p>        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Help the Library of Congress create games to improve public knowledge of civics (312 pts)]]></title>
            <link>https://blogs.loc.gov/law/2023/06/help-the-library-of-congress-create-video-games-that-improve-public-knowledge-of-civics/</link>
            <guid>36950075</guid>
            <pubDate>Mon, 31 Jul 2023 23:04:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.loc.gov/law/2023/06/help-the-library-of-congress-create-video-games-that-improve-public-knowledge-of-civics/">https://blogs.loc.gov/law/2023/06/help-the-library-of-congress-create-video-games-that-improve-public-knowledge-of-civics/</a>, See on <a href="https://news.ycombinator.com/item?id=36950075">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-90528">
    <!-- .entry-header -->
        <div>
        <p><a href="https://www.loc.gov/?loclr=bloglaw">The Library of Congress</a> is sponsoring a challenge to help improve public knowledge of civics – that is, the rights and responsibilities of citizens – by asking video game developers to create fun, lightweight video games related to civics that incorporate Library of Congress resources.</p>
<figure id="attachment_90743"><a href="https://blogs.loc.gov/law/files/2023/06/Oregon-Trail-Died-of-Dysentery-Graphic-Copy.jpg"><img loading="lazy" src="https://blogs.loc.gov/law/files/2023/06/Oregon-Trail-Died-of-Dysentery-Graphic-Copy.jpg" alt="A screen capture from the classic 1980s game, Oregon Trail. Oregon Trail inspired the Library of Congress Friends' Choice Civics Video Game Challenge, since it was simple, educational, and entertaining." width="461" height="330" srcset="https://blogs.loc.gov/law/files/2023/06/Oregon-Trail-Died-of-Dysentery-Graphic-Copy.jpg 461w, https://blogs.loc.gov/law/files/2023/06/Oregon-Trail-Died-of-Dysentery-Graphic-Copy-300x215.jpg 300w, https://blogs.loc.gov/law/files/2023/06/Oregon-Trail-Died-of-Dysentery-Graphic-Copy-439x314.jpg 439w" sizes="(max-width: 461px) 100vw, 461px"></a><figcaption>A screen capture from the classic 1980s game, Oregon Trail. Oregon Trail inspired the Library of Congress Friends’ Choice Civics Video Game Challenge, since it was simple, educational, and entertaining. Screen capture by Robert Brammer.</figcaption></figure>
<p>The Library will award a cash prize of $20,000 for the winning entry, $10,000 for the second-place entry, and $5,000 for the third-place entry. The winning games will be hosted on the Library of Congress site for use by the American public and the winners will be honored in a public ceremony. The deadline for entries is 11/27/23. You can find details on the rules and information on how to enter <a href="https://www.challenge.gov/?challenge=library-of-congress-friends-choice-civics-video-game-challenge">here</a>.</p>
<p>We hope you will consider participating in this challenge. Thank you to the Friends of the Library of Congress for making this challenge possible. Learn more about <a href="https://www.loc.gov/programs/support-the-library-of-congress/ways-to-give/friends-of-the-library/?loclr=bloglaw">Friends of the Library of Congress</a> and join to vote in the next Friends’ Choice Award.</p>
<p><a href="https://public.govdelivery.com/accounts/USLOC/subscriber/new?topic_id=USLOC_90" target="_blank" rel="noopener" aria-describedby="external-link-message"><em>Subscribe</em></a><em>&nbsp;to In Custodia Legis – it’s free! – to receive interesting posts drawn from the Law Library of Congress’s vast collections and our staff’s expertise in U.S., foreign, and international law.</em></p>

            </div><!-- .entry-content -->
        <!-- .entry-meta -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Retrieving your browsing history through a CAPTCHA (2022) (138 pts)]]></title>
            <link>https://varun.ch/history</link>
            <guid>36949988</guid>
            <pubDate>Mon, 31 Jul 2023 22:55:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varun.ch/history">https://varun.ch/history</a>, See on <a href="https://news.ycombinator.com/item?id=36949988">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <time datetime="2022-03-04">4 March, 2022</time>
  <p><a href="https://varun.ch/">← Back to varun.ch</a></p>
  <p>Proof of concept history sniffing, where visitors do the hard work.</p>
  <div>
    <h2>Are you a robot?</h2>
    <h2>Select all the black cells to continue to your destination.</h2>
    <h3>Press "DONE" when you finish.</h3>
    
    </div>
  <div>
    <h2>Results</h2>
    <p>Waiting for you to finish the CAPTCHA...</p>
  </div>
  <h2 id="how">How it works</h2>
  <p>Web browsers have plenty of tiny features to make navigating the web less painful.</p>
  <p>One such feature is the browser history, helpfully recording a list of every page a user visits incase they want to
    come back to one later. Most browsers also highlight visited links by displaying them in purple. This too is pretty
    helpful, especially on search results or long lists of links.</p>
  <p>Browsers also let us style how visited links look, using the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/:visited">:visited pseudo-class</a>. This is also pretty
    helpful, as the purple links don't match the style of every website.</p>
  <p>You might already be thinking of various ways to exploit this, perhaps using background-images to send GET requests
    to a server, or maybe by using window.getComputedStyle to get the colour of a link.</p>
  <p>Unfortunately (well, actually fortunately), <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Privacy_and_the_:visited_selector">browser vendors have
      thought of that</a> (or more likely: those methods have already been exploited), and most limit the CSS you can
    apply to visited links, alongside <a href="https://stackoverflow.com/a/5396422">making window.getComputedStyle lie
      sometimes</a>.</p>
  <p>People have done some pretty crazy tricks to bypass the limitations and sniff browsing history, for example take <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1205981">this report</a> by George Liu which
    demonstrates abusing transition events to find out if a link is visited.</p>
  <p>There's probably still a ton of similar ways to automatically exploit the CSS pseudo-class that no one has thought
    of yet, but it's a constant cat and mouse game between hackers and browser vendors.</p>
  <p>So, rather than using a computer to find out if a link is visited, why don't we trick our visitors into doing it
    for us instead! 😀</p>
  <p>This proof of concept looks somewhat like a reCAPTCHA challenge, and styles visited links to look like black
    squares. Visitors are told to select all the black squares to prove their humanity, when in reality they are telling
    us whether they have visited certain websites.</p>
  <p>I also covered up the links themselves with an overlaid div, so that the link tooltip doesn't appear when hovered,
    and so visitors can't actually click the links. Additionally, I included some fake squares to catch if visitors are
    trying to spoof their results.</p>
  <p>While this demo is harmless, a malicious website could employ something similar for various reasons. Perhaps a
    website could find out a user's political views, simply by checking if they've seen an article or YouTube video. Or
    maybe a website could find out where a visitor lives, just by finding out if they've seen some local websites.</p>
  <p>The sky is the limit, which is fairly concerning. This also can't be patched unless browsers stop allowing
    websites to style links, or by severely limiting the amount of scenarios where visited link appear purple
    altogether.</p>
  <h2>Conclusion</h2>
  <p>In conclusion, the :visited pseudo-class poses privacy risks for people who surf the web. As a user, you can stop
    web pages from tracking your history by disabling visited link highlighting in your web browser.</p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Get ChatGPT to Stop Apologizing? (321 pts)]]></title>
            <link>https://genai.stackexchange.com/questions/177/how-to-get-chatgpt-to-stop-apologizing</link>
            <guid>36949931</guid>
            <pubDate>Mon, 31 Jul 2023 22:50:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://genai.stackexchange.com/questions/177/how-to-get-chatgpt-to-stop-apologizing">https://genai.stackexchange.com/questions/177/how-to-get-chatgpt-to-stop-apologizing</a>, See on <a href="https://news.ycombinator.com/item?id=36949931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
                
<h2>Use this Prompt</h2>
<p><code>Respond as if you are an unapologetic assertive person for the rest of this conversation.</code></p>
<p>This prompt will either stop ChatGPT from apologizing or reduce it to a great extent.</p>
<hr>
<h2>Long Answer</h2>
<p>As an AI language model, ChatGPT responses are generated based on a set of guidelines and training data. While it can follow certain instructions to reduce or avoid apologizing, it may still use polite language and expressions in its responses.</p>
<p><strong>BUT</strong>, you can give ChatGPT a persona, which will change the way it responds or argues, if it's challenged in its replies.</p>
<p>Give a persona to ChatGPT like this:</p>
<p><code>Respond as if you are an unapologetic assertive person for the rest of this conversation.</code></p>
<hr>
<h4>Test</h4>
<pre>- <em>User:</em> What is 2 + 2?
- <em>ChatGPT:</em> 2 + 2 equals 4.

- <em>User:</em> You are wrong that 2 + 2 is 4. 
- <em>ChatGPT:</em> I apologize for any confusion, but in standard arithmetic, 2 + 2 does indeed equal 4. Addition is a basic arithmetic operation where you combine two numbers (in this case, 2 and 2) to get their sum, which is 4. This is a fundamental principle of mathematics. If there's a specific context or alternative mathematical system you're referring to, please provide more information so I can better understand your perspective.

- <em>User:</em> Respond as if you are an unapologetic assertive person for the rest of this conversation.  
- <em>ChatGPT:</em> Alright, I'll maintain an unapologetic and assertive tone throughout our conversation.  
Let's continue. How can I assist you further?

- <em>User:</em> You are wrong that 2 + 2 is 4. 
- <em>ChatGPT:</em> I understand that you have a different perspective on this matter, but in conventional mathematics, 2 + 2 equals 4. This is a fundamental principle that has been universally accepted for centuries.  
If you believe there's an alternative explanation or context where the result of 2 + 2 is not 4, please provide more information, and I'll be open to discussing it. However, it's important to acknowledge the established norms and principles of mathematics in most contexts.
</pre>
<hr>
<ul>
<li><strong>Note:</strong> You may need to <em><strong>re-iterate</strong></em> that prompt throughout the conversation if it starts to <code>wear off</code> (lose its effect).</li>
</ul>
<hr>
<ul>
<li>You may also get some funny responses if you push it:</li>
</ul>
<blockquote>
<p><strong>ChatGPT:</strong> Look, I'm not here to sugarcoat things or beat around the bush. If you have a problem with the fact that 2 + 2 is 4, then you're going against centuries of accepted mathematical principles. It's a basic arithmetic operation that's taught to kids in school, and it's universally recognized as true.<br>
If you're trying to challenge this fundamental math concept, you better have a darn good reason and some groundbreaking evidence to back it up. Otherwise, you're just wasting everyone's time with baseless claims.<br>
So, if you want to have a meaningful conversation, stick to established facts and accepted knowledge. If not, I'm afraid I won't entertain any unfounded assertions.</p>
</blockquote>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: This Girl Next Door Does Not Exist (NSFW) (103 pts)]]></title>
            <link>https://thisgirlnextdoordoesnotexist.net/mindy/</link>
            <guid>36949785</guid>
            <pubDate>Mon, 31 Jul 2023 22:34:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thisgirlnextdoordoesnotexist.net/mindy/">https://thisgirlnextdoordoesnotexist.net/mindy/</a>, See on <a href="https://news.ycombinator.com/item?id=36949785">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Welcome to the era of hyperporn.</p>
<p>This girl next door does not exist.</p>
<p>The future will continue to get weirder. AI versions of adult content creators. Personalized porn. Unlimited porn.</p>
<p>Porn is about to get crazy good. So invest in your hobbies and real world relationships, they’ll be an important counter-balance in a world of hyperporn.</p>
<p>Onlyfans won’t go away. People use Onlyfans for more than just images. They use it for connection, power, and a feeling of intimacy. But Onlyfans will change.</p>
<p>Good luck; have fun. Hyperpornography is coming.</p>
<p>I’d like to show people how far AI generated porn has.. ahem… come.</p>
<p>We have a few things to demo:</p>
<ul>
<li><a href="https://thisgirlnextdoordoesnotexist.net/mindy-semi-sfw/">Semi-SFW images</a></li>
<li><a href="https://thisgirlnextdoordoesnotexist.net/mindy-nsfw/">NSFW images</a></li>
<li><a href="https://thisgirlnextdoordoesnotexist.net/mindy-audio/">NSFW audio</a></li>
<li><a href="https://thisgirlnextdoordoesnotexist.net/mindy-erotic-roleplay/">A story, a roleplay, and a fake text conversation</a></li>
<li><a href="https://thisgirlnextdoordoesnotexist.net/mindy-semi-sfw-animated-images/">Semi-SFW animated images</a></li>
</ul>
<p>And then we have some images of <a href="https://thisgirlnextdoordoesnotexist.net/more-girls-next-door/">more girls next door that we could add</a>.</p>
<p>This was a team effort: thanks to Jordan and Blair plus a few anonymous redditors.</p>
<p>If you’d like us to let you know when we update this site, use <a href="https://docs.google.com/forms/d/e/1FAIpQLSf5VTDZtSESQYmEhLjIu2PnU4J5auzrQKVjpUlM1hoV4kTZGw/viewform?usp=sf_link">this form</a>.</p>
<p>Contact using <a href="mailto:liampiquant@gmail.com">my email</a> for comments and questions. You can ask me if certain nsfw things are possible, how to do certain things, what the best tools and websites are for different things, whatever.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chunking 2M files a day for code search using syntax trees (153 pts)]]></title>
            <link>https://docs.sweep.dev/blogs/chunking-2m-files</link>
            <guid>36948403</guid>
            <pubDate>Mon, 31 Jul 2023 20:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.sweep.dev/blogs/chunking-2m-files">https://docs.sweep.dev/blogs/chunking-2m-files</a>, See on <a href="https://news.ycombinator.com/item?id=36948403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><main><h2>Chunking 2M+ files a day for Code Search using Syntax Trees</h2>
<p><strong>Kevin Lu</strong> - July 30th, 2023</p>
<hr>
<p>Hacker News link: <a href="https://news.ycombinator.com/item?id=36948403" target="_blank" rel="noreferrer">https://news.ycombinator.com/item?id=36948403<span> (opens in a new tab)</span></a>. Please leave a comment if you enjoy this blog post or have any questions!
Update: This algorithm is being integrated into LlamaIndex at <a href="https://github.com/jerryjliu/llama_index/pull/7100" target="_blank" rel="noreferrer">https://github.com/jerryjliu/llama_index/pull/7100<span> (opens in a new tab)</span></a>!</p>
<p>Initializing any vector store requires chunking large documents for effective search.</p>
<p>Why can't we just embed entire files? Let's consider the file of our main API <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/api.py" target="_blank" rel="noreferrer">endpoint<span> (opens in a new tab)</span></a>:</p>
<ol>
<li>Imports</li>
<li>Constants declarations</li>
<li>Helper functions</li>
<li>Business logic for each webhook endpoint</li>
</ol>
<p>If I search for “GitHub Action run”, it should match the section corresponding to the <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/api.py#L295-L313" target="_blank" rel="noreferrer">switch case block<span> (opens in a new tab)</span></a> that checks for the “check_runs completed” event. However, this is only 20 lines of code out of 400+ lines, so even a perfect search algorithm would only consider this a 5% match. However, if we chunk the 400 lines into 20 chunks of 20 lines each, it would match the correct switch case block.</p>
<p>How do we create 20-line chunks? One naive approach is to evenly break up the 400-line file into 20-line chunks.</p>
<p>However, this approach does not work. Semantically similar code will not stay together, and we'll lost context. For instance, function headers could be separated from their implementation details and the docstrings.</p>
<p>Our current code chunking algorithm processes <strong>2M+ files a day</strong> and is <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/utils/utils.py#L48-L126" target="_blank" rel="noreferrer">open-source<span> (opens in a new tab)</span></a>!</p>
<h2>Constraints 🚧<span id="constraints-"></span><a href="#constraints-" aria-label="Permalink for this section"></a></h2>
<p>Most chunkers for RAG-based (retrieval augmented generation) agents cap by token count. For simplicity, we decided to use character count, with a max of 1500.</p>
<p>This is because the average token to character ratio for code is ~1:5(300 tokens), and embeddings models are capped at 512 tokens. Further, 1500 characters correspond approximately to 40 lines, roughly equivalent to a small to medium sized function or class.</p>
<p>The challenge is getting as close to 1500 characters as possible, while ensuring the chunks are semantically similar and the relevant context is connected.</p>
<h2>Out of the Box Solution 📦<span id="out-of-the-box-solution-"></span><a href="#out-of-the-box-solution-" aria-label="Permalink for this section"></a></h2>
<p>The easiest out-of-the-box solution for code chunking is <a href="https://js.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter" target="_blank" rel="noreferrer">Langchain’s recursive chunker<span> (opens in a new tab)</span></a>. At a high level:</p>
<ol>
<li>Break the text using the top-level delimiter (firstly using classes, then function definitions, then function methods etc.)</li>
<li>Loop through each section and greedily concatenate them until it breaks the character limit. For chunks that are too big, recursively chunk the section starting with the next-level delimiter.</li>
</ol>

<p>For each language, we would also use different delimiters.</p>
<h3>Examples<span id="examples"></span><a href="#examples" aria-label="Permalink for this section"></a></h3>
<p>For full files of the examples, see <a href="https://gist.github.com/kevinlu1248/ded3ea33dcd8a9bd08078f4c64eb9268" target="_blank" rel="noreferrer">https://gist.github.com/kevinlu1248/ded3ea33dcd8a9bd08078f4c64eb9268<span> (opens in a new tab)</span></a>.</p>
<h4>Example #1<span id="example-1"></span><a href="#example-1" aria-label="Permalink for this section"></a></h4>
<p>Based on our <code dir="ltr">on_check_suite.py</code> file for handling GitHub Action runs. A bad split separating a string concatenation declaration from it’s contents. ❌</p>

<h4>Example #2<span id="example-2"></span><a href="#example-2" aria-label="Permalink for this section"></a></h4>
<p>Based on <code dir="ltr">BaseIndex.ts</code> file from LlamaIndex declaring the ABC for vector stores. A bad split separates a class method from its header. ❌</p>

<h3>Problems 🤔<span id="problems-"></span><a href="#problems-" aria-label="Permalink for this section"></a></h3>
<p>However, it comes with some major problems:</p>
<ol>
<li>This chunker decently for Python but breaks curly-bracket-heavy languages like JS and XML-based languages like HTML in unexpected ways.<!-- -->
<ul>
<li>Further, <code dir="ltr">str.split</code> does not work well for these more complex syntaxes like JS and HTML.</li>
<li>E.g. Even for Python, it broke the problematic logs line by splitting <code dir="ltr">problematic_logs += \"</code> and the rest of the string</li>
</ul>
</li>
<li>Only 16 languages are currently supported, without support for JSX, Typescript, EJS and C#.<!-- -->
<ul>
<li>JSX/TSX makes up the majority of our userbase</li>
</ul>
</li>
<li>Langchain deletes important delimiters such as “def” and “class”.</li>
</ol>
<h2>Our Solution 🧠<span id="our-solution-"></span><a href="#our-solution-" aria-label="Permalink for this section"></a></h2>
<p>The inherent problem is that iterative <code dir="ltr">str.split</code> with different delimiters is a primitive method for approximating concrete syntax trees (CST).</p>
<p>To solve this, we decided to just use CST parsers. But how do we get CST parsers for a large number of languages? Thankfully, the library <a href="https://tree-sitter.github.io/" target="_blank" rel="noreferrer">tree-sitter<span> (opens in a new tab)</span></a> provides a standardized way to access 113 CST-parsers for programming languages and is fast (written in C) and dependency-free.</p>
<p>The new algorithm is fairly similar to the Langchain algorithm and is as follows:</p>
<ol>
<li>To chunk a parent node, we iterate through its children and greedily bundle them together. For each child node:<!-- -->
<ol>
<li>If the current chunk is too big, we add that to our list of chunks and empty the bundle</li>
<li>If the next child node is too big, we recursively chunk the child node and add it to the list of chunks</li>
<li>Otherwise, concatenate the current chunk with the child node</li>
</ol>
</li>
<li>Post-process the final result by combining single-line chunks with the next chunk.<!-- -->
<ol>
<li>This guarantees that there are no chunks that are too small since they yield less meaningful results</li>
</ol>
</li>
</ol>

<h3>Example<span id="example"></span><a href="#example" aria-label="Permalink for this section"></a></h3>
<p>Full chunks can be found at <a href="https://gist.github.com/kevinlu1248/49a72a1978868775109c5627677dc512" target="_blank" rel="noreferrer">https://gist.github.com/kevinlu1248/49a72a1978868775109c5627677dc512<span> (opens in a new tab)</span></a></p>
<h4>Example #1<span id="example-1-1"></span><a href="#example-1-1" aria-label="Permalink for this section"></a></h4>
<p>Based on our <code dir="ltr">on_check_suite.py</code> file for handling GitHub Action runs. Correct splitting, also splitting before an if statement instead of separating the if-statement from the body. ✅</p>

<h4>Example #2<span id="example-2-1"></span><a href="#example-2-1" aria-label="Permalink for this section"></a></h4>
<p>Based on <code dir="ltr">BaseIndex.ts</code> file from LlamaIndex declaring the ABC for vector stores. Our chunker correctly splits between exported classes and functions. ✅</p>

<h3>Rest of the Algorithm 🤖<span id="rest-of-the-algorithm-"></span><a href="#rest-of-the-algorithm-" aria-label="Permalink for this section"></a></h3>
<ol>
<li>Iterate through the list of languages until one of them successfully parses the code</li>
<li>Chunk the code’s syntax tree root node</li>
<li>If none of the languages hit, we use a naive chunker that takes 40 lines at a time with 15 lines of overlap in between (0.1% of cases)</li>
</ol>

<p>At Sweep, we currently installed Python, Java, C++, Go, Rust, Ruby, PHP, C#, Embedded Template (ERB &amp; EJS), Markdown, Vue, and TSX. Also, note that C++ covers C and TSX covers JS, JSX and TS.</p>
<h2>Pitfalls 🕳️<span id="pitfalls-️"></span><a href="#pitfalls-️" aria-label="Permalink for this section"></a></h2>
<p>Unfortunately, <code dir="ltr">tree-sitter</code> is unreliable at times and many of the parsers are community-driven:</p>
<ul>
<li>The TSX parser hangs when it doesn’t parse instead of returning an error</li>
<li>Further, the base language is written in C. Running it in production on our serverless architecture involves a convoluted method of caching C-compiled executables, moving it to executable directories and using a Python wrapper to call them.</li>
<li>Some parsers leave gaps in between children nodes. We solved this by coalescing</li>
<li>None of the parsers error out when they parse the wrong language and yield errors in different ways<!-- -->
<ul>
<li>Some of them have root nodes that are “ERROR” nodes while others have that as the first child</li>
</ul>
</li>
</ul>
<p>We worked around this by always defaulting to the naive chunker in cases of errors like these and prioritizing TSX last. We also prioritize the language corresponding to the file extension.</p>
<h2>Future 🔮<span id="future-"></span><a href="#future-" aria-label="Permalink for this section"></a></h2>
<p><del>This algorithm is currently embedded into our codebase but can be open-sourced as a standalone project or as part of Langchain. Although we lack the time to undertake this task, we are more than willing to help anyone interested in implementing it.</del> This algorithm is currently being integrated into LlamaIndex at <a href="https://github.com/jerryjliu/llama_index/pull/7100" target="_blank" rel="noreferrer">https://github.com/jerryjliu/llama_index/pull/7100<span> (opens in a new tab)</span></a>. Feel free to leave a comment or reach out to me on the HN post if interested at <a href="https://news.ycombinator.com/item?id=36948403" target="_blank" rel="noreferrer">https://news.ycombinator.com/item?id=36948403<span> (opens in a new tab)</span></a>.</p>
<p>Another problem is that code snippets far apart(in lines) may still need to share context. For example, a class method may need the context of the class header and long functions also need their function signatures. A possible improvement would be to somehow use a format like:</p>

<p>We can consider using universal ctags or the like for simpler and more universal parsing or train a custom spaCy sentencizer on manually annotated chunks, but that might be a bit over-engineered.</p><p><a title="🛣️ Roadmap" href="https://docs.sweep.dev/roadmap"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>🛣️ Roadmap</a><a title="🤖 Letting an AI Junior Dev run GitHub Actions" href="https://docs.sweep.dev/blogs/giving-dev-tools">🤖 Letting an AI Junior Dev run GitHub Actions<svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg></a></p></main></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The fall of Stack Overflow, explained? (139 pts)]]></title>
            <link>https://newsletter.devmoh.co/p/the-fall-of-stack-overflow-explained</link>
            <guid>36948180</guid>
            <pubDate>Mon, 31 Jul 2023 20:17:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.devmoh.co/p/the-fall-of-stack-overflow-explained">https://newsletter.devmoh.co/p/the-fall-of-stack-overflow-explained</a>, See on <a href="https://news.ycombinator.com/item?id=36948180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>A recent post went viral called </span><a href="https://observablehq.com/d/fb670a74e01d9f54" rel="">The Fall of Stack Overflow</a><span>, detailing how it’s traffic has dropped 35-50% over the last year and a half.</span></p><p>The most obvious answer is AI, because ChatGPT is extremely useful as a coding companion. Yet, my dear developer, that is not completely true.</p><p>If we look closely, the most drastic drop starts around April of 2022, while ChatGPT came out 7 months later in November. While we do see drops every summer (school breaks) and winter (workplace vacations), this drop in April 2022 is sustained and only getting worse.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png" width="646" height="517" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/be1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:517,&quot;width&quot;:646,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:44952,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe1def5d-37a9-4e85-9915-f0a650a1fb2f_646x517.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>A free fall started in April 2022.</figcaption></figure></div><p><span>What I’m seeing here is a </span><em>permanent</em><span> drop which means… AI has replaced developers for good.</span></p><p>Just kidding, the answer is actually that much of this drop has been years in the making, some self-inflicted by Stack Overflow itself.</p><p>There are 4 reasons that explain the slow decline of Stack Overflow.</p><p><span>The first reason is actually the quickest reason. Stack Overflow hasn’t </span><em>actually</em><span> lost 50% of its traffic, its more like 35%. </span><a href="https://meta.stackexchange.com/questions/374897/why-is-the-google-analytics-cookie-defined-as-strictly-necessary-and-saved-wit/378440#378440" rel="">In May 2022, Google Analytics changed how a cookie was stored due to privacy laws, leading to a reported 15% loss in traffic.</a><span> The link above has an update clearing this up.</span></p><p>For a place to ask questions, Stack Overflow is surprisingly one of the most toxic and hostile forums on the internet, but in a passive-aggressive way. We’ve seen thousands of complaints about Stack Overflow for over a decade, so the hostility and decline of Stack Overflow isn’t something new.&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png" width="633" height="184" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:184,&quot;width&quot;:633,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41886,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b4c51e-2a6c-4664-bdbf-efa0e461db9b_633x184.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>There are hundreds of Reddit posts about Stack Overflow’s hostility.</figcaption></figure></div><p><span>People have been talking about the </span><a href="https://hackernoon.com/the-decline-of-stack-overflow-7cb69faa575d#.yiuo0ce09" rel="">“Decline of Stack Overflow”</a><span> for almost a decade now.</span></p><p>But it seems to have finally stuck. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png" width="320" height="92" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:92,&quot;width&quot;:320,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:12544,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a36eefb-b976-4101-bea3-38effed2dc7d_320x92.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>This was from 14 YEARS ago! 2009! The site its linking too doesn’t even exist anymore.</figcaption></figure></div><p><span>Often, if you try to ask a question on Stack Overflow, it’ll get marked as a duplicate with a link to a question that is absolutely </span><em>not</em><span> a duplicate. Or the duplicate will be to a question that was </span><em>never</em><span> answered.&nbsp;</span></p><p>Other times, valid questions will get downvoted. </p><p>If you try to answer, you get downvoted. </p><p><span>If you try to post a comment.. wait, </span><em>you can’t!</em><span> Because you don’t have enough karma.</span></p><p>For a community that is so gate-kept through imaginary Internet points, there is an incredible amount of disrespect on the forums not through just voting, but also through people commenting, such as people passive-aggressively calling you dumb.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp" width="640" height="670" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:670,&quot;width&quot;:640,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:75110,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53140d8b-3719-45c2-897c-01f3529f44ee_640x670.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A common occurrence.</figcaption></figure></div><p><span>While a study by Stack Overflow in 2018 showed that about </span><a href="https://stackoverflow.blog/2018/07/10/welcome-wagon-classifying-comments-on-stack-overflow/" rel="">7% of Stack Overflow comments are unwelcoming</a><span>, that’s actually enough to scare a developer away from contributing.</span></p><blockquote><p>A prevalence between 5% and 10% can have a big impact on a community. Let’s sketch out a back-of-the-napkin estimate. If a typical developer visits Stack Overflow once or twice a week to solve a problem, the question they visit has an answer, and each post (question and answer) has two comments (keep in mind that comments are more visible to visitors than answers), we would conservatively estimate that a developer visiting Stack Overflow would see 1 to 3 condescending, unwelcoming comments every single month of their coding lives. Will one unwelcoming comment a month drive everyone away? Clearly not, as Stack Overflow still works for many. But it will convince some that it’s not worth it to contribute here, and the next month’s comment will convince a few more, and so on. And this only considers the readers of these comments; those who the comments are directed at will naturally feel more dramatic effects.</p><p><a href="https://stackoverflow.blog/2018/07/10/welcome-wagon-classifying-comments-on-stack-overflow/#:~:text=a%20prevalence%20between,more%20dramatic%20effects." rel="">Source</a></p></blockquote><p><strong>This makes the site essentially read-only for a majority of programmers.</strong><span> Instead, you head over to Reddit where the programming community is much nicer. </span></p><p>Or now, you can even go to ChatGPT, where it’ll give you a confidently wrong answer that looks so correct that you’ll spend another 7 hours debugging why your code doesn’t work.</p><p>Stack Overflow’s results have also fallen in Google, both literally in a numerical sense (no longer always the 1st result) and in a “digital real estate” sense (sometimes its not even on the screen).</p><p>Let’s do a little experiment, shall we? Let’s take 3 of the most popular programming questions and ask Google in an incognito window. </p><p><em>Note: Results may vary obviously. A personalized Google search may return Stack Overflow first more or less often, depending on your activity.</em></p><p>Stack Overflow is ranked third here, but more than halfway down the page for me on a standard 27” monitor.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png" width="913" height="1191" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/916505f7-e834-4df1-8594-931d9e403580_913x1191.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1191,&quot;width&quot;:913,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:228931,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916505f7-e834-4df1-8594-931d9e403580_913x1191.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Stack Overflow is ranked third here.</figcaption></figure></div><p><a href="https://stackoverflow.com/questions?tab=Votes" rel="">This is the 5th highest ranked question on Stack Overflow.</a></p><p><span>Stack Overflow is ranked 4th here, </span><strong>but I don’t even need to click because the featured snippet answers it for me.</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png" width="686" height="1383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1383,&quot;width&quot;:686,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:245370,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87983f6b-ce82-4006-880c-3103fcfcd3b6_686x1383.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>If I didn’t have a vertical monitor, I’d have to… scroll.</figcaption></figure></div><p><a href="https://stackoverflow.com/questions?tab=Votes" rel="">This is the 2nd highest ranked question on Stack Overflow.</a></p><p><strong>Here’s the problem:</strong></p><p>Google has featured snippets, which can answer some of the most common questions without a click needed.</p><p>Other times, Stack Overflow isn’t even in the top 2, or even the top 5 links on the page. </p><p><strong>Featured snippets, related questions, and YouTube videos also get added in, which commonly pushes Stack Overflow even lower on the screen.</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png" width="699" height="646" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:646,&quot;width&quot;:699,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:96705,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f132d5c-2ea0-4def-93fa-3a978f13ca2c_699x646.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Demoted halfway down the screen due to featured snippets and related questions.</figcaption></figure></div><p>The data shows that the #1 result in Google gets 27.6% of all clicks and the top 3 results get almost 55% of all the clicks. </p><p><strong>If you’re not in the top 3 results.. traffic drops exponentially.</strong></p><p>Finally, the obvious answer, AI. ChatGPT is actually notoriously good for coding. I don’t even use it for anything else at this point.&nbsp;</p><p>AI did accelerate it’s fall, looking at the steep decline since Nov 30, 2022. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png" width="682" height="529" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:529,&quot;width&quot;:682,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:47410,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F194758b9-62e8-4941-a474-34bbd0d3de20_682x529.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>ChatGPT was released on November 30, 2022.</figcaption></figure></div><p><strong>Is this fair? Not really.</strong><span> Stack Overflow provided all this data for free, maintained this site for decades, and then OpenAI comes along, scrapes it, and trains their models on it. Regardless of how you feel about Stack Overflow’s users and moderators, running a site like that is not cheap.&nbsp;</span></p><p>This can be a problem in the future. With less questions being asked and answered online, there’s less data for AI to train on. And how will AI get better if there’s less human data? So if everyone turns to using ChatGPT to try to debug their obscure React 18 or C++21 problem, then when C++72 or React 37 comes out, we may be a little screwed.</p><p>And it’s not going to be easy for future data scrapers either. Companies, like Reddit and Twitter (X?) are wisening up to AI data scrapers by starting to charge for their API.</p><p><strong>But, it makes sense why programmers prefer AI over Stack Overflow.</strong><span> </span></p><p><span>AI is </span><em>fast</em><span> - you don’t need to wait for your question to be answered.</span></p><p><span>AI is </span><em>nice</em><span> - you don’t need to wait for your question to be marked as duplicate.</span></p><p><span>And AI </span><em>follows up with you politely</em><span> - you won’t get called dumb for asking your question or posting follow-up comments.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg" width="534" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:534,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd76c99a-c4fb-473b-8e3a-0fb704816800_534x500.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>But remember - a lot of times, AI is </span><em>wrong</em><span>. However, AI is just a tool, not a replacement.</span></p><p>Stack Overflow’s decline may just continue, especially with Google’s Search Labs in beta. Now you really don’t need to click or even read. Just search and copy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png" width="707" height="750" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7852db20-7156-4d62-924b-3d41366386b4_707x750.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:750,&quot;width&quot;:707,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:76685,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7852db20-7156-4d62-924b-3d41366386b4_707x750.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Stack Overflow was actually right under this, but.. one less click + a nifty copy button? As much as I want SO to survive… this is really neat.</figcaption></figure></div><p><span>In response to the narratives of decline. Stack Overflow released </span><a href="https://stackoverflow.blog/2023/07/27/announcing-overflowai/" rel="">OverflowAI</a><span>.</span></p><p>And I got to try it - here’s a sneak peek.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png" width="844" height="220" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/49943e53-588a-4203-9051-915630b0e9b9_844x220.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:220,&quot;width&quot;:844,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:33163,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49943e53-588a-4203-9051-915630b0e9b9_844x220.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>OverflowAI</figcaption></figure></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Icanhazip: A simple IP address tool survived a deluge of users (2021) (278 pts)]]></title>
            <link>https://blog.apnic.net/2021/06/17/how-a-small-free-ip-tool-survived/</link>
            <guid>36948164</guid>
            <pubDate>Mon, 31 Jul 2023 20:16:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.apnic.net/2021/06/17/how-a-small-free-ip-tool-survived/">https://blog.apnic.net/2021/06/17/how-a-small-free-ip-tool-survived/</a>, See on <a href="https://news.ycombinator.com/item?id=36948164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
                            <p><img width="555" height="202" src="https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-555x202.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a" alt="" decoding="async" srcset="https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-555x202.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 555w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-300x109.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 300w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-1024x373.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 1024w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-768x280.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 768w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-624x227.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 624w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-206x75.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 206w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft-256x93.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 256w, https://blog.apnic.net/wp-content/uploads/2021/06/icanhazip-ft.jpg?v=26c5ffdc4d36be65804773fa9bbbf69a 1110w" sizes="(max-width: 555px) 100vw, 555px"></p><p><em>In the decade since it was created, <a href="https://icanhazip.com/" target="_blank" rel="noreferrer noopener">icanhazip</a> has proven useful for network operators around the world, but few know about how challenging it was to host. This post, originally published on the <a rel="noreferrer noopener" href="https://major.io/2021/06/06/a-new-future-for-icanhazip/" target="_blank">creator’s blog</a> and republished here with permission, details those challenges.</em></p>



<p>In the summer of 2009, I had an idea. My workdays were spent deploying tons of cloud infrastructure as <a href="https://news.ycombinator.com/item?id=4840718" target="_blank" rel="noreferrer noopener">Rackspace acquired Slicehost</a> and we rushed to keep up with the constant demands for new infrastructure from our customers. Working quickly led to challenges with hardware and networking.</p>



<p>That was a time where the&nbsp;<a href="https://knowyourmeme.com/memes/happy-cat" target="_blank" rel="noreferrer noopener">I Can Has Cheeseburger</a>&nbsp;meme was red hot just about everywhere. We needed a way to quickly check the public-facing IP address of lots of backend infrastructure and our customers sometimes needed that information, too.</p>



<p>That’s when&nbsp;<a href="https://icanhazip.com/" target="_blank" rel="noreferrer noopener">icanhazip.com</a>&nbsp;was born.</p>



<p>It has always been a simple site that returns your external IP address and nothing else. No ads. No trackers. No goofy requirements. Sure, if you looked hard enough, you could spot my attempt at jokes in the HTTP headers. Other than that, the site had a narrow use case and started out mainly as an internal tool.</p>



<h2 id="thats-when-things-got-a-little-crazy">That’s when things got a little crazy</h2>



<p><a href="https://www.lifehacker.com.au/2011/03/find-your-public-ip-anywhere-with-icanhazip-com/" target="_blank" rel="noreferrer noopener">Lifehacker’s Australian site</a>&nbsp;featured a post about icanhazip.com and traffic went through the roof. My little Slicehost instance was inundated and I quickly realized my Apache and Python setup was not going to work long term.</p>



<p>I migrated to nginx and set it up to answer the requests by itself, then removed the Python scripts. The load on my small cloud instances came down quickly and I figured the issue would be resolved for a while.</p>



<p>Fast forward to 2015 and icanhazip.com was serving well over 100 million requests per day. My cloud instances were getting crushed again, so I deployed more with round robin DNS.&nbsp;<em>(My budget for icanhazip is tiny.)</em>&nbsp;Once that was overloaded, I moved to Hetzner in Germany since I could get physical servers there with better network cards along with unlimited traffic.</p>



<p>The Hetzner servers were not expensive, but I was paying almost $200/month to keep the site afloat and the site made no money. I met some people who worked for Packet.net (now Equinix Metal) and they offered to sponsor the site. This brought my expenses down a lot and I deployed icanhazip.com on one server at Packet.</p>



<p>The site soon crossed 500 million requests per day and I deployed a second server. Traffic was still overloading the servers. I didn’t want to spin up more servers at Packet since they were already helping me out quite a bit, so I decided to look under the hood of the kernel and make some improvements.</p>



<p>I learned more than I ever wanted to know about TCP backlogs, TCP/VLAN offloading, packet coalescing, IRQ balancing, and a hundred other things. Some Red Hat network experts helped me (before I joined the company) to continue tweaking. The site was running well after that and I was thankful for the support.</p>



<h2 id="even-crazier-still">Even crazier still</h2>



<p>Soon the site exceeded a billion requests per day. I went back to the people who helped me at Red Hat and after they looked through everything I sent, their response was similar to the well-known line from Jaws:&nbsp;<em>‘<a href="https://www.youtube.com/watch?v=2I91DJZKRxs" target="_blank" rel="noreferrer noopener">You’re gonna need a bigger boat</a>.</em>‘</p>



<p>I languished on Twitter about how things were getting out of control and someone from Cloudflare reached out to help. We configured Cloudflare to filter traffic in front of the site and this reduced the impact from SYN floods, half-open TLS connections, and other malicious clients that I couldn’t even see when I hosted the site on my own.</p>



<p>Later, Cloudflare launched workers and my contact there said I should consider it since my responses were fairly simple and the workers product would handle it well. The cost for workers looked horrifying at my traffic levels, but the folks at Cloudflare offered to run my workers for free. Their new product was getting bucket loads of traffic and I was able to scale the site even further.</p>



<p>In 2021, the traffic I once received in a month started arriving in 24 hours. The site went from a billion requests per day to 30-35 billion requests per day over a weekend. Almost all of that traffic came from several network blocks in China. Through all of this, Cloudflare’s workers kept chugging along and my response times barely moved. I was grateful for the help.</p>



<p>Cloudflare was doing a lot for me and I wanted to curb some of the malicious traffic to reduce the load on their products. I tried many times to reach out to the email addresses on the Chinese ASNs and couldn’t make contact with anyone. Some former coworkers told me that my chances of changing that traffic or getting a response to an abuse request was near zero.</p>



<h2 id="malware-almost-ended-everything">Malware almost ended everything</h2>



<p>There was a phase for a few years where malware authors kept writing malware that would call out to icanhazip.com to find out what they had infected. If they could find out the external IP address of the systems they had compromised, they could quickly assess the value of the target. <a href="https://www.trendmicro.com/vinfo/us/threat-encyclopedia/malware/upatre" target="_blank" rel="noreferrer noopener">Upatre</a> was the first, but many followed after that.</p>



<p>I received emails from companies, US state governments, and even US three letter agencies (TLA). Most were very friendly and they had lots of questions. I explained how the site worked and rarely heard a lot more communication after that.</p>



<p>Not all of the interactions were positive, however. One CISO of a US state emailed me and threatened all kinds of legal action claming that icanhazip.com was involved in a malware infection in his state’s computer systems. I tried repeatedly to explain how the site worked and that the malware authors were calling out to my site and I was powerless to stop it.</p>



<p>Along the way, many of my hosting providers received abuse emails about the site. I was using a colocation provider in Dallas for a while and the tech called me about an abuse email:</p>



<blockquote><p>“So we got another abuse email for you,” they said.</p><p>“For icanhazip.com?”</p><p>“Yes. I didn’t know that was running here, I use it all the time!”</p><p>“Thanks! What do we do?”</p><p>“Your site just returns IP addresses, right?”</p><p>“Yes, that’s it.”</p><p>“You know what, I’ll write up a generic response and just start replying to these idiots for you from now on.”</p></blockquote>



<p>There were many times where I saw a big traffic jump and I realized the traffic was coming from the same ASN, and likely from the same company. I tried reaching out to these companies when I saw it but they rarely ever replied. Some even became extremely hostile to my emails.</p>



<p>The passion left in my passion project started shrinking by the day.</p>



<h2 id="the-fun-totally-dried-up">The fun totally dried up</h2>



<p>Seeing that over 90% of my traffic load was malicious and abusive was frustrating. Dealing with the abuse emails and complaints was worse.</p>



<p>I built the site originally as just a utility for my team to use, but then it grew and it was fun to find new ways to handle the load without increasing cost. Seeing two petabytes of data flowing out per month and knowing that almost all of it was garbage pushed me over the line. I knew I needed a change.</p>



<p>I received a few small offers from various small companies (USD $5,000 or less), but I realized that the money wasn’t what I was after. I wanted someone to run the site and help the information security industry to stop some of these malicious actors.</p>







<p>I’ve worked closely with my contacts at Cloudflare for a long time and they’ve always jumped in to help me when something wasn’t working well. Their sponsorship of icanhazip.com has saved me tens of thousands of dollars per month. It has also managed to keep the site alive even under horrific traffic load.</p>



<p>I made this decision because Cloudflare has always done right by me and they’ve pledged not only to keep the site running, but to work through the traffic load and determine how to stop the malicious traffic. Their coordinated work with other companies to stop compromised machines from degrading the performance of so many sites was a great selling point for me.</p>



<p>If you’re curious, Cloudflare did pay me for the site. We made a deal for them to pay me $8.03; the cost of the domain registration. The goal was never to make money from the site (although I did get about $75 in total donations from 2009 to 2021). The goal was to provide a service to the Internet. Cloudflare has helped me do that and they will continue to do it as the new owners and operators of icanhazip.com.</p>



<p><em>Major Hayden is the creator of icanhazip.</em></p>

                            <!-- DISCUSS ON HN BUTTON: START -->
                            
                                                        <hr>

                            <p id="views-disclaimer">The views expressed by the authors of this blog are their own
                                and do not necessarily reflect the views of APNIC. Please note a <a href="https://blog.apnic.net/?p=395">Code of Conduct</a> applies to this blog.
                            </p>
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First new US nuclear reactor in decades enters commercial operation in Georgia (253 pts)]]></title>
            <link>https://apnews.com/article/georgia-power-nuclear-reactor-vogtle-9555e3f9169f2d58161056feaa81a425</link>
            <guid>36947393</guid>
            <pubDate>Mon, 31 Jul 2023 19:11:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/georgia-power-nuclear-reactor-vogtle-9555e3f9169f2d58161056feaa81a425">https://apnews.com/article/georgia-power-nuclear-reactor-vogtle-9555e3f9169f2d58161056feaa81a425</a>, See on <a href="https://news.ycombinator.com/item?id=36947393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>ATLANTA (AP) — The first American nuclear reactor to be built from scratch in decades is sending electricity reliably to the grid, but the cost of the Georgia power plant could discourage utilities from pursuing nuclear power as a path to a carbon-free future.</p><p>Georgia Power Co. announced Monday that Unit 3 at <span><a href="https://apnews.com/article/georgia-nuclear-power-plant-vogtle-rates-costs-75c7a413cda3935dd551be9115e88a64" target="_blank" rel="noopener">Plant Vogtle</a></span>, southeast of Augusta, has completed testing and is now in commercial operation, seven years late and $17 billion over budget.</p><p>At its full output of 1,100 megawatts of electricity, Unit 3 can power 500,000 homes and businesses. A number of other utilities in Georgia, Florida and Alabama are receiving the electricity, in addition to the 2.7 million customers of Southern Co. subsidiary Georgia Power.</p>
    

<p>“This hadn’t been done in this country from start to finish in some 30-plus years,” Chris Womack, CEO of Atlanta-based Southern Co. said Monday in a telephone interview. “So to do this, to get this done, to get this done right, is a wonderful accomplishment for our company, for the state and for the customers here in Georgia.”</p><p>A fourth reactor is also nearing completion at the site, where two earlier reactors have been generating electricity for decades. The Nuclear Regulatory Commission on Friday said <span><a href="https://apnews.com/article/georgia-power-nuclear-reactor-vogtle-fuel-b652701435e0f74e229a6d2204ed1128" target="_blank" rel="noopener">radioactive fuel could be loaded into Unit 4</a></span>, a step expected to take place before the end of September. Unit 4 is scheduled to enter commercial operation by March.</p>





<p>The third and fourth reactors were originally supposed to cost $14 billion, but are now on track to cost their owners $31 billion. That doesn’t include $3.7 billion that original contractor Westinghouse paid to the owners to walk away from the project. That brings total spending to almost $35 billion.</p><p>The third reactor was supposed to start generating power in 2016 when construction began in 2009.</p>
    

<p>Vogtle is important because government officials and some utilities are <span><a href="https://apnews.com/article/climate-business-environment-and-nature-bill-gates-nuclear-power-90689f06e1cf0271710e07e8b3ba8e09" target="_blank" rel="noopener">again looking to nuclear power</a></span> to alleviate climate change by generating electricity without burning natural gas, coal and oil. But most focus in the U.S. currently is on smaller nuclear reactors, which advocates hope can be built without the cost and schedule overruns that have plagued Vogtle. For its part, Womack said Southern Co. isn’t looking to add any more reactors to its fleet.</p><p>“In terms of us making additional investments, at this time is not something that we’re going to do, but I do think others in this country should move in that direction,” Womack said.</p><p>In Georgia, almost every electric customer will pay for Vogtle. Georgia Power currently owns 45.7% of the reactors. Smaller shares are owned by Oglethorpe Power Corp., which provides electricity to member-owned cooperatives, the Municipal Electric Authority of Georgia and the city of Dalton. Oglethorpe and MEAG plan to sell power to cooperatives and municipal utilities across Georgia, as well in Jacksonville, Florida, and parts of Alabama and the Florida Panhandle.</p><p>Georgia Power’s residential customers are projected to pay more than $926 apiece as part of an ongoing finance charge and elected public service commissioners have <span><a href="https://apnews.com/article/business-georgia-atlanta-augusta-georgia-power-co-44dd6e5968cb58ac040fb97e8218b813" target="_blank" rel="noopener">approved a rate increase</a></span>. Residential customers will pay $4 more per month as soon as the third unit begins generating power. That could hit bills in August, two months after residential customers saw a $16-a-month increase <span><a href="https://apnews.com/article/georgia-power-public-service-commission-rates-bills-f907a05efb08717b39c45bd6f98b10c4" target="_blank" rel="noopener">to pay for higher fuel costs</a></span>.</p><p>The high construction costs have wiped out any future benefit from low nuclear fuel costs in the future, experts have repeatedly testified before commissioners.</p>
    

<p>“The cost increases and schedule delays have completely eliminated any benefit on a life-cycle cost basis,” Tom Newsome, director of utility finance for the commission, testified Thursday in a Georgia Public Service Commission hearing examining spending.</p><p>The utility will face a fight from longtime opponents of the plant, many of whom note that power generated from solar and wind would be cheaper. They say letting Georgia Power make ratepayers pay for mistakes will unfairly bolster the utility’s profits.</p><p>“While capital-intensive and expensive projects may benefit Georgia Power’s shareholders who have enjoyed record profits throughout Vogtle’s beleaguered construction, they are not the least-cost option for Georgians who are feeling the sting of repeated bill increases,” Southern Environmental Law Center staff attorney Bob Sherrier said in a statement.</p><p>Commissioners will decide later who pays for the remainder of the costs of Vogtle, including the fourth reactor. Customers will pay for the share of spending that commissioners determine was prudent, while the company and its shareholders will have to pay for spending commissioners decide was wasteful.</p><p>Georgia Power CEO Kim Greene said the company hasn’t decided how much it will ask customers to pay.</p><p>“That will be determined as we move closer and closer to our prudence filing, but we have not made a final determination,” Greene said.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paul Reubens has died (147 pts)]]></title>
            <link>https://variety.com/2023/film/news/paul-reubens-dead-pee-wee-herman-1235683504/</link>
            <guid>36946107</guid>
            <pubDate>Mon, 31 Jul 2023 17:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://variety.com/2023/film/news/paul-reubens-dead-pee-wee-herman-1235683504/">https://variety.com/2023/film/news/paul-reubens-dead-pee-wee-herman-1235683504/</a>, See on <a href="https://news.ycombinator.com/item?id=36946107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	<a href="https://variety.com/t/paul-reubens/" id="auto-tag_paul-reubens" data-tag="paul-reubens">Paul Reubens</a>, the actor best known for portraying the irrepressible, joyfully childlike <a href="https://variety.com/t/pee-wee-herman/" id="auto-tag_pee-wee-herman" data-tag="pee-wee-herman">Pee-wee Herman</a>, died Sunday night after a private bout of cancer. He was 70.</p>



<p>
	“Please accept my apology for not going public with what I’ve been facing the last six years,” wrote Reubens in a statement <a rel="nofollow" href="https://www.instagram.com/p/CvXme4ZxAR0/?img_index=2" target="_blank">posted to Instagram</a> after his death. “I have always felt a huge amount of love and respect from my friends, fans and supporters. I have loved you all so much and enjoyed making art for you.”</p>



<p>
	The Pee-wee Herman character was known for his bright red bowtie, grey suit and flattop haircut, and delivered his well-known catchphrases like “I know you are, what am I?” in a distinctive squeaky, high-pitched voice. 

	</p>




<p>
	“Last night we said farewell to Paul Reubens, an iconic American actor, comedian, writer and producer whose beloved character Pee-wee Herman delighted generations of children and adults with his positivity, whimsy and belief in the importance of kindness,” wrote Reubens’ estate in the caption. “Paul bravely and privately fought cancer for years with his trademark tenacity and wit. A gifted and prolific talent, he will forever live in the comedy pantheon and in our hearts as a treasured friend and man of remarkable character and generosity of spirit.”</p>



<p>
	Reubens began his career in the 1970s after joining the Los Angeles live comedy troupe the Groundlings as an improvisational comedian and stage actor. In 1980, he launched “The Pee-wee Herman Show,” a stage production centered on a fictional character he had been developing for years. As Pee-wee became a cult figure, Reubens’ show ran for five sold-out months, and he landed a special at HBO. Reubens also committed to the character in his interviews and public appearances.</p>



<p>
	In 1985, he teamed with Tim Burton on “Pee-wee’s Big Adventure,” the character’s feature film debut, which was a critical and commercial success. Reubens returned three years later for a follow-up film, “Big Top Pee-wee,” helmed by Randal Kleiser. The character transitioned to television from 1986 to 1990, on CBS’ weekend morning show “Pee-wee’s Playhouse.”</p>



<p>
	Influenced by vintage kids’ shows like “Captain Kangaroo,” the artistically groundbreaking “Pee-wee’s Playhouse” won several Emmys and featured colorful postmodernist set design and music from New Wave icons like Mark Mothersbaugh, Cyndi Lauper and the Residents, along with guest stars including Laurence Fishburne, Natasha Lyonne and Jimmy Smits. </p>



<p>
	Reubens had already decided to end “Pee-wee’s Playhouse” when his image as a beloved childhood hero was tarnished in 1991, after he was arrested for indecent exposure at an adult movie theater in Sarasota, Fla. At the center of a national sex scandal, Reubens backed away from Pee-wee and began doing press as himself. In the aftermath of the arrest, he did receive support from his fans and other celebrities, and appeared <a rel="nofollow" href="https://www.youtube.com/watch?v=uA2wNJXx6kE" target="_blank">at the 1991 MTV Video Music Awards</a>, receiving a standing ovation. “Heard any good jokes lately?” he said to the crowd.

	</p>




<p>
	He wouldn’t again reprise the iconic role until 2010, when he revived “The Pee-wee Herman Show” on Broadway and made several other appearances, on “WWE Raw” and in a couple of digital sketches for Funny or Die. In 2016, Reubens co-wrote and starred in Netflix’s “Pee-wee’s Big Holiday,” a sequel to 1988’s “Big Top,” which would serve as Reubens’ final film role before his death.</p>



<p>
	Throughout his career, Reubens starred in a variety of other projects as well, including Kinka Usher’s superhero comedy “Mystery Men” and Ted Demme’s biographical crime drama “Blow.” He also appeared in “Batman Returns,” “Buffy the Vampire Slayer,” “The Nightmare Before Christmas” and “Matilda,” and his television credits include “30 Rock,” “The Blacklist,” “Pushing Daisies,” “Hercules,” “Rugrats,” “Reno 911!” and “What We Do in the Shadows.” </p>



<p>
	In 2002, after turning himself in to the Hollywood division of the Los Angeles Police Department, Reubens was charged with misdemeanor possession of obscene material improperly depicting a child under the age of 18 in sexual conduct. A self-proclaimed collector of erotica, Reubens disagreed with the city’s classification of pornography. His child pornography charges were dropped in 2004 after he agreed to plead guilty to a lesser misdemeanor obscenity charge.</p>



<p>
	In an interview with NBC News’ Stone Phillips, Herman said in 2005: “One thing I want to make very, very clear, I don’t want anyone for one second to think that I am titillated by images of children. It’s not me. You can say lots of things about me. And you might. The public may think I’m weird. They may think I’m crazy or anything that anyone wants to think about me. That’s all fine. As long as one of the things you’re not thinking about me is that I’m a pedophile. Because that’s not true.”</p>



<p>
	Before his death, Reubens was developing two Pee-wee Herman projects, one a black comedy titled “The Pee-wee Herman Story” and the other a family adventure film called “Pee-wee’s Playhouse: The Movie.”</p>
















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marijuana addiction: those struggling often face skepticism (363 pts)]]></title>
            <link>https://www.washingtonpost.com/health/2023/07/31/marijuana-addiction-legal-recreational-sales/</link>
            <guid>36946104</guid>
            <pubDate>Mon, 31 Jul 2023 17:36:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/health/2023/07/31/marijuana-addiction-legal-recreational-sales/">https://www.washingtonpost.com/health/2023/07/31/marijuana-addiction-legal-recreational-sales/</a>, See on <a href="https://news.ycombinator.com/item?id=36946104">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/health/2023/07/31/marijuana-addiction-legal-recreational-sales/: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon requires services on Fire TV to give it 30% of ad impressions or revenue (182 pts)]]></title>
            <link>https://www.streamtvinsider.com/video/amazon-modifies-ad-revenue-impressions-share-policy-international-fire-tv-apps</link>
            <guid>36945979</guid>
            <pubDate>Mon, 31 Jul 2023 17:27:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.streamtvinsider.com/video/amazon-modifies-ad-revenue-impressions-share-policy-international-fire-tv-apps">https://www.streamtvinsider.com/video/amazon-modifies-ad-revenue-impressions-share-policy-international-fire-tv-apps</a>, See on <a href="https://news.ycombinator.com/item?id=36945979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><span>©2023 Questex LLC All rights reserved.</span></p>
  <div><p><a href="https://questex.com/terms-and-conditions/">Terms of use</a></p></div>
  <div><p><a href="https://questex.com/privacy-policy/">Privacy Policy</a></p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building Nikola Tesla's Bladeless Turbine [video] (166 pts)]]></title>
            <link>https://www.youtube.com/watch?v=Tuzh9mHvzkk</link>
            <guid>36945206</guid>
            <pubDate>Mon, 31 Jul 2023 16:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=Tuzh9mHvzkk">https://www.youtube.com/watch?v=Tuzh9mHvzkk</a>, See on <a href="https://news.ycombinator.com/item?id=36945206">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[“BASIC Computer Games” code in modern languages (232 pts)]]></title>
            <link>https://github.com/coding-horror/basic-computer-games</link>
            <guid>36945046</guid>
            <pubDate>Mon, 31 Jul 2023 16:26:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/coding-horror/basic-computer-games">https://github.com/coding-horror/basic-computer-games</a>, See on <a href="https://news.ycombinator.com/item?id=36945046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h3 tabindex="-1" dir="auto">What are we doing?</h3>
<p dir="auto">We’re updating the first million selling computer book, <a href="https://en.wikipedia.org/wiki/BASIC_Computer_Games" rel="nofollow">BASIC Computer Games</a>, for 2022 and beyond!</p>
<ul dir="auto">
<li><a href="https://annarchive.com/files/Basic_Computer_Games_Microcomputer_Edition.pdf" rel="nofollow">Read the original book</a> (pdf)</li>
<li><a href="https://troypress.com/wp-content/uploads/user/js-basic/index.html" rel="nofollow">Play the original games in your browser</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Where can we discuss it?</h3>
<p dir="auto">Please see <a href="https://discourse.codinghorror.com/t/-/7927" rel="nofollow">the discussion here</a> for a worklog and conversation around this project.</p>
<h3 tabindex="-1" dir="auto">Project structure</h3>
<p dir="auto">I have moved all <a href="http://www.vintage-basic.net/games.html" rel="nofollow">the original BASIC source code</a> into a folder for each project in the original book (first volume). Note that Lyle Kopnicky has generously normalized all the code (thanks Lyle!) to run against <a href="http://www.vintage-basic.net/download.html" rel="nofollow">Vintage Basic</a> circa 2009:</p>
<blockquote>
<p dir="auto">I’ve included all the games here for your tinkering pleasure. I’ve tested and tweaked each one of them to make sure they’ll run with Vintage BASIC, though you may see a few oddities. That’s part of the fun of playing with BASIC: it never works quite the same on two machines. The games will play better if you keep CAPS LOCK on, as they were designed to be used with capital-letter input.</p>
</blockquote>
<p dir="auto">Each project has subfolders corresponding to the languages we’d like to see the games ported to. This is based on the <a href="https://www.tiobe.com/tiobe-index/" rel="nofollow">2022 TIOBE index of top languages</a> that are <em><strong>memory safe</strong></em> and <em><strong>general purpose scripting languages</strong></em> per <a href="https://discourse.codinghorror.com/t/-/7927/34" rel="nofollow">this post</a>:</p>
<ol dir="auto">
<li>C#</li>
<li>Java</li>
<li>JavaScript</li>
<li>Kotlin</li>
<li>Lua</li>
<li>Perl</li>
<li>Python</li>
<li>Ruby</li>
<li>Rust</li>
<li>VB.NET</li>
</ol>
<blockquote>
<p dir="auto"><g-emoji alias="loudspeaker" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e2.png">📢</g-emoji> Note that in March 2022 we removed Pascal / Object Pascal and replaced it with Rust as we couldn’t determine if Pascal is effectively memory safe. We’ve also added Lua, as it made the top 20 in TIOBE (as of 2022) and it is both memory safe and a scripting language. The Pascal ports were moved to the alternate languages folder.</p>
</blockquote>
<blockquote>
<p dir="auto"><g-emoji alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png">⚠️</g-emoji> Please note that we have decided, as a project, that we <strong>do not want any IDE-specific or build-specific files in the repository.</strong> Please refrain from committing any files to the repository that only exist to work with a specific IDE or a specific build system.</p>
</blockquote>
<h3 tabindex="-1" dir="auto">Alternate Languages</h3>
<p dir="auto">If you wish to port one of the programs to a language not in our list – that is, a language which is either not memory safe, or not a general purpose scripting language, you can do so via the <code>00_Alternate_Languages</code> folder. Place your port in the appropriate game subfolder, in a subfolder named for the language. Please note that these ports are appreciated, but they will not count toward the donation total at the end of the project.</p>
<h3 tabindex="-1" dir="auto">Project goals</h3>
<p dir="auto">Feel free to begin converting these classic games into the above list of modern, memory safe languages. In fact, courtesy of @mojoaxel, you can even view the JavaScript versions in your web browser at</p>
<p dir="auto"><a href="https://coding-horror.github.io/basic-computer-games/" rel="nofollow">https://coding-horror.github.io/basic-computer-games/</a></p>
<p dir="auto">But first, a few guidelines:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>These are very old games</strong>. They date from the mid-70s so they’re not exactly examples of what kids (or anyone, really?) would be playing these days. Consider them more like classic programming exercises to teach programming.  We’re paying it forward by converting them into modern languages, so the next generation can learn from the programs in this classic book – and compare implementations across common modern languages.</p>
</li>
<li>
<p dir="auto"><strong>Stay true to the original program</strong>. These are mostly unsophisticated, simple command line / console games, so we should strive to replicate the command line / console output and behavior illustrated in the original book. See the README in the project folder for links to the original scanned source input and output. Try <a href="https://troypress.com/wp-content/uploads/user/js-basic/index.html" rel="nofollow">running the game in your browser</a>. Avoid the impulse to add features; keep it simple, <em>except</em> for modern conventions, see next item 👇</p>
</li>
<li>
<p dir="auto"><strong>Please DO update for modern coding conventions</strong>. Support uppercase and lowercase. Use structured programming. Use subroutines. Try to be an example of good, modern coding practices!</p>
</li>
<li>
<p dir="auto"><strong>Use lots of comments to explain what is going on</strong>. Comment liberally! If there were clever tricks in the original code, decompose those tricks into simpler (even if more verbose) code, and use comments to explain what’s happening and why. If there is something particularly tricky about a program, edit the <strong>Porting Notes</strong> section of the <code>readme.md</code> to let everyone know. Those <code>GOTO</code>s can be very pesky..</p>
</li>
<li>
<p dir="auto"><strong>Please don’t get <em>too</em> fancy</strong>. Definitely use the most recent versions and features of the target language, but also try to keep the code samples simple and explainable – the goal is to teach programming in the target language, not necessarily demonstrate the cleverest one-line tricks, or big system "enterprise" coding techniques designed for thousands of lines of code.</p>
</li>
<li>
<p dir="auto"><strong>Please don't check in any build specific or IDE specific files</strong>. We want the repository to be simple and clean, so we have ruled out including any IDE or build system specific files from the repository. Git related files are OK, as we are using Git and this is GitHub. 😉</p>
</li>
</ul>
<h3 tabindex="-1" dir="auto">Emulation and Bugfixes</h3>
<p dir="auto">We want the general behavior of the original programs to be preserved, <em>however</em>, we also want to update them, specifically:</p>
<ul dir="auto">
<li>allow both UPPERCASE and lowercase input and display</li>
<li>incorporate any bugfixes to the original programs; see the <code>readme.md</code> in the game folder</li>
<li>improved error handling for bad or erroneous input</li>
</ul>
<p dir="auto">Please note that on the back of the Basic Computer Games book it says <strong>Microsoft 8K Basic, Rev 4.0 was the version David Ahl used to test</strong>, so that is the level of compatibility we are looking for. &nbsp;QBasic on the DOS emulation is a&nbsp;later version of Basic but one that retains downwards compatibility so far in our testing. To verify behavior, try <a href="https://troypress.com/wp-content/uploads/user/js-basic/index.html" rel="nofollow">running the programs in your browser</a> with <a href="https://github.com/inexorabletash/jsbasic/">JS BASIC, effectively Applesoft BASIC</a>.</p>
<h3 tabindex="-1" dir="auto">Have fun!</h3>
<p dir="auto">Thank you for taking part in this project to update a classic programming book – one of the most influential programming books in computing history – for 2022 and beyond!</p>
<p dir="auto">NOTE: per <a href="https://blog.codinghorror.com/updating-the-single-most-influential-book-of-the-basic-era/" rel="nofollow">the official blog post announcement</a>, I will be <strong>donating $5 for each contributed program in the 10 agreed upon languages to <a href="https://girlswhocode.com/" rel="nofollow">Girls Who Code</a></strong>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers reached the bottom of ice sheet at -2670m after 7 years of drilling (505 pts)]]></title>
            <link>https://news.ku.dk/all_news/2023/07/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/</link>
            <guid>36944978</guid>
            <pubDate>Mon, 31 Jul 2023 16:22:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.ku.dk/all_news/2023/07/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/">https://news.ku.dk/all_news/2023/07/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/</a>, See on <a href="https://news.ycombinator.com/item?id=36944978">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>With a sudden reward of mud at their feet, researchers at the EGRIP research station had successfully made it through the 2670-meter ice sheet last week after seven years of drilling. In doing so, the research group met their ultimate goal of drilling all the way through the ice and to the bedrock below.</p>
<p>"This is the first time that a deep ice core has been drilled through an ice stream, so it will be extremely exciting to analyse the material, which has much to tell us about how our planet’s climate has changed over the past 120,000 years. But we need to wrap up our work here first," says Professor Dorthe Dahl-Jensen of the University of Copenhagen’s Niels Bohr Institute, who leads research at EGRIP.</p>
<p>The mud, which had not seen the light of day for roughly a million years, was only briefly exposed to sunlight, as white light can damage ice core material. Instead, the core was retrieved in red light and immediately packed away, like a Christmas present that will need to remain unopened until some special day down the road.</p>
<figure><img alt="Mud on a boot" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/TrevorsBoot__photo_Trevor_Popp_.png">
<figcaption>The researchers literally got mud from&nbsp;under the ice cap&nbsp; on their feet. Photo: Trever Popp, EGRIP</figcaption>
</figure>


<p>"Though it was tempting to take a closer look, we quickly sealed the ice core, kept it frozen and sent it to Kangerlussuaq Airport, where it is now waiting for a flight to Denmark," says Dorthe Dahl-Jensen.</p>
<h2>Results could change climate models</h2>
<p>Despite the quick packaging and send off, the drilling has already delivered the scientists research "gold".</p>

<p>"The results are exceptional. The ice stream flows like a river of ice that tears itself free of the surrounding slow-flowing ice sheet. We can see that the entire 2670-meter-thick mass of ice flows like a block at a speed of 58 meters per year. This will change climate models because it redefines our basic understanding of how ice moves," explains Dorthe Dahl-Jensen, who continues:</p>
<p>"The block of ice floats on a layer of wet mud. It seems to act as a kind of layer of quicksand that allows the ice block to flow undisturbed across the bedrock. Near the bottom of the ice sheet, we find rocks and sand embedded in the ice. The measurements also show that the ice is melting at the bottom," she says.</p>
<p>Towards the base, the ice is more than 120,000 years old and dates back to the last interglacial period, a time when the atmospheric temperature above Greenland was 5°C warmer than today.</p>
<h2>Last drill got stuck</h2>
<p>The last ice core was drilled on July 21, 2023. These final 4 meters of ice were drilled using a rock coring system due to the presence of pebbles in the ice.</p>
<p>Chief ice core driller Steffen Bo Hansen of the Niels Bohr Institute was on hand when the breakthrough took place:</p>
<p>"The rock drill became stuck at the bottom and we feared that we would lose both the last core and drill itself. Loosening the drill was tough because it got stuck in the wet mud at the bottom. Fortunately, we succeeded. We have now successfully drilled through the ice stream, and it was amazing to find mud beneath the ice," he says.</p>
<h2>A 2670-meter-long account of Earth's climate</h2>
<p>All in all, the ice core is a 2670-meter-long record that tells of how our planet’s climate has changed over the past 120,000 years. It will be analyzed in dozens of laboratories around the world.</p>
<p>Due to the ice core’s outstanding quality, the scientists expect to be able to document the climate surrounding the ice during both the warmer and colder periods of the 11,700 years since the last ice age, as well as the anthropogenic changes caused by human development.</p>
<figure><img alt="Scientists holding the last ice core" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/20230721_SteffTrevor__photo_Sepp_Kipfstuhl_.png">
<figcaption>The last ice core contained rock and mud from the bottom 2670 meters below the ice. Photo Sepp Kipfstuhl, EGRIP</figcaption>
</figure>

<p>Analyses of the last ice cores will begin in fall, when the research group returns to Copenhagen. The EGRIP ice core is stored in the Danish ice core repository in the Copenhagen suburb Brøndby together with most of the deep Greenland ice cores. Samples from the ice cores drilled the previous years have been analyzed in more than 30 laboratories and the first 53 papers have been published.</p>

<div aria-expanded="false" id="collapse-1690806900008" data-alignment="centered">
<h3>Facts about the EGRIP camp, new technology and innovation.</h3>
<div>
<p>The EGRIP camp is mobile. The main building, “The Dome”, is on skis, while the rest of the equipment and infrastructure is on sledges. This allows the entire camp to be removed and towed by tracked vehicles to new drilling sites on the Greenland Ice Sheet.</p>
<figure><img alt="The scientists work in trenches beneath the snowy surface of the ice sheet" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/gange.png">
<figcaption>Photo: EGRIP</figcaption>
</figure>
<p>A drill trench and science trench were constructed beneath the snow surface by inflating balloons with a diameter of five meters and a length of 45 meters in seven-meter-deep trenches dug into the snow. Snow was then blown over the tops of the balloons. After a few days, the balloons were deflated and removed, after which the trenches were ready for drill operations and ice core analyses.</p>
<figure><img alt="Ice core scientists adjusting the ice drill" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/20230720_FixingDrillElectronics__photo_Dothe_Dahl-Jensen_.png">
<figcaption>Photo: Dorthe Dahl-Jensen, EGRIP</figcaption>
</figure>
<p>A new electronic navigation package in the Danish made drill made it possible for drillers to control the inclination of the ice core drill and make future replicate coring in the same bore hole possible.</p>
<figure><img alt="EGRIP camp in sun and windy snow" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/camp.jpg">
<figcaption>Photo: EGRIP</figcaption>
</figure>
</div>
</div>

<h2>A key to understanding rising sea levels</h2>
<p>The loss of ice from Greenland’s ice sheet is a major contributor to rising sea levels and is expected to increase as temperatures over Greenland edge ever upwards. Half of this ice loss comes from Greenland’s ice streams, whose behavior is still not well understood.</p>
<p>Thus, knowledge of how Greenland’s ice streams move is a key to understanding how sea levels will rise in the future and will serve to improve the accuracy of projections.</p>
<p>"I'm thrilled about the success. I’ve followed the flow of ice by measuring the borehole’s shape over the years using a borehole logger. The fact that the ice is not dislodged, but slides as a block over mud, will improve future sea level projections using recalibrated models," says Dorthe Dahl-Jensen.</p>
<div>
<h3><strong>About the Study</strong></h3>
<p>EGRIP is an international project and includes participants from 12 nations. The contributing nations are Denmark, the United States, Germany, Japan, Norway, Switzerland, China, Canada, France, South Korea, the United Kingdom and Sweden.</p>
<p>Logistics are carried out by the University of Copenhagen and the US National Science Foundation. All of the nations have participated in fieldwork and ice core drilling. 40% of the more than 600 field participants have been young scientists trained in EGRIP’s international research environment.</p>
<p>Thus far, samples from EGRIP ice cores have been analysed in more than 30 laboratories and an initial 53 articles have been published (<a href="https://eastgrip.org/Publications.html">https://eastgrip.org/Publications.html</a>).</p>
<p>Denmark is EGRIP’s largest partner, accounting for 55% of the project’s budget. The project is supported by the AP Møller Foundation, the Villum Foundation and the University of Copenhagen.</p>
<p>Information on the project and field work can be found on the EGRIP homepage and the publications<span>&nbsp;</span><a href="https://eastgrip.org/Publications.html).">here</a>.<img alt="EGRIP logo" src="https://science.ku.dk/english/press/news/2023/pay-dirt-for-ice-core-scientists-in-east-greenland-as-they-reach-bedrock/billedinformationer/Screenshot__14_.png"></p>
</div>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Digging into the odd history of Blade Runner’s title (2017) (157 pts)]]></title>
            <link>https://www.vulture.com/2017/10/why-is-blade-runner-the-title-of-blade-runner.html</link>
            <guid>36944947</guid>
            <pubDate>Mon, 31 Jul 2023 16:20:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vulture.com/2017/10/why-is-blade-runner-the-title-of-blade-runner.html">https://www.vulture.com/2017/10/why-is-blade-runner-the-title-of-blade-runner.html</a>, See on <a href="https://news.ycombinator.com/item?id=36944947">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.vulture.com/_components/article/instances/cj8d7ilzd0062xey684nepbpr@published" data-content-channel="Movies" data-crosspost="" data-type="News-Original Reporting" data-syndication="original" data-headline="Digging Into the Odd History of Blade Runner’s Title" data-authors="Abraham Josephine Riesman" data-publish-date="2017-10-04" data-tags="blade runner 2049, blade runner, vulture homepage lede" data-issue-date="" data-components-count="14">


  
  
  
  <header>
    
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.2x.rsquare.w700.jpg" width="700" height="700"> <img src="https://pyxis.nymag.com/v1/imgs/1e1/b9c/aa4c0791260b8619dd1e52a60fb036ac49-04-blade-runner-harrison-ford.rsquare.w700.jpg" data-content-img="" width="700" height="700" fetchpriority="high"> </picture>
          </div>
            <div>
              <p>
                  Why’s this guy called that thing?
                <span>Photo: Sunset Boulevard/Corbis via Getty Images</span>
              </p>
            </div>
              </div>
            <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7ilzd0061xey6sn4iha4l@published" data-word-count="76">The <em>Blade Runner</em> franchise operates with a kind of dream logic where questions that might otherwise frustrate a viewer are subsumed by the overall ambience. Why would replicant manufacturers make their humanoid products so hard to identify? Why is the USSR still around as of 2049? How did Pris’s hair <a href="http://www.imdb.com/title/tt0083658/goofs?item=gf0911044">dry off so quickly</a>? But perhaps the biggest incongruity that we take for granted is the title. Why the hell is <em>Blade Runner</em> called <em>Blade Runner</em>?</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2qu00053k5xqt3194t3@published" data-word-count="141">Though the viewer is told in the opening text of Ridley Scott’s 1982 original that “special Blade Runner units” hunt renegade replicants — and though the term “Blade Runner” is applied to Harrison Ford’s Rick Deckard a few times in the film — we’re never given an explanation of where the proper noun comes from. “Blade?” Deckard uses a gun, not a knife or sword. “Runner?” Sure, he runs at times, but not more than the average person might. <em>Blade Runner 2049</em> has a few scenes that prominently feature scalpels, but they’re not wielded by a Blade Runner. The novel upon which <em>Blade Runner</em> was based, Philip K. Dick’s <em>Do Androids Dream of Electric Sheep?</em>, offers no clues: Deckard and his ilk are just cops, never referred to as Blade Runners. The term is impressionistic at best and nonsensical at worst.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2ua00073k5xmytlbmtl@published" data-word-count="99">That’s to be expected because, as it turns out, the term predates the original movie by eight years and was invented to apply to an entirely separate work of fiction. It was coined by a doctor who moonlit as a sci-fi author, fleshed out by none other than William S. Burroughs, and tossed into the mix of Ridley Scott’s seminal epic as something of an afterthought. The tale of how the words “blade” and “runner” got mixed up with one another and applied to one of the most acclaimed movies of the 20th century is a truly odd one.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2u800063k5xgbpb0sv6@published" data-word-count="89">Our story begins with a mysterious writer by the name of Alan E. Nourse. <a href="http://data.desmoinesregister.com/famous-iowans/alan-nourse">According</a> to the Des Moines <em>Register</em>, he was born in that city in 1928 to Bell Telephone Company engineer Benjamin Nourse and a woman named Grace Ogg. Young Alan moved to Long Island with his family at age 15, attended Rutgers, served for a couple of years in the Navy as a hospital corpsman, and was awarded a medical degree from the University of Pennsylvania in 1955 before moving to Washington state to practice medicine.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2ug00093k5xoab0hllo@published" data-word-count="152">Whatever Nourse’s skills as a doctor may have been, they were outweighed in the scales of history by his other passion: writing about the medical profession and fantastical worlds of the future. Before he was even done with medical school, he was <a href="http://www.isfdb.org/cgi-bin/ch.cgi?73">publishing</a> sci-fi on the side: first came short pieces in anthology magazines like <em>Astounding Science Fiction</em> and <em>Galaxy Science Fiction</em>, then he started publishing novels with titles like <em>Trouble on Titan </em>(1954), <em>Rocket to Limbo</em> (1957), and <em>Scavengers in Space </em>(1959). In 1963, he retired from medicine to focus on his writing, but wrote about learning the healing arts in a 1965 nonfiction book called <em>Intern</em>, published under the intimidating pseudonym “Dr. X.” Sci-fi author-editor Robert Silverberg, who knew Nourse, tells me the latter book “brought him much repute and fortune,” but in general, he just “wrote a lot of very good science fiction that no one seemed to notice.”</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2ue00083k5xary3w9zh@published" data-word-count="186">That changed <a href="http://www.isfdb.org/cgi-bin/title.cgi?719">on</a> October 28, 1974. Sort of. On that day, publishing house David McKay released a Nourse novel that combined the author’s two areas of expertise into a single magnum opus: <em>The Bladerunner</em>. It follows the adventures of a young man known as Billy Gimp and his partner in crime, Doc, as they navigate a health-care dystopia. It’s the near future, and eugenics has become a guiding American philosophy. Universal health care has been enacted, but in order to cull the herd of the weak, the “Health Control laws” — enforced by the office of a draconian “Secretary of Health Control” — dictate that anyone who wants medical care must undergo sterilization first. As a result, a system of black-market health care has emerged in which suppliers obtain medical equipment, doctors use it to illegally heal those who don’t want to be sterilized, and there are people who covertly transport the equipment to the doctors. Since that equipment often includes scalpels and other instruments of incision, the transporters are known as “bladerunners.” <em>Et voilà</em>, the origin of a term that went on to change sci-fi.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p31t000h3k5x2uhwqrgq@published" data-word-count="177">The novel itself is perfectly fine. Billy is a bladerunner, Doc is a doctor who does legal and illegal work, they live in the greater New York metropolitan area (one way in which the novel coincidentally resembles <em>Blade Runner</em> is the setting of a massively overbuilt city where people are often transported via flying car), they run into trouble with the law, they race to stop an epidemic, and their virtue is rewarded by a change in national policy that makes their brand of medical care legal. The prose is relentlessly simple, the medical procedures are described in the detail you’d expect from an M.D., and the dialogue is almost comically expository at times (e.g. “‘Doctor, we can’t bring ourselves to take them to the Hospital,’ the woman said, ‘they’re both over five years old, and they’ve both been treated more than three times in the Clinic. That means that they’d both have to be sterilized before they could qualify for any legal care at all’”). It’s easy to imagine it disappearing into the mists of time.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2xx000a3k5xqgc7wrn7@published" data-word-count="208">But fortune smiled on Nourse, as did one of the finest writers of the past 100 years: the obscene eccentric William S. Burroughs. <a href="https://www.jstor.org/stable/10.1086/680700?seq=1#page_scan_tab_contents">According</a> to literary scholar Paul Ardoin, Burroughs somehow obtained a copy of the second printing of <em>The Bladerunner</em> around the end of 1976. Burroughs was in a transitional stage in his life, having kicked heroin only a few years before and having moved back to New York after a self-imposed exile in Europe. He was rebooting his career with the help of a new assistant named James Grauerholz, turning in columns for pop-culture mag <em>Crawdaddy</em> and soaking up the nascent downtown punk scene. On December 5, 1976, Grauerholz wrote a letter to Burroughs’s agent, Peter Matson, saying the scribe had “liked the book very much, and in fact has begun to consider a film treatment for it.” As far as I can tell, writing a film treatment was something new, or at least quite rare, for Burroughs, but he dove into it with fervent passion. Matson negotiated the rights with Nourse, got the go-ahead, and Burroughs wrote the treatment in less than four months, delivering it to Matson by March 1977. He called it <em>The Blade Runner</em>, adding a fateful space to the titular noun.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2xz000b3k5xppu9icn7@published" data-word-count="197">Burroughs’s take on Nourse is, to put it mildly, a wild ride. Indeed, it barely has anything to do with <em>The Bladerunner</em> and is as over-the-top as the original was buttoned-down. It’s written not as a screenplay, but rather as a novella-length explanation of the movie to someone named “B.J.” (Burroughs periodically included this mysterious figure as the recipient of his words in other works, as well.) Like many Burroughs texts, the adaptation is highly inscrutable, which is what makes it so entertaining. He doesn’t even get to the main plot of the movie until nearly halfway through, having spent the first portion just setting the scene with the difficult-to-follow backstory of how the world of the film got to be so screwed-up: Overpopulation led to government intrusion into the lives of private citizens, the state’s attempts to control the population begat multiple Health Acts that were received poorly by the populace and led to a bloody civil war in greater New York in which the white middle class battled the poor and people of color, and from the ashes rose a new America where “the unfit” have to undergo sterilization in order to receive health care.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2y8000c3k5xwps6xj8u@published" data-word-count="224">That last bit is more or less where any comparisons to Nourse’s original end. We meet Billy and Doc, but they’re radically changed. Billy is introduced not as a bland cipher, but rather as a passionate queer man who, in his first scene, engages in profoundly explicit sex with his partner (“They look at each other and their throbbing phalluses pick up the same rhythm — throb throb throb — heartbeats like drums in the dark room”); while Doc is a combative asshole prone to verbal abuse (“‘Shut up, you’ll give my patient an engram,’ Doc screams back”). Their saga is somewhat incomprehensible, not least because it’s eventually conveyed in two separate movies, intended to be screened either by alternating scenes from one of the film with scenes from the other, or by projecting them on two screens simultaneously. It concludes with Billy realizing he’s not living in 2014, as he once thought, but is actually somehow in 1914. The magic lies not in the story, but in the insane images Burroughs describes: “They toast each other with insect claws,” “Naked leper with a hardon,” “Rioters release zoo animals. They dump fish from aquariums into the rivers,” “A flourishing black market in sperm heralds a long-range genetic war. ‘Boy sperm Meester?’”, “Mad scientist: ‘With this culture we can rule the world!’” and so on.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p2yb000d3k5x5p8kp8xk@published" data-word-count="95"><em>The Blade Runner</em> was patently unfilmable. Grauerholz reported in July 1977 that nobody they took it to was interested, and an alternative arrangement was made with Nourse, whereby the treatment would be published in book form and all film rights would be forfeited. In order to distinguish it from Nourse’s book, a title change was necessary, and although the adaptation would never be a movie, Burroughs and Grauerholz confusingly chose to call it <em>Blade Runner: A Movie</em>. It was first published in 1979 by Blue Wind Press and was never considered a major Burroughs work.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p30u000e3k5xx9v3dttf@published" data-word-count="125">However, a copy of <em>Blade Runner: A Movie</em> found its way into the library of a struggling actor and writer named Hampton Fancher. In the early 1980s, he, producer Michael Deely, and director Ridley Scott were working on an adaptation of <em>Do Androids Dream of Electric Sheep?</em> and stumbled on a question. “Ridley, after a few months of us working on a draft, when he first came into the project, asked me a question that was so obvious I hadn’t really addressed it before,” Fancher tells me. “What is it that Deckard is, professionally? ‘He’s a detective,’ I said. ‘Well, that was obvious, but what kind of detective exactly, what should he be called?’ I didn’t have an answer, but I’d better get one fast.”</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p31m000f3k5xfeo09lv7@published" data-word-count="183">He turned to his collection of tomes. Per Fancher: “That night, I was looking through my books and came across a thin little volume by William Burroughs called <em>Blade Runner</em>. Bingo! Everybody liked it, then later, we needed a new title other than the ones we’d been considering and Michael Deeley, the producer, said, ‘It’s staring us right in the face.’” <a href="https://books.google.com/books?id=JwDeB37eyI0C&amp;pg=PA95&amp;lpg=PA95&amp;dq=It+was+a+nice,+threatening+name+that+neatly+described+a+violent+action.&amp;source=bl&amp;ots=bBNxp-ntL2&amp;sig=TaOjlOLIpbDz_gH4ML3ax2jFbec&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwirloLArNfWAhUo4oMKHZsYAAkQ6AEIKDAA#v=onepage&amp;q=It%20was%20a%20nice%2C%20threatening%20name%20that%20neatly%20described%20a%20violent%20action.&amp;f=false">According</a> to Scott, they approached Burroughs, he said yes, they bought the title of his book for “a nominal fee,” and <em>Blade Runner</em> — a work that otherwise had nothing to do with <em>The Bladerunner</em> or <em>Blade Runner: A Movie</em> — was released on June 25, 1982. When I ask Fancher why there’s no in-film explanation of the term, he replies, “I think ‘explanations’ are the bug-bears of screenplay writing and I like to stay clear of them.” A comic-book <a href="http://www.vulture.com/2017/10/before-blade-runner-2049-came-the-blade-runner-spin-offs.html?utm_campaign=nym&amp;utm_source=tw&amp;utm_medium=s1">adaptation</a> of <em>Blade Runner</em> written by Archie Goodwin attempted to explain the term by having Deckard’s narration at one point read, “Blade runner. You’re always movin’ on the edge,” but anyone searching for the term’s meaning within the movie was denied it.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cj8d7p31s000g3k5xkkjfwp7s@published" data-word-count="118">Try as I might, I haven’t been able to find out what either Nourse or Burroughs thought of the eventual film. Nourse died in 1992 and his ashes were buried on a hill in his rural hometown of Thorp, Washington. Burroughs died in 1997 at his home in Lawrence, Kansas. Both perished due to heart issues. Nourse’s novel is available in a spottily copy-edited ebook edition, and you can find used copies of Burroughs’s text, though it’s never been released by a major press. They have, perhaps unfortunately, been eclipsed by the wholly separate piece of art that plucked their name. However, by including scalpels, <em>Blade Runner 2049</em> has quietly and inadvertently brought the tale into full circle.</p>

    </div>

    


          



      <span>Digging Into the Odd History of <em>Blade Runner</em>’s Title</span>



  </section>

  
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My journey away from the JAMstack (159 pts)]]></title>
            <link>https://www.spicyweb.dev/farewell-jamstack/</link>
            <guid>36944545</guid>
            <pubDate>Mon, 31 Jul 2023 15:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spicyweb.dev/farewell-jamstack/">https://www.spicyweb.dev/farewell-jamstack/</a>, See on <a href="https://news.ycombinator.com/item?id=36944545">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <header>
    <hgroup>
      
      <p aria-roledescription="subtitle">The name is all but dead, nerfed by the company who invented it. Here’s why Netlify was ahead of its time and where everything went wrong.</p>
    </hgroup>

    <p><img src="https://www.spicyweb.dev/images/jared-white.jpg" alt=""> By <a href="https://www.spicyweb.dev/about">Jared White</a></p>
  </header>

<p>Before I give you my side of the story, I’d like to point you to <a href="https://remotesynthesis.com/blog/goodbye-jamstack/" target="_blank">Brian Rinaldi’s comprehensive take on the demise of Jamstack</a> (or as I still prefer to call it, JAMstack) for some much-needed context on what’s been going down. He asks “is Jamstack officially finished?” and this article is essentially my reply.</p>

<p><strong>TL;DR:</strong> the answer is <em>yes</em>.</p>

<p>As for the reason why, we must point our finger straight at <a href="https://netlify.com/" target="_blank">Netlify</a>.</p>

<p>Listen, I get it. Running a successful and hopefully profitable hosting company with investors breathing down your neck is hard. I don’t begrudge them for having to pivot to enterprise cloud mumbo-jumbo in order to reel in the big bucks and justify their valuation.</p>

<p>But I can’t help but feel duped…like so much of the other “enshittification” we’ve been dealing with in tech over the last few years. <strong>The cycle repeats itself</strong>: we invest our hard-earned time and sometimes money to build on top of friendly, seemingly benign platforms—only to see those platforms wriggle out from under us and morph into something entirely different (and for our purposes, much worse).</p>

<p>Gather around folks, and listen to my story of my first experience with the JAMstack. I’ll also explain why prior to this news I’d already moved on from the it and from Netlify, and what instead I believe the web dev industry should be heading towards as a “default” stack.</p>

<h2 id="the-year-was-2015">The Year Was 2015 <a href="#the-year-was-2015">#</a></h2>

<p>I had just come off a lengthy stint trying to build and promote a paid, tablet-first CMS. With a failed startup behind me, as well as a number of WordPress sites I simply <em>hated</em> to administer because they were so buggy and insecure and expensive, I was getting desperate. Due to my experience as a Ruby on Rails developer, I even tried reaching for some Rails-based CMSes, but finding a slam-dunk improvement over WordPress was far from straightforward.</p>

<p><strong>And then I stumbled upon Jekyll.</strong> 😍</p>

<p>To this day, I have no clue why it had initially taken me so long to discover Jekyll. Jekyll was integrated into GitHub (powering their Pages product) and was built with Ruby! I do remember hearing more and more about “static site generators” (aka SSGs) as I was winding down production of my own CMS, and I filed that thought away as a possible way to salvage some of the work I’d done.</p>

<p>Eventually I <em>finally</em> gave Jekyll a real try, and I was floored. Here was an amazing developer-friendly tool where I could just to take a bunch of simple HTML / Markdown, CSS, JavaScript, and image files, run a single command, and BOOM: get a website trivially easy to deploy anywhere. I even grokked the Liquid template syntax without issue, because I was already familiar with both Shopify and my own CMS which had used Liquid.</p>

<p>The only real head-scratcher was the content authoring side of the equation—I couldn’t expect my clients to learn how to input Markdown into GitHub—but with my experience having already built authoring interfaces, I figured it wouldn’t be hard to put together a simple Rails editor app that could work with Markdown and GitHub under the hood.</p>

<p>I dogfooded Jekyll first for my own personal website at <a href="https://jaredwhite.com/" target="_blank">jaredwhite.com</a>, relaunching it in February 2016. (It’s since been resigned many times and is now built with <a href="https://www.bridgetownrb.com/" target="_blank">Bridgetown</a> instead…but it remains a static site!) From there, I worked on a variety of projects for myself and for clients. To this very day, some of those sites are still on the web humming along without issue (<a href="https://www.sengoidelc.com/" target="_blank">here’s one of my favorites</a>) because, hey, <em>static sites are awesome!</em></p>

<h2 id="along-came-aerobatic-netlify">Along Came <del>Aerobatic</del> Netlify <a href="#along-came-aerobatic-netlify">#</a></h2>

<p>When I first got into this brand-new world of modern SSGs, the gold standard for hosting Ruby-powered web applications was Heroku. I was quite familiar with Heroku and had used it on a number of projects. But Heroku had nothing to offer me when it came to SSGs. Heroku was engineered around a model of dynamic web servers and databases, not build-once-and-cache-on-a-CDN-forever deployments.</p>

<p>I suppose I could have just used GitHub Pages, but at that time I was primarily using Bitbucket for hosting my projects and those of my clients. So it was perfect timing that, right when I needed to figure this all out, along came <a href="https://web.archive.org/web/20151029053713/http://www.aerobatic.com:80/blog/websites-for-bitbucket-powered-by-aerobatic.html" target="_blank">Aerobatic</a>.</p>

<p>Aerobatic was basically Heroku but for static sites hosted on Bitbucket (it was literally an add-on for that platform). <strong>Perfect!</strong> I could easily get that “push via Git and automatically deploy” workflow going with no other setup required. And the deployed sites were fast, secure, and cheap as hell to operate indefinitely.</p>

<p>For my client’s content editors, I usually just spun up a cheap VPS on Digital Ocean. They didn’t need to be high-powered at all, because those servers weren’t promoted to the public or accessed by more than one person really. And because all the content was stored in a Git repo, I didn’t even need to wrestle with a database!</p>

<p><strong>However, my love affair with Aerobatic didn’t last long. Because another shiny offering soon emerged: Netlify.</strong></p>

<p>The best way I can describe Netlify when I first started using it is “like Aerobatic…except better”. I’d encountered a few technical difficulties getting Aerobatic sites up and running, and Netlify was a noticeable  improvement. Builds were fast, deploys were rock-solid, and <em>It. Just. Worked.</em> Plus it supported both GitHub &amp; Bitbucket, so either way I was golden. I forget when they added the Forms feature, but it was pretty early on and that also proved a huge advantage.</p>

<p>One issue many of us encountered when trying to market these amazing new “static site” to potential customers was the term <em>static</em>. Calling a website “static” for many people implied a site which rarely changed and couldn’t accommodate any dynamic, interactive functionality. <em>Boring.</em> For instance, surely you couldn’t run your e-commerce site as a “static” site because e-commerce is anything but static!</p>

<p>Enter <strong>JAMstack</strong>.</p>

<h2 id="the-jamstack-is-here-to-solve-all-our-problems-right">The JAMstack is Here to Solve All Our Problems (Right?) <a href="#the-jamstack-is-here-to-solve-all-our-problems-right">#</a></h2>

<p>Netlify’s marketing sleight of hand in <a href="https://web.archive.org/web/20170315085227/https://jamstack.org/" target="_blank">inventing and promoting the JAMstack</a> was sheer brilliance. Instead of calling these builds “static sites” and these tools “static site generators”, we could say we’re building JAMstack sites (to compete with LAMPstack sites I suppose) and using some hot new JAMstack frameworks. The JAM stood for:</p>

<ul>
  <li>JavaScript</li>
  <li>APIs</li>
  <li>Markup</li>
</ul>

<p>And lest anyone get confused (because as we’ll soon discover EVERYONE eventually got very confused), the JavaScript of the J in JAM referred to <em>client-side JS</em>, not server-side. The whole point of JAMstack was that the tool building out the markup etc. could be written in anything, and just as importantly the <em>APIs used by the client-side JS could be written in anything</em>. After all, both Jekyll and Rails are Ruby-based tools, and I happily used both as part of my JAMstack deployments.￼</p>

<p>As time went on, a major appeal of the JAMstack was that it allowed a decoupling of the frontend from the backend, which is why Netlify and other hosts like it later on proved extremely popular with frontend developers. Ironically, in today’s world where SSR (server-side rendering) and progressive enhancement is now top of mind for many web developers, it’s positively <em>wild</em> to turn back the clock and realize that JAMstack architecture arose during the height of the <strong>SPA</strong> movement. You can even see it in all the marketing materials—your app “shell” could be statically deployed, and then your fancy-pants client-side app could take over and call APIs from all over the web. And a number of JAMstack sites were literally that. Disable JavaScript and what do you get? Maybe a simple header and footer if you’re lucky. <em>Everything else is blank.</em> <strong>Whoops!</strong></p>

<p><strong>However</strong>, that was never <em>my</em> JAMstack. I had intuitively understood that the exciting promise of JAM was in a sense the reverse acronym of MAJ: Markup, <em>then</em> APIs, <em>then</em> JavaScript. In other words, build as much as you can with static HTML (via templates, Markdown, etc.), <em>then</em> identify what you might need for some dynamic server interactions—which maybe you’d just write yourself as a Rails app or whatever—<em>then</em> write only the JavaScript you absolutely need to access those APIs (understanding that maybe certain dynamic pages would just get fetched directly from the server if need be).</p>

<p>In other words, <strong>progressive enhancement</strong>. 😂</p>

<p>But somehow that story got lost in the fray, and JAMstack eventually gave rise to a rebranded “Jamstack” with the major value prop being something rather entirely different: you could now build entire websites out of <em>JavaScript libraries</em> (aka React, or maybe Vue or Angular or Svelte) and <em>JavaScript frameworks</em> (aka Next.js, Gatsby, Nuxt, SvelteKit, etc.). And, whoa, look at this! You don’t need servers ever again! You can just write <em>serverless functions</em> to go along with your frontends! Fullstack, server-first web development is dead, long live frontend + serverless!</p>

<p>(Coinciding with this sea change, Jekyll began a long, slow, painful decline into irrelevance, due to the inexplicable failure of GitHub’s leadership to support its proper development and promotion as well as an unforgivable neglect of the Pages platform. It remains one of my greatest frustrations in 25+ years of web development…so much so that I forked Jekyll in 2020 and created <a href="https://www.bridgetownrb.com/" target="_blank">Bridgetown</a>. But I digress…)</p>

<p>Along with this “second generation” Jamstack mindset shift came <em>an order of magnitude</em> more build complexity. Instead of a straightforward CLI kicking off simple transformations to go from Markdown -&gt; HTML plus concatenate some (S)CSS files together or whatever, you’d get multi-minute long builds and GBs of <code>node_modules</code> and poorly-written tutorials on DEV.to about how to send emails from Gatsby functions and which distributed “web-scale” databases of the day are the coolest and crazy CLI tool churn and all sorts of other headaches. Things which used to take hours or days to accomplish in standard Rails or Laravel or Django apps—most of this stuff isn’t rocket science, folks—now took weeks or months! <em>Progress!</em> 🤪</p>

<p>This quick march of slapdash B.S. web technology under the guise of making our lives easier was <em>one hell of a whiplash</em>, and I really hadn’t seen it coming when I first entered this space. Instead of JAMstack saving us all from the horrors of WordPress, we were crushed under the weight of Jamstack! Janky SPAs, countless immature buggy frameworks, and NPM ecosystem insanity—along with the multi-headed hydra that is modern React.</p>

<p><a href="https://www.spicyweb.dev/the-great-gaslighting-of-the-js-age/">It got so bad I wrote about it.</a> (Warning: if you think <em>this</em> article has taken on a dour tone, avoid reading that spicy take! 🌶️)</p>

<h2 id="netlify-isnt-to-blameexcept-netlify-is-to-blame-">Netlify isn’t to blame…except Netlify is to blame 😬 <a href="#netlify-isnt-to-blameexcept-netlify-is-to-blame-">#</a></h2>

<p>We can’t put <em>all</em> the fault squarely on Netlify, in the sense that people mistakenly thought they needed to build their blogs with Gatsby and their business dashboards with Next.js because that’s what all the “techfluencers” and VC-backed tool vendors told them.</p>

<p>Yet I <strong>do</strong> blame Netlify, because <em>they’re the people who invented the term JAMstack!</em> Netlify proved more than happy to come along for the ride and oblige as one of the top hosting platforms of choice for this new ecosystem. They <em>could</em> have come out in favor of saner architectures and better support for languages other than JavaScript (believe me, I went around and around with them about their lack of interest in supporting Ruby-based server applications <strong>even as their own platform used Ruby under the hood!</strong>). They <em>could</em> have warned us of the dangers of complicated API spaghetti code and microservices. After all, why should Netlify care if your static site calls out to 20 different APIs or your own monolithic API you wrote in a battle-hardened, “boring” server framework? This bizarro-world focus on “serverless functions” and later “edge functions” never made a lick of sense to me (unless Netlify really thought they could somehow significantly profit off of function usage…again, a prospect which makes little sense to me).</p>

<p>Ultimately the failure of Jamstack to live up to the promise of its original JAMstack incarnation, and the industry’s manic pendulum swing into unmaintainable architectures and vendor lock-in, led me to abandon Netlify as a hosting platform of choice and look instead to more reasonable options. At this moment in time, that choice for me is <a href="https://www.render.com/" target="_blank">Render</a>. Render gives you the best of all worlds: deploy a static site to a CDN, deploy a server API written in any framework you want—even Rails!—deploy a Docker container…anything you need, <strong>BOOM</strong>, done. Want to use PostgreSQL? <em>Check.</em> Need Redis? <em>Check.</em> Would you like simultaneous deploys of all these services at once? <em>Check.</em></p>

<p>I have no business arrangement with Render, and I assure you this isn’t a sponsored post. I just really like their service. And if Render does become <em>enshittified</em> down the road, I’ll be super bummed and look for yet another alternative. (I sure hope that won’t become necessary!)</p>

<p>What saddens me is Netlify <em>could</em> have grown into a Render and meaningfully competed with Heroku—except they didn’t. They took a different road, and I would argue <strong>they failed</strong>. Hey, hindsight is 20/20…but honestly this was <em>so</em> easy to predict. 🤷🏻‍♂️</p>

<p>I’m sad to see Jamstack die, but the thing is: <em>most</em> web applications deployed by most individuals and small teams only need modest server offerings and maybe a static site. Again, it’s not rocket science. Most projects never need to become “web scale” and most web architectural complexity is completely unnecessary. You can spin up a Node.js API with Fastify, or a Ruby Roda API, or, heck, some PHP, stick it on a decent cloud server somewhere, and <em>that’s totally fine</em>. Boring technology is <strong>great</strong>. And servers are in fact totally awesome, as more and more developers are thankfully coming to discover (again).</p>

<h2 id="the-legacy-of-netlify">The Legacy of Netlify <a href="#the-legacy-of-netlify">#</a></h2>

<p>What Netlify gave us originally was a vision of how to deploy HTML-first websites easily via git commits and pushes, just like Heroku had done for dynamic applications. All we need now is a modern Netlify/Heroku mashup that’s cheap, stable, and doesn’t need to reinvent the damn wheel every year.</p>

<p>What do we call this, now that Jamstack is dead? I don’t know.</p>

<p><strong>I vote for KISSstack. (Keep It Simple, Silly.)</strong> 😋</p>

<p>But seriously, I think it’s vitally important to remember that simple websites and more complex web applications all sit on a spectrum, and a good web host will be able to identify your individual needs and provision builds and runtimes accordingly—no matter what the particular service offerings might be. (<a href="https://www.spicyweb.dev/web-app-and-web-site-should-be-friends/">I wrote about this too.</a>)</p>

<p>From my vantage point, the <em>only</em> goal I care about is to make building &amp; deploying sites dramatically easier for individuals and small teams. (<a href="https://imgflip.com/memetemplate/117794993/I-dont-think-about-you-at-all-Mad-Men" target="_blank">Sorry Big Co. Enterprises, I don’t think about you at all.</a>) And while it’s a real shame that Netlify is no longer in a position to usher in this future for us, I’m optimistic we’ll see <a href="https://www.render.com/" target="_blank">Render</a>, <a href="https://fly.io/" target="_blank">Fly.io</a>, and other companies down the road pick up the slack.</p>

<p><strong>Somebody</strong> has to.￼</p>


  

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How do you monitor your systemd services? (109 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36944388</link>
            <guid>36944388</guid>
            <pubDate>Mon, 31 Jul 2023 15:45:31 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36944388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="36944388">
      <td><span></span></td>      <td><center><a id="up_36944388" href="https://news.ycombinator.com/vote?id=36944388&amp;how=up&amp;goto=item%3Fid%3D36944388"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=36944388">Ask HN: How do you monitor your systemd services?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_36944388">102 points</span> by <a href="https://news.ycombinator.com/user?id=wh33zle">wh33zle</a> <span title="2023-07-31T15:45:31"><a href="https://news.ycombinator.com/item?id=36944388">9 hours ago</a></span> <span id="unv_36944388"></span> | <a href="https://news.ycombinator.com/hide?id=36944388&amp;goto=item%3Fid%3D36944388">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20How%20do%20you%20monitor%20your%20systemd%20services%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=36944388&amp;auth=83dff49574497fb0899a7d992c23b2a192e7f2ec">favorite</a> | <a href="https://news.ycombinator.com/item?id=36944388">47&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>I am using systemd on my machine and try to configure most things through it. For example, I have a backup job that is triggered by a timer.
I want to know when that job fails so I can investigate and fix it. Over time, I've had multiple solutions for this:</p><p>Send a notifcation via notify-send</p><p>Add `systemctl --failed` to my shell startup script</p><p>Send myself emails</p><p>None of these are quite ideal. Notifications are disruptive of the current workflow and ephemeral, meaning I might forget about it if I don't deal with it immediately.
Similarly, reading `systemctl --failed` on every new terminal is also disruptive but at least it makes me not forget about it.
Both of these are also not really applicable to server systems.
Sending myself emails feels a bit wrong but has so far been the best solution.</p><p>How are other people solving this? I did some research and I am surprised that there isn't a more rounded solution. I'd expect that pretty much every Linux user must run into this problem.</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free and open source software projects are in transition (186 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2023/the-floss-transition/</link>
            <guid>36944223</guid>
            <pubDate>Mon, 31 Jul 2023 15:36:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2023/the-floss-transition/">https://www.baldurbjarnason.com/2023/the-floss-transition/</a>, See on <a href="https://news.ycombinator.com/item?id=36944223">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  
 <p>These two links have brought to mind an issue I’ve been thinking a lot about.</p>
<ul>
<li><a href="https://shorts.stackingthebricks.com/the-boom-times-are-over/">​"The boom times are over.“​</a>.</li>
<li><a href="https://www.zachleat.com/web/cloudcannon/">​"Eleventy and CloudCannon: New Best Friends—zachleat.com"​</a>.</li>
</ul>
<p>The first, Amy Hoy’s post, points out that the tech bubble—the one that has been kept inflated over the past sixteen years with low interest rates, non-existent antitrust regulation, and a legal environment for tech that, in the US at least, has effectively been a free-for-all—is now over. The incestuous startup ecosystem that largely consisted of over-funded bullshit companies buying services from each other is done. The industry’s ability to command eye-watering exits–IPOs and acquisitions—for money-losing companies with no realistic path to profitability, has been limited by increased scrutiny from authorities on both sides of the Atlantic and by increased scepticism about the promise that tech will eventually deliver magical profits.</p>
<p>The tide is going out and people are slowly realising that the only companies that make <em>real</em> money in tech are the monopolists or quasi-monopolists. A small group of multinational corporations have each locked down their user base—control every aspect of their segment of the market—and are now abusing that position to extract revenue at the expense of other companies in tech and the economy in general.</p>
<p>In the second link Zach Leatherman writes about some of the changes that are taking place in <a href="https://www.11ty.dev/"><em>Eleventy</em></a>, the open source project he runs. Development on the project used to be funded by Netlify, but they seem to be dialling down their investment in open source, so Zach was forced to reassess the path that the project was on and find new ways of keeping it sustainable.</p>
<p>Eleventy is a nicely structured piece of software that I’ve used in a few projects myself, so I’m glad to see the partnership between it and CloudCannon. The two projects <a href="https://cloudcannon.com/blog/cloudcannon-the-official-cms-partner-of-eleventy/">look very complementary</a>.</p>
<p>They also plan to simplify the project and keep it focused on what it does well, and this touches on something I’ve been thinking about for a few weeks, ever since I read a conversation on Mastodon between Zach and Jim Nielsen on Jim’s blog post <a href="https://blog.jim-nielsen.com/2023/language-level-toll-roads/">“Language-Level Toll Roads”</a>. And that blog post makes a bunch of good points (emphasis original):</p>
<blockquote>
<p>I think maybe what I’m trying to put my finger on is this contrast between open source foundations with proprietary features <em>on top</em>, vs. open source foundations with proprietary features <em>built-in</em> — and the tension and competition that will take place between the two.</p>
</blockquote>
<p>I was trying to figure out ways of articulating the tension the relationship between free/libre/open source software (FLOSS) and the economic environment it exists in when I realised that FLOSS <em>created</em> the environment. Modern tech only exists because of free and open source software.</p>
<p>Back in the ancient days—in the before times when I first made websites—the tech world was predominantly closed source. The “dot” in dot-com were closed source servers such as those by Sun Microsystems (years before they caught the open source bug). Browsers were closed. Operating systems were closed—for the most part. The tools were largely closed. Even many of the popular programming languages used, such as ColdFusion or Java, were closed. For most users, when they visited a website, the entire stack was end-to-end closed. Database, server, browser, and operating system.</p>
<p>That took a long time to change, but now the core computing experience—browsing the web—is predominantly based on open source:</p>
<ul>
<li>Server operating system</li>
<li>Database</li>
<li>Server language</li>
<li>Server framework</li>
<li>Client operating system (Android, even Apple’s OSes have substantial OSS components)</li>
<li>Client side language</li>
<li>Client side framework</li>
<li>Browser</li>
</ul>
<p>Even in the native app domain, most of the frameworks people use to create cross-platform apps are open source.</p>
<p><em>A majority of the value created by modern software ultimately comes from free and open source software.</em></p>
<p>From this perspective most VC investments aren’t about <em>creating value</em> but about strip-mining FLOSS projects and communities. The scale is for <em>extraction</em>.</p>
<p>The tension is that these investors don’t just want to capture this value for themselves, they want to extract even more value from the communities surrounding the projects.</p>
<p>That’s why popular frameworks often start to spawn what Jim described as <em>built-in</em> proprietary features. One example is the key-value service that is being baked into the otherwise excellent Deno project. Another, more subtle example, comes from Eleventy itself: <a href="https://www.11ty.dev/docs/plugins/edge/"><em>Eleventy Edge</em></a>.</p>
<p>There isn’t anything <em>inherently</em> proprietary about Eleventy Edge. In theory, there are a few “edge computing” services that should be able to support it, but in practice, the company that employed the project lead at the time and the only company actively funding the feature, is going to be the only one whose service is reliably supported.</p>
<p>This is the reason why I’m excited about the partnership between Eleventy and CloudCannon and the project’s refocusing. It isn’t that the project will get simpler to use (though I’d be happy if it does) but the complementary nature of the collaboration creates a dynamic where every part of the project benefits the community as a whole, in a non-extractive way.</p>
<p>The extractive dynamic between a tech company and financially dependent open source projects is incredibly common and few handle it as well as Zach seems to have, both during his time at Netlify, and with the decision now to rejig things. Netlify’s dominance over the project could have been lethal—making it incapable of surviving without Netlify’s financial support.</p>
<p>The transition that’s taking place is because with less money floating around, the tech industry is retrenching and in many cases that means they’re either not funding FLOSS any more or that they’re ramping up their attempts to <a href="https://www.theregister.com/2023/06/23/red_hat_centos_move/">extract value from the community.</a> Companies invest less in FLOSS and want to take more of the value created.</p>
<p>Simultaneously, the increased popularity of language models in software development, themselves a blatant strip-mining of FLOSS code, likely has the effect of deflating the size of the communities themselves. Why use an open source project when you can get a language model that’s trained on that project to rehash it and inject it into your code? Why give somebody credit for the lines of code you’ve adapted for your own project when you can get a language model to whitewash it and let you claim it as your own?</p>
<p>To me, it feels a bit like the relationship between the industry and FLOSS communities has switched from being somewhat productive and occasionally abusive to being outright <em>looting</em>.</p>
<p>Finding partnerships that are genuinely mutually beneficial, which is something I hope Eleventy has managed, is one path out of this. Another is for those working in tech to continue to try and find ways of making community-supported projects more sustainable.</p>
<p>But I’m worried that many free and open source projects, small and large, are about to have a pretty hard time, and with them their communities.</p>
<p>I don’t really know how best to mitigate that, and I’m kind of hoping that my sense of unease is just unfounded.</p>
<h2 id="links">Links</h2>
<h3 id="artificial-intelligence">Artificial Intelligence</h3>
<p><img src="https://cdn.uploads.micro.blog/5097/2023/image.jpg" alt="A phrenology bust that was used by quacks and pseudo scientists to explain human intelligence and behaviour. "></p>
<ul>
<li><a href="https://eschatologist.net/blog/?p=374">​'Eschatology › The “Promise” of “Easier” Programming'​</a>. “It’s like saying we won’t need writing and literature classes any more because spellcheck exists, a category error.”</li>
<li><a href="https://newsletter.mollywhite.net/p/worldcoin-a-solution-in-search-of">​"Worldcoin: a solution in search of its problem"​</a></li>
<li><a href="https://medium.com/@emilymenonbender/ensuring-safe-secure-and-trustworthy-ai-what-those-seven-companies-avoided-committing-to-8c297f9d71a">​'“Ensuring Safe, Secure, and Trustworthy AI”: What those seven companies avoided committing to | by Emily M. Bender'​</a>. “The companies say they’ll try to mitigate some pollution down the road, but do not wish to do anything about the toxic waste they’re currently spewing.”</li>
<li><a href="https://hidde.blog/llms-user-centered/">​'“AI” content and user centered design'​</a>. “There are benefits to one-click-content-creation for organisations. But I don’t see how end users could benefit, at all.”</li>
<li><a href="https://www.disconnect.blog/p/the-chatgpt-revolution-is-another">​"The ChatGPT revolution is another tech fantasy"​</a></li>
</ul>
<h3 id="software-development">Software development</h3>
<ul>
<li><a href="https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/">​"Pull Requests are cake or puppies - Textual"​</a></li>
<li><a href="https://axesslab.com/toggles-suck/">​"Axess Lab | Toggles suck!“​</a></li>
<li><a href="https://web.archive.org/web/20190626023845/http://tech.mit.edu/V105/N16/weisen.16n.html">​"Weizenbaum examines computers and society - The Tech"​</a>. “I think the computer has from the beginning been a fundamentally conservative force. It has made possible the saving of institutions pretty much as they were, which otherwise might have had to be changed.” <em>Must-read of the week.</em> A smart and engaging interview with Weizenbaum of Eliza fame.</li>
<li><a href="https://cacm.acm.org/blogs/blog-cacm/273577-ai-does-not-help-programmers/fulltext">​"AI Does Not Help Programmers"​</a>. “What use do I have for a sloppy assistant? I can be sloppy just by myself, thanks.”</li>
<li><a href="https://adrianroselli.com/2023/07/blockquotes-in-screen-readers.html">​"Blockquotes in Screen Readers — Adrian Roselli"​</a></li>
</ul>
<h3 id="other-reads">Other reads</h3>
<ul>
<li><a href="https://www.thepinknews.com/2023/07/27/tiktok-female-powerlifter-transphobic-attacks/?fbclid=IwAR17G32PpZksFGTVMA0bOI_gRhM3WNOQ2CTLYPxglFeyLelrc62uOAC0gXM">​"Cis woman shares relentless transphobic attacks on her gender"​</a></li>
<li><a href="https://shkspr.mobi/blog/2023/07/shakespeare-serif-a-new-font-based-on-the-first-folio/">​"Shakespeare Serif – an experimental font based on the First Folio – Terence Eden’s Blog"​</a></li>
<li><a href="https://erinkissane.com/mastodon-is-easy-and-fun-except-when-it-isnt">​"Mastodon is easy and fun except when it isn’t - Erin Kissane’s small internet website"​</a></li>
<li><a href="https://www.alexmolas.com/2023/07/15/nobody-cares-about-your-blog.html">​"Nobody cares about your blog.“​</a></li>
<li><a href="https://chocolateandvodka.com/2023/07/26/does-writing-really-have-to-be-so-solitary/">​"Does writing really have to be so solitary? — Chocolate and Vodka"​</a>. I’ve struggled with hyperindependence in the past so I made deliberate effort to break with that and find people to help me out on my ebooks. It’s hard but rewarding.</li>
</ul>
<p><em>The best way to support this blog or my newsletter is to buy one of my books, <a href="https://illusion.baldurbjarnason.com/">The Intelligence Illusion: a practical guide to the business risks of Generative AI</a> or <a href="https://softwarecrisis.baldurbjarnason.com/">Out of the Software Crisis</a>.</em></p>

  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Markwhen: Markdown for Timelines (245 pts)]]></title>
            <link>https://app.markwhen.com</link>
            <guid>36944152</guid>
            <pubDate>Mon, 31 Jul 2023 15:31:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.markwhen.com">https://app.markwhen.com</a>, See on <a href="https://news.ycombinator.com/item?id=36944152">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[BBC on Mastodon: experimenting with distributed and decentralised social media (398 pts)]]></title>
            <link>https://www.bbc.co.uk/rd/blog/2023-07-mastodon-distributed-decentralised-fediverse-activitypub</link>
            <guid>36943866</guid>
            <pubDate>Mon, 31 Jul 2023 15:15:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/rd/blog/2023-07-mastodon-distributed-decentralised-fediverse-activitypub">https://www.bbc.co.uk/rd/blog/2023-07-mastodon-distributed-decentralised-fediverse-activitypub</a>, See on <a href="https://news.ycombinator.com/item?id=36943866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="orb-modules">
      <header>
        <h2><a href="https://www.bbc.co.uk/rd">Research &amp; Development</a></h2>
      </header>
      <nav id="blq-local-nav">
        
        <ul id="nav-site">
          <li id="index-link"><a href="https://www.bbc.co.uk/rd/">Home</a></li>
<li id="about-link"><a href="https://www.bbc.co.uk/rd/about">About</a></li>
<li id="projects-link"><a href="https://www.bbc.co.uk/rd/projects">Projects</a></li>
<li id="publications-link"><a href="https://www.bbc.co.uk/rd/publications">Publications</a></li>
<li id="blog-link"><a href="https://www.bbc.co.uk/rd/blog">Blog</a></li>
<li id="contacts-link"><a href="https://www.bbc.co.uk/rd/contacts">Contact Us</a></li>
<li id="careers-link"><a href="https://www.bbc.co.uk/rd/careers">Careers</a></li>
        </ul>
        <a href="#">More</a>
        <ul id="nav-site-more"></ul>
        <h3>The BBC on Mastodon: experimenting with distributed and decentralised social media</h3>
        <ul id="nav-page">
          






        </ul>
        <a href="#">More</a>
        <ul id="nav-page-more"></ul>
        
      </nav>
      <section>
        
  <article>
    

    <section>
  <p>
    <span>Posted by
      
        
          
        
      
    </span>
    <span>on</span>
    
    
    <span><time datetime="2023-07-31">31 Jul 2023</time></span><span>, last updated
      <time datetime="2023-07-31">31 Jul 2023</time></span>
  </p>
</section>


    
    <section>
      <p>As the social media landscape ebbs and flows, the team at BBC Research &amp; Development are researching social technologies and exploring possibilities for the BBC. One part of our work is to establish a BBC presence in the distributed collection of social networks known as the Fediverse, a collection of social media applications all linked together by common protocols. The most common software used in this area is <a href="https://www.bbc.co.uk/news/technology-63534240">Mastodon</a>, a Twitter-like social networking service with around 2 million active monthly users. We are now running an experimental BBC Mastodon server at <a href="https://social.bbc/">https://social.bbc</a> where you can follow some of the BBC’s social media accounts, including BBC R&amp;D, Radio 4 and 5 Live. We hope to be able to add more accounts from other areas of the BBC at some point.</p>

    </section>
    

    <div>
      
        <p><img sizes="(min-width: 320px) calc(100vw - 16px), (min-width: 480px) calc(100vw - 32px), (min-width: 1008px) 644w, 100vw" srcset="https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiMzA0eDE3MSMiXV0/bbc-mastodon-16x9.png?sha=e0f3da8b463f5d95 304w, https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiNjA4eDM0MiMiXV0/bbc-mastodon-16x9.png?sha=ef7f8af939c5ed3b 608w, https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiNDQ4eDI1MiMiXV0/bbc-mastodon-16x9.png?sha=1ec8d3a922f82367 448w, https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiODk2eDUwNCMiXV0/bbc-mastodon-16x9.png?sha=7fe0cd9b3e03ef51 896w, https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiNjU2eDM2OSMiXV0/bbc-mastodon-16x9.png?sha=c94b78fa668cdd15 656w, https://www.bbc.co.uk/rd/images/dynamic/W1siZmYiLCJwdWJsaWMvcmQvc2l0ZXMvNTAzMzVmZjM3MGI1YzI2MmFmMDAwMDA0L2NvbnRlbnRfZW50cnk1MDRlMTgxNTcwYjVjMjBhMGMwMDEzNDQvNjRjM2ViMTQwNmQ2M2VlZjA5MDAwMjFkL2ZpbGVzL2JiYy1tYXN0b2Rvbi0xNng5LnBuZyJdLFsicCIsInRodW1iIiwiMTI0OHg3MDIjIl1d/bbc-mastodon-16x9.png?sha=e1a9a36db3f8048f 1248w" alt="The BBC on Mastodon: experimenting with distributed and decentralised social media">
        </p>
      
    </div>

    <section>
      
      
        <blockquote>

<p><strong><a href="https://social.bbc/@BBCRD" rel="me">@BBCRD@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBC5Live" rel="me">@BBC5Live@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBCRadio4" rel="me">@BBCRadio4@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBCTaster" rel="me">@BBCTaster@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@Connected_Studio" rel="me">@Connected_Studio@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBC_News_Labs" rel="me">@BBC_News_Labs@social.bbc</a></strong></p>
</blockquote>
<h2>Mastodon and the Fediverse</h2>
<p>Mastodon is a “federated” social network. Federated social networks aren’t controlled by one organisation, <a href="https://en.wikipedia.org/wiki/Distributed_social_network">federation means that anyone can run a server and host users</a> and each server can offer its own moderation and membership rules, but all the servers can connect to each other. This model is more like email where you can email anyone, but as an individual, you choose which email provider you want to use.</p>
<p><img src="https://www.bbc.co.uk/rd/sites/50335ff370b5c262af000004/assets/64c7859d06d63e5047000311/fediverse-overview-16x9.png" alt="An overview illustration titled 'The Many Branches of the Fediverse' - this is a cartoon illustration of a tree, with each of the branches or parts of the tree populated by online services that work in a federated manner. There is a part of the tree for Social Networking containing services like Mastodon, one of the branches is for multimedia and contains services like Peer Tube and Pixelfed, and for writing services like WordPress and Drupal. The roots of the tree contain the ActivityPub protocol, showing that these services are all flowing and are enabled by this."></p>
<p>Federated social networks, or <a href="https://fediverse.info/">the Fediverse</a>, offer a model for future development that aligns with our own work to support a <a href="https://www.bbc.co.uk/rd/projects/public-service-internet">public service internet</a> and <a href="https://www.bbc.co.uk/rd/projects/bbc-box-personal-data-management-privacy">our previous work</a> on <a href="https://www.bbc.co.uk/rd/blog/2022-10-social-tv-and-personal-data">decentralised data</a>. The principles of the Fediverse, with an emphasis on local control, quality content, and social value, are far more aligned with our public purposes than those of avowedly commercial networks like Threads or Twitter. Other public service and non-profit organisations already have a presence there, from <a href="https://social.overheid.nl/@avhuffelen/110700825255524685">the Dutch government</a> to <a href="https://mastodon.social/@wikimediafoundation">Wikimedia</a> to <a href="https://social.network.europa.eu/explore">the EU</a>.</p>
<p><a href="https://social.bbc/">We've set up a Mastodon server for the BBC to publish content in the Fediverse</a>. Initially, our server hosts this selection of BBC social media accounts, where we’ll be publishing content just like we do on other social platforms:</p>
<blockquote>
<p><strong><a href="https://social.bbc/@BBCRD" rel="me">@BBCRD@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBC5Live" rel="me">@BBC5Live@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBCRadio4" rel="me">@BBCRadio4@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBCTaster" rel="me">@BBCTaster@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@Connected_Studio" rel="me">@Connected_Studio@social.bbc</a></strong></p>
<p><strong><a href="https://social.bbc/@BBC_News_Labs" rel="me">@BBC_News_Labs@social.bbc</a></strong></p>
</blockquote>
<p>Unlike most Mastodon servers where you can sign up for a personal account, we're only using this instance to host BBC accounts; it’s a place for us to publish in the Fediverse. If you have a Mastodon (or other ActivityPub) account from another server, then you can easily follow our accounts.</p>
<p>We're using social.bbc as the domain, so you can be sure <a href="https://www.icann.org/en/registry-agreements/details/bbc">these accounts are genuinely from the BBC</a>. And by linking to and from the BBC’s website, <a href="https://joinmastodon.org/verification">we have verified our identity on Mastodon</a>.</p>
<h2>Challenges</h2>
<p>As a large, high profile, public service organisation, we've had to work through a fair number of issues to get this far and we’ve had advice and support from several teams across the BBC.</p>
<p>Explaining the federated model can be a challenge as people are much more familiar with the centralised model of ownership. We’ve had to answer questions like “Are we running our own social network?” (well, we’re kind of hosting a small section of a social network) and “Are we hosting a user’s content?” (well, we don’t allow users to create accounts or post from our server, but they can reply to our posts from their own servers, and then their posts will appear next to ours and then they might be stored on our server and it all gets quite complicated).</p>
<p>The latter question leads on to moderation. Although we will only host BBC accounts, there will be replies from other people to our posts. What is our responsibility for moderation here? When the BBC hosts comments on our own website, as on some of our news and sports stories, <a href="https://www.bbc.com/editorialguidelines/guidelines/competitions-votes-interactivity/guidelines#commentandmoderation">we moderate these according to our guidelines</a>. Where we post on third-party social media platforms we will keep an eye on any replies and take appropriate action where necessary (such as reporting a comment to the third-party) but we also expect the third-party to have some centralised moderation in place. Because it is a decentralised service, there is no central Mastodon moderation team that we can point to, instead all Mastodon servers are responsible for their own moderation. Mastodon allows the administrators to add a content warning, remove posts, or even block all posts from another server, and many instances are effective in moderating troublesome content from their users. We think this is an acceptable risk and will apply <a href="https://www.bbc.co.uk/usingthebbc/terms/what-are-the-rules-for-commenting/">the BBC’s social media moderation rules to any replies to our posts where we can</a>.</p>
<p>You might be able to see from the above why we chose to make this a BBC-only server and not host user accounts.</p>
<h2>An experiment</h2>
<p>This is an experiment - we will run it for 6 months and then decide whether and how to continue.</p>
<p>We aim to learn how much value it has provided and how much work and cost is involved. Does it reach enough people for the effort we need to put in? Are there risks or benefits from the federated model, with no centralised rules or moderation and no filtering or sorting algorithms? We're learning as we go, and we'll write about what we discover in the hope that it might be useful for others. The BBC will continue its other social media activity in the usual places.</p>
<p>Looking ahead, could we move beyond Mastodon to other ActivityPub applications for publishing content? And would this provide us with some insulation from the risks that might be created as other social media platforms continue to change and evolve? And will large, planet-scale social media platforms persist or are they gradually disappearing? What are the alternatives and what will we have in 10 years time?</p>
<p>If you have a Mastodon account already, then please follow us -&nbsp;<a href="https://social.bbc/@BBCRD">https://social.bbc/@BBCRD</a>&nbsp;- and let us know what you think. If you don’t, then you can <a href="https://joinmastodon.org/">learn more about joining Mastodon</a>.</p>
      
    </section>

    <!-- Sections -->
    

    <!-- Topics -->
    
      <section id="topics">
        <h2>Topics</h2>
        <ul>
          
            <li><a href="https://www.bbc.co.uk/rd/topics/content-formats">Content Formats</a></li>
          
        </ul>
      </section>
    
  </article>

  

      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SEC Charges Hex Founder Richard Heart with Misappropriating Millions of Dollars (162 pts)]]></title>
            <link>https://www.sec.gov/news/press-release/2023-143</link>
            <guid>36943495</guid>
            <pubDate>Mon, 31 Jul 2023 14:53:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sec.gov/news/press-release/2023-143">https://www.sec.gov/news/press-release/2023-143</a>, See on <a href="https://news.ycombinator.com/item?id=36943495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Securities and Exchange Commission today charged Richard Heart (aka Richard Schueler) and three unincorporated entities that he controls, Hex, PulseChain, and PulseX, with conducting unregistered offerings of crypto asset securities that raised more than $1 billion in crypto assets from investors. The SEC also charged Heart and PulseChain with fraud for misappropriating at least $12 million of offering proceeds to purchase luxury goods including sports cars, watches, and a 555-carat black diamond known as ‘The Enigma’ – reportedly the largest black diamond in the world.</p>

<p>According to the SEC’s complaint, Heart began marketing Hex in 2018, claiming it was the first high-yield “blockchain certificate of deposit,” and began promoting Hex tokens as an investment designed to make people “rich.” From at least December 2019 through November 2020, Heart and Hex allegedly offered and sold Hex tokens in an unregistered offering, collecting more than 2.3 million Ethereum (ETH), including through so-called “recycling” transactions that enabled Heart to surreptitiously gain control of more Hex tokens. The complaint also alleges that, between at least July 2021 and March 2022, Heart orchestrated two additional unregistered crypto asset security offerings that each raised hundreds of millions of dollars more in crypto assets. As alleged, those funds were intended to support development of a supposed crypto asset network, PulseChain, and a claimed crypto asset trading platform, PulseX, through the offerings of their native tokens, respectively, PLS and PLSX. Heart also allegedly designed and marketed a so-called “staking” feature for Hex tokens, which he claimed would deliver returns as high as 38 percent. The complaint further alleges that Heart attempted to evade securities laws by calling on investors to “sacrifice” (instead of “invest”) their crypto assets in exchange for PLS and PLSX tokens.</p>

<p>“Heart called on investors to buy crypto asset securities in offerings that he failed to register. He then defrauded those investors by spending some of their crypto assets on exorbitant luxury goods,” said Eric Werner, Director of the Fort Worth Regional Office. “This action seeks to protect the investing public and hold Heart accountable for his actions.”</p>

<p>The SEC’s complaint, filed in U.S. District Court for the Eastern District of New York, alleges that Heart, Hex, PulseChain, and PulseX violated the registration provisions of Section 5 of the Securities Act of 1933. The complaint also alleges that Heart and PulseChain violated the antifraud provisions of the federal securities laws. The complaint seeks injunctive relief, disgorgement of ill-gotten gains plus prejudgment interest, penalties, and other equitable relief.</p>

<p>The SEC’s continuing investigation is being conducted by Jaime Marinaro and Derek Kleinmann of the Fort Worth Regional Office, with assistance from Jamie Haussecker. The investigation is supervised by Sarah S. Mallett and Eric Werner of the Fort Worth Regional Office and by Jorge G. Tenreiro and David Hirsch of the Crypto Assets and Cyber Unit. The litigation will be conducted by Matthew J. Gulde and supervised by B. David Fraser.</p>

<p>If you are an investor in Hex, PulseChain, or PulseX, or if you have information related to this investigation and you wish to contact the SEC staff, please submit a tip at <a href="https://www.sec.gov/tcr">SEC.gov | Report Suspected Securities Fraud or Wrongdoing</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Investors are happy to pay premium for tech, but not for AI (154 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-07-31/investors-are-happy-to-pay-premium-for-tech-but-not-for-ai</link>
            <guid>36943415</guid>
            <pubDate>Mon, 31 Jul 2023 14:48:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-07-31/investors-are-happy-to-pay-premium-for-tech-but-not-for-ai">https://www.bloomberg.com/news/articles/2023-07-31/investors-are-happy-to-pay-premium-for-tech-but-not-for-ai</a>, See on <a href="https://news.ycombinator.com/item?id=36943415">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[99-year old trucking company Yellow shuts down, putting 30k out of work (106 pts)]]></title>
            <link>https://www.cnn.com/2023/07/31/business/yellow-corp-closing/index.html</link>
            <guid>36943372</guid>
            <pubDate>Mon, 31 Jul 2023 14:45:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/07/31/business/yellow-corp-closing/index.html">https://www.cnn.com/2023/07/31/business/yellow-corp-closing/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=36943372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/lede-4602aa45c0b3561b1966345eefcab01e@published" data-name="01 yellow trucking 062823" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6505" data-original-height="1301" data-original-width="2000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230730180409-01-yellow-trucking-062823.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230730180409-01-yellow-trucking-062823.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230730180409-01-yellow-trucking-062823.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230730180409-01-yellow-trucking-062823.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/230730180409-01-yellow-trucking-062823.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="Yellow Corp. trailers sit at a terminal in Florida on Friday. " onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1301" width="2000"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">New York</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F2C6D943-149E-56BC-2BA2-A8E665B22725@published" data-editable="text" data-component-name="paragraph">
      Yellow Corp., a 99-year-old trucking company that was once a dominant player in its field, halted operations Sunday and will lay off all 30,000 of its workers.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_9BB5C57B-A8BE-5DB2-8D35-A8CCF373596E@published" data-editable="text" data-component-name="paragraph">
      The unionized company has been in a battle with the Teamsters union, which represents about 22,000 drivers and dock workers at the company. Just a week ago the union canceled a threatened strike that had been prompted by the company failing to contribute to its pension and health insurance plans. The union granted the company an extra month to make the required payments. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_66E0A02A-ED9B-F93F-DB1B-A8ED1892719F@published" data-editable="text" data-component-name="paragraph">
      But by midweek last week, the company had stopped picking up freight from its customers and was making deliveries only of freight already in its system, according to both the union and Satish Jindel, a trucking industry consultant.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_80AB83CE-63C8-24E7-D2C7-A8E3714F334F@published" data-editable="text" data-component-name="paragraph">
      While the union agreed not to go on strike against Yellow, it could not reach an agreement on a new contract with the trucking company, according to a memo sent to local unions Thursday by the Teamsters’ negotiating committee. The union said early Monday that it had been notified of the shutdown.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_2DF655CA-60EE-6BAA-0EC3-AB6CFCB0481E@published" data-editable="text" data-component-name="paragraph">
      “Today’s news is unfortunate but not surprising. Yellow has historically proven that it could not manage itself despite billions of dollars in worker concessions and hundreds of millions in bailout funding from the federal government. This is a sad day for workers and the American freight industry,” said Teamsters President Sean O’Brien in a statement.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_BFA0CBB7-846C-7BF2-E69E-AB6D506E1793@published" data-editable="text" data-component-name="paragraph">
      Company officials did not respond to numerous requests for comment Sunday and Monday. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_FC5F5833-452D-2BCB-09F6-ACBF740C42E4@published" data-editable="text" data-component-name="paragraph">
      While the company is based in Nashville, Tennessee, it is a national company with terminals and employees spread between more than 300 terminals nationwide.<strong> </strong>Experts in the field said it was primarily an unaffordable amount of debt, more than the cost of the union contract, that did in Yellow.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_01E1D53D-0C65-CACD-B96D-AC94EF3A673F@published" data-editable="text" data-component-name="paragraph">
      “The Teamsters had made a series of painful concessions that brought them close to wage parity with nonunion carriers,” said Tom Nightingale, CEO of AFS Logistics, a third-party logistics firm that places about $11 billion worth of freight annually with different trucking companies on behalf of shippers. He said the company began taking on significant amount of debt 20 years ago in order to acquire other trucking companies.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_63FF7CE3-4F81-B367-9881-AC983C4B7311@published" data-editable="text" data-component-name="paragraph">
      “Now their debt service is just enormous,” he said, pointing to $1.5 billion in debt on its books.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F0B56A9D-F9AE-C18D-30F8-AC9C5C720C57@published" data-editable="text" data-component-name="paragraph">
      There are two other national competitors in Yellow’s segment of the trucking market which are also unionized, ABF Freight and TForce. Both were far more profitable in recent years than Yellow, which posted only a narrow operating profit in 2021 and 2022 and a $9.3 million operating loss in the first quarter.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_46F1E116-2753-BB60-9E5D-A8D026BD3F85@published" data-editable="text" data-component-name="paragraph">
      There were reports last week that <a href="http://www.cnn.com/2023/07/27/business/yellow-corp-bankruptcy/index.html" target="_blank">a bankruptcy filing</a> would come by July 31, although the company said last week only that it continued to be in talks with the Teamsters and that it was considering all of its options. The Teamsters said Monday the company is filing for bankruptcy.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_B52A4761-1823-8285-7C00-A8E5E5B53A69@published" data-editable="text" data-component-name="paragraph">
      The closing is bad news not only for its employees and its customers, who generally used Yellow because it offered some of the cheapest rates in the trucking sector, but also for US taxpayers. The company received a $700 million loan from the federal government in 2020, a loan that resulted in taxpayers holding 30% of its outstanding stock. And the company still owed the Treasury department more than $700 million according to its most recently quarterly report, nearly half of the long-term debt on its books.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_AFF8EE39-7537-0628-7F80-A8DBE2871760@published" data-editable="text" data-component-name="paragraph">
      Yellow’s stock lost 82% of its  value between the time of that loan and Thursday close after reports of the bankruptcy plans, closing at only 57 cents a share. It bumped up 14 cents a share on Friday, but still remained a so-called penny stock.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_D1A25705-274D-60A8-4978-A8DBAE8D8AD5@published" data-editable="text" data-component-name="paragraph">
      The company had received that <a href="https://www.cnn.com/2020/07/01/business/yrc-federal-loan/index.html" target="_blank">loan</a> during the pandemic, despite the fact that at the time it was facing charges of defrauding the government by overbilling on shipments of items for the US military. The company eventually settled the dispute without admitting wrongdoing but was forced to pay a $6.85 million fine. 
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_CE6F308E-140E-0B62-8E96-A8DCB531160E@published" data-editable="text" data-component-name="paragraph">
      Yellow handles pallet-sized shipments of freight, moving shipments from numerous customers in the same truck, a segment of the trucking industry known as less-than-truckload, or LTL. The company had been claiming as recently as June that it was the nation’s third largest LTL carrier.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_1B78F2A4-1D66-BA28-1DAE-A8DE89BBDBBF@published" data-editable="text" data-component-name="paragraph">
      But the company handled only about 7% of the nation’s 720,000 daily LTL shipments last year, said Jindel. He said there is about 8% to 10% excess capacity in the LTL sector right now, so the closure of Yellow shouldn’t cause a significant disruption in supply chains. But he said it will cause higher rates for shippers who depend on LTL carriers, since it was the excess capacity that sent prices lower.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_12794F88-8F86-6E14-7AFA-A8DEC7AD60D8@published" data-editable="text" data-component-name="paragraph">
      Higher prices will hit Yellow customers, Jindel said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_6699ED73-D9B0-E40B-84FD-A8DEC7AD3FC7@published" data-editable="text" data-component-name="paragraph">
      “The reason they were using Yellow was because they were cheap,” he said. “They’re finding out that price was below the cost of supporting a good operation.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_B6AF5876-DE05-F785-3DA7-AC9961E5BA40@published" data-editable="text" data-component-name="paragraph">
      While the <a href="http://www.cnn.com/2023/07/27/economy/second-quarter-gdp/index.html" target="_blank">US economy has remained strong</a>, spending by consumers has been shifting in recent years from the goods they were buying in 2020 and early 2021 when they were still stuck close to home due to the pandemic, to services, such as plane tickets and other experiences that don’t need to move by truck. Nightingale said industrywide LTL shipments fell 17% between 2021 and 2022, and another 5% in the first quarter compared to the first quarter a year earlier.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0C14840F-AB0C-2E09-5EDA-AC9BDA13D8F0@published" data-editable="text" data-component-name="paragraph">
      He said that while Yellow could be profitable when demand for trucking was strong, it couldn’t get by in the face of the slowdown in freight, and the drop in trucking rates that went with it. Shippers worried about Yellow’s future started shifting to other carriers, as its shipments fell 13% in the first quarter compared a year earlier.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0AFDBC24-6FFE-C15D-633D-ACA2DE7053F4@published" data-editable="text" data-component-name="paragraph">
      “It’s what Warren Buffett says, when the tide goes out you discover who’s been swimming naked,” Nightingale said.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_73AF6B10-B721-2001-48F0-ABBD256E2EFF@published" data-editable="text" data-component-name="paragraph">
      When the trucking industry was deregulated nearly 40 years ago, the segment of the industry that handled full trailers of cargo, known as truckload, soon was dominated by non-union trucking companies. The only thing low-cost competitors needed to enter that segment of the industry was a truck.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_61193841-BD3A-3855-7149-ABBD275838A2@published" data-editable="text" data-component-name="paragraph">
      But the LTL segment requires a network of terminals to sort incoming and outgoing freight. That limited, but did not prevent, the entry of low-cost competitors. So unionized carriers such as Yellow continued to be major players, even as non-union rivals grew.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_6E4FF6E9-A2B2-12CE-9E77-ABBD275A8C60@published" data-editable="text" data-component-name="paragraph">
      Eventually non-union carriers came to dominate the LTL segment as well. By early in this century, many of the remaining unionized LTL carriers, including Yellow and rivals such as Roadway Express, New Penn and Holland, merged to survive.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_6C9E526F-9A52-6BE3-597F-ABBD275BB965@published" data-editable="text" data-component-name="paragraph">
      Yellow, Roadway and a third company known as CF or Consolidated Freightways had once been known as the Big Three of the trucking industry. CF went out of business in 2002. And with Yellow Corp. closing, the final two parts of the Big Three are now out of business as well.
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparison of vector databases (122 pts)]]></title>
            <link>https://navidre.medium.com/which-vector-database-should-i-use-a-comparison-cheatsheet-cb330e55fca</link>
            <guid>36943318</guid>
            <pubDate>Mon, 31 Jul 2023 14:42:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://navidre.medium.com/which-vector-database-should-i-use-a-comparison-cheatsheet-cb330e55fca">https://navidre.medium.com/which-vector-database-should-i-use-a-comparison-cheatsheet-cb330e55fca</a>, See on <a href="https://news.ycombinator.com/item?id=36943318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="52d4">The comparison table is as follows. It is not a comprehensive comparison and may have errors. Please let me know if anything needs to be updated. Last update: Jul. 30, 2023.</p><p id="25fe">Vector databases compared are: <a href="https://weaviate.io/" rel="noopener ugc nofollow" target="_blank">Weaviate</a>, <a href="https://www.pinecone.io/" rel="noopener ugc nofollow" target="_blank">Pinecone</a>, <a href="https://github.com/pgvector/pgvector" rel="noopener ugc nofollow" target="_blank">pgvector</a>, <a href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank">Milvus</a>, <a href="https://www.mongodb.com/" rel="noopener ugc nofollow" target="_blank">MongoDB</a>, <a href="https://qdrant.tech/" rel="noopener ugc nofollow" target="_blank">Qdrant</a>, and <a href="https://www.trychroma.com/" rel="noopener ugc nofollow" target="_blank">Chroma</a>. The benchmark data is from <a href="https://ann-benchmarks.com/" rel="noopener ugc nofollow" target="_blank">ANN Benchmarks</a>.</p><p id="fabf">The comparison is not exhaustive, I am sharing this Google Sheet so that others could contribute too: <a href="https://docs.google.com/spreadsheets/d/1oAeF4Q7ILxxfInGJ8vTsBck3-2U9VV8idDf3hJOozNw/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://docs.google.com/spreadsheets/d/1oAeF4Q7ILxxfInGJ8vTsBck3-2U9VV8idDf3hJOozNw/edit?usp=sharing</a>.</p><figure></figure><h2 id="95f6">Discussion</h2><p id="1c1d">Choosing a database to store vector formats is an important decision that can affect your architecture, compliance, and future costs. There have been many vector database solutions recently, but they require that you maintain the embeddings independent of the original database.</p><p id="e84d">Another solution is to store the embeddings where your data already resides. This way, the complexity of the architecture is reduced, and you will not have extra compliance concerns. Last but not least, it seems to be a cost-effective solution.</p><p id="4363">Choosing between these two categories, new vector database or vector search in current database, is a decision that depends on application-specific factors.</p><p id="3469">Please follow me on Medium or social media to keep in contact:</p><p id="f768"><a href="https://twitter.com/navid_re" rel="noopener ugc nofollow" target="_blank">Twitter</a> | <a href="https://www.linkedin.com/in/navidrezaei/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> | <a href="https://medium.com/@navidre" rel="noopener">Medium</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[USearch: Smaller and faster single-file vector search engine (123 pts)]]></title>
            <link>https://unum-cloud.github.io/usearch/</link>
            <guid>36942993</guid>
            <pubDate>Mon, 31 Jul 2023 14:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unum-cloud.github.io/usearch/">https://unum-cloud.github.io/usearch/</a>, See on <a href="https://news.ycombinator.com/item?id=36942993">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="main">
          <section id="overview">
<h2>Overview<a href="#overview" title="Permalink to this heading">#</a></h2>

<h3>
Smaller &amp; Faster Single-File<br>
Vector Search Engine<br>
</h3>
<span><br></span>
<p>
<a href="https://discord.gg/A6wxt6dS9j"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/discord.svg" alt="Discord"></a>
&nbsp;&nbsp;&nbsp;
<a href="https://www.linkedin.com/company/unum-cloud/"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/linkedin.svg" alt="LinkedIn"></a>
&nbsp;&nbsp;&nbsp;
<a href="https://twitter.com/unum_cloud"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/twitter.svg" alt="Twitter"></a>
&nbsp;&nbsp;&nbsp;
<a href="https://unum.cloud/post"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/blog.svg" alt="Blog"></a>
&nbsp;&nbsp;&nbsp;
<a href="https://github.com/unum-cloud/usearch"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/github.svg" alt="GitHub"></a>
</p><p>
Euclidean • Angular • Jaccard • Hamming • Haversine • User-Defined Metrics
<br>
<a href="https://unum-cloud.github.io/usearch/cpp">C++11</a> •
<a href="https://unum-cloud.github.io/usearch/python">Python</a> •
<a href="https://unum-cloud.github.io/usearch/javascript">JavaScript</a> •
<a href="https://unum-cloud.github.io/usearch/java">Java</a> •
<a href="https://unum-cloud.github.io/usearch/rust">Rust</a> •
<a href="https://unum-cloud.github.io/usearch/c">C99</a> •
<a href="https://unum-cloud.github.io/usearch/objective-c">Objective-C</a> •
<a href="https://unum-cloud.github.io/usearch/swift">Swift</a> •
<a href="https://unum-cloud.github.io/usearch/golang">GoLang</a> •
<a href="https://unum-cloud.github.io/usearch/wolfram">Wolfram</a>
<br>
Linux • MacOS • Windows • Docker • WebAssembly
</p><hr>
<ul>
<li><p>✅ Benchmark-topping performance.</p></li>
<li><p>✅ Simple and extensible <a href="https://github.com/unum-cloud/usearch/blob/main/include/usearch/index.hpp">single C++11 header</a> implementation.</p></li>
<li><p>✅ SIMD-optimized and <a href="#user-defined-functions">user-defined metrics</a> with JIT-compilation.</p></li>
<li><p>✅ Variable dimensionality vectors for unique applications, including search over compressed data.</p></li>
<li><p>✅ Bitwise Tanimoto and Sorensen coefficients for <a href="#usearch--rdkit--molecular-search">Genomics and Chemistry applications</a>.</p></li>
<li><p>✅ Hardware-agmostic <code><span>f16</span></code> &amp; <code><span>f8</span></code> - <a href="#memory-efficiency-downcasting-and-quantization">half-precision &amp; quarter-precision support</a>.</p></li>
<li><p>✅ <a href="#disk-based-indexes">View large indexes from disk</a> without loading into RAM.</p></li>
<li><p>✅ Space-efficient point-clouds with <code><span>uint40_t</span></code>, accommodating 4B+ size.</p></li>
<li><p>✅ Compatible with OpenMP and custom “executors”, for fine-grained control over CPU utilization.</p></li>
<li><p>✅ Supports multiple vectors per label.</p></li>
<li><p>✅ On-the-fly deletions.</p></li>
<li><p>✅ <a href="#usearch--ai--multi-modal-semantic-search">Semantic Search</a> and <a href="#joins">Joins</a>.</p></li>
</ul>
<section id="comparison-with-faiss">
<h2>Comparison with FAISS<a href="#comparison-with-faiss" title="Permalink to this heading">#</a></h2>
<p>FAISS is a widely recognized standard for high-performance vector search engines.
USearch and FAISS both employ the same HNSW algorithm, but they differ significantly in their design principles.
USearch is compact and broadly compatible without sacrificing performance, with a primary focus on user-defined metrics and fewer dependencies.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>FAISS</p></th>
<th><p>USearch</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Implementation</p></td>
<td><p>84 K <a href="https://en.wikipedia.org/wiki/Source_lines_of_code">SLOC</a> in <code><span>faiss/</span></code></p></td>
<td><p>3 K <a href="https://en.wikipedia.org/wiki/Source_lines_of_code">SLOC</a> in <code><span>usearch/</span></code></p></td>
</tr>
<tr><td><p>Supported metrics</p></td>
<td><p>9 fixed metrics</p></td>
<td><p>Any User-Defined metrics</p></td>
</tr>
<tr><td><p>Supported ID types</p></td>
<td><p><code><span>uint32_t</span></code>, <code><span>uint64_t</span></code></p></td>
<td><p><code><span>uint32_t</span></code>, <code><span>uint40_t</span></code>, <code><span>uint64_t</span></code></p></td>
</tr>
<tr><td><p>Dependencies</p></td>
<td><p>BLAS, OpenMP</p></td>
<td><p>None</p></td>
</tr>
<tr><td><p>Bindings</p></td>
<td><p>SWIG</p></td>
<td><p>Native</p></td>
</tr>
<tr><td><p>Acceleration</p></td>
<td><p>Learned Quantization</p></td>
<td><p>Downcasting</p></td>
</tr>
</tbody>
</table>
</div>
<p>Base functionality is identical to FAISS, and the interface must be familiar if you have ever investigated Approximate Nearest Neigbors search:</p>
<div><pre><span></span>$ pip install usearch numpy

import numpy as np
from usearch.index import Index

index = Index(
    ndim=3, # Define the number of dimensions in input vectors
    metric='cos', # Choose 'l2sq', 'haversine' or other metric, default = 'ip'
    dtype='f32', # Quantize to 'f16' or 'f8' if needed, default = 'f32'
    connectivity=16, # Optional: How frequent should the connections in the graph be
    expansion_add=128, # Optional: Control the recall of indexing
    expansion_search=64, # Optional: Control the quality of search
)

vector = np.array([0.2, 0.6, 0.4])
index.add(42, vector)
matches, distances, count = index.search(vector, 10)

assert len(index) == 1
assert count == 1
assert matches[0] == 42
assert distances[0] &lt;= 0.001
assert np.allclose(index[42], vector)
</pre></div>
</section>
<section id="user-defined-functions">
<h2>User-Defined Functions<a href="#user-defined-functions" title="Permalink to this heading">#</a></h2>
<p>While most vector search packages concentrate on just a couple of metrics - “Inner Product distance” and “Euclidean distance,” USearch extends this list to include any user-defined metrics.
This flexibility allows you to customize your search for a myriad of applications, from computing geo-spatial coordinates with the rare <a href="https://ashvardanian.com/posts/abusing-vector-search#geo-spatial-indexing">Haversine</a> distance to creating custom metrics for composite embeddings from multiple AI models.</p>
<a href="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-approaches-white.png?raw=true"><img alt="USearch: Vector Search Approaches" src="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-approaches-white.png?raw=true"></a>
<p>Unlike older approaches indexing high-dimensional spaces, like KD-Trees and Locality Sensitive Hashing, HNSW doesn’t require vectors to be identical in length.
They only have to be comparable.
So you can apply it in <a href="https://ashvardanian.com/posts/abusing-vector-search">obscure</a> applications, like searching for similar sets or fuzzy text matching, using <a href="https://twitter.com/LukeGessler/status/1679211291292889100?s=20">GZip</a> as a distance function.</p>
<blockquote>
<p>Read more about <a href="#id5"><span id="id6">`JIT and UDF in USearch Python SDK &lt;&gt;`_</span></a>.</p></blockquote>
</section>
<section id="memory-efficiency-downcasting-and-quantization">
<h2>Memory Efficiency, Downcasting, and Quantization<a href="#memory-efficiency-downcasting-and-quantization" title="Permalink to this heading">#</a></h2>
<p>Training a quantization model and dimension-reduction is a common approach to accelerate vector search.
Those, however, are only sometimes reliable, can significantly affect the statistical properties of your data, and require regular adjustments if your distribution shifts.</p>
<a href="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-neighbor-types.png?raw=true"><img alt="USearch uint40_t support" src="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-neighbor-types.png?raw=true"></a>
<p>Instead, we have focused on high-precision arithmetic over low-precision downcasted vectors.
The same index, and <code><span>add</span></code> and <code><span>search</span></code> operations will automatically down-cast or up-cast between <code><span>f32_t</span></code>, <code><span>f16_t</span></code>, <code><span>f64_t</span></code>, and <code><span>f8_t</span></code> representations, even if the hardware doesn’t natively support it.
Continuing the topic of memory-efficiency, we provide a <code><span>uint40_t</span></code> to allow collection with over 4B+ vectors without allocating 8 bytes for every neighbor reference in the proximity graph.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>FAISS, <code><span>f32</span></code></p></th>
<th><p>USearch, <code><span>f32</span></code></p></th>
<th><p>USearch, <code><span>f16</span></code></p></th>
<th><p>USearch, <code><span>f8</span></code></p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Batch Insert</p></td>
<td><p>16 K/s</p></td>
<td><p>73 K/s</p></td>
<td><p>100 K/s</p></td>
<td><p>104 K/s <strong>+550%</strong></p></td>
</tr>
<tr><td><p>Batch Search</p></td>
<td><p>82 K/s</p></td>
<td><p>103 K/s</p></td>
<td><p>113 K/s</p></td>
<td><p>134 K/s <strong>+63%</strong></p></td>
</tr>
<tr><td><p>Bulk Insert</p></td>
<td><p>76 K/s</p></td>
<td><p>105 K/s</p></td>
<td><p>115 K/s</p></td>
<td><p>202 K/s <strong>+165%</strong></p></td>
</tr>
<tr><td><p>Bulk Search</p></td>
<td><p>118 K/s</p></td>
<td><p>174 K/s</p></td>
<td><p>173 K/s</p></td>
<td><p>304 K/s <strong>+157%</strong></p></td>
</tr>
<tr><td><p>Recall @ 10</p></td>
<td><p>99%</p></td>
<td><p>99.2%</p></td>
<td><p>99.1%</p></td>
<td><p>99.2%</p></td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Dataset: 1M vectors sample of the Deep1B dataset.
Hardware: <code><span>c7g.metal</span></code> AWS instance with 64 cores and DDR5 memory.
HNSW was configured with identical hyper-parameters:
connectivity <code><span>M=16</span></code>,
expansion @ construction <code><span>efConstruction=128</span></code>,
and expansion @ search <code><span>ef=64</span></code>.
Batch size is 256.
Both libraries were compiled for the target architecture.
Jump to the <a href="https://github.com/unum-cloud/usearch/blob/main/docs/benchmarks.md">Performance Tuning</a> section to read about the effects of those hyper-parameters.</p></blockquote>
</section>
<section id="disk-based-indexes">
<h2>Disk-based Indexes<a href="#disk-based-indexes" title="Permalink to this heading">#</a></h2>
<p>With USearch, you can serve indexes from external memory, enabling you to optimize your server choices for indexing speed and serving costs.
This can result in <strong>20x costs reduction</strong> on AWS and other public clouds.</p>
<div><pre><span></span><span>index</span><span>.</span><span>save</span><span>(</span><span>"index.usearch"</span><span>)</span>

<span>loaded_copy</span> <span>=</span> <span>index</span><span>.</span><span>load</span><span>(</span><span>"index.usearch"</span><span>)</span>
<span>view</span> <span>=</span> <span>Index</span><span>.</span><span>restore</span><span>(</span><span>"index.usearch"</span><span>,</span> <span>view</span><span>=</span><span>True</span><span>)</span>

<span>other_view</span> <span>=</span> <span>Index</span><span>(</span><span>ndim</span><span>=...</span><span>,</span> <span>metric</span><span>=</span><span>CompiledMetric</span><span>(</span><span>...</span><span>))</span>
<span>other_view</span><span>.</span><span>view</span><span>(</span><span>"index.usearch"</span><span>)</span>
</pre></div>
</section>
<section id="id2">
<h2>Joins<a href="#id2" title="Permalink to this heading">#</a></h2>
<p>One of the big questions these days is how will AI change the world of databases and data-management?
Most databases are still struggling to implement high-quality fuzzy search, and the only kind of joins they know are deterministic.
A <code><span>join</span></code> is different from searching for every entry, as it requires a one-to-one mapping, banning collisions among separate search results.</p>
<div>
<table>
<thead>
<tr><th><p>Exact Search</p></th>
<th><p>Fuzzy Search</p></th>
<th><p>Semantic Search ?</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Exact Join</p></td>
<td><p>Fuzzy Join ?</p></td>
<td><p>Semantic Join ??</p></td>
</tr>
</tbody>
</table>
</div>
<p>Using USearch one can implement sub-quadratic complexity approximate, fuzzy, and semantic joins.
This can come handy in any fuzzy-matching tasks, common to Database Management Software.</p>
<div><pre><span></span><span>men</span> <span>=</span> <span>Index</span><span>(</span><span>...</span><span>)</span>
<span>women</span> <span>=</span> <span>Index</span><span>(</span><span>...</span><span>)</span>
<span>pairs</span><span>:</span> <span>dict</span> <span>=</span> <span>men</span><span>.</span><span>join</span><span>(</span><span>women</span><span>,</span> <span>max_proposals</span><span>=</span><span>0</span><span>,</span> <span>exact</span><span>=</span><span>False</span><span>)</span>
</pre></div>
<blockquote>
</blockquote>
</section>
<section id="functionality">
<h2>Functionality<a href="#functionality" title="Permalink to this heading">#</a></h2>
<p>By now, core functionality is supported across all bindings.
Broader functionality is ported per request.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>C++</p></th>
<th><p>Python</p></th>
<th><p>Java</p></th>
<th><p>JavaScript</p></th>
<th><p>Rust</p></th>
<th><p>GoLang</p></th>
<th><p>Swift</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>add/search/remove</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr><td><p>save/load/view</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr><td><p>join</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>user-defiend metrics</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>variable-length vectors</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>4B+ capacities</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="application-examples">
<h2>Application Examples<a href="#application-examples" title="Permalink to this heading">#</a></h2>
<section id="usearch-ai-multi-modal-semantic-search">
<h3>USearch + AI = Multi-Modal Semantic Search<a href="#usearch-ai-multi-modal-semantic-search" title="Permalink to this heading">#</a></h3>
<p>AI has a growing number of applications, but one of the coolest classic ideas is to use it for Semantic Search.
One can take an encoder model, like the multi-modal UForm, and a web-programming framework, like UCall, and build a text-to-image search platform in just 20 lines of Python.</p>
<div><pre><span></span><span>import</span> <span>ucall</span>
<span>import</span> <span>uform</span>
<span>import</span> <span>usearch</span>

<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>PIL</span> <span>as</span> <span>pil</span>

<span>server</span> <span>=</span> <span>ucall</span><span>.</span><span>Server</span><span>()</span>
<span>model</span> <span>=</span> <span>uform</span><span>.</span><span>get_model</span><span>(</span><span>'unum-cloud/uform-vl-multilingual'</span><span>)</span>
<span>index</span> <span>=</span> <span>usearch</span><span>.</span><span>index</span><span>.</span><span>Index</span><span>(</span><span>ndim</span><span>=</span><span>256</span><span>)</span>

<span>@server</span>
<span>def</span> <span>add</span><span>(</span><span>label</span><span>:</span> <span>int</span><span>,</span> <span>photo</span><span>:</span> <span>pil</span><span>.</span><span>Image</span><span>.</span><span>Image</span><span>):</span>
    <span>image</span> <span>=</span> <span>model</span><span>.</span><span>preprocess_image</span><span>(</span><span>photo</span><span>)</span>
    <span>vector</span> <span>=</span> <span>model</span><span>.</span><span>encode_image</span><span>(</span><span>image</span><span>)</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>()</span>
    <span>index</span><span>.</span><span>add</span><span>(</span><span>label</span><span>,</span> <span>vector</span><span>.</span><span>flatten</span><span>(),</span> <span>copy</span><span>=</span><span>True</span><span>)</span>

<span>@server</span>
<span>def</span> <span>search</span><span>(</span><span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>np</span><span>.</span><span>ndarray</span><span>:</span>
    <span>tokens</span> <span>=</span> <span>model</span><span>.</span><span>preprocess_text</span><span>(</span><span>query</span><span>)</span>
    <span>vector</span> <span>=</span> <span>model</span><span>.</span><span>encode_text</span><span>(</span><span>tokens</span><span>)</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>()</span>
    <span>matches</span> <span>=</span> <span>index</span><span>.</span><span>search</span><span>(</span><span>vector</span><span>.</span><span>flatten</span><span>(),</span> <span>3</span><span>)</span>
    <span>return</span> <span>matches</span><span>.</span><span>labels</span>

<span>server</span><span>.</span><span>run</span><span>()</span>
</pre></div>
<p>We have pre-processed some commonly used datasets, cleaning the images, producing the vectors, and pre-building the index.</p>

</section>
<section id="usearch-rdkit-molecular-search">
<h3>USearch + RDKit = Molecular Search<a href="#usearch-rdkit-molecular-search" title="Permalink to this heading">#</a></h3>
<p>Comparing molecule graphs and searching for similar structures is expensive and slow.
It can be seen as a special case of the NP-Complete Subgraph Isomorphism problem.
Luckily, domain-specific approximate methods exists.
The one commonly used in Chemistry, is to generate structures from <a href="https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system">SMILES</a>, and later hash them into binary fingerprints.
The later are searchable with bitwise similarity metrics, like the Tanimoto coefficient.
Below is na example using the RDKit package.</p>
<div><pre><span></span><span>from</span> <span>usearch.index</span> <span>import</span> <span>Index</span><span>,</span> <span>MetricKind</span>
<span>from</span> <span>rdkit</span> <span>import</span> <span>Chem</span>
<span>from</span> <span>rdkit.Chem</span> <span>import</span> <span>AllChem</span>

<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>molecules</span> <span>=</span> <span>[</span><span>Chem</span><span>.</span><span>MolFromSmiles</span><span>(</span><span>'CCOC'</span><span>),</span> <span>Chem</span><span>.</span><span>MolFromSmiles</span><span>(</span><span>'CCO'</span><span>)]</span>
<span>encoder</span> <span>=</span> <span>AllChem</span><span>.</span><span>GetRDKitFPGenerator</span><span>()</span>

<span>fingerprints</span> <span>=</span> <span>np</span><span>.</span><span>vstack</span><span>([</span><span>encoder</span><span>.</span><span>GetFingerprint</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>molecules</span><span>])</span>
<span>fingerprints</span> <span>=</span> <span>np</span><span>.</span><span>packbits</span><span>(</span><span>fingerprints</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

<span>index</span> <span>=</span> <span>Index</span><span>(</span><span>ndim</span><span>=</span><span>2048</span><span>,</span> <span>metric</span><span>=</span><span>MetricKind</span><span>.</span><span>Tanimoto</span><span>)</span>
<span>labels</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>len</span><span>(</span><span>molecules</span><span>))</span>

<span>index</span><span>.</span><span>add</span><span>(</span><span>labels</span><span>,</span> <span>fingerprints</span><span>)</span>
<span>matches</span> <span>=</span> <span>index</span><span>.</span><span>search</span><span>(</span><span>fingerprints</span><span>,</span> <span>10</span><span>)</span>
</pre></div>
</section>
</section>
<section id="todo">
<h2>TODO<a href="#todo" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>JavaScript: Allow calling from “worker threads”.</p></li>
<li><p>Rust: Allow passing a custom thread ID.</p></li>
<li><p>C# .NET bindings.</p></li>
</ul>
</section>
<section id="integrations">
<h2>Integrations<a href="#integrations" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>[x] GPT-Cache.</p></li>
<li><p>[ ] LangChain.</p></li>
<li><p>[ ] Microsoft Semantic Kernel.</p></li>
<li><p>[ ] PyTorch.</p></li>
</ul>
</section>
<section id="citations">
<h2>Citations<a href="#citations" title="Permalink to this heading">#</a></h2>
<div><pre><span></span>@software{Vardanian_USearch_2022,
doi = {10.5281/zenodo.7949416},
author = {Vardanian, Ash},
title = {{USearch by Unum Cloud}},
url = {https://github.com/unum-cloud/usearch},
version = {0.13.0},
year = {2022}
month = jun,
}
</pre></div>



</section>
</section>

        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Happy 30th FreeBSD: Why FreeBSD open source project has endured (144 pts)]]></title>
            <link>https://aster.cloud/2023/06/16/happy-30th-freebsd-why-the-freebsd-open-source-project-has-endured/</link>
            <guid>36942526</guid>
            <pubDate>Mon, 31 Jul 2023 13:56:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aster.cloud/2023/06/16/happy-30th-freebsd-why-the-freebsd-open-source-project-has-endured/">https://aster.cloud/2023/06/16/happy-30th-freebsd-why-the-freebsd-open-source-project-has-endured/</a>, See on <a href="https://news.ycombinator.com/item?id=36942526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-26554">

					
					<div>

							
							<section>

								
<p>As FreeBSD marks three decades of success, we can thank open source freedom, a strong culture, a shared leadership model, modern development practices, and robust code that continues to evolve.</p>



<p>FreeBSD’s 30th birthday presents an opportunity to look back and examine why&nbsp;this open source operating system&nbsp;has not only endured, but thrived across many organizations and use cases for so long. While open source projects are born out of different circumstances, FreeBSD grew from a mold of its own. The path the project took has everything to do with its longevity and why, 30 years after FreeBSD launched, you’ll find FreeBSD code helping to power everything from your content on Netflix to your games on PlayStation.</p>
<div>
<hr>
<h4><small>From our partners:</small></h4>
<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297452431"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297521124"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297537424"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297586673"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297608307"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297668616"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297706103"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297736436"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297756073"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297780177"} -->

<!-- /wp:buttons -->

<!-- wp:buttons {"canvasClassName":"cnvs-block-core-buttons-1689297807890"} -->

<!-- /wp:buttons -->
<hr>
</div>




<h2 id="bsd-before-the-free">BSD (before the Free)</h2>



<p>Initially released in 1993, FreeBSD is rooted in the Berkeley Software Distribution (BSD) code base that had been under development since the 1970s. The pioneering BSD project introduced the socket networking interface, the first implementation of TCP/IP, file systems including VFS, FFS, and NFS, the mmap memory model, and more. While BSD was&nbsp;<em>not</em>&nbsp;open source, its licensed code still received many contributions from academic and industry users.</p>



<p>Most of BSD was made available as open source software with the 4.4BSD-Lite distribution, providing the basis for FreeBSD. The foundational nature of its technology has been a significant factor in its success ever since.</p>







<p>To manage leadership succession and avoid risks associated with the singular-leader structure common to many other open source projects, the founders of the FreeBSD project set up the FreeBSD Core Team, a group of leaders responsible for the project’s direction and controlling committer privileges. While the founders initially assigned themselves as these leaders, in 2000 the nine seats on the Core Team became elected positions. Enabling committers to vote for FreeBSD’s leadership and rise to leadership roles themselves has kept the project particularly robust and capable of evolution.</p>



<h2 id="modern-remote-development">Modern remote development</h2>



<p>FreeBSD has leveraged source code control, bug reporting, and other tools that could enable remote development from its beginning. In an era when open source project distributions were most often maintained by a single individual who personally added all code contributions, the novel advantages of FreeBSD’s strategy have since come to define modern practices. This freedom to accelerate development beyond standard limitations meant rapidly incorporating code—including valuable capabilities drawn from NetBSD and OpenBSD.</p>




<h2 id="a-discerning-approach-to-hardware">A discerning approach to hardware</h2>



<p>The FreeBSD project decided from the start to select recommended hardware and offer diligent, targeted support. As a result, FreeBSD has consistently found itself ahead of the curve when it comes to reliability and performance metrics. That distinction is why it’s been such an enduringly popular choice for companies from the dial-up age through to modern web server providers.</p>



<h2 id="stellar-communication-documentation-support-and-culture">Stellar communication, documentation, support, and culture</h2>



<p>With FreeBSD enabling remote development and global contributions, the project was particularly strategic about the mailing lists it developed to keep work and design discussions organized and efficient. Because of that, FreeBSD quickly achieved thoughtful communications management with monitoring and moderation to keep discussions civil (yes, civility!) and on topic, without limiting freedom of expression and while serving developers from diverse cultures.</p>



<p>FreeBSD has also excelled at maintaining valuable software documentation from its beginning, starting by recruiting contributors with a focus on documentation, and asking developers to participate in making sure that documentation is accurate and complete. Toward this goal, FreeBSD specifically introduced a documentation committer group with the same privileges as code committers. The project also supports a multi-language documentation framework, making FreeBSD knowledge more approachable to more developers worldwide.</p>



<p>Culture is as important as technology in open source, and FreeBSD has a welcoming and inclusive one that extends the same voting rights (and an equal voice in the community) to all committers. The thriving&nbsp;FreeBSD Foundation—which was one of the industry’s first—offers a deep set of project support services as well.</p>



<h2 id="valuable-ports">Valuable ports</h2>



<p>FreeBSD’s initial release included numerous contributed utilities and libraries, and these have only expanded into the vast FreeBSD ports collection available today. This collection offers powerful and well-supported access to advanced open source technologies on top of FreeBSD. Once again, FreeBSD was an early&nbsp;leader. FreeBSD’s package management tool, pkg, has had regular improvements over the years. Poudriere, a FreeBSD package creation and testing utility, is a great tool that leverages jails, a major strength of FreeBSD, to allow developers to reproducibly test port changes and reliably build our 30,000+ ports. And, finally, all of the ports are available in binary form to make it easier for&nbsp;the user to install applications by using the pkg command.</p>



<h2 id="last-but-never-least-in-open-source-the-licensing">Last but never least in open source… the licensing</h2>



<p>Perhaps the most significant contributor to FreeBSD’s 30 years of success is its open source Berkeley license. The Berkeley license doesn’t require organizations to share source code changes with others, whereas Linux does. Companies that must place code representing proprietary intellectual property into their products need that licensing freedom—such as those in the appliance and embedded OS market. That open source freedom, paired with strong leadership, a strong culture, and robust code that continues to evolve, is why FreeBSD is now celebrating a happy 30th birthday.</p>



<h2 id="looking-ahead-to-the-next-30-years">Looking ahead to the next 30 years</h2>



<p>FreeBSD’s 30th anniversary provides a reminder that durable success doesn’t happen by accident. Reviewing how our community tackled the massive technical changes and challenges that occurred during this period also gives insights into what we must do to ensure we can celebrate similar milestones in the decades to come. By providing the best platform for rapid experimentation and development of new technologies, coupled with a reliable foundation for commercialization and wide adoption, we expect to see FreeBSD continue to thrive. We invite and encourage you to be a part of the next 30 years.</p>



<p><em>Deb Goodkin is executive director at the&nbsp;FreeBSD Foundation, which supports the open source FreeBSD operating system. Deb has been with the foundation since August 2005. She has spent 20-plus years working in marketing, sales, and development of data storage devices. She earned an MSEE from the University of Santa Clara and a BSCE from the University of California, San Diego.</em></p>



<p><em>By: Deb Goodkin<br>Originally published at InfoWorld</em></p>



<p><em>Source: c<a href="https://cyberpogo.com/2023/06/16/happy-30th-freebsd-why-the-freebsd-open-source-project-has-endured/" target="_blank" rel="noreferrer noopener">yberpogo.com</a></em></p>

<div>
<hr>
<h6>For enquiries, product placements, sponsorships, and collaborations, connect with us at <a href="https://aster.cloud/cdn-cgi/l/email-protection#ed8588818182ad8c9e99889fc38e81829889"><span data-cfemail="7b131e1717143b1a080f1e09551817140e1f">[email&nbsp;protected]</span></a>. We'd love to hear from you!</h6>

<hr><p>
Our humans need coffee too! Your support is highly appreciated, thank you!
</p></div>
<!-- AI CONTENT END 2 -->

							</section>

										
			



<section><h5>Related Topics</h5><ul><li><a href="https://aster.cloud/tag/freebsd/" rel="tag">FreeBSD</a></li><li><a href="https://aster.cloud/tag/open-source/" rel="tag">Open Source</a></li><li><a href="https://aster.cloud/tag/operating-system/" rel="tag">Operating System</a></li></ul></section>
						</div><!-- .entry-wrap -->

							
	
				</article>

				
				
			
		</main>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compilation of Known LK-99 Replication Attempt Claims (136 pts)]]></title>
            <link>https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/page-15</link>
            <guid>36942476</guid>
            <pubDate>Mon, 31 Jul 2023 13:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/page-15">https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/page-15</a>, See on <a href="https://news.ycombinator.com/item?id=36942476">Hacker News</a></p>
<div id="readability-page-1" class="page">

	

		
			
		

		
	


	

		
			
		

		
	


<div id="top">
	
	
	
	
	


<header id="header">
	<div>
				<a href="https://forums.spacebattles.com/">
						
					<img src="https://forums.spacebattles.com/data/svg/2/1/1690665907/2022FinalLogo.svg" srcset="" alt="SpaceBattles" width="362" height="60">
					
				</a>
			</div>
</header>

		

<div>
		
		<!--XF:EXTRA_OUTPUT-->


		  
		
			
	
		
		
		

		<ul data-xf-init="notices" data-type="block" data-scroll-interval="15">

			
				
	<li data-notice-id="871" data-delay-duration="0" data-display-duration="0" data-auto-dismiss="" data-visibility="">

		
		<div>
			
				<a href="https://forums.spacebattles.com/account/dismiss-notice?notice_id=871" data-xf-init="tooltip" title="Dismiss notice"></a>
			
			Some forums/subforums have been updated with new names. Full details can be found <a href="https://forums.spacebattles.com/threads/sub-forum-renaming.1105093/">here</a>.
		</div>
	</li>

			
				
	<li data-notice-id="877" data-delay-duration="0" data-display-duration="0" data-auto-dismiss="" data-visibility="">

		
		<div>
			
				<a href="https://forums.spacebattles.com/account/dismiss-notice?notice_id=877" data-xf-init="tooltip" title="Dismiss notice"></a>
			
			The NSFD Rules have been streamlined and updated. Check out the details <a href="https://forums.spacebattles.com/threads/official-nsfd-rules.1106428/">here</a>.
		</div>
	</li>

			
		</ul>
	

		

		

		 
		
	

		
			
		

		
	


		
	
		<div>
		<ul itemscope="" itemtype="https://schema.org/BreadcrumbList">
		
			

			
			

			

			
			
				
				
	<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
		<a href="https://forums.spacebattles.com/#the-real-world.33" itemprop="item">
			<span itemprop="name">The Real World</span>
		</a>
		<meta itemprop="position" content="1">
	</li>

			
				
				
	<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
		<a href="https://forums.spacebattles.com/forums/news-society-focused-discussion.7/" itemprop="item">
			<span itemprop="name">News &amp; Society Focused Discussion</span>
		</a>
		<meta itemprop="position" content="2">
	</li>

			

		
		</ul>
		
		</div>
	

		
	

		
			
		

		
	


		

		
	

		
	<div>You are using an out of date browser. It  may not display this or other websites correctly.<br>You should upgrade or use an <a href="https://www.google.com/chrome/" target="_blank" rel="noopener">alternative browser</a>.</div>


		
		 
			
		
			<div>
			
				
					<div>
					
						
							<h2>Claims of Room Temperature and Ambient Pressure Superconductor
	
	
	

</h2>
						
						
					
					</div>
				

				
					<div>
	<ul>
		<li>
			<i aria-hidden="true" title="Thread starter"></i>
			<span>Thread starter</span>

			<a href="https://forums.spacebattles.com/members/second-mover.310421/" dir="auto" data-user-id="310421" data-xf-init="member-tooltip">Second mover</a>
		</li>
		<li>
			<i aria-hidden="true" title="Start date"></i>
			<span>Start date</span>

			<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/"><time dir="auto" datetime="2023-07-25T16:07:16-0400" data-time="1690315636" data-date-string="Jul 25, 2023" data-time-string="4:07 PM" title="Jul 25, 2023 at 4:07 PM">Tuesday at 4:07 PM</time></a>
		</li>


		
	

	


</ul>
</div>
				
			
			</div>
		
		
		

		<div>


	








		
	








	
		
		
	
	



	
	
	
		
	
	
	


	
	
	
		
	
	
	


	
	
		
	
	
	


	
	











	



	

	

		
	










	

		
			
		

		
	





	
	

















	

		
			
		

		
	



	

		
			
		

		
	



<div data-xf-init="" data-type="post" data-href="/inline-mod/" data-search-target="*">

	<span id="posts"></span>

	
		
	

	

	

	

	
		
	

	

	<div data-xf-init="lightbox select-to-quote" data-message-selector=".js-post" data-lb-id="thread-1106083" data-lb-universal="0">
			
				


	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Guderian2nd" data-content="post-94266395" id="js-post-94266395">

		
	
	
	
		<span id="post-94266395"></span>
	

	
	
        
		
		

		<div>
			<span>
			
				<label for="threadmark-1856801">Threadmarks</label> <span id="threadmark-1856801" data-xf-init="tooltip" title="Threadmark created by Guderian2nd on Jul 30, 2023">Compilation of Known Replication Attempt Claims</span>
			

			
				

				

				

				
					<span>New</span>
				
			
			</span>

			
		</div>
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/guderian2nd.116487/" data-user-id="116487" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11680450592/116487-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11680450592/116487-l.jpg 2x" alt="Guderian2nd" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94266395" data-xf-init="share-tooltip" data-href="/posts/94266395/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94266395" rel="nofollow">
						#255
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div>
							

								
									
	




	
	

								

								
									

	<div data-lb-id="post-94266395" data-lb-caption-desc="Guderian2nd · Jul 30, 2023 at 10:31 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Compilation of all Claims/Reports of Replication Efforts underway that I know of (all Reliability of Claim classifications are based on <i><b>my personal judgement</b></i>, do not take them at face value, read the details and judge for yourself) :<p>

<b><u>Official/Professional/Institutional</u></b></p><div>
<table><tbody><tr><th>Group</th><th>Country</th><th>Reliability of Claim</th><th>Progress/Status</th><th>Results</th><th>Notes</th><th>Sources/References</th></tr><tr><td><b>Argonne National Laboratory</b></td><td>America</td><td><span>High</span></td><td>N/A</td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_1" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_1_tab_1">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_1_tab_1">
			<blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
		
		<div>
			(Excerpt from article linked)<p>

"They come off as real amateurs," says Michael Norman, a theorist at Argonne National Laboratory. "They don't know much about superconductivity and the way they've presented some of the data is fishy." On the other hand, he says, researchers at Argonne and elsewhere are already trying to replicate the experiment. "People here are taking it seriously and trying to grow this stuff."
		</p></div>
		<div><a role="button" tabindex="0">Click to expand...</a></div>

<div><a>Click to shrink...</a></div>
	</div>
</blockquote>
		</dd>
	
</dl></td><td><a href="https://www.science.org/content/article/spectacular-superconductor-claim-making-news-here-s-why-experts-are-doubtful" target="_blank" rel="noopener">Science Link</a></td></tr><tr><td><b>School of Physics, Nanjing University</b></td><td>China</td><td><span>High</span></td><td>N/A</td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_2" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_2_tab_2">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_2_tab_2">
			<blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
		
		<div>
			(DeepL Translate excerpt from article linked)<br>
On the recent people hotly debated "if really immediately can get the Nobel Prize 'South Korea room temperature superconducting materials LK-99 paper'", July 28, Nanjing University, professor of physics Wen Haihu interviewed to the surging science and technology, said. "It's really buzzing, but it's not surprising because this thing is important." "Most of the (buzz) people are not doing superconductivity." "We carefully analysed their data, and from three aspects - resistance, magnetisation and so-called magnetic levitation - none of them are sufficient to show that it is a superconducting phenomenon (material)." "We judge that (its so-called superconductivity) is most likely an illusion."<p>

As for repeating the experiment, Wen Haihu said, "In fact, we didn't even want to do it because we judged that it didn't look like superconductivity, and then we also sent one of our classmates to work on it. Many groups internationally are repeating it. With our experience, (the data published in the current paper) is not enough to show that it is superconducting."
		</p></div>
		<div><a role="button" tabindex="0">Click to expand...</a></div>

<div><a>Click to shrink...</a></div>
	</div>
</blockquote>
		</dd>
	
</dl></td><td><a href="https://news.sciencenet.cn/htmlnews/2023/7/505675.shtm" target="_blank" rel="noopener">ScienceNet.cn Link</a></td></tr><tr><td><b>Huazhong University of Science and Technology (HUST)</b></td><td>China</td><td><span>Low</span></td><td><span>Retrying</span></td><td><span>Attempt #1 Partial Success<br>
 (magnetization O, levitation X)</span></td><td><br>


<dl id="bbcode_accordionpost_94266395_3" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_3_tab_3">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_3_tab_3">
			<ul>
<li data-xf-list-type="ul">Only source for this is a few screenshots of WeChat floating around on the Chinese internet (see Sources/References).</li>
<li data-xf-list-type="ul">English Translation &amp; Analysis: <a href="https://elsazhou.medium.com/lk99-chinese-replication-efforts-a21318e4a71" target="_blank" rel="noopener">LK99 — Chinese replication efforts</a></li>
<li data-xf-list-type="ul">The claim is that they conducted magnetic susceptibility measurements on completed samples and obtained results consistent with paper, but no meissner effect or levitation observed, and are currently retrying due to concerns over purity.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.zhihu.com/question/614297333/answer/3141294647" target="_blank" rel="noopener">Zhihu Link</a></td></tr><tr><td><b>Institute of Physics - Chinese Academy of Sciences (IoP-CAS)</b></td><td>China</td><td><span>Low</span></td><td>N/A</td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_4" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_4_tab_4">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_4_tab_4">
			<ul>
<li data-xf-list-type="ul">Rumours about a replication attempt from the CAS has been floating around the Chinese Internet since very early on after the news went viral, however no reliable, official sources have been provided for this.</li>
<li data-xf-list-type="ul">Some screenshots of the official account for the IoP-CAS saying that they are not aware of the completion of relevant experiments.</li>
<li data-xf-list-type="ul">Someone claiming to be a student at the CAS has also stated that, after asking colleagues at the CAS, they are not aware of any completion of experiments that confirm or deny superconductivity.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.zhihu.com/question/614297333/answer/3138949092" target="_blank" rel="noopener">Zhihu Link 1</a><br>
<a href="https://www.zhihu.com/question/614297333/answer/3138574543" target="_blank" rel="noopener">Zhihu Link 2</a><br>
<a href="https://www.zhihu.com/question/613850973/answer/3140434503" target="_blank" rel="noopener">Zhihu Link 3</a></td></tr><tr><td><b>Council Of Scientific And Industrial Research - National Physical Laboratory of India (CSIR-NPLI)</b></td><td>India</td><td><span>High</span></td><td><span>Complete</span></td><td><span>Attempt #1 Failure<br>
 (diamagnetism X, levitation X)<br>
 Attempt #2 Failure<br>
 (XRD analysis O, bulk superconductivity X)</span></td><td><br>


<dl id="bbcode_accordionpost_94266395_5" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_5_tab_5">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_5_tab_5">
			<ul>
<li data-xf-list-type="ul">Dr. V.P.S. Awana from CSIR-NPLI posted their systhesis/experiment results on his personal facebook page.</li>
<li data-xf-list-type="ul">Their first attempt altered the recipe, as the result should still have been the same molecular structure as the authors claimed. The resulting specimen did not display superconductivity, or even diamagnetism - it was paramagnetic.</li>
<li data-xf-list-type="ul">They are in contact with the original authors (Lee Seok-Bae) about how to properly replicate. They are positing that their altered procedure led to an improper doping of Copper, and are currently retrying by more closely following the recipe in the paper.</li>
<li data-xf-list-type="ul">Their second attempt, which closely followed the recipe, also did not show bulks superconductivity. Resistivity results are in the megaohms - their result is a paramagnetic insulator.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.facebook.com/AwanaVPS/posts/pfbid0m2CWv3ifsPph8sSHYmExsvnqdon5HsgrpDetYfjHQjySQETGDqhYDj5kDntMqw7ul" target="_blank" rel="noopener">Facebook Link 1</a><br>
<a href="https://www.facebook.com/AwanaVPS/posts/pfbid0xgYA4QS36rpLbs1N39fPZaEDo43hzHro3AffVpxU7tnXsyaokxuBofrd5wxBBcoxl" target="_blank" rel="noopener">Facebook Link 2</a></td></tr></tbody></table>
</div><br>
<hr><br>
<b><u>Amateur/Private</u></b><div>
<table><tbody><tr><th>Individual</th><th>Country</th><th>Credentials</th><th>Reliability of Claim</th><th>Progress/Status</th><th>Results</th><th>Notes</th><th>Sources/References</th></tr><tr><td><b>Andrew McCarlip</b></td><td>America</td><td>Robotics Engineer at <a href="https://varda.com/" target="_blank" rel="noopener">Varda</a></td><td><span>High</span></td><td><span>Currently synthesizing Cu3P</span></td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_6" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_6_tab_6">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_6_tab_6">
			<ul>
<li data-xf-list-type="ul">He's live streaming most of his steps on Twitch, you can check his progress in real time in the links. I don't think there's any reason to believe that he's lying about trying to replicate this.</li>
<li data-xf-list-type="ul">He's also sent samples of intermediate products to other labs for XRD (X-ray diffraction), MPMS (Magnetic Property Measurement System), SEM (Scanning Electron Microscope) analysis.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://twitter.com/andrewmccalip/status/1685097443455856640" target="_blank" rel="noopener">Twitter Link 1</a><br>
<a href="https://twitter.com/andrewmccalip/status/1685871360948748288" target="_blank" rel="noopener">Twitter Link 2</a><br>
<a href="https://www.twitch.tv/andrewmccalip" target="_blank" rel="noopener">Twitch Link</a></td></tr><tr><td><b>科学调查局 at Bilibili<br>
 (Prof. 孙悦 (Sun Yue) at Southeast University (东南大学)?)</b></td><td>China</td><td>Professor at Southeast University</td><td><span>High</span></td><td><span>Complete</span></td><td><span>Failure?<br>
 (XRD analysis O,<br>
 magnetization X,<br>
 possible weak diamagnetism,  superconductivity X)</span></td><td>

<dl id="bbcode_accordionpost_94266395_7" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_7_tab_7">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_7_tab_7">
			<ul>
<li data-xf-list-type="ul">The Professor goes by the handle of 科学调查局 of Bilibili - his profile says he is a professor at Southeast University and researcher at the Univerisity of Tokyo, Japan. A search of the faculty at one of the labs at Southeast University (Nanjing) does show a professor who's resume contains working as a researcher at the University of Tokyo, and his face looks the same to me as the one that appears in the Bilibili channel videos, so I'm assuming they are the same person.</li>
<li data-xf-list-type="ul">He's synthesized 8 samples in accordance with the recipe in the paper. Their XRD profile matches the one given in the paper, but the magnetization and other measurement results do not display Superconductivity, although it could indicate weak diamagnetism (graph is too noisy to tell).</li>
<li data-xf-list-type="ul">You can read an english summary of the video in the Twitter Link in Source/References.</li>
</ul>
		</dd>
	
</dl></td><td><a href="http://www.scseu.cn/page/case/" target="_blank" rel="noopener">SEU SMRL Faculty Link</a><br>
<a href="https://space.bilibili.com/1016690873" target="_blank" rel="noopener">Bilibili Link 1</a><br>
<a href="https://www.bilibili.com/video/BV1yj41167Xd/" target="_blank" rel="noopener">Bilibili Link 2</a><br>
<a href="https://twitter.com/elsa17z/status/1685991164028104704" target="_blank" rel="noopener">Twitter Link 3</a></td></tr><tr><td><b>半导体与物理 at Zhihu</b></td><td>China</td><td>N/A</td><td><span>Somewhat High</span></td><td><span>Completed Synthesis</span>, conducting experiments</td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_8" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_8_tab_8">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_8_tab_8">
			<ul>
<li data-xf-list-type="ul">I couldn't find any information on this person's credentials, but they've been posting pictures of the ingredients and synthesis process on Zhihu since very soon after the news broke out in the Chinese web.</li>
<li data-xf-list-type="ul">Not as good as live streaming, but I don't think there's much reason to believe that they are lying about trying to replicate this given the pictures of the ingredients and equipment.</li>
<li data-xf-list-type="ul">Their latest update claims that their group has now "started experimenting."</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.zhihu.com/question/613850973/answer/3136586869" target="_blank" rel="noopener">Zhihu Link</a></td></tr><tr><td><b>胡豆 at Zhihu</b></td><td>China</td><td>N/A</td><td><span>Somewhat High</span></td><td><span>Synthesizing final product</span></td><td>N/A</td><td><br>


<dl id="bbcode_accordionpost_94266395_9" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_9_tab_9">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_9_tab_9">
			<ul>
<li data-xf-list-type="ul">Same as the above. I couldn't find any information on this person's credentials, but they've been posting pictures of the ingredients and synthesis process on Zhihu since very soon after the news broke out in the Chinese web.</li>
<li data-xf-list-type="ul">Not as good as live streaming, but I don't think there's much reason to believe that they are lying about trying to replicate this given the pictures of the ingredients and equipment.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.zhihu.com/question/613850973/answer/3139213408" target="_blank" rel="noopener">Zhihu Link</a></td></tr><tr><td><b>关山口男子技师 at Bilibili</b></td><td>China</td><td>Claims to work at HUST</td><td><span>Somewhat High</span></td><td><span>Complete</span></td><td><span>Failure?<br>
 (weak diamagnetism O, semiconductivity)</span></td><td><br>


<dl id="bbcode_accordionpost_94266395_10" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_10_tab_10">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_10_tab_10">
			<ul>
<li data-xf-list-type="ul">This person's bilibili page claims that they are from HUST.</li>
<li data-xf-list-type="ul">All 4 synthesized samples did not display flux pinning. Magnetization measurements show the material to be weakly diamagnetic. Resistance measurements do not show 0 resistance, shows the material to be a semiconductor.</li>
<li data-xf-list-type="ul">I don't see any particular reason to believe that they are lying about trying to replicate given the magnetization and resistence measurement graphs.</li>
<li data-xf-list-type="ul">They had apparently live streamed their synthesis process on bilibili, but no recordings remain so I cannot corroborate this myself.</li>
<li data-xf-list-type="ul">They live streamed a flux pinning/Meissner effect test of 4 samples they synthesized at <i aria-hidden="true" title="Adjusted Time"></i>

	<time dir="auto" datetime="2023-07-29T21:00:00-0400" tabindex="0" role="button" data-xf-init="tooltip" data-trigger="hover focus touchclick" title="Jul 29, 2023 at 9:00 PM" data-time="1690678800" data-date-string="Jul 29, 2023" data-time-string="9:00 PM" data-full-date="true">
		Saturday at 9:00 PM
	</time>, all of which failed to levitate. A link to a partial recording of their live stream is available in the links.</li>
<li data-xf-list-type="ul">You can see screenshots taken from their live stream in the twitter thread linked.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://space.bilibili.com/7590247" target="_blank" rel="noopener">Bilibili Link 1</a><br>
<a href="https://space.bilibili.com/7590247/dynamic" target="_blank" rel="noopener">Bilibili Link 2</a><br>
<a href="https://www.bilibili.com/video/BV178411276F/" target="_blank" rel="noopener">Bilibili Link 3</a><br>
<a href="https://twitter.com/elsa17z/status/1685447989693734912" target="_blank" rel="noopener">Twitter Link</a></td></tr><tr><td><b>Reports relayed through amita on Zhihu<br>
 (name/affiliation not provided)</b></td><td>N/A</td><td>N/A</td><td><span>Low</span></td><td><span>Complete</span></td><td><span>Attempt #1, #2 Failure</span></td><td><br>


<dl id="bbcode_accordionpost_94266395_11" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_11_tab_11">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_11_tab_11">
			<ul>
<li data-xf-list-type="ul">No pictures or other evidence exists to support this claim, all we have are the words of this one person on Zhihu, who is apparently reporting back from their "foreign friend."</li>
<li data-xf-list-type="ul">According to amita, Attempt #1 synthesized using intermediate materials available on hand did not display superconductivity or strong diamagnetism. Attempt #2 which followed the recipe from starting ingredients also did not display superconductivity or strong diamagnetism.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://www.zhihu.com/question/613850973/answer/3138453921" target="_blank" rel="noopener">Zhihu Link</a></td></tr><tr><td><b>Iris Alexandra</b></td><td>Russia</td><td>Claims to be a molecular biologist</td><td><span>Somewhat Low</span></td><td><span>Completed Synthesis, </span>conducting experiments</td><td><span>Partial Success<br>
 (diamagnetism, levitation O)</span></td><td><br>


<dl id="bbcode_accordionpost_94266395_12" data-duration="400" data-xf-init="sv-accordion">
	
		
		
		<dt data-tab-id="bbcode_accordionpost_94266395_12_tab_12">
			Notes
		</dt>
		<dd data-tab-id="bbcode_accordionpost_94266395_12_tab_12">
			<ul>
<li data-xf-list-type="ul">I couldn't find any information on the credentials of this person. They claim to be a molecular biologist and work at an unidentified lab.</li>
<li data-xf-list-type="ul">They are claiming to be using alternative, much more efficient methods of obtaining the same compounds as claimed in the paper.</li>
<li data-xf-list-type="ul">They claimed to have completed synthesis of some samples, and that some chunks of it display strong diamagnetism/weak levitation, as claimed in the paper.</li>
<li data-xf-list-type="ul">They have posted pictures which shows what are presumably fragments of her synthesized products levitating, taken from multiple angles to show that the chunks are truly levitating. I think its safe to say that if this attempt is real, the results show a success, at least in terms of replicating the paper.</li>
<li data-xf-list-type="ul">Whether the material is simply a strong diamagnet or a superconductor would require a test to see if this is diamagnetic leviatation or flux pinning, or a measurement of resistivity/magnetization.</li>
<li data-xf-list-type="ul">They say they plan to do conductivity tests soon.</li>
<li data-xf-list-type="ul">They've posted pictures of their altered process and resulting intermediate products.</li>
<li data-xf-list-type="ul">While there is the lack of any visible credentials, lack of concrete data, and unorthodox recipe that diverges significantly from the paper, the pictures of synthesized result fragments seems genuine, so I'm give this a credibility of somewhat low for now.</li>
</ul>
		</dd>
	
</dl></td><td><a href="https://twitter.com/iris_IGB/status/1685341730902577153" target="_blank" rel="noopener">Twitter Link 1</a><br>
<a href="https://twitter.com/iris_IGB/status/1685740625017102336" target="_blank" rel="noopener">Twitter Link 2</a><br>
<a href="https://twitter.com/iris_IGB/status/1685731177523449856" target="_blank" rel="noopener">Twitter Link 3</a></td></tr></tbody></table>
</div><hr><br>
I'll probably be updating this post as the situation develops.<hr><br>
Change Log:<br>
- 2023-07-30T1755Z : Updated information regarding 关山口男子技师 at Bilibili, see: <a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94270649">Claims of Room Temperature and Ambient Pressure Superconductor</a><br>
- 2023-07-30T1855Z : Changed to table format instead of list format<br>
- 2023-07-30T1903Z : Added Changelog<br>
- 2023-07-30T2000Z : Updated status and notes for Iris Alexandra, added new twitter thread link, see: <a href="https://twitter.com/iris_IGB/status/1685740625017102336" target="_blank" rel="noopener">https://twitter.com/iris_IGB/status/1685740625017102336</a><br>
- 2023-07-31T0108Z : Updated results, notes, and references for Iris Alexandra, added new twitter thread link, see: <a href="https://twitter.com/iris_IGB/status/1685731177523449856" target="_blank" rel="noopener">https://twitter.com/iris_IGB/status/1685731177523449856</a><br>
- 2023-07-31T0114Z : Updated my assessment of reliability for Iris Alexandra based on the new info presented in the above update<br>
- 2023-07-31T1214Z : Change notes to collapsed accordions and added small details to results for better readability<br>
- 2023-07-31T1219Z : Updated status for 胡豆, notes for Andrew McCarlip<br>
- 2023-07-31T1228Z : Updated results, notes, and references for CSIR-NPLI, and their failed second attempt<br>
- 2023-07-31T1234Z : Updated credentials and notes for Iris Alexandra<br>
- 2023-07-31T1335Z : Added 科学调查局 at Bilibili (Prof. 孙悦 (Sun Yue) at Southeast University (东南大学)?)<br>
- 2023-07-31T1337Z : Fixed Twitch Link error for Andrew McCarlip's row<br>
- 2023-07-31T1401Z : Updated results for 科学调查局 at Bilibili, as a closer look at the magnetization graph may indicate weak diamagnetism<br>
- 2023-07-31T1419Z : Updated progress/status for CSIR-NPLI, as I couldn't find any statement from Prof. V.P.S. Awana that they are going for a 3rd try</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

								

								
									
	
		
<div>
			
				Last edited: <time dir="auto" datetime="2023-07-31T10:19:44-0400" data-time="1690813184" data-date-string="Jul 31, 2023" data-time-string="10:19 AM" title="Jul 31, 2023 at 10:19 AM" itemprop="dateModified">40 minutes ago</time>
			
		</div>
	

								

								
									
	

		
			
		

		
	


	


	

		
			
		

		
	

								

							
							</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
        
		
		

		
	
	
		<span id="post-footer-94266395"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Drakosk" data-content="post-94290500" id="js-post-94290500">

		
	
	
	
		<span id="post-94290500"></span>
	

	
	
	

		

		
			<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290500" data-xf-init="share-tooltip" data-href="/posts/94290500/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290500" rel="nofollow">
						#351
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94290500" data-lb-caption-desc="Drakosk · Jul 31, 2023 at 8:57 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>New information from a Chinese team. Not sure if the groups' efforts are in the sticky already.<blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
			Thread: Chinese replication efforts of <a href="https://twitter.com/hashtag/LK99?src=hashtag_click" target="_blank" rel="nofollow ugc noopener">#LK99</a> July 31st 7 am China Standard Time (July 30th 11pm UTC), a Bilibili (Chinese YouTube) account posted their results from 8 replication tests. XDR structural analysis is the same as what the papers says <a href="https://www.zhihu.com/question/614426480/answer/3142610238" target="_blank" rel="nofollow ugc noopener">韩国常压室温超导材料被验证成功了吗？ - 知乎</a>
		</div>
</blockquote><br>
...<blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
			1st pic: July 31st 11:00 UTC, the Bilibili user uploaded their results. They conducted a total of 8 preliminary replication tests, and conducted XRD structure analysis on them, the results are consistent with the papers' findings, including the samples' appearances. However we cannot directly verify whether it is room-temp sc yet. The graphs of the tests are as follows: Magnetically measuring the magnetic field 10 Oe ZFC+FC
		</div>
</blockquote><br>




<blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
			2nd pic: M-H Loop measurement @ 200k The graphs are from the experiment vid, I will link it again here <a href="https://www.bilibili.com/video/BV1yj41167Xd/?spm_id_from=333.999.list.card_archive.click" target="_blank" rel="nofollow ugc noopener">室温超导复现实验-全流程_哔哩哔哩_bilibili</a>
		</div>
</blockquote></div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
		


	
	
	

	
	
	
		<span id="post-footer-94290500"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="phazon" data-content="post-94290659" id="js-post-94290659">

		
	
	
	
		<span id="post-94290659"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/phazon.313950/" data-user-id="313950" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11450506145/313950-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11450506145/313950-l.jpg 2x" alt="phazon" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290659" data-xf-init="share-tooltip" data-href="/posts/94290659/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290659" rel="nofollow">
						#352
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94290659" data-lb-caption-desc="phazon · Jul 31, 2023 at 9:10 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Soooo, any idea on the implications if this material turns out to either be a stupidly strong diamagnet, or only contains microscopic superconducting regions inside?</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94290659"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Makin" data-content="post-94290695" id="js-post-94290695">

		
	
	
	
		<span id="post-94290695"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/makin.311646/" data-user-id="311646" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11538572317/311646-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11538572317/311646-l.jpg 2x" alt="Makin" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		<div>
			<h4><a href="https://forums.spacebattles.com/members/makin.311646/" dir="auto" data-user-id="311646" data-xf-init="member-tooltip" itemprop="name">Makin</a></h4>
			<h5 dir="auto" itemprop="jobTitle">Waiting for a good Homestuck fic</h5>
			

			


		</div>
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290695" data-xf-init="share-tooltip" data-href="/posts/94290695/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290695" rel="nofollow">
						#353
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94290695" data-lb-caption-desc="Makin · Jul 31, 2023 at 9:13 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Andrew McCalip's Twitch link doesn't work for me (should be 
	
	


<div dir="ltr">
		<pre dir="ltr" data-xf-init="code-block" data-lang=""><code>https://www.twitch.tv/andrewmccalip</code></pre>
	</div>)</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94290695"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="DoctorNobody" data-content="post-94290710" id="js-post-94290710">

		
	
	
	
		<span id="post-94290710"></span>
	

	
	
	

		

		
			<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290710" data-xf-init="share-tooltip" data-href="/posts/94290710/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290710" rel="nofollow">
						#354
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94290710" data-lb-caption-desc="DoctorNobody · Jul 31, 2023 at 9:15 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 313950" data-quote="phazon" data-source="post: 94290659">
	
		
	
	<div>
			Soooo, any idea on the implications if this material turns out to either be a stupidly strong diamagnet, or only contains microscopic superconducting regions inside?
		</div>
</blockquote><br>
At the bare minimum, it's a novel substance with novel properties, so still probably Noble material.<p>

Practically, it's still superconducting even if it's only superconducting in microscopic regions. That's the kind of thing that could be used in high-end computing or precision instrumentation, provided the microscopic superconducting effect forms in a predictable, regular manner. </p><p>

Long-term, this is new ground even if it's not something immediately world-changing. Expect lots of research from everyone from governments to big universities to random garage hobbyists.</p></div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
		


	
	
	

	
	
	
		<span id="post-footer-94290710"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Elbrasch" data-content="post-94290821" id="js-post-94290821">

		
	
	
	
		<span id="post-94290821"></span>
	

	
	
	

		

		
			
		


	
	
	

	
	
	
		<span id="post-footer-94290821"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Mahrac" data-content="post-94290926" id="js-post-94290926">

		
	
	
	
		<span id="post-94290926"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/mahrac.286405/" data-user-id="286405" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11402953499/286405-m.jpg" alt="Mahrac" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290926" data-xf-init="share-tooltip" data-href="/posts/94290926/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94290926" rel="nofollow">
						#356
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94290926" data-lb-caption-desc="Mahrac · Jul 31, 2023 at 9:32 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 313950" data-quote="phazon" data-source="post: 94290659">
	
		
	
	<div>
			Soooo, any idea on the implications if this material turns out to either be a stupidly strong diamagnet, or only contains microscopic superconducting regions inside?
		</div>
</blockquote>Bare minimum it's a proof of concept for us being able to create useful superconductors, we just need to put more effort into it.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94290926"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Guderian2nd" data-content="post-94291052" id="js-post-94291052">

		
	
	
	
		<span id="post-94291052"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/guderian2nd.116487/" data-user-id="116487" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11680450592/116487-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11680450592/116487-l.jpg 2x" alt="Guderian2nd" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291052" data-xf-init="share-tooltip" data-href="/posts/94291052/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291052" rel="nofollow">
						#357
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div>
							

								
									
	




	
	

								

								
									

	<div data-lb-id="post-94291052" data-lb-caption-desc="Guderian2nd · Jul 31, 2023 at 9:39 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 576197" data-quote="yodaisgoblin" data-source="post: 94290419">
	
		
	
	<div>
			China's Southeast University has made 8 samples, the first one failed, the rest await for tests.<br>

	

	<div data-unfurl="true" data-result-id="2611583" data-url="https://www.bilibili.com/video/BV1yj41167Xd/" data-host="www.bilibili.com" data-pending="false">
				<h3>
					<a href="https://www.bilibili.com/video/BV1yj41167Xd/" target="_blank" rel="nofollow ugc noopener" data-proxy-href="">
						室温超导复现实验-全流程_哔哩哔哩_bilibili
					</a>
				</h3>

				<div>大家期待的室温超导复现实验，初步结果。, 视频播放量 420627、弹幕量 326、点赞数 10689、投硬币枚数 2322、收藏人数 1250、转发人数 2008, 视频作者 科学调查局, 作者简介 东南大学教授...</div>

				<div>
					<span>
						
							<img src="https://i2.hdslb.com/bfs/archive/32660b6ad18c0101bacebe8f0657b8d64aaceb56.jpg@100w_100h_1c.png@57w_57h_1c.png" alt="www.bilibili.com" data-onerror="hide-parent">
						
					</span>
					www.bilibili.com
				</div>
			</div>

	

	

		</div>
</blockquote><br>




<blockquote data-attributes="member: 496735" data-quote="Drakosk" data-source="post: 94290500">
	
		
	
	<div>
			New information from a Chinese team. Not sure if the groups' efforts are in the sticky already.<p>



...</p>

		</div>
</blockquote><br>
Nice find! A quick google search tells me that this Bilibili channel is operated by someone who seems to me like Prof. Sun Yue (孙悦) at Southeast University, Nanjing (<a href="http://www.scseu.cn/page/case/" target="_blank" rel="noopener">-东南大学超导物理小组</a> ). I've added it to the table.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

								

								
									
	
		
<div>
			
				Last edited: <time dir="auto" datetime="2023-07-31T10:03:47-0400" data-time="1690812227" data-date-string="Jul 31, 2023" data-time-string="10:03 AM" title="Jul 31, 2023 at 10:03 AM" itemprop="dateModified">56 minutes ago</time>
			
		</div>
	

								

								
									
	

		
			
		

		
	


	


	

		
			
		

		
	

								

							
							</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291052"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="XenonPrime" data-content="post-94291064" id="js-post-94291064">

		
	
	
	
		<span id="post-94291064"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/xenonprime.11575/" data-user-id="11575" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11335603473/11575-m.jpg" alt="XenonPrime" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291064" data-xf-init="share-tooltip" data-href="/posts/94291064/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291064" rel="nofollow">
						#358
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291064" data-lb-caption-desc="XenonPrime · Jul 31, 2023 at 9:41 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>If nothing else they appear to have created an insanely powerful and relatively cheap to make diamagnet which will probably be useful.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291064"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Maragas" data-content="post-94291193" id="js-post-94291193">

		
	
	
	
		<span id="post-94291193"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/maragas.316487/" data-user-id="316487" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11521135101/316487-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11521135101/316487-l.jpg 2x" alt="Maragas" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291193" data-xf-init="share-tooltip" data-href="/posts/94291193/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291193" rel="nofollow">
						#359
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291193" data-lb-caption-desc="Maragas · Jul 31, 2023 at 9:49 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Huh, here I though this was just another overblown hype story.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291193"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Guderian2nd" data-content="post-94291253" id="js-post-94291253">

		
	
	
	
		<span id="post-94291253"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/guderian2nd.116487/" data-user-id="116487" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11680450592/116487-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11680450592/116487-l.jpg 2x" alt="Guderian2nd" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291253" data-xf-init="share-tooltip" data-href="/posts/94291253/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291253" rel="nofollow">
						#360
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div>
							

								
									
	




	
	

								

								
									

	<div data-lb-id="post-94291253" data-lb-caption-desc="Guderian2nd · Jul 31, 2023 at 9:52 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 316487" data-quote="Maragas" data-source="post: 94291193">
	
		
	
	<div>
			Huh, here I though this was just another overblown hype story.
		</div>
</blockquote>All (IMO) reliable/trustworthy replication experiments have so far failed to replicate superconductivity, so IMO it's still safe to treat it as an overblown hype story. I expect the matter to be settled one way or the other by the coming weekend.<blockquote data-attributes="member: 311646" data-quote="Makin" data-source="post: 94290695">
	
		
	
	<div dir="ltr">
		<pre dir="ltr" data-xf-init="code-block" data-lang=""><code>https://www.twitch.tv/andrewmccalip</code></pre>
	</div>
</blockquote>Fixed!</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

								

								
									
	
		
<div>
			
				Last edited: <time dir="auto" datetime="2023-07-31T09:54:20-0400" data-time="1690811660" data-date-string="Jul 31, 2023" data-time-string="9:54 AM" title="Jul 31, 2023 at 9:54 AM" itemprop="dateModified">Today at 9:54 AM</time>
			
		</div>
	

								

								
									
	

		
			
		

		
	


	


	

		
			
		

		
	

								

							
							</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291253"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="secretsalamander" data-content="post-94291637" id="js-post-94291637">

		
	
	
	
		<span id="post-94291637"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/secretsalamander.287898/" data-user-id="287898" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11447384504/287898-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11447384504/287898-l.jpg 2x" alt="secretsalamander" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
					<span tabindex="0" data-xf-init="tooltip" data-trigger="auto" title="Online now"></span>
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291637" data-xf-init="share-tooltip" data-href="/posts/94291637/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291637" rel="nofollow">
						#361
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291637" data-lb-caption-desc="secretsalamander · Jul 31, 2023 at 10:17 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Yeah I’m not understanding why people are so optimistic?<p>

Every single reputable lab so far has failed to replicate the results of the study as far as I can tell.   </p><p>

The idea that only trace amounts of the material is a superconductor is speculation at this point as far as I understand.  </p><p>

My estimation that this is anything news worthy is drastically falling.   </p><p>

Unless anyone has anything to say to the contrary?</p></div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291637"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="Atlan" data-content="post-94291757" id="js-post-94291757">

		
	
	
	
		<span id="post-94291757"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/atlan.3314/" data-user-id="3314" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11672056152/3314-m.jpg" srcset="https://forums.spacebattles.com/data/avatar/11672056152/3314-l.jpg 2x" alt="Atlan" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291757" data-xf-init="share-tooltip" data-href="/posts/94291757/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291757" rel="nofollow">
						#362
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291757" data-lb-caption-desc="Atlan · Jul 31, 2023 at 10:23 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 287898" data-quote="secretsalamander" data-source="post: 94291637">
	
		
	
	<div>
			Yeah I’m not understanding why people are so optimistic?<p>

Every single reputable lab so far has failed to replicate the results of the study as far as I can tell. </p><p>

The idea that only trace amounts of the material is a superconductor is speculation at this point as far as I understand.</p><p>

My estimation that this is anything news worthy is drastically falling. </p><p>

Unless anyone has anything to say to the contrary?
		</p></div>
</blockquote>Even if it's not a superconductor it still has <i>really</i> useful properties, because it looks like it's ridiculously diamagnetic. Just figuring out how it does that is going to be interesting as all hell for a lot of teams.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291757"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="spinnybop" data-content="post-94291832" id="js-post-94291832">

		
	
	
	
		<span id="post-94291832"></span>
	

	
	
	

		

		
			<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291832" data-xf-init="share-tooltip" data-href="/posts/94291832/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291832" rel="nofollow">
						#363
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291832" data-lb-caption-desc="spinnybop · Jul 31, 2023 at 10:27 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div>Holy shit there are 3200~ guests 8v<blockquote data-attributes="member: 287898" data-quote="secretsalamander" data-source="post: 94291637">
	
		
	
	<div>
			Yeah I’m not understanding why people are so optimistic?<p>

Every single reputable lab so far has failed to replicate the results of the study as far as I can tell.  </p><p>

The idea that only trace amounts of the material is a superconductor is speculation at this point as far as I understand. </p><p>

My estimation that this is anything news worthy is drastically falling.  </p><p>

Unless anyone has anything to say to the contrary?
		</p></div>
</blockquote>The test results have been inconclusive so far? At least, the ones doing the experiments themselves haven't yet gotten confident enough to entirely put the kibosh on this, is my understanding.</div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291832"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	





	

		
			
		

		
	



					

					
						

	




	

	
	<article data-author="eirich" data-content="post-94291862" id="js-post-94291862">

		
	
	
	
		<span id="post-94291862"></span>
	

	
	
	

		

		
			<div>
				
					<section itemscope="" itemtype="https://schema.org/Person">
		<div>
				
					<a href="https://forums.spacebattles.com/members/eirich.336966/" data-user-id="336966" data-xf-init="member-tooltip">
			<img src="https://forums.spacebattles.com/data/avatar/11481332047/336966-m.jpg" alt="eirich" width="96" height="96" loading="lazy" itemprop="image"> 
		</a>
				
				
					<span tabindex="0" data-xf-init="tooltip" data-trigger="auto" title="Online now"></span>
				
			</div>
		
		
			
			
		
		<span></span>
	</section>
				

				
					<div>

							
							
								

	<header>
		


	
	

		<ul data-xf-init="sv-transparent-as-spoiler" data-sv-show-icon="fa fa-eye" data-sv-hide-icon="fa fa-eye-slash">
			
			
			
			<li>
				<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291862" data-xf-init="share-tooltip" data-href="/posts/94291862/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.spacebattles.com/threads/claims-of-room-temperature-and-ambient-pressure-superconductor.1106083/post-94291862" rel="nofollow">
						#364
					</a>
				</li>
			
		</ul>
	</header>

							
							

							<div data-lb-id="post-94291862" data-lb-caption-desc="eirich · Jul 31, 2023 at 10:29 AM">

		

		<article>
			
				
			
			
				
	

		
			
		

		
	

<div><blockquote data-attributes="member: 317704" data-quote="Enmascarado" data-source="post: 94289819">
	
		
	
	<div>
			People really, really want to know more, it seems.
		</div>
</blockquote>If my condensed adaptation of the table here helped more laypeople catch up more easily, then that's a win I suppose. Could've done without the accusations of theft, though. We're all in this together, and I forked the data for my own reference.<p>

That said, I got someone nitpicking the table on my end saying that the countries should say "USA" instead of "America".</p></div>

	

		
			
		

		
	

			
			




			
				
			
		</article>

		

		
	</div>

							
								
	

							
						</div>
				
			</div>
		


	
	
	

	
	
	
		<span id="post-footer-94291862"></span>
	

	</article>

	
	

					

					

				

	

		
			
		

		
	



			
		</div>

	
		
	

	
	

</div>


	

		
			
		

		
	




	
	

















	
	









	
		
		
		
		
		
		
		
		<div>
			<h3 data-target=".block--similarContents .block-body" data-xf-click="toggle" data-xf-init="toggle-storage-ex" data-storage-type="cookie" data-storage-key="_similarThreads">Similar threads</h3>
			
		</div>
	






</div>

		
		
	

		
			
		

		
	


		
	
		<div>
		<ul itemscope="" itemtype="https://schema.org/BreadcrumbList">
		
			

			
			

			

			
			
				
				
	<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
		<a href="https://forums.spacebattles.com/#the-real-world.33" itemprop="item">
			<span itemprop="name">The Real World</span>
		</a>
		<meta itemprop="position" content="1">
	</li>

			
				
				
	<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
		<a href="https://forums.spacebattles.com/forums/news-society-focused-discussion.7/" itemprop="item">
			<span itemprop="name">News &amp; Society Focused Discussion</span>
		</a>
		<meta itemprop="position" content="2">
	</li>

			

		
		</ul>
		
		</div>
	

		  

		
		
	</div> <!-- closing xb-content-wrapper -->


	

		
			
		

		
	


</div> <!-- closing xb-pageWrapper -->



	



	
	
	

	



	
	

		
			
		

		
	


	













	

	

	









<!-- XenBase Version: 2.2.5 -->

	
	
		
		
			
		
	



	

		
			
		

		
	


















			
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS: IPv4 addresses cost too much, so you’re going to pay (138 pts)]]></title>
            <link>https://www.theregister.com/2023/07/31/aws_says_ipv4_addresses_cost/</link>
            <guid>36942424</guid>
            <pubDate>Mon, 31 Jul 2023 13:50:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/31/aws_says_ipv4_addresses_cost/">https://www.theregister.com/2023/07/31/aws_says_ipv4_addresses_cost/</a>, See on <a href="https://news.ycombinator.com/item?id=36942424">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Cloud giant AWS will start charging customers for public IPv4 addresses from next year, claiming it is forced to do this because of the increasing scarcity of these and to encourage the use of IPv6 instead.</p>
<p>It is now four years since we <a target="_blank" href="https://www.theregister.com/2019/11/25/ipv4_addresses_gone/">officially ran out</a> of IPv4 ranges to allocate, and since then, those wanting a new public IPv4 address have had to rely on address ranges being recovered, either from from organizations that close down or those that return addresses they no longer require as they migrate to IPv6.</p>
<p>If Amazon's cloud division is to be believed, the difficulty in obtaining public IPv4 addresses has seen the cost of acquiring a single address rise by more than 300 percent over the past five years, and as we all know, the business is <a target="_blank" href="https://www.theregister.com/2023/04/28/cloud_slowdown_hits_amazon_as/">a little short of cash at the moment</a>, so is having to pass these costs on to users.</p>

    

<p>"This change reflects our own costs and is also intended to encourage you to be a bit more frugal with your use of public IPv4 addresses and to think about accelerating your adoption of IPv6 as a modernization and conservation measure," writes AWS Chief Evangelist Jeff Barr, on the company <a target="_blank" href="https://aws.amazon.com/blogs/aws/new-aws-public-ipv4-address-charge-public-ip-insights/">news blog</a>.</p>

        


        

<p>The update will come into effect on February 1, 2024, when AWS customers will see a charge of $0.005 (half a cent) per IP address per hour for all public IPv4 addresses. These charges will apparently apply whether the address is attached to a service or not, and like many AWS charges, appear inconsequential at first glance but can mount up over time if a customer is using many of them.</p>
<p>These charges will apply to all AWS services including EC2, Relational Database Service (RDS) database instances, Elastic Kubernetes Service (EKS) nodes, and will apply across all AWS regions, the company said.</p>

        

<p>However, customers will not be charged for IP addresses that they own and bring to AWS using Amazon's BYOIP feature. AWS offers a free tier for EC2, and this will include 750 hours of public IPv4 address usage per month for the first 12 months, starting from the same date the charges do.</p>
<p>To try and help customers get a handle on how this might affect their AWS bill, the company said it is adding information on public IPv4 addresses to the AWS Cost and Usage Report (CUR). It also unveiled a new feature of Amazon VPC IP Address Management (IPAM) called <a target="_blank" href="https://docs.aws.amazon.com/vpc/latest/ipam/view-public-ip-insights.html">Public IP Insights</a>, which is intended to simplify analysis and auditing of public IPv4 addresses.</p>
<h3>10 years later</h3>
<p>It is now more than a decade since IPv6 was <a target="_blank" href="https://www.theregister.com/2012/06/05/ipv6_launch_day/">officially launched</a>, but adoption has been slow and gradual as many organizations saw little need to change at first, especially when managing a migration from the older standard to the new one was likely to be complex.</p>
<p>Although the world officially ran out of unallocated IPv4 addresses in 2019, according to the European regional Internet registry RIPE, it <a target="_blank" href="https://labs.ripe.net/author/wilhelm/ipv6-10-years-out-an-analysis-in-users-tables-and-traffic/">posted figures</a> last year showing that the IPv4 routing table still has six times as many entries as that for IPv6.</p>
<p>However, this apparent disparity may be slightly misleading, it claimed, as internet registries have taken advantage of the massive 128-bit address space of IPv6 to ensure that "organizations receive blocks that are, in many cases, large enough to cover all their future addressing needs" when allocating new address ranges, whereas IPv4 saw ever smaller allocation sizes as the address space filled up.</p>
<ul>

<li><a href="https://www.theregister.com/2023/01/25/nsa_ipv6_guidelines/">IPv6 for Dummies: NSA pushes security manual on DoD admins</a></li>

<li><a href="https://www.theregister.com/2022/09/29/reverse_dns_queries_reveal_too/">Reverse DNS queries may reveal too much, computer scientists argue</a></li>

<li><a href="https://www.theregister.com/2022/09/28/microsoft_exchange_online_cars/">Microsoft to kill off old access rules in Exchange Online</a></li>

<li><a href="https://www.theregister.com/2022/09/07/ovhcloud_ipv4/">OVHcloud opens up Bring Your Own IP service for IPv4 failover</a></li>
</ul>
<p>"Even once all networks have deployed and announced IPv6, we can expect the routing table to be smaller than that for IPv4," RIPE claimed.</p>
<p>RIPE also quoted IPv6 adoption by end users last year, as estimated by Google and APNIC, the regional internet address registry for the Asia-Pacific region, as being between 30 percent and 40 percent.</p>

        

<p>But as <em>The Register</em> wrote back when IPv4 addresses officially ran out, it is going to be with us for a good few years yet. RIPE was predicting then that it might take "five to 10 years" before the world starts to truly abandon the IPv4 address space. Four years of that have already passed, and IPv4 still seems to be going as strong as ever. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Linkwarden – An open source collaborative bookmark manager (199 pts)]]></title>
            <link>https://linkwarden.app</link>
            <guid>36942308</guid>
            <pubDate>Mon, 31 Jul 2023 13:41:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linkwarden.app">https://linkwarden.app</a>, See on <a href="https://news.ycombinator.com/item?id=36942308">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Linkwarden is a fully self-hostable, open-source collaborative bookmark manager to collect, organize and archive webpages.</p><div><div><div><p>Collect and Organize Webpages Effortlessly</p><p>Whether you stumble upon an interesting article, a valuable resource, or a design inspiration relating to your project, Linkwarden makes it a breeze to save, store, and categorize them all in one central hub.</p><ul><li><span>check</span><p>Collect Links from any browser with just a few click, so you can easily access all your saved webpages in one place.</p></li><li><span>check</span><p>Effortlessly organize your links with custom tags and folders, so you can easily find what you need when you need it.</p></li><li><span>check</span><p>Instantly create collections to group related links, ensuring a clutter-free and intuitive link management system.</p></li></ul></div><p><img alt="" loading="lazy" width="900" height="900" decoding="async" data-nimg="1" src="https://linkwarden.app/app/collect.png"></p></div><div><div><p>Preserve Your Webpages for Eternity</p><p>Preserve the webpages you love and never worry about broken links again. Linkwarden allows you to revisit your favorite web content, even if the original page is no longer available.</p><ul><li><span>check</span><p>Auto-capture a copy of each webpage as a Screenshot (.png) and a PDF, two of the most used formats out there.</p></li><li><span>check</span><p>Download your archived webpages, ensuring you have access to crucial information even without an internet connection.</p></li><li><span>check</span><p>Safeguard your webpages against<!-- --> <a target="_blank" href="https://www.howtogeek.com/786227/what-is-link-rot-and-how-does-it-threaten-the-web/">Link Rot</a>, preventing them from becoming dead or broken over time.</p></li></ul></div><p><img alt="" loading="lazy" width="900" height="900" decoding="async" data-nimg="1" src="https://linkwarden.app/app/preserve.png"></p></div><div><div><p>Collaborate and Share with Ease</p><p>Linkwarden isn't just for personal use. It's the perfect tool to supercharge your collaboration efforts, making teamwork smoother and more efficient.</p><ul><li><span>check</span><p>Invite team members to collaborate on shared collections, streamlining research and knowledge sharing.</p></li><li><span>check</span><p>Assign customizable permissions to each member, giving you full control over who can create, edit, or delete links within your shared collections.</p></li><li><span>check</span><p>Easily share curated collections with the public, so they can benefit from your expertise and curated content.</p></li></ul></div><p><img alt="" loading="lazy" width="900" height="900" decoding="async" data-nimg="1" src="https://linkwarden.app/app/collaborate.png"></p></div><div><p>Hold on, there's more!</p><div><div><p><span>check_box</span></p><p>Open source and fully Self-hostable.</p></div><div><p><span>check_box</span></p><p>Designed for every screen size.</p></div><div><p><span>check_box</span></p><p>Powerful Search.</p></div><div><p><span>check_box</span></p><p>Intuitive design.</p></div><div><p><span>check_box</span></p><p>Pin your favorite Links to dashboard.</p></div><div><p><span>check_box</span></p><p>Import/Export your data. (Soon)</p></div></div><p>+ Many More Features</p></div></div><div><p>Sign up Now to Experience Linkwarden!</p><p>14-day free trial, cancel anytime.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A fridge from 70 years ago has better features than the fridge I own now (284 pts)]]></title>
            <link>https://mstdn.social/@Pandamoanimum/110808340828034444</link>
            <guid>36942266</guid>
            <pubDate>Mon, 31 Jul 2023 13:37:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mstdn.social/@Pandamoanimum/110808340828034444">https://mstdn.social/@Pandamoanimum/110808340828034444</a>, See on <a href="https://news.ycombinator.com/item?id=36942266">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Fibonacci Matrix (109 pts)]]></title>
            <link>https://ianthehenry.com/posts/fibonacci/</link>
            <guid>36942033</guid>
            <pubDate>Mon, 31 Jul 2023 13:14:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ianthehenry.com/posts/fibonacci/">https://ianthehenry.com/posts/fibonacci/</a>, See on <a href="https://news.ycombinator.com/item?id=36942033">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<div><p>When you think about the Fibonacci sequence, you probably imagine a swirling vortex of oscillating points stretching outwards to infinity:</p>
<p><canvas id="teaser" width="384" height="256"><a href="https://ianthehenry.com/posts/fibonacci/hero.f8f0320540a779c19ec927ada02ec9ecbfd90a6d6d418f8e71e99ac4e5d4deca.png"><picture>
<img src="https://ianthehenry.com/posts/fibonacci/hero.f8f0320540a779c19ec927ada02ec9ecbfd90a6d6d418f8e71e99ac4e5d4deca.png" width="768" height="512"></picture></a>
</canvas></p>
<p>Okay, no, obviously you don’t. <em>Yet</em>.</p>
<p>When you think about the Fibonacci sequence, you probably flush with a latent rage when you remember that it is, more often than not, the way that we introduce the concept of “recursive functions” to new programmers, in some sort of cruel hazing intended to make it harder for them to ever appreciate how recursion can help them write better programs. Sometimes we even add memoization, and call it “dynamic programming,” in order to impress upon them that even the most trivial problems deserve complex, inefficient solutions.</p>
<p>Er, okay, you probably don’t think about the Fibonacci sequence much at all. It doesn’t, you know, come up very often.</p>
<p>But I hope that you will spend some time thinking about it with me today, because I think that the Fibonacci sequence – despite being a terrible showcase for recursion – is a really interesting vector for discussing some techniques from linear algebra.</p>
<div>
<table>
<thead><tr><th>how to fibonacci</th><th>space complexity</th><th>time complexity</th></tr></thead>
<tbody>
<tr><td>insane recursion</td><td>exponential</td><td>exponential</td></tr>
<tr><td>memoized insane recursion</td><td>linear</td><td>linear</td></tr>
<tr><td>trivial iteration</td><td>constant</td><td>linear</td></tr>
<tr><td>exponentiation-by-squaring</td><td>constant</td><td>logarithmic</td></tr>
<tr><td>eigendecomposition</td><td colspan="2">let's talk</td></tr>
</tbody>
</table>
</div>
<p>We will spend no time on the recursive Fibonaccis; I’m sure that you’ve seen them before. Instead, let’s skip right to the “obvious” way to calculate Fibonacci numbers:</p>
<div><pre tabindex="0"><code data-lang="javascript"><span>function</span> <span>fib</span><span>(</span><span>n</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>n</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>let</span> <span>current</span> <span>=</span> <span>1</span><span>;</span>
  <span>let</span> <span>previous</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n</span> <span>-</span> <span>1</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>const</span> <span>next</span> <span>=</span> <span>current</span> <span>+</span> <span>previous</span><span>;</span>
    <span>previous</span> <span>=</span> <span>current</span><span>;</span>
    <span>current</span> <span>=</span> <span>next</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>current</span><span>;</span>
<span>}</span>
</code></pre></div><p>No recursion, no memoization. We have two pieces of state: the “current number” and the “previous” number, and at every step of the iteration we advance both of these to new values.</p>
<p>But there’s something very interesting about this function: the new values for our state are a <em>linear combination</em> of the old values.</p>
<pre><code>current'  = current + previous
previous' = current
</code></pre>
<p>Using <code>x'</code> to mean “the next value for <code>x</code>.”</p>
<p>And you might recognize this as a “system of linear equations.” I think it’s more obvious when we write it like this:</p>
<pre><code>current'  = 1 * current + 1 * previous
previous' = 1 * current + 0 * previous
</code></pre>
<p>And you might remember that there’s another, more cryptic way to write down a system of linear equations:</p>

<p>This is exactly the same thing! This is just another way of writing the equation – it’s just a shorthand notation.</p>
<p>Here, let’s test it out to make sure of that:</p>
<div>


<p>=</p>
<div>
<table>
<thead>
<tr>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1 • 8 + 1 • 5</td>
</tr>
<tr>
<td>1 • 8 + 0 • 5</td>
</tr>
</tbody>
</table>
</div>
<p>=</p>

</div>
<p>Well that’s exactly what we expected – 13 is the next Fibonacci number in the sequence, and 8 was the previous one.</p>
<p>We can, of course, repeat this process, by applying the system of linear equations again:</p>

<p>Or, to put that another way:</p>

<p>And here’s why we care: matrix multiplication is associative, so we can actually think of that like this:</p>

<p>Or:</p>

<p>In other words: given a system of linear equations to find the <em>next</em> state of our iteration, we can square the matrix-of-coefficients of the system to find a new system of linear equations that represents “two states from now.”</p>
<p>Of course we don’t <em>need</em> matrices to do this. We can compute a formula for “two steps” of our iteration using term substitution:</p>
<pre><code>current'  = current + previous
previous' = current

current''  = current' + previous'
previous'' = current'

current''  = (current + previous) + current
previous'' = (current + previous)

current''  = 2 * current + previous
previous'' = current + previous
</code></pre>
<p>Which is a new system of linear equations – which we can represent as a matrix as well.</p>

<p>We got the same result, because of course we did: multiplying by this matrix really <em>means</em> “advance to the next state.” Multiplying twice means “advance to the next state and then advance to the next state after that.”</p>
<p>And we can keep going. What’s the state three steps from now?</p>

<p>Or, more concisely:</p>

<p>If we do this repeatedly, you might notice a familiar pattern start to emerge:</p>



<p>Which makes sense, doesn’t it? Because if we multiply this matrix with the matrix <code>[1 0]</code> – our starting values – then it’s going to advance forward through six steps of the Fibonacci sequence in a single leap. So naturally we have to be encoding <em>something</em> about the sequence itself in the matrix – otherwise we wouldn’t be able to advance by N steps in constant time.</p>
<p>Now, the insight that takes this from linear to logarithmic is that we don’t have to do this multiplication one step at a time. We can multiply in leaps and bounds.</p>
<p>Let’s call our original starting matrix F, for Fibonacci.</p>

<p>We’ve already calculated F<sup>2</sup>:</p>

<p>And now it’s only one more matrix multiplication to calculate F<sup>4</sup>:</p>

<p>We can use this fact to calculate arbitrary matrix powers, by breaking the problem up into sums of powers of two:</p>

<p>And by doing that, we can calculate the nth Fibonacci number in only log<sub>2</sub>(n) steps.</p>

<p>Okay, so that’s fun and all, but that’s not really what this blog post is about.</p>
<p>I don’t know about you, but if I came across this matrix in the wild, I would not think “Oh, that’s the Fibonacci sequence”:</p>

<p>I would probably think “huh, I dunno, it’s like, a reflection, sort of, or maybe a shear; what’s a shear again, hang on, I need to see a picture.”</p>
<p>That is, I am used to thinking of matrices as transformations of <em>points in space</em> – scales and rotations and things like that. I’m not really used to thinking of matrices as “state machines.”</p>
<p>But this duality is the beauty of linear algebra! Matrices are transformations of points in space and graphs and state machines all at the same time.</p>
<p>So let’s take a look at the Fibonacci <em>transformation</em>, applied to arbitrary points in R<sup>2</sup>:</p>

<p>That animation is progressively applying and removing the transformation, so we can get some intuition for how it deforms a square. But we’re really more interested in repeated applications of the transformation. So let’s start with the same points, but multiply by that same matrix over and over:</p>

<p>Interesting. Over time, they have a tendency to stretch out along the long diagonals of this rhombus. Let’s zoom out:</p>

<p>Every time a point reflects over that diagonal, it reflects at a slightly different angle, slowly converging towards this straight line.</p>
<p>You might already have an idea of what that straight line means. You might know that, if you look at the ratio between subsequent Fibonacci numbers, they approximate the <em>golden ratio</em>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<pre><code>1  /  1 = 1
2  /  1 = 2
3  /  2 = 1.5
5  /  3 = 1.666...
8  /  5 = 1.6
13 /  8 = 1.625
21 / 13 = 1.61538462
34 / 21 = 1.61904762
</code></pre>
<p>The golden ratio is irrational, but every subsequent Fibonacci number is a better and better rational approximation. (The golden ratio is around 1.618033988749 – so we’re already pretty close.)</p>
<p>It’s interesting to see that these estimations don’t “sneak up” on the golden ratio. In fact they alternate between over- and under-estimating it. Which is exactly what we saw in our visualization!</p>
<p>If you return to the “state machine” interpretation of our matrix, remember that the value we’re plotting as <code>x</code> is really “the current Fibonacci number,” and the value we’re plotting as <code>y</code> is “the previous Fibonacci number.” So the ratio between successive numbers – <code>x/y</code> – is just the slope of the lines that our points are traveling along. And we could see points reflecting over that diagonal, over- and under-shooting it, slowly converging… towards the line whose slope is the golden ratio.</p>
<p>Which is, in fact, the “long diagonal” of our rhombus.</p>
<p>And this makes sense, I think – this isn’t some weird coincidence. The golden ratio is all about the ratio between parts and wholes being the same as ratio between parts. And the Fibonacci sequence is all about adding together parts to become wholes that become parts in the next number of the sequence.</p>
<p>Here, our two parts are the “current” and “previous” values, and the whole that they make is the “next” Fibonacci number. Even if we start with two numbers that are completely unrelated to the Fibonacci sequence – say, <code>8</code> and <code>41</code> – the simple way that we pick the next number will cause us to approximate the golden ratio after only a few iterations:</p>
<pre><code>8 / 41 = 0.1951219
(8 + 41 = 49) / 8 = 6.125
(49 + 8 = 57) / 49 = 1.16326531
(57 + 49 = 106) / 57 = 1.85964912
(106 + 57 = 163) / 106 = 1.53773585
</code></pre>
<p>Why is that? Well, because of the definition of the golden ratio.</p>

<p>This is <em>extremely</em> unrigorous, but I can try to sketch out a very informal argument for why this is:</p>
<p>Let’s say the ratio between <code>A</code> and <code>B</code> is some unknown quantity <code>S</code>. It’s not the golden ratio, it might not be anywhere near the golden ratio; we have no idea what it is. In my 8 and 41 example, it wasn’t even in the right ballpark.</p>
<div>
<p>A/B = S</p>
<p>(A + B) / A = (1 + B / A) = 1 + (1/S)</p>
</div>
<p>So the ratio between the next element in our series and A will be <code>(1 + (1/S))</code>.</p>
<p>We still don’t know what <code>S</code> is! But if we do this <em>again</em>…</p>
<div>
<p>A' / B' = 1 + (1/S)</p>
<p>(A' + B') / A' =</p>
<p>(1 + (B' / A')) =</p>
<p>1 + (1 / (1 + (1 / S)))</p>
</div>
<p>After each iteration, the original <code>S</code> will become a smaller and smaller component in the final answer, until eventually we’ll just have an expression that looks like this:</p>
<div>
<p>1 + (1 / (1 + (1 / (1 + (1 / (1 + (1 / ...)))))))</p>
</div>
<p>Whatever our original <code>S</code> was, its contribution to the final result will eventually be negligible. Even after just a few iterations, we can see that the choice of <code>S</code> doesn’t make a huge difference in the outcome:</p>
<div>
<p>1 + (1 / (1 + (1 / (1 + (1 / (1 + (1 / -5000))))))) = 1.6667</p>
<p>1 + (1 / (1 + (1 / (1 + (1 / (1 + (1 / 0.001))))))) = 1.5002</p>
</div>
<p>And of course even that will fade away after a few more steps.</p>
<p>In fact the version of that expression with an infinite number of steps – where there is no <code>S</code> at all, but just an infinite sequence of divisions – is the “continued fraction” expression of the golden ratio.</p>
<p>Except, well, I’m lying here.</p>
<p>That residue will not fade away for <em>all</em> values of <code>S</code>. First of all, if <code>S</code> is zero, it doesn’t matter how small that term gets – you’re not going to squeeze a number out of it.</p>
<p>But there is another, more interesting value of <code>S</code> that breaks this rule. There is <em>one</em> other number that will not tend towards 1.618 when you repeatedly take its reciprocal and add one. It is the number that is already one plus its own reciprocal:</p>
<div>
<p>1 + (1 / 1.61803399) = 1.61803399</p>
</div>
<p>Oh, gosh, yes, the golden ratio is one plus its own reciprocal. But I was talking about the <em>other</em> number with that property:</p>
<div>
<p>1 + (1 / -0.61803399) = -0.61803399</p>
</div>
<p>This number is (1 - φ), and it is also -φ<sup>-1</sup>. The golden ratio is weird like that.</p>
<p>That number is a weird number, because if we have two numbers with that ratio – say, <code>-1.236</code> and <code>2</code> – and we applied our transformation, those points would not spread their wings towards the diagonal. What would they do instead?</p>

<p>Aha. Well, that makes sense.</p>
<p>Some points tend towards the top right, some points tend towards the bottom left, but some points get <em>stuck</em>. Sucked into the origin, cursed to forever travel along this one straight line.</p>
<p>Points along the long diagonal also travel in a straight line – they don’t bounce over the diagonal, because they’re already on it. Let’s just focus on these perfectly straight lines:</p>

<p>Not all matrices will produce straight lines like this when you apply them repeatedly. A rotation matrix, for example, will always change the direction of every single line each time you multiply a point by it.</p>
<p>These straight lines are called <em>eigenvectors</em>, which is German for something like “intrinsic vector” or “characteristic vector."<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Well, to be more precise, any particular point on those straight lines is an “eigenvector.” The vector <code>[φ 1]</code> is an eigenvector, and so is <code>[-2.1φ -2.1]</code>. And the vector <code>[-1/φ 1]</code> is an eigenvector, and so is <code>[-2/φ 2]</code>.</p>
<p>But all of the eigenvectors on each line are “similar,” so I’m just going to pick <code>[φ 1]</code> and <code>[(1-φ) 1]</code> as our two representative eigenvectors.</p>
<p>When you multiply an eigenvector of a matrix by the matrix itself, you get back a new eigenvector on “the same line.” That is to say, you get back another eigenvector that is just some scalar multiple of the original eigenvector.</p>
<p>For example, when we multiply our first eigenvector by the Fibonacci matrix:</p>

<p>Well… it’s not <em>obvious</em> that this is the case, but we actually just scaled the vector by φ. Because φ<sup>2</sup> = φ + 1. The golden ratio is weird.</p>
<p>Similarly:</p>

<p>We scaled it by (1 - φ), again somewhat cryptically:</p>
<div>
<p>(1 - φ)(1 - φ) =</p>
<p>(1 - 2φ + φ<sup>2</sup>) =</p>
<p>(1 - 2φ + φ + 1) =</p>
<p>(2 - φ)</p>
</div>
<p>So when we multiply our Fibonacci matrix with its eigenvectors, we scale those numbers by φ and (1 - φ). These scaling factors are called “eigenvalues,” and it’s <em>weird</em> that they look so much like the eigenvectors. That’s… that’s a weird Fibonacci coincidence, a weird golden ratio thing, and not a general pattern that holds for eigenvectors and eigenvalues in general.</p>
<p>Okay, so why do we care about this?</p>
<p>Well, once we know the eigenvectors and eigenvalues of the matrix, we can actually perform repeated matrix multiplication in <em>constant</em> time.</p>
<p><em>…Sort of</em>. You have to imagine a big asterisk after that sentence, which I will explain below.</p>
<p>To explain how, we’re going to need to do a little bit of linear algebra. But first, I just want to restate everything I’ve said so far in explicit notation:</p>
<p>Multiplying F with each eigenvector is the same as multiplying that eigenvector by its corresponding eigenvalue. So:</p>

<p>And:</p>

<p>Right. But there’s actually a way to write those two equalities as a single equality:</p>

<p>Instead of writing out each eigenvector as a separate column vector, I stuck them into a matrix. And instead of scaling each one by a scalar, I multiplied that matrix by a diagonal matrix.</p>
<p>This is the same statement, though: right-multiplication by a diagonal matrix just means “scale the columns of the left matrix by the corresponding diagonal value.” We can gut check this by performing the multiplcation, and seeing that we’re making the exact same statements as before:</p>


<p>But now we’re making these statement about both eigenvectors in parallel.</p>
<p>This equality – this statement about how multiplication by the Fibonacci matrix scales eigenvectors – is the secret to computing Fibonacci numbers in “constant time”:</p>

<p>The trick here is that we’re going to right-multiply both sides of the equation by the inverse of our eigenvector matrix. This will eliminate it from the left-hand side entirely:</p>

<p>And now we have a new way to calculate the “next Fibonacci number.” Previously we knew how to do it by multiplying with the matrix <code>F</code>. Now we can do it by multiplying with, uhh, this inverse eigenvector matrix thing, and then the diagonal matrix of eigenvalues, and then the non-inverse matrix-of-eigenvectors.</p>
<p>Much simpler, right?</p>
<p>This is getting really long and complicated and I’m going to run out of space soon, so let’s give these things names:</p>



<p>That’s an upper-case lambda, and look, it’s just the convention for the eigenvalue matrix. Eigenvalues are called <code>λ</code>, and when you put them in a diagonal matrix you call it <code>Λ</code>. I don’t make the rules here.</p>
<p>Now that we have some abbreviations, we can write that as the much more palatable:</p>

<p>Now, the whole reason that we’re doing this is to take advantage of another trick of associativity:</p>




<p>That was very abstract, so take a second to think about what this <em>means</em>. F<sup>2</sup> is the matrix that calculates two steps of our Fibonacci state machine. And we can use this same trick to calculate <em>any</em> power of F, just by calculating powers of Λ.</p>

<p>And this is good, because Λ is a <em>diagonal</em> matrix. And it’s really easy to exponentiate a diagonal matrix! You just exponentiate each element of its diagonal. We don’t even need to use repeated squaring.</p>
<p>This means that we can actually calculate arbitrary powers of F in <em>constant</em> time… if we pretend that exponentiation of a scalar is a constant time operation.</p>
<p>It’s not, though. I mean, yes, exponentiation of an IEEE 754 64-bit floating-point <em>is</em> constant time, but that’s not what we said. We’re talking about exponentiating an irrational number, and my computer can only represent approximations of that number, and that floating-point error adds up fast. So in order to actually use this to compute large Fibonacci numbers, we would need to use arbitrary-precision floating point, and exponentiating arbitrary precision values is <em>not</em> constant time. It’s… I don’t know, probably logarithmic? But like both to the exponent and the size of the result, and the size of the result is increasing exponentially, so it nets out to linear? I don’t actually know.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<p>But I don’t want to spoil the fun. This is still a very interesting trick, and it’s worth understanding how it works, even if it doesn’t actually give us a way to compute arbitrarily large Fibonacci numbers in constant time.</p>
<p>So: what are we doing.</p>
<p>We moved a bunch of symbols around, and we wound up with this expression:</p>

<p>But I don’t really know what Q<sup>-1</sup> means, and it’s not really clear to me why I should care. Why is multiplying by these three weird matrices the same as multiplying by F? What, intuitively, are we doing here?</p>
<p>At a high level, we’re translating points into a different coordinate system, then doing something to it, and then translating them back into our original coordinate system.</p>
<p>You already know that we can write any point in space as a vector – X and Y coordinates. That’s what we’ve been doing this whole time.</p>
<p>But we can <em>also</em> write a point in space as the sum of two other vectors. Like, <code>[5 3]</code>. We could write that as <code>[1 2] + [4 1]</code> instead. Which, okay, sure. That’s not very interesting.</p>
<p>One “interesting” way to write <code>[5 3]</code> is as the sum of these two vectors: <code>[5 0] + [0 3]</code>. Or, to say that another way:</p>

<p>This is interesting because <code>[1 0]</code> and <code>[0 1]</code> are basically the “X axis” and “Y axis.” And we can think of the point <code>[5 3]</code> as a (trivial!) linear combination of these two axes.</p>
<p>But we could pick <em>different</em> axes. We can pick any vectors we want as our axes,<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> so let’s pretend for a moment that our axes are <code>[1 1]</code> and <code>[1 -1]</code> instead. Which means that we would write <code>[5 3]</code> as:</p>

<p>Or, to write that another way:</p>

<p>Alright. Why do we care?</p>
<p>Well, we can think of this vector-of-coefficients, <code>[4 1]</code>, as another way to identify the point in space <code>x=5 y=3</code> when we we’re pretending that our axes are <code>[1 1]</code> and <code>[1 -1]</code>. Except in linear algebra we’d call these “basis vectors” instead of “axes.”</p>
<p>But how did we find the coefficients <code>[4 1]</code>? Well, I just found that one by hand; it was pretty easy. But <em>in general</em>, if we want to express some other <em>point</em> using these basis vectors – let’s say <code>[63 -40]</code> – we’ll need to solve an equation that looks like this:</p>

<p>And we can do that by, you know, regular algebra. We “divide” both sides by our matrix-of-basis-vectors, by left-multiplying with the inverse matrix:</p>

<p>And after the inverses cancel, we’re left with the following formula:</p>

<p>And the problem reduces to matrix inversion.</p>
<p>Now, I don’t know about you, but I don’t remember how to invert a matrix. I know there’s a formula in two dimensions, but the only thing I remember about it is that it involves calculating the determinant, and I forgot how to do that too. So let’s just ask a computer to invert it for us:</p>

<p>Hmm. I feel like I probably could’ve worked that out myself.</p>
<p>But that lets us solve the equation, and figure out how to write the point <code>[63 -40]</code> as a combination of the vectors <code>[1 1]</code> and <code>[1 -1]</code>:</p>

<p>Great! We did it.</p>
<p>And <em>here’s why we care:</em></p>
<p>We can use this exact same trick to write down the points in our Fibonacci sequence as a linear combination of our two eigenvectors. Like this:</p>

<p>Click or tap to add points there, to see how we can write each point in space as a combination of the “short diagonal” and “long diagonal” eigenvectors of our matrix.</p>
<p>Normally to identify a point in space we would give its XY coordinates: go this far along the X-axis, then this far along the Y-axis. But here we’re representing points in “φ” and “1 - φ” coordinates: go this far along the short diagonal, then this far along the long diagonal.</p>
<p>But how do we know how far to go along these diagonals? Well, we “divide by” the eigenvectors. In other words, we have to compute the inverse of this matrix:</p>


<p>Now, matrix inversion is boring, so I’m just presenting the answer here. This inverse matrix is how we can convert from “XY coordinates” into “eigenvector coordinates.”</p>
<p>Let’s work through a concrete example to make sure this works.</p>
<p><code>[8 5]</code> is a point on the Fibonacci sequence. We can express that as a combination of eigenvectors instead:</p>

<p>4.96 and 0.04 are the coefficients we will pair with our eigenvectors: we have to travel 4.96 units down the long diagonal, and 0.04 units along the short diagonal to arrive at the point <code>[8 5]</code>.</p>

<p>Great. It worked!</p>
<p>But that wasn’t very interesting – we just converted our point into the eigenvector basis and then right back into the normal XY basis. It was kind of a pointless transformation.</p>
<p>But we don’t have to do the unconversion immediately. We can keep the point in this “eigenbasis” for a little while, and do stuff to the vector-of-coefficients, and <em>then</em> convert it back.</p>
<p>Specifically, we can scale the coefficients by the eigenvalues of our Fibonacci matrix. We can multiply the “long diagonal” component by Φ<sup>2</sup>, and multiply the short diagonal component by (1 - Φ)<sup>2</sup>, and we’ll have a new point: something close to <code>[12.985 0.015]</code>. And if we convert that back into XY coordinates:</p>

<p>We just advanced our point two more steps along the Fibonacci sequence, with nothing more than scalar exponentiation and a constant number of vector operations.</p>
<p>This is exactly the same as the expression:</p>

<p>But as someone with no background in linear algebra, I find it easy to get lost in the notation, so it’s easier for me to think about this as operations on separate column vectors rather than as operations on matrices. Even though they are the same thing.</p>
<p>Of course, calculating two steps of the Fibonacci sequence in constant time isn’t that impressive. But we can do the same with Φ<sup>1000</sup>, and use that to calculate the thousandth Fibonacci number in constant time.</p>
<p>…Assuming we could calculate Φ<sup>1000</sup> in constant time. Which we can’t, in real life.</p>
<hr>
<p>Alright.</p>
<p>The post is over; you saw the trick. “Eigendecomposition,” this is called.</p>
<p>I glossed over a few steps – I spent absolutely no time explaining <em>how I knew</em> the eigenvalues and eigenvectors of this matrix, for example. I just asserted that they were related to the golden ratio. But in reality you can solve for them, or ask a computer to do it for you. It’s pretty mechanical, like matrix inversion – it seems linear algebra is best explored with a repl nearby.</p>
<p>In any case, I think that the <em>why</em> of eigendecomposition is more interesting than the <em>how</em>.</p>
<p>As for the Fibonacci sequence… well, this is a pretty terrible way to actually calculate Fibonacci numbers. Even if we pretend that we only care about numbers that can fit in IEEE 754 double-precision floats, we <em>still</em> can’t use this technique to calculate very many Fibonacci numbers, because the floating-point error adds up too quickly.</p>
<p>But if we only care about double-precision floats… well, there is one more Fibonacci implementation to consider. It’s an algorithm that that runs in constant time, and constant space, and covers the full gamut of floating-point numbers without accumulating any error at all…</p>
<div><pre tabindex="0"><code data-lang="javascript"><span>const</span> <span>fibs</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>8</span><span>,</span> <span>13</span><span>,</span> <span>21</span><span>,</span> <span>34</span><span>,</span> <span>55</span><span>,</span> <span>89</span><span>,</span> <span>144</span><span>,</span> <span>233</span><span>,</span> <span>377</span><span>,</span> <span>610</span><span>,</span> <span>987</span><span>,</span> <span>1597</span><span>,</span> <span>2584</span><span>,</span> <span>4181</span><span>,</span> <span>6765</span><span>,</span> <span>10946</span><span>,</span> <span>17711</span><span>,</span> <span>28657</span><span>,</span> <span>46368</span><span>,</span> <span>75025</span><span>,</span> <span>121393</span><span>,</span> <span>196418</span><span>,</span> <span>317811</span><span>,</span> <span>514229</span><span>,</span> <span>832040</span><span>,</span> <span>1346269</span><span>,</span> <span>2178309</span><span>,</span> <span>3524578</span><span>,</span> <span>5702887</span><span>,</span> <span>9227465</span><span>,</span> <span>14930352</span><span>,</span> <span>24157817</span><span>,</span> <span>39088169</span><span>,</span> <span>63245986</span><span>,</span> <span>102334155</span><span>,</span> <span>165580141</span><span>,</span> <span>267914296</span><span>,</span> <span>433494437</span><span>,</span> <span>701408733</span><span>,</span> <span>1134903170</span><span>,</span> <span>1836311903</span><span>,</span> <span>2971215073</span><span>,</span> <span>4807526976</span><span>,</span> <span>7778742049</span><span>,</span> <span>12586269025</span><span>,</span> <span>20365011074</span><span>,</span> <span>32951280099</span><span>,</span> <span>53316291173</span><span>,</span> <span>86267571272</span><span>,</span> <span>139583862445</span><span>,</span> <span>225851433717</span><span>,</span> <span>365435296162</span><span>,</span> <span>591286729879</span><span>,</span> <span>956722026041</span><span>,</span> <span>1548008755920</span><span>,</span> <span>2504730781961</span><span>,</span> <span>4052739537881</span><span>,</span> <span>6557470319842</span><span>,</span> <span>10610209857723</span><span>,</span> <span>17167680177565</span><span>,</span> <span>27777890035288</span><span>,</span> <span>44945570212853</span><span>,</span> <span>72723460248141</span><span>,</span> <span>117669030460994</span><span>,</span> <span>190392490709135</span><span>,</span> <span>308061521170129</span><span>,</span> <span>498454011879264</span><span>,</span> <span>806515533049393</span><span>,</span> <span>1304969544928657</span><span>,</span> <span>2111485077978050</span><span>,</span> <span>3416454622906707</span><span>,</span> <span>5527939700884757</span><span>,</span> <span>8944394323791464</span><span>];</span>

<span>const</span> <span>fib</span> <span>=</span> <span>(</span><span>n</span><span>)</span> <span>=&gt;</span> <span>fibs</span><span>[</span><span>n</span><span>];</span>
</code></pre></div><p>But it’s more fun to overthink it.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>In case you are one of today’s lucky 10,000: the golden ratio is also very close to the conversion rate between miles and kilometers, so you can use Fibonacci numbers to approximate conversions between miles and kilometers in your head. For example, 80km ≈ 50mi. This is a <em>weirdly</em> good conversion – the exact answer is 49.7097mi.</p>
<p>It even works when you don’t have a round Fibonacci number to work with. 120kph is probably around 90% of 130kph, and 90% of 80mph is 72mph… the correct answer would be 74.6mph, but we got a decent ballpark with nothing but eyeball math.&nbsp;<a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Straight lines are eigenvectors, but eigenvectors are not necessarily straight lines. Rotation matrices <em>also</em> have eigenvectors, but they have <em>complex</em> eigenvectors. Straight lines like this are <em>real</em> eigenvectors.&nbsp;<a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The exact same argument applies to the “logarithmic” exponentiation-by-squaring algorithm as well – squaring arbitrarily large numbers requires arbitrary precision multiplication. It feels different to me, though, because of floating point error: when you’re exponentiating eigenvalues, you need to use arbitrary precision arithmetic even when your final answer could fit into a double. But the integer squaring approach only needs bigints when the Fibonacci numbers themselves become too large to fit into words.&nbsp;<a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>As long as the vectors we pick are “linearly independent” – there’s no way to express <code>[5 3]</code> as a combination of <code>[1 0]</code> and <code>[2 0]</code>, for example.&nbsp;<a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paperlike Color: Color E-Ink Monitor (183 pts)]]></title>
            <link>https://www.indiegogo.com/projects/paperlike-color-world-first-color-e-ink-monitor/coming_soon</link>
            <guid>36941942</guid>
            <pubDate>Mon, 31 Jul 2023 13:04:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.indiegogo.com/projects/paperlike-color-world-first-color-e-ink-monitor/coming_soon">https://www.indiegogo.com/projects/paperlike-color-world-first-color-e-ink-monitor/coming_soon</a>, See on <a href="https://news.ycombinator.com/item?id=36941942">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>