<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 26 Aug 2023 22:00:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[90% of “eco-friendly” paper straws contain traces of toxic forever chemicals (241 pts)]]></title>
            <link>https://scienceswitch.com/2023/08/27/90-of-eco-friendly-paper-straws-contain-traces-of-toxic-forever-chemicals/</link>
            <guid>37275856</guid>
            <pubDate>Sat, 26 Aug 2023 19:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scienceswitch.com/2023/08/27/90-of-eco-friendly-paper-straws-contain-traces-of-toxic-forever-chemicals/">https://scienceswitch.com/2023/08/27/90-of-eco-friendly-paper-straws-contain-traces-of-toxic-forever-chemicals/</a>, See on <a href="https://news.ycombinator.com/item?id=37275856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

							<p>The growing movement against single-use plastics has led many bars and restaurants to swap plastic straws for paper ones. On the surface, this seems like an easy win – we get to sip our drinks through an eco-friendly alternative while keeping tons of plastic out of landfills and oceans. But the truth about paper straws is more complicated.</p>
<p>A <a href="https://www.scimex.org/newsfeed/paper-straws-contain-forever-chemicals-which-mean-they-might-not-be-better-than-plastic-ones">study conducted</a> at the University of Antwerp found that a shocking 90% of so-called eco-friendly paper straws actually contain traces of “forever chemicals.” Forever chemicals, more formally known as <a href="https://chemtrust.org/pfas/">per-and polyfluoroalkyl substances</a>&nbsp;(PFAS), are compounds that don’t break down once released into the environment or our bodies. They stick around virtually forever, which is how they got their ominous nickname.</p>
<p>PFAS have been linked to concerning health effects including high cholesterol, reduced immune response, thyroid disease, and increased risk of certain cancers. So why are they turning up in paper straws? The researchers tested 39 different brands of straws made from various materials like paper, bamboo, glass, stainless steel, and plastic. PFAS were detected in the majority – 69% overall.</p>
<p>But paper straws were by far the worst offenders, with PFAS identified in a whopping 90% of brands tested. The concentrations varied quite a bit, but the frequent presence of the chemicals suggests they were likely intentionally added in some cases. PFAS are sometimes used as a <a href="https://www.theguardian.com/environment/2022/jan/26/water-resistant-products-toxic-pfas-study">water-resistant coating</a> – not something you want leaching into your daily iced tea.</p>
<p>Among the PFAS found in paper straws was <a href="https://pubchem.ncbi.nlm.nih.gov/compound/Perfluorooctanoic-acid">perfluorooctanoic acid</a> (PFOA), which has actually been <a href="https://chemicalwatch.com/189390/global-ban-on-pfoa-enters-into-force-for-most-countries">globally banned since 2020</a> due to health risks including cancer and organ damage. Also frequently detected were other concerning PFAS chemicals <a href="https://en.wikipedia.org/wiki/Trifluoroacetic_acid">trifluoroacetic acid</a>&nbsp;(TFA) and <a href="https://en.wikipedia.org/wiki/Triflic_acid">trifluoromethanesulfonic acid</a> (TFMS). While bamboo straws fared slightly better than paper ones, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0045653521007074?via%3Dihub">PFAS was still found in 80%</a> of the bamboo brands tested. Plastic and glass straws also occasionally contained PFAS, though less commonly than plant-based options.</p>
<p>The one material that seems safest is stainless steel – the researchers did not detect any PFAS compounds in the steel straws analyzed. While the PFAS levels measured in this study were fairly low, these chemicals have the ominous ability to accumulate in the human body and the environment over time. The findings raise the question – if paper straws leach PFAS into our drinks over months and years of use, could they be harming our health?</p>
<p>Unfortunately the current research didn’t examine whether the chemicals transfer into liquids. But previous studies have shown PFAS can migrate from food packaging materials into actual food and drinks. More research is critically needed to determine if PFAS leach out of paper straws during typical use.</p>
<p>In the meantime, it’s clear we need to rethink the assumption that paper and other plant-based products are inherently better for health and sustainability compared to plastic. The revelation about paper straws casts doubt on the idea that swapping plastic for paper is a foolproof eco-friendly solution. After all, PFAS spreading from straws into waterways and landfills still contribute to environmental contamination – regardless of that paper label.</p>
<p>The study was published in the journal&nbsp;<i><a href="https://www.tandfonline.com/doi/full/10.1080/19440049.2023.2240908" rel="noopener">Food Additives and Contaminants</a></i>.</p>
			
			
			
							
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slack’s Migration to a Cellular Architecture (179 pts)]]></title>
            <link>https://slack.engineering/slacks-migration-to-a-cellular-architecture/</link>
            <guid>37274871</guid>
            <pubDate>Sat, 26 Aug 2023 17:27:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slack.engineering/slacks-migration-to-a-cellular-architecture/">https://slack.engineering/slacks-migration-to-a-cellular-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=37274871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-area">
		<main id="primary">
			<article id="post-16208">
				<!-- .entry__header -->

									<div>
						<h2>Summary</h2>
<p><span>In recent years, </span><a href="https://aws.amazon.com/solutions/guidance/cell-based-architecture-on-aws/"><span>cellular architectures</span></a><span> have become increasingly popular for large online services as a way to increase redundancy and limit the blast radius of site failures. In pursuit of these goals, we have migrated the most critical user-facing services at Slack from a monolithic to a cell-based architecture over the last 1.5 years. In this series of blog posts, we’ll discuss our reasons for embarking on this massive migration, illustrate the design of our cellular topology along with the engineering trade-offs we made along the way, and talk about our strategies for successfully shipping deep changes across many connected services.</span></p>
<h2><b>Background: the incident</b></h2>
<figure id="attachment_16211" aria-describedby="caption-attachment-16211"><img decoding="async" src="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg?w=640" alt="Graph of TCP retransmits by AZ, with one AZ worse than the others" width="640" height="188" srcset="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg 1600w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg?resize=640,188 640w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg?resize=768,226 768w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg?resize=1280,376 1280w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image1.jpg?resize=1536,451 1536w" sizes="(max-width: 479px) 90vw, (max-width: 599px) 432px, 536px"><figcaption id="caption-attachment-16211">TCP retransmits by AZ, 2021-06-30 outage</figcaption></figure>
<p><span>At Slack, we conduct an incident review after each notable service outage. Below is an excerpt from our internal report summarizing one such incident and our findings:&nbsp;</span></p>
<p><i><span>At 11:45am PDT on 2021-06-30, our cloud provider experienced a network disruption in one of several availability zones in our U.S. East Coast region, where the majority of Slack is hosted. A network link that connects one availability zone with several other availability zones containing Slack servers experienced intermittent faults, causing slowness and degraded connections between Slack servers and degrading service for Slack customers.</span></i></p>
<p><i><span>At 12:33pm PDT on 2021-06-30, the network link was automatically removed from service by our cloud provider, restoring full service to Slack customers. After a series of automated checks by our cloud provider, the network link entered service again.</span></i></p>
<p><i><span>At 5:22pm PDT on 2021-06-30, the same network link experienced the same intermittent faults. At 5:31pm PDT on 2021-06-30, the cloud provider permanently removed the network link from service, restoring full service to our customers.</span></i></p>
<p><span>At first glance, this appears to be pretty unremarkable; a piece of physical hardware upon which we were reliant failed, so we served some errors until it was removed from service. However, as we went through the reflective process of incident review, we were led to wonder why, in fact, this outage was visible to our users </span><i><span>at all</span></i><span>.&nbsp;</span></p>
<p><span>Slack operates a global, multi-regional edge network, but most of our core computational infrastructure resides in multiple Availability Zones within a single region, us-east-1. Availability Zones (AZs) are isolated datacenters within a single region; in addition to the physical isolation they offer, components of cloud services upon which we rely (virtualization, storage, networking, etc.) are blast-radius limited such that they should not fail simultaneously across multiple AZs. This enables builders of services hosted in the cloud (such as Slack) to architect services in such a way that the availability of the entire service in a region is greater than the availability of any one underlying AZ. So to restate the question above — why didn’t this strategy work out for us on June 30? Why did one failed AZ result in user-visible errors?</span></p>
<p><span>As it turns out, detecting failure in distributed systems is a hard problem. A single Slack API request from a user (for example, loading messages in a channel) may fan out into hundreds of RPCs to service backends, each of which must complete to return a correct response to the user. Our service frontends are continuously attempting to detect and exclude failed backends, but we’ve got to record some failures before we can exclude a failed server! To make things even harder, some of our key datastores (including </span><a href="https://slack.engineering/scaling-datastores-at-slack-with-vitess/"><span>our main datastore Vitess</span></a><span>) offer strongly consistent semantics. This is enormously useful to us as application developers but also requires that there be a single backend available for any given write. If a shard primary is unavailable to an application frontend, writes to that shard will fail until the primary returns or a secondary is promoted to take its place.</span></p>
<p><span>We might class the outage above as a </span><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf"><i><span>gray failure</span></i></a><span>. In a gray failure, different components have different views of the availability of the system. In our incident, systems within the impacted AZ saw complete availability of backends within their AZ, but backends outside the AZ were unavailable, and vice versa systems in unimpacted AZs saw the impacted AZ as unavailable. Even clients within the same AZ would have different views of backends in the impacted AZ, depending on whether their network flows happened to traverse the failed equipment. Informally, it seems that this is quite a lot of complexity to ask a distributed system to deal with along the way to doing its real job of serving messages and cat GIFs to our customers.</span></p>
<p><span>Rather than try to solve automatic remediation of gray failures, our solution to this conundrum was to make the computers’ job easier by tapping the power of human judgment. During the outage, it was quite clear to engineers responding that the impact was largely due to one AZ being unreachable — nearly every graph we had aggregated by target AZ looked similar to the retransmits graph above. If we had a button that told all our systems “This AZ is bad; avoid it.” we would absolutely have smashed it! So we set out to build a button that would drain traffic from an AZ.</span></p>
<h2><b>Our solution: AZs are cells, and cells may be drained</b></h2>
<p><span>Like a lot of satisfying infrastructure work, an AZ drain button is conceptually simple yet complicated in practice. The design goals we chose are:</span></p>
<ol>
<li><span>Remove as much traffic as possible from an AZ within 5 minutes. Slack’s </span><a href="https://slack.com/terms/service-level-agreement"><span>99.99% availability SLA</span></a><span>&nbsp;allows us less than 1 hour per year of total unavailability, and so to support it effectively we need tools that work quickly.</span></li>
<li><span>Drains must not result in user-visible errors. An important quality of draining is that it is a </span><a href="https://www.oreilly.com/content/generic-mitigations/"><span>generic mitigation</span></a><span>: as long as a failure is contained within a single AZ, a drain may be effectively used to mitigate even if the root cause is not yet understood. This lends itself to an experimental approach wherein, during in an incident, an operator may try draining an AZ to see if it enables recovery, then undrain if it does not. If draining results in additional errors this approach is not useful.</span></li>
<li><span>Drains and undrains must be incremental. When undraining, an operator should be able to assign as little as 1% of traffic to an AZ to test whether it has truly recovered.</span></li>
<li><span>The draining mechanism must not rely on resources in the AZ being drained. For example, it’s not OK to activate a drain by just SSHing to every server and forcing it to healthcheck down. This ensures that drains may be put in place even if an AZ is completely offline.</span></li>
</ol>
<p><span>A naive implementation that fits these requirements would have us plumb a signal into each of our RPC clients that, when received, causes them to fail a specified percentage of traffic away from a particular AZ. This turns out to have a lot of complexity lurking within. Slack does not share a common codebase or even runtime; services in the user-facing request path are written in Hack, Go, Java, and C++. This would necessitate a separate implementation in each language. Beyond that concern, we support a number of internal service discovery interfaces including the Envoy xDS API, the Consul API, and even DNS. Notably, DNS does not offer an abstraction for something like an AZ or partial draining; clients expect to resolve a DNS address and receive a list of IPs and no more. Finally, we rely heavily on open-source systems like Vitess, for which code-level changes present an unpleasant choice between maintaining an internal fork and doing the additional work to get changes merged into upstream.</span></p>
<p><span>The main strategy we settled on is called </span><i><span>siloing</span></i><span>. Services may be said to be </span><i><span>siloed</span></i><span>&nbsp;if they only receive traffic from within their AZ and only send traffic upstream to servers in their AZ. The overall architectural effect of this is that each service appears to be N virtual services, one per AZ. Importantly, we may effectively remove traffic from all siloed services in an AZ simply by redirecting user requests away from that AZ. If no new requests from users are arriving in a siloed AZ, internal services in that AZ will naturally quiesce as they have no new work to do.</span></p>
<figure id="attachment_16212" aria-describedby="caption-attachment-16212"><img decoding="async" src="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image2.jpg?w=640" alt="A digram showing request failures across multiple AZs caused by a failure in a single AZ." width="640" height="434" srcset="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image2.jpg 1160w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image2.jpg?resize=640,435 640w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image2.jpg?resize=768,522 768w" sizes="(max-width: 479px) 90vw, (max-width: 599px) 432px, 536px"><figcaption id="caption-attachment-16212">Our original architecture. Backends are spread across AZs, so errors present in frontends in all AZs.</figcaption></figure>
<p><span>And so we finally arrive at our cellular architecture. All services are present in all AZs, but each service only communicates with services within its AZ. Failure of a system within one AZ is contained within that AZ, and we may dynamically route traffic away to avoid those failures simply by redirecting at the frontend.</span></p>
<figure id="attachment_16213" aria-describedby="caption-attachment-16213"><img decoding="async" loading="lazy" src="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image3.jpg?w=640" alt="A digram showing client requests siloed within AZs, routing around a failed AZ." width="640" height="424" srcset="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image3.jpg 1160w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image3.jpg?resize=640,424 640w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image3.jpg?resize=768,508 768w" sizes="(max-width: 479px) 90vw, (max-width: 599px) 432px, 536px"><figcaption id="caption-attachment-16213">Siloed architecture. Failure in one AZ is contained to that AZ; traffic may be routed away.</figcaption></figure>
<p><span>Siloing allows us to concentrate our efforts on the traffic-shifting implementation in one place: the systems that route queries from users into the core services in us-east-1. Over the last several years we have invested heavily in </span><a href="https://slack.engineering/migrating-millions-of-concurrent-websockets-to-envoy/"><span>migrating from HAProxy to the Envoy / xDS ecosystem,</span></a><span>&nbsp;and so all our edge load balancers are now running Envoy and receive configuration from Rotor, our in-house xDS control plane. This enabled us to power AZ draining by simply using two out-of-the-box Envoy features: weighted clusters and dynamic weight assignment via RTDS. When we drain an AZ, we simply send a signal through Rotor to the edge Envoy load balancers instructing them to reweight their per-AZ target clusters at us-east-1. If an AZ at us-east-1 is reweighted to zero, Envoy will continue handling in-flight requests but assign all new requests to another AZ, and thus the AZ is drained. Let’s see how this satisfies our goals:</span></p>
<ol>
<li><span>Propagation through the control plane is on the order of seconds; Envoy load balancers will apply new weights immediately.</span></li>
<li><span>Drains are graceful; no queries to a drained AZ will be abandoned by the load balancing layer.</span></li>
<li><span>Weights provide gradual drains with a granularity of 1%.</span></li>
<li><span>Edge load balancers are located in different regions entirely, and the control plane is replicated regionally and resilient against the failure of any single AZ.</span></li>
</ol>
<p><span>Here is a graph showing bandwidth per AZ as we gradually drain traffic from one AZ into two others. Note how pronounced the “knees” in the graph are; this reflects the low propagation time and high granularity afforded us by the Envoy/xDS implementation.</span></p>
<figure id="attachment_16214" aria-describedby="caption-attachment-16214"><img decoding="async" loading="lazy" src="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?w=640" alt="Graph showing queries per second per AZ. One AZ's rate drops while the others rise at 3 distinct points in time and then the rates re-converge at an even split." width="640" height="416" srcset="https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg 1999w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?resize=640,416 640w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?resize=768,499 768w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?resize=1280,832 1280w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?resize=1536,999 1536w, https://slack.engineering/wp-content/uploads/sites/7/2023/08/image4.jpg?resize=1920,1249 1920w" sizes="(max-width: 479px) 90vw, (max-width: 599px) 432px, 536px"><figcaption id="caption-attachment-16214">Queries per second, by AZ.</figcaption></figure>
<p><span>In our next post we’ll dive deeper into the details of our technical implementation. We’ll discuss how siloing is implemented for internal services, and which services can’t be siloed and what we do about them. We’ll also discuss how we’ve changed the way we operate and build services at Slack now that we have this powerful new tool at our disposal. Stay tuned!</span></p>
					</div><!-- .entry__content -->
				<!-- .entry__footer -->
			</article><!-- #post-16208 -->

		
		</main><!-- #primary -->

		
<!-- #secondary -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[n8n.io - A powerful workflow automation tool (123 pts)]]></title>
            <link>https://n8n.io</link>
            <guid>37274052</guid>
            <pubDate>Sat, 26 Aug 2023 16:06:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://n8n.io">https://n8n.io</a>, See on <a href="https://news.ycombinator.com/item?id=37274052">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-691fb278="" id="__nuxt" data-server-rendered="true"><div data-v-43b42ddf="" data-v-691fb278=""><div data-v-43b42ddf=""><p data-v-43b42ddf="">
        Workflow automation for technical people
      </p> <h2 data-v-43b42ddf="">
        Build complex automations 10x faster, without fighting APIs
      </h2> <p data-v-43b42ddf="">Your days spent slogging through a spaghetti of scripts are over. <br>Use JavaScript when you need flexibility and UI for everything else.</p> <div data-v-0e3fb934="" data-v-43b42ddf=""><a href="https://github.com/n8n-io/n8n" data-v-0e3fb934=""><div data-v-0e3fb934="" data-v-43b42ddf=""><p><img src="https://n8n.io/_nuxt/image/87df9a.svg" width="32" height="32" alt="GitHub logo" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/github_white_3112efbe15_d6f929e422.svg" data-v-43b42ddf=""></p> </div></a></div></div> <div data-v-43b42ddf=""><p><img src="https://n8n.io/_nuxt/image/a57c32.svg" alt="" loading="lazy" data-v-43b42ddf=""> <span data-v-43b42ddf="">Full source code available</span></p><p><img src="https://n8n.io/_nuxt/image/a57c32.svg" alt="" loading="lazy" data-v-43b42ddf=""> <span data-v-43b42ddf="">Self host-able</span></p><p><img src="https://n8n.io/_nuxt/image/a57c32.svg" alt="" loading="lazy" data-v-43b42ddf=""> <span data-v-43b42ddf="">55,385 community members</span></p></div> <p><img src="https://n8n.io/_nuxt/image/f4908d.svg" alt="homepage bg mobile" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/Group_491_1_3966733d3a.svg" format="webp" fetchpriority="high" data-v-43b42ddf=""> <img src="https://n8n.io/_nuxt/image/f07ac5.svg" alt="n8n_image" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/Frame_1035_bf4f8a8954.svg" fetchpriority="high" format="webp" data-v-43b42ddf=""></p></div><div data-v-53511fec="" data-v-691fb278=""><div data-index="0" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Code when you need, no code when you don’t&nbsp;
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Connect APIs with no code to automate basic tasks. Or write vanilla Javascript when you need to manipulate complex data.</p>
</span></p></div><div data-index="1" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Build custom scenarios at speed
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>You can implement multiple triggers. Branch and merge your workflows. And even pause flows to wait for external events.</p>
</span></p></div><div data-index="2" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Integrate with any app
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Interface easily with any API or service with custom HTTP requests.</p>
</span></p></div><div data-index="3" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Independent instances for each environment
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Avoid breaking live workflows by separating dev and prod environments with unique sets of auth data.</p>
</span></p></div><div data-index="4" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Bulk operations&nbsp;
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>n8n nodes let you process data at scale with a built-in iteration functionality in every node.</p>
</span></p></div><div data-index="5" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Painless debugging
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>See the execution data of every workflow. Integrate error nodes into workflows to catch errors. And rerun individual nodes to test fixes fast.</p>
</span></p></div><div data-index="6" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Host on your own infrastructure
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Fully on-prem for those that need the security</p>
</span></p></div></div><div data-v-4aa551c5="" data-v-691fb278=""> <div data-v-4aa551c5=""><ul data-v-4aa551c5=""><li role="presentation" data-v-4aa551c5=""><span role="tab" data-v-4aa551c5="">
          Customer integrations
        </span></li><li role="presentation" data-v-4aa551c5=""><span role="tab" data-v-4aa551c5="">
          SaaS backend prototyping
        </span></li><li role="presentation" data-v-4aa551c5=""><span role="tab" data-v-4aa551c5="">
          Lead automation
        </span></li><li role="presentation" data-v-4aa551c5=""><span role="tab" data-v-4aa551c5="">
          CRM customization
        </span></li></ul></div> <div data-v-4aa551c5=""><div data-v-4aa551c5=""><div data-v-4aa551c5=""><h3>Optimize engineering resources</h3>
<p>Save time building customer integrations. Engineer faster POCs. And keep your customer-specific functionality separate from product. All without writing a single line of code.</p>
</div> <div data-v-4aa551c5=""><p><img src="https://n8n.io/_nuxt/image/736d75.png" alt="eng-resources" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/common_uses_cases_engineering_resources_96ca4f3e48.png" format="webp" data-v-4aa551c5=""></p> </div></div><div data-v-4aa551c5=""><div data-v-4aa551c5=""><h3>Build and test new features faster</h3>
<p>Avoid throwing away features that took forever to build. With n8n, you can quickly set up end points to test what works. And easily debug to fix what doesn’t.</p>
</div> <div data-v-4aa551c5=""><p><img src="https://n8n.io/_nuxt/image/0ebf9c.png" alt="common_uses_cases_newFeatures" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/common_uses_cases_new_Features_bd1ae37b46.png" format="webp" data-v-4aa551c5=""></p> </div></div><div data-v-4aa551c5=""><div data-v-4aa551c5=""><h3>Save time&nbsp;managing leads</h3>
<p>Take the stress out of managing your leads by connecting all your marketing tools to run on autopilot.</p>
</div> <div data-v-4aa551c5=""><p><img src="https://n8n.io/_nuxt/image/b0bef3.png" alt="common_uses_cases_leads" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/common_uses_cases_leads_ae5eddfdbf.png" format="webp" data-v-4aa551c5=""></p> </div></div><div data-v-4aa551c5=""><div data-v-4aa551c5=""><h3>CRM customization</h3>
<p>Push past the limitations of your CRM by building custom integrations to move any data you want between your apps and systems.</p>
</div> <div data-v-4aa551c5=""><p><img src="https://n8n.io/_nuxt/image/d6a2ea.png" alt="common_uses_cases_CRM" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-stage/assets/common_uses_cases_CRM_085a831754.png" format="webp" data-v-4aa551c5=""></p> </div></div></div></div><div data-v-53511fec="" data-v-691fb278=""><div data-index="0" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Scalable performance
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>220 workflow executions per sec on a single instance, and add more instances if required. <a href="https://docs.n8n.io/hosting/scaling/performance-benchmarking/">More info</a></p>
</span></p></div><div data-index="1" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Customizable error handling
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Get notified whenever a workflow fails — be it via email, Slack or a log aggregator</p>
</span></p></div><div data-index="2" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Share workflows with a click
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Reuse, export to JSON, or import workflows with a single copy/paste.</p>
</span></p></div><div data-index="3" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Use 600+ templates to move faster
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Get a head start on your workflows with templates developed by our core team and community.</p>
</span></p></div><div data-index="4" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          350+ native integrations
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>Connect to all your favorite apps. Or write your own integration with a general connector to the rest.</p>
</span></p></div><div data-index="5" data-v-5efc53c4="" data-v-53511fec=""><h3 data-v-5efc53c4="" data-v-53511fec="">
          Automated API auth
        </h3> <p><span data-v-5efc53c4="" data-v-53511fec=""><p>All you have to do is enter the API key. n8n handles the rest of the auth. No reading through docs required.</p>
</span></p></div></div><div data-v-59da2cda="" data-v-691fb278=""><div data-v-4dc91236="" data-v-59da2cda=""><p><img src="https://n8n.io/_nuxt/image/502eb8.svg" alt="how-it-works-1" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/how_It_Works_1_db22134a11.svg" data-v-4dc91236=""></p> <div data-v-4dc91236=""><h3 data-v-4dc91236="">Pull in data</h3> <p data-v-4dc91236="">Set up triggers for app events or specific times to fetch data across your app stack</p></div> <p><img src="https://n8n.io/_nuxt/image/579b4a.svg" width="64" height="73" alt="arrow_primary" loading="lazy" data-v-4dc91236=""> <img src="https://n8n.io/_nuxt/image/fe7f83.svg" width="105" height="116" alt="arrow_secondary" loading="lazy" data-v-4dc91236=""></p></div><div data-v-4dc91236="" data-v-59da2cda=""><p><img src="https://n8n.io/_nuxt/image/8fd21a.svg" alt="how-it-works-2" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/how_It_Works_2_dd2c4fc758.svg" data-v-4dc91236=""></p> <div data-v-4dc91236=""><h3 data-v-4dc91236="">Set up steps</h3> <p data-v-4dc91236="">Use 220+ app nodes to create, read, and update the valuable data across your apps</p></div> <p><img src="https://n8n.io/_nuxt/image/579b4a.svg" width="64" height="73" alt="arrow_primary" loading="lazy" data-v-4dc91236=""> <img src="https://n8n.io/_nuxt/image/fe7f83.svg" width="105" height="116" alt="arrow_secondary" loading="lazy" data-v-4dc91236=""></p></div><div data-v-4dc91236="" data-v-59da2cda=""><p><img src="https://n8n.io/_nuxt/image/1f8301.svg" alt="how-it-works-3" loading="lazy" srcset="https://n8niostorageaccount.blob.core.windows.net/n8nio-strapi-blobs-prod/assets/how_It_Works_3_7a4b095a4b.svg" data-v-4dc91236=""></p> <div data-v-4dc91236=""><h3 data-v-4dc91236="">Save time - every day</h3> <p data-v-4dc91236="">From monthly syncs to millions of executions, sit back as your workflow does the heavy lifting</p></div> <!----> <!----></div></div><div data-v-7442cf86="" data-v-691fb278=""><div data-v-67dbc12e="" data-v-7442cf86=""> <p>Your workflows<br>
Your way</p> <ul data-v-67dbc12e=""><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p><strong>Full source code available:</strong><br>
Audit, tweak, and fork our codebase to suit your needs.</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p><strong>Self-hostable:</strong> Easily keep your data secure. And ensure compliance with data privacy laws.</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p><strong>Embeddable:</strong> White label our UI to give your customers access to 220+ native integrations.</p></li></ul> </div><div data-v-67dbc12e="" data-v-7442cf86=""> <p>Build without blowing your budget</p> <ul data-v-67dbc12e=""><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>Other platforms’ per-execution pricing can eat up your budget insanely fast.</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>With n8n, you can self-host for free. Or <strong>pay for a package of workflows</strong> in the cloud.</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>So you can make your flows as complex as you like — at no extra cost.</p></li></ul> </div><div data-v-67dbc12e="" data-v-7442cf86=""> <p>Resolve 99% of issues&nbsp;in hours, not months</p> <ul data-v-67dbc12e=""><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>You don’t have to wait weeks for someone on your vendor’s team to fix your issue. (If they can fix it at all.)</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>Get access to a <strong>6K-strong forum</strong> of n8n engineers and community experts available 24/7 to answer your questions.</p></li><li data-v-67dbc12e=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="16" fill="none" style="color:#8287eb" data-v-67dbc12e=""><path fill="currentColor" d="m23.472 6.728-6-6a1.8 1.8 0 0 0-2.544 2.544L17.854 6.2H1.8a1.8 1.8 0 0 0 0 3.6h16.054l-2.926 2.928a1.801 1.801 0 1 0 2.544 2.544l6-6a1.797 1.797 0 0 0 0-2.544Z" data-v-67dbc12e=""></path></svg> <p>You can expect same-day responses (almost) every time.</p></li></ul> </div></div><div data-v-2dd2ed8c="" data-v-691fb278=""><p data-v-2dd2ed8c="">
        Scale your company's operations with our advanced on-prem or cloud automation
      </p>  <!----></div><div data-v-17ea5a8e="" data-v-691fb278=""><p>Stop struggling with your scripts<br>
Start creating workflows 10X faster — with n8n</p> </div> <p><a href="https://www.producthunt.com/posts/n8n-1-0?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-n8n-1-0" target="_blank" data-v-691fb278=""><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=406015&amp;theme=dark" alt="n8n 1.0 - Workflow automation for technical people | Product Hunt" width="250" height="54" data-v-691fb278=""></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Maps is a critical dependency for nutrition facts on mcdonalds.com (105 pts)]]></title>
            <link>https://mastodon.social/@simevidas/110956696765338181</link>
            <guid>37273907</guid>
            <pubDate>Sat, 26 Aug 2023 15:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@simevidas/110956696765338181">https://mastodon.social/@simevidas/110956696765338181</a>, See on <a href="https://news.ycombinator.com/item?id=37273907">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Let Maintainers Be Maintainers (128 pts)]]></title>
            <link>https://graydon2.dreamwidth.org/306832.html</link>
            <guid>37272929</guid>
            <pubDate>Sat, 26 Aug 2023 13:52:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://graydon2.dreamwidth.org/306832.html">https://graydon2.dreamwidth.org/306832.html</a>, See on <a href="https://news.ycombinator.com/item?id=37272929">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A short note about corporate free / open source software (FOSS), and corporate-employed maintainers. Or specifically "corporate-employed maintainers .. with bad incentives". I tried to come up with a pithy name, but that's the best I could do: CEMBIs.</p><p>I've worked professionally in FOSS for a long time. I've seen a lot of corporate approaches to FOSS participation over that time, and seen the FOSS community develop a fairly nuanced understanding of what sorts of corporate strategies are welcome or unwelcome, healthy or harmful to a project. We have articulated a lot of thoughts about (say) open core and dual licensing business models, or (say) which forms of corporate "embrace" represent a step on an "extend/extinguish" path, or (say) which forms of telemetry are appropriate and which put users at risk of surveillance.</p><p>What I haven't seen a lot of discussion of, and wish I did see, is the structure and content of relationships that exist between corporate-employed FOSS maintainers and their employers. And I think this matters because the people doing corporate FOSS aren't soul-less automata executing corporate strategy. They are people with their own motivations, incentives, a certain amount of autonomy, but (most relevant to my concerns) a set of performance-evaluation criteria they have to satisfy to remain employed and/or get promoted.</p><p>Companies incentivize lots of things, but I worry (and in many cases I either know first hand or have heard second hand) that companies often have an incentive structure that rewards <em>novelty</em>, especially in the form of <em>features</em> if not entire <em>products</em>. There's a good reason for this when the company is "making products to sell": this year's new-and-improved is always sellable over last year's tired old model. But it's also just a reflection of the "growth orientation" or capitalism in general: whatever activity the company accomplished last year, a common measure of health and vitality isn't consistent execution but <em>growth of the business</em>. Failure to grow is treated as stagnation which is treated as equivalent to death. This orientation can be embedded so deep in a company's DNA that it's the incentive structure given to <em>everyone</em> who works there, regardless of whether they're making products, auditing the accounts, or <em>maintaining corporate infrastructure</em>.</p><p>And to a large measure, that's what FOSS is. Not always, but usually: <a href="https://en.wikipedia.org/wiki/Infrastructure">infrastructure</a>. It's stuff that's supposed to work the same way from one day to the next. Stuff that's not supposed to be noticed because it just works. Reliably, efficiently, silently. Stuff that has a massive installed base of users relying on it, massive social and institutional inertia, and thereby massive (and sensible) built-in resistance to novelty. You don't actually want novelty in the electrical grid, the drinking water system, sewers, roads, bridges, rail lines, telecoms .. you want this stuff to be <em>absolutely rock solid</em> and not novel in the least. That's what maybe 90 or 95% of FOSS is like, certainly the stuff that <em>needs</em> reliable corporate maintainers.</p><p>For corporate-employed FOSS maintainers working at a firm with these "growth and novelty" incentives -- CEMBIs -- this leads to a real quandry. They're in a position where their job performance is very likely to be evaluated in terms of visible growth and novelty (it might be dressed up in more abstract terms like "real-world impact" or "visibility" but it still means the same thing) even though that is exactly the wrong thing for the health of the project they're maintaining. The incentives are bad. If they do the <em>best</em> thing for the project <em>as infrastructure</em> -- triage and fix bugs from the backlog, optimize performance, increase security and reliability, pay down tech debt, simplify and automate ongoing maintenance -- the bias of their organization is likely to view them as "doing nothing", or at best doing "low-value work" that only counts as "reducing fixed costs", not leading the way towards new growth. To be seen in a positive light by their employer, the CEMBI winds uphaving to do essentially <em>anti-maintenance work</em>: make the program "do something new and exciting", that it didn't do yesterday. Ignore maintenance of "what is", focus on "what's next".</p><p>Seeing this over and over in FOSS makes me a bit sad. I guess I've maybe been watching too many re-runs of The West Wing lately, but while I've been thinking about this subject, I keep thinking of the "<a href="https://en.wikipedia.org/wiki/Let_Bartlet_Be_Bartlet">Let Bartlet Be Bartlet</a>" episode near the end of the first season, where the characters come around to the idea that maybe it'd be best to just do what they were elected to do. I keep thinking it'd be nice if employers could incentivize their employees to do what they were hired to do. To "<b>Let Maintainers Be Maintainers</b>". Maintaining FOSS isn't low-value work. It's <em>essential</em> work, stuff that you ignore at your medium and long-term peril. As a new homeowner I will make more salient analogies: it's testing the wiring for faults, testing the walls for mould, replacing the roof before it leaks. It's work that <em>has to be done</em> in order for FOSS to keep functioning over the long term. Software actually does "break down and wear out": requirements change; upstream and downstream platforms and libraries change incompatibly; patterns of usage change; hardware changes; new subsystems become performance bottlenecks; new bugs are discovered, some of which will be high severity security vulnerabilities, others will merely grow in importance as they're encountered more often. Software maintenance is <em>real and important work</em>, and if a company hires a maintainer of a project "in order to support the project", it's what that company should be incentivizing and evaluating those maintainers in terms of.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E-ink is so Retropunk (440 pts)]]></title>
            <link>https://rmkit.dev/eink-is-so-retropunk/</link>
            <guid>37272652</guid>
            <pubDate>Sat, 26 Aug 2023 13:21:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rmkit.dev/eink-is-so-retropunk/">https://rmkit.dev/eink-is-so-retropunk/</a>, See on <a href="https://news.ycombinator.com/item?id=37272652">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’ve long been struggling to describe why e-ink is so much fun for me, but I
think I’ve finally realized what it is: <strong>e-ink is just so so so retropunk</strong>.</p>

<p><img src="https://i.imgur.com/8760cI9.jpg" alt=""></p>

<p>An e-ink device is a hacker’s dream - or at least, this hacker’s dream.  They
are a return to the magical feeling of computers of the 80s and 90s. It’s a
world where Microsoft and Apple never existed and we don’t have to suffer with
abstractions on top of abstractions.  It’s DOS for the 2020s. It’s graphing
calculators for grown-ups.</p>

<h2 id="features">Features</h2>

<p>The e-ink devices I favor are low powered ARM devices running linux without a
display server or gigabytes of RAM. Let’s break down why that’s so awesome:</p>

<ul>
  <li>Low Powered: They can last for weeks on a single charge</li>
  <li>ARM is a simple architecture with a low instruction count and even lower cost</li>
  <li>Linux: as much as I like it, Android is a complicated mess</li>
  <li>Apps are simple: they talk to the kernel to read input and draw directly to the framebuffer</li>
  <li>Low RAM and slow CPUs: There’s no room to build complicated stacks of software, which means no window managers, no browsers and definitely no electron apps</li>
</ul>

<p>As similar as they are to the computers of the early 90s, they are different in
some tangible ways:</p>

<ul>
  <li>The resolution is much higher than an old computer - The PPI is between 200 - 300</li>
  <li>All devices supports touch events, some even support a pen stylus</li>
  <li>They are super portable, weighing between 200 - 400 grams, with displays ranging from 6” to 10”</li>
</ul>

<h2 id="the-software">The Software</h2>

<p>Since the devices are niche, the software ecosystem is way more
<strong>homebrew</strong> (as in the Homebrew Computing Club): people write and share their
apps and the community is tight knit. The people who use eink devices are
enthusiasts: they’ve given up the joys of color displays to work on these
under-powered devices that are devoid of app stores, tracking pixels, pay to
play features and constant distractions. There’s no email on these devices,
there’s no chat or social networks, there’s only simple applications.</p>

<p>Don’t be fooled though: the device constraints lead to interesting and quirky
software. In the <a href="https://toltec-dev.org/">reMarkable eco-system</a>, there’s dozens of
applications, including:</p>

<ul>
  <li>multi-tasking application launchers like <a href="https://github.com/Eeems/oxide/">oxide</a> and <a href="https://github.com/rmkit-dev/rmkit/tree/master/src/remux">remux</a></li>
  <li><a href="https://github.com/timower/rM2-stuff">terminal emulators</a></li>
  <li>an <a href="https://github.com/bkirwi/folly">interactive fiction interpreter</a></li>
  <li>an <a href="https://github.com/bkirwi/sill">experimental shell that you can write into</a></li>
  <li>alternative ebook readers like <a href="https://github.com/koreader/koreader/">koreader</a> and <a href="https://github.com/LinusCDE/plato/">plato</a></li>
  <li>a <a href="https://rmkit.dev/apps/sas">simple app script that follows the unix philosphy</a></li>
  <li><a href="https://github.com/LinusCDE/chessmarkable">a chess board</a></li>
  <li>even a <a href="https://github.com/LinusCDE/doomarkable">port of doom</a></li>
  <li>and so <a href="https://rmkit.dev/">much more</a> - like <a href="https://toltec-dev.org/stable/">much, much, more</a></li>
</ul>

<p>Since eink is currently niche, it also means green fields: there are lots of
opportunities to write applications that fills out the ecosystem. In short, a
hacker’s playground.</p>

<h2 id="how-to-get-started">How to get started</h2>

<p>Convinced that you should hack on eink devices? Grab a reMarkable or Kobo and
get hacking ;) Join the <a href="https://discord.gg/hAKFTcuu">reMarkable discord
server</a> or browse the <a href="https://www.mobileread.com/forums/forumdisplay.php?f=247">Mobile Read Kobo
Forums</a>.</p>

<p>For reMarkable, the toltec repository is a good place to get started - one of
the maintainers, Eeems, <a href="https://eeems.website/toltec/">has written a great
tutorial</a>.</p>

<p>If you want more specific advice, feel free to directly <a href="https://rmkit.dev/about">get in touch</a></p>

<h2 id="why-write-a-post-now">Why write a post now?</h2>

<p>Several years ago, I started hacking on e-ink devices and had an enormous
amount of fun writing applications and seeing what others have built.
Unfortunately, I’ve had several false starts with writing about e-ink: whether
it was about what I’ve actually done, or the lessons learned along the way or
even a set of things to consider when developing e-ink apps, the posts would
lay half finished because they just never felt compelling - my enthusiasm for
e-ink just wasn’t coming through.</p>

<p>Instead of trying to push any of those posts to completion, I’ve decided to try
to articulate what is so cool about e-ink to me.</p>

<h2 id="appendix-hacker-unfriendly-devices">Appendix: Hacker unfriendly devices</h2>

<h4 id="kindles">Kindles</h4>

<p>The Kindle requires a jailbreak to use and is running a modified version of
Kindle Fire. The Kindle Scribe is still secured, though. For this reason, I don’t
particularly recommend the Kindle devices.</p>

<h4 id="onyx">Onyx</h4>

<p>In every eink thread that comes up, the Onyx is brought up as not following the
GPL: <a href="https://www.reddit.com/r/Onyx_Boox/comments/p9ztru/lets_help_onyx_become_a_better_company/">they use a modified linux kernel and haven’t published the source for it</a>.</p>

<h4 id="pine">Pine</h4>

<p>The Pine Note is cool and open, but it’s software is still in development. Use
only if you are willing to take on an <a href="https://wiki.pine64.org/wiki/PineNote#State_of_the_software">early product aimed at early adopters and
developers</a> - In other words,
maybe the Pine Note is too hacker friendly.</p>

  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fish – A friendly interactive shell (211 pts)]]></title>
            <link>https://github.com/fish-shell/fish-shell</link>
            <guid>37272611</guid>
            <pubDate>Sat, 26 Aug 2023 13:17:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fish-shell/fish-shell">https://github.com/fish-shell/fish-shell</a>, See on <a href="https://news.ycombinator.com/item?id=37272611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a href="https://fishshell.com/" rel="nofollow">fish</a> - the friendly interactive shell <a href="https://github.com/fish-shell/fish-shell/actions"><img alt="Build Status" src="https://github.com/fish-shell/fish-shell/workflows/make%20test/badge.svg">
</a> <a href="https://cirrus-ci.com/github/fish-shell/fish-shell" rel="nofollow"><img alt="Cirrus CI Build Status" src="https://camo.githubusercontent.com/a3f090242fed30c7af9884c39e814e1e0ab15cecf6beb4797da42cbe6e4d4815/68747470733a2f2f6170692e6369727275732d63692e636f6d2f6769746875622f666973682d7368656c6c2f666973682d7368656c6c2e7376673f6272616e63683d6d6173746572" data-canonical-src="https://api.cirrus-ci.com/github/fish-shell/fish-shell.svg?branch=master"></a></h2>
<p dir="auto">fish is a smart and user-friendly command line shell for macOS, Linux,
and the rest of the family. fish includes features like syntax
highlighting, autosuggest-as-you-type, and fancy tab completions that
just work, with no configuration required.</p>
<p dir="auto">For downloads, screenshots and more, go to <a href="https://fishshell.com/" rel="nofollow">https://fishshell.com/</a>.</p>
<a name="user-content-quick-start"></a>
<h2 tabindex="-1" dir="auto">Quick Start</h2>
<p dir="auto">fish generally works like other shells, like bash or zsh. A few
important differences can be found at
<a href="https://fishshell.com/docs/current/tutorial.html" rel="nofollow">https://fishshell.com/docs/current/tutorial.html</a> by searching for the
magic phrase “unlike other shells”.</p>
<p dir="auto">Detailed user documentation is available by running <code>help</code> within
fish, and also at <a href="https://fishshell.com/docs/current/index.html" rel="nofollow">https://fishshell.com/docs/current/index.html</a></p>
<a name="user-content-getting-fish"></a>
<h2 tabindex="-1" dir="auto">Getting fish</h2>
<a name="user-content-macos"></a>
<h3 tabindex="-1" dir="auto">macOS</h3>
<p dir="auto">fish can be installed:</p>
<ul dir="auto">
<li>using <a href="http://brew.sh/" rel="nofollow">Homebrew</a>: <code>brew install fish</code></li>
<li>using <a href="https://www.macports.org/" rel="nofollow">MacPorts</a>:
<code>sudo port install fish</code></li>
<li>using the <a href="https://fishshell.com/" rel="nofollow">installer from fishshell.com</a></li>
<li>as a <a href="https://fishshell.com/" rel="nofollow">standalone app from fishshell.com</a></li>
</ul>
<p dir="auto">Note: The minimum supported macOS version is 10.10 "Yosemite".</p>
<a name="user-content-packages-for-linux"></a>
<h3 tabindex="-1" dir="auto">Packages for Linux</h3>
<p dir="auto">Packages for Debian, Fedora, openSUSE, and Red Hat Enterprise
Linux/CentOS are available from the <a href="https://software.opensuse.org/download.html?project=shells%3Afish&amp;package=fish" rel="nofollow">openSUSE Build
Service</a>.</p>
<p dir="auto">Packages for Ubuntu are available from the <a href="https://launchpad.net/~fish-shell/+archive/ubuntu/release-3" rel="nofollow">fish
PPA</a>,
and can be installed using the following commands:</p>
<pre>sudo apt-add-repository ppa:fish-shell/release-3
sudo apt update
sudo apt install fish
</pre>
<p dir="auto">Instructions for other distributions may be found at
<a href="https://fishshell.com/" rel="nofollow">fishshell.com</a>.</p>
<a name="user-content-windows"></a>
<h3 tabindex="-1" dir="auto">Windows</h3>
<ul dir="auto">
<li>On Windows 10, fish can be installed under the WSL Windows Subsystem
for Linux with the instructions for the appropriate distribution
listed above under “Packages for Linux”, or from source with the
instructions below.</li>
<li>Fish can also be installed on all versions of Windows using
<a href="https://cygwin.com/" rel="nofollow">Cygwin</a> (from the <strong>Shells</strong> category).</li>
</ul>
<a name="user-content-building-from-source"></a>
<h3 tabindex="-1" dir="auto">Building from source</h3>
<p dir="auto">If packages are not available for your platform, GPG-signed tarballs are
available from <a href="https://fishshell.com/" rel="nofollow">fishshell.com</a> and
<a href="https://github.com/fish-shell/fish-shell/releases">fish-shell on
GitHub</a>. See the
<a href="#building">Building</a> section for instructions.</p>
<a name="user-content-running-fish"></a>
<h2 tabindex="-1" dir="auto">Running fish</h2>
<p dir="auto">Once installed, run <code>fish</code> from your current shell to try fish out!</p>
<a name="user-content-dependencies"></a>
<h3 tabindex="-1" dir="auto">Dependencies</h3>
<p dir="auto">Running fish requires:</p>
<ul dir="auto">
<li>curses or ncurses (preinstalled on most *nix systems)</li>
<li>some common *nix system utilities (currently <code>mktemp</code>), in
addition to the basic POSIX utilities (<code>cat</code>, <code>cut</code>, <code>dirname</code>,
<code>ls</code>, <code>mkdir</code>, <code>mkfifo</code>, <code>rm</code>, <code>sort</code>, <code>tee</code>, <code>tr</code>,
<code>uname</code> and <code>sed</code> at least, but the full coreutils plus <code>find</code> and
<code>awk</code> is preferred)</li>
<li>The gettext library, if compiled with
translation support</li>
</ul>
<p dir="auto">The following optional features also have specific requirements:</p>
<ul dir="auto">
<li>builtin commands that have the <code>--help</code> option or print usage
messages require <code>nroff</code> or <code>mandoc</code> for
display</li>
<li>automated completion generation from manual pages requires Python 3.5+</li>
<li>the <code>fish_config</code> web configuration tool requires Python 3.5+ and a web browser</li>
<li>system clipboard integration (with the default Ctrl-V and Ctrl-X
bindings) require either the <code>xsel</code>, <code>xclip</code>,
<code>wl-copy</code>/<code>wl-paste</code> or <code>pbcopy</code>/<code>pbpaste</code> utilities</li>
<li>full completions for <code>yarn</code> and <code>npm</code> require the
<code>all-the-package-names</code> NPM module</li>
<li><code>colorls</code> is used, if installed, to add color when running <code>ls</code> on platforms
that do not have color support (such as OpenBSD)</li>
</ul>
<a name="user-content-switching-to-fish"></a>
<h3 tabindex="-1" dir="auto">Switching to fish</h3>
<p dir="auto">If you wish to use fish as your default shell, use the following
command:</p>
<pre>chsh -s /usr/local/bin/fish
</pre>
<p dir="auto"><code>chsh</code> will prompt you for your password and change your default
shell. (Substitute <code>/usr/local/bin/fish</code> with whatever path fish was
installed to, if it differs.) Log out, then log in again for the changes
to take effect.</p>
<p dir="auto">Use the following command if fish isn’t already added to <code>/etc/shells</code>
to permit fish to be your login shell:</p>
<pre>echo /usr/local/bin/fish | sudo tee -a /etc/shells
</pre>
<p dir="auto">To switch your default shell back, you can run <code>chsh -s /bin/bash</code>
(substituting <code>/bin/bash</code> with <code>/bin/tcsh</code> or <code>/bin/zsh</code> as
appropriate).</p>
<a name="user-content-building"></a>
<h2 tabindex="-1" dir="auto">Building</h2>
<a name="user-content-id1"></a>
<h3 tabindex="-1" dir="auto">Dependencies</h3>
<p dir="auto">Compiling fish from a tarball requires:</p>
<ul dir="auto">
<li>a C++11 compiler (g++ 4.8 or later, or clang 3.3 or later)</li>
<li>CMake (version 3.5 or later)</li>
<li>a curses implementation such as ncurses (headers and libraries)</li>
<li>PCRE2 (headers and libraries) - optional, this will be downloaded if missing</li>
<li>gettext (headers and libraries) - optional, for translation support</li>
</ul>
<p dir="auto">Sphinx is also optionally required to build the documentation from a
cloned git repository.</p>
<p dir="auto">Additionally, running the test suite requires Python 3.5+ and the pexpect package.</p>
<a name="user-content-dependencies-git-master"></a>
<h3 tabindex="-1" dir="auto">Dependencies, git master</h3>
<p dir="auto">Building from git master currently requires, in addition to the dependencies for a tarball:</p>
<ul dir="auto">
<li>Rust (version 1.67 or later)</li>
<li>libclang, even if you are compiling with GCC</li>
<li>an Internet connection</li>
</ul>
<p dir="auto">fish is in the process of being ported to Rust, replacing all C++ code, and as such these dependencies are a bit awkward and in flux.</p>
<p dir="auto">In general, we would currently not recommend running from git master if you just want to <em>use</em> fish.
Given the nature of the port, what is currently there is mostly a slower and buggier version of the last C++-based release.</p>
<a name="user-content-building-from-source-all-platforms-makefile-generator"></a>
<h3 tabindex="-1" dir="auto">Building from source (all platforms) - Makefile generator</h3>
<p dir="auto">To install into <code>/usr/local</code>, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir build; cd build
cmake ..
make
sudo make install"><pre>mkdir build<span>;</span> <span>cd</span> build
cmake ..
make
sudo make install</pre></div>
<p dir="auto">The install directory can be changed using the
<code>-DCMAKE_INSTALL_PREFIX</code> parameter for <code>cmake</code>.</p>
<a name="user-content-build-options"></a>
<h3 tabindex="-1" dir="auto">Build options</h3>
<p dir="auto">In addition to the normal CMake build options (like <code>CMAKE_INSTALL_PREFIX</code>), fish has some other options available to customize it.</p>
<ul dir="auto">
<li>BUILD_DOCS=ON|OFF - whether to build the documentation. This is automatically set to OFF when Sphinx isn't installed.</li>
<li>INSTALL_DOCS=ON|OFF - whether to install the docs. This is automatically set to on when BUILD_DOCS is or prebuilt documentation is available (like when building in-tree from a tarball).</li>
<li>FISH_USE_SYSTEM_PCRE2=ON|OFF - whether to use an installed pcre2. This is normally autodetected.</li>
<li>MAC_CODESIGN_ID=String|OFF - the codesign ID to use on Mac, or "OFF" to disable codesigning.</li>
<li>WITH_GETTEXT=ON|OFF - whether to build with gettext support for translations.</li>
</ul>
<p dir="auto">Note that fish does <em>not</em> support static linking and will attempt to error out if it detects it.</p>
<a name="user-content-help-it-didnt-build"></a>
<h3 tabindex="-1" dir="auto">Help, it didn’t build!</h3>
<p dir="auto">If fish reports that it could not find curses, try installing a curses
development package and build again.</p>
<p dir="auto">On Debian or Ubuntu you want:</p>
<pre>sudo apt install build-essential cmake ncurses-dev libncurses5-dev libpcre2-dev gettext
</pre>
<p dir="auto">On RedHat, CentOS, or Amazon EC2:</p>
<pre>sudo yum install ncurses-devel
</pre>
<a name="user-content-contributing-changes-to-the-code"></a>
<h2 tabindex="-1" dir="auto">Contributing Changes to the Code</h2>
<p dir="auto">See the <a href="https://github.com/fish-shell/fish-shell/blob/master/CONTRIBUTING.rst">Guide for Developers</a>.</p>
<a name="user-content-contact-us"></a>
<h2 tabindex="-1" dir="auto">Contact Us</h2>
<p dir="auto">Questions, comments, rants and raves can be posted to the official fish
mailing list at <a href="https://lists.sourceforge.net/lists/listinfo/fish-users" rel="nofollow">https://lists.sourceforge.net/lists/listinfo/fish-users</a>
or join us on our <a href="https://gitter.im/fish-shell/fish-shell" rel="nofollow">gitter.im
channel</a>. Or use the <a href="https://unix.stackexchange.com/questions/tagged/fish" rel="nofollow">fish tag
on Unix &amp; Linux Stackexchange</a>.
There is also a fish tag on Stackoverflow, but it is typically a poor fit.</p>
<p dir="auto">Found a bug? Have an awesome idea? Please <a href="https://github.com/fish-shell/fish-shell/issues/new">open an
issue</a>.</p>

</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This venture-backed startup has quietly bought more than 80 mom-and-pop shops (175 pts)]]></title>
            <link>https://techcrunch.com/2023/08/24/this-venture-backed-startup-has-quietly-bought-more-than-80-mom-and-pop-shops/</link>
            <guid>37272298</guid>
            <pubDate>Sat, 26 Aug 2023 12:37:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/08/24/this-venture-backed-startup-has-quietly-bought-more-than-80-mom-and-pop-shops/">https://techcrunch.com/2023/08/24/this-venture-backed-startup-has-quietly-bought-more-than-80-mom-and-pop-shops/</a>, See on <a href="https://news.ycombinator.com/item?id=37272298">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary"><a href="https://www.teamshares.com/" target="_blank" rel="noopener">Teamshares</a> is a low-flying, New York-based startup with big ambitions to capitalize on an opportunity in plain sight: that of small businesses without a succession plan.</p>
<p>It’s not a small market. According to the U.S. Small Business Administration, small businesses represent 99.7% of U.S. employer firms and 64% of private-sector jobs. Meanwhile, just 15% or so of small business owners pass along their company to a family member, with many others simply closing up shop at some point.</p>
<p>With an aging population in the U.S., Teamshares is betting this market will grow even bigger, which is why since 2018, it has snapped up 84 small businesses from retiring owners. These owners like its pitch. Though Teamshares says that it sometimes pays below market price for a company, it installs a new president that it trains and grants 10% of the business’s stock to its employees. <span>Moreover</span>, it promises to increase those employees’ ownership to 80% within 20 years. It sounds almost valiant, like when KKR bought out a door company in 2015 and promised every employee a payout of at least $15,000 if the company met its targets when sold. When in 2022, KKR sold the company for 10 times what it paid, its 800 employees saw a payout of <a href="https://hbswk.hbs.edu/item/how-kkr-got-more-by-giving-ownership-to-the-factory-floor" target="_blank" rel="noopener">$360 million</a>.</p>
<p>But Teamshares isn’t in the private equity business. It’s a fintech company that has raised $245 million in venture capital to date, including from QED Investors, Spark Capital, Union Square Ventures, Inspired Capital, Khosla Ventures and Slow Ventures. It has also secured another $150 million in debt.</p>
<p>Those backers aren’t funding Teamshares so that it can grow and resell the businesses it acquires. In fact, according to co-founder and CEO Michael Brown, Teamshares doesn’t want to sell the companies it is buying — ever. The plan instead is to generate revenue from a growing array of fintech products that it sells to the businesses it buys. Think insurance, think credit cards. If everything goes as planned, Teamshares will eventually replace the majority of vendors these companies use — and become a brand known to many others outside of its immediate sphere. Certainly, it’s among the more unique fintech models this reporter can recall. More below, edited for length.</p>
<p><strong>TC: Other than some exceptions like KKR, which is focused in part on employee ownership because owners tend to be better employees, I don’t know of another venture-backed company doing what you’re doing. How did you settle on this broader idea?</strong></p>
<p>MB:&nbsp; I spent the first seven years of my career in investment banking. And that’s where I met <a href="https://www.linkedin.com/in/alexeu/" target="_blank" rel="noopener">Alex Eu</a> and <a href="https://www.linkedin.com/in/kevinshiiba/" target="_blank" rel="noopener">Kevin Shiiba</a>, the other two founders. Kevin decided he wanted to join the tech industry very early [and joined the] coding bootcamp General Assembly; Alex and I went and bought one, and then eventually eight, small businesses. We transitioned from being financial spreadsheet people to being operators and later entrepreneurs; learning how to operate a businesses informs [our work] today.</p>
<p><strong>How did you exit those businesses?</strong></p>
<p>We still own the ones in Canada; they’re running themselves today. There’s a president, a vice president. They’re just sort of like a dormant legacy business, but they’ve started the employee ownership journey, too, and that’s continuing on.</p>
<p><strong>You make money off those businesses through dividends? Is this how you’ll make money at Teamshares?</strong></p>
<p>How Teamshares makes money is we buy businesses, we dilute ourselves voluntarily to get employee ownership jump-started. We [carve out] 10% for all the employees and an additional 5% for [a president who we hire to run each business], and that stock is a gift — it’s earned over time through service.</p>
<p>From a financial standpoint, we’re [structured] just like Berkshire Hathaway, so if we buy a business with $5 million in revenue, then that becomes our revenue the next day. We profit from the profits of the business that was acquired, proportionate to our ownership, and we sell our stock back over time to the companies until it becomes 80% employee owned. We also have new revenue streams that we’ve just started launching. We built a neobank, we’re soon to launch credit cards, and we’re building an insurance business as well, so there’s a secondary layer of financial products that will basically replace the vendors that the companies used to use.</p>
<p><strong>These products are going to be available exclusively to Teamshares companies or you start there and expand out?</strong></p>
<p>The hope is the latter. We only build something if a product doesn’t exist for our exact use case, which is some combination of really traditional small business or employee ownership. And there’s not a lot of stuff [out there]. When we set out, we didn’t think we’d build a neobank, but there just wasn’t something that existed to our satisfaction, in part because small businesses still unfortunately receive a lot of checks. But the hope would be that in the future — let’s call it in the next five years — we could scale up and open these products up and have small businesses generally get to know Teamshares.</p>
<p><strong>What do the companies you’ve acquired so far have in common?</strong></p>
<p>Where <em>we</em> have commonality in the companies is around employee ownership, financial education, the president program and financial infrastructure. So, we’re audited by KPMG, for example, and we help these companies go from mom-and-pop accounting to having real financial infrastructure and being able to produce statement financials every month that are in accordance with GAAP. But we really believe in the companies [operating as] independently as possible. We provide support, and we work closely with the presidents. But we don’t think that it’s a good idea to try and integrate all the companies.</p>
<p><strong>So you aren’t trying to roll up similar companies, or swaths of similar companies?</strong></p>
<p>There are some exceptions where, for example, we’ve been buying pizza shops in a state back East, and those are being integrated to create one larger company that’s going to create more employee ownership wealth than could a stand-alone set of pizza shops. We’re doing this again in pool maintenance, where a lot of the businesses are really [small] and actually [buying] a first one that’s small but big enough to support the cost of a president, and then you can add smaller ones. So there’s a roll-up-esque element of certain companies we work with, but in general, we think these are really high-quality businesses that can operate fairly independently and we actually make a very devout customer promise that the companies are going to become 80% employee owned, or never for sale again.</p>
<p><strong>What’s your investing criteria?</strong></p>
<p>There are over 40 specific industries [represented in Teamshares’ current portfolio], but they really fall into about six categories, which are business services, consumer services, distribution, manufacturing, restaurants, and retail. So they’re all traditional businesses that are, on average, 30 years old, with annual revenue of between $2 million and $10 million generally.</p>
<p>We have a belief that employee ownership works in every industry, and our actual final decision — amongst the 70,000 leads we get every year — is all done on a case-by-case basis. But we start off by filtering the companies on what we call our structural criteria. So is it a true retirement sale? Are the owners of that age? Are there two or more managers? Is there low customer concentration? Do the earnings show up on the tax returns?</p>
<p><strong>You’re planning to sell these companies your products. Are there other ways the companies in the Teamshares ecosystem can work together?</strong></p>
<p>Absolutely. We’re now getting to the size where we’re starting to organize the companies, around industry groups. So there’s talk of the restaurant companies all kind of banding together [toward the goal of] common purchasing. The presidents [sometimes] share knowledge about what’s the best sort of ERP system and other software to use? Then there’s other things that don’t make sense for us to build but we can arrange large, corporate vendor partnerships. So, for example, you know, lots of these companies need vehicles, so having a national account with one of the major vehicle lessors is going to make sense.</p>
<p><strong>You mentioned Berkshire Hathaway early on. Is that what you aspire to build? Do you want Teamshares to go public?</strong></p>
<p>The most probable outcome is we go public, but there are ways to stay private, too. We do not plan to ever sell Teamshares; we would want it to be independent.</p>
<p>In terms of the Berkshire Hathaway piece, we subscribe to a lot of their philosophy about being very long-term minded and being pretty efficient in our underwriting and keeping things simple. But we’re not a one-for-one translation of the model. Their model is to have the permanent ownership forever, whereas our model has employee ownership as a twist, so we’re actually forgoing some amount of future growth by making employee ownership happen. And we believe that’s the right thing to do. And we believe the companies will be bigger and better for it.</p>
<p>Also Berkshire Hathaway can only buy companies that already have a CEO in place, whereas that’s not a luxury you can have in small business. We realized we had to build up a new generation of people, generally in their 30s and 40s, who were ready for something more entrepreneurial and ready for something really mission aligned. And so we recruit people from some really great companies — McKinsey, USAA, Tesla and Amazon — and train them to run these small businesses.</p>
<p><strong>How many employees do you have, and how big is your tech team?</strong></p>
<p>We have about 140 people altogether, and a 70-person tech team, so we’ve closed seven companies a month with two people. We’ve created a lot of leverage through building a lot of software for ourselves and for the companies.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The EU’s Digital Services Act is now in effect (105 pts)]]></title>
            <link>https://www.theverge.com/23845672/eu-digital-services-act-explained</link>
            <guid>37271653</guid>
            <pubDate>Sat, 26 Aug 2023 11:01:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/23845672/eu-digital-services-act-explained">https://www.theverge.com/23845672/eu-digital-services-act-explained</a>, See on <a href="https://news.ycombinator.com/item?id=37271653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The European Union’s Digital Services Act (DSA) has officially gone into effect. Starting on August 25th, 2023, tech giants like Google, Facebook, Amazon, and more must comply with sweeping legislation that holds online platforms legally accountable for the content posted to them.</p><p>Even though this new law was passed in the EU, we’ll likely see far-reaching global effects as companies adjust their policies to comply. Here’s what exactly the DSA does and how the EU plans on enforcing it.</p><p><h3>What is the Digital Services Act?</h3></p><p>The overarching goal of the DSA is to foster safer online environments. Under the new rules, online platforms must implement ways to prevent and remove posts containing illegal goods, services, or content while simultaneously giving users the means to report this type of content.</p><p>Additionally, the DSA bans targeted advertising based on a person’s sexual orientation, religion, ethnicity, or political beliefs and puts restrictions on targeting ads to children. It also requires online platforms to provide more transparency on how their algorithms work. </p><p>The DSA carves out additional rules for what it considers “very large online platforms,” forcing them to give users the right to opt out of recommendation systems and profiling, share key data with researchers and authorities, cooperate with crisis response requirements, and perform external and independent auditing. </p><p>The European Parliament <a href="https://www.europarl.europa.eu/news/en/press-room/20220701IPR34364/digital-services-landmark-rules-adopted-for-a-safer-open-online-environment">passed the DSA in July 2022</a>. While the EU doesn’t require smaller companies to comply with the DSA just yet, it asked very large online platforms to comply four months after their designation as such, <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_2413">which occurred in April</a>.</p><p><h3>Which online platforms are affected?</h3></p><p>The EU considers very large online platforms (or very large online search engines) as those with over 45 million monthly users in the EU. So far, the EU has designed 19 platforms and search engines that fall into that category, including the following:</p><div><ul><li>Alibaba AliExpress</li><li>Amazon Store</li><li>Apple App Store</li><li>Booking.com</li><li>Facebook</li><li>Google Play</li><li>Google Maps</li><li>Google Shopping</li><li>Instagram</li><li>LinkedIn</li><li>Pinterest</li><li>Snapchat</li><li>TikTok</li><li>Twitter</li><li>Wikipedia</li><li>YouTube</li><li>Zalando</li><li>Bing</li><li>Google Search</li></ul></div><p>The EU will require each of these platforms to update their user numbers at least every six months. If a platform has less than 45 million monthly users for an entire year, they’ll be removed from the list.</p><p><h3>What are online platforms doing to comply?</h3></p><p>Many of these companies have already outlined the ways in which they’re going to comply with the DSA. Here’s a brief overview of the most notable ones.</p><p><h4>Google</h4></p><p>While Google says it already complies with some of the policies envisioned by the DSA, including the ability to give YouTube creators to appeal video removals and restrictions, <a href="https://www.theverge.com/2023/8/24/23845117/google-expanding-ads-transparency-center-comply-eu-dsa">Google announced that it’s expanding</a> its Ads Transparency Center to meet the requirements outlined by the legislation.</p><p>The company also committed to expanding data access to researchers to provide more information about “how Google Search, YouTube, Google Maps, Google Play and Shopping work in practice.” It will also improve its transparency reporting and analyze potential “risks of illegal content dissemination, or risks to fundamental rights, public health or civic discourse.”</p><p><h4>Meta</h4></p><p>Meta, the parent company of Facebook and Instagram, is working to expand its Ad Library, which currently compiles the ads shown on its platforms. The company will soon start displaying and archiving all the ads that target users in the EU while also including the parameters used to target the ads, as well as who was served the ad.</p><div><p>In June, Meta released <a href="https://www.theverge.com/2023/6/29/23778068/meta-facebook-instagram-social-media-algorithms-ai-transparency">a lengthy report about how its algorithm works</a> across Facebook and Instagram as part of its push toward transparency. It will also start <a href="https://www.theverge.com/2023/8/22/23841173/instagram-facebook-meta-chronological-feed-stories-reels-european-union-digital-services-act">allowing European users to view content chronologically on Reels</a>, Stories, and Search on both Facebook and Instagram — without being subject to its personalization engine.</p></div><p><h4>TikTok</h4></p><p>Similar to the measures Meta is rolling out, TikTok has also announced that it’s making its algorithm optional for users in the EU. When the algorithm is disabled, users will see videos from “both the places where they live and around the world” in their For You and Live feeds instead of videos based on personal interests. </p><p>It will also enable users to view content chronologically on their Following and Friends feeds. TikTok is making some changes to its advertising policies as well. For European users aged 13 to 17, TikTok will stop showing personalized ads based on their activity in the app.</p><p><h4>Snap</h4></p><p>Snapchat will also give users in the EU the option to opt out of personalized feeds on its Discover and Spotlight pages and <a href="https://help.snapchat.com/hc/en-us/articles/17338132910484-Personalisation-on-Snapchat?_ga=2.55027560.2100881955.1692971960-1974149196.1692971960">has also published reports</a> on how it ranks the posts on these feeds. The company has committed to providing users with more information about why their posts or account has been removed and will give them the tools they need to appeal the decision.</p><p>In addition, Snapchat will no longer serve personalized ads to European Snapchat users aged 13 to 17. It will also create an archive of targeted advertisements it shows in the EU and will give European Snapchat users over the age of 18 more control over the ads they see.</p><p><h3>What happens if these platforms don't comply?</h3></p><p>Online platforms that don’t comply with the DSA’s rules could see fines of up to 6 percent of their global turnover. <a href="https://ec.europa.eu/commission/presscorner/detail/en/QANDA_20_2348">According to the EU Commission</a>, the Digital Services Coordinator and the Commission&nbsp;will have the power to “require immediate actions where necessary to address very serious harms.” A platform continually refusing to comply could result in a temporary suspension in the EU.</p><p>The EU is already seeing some companies push back on the DSA. In July, Amazon filed a petition that asks the EU to reevaluate its classification as a very large online platform, claiming that it’s getting “unfairly singled out.” <a href="https://www.reuters.com/business/retail-consumer/zalando-sues-eu-commission-over-landmark-online-content-rules-2023-06-27/">German retailer Zalando also filed a lawsuit</a> against the EU Commission, similarly claiming that it doesn’t meet the definition of a very large online platform.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Clean mount lists in Linux (153 pts)]]></title>
            <link>https://dbohdan.com/clean-mount-lists</link>
            <guid>37271611</guid>
            <pubDate>Sat, 26 Aug 2023 10:54:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dbohdan.com/clean-mount-lists">https://dbohdan.com/clean-mount-lists</a>, See on <a href="https://news.ycombinator.com/item?id=37271611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Default installations of Linux distributions mount more filesystems than they used to. This is because of <a href="https://en.wikipedia.org/wiki/Loop_device">loop devices</a>, <a href="https://en.wikipedia.org/wiki/Cgroups">cgroups</a>, and, in Ubuntu, <a href="https://en.wikipedia.org/wiki/Snap_(software)">snaps</a>. As a result, the output from GNU df(1) as well as from <a href="https://en.wikipedia.org/wiki/Util-linux">lsblk(8) and mount(8)</a> is more difficult to understand at a glance.</p>
<p>It is possible to make the output of these commands more readable by removing some of the “noise” devices. The following is a list of command arguments that remove irrelevant devices. After the list, I show how to replace the default commands in <a href="https://fishshell.com/">fish</a>. You can adapt the replacement script for other shells.</p>
<h2 id="contents">Contents</h2>
<nav id="TOC" role="doc-toc">
<ul>
<li>
<a href="#df">df</a>
</li>
<li>
<a href="#lsblk">lsblk</a>
</li>
<li>
<a href="#mount">mount</a>
<ul>
<li>
<a href="#include-list">Include list</a>
</li>
<li>
<a href="#exclude-list">Exclude list</a>
</li>
<li>
<a href="#fish">fish configuration</a>
</li>
</ul>
</li>
<li>
<a href="#findmnt">findmnt instead of df and mount</a>
</li>
</ul>
</nav>
<h2 id="df">df</h2>
<p>GNU df(1) allows you to exclude <a href="https://en.wikipedia.org/wiki/Tmpfs">tmpfs</a> with a simple option. In Ubuntu 22.04, this removes <code>/dev/shm</code>, <code>/run</code>, <code>/run/user/*</code>, and other mount points from its output. In an improvement from Ubuntu 20.04, df(1) is already <a href="https://bugs.launchpad.net/ubuntu/+source/apt/+bug/1756595">patched</a> to exclude <a href="https://en.wikipedia.org/wiki/SquashFS">Squashfs</a> (snaps).</p>
<p>Command:</p>
<pre><code>df -x tmpfs</code></pre>
<p>The improvement on my system is as follows:</p>
<pre><code>&gt; df | wc -l
25
&gt; df -x tmpfs | wc -l
19</code></pre>
<h2 id="lsblk">lsblk</h2>
<p>The command lsblk(8) can exclude devices by major device type. Snaps are loopback devices. According to <a href="https://www.kernel.org/doc/Documentation/admin-guide/devices.txt"><code>devices.txt</code></a> in the Linux kernel admin guide, the device type for loopback devices is 7.</p>
<p>Command:</p>
<pre><code>lsblk -e 7</code></pre>
<p>Improvement:</p>
<pre><code>&gt; lsblk | wc -l
56
&gt; lsblk -e 7 | wc -l
28</code></pre>
<h2 id="mount">mount</h2>
<p>We can simplify the output of GNU mount(8) by either excluding certain filesystem types or only including certain filesystem types.</p>
<h3 id="include-list">Include list</h3>
<p>Example command:</p>
<pre><code>mount -l -t btrfs,fat,exfat,ext2,ext4,iso9660,ntfs3,ufs,vfat,xfs,zfs</code></pre>
<p>Choose the type based on what filesystems you work with. For a list of supported filesystem type, look in <code>/proc/filesystems</code> and <code>/lib/modules/"$(uname -r)"/kernel/fs/</code>.</p>
<h3 id="exclude-list">Exclude list</h3>
<p>This is a little more involved, since mount(8) seems to lack a built-in “exclude” option. We can filter the output by the type column with awk.</p>
<p>Example command:</p>
<pre><code>mount | awk '$5 !~ /(autofs|binfmt_misc|bpf|cgroup2|configfs|debugfs|devpts|devtmpfs|fuse|hugetlbfs|mqueue|nfsd|nsfs|proc|pstore|ramfs|rpc_pipefs|securityfs|squashfs|sysfs|tmpfs|tracefs)/'</code></pre>
<p>The improvement with the exclude list is,</p>
<pre><code>&gt; mount | wc -l
77
&gt; mount | awk '...' | wc -l
19</code></pre>
<h3 id="fish">fish configuration</h3>
<p>This configuration script replaces commands with wrappers that use arguments from the previous sections by default. They only use the arguments if you do not give arguments of your own. To ignore the wrapper and run, for example, <code>mount</code> without any arguments, use <code>command mount</code> or <code>mount --</code>.</p>
<h4 id="installation">Installation</h4>
<pre><code>cd ~/.config/fish/conf.d/
curl -O https://dbohdan.com/clean-mount-lists.fish
less clean-mount-lists.fish  # Examine the code.</code></pre>
<h4 id="source">Source</h4>
<pre><code># clean-mount-lists 0.2.0
# Wrap commands to show cleaner mount lists in Linux.
# See https://dbohdan.com/clean-mount-lists
# License: MIT.
# https://dbohdan.mit-license.org/@2023

if status is-interactive; and test "$(uname)" = Linux
    if not set --query clean_mount_lists_exclude
        set --universal clean_mount_lists_exclude \
            autofs binfmt_misc bpf cgroup2 configfs debugfs devpts \
            devtmpfs fuse hugetlbfs mqueue nfsd nsfs proc pstore ramfs \
            rpc_pipefs securityfs squashfs sysfs tmpfs tracefs
    end

    function df --wraps df
        if test (count $argv) -eq 0
            # `-x` requires GNU df(1).
            command df -h -x tmpfs
        else
            command df $argv
        end
    end

    function mount --wraps mount
        if test (count $argv) -eq 0
            set --local re (string join '|' $clean_mount_lists_exclude)

            command mount | awk -v re=$re '$5 !~ re'
        else
            command mount $argv
        end
    end

    function lsblk --wraps lsblk
        if test (count $argv) -eq 0
            command lsblk -e 7
        else
            command lsblk $argv
        end
    end
end
</code></pre>
<h2 id="findmnt">findmnt instead of df and mount</h2>
<p><a href="https://linux.die.net/man/8/findmnt">findmnt(8)</a> from util-linux is an alternative to df(1) and mount(8) with better options for filtering. For example,</p>
<pre><code>findmnt --df --options rw --real</code></pre>
<p>produces output like <code>df -h</code>, but only for real and read-write filesystems.</p>
<p>Thanks to the <a href="https://news.ycombinator.com/item?id=37271611">HN discussion thread</a> for suggesting findmnt(8) and the <code>--options rw --real</code> invocation.</p>


          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[As I get older, I just don't care about new technology (152 pts)]]></title>
            <link>https://old.reddit.com/r/webdev/comments/1613yqj/as_i_get_older_i_just_dont_care_about_new/</link>
            <guid>37271401</guid>
            <pubDate>Sat, 26 Aug 2023 10:19:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/webdev/comments/1613yqj/as_i_get_older_i_just_dont_care_about_new/">https://old.reddit.com/r/webdev/comments/1613yqj/as_i_get_older_i_just_dont_care_about_new/</a>, See on <a href="https://news.ycombinator.com/item?id=37271401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Maybe it's just the depressive phase I'm currently in, or if I'm just getting older and have less and less patience for things, but I just don't care about new technology.</p>

<p>Trying to do this Next 12 -&gt; Next 13 upgrade is not fun work for a production app, and on top of that there is this whole new "app" concept in Next... and I just don't care. I adopted Turborepo and regret that 10x over.</p>

<p>I want to build things for people. Not constantly update my tools because other developers are bored.</p>

<p>(please take this all with a grain of salt. I'm tired and depressed and my coworkers are useless)</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NES Emulator in Common Lisp (2016) (119 pts)]]></title>
            <link>https://github.com/samanthadoran/potential-disco</link>
            <guid>37271269</guid>
            <pubDate>Sat, 26 Aug 2023 10:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/samanthadoran/potential-disco">https://github.com/samanthadoran/potential-disco</a>, See on <a href="https://news.ycombinator.com/item?id=37271269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">potential-disco</h2>
<p dir="auto">Trying to emulate the NES again in Common Lisp</p>
<p dir="auto">TODO: Other mapppers besides NROM<br>
TODO: Audio<br>
TODO: Run at proper speed instead of just letting it go however fast it pleases.<br>
TODO: Write more idiomatic Lisp</p>
<h4 tabindex="-1" dir="auto">Examples</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/44db2860bd2f8ad6ab26a51e4bf860a822f4e85ab3e9077f1168e520a2e60c6a/68747470733a2f2f692e6779617a6f2e636f6d2f35623862313631626537343238313235356534386236336462343561373238352e676966"><img src="https://camo.githubusercontent.com/44db2860bd2f8ad6ab26a51e4bf860a822f4e85ab3e9077f1168e520a2e60c6a/68747470733a2f2f692e6779617a6f2e636f6d2f35623862313631626537343238313235356534386236336462343561373238352e676966" alt="Super Mario Bros" data-animated-image="" data-canonical-src="https://i.gyazo.com/5b8b161be74281255e48b63db45a7285.gif"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2d3447d9e5b3ad4174558df1047905c4c0558694704cd9e015e9a5f123d09e4c/68747470733a2f2f692e6779617a6f2e636f6d2f64396166346236663332613162363739306265343636323763323033353330362e676966"><img src="https://camo.githubusercontent.com/2d3447d9e5b3ad4174558df1047905c4c0558694704cd9e015e9a5f123d09e4c/68747470733a2f2f692e6779617a6f2e636f6d2f64396166346236663332613162363739306265343636323763323033353330362e676966" alt="Galaga" data-animated-image="" data-canonical-src="https://i.gyazo.com/d9af4b6f32a1b6790be46627c2035306.gif"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ed8c3793ee37feefbef576d326c9d5d29edcd59846609841a43a2de90cf7c474/68747470733a2f2f692e6779617a6f2e636f6d2f65646663316463343234356365306266626266393961663865383438373065302e676966"><img src="https://camo.githubusercontent.com/ed8c3793ee37feefbef576d326c9d5d29edcd59846609841a43a2de90cf7c474/68747470733a2f2f692e6779617a6f2e636f6d2f65646663316463343234356365306266626266393961663865383438373065302e676966" alt="Donkey Kong" data-animated-image="" data-canonical-src="https://i.gyazo.com/edfc1dc4245ce0bfbbf99af8e84870e0.gif"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1ae921f93fa87a01b0ef491f96a4f881f2110f8df0f784b412f9324768d80fb2/68747470733a2f2f692e6779617a6f2e636f6d2f65663231636436356466373236373636323633376337333561613430366264652e676966"><img src="https://camo.githubusercontent.com/1ae921f93fa87a01b0ef491f96a4f881f2110f8df0f784b412f9324768d80fb2/68747470733a2f2f692e6779617a6f2e636f6d2f65663231636436356466373236373636323633376337333561613430366264652e676966" alt="Volley Ball" data-animated-image="" data-canonical-src="https://i.gyazo.com/ef21cd65df7267662637c735aa406bde.gif"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5b102ced9fb1c697db6b3c919ece21454a21445396600a911a2c572cd72929a8/68747470733a2f2f692e6779617a6f2e636f6d2f66366630373637663338303633383862393966623334333139303430366237312e706e67"><img src="https://camo.githubusercontent.com/5b102ced9fb1c697db6b3c919ece21454a21445396600a911a2c572cd72929a8/68747470733a2f2f692e6779617a6f2e636f6d2f66366630373637663338303633383862393966623334333139303430366237312e706e67" alt="NesTest" data-canonical-src="https://i.gyazo.com/f6f0767f3806388b99fb343190406b71.png"></a></p>
<h4 tabindex="-1" dir="auto">Usage</h4>
<p dir="auto">In your favorite common lisp repl (I haven't tested outside of
sbcl), just run</p>
<div data-snippet-clipboard-copy-content="(asdf:load-system :console)
(nes:setup-and-emulate path-to-rom)"><pre><code>(asdf:load-system :console)
(nes:setup-and-emulate path-to-rom)
</code></pre></div>
<p dir="auto">Where path to rom is a string<br>
The controls map to..
Start: Tab<br>
Select: Grave<br>
Left, Down, Right, Up: W, A, S, D<br>
A, B: Left Arrow, Down Arrow<br>
I'm sorry, they aren't re-mappable yet. =(</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[66% of Americans say they want extended European-style vacation policies at work (128 pts)]]></title>
            <link>https://www.cnbc.com/2023/08/25/66percent-of-americans-say-they-want-extended-european-style-vacation-policies-at-work.html</link>
            <guid>37270881</guid>
            <pubDate>Sat, 26 Aug 2023 08:47:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/08/25/66percent-of-americans-say-they-want-extended-european-style-vacation-policies-at-work.html">https://www.cnbc.com/2023/08/25/66percent-of-americans-say-they-want-extended-european-style-vacation-policies-at-work.html</a>, See on <a href="https://news.ycombinator.com/item?id=37270881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="MakeItRegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-1" data-analytics="MakeItRegularArticle-articleBody-5-1"><div><p>In many parts of Europe, it's common for workers to <a href="https://www.cnbc.com/2023/08/18/9-european-countries-where-workers-get-more-than-a-month-of-vacation.html">take off weeks at a time</a>, especially during the summer. Envious Americans say it's time for the U.S. to follow suit.</p><p>Some 66% of U.S. workers say companies should adopt extended vacation policies, like a month off in August, in their workplaces, according to a <a href="https://pro.morningconsult.com/analysis/us-sentiment-four-day-work-week" target="_blank">Morning Consult survey</a> of 1,047 U.S. adults.</p><p>While the average American is lucky to get <a href="https://www.bls.gov/charts/employee-benefits/paid-leave-sick-vacation-days-by-service-requirement.htm" target="_blank">11 vacation days</a> from their employer each year, workers in the European Union are guaranteed&nbsp;at least<a href="https://cepr.net/images/stories/reports/no-vacation-nation-2019-05.pdf#page=5" target="_blank">&nbsp;20 working days of paid vacation</a> due to the European Union Working Time Directive, which passed in the early 1990s. Several countries offer even more by law before paid public holidays come into play, which can add up to more than a month of business days in vacation time per year.</p><p>But not all U.S. workers say they'd welcome longer vacation policies: 21% of Americans say companies should not adopt extended PTO policies in their workplace, while the remaining respondents say they don't know or don't have an opinion.</p><p>The survey didn't specifically address the concerns of those against extended time off work, says Ellyn Briggs, brands analyst at Morning Consult. However, in responses to a separate question about people's attitudes toward a four-day workweek, roughly half of American workers say they'd use their extra time to catch up on work or learn a work-related skill.</p><p>Separately, 41% of U.S. workers report being more satisfied in their career today than before, which is nearly double the share of those who feel less satisfied in their career today, according to Morning Consult data. "These data points suggest a portion of employed U.S. adults generally enjoy their work and seek new opportunities to improve upon it," Briggs says. "Extended periods off may hold little appeal for this group."</p><p>That being said, generous vacations aren't the only European practice that Americans say should become the norm here: 65% of U.S. workers would like to see extended lunch breaks, 62% want workweeks shorter than 40 hours, and 51% support slower employee response time outside of work hours, similar to many labor laws common throughout Europe.</p><p><em><strong>Want to be smarter and more successful with your money, work &amp; life?&nbsp;</strong></em><a href="https://www.cnbc.com/makeitnewsletter/?__source=makeit%7Cnlarticleteaser"><em><strong>Sign up for our new newsletter</strong></em></a><em><strong>!</strong></em></p><p><em>Get CNBC's free&nbsp;</em><a href="https://www.cnbc.com/buffett-whitepaper/">Warren Buffett Guide to Investing</a><em>, which distills the billionaire's No. 1 best piece of advice for regular investors, do's and don'ts, and three key investing principles into a clear and simple guidebook.</em></p><p><em><strong>Check out: </strong></em><a href="https://www.cnbc.com/2023/07/09/how-a-norway-28-year-old-prepares-for-required-3-week-summer-vacation.html"><em><strong>28-year-old social media manager in Norway is required to take 3 weeks of vacation in summer</strong></em></a></p></div><div id="Placeholder-ArticleBody-Video-107268190" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000306846" aria-labelledby="Placeholder-ArticleBody-Video-107268190"><p><img src="https://image.cnbcfm.com/api/v1/image/107268257-mm-torres-still.jpg?v=1688993102&amp;w=750&amp;h=422&amp;vtcrop=y" alt="How a Gen Z couple earning $43,000 in Nashville, Tennessee spends their money"><span></span><span><span data-test="PlayButton"></span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uncle Sam accuses SpaceX of not considering asylees and refugees for employment (101 pts)]]></title>
            <link>https://www.theregister.com/2023/08/25/spacex_discrimination_lawsuit/</link>
            <guid>37270634</guid>
            <pubDate>Sat, 26 Aug 2023 07:41:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/08/25/spacex_discrimination_lawsuit/">https://www.theregister.com/2023/08/25/spacex_discrimination_lawsuit/</a>, See on <a href="https://news.ycombinator.com/item?id=37270634">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Fresh from blowing up a small portion of Texas with Starship, SpaceX is once again being forced to focus on more earthly matters, like discriminatory hiring practices, in a lawsuit brought by the US Department of Justice.</p>
<p>The <a target="_blank" rel="nofollow" href="https://www.justice.gov/media/1311656/dl?inline">complaint</a> [PDF] filed Wednesday through the Office of the Chief Administrative Hearing Officer, part of the department's Executive Office for Immigration Review, accuses SpaceX of discriminating against asylees and refugees and "routinely" discouraging people with this citizenship status against even applying for roles at the company.</p>
<p>We're all used to CEO Elon Musk saying things of dubious veracity as the owner of <span>Twitter</span> X, but in this case the DoJ claims that statements from both SpaceX and its boss were so wrong they broke federal law, specifically the Immigration and Nationality Act (INA). The rules stipulate that asylees and refugees cannot be discriminated against for their citizenship status in the process of applying for job.</p>

    

<p>SpaceX fell foul of the law, the DoJ alleges, because it repeatedly and incorrectly claimed it could only hire US citizens and lawful permanent residents, thereby discouraging asylees and refugees from even bothering. Between September 2018 and May 2022, it was accused of tracking applicants by citizen status and marking asylees and refugees as ineligible for employment under the International Traffic in Arms Regulations (ITAR).</p>

        


        

<p>Explaining why this was way off-piste, the DoJ said in a <a target="_blank" href="https://www.justice.gov/opa/pr/justice-department-sues-spacex-discriminating-against-asylees-and-refugees-hiring">statement</a> yesterday: "Under these regulations, asylees, refugees, lawful permanent residents, US citizens and US nationals working at US companies can access export-controlled items without authorization from the US government. Therefore, these laws do not require SpaceX to treat asylees and refugees differently than US citizens or green card holders."</p>
<p>The DoJ added that asylees and refugees "undergo thorough vetting by the United States government. Under the INA, employers cannot discriminate against them in hiring, unless a law, regulation, executive order or government contract requires the employer to do so. In this instance, no law, regulation, executive order or government contract required or permitted SpaceX to engage in the widespread discrimination against asylees or refugees that the department's investigation found."</p>

        

<p>The complaint alleges that SpaceX's incorrect stance went right to the top, highlighting a number of times where Musk said that the working at the company was off-limits to anyone who wasn't a US citizen or lacked a green card.</p>
<p>On June 16, 2020, Musk posted on Twitter: "US law requires at least a green card to be hired at SpaceX, as rockets are considered advanced weapons technology."</p>
<p>It also said that during an international space conference in September 2016, "SpaceX's CEO stated the SpaceX had to comply with ITAR, which meant that a normal work visa is insufficient to work at SpaceX unless the company can obtain 'special permission from the Secretary of Defense or Secretary of State.' He then added that SpaceX is 'not allowed' to hire people who don't have a 'green card' and that 'unless [you] can somehow get a green card, we are legally prevented from hiring anyone.'"</p>
<ul>

<li><a href="https://www.theregister.com/2023/08/23/spacex_counter_omnispace/">SpaceX, T-Mobile US phone service will interfere with ours, claims rival</a></li>

<li><a href="https://www.theregister.com/2023/07/06/spacex_denies_environmental_lawsuit/">SpaceX says, sure, Starship blew up but you can forget about the rest of that lawsuit</a></li>

<li><a href="https://www.theregister.com/2023/05/10/vast_trip_space_station/">This upstart is selling tickets for a SpaceX trip to the world's first private space station</a></li>

<li><a href="https://www.theregister.com/2023/04/26/us_faa_starship/">US watchdog grounds SpaceX Starship after that explosion</a></li>
</ul>
<p>In an online video dating all the way back to 2012, the complaint quoted Musk as saying: "It's quite difficult for us to employ people that don't have a green card because of US ITAR rules." He added that his "first advice" to non-US citizens hoping for a job at SpaceX would be: "Do anything you can to get a green card."</p>
<p>The complaint also claimed that SpaceX's Vice President of Human Resources said on an online chat forum in 2016: "To comply with US government space technology export regulations including ITAR, applicants must generally be US citizens or lawful permanent residents."</p>

        

<p>The DoJ points out that not everyone working at SpaceX is a rocket scientist, also employing "welders, cooks, crane operators, baristas and dishwashers... The jobs at issue in the lawsuit are not limited to those that require advanced degrees."</p>
<p>Assistant Attorney General Kristen Clarke of the Justice Department's Civil Rights Division said: "Our investigation found that SpaceX failed to fairly consider or hire asylees and refugees because of their citizenship status and imposed what amounted to a ban on their hire regardless of their qualification, in violation of federal law.</p>
<p>"Our investigation also found that SpaceX recruiters and high-level officials took actions that actively discouraged asylees and refugees from seeking work opportunities at the company.</p>
<p>"Asylees and refugees have overcome many obstacles in their lives, and unlawful employment discrimination based on their citizenship status should not be one of them. Through this lawsuit we will hold SpaceX accountable for its illegal employment practices and seek relief that allows asylees and refugees to fairly compete for job opportunities and contribute their talents to SpaceX's workforce."</p>
<p>The suit seeks "fair consideration and back pay for asylees and refugees who were deterred or denied employment at SpaceX due to the alleged discrimination," civil penalties to be determined in court, and policy changes to ensure the company does not flout the INA again.</p>
<p>It could be that SpaceX has been erring on the side caution when it comes to ITAR because it has a number of lucrative contracts with NASA and the US Department of Defense. Accidental violation of export control laws and regulations could indeed put such contracts at risk.</p>
<p>However, by law, asylees and refugees should never fall under these restrictions, thus the DoJ believes SpaceX has, for lack of a better term, done goofed.</p>
<p><em>The Register</em> has asked SpaceX to comment. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Companies That Union-Bust Must Now Automatically Recognize Union, NLRB Rules (147 pts)]]></title>
            <link>https://www.vice.com/en/article/dy3xej/companies-that-union-bust-must-now-automatically-recognize-union-nlrb-rules</link>
            <guid>37269909</guid>
            <pubDate>Sat, 26 Aug 2023 04:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/dy3xej/companies-that-union-bust-must-now-automatically-recognize-union-nlrb-rules">https://www.vice.com/en/article/dy3xej/companies-that-union-bust-must-now-automatically-recognize-union-nlrb-rules</a>, See on <a href="https://news.ycombinator.com/item?id=37269909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>NLRB sign. Image Credit: Getty Images</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>The National Labor Relations Board issued a ruling on Friday that <a href="https://www.nlrb.gov/news-outreach/news-story/board-issues-decision-announcing-new-framework-for-union-representation" target="_blank"><span>changes the framework</span></a> for unionizations, making it easier for workers to organize and harder for companies to fight back against them.&nbsp;</p></span><span data-component="TextBlock"><p>The new process comes as part of a decision in the case between Cemex Construction Materials Pacific, LLC and the International Brotherhood of Teamsters, where the Board found that the employer had committed over 20 “instances of objectionable or unlawful misconduct” between the filing of the union election petition and the election itself, intending to dissuade workers from organizing.&nbsp;</p></span></p><p><span data-component="TextBlock"><p>The decision requires that if a majority of workers ask a company for voluntary recognition of their union, the company must either immediately recognize them or promptly file a petition asking the Board to hold a union election.&nbsp;</p></span><span data-component="TextBlock"><p>“However, if an employer who seeks an election commits any unfair labor practice that would require setting aside the election, the petition will be dismissed, and—rather than re-running the election—the Board will order the employer to recognize and bargain with the union,” an <a href="https://www.nlrb.gov/news-outreach/news-story/board-issues-decision-announcing-new-framework-for-union-representation" target="_blank"><span>NLRB press release stated</span></a>. If the company neither recognizes the union nor files a petition, the Board will issue a bargaining order forcing the company to come to the table.&nbsp;</p></span></p><p><span data-component="TextBlock"><p>“This is a very important ruling that will help workers to be able to unionize free of coercion, especially at companies like Trader Joe's, Starbucks and Amazon,” said Seth Goldstein, a partner at Julien, Mirer, Singla and Goldstein, who has represented workers at those companies attempting to unionize and <a href="https://www.nytimes.com/2023/07/21/opinion/starbucks-union-strikes-labor-movement.html" target="_blank"><span>facing union-busting efforts</span></a>. “This has been the law of the land for 80 years, so it really goes back to what should have been all along.”&nbsp;</p></span><span></span><span data-component="TextBlock"><p>Goldstein was referring to a 1949 Supreme Court decision known as <a href="https://www.politico.com/news/magazine/2022/06/07/the-lie-that-helped-kill-the-labor-movement-00037459" target="_blank"><span>Joy Silk</span></a>, which stated that an employer had to voluntarily recognize and bargain with a majority of workers who wanted a union, and could only contest the unionization if it had “good faith doubt” about the union’s majority status. Joy Silk was <a href="https://supreme.justia.com/cases/federal/us/395/575/" target="_blank"><span>abandoned in 1969</span></a> in favor of giving companies more leverage in the unionization process.&nbsp;</p></span><span data-component="TextBlock"><p>But NLRB General Counsel Jennifer Abruzzo issued a memo earlier this year <a href="https://www.jdsupra.com/legalnews/nlrb-general-counsel-calls-for-4375993/" target="_blank"><span>demanding that the Board revive Joy Silk</span></a>, something that <a href="https://www.politico.com/news/magazine/2022/06/07/the-lie-that-helped-kill-the-labor-movement-00037459" target="_blank"><span>labor activists have been fighting</span></a> for since it was overturned. The Cemex decision issued on Friday is a partial step in that direction.&nbsp;</p></span><span data-component="TextBlock"><p>“What this new decision does is, it's a compromise,” said Eric Blanc, an assistant professor of labor studies at Rutgers University. “It's not a return to ‘card check,’” the unionization process in the 1930s and ‘40s that said if a majority of workers signed cards stating they wanted a union, the company was obligated to recognize and bargain with them—which Joy Silk had upheld.&nbsp;</p></span><span data-component="TextBlock"><p>“If there's intense illegal union busting, as is very often the case, the NLRB can force the employers to immediately recognize the union rather than have to go through another union election,” Blanc said. “But it's far short of what many union organizers were hoping for. By not making ‘card check’ the norm, [it] still opens up the process to all sorts of legal appeals and delays, which is ultimately one of the main tactics of employers—to delay the union first and then hold things up in endless appeals. This unfortunately doesn't avoid that dynamic, but it does get the NLRB more powers to require employers to recognize unions, and that should be at least a partial deterrent on employers’ willingness to break the law.”&nbsp;</p></span><span data-component="TextBlock"><p>Goldstein said that despite the incomplete return to Joy Silk, he thought it was a “big step forward.”&nbsp;</p></span><span data-component="TextBlock"><p>“The Board is taking a proactive stance, that unfair labor violations are going to be challenged,” he said. “We haven’t seen this kind of activism from the Board since the 1940s. I think this is going to really help workers.”</p></span></p></div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg Explorer (173 pts)]]></title>
            <link>https://ffmpeg.lav.io</link>
            <guid>37269425</guid>
            <pubDate>Sat, 26 Aug 2023 02:33:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ffmpeg.lav.io">https://ffmpeg.lav.io</a>, See on <a href="https://news.ycombinator.com/item?id=37269425">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[We are not empty: The concept of the atomic void is a mistake (129 pts)]]></title>
            <link>https://aeon.co/essays/why-the-empty-atom-picture-misunderstands-quantum-theory</link>
            <guid>37268886</guid>
            <pubDate>Sat, 26 Aug 2023 00:55:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeon.co/essays/why-the-empty-atom-picture-misunderstands-quantum-theory">https://aeon.co/essays/why-the-empty-atom-picture-misunderstands-quantum-theory</a>, See on <a href="https://news.ycombinator.com/item?id=37268886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The camera zooms in on the person’s arm to reveal the cells, then a cell nucleus. A DNA strand grows on the screen. The camera focuses on a single atom within the strand, dives into a frenetic cloud of rocketing particles, crosses it, and leaves us in oppressive darkness. An initially imperceptible tiny dot grows smoothly, revealing the atomic nucleus. The narrator lectures that the nucleus of an atom is tens of thousands of times smaller than the atom itself, and poetically concludes that we are made from emptiness.</p>
<p>How often have you seen such a scene or read something equivalent to it in popular science? I am sure plenty, if you are fans of this genre like me. However, the narrative is wrong. Atomic nuclei in a molecule are not tiny dots, and there are no empty spaces within the atom.</p>
<p>The <em>empty atom</em> picture is likely the most repeated mistake in popular science. It is unclear who created this myth, but it is sure that Carl Sagan, in his classic TV series <em>Cosmos</em> (1980), was crucial in popularising it. After wondering how small the nuclei are compared with the atom, Sagan concluded that</p>
<blockquote>[M]ost of the mass of an atom is in its nucleus; the electrons are by comparison just clouds of moving fluff. Atoms are mainly empty space. Matter is composed chiefly of nothing.</blockquote>
<p>I still remember how deeply these words spoke to me when I heard them as a kid in the early 1980s. Today, as a professional theoretical chemist, I know that Sagan’s statements failed to recognise some fundamental features of atoms and molecules.</p>
<p>Yet his reasoning is still influential. While preparing this essay, I ran a poll on Twitter asking whether people agreed with Sagan’s quote above. Of the 180 voters, <span>43 per</span> cent answered that they mostly agreed, and <span>27 per</span> cent fully agreed. Google ‘atoms empty space’, and you will find tens of essays, blog posts and YouTube videos concluding that atoms are <span>99.9 per</span> cent empty space. To be fair, you will also find a reasonable share of articles debunking the idea.</p>
<p>Misconceptions feeding the idea of the empty atom can be dismantled by carefully interpreting quantum theory, which describes the physics of molecules, atoms and subatomic particles. According to quantum theory, the building blocks of matter – like electrons, nuclei and the molecules they form – can be portrayed either as waves or particles. Leave them to evolve by themselves without human interference, and they act like delocalised waves in the shape of continuous clouds. On the other hand, when we attempt to observe these systems, they appear to be localised particles, something like bullets in the classical realm. But accepting the quantum predictions that nuclei and electrons fill space as continuous clouds has a daring conceptual price: it implies that these particles do not vibrate, spin or orbit. They inhabit a motionless microcosmos where time only occasionally plays a role.</p>
<p>Most problems surrounding the description of the submolecular world come from frustrated attempts to reconcile conflicting pictures of waves and particles, leaving us with inconsistent chimeras such as particle-like nuclei surrounded by wave-like electrons. This image doesn’t capture quantum theory’s predictions. To compensate, our conceptual reconstruction of matter at the submolecular level should consistently describe how nuclei and electrons behave when not observed – like the proverbial sound of a tree falling in the forest without anyone around.</p>
<p><span>H</span>ere’s a primer on how to think of the fundamental components of matter: a molecule is a stable collection of nuclei and electrons. If the collection contains a single nucleus, it is called an atom. Electrons are elementary particles with no internal structure and a negative electric charge. On the other hand, each nucleus is a combined system composed of several protons and a roughly equal number of neutrons. Each proton and neutron is 1,836 times more massive than an electron. The proton has a positive charge of the same magnitude as an electron’s negative charge, while neutrons, as their name hints, have no electric charge. Usually, but not necessarily, the total number of protons in a molecule equals the number of electrons, making molecules electrically neutral.</p>
<p>The interior of the protons and neutrons is likely the most complex place in the Universe. I like to consider each of them a hot soup of three permanent elementary particles known as quarks boiling along inside, with an uncountable number of virtual quarks popping into existence and disappearing almost immediately. Other elementary particles called gluons hold the soup within a pot of <span>0.9 femtometres</span> radius. (A femtometre, abbreviated fm, is a convenient scale that measures systems tens of thousands of times smaller than an atom. Corresponding to <span>10</span><span><sup>‑15</sup></span><span> m,</span> we must juxtapose <span>1 trillion</span> femtometres to make one millimetre.)</p>
<p>Instead of localised bullets in empty space, matter delocalises into continuous quantum clouds</p>
<p>Particles with the same electric charge sign repel each other. So additional interactions are required to hold protons close-packed in the nucleus. These interactions arise from quark and antiquark pairs called pions that constantly spill out of each proton and neutron to be absorbed by another such particle nearby. The energy exchanged in this transfer is big enough to compensate for the electric repulsion between protons and, thus, bind together protons and neutrons, storing the immense energy that may be released in nuclear fission processes.</p>
<p>However, the extremely short lifetime of the pions limits how far protons and neutrons may be from each other, curbing the nucleus size to a 1 to <span>10 fm</span> radius. Thus, from a particle perspective, the nucleus is tiny compared with an atom. A nitrogen nucleus, composed of seven protons and seven neutrons, has a radius of about <span>3 fm.</span> In contrast, nitrogen’s atomic <a href="https://doi.org/10.1002/chem.201602949" target="_blank" rel="noreferrer noopener">radius</a> is <span>179,000 fm.</span> At the scale of atoms and molecules, nuclei are no more than heavy, point-like positive charges without any apparent internal structure. So are the electrons: they are just light, point-like negative charges.</p>
<p>If atoms and molecules remained a collection of point-like particles, they <em>would</em> be mostly empty space. But at their size scale, they must be described by quantum theory. And this theory predicts that the wave-like picture predominates until a measurement disturbs it. Instead of localised bullets in empty space, matter delocalises into continuous quantum clouds.</p>
<p><span>M</span>atter is fundamentally quantum. Molecules cannot be assembled under the rules of classical physics. The classical electrical interactions between nuclei and electrons are insufficient to build a stable molecule. Due to the electric attraction of charges of opposite signs, the negatively charged electrons would quickly spiral toward the positively charged nuclei and glue to them. The resulting combined particles with no net charge would fly apart, preventing any molecule from forming.</p>
<p>Two quantum properties avoid this bleak fate.</p>
<p>The first property arises from the Heisenberg <a href="https://aeon.co/essays/our-simple-magic-free-recipe-for-quantum-entanglement" target="_blank" rel="noopener">uncertainty principle</a>, which holds that a quantum particle cannot simultaneously be at a precise position and also have zero speed. This implies that an electron cannot glue to a nucleus because both particles would be in a well-defined place and at rest to each other – defying a central rule of the quantum world.</p>
<p>The second quantum property is the Pauli exclusion principle. The fundamental components of matter are split into two types, bosons and fermions. The gluons inside the proton are examples of bosons. We can have as many of them as we want, sharing the same position simultaneously. On the other hand, fermions – such as electrons, quarks, protons and neutrons – obey a much more restrictive rule named the Pauli exclusion principle: no two identical fermions can simultaneously occupy the same space and have the same spin (a quantum property analogous to a classical rotation of a particle about its axis).</p>
<p>In the quantum world, the wave function represents more than a mere lack of knowledge</p>
<p>With all those effects encoded into the Schrödinger equation, the master equation of quantum theory, it predicts that our point-like nuclei and electrons must, in fact, behave like waves. They delocalise in quantum clouds much bigger than their particle-picture size to satisfy the Heisenberg uncertainty principle, with electrons shaped into different clouds to satisfy the Pauli exclusion principle. The lighter the particles are, the bigger the delocalisation. Thus, a single electron cloud may spread over multiple nuclei, forming a chemical bond and stabilising the molecule.</p>
<p>Take an ammonia molecule, NH<sub>3</sub>, illustrated below. The small blue smudge in the middle is the nitrogen nucleus cloud, while the three green blobs are the proton (hydrogen nuclei) clouds. The 10 electrons of the ammonia molecule delocalise into the fat yellow cloud, tying the party together.</p>
<figure><img alt="" loading="lazy" width="2400" height="2400" decoding="async" data-nimg="1" srcset="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2662%2Finsert-scatterplot-HR.jpg&amp;w=3840&amp;q=90 1x" src="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2662%2Finsert-scatterplot-HR.jpg&amp;w=3840&amp;q=90"><figcaption><p>Figure 1: Electronic and nuclear quantum clouds in an ammonia molecule. The yellow cloud represents the 10 electrons in this molecule. The small blue cloud is the nitrogen nucleus, while the three green clouds indicate each hydrogen nucleus. Electronic points in front of the nuclei were made transparent so as not to hide the nuclear clouds. Technical details are explained in <a href="http://dx.doi.org/10.1039/D3CP00247K" target="_blank" rel="noreferrer noopener">Toldo et al 2023</a>. Courtesy the author</p></figcaption></figure>
<p>A particle-like nitrogen nucleus has a <span>3 fm</span> radius. However, in the ammonia molecule, the nitrogen nucleus grows to a respectable <span>3,000 fm</span> radius due to delocalisation. The delocalisation of the hydrogen nuclei is even more impressive. They grow from a radius of <span>0.9 fm</span> when seen as particles to clouds of about <span>23,000 fm.</span> But the electrons take the cake. Due to their tiny mass, they grow from particles much smaller than a nucleus into a cloud that defines the molecular volume.</p>
<p>Nuclei and electrons, however, are not atomic giants. If the nitrogen nucleus is measured (for instance, by throwing fast electrons against it and observing them bounce back), the nuclear cloud would immediately collapse into the initial <span>3 fm</span> dot. The same is true for each electron.</p>
<p>Indeed, quantum theory prescribes a precise relationship between the wave and particle pictures. The clouds of the wave picture are mathematically described by a wave function, essentially an equation that attributes an intensity to every point in space and how these intensities change with time. The wave function is analogous to mathematical functions describing conventional sound or water waves, but with the peculiarity that it has an <a href="https://aeon.co/essays/how-imaginary-numbers-describe-the-fundamental-shape-of-nature" target="_blank" rel="noopener">imaginary-number component</a>, which is negative when squared.</p>
<p>The square of the wave function modulus (a mathematical operation that always yields positive numbers) gives the probability of finding the particle at each point in space if we attempt to observe it. The denser the cloud, the bigger the odds of observing the particle there. Thus, if we try to measure the point-like nitrogen nucleus, we are sure that it will be somewhere in the region of the delocalised nitrogen nucleus cloud, the blue smudge in the figure.</p>
<p>However, interpreting the quantum cloud as probability does not mean it is just a measure of a lack of knowledge about the system. If I left my keys in one of my jacket’s two pockets, but I am unsure which one, I may write a probability function with a <span>50 per</span> cent value at each pocket and zero value at every other point of my office. This function obviously does not imply that my keys are delocalised over the two pockets. It just states my ignorance, which can be easily fixed by checking the jacket.</p>
<p>In the quantum world, the wave function represents more than a mere lack of knowledge. Delocalised systems – like nuclear and electronic clouds – cause phenomena that localised particles cannot explain. The existence of chemical bonds forming molecules is a direct example of the effect of electronic delocalisation. In the case of nuclear delocalisation, one of its main effects is to boost the chances of a hydrogen nucleus (a single proton) flowing from one molecule to another nearby. This kind of enhanced proton transfer has dramatic biological consequences, like <a href="https://doi.org/10.1073/pnas.1417923111" target="_blank" rel="noreferrer noopener">increasing</a> the acidity of specific enzymes compared with how acidic they would be if hydrogen nuclei behaved as particles.</p>
<p><span>A</span>lthough electron clouds are commonly depicted in popular science and chemistry, delocalisation of the nucleus is often interpreted as vibrations and rotations. But these are only classical, albeit helpful, analogies. From a quantum perspective and for conceptual consistency, nuclei should be depicted on the same footing as electrons, as clouds as well.</p>
<p>Yet another misconception is that atoms are empty because their mass is in their nucleus. The atomic mass is indeed highly localised. In an ammonia molecule, <span>82 per</span> cent of the mass is in the blue smudge of the nitrogen nucleus shown in <span>Figure 1</span> above. If we add the masses of the three green proton clouds, they account for <span>99.97 per</span> cent of the total. Thus, the big yellow cloud of the electrons carries only <span>0.03 per</span> cent of the mass.</p>
<p>The association between this mass concentration and the idea that atoms are empty stems from a flawed view that mass is the property of matter that fills a space. However, this concept does not hold up to close inspection, not even in our human-scale world. When we pile objects on top of each other, what keeps them separated is not their masses but the electric repulsion between the outmost electrons at their touching molecules. (The electrons cannot collapse under pressure due to the Heisenberg uncertainty and Pauli exclusion principles.) Therefore, the electron’s electric charge ultimately fills the space.</p>
<p>Anyone taking Chemistry 101 is likely to be faced with diagrams of electrons orbiting in shells</p>
<p>In atoms and molecules, electrons are everywhere! Look how the yellow cloud permeates the entire molecular volume in <span>Figure 1.</span> Thus, when we see that atoms and molecules are packed with electrons, the only reasonable conclusion is that they are filled with matter, not the opposite.</p>
<p>Despite all this, anyone taking Chemistry 101 is likely to be faced with diagrams of electrons orbiting in shells, like concentric and separated layers with empty space between them. The idea that these diagrams represent physical reality is a third common misconception. Electrons do not literally orbit around the atomic nucleus in the shape of these shells.</p>
<p>In atoms and molecules, electrons must have specific energies, each energy associated with a particular cloud shape. Consider, for example, an atom with a single electron. In the lowest possible energy, the ground energy level, this electron delocalises into a spherical cloud, dense at the centre of the atom and gradually fading out. The single-electron wave functions describing these clouds are called orbitals.</p>
<p>At higher energy levels, the single electron delocalises into more complex clouds with nested spheres, multiple blobs or even doughnut shapes. Thus, when speaking of atoms and molecules, electrons are not little particles chaotically rocketing around the nuclei until they become a fuzzy cloud, as often depicted. And electrons are not <em>in</em> the orbitals, nor do they <em>populate</em> them. Electrons <em>are</em> the orbitals. They are delocalised clouds.</p>
<p><span>W</span>ith multiple electrons, which have been terra incognita in popular science, things get much more complicated. This is hardly a surprise since even professional theoretical chemists are uncomfortable describing them, despite their exceptional competence in predicting the properties of multi-electron systems.</p>
<p>Like ill-fitting clothes, chemistry vernacular is filled with awkward analogies and descriptions. Chemists may say that an electron <em>occupies</em> or <em>populates</em> an orbital as if orbitals were pre-existing places where electrons are put. Chemists often draw diagrams where orbitals are represented as short horizontal lines and electrons as small vertical arrows on those lines, like objects on shelves. All these verbal and visual metaphors fail to translate what quantum theory tells us about atoms and molecules.</p>
<p>When dealing with multi-electron systems (encompassing virtually all molecules), quantum theory no longer distinguishes between each electron; they are all described by a single wave function, a single cloud. Nevertheless, single electron orbitals are still a valid approximation that chemists constantly use to rationalise chemical reactions. The multi-electron wave function resembles a composition of these individual clouds overlapping within the volume defining the molecule. They feel each other; they recombine into new shapes; some bulge and others shrink; the clouds skew, stretch and twist until they comfortably adapt, occupying every available space. It may look like a messy sock drawer.</p>
<p>For a fraction of a picosecond, the tempest rages and reshapes the molecular landscape until stillness is restored</p>
<p>A molecule is a static object without any internal motion. The quantum clouds of all nuclei and electrons remain absolutely still for a molecule with a well-defined energy. Time is irrelevant. Quantum theory does not predict vibrating nuclei or orbiting and spinning electrons; those dynamic features are classical analogues to intrinsic quantum properties. Angular momentum, for instance, which in classical physics quantifies rotational speed, manifests as blobs in the wave function. The more numerous the blobs, the bigger the angular momentum, even though nothing rotates.</p>
<p>Time, however, comes into play when a molecule collides with another one, triggering a chemical reaction. Then, a storm strikes. The quantum steadiness bursts when the sections of the electronic cloud pour from one molecule upon another. The clouds mix, reshape, merge, and split. The nuclear clouds rearrange to accommodate themselves within the new electronic configuration, sometimes even migrating between molecules. For a fraction of a picosecond <span>(10</span><span><sup>-12</sup></span><span> seconds</span> or a billionth of a millisecond), the tempest rages and reshapes the molecular landscape until stillness is restored in the newly formed compounds.</p>
<p>In the Flammarion engraving <span>(Figure 2</span> below), a person at the edge of Earth dares to look beyond the firmament dome to uncover the marvellous machinery of clouds controlling the heavens. They could well be looking at a molecule instead. Then, this non-disturbing observer would find that nuclei and electrons are majestic, stable, structured, closed-packed clouds, driving every aspect of matter as we <span>know it.</span></p>
<figure><img alt="" loading="lazy" width="2400" height="2400" decoding="async" data-nimg="1" srcset="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2661%2Finsert-The_Flammarion_Engraving_(ca._1888).jpg&amp;w=3840&amp;q=90 1x" src="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2661%2Finsert-The_Flammarion_Engraving_(ca._1888).jpg&amp;w=3840&amp;q=90"><figcaption><p>Figure 2: Wood engraving from <em>L’atmosphère: météorologie populaire</em> (1888) by Camille Flammarion. Courtesy Wikipedia</p></figcaption></figure>
<p><span>M</span>y criticism of the <em>empty atom</em> picture isn’t meant to shame people’s previous attempts to describe atoms and molecules to the public. On the contrary, I applaud their effort in this challenging enterprise. Our common language, intuitions and even basic reasoning processes are not adapted to face quantum theory, this alien world of strangeness surrounded by quirky landscapes we mostly cannot make <span>sense of.</span></p>
<p>And there is so much we do not understand. We have yet to learn how to reconcile the dual wave-like and particle-like behaviour of matter. We do not even know whether wave functions have objective reality. Our brains melt, facing the multiple potential interpretations of quantum theory to the point that outstanding scientists seemingly <a href="https://aeon.co/essays/materialism-alone-cannot-explain-the-riddle-of-consciousness" target="_blank" rel="noopener">gave up hope</a> that we may reach a scientific consensus. We turn a blind eye to the dirty tricks we carry from the conceptual construction of quantum theory to the actual predictions.</p>
<p>The account of the quantum molecular world I presented is on comfortably safe grounds</p>
<p>We could conform to the unsatisfying ‘Shut up and calculate!’ attitude that has accompanied the increasingly weird predictions of quantum theory, which enabled the outstanding technological advancements of the past <span>100 years,</span> from lasers to microprocessors. However, we do not want to make only useful predictions. Our ultimate goal is to tell stories about our Universe. Thus, we calculate but <a href="https://aeon.co/essays/shut-up-and-calculate-does-a-disservice-to-quantum-mechanics" target="_blank" rel="noopener">do not shut up</a>. Generations of scientists and science popularisers do their best to translate all this strangeness into friendly metaphors of a theoretical body still full of mystery. We build new mental images of the quantum world one step at a time, even under the risk of tripping up here and there.</p>
<p>The account of the quantum molecular world I presented is on comfortably safe grounds. It is based on a quantum theory domain that is highly consensual among specialists. It is the town square of what the Nobel laureate <a href="https://aeon.co/ideas/perspective-is-a-lesson-in-how-science-collaborates-with-art" target="_blank" rel="noopener">Frank Wilczek</a> called the Core Theory, the physics framework describing fundamental particles, their interactions and Albert Einstein’s general relativity. Physicists are so confident about this core’s stability that they believe it should persist within any new theories of matter developed in the future.</p>
<p>Breathing this confidence and realising we are not made of empty space may be a soothing thought.</p>
<p><em>This Essay was made possible through the support of a grant to Aeon+Psyche from the John Templeton Foundation. The opinions expressed in this publication are those of the author and do not necessarily reflect the views of the Foundation. Funders to Aeon+Psyche are not involved in editorial decision-making.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Training immune cells to remove ‘trash’ helps resolve lung inflammation (105 pts)]]></title>
            <link>https://today.uic.edu/immune-cells-acute-lung-injury/</link>
            <guid>37268738</guid>
            <pubDate>Sat, 26 Aug 2023 00:33:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.uic.edu/immune-cells-acute-lung-injury/">https://today.uic.edu/immune-cells-acute-lung-injury/</a>, See on <a href="https://news.ycombinator.com/item?id=37268738">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Inflammation is a standard part of our bodies’ immune system response. But sometimes this response becomes hyperactivated in our lungs, causing inflammation to continue unchecked, which can be fatal. Many deaths from COVID-19 have been due to excessive inflammation, which results in acute lung injury.</p>



<p>A group of researchers at the University of Illinois Chicago have investigated how lungs counterbalance inflammation. Their work points to cells in the lung that reduce inflammation by removing cellular debris, ingesting harmful bacteria and releasing anti-inflammatory proteins. What’s more, these cells can be trained by an initial infection to do this job even better during a subsequent infection.</p>



<figure><a href="https://today.uic.edu/macrophage-red-fluorescent-staining-that-has-ingested-bacteria/"><img decoding="async" width="387" height="258" src="https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-387x258.jpg" alt="Macrophage (red fluorescent staining) that has ingested bacteria (green fluorescence)." srcset="https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-387x258.jpg 387w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-590x393.jpg 590w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-768x512.jpg 768w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-1536x1024.jpg 1536w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-1000x667.jpg 1000w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-500x333.jpg 500w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-300x200.jpg 300w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4-1320x880.jpg 1320w, https://today.uic.edu/wp-content/uploads/2023/08/Mac-phalloidin-Ecoli-GFP-2_6x4.jpg 1800w" sizes="(max-width: 387px) 100vw, 387px"></a><figcaption>Macrophage (red fluorescent staining) that has ingested bacteria (green fluorescence). 
Image credit: Rehman laboratory.</figcaption></figure>



<p>The scientists demonstrated that injecting these trained cells into mice helped keep them alive after an infection with pneumonia. These results suggest that such trained cells could become part of a cell therapy that prevents excessive inflammation. The research <a href="https://doi.org/10.1084/jem.20221388">is published in the Journal of Experimental Medicine</a>.</p>



<p>The researchers found that after an initial exposure to a bacterial toxin, lung immune cells called alveolar macrophages helped reduce the severity of inflammation brought on by a second exposure to the bacterial toxin one week later. The benefit of this “memory” or “training” was present even when the second exposure occurred a month later, explained senior author <a href="https://bcmg.com.uic.edu/faculty/rehman_jalees.html">Dr. Jalees Rehman</a>, Benjamin Goldberg Professor and head of the UIC Department of Biochemistry and Molecular Genetics.</p>



<p>The cells appear to become particularly good at removing post-infection debris — such as cellular debris from immune cells that fought the infection or from one’s damaged tissue — Rehman explained. “Clearing out this debris is important because its persistence can trigger the immune system to continue to react, thus increasing inflammation,” Rehman said. Because this debris isn’t specific to one type of infection, these trained macrophages might help reduce the risk of acute lung injury from subsequent infections that arise from a different disease. The researchers found that the molecules involved in the removal of cell debris were higher in the trained alveolar macrophages.</p>



<p>Alveolar macrophages are unusual cells in that we are born with them and they stay in our lungs into adulthood. During infections, alveolar macrophages die but they can regenerate from surviving alveolar macrophages. They also pass along epigenetic information to their cellular progeny, which means new macrophages could retain a memory of previous infections, Rehman explained. All of this combines to make them very effective in helping to reduce acute lung injury.</p>



<p>Many other organs have macrophages, so future research could explore whether those cells could be trained by an initial infection as well or by directly increasing the levels of the molecules that help with debris removal, said Rehman, who is also a member of the University of Illinois Cancer Center.</p>



<p>The other authors on the study are Sreeparna Chakraborty, Abhalaxmi Singh, Li Wang, Xinge Wang, Mark A. Sanborn, Zijing Ye, Mark Maienschein-Cline, Amitabha Mukhopadhyay, Balaji Ganesh, and Asrar B. Malik, all from UIC’s College of Medicine.</p>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/print-button-gray.png" alt="Print Friendly, PDF &amp; Email"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sidewalk Garden (206 pts)]]></title>
            <link>https://zachklein.com/Sidewalk+Garden</link>
            <guid>37268616</guid>
            <pubDate>Sat, 26 Aug 2023 00:14:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zachklein.com/Sidewalk+Garden">https://zachklein.com/Sidewalk+Garden</a>, See on <a href="https://news.ycombinator.com/item?id=37268616">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Neural Nets: 33 years ago and 33 years from now (2022) (254 pts)]]></title>
            <link>http://karpathy.github.io/2022/03/14/lecun1989/</link>
            <guid>37268610</guid>
            <pubDate>Sat, 26 Aug 2023 00:13:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://karpathy.github.io/2022/03/14/lecun1989/">http://karpathy.github.io/2022/03/14/lecun1989/</a>, See on <a href="https://news.ycombinator.com/item?id=37268610">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  

<p>The Yann LeCun et al. (1989) paper <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">Backpropagation Applied to Handwritten Zip Code Recognition</a> is I believe of some historical significance because it is, to my knowledge, the earliest real-world application of a neural net trained end-to-end with backpropagation. Except for the tiny dataset (7291 16x16 grayscale images of digits) and the tiny neural network used (only 1,000 neurons), this paper reads remarkably modern today, 33 years later - it lays out a dataset, describes the neural net architecture, loss function, optimization, and reports the experimental classification error rates over training and test sets. It’s all very recognizable and type checks as a modern deep learning paper, except it is from 33 years ago. So I set out to reproduce the paper 1) for fun, but 2) to use the exercise as a case study on the nature of progress in deep learning.</p>

<p><img src="http://karpathy.github.io/assets/lecun/lecun1989.png" width="100%"></p>

<p><strong>Implementation</strong>. I tried to follow the paper as close as possible and re-implemented everything in PyTorch in this <a href="https://github.com/karpathy/lecun1989-repro">karpathy/lecun1989-repro</a> github repo. The original network was implemented in Lisp using the Bottou and LeCun 1988 <a href="https://leon.bottou.org/papers/bottou-lecun-88">backpropagation simulator SN</a> (later named Lush). The paper is in french so I can’t super read it, but from the syntax it looks like you can specify neural nets using higher-level API similar to what you’d do in something like PyTorch today. As a quick note on software design, modern libraries have adopted a design that splits into 3 components: 1) a fast (C/CUDA) general Tensor library that implements basic mathematical operations over multi-dimensional tensors, and 2) an autograd engine that tracks the forward compute graph and can generate operations for the backward pass, and 3) a scriptable (Python) deep-learning-aware, high-level API of common deep learning operations, layers, architectures, optimizers, loss functions, etc.</p>

<p><strong>Training</strong>. During the course of training we have to make 23 passes over the training set of 7291 examples, for a total of 167,693 presentations of (example, label) to the neural network. The original network trained for 3 days on a <a href="https://en.wikipedia.org/wiki/Sun-4">SUN-4/260</a> workstation. I ran my implementation on my MacBook Air (M1) CPU, which crunched through it in about 90 seconds (~<strong>3000X naive speedup</strong>). My conda is setup to use the native arm64 builds, rather than Rosetta emulation. The speedup may have been more dramatic if PyTorch had support for the full capability of the M1 (including the GPU and the NPU), but this seems to still be in development. I also tried naively running the code on an A100 GPU, but the training was actually <em>slower</em>, most likely because the network is so tiny (4 layer convnet with up to 12 channels, total of 9760 params, 64K MACs, 1K activations), and the SGD uses only a single example at a time. That said, if one really wanted to crush this problem with modern hardware (A100) and software infrastructure (CUDA, PyTorch), we’d need to trade per-example SGD for full-batch training to maximize GPU utilization and most likely achieve another ~100X speedup of training latency.</p>

<p><strong>Reproducing 1989 performance</strong>. The original paper reports the following results:</p>

<div><pre><code>eval: split train. loss 2.5e-3. error 0.14%. misses: 10
eval: split test . loss 1.8e-2. error 5.00%. misses: 102
</code></pre></div>

<p>While my training script repro.py in its current form prints at the end of the 23rd pass:</p>

<div><pre><code>eval: split train. loss 4.073383e-03. error 0.62%. misses: 45
eval: split test . loss 2.838382e-02. error 4.09%. misses: 82
</code></pre></div>

<p>So I am reproducing the numbers <em>roughly</em>, but not exactly. Sadly, an exact reproduction is most likely not possible because the original dataset has, I believe, been lost to time. Instead, I had to simulate it using the larger MNIST dataset (hah never thought I’d say that) by taking its 28x28 digits, scaling them down to 16x16 pixels with bilinear interpolation, and randomly without replacement drawing the correct number of training and test set examples from it. But I am sure there are other culprits at play. For example, the paper is a bit too abstract in its description of the weight initialization scheme, and I suspect that there are some formatting errors in the pdf file that, for example, erase dots “.”, making “2.5” look like like “2 5”, and potentially (I think?) erasing square roots. E.g. we’re told that the weight init is drawn from uniform “2 4 / F” where F is the fan-in, but I am guessing this surely (?) means “2.4 / sqrt(F)”, where the sqrt helps preserve the standard deviation of outputs. The specific sparse connectivity structure between the H1 and H2 layers of the net are also brushed over, the paper just says it is “chosen according to a scheme that will not be discussed here”, so I had to make some some sensible guesses here with an overlapping block sparse structure. The paper also claims to use tanh non-linearity, but I am worried this may have actually been the “normalized tanh” that maps ntanh(1) = 1, and potentially with an added scaled-down skip connection, which was trendy at the time to ensure there is at least a bit of gradient in the flat tails of the tanh. Lastly, the paper uses a “special version of Newton’s algorithm that uses a positive, diagonal approximation of Hessian”, but I only used SGD because it is significantly simpler and, according to the paper, “this algorithm is not believed to bring a tremendous increase in learning speed”.</p>

<p><strong>Cheating with time travel</strong>. Around this point came my favorite part. We are living here 33 years in the future and deep learning is a highly active area of research. How much can we improve on the original result using our modern understanding and 33 years of R&amp;D? My original result was:</p>

<div><pre><code>eval: split train. loss 4.073383e-03. error 0.62%. misses: 45
eval: split test . loss 2.838382e-02. error 4.09%. misses: 82
</code></pre></div>

<p>The first thing I was a bit sketched out about is that we are doing simple classification into 10 categories, but at the time this was modeled as a <a href="https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html">mean squared error</a> (MSE) regression into targets -1 (for negative class) or +1 (for positive class), with output neurons that also had the tanh non-linearity. So I deleted the tanh on output layers to get class logits and swapped in the standard (multiclass) <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">cross entropy loss</a> function. This change dramatically improved the training error, completely overfitting the training set:</p>

<div><pre><code>eval: split train. loss 9.536698e-06. error 0.00%. misses: 0
eval: split test . loss 9.536698e-06. error 4.38%. misses: 87
</code></pre></div>

<p>I suspect one has to be much more careful with weight initialization details if your output layer has the (saturating) tanh non-linearity and an MSE error on top of it. Next, in my experience a very finely-tuned SGD can work very well, but the modern <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">Adam optimizer</a> (learning rate of 3e-4, of course :)) is almost always a strong baseline and needs little to no tuning. So to improve my confidence that optimization was not holding back performance, I switched to AdamW with LR 3e-4, and decay it down to 1e-4 over the course of training, giving:</p>

<div><pre><code>eval: split train. loss 0.000000e+00. error 0.00%. misses: 0
eval: split test . loss 0.000000e+00. error 3.59%. misses: 72
</code></pre></div>

<p>This gave a slightly improved result on top of SGD, except we also have to remember that a little bit of weight decay came in for the ride as well via the default parameters, which helps fight the overfitting situation. As we are still heavily overfitting, next I introduced a simple data augmentation strategy where I shift the input images by up to 1 pixel horizontally or vertically. However, because this simulates an increase in the size of the dataset, I also had to increase the number of passes from 23 to 60 (I verified that just naively increasing passes in original setting did not substantially improve results):</p>

<div><pre><code>eval: split train. loss 8.780676e-04. error 1.70%. misses: 123
eval: split test . loss 8.780676e-04. error 2.19%. misses: 43
</code></pre></div>

<p>As can be seen in the test error, that helped quite a bit! Data augmentation is a fairly simple and very standard concept used to fight overfitting, but I didn’t see it mentioned in the 1989 paper, perhaps it was a more recent innovation (?). Since we are still overfitting a bit, I reached for another modern tool in the toolbox, <a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html">Dropout</a>. I added a weak dropout of 0.25 just before the layer with the largest number of parameters (H3). Because dropout sets activations to zero, it doesn’t make as much sense to use it with tanh that has an active range of [-1,1], so I swapped all non-linearities to the much simpler <a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html">ReLU</a> activation function as well. Because dropout introduces even more noise during training, we also have to train longer, bumping up to 80 passes, but giving:</p>

<div><pre><code>eval: split train. loss 2.601336e-03. error 1.47%. misses: 106
eval: split test . loss 2.601336e-03. error 1.59%. misses: 32
</code></pre></div>

<p>Which brings us down to only 32 / 2007 mistakes on the test set! I verified that just swapping tanh -&gt; relu in the original network did not give substantial gains, so most of the improvement here is coming from the addition of dropout. In summary, if I time traveled to 1989 I’d be able to cut the rate of errors by about 60%, taking us from ~80 to ~30 mistakes, and an overall error rate of ~1.5% on the test set. This gain did not come completely free because we also almost 4X’d the training time, which would have increased the 1989 training time from 3 days to almost 12. But the inference latency would not have been impacted. The remaining errors are here:</p>

<p><img src="http://karpathy.github.io/assets/lecun/errors32.png" width="100%"></p>

<p><strong>Going further</strong>. However, after swapping MSE -&gt; Softmax, SGD -&gt; AdamW, adding data augmentation, dropout, and swapping tanh -&gt; relu I’ve started to taper out on the low hanging fruit of ideas. I tried a few more things (e.g. weight normalization), but did not get substantially better results. I also tried to miniaturize a <a href="https://arxiv.org/abs/2010.11929">Visual Transformer (ViT)</a>) into a “micro-ViT” that roughly matches the number of parameters and flops, but couldn’t match the performance of a convnet. Of course, many other innovations have been made in the last 33 years, but many of them (e.g. residual connections, layer/batch normalizations) only become relevant in much larger models, and mostly help stabilize large-scale optimization. Further gains at this point would likely have to come from scaling up the size of the network, but this would bloat the test-time inference latency.</p>

<p><strong>Cheating with data</strong>. Another approach to improving the performance would have been to scale up the dataset, though this would come at a dollar cost of labeling. Our original reproduction baseline, again for reference, was:</p>

<div><pre><code>eval: split train. loss 4.073383e-03. error 0.62%. misses: 45
eval: split test . loss 2.838382e-02. error 4.09%. misses: 82
</code></pre></div>

<p>Using the fact that we have all of MNIST available to us, we can simply try scaling up the training set by ~7X (7,291 to 50,000 examples). Leaving the baseline training running for 100 passes already shows some improvement from the added data alone:</p>

<div><pre><code>eval: split train. loss 1.305315e-02. error 2.03%. misses: 60
eval: split test . loss 1.943992e-02. error 2.74%. misses: 54
</code></pre></div>

<p>But further combining this with the innovations of modern knowledge (described in the previous section) gives the best performance yet:</p>

<div><pre><code>eval: split train. loss 3.238392e-04. error 1.07%. misses: 31
eval: split test . loss 3.238392e-04. error 1.25%. misses: 24
</code></pre></div>

<p>In summary, simply scaling up the dataset in 1989 would have been an effective way to drive up the performance of the system, at no cost to inference latency.</p>

<p><strong>Reflections</strong>. Let’s summarize what we’ve learned as a 2022 time traveler examining state of the art 1989 deep learning tech:</p>

<ul>
  <li>First of all, not much has changed in 33 years on the macro level. We’re still setting up differentiable neural net architectures made of layers of neurons and optimizing them end-to-end with backpropagation and stochastic gradient descent. Everything reads remarkably familiar, except it is smaller.</li>
  <li>The dataset is a baby by today’s standards: The training set is just 7291 16x16 greyscale images. Today’s vision datasets typically contain a few hundred million high-resolution color images from the web (e.g. Google has JFT-300M, <a href="https://openai.com/blog/clip/">OpenAI CLIP</a> was trained on a 400M), but grow to as large as a small few billion. This is approx. ~1000X pixel information per image (384*384*3/(16*16)) times 100,000X the number of images (1e9/1e4), for a rough 100,000,000X more pixel data at the input.</li>
  <li>The neural net is also a baby: This 1989 net has approx. 9760 params, 64K MACs, and 1K activations. <a href="https://arxiv.org/abs/2106.04560">Modern (vision) neural nets</a> are on the scale of small few billion parameters (1,000,000X) and O(~1e12) MACs (~10,000,000X). Natural language models can reach into trillions of parameters.</li>
  <li>A state of the art classifier that took 3 days to train on a workstation now trains in 90 seconds on my fanless laptop (3,000X naive speedup), and further ~100X gains are very likely possible by switching to full-batch optimization and utilizing a GPU.</li>
  <li>I was, in fact, able to tune the model, augmentation, loss function, and the optimization based on modern R&amp;D innovations to cut down the error rate by 60%, while keeping the dataset and the test-time latency of the model unchanged.</li>
  <li>Modest gains were attainable just by scaling up the dataset alone.</li>
  <li>Further significant gains would likely have to come from a larger model, which would require more compute, and additional R&amp;D to help stabilize the training at increasing scales. In particular, if I was transported to 1989, I would have ultimately become upper-bounded in my ability to further improve the system without a bigger computer.</li>
</ul>

<p>Suppose that the lessons of this exercise remain invariant in time. What does that imply about deep learning of 2022? What would a time traveler from 2055 think about the performance of current networks?</p>

<ul>
  <li>2055 neural nets are basically the same as 2022 neural nets on the macro level, except bigger.</li>
  <li>Our datasets and models today look like a joke. Both are somewhere around 10,000,000X larger.</li>
  <li>One can train 2022 state of the art models in ~1 minute by training naively on their personal computing device as a weekend fun project.</li>
  <li>Today’s models are not optimally formulated, and just changing some of the details of the model, loss function, augmentation or the optimizer we can about halve the error.</li>
  <li>Our datasets are too small, and modest gains would come from scaling up the dataset alone.</li>
  <li>Further gains are actually not possible without expanding the computing infrastructure and investing into some R&amp;D on effectively training models on that scale.</li>
</ul>

<p>But the most important trend I want to comment on is that the whole setting of training a neural network from scratch on some target task (like digit recognition) is quickly becoming outdated due to finetuning, especially with the emergence of <a href="https://arxiv.org/abs/2108.07258">foundation models</a> like GPT. These foundation models are trained by only a few institutions with substantial computing resources, and most applications are achieved via lightweight finetuning of part of the network, prompt engineering, or an optional step of data or model distillation into smaller, special-purpose inference networks. I think we should expect this trend to be very much alive, and indeed, intensify. In its most extreme extrapolation, you will not want to train any neural networks at all. In 2055, you will ask a 10,000,000X-sized neural net megabrain to perform some task by speaking (or thinking) to it in English. And if you ask nicely enough, it will oblige. Yes you could train a neural net too… but why would you?</p>



  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Support ActivityPub for merge requests (102 pts)]]></title>
            <link>https://gitlab.com/groups/gitlab-org/-/epics/11247</link>
            <guid>37268068</guid>
            <pubDate>Fri, 25 Aug 2023 22:57:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlab.com/groups/gitlab-org/-/epics/11247">https://gitlab.com/groups/gitlab-org/-/epics/11247</a>, See on <a href="https://news.ycombinator.com/item?id=37268068">Hacker News</a></p>
<div id="readability-page-1" class="page">





<header data-testid="navbar">
<a href="#content-body">Skip to content</a>
<div>
<div>
<div>
<span>GitLab</span>
<a title="Homepage" id="logo" data-track-label="main_navigation" data-track-action="click_gitlab_logo_link" data-track-property="navigation_top" href="https://gitlab.com/"><svg role="img" width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="m24.507 9.5-.034-.09L21.082.562a.896.896 0 0 0-1.694.091l-2.29 7.01H7.825L5.535.653a.898.898 0 0 0-1.694-.09L.451 9.411.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 2.56 1.935 1.554 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#E24329"></path>
  <path d="m24.507 9.5-.034-.09a11.44 11.44 0 0 0-4.56 2.051l-7.447 5.632 4.742 3.584 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#FC6D26"></path>
  <path d="m7.707 20.677 2.56 1.935 1.555 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935-4.743-3.584-4.755 3.584Z" fill="#FCA326"></path>
  <path d="M5.01 11.461a11.43 11.43 0 0 0-4.56-2.05L.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 4.745-3.584-7.444-5.632Z" fill="#FC6D26"></path>
</svg>

</a><div>
<a data-testid="canary_badge_link" href="https://next.gitlab.com/" rel="noopener noreferrer" target="_blank">Next
</a></div>
</div>

<ul>
<li>

<div>
<ul>
<li>
<a href="https://about.gitlab.com/stages-devops-lifecycle">GitLab: the DevOps platform
</a></li>
<li>
<a href="https://gitlab.com/explore">Explore GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/install">Install GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/is-it-any-good">How GitLab compares
</a></li>
<li>
<a href="https://about.gitlab.com/get-started">Get started
</a></li>
<li>
<a href="https://docs.gitlab.com/">GitLab docs
</a></li>
<li>
<a href="https://about.gitlab.com/learn">GitLab Learn
</a></li>
</ul>
</div>
</li>
<li>
<a href="https://about.gitlab.com/pricing">Pricing
</a></li>
<li>
<a href="https://about.gitlab.com/sales">Talk to an expert
</a></li>
</ul>

</div>
<div>
<ul>
<li>
<div data-autocomplete-path="/search/autocomplete" data-issues-path="/dashboard/issues" data-mr-path="/dashboard/merge_requests" data-search-context="{&quot;group&quot;:{&quot;id&quot;:9970,&quot;name&quot;:&quot;GitLab.org&quot;,&quot;full_name&quot;:&quot;GitLab.org&quot;},&quot;group_metadata&quot;:{&quot;issues_path&quot;:&quot;/groups/gitlab-org/-/issues&quot;,&quot;mr_path&quot;:&quot;/groups/gitlab-org/-/merge_requests&quot;},&quot;scope&quot;:&quot;epics&quot;,&quot;for_snippets&quot;:null}" data-search-path="/search" id="js-header-search">
<form action="/search" accept-charset="UTF-8" method="get"><div>
<svg data-testid="search-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#search"></use></svg>

</div>







<kbd data-html="true" data-placement="bottom" title="Use the shortcut key <kbd>/</kbd> to start a search">
/
</kbd>
</form></div>

</li>
<li>
<a title="Search" aria-label="Search" data-toggle="tooltip" data-placement="bottom" data-container="body" data-track-action="click_link" data-track-label="global_search" data-track-property="navigation_top" href="https://gitlab.com/search?group_id=9970"><svg data-testid="search-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#search"></use></svg>
</a></li>
</ul>
</div>
<div>
<ul>
<li>
<a data-toggle="dropdown" data-track-action="click_question_mark_link" data-track-label="main_navigation" data-track-property="navigation_top" href="https://gitlab.com/help"><span>
Help
</span>
<svg data-testid="question-o-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#question-o"></use></svg>
<span></span>
<svg data-testid="chevron-down-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#chevron-down"></use></svg>
</a><div>
<ul>
<li>

</li>
<li>

</li>

<li>
<a data-track-action="click_link" data-track-label="help" data-track-property="navigation_top" href="https://gitlab.com/help">Help</a>
</li>
<li>
<a data-track-action="click_link" data-track-label="support" data-track-property="navigation_top" href="https://about.gitlab.com/get-help/">Support</a>
</li>
<li>
<a target="_blank" rel="noopener noreferrer" data-track-action="click_link" data-track-label="community_forum" data-track-property="navigation_top" href="https://forum.gitlab.com/">Community forum</a>

</li>
<li>

</li>
<li></li>
<li>
<a data-track-action="click_link" data-track-label="submit_feedback" data-track-property="navigation_top" href="https://about.gitlab.com/submit-feedback">Submit feedback</a>
</li>
<li>
<a target="_blank" data-track-action="click_link" data-track-label="contribute_to_gitlab" data-track-property="navigation_top" href="https://about.gitlab.com/contributing">Contribute to GitLab
</a>

</li>

</ul>

</div>
</li>
<li>
<ul data-view-model="{&quot;primary&quot;:[{&quot;type&quot;:&quot;header&quot;,&quot;title&quot;:&quot;Explore&quot;},{&quot;id&quot;:&quot;project&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Projects&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;project&quot;,&quot;href&quot;:&quot;/explore&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:null,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Projects&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;groups&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Groups&quot;,&quot;active&quot;:true,&quot;icon&quot;:&quot;group&quot;,&quot;href&quot;:&quot;/explore/groups&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:null,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Groups&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;topics&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Topics&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;labels&quot;,&quot;href&quot;:&quot;/explore/projects/topics&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:null,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Topics&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;snippets&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Snippets&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;snippet&quot;,&quot;href&quot;:&quot;/explore/snippets&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:null,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Snippets&quot;},&quot;partial&quot;:null,&quot;component&quot;:null}],&quot;secondary&quot;:[],&quot;views&quot;:{},&quot;shortcuts&quot;:[{&quot;id&quot;:&quot;project-shortcut&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Projects&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;&quot;,&quot;href&quot;:&quot;/explore&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:&quot;dashboard-shortcuts-projects&quot;,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Projects&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;groups-shortcut&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Groups&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;&quot;,&quot;href&quot;:&quot;/explore/groups&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:&quot;dashboard-shortcuts-groups&quot;,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Groups&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;topics-shortcut&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Topics&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;&quot;,&quot;href&quot;:&quot;/explore/projects/topics&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:&quot;dashboard-shortcuts-topics&quot;,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Topics&quot;},&quot;partial&quot;:null,&quot;component&quot;:null},{&quot;id&quot;:&quot;snippets-shortcut&quot;,&quot;type&quot;:&quot;item&quot;,&quot;title&quot;:&quot;Snippets&quot;,&quot;active&quot;:false,&quot;icon&quot;:&quot;&quot;,&quot;href&quot;:&quot;/explore/snippets&quot;,&quot;view&quot;:&quot;&quot;,&quot;css_class&quot;:&quot;dashboard-shortcuts-snippets&quot;,&quot;data&quot;:{&quot;testid&quot;:&quot;menu_item_link&quot;,&quot;qa_title&quot;:&quot;Snippets&quot;},&quot;partial&quot;:null,&quot;component&quot;:null}],&quot;menuTooltip&quot;:&quot;Main menu&quot;}" id="js-top-nav">
<li>
<a data-toggle="dropdown" href="#" type="button">
<svg data-testid="hamburger-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#hamburger"></use></svg>
</a>
</li>
</ul>
<div>
<a href="https://gitlab.com/explore">Projects
</a><a href="https://gitlab.com/explore/groups">Groups
</a><a href="https://gitlab.com/explore/projects/topics">Topics
</a><a href="https://gitlab.com/explore/snippets">Snippets
</a></div>

</li>
<li>
<a href="https://gitlab.com/users/sign_up"><span>
Register

</span>

</a></li>
<li>
<a href="https://gitlab.com/users/sign_in?redirect_to_referer=yes">Sign in</a>
</li>
</ul>
</div>

</div>
</header>


<div>


<div data-testid="top-bar">

<nav aria-label="Breadcrumbs" data-qa-selector="breadcrumb_links_content" data-testid="breadcrumb-links">
<ul>
<li><a href="https://gitlab.com/gitlab-org"><img alt="GitLab.org" width="15" height="15" data-src="/uploads/-/system/group/avatar/9970/project_avatar.png" src="https://gitlab.com/uploads/-/system/group/avatar/9970/project_avatar.png">GitLab.org</a><svg data-testid="chevron-lg-right-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#chevron-lg-right"></use></svg></li>
<li><a href="https://gitlab.com/groups/gitlab-org/-/epics">Epics</a><svg data-testid="chevron-lg-right-icon"><use href="/assets/icons-b25b55b72e1a86a9ca8055a5c421aae9b89fc86363fa02e2109034d756e56d28.svg#chevron-lg-right"></use></svg></li>

<li data-qa-selector="breadcrumb_current_link" data-testid="breadcrumb-current-link">
<a href="https://gitlab.com/groups/gitlab-org/-/epics/11247">&amp;11247</a>
</li>
</ul>

</nav>



</div>
<div>
<main id="content-body">





<div>





</div>

</main>
</div>


</div>










</div>]]></description>
        </item>
        <item>
            <title><![CDATA[CVE-2020-19909 is everything that is wrong with CVEs (200 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2023/08/26/cve-2020-19909-is-everything-that-is-wrong-with-cves/</link>
            <guid>37267940</guid>
            <pubDate>Fri, 25 Aug 2023 22:43:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2023/08/26/cve-2020-19909-is-everything-that-is-wrong-with-cves/">https://daniel.haxx.se/blog/2023/08/26/cve-2020-19909-is-everything-that-is-wrong-with-cves/</a>, See on <a href="https://news.ycombinator.com/item?id=37267940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>This is a story consisting of several little building blocks and they occurred spread out in time and in different places. It is a story that shows with clarity how our current system with CVE Ids and lots of power given to NVD is a completely broken system.</p>







<p>On August 25 2023, we get <a href="https://curl.se/mail/lib-2023-08/0031.html">an email to the curl-library mailing list</a> that informs us that “someone” has recently created a CVE, a security vulnerability identification number and report really, for a curl problem.</p>



<pre>I wanted to let you know that there's a recent curl CVE published and it doesn't look like it was acknowledged by the curl authors since it's not mentioned in the curl website: CVE-2020-19909</pre>



<p>We can’t tell who filed it. We just know that it is now there.</p>



<h2>We own our curl issues</h2>



<p>In the curl project we work hard and fierce on security and we always work with security researchers who report problems. We file our own CVEs, we document them and we make sure to tell the world about them. <a href="https://curl.se/docs/security.html">We list over 140 of them</a> with every imaginable detail about them provided. We aim at providing gold-level documentation for <em>everything</em> and that includes our past security vulnerabilities.</p>



<p>That someone else suddenly has submitted a CVE for curl is a surprise. We have not been told about this and we would <em>really</em> have liked to.  Now there is a new CVE out there reporting a curl issue and we have no details to say about it on the website. Not good.</p>



<p>I bet curl users soon would like to know the details about this.</p>



<h2>Wait 2020?</h2>



<p>The new CVE has an ID containing 2020 and that is weird. When you register a CVE you typically get it with the year you request it. Unless you get an ID for an <em>old</em> problem of the past. Is that what they did?</p>



<p>Sources seem to indicate that this was published just days ago.</p>



<h2>What is this CVE?</h2>



<p>Of course the top link when you search for this CVE is to NVD. <a href="https://daniel.haxx.se/blog/2023/06/12/nvd-damage-continued/" data-type="post" data-id="22645">Not the most reliable organization</a>, but now we can’t be too picky. On their site <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-19909">they explain this</a> with very few details:</p>



<pre>Integer overflow vulnerability in tool_operate.c in curl 7.65.2 via crafted value as the retry delay.</pre>



<p>And then the craziest statement of the year. They grade it a <strong>9.8 CRITICAL</strong> issue. With 10 as a maximum, this is close to the worst case possible, right?</p>



<h2>The code</h2>



<p>Let’s pause NVD in their panic state for a moment because I immediately recognized this description. Brief as it is.</p>



<p>I spend a lot of time in the curl security team receiving reports, reviewing reports, reviewing source code, assessing claims and figuring out curl security issues.<em> I had seen this claim before!</em></p>



<p>On July 27, 2019, a Jason Lee file an <a href="https://hackerone.com/reports/661847">issue on hackerone</a>, where he reported that there was an integer overflow problem in curl’s <code>--retry-delay</code> command line option. The option accepts number of seconds and then internally converts to milliseconds by multiplying the value by 1000. The option sets how long time curl should wait until it makes a retry if the previous transfer failed with a transient error.</p>



<p>This means that on a 64 bit machine, if you write </p>



<pre>curl --retry-delay 18446744073709552 ...</pre>



<p>The number will overflow the math and instead of waiting until the end of the universe, it might retry again within the next few seconds. The above example apparently made it 384 seconds instead. On Windows, which uses 32 bit longs, you can get the problem already by asking for more than two million seconds (roughly 68 years).</p>



<p>A bug, sure. Security problem? No. I told Jason that in 2019 and then we closed the security report. I then filed <a href="https://github.com/curl/curl/pull/4166">a pull-request and fixed the bug</a>. Credits to Jason for the report. We moved on. The fix was shipped in curl 7.66.0, released in September 2019.</p>



<h2>Grading issues</h2>



<p>In previous desperate attempts from me to reason with NVD and stop their scaremongering and their grossly inflating the severity level of issues, they have insisted that they take in all publicly available data about the problem and make an assessment.</p>



<p>It was obvious already before that NVD really does not try very hard to actually understand or figure out the problem they grade. In this case it is quite impossible for me to understand how they could come up with this severity level. It’s like they saw “integer overflow” and figure that <em>wow, yeah that is the most horrible flaw we can imagine</em>, but clearly nobody at NVD engaged their brains nor looked at the “vulnerable” code or the patch that fixed the bug. Anyone that looks can see that this is not a security problem.</p>



<p>The issue listed by NVD even links to <a href="https://github.com/curl/curl/pull/4166">my pull request</a> I mention above. There is no doubt that it is the exact same bug they refer to.</p>



<h2>Spreading like a virus</h2>



<p>NVD hosts a CVE database and there is an entire world and eco system now that pulls the records from them.</p>



<p>NVD now has this CVE-2020-19909 entry in there, rated 9.8 CRITICAL and now this disinformation spreads across the world. Now when we search for this CVE number we find numerous sites that repeats the same data. “This is a 9.8 CRITICAL problem in curl” – when it is not.</p>



<h2>I will object</h2>



<p>I learned about this slap in my face just a few hours ago, but I intend to do what I can to reject this CVE.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beating GPT-4 on HumanEval with a fine-tuned CodeLlama-34B (715 pts)]]></title>
            <link>https://www.phind.com/blog/code-llama-beats-gpt4</link>
            <guid>37267597</guid>
            <pubDate>Fri, 25 Aug 2023 22:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phind.com/blog/code-llama-beats-gpt4">https://www.phind.com/blog/code-llama-beats-gpt4</a>, See on <a href="https://news.ycombinator.com/item?id=37267597">Hacker News</a></p>
Couldn't get https://www.phind.com/blog/code-llama-beats-gpt4: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>