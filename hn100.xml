<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 15 May 2024 04:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The most talented person in the world (150 pts)]]></title>
            <link>https://matt.sh/the-most-talented-person</link>
            <guid>40361387</guid>
            <pubDate>Tue, 14 May 2024 23:37:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matt.sh/the-most-talented-person">https://matt.sh/the-most-talented-person</a>, See on <a href="https://news.ycombinator.com/item?id=40361387">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="individualArticle">
  <article id="the-most-talented-person">
   <header>
    <a href="https://matt.sh/the-most-talented-person">so talent much person</a>
   </header>
  <div>
    <h2 id="_the-most-talented-person-in-the-world">The Most Talented Person In The World</h2>
<p>I discovered a genius online. Just look at <a href="https://www.bing.com/search?q=%22Jodie+Chiffey%22">all her accomplishments</a>:</p>
<ul>
<li><p>Jodie is a cross-functional 3D designer and blogger. She has special interests in open source 3D printing for R&amp;D and has spent a lot of time at different projects across the globe to learn more about 3D printing. Most of what she has learned is from hands-on experience.</p></li>
<li><p>Jodie Chiffey is a blogger, and mom who loves nothing more than testing out the latest grills, gadgets, and outdoor cooking tech. As passionate about food as she is about family, Jodie loves spending time outdoors and is always the one found hovering over the grill at parties, camping trips, and local community events.</p></li>
<li><p>Jodie discovered her passion for grilling when she realized how much filler she was able to eliminate from her diet by grilling. So, she began to devote herself to learning more about grilling and mastering her grilling technique. Now, she spends most of her time outdoors grilling non-processed foods and enjoying fresh food on her plate.</p></li>
<li><p>Jodie Chiffey - Mellifluent Performer at Guitar Space - Jodie fell in love with the guitar at a young age, but has hit a lot of bumps in the road with her journey. She knows all of the frustrations that come with learning the instrument without any formal lessons. But, she pushed through all of those challenges and she’s now here to teach other people too. If you’re looking for advice that’ll stick with you for a lifetime, Jodie’s here to share everything she knows. (mattnote: also lol at “Mellifluent” —&nbsp;ESL spam disease slipping in there)</p></li>
<li><p>Jodie Chiffey loves the outdoors. If you aren’t sure where to find her, check the nearest dirt trail. She loves being outdoors and spends a good deal of time reviewing products like clothing, footwear, and other outdoor gear.</p></li>
<li><p>Jodie is a full-time blogger who reviews a lot of the products for us. She writes many of our backpacking gear reviews, outdoor skills advice, and information, and helps visitors find the best destinations for backpacking, camping, hiking, and a lot more.</p></li>
<li><p>If Jodie’s friends have a travel or outdoors question, they know who to ask and that’s why we featured on our website. Now you can get the same great advice her friends enjoy, so you know where to go and what gear to take with you.</p></li>
<li><p>Jodie Chiffey - Travel Lover at RV Pioneers- Jodie Chiffey enjoys the outdoors. She goes mountain biking and loves spending time in nature and what better way to get there than to go in an RV? She shares her information here on RV Pioneers.</p></li>
<li><p>Jodie knows quite a bit about beer and brewing it. From different types of hops and how they will affect your brew to her own opinion on various craft brews on the market. Jodie isn’t afraid to bring you her opinion on a new brew here at Beertannica, along with helping you decide if an ingredient or beer is the one for you. Her comprehensive guides will answer all your questions and more!</p></li>
<li><p>As a fellow business owner and business strategist, Jodie shares valuable insight into the strategies and tactics business owners can use to increase their growth.</p></li>
<li><p>Jodie’s run through a lot of shoes. After all, she’s a competitive racer! She understands all of the important features of an ideal running shoe and the biomechanics of the feet of different kinds of runners. You’ll be surprised to learn that Jodie doesn’t have a degree or diploma in athletic shoes; she’s just passionate about them and owns more than fifty pairs of running shoes herself. She’s dedicated her life to studying athletic shoes in detail and writing about them.</p></li>
<li><p>Jodie has been a certified personal trainer for several years now and has a passion for wellness, health, fitness like no other. She’s been educating herself on nutrition since she was in high school. His boyfriend is a professional herbalist and food healer, so she takes the health and wellness discussions into the homefront. She uses and tests health products, protein supplements personally and shares her insights on topics such as protein, diets, muscle recovery, muscle building, supplements, and naturally-sourced products.</p></li>
<li><p>Jodie is a nutrition and health expert who owns over 50 pairs of athletic shoes and puts them to good use. She is always looking for a new healthy recipe, loves juicing and tests new products at home, and reports back to us here at Alt Protein. Jodie’s articles and recipes can also be found on her successful blog called The Juice Chief.</p></li>
<li><p>Jodie Chiffey understands how frustrating it can be to sort your way through long pieces of boring content just to try to get a simple explanation of the digital topic you’re looking to learn about. That’s why she’s here to break down all of the complex topics, to help you learn, understand, and grow in your own digital life. She wants to be there to give you all of the information you need to know to make your own personal decisions in regards to the digital topics you’re bringing into your life!</p></li>
<li><p>Jodie Chiffey - Jodie is an avid traveler who loves camping and hiking. Why do you love mountain biking? I’ve had two separate passions for quite a long time - cycling and hiking. Whenever I was planning to spend some time outdoors, I had to decide which one to choose. It all made perfect sense when I discovered mountain biking, a beautiful blend of both of my favorite activities with the added value of adrenaline. What is your budget bike pick? If I were looking for a budget-friendly bike these days, I would undoubtedly go with GT Aggressor Expert. It’s super comfortable and lots of fun to ride. Nevertheless, Giant has some great entry-level mountain bikes these days too. What is your splurge bike pick? If I had an endless budget, I would probably buy a Santa Cruz 5010 - ideally in the exclusive X01 AXS RSV Carbon CC configuration. It’s one of the best bicycles I have had the chance to ride so far. What’s your favorite trail that you’ve ridden? Last summer, I enjoyed some tremendous single trails in the Austrian Alps around Nassfeld. Short but spicy Yannick Trail was probably my favorite. It was pretty demanding, and the views were truly priceless.</p></li>
<li><p>Jodie Chiffey - Jodie Chiffey spends a lot of time helping people figure out how to get the perfect yard. With so many variants from climate, soil type, to the amount of rainfall, she researches and helps Turf and Till readers choose the best products for their needs. Why are you giving advice on Turf and Till? After spending three and a half years transforming my yard from a generic underestimated wasteland into the green haven of my dreams, I have felt two contradictory emotions: relief and sadness. I have realized that I will miss all the research, consideration, and hard work and started looking for new ways to approach this topic and make it a permanent part of my life. That was when I started helping others to fulfill their landscape-related dreams too. Since then, I have worked on numerous exciting projects and gained valuable experience. I see writing for Turf and Till as a natural continuation of my work in this field. Moreover, it is also an excellent opportunity to give back to the online community that has taught me a lot in my beginnings. What is your favorite part of landscaping? My favorite part is turning a blueprint into a reality. I am a huge overthinker, so planning is the most exciting yet also the most demanding and frustrating part of every project for me. When I am finally satisfied with the plan and can watch it turn into a real landscape, someone’s garden, or yard, it is the most gratifying moment I know. If you had to give one piece of advice to someone fixing up their yard, what would it be? Don’t be afraid to think big. There is always space for downgrades and compromises later, but don’t settle with any of it before you even start. If I earned a dollar for each “impossible” idea I have seen turning into a reality, I would be very rich by now.</p></li>
</ul>
<h2 id="_web-spam-bullshit">web spam bullshit</h2>
<p>All of those sites are labeled as “A Venture 4th Media Company” which has such wondrous important content all run by the same “writer” on:</p>
<ul>
<li><a href="https://mtbinsider.com/author/jodie-chiffey/">https://mtbinsider.com/author/jodie-chiffey/</a></li>
<li><a href="https://turfandtill.com/author/jodie-chiffey/">https://turfandtill.com/author/jodie-chiffey/</a></li>
<li><a href="https://www.betterwander.com/author/jodie-chiffey/">https://www.betterwander.com/author/jodie-chiffey/</a></li>
<li><a href="https://artofgrill.com/author/jodie-chiffey/">https://artofgrill.com/author/jodie-chiffey/</a></li>
<li><a href="https://theathleticfoot.com/author/jodie-chiffey/">https://theathleticfoot.com/author/jodie-chiffey/</a></li>
<li><a href="https://altprotein.com/team-members/jodie-chiffey/">https://altprotein.com/team-members/jodie-chiffey/</a></li>
<li><a href="https://digitalguyde.com/us/">https://digitalguyde.com/us/</a></li>
<li><a href="https://total3dprinting.org/author/jodie-chiffey/">https://total3dprinting.org/author/jodie-chiffey/</a></li>
<li><a href="https://muckrack.com/jodie-chiffey/articles">https://muckrack.com/jodie-chiffey/articles</a></li>
<li><a href="https://muckrack.com/jodie-chiffey-1">https://muckrack.com/jodie-chiffey-1</a></li>
</ul>
<p>or is it “A <a href="https://www.linkedin.com/company/center-keel-media">Center Keel Media</a> Company?” Either way, remember to take your amazon affiliate link <a href="https://thehorseandstable.com/best-horse-supplements/">horse supplements</a> and buy your amazon affiliate link <a href="https://www.insecthobbyist.com/category/reptiles/">best snake traps of 2022</a> from a purely <a href="https://explore3dprint.com/buyers-guide/">AI generated photoshop author image</a> from your <a href="https://marketingsatchel.com/">marketing satchel</a> providing such important online content as <a href="https://wizerlist.com/">https://wizerlist.com/</a> and <a href="https://americansportbike.com/">https://americansportbike.com/</a> and <a href="https://birdinginsider.com/">https://birdinginsider.com/</a> and <a href="https://curatedcabinets.com/">https://curatedcabinets.com/</a> and more auto-generated link farm low value crap clogging up the global search engine brain for affiliate commissions.</p>
<blockquote>
<p>“<a href="https://www.linkedin.com/company/venture-4th-media">We specialize</a> in developing and transacting digital media assets, providing the best possible visitor experience in every market vertical we enter. Our portfolio is diverse and balanced across multiple established and high growth market niches. We take a circumspect approach to building web assets, focused on the long-term value of acquiring and generating cash flow positive properties, uniquely positioned to capitalize on the maturation of online commerce.”</p>
</blockquote>
<p><em>pardon me while i vom</em></p>
<blockquote>
<p>Specialties: Search Engine Optimization, eCommerce, Content Marketing, and Internet Marketing</p>
</blockquote>
<p>of course it’s just a huge affiliate link bot farm network. There are a dozen sites with “Jodie Chiffey” as primary author each with dozens of pages about “The Top 10 X For Y!” each with low effort summaries and affiliate links everywhere polluting tons of search results.</p>
<p>also, these “media companies” are two examples out of hundreds or thousands operating to manipulate global search results at scale for low-effort-low-return pennies-per-click ad or affiliate revenue. We’re going to need cryptographically authenticated proof-of-utility to be indexed by search engines fairly soon (or maybe not? who cares? google is happy to <a href="https://www.wheresyoured.at/the-men-who-killed-google/">pollute the world with search garbage</a> because more garbage means more ads means more google revenue and google is nothing without its <a href="https://www.cnbc.com/2024/04/25/alphabet-issues-first-ever-dividend-70-billion-buyback.html">$70 billion per year stock buyback program</a>).</p>
<p>Also if you haven’t searched for tech help over the past couple years, there are hundreds of fake “tech blog” sites doing the same thing: a site appearing as if it’s “a personal blog,” but having thousands of “helpful” pages in 300 different topic areas half scraped from github issues and half auto-generated. Also, by pure coincidence I’m sure, each page has 50 google ads or it bounces direct to spyware install sites when you navigate away. Each one of those sites is an “expert” in 100 different projects, platforms, programming languages, and strategies, yet they all are written from a first person “it’s just my blog lol!” point of view.</p>
<p>Curiously, each of these sites has the exact same layout, looks driven from the same CMS, has the same headers and footers, has the same navigation everywhere, has the same vapid FAQs (“Mountain Biking Tips: WEAR A HELMET!!”), all copied across thousands of sites all ranking in the top results for common queries to every day questions…</p>
<p>of course, this garbage is also flooding youtube as well with new emotionless and storyless and zero-personality autogenerated near-human voices all over the place:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=oknB7TihO5A">https://www.youtube.com/watch?v=oknB7TihO5A</a></li>
<li><a href="https://www.youtube.com/@top5reviews-te8eh/videos">https://www.youtube.com/@top5reviews-te8eh/videos</a></li>
<li><a href="https://www.youtube.com/@5besstones/videos">https://www.youtube.com/@5besstones/videos</a></li>
<li><a href="https://www.youtube.com/@yourreviews2613/videos">https://www.youtube.com/@yourreviews2613/videos</a></li>
<li><a href="https://www.youtube.com/@6BestOnesOfficial/videos">https://www.youtube.com/@6BestOnesOfficial/videos</a></li>
</ul>
<p>people talk a lot about “<a href="https://www.youtube.com/watch?v=C6L07VdZO4o">dead internet theory</a>” and how everything is becoming bots and scams and advertising bait, but those aren’t automatic outcomes. The “dead internet” is a process of <a href="https://old.reddit.com/r/ClicBot/comments/1chlcnk/from_debt_to_wealth_my_personal_finance_success/">direct information platform exploitation</a> by manipulative people operating on unchecked-and-unauthenticated platforms drawn to running scams due to their life circumstances (we’re ignoring the other branch of <a href="https://en.wikipedia.org/wiki/Russian_web_brigades">politically controlled “information warfare”</a> scams for now). Bot/scam/advertising/affiliate manipulation is born from usually living in low income societies where the most logical upward trajectory is just exploiting and manipulating high income people and societies who aren’t their own people (much like how a good way to stop spyware is changing your windows locale to russia because russian spyware firms don’t attack their own). Who cares if you make a million fake websites and destroy the information coherency of the planet if it earns you a passive $3 per day?</p>
<p>The only future of the internet is, sadly, proof-of-person and proof-of-residence on every public network interaction. There’s no going back to “high trust anonymous internet” when half the world is willing to exploit the other half. We end up with real time <a href="https://www.youtube.com/watch?v=Y82KJWFdWZw">global access</a> from “low trust low income max exploitation because <a href="https://www.youtube.com/@ScammerPayback/videos">who is going to stop us</a>” wankers to “high trust high income low questioning” societies and <a href="https://www.propublica.org/article/whats-a-pig-butchering-scam-heres-how-to-avoid-falling-victim-to-one">everything falls apart</a>.</p>
<p>the net of a million million lies is upon us and only you can prevent information fires.</p>
<p>Welcome to the future of the entire Internet. Jodie the full time 3d-printing expert, grill master, expert guitarist, marketing wonder, brewqueen, personal trainer, avid camper, certified nutritionist, professional hiker, marathon runner, constant traveler, yard work enthusiast, mountain biker, rv driver, sportshoe expert, and mommy blogger welcomes you too.</p>

  </div>
  
  </article>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ilya Sutskever to leave OpenAI (530 pts)]]></title>
            <link>https://twitter.com/ilyasut/status/1790517455628198322</link>
            <guid>40361128</guid>
            <pubDate>Tue, 14 May 2024 23:01:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ilyasut/status/1790517455628198322">https://twitter.com/ilyasut/status/1790517455628198322</a>, See on <a href="https://news.ycombinator.com/item?id=40361128">Hacker News</a></p>
Couldn't get https://twitter.com/ilyasut/status/1790517455628198322: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Most common PIN codes (2012) (110 pts)]]></title>
            <link>http://www.datagenetics.com/blog/september32012/index.html</link>
            <guid>40359736</guid>
            <pubDate>Tue, 14 May 2024 20:22:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.datagenetics.com/blog/september32012/index.html">http://www.datagenetics.com/blog/september32012/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=40359736">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">

<fb:like send="true" width="450" show_faces="true" colorscheme="dark" font="arial"></fb:like>




<table>
<tbody><tr>
<td>
<p>A good friend of mine, <a href="http://blog.abodit.com/">Ian</a>, recently forwarded me an internet joke.   The headline was something like:</p>
<p><span size="6" face="timesroman"><i>“All credit card PIN numbers in the World leaked”</i></span></p>
<p>The body of the message simply said <span color="gold"><b>0000 0001 0002 0003 0004 </b></span> …</p>
</td>
<td><img src="http://www.datagenetics.com/blog/september32012/p.png"></td>
</tr>
</tbody></table>

<p>Ian’s messages made me chuckle.  Then, later the same day, I read this <a href="http://xkcd.com/1105/">XKCD cartoon</a>.  The merging of these two humorous topics created the seed for this article.</p>



<table>
<tbody><tr>
<td rowspan="3"><img src="http://www.datagenetics.com/blog/september32012/xkcd.png"></td>
<td></td><td></td>
</tr><tr>
<td>
<p><span size="2">I love Randall’s work.  My favorite, to date, is this <a href="http://xkcd.com/327/">one</a>.  I have a signed copy of it on my office wall.</span></p><span size="2">

<p><span size="2">Like many of his creations, this cartoon is excellent at bifurcating readers;  people read it, then either smile and chuckle, or stare blankly at it followed by a <i>“Huh? I don’t get it!”</i> comment. Then you explain it, and get a reply <i>“Yeeaaaaaa…no, I still don’t get it!”</i></span></p><span size="2">
<p><span size="2">Esoteric humor in action.</span></p>
<p><span size="2">You can be cool and buy his <a href="http://store.xkcd.com/xkcd/#SignedPrints">signed artwork</a> too.</span></p><span size="2">
</span></span></span></td>
</tr>
<tr><td></td>
</tr></tbody></table>

<h3>What is the least common PIN number?</h3>
<table>
<tbody><tr>
<td>
<p>There are 10,000 possible combinations that the digits 0-9 can be arranged to form a 4-digit pin code.  Out of these ten thousand codes, which is the least commonly used? </p>
<p>Which of these pin codes is the <span color="gold">least</span> predictable?</p>
<p>Which of these pin codes is the <span color="gold">most</span> predictable?</p>
<p>If you were given the task of trying to crack a random credit card by repeatedly trying PIN codes, what order should you try guessing to maximize your chances of selecting the correct number in the shortest time?</p>
</td>
<td><img src="http://www.datagenetics.com/blog/september32012/q.png"></td>
</tr>
</tbody></table>

<p>If you had to make predication about what the least commonly used 4-digit PIN is, what would be your guess?</p>

<p>This tangentially relates to the XKCD cartoon.  In Randall’s cartoon, the perpetrator’s plan backfired because his selected license plate was so unique that it was very memorable.  What is the least memorable license plate?  Ask any spy you know (snigger) what the best way to blend into a crowd is.  Their answer will be not stand out, to appear “normal”, and not be notable in any way.</p>

<table>
<tbody><tr>
<td><img src="http://www.datagenetics.com/blog/september32012/h.png"></td>
<td>
<p>People are notoriously bad at generating random passwords.  I hope this article will scare you into being a little more careful in how you select your next PIN number.</p>

<p>Are you curious about what the least commonly used PIN number might be?</p>
<p>How about the most popular?</p>
<p>Read on …</p>
</td>
</tr>
</tbody></table>

<h2>DISCLAIMER</h2>

<p>This article is <b>not</b> intended to be a hacker bible, or to be used as a utility, resource, or tool to help would-be thieves perform nefarious actions.  I will only disclose data sufficient to make my points, and will try to avoid giving specific data outside of the obvious examples.  I do not want to be an enabler for script-kiddies.   Please do not email me asking for the database I used; if you do, you will be wasting your time as I’m not going to respond.  I’m not going to sell, donate or release the source data – don’t ask!</p>

<h3>Source</h3>

<p>Obviously, I don’t have access to a credit card PIN number database.  Instead I’m going to use a proxy.  I’m going to use data condensed from released/exposed/discovered password tables and security breaches.</p>

<h3>Soap Box – Password Database Exposures</h3>
<table>
<tbody><tr>
<td>
<p>Over the years, there have been numerous password table security breaches:  Some very high profile, some low profile, but all embarrassing (and many exceedingly expensive; both in direct fines and indirect loss of business through erosion of trust and reputation). </p>
<p>Fool me once, well, no, even that’s not really acceptable, but fool me twice …  I’ll go even further: <b>Any</b> developer who stores the password table of their database in clear text  should be so mortified by this lack of security that they should not be sleeping at night until they fix it.  Ignoring the fact that you should never have ever coded it this way, you have an <u>obligation</u> to learn from these past breaches.</p>
<p>If you work for a company and are knowledgeable that your customer database is <i>“protected”</i> by such lightweight security then run, don’t walk, to your CEO/Presidents office, pound on the door and insist (s)he puts out a mandate to fix the matter with extreme prejudice.  Don’t leave until you get an affirmative response. Badger, badger then badger them again. Make yourself a proverbial thorn in their side.</p>
</td>
<td><img src="http://www.datagenetics.com/blog/september32012/s.png"></td>
</tr>
</tbody></table>

<p>I’m not trying to sell my services as a consultant here (though if you are interested, my rates are very reasonable compared to the cost of legal defense, potential FTC sanctions, class action suits, shareholder backlash,  fines, loss of reputation and business …)  There are plenty of security experts in the industry who can help you (if you need help filtering them and don’t have referrals, someone who has CISSP qualifications is a good place to start).</p>
<p><span><span color="black">&nbsp;<b>Bottom line</b>&nbsp;</span></span> Security strengthens with layers, and the simple application of encryption on your database table can help protect your customer’s data if this table is exposed.  It does not defend against all possible attacks, but it does nothing but good things.  What possible reason is there store things in clear-text? </p>

<h3>Back to the data</h3>

<table>
<tbody><tr>
<td><img src="http://www.datagenetics.com/blog/september32012/l.png"></td>
<td>
<p>By combining the exposed password databases I’ve encountered, and filtering the results to just those rows that are exactly four digits long <span color="gold">[0-9]</span> the output is a database of all the four digit character combinations that people have used as their account passwords.</p>
</td>
</tr>
</tbody></table>
<p>Given that users have a free choice for their password, if users select a four digit password to their online account, it’s not a stretch to use this as a proxy for four digit PIN codes.</p>

<h2>The Data</h2>

<p>I was able to find almost <i>3.4 million</i> four digit passwords.   Every single one of the of the 10,000 combinations of digits from <span color="gold">0000</span> through to <span color="gold">9999</span> were represented in the dataset.</p>

<table>
<tbody><tr><td><p>The most popular password is <span>&nbsp;1234&nbsp;</span> …</p></td><td></td><td></td></tr>
</tbody></table>

<table>
<tbody><tr><td></td><td><p>… it’s <i>staggering</i> how popular this password appears to be.  Utterly <i>staggering</i> at the lack of imagination …</p></td><td></td></tr>
</tbody></table>

<table>
<tbody><tr><td></td><td><p>… nearly 11% of the 3.4 million passwords are <span>&nbsp;1234&nbsp;</span> <i>!!!</i></p></td></tr>
</tbody></table>

<table>
<tbody><tr>
<td>
<p>The next most popular 4-digit PIN in use is <span>&nbsp;1111&nbsp;</span>  with over 6% of passwords being this.</p>
<p>In third place is <span>&nbsp;0000&nbsp;</span> with almost 2%.</p>
<p>A table of the top 20 found passwords in shown at the right.  A staggering <span color="gold">26.83%</span> of all passwords could be guessed by attempting these 20 combinations!</p>

<p>(Statistically, with 10,000 possible combination, if passwords were uniformly randomly distributed, we would expect the these twenty passwords to account for just 0.2% of the total, not the 26.83% encountered)</p>

<p>Looking more closely at the top few records, all the usual suspects are present <span>&nbsp;1111&nbsp;</span> <span>&nbsp;2222&nbsp;</span> <span>&nbsp;3333&nbsp;</span> … <span>&nbsp;9999&nbsp;</span> as well as <span>&nbsp;1212&nbsp;</span> and (snigger) <span>&nbsp;6969&nbsp;</span>.</p>
<p>It’s not a surprise to see patterns like <span>&nbsp;1122&nbsp;</span> and <span>&nbsp;1313&nbsp;</span> occurring high up in the list, nor <span>&nbsp;4321&nbsp;</span> or <span>&nbsp;1010&nbsp;</span>.</p>

<p><span>&nbsp;2001&nbsp;</span> makes an appearance at #19. <span>&nbsp;1984&nbsp;</span> follows not far behind in position #26, and James Bond fans may be interested to know <span>&nbsp;0007&nbsp;</span> is found between the two of them in position #23 (another variant <span>&nbsp;0070&nbsp;</span> follows not much further behind at #28).</p>
</td>
<td>

<table>
<thead><tr><th></th><th>PIN</th><th>Freq</th></tr></thead>
<tbody><tr><td>#1</td><td>1234</td><td>10.713%</td></tr>
<tr><td>#2</td><td>1111</td><td>6.016%</td></tr>
<tr><td>#3</td><td>0000</td><td>1.881%</td></tr>
<tr><td>#4</td><td>1212</td><td>1.197%</td></tr>
<tr><td>#5</td><td>7777</td><td>0.745%</td></tr>
<tr><td>#6</td><td>1004</td><td>0.616%</td></tr>
<tr><td>#7</td><td>2000</td><td>0.613%</td></tr>
<tr><td>#8</td><td>4444</td><td>0.526%</td></tr>
<tr><td>#9</td><td>2222</td><td>0.516%</td></tr>
<tr><td>#10</td><td>6969</td><td>0.512%</td></tr>
<tr><td>#11</td><td>9999</td><td>0.451%</td></tr>
<tr><td>#12</td><td>3333</td><td>0.419%</td></tr>
<tr><td>#13</td><td>5555</td><td>0.395%</td></tr>
<tr><td>#14</td><td>6666</td><td>0.391%</td></tr>
<tr><td>#15</td><td>1122</td><td>0.366%</td></tr>
<tr><td>#16</td><td>1313</td><td>0.304%</td></tr>
<tr><td>#17</td><td>8888</td><td>0.303%</td></tr>
<tr><td>#18</td><td>4321</td><td>0.293%</td></tr>
<tr><td>#19</td><td>2001</td><td>0.290%</td></tr>
<tr><td>#20</td><td>1010</td><td>0.285%</td></tr>
</tbody></table>
</td>
</tr>
</tbody></table>


<p>The first “puzzling” password I encountered was <span>&nbsp;2580&nbsp;</span> in position #22.   What is the significance of these digits? Why should so many people select this code to make it appear so high up the list?</p>

<table>
<tbody><tr>
<td rowspan="2"><img src="http://www.datagenetics.com/blog/september32012/keypad.png"></td>
<td colspan="2">
<p>Then I realized that <span>&nbsp;2580&nbsp;</span>is a straight down the middle of a telephone keypad!</p></td></tr>
<tr><td>
<p> (Interestingly, this is very compelling evidence confirming the hypothesis that a 4-digit password list is a great proxy for a PIN number database.  If you look at the numeric keypad on a PC-keyboard you’ll see that 2580 is slightly more awkward to type on the PC than a phone because the order of keys on a keyboard is the inverted.  Cash machines and other terminals that take credit cards use a phone style numeric pads.  It appears that many people have an easy to type/remember PIN number for their credit card and are re-using the same four digits for their online passwords, where the <i>"straight down the middle"</i> mnemonic no longer applies).</p></td>
<td><img src="http://www.datagenetics.com/blog/september32012/kp.png"></td>
</tr>
</tbody></table>

<p>(Another fascinating piece of trivia is that people seem to prefer even numbers over odd, and codes like <span>&nbsp;2468&nbsp;</span> occur higher than a odd number equivalent, such as <span>&nbsp;1357&nbsp;</span>).</p>

<h2>Cumulative Frequency</h2>

<p>As noted above, the more popular password selections dominate the frequency tables.  The most popular PIN code of <span>&nbsp;1234&nbsp;</span> is more popular than the <i>lowest 4,200 codes combined!</i></p>
<p>That's right, you might be able to crack over 10% of all codes with one guess!  Expanding this, you could get 20% by using just five numbers!</p>
<p>Below is a cumulative frequency graph:</p>

<p><img src="http://www.datagenetics.com/blog/september32012/c.png"></p><p>Statistically, <i>one third</i> of all codes can be guessed by trying just 61 distinct combinations!</p>
<p>The 50% cumulative chance threshold is passed at just 426 codes (far less than the 5,000 that a random uniformly distribution would predict).  Paranoid yet?</p>

<h2>Bottom of the pile</h2>

<table>
<tbody><tr>
<td>

<p>OK, we've investigated most frequently used PINS and found they tend to be predictable and easy to remember, let's turn for a second to the bottom of the pile.</p>
<p> What are the least "interesting" (least used) PINS?</p>
<p>In my dataset the answer is <span>&nbsp;8068&nbsp;</span> with just 25 occurrences in 3.4 million (this equates to 0.000744%, far, far fewer than random distribution would predict, and five orders of magnitude behind the most popular choice).</p>
<p>To the right are the twenty least popular 4-digit passwords encountered.</p>
<table>
<tbody><tr><td><img src="http://www.datagenetics.com/blog/september32012/k.png" width="200"></td>
<td>
<p><span><span color="black">&nbsp;<b>Warning</b>&nbsp;</span></span> Now that we’ve learned that, historically, <span>&nbsp;8068&nbsp;</span> is (was?) the least commonly used password 4-digit PIN, please don’t go out and change yours to this!  Hackers can read too!  They will also be promoting 8068 up their attempt trees in order to catch people who read this (or similar) articles.</p>
<p>Check out about the <a href="http://en.wikipedia.org/wiki/Nash_equilibrium">Nash Equilibrium</a></p>
</td>
</tr></tbody></table>

</td>

<td>
<table>
<thead><tr><th></th><th>PIN</th><th>Freq</th></tr></thead>
<tbody><tr><td>#9980</td><td>8557</td><td>0.001191%</td></tr>
<tr><td>#9981</td><td>9047</td><td>0.001161%</td></tr>
<tr><td>#9982</td><td>8438</td><td>0.001161%</td></tr>
<tr><td>#9983</td><td>0439</td><td>0.001161%</td></tr>
<tr><td>#9984</td><td>9539</td><td>0.001161%</td></tr>
<tr><td>#9985</td><td>8196</td><td>0.001131%</td></tr>
<tr><td>#9986</td><td>7063</td><td>0.001131%</td></tr>
<tr><td>#9987</td><td>6093</td><td>0.001131%</td></tr>
<tr><td>#9988</td><td>6827</td><td>0.001101%</td></tr>
<tr><td>#9989</td><td>7394</td><td>0.001101%</td></tr>
<tr><td>#9990</td><td>0859</td><td>0.001072%</td></tr>
<tr><td>#9991</td><td>8957</td><td>0.001042%</td></tr>
<tr><td>#9992</td><td>9480</td><td>0.001042%</td></tr>
<tr><td>#9993</td><td>6793</td><td>0.001012%</td></tr>
<tr><td>#9994</td><td>8398</td><td>0.000982%</td></tr>
<tr><td>#9995</td><td>0738</td><td>0.000982%</td></tr>
<tr><td>#9996</td><td>7637</td><td>0.000953%</td></tr>
<tr><td>#9997</td><td>6835</td><td>0.000953%</td></tr>
<tr><td>#9998</td><td>9629</td><td>0.000953%</td></tr>
<tr><td>#9999</td><td>8093</td><td>0.000893%</td></tr>
<tr><td>#10000</td><td>8068</td><td>0.000744%</td></tr>
</tbody></table>

</td>
</tr>
</tbody></table>

<h2>Memorable Years</h2>

<p>Many of the high frequency PIN numbers can be interpreted as years, <i>e.g.</i>  <span>&nbsp;1967&nbsp;</span> <span>&nbsp;1956&nbsp;</span> <span>&nbsp;1937&nbsp;</span> … It appears that many people use a year of birth (or possibly an anniversary) as their PIN. This will certainly help them remember their code, but it greatly increases its predictability.</p>

<p>Just look at the stats: Every single <span>&nbsp;19??&nbsp;</span> combination can be found in the <i>top fifth</i> of the dataset!</p>
<p>Below is a plot of this in graphical format.  In this chart, each <span color="yellow">yellow</span> line represents a PIN number that starts <span>&nbsp;19??&nbsp;</span> </p>
<p><img src="http://www.datagenetics.com/blog/september32012/c2.png"></p><p>If all the passwords were uniformly distributed, there should be no significant difference between the frequency of occurrence of, <i>for instance</i>, <span>&nbsp;1972&nbsp;</span> and any other PIN ending in seventy two <span>&nbsp;??72&nbsp;</span>.  However, as we shall see, this is not the case at all.</p>
<p><span>&nbsp;1972&nbsp;</span> occurs in ordinal position #76 (with a frequency 0.099363%).  Here’s a histogram for the occurrences of all <span>&nbsp;??72&nbsp;</span> probabilities.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/r.png"></p><p>You can clearly see the spike at <span>&nbsp;1972&nbsp;</span> (with smaller spikes at <span>&nbsp;7272&nbsp;</span>  and <span>&nbsp;1472&nbsp;</span>)</p>
<p>If you calculate the ratio of the peak of <span>&nbsp;1972&nbsp;</span> to the average of all the other <span>&nbsp;??72&nbsp;</span> PINS you get the ratio of <span color="gold">&nbsp;<b>22:1</b></span></p>
<p>PINS starting with <span>&nbsp;19??&nbsp;</span> are much more likley to occur. Of course, it’s not just 1972.  Here is plot of the ratio of <span color="gold">19</span> to <span color="gold">non-19</span> for all hundred combinations.  Along the x-axis are all the combinations of last two digits �XX, and for each of these the ratio of the 19XX to average of all the other ??XX occurrences has been calculated.  Here’s the chart:</p>
<p><img src="http://www.datagenetics.com/blog/september32012/r2.png"></p><p>It's a pretty good approximation for a demographic chart! (suggested by the red-dashed trend line) which would probably allow a fair estimation of the ages (years of birth) of the people using the various websites. (Of course, hackers invert this strategy and use the age of a target to try and give information to guess a user's PIN.  Looking at this graph, this might give them up to a <i>40x</i> advantage!)</p>
<p>Just about all the ratios are above <span color="gold">1.0</span>.  The noteable exceptions are <span>&nbsp;??34&nbsp;</span> and <span>&nbsp;??00&nbsp;</span> (which are easy to explain, since the massive popularity of <span>&nbsp;1234&nbsp;</span> and <span>&nbsp;0000&nbsp;</span> dwarf <span>&nbsp;1934&nbsp;</span> and <span>&nbsp;1900&nbsp;</span>respectively).  Simiarly <span>&nbsp;33&nbsp;</span> <span>&nbsp;44&nbsp;</span> <span>&nbsp;55&nbsp;</span> <span>&nbsp;66&nbsp;</span> … are lower than expected as the quad codes like <span>&nbsp;3333&nbsp;</span> mask out even the <span>&nbsp;1933&nbsp;</span> boost.</p>
<p>There are also spikes in the graph corresponding to the popular PINS of <span>&nbsp;1919&nbsp;</span> <span>&nbsp;1984&nbsp;</span> and <span>&nbsp;1999&nbsp;</span></p>
<h2>Patterns in data</h2>

<table>
<tbody><tr>
<td><img src="http://www.datagenetics.com/blog/september32012/g2.png"></td>
<td>
<p>I love pretty ways to graphically vizualize data.  Pictures really do paint thousands of words.</p>
<p>Another interesting way to visualize the PIN data is in this grid plot of the distribution.  In this heatmap, the x-axis depicts the left two digits from <span color="gold">[00]</span> to <span color="gold">[99]</span> and the y-axis depicts the right two digits from <span color="gold">[00]</span> to <span color="gold">[99]</span>.  The bottom left is <span>&nbsp;0000&nbsp;</span> and the top right is <span>&nbsp;9999&nbsp;</span>.</p>
<p>Color is used to represent frequency.  The higher frequency occurences are yellow to white hot, and the lower frequency occurences are red, through dark red to black.</p>
<p><span><span color="black">&nbsp;<b>Geek Note</b>&nbsp;</span></span> The scaling is logarithmic.</p>
</td>
</tr>
</tbody></table>
<p>You could look at this plot all day!</p>
<p>The bright line for the leading diagonal shows the repeated couplets that people love to use for their PIN numbers <span>&nbsp;0000&nbsp;</span> <span>&nbsp;0101&nbsp;</span> <span>&nbsp;0202&nbsp;</span> …
<span>&nbsp;5454&nbsp;</span> <span>&nbsp;5555&nbsp;</span> <span>&nbsp;5656&nbsp;</span>
…
<span>&nbsp;9898&nbsp;</span>
<span>&nbsp;9999&nbsp;</span>.</p>
<p>Every eleventh dot on the leading diagonal is brighter corresponding to the quad numbers
<i>e.g.</i> <span>&nbsp;4444&nbsp;</span> <span>&nbsp;5555&nbsp;</span>.  Here is a larger scale version:</p>


<p><img src="http://www.datagenetics.com/blog/september32012/grid.png" width="800"></p><h3>Interesting things</h3>

<p>There are so many interesting things to learn from this heatmap.  Here are just a couple:</p>

<table>

<tbody><tr>
<td><img src="http://www.datagenetics.com/blog/september32012/m1.png">
</td><td colspan="2">
<p>The first is the interesting harmonics of shading (seen here more easily in a gray scale plot).</p>
<p>You can make out a <i>“grid pattern”</i> in the plot.</p>
<p>The lighter areas corresponding to couplets of numbers that are close to each other.  For some reason, people don't like to select pairs of numbers that have larger numerical gaps between them.  Combinations like <span>&nbsp;45&nbsp;</span> and <span>&nbsp;67&nbsp;</span> occur much more frequently than things like <span>&nbsp;29&nbsp;</span> and <span>&nbsp;37&nbsp;</span> </p>
</td>
</tr>

<tr><td colspan="3">&nbsp;</td></tr>

<tr>
<td><img src="http://www.datagenetics.com/blog/september32012/m2.png">
</td><td>
<p>Here we see the line corresponding to <span>&nbsp;19XX&nbsp;</span>.  The intensity the dots relates to the chart we plotted earlier</p>
<p>There are a large number of codes starting with 19, especially towards the higher end.
</p></td>
<td><img src="http://www.datagenetics.com/blog/september32012/by.jpg"></td>
</tr>

<tr><td colspan="3">&nbsp;</td></tr>

<tr>
<td><img src="http://www.datagenetics.com/blog/september32012/m3.png">
</td><td>
<p>There is a strong bias towards the lower left quadrant.  People love to start their PIN numbers with <span color="gold">0</span>, and even more so with the digit <span color="gold">1</span>.</p>
<p>The chart on the right shows the relative frequency of the first digit of 4-digit pin codes.</p>
<p>As you can see, the digit <span color="gold">1</span> dominates (and it's not all down to the <span>&nbsp;19XX&nbsp;</span> phenomenon.)</p>
</td>
<td><img src="http://www.datagenetics.com/blog/september32012/ld.png"></td>
</tr>

<tr><td colspan="3">&nbsp;</td></tr>

<tr>
<td><img src="http://www.datagenetics.com/blog/september32012/m4.png">
</td><td colspan="2">
<p>Little bright specs dot the plot in places corresponding to numerical runs (both ascending and descending) such as <span>&nbsp;2345&nbsp;</span> , <span>&nbsp;4321&nbsp;</span> and <span>&nbsp;5678&nbsp;</span>.</p>
<p>I've highlighted just a couple on the plot to the left.</p>
<p>Jumps in steps of two are also visible <i>e.g.</i> <span>&nbsp;2468&nbsp;</span></p>
</td>

</tr>

<tr><td colspan="3">&nbsp;</td></tr>


</tbody></table>

<table>
<tbody><tr>
<td>
<p><i>Repeated-pair</i> couplets of numbers are very common, such as <span>&nbsp;XYXY&nbsp;</span></p>  <p>The hundred sets of repeating couplet pairs represent a staggering <span color="gold">17.8%</span> of all observed PIN numbers.</p>
</td>
<td><img src="http://www.datagenetics.com/blog/september32012/dd.jpg"></td>
</tr>
</tbody></table>

<h2>More than four</h2>

<p>The purpose of this posting was to investigate patterns and frequency of four digit PIN numbers.  However, the database I collected also has <i>all-numeric</i> password of different lengths.  It's worth taking a quick look at these too.</p>

<p><img src="http://www.datagenetics.com/blog/september32012/pl.png"></p><p>I found close to 7 million all-numeric passwords.  Approximately half of these were the four-digit codes we've just examined.</p>
<p>Six digit codes are the next most popular length, followed eight.</p>
<p>I hope, hope that the people who have passwords of nine digits long are <u>not</u> using their Social Security Numbers!</p>
<p>Below are the top 20 passwords for the various lengths, along with their share of their same-size namespace.</p>


<table>
<thead><tr><th>#</th><th colspan="2">5</th><th colspan="2">6</th><th colspan="2">7</th><th colspan="2">8</th><th colspan="2">9</th><th colspan="2">10</th></tr></thead>
<thead><tr><th></th><th>PSWD</th><th>%</th><th>PSWD</th><th>%</th><th>PSWD</th><th>%</th><th>PSWD</th><th>%</th><th>PSWD</th><th>%</th><th>PSWD</th><th>%</th></tr></thead>
<tbody><tr><td>#1</td><td>12345</td><td>22.802%</td><td>123456</td><td>11.684%</td><td>1234567</td><td>3.440%</td><td>12345678</td><td>11.825%</td><td>123456789</td><td>35.259%</td><td>1234567890</td><td>20.431%</td></tr>
<tr><td>#2</td><td>11111</td><td>4.484%</td><td>123123</td><td>1.370%</td><td>7777777</td><td>1.721%</td><td>11111111</td><td>1.326%</td><td>987654321</td><td>3.661%</td><td>0123456789</td><td>2.323%</td></tr>
<tr><td>#3</td><td>55555</td><td>1.769%</td><td>111111</td><td>1.296%</td><td>1111111</td><td>0.637%</td><td>88888888</td><td>0.959%</td><td>123123123</td><td>1.587%</td><td>0987654321</td><td>2.271%</td></tr>
<tr><td>#4</td><td>00000</td><td>1.258%</td><td>121212</td><td>0.623%</td><td>8675309</td><td>0.465%</td><td>87654321</td><td>0.815%</td><td>789456123</td><td>1.183%</td><td>1111111111</td><td>2.087%</td></tr>
<tr><td>#5</td><td>54321</td><td>1.196%</td><td>123321</td><td>0.591%</td><td>1234321</td><td>0.220%</td><td>00000000</td><td>0.675%</td><td>999999999</td><td>0.825%</td><td>1029384756</td><td>1.293%</td></tr>
<tr><td>#6</td><td>13579</td><td>1.112%</td><td>666666</td><td>0.577%</td><td>0000000</td><td>0.188%</td><td>12341234</td><td>0.569%</td><td>147258369</td><td>0.591%</td><td>9876543210</td><td>0.971%</td></tr>
<tr><td>#7</td><td>77777</td><td>0.618%</td><td>000000</td><td>0.521%</td><td>4830033</td><td>0.158%</td><td>69696969</td><td>0.348%</td><td>741852963</td><td>0.455%</td><td>0000000000</td><td>0.942%</td></tr>
<tr><td>#8</td><td>22222</td><td>0.454%</td><td>654321</td><td>0.506%</td><td>7654321</td><td>0.154%</td><td>12121212</td><td>0.320%</td><td>111111111</td><td>0.425%</td><td>1357924680</td><td>0.479%</td></tr>
<tr><td>#9</td><td>12321</td><td>0.412%</td><td>696969</td><td>0.454%</td><td>5201314</td><td>0.128%</td><td>11223344</td><td>0.293%</td><td>123454321</td><td>0.413%</td><td>1122334455</td><td>0.441%</td></tr>
<tr><td>#10</td><td>99999</td><td>0.397%</td><td>112233</td><td>0.417%</td><td>0123456</td><td>0.124%</td><td>12344321</td><td>0.275%</td><td>123654789</td><td>0.378%</td><td>1234512345</td><td>0.402%</td></tr>
<tr><td>#11</td><td>33333</td><td>0.338%</td><td>159753</td><td>0.283%</td><td>2848048</td><td>0.124%</td><td>77777777</td><td>0.262%</td><td>147852369</td><td>0.356%</td><td>1234554321</td><td>0.380%</td></tr>
<tr><td>#12</td><td>00700</td><td>0.261%</td><td>292513</td><td>0.250%</td><td>7005425</td><td>0.120%</td><td>99999999</td><td>0.223%</td><td>111222333</td><td>0.304%</td><td>5555555555</td><td>0.259%</td></tr>
<tr><td>#13</td><td>90210</td><td>0.244%</td><td>131313</td><td>0.235%</td><td>1080413</td><td>0.111%</td><td>22222222</td><td>0.219%</td><td>963852741</td><td>0.255%</td><td>1212121212</td><td>0.244%</td></tr>
<tr><td>#14</td><td>88888</td><td>0.217%</td><td>123654</td><td>0.228%</td><td>7895123</td><td>0.107%</td><td>55555555</td><td>0.205%</td><td>321654987</td><td>0.253%</td><td>9999999999</td><td>0.231%</td></tr>
<tr><td>#15</td><td>38317</td><td>0.216%</td><td>222222</td><td>0.212%</td><td>1869510</td><td>0.102%</td><td>33333333</td><td>0.176%</td><td>420420420</td><td>0.241%</td><td>2222222222</td><td>0.219%</td></tr>
<tr><td>#16</td><td>09876</td><td>0.185%</td><td>789456</td><td>0.209%</td><td>3223326</td><td>0.100%</td><td>44444444</td><td>0.165%</td><td>007007007</td><td>0.227%</td><td>7777777777</td><td>0.206%</td></tr>
<tr><td>#17</td><td>44444</td><td>0.179%</td><td>999999</td><td>0.194%</td><td>1212123</td><td>0.096%</td><td>66666666</td><td>0.160%</td><td>135792468</td><td>0.164%</td><td>3141592654</td><td>0.195%</td></tr>
<tr><td>#18</td><td>98765</td><td>0.169%</td><td>101010</td><td>0.190%</td><td>1478963</td><td>0.088%</td><td>11112222</td><td>0.140%</td><td>397029049</td><td>0.158%</td><td>3333333333</td><td>0.186%</td></tr>
<tr><td>#19</td><td>01234</td><td>0.160%</td><td>777777</td><td>0.188%</td><td>2222222</td><td>0.085%</td><td>13131313</td><td>0.131%</td><td>012345678</td><td>0.154%</td><td>7894561230</td><td>0.165%</td></tr>
<tr><td>#20</td><td>42069</td><td>0.154%</td><td>007007</td><td>0.186%</td><td>5555555</td><td>0.082%</td><td>10041004</td><td>0.127%</td><td>123698745</td><td>0.152%</td><td>1234567891</td><td>0.161%</td></tr>
</tbody></table>

<h3>Some interesting observations (and a little speculation)</h3>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;For five digit passwords, users appear to have <i>even less</i> imagination in selecting their codes (22.8% select 12345).  All the usual suspects occur, but a new addition is the puerile addition in position #20 of the concatenation of 420 and 69.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;For six digit password, again 696969 appears highly.  Also of note is 159753 (a "X" mark over the numeric keypad).  James Bond returns with 007007.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;For seven digits, the standby of 1234567 is a much lower frequency (though still the top).  I speculate that this is because many people may be using their telephone number (without area code) as a seven digit password.  Telephone numbers are fairly distinct, and already memorized, so when a seven digit code is needed, they spring to mind easily.  The higher frequency of usage of telephone numbers reduces the need to use imagination (or lack thereof) and select something else.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;Is Jenny there?  The fouth most popular seven digit password is <a href="http://en.wikipedia.org/wiki/867-5309/Jenny">8675309</a> (It's a popular 80's song).</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;Eight digit passwords are just as expected.  Lots of pattern, and lots of repetition.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;Common nine digit passwords also follow patterns and repetition. 789456123 appears as an easy <i>"Along the top, middle and bottom of the keypad"</i> 147258369 is related in the vertical direction (and other variants appear high up). Again we get a 420 moment with 420420420, and also the shaken, not stirred, but repeated 007007007 returns.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;Interestingly for ten digits 1029384756 appears (alternating ascending/descending digits), as well as the odd/even 1357924680.</p>
<p><img src="http://www.datagenetics.com/blog/september32012/key.gif">&nbsp;Hurrah for math!  In position #17 of the ten digit password list we get 3141592654 (The first few digits of <i>Pi</i>)</p>

<h2>Conclusions</h2>

<table>
<tbody><tr>
<td><img src="http://www.datagenetics.com/blog/september32012/d.png">
</td>

<td><p>If you are a <span><span color="black">&nbsp;<b>developer</b>&nbsp;</span></span>, <span><span color="black">&nbsp;<b>tester</b>&nbsp;</span></span> or <span><span color="black">&nbsp;<b>executive</b>&nbsp;</span></span>  I hope you are sufficiently paranoid that you will <i>immediately</i> check to see that your systems do not store sensitive information, like passwords, unencrypted.  The entire reason I was able to perform this analysis is because <del>dumb</del> stupid and lazy coders stored information in clear text.  Your lazyness has the potential to impact millions.</p>
<p>If you are a <span><span color="black">&nbsp;<b>consumer</b>&nbsp;</span></span> and your recognize any of the numbers I've used in this article to be your passwords/pins I hope you apply common sense and immediately change them to something a little less predictable.  Alternatively, you could be lazy and not change things (In that case, at least the only person you are harming with this apathy is yourself.)</p>
</td>
</tr>
</tbody></table>

<h2>Updates</h2>
<p>Since publishing this article, it's been brought to my attention that, of course, in addition to anniversary years, many people encapsulate dates in the format MMDD (such as birthdays …) for their PIN codes.</p>
<p>This clearly explains the lower left corner where, if you look at the heatmap, there is a huge contrast change at the height of around 30-31 (the number of days in a month), extending to 12 on the x-axis. (Thanks to <b>zero79</b> for first pointing this out).</p>
<p><img src="http://www.datagenetics.com/blog/september32012/mmdd.png"></p><p>Many people also asked the significance of 1004 in the four character PIN table.  This comes from Korean speakers.  When spoken, "1004" is <i>cheonsa</i> (cheon = 1000, sa=4).</p>
<p>"Cheonsa" also happens to be the Korean word for <i>Angel</i>.</p>


<h2>Another XKCD cartoon</h2>

<p>It only seems appropriate to end with another XKCD cartoon.  This one is <a href="http://xkcd.com/936/">Password Strength</a></p>



<p><img src="http://www.datagenetics.com/blog/september32012/xkcd936.png"></p>

<p>You can find a complete list of all the articles <a href="http://www.datagenetics.com/blog.html">here</a>.<sup><img src="http://www.datagenetics.com/images/n.gif"></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Click <a href="https://datagenetics.com/newsletter/subscribe.html">here</a> to receive email alerts on new articles.</p>






</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The new APT 3.0 solver (131 pts)]]></title>
            <link>https://blog.jak-linux.org/2024/05/14/solver3/</link>
            <guid>40358588</guid>
            <pubDate>Tue, 14 May 2024 18:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jak-linux.org/2024/05/14/solver3/">https://blog.jak-linux.org/2024/05/14/solver3/</a>, See on <a href="https://news.ycombinator.com/item?id=40358588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>APT 2.9.3 introduces the first iteration of the new solver codenamed
solver3, and now available with the –solver 3.0 option. The new solver
works fundamentally different from the old one.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>Solver3 is a fully backtracking dependency solving algorithm that defers
choices to as late as possible. It starts with an empty set of packages,
then adds the manually installed packages, and then installs packages
automatically as necessary to satisfy the dependencies.</p>
<p>Deferring the choices is implemented multiple ways:</p>
<p>First, all install requests
recursively mark dependencies with a single solution for install, and any
packages that are being rejected due to conflicts or user requests will
cause their reverse dependencies to be transitively marked as rejected,
provided their or group cannot be solved by a different package.</p>
<p>Second, any dependency with more than one choice is pushed to a priority
queue that is ordered by the number of possible solutions, such that we
resolve a|b before a|b|c.</p>
<p>Not <em>just</em> by the number of solutions, though. One important point to
note is that optional dependencies, that is, Recommends, are always
sorting after mandatory dependencies. Do note on that: Recommended
packages do not “nest” in backtracking - dependencies of a Recommended
package themselves are not optional, so they will have to be resolved
before the next Recommended package is seen in the queue.</p>
<p>Another important step in deferring choices is extracting the common
dependencies of a package across its version and then installing them
before we even decide which of its versions we want to install - one
of the dependencies might cycle back to a specific version after all.</p>
<p>Decisions about package levels are recorded at a certain decision level,
if we reach a conflict we backtrack to the previous decision level,
mark the decision we made (install X) in the inverse (DO NOT INSTALL X),
reset all the state all decisions made at the higher level, and restore
any dependencies that are no longer resolved to the work queue.</p>
<h2 id="comparison-to-sat-solver-design">Comparison to SAT solver design.</h2>
<p>If you have studied SAT solver design, you’ll find that essentially
this is a DPLL solver without pure literal elimination. A pure literal
eliminitation phase would not work for a package manager: First negative
pure literals (packages that everything conflicts with) do not exist,
and positive pure literals (packages nothing conflicts with) we do not want
to mark for install - we want to install as little as possible (well subject,
to policy).</p>
<p>As part of the solving phase, we also construct an implication graph, albeit
a partial one: The first package installing another package is marked as the
reason (A -&gt; B), the same thing for conflicts (not A -&gt; not B).</p>
<p>Once we have added the ability to have multiple parents in the implication
graph, it stands to reason that we can also implement the much more advanced
method of conflict-driven clause learning; where we do not jump back to the
previous decision level but exactly to the decision level that caused the
conflict. This would massively speed up backtracking.</p>
<h2 id="what-changes-can-you-expect-in-behavior">What changes can you expect in behavior?</h2>
<p>The most striking difference to the classic APT solver is that solver3 always keeps
manually installed packages around, it never offers to remove them. We will relax that
in a future iteration so that it can <em>replace</em> packages with new ones, that is, if your
package is no longer available in the repository (obsolete), but there is one that
Conflicts+Replaces+Provides it, solver3 will be allowed to install that and remove the
other.</p>
<p>Implementing that policy is rather trivial: We just need to queue <code>obsolete | replacement</code>
as a dependency to solve, rather than mark the obsolete package for install.</p>
<p>Another critical difference is the change in the autoremove behavior: The new solver
currently only knows the strongest dependency chain to each package, and hence it will
not keep around any packages that are only reachable via weaker chains.
A common example is when <code>gcc-&lt;version&gt;</code> packages accumulate on your system over the
years. They all have <code>Provides: c-compiler</code> and the <code>libtool</code> <code>Depends: gcc | c-compiler</code>
is enough to keep them around.</p>
<h2 id="new-features">New features</h2>
<p>The new option <code>--no-strict-pinning</code> instructs the solver to consider all versions of
a package and not just the candidate version. For example, you could use <code>apt install foo=2.0 --no-strict-pinning</code>
to install version 2.0 of foo and upgrade - or downgrade - packages as needed to satisfy <code>foo=2.0</code> dependencies.
This mostly comes in handy in use cases involving Debian experimental or the Ubuntu proposed pockets, where you
want to install a package from there, but try to satisfy from the normal release as much as possible.</p>
<p>The implication graph building allows us to implement an <code>apt why</code> command, that while not as nicely
detailed as aptitude, at least tells you the exact reason why a package is installed. It will only show
the strongest dependency chain at first of course, since that is what we record.</p>
<h2 id="what-is-left-to-do">What is left to do?</h2>
<p>At the moment, error information is not stored across backtracking in any way, but we generally
will want to show you the first conflict we reach as it is the most natural one; or all conflicts.
Currently you get the last conflict which may not be particularly useful.</p>
<p>Likewise, errors currently are just rendered as implication graphs of the form <code>[not] A -&gt; [not] B -&gt; ...</code>,
and we need to put in some work to present those nicely.</p>
<p>The test suite is not passing yet, I haven’t really started working on it. A challenge is that most
packages in the test suite are manually installed as they are mocked, and the solver now doesn’t remove
those.</p>
<p>We plan to implement the replacement logic such that foo can be replaced by <code>foo2 Conflicts/Replaces/Provides foo</code>
without needing to be automatically installed.</p>
<p>Improving the backtracking to be non-chronological conflict-driven clause learning would vastly
enhance our backtracking performance. Not that it seems to be an issue right now in my limited
testing (mostly noble 64-bit-time_t upgrades). A lot of that complexity you have normally is not
there because the manually installed packages and resulting unit propagation (single-solution
Depends/Reverse-Depends for Conflicts) already ground us fairly far in what changes we can actually make.</p>
<p>Once all the stuff has landed, we need to start rolling it out and gather feedback. On Ubuntu I’d like
automated feedback on regressions (running solver3 in parallel, checking if result is worse and then
submitting an error to the error tracker), on Debian this could just be a role email address to send
solver dumps to.</p>
<p>At the same time, we can also incrementally start rolling this out. Like phased updates in Ubuntu,
we can also roll out the new solver as the default to 10%, 20%, 50% of users before going to the
full 100%. This will allow us to capture regressions early and fix them.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PaliGemma (103 pts)]]></title>
            <link>https://ai.google.dev/gemma/docs/paligemma</link>
            <guid>40358461</guid>
            <pubDate>Tue, 14 May 2024 18:30:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.google.dev/gemma/docs/paligemma">https://ai.google.dev/gemma/docs/paligemma</a>, See on <a href="https://news.ycombinator.com/item?id=40358461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  
    
  <div header-position="top">

    
      
      <header>

        

        
        
        

        
      </header>
      

      

        <div description-position="bottom">
        

        

        
          <div>
             <p>
  PaliGemma is a lightweight open <i>vision-language model</i> (VLM) inspired by
  <a href="https://arxiv.org/abs/2310.09199">PaLI-3</a>,
  and based on open components like the <a href="https://arxiv.org/abs/2303.15343">SigLIP
  vision model</a> and the <a href="https://arxiv.org/abs/2403.08295">Gemma language
  model</a>. PaliGemma takes both images and text as inputs and can answer questions about
  images with detail and context, meaning that PaliGemma can perform deeper analysis of
  images and provide useful insights, such as captioning for images and short videos,
  object detection, and reading text embedded within images.
</p> <p>
  There are two sets of PaliGemma models, a general purpose set and a research-oriented set:
  </p><ul>
    <li>
      <a href="https://www.kaggle.com/models/google/paligemma">PaliGemma</a> -
      General purpose pretrained models that can be fine-tuned on a variety of tasks.
    </li>
    <li>
      <a href="https://www.kaggle.com/models/google/paligemma-ft">PaliGemma-FT</a> -
        Research-oriented models that are fine-tuned on specific research datasets.
    </li>
  </ul>
  <p>
  Key benefits include:
</p>

          </div>
        

        
          <ul>
            
              <li>
  

  <div icon-position="left">
      
    <h4 id="multimodal-comprehension" data-text="Multimodal comprehension" tabindex="0">
      
    
        Multimodal comprehension
      
  
    </h4>
  

      
        <p>
          Simultaneously understands both images and text.

        </p>
      

      
    </div>

  
</li>
            
              <li>
  

  <div icon-position="left">
      
    <h4 id="versatile-base-model" data-text="Versatile base model" tabindex="0">
      
    
        Versatile base model
      
  
    </h4>
  

      
        <p>
          Can be fine-tuned on a wide range of vision-language tasks.

        </p>
      

      
    </div>

  
</li>
            
              <li>
  

  <div icon-position="left">
      
    <h4 id="off-the-shelf-exploration" data-text="Off-the-shelf exploration" tabindex="0">
      
    
        Off-the-shelf exploration
      
  
    </h4>
  

      
        <p>
          Comes with a checkpoint fine-tuned on on a mixture of tasks for immediate research use.

        </p>
      

      
    </div>

  
</li>
            
          </ul>
        

        
      </div>
      

    
    </div>

  <div header-position="top">

    
      
      <header>

        

        
        <p>

          
    <h2 id="learn-more" data-text="Learn more" tabindex="0">
      
    
        Learn more
      
  
    </h2>
  

          
        </p>
        

        
      </header>
      

      

        <div>
        
          <div description-position="bottom">
        

        
    <h3 id="view-the-model-card" data-text="View the model card" tabindex="0">
      
  <a href="https://ai.google.dev/gemma/docs/paligemma/model-card">
    
        View the model card
      
  </a>
  
    </h3>
  

        
          <p>
            PaliGemma's model card contains detailed information about the model, implementation information, evaluation information, model usage and limitations, and more.

          </p>
        

        

        
      </div>
        
          <div description-position="bottom">
        

        
    <h3 id="view-on-kaggle" data-text="View on Kaggle" tabindex="0">
      
  <a href="https://www.kaggle.com/models/google/paligemma">
    
        View on Kaggle
      
  </a>
  
    </h3>
  

        
          <p>
            View more code, Colab notebooks, information, and discussions about PaliGemma on Kaggle.

          </p>
        

        

        
      </div>
        
          <div description-position="bottom">
        

        
    <h3 id="run-in-colab" data-text="Run in Colab" tabindex="0">
      
  <a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma">
    
        Run in Colab
      
  </a>
  
    </h3>
  

        
          <p>
            Run a working example for fine-tuning PaliGemma with JAX in Colab.

          </p>
        

        

        
      </div>
        
        </div>
      

    
    </div>

  

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Glider – open-source eInk monitor with an emphasis on low latency (416 pts)]]></title>
            <link>https://github.com/Modos-Labs/Glider</link>
            <guid>40358309</guid>
            <pubDate>Tue, 14 May 2024 18:19:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Modos-Labs/Glider">https://github.com/Modos-Labs/Glider</a>, See on <a href="https://news.ycombinator.com/item?id=40358309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Glider</h2><a id="user-content-glider" aria-label="Permalink: Glider" href="#glider"></a></p>
<p dir="auto">Open source Eink monitor with an emphasis on low latency.</p>
<p dir="auto">Note: This repo only contains the hardware design, the gateware running on the FPGA is my open-source <a href="https://gitlab.com/zephray/Caster/" rel="nofollow">Caster EPDC</a> design. This README also contains information about the Caster as well.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/glider_overall_block_diagram.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/glider_overall_block_diagram.svg" alt="Overall Blockdiagram"></a></p>
<p dir="auto">This is a long document, containing not just information about this project, but also pretty much everything I know about Eink. Given it's a bit hard to gather information about Eink online, I think this is the right thing to do. Use the following table of contents to navigate around.</p>
<p dir="auto">Eink is a registered trademark and brand of E Ink Corporation. All the contents provided in this repo are based on publicly available information online and original research. They are not endorsed by Eink in anyway and they may contain errors and/ or inaccurarcies.</p>
<p dir="auto">If you are interested in Eink or any other display technogies, I have a Discord server for that. Feel free to join: <a href="https://discord.gg/rtT7euSHQS" rel="nofollow">https://discord.gg/rtT7euSHQS</a> . (This Discord server is also not endorsed by Eink or any other company. It's not a customer support server.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#hardware">Hardware</a></li>
<li><a href="#components">Components</a></li>
</ul>
</li>
<li><a href="#eink-screens">Eink Screens</a>
<ul dir="auto">
<li><a href="#basic-theory-of-operation">Basic Theory of Operation</a></li>
<li><a href="#advantages-and-disadvantages">Advantages and Disadvantages</a></li>
<li><a href="#the-role-of-eink-controller">The Role of Eink Controller</a></li>
<li><a href="#screen-panel-types">Screen Panel Types</a></li>
<li><a href="#using-screen-with-integrated-controller">Using Screen with Integrated Controller</a></li>
<li><a href="#using-screen-without-integrated-controller">Using Screen without Integrated Controller</a></li>
<li><a href="#understanding-waveform">Understanding Waveform</a></li>
<li><a href="#greyscale-display">Greyscale Display</a></li>
<li><a href="#color-display">Color Display</a></li>
<li><a href="#dithering">Dithering</a></li>
<li><a href="#eink-screen-generations">Eink Screen Generations</a></li>
</ul>
</li>
<li><a href="#design-of-caster-and-glider">Caster/ Glider Design</a>
<ul dir="auto">
<li><a href="#low-latency-drive">Low Latency Drive</a></li>
<li><a href="#hybrid-greyscale-mode">Hybrid Greyscale Mode</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="https://github.com/Modos-Labs/Glider/blob/main">Hardware Design Decisions</a></li>
<li><a href="#gateware-architecture">Gateware Architecture</a></li>
<li><a href="#firmware-functions">Firmware Functions</a></li>
<li><a href="#resources-utilization">Resources Utilization</a></li>
</ul>
</li>
<li><a href="#building">Building</a>
<ul dir="auto">
<li><a href="#pcb">PCB</a></li>
<li><a href="#fpga-bitstream">FPGA Bitstream</a></li>
<li><a href="#mcu-firmware">MCU Firmware</a></li>
<li><a href="#working-with-waveforms">Working with Waveforms</a></li>
<li><a href="#compatible-screens">Compatible Screens</a></li>
</ul>
</li>
<li><a href="#references">References</a></li>
<li><a href="#license">License</a></li>
<li><a href="#appendix">Appendix</a>
<ul dir="auto">
<li><a href="#using-screens-without-datasheet">Using Screens without Datasheet</a></li>
<li><a href="#screen-list">Screen List</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Complete solution for low-latency/ high-refresh-rate EPD monitor</li>
<li>Supports electrophoretics display panels with parallel I/F (Eink(R), SiPix and DES)</li>
<li>Supports both monochrome and color-filter-array (such as Kaleido(TM)) based color screen</li>
<li>Extremely low processing delay of &lt;20 us</li>
<li>Supports binary, 4-level grayscale, and 16-level grayscale output modes</li>
<li>Latency optimized binary and 4-level grayscale driving modes</li>
<li>Hybrid automatic binary and 16-level grayscale driving mode</li>
<li>Host software runtime controllable regional update and mode switching</li>
<li>Hardware bayer dithering, blue-noise dithering, and error-diffusion dithering with no additional latency</li>
<li>Controller natively supports FPD-Link (LVDS), DVI (TMDS), and MIPI-DSI input</li>
<li>Board level design supports USB-C (USB Type-C DisplayPort Alt Mode) and DVI input</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware</h3><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/r0p7_mb.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/r0p7_mb.jpg" alt="r0p7_mb"></a></p>
<ul dir="auto">
<li>Xilinx(R) Spartan-6 LX16 FPGA running Caster</li>
<li>DDR3-800 framebuffer memory</li>
<li>Type-C DisplayPort Alt-Mode video input with on-board PTN3460 DP-LVDS bridge or</li>
<li>DVI (via microHDMI connector) video input with on-board ADV7611 decoder</li>
<li>Epaper power supply with up to 1A peak current on +/-15V rail supporting large panels</li>
<li>VCOM kick-back voltage measurement support</li>
<li>On-board RaspberryPi(R) RP2040 microcontroller for USB communication and firmware upgrade</li>
<li>Up to 133MP/s processing rate with dithering enabled, &gt;200MP/s when disabled</li>
</ul>
<p dir="auto">The board is designed with KiCad. You may need the latest stable version of KiCad to open the source file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Components</h3><a id="user-content-components" aria-label="Permalink: Components" href="#components"></a></p>
<p dir="auto">This repo hosts the PCB design, firmware source code, and a reference 3D-printable case design. The RTL code is in a seperate repo: <a href="https://gitlab.com/zephray/Caster/" rel="nofollow">https://gitlab.com/zephray/Caster/</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Eink Screens</h2><a id="user-content-eink-screens" aria-label="Permalink: Eink Screens" href="#eink-screens"></a></p>
<p dir="auto">Eink is the brand of a family of paper-like electrophoretic displays. The underlying technology is invented in the MIT Media Lab between 1995 and 1997 by Barrett Comiskey, J.D. Albert, and Joseph Jacobson. They later founded the E Ink Corporation to commercialize this technology.</p>
<p dir="auto">Nowadays they are commonly used on e-readers and electronic shelf labels. You’ve probably seen them on Kindle, or in stores, or maybe in some train stations as well.</p>
<table>
<thead>
<tr>
<th>eReader/ Tablets</th>
<th>Electronic Shelf Label</th>
<th>Digital Signage</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/app_ereader.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/app_ereader.jpg" alt="app_ereader"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/app_esl.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/app_esl.jpg" alt="app_esl"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/app_signage.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/app_signage.jpg" alt="app_signage"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">(Source: <a href="https://www.eink.com/application" rel="nofollow">https://www.eink.com/application</a>, image copyright Eink corporation)</p>
<p dir="auto">This section gives an overview of the electrophoretics displays, including the screen panels available and underlying technology. Note this project obviously doesn't and can't support all electrophoretic screens. This documentation also solely focuses on using existing off-the-shelf screen panels rather than the physics or manufacturing process of one.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Theory of Operation</h3><a id="user-content-basic-theory-of-operation" aria-label="Permalink: Basic Theory of Operation" href="#basic-theory-of-operation"></a></p>
<p dir="auto">In the simplest form, you have charged particles with different colors, dispersed in some oil in some transparent container. By applying electric fields the particles can be moved up or down to produce either black or white, or a mixture of that.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/eink_carta.gif"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/eink_carta.gif" alt="eink-particle" data-animated-image=""></a></p>
<p dir="auto">(Source: <a href="https://www.eink.com/tech/detail/How_it_works" rel="nofollow">https://www.eink.com/tech/detail/How_it_works</a> , copyright Eink Corporation)</p>
<p dir="auto">There are multiple technologies based on this basic concept, namely Eink’s micro-capsule display, SiPix (now acquired by Eink)’s micro-cup display, and WFT’s DES display. They differs in specifics ways of confining the particles in containers, but otherwise very similar.</p>
<p dir="auto">The pixels on the screen are typically arranged as a 2D array, driven with TFTs. The pixels are scanned/ driven periodically at a fixed refresh rate, typically ranging from 50Hz to 120Hz. Applying positive voltage on the pixel will typically drive the particles towards the white state, while applying negative voltage will drive the particles towards the black state. This is similar to active matrix TN/IPS LCDs, which also uses 2D TFT arrays and uses electrical fields for changing state. However unlike LCDs, EPDs maintain their state after the electrical field is removed. So unlike LCDs which require continuously refreshing, the EPDs only need to be refreshed till the pixels are fully driven.</p>
<p dir="auto">In terms of driving the screen panel, depending on the pixel value (1 or 0), each pixel would be driven either with a positive voltage or a negative voltage. A global counter can be used to count the frames elapsed, and stop driving the pixels after a predefined period of time (for example, 100ms). Two framebuffers are typically used for determining if the pixel has changed color or not. If not, then the pixel does not need to be driven.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advantages and Disadvantages</h3><a id="user-content-advantages-and-disadvantages" aria-label="Permalink: Advantages and Disadvantages" href="#advantages-and-disadvantages"></a></p>
<p dir="auto">In terms of display quality, EPDs are no match for modern IPS LCDs. The following is a comparison table of key parameterics. Specific number would vary depending on the screen used, but should be within the same ballpack.</p>
<table>
<thead>
<tr>
<th></th>
<th>Monochrome EPD</th>
<th>CFA-based Color EPD</th>
<th>Transmissive TFT IPS LCD</th>
<th>Reflective TFT TN LCD</th>
</tr>
</thead>
<tbody>
<tr>
<td>Contrast Ratio</td>
<td>~17:1</td>
<td>~14:1</td>
<td>~1000:1</td>
<td>~14:1</td>
</tr>
<tr>
<td>Colors</td>
<td>16 (Greyscale)</td>
<td>4096</td>
<td>16M</td>
<td>256</td>
</tr>
<tr>
<td>Color Gamut</td>
<td>N/A</td>
<td>~1.5% sRGB</td>
<td>~99.9% sRGB</td>
<td>N/A</td>
</tr>
<tr>
<td>Reflectivity</td>
<td>~45%</td>
<td>~25%</td>
<td>N/A</td>
<td>~15%</td>
</tr>
<tr>
<td>Response Time</td>
<td>~150ms</td>
<td>~150ms</td>
<td>~10ms</td>
<td>~15ms</td>
</tr>
</tbody>
</table>
<p dir="auto">It has a few advantages. It reflect lights instead of emitting lights, so it generally consumes less power and can be used outdoors, etc. It’s also bistable, means that it retains the image after the power has been removed. Personally, the biggest differentiating factor for me (author of this README) is that it looks like paper.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/rlcd_eink.gif"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/rlcd_eink.gif" alt="rlcd-vs-eink" data-animated-image=""></a></p>
<p dir="auto">The image above shows a comparison between reflective TFT LCD (SHARP memory LCD in this case) and Eink. The LCD has a mirror-like texture which changes reflectivity drastically in different angles, while the Eink is more paper-like.</p>
<table>
<thead>
<tr>
<th>ZBD LCD</th>
<th>Ch LCD</th>
<th>STN LCD</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/zbdlcd.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/zbdlcd.jpg" alt="zbd"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/chlcd.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/chlcd.jpg" alt="chlcd"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/stnlcd.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/stnlcd.jpg" alt="stnlcd"></a></td>
</tr>
<tr>
<td>Bistable, reflective, high contrast, no greyscale, ~10s refresh</td>
<td>Bistable, reflective, lower contrast, up to 32 level greyscale, ~5s refresh</td>
<td>Volatile, reflective, lower contrast, up to 32 level greyscale, ~100ms response</td>
</tr>
</tbody>
</table>
<p dir="auto">There are many other reflective or bistable display technologies. They are all interesting displays on their own, but none of them feels like paper (yet).</p>
<p dir="auto">Overally, there is no single perfect display technology. Each has its own unique strength. Pick the right one for your project.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Role of Eink Controller</h3><a id="user-content-the-role-of-eink-controller" aria-label="Permalink: The Role of Eink Controller" href="#the-role-of-eink-controller"></a></p>
<p dir="auto">The Eink controller is in some ways similar to the display controller (DC/ CRTC) + timing controller (TCON) in a typical LCD based system. It takes the raw image data and convert it to signals required to drive the screen.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/eink_controller.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/eink_controller.svg" alt="eink-controller"></a></p>
<p dir="auto">To understand the actual work of an eink controller, start from the basic concept. The color of a pixel can be changed by applying positive or negative voltage for a finite period of time. From the controller’s perspective, depending on the current state of the pixel and the desired state of the pixel, there are 4 possibilities.</p>
<table>
<thead>
<tr>
<th>Current State</th>
<th>Target State</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>Black</td>
<td>Black</td>
<td>No operation</td>
</tr>
<tr>
<td>Black</td>
<td>White</td>
<td>Apply positive voltage</td>
</tr>
<tr>
<td>White</td>
<td>Black</td>
<td>Apply negative voltage</td>
</tr>
<tr>
<td>White</td>
<td>White</td>
<td>No operation</td>
</tr>
</tbody>
</table>
<p dir="auto">The controller need to store and maintain the screen state inside of its own buffer memory, so it would typically have a large on-chip SRAM or an off-chip SDRAM controller. The controller should also have a timer to ensure the screen doesn't get overdriven or underdriven.</p>
<p dir="auto">Controller often use the so-called "<a href="#understanding-waveform">waveform</a>" to replace the action colume of the previous table. Instead of hardcoding the action for state transition, the actions are stored into a look-up-table (LUT) which can be modified at runtime to allow higher flexibility.</p>
<p dir="auto">Controllers may also offer more advanced features such as <a href="#dithering">dithering</a> acceleration, multiple region update, automatic LUT selection, etc.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Screen Panel Types</h3><a id="user-content-screen-panel-types" aria-label="Permalink: Screen Panel Types" href="#screen-panel-types"></a></p>
<p dir="auto">As discussed in the previous section, an Eink screen need to be coupled to an Eink controller to function. Aside from that, screen also needs high voltage drivers to drive the TFTs and the pixels. Virtually all E-paper panels use either COG (Chip-on-Glass) or TAB (Tape Auto Bonding) to integrate some chips onto the screen panel itself. Most of the screens available today can be divided into two categories based on whether or not the controller is integrated in:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/screen_types.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/screen_types.svg" alt="screen-types"></a></p>
<p dir="auto">Here is a non-exhaustive list of the type based on their size: (the size or resolution is not related to or limited by the type, it is just for a certain size, the vendors tend to make them the same type.)</p>
<ul dir="auto">
<li>Screens without controller: 4.3", 6.0", 7.8", 8.0", 9.7", 10.3", 13.3", 25.3", 31.2", 42"</li>
<li>Screens with controller: 1.02", 1.54", 2.13", 2.6", 2.9", 3.71", 4.2", 5.65", 5.83", 7.5", 12.48"</li>
</ul>
<p dir="auto">One may notice that almost all e-readers/ e-ink cellphones use screens without controller, while almost all e-ink electronic shelf labels (ESL) use screens with controller. This gives some hints about the advantages and disadvantages of two types:</p>
<table>
<thead>
<tr>
<th></th>
<th>Without Controller</th>
<th>With Controller</th>
</tr>
</thead>
<tbody>
<tr>
<td>System Cost</td>
<td>High. A dedicated controller or SoC with integrated contoller is usually required. Needs a dedicated power supply.</td>
<td>Low. Virtually any MCUs could drive the screen directly, and the power supply is integrated in.</td>
</tr>
<tr>
<td>Greyscale Levels</td>
<td>Generally 16 (4bpp), up to 32 (5bpp)</td>
<td>Generally 2 (BW only) or 4 (2bpp), with some hack, up to 16 (4bpp)</td>
</tr>
<tr>
<td>Refresh Speed</td>
<td>Generally fast (100ms~300ms) for BW. Depends on the screen used and the system architecture</td>
<td>Generally fast (100ms~300ms) for BW if the partial refresh is enabled. Greyscales much slower, BWR or BWY screens would be even slower.</td>
</tr>
<tr>
<td>Total Update Latency</td>
<td>Generally the same as refresh time. Depends on the system architecture</td>
<td>Slow. Ranging from 100ms to several seconds based on the resolution.</td>
</tr>
</tbody>
</table>
<p dir="auto">Please keep in mind the discussion is about off-the-shelf screens you can buy today. These tradeoffs do not necessarily come from the fact the controller is integrated or not.</p>
<p dir="auto">Note that I mentioned the refresh speed and total update latency. They are different:</p>
<p dir="auto">The refresh speed refers to the time it takes to start refreshing the screen: from starting seeing screen changing, to the screen finish showing the new content.</p>
<p dir="auto">The total update latency refers to the latency when the processor needs to update the screen, to the screen finish showing the new content. As you could see, this is the biggest issue for screens with controllers. This is the main reason why they are almost never used on e-readers or cellphones or PC monitors.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/screen_cntlr.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/screen_cntlr.svg" alt="screen-controller-diagram"></a></p>
<p dir="auto">This diagram illustrates the difference between two. It should be noted that the screens without controller have the flexibility to be driven quickly, but the system designer might not architect the system for low latency.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Screen with Integrated Controller</h3><a id="user-content-using-screen-with-integrated-controller" aria-label="Permalink: Using Screen with Integrated Controller" href="#using-screen-with-integrated-controller"></a></p>
<p dir="auto">Screens with integrated controller have almost everything already integrated. Common display panels in this type only need few external capacitors, inductors, and MOSFETs to support the integrated bipolar power supply circuit, then it could be hooked up to MCUs or MPUs using common interfaces like SPI or I2C. There are a lot of driving boards and examples of these screens available online.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Screen without Integrated Controller</h3><a id="user-content-using-screen-without-integrated-controller" aria-label="Permalink: Using Screen without Integrated Controller" href="#using-screen-without-integrated-controller"></a></p>
<p dir="auto">This could get complicated. Note I used a lot of "generally" in the previous comparison table because there are many things one could do to drive them. Some of them would certainly impact the performance. The main issue here the controller chip. There are three solutions to drive these screen:</p>
<ul dir="auto">
<li>Using a dedicated controller chip to drive the screen</li>
<li>Using an SoC that has an integrated controller</li>
<li>Using a fast MCU/SoC to emulate the controller with GPIO (software timing controller)</li>
</ul>
<p dir="auto">Then, again here is a comparison between them:</p>
<table>
<thead>
<tr>
<th></th>
<th>Specialized controller chip</th>
<th>SoC with integrated controller</th>
<th>MCU + Software TCON</th>
</tr>
</thead>
<tbody>
<tr>
<td>Resolution</td>
<td>UXGA+</td>
<td>UXGA+</td>
<td>Limited by MCU RAM. Up to XGA with SRAM, UXGA with PSRAM, UXGA+ with DDR</td>
</tr>
<tr>
<td>Greyscale</td>
<td>Up to 32</td>
<td>Up to 32</td>
<td>Up to 32</td>
</tr>
<tr>
<td>Partial Update</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Total Update Latency</td>
<td>Depends. Could be very close as refresh speed, could be slow like screens with controller</td>
<td>Same as refresh speed</td>
<td>Same as refresh speed if data is internally generated (not streaming from an external device such as a PC)</td>
</tr>
<tr>
<td>Suitable Applications</td>
<td>IoT devices, E-readers, cellphones, E-ink monitors. possibly E-ink laptops</td>
<td>Advanced IoT devices, E-readers, cellphones, E-ink typewriters, possibly lower performance E-ink laptops</td>
<td>When using MCU: IoT devices, large ESLs, simple DIY E-readers. When using MPU: Same as SoC with integrated controller</td>
</tr>
</tbody>
</table>
<p dir="auto">When using a dedicated controller, it could accept data from external devices. This allows it to be used in various different types of applications. Ranging from IoT devices, ESLs, to PC monitors with relatively fast refresh rate and low latency.</p>
<p dir="auto">When using SoC or MCU, the display content is generated by the SoC or MCU itself, which ultimately is limited by the capability of the SoC or MCU. Given the current SoCs with E-ink display controllers are usually limited in performance, the application is limited. The same goes for MCU, it does what an MCU could do. You could find ways to stream video data into SoC or MCUs by using USB, camera interface, WiFi, etc., but this might not be optimal.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Existing Solutions</h4><a id="user-content-existing-solutions" aria-label="Permalink: Existing Solutions" href="#existing-solutions"></a></p>
<ul dir="auto">
<li>Specialized controller chip
<ul dir="auto">
<li>Closed-source
<ul dir="auto">
<li>EPSON S1D13xxx: Widely used EPD controller in early E-readers. Proprietary, no documents available. Probably EOL.</li>
<li>IT8951: Used on waveshare EPD Hat. Documents available, works with large EPDs up to 2048x2048. The drawback is the speed as the interface between processor and IT8951 could be slow. This is similar to the situation on screens with integrated controller</li>
<li>T1000: Also known as IT8957, upgraded model of IT8951. It supports even higher resolution. It features higher speed MIPI DSI interface to mitigate the slow speed of IT8951.</li>
<li>Waveshare HDMI driver board: FPGA-based controller. Closed source but easily purchasable, could be integrated into larger projects as a module.</li>
</ul>
</li>
<li>Open-source
<ul dir="auto">
<li>This project (Caster + Glider): FPGA-based controller, multiple update modes, ultra low latency processing, wide range of screen support.</li>
<li><a href="https://hackaday.io/project/21607-paperback-a-desktop-epaper-monitor" rel="nofollow">https://hackaday.io/project/21607-paperback-a-desktop-epaper-monitor</a>: FPGA-based controller. However, doesn't support partial update mode and slower speed.</li>
<li><a href="https://hackaday.io/project/21168-fpga-eink-controller" rel="nofollow">https://hackaday.io/project/21168-fpga-eink-controller</a>: FPGA-based controller, supports vendor waveform with reasonable speed.</li>
</ul>
</li>
</ul>
</li>
<li>SoC with integrated controller
<ul dir="auto">
<li>RK29xx: Fairly old, Cortex-A8 based (RPi 1 level performance), 55nm, EOL</li>
<li>RK3026/RK3028: Fairly old, Cortex-A9 based (RPi 2 level performance), 40nm, EOL</li>
<li>i.MX 50: Fairly old, Cortex-A8 based (RPi 1 level performance), 65nm, in production</li>
<li>i.MX 6ULL: Cortex-A7 based (RPi 1 level performance), 40nm, in production</li>
<li>i.MX 6S/D: Fairly old, Cortex-A9 based (RPi 2-3 level performance), 40nm, in production</li>
<li>i.MX 7S/D: Cortex-A7 based (RPi 2 level performance), 28nm, in production</li>
<li>i.MX 8ULP: Cortex-A35 based (RPi 2 level performance), 28nm FD-SOI, in production</li>
<li>AW B200: Cortex-A53 based (RPi 2 level performance), 28nm, in production</li>
<li>MT8113: Cortex-A53 based (RPi 2 level performance), 12nm, in production</li>
<li>RK3566/RK3568: Cortex-A55 based (RPi 3 level performance), 22nm, in production</li>
<li>RK3576: Cortex-A72 + A53 based (RPi 4-5 level performance), 8nm, in production</li>
</ul>
</li>
<li>MCU/SoC + Software TCON
<ul dir="auto">
<li><a href="http://essentialscrap.com/eink/waveforms.html" rel="nofollow">http://essentialscrap.com/eink/waveforms.html</a>: One of the earliest e-ink hack. Limited in performance but still could be used as a reference</li>
<li>NekoCal: One of the earliest e-ink software TCON with greyscale support. Used to be available as a DIY kit. No longer updated, still could be used as a reference</li>
<li>InkPlate 6/10: Commercially available. Based on ESP32.</li>
<li>EPDiy: Based on ESP32, supports a lot of different screens, recommended if want to build some device with ESP32+Eink or embedding it into a larger project.</li>
</ul>
</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Interface Signals and Timing</h4><a id="user-content-interface-signals-and-timing" aria-label="Permalink: Interface Signals and Timing" href="#interface-signals-and-timing"></a></p>
<p dir="auto">The interface signals and timing are fairly similar to LCDs without controller. Following is the list of signals typically found on EPDs:</p>
<ul dir="auto">
<li>GDOE/ MODE: Gate driver output enable</li>
<li>GDCLK/ CKV: Gate driver clock (like HSYNC in LCD)</li>
<li>GDSP/ SPV: Gate driver start pulse (like VSYNC in LCD)</li>
<li>SDCLK/ XCL: Source driver clock (like PCLK in LCD)</li>
<li>SDLE/ XLE: Source driver latch enable (like HSYNC in LCD)</li>
<li>SDOE/ XOE: Source driver output enable</li>
<li>SDCE/ XSTL: Source driver start pulse (like DE in LCD)</li>
<li>SD: Source driver data (8-bit or 16-bit)</li>
</ul>
<p dir="auto">SD signals goes into the source driver, typically the X direction. GD signals goes into the gate driver, typically the Y direction. It's a 2D array, gate driver selects one line at a time, and the source driver output the voltage for all the pixels in that line.</p>
<p dir="auto">Conceptually, it's like raster scan on a CRT. To send one field of data, both GD and SD are reset to the start position by using the start pulse signal. Data are then transmitted into the source driver 4 or 8 pixel at a time. Once the line has been fully transmitted, the source driver is reset to the beginning position by start pulse signal, and the gate driver moves to the next line by a pulse on the gate driver clock. Once all lines have been scanned, the entire process repeats for the next field.</p>
<p dir="auto">One notable difference with LCD is that each pixel is represented by 2 bits. This, however, doesn't mean each pixel is 2bpp or 4-level greyscale. The 2-bit per pixel is used to encode the voltage applied to the pixel:</p>
<ul dir="auto">
<li>00: No voltage</li>
<li>01: Negative voltage</li>
<li>10: Positive voltage</li>
<li>11: No voltage</li>
</ul>
<p dir="auto">Just like CRT/ LCD, ther are also blanking periods in the entire timing (means it's just waiting without active pixel data being sent). They have identical meaning to CRT/ LCD systems:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/display-timings.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/display-timings.png" alt="display-timings"></a></p>
<p dir="auto">(Source: <a href="https://projectf.io/posts/video-timings-vga-720p-1080p/" rel="nofollow">https://projectf.io/posts/video-timings-vga-720p-1080p/</a>, Copyright Will Green)</p>
<p dir="auto">The following is a piece of pseudo-code implementing the Eink timing:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#define DATA_BUS_WIDTH      8 // 8bit wide bus
#define PIXEL_PER_CYCLE     (DATA_BUS_WIDTH / 2)
#define VFP     12  // Vertical front porch
#define VSYNC   1   // Vertical sync length
#define VBP     2   // Vertical back porch
#define VACT    758 // Vertical active lines
#define HFP     72  // Horizontal front porch
#define HSYNC   2   // Horizontal sync length
#define HBP     2   // Horizontal back porch
#define HACT    (1024 / PIXEL_PER_CYCLE)

void pulse_h_clock() {
    sdclk = 1;
    sdclk = 0;
}

void drive_line(bool v_in_act) {
    sdce = 1;
    gdclk = 0;
    for (int i = 0; i < HFP; i++) pulse_h_clock();
    sdle = 1;
    gdclk = 1;
    for (int i = 0; i < HSYNC; i++) pulse_h_clock();
    sdle = 0;
    for (int i = 0; i < HBP; i++) pulse_h_clock();
    if (v_in_act) sdce = 0;
    for (int i = 0; i < HACT; i++) {
        send_data();
        pulse_h_clock();
    }
}

void drive_frame() {
    gdoe = 0;
    sdoe = 0;
    gdsp = 1;
    for (int i = 0; i < VFP; i++) drive_line(false);
    gdsp = 0;
    gdoe = 1;
    sdoe = 1;
    for (int i = 0; i < VSYNC; i++) drive_line(false);
    gdsp = 1;
    for (int i = 0; i < VBP; i++) drive_line(false);
    for (int i = 0; i < VACT; i++) drive_line(true);
}"><pre><span>#define</span> <span>DATA_BUS_WIDTH</span>      8 // 8bit wide bus
<span>#define</span> <span>PIXEL_PER_CYCLE</span>     (DATA_BUS_WIDTH / 2)
<span>#define</span> <span>VFP</span>     12  // Vertical front porch
<span>#define</span> <span>VSYNC</span>   1   // Vertical sync length
<span>#define</span> <span>VBP</span>     2   // Vertical back porch
<span>#define</span> <span>VACT</span>    758 // Vertical active lines
<span>#define</span> <span>HFP</span>     72  // Horizontal front porch
<span>#define</span> <span>HSYNC</span>   2   // Horizontal sync length
<span>#define</span> <span>HBP</span>     2   // Horizontal back porch
<span>#define</span> <span>HACT</span>    (1024 / PIXEL_PER_CYCLE)

<span>void</span> <span>pulse_h_clock</span>() {
    <span>sdclk</span> <span>=</span> <span>1</span>;
    <span>sdclk</span> <span>=</span> <span>0</span>;
}

<span>void</span> <span>drive_line</span>(<span>bool</span> <span>v_in_act</span>) {
    <span>sdce</span> <span>=</span> <span>1</span>;
    <span>gdclk</span> <span>=</span> <span>0</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>HFP</span>; <span>i</span><span>++</span>) <span>pulse_h_clock</span>();
    <span>sdle</span> <span>=</span> <span>1</span>;
    <span>gdclk</span> <span>=</span> <span>1</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>HSYNC</span>; <span>i</span><span>++</span>) <span>pulse_h_clock</span>();
    <span>sdle</span> <span>=</span> <span>0</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>HBP</span>; <span>i</span><span>++</span>) <span>pulse_h_clock</span>();
    <span>if</span> (<span>v_in_act</span>) <span>sdce</span> <span>=</span> <span>0</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>HACT</span>; <span>i</span><span>++</span>) {
        <span>send_data</span>();
        <span>pulse_h_clock</span>();
    }
}

<span>void</span> <span>drive_frame</span>() {
    <span>gdoe</span> <span>=</span> <span>0</span>;
    <span>sdoe</span> <span>=</span> <span>0</span>;
    <span>gdsp</span> <span>=</span> <span>1</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>VFP</span>; <span>i</span><span>++</span>) <span>drive_line</span>(false);
    <span>gdsp</span> <span>=</span> <span>0</span>;
    <span>gdoe</span> <span>=</span> <span>1</span>;
    <span>sdoe</span> <span>=</span> <span>1</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>VSYNC</span>; <span>i</span><span>++</span>) <span>drive_line</span>(false);
    <span>gdsp</span> <span>=</span> <span>1</span>;
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>VBP</span>; <span>i</span><span>++</span>) <span>drive_line</span>(false);
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>VACT</span>; <span>i</span><span>++</span>) <span>drive_line</span>(true);
}</pre></div>
<p dir="auto">More explanation can be found at <a href="http://essentialscrap.com/eink/index.html" rel="nofollow">http://essentialscrap.com/eink/index.html</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding Waveform</h3><a id="user-content-understanding-waveform" aria-label="Permalink: Understanding Waveform" href="#understanding-waveform"></a></p>
<p dir="auto">The waveform is a look up table for the eink controller to determine how to drive the pixels, mostly useful for greyscale image display, but generally used for binary image display as well.</p>
<p dir="auto">The look up table has 3 inputs (dimensions): frame number, source grayscale level, destination grayscale level. During the update process, for a certain pixel, the source and destination level stays the same, and the frame number increases each frame. The look up process is done for every pixel every frame. The controller may choose different LUTs depending on the ambient temperature. Mode switching is also implemented by simply switching between different LUTs.</p>
<p dir="auto">This is essentially what typically eink controller does. For each pixel, look up in the table to determine the voltage to use. Repeat this for a couple of frames with an incrementing frame counter, until all pixels are fully driven.</p>
<p dir="auto">It should be obvious that the waveform file itself is independent to the resolution as the waveform only cares about single pixel. With an incorrect or un-optimal waveform, the screen should at least display some recognizable image.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Waveform Example</h4><a id="user-content-waveform-example" aria-label="Permalink: Waveform Example" href="#waveform-example"></a></p>
<p dir="auto">There are several sample waveform tables provided in the project repo. Take the GC16 (Greyscale clearing 16-level) waveform of GDEW101C01 as an example: <a href="https://github.com/zephray/NekoInk/blob/master/waveform/gdew101_gd/test_M2_T0.csv">https://github.com/zephray/NekoInk/blob/master/waveform/gdew101_gd/test_M2_T0.csv</a></p>
<p dir="auto">Take one line from that file:</p>
<p dir="auto"><code>6,13,0,0,0,0,0,0,0,0,0,2,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,0</code></p>
<p dir="auto">This means from greyscale level 6 to level 13, it needs to go through the following sequence. Each number means the operation on that frame, 0 is no-operation, 1 is darken, and 2 is lighten. In this case, there are 38 frames, first 9 frames do nothing, then lighten for 1 frame, darken for 10 frames, lighten for 16 frames, and finally darken for 1 frame and no-operation for the last frame. This is the sequence to change a pixel from level 6 to level 13. Such lookup is done for every pixel on every frame.</p>
<p dir="auto">For specifics on waveform file formats, check the <a href="#working-with-waveforms">Working with Waveforms</a> section.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Waveform Modes</h4><a id="user-content-waveform-modes" aria-label="Permalink: Waveform Modes" href="#waveform-modes"></a></p>
<p dir="auto">To give system designers more flexibility, Eink controllers often offers multiple "modes", like binary mode, 16-level grayscale mode, 16-level grayscale mode with reduced flashing, 4-level grayscale mode, etc.</p>
<p dir="auto">The waveform provided by Eink has many modes. There is a good document from Eink describing the modes:</p>
<p dir="auto"><a href="https://www.waveshare.net/w/upload/c/c4/E-paper-mode-declaration.pdf" rel="nofollow">https://www.waveshare.net/w/upload/c/c4/E-paper-mode-declaration.pdf</a></p>
<p dir="auto">It provides a good overview of the modes. I am just going to add some comments.</p>
<ul dir="auto">
<li>GC in the GC16 stands for "greyscale clearing". GC does not stands for greyscale. There are 16-level greyscale modes that aren't called GC16.</li>
<li>Officially there is no 32-level greyscale modes (yet). There are 5bit waveforms, which means they internally use 5 bits for each pixel, which potentially allows up to 32-level greyscale, but no such waveform exists (yet).</li>
<li>These is no 16 level greyscale modes without flashing. The DU4 is the only greyscale mode that's non-flashing.</li>
<li>The GL16 mode, as described, only works for black text on white background. When refreshing greyscale images, the GL16 is similar to the GC16.</li>
<li>The GLR16 mode is also called the REGAL mode, and the GLD16 mode is also called as the REGAL-D mode.</li>
<li>Eink doesn't even know if it should be spelled as REAGL or REGAL:  Google search "REAGL site:eink.com" and "REGAL site:eink.com" both returned several results.</li>
<li>Eink provided waveform usually implements all these modes, however it is not always required. The waveform file may also contain waveform tables in other orders.</li>
<li>In terms of the waveform, the waveform for GL16, GLR16, and GLD16 are identical. This is expected, the REGAL requires additional algorithm on the host image processing, and is not a technology based on tweaking the waveform.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Waveform Tweaks</h4><a id="user-content-waveform-tweaks" aria-label="Permalink: Waveform Tweaks" href="#waveform-tweaks"></a></p>
<p dir="auto">Some commercial implementations allow users to reduce the frame count and/ or alter the waveform playback speed, so the user can trade between contrast ratio and frame rate.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Greyscale Display</h3><a id="user-content-greyscale-display" aria-label="Permalink: Greyscale Display" href="#greyscale-display"></a></p>
<p dir="auto">Other than full white and full black, with appropriate modulation, Eink screens can also display some levels of greyscale (typically 16).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/eink_32g.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/eink_32g.jpg" alt="greyscale"></a></p>
<p dir="auto">For grayscale display, the basic idea is simple. If the pixel is not fully driven (say only drives for 50ms while it takes 100ms to reach full black/ white), it would stay in a gray state.</p>
<p dir="auto">There are two ways of achieving this modulation:</p>
<ul dir="auto">
<li>Modulate the frame time</li>
<li>Modulate the number of frames with constant frame rate</li>
</ul>
<p dir="auto">Both are possible, as described below</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Frame Time Modulation</h4><a id="user-content-frame-time-modulation" aria-label="Permalink: Frame Time Modulation" href="#frame-time-modulation"></a></p>
<p dir="auto">This method changes the drive time by changing the length of a single frame. The screen would only be driven for 15 or 31 frames for 16-level and 32-level greyscale, but the frame time (thus frame rate) is altered to provide the desired driving time. The LUT would be a one dimension look up table, only containing the incremental time required to drive to the next greyscale level. The source/ gate driver output enable line maybe toggled to achieve the desired driving time.</p>
<p dir="auto">This method doesn't seem to be implemented in any commercial solutions and is significantly slower than the second method. But it certainly works. In fact the 32-level greyscale demo shown in the picture above is achieved using this method.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Frame Count Modulation</h4><a id="user-content-frame-count-modulation" aria-label="Permalink: Frame Count Modulation" href="#frame-count-modulation"></a></p>
<p dir="auto">This method changes the drive time by changing the number of frames being applied to the screen. The screen is still being driven at a constant frame rate. The following is a simplified hypothetical waveform table for achieving 4-level greyscale:</p>
<table>
<thead>
<tr>
<th>Previous State</th>
<th>Target State</th>
<th>Frame 0</th>
<th>Frame 1</th>
<th>Frame 2</th>
<th>Frame 3</th>
<th>Frame 4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Black</td>
<td>Black</td>
<td>NOP</td>
<td>NOP</td>
<td>NOP</td>
<td>NOP</td>
<td>NOP</td>
</tr>
<tr>
<td>Black</td>
<td>Dark Grey</td>
<td>VPOS</td>
<td>VNEG</td>
<td>VPOS</td>
<td>NOP</td>
<td>NOP</td>
</tr>
<tr>
<td>Black</td>
<td>Light Grey</td>
<td>VPOS</td>
<td>VNEG</td>
<td>VPOS</td>
<td>VPOS</td>
<td>NOP</td>
</tr>
<tr>
<td>Black</td>
<td>White</td>
<td>VPOS</td>
<td>VNEG</td>
<td>VPOS</td>
<td>VPOS</td>
<td>VPOS</td>
</tr>
</tbody>
</table>
<p dir="auto">Note how it alternates between VPOS and VNEG in the beginning. This is often called the "activation phase" to improve contrast ratio. Putting this detail aside, it changes the number of VPOS frames to settle down on different grey levels.</p>
<p dir="auto">Actual grayscale driving sequence used in the commercial implementation is more complex than that, often involving switching the pixel towards black/white a few times before settling. This design is partially due to the limited time control granularity and other temperature/ manufacturing variance related concerns. Some side-effects of such a driving sequence are that the refreshing process is “flashing”, and is slower compared to displaying only 1-bit binary image.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Color Display</h3><a id="user-content-color-display" aria-label="Permalink: Color Display" href="#color-display"></a></p>
<p dir="auto">There are several different technologies that could be used to build full color EPDs. The 2 most common ways are to use a color-filter-array (CFA) or use a multi pigment color display.</p>
<p dir="auto">The following picture have the multiple pigment color display (ACeP Gallery 3) on the left, and CFA-based color screen (Kaleido Plus) on the right, displaying the same image.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/gallery3_kaleido_plus.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/gallery3_kaleido_plus.jpg" alt="gallery3_kaleido"></a></p>
<p dir="auto">(Original illustration copyright MiHoYo)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Color Filter Array</h4><a id="user-content-color-filter-array" aria-label="Permalink: Color Filter Array" href="#color-filter-array"></a></p>
<p dir="auto">CFA stands for color filter array, which is basically colored glass/ film on top of the screen pixel. This is also the technology used on most color LCDs. Eink Kaleido, Eink Triton and color DES are based on this technology. The main advantage is that it's relative simple to control, and the low level driving is the same with the greyscale panels. Thus it has the same level of refreshing time (100~200ms), and same level of greyscale (16 level translate to 16^3=4096 colors). The draw back is that the CFA filters out some light (due to its colored nature), the screen reflectivity is negatively affected by the CFA. The screen ends up being quite dark. Up to now, most color E-readers uses CFA-based display. This project supports all three major types of CFA-based EPD screens: color DES screen, Eink Triton, and Eink Kaleido.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Case Study: GDEW101C01 (CFA-based, DES)</h4><a id="user-content-case-study-gdew101c01-cfa-based-des" aria-label="Permalink: Case Study: GDEW101C01 (CFA-based, DES)" href="#case-study-gdew101c01-cfa-based-des"></a></p>
<p dir="auto">The GDEW101C01 is a 10.1" color DES screen made by Good Display / WeiFeng Tech. It uses CFA to produce color image. As a result, to the eink controller hardware, it's just a normal greyscale panel with bunch of pixels. But the pixels are colored depending on their location due to the CFA. The coloring of the pixels can be either handled by hardware or software.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Pixel Arragement</h5><a id="user-content-pixel-arragement" aria-label="Permalink: Pixel Arragement" href="#pixel-arragement"></a></p>
<p dir="auto">Color DES is a bit different from a typical color TFT LCD in terms of CFA design. Typically on TFT LCDs, one RGB pixel is called a pixel, and each R/G/B component is called as a sub-pixel. On color DES, the sub-pixel is ended up being called as pixel, and each pixel is either red, green, or blue. In display industry, such pixels are more commonly referred as dots.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/subpixel.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/subpixel.jpg" alt="subpixel"></a></p>
<p dir="auto">Pengo, CC BY-SA 3.0 <a href="https://creativecommons.org/licenses/by-sa/3.0" rel="nofollow">https://creativecommons.org/licenses/by-sa/3.0</a>, via Wikimedia Commons</p>
<p dir="auto">The actual photo of DES panel under microscope:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_des.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_des.jpg" alt="color-des"></a></p>
<p dir="auto">In the above photo, the DES pixel arrangement is the same as the OLPC XO-1.</p>
<p dir="auto">Having no subpixel / each pixel only has 1 color doesn't necessarily mean that the effective resolution needs to be divide by 3. This arrangement is slightly more "efficient" than RGB strip in terms of perceptive resolution. You could find more detailed analysis in the paper Comparing the Effective Resolution of Various RGB Subpixel Layout.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Processing image for Color DES</h5><a id="user-content-processing-image-for-color-des" aria-label="Permalink: Processing image for Color DES" href="#processing-image-for-color-des"></a></p>
<p dir="auto">If the image is displayed on color DES without any processing, it would look like a greyscale image. This is similar when you just send the same color value to R/G/B components on a color LCD display.</p>
<p dir="auto">To get color, send only the color component that correspond to the pixel color.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/PixelLayoutDiagonal.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/PixelLayoutDiagonal.png" alt="pixel-layout"></a>
(Source: <a href="https://wiki.laptop.org/go/File:PixelLayoutDiagonal.png" rel="nofollow">https://wiki.laptop.org/go/File:PixelLayoutDiagonal.png</a>, public domain)</p>
<p dir="auto">For example, for pixel 01, the pixel on the screen is green. Then only the green component from the frame buffer should be sent to the screen.</p>
<p dir="auto">To get basic 4096 color image display, this is everything needed. However generally to improve image quality, few more steps are applied:</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Low pass filtering</h5><a id="user-content-low-pass-filtering" aria-label="Permalink: Low pass filtering" href="#low-pass-filtering"></a></p>
<p dir="auto">The previous described image displaying process is essentially a down-sampling process for each color components: Only 1/3 of the pixel are sent to the screen. Then this becomes a classic signal processing issue: sampling the signal would cause frequency components above Nyquist to fold back to the low frequency part. Or in simpler words, you would see jagged edges/ aliasing, which are things that wasn't present in the original image. To prevent this, low pass filtering (blurring) needs to applied first to the image to remove these high frequency components. The following diagram from OLPC wiki shows a simple way of implementing a such filter:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/PixelProcDiagonal.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/PixelProcDiagonal.png" alt="pixel-proc"></a>
(Source: <a href="https://wiki.laptop.org/go/File:PixelProcDiagonal.png" rel="nofollow">https://wiki.laptop.org/go/File:PixelProcDiagonal.png</a>, public domain)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Multi-Pigment Color Display</h4><a id="user-content-multi-pigment-color-display" aria-label="Permalink: Multi-Pigment Color Display" href="#multi-pigment-color-display"></a></p>
<p dir="auto">Another technology for implemneting color EPD is by using a multi-pigment color display. This is a technology developed initially by SiPix, and further improved by Eink. The basic idea is to use ink particles with different colors inside a single pixel. By applying a sequence of voltages, the ink particles can be arranged to display different colors.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/eink_spectra6.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/eink_spectra6.jpg" alt="spectra6"></a></p>
<p dir="auto">(Source: <a href="https://www.eink.com/tech/detail/How_it_works" rel="nofollow">https://www.eink.com/tech/detail/How_it_works</a> , copyright Eink Corporation)</p>
<p dir="auto">One major advantage of this solution is it can achieve higher resolution (because it doesn't have a CFA, so no resolution reduction), higher reflectivity (because it doesn't have a CFA, so no light loss), and higher color saturation (because it doesn't have a CFA, no need to play the reflectivity vs saturation trade off game).</p>
<p dir="auto">Eink has 2 lines of products using this Technology, Eink Gallery and Eink Spectra. The advantage is it's much brighter compared to CFA based solutions. The disadvantage is it's much more difficult to drive, and quite slow: 1st /2nd gen Eink Gallery screen takes 30s (!) to refresh, and Spectra 6 Plus devices takes 7s to refresh. It's possible to trade-in some color saturation for higher speed, though still much slower than CFA based solutions. The specific product lines will be discussed in <a href="#eink-screen-generations">Eink Screen Generations</a></p>
<p dir="auto"><h5 tabindex="-1" dir="auto">What Happened To ACeP?</h5><a id="user-content-what-happened-to-acep" aria-label="Permalink: What Happened To ACeP?" href="#what-happened-to-acep"></a></p>
<p dir="auto"><a href="https://arstechnica.com/gadgets/2022/04/new-e-ink-gallery-displays-could-finally-make-full-color-e-readers-good/" rel="nofollow">ACeP was supposed to the "next big thing" in ereader</a>. Back in the end 2022, Eink anounnced that <a href="https://www.e-ink-info.com/e-ink-gallery-3-acep-color-epaper-displays-move-mass-production" rel="nofollow">"Gallery 3 has moved into mass production, with customer products from Bigme, BOOX, iFlyTek, iReader, PocketBook, Readmoo, and AOC coming down the pipeline in 2023 and beyond"</a>. But 2023 passed with exactly one product, the Bigme Galy, with mixed receptions. Early 2024, it was announced that <a href="https://goodereader.com/blog/electronic-readers/bigme-galy-is-discontinued" rel="nofollow">Bigme Galy has been discontinued</a>, and <a href="https://www.ineltek.com/wp-content/uploads/2024/04/EInk_AC073TC1_EOLNoticeLetter_notice_20240401.pdf" rel="nofollow">Eink have announced EOL for certain ACeP based products</a>. It does sound like ACeP is now dead.</p>
<p dir="auto">The following are purely my own speculation. But I see this as 2 separate decisions:</p>
<ul dir="auto">
<li>There will be no more multi-pigment based display for eReader market</li>
<li>ACeP (CMYW) is being replaced with Spectra 6 (RYBW) in other markets</li>
</ul>
<p dir="auto">The second one is evident from the EOL noticed linked previously, the 7.3" ACeP screen has a direct replacement of 7.3" Spectra 6 screen. One major drawback of ACeP in digital signage market (as far as I see) is its inability to reproduce the cyan color. This actually means there is no good way to display blue sky on an ACeP screen, not even through dithering, it's simply outside of its color gamut. By changing the base colors used, Eink was able to mitigate this issue in the Spectra 6 product lines.</p>
<p dir="auto">The first one is more or less speculation. I have two clues for that. One is the fact that Eink is doubling down on digital signage for Spectra 6: <a href="https://www.beck-elektronik.de/en/newsroom/news/article/e-ink-spectratm-6-der-hingucker-des-jahres-2024" rel="nofollow">Both 13.3" and 31.5" Spectra 6 screen will have integrated controller</a>. This make them much more interesting for the signage applications, but unsuitable for eReader applications. The other is that <a href="https://www.ereaderpro.co.uk/en/blogs/news/e-ink-news-eink-technology-has-unveiled-the-new-generation-of-colour-e-paper-technology-e-ink-spectra-6-plus-designed-for-retail-tags-and-advertising-billboards" rel="nofollow">the 8" Spectra 6 Plus screen</a>, while using the same backplane as the Gallery 3 ACeP screen, now quote a 7 second refresh time (compared to less than a second on Gallery 3). If Eink still wanted to make a Spectra 6 eReader screen, this 8" backplane would be the one to use given it was used in ACeP product line.</p>
<p dir="auto">Ojectively, ACeP screen on the Bigme Galy pretty much doesn't make any sense anyway. It suffers from poor reflectivity and poor saturation, to a point where it's not much better than Kaleido (see the previous photo). The difference between the Gallery 3 and Gallery Palette (which is supposed to be a lower end product) is also stunning:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/gallery3_gallerypalette.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/gallery3_gallerypalette.jpg" alt="acep_comparison"></a></p>
<p dir="auto">(Original illustration copyright MiHoYo)</p>
<p dir="auto">The one on the left is the Gallery 3 used on eReaders, the one on the right (brighter and more saturated one) is the Gallery Palette used on ESLs. Though to be honest I hacked the right one a bit to display 512 colors opposed to the stock 7 colors. If the Gallery 3 had the same image quality as previous ACeP/ Gallery screens, it would make sense to trade in response time for better image quality. But it doesn't.</p>
<p dir="auto">So is the ACeP dead? Yes and no. Yes in a sense that we are less likely to see any new ACeP products in the future, and we are also unlikely to see any Spectra 6 based eReader products. No in a sense that ACeP is superseded by Spectra 6, so the technology lives on. Just like how the Pearl replaced the Vizplex, and the Carta replaced the Pearl. Now we have Carta so we don't look back to the older generation of screens. Also, in another sense, there are likely at least thousands of ACeP screens already manufactured but didn't made into the consumer devices. We will probably see these screens in the not too distant future!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dithering</h3><a id="user-content-dithering" aria-label="Permalink: Dithering" href="#dithering"></a></p>
<p dir="auto">Eink and DES panels typically only supports up to 16 level of greyscale with the vendor provided waveform. To improve response time, or to avoid flashing image, binary (1-bit, 2-level) display is also used. Dithering could be applied to produce better image (increasing SNR, in signal processing sense).</p>
<p dir="auto">The following is applying dithering to a simple black to white gradient. Note the results are not optimal due to limitations in quantization and incorrect gamma correction. But the idea is the same.</p>
<table>
<thead>
<tr>
<th>Original</th>
<th>Binary No-dithering</th>
<th>2 Row Sierra Dithered</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_orig.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_orig.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_no_dither.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_no_dither.png" alt="nodither"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_ed.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_ed.png" alt="errordiffusion"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Dithering can help when the screen has native 16-level greyscale as well:</p>
<table>
<thead>
<tr>
<th>Original</th>
<th>16 Level Greyscale No-dithering</th>
<th>16 Level Greyscale Dithered</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_orig.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_orig.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_4bpp_nd.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_4bpp_nd.png" alt="nodither"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_4bpp_ed.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_4bpp_ed.png" alt="errordiffusion"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">As you can see, the non-dithered image loses all the greyscale inbetween, while the dithered version on the right gives illusion of greyscale while only using full black and full white colors.</p>
<p dir="auto">To understand it further, take the following example:</p>
<p dir="auto">Say the source image is 30% brightness (or 0.3). This cannot be displayed on a binary screen which can only display 0% (0.0, black) or 100% (1.0, white) brightness. A simple thresholding process is added to determine if the screen should display 0 or 1 by checking the incoming brightness. If it's less than 0.5 then the display brightness is rounded down to 0, otherwise 1. Because 0.3 is always lower than 0.5, the whole screen displays 0 (black).</p>
<p dir="auto">This is less than ideal. A better way is to set around 30% of the pixel black, while 70% of the pixel white. Different dithering algorithms can be used to achieve this 30/70 distribution. Two common methods used are ordered dithering and error-diffusion dithering, which will be described below.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Ordered Dithering</h4><a id="user-content-ordered-dithering" aria-label="Permalink: Ordered Dithering" href="#ordered-dithering"></a></p>
<p dir="auto">The ordered dithering adds a pre-computed/ fixed texture to the image before the thresholding process. In other words, it basically adds some noise to the image. This may sound weird initially, but it should be easy to see the effect of noise in the example.</p>
<p dir="auto">Using the example of previously described displaying 30% brightness grey on a binary screen. The goal is let the rounding process to end up in 0 for 30% of the time, and 1 for 70% of the time. This could be achived by adding a noise. In the simplist case, a random number with a uniform distribution between [-0.5, 0.5] is added to the incoming brightness. The brightness has a value of 0.3, when adding this number to the random number, the random number now has a uniform distribution between [-0.2, 0.8]. The threshold is still set to 0.5, and now the probability distribution can be seen as below:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/dithering_pdf.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/dithering_pdf.svg" alt="pdf"></a></p>
<p dir="auto">The pixel now has 30% chance of being rounded up to 1, and 70% chance of being rounded down to 0. Before dithering, it would always be rounded down to 0.</p>
<p dir="auto">However, purely random number is generally not the best noise to use. Bayer dithering matrix and blue noise are more commonly used, with the results as illustrated below. The idea is the same, but instead of adding random numbers, pre-computed number from the bayer dithering matrix (array) or blue noise texture (array) is added to the image.</p>
<table>
<thead>
<tr>
<th>Random Dithering</th>
<th>Bayer Dithering</th>
<th>Blue-noise Dithering</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_rand.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_rand.png" alt="random"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_bayer.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_bayer.png" alt="bayer"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_bn.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_bn.png" alt="bluenoise"></a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Error-Diffusion Dithering</h4><a id="user-content-error-diffusion-dithering" aria-label="Permalink: Error-Diffusion Dithering" href="#error-diffusion-dithering"></a></p>
<p dir="auto">The basic idea is when rounding down the color (selecting the closest color from the 16-level greyscale from 256-level input), the error value (difference) is calculated and added to neighboring pixels (so these error would be considered when processing these pixels later). The whole process is called error-diffusion.</p>
<p dir="auto">Still using the previous example of 30% brightness image, and assume an extremely simple dither kernel: diffuse all error to the next pixel. Let's see it in action.</p>
<p dir="auto">In the first pixel, 0.3 (image brightness) is less than 0.5 (threshold), so it's displayed as 0 (black). This introduce a 0.3 error: the displayed color is 0.3 darker than the requested color. So 0.3 is being diffused to the next pixel, hoping the next pixel can correct the error.</p>
<p dir="auto">Onto the second pixel. The value is 0.3 (image brightness) + 0.3 (diffused error) = 0.6. It's now larger than 0.5 (threshold), so it's displayed as 1 (white). This introduces a -0.4 error: the displayed color is 0.4 brighter than the requested color. -0.4 will be diffused to the next pixel.</p>
<p dir="auto">The 3rd pixel, the value is now 0.3 - 0.4 = -0.1. This is less than 0.5, and displayed as 0 (black). Error -0.1 is diffused further.</p>
<p dir="auto">And this process just goes on. With enough pixels, eventually it would yields about 30% of white pixels and 70% of dark pixels.</p>
<p dir="auto">Similar to how random value is not the best thing to do in ordered dithering, dithering to the right is also less than ideal. It creates very repetitive patterns. I mentioned the word kernel. Error diffusing uses a diffusion kernel, which specifies the target and percentage of the diffused error. There are many classic kernels, such as Floyd–Steinberg, Stucki, and Sierra etc. commonly used for image dithering. They all diffuse to more than 1 pixels to improve the overall look of the image. As shown below, even just diffuse error to 2 pixels (half of the error goes to the pixel on the right, and the rest half of the error goes to the pixel on the bottom) yields much better result:</p>
<table>
<thead>
<tr>
<th>Dither to Right</th>
<th>Right and Down</th>
<th>Floyd-Steinberg</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_naive.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_naive.png" alt="right"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_naive2.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_naive2.png" alt="rightdown"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/grad_fs.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/grad_fs.png" alt="fs"></a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Applying Dithering on CFA-based Color Screens</h4><a id="user-content-applying-dithering-on-cfa-based-color-screens" aria-label="Permalink: Applying Dithering on CFA-based Color Screens" href="#applying-dithering-on-cfa-based-color-screens"></a></p>
<p dir="auto">Dithering can be applied on CFA-based color screens such as Eink Kaleido and color DES screens as well. The following is on a simulated DES screen: (left original is assuming screen has native 24bpp color, still on a simulated screen)</p>
<table>
<thead>
<tr>
<th>16M color DES (does not exist)</th>
<th>8-color DES</th>
<th>8-color DES Dithered</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_8bpp.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_8bpp.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_nd.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_nd.png" alt="nodither"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_ed.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_ed.png" alt="errordiffusion"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Ordinary dithering kernels don't work too well on color screens. For example, the error-diffusion dithering process pushes/ diffuses error neighboring pixels without considering their color. Ideally it should push/ diffuse the error only to pixels with the same color. This is fairly easy to fix though, by tweaking the kernel it would achieve good results on CFA-based screens as well. (I am going to shamelessly call it Wenting's kernel)</p>
<table>
<thead>
<tr>
<th>16M color DES (does not exist)</th>
<th>8-color DES naively apply Floyd-Steinberg (wrong)</th>
<th>8-color DES with Wenting's kernel</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_8bpp.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_8bpp.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_fs_wrong.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_fs_wrong.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_ed.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_ed.png" alt="errordiffusion"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Of course one can apply bayer-like ordered dithering, blue noise dithering, or dithering on 4096-color mode as well:</p>
<table>
<thead>
<tr>
<th>8-color DES Bayer-like</th>
<th>8-color DES Blue-noise</th>
<th>4096-color DES Error-diffusion</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_bayer.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_bayer.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_bn.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_bn.png" alt="original"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/color_4bpp_ed.png"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/color_4bpp_ed.png" alt="errordiffusion"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">It's called bayer because, similar to how naively doing error diffusion doesn't work, the bayer matrix has to be modified to work on color screen.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Gamma Correction</h4><a id="user-content-gamma-correction" aria-label="Permalink: Gamma Correction" href="#gamma-correction"></a></p>
<p dir="auto">Another thing to consider is gamma. The dithering process involves a step of selecting the closest value. However, selecting the closest numerical value is not necessarily mean the closest color. The image typically is in sRGB space, which is non-linear. This causes the simple rounding to pick the wrong color, also calculating the wrong error value. One solution is to work in the linear space. This is also known as gamma-aware dithering. You could read more related info online, for example here: <a href="https://learnopengl.com/Advanced-Lighting/Gamma-Correction" rel="nofollow">https://learnopengl.com/Advanced-Lighting/Gamma-Correction</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/dither_gamma.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/dither_gamma.jpg" alt="dither-gamma"></a></p>
<p dir="auto">The difference is quite evident when dithering down to 1 bit for color screen. Top left is the original image, top right is dithering in the sRGB space, while bottom left is dithering in the linear space.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Further Reading</h4><a id="user-content-further-reading" aria-label="Permalink: Further Reading" href="#further-reading"></a></p>
<p dir="auto">See <a href="https://en.wikipedia.org/wiki/Dither" rel="nofollow">https://en.wikipedia.org/wiki/Dither</a> for more information about dithering.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Eink Screen Generations</h3><a id="user-content-eink-screen-generations" aria-label="Permalink: Eink Screen Generations" href="#eink-screen-generations"></a></p>
<p dir="auto">Depending on how you count, there are multiple generations of Eink screens commericially available. For monochrome screens before 2023, it's possible to tell the generation by looking at the 6th digit on the serial number:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/eink_serial.jpg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/eink_serial.jpg" alt="eink_serial"></a></p>
<p dir="auto">And use the following table:</p>
<table>
<thead>
<tr>
<th>FPL Platform</th>
<th>FPL Code</th>
<th>Marketing Name</th>
<th>First Introduced</th>
</tr>
</thead>
<tbody>
<tr>
<td>2.0</td>
<td>0</td>
<td></td>
<td>2004</td>
</tr>
<tr>
<td>2.1</td>
<td>1</td>
<td></td>
<td>?</td>
</tr>
<tr>
<td>2.3</td>
<td>2</td>
<td></td>
<td>?</td>
</tr>
<tr>
<td>V100</td>
<td>3</td>
<td>Vizplex</td>
<td>2007</td>
</tr>
<tr>
<td>V110</td>
<td>4</td>
<td>Vizplex</td>
<td>2008</td>
</tr>
<tr>
<td>V110A</td>
<td>5</td>
<td>Vizplex</td>
<td>2008</td>
</tr>
<tr>
<td>V220</td>
<td>6</td>
<td>Pearl</td>
<td>2010</td>
</tr>
<tr>
<td>V250</td>
<td>7</td>
<td>Pearl</td>
<td>?</td>
</tr>
<tr>
<td>V220E</td>
<td>8</td>
<td>Pearl</td>
<td>?</td>
</tr>
<tr>
<td>V320</td>
<td>9, R</td>
<td>Carta 1.2 / 1000 / 1100</td>
<td>2013</td>
</tr>
<tr>
<td>V400</td>
<td>A, C</td>
<td>Roadrunner / Carta 1200</td>
<td>2021</td>
</tr>
<tr>
<td>V450</td>
<td></td>
<td>Carta 1250</td>
<td>?</td>
</tr>
<tr>
<td>?</td>
<td></td>
<td>Carta 1300</td>
<td>2023</td>
</tr>
</tbody>
</table>
<p dir="auto">I will let you to decide how to count the generations.</p>
<p dir="auto">For the CFA-based screens, the following generations of screens exist:</p>
<ul dir="auto">
<li>Eink Triton: First generation color screen. Uses RGBW glass color filter and square pixel. Underlying screen panel uses Pearl film.</li>
<li>Eink Triton 2: 2nd generation color screen. Uses RGB glass color filter and stripe pixel. Underlying screen panel uses Pearl film.</li>
<li>Eink Kaleido: 3rd or 2nd gen color screen depending on the definition. Uses RGB color filter. Each pixel is still square, but each color covers 3 pixels. Underlying screen panel uses Carta film.</li>
<li>Eink Kaleido Plus: 2nd gen Kaleido. Uses RGB color filter. Each pixel is still square but different configurations exist. Some screens has each color covering 2 pixels, some others have each color covering only 1 pixel. Underlying screen panel uses Carta film.</li>
<li>Eink Kaleido 3: 3rd gen Kaleido. Exists many different configurations, ranging from RGBW filter covering 1 pixel per color, to RGB filter covering 3 pixels per color more like the original Kaleido. Underlying screen panel uses Carta 1000/1200/1250/1300 film depending on the model.</li>
<li>Eink Kaleido 3 Outdoor: Wide temperature version of Kaleido 3.</li>
</ul>
<p dir="auto">As far as I know, all CFA-based color screen panels don't come with integrated controller.</p>
<p dir="auto">For the multiple-pigment color screens based on SiPix technology, the following generations of screens exist:</p>
<p dir="auto">(Color abbreviation: B: black, W: white, R: red, Y: yellow, B: blue, C: cyan, M: magenta)</p>
<ul dir="auto">
<li>Eink Spectra 3000: BWR or BWY 3 color screen.</li>
<li>Eink Spectra 3100: BWRY 4 color screen.</li>
<li>Eink Spectra 3100 Plus：BWRY 4 color screen. Orange display is now possible with driver circuit changes</li>
<li>Eink Spectra 6: RYBW 4 color screen. Can reproduce 6 different colors by mixing colors</li>
<li>Eink Spectra 6 Plus: RYBW 4 color screen. Still reproduce 6 different colors. Allows faster refresh compare to 6 with driver circuit changes</li>
<li>Eink Gallery: CMYW 4 color screen (ACeP).</li>
<li>Eink Gallery Plus: CMYW 4 color screen (ACeP).</li>
<li>Eink Gallery Palette： CMYW 4 color screen (ACeP). Reproduce 7 different colors.</li>
<li>Eink Gallery 3: CMYW 4 color screen (ACeP). Reproduce 12 different colors, much faster than other Gallery screens at the cost of lower saturation and lowr reflectivity</li>
</ul>
<p dir="auto">There are both integrated-controller Spectra/Gallery screens and controller-less Spectra/Gallery screens.</p>
<p dir="auto">Addtional notes regarding the multi-pigment color screens:</p>
<ul dir="auto">
<li>ACeP, or Advanced Color ePaper refers to the CMYW 4 color screen. Is not a product line on its own</li>
<li>To be honest, I don't know how many colors can be reproduced on Gallery or Gallery Plus screens based on public information. Eink claims 30000 or 60000 colors in their materials, but they also clarified these numbers refers to color gamut. In other words, they represent color saturation rather than number of different colors can be displayed on screen. Dithering is heavily used to display color image on Gallery screens.</li>
<li>It's possible to achieve more colors on Gallery Palette screens. 7 is not a physical limit.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design of Caster and Glider</h2><a id="user-content-design-of-caster-and-glider" aria-label="Permalink: Design of Caster and Glider" href="#design-of-caster-and-glider"></a></p>
<p dir="auto">This section describes the design specific to the Caster and Glider. The following is an overall block diagram showing both hardware and gateware components in the signal chain:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/glider_overall_block_diagram.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/glider_overall_block_diagram.svg" alt="Overall ABlockdiagram"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Gateware Architecture</h3><a id="user-content-gateware-architecture" aria-label="Permalink: Gateware Architecture" href="#gateware-architecture"></a></p>
<p dir="auto">The FPGA gateware is divided into multiple modules. The caster.v is the top-level of the EPDC core design, but several additional components are connected under top.v to form a complete image processing system. Different components are generally inter-connected with synchronous or asynchronous (in case of clock domain crossing) FIFOs.</p>
<p dir="auto">The top-level design has 3 major clock domains: clk_vi: Input video clock domain, running at ½ pixel rate. clk_epdc: EPDC clock domain, running at ¼ pixel rate. clk_mem: Memory clock domain, running at ¼ memory transfer rate.</p>
<p dir="auto">To understand how it works, the following is a guided tour around the life cycle of a pixel.</p>
<p dir="auto">Before an incoming pixel can be processed by the controller, the memif module needs to retrieve the local pixel state from the DDR SDRAM. Once the value is retrieved, it’s pushed into the state readout/ input FIFO (bi_fifo). At/ around the same time, input video stream is pushed into the video input FIFO (vi_fifo).</p>
<p dir="auto">The EPDC runs a local Eink timing generator for counting pixels and blankings. This timing should be a slightly delayed version of the incoming video timing. Once the local timing generator determines that it needs to output the pixel soon, the EPDC logic pops out one pair of the video input and state readout and starts processing.
Two values goes through the video processing pipeline:</p>
<ul dir="auto">
<li>Stage 1: This pipeline stage waits for the FIFO to output the data.</li>
<li>Stage 2: The 8-bit input image is dithered down to 1-bit and 4-bit at this stage for later use.</li>
<li>Stage 3: The waveform lookup is done at this stage for 16-level grayscale modes</li>
<li>Stage 4: Based on the pixel state, new state and voltage selection value is determined at this stage.</li>
<li>Stage 5: New state is pushed into the state writeback/ out FIFO (bo_fifo) and the voltage selection is sent to the screen.</li>
</ul>
<p dir="auto">The memif module later pops out the writeback value from the bo_fifo and writes back to the DDR SDRAM.</p>
<p dir="auto">The EPDC always processes 4 pixels per clock. For screens with different interface width, a rate adapter is added after the EPDC output. Some logic are duplicated 2 or 4 times (such as the waveform RAM or the pixel decision logic), while some are extended and daisy-chained (such as the error diffusion dithering unit) to achieve the 4 pixels per clock throughput.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Firmware Functions</h3><a id="user-content-firmware-functions" aria-label="Permalink: Firmware Functions" href="#firmware-functions"></a></p>
<p dir="auto">The MCU manages house-keeping items as described below. It currently doesn’t use any operating system, but rather relying on a main-loop style operation.</p>
<ul dir="auto">
<li>EPD Power Supply: The power supply provides common, source, and gate supply to the EPD panel. In addition to basic on/off switch, the MCU can also adjust the VCOM voltage, and measure the optimal VCOM voltage of the panel installed. The VCOM measurement is done by isolating the VCOM supply from the screen with keeping the gate supply, scan the screen with source = VCOM, and measure the kick-back voltage on VCOM.</li>
<li>FPGA Bitstream Loading: The FPGA doesn’t have its own flash memory, the bitstream is pushed over SPI from the MCU to the FPGA upon powering up. In this way the FPGA bitstream can be easily bundled together with the MCU’s firmware and updated together.</li>
<li>Type-C Negotiation: The on-board USB Type-C port can support video input in addition to powering the board using the USB-C DisplayPort Alt Mode. The MCU runs a USB-C PD stack to communicate this capability to the video source device over standard USB PD protocol. The MCU also controls the Type-C signal mux to remap the lanes to the correct place depending on the cable orientation.</li>
<li>Video decoder initialization: The FPGA used on the board doesn’t have high speed deserializers to interface with common high speed video interface such as DisplayPort or DVI directly. Instead, dedicated video decoder chips are used on the board. They typically needs initialization before use, and the MCU takes care of this. In this specific design the DP decoder chip also handles AUX P/N line flipping based on the Type-C cable orientation.</li>
<li>PC communication: One advantage of the Caster is that update modes and forced update/ clearing can be applied on a per-pixel basis. Software may utilize this to assign different modes to different windows or change update modes depending on the content on the fly. This is done by sending requests to the MCU over USB connection. The MCU runs TinyUSB and present itself as an HID device so it can forward messages between the hos PC and the FPGA.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Low Latency Drive</h3><a id="user-content-low-latency-drive" aria-label="Permalink: Low Latency Drive" href="#low-latency-drive"></a></p>
<p dir="auto">The Caster implements several techniques for reducing the latency, which will be explained here.</p>
<p dir="auto">As described before, the existing basic driving method employs a global counter for looking up the waveform table. This imposes a limit on the global image update rate: the controller only accepts a new incoming image after the previous update is finished. The update usually takes about 100ms, translating to an image rate of 10Hz. Or, in other words, the user needs to potentially wait up to 100ms before the new image is even processed by the controller.</p>
<p dir="auto">One way to mitigate this issue is by having multiple update regions. For example, imagine the user is typing a and b. In a single region controller design, a is being drawn to the screen immediately, while the b needs to wait 100ms before it gets drawn. If the controller supports multiple regions, it could start drawing the letter b as soon as it’s typed, reducing the latency. This however requires the software to program the controller to correctly set the region to the letter boundary, and re-allocating regions on the fly as the number of regions is generally quite limited (like 4-16).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/caster_pipelined_update.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/caster_pipelined_update.svg" alt="caster-pipelined"></a></p>
<p dir="auto">The Caster simply treats every pixel as an individual update region, for maximum flexibility and is transparent to the software.</p>
<p dir="auto">Another latency optimization technique the Caster implemented is on the pixel that’s already being updated. For example, if the user types the letter a and deletes it right after. With the basic driving method, the controller needs to wait till the letter a is fully displayed before it can erase it. The previously proposed/ implemented regional update doesn’t help here because in this situation it’s about the same pixel so it has to be in the same region. The second technique is early cancellation. If a pixel changes before it’s fully driven, instead of waiting for it to be fully driven, it’s driven towards the requested input state, and the frame counter is updated depending on the newly calculated driving time.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Modos-Labs/Glider/blob/main/assets/caster_early_cancel.svg"><img src="https://github.com/Modos-Labs/Glider/raw/main/assets/caster_early_cancel.svg" alt="caster-early-cancel"></a></p>
<p dir="auto">By combining both, it’s then possible to implement low latency binary and 4-level grayscale modes. The tradeoff between framerate and contrast ratio is also no longer relevant. Both high frame rate and high contrast ratio are achieved automatically.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hybrid Greyscale Mode</h3><a id="user-content-hybrid-greyscale-mode" aria-label="Permalink: Hybrid Greyscale Mode" href="#hybrid-greyscale-mode"></a></p>
<p dir="auto">As discussed previously, getting <a href="#greyscale-display">greyscale</a> image on Eink is a sophiscated process, much slower than binary, and shows flashing images during the process. This pose challenges on how to make it useful for the users.</p>
<p dir="auto">On eReaders, the software could switch between fast and slow modes based on the action. The eReader software may also simply not support things that doesn’t work well on the screen. For example, there might be no scrolling but only whole page flipping. What’s being done on existing eink monitors is throwing the problem back to the user. The user simply need to accept that update is slow, latency is long, and the process is flashing.</p>
<p dir="auto">What Caster implemented is allowing it to switch between the fast binary mode and slow greyscale mode automatically on a per pixel basis. When the input image is changed, it switches to binary mode and do the update. When the image hasn’t changed for a while, it re-renders the image in greyscale.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Limitations</h3><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<p dir="auto">The method does come with downsides: it requires much more memory bandwidth to implement. Taking a 1080P panel as an example (roughly 120 Mp/s (million pixels per second) with reduced blanking). With the traditional method, the controller only needs the old pixel state and the new pixel state (4bpp each) to determine the voltage needed, or 8-bit/ 1-byte memory read per pixel. The bandwidth requirement is then 120Mp/s x 1B/pixel = 120MB/s. One single 16-bit SDR-133 SDRAM is more than enough to handle this. The Caster currently stores 16bit state per pixel (for 2 sets of old pixel values and pixel specific timer counters), and the pixel state needs to be updated per frame, so pixel state buffer alone requires 2-byte read and 2-byte write per pixel. It then takes another 0.5-byte per pixel to read the new image value from memory. 120Mp/s x 4.5B/pixel = 540MB/s. A 16-bit DDR-333 memory is then needed to implement this. The Glider hardware uses a DDR3-800 memory to allow even higher resolution. If the controller is not integrated inside an SoC (like our case, the controller is sitting inside the monitor, not part of your PC’s CPU/GPU), it also needs to use actual low latency video interfaces like DVI or DP, instead of simpler but slower interfaces like USB or I80/SPI. This could drive up cost as well. These techniques also don't help with use cases like reading books, so commercial ereader solutions have little reason to spend the extra trouble to implement these.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Resources Utilization</h3><a id="user-content-resources-utilization" aria-label="Permalink: Resources Utilization" href="#resources-utilization"></a></p>
<p dir="auto">The following number are for reference only and would vary depending on RTL options and specific target.</p>
<ul dir="auto">
<li>1704 FF</li>
<li>2531 LUT6</li>
<li>60 KB BRAM</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PCB</h3><a id="user-content-pcb" aria-label="Permalink: PCB" href="#pcb"></a></p>
<p dir="auto">The PCB is designed with KiCAD 8.0. To get optimal results, use a 4-layer stack up with 1080 PP layers, but 2313 or 3313 are also acceptable.</p>
<p dir="auto">There are 2 versions of the mainboard, one full version and a lite version. For now only the full version is being actively worked on. The lite version removes dedicated external decoders for DVI/ DP and removes bulk of the TypeC circuitry to lower the cost. The only video interface being a DVI port feeding directly into the FPGA.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FPGA Bitstream</h3><a id="user-content-fpga-bitstream" aria-label="Permalink: FPGA Bitstream" href="#fpga-bitstream"></a></p>
<p dir="auto">To be written</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MCU Firmware</h3><a id="user-content-mcu-firmware" aria-label="Permalink: MCU Firmware" href="#mcu-firmware"></a></p>
<p dir="auto">To be written</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Working with Waveforms</h3><a id="user-content-working-with-waveforms" aria-label="Permalink: Working with Waveforms" href="#working-with-waveforms"></a></p>
<p dir="auto">The following section describes the waveform file format and how to use them.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Obtaining Waveform</h4><a id="user-content-obtaining-waveform" aria-label="Permalink: Obtaining Waveform" href="#obtaining-waveform"></a></p>
<p dir="auto">In general, the screen vendor (Eink, Good Display, etc.) should provide the waveform file.</p>
<p dir="auto">If your screen has a flash chip on it, it's also possible to extract the waveform from a flash dump:</p>
<p dir="auto"><code>dd if=somedump.bin of=waveform.wbf bs=1 skip=2182</code></p>
<p dir="auto">If you have access to an application board, it might also be possible to extract the waveform there. For example, if the system uses T1000 controller, the waveform is usually stored in the SPI flash connected to the T1000.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Waveform Formats</h4><a id="user-content-waveform-formats" aria-label="Permalink: Waveform Formats" href="#waveform-formats"></a></p>
<p dir="auto">E-Ink distribute waveforms in the wbf file format. SoC/ Eink controller hardware often require converting the file into vendor-specific file format. Caster/ Glider also uses a specific binary format. This project defines a common human-readable format (Interchangable Waveform Format, IWF) and provides several tools for working with different binary formats and the IWF format.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Interchangable Waveform Format</h4><a id="user-content-interchangable-waveform-format" aria-label="Permalink: Interchangable Waveform Format" href="#interchangable-waveform-format"></a></p>
<p dir="auto">The waveform consists of one descriptor file in iwf extension (ini format) and various lut data files in csv format.</p>
<p dir="auto">The descriptor contains the follwoing required fields:</p>
<ul dir="auto">
<li>VERISON: the version of the descriptor (should be 2.0)</li>
<li>NAME: (optional) original name for the waveform</li>
<li>BPP: (optional, default 4) 4 or 5, representing the internal state count used for waveform</li>
<li>PREFIX: the filename prefix for actual waveform files</li>
<li>MODES: the total modes supported by the waveform</li>
<li>TEMPS: the total number of temperature ranges supported by the waveform</li>
<li>TxRANGE: the supported temperature in degC, where x is the temperature ID</li>
<li>TUPBOUND: (optional) upper bound for temperature range, each range is TxRANGE to Tx+1RANGE (or TUPBOUND in case of the last one)</li>
<li>TABLES: total number of LUTs inside the waveform</li>
<li>TBxFC: the frame count for the table, where x is the LUT ID</li>
</ul>
<p dir="auto">Each mode has its own mode section named [MODEx], where x is the mode ID, containing the following fields:</p>
<ul dir="auto">
<li>NAME: the name for that mode</li>
<li>T*TABLE: the table used for the temperature in that mode</li>
</ul>
<p dir="auto">There should be a number of LUTs, saved in the filename like PREFIX_TBx.csv, where x is the LUT ID. Each csv file should contain the a LUT like this: lut[src][dst][frame], which means, to transition from src greyscale level to dst greyscale level, at a certain frame in a frame sequence, what voltage should be applied to the screen (0/3: GND / Keep, 1: VNEG / To black, 2: VPOS / To white). Each line contains the frame sequence for one or more source to destination pairs.</p>
<p dir="auto">For example:</p>
<ul dir="auto">
<li><code>4,7,1,1,1,0,2</code> means to transition from greyscale level 4 to greyscale level 7, there should be 5 frames, each applying VNEG VNEG VNEG GND VPOS</li>
<li><code>0:14,15,2,2,2</code> means to transition from any greyscale level between 0 and 14 to greyscale level 15, there should be 3 frames, each applying VPOS VPOS VPOS</li>
</ul>
<p dir="auto">These are provided to only illustrate the file format, they are not valid or meaningful Eink driving sequences.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Converting</h4><a id="user-content-converting" aria-label="Permalink: Converting" href="#converting"></a></p>
<p dir="auto">The following converters are provided in the repo:</p>
<ul dir="auto">
<li>To convert from iwf to fw (iMX6/7 EPDC format): <code>./mxc_wvfm_asm v1/v2 input.iwf output.fw</code></li>
<li>To convert from fw to iwf: <code>./mxc_wvfm_dump v1/v2 input.fw output_prefix</code></li>
<li>To convert from wbf to iwf: <code>./wbf_wvfm_dump input.wbf output_prefix</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Compatible Screens</h3><a id="user-content-compatible-screens" aria-label="Permalink: Compatible Screens" href="#compatible-screens"></a></p>
<p dir="auto">This project only focuses on driving off-the-shelf active matrix electrophoretics displays without integrated controllers. See <a href="#screen-panels">Screen Panels</a> for differences between different types of screen panels available. That's being said, this project is compatible with majority of these panels, including sizes from 4.3" up to 13.3", and potentially supporting panels as large as 42" as well (additional power supply required in that case).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Screen Adapters</h4><a id="user-content-screen-adapters" aria-label="Permalink: Screen Adapters" href="#screen-adapters"></a></p>
<p dir="auto">Different screen panels have different connectors. It would take a huge amount of space to have every possible screen connector on the motherboard. Instead, a series of different screen adapters are provided to adapt to screen with different pinouts.</p>
<p dir="auto">The mainboard natives supports certain 40 pin screens, such as:</p>
<ul dir="auto">
<li>10.3" 1872x1404: ED103TC1, ES103TC2</li>
<li>10.1" 2232x1680: GDEW101M01, GDEW101C01</li>
</ul>
<p dir="auto">To see which adapter might work for your screen, check out the <a href="#screen-list">Appendix 1 - Screen List</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pixel Rate Considerations</h4><a id="user-content-pixel-rate-considerations" aria-label="Permalink: Pixel Rate Considerations" href="#pixel-rate-considerations"></a></p>
<p dir="auto">The input protocol and processing rate limits the screen model supported.</p>
<p dir="auto">Limit from processing rate (logic and routing delay):</p>
<ul dir="auto">
<li>Processing rate when dithering enabled: 133 MP/s</li>
<li>Processing rate when dithering disabled: 280 MP/s</li>
<li>Estimated processing rate with 8-wide design: 500 MP/s</li>
</ul>
<p dir="auto">Limit from video interface:</p>
<ul dir="auto">
<li>Maximum pixel rate using DVI (with ADV7611): 165 MP/s</li>
<li>Maximum pixel rate using DVI (direct deserializer): 105 MP/s</li>
<li>Maximum pixel rate using DisplayPort (with PTN3460): 224 MP/s</li>
<li>Maximum pixel rate using DisplayPort (with 7-series 6G SerDes): 720 MP/s</li>
<li>Maximum pixel rate using MIPI (with 1.05Gbps LVDS): 230 MP/s</li>
</ul>
<p dir="auto">Limit from memory interface (assuming 90% BW utilization):</p>
<ul dir="auto">
<li>SDR-166 x16: 60 MP/s</li>
<li>SDR-166 x32: 120 MP/s</li>
<li>DDR-400 x16: 180 MP/s</li>
<li>DDR2/3-667 x16: 300 MP/s</li>
<li>DDR2/3-800 x16: 360 MP/s</li>
<li>DDR2/3-1066 x16: 480 MP/s</li>
<li>DDR2/3-800 x32: 720 MP/s</li>
</ul>
<p dir="auto">Common screen resolution peak pixel rate (with CVT-RBv2):</p>
<ul dir="auto">
<li>1024x758 (6.0") @ 85Hz: 74 MP/s</li>
<li>1448x1072 (6.0") @ 60Hz: 101 MP/s</li>
<li>1448x1072 (6.0") @ 85Hz: 145 MP/s</li>
<li>1600x1200 (13.3") @ 60Hz: 125 MP/s</li>
<li>1600x1200 (13.3") @ 85Hz: 178 MP/s</li>
<li>1872x1404 (10.3") @ 60Hz: 169 MP/s</li>
<li>1872x1404 (10.3") @ 85Hz: 243 MP/s</li>
<li>1920x1440 (8.0") @ 60Hz: 177 MP/s</li>
<li>1920x1440 (8.0") @ 85Hz: 255 MP/s</li>
<li>2200x1650 (13.3") @ 60Hz: 232 MP/s</li>
<li>2200x1650 (13.3") @ 85Hz: 333 MP/s</li>
<li>2560x1600 (12.0") @ 60Hz: 261 MP/s</li>
<li>2560x1600 (12.0") @ 85Hz: 374 MP/s</li>
<li>2560x1920 (13.3") @ 60Hz: 313 MP/s</li>
<li>2560x1920 (13.3") @ 85Hz: 449 MP/s</li>
<li>3200x1800 (25.3") @ 60Hz: 364 MP/s</li>
<li>3200x1800 (25.3") @ 85Hz: 522 MP/s</li>
</ul>
<p dir="auto">( Calculate yourself: <a href="https://tomverbeure.github.io/video_timings_calculator" rel="nofollow">Video Timings Calculator by Tom Verbeure</a> )</p>
<p dir="auto">Rendering the grayscale requires the screen to be refreshed at 85Hz (85Hz is the Eink supported refresh rate, 60Hz can be made to work with some effort in some cases). Running input refresh rate lower than the internal refresh rate incurs additional processing latency from both source (PC) and monitor due to buffering.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Case</h3><a id="user-content-case" aria-label="Permalink: Case" href="#case"></a></p>
<p dir="auto">A reference case design is provided. The case is 3D printable and designed with FreeCAD. Note the design is currently outdated.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">References</h2><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<p dir="auto">Here is a list of helpful references related to driving EPDs:</p>
<ul dir="auto">
<li>Reverse engineering and explanation on driving EPDs: <a href="http://essentialscrap.com/eink/index.html" rel="nofollow">http://essentialscrap.com/eink/index.html</a></li>
<li>An early Eink DIY project with many useful info: <a href="http://spritesmods.com/?art=einkdisplay&amp;page=1" rel="nofollow">http://spritesmods.com/?art=einkdisplay&amp;page=1</a></li>
<li>STM32 Software bit-banging EPD driver with grayscale: <a href="https://hackaday.io/project/11537-nekocal-an-e-ink-calendar" rel="nofollow">https://hackaday.io/project/11537-nekocal-an-e-ink-calendar</a></li>
<li>ESP32 board designed for driving parallel EPDs: <a href="https://github.com/vroland/epdiy">https://github.com/vroland/epdiy</a></li>
<li>An early tool for reading Eink's wbf file format: <a href="https://github.com/fread-ink/inkwave">https://github.com/fread-ink/inkwave</a></li>
<li>A more up-to-date Eink's wbf format parser: <a href="https://patchwork.kernel.org/project/linux-arm-kernel/patch/20220413221916.50995-2-samuel@sholland.org/" rel="nofollow">https://patchwork.kernel.org/project/linux-arm-kernel/patch/20220413221916.50995-2-samuel@sholland.org/</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This document, other than refereneces explicitly given with their corresponding license, is released into public domain.</p>
<p dir="auto">The hardware design is released under the CERN Open Source Hardware License strongly-reciprocal variant, CERN-OHL-S. A copy of the license is provided in the source repository. Additionally, user guide of the license is provided on ohwr.org.</p>
<p dir="auto">The firmware code is licensed under the MIT license with the following exceptions:</p>
<p dir="auto">The USB PD library is derived from the Chromium OS project and the reclamier labs. The library is licensed under the BSD license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Appendix</h2><a id="user-content-appendix" aria-label="Permalink: Appendix" href="#appendix"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Screens without Datasheet</h3><a id="user-content-using-screens-without-datasheet" aria-label="Permalink: Using Screens without Datasheet" href="#using-screens-without-datasheet"></a></p>
<p dir="auto">To be written</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Screen List</h3><a id="user-content-screen-list" aria-label="Permalink: Screen List" href="#screen-list"></a></p>
<p dir="auto">This is a list of Eink screens and their key parameters and their compatibilities with Caster/ Glider. The information are gathered from public sources, so they might be incorrect. This is not a complete list of all screens Eink have ever produced or in production. This table is intended for hobbiests buying used screens. If you are designing a product with Eink screen please contact Eink directly.</p>
<p dir="auto">Other than a few exceptions, only screens without integrated TCON are listed here (in other words, SPI screens are generally not included here). These screens are the main focus of this project anyway.</p>
<p dir="auto">Screen size is the first 3 numbers in the model number, so it's not listed separately in the table. For example, ED060SC4 is 6.0", ED097OC1 is 9.7", and ES133UT1 is 13.3".</p>
<p dir="auto">The adapter column refers to the adapter needed for this particular screen, however there is no guarentee that it would work, even if it's listed as tested.</p>
<table>
<thead>
<tr>
<th>Model Name</th>
<th>Model Number</th>
<th>FPL Platform</th>
<th>Resolution</th>
<th>Marketing Name</th>
<th>R Typ</th>
<th>CR Typ</th>
<th>Year</th>
<th>Interface</th>
<th>Pin Count</th>
<th>Adapter</th>
<th>Tested?</th>
</tr>
</thead>
<tbody>
<tr>
<td>ED043WC1</td>
<td></td>
<td>V220</td>
<td>800x480</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2013</td>
<td>TTL</td>
<td>39</td>
<td>39P-C</td>
<td></td>
</tr>
<tr>
<td>ED043WC3</td>
<td>VA3200-DCA</td>
<td>V220</td>
<td>800x480</td>
<td>Pearl</td>
<td></td>
<td></td>
<td>2014</td>
<td>TTL</td>
<td>39</td>
<td>39P-C</td>
<td></td>
</tr>
<tr>
<td>ED043WC5</td>
<td>VD1405-CGA</td>
<td>400</td>
<td>800x480</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>SPI</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED047TC1</td>
<td></td>
<td>V220</td>
<td>960x540</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2015</td>
<td>TTL</td>
<td>44</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED047TC2</td>
<td></td>
<td>V220</td>
<td>960x540</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2016</td>
<td>TTL</td>
<td>44</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ET047TC1</td>
<td></td>
<td>320</td>
<td>960x540</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED050SC3</td>
<td></td>
<td>V110</td>
<td>800x600</td>
<td>Vizplex</td>
<td>35%</td>
<td>&gt;6:1</td>
<td>2008</td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>ED050SU3</td>
<td></td>
<td>V220</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED052TC2</td>
<td></td>
<td>320</td>
<td>960x540</td>
<td>Carta</td>
<td>45%</td>
<td>16:1</td>
<td>2016</td>
<td>TTL</td>
<td>40</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED052TC4</td>
<td>VB3300-EBA</td>
<td>320</td>
<td>1280x720</td>
<td>Carta 1.2</td>
<td>45%</td>
<td>16:1</td>
<td>2017</td>
<td>TTL</td>
<td>50</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC058TC1</td>
<td>SA1452-EHA</td>
<td>320</td>
<td>1440x720</td>
<td>Kaleido / Carta</td>
<td>24%</td>
<td>15:1</td>
<td>2020</td>
<td>TTL</td>
<td>50</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED058TC7</td>
<td></td>
<td>320</td>
<td></td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED058TC8</td>
<td>VB3300-EHB</td>
<td>320</td>
<td>1440x720</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060SC1</td>
<td></td>
<td>2.1</td>
<td>800x600</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SC3</td>
<td></td>
<td>V100</td>
<td>800x600</td>
<td>Vizplex</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SC4</td>
<td></td>
<td>V110</td>
<td>800x600</td>
<td>Vizplex</td>
<td>35%</td>
<td>&gt;6:1</td>
<td>2008</td>
<td>TTL</td>
<td>39</td>
<td>39P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SC7</td>
<td></td>
<td>V220E</td>
<td>800x600</td>
<td>Pearl</td>
<td>40%</td>
<td>12:1</td>
<td>2010</td>
<td>TTL</td>
<td>34</td>
<td>34P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SCA</td>
<td></td>
<td>V110</td>
<td>800x600</td>
<td>Vizplex</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060SCE</td>
<td></td>
<td>V220/V220E</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SCF</td>
<td></td>
<td>V220</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060SCG</td>
<td></td>
<td>V220E</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SCN</td>
<td></td>
<td>V220E</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060SCS</td>
<td></td>
<td></td>
<td>800x600</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SCP</td>
<td></td>
<td>V220</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060SCQ</td>
<td></td>
<td>V220</td>
<td>800x600</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060SCS</td>
<td></td>
<td></td>
<td>800x600</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060SCT</td>
<td></td>
<td>320</td>
<td>800x600</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-B</td>
<td></td>
</tr>
<tr>
<td>ED060SD1</td>
<td></td>
<td>320</td>
<td>800x600</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XC3</td>
<td></td>
<td>V220</td>
<td>1024x758</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ED060XC5</td>
<td></td>
<td>V220</td>
<td>1024x758</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2011</td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060XC8</td>
<td></td>
<td>V320</td>
<td>1024x758</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>35</td>
<td>35P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ED060XC9</td>
<td></td>
<td></td>
<td>1024x758</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060XCD</td>
<td></td>
<td>320</td>
<td>1024x758</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XCG</td>
<td>VD1405-FOA</td>
<td>320/400</td>
<td>1024x758</td>
<td>Carta 1000 / 1200</td>
<td>40%</td>
<td>17:1</td>
<td>2020</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XCH</td>
<td>VD1405-FOE</td>
<td>400</td>
<td>1024x758</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XD4</td>
<td></td>
<td>320</td>
<td>1024x758</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ED060XD6</td>
<td></td>
<td></td>
<td>1024x758</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060XG1</td>
<td></td>
<td>V110/V220</td>
<td>1024x758</td>
<td>Vizplex / Pearl</td>
<td>40%</td>
<td>12:1</td>
<td>2012</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XG2</td>
<td></td>
<td>V220</td>
<td>1024x758</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XG3</td>
<td></td>
<td>320</td>
<td>1024x758</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XH2</td>
<td></td>
<td></td>
<td>1024x758</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060XH7</td>
<td></td>
<td>320</td>
<td>1024x758</td>
<td>Carta 1.2</td>
<td>45%</td>
<td>17:1</td>
<td>2015</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060XH9</td>
<td>VB3300-FOG</td>
<td>320</td>
<td>1024x758</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060TC1</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>35</td>
<td>35P-A</td>
<td></td>
</tr>
<tr>
<td>ED060KC1</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td>46%</td>
<td>17:1</td>
<td>2014</td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060KC4</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060KD1</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ED060KG1</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td>47%</td>
<td>17:1</td>
<td>2015</td>
<td>TTL</td>
<td>34</td>
<td>34P-A</td>
<td></td>
</tr>
<tr>
<td>ED060KH4</td>
<td></td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060KH6</td>
<td>VB3300-FOE</td>
<td>320</td>
<td>1448x1072</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED060KHC</td>
<td></td>
<td></td>
<td>1448x1072</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC060KH3</td>
<td>SA1452-FOA</td>
<td></td>
<td>1448x1072</td>
<td>Kaleido</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED061KC1</td>
<td>VD1405-FAA</td>
<td>400</td>
<td>1648x824</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED067KC1</td>
<td>VB3300-FGA</td>
<td>320</td>
<td>1800x900</td>
<td>Carta</td>
<td>45%</td>
<td>16:1</td>
<td>2020</td>
<td>TTL</td>
<td>50</td>
<td>50P-B</td>
<td></td>
</tr>
<tr>
<td>EC067KC1</td>
<td>SA1452-FGA</td>
<td></td>
<td>1800x900</td>
<td>Kaleido</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50</td>
<td>50P-B</td>
<td></td>
</tr>
<tr>
<td>ED068TG1</td>
<td></td>
<td>320</td>
<td>1440x1080</td>
<td>Carta</td>
<td></td>
<td></td>
<td>&lt;2013</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED068TH1</td>
<td></td>
<td>320</td>
<td>1440x1080</td>
<td>Carta</td>
<td></td>
<td></td>
<td>&lt;2014</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED068TH3</td>
<td>VB3300-FHA</td>
<td>320</td>
<td>1440x1080</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED068KC1</td>
<td></td>
<td>400SU</td>
<td>1648x1236</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED068KC5</td>
<td>VD1405-FHF</td>
<td>400</td>
<td>1648x1236</td>
<td>Carta 1200</td>
<td>&gt;44%</td>
<td>&gt;19:1</td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED070KC2</td>
<td></td>
<td>320</td>
<td>1680x1264</td>
<td>Carta 1100</td>
<td>&gt;47%</td>
<td>&gt;16:1</td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED070KC3</td>
<td></td>
<td>320</td>
<td>1680x1264</td>
<td>Carta 1100</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED070KC4</td>
<td>VD1400-GOC</td>
<td>400</td>
<td>1680x1264</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED070KH1</td>
<td></td>
<td>320</td>
<td>1680x1264</td>
<td>Carta 1100</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC070KH1</td>
<td>SC1452-GOA</td>
<td></td>
<td>1680x1264</td>
<td>Kaleido Plus</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LB071WS1</td>
<td></td>
<td></td>
<td>1024x600</td>
<td></td>
<td></td>
<td>7:1</td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ET073TC1</td>
<td></td>
<td>V320</td>
<td>750x200</td>
<td>Carta</td>
<td></td>
<td></td>
<td>2016</td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED078KC1</td>
<td></td>
<td></td>
<td>1872x1404</td>
<td>Carta 1.2</td>
<td>45%</td>
<td>16:1</td>
<td>2016</td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>ED078KC2</td>
<td>VB3300-GHC</td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>ED078KH1</td>
<td></td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>ED078KH3</td>
<td></td>
<td>320</td>
<td>1872x1404</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>ED078KH4</td>
<td>VB3300-GHB</td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>EC078KH3</td>
<td>SC1452-GHA</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido Plus</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>EC078KH4</td>
<td>SC1452-GHB</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido Plus ?</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>EC078KH5</td>
<td>SC1452-GHC</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido Plus ?</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>EC078KH6</td>
<td>SC1452-GHD</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido 3</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>EC078KH7</td>
<td>SC1452-GHE</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido 3</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td></td>
</tr>
<tr>
<td>ED080XC1</td>
<td></td>
<td>V110</td>
<td>1024x768</td>
<td>Vizplex</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED080TC1</td>
<td></td>
<td>V220</td>
<td>1600x1200</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC080SC2</td>
<td></td>
<td>V250</td>
<td>600xRGBx800</td>
<td>Triton 2</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td>40P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ES080KC2</td>
<td>VD1400-HOB</td>
<td>400</td>
<td>1920x1440</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES080KH1</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>AC080KH1</td>
<td>AD1004-HOA</td>
<td>HAL3</td>
<td>1920x1440</td>
<td>Gallery 3</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED097OC1</td>
<td></td>
<td>V110A</td>
<td>1200x825</td>
<td>Vizplex</td>
<td>35%</td>
<td>7:1</td>
<td>2008</td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>ED097OC4</td>
<td></td>
<td>V110A/V220</td>
<td>1200x825</td>
<td>Vizplex / Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>ED097OD2</td>
<td></td>
<td>V220</td>
<td>1200x825</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>ED097TC1</td>
<td></td>
<td>V220</td>
<td>1200x825</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>ED097TC2</td>
<td>VB3300-JGA</td>
<td>320</td>
<td>1200x825</td>
<td>Carta 1.2</td>
<td>42%</td>
<td>16:1</td>
<td>2016</td>
<td>TTL</td>
<td>33</td>
<td>33P-A</td>
<td></td>
</tr>
<tr>
<td>EL097TR2</td>
<td>EA2220-JGB</td>
<td></td>
<td>1200x825</td>
<td>Spectra 3000</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED100UC1</td>
<td>VB3300-KOA</td>
<td>320</td>
<td>1600x1200</td>
<td>Carta</td>
<td>45%</td>
<td>16:1</td>
<td>2020</td>
<td>TTL</td>
<td>40</td>
<td>DIRECT</td>
<td></td>
</tr>
<tr>
<td>ES103TC1</td>
<td>VB3300-KCA</td>
<td>320</td>
<td>1872x1404</td>
<td>Carta 1.2</td>
<td>40%</td>
<td>12:1</td>
<td>2016</td>
<td>TTL</td>
<td>40</td>
<td>DIRECT</td>
<td></td>
</tr>
<tr>
<td>ED103TC2</td>
<td>VB3300-KCD</td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td>43%</td>
<td>14:1</td>
<td>2019</td>
<td>TTL</td>
<td>40</td>
<td>DIRECT</td>
<td></td>
</tr>
<tr>
<td>ES103TD1</td>
<td></td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES103TD3</td>
<td></td>
<td>320</td>
<td>1872x1404</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC103TD1</td>
<td>SA1452-KCC</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC103TH2</td>
<td>SC1452-KCB</td>
<td></td>
<td>1872x1404</td>
<td>Kaleido Plus</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC103KH2</td>
<td>SC1452-KCD</td>
<td></td>
<td>2480x1860</td>
<td>Kaleido 3</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES107KC1</td>
<td>VD1400-KGA</td>
<td>400</td>
<td>2560x1920</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES108FC1</td>
<td></td>
<td>320</td>
<td>1920x1080</td>
<td>Carta</td>
<td>46%</td>
<td>16:1</td>
<td>2017</td>
<td>TTL</td>
<td>50</td>
<td>50P-C</td>
<td></td>
</tr>
<tr>
<td>ES108FC2</td>
<td></td>
<td>320</td>
<td>1920x1080</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED113TC1</td>
<td>VB3300-LCA</td>
<td>320</td>
<td>2400x1034</td>
<td>Carta</td>
<td>35%</td>
<td>12:1</td>
<td>2017</td>
<td>TTL</td>
<td>50</td>
<td>50P-A</td>
<td></td>
</tr>
<tr>
<td>ED113TC2</td>
<td>VB3300-LCB</td>
<td>320</td>
<td>2400x1034</td>
<td>Carta 1.2</td>
<td>35%</td>
<td>12:1</td>
<td>2019</td>
<td>TTL</td>
<td>50</td>
<td>50P-A</td>
<td></td>
</tr>
<tr>
<td>EC113TC1</td>
<td>SC1452-LCA</td>
<td></td>
<td>2400x1034</td>
<td>Kaleido Plus ?</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50</td>
<td>50P-A</td>
<td></td>
</tr>
<tr>
<td>ED115OC1</td>
<td></td>
<td>V220</td>
<td>2760x2070</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2012</td>
<td>TTL</td>
<td>40</td>
<td>DIRECT</td>
<td></td>
</tr>
<tr>
<td>AC118TC1</td>
<td>AD1004-LHA</td>
<td></td>
<td></td>
<td>Gallery 3</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES120MC1</td>
<td>VD1400-MOA</td>
<td>400</td>
<td>2560x1600</td>
<td>Carta 1200</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>40</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES133UT1</td>
<td></td>
<td>V220</td>
<td>1600x1200</td>
<td>Pearl</td>
<td>35%</td>
<td>12:1</td>
<td>2013</td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ES133UT2</td>
<td></td>
<td>320</td>
<td>1600x1200</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>ES133UE2</td>
<td></td>
<td>320</td>
<td>1600x1200</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>ED133UT2</td>
<td>VB3300-NCB</td>
<td>320</td>
<td>1600x1200</td>
<td>Carta 1.2</td>
<td>45%</td>
<td>16:1</td>
<td>2016</td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>ED133UT3</td>
<td>VB3300-NCC</td>
<td>320</td>
<td>1600x1200</td>
<td>Carta</td>
<td>45%</td>
<td>16:1</td>
<td>2019</td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>ES133TT3</td>
<td></td>
<td>320</td>
<td>2200x1650</td>
<td>Carta 1.2</td>
<td>40%</td>
<td>12:1</td>
<td>2016</td>
<td>TTL</td>
<td>39</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ES133TT5</td>
<td>VH1948-NCC</td>
<td>450</td>
<td>2200x1650</td>
<td>Carta 1250</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC133UJ1</td>
<td>SD1452-NCB</td>
<td></td>
<td>1600x1200</td>
<td>Kaleido 3 Outdoor</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>AC133UT1</td>
<td>AA1020-NCA</td>
<td></td>
<td>1600x1200</td>
<td>Gallery / Gallery 4000</td>
<td>35%</td>
<td>10:1</td>
<td>2020</td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>EL133US1</td>
<td></td>
<td></td>
<td>1600x1200</td>
<td>Spectra 3000</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td>Yes</td>
</tr>
<tr>
<td>EL133UR1</td>
<td>EA2220-NCC</td>
<td></td>
<td>1600x1200</td>
<td>Spectra 3000</td>
<td>33%</td>
<td>15:1</td>
<td>2020</td>
<td>TTL</td>
<td>39</td>
<td>39P-A</td>
<td></td>
</tr>
<tr>
<td>EL133UF1</td>
<td>ED2208-NCA</td>
<td></td>
<td>1600x1200</td>
<td>Spectra 6</td>
<td></td>
<td></td>
<td></td>
<td>QSPI</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED140TT1</td>
<td>VB3300-IDA</td>
<td>320</td>
<td>1440x300</td>
<td>Carta</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>AC253TT1</td>
<td>AA1020-PEA</td>
<td></td>
<td>3200x1800</td>
<td>Gallery Plus / Gallery 4000</td>
<td>35%</td>
<td>10:1</td>
<td>2020</td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EL253EW1</td>
<td>ED2208-PEA</td>
<td></td>
<td>3200x1800</td>
<td>Spectra 6</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC253TT1</td>
<td>SD1452-PEA</td>
<td></td>
<td>3200x1800</td>
<td>Kaleido 3 Outdoor</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED253TT1</td>
<td>VB3300-PEA</td>
<td>320</td>
<td>3200x1800</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED253TT2</td>
<td>VB3300-PEB</td>
<td>320</td>
<td>3200x1800</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED253TT3</td>
<td>VB3300-PEC</td>
<td>320</td>
<td>3200x1800</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EL253TV1</td>
<td>EB2200-PEA</td>
<td></td>
<td>3200x1800</td>
<td>Spectra 3100</td>
<td></td>
<td></td>
<td></td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED280TT1</td>
<td>VB3300-PHA</td>
<td>320</td>
<td>3840x1080</td>
<td>Carta 1.2</td>
<td>40%</td>
<td>12:1</td>
<td>2020</td>
<td>MiniLVDS</td>
<td>51x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED312TT2</td>
<td>VA3200-QAA</td>
<td>V220</td>
<td>2560x1440</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50x4</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED312TT3</td>
<td>VA3200-QAB</td>
<td>V220</td>
<td>2560x1440</td>
<td>Pearl</td>
<td>40%</td>
<td>12:1</td>
<td>2018</td>
<td>TTL</td>
<td>50x4</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EC312TT2</td>
<td>SB1452-QAA</td>
<td></td>
<td>2560x1440</td>
<td>Triton</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50x4</td>
<td></td>
<td></td>
</tr>
<tr>
<td>EL315TW1</td>
<td>ED2208-QBA</td>
<td></td>
<td>2560x1440</td>
<td>Spectra 6</td>
<td></td>
<td></td>
<td></td>
<td>QSPI</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED420TT1</td>
<td></td>
<td>V220</td>
<td>2880x2160</td>
<td>Pearl</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED420TT3</td>
<td>VB3300-RBA</td>
<td>320</td>
<td>2880x2160</td>
<td>Carta 1.2</td>
<td>45%</td>
<td>16:1</td>
<td>2020</td>
<td>TTL</td>
<td>50x2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ED420TT5</td>
<td>VB3300-RBB</td>
<td>320</td>
<td>2880x2160</td>
<td>Carta 1.2</td>
<td></td>
<td></td>
<td></td>
<td>TTL</td>
<td>50x2</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p dir="auto">Note: Carta 1.2 is also known as Carta 1000. If the table cell says Carta it also likely means Carta 1000 (could be 1100 as well, I don't know for sure).</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini Flash (330 pts)]]></title>
            <link>https://deepmind.google/technologies/gemini/flash/</link>
            <guid>40358071</guid>
            <pubDate>Tue, 14 May 2024 18:00:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/technologies/gemini/flash/">https://deepmind.google/technologies/gemini/flash/</a>, See on <a href="https://news.ycombinator.com/item?id=40358071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <tr>
      <td>
        <p>General</p>
        <p>MMLU</p>
        <p>Representation of questions in 57 subjects (incl. STEM, humanities, and others)</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>General</p>
      </td>
      <td>
        <p>MMLU</p>
      </td>
      <td>
        <p>Representation of questions in 57 subjects (incl. STEM, humanities, and others)</p>
      </td>


      <td>
        

        <p>71.8%</p>
        
      </td>
      <td>
        

        <p>83.7%</p>
        
      </td>
      <td>
        <div>
          <p>Gemini 1.5 Pro</p>
          <p>(Feb 2024)</p>
        </div>

        <p>81.9%</p>
        
      </td>
      <td>
        <p>Gemini 1.5 Flash</p>

        <p>78.9%</p>
      </td>
    </tr>

    <tr>
      <td>
        <p>Code</p>
        <p>Natural2Code</p>
        <p>Python code generation. Held out dataset HumanEval-like, not leaked on the web</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Code</p>
      </td>
      <td>
        <p>Natural2Code</p>
      </td>
      <td>
        <p>Python code generation. Held out dataset HumanEval-like, not leaked on the web</p>
      </td>


      <td>
        

        <p>69.6%</p>
        
      </td>
      <td>
        

        <p>74.9%</p>
        
      </td>
      <td>
        <div>
          <p>Gemini 1.5 Pro</p>
          <p>(Feb 2024)</p>
        </div>

        <p>77.7%</p>
        
      </td>
      <td>
        

        <p>77.2%</p>
        
      </td>
    </tr>


    <tr>
      <td>
        <p>Math</p>
        <p>MATH</p>
        <p>Challenging math problems (incl. algebra, geometry, pre-calculus, and others)</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Math</p>
      </td>
      <td>
        <p>MATH</p>
      </td>
      <td>
        <p>Challenging math problems (incl. algebra, geometry, pre-calculus, and others)</p>
      </td>


      <td>
        

        <p>32.6%</p>
        
      </td>
      <td>
        <p>Gemini 1.0 Ultra</p>

        <p>53.2%</p>
        
      </td>
      <td>
        <div>
          <p>Gemini 1.5 Pro </p>
          <p>(Feb 2024)</p>
        </div>

        <p>58.5%</p>
        
      </td>
      <td>
        

        <p>54.9%</p>
        
      </td>
    </tr>


    <tr>
      <td>
        <p>Reasoning</p>
        <p>GPQA (main)</p>
        <p>Challenging dataset of questions written by domain experts in biology, physics, and chemistry</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Reasoning</p>
      </td>
      <td>
        <p>GPQA (main)</p>
      </td>
      <td>
        <p>Challenging dataset of questions written by domain experts in biology, physics, and chemistry</p>
      </td>


      <td>
        

        <p>27.9%</p>
        
      </td>
      <td>
        

        <p>35.7%</p>
        
      </td>
      <td>
        <div>
          <p>Gemini 1.5 Pro</p>
          <p>(Feb 2024)</p>
        </div>

        <p>41.5%</p>
        
      </td>
      <td>
        

        <p>39.5%</p>
        
      </td>
    </tr>

    <tr>
        <td>
          <p>Reasoning</p>
          <p>Big-Bench Hard</p>
          <p>Diverse set of challenging tasks requiring multi-step reasoning</p>
        </td>
      </tr>
      <tr>
        <td>
          
        </td>
        <td>
          <p>Big-Bench Hard</p>
        </td>
        <td>
          <p>Diverse set of challenging tasks requiring multi-step reasoning</p>
        </td>


        <td>
          

          <p>75.0%</p>
          
        </td>
        <td>
          

          <p>83.6%</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>84.0%</p>
          
        </td>
        <td>
          

          <p>85.5%</p>
          
        </td>
      </tr>


      <tr>
        <td>
          <p>Multilingual</p>
          <p>WMT23</p>
          <p>Language translation</p>
        </td>
      </tr>
      <tr>
        <td>
          <p>Multilingual</p>
        </td>
        <td>
          <p>WMT23</p>
        </td>
        <td>
          <p>Language translation</p>
        </td>


        <td>
          

          <p>71.7</p>
          
        </td>
        <td>
          

          <p>74.4</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>75.2</p>
          
        </td>
        <td>
          

          <p>74.1</p>
          
        </td>
      </tr>


      <tr>
        <td>
          <p>Image</p>
          <p> MMMU</p>
          <p>Multi-discipline college-level reasoning problems</p>
        </td>
      </tr>
      <tr>
        <td>
          <p>Image</p>
        </td>
        <td>
          <p>MMMU</p>
        </td>
        <td>
          <p>Multi-discipline college-level reasoning problems</p>
        </td>


        <td>
          

          <p>47.9%</p>
          
        </td>
        <td>
          

          <p>59.4%</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>58.5%</p>
          
        </td>
        <td>
          

          <p>56.1%</p>
          
        </td>
      </tr>


      <tr>
        <td>
          <p>Image</p>
          <p> MathVista</p>
          <p>Multi-discipline college-level reasoning problems</p>
        </td>
      </tr>
      <tr>
        <td>
          
        </td>
        <td>
          <p>MathVista</p>
        </td>
        <td>
          <p>Mathematical reasoning in visual contexts</p>
        </td>


        <td>
          

          <p>45.2%</p>
          
        </td>
        <td>
          

          <p>53.0%</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>52.1%</p>
          
        </td>
        <td>
          

          <p>54.3%</p>
          
        </td>
      </tr>


      <tr>
        <td>
          <p>Audio</p>
          <p> FLEURS (55 languages)</p>
          <p>Automatic speech recognition (based on word error rate, lower is better)</p>
        </td>
      </tr>
      <tr>
        <td>
          <p>Audio</p>
        </td>
        <td>
          <p>FLEURS (55 languages)</p>
        </td>
        <td>
          <p>Automatic speech recognition (based on word error rate, lower is better)</p>
        </td>


        <td>
          

          <p>6.4</p>
          
        </td>
        <td>
          

          <p>6.0</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>6.6</p>
          
        </td>
        <td>
          

          <p>9.8</p>
          
        </td>
      </tr>


      <tr>
        <td>
          <p>Video</p>
          <p>EgoSchema</p>
          <p>Video question answering</p>
        </td>
      </tr>
      <tr>
        <td>
          <p>Video</p>
        </td>
        <td>
          <p>EgoSchema</p>
        </td>
        <td>
          <p>Video question answering</p>
        </td>


        <td>
          

          <p>55.7%</p>
          
        </td>
        <td>
          

          <p>61.5%</p>
          
        </td>
        <td>
          <div>
            <p>Gemini 1.5 Pro</p>
            <p>(Feb 2024)</p>
          </div>

          <p>63.2%</p>
          
        </td>
        <td>
          

          <p>63.5%</p>
          
        </td>
      </tr>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Veo (1138 pts)]]></title>
            <link>https://deepmind.google/technologies/veo/</link>
            <guid>40358041</guid>
            <pubDate>Tue, 14 May 2024 17:58:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/technologies/veo/">https://deepmind.google/technologies/veo/</a>, See on <a href="https://news.ycombinator.com/item?id=40358041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p data-block-key="6gb7v">Veo is our most capable video generation model to date. It generates high-quality, 1080p resolution videos that can go beyond a minute, in a wide range of cinematic and visual styles.</p><p data-block-key="c6nlk">It accurately captures the nuance and tone of a prompt, and provides an unprecedented level of creative control — understanding prompts for all kinds of cinematic effects, like time lapses or aerial shots of a landscape.</p><p data-block-key="a5heq">Our video generation model will help create tools that make video production accessible to everyone. Whether you're a seasoned filmmaker, aspiring creator, or educator looking to share knowledge, Veo unlocks new possibilities for storytelling, education and more.</p><p data-block-key="8rfgr">Over the coming weeks some of these features will be available to select creators through <a href="http://labs.google/videofx" rel="noopener" target="_blank">VideoFX</a>, a new experimental tool at labs.google. You can join the <a href="http://labs.google/VideoFX" rel="noopener" target="_blank">waitlist</a> now.</p><p data-block-key="5veag">In the future, we’ll also bring some of Veo’s capabilities to <a href="https://www.youtube.com/shorts" rel="noopener" target="_blank">YouTube Shorts</a> and other products.</p>
</div><div>
  <h2 data-block-key="6gb7v">Greater understanding of language and vision</h2><p data-block-key="ecr6v">To produce a coherent scene, generative video models need to accurately interpret a text prompt and combine this information with relevant visual references.</p><p data-block-key="6mpal">With advanced understanding of natural language and visual semantics, Veo generates video that closely follows the prompt. It accurately captures the nuance and tone in a phrase, rendering intricate details within complex scenes.</p>
</div><div>
  <h2 data-block-key="penxw">Controls for film-making</h2><p data-block-key="eg3us">When given both an input video and editing command, like adding kayaks to an aerial shot of a coastline, Veo can apply this command to the initial video and create a new, edited video.</p>
</div><div>
  <p data-block-key="40xdi">In addition, it supports masked editing, enabling changes to specific areas of the video when you add a mask area to your video and text prompt.</p><p data-block-key="8tcfm">Veo can also generate a video with an image as input along with the text prompt. By providing a reference image in combination with a text prompt, it conditions Veo to generate a video that follows the image’s style and user prompt’s instructions.</p>
</div><p data-block-key="u0m94">The model is also able to make video clips and extend them to 60 seconds and beyond. It can do this either from a single prompt, or by being given a sequence of prompts which together tell a story.</p><div>
  <h2 data-block-key="hx1qs">Consistency across video frames</h2><p data-block-key="dl81n">Maintaining visual consistency can be a challenge for video generation models. Characters, objects, or even entire scenes can flicker, jump, or morph unexpectedly between frames, disrupting the viewing experience.</p><p data-block-key="77hdm">Veo's cutting-edge latent diffusion transformers reduce the appearance of these inconsistencies, keeping characters, objects and styles in place, as they would in real life.</p>
</div><div>
  <h2 data-block-key="t4vz1">Built upon years of video generation research</h2><p data-block-key="5icm9">Veo builds upon years of generative video model work including <a href="https://deepmind.google/discover/blog/neural-scene-representation-and-rendering/" rel="noopener" target="_blank">Generative Query Network</a> (GQN), <a href="https://arxiv.org/abs/1907.06571" rel="noopener" target="_blank">DVD-GAN</a>, <a href="https://imagen.research.google/video/" rel="noopener" target="_blank">Imagen-Video</a>, <a href="https://phenaki.video/" rel="noopener" target="_blank">Phenaki</a>, <a href="https://walt-video-diffusion.github.io/" rel="noopener" target="_blank">WALT</a>, <a href="https://sites.research.google/videopoet/" rel="noopener" target="_blank">VideoPoet</a> and <a href="https://lumiere-video.github.io/" rel="noopener" target="_blank">Lumiere</a>, and also our <a href="https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/" rel="noopener" target="_blank">Transformer architecture</a> and <a href="https://deepmind.google/technologies/gemini/#introduction" rel="noopener" target="_blank">Gemini</a>.</p><p data-block-key="3mt37">To help Veo understand and follow prompts more accurately, we have also added more details to the captions of each video in its training data. And to further improve performance, the model uses high-quality, compressed representations of video (also known as latents) so it’s more efficient too. These steps improve overall quality and reduce the time it takes to generate videos.</p>
</div><div>
  <h2 data-block-key="wdxqg">Responsible by design</h2><p data-block-key="conb7">It's critical to bring technologies like Veo to the world responsibly. Videos created by Veo are watermarked using <a href="https://deepmind.google/technologies/synthid/" rel="noopener" target="_blank">SynthID</a>, our cutting-edge tool for watermarking and identifying AI-generated content, and passed through safety filters and memorization checking processes that help mitigate privacy, copyright and bias risks.</p><p data-block-key="5bgom">Veo’s future will be informed by our work with leading creators and filmmakers. Their feedback helps us improve our generative video technologies and makes sure they benefit the wider creative community and beyond.</p>
</div><p data-block-key="3s614"><i>Note: All videos on this page were generated by Veo and have not been modified.</i></p><div>
  <h3 data-block-key="fnixr">Acknowledgements</h3><p data-block-key="67cd">This work was made possible by the exceptional contributions of: Abhishek Sharma, Adams Yu, Ali Razavi, Andeep Toor, Andrew Pierson, Ankush Gupta, Austin Waters, Daniel Tanis, Dumitru Erhan, Eric Lau, Eleni Shaw, Gabe Barth-Maron, Greg Shaw, Han Zhang, Henna Nandwani, Hernan Moraldo, Hyunjik Kim, Irina Blok, Jakob Bauer, Jeff Donahue, Junyoung Chung, Kory Mathewson, Kurtis David, Lasse Espeholt, Marc van Zee, Matt McGill, Medhini Narasimhan, Miaosen Wang, Mikołaj Bińkowski, Mohammad Babaeizadeh, Mohammad Taghi Saffar, Nick Pezzotti, Pieter-Jan Kindermans, Poorva Rane, Rachel Hornung, Robert Riachi, Ruben Villegas, Rui Qian, Sander Dieleman, Serena Zhang, Serkan Cabi, Shixin Luo, Shlomi Fruchter, Signe Nørly, Srivatsan Srinivasan, Tobias Pfaff, Tom Hume, Vikas Verma, Weizhe Hua, William Zhu, Xinchen Yan, Xinyu Wang, Yelin Kim, Yuqing Du and Yutian Chen.</p><p data-block-key="52ut7">We extend our gratitude to Aida Nematzadeh, Alex Cullum, April Lehman, Aäron van den Oord, Charlie Chen, Charline Le Lan, Cristian Țăpuș, David Bridson, Emanuel Taropa, Gavin Buttimore, Geng Yan, Greg Shaw, Harsha Vashisht, Hartwig Adam, Huisheng Wang, Jacob Austin, Jim Lin, Jonas Adler, Joost van Amersfoort, Jordi Pont-Tuset, Josh V. Dillon, Kristian Kjems, Lois Zhou, Luis C. Cobo, Maigo Le, Malcolm Reynolds, Marcus Wainwright, Mary Cassin, Matt Smart, Matt Young, Mingda Zhang, Minh Giang, Moritz Dickfeld, Nancy Xiao, Nelly Papalampidi, Nir Shabat, Ollie Purkiss, Oskar Bunyan, Patrice Oehen, Pete Aykroyd, Petko Georgiev, Phil Chen, Rakesh Shivanna, Ramya Ganeshan, Richard Nguyen, RJ Mical, Rohan Anil, Sam Haves, Shanshan Zheng, Sholto Douglas, Siddhartha Brahma, Tatiana López, Tobias Pfaff, Victor Gomes, Vighnesh Birodkar, Xin Chen, Yi-Ling Wang, Yilin Ma, Yori Zwols, Yu Qiao, Yuchen Liang, Yusuf Aytar and Zu Kim for their invaluable partnership in developing and refining key components of this project.</p><p data-block-key="2t4u">Special thanks to Douglas Eck, Nando de Freitas, Oriol Vinyals, Eli Collins, Koray Kavukcuoglu and Demis Hassabis for their insightful guidance and support throughout the research process.</p><p data-block-key="5hie">We also acknowledge the many other individuals who contributed across Google DeepMind and our partners at Google.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alabama prisoners' organs vanish, and there's a whole lot of passing the buck (124 pts)]]></title>
            <link>https://www.al.com/news/2024/02/archibald-alabama-prisoners-organs-vanish-and-theres-a-whole-lot-of-passing-the-buck-and-the-bodies.html</link>
            <guid>40357724</guid>
            <pubDate>Tue, 14 May 2024 17:32:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.al.com/news/2024/02/archibald-alabama-prisoners-organs-vanish-and-theres-a-whole-lot-of-passing-the-buck-and-the-bodies.html">https://www.al.com/news/2024/02/archibald-alabama-prisoners-organs-vanish-and-theres-a-whole-lot-of-passing-the-buck-and-the-bodies.html</a>, See on <a href="https://news.ycombinator.com/item?id=40357724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="MNIDF2JXAJBHBLDPVV5LICSLEQ"><i>This is an opinion column.</i></p><p id="VAR73NT36BAVDN2BGOWWTXL5AI">What’s happening in Alabama is ghoulish. Like some kind of B movie.</p><p id="JZSY5PREVRANRIWWQEOHUH4SGQ"><i>Evasion by the Body Snatchers</i>. Or <i>Resident Retrieval.</i></p><p id="G3AOB6LWXRB6BJIA5LNMTOGM4E">Except it’s real life. And real death.</p><p id="I73BYVSE6RGRHE3CSMCW4WKINU">Brandon Dotson died in November at an Alabama prison in Clayton. When his <a href="https://www.al.com/news/birmingham/2024/01/alabama-still-cant-find-heart-missing-from-prisoners-body.html">body was returned to Dotson’s family, it contained no heart</a>.</p><p id="TZ6UBE5TIJBE7FIE5QDT36PIEM">Like the prison system itself, some would argue.</p><p id="WU4NCETNWRDYBFZ3AZ34QFJ7JY">Kelvin Moore died earlier last year at a prison in – dare I even say it – Harvest, Alabama. When his family got his body <a href="https://andscape.com/features/alabama-prison-kelvin-moore-missing-organs/">it was missing organs, too</a>.</p><p id="H3IHH56BLVGA7MLUVCCFU6QFR4">And when Charles Singleton, incarcerated at the Hamilton Aged and Infirmed prison in north Alabama, died at a hospital in November 2021, his body was returned to family after an autopsy at UAB.</p><p id="A3HN5L3U75E5ZGWMWYURU2H4QQ"><a href="https://www.al.com/news/birmingham/2024/02/alabama-prisoners-brain-missing-after-uab-autopsy-says-family.html">It was missing a brain</a>, among other organs.</p><p id="PZOM5UFOGNHR5GGEGA6JKHILUQ">I’d make a Wizard of Oz joke about Alabama missing the courage to address these nightmares, but there is nothing whimsical about this.</p><p id="WDVYABV42BA65DBJ4NFLLO5C2A">Alabama, apparently with the University of Alabama at Birmingham and the Alabama Department of Forensic Sciences as its scalpels, is treating its incarcerated people in death the same way it does in life.</p><p id="JPZOQ5E7JZGVPE2XU2AJKZI3EY">As meat. Stripped of humanity, exploited for labor or whim or scientific advancement because – because we can call them criminals instead of people.</p><p id="O3ZF3AVTBJGP7LQTYHXAZH5DRE">It’s as simple as that.</p><p id="E43CROYIDFB7XCV5MCAMRJOKEQ">Oh, the Alabama Department of Corrections can shrug and point vaguely at UAB, and UAB can shrug and point vaguely to legal documents that appear to give it the right to remove organs for study and instruction. And they are probably safe on that. The best medical complex in these parts likely covered its own parts when it took part in taking those parts.</p><p id="OBGKB3BZIVFLHONDGICOR6F5HE">But there were warnings.</p><p id="XI2JUF2VSFAWTM47QIYBNG4DKE">In 2018, UAB medical students worried about the process of extracting organs from people who died in custody and did not give consent. Two of those students, representing a group of 13, went before doctors that September to “seek guidance about the legal and the ethical status of this tissue procurement process and the teaching use of these specimens.”</p><p id="64QDZTC475H2FFLO52IBYWZZDI">The students did not get a lot of satisfaction, according to notes of that meeting filed in federal court.</p><p id="NZQXBTURKVFQFM3DTS5PJIDE5A">The students were told the removal of organs were part of autopsies required by law for prisoners. They were told that using them for teaching future physicians “benefits future patients,” and if organs weren’t used they’d be thrown away and would serve no useful purpose.</p><p id="LCEIYMNBEVFLDKSMU4OYHXWVF4">The students were told that in private autopsies – not the ones involving prisoner deaths – family members can opt out of allowing that sort of organ use. UAB ethicists told those students opting out is extremely rare.</p><p id="ST7DJFC6AJDAROCF7HKBCQHHAI">“Of over 3,000 cases of gross autopsy performed at UAB from 2011 to present, only four families refused to allow the teaching uses of the deceased person’s specimens,” they said.</p><p id="IIZG4JIUMBCITC2TJUJOYPRQNY">But that’s the thing.</p><p id="KO6X2WGG4FEDHDJTJP5VZNSEN4">The families of these inmates had no such opportunity. They got news of their loved ones’ deaths, and bodies returned with pieces missing.</p><p id="TZG6MTTGZBEZZMROKMQG2MV3EY">UAB has insisted it follows the letter of the law. A UAB statement sent recently to <a href="http://al.com/" target="_blank">AL.com</a> said the school “only conducts autopsies after obtaining consent or authorization from the appropriate state official.”</p><p id="Z3C75MI76NGVZDDRDOZEESXIWQ">Whoever that might be.</p><p id="V54TPHWJQZD6FDNN3A56LZKBWM">It went on to say “the ADOC is responsible for obtaining proper authorizations from the appropriate legal representative of the deceased. The authorization forms not only provide permission for the autopsy, but also specifically include consent for the removal of organs or tissues for diagnostic or other testing including final disposition.”</p><p id="VTF476LH3FCQHPXTQOLFWFHF2M">ADOC, in another statement to my colleague Ivana Hrynkiw, said “the ADOC does not authorize or perform autopsies. Once an inmate dies, the body is transported to the Alabama Department of Forensic Sciences or UAB for autopsy.”</p><p id="EBQDYS6YNRASTKDKTVUZY5BW6Y">The <a href="https://andscape.com/features/alabama-prison-kelvin-moore-missing-organs/">publication Andscape</a> spoke to a former UAB&nbsp; student about how <a href="https://andscape.com/features/alabama-prison-kelvin-moore-missing-organs/">course instructors explained</a> what happens:</p><p id="4SYHMX7A45FAXEONGRZBYEHVPE">“They shared with us that when the prison warden filled out the autopsy request form, they rarely check the box to opt out of organ use for educational and research purposes,” the student told that publication.</p><p id="P2PUHM52RJAJZFDNZRKGAIDK3Y">That’s been a tug of war, too.</p><p id="DWGSL3B5K5FNRAWTO5FRC7QEH4">In a federal courtroom back and forth over Dotson’s missing heart, Alabama prison officials said they gave the body, intact, to the Alabama Department of Forensic Sciences, which didn’t have much of an answer for any of it. It was after a second autopsy, ordered by the Dotson family and performed by a private doctor, that no heart was found.</p><p id="5MRVBUBFJRB3ZIUTELDNAG436M">In more ways than one.</p><p id="CZ6OW24UYVAIJARQYL5PPTBLJE">It’s a whole lot of passing the buck. And the bodies.</p><p id="RGTXY4HKZVABRM2VC7J7XBGKXA">Because when prisoners’ families have no opportunity to opt out of organ collection, nobody opts out. ADOC passes to UAB or the Alabama Department of Forensic Sciences and UAB takes what it will and passes what’s left of the bodies to the only people who care about them.</p><p id="VNBD6SD3Y5F5TOJCAWIZZDCZDM">And nobody in charge thinks it matters at all.</p><p id="EIJO4PCC75DZ7CSSBSKK4O6YLM">It’s just a body. Just a prisoner.</p><p id="Y2E6ICX6GRG7VJGAUIV7KKPBVU"><i>John Archibald is a two-time Pulitzer winner for AL.com.</i></p></div><p>If you purchase a product or register for an account through a link on our site, we may receive compensation.<span> By using this site, you consent to our <a href="https://www.advancelocal.com/advancelocalUserAgreement/user-agreement.html" target="_blank" rel="noopener noreferrer">User Agreement</a> and agree that your clicks, interactions, and personal information may be collected, recorded, and/or stored by us and social media and other third-party partners in accordance with our <a href="https://www.advancelocal.com/advancelocalUserAgreement/privacy-policy.html" target="_blank" rel="noopener noreferrer">Privacy Policy.</a></span></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Edge AI Model Explorer (233 pts)]]></title>
            <link>https://github.com/google-ai-edge/model-explorer</link>
            <guid>40357681</guid>
            <pubDate>Tue, 14 May 2024 17:29:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google-ai-edge/model-explorer">https://github.com/google-ai-edge/model-explorer</a>, See on <a href="https://news.ycombinator.com/item?id=40357681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">Model Explorer <a href="https://badge.fury.io/py/ai-edge-model-explorer" rel="nofollow"><img src="https://camo.githubusercontent.com/590aa6824f7a10547298327b66cfcc6a926b355943eb17b763a9ec05aa80db71/68747470733a2f2f62616467652e667572792e696f2f70792f61692d656467652d6d6f64656c2d6578706c6f7265722e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/ai-edge-model-explorer.svg"></a></h2><a id="user-content-model-explorer-" aria-label="Permalink: Model Explorer " href="#model-explorer-"></a></div>
<p dir="auto">Model Explorer offers an intuitive and hierarchical visualization of model
graphs. It organizes model operations into nested layers, enabling users to
dynamically expand or collapse these layers. It also provides a range of
features to facilitate model exploration and debugging, including the ability to
highlight input and output operations, overlay metadata on nodes, display layers
in interactive pop-ups, perform searches, show identical layers, GPU-accelerated
graph rendering, among others. It currently supports TFLite, TF, TFJS, MLIR, and
PyTorch (Exported Program) model format, and provides an extension framework for
developers to easily add support for additional formats.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/google-ai-edge/model-explorer/blob/main/screenshots/main_ui.png"><img width="890" alt="Home page screenshot" src="https://github.com/google-ai-edge/model-explorer/raw/main/screenshots/main_ui.png"></a></p>

<p dir="auto">To start using Model Explorer, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ pip install ai-edge-model-explorer
$ model-explorer"><pre>$ pip install ai-edge-model-explorer
$ model-explorer</pre></div>
<p dir="auto">Please check out our <a href="https://github.com/google-ai-edge/model-explorer/wiki">Wiki</a> for
more details:</p>
<ul dir="auto">
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/1.-Installation">Installation</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/2.-User-Guide">User Guide</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/3.-Command-Line-Guide">Command Line Guide</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/4.-API-Guide">API Guide</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/5.-Run-in-Colab-Notebook">Run in Colab Notebook</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/6.-Develop-Adapter-Extension">Develop Adapter Extension</a></li>
<li><a href="https://github.com/google-ai-edge/model-explorer/wiki/7.-Limitations-and-Known-Issues">Limitations and Known Issues</a></li>
</ul>
<p dir="auto">We invite you to participate in our future research studies on Model Explorer. Sign up <a href="https://docs.google.com/forms/d/e/1FAIpQLScGOkQOIKmIzkt3P0ywhSfwbl-TRb2epEV5J8NTXEesZqc3vw/viewform" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributions</h2><a id="user-content-contributions" aria-label="Permalink: Contributions" href="#contributions"></a></p>
<p dir="auto">We are not accepting contributions to Model Explorer at this time. The Model Explorer team will contribute to this repository.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Is Shuttering Workplace, Its Enterprise Version of Facebook (122 pts)]]></title>
            <link>https://finance.yahoo.com/news/meta-shuttering-workplace-enterprise-version-170030864.html</link>
            <guid>40357671</guid>
            <pubDate>Tue, 14 May 2024 17:28:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/meta-shuttering-workplace-enterprise-version-170030864.html">https://finance.yahoo.com/news/meta-shuttering-workplace-enterprise-version-170030864.html</a>, See on <a href="https://news.ycombinator.com/item?id=40357671">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Meta Platforms Inc. is shutting down Workplace, the enterprise version of Facebook that it once hoped might rival Slack and other office productivity tools.</p><p>Most Read from Bloomberg</p><ul><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-12/trump-vows-day-one-executive-order-targeting-offshore-wind?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Trump Vows ‘Day One’ Executive Order Targeting Offshore Wind;elm:context_link;itc:0;sec:content-canvas">Trump Vows ‘Day One’ Executive Order Targeting Offshore Wind</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-14/biden-imposes-sweeping-tariffs-on-chinese-chips-minerals-evs?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Biden Accuses China of ‘Cheating’ on Trade, Imposes New Tariffs;elm:context_link;itc:0;sec:content-canvas">Biden Accuses China of ‘Cheating’ on Trade, Imposes New Tariffs</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2024-05-13/macron-suggests-big-m-a-plan-for-europe-s-economy-revival?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Macron Puts French Banks in Play With Plan to Transform Europe;elm:context_link;itc:0;sec:content-canvas">Macron Puts French Banks in Play With Plan to Transform Europe</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2024-05-13/not-just-adani-ambani-5-billionaires-helping-modi-transform-india-s-economy?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Five Under-the-Radar Billionaires Making Vast Fortunes in Modi's India;elm:context_link;itc:0;sec:content-canvas">Five Under-the-Radar Billionaires Making Vast Fortunes in Modi's India</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-13/flood-of-chinese-used-cooking-oil-spurs-call-to-boost-us-tariffs?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Flood of China Used Cooking Oil Spurs Call to Hike US Levies;elm:context_link;itc:0;sec:content-canvas">Flood of China Used Cooking Oil Spurs Call to Hike US Levies</a></p></li></ul><p>Workplace will be phased out over the next two years and will remain operational until the end of August 2025, according to a company spokesperson. The service operated much like the original Facebook social network, but let people have separate accounts for their work interactions. Workplace had as many as 7 million total paying subscribers in May 2021.</p><p>“We are discontinuing Workplace from Meta so we can focus on building AI and metaverse technologies that we believe will fundamentally reshape the way we work,” the spokesperson said in a statement. The company said it will help existing customers transition to Zoom Video Communications Inc.’s Workvivo product, a similar enterprise-focused social network, over the next few years.</p><p>TechCrunch first reported on Meta’s plan to shutter Workplace.</p><p>Meta once had ambitious plans for Workplace, and viewed it as a way to make money through subscriptions as well as a chance to extend Facebook’s reach by infusing the product into work and office settings. At one point, Meta touted a list of high-profile customers, including Starbucks Corp., Walmart Inc. and Spotify Technology SA.</p><p>The company will continue to focus on workplace-related products, a spokesperson said, but in other areas, such as the metaverse by building features for the company’s Quest VR headsets.</p><p>Workplace will continue to exist internally at Meta for company employees, who use the product for everyday collaboration with colleagues. Even after Workplace is shut down in August 2025, customers will have access to their data until the end of May 2026, Meta said.</p><p>Most Read from Bloomberg Businessweek</p><ul><li><p><a href="https://www.bloomberg.com/news/features/2024-05-14/the-stock-market-multilevel-marketing-company-for-teens?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:How the ‘Harvard of Trading’ Ruined Thousands of Young People’s Lives;elm:context_link;itc:0;sec:content-canvas">How the ‘Harvard of Trading’ Ruined Thousands of Young People’s Lives</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-13/parents-sue-video-game-makers-for-purposely-addicting-their-kids?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Kids Hooked on Video Games Prompt a Flurry of Lawsuits;elm:context_link;itc:0;sec:content-canvas">Kids Hooked on Video Games Prompt a Flurry of Lawsuits</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-14/china-tensions-drive-spending-at-us-east-coast-ports?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:US East Coast Ports Are Spending Billions to Profit From Asia’s Shifting Exports;elm:context_link;itc:0;sec:content-canvas">US East Coast Ports Are Spending Billions to Profit From Asia’s Shifting Exports</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2024-05-11/us-prison-labor-powers-billions-in-corporate-government-revenue?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Cheap Prison Labor Is Keeping People Locked Up Longer, Suit Alleges;elm:context_link;itc:0;sec:content-canvas">Cheap Prison Labor Is Keeping People Locked Up Longer, Suit Alleges</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2024-05-10/the-caitlin-clark-effect-is-already-changing-the-wnba?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:‘The Caitlin Clark Effect Is Real,’ and It’s Already Changing the WNBA;elm:context_link;itc:0;sec:content-canvas">‘The Caitlin Clark Effect Is Real,’ and It’s Already Changing the WNBA</a></p></li></ul><p>©2024 Bloomberg L.P.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Glance: A self-hosted dashboard that puts all your feeds in one place (111 pts)]]></title>
            <link>https://github.com/glanceapp/glance</link>
            <guid>40357611</guid>
            <pubDate>Tue, 14 May 2024 17:23:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/glanceapp/glance">https://github.com/glanceapp/glance</a>, See on <a href="https://news.ycombinator.com/item?id=40357611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><em>What if you could see everything at a...</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Glance</h2><a id="user-content-glance" aria-label="Permalink: Glance" href="#glance"></a></p>
<p dir="auto"><a href="#installation">Install</a> • <a href="https://github.com/glanceapp/glance/blob/main/docs/configuration.md">Configuration</a> • <a href="https://github.com/glanceapp/glance/blob/main/docs/themes.md">Themes</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/glanceapp/glance/blob/main/docs/images/readme-main-image.png"><img src="https://github.com/glanceapp/glance/raw/main/docs/images/readme-main-image.png" alt="example homepage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Various widgets</h4><a id="user-content-various-widgets" aria-label="Permalink: Various widgets" href="#various-widgets"></a></p>
<ul dir="auto">
<li>RSS feeds</li>
<li>Subreddit posts</li>
<li>Weather</li>
<li>Bookmarks</li>
<li>Latest YouTube videos from specific channels</li>
<li>Calendar</li>
<li>Stocks</li>
<li>iframe</li>
<li>Twitch channels &amp; top games</li>
<li>GitHub releases</li>
<li>Repository overview</li>
<li>Site monitor</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Themeable</h4><a id="user-content-themeable" aria-label="Permalink: Themeable" href="#themeable"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/glanceapp/glance/blob/main/docs/images/themes-example.png"><img src="https://github.com/glanceapp/glance/raw/main/docs/images/themes-example.png" alt="multiple color schemes example"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Optimized for mobile devices</h4><a id="user-content-optimized-for-mobile-devices" aria-label="Permalink: Optimized for mobile devices" href="#optimized-for-mobile-devices"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/glanceapp/glance/blob/main/docs/images/mobile-preview.png"><img src="https://github.com/glanceapp/glance/raw/main/docs/images/mobile-preview.png" alt="mobile device previews"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fast and lightweight</h4><a id="user-content-fast-and-lightweight" aria-label="Permalink: Fast and lightweight" href="#fast-and-lightweight"></a></p>
<ul dir="auto">
<li>Minimal JS, no bloated frameworks</li>
<li>Very few dependencies</li>
<li>Single, easily distributed &lt;15mb binary and just as small docker container</li>
<li>All requests are parallelized, uncached pages usually load within ~1s (depending on internet speed and number of widgets)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Checkout the <a href="https://github.com/glanceapp/glance/blob/main/docs/configuration.md">configuration docs</a> to learn more. A <a href="https://github.com/glanceapp/glance/blob/main/docs/configuration.md#preconfigured-page">preconfigured page</a> is also available to get you started quickly.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto"><p dir="auto">Caution</p>
<p dir="auto">The project is under active development, expect things to break every once in a while.</p>
</div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manual</h4><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto">Checkout the <a href="https://github.com/glanceapp/glance/releases">releases page</a> for available binaries. You can place the binary inside <code>/opt/glance/</code> and have it start with your server via a <a href="https://linuxhandbook.com/create-systemd-services/" rel="nofollow">systemd service</a>. To specify a different path for the config file use the <code>--config</code> option:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/opt/glance/glance --config /etc/glance.yml"><pre>/opt/glance/glance --config /etc/glance.yml</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Docker</h4><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">Make sure you have a valid <code>glance.yml</code> file in the same directory before running the container.</p>
</div>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d -p 8080:8080 \
  -v ./glance.yml:/app/glance.yml \
  -v /etc/timezone:/etc/timezone:ro \
  -v /etc/localtime:/etc/localtime:ro \
  glanceapp/glance"><pre>docker run -d -p 8080:8080 \
  -v ./glance.yml:/app/glance.yml \
  -v /etc/timezone:/etc/timezone:ro \
  -v /etc/localtime:/etc/localtime:ro \
  glanceapp/glance</pre></div>
<p dir="auto">Or if you prefer docker compose:</p>
<div dir="auto" data-snippet-clipboard-copy-content="services:
  glance:
    image: glanceapp/glance
    volumes:
      - ./glance.yml:/app/glance.yml
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - 8080:8080
    restart: unless-stopped"><pre><span>services</span>:
  <span>glance</span>:
    <span>image</span>: <span>glanceapp/glance</span>
    <span>volumes</span>:
      - <span>./glance.yml:/app/glance.yml</span>
      - <span>/etc/timezone:/etc/timezone:ro</span>
      - <span>/etc/localtime:/etc/localtime:ro</span>
    <span>ports</span>:
      - <span>8080:8080</span>
    <span>restart</span>: <span>unless-stopped</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from source" href="#building-from-source"></a></p>
<p dir="auto">Requirements: <a href="https://go.dev/dl/" rel="nofollow">Go</a> &gt;= v1.22</p>
<p dir="auto">To build:</p>
<div dir="auto" data-snippet-clipboard-copy-content="go build -o build/glance ."><pre>go build -o build/glance <span>.</span></pre></div>
<p dir="auto">To run:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Building Docker image</h3><a id="user-content-building-docker-image" aria-label="Permalink: Building Docker image" href="#building-docker-image"></a></p>
<p dir="auto">Build Glance with CGO disabled:</p>
<div dir="auto" data-snippet-clipboard-copy-content="CGO_ENABLED=0 go build -o build/glance ."><pre>CGO_ENABLED=0 go build -o build/glance <span>.</span></pre></div>
<p dir="auto">Build the image:</p>
<p dir="auto"><strong>Make sure to replace "owner" with your name or organization.</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build -t owner/glance:latest -f Dockerfile.single-platform ."><pre>docker build -t owner/glance:latest -f Dockerfile.single-platform <span>.</span></pre></div>
<p dir="auto">Push the image to your registry:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker push owner/glance:latest"><pre>docker push owner/glance:latest</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VMware Fusion Pro and Workstation Pro now free for all personal use (287 pts)]]></title>
            <link>https://blogs.vmware.com/teamfusion/2024/05/fusion-pro-now-available-free-for-personal-use.html</link>
            <guid>40357271</guid>
            <pubDate>Tue, 14 May 2024 16:55:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.vmware.com/teamfusion/2024/05/fusion-pro-now-available-free-for-personal-use.html">https://blogs.vmware.com/teamfusion/2024/05/fusion-pro-now-available-free-for-personal-use.html</a>, See on <a href="https://news.ycombinator.com/item?id=40357271">Hacker News</a></p>
Couldn't get https://blogs.vmware.com/teamfusion/2024/05/fusion-pro-now-available-free-for-personal-use.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Sir, there's a cat in your mirror dimension (328 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/sir-theres-a-cat-in-your-mirror-dimension</link>
            <guid>40357141</guid>
            <pubDate>Tue, 14 May 2024 16:42:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/sir-theres-a-cat-in-your-mirror-dimension">https://lcamtuf.substack.com/p/sir-theres-a-cat-in-your-mirror-dimension</a>, See on <a href="https://news.ycombinator.com/item?id=40357141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>A </span><a href="https://lcamtuf.substack.com/p/not-so-fast-mr-fourier" rel="">while back</a><span>, we talked about the </span><em>frequency domain</em><span>: a clever reinterpretation of everyday signals that translates them into the amplitudes of constituent waveforms. The most common basis for this operation are sine waves running at increasing frequencies, but </span><a href="https://lcamtuf.substack.com/p/is-the-frequency-domain-a-real-place" rel="">countless other waveforms</a><span> can be used to create a number of alternative frequency domains.</span></p><p><span>In that earlier article, I also noted two important properties of frequency domain transforms. First, they are reversible: you can recover the original </span><em>(“time domain” </em><span>or </span><em>“spatial domain”</em><span>) data from its frequency image. Second, the transforms have input-output symmetry: the same mathematical operation is used to go both ways. In effect, we have a lever that takes us to a mirror dimension and back. Which of the lever positions is called home is a matter of habit, not math.</span></p><p>Of course, in real life, the distinction matters — and it’s particularly important for compression. If you take an image, convert it to the frequency-domain representation, and then reduce the precision of (or outright obliterate!) the high-frequency components, the resulting image still looks perceptually the same — but you now have much less data to transmit or store:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1032742,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cb2d736-32e9-47f3-a2b1-3d3dd38a8690_1600x1600.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em>Using MS Paint as a cutting-edge compression tool.</em></figcaption></figure></div><p>This makes you wonder: if the frequency-domain representation of a typical image looks like diffuse noise, if most of it is perceptually unimportant, and if the transform is just a lever that takes us back and forth between two functionally-equivalent dimensions… could we start calling that mirror dimension home and move some stuff in?</p><p>To answer this stoner question, I grabbed a photo of a cat and then calculated its frequency-domain form with the discrete cosine transform (DCT):</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg" width="1456" height="728" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:728,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:641657,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89dea704-5264-47a5-a8c7-a8a7765d1cc2_1600x800.jpeg 1456w" sizes="100vw"></picture></div></a><figcaption><em>Time cat, frequency cat.</em></figcaption></figure></div><p>Next, I reused the photo of a woman from an earlier example and placed the mirror-dimension “cat noise” pattern over it, dialing down opacity to minimize visible artifacts:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png" width="800" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d3bb8d20-72c3-42e7-b588-65d712818362_800x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308512,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bb8d20-72c3-42e7-b588-65d712818362_800x800.png 1456w" sizes="100vw"></picture></div></a><figcaption><em>Time woman with a frequency cat.</em></figcaption></figure></div><p>The compositing operation is necessarily lossy, but my theory was that if the composite image is run through DCT to compute its frequency-domain representation, the photo of a woman would be decomposed to fairly uniform noise, perhaps easy to attenuate with a gentle blur; while the injected “cat noise” would coalesce into a perceptible image of a cat.</p><p>But would it?… Yes!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png" width="800" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:406694,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cb815ef-c780-4dfb-ad6e-bdd84a1f3814_800x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Frequency cat with a time woman.</em></figcaption></figure></div><p><span>If you want to see for yourself, </span><a href="https://lcamtuf.coredump.cx/woman-with-cat.png" rel="">download the composite image</a><span> and have fun. In MATLAB, you can do the following:</span></p><blockquote><pre><code>woman = imread("woman-with-cat.png");

colormap('gray');
imagesc(woman, [0 255]);
pause(1);

cat = dct2(woman);
imagesc(imgaussfilt(cat, 1), [-4 4]);</code></pre></blockquote><p>Interestingly, the kitty survives resizing of the host document. Upscaling tiles the image; downscaling truncates it.</p><p>My lingering question was how badly the cat would get mangled by lossy compression; as it turns out, the impact is less than I expected. At higher JPEG quality settings, the image looks quite OK. As the quality setting is lowered, the bottom right quadrant — corresponding to higher-frequency components — gets badly quantized:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1197263,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb583fe71-a273-4e72-b583-44ad3c04568a_1600x1600.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>The havoc of JPEG compression, as seen in the frequency domain.</em></figcaption></figure></div><p>This visualization offers a fascinating glimpse of just how much information is destroyed by the JPEG algorithm — mostly without us noticing.</p><p>There’s plenty of prior art for using audio spectrograms for hidden messages, and some discussion of text steganography piggybacked on top of JPEG DCT coefficients. My point isn’t that the technique is particularly useful or that it has absolutely no precedent. It’s just that the frequency domain and the time domain are coupled together in funny ways.</p><p><em><span>For more articles about electronics, algorithms, snowplowing, and 19th century repeating pistols, see </span><a href="https://lcamtuf.coredump.cx/offsite.shtml" rel="">this categorized list</a><span>.</span></em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Femtosecond lasers create 3D midair plasma displays you can touch (217 pts)]]></title>
            <link>https://spectrum.ieee.org/femtosecond-lasers-create-3d-midair-plasma-displays-you-can-touch</link>
            <guid>40356751</guid>
            <pubDate>Tue, 14 May 2024 16:10:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/femtosecond-lasers-create-3d-midair-plasma-displays-you-can-touch">https://spectrum.ieee.org/femtosecond-lasers-create-3d-midair-plasma-displays-you-can-touch</a>, See on <a href="https://news.ycombinator.com/item?id=40356751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Femtosecond Lasers Create 3-D Midair Plasma Displays You Can Touch" data-elid="2650272901" data-post-url="https://spectrum.ieee.org/femtosecond-lasers-create-3d-midair-plasma-displays-you-can-touch" data-authors="Evan Ackerman" data-page-title="Femtosecond Lasers Create 3-D Midair Plasma Displays You Can Touch - IEEE Spectrum"><p>Science fiction has promised us three-dimensional midair displays since at least the first <em>Star Wars</em> movie. We’ve seen <a href="https://spectrum.ieee.org/consumer-electronics/audiovideo/holographic-displays-coming-to-smartphones">a few holographic&nbsp;technologies</a> that have <a href="https://spectrum.ieee.org/consumer-electronics/audiovideo/glassesfree-3d-from-almost-any-angle">come close</a>;&nbsp;they rely on optical tricks of one sort or&nbsp;another to make it seem like you’re seeing an image hovering in front of you.</p><p>There’s nothing wrong with such optical tricks (if you can get them to work), but the fantasy is to have true midair&nbsp;pixels that present no concerns about things like viewing angles. This technology does exist, and has for a while, in the form of <a href="https://spectrum.ieee.org/tech-talk/consumer-electronics/audiovideo/alternatives-to-holograms-for-real-3-d-displays">laser-induced plasma displays</a>&nbsp;that ionize air molecules to create glowing points of light. If lasers and plasma sound&nbsp;like a dangerous way to make a display, that's because it is. But Japanese researchers have upped the speed of their lasers to create <a href="https://digitalnature.slis.tsukuba.ac.jp/2015/06/fairy-lights-in-femtoseconds/">a laser plasma display that’s touchably safe</a>.</p><!--nextpage--><p>Here’s what a conventional (if that’s a word that we can apply to this technology) laser-induced plasma display looks like, from a Japanese company called Aerial Burton:</p><p><span data-rm-shortcode-id="ae47dc46174f8e6d0371f0f0aebb196b"><iframe type="lazy-iframe" data-runner-src="https://www.youtube.com/embed/GNoOiXkXmYQ?rel=0" width="100%" height="auto" allowfullscreen="" frameborder="0" scrolling="no"></iframe></span><small placeholder="Add Photo Caption..."></small><small placeholder="Add Photo Credit..."></small></p><p>Those brightly glowing&nbsp;voxels (pixels&nbsp;in three dimensional space) are air molecules that have been ionized at the focal point of an infrared laser and are releasing extra energy in the form of bluish-white&nbsp;photons. The plasma doesn’t last long, so the way to make a display is to use a laser that scans through a volume of air very quickly, firing tens or hundreds of of thousands of times per second to create a sequence of short-lived (nanosecond-scale) voxels that create the effect&nbsp;of a moving image. 
</p><p>However, a nanosecond-scale plasma burst still contains&nbsp;a significant amount of energy;&nbsp;you don’t want to go walking through one of these displays, because it <strong>will</strong> burn you. Researchers from the University of Tsukuba, Utsunomiya University, Nagoya Institute of Technology, and the University of Tokyo have developed a&nbsp;<a href="https://arxiv.org/pdf/1506.06668v1.pdf">“Fairy Lights” display system</a>&nbsp;that uses femtosecond lasers instead. The result is a plasma display that’s safe to touch.</p><p><span data-rm-shortcode-id="4e9d8e42e895db6f7595cc4bbec21897"><iframe type="lazy-iframe" data-runner-src="https://www.youtube.com/embed/AoWi10YVmfE?rel=0" width="100%" height="auto" allowfullscreen="" frameborder="0" scrolling="no"></iframe></span><small placeholder="Add Photo Caption..."></small><small placeholder="Add Photo Credit..."></small></p><p>Each one of those dots (voxels) is being generated by a laser that’s pulsing in just a few tens of femtoseconds. A femotosecond is&nbsp;one millionth of one billionth of one second.&nbsp;&nbsp;The researchers found that a pulse duration that minuscule doesn't result in any appreciable skin damage unless the laser is firing at that same spot at one shot per millisecond for a duration of 2,000 milliseconds. The Fairy Lights display keeps the exposure time (shots per millisecond) well under that threshhold: 
</p><blockquote><p><em>Our system has the unique characteristic that the plasma is&nbsp;touchable. It was found that the contact between plasma and a&nbsp;finger causes a brighter light. This effect can be used as a cue of&nbsp;the contact.&nbsp;One possible control is touch interaction in which&nbsp;floating images change when touched by a user. The other is&nbsp;damage reduction. For safety, the plasma voxels are shut off&nbsp;within a single frame (17 ms = 1/60 s) when users touch the&nbsp;voxels. This is sufficiently less than the harmful exposure time&nbsp;(2,000 ms).</em></p></blockquote><p>Even cooler, you can apparently feel the plasma as you touch it:</p><blockquote><p><em>Shock waves are generated by plasma when a user touches the&nbsp;plasma voxels. The user feels an impulse on the finger as if&nbsp;the light has physical substance. The detailed investigation of&nbsp;the characteristics of this plasma-generated haptic sensation&nbsp;with sophisticated spatiotemporal control is beyond the scope of&nbsp;this paper.</em></p></blockquote><p>Well, that’s too bad, but maybe we’ll get more details in the <em>next</em> paper.</p><p><img id="f8b9a" data-rm-shortcode-id="2b01574a175bdea629fbe510e3ee7224" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/img.jpg?id=25578358&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/img.jpg?id=25578358&amp;width=980" width="620" height="258" alt="img"><small placeholder="Add Photo Caption..."></small><small placeholder="Add Photo Credit...">Images: Yoichi Ochiai/University of Tsukuba</small></p><p>As you can see from the pics and video, these displays are tiny: the workspace encompasses&nbsp;just eight cubic millimeters. The spatiotemporal resolution is relatively high, though, at up to 200,000 voxels per second, and the image framerate depends on how many voxels your image needs.</p><p>To become useful as the consumer product of our dreams, the display is going to need to scale up.&nbsp;The researchers suggest that it’s certainly possible to do this with different optical devices. We’re holding out for something that’s small enough to&nbsp;fit into a phone or wristwatch, and it’s not <em>that</em> crazy to look at this project and believe that such a gadget&nbsp;might not be so far away.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox search update (208 pts)]]></title>
            <link>https://blog.mozilla.org/en/products/firefox/firefox-search-update/</link>
            <guid>40355982</guid>
            <pubDate>Tue, 14 May 2024 15:07:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/products/firefox/firefox-search-update/">https://blog.mozilla.org/en/products/firefox/firefox-search-update/</a>, See on <a href="https://news.ycombinator.com/item?id=40355982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-74713">
  

  <div>
    
<figure><img decoding="async" fetchpriority="high" width="1024" height="538" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-1024x538.png" alt="An illustration shows the Firefox logo, a fox curled up in a circle." srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-1024x538.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-300x158.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-768x403.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-1536x806.png 1536w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-2048x1075.png 2048w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/01/firefox-browser-logo-1000x525.png 1000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Innovation and privacy go hand in hand here at Mozilla. To continue developing features and products that resonate with our users, we’re adopting a new approach to better understand how you engage with Firefox. Rest assured, the way we gather these insights will always put user <a href="https://www.mozilla.org/en-US/privacy/firefox/" target="_blank" rel="noreferrer noopener">privacy first</a>.</p>



<h2><strong>What’s new in Firefox’s approach to search data&nbsp;</strong></h2>



<p>To improve Firefox based on your needs, understanding how users interact with essential functions like search is key. We’re ramping up our efforts to enhance search experience by developing new features like <a href="https://blog.mozilla.org/products/firefox/firefox-news/firefox-suggest/">Firefox Suggest</a>, which provides recommended online content that corresponds to queries. To make sure that features like this work well, we need better insights on overall search activity – all without trading off on our commitment to user privacy. Our goal is to understand what types of searches are happening so that we can prioritize the correct features by use case.</p>



<div><p>With the <a href="https://www.mozilla.org/firefox/releases/" target="_blank" rel="noreferrer noopener">latest version of Firefox</a> for U.S. desktop users, we’re introducing a new way to measure search activity broken down into high level categories. This measure is not linked with specific individuals and is further anonymized using a technology called <a href="https://blog.mozilla.org/products/firefox/partnership-ohttp-prio/">OHTTP</a> to ensure it can’t be connected with user <a href="https://blog.mozilla.org/internet-culture/what-is-an-ip-address/">IP addresses</a>.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Let’s say you’re using Firefox to <a href="https://blog.mozilla.org/products/firefox/firefox-tips/internet-safety-for-families-total-cookie-protection/">plan a trip</a> to Spain and search for “Barcelona hotels.” Firefox infers that the search results fall under the category of “travel,” and it increments a counter to calculate the total number of searches happening at the country level.</p><p>Here’s the current list of categories we’re using: animals, arts, autos, business, career, education, fashion, finance, food, government, health, hobbies, home, inconclusive, news, real estate, society, sports, tech and travel.</p></div>



<p>Having an understanding of what types of searches happen most frequently will give us a better understanding of what’s important to our users, without giving us additional insight into individual browsing preferences. This helps us take a step forward in providing a browsing experience that is more tailored to your needs, without us stepping away from the principles that make us who we are.&nbsp;</p>



<h2><strong>What Firefox’s search data collection means for you</strong></h2>



<p>We understand that any new data collection might spark some questions. Simply put, this new method only categorizes the websites that show up in your searches — not the specifics of what you’re personally looking up.&nbsp;</p>



<p>Sensitive topics, like searching for particular health care services, are categorized only under broad terms like health or society. Your search activities are handled with the same level of confidentiality as all other data regardless of any local laws surrounding certain health services.&nbsp;</p>



<p>Remember, you can always opt out of sending any technical or usage data to Firefox. <a href="https://support.mozilla.org/en-US/kb/share-data-mozilla-help-improve-firefox" target="_blank" rel="noreferrer noopener">Here’s a step-by-step guide</a> on how to adjust your settings. We also don’t collect category data when you use <a href="https://blog.mozilla.org/mozilla/firefoxs-private-browsing-mode-upleveled-for-you/">Private Browsing mode</a> on Firefox.&nbsp;&nbsp;</p>



<p>As far as user experience goes, you won’t see any visible changes in your browsing. Our new approach to data will just enable us to better refine our product features and offerings in ways that matter to you.&nbsp;</p>



<p>We’re here to make the internet safer, faster and more in tune with what you need – just as we have since open-sourcing our browser code more than <a href="https://blog.mozilla.org/mozilla/mitchell-baker-mozilla-25-anniversary/">25 years ago</a>. Thanks for being part of our journey!</p>



<a href="https://www.mozilla.org/en-US/firefox/new?utm_medium=mozilla-websites&amp;utm_source=blog.mozilla.org&amp;utm_content=inline-cta">
  <p><img width="512" height="512" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/12/Fx-Browser-icon-fullColor-512-512x512.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/12/Fx-Browser-icon-fullColor-512.png 512w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/12/Fx-Browser-icon-fullColor-512-300x300.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2020/12/Fx-Browser-icon-fullColor-512-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px">  </p>
  <div>
     <h3>Get Firefox</h3>      <p><span>Get the browser that protects what’s important</span>   </p></div>
</a>
  </div>

</article><!-- #post-74713 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Pico: An open-source Ngrok alternative built for production traffic (188 pts)]]></title>
            <link>https://github.com/andydunstall/pico</link>
            <guid>40355744</guid>
            <pubDate>Tue, 14 May 2024 14:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/andydunstall/pico">https://github.com/andydunstall/pico</a>, See on <a href="https://news.ycombinator.com/item?id=40355744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">Pico <a href="https://github.com/andydunstall/pico/actions/workflows/build.yaml"><img src="https://github.com/andydunstall/pico/actions/workflows/build.yaml/badge.svg" alt="Build"></a></h2><a id="user-content-pico-" aria-label="Permalink: Pico " href="#pico-"></a></div>
<p dir="auto">Pico is an open-source alternative to <a href="https://ngrok.com/" rel="nofollow">Ngrok</a>, designed to
serve production traffic and be simple to host (particularly on Kubernetes).
Such as you may use Pico to expose services in a customer network, a bring your
own cloud (BYOC) service or to connect to IoT devices.</p>
<p dir="auto">The proxy server may be hosted as a cluster of nodes for fault tolerance, scale
and zero downtime deployments.</p>
<p dir="auto">Upstream services connect to Pico and register endpoints. Pico will then route
requests for an endpoint to a registered upstream service via its outbound-only
connection. This means you can expose your services without opening a public
port.</p>
<p dir="auto">Incoming HTTP(S) requests identify the ID of the target endpoint using either
the <code>Host</code> header or an <code>x-pico-endpoint</code> header. If multiple upstream services
have registered the same endpoint, Pico load balances requests for that
endpoint among the registered upstreams.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/andydunstall/pico/blob/main/assets/images/overview.png"><img src="https://github.com/andydunstall/pico/raw/main/assets/images/overview.png" alt="overview" width="80%"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
<li><a href="#design-goals">Design Goals</a></li>
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#docs">Docs</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design Goals</h2><a id="user-content-design-goals" aria-label="Permalink: Design Goals" href="#design-goals"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Production Traffic</h3><a id="user-content-production-traffic" aria-label="Permalink: Production Traffic" href="#production-traffic"></a></p>
<p dir="auto">Pico is designed to serve production traffic rather than as a tool for testing
and development. Such as you could use Pico to:</p>
<ul dir="auto">
<li>Access customer networks</li>
<li>Build a bring your own cloud (BYOC) solution</li>
<li>Access IoT devices</li>
</ul>
<p dir="auto">To support this, Pico may run as a cluster of nodes in order to be fault
tolerant, scale horizontally and support zero downtime deployments. It also has
observability tools for monitoring and debugging.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hosting</h3><a id="user-content-hosting" aria-label="Permalink: Hosting" href="#hosting"></a></p>
<p dir="auto">Pico is built to be simple to host on Kubernetes. A Pico cluster may be hosted
as a Kubernetes StatefulSet behind a HTTP load balancer or Kubernetes Gateway.</p>
<p dir="auto">Upstream service connections and proxy client requests may be load balanced to
any node in the cluster and Pico will manage routing the requests to the
correct upstream.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Secure</h3><a id="user-content-secure" aria-label="Permalink: Secure" href="#secure"></a></p>
<p dir="auto">Upstream services connect to Pico via an outbound-only connection. Pico will
then route any requests to the upstream via that connection. Therefore the
upstream never has to open a port to listen for requests.</p>
<p dir="auto">Pico supports authenticating upstream services before they can register
endpoints.</p>
<p dir="auto">Since Pico can be self-hosted, you can host it in the same network as your
proxy clients so never accept requests from an external network. Such as you
may have authenticated upstream services register from the Internet over TLS,
then only provide an internal route for proxy clients in the same network as
Pico.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">See <a href="https://github.com/andydunstall/pico/blob/main/docs/getting-started.md">Getting Started</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<ul dir="auto">
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/getting-started.md">Getting Started</a></li>
<li>Architecture
<ul dir="auto">
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/architecture/overview.md">Overview</a></li>
</ul>
</li>
<li>Manage
<ul dir="auto">
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/manage/overview.md">Overview</a></li>
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/manage/configure.md">Configure</a></li>
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/manage/kubernetes.md">Kubernetes</a></li>
<li><a href="https://github.com/andydunstall/pico/blob/main/docs/manage/observability.md">Observability</a></li>
</ul>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blazingly fast linked lists (170 pts)]]></title>
            <link>https://dygalo.dev/blog/blazingly-fast-linked-lists/</link>
            <guid>40355227</guid>
            <pubDate>Tue, 14 May 2024 13:51:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dygalo.dev/blog/blazingly-fast-linked-lists/">https://dygalo.dev/blog/blazingly-fast-linked-lists/</a>, See on <a href="https://news.ycombinator.com/item?id=40355227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
  <figure>
    <img src="https://dygalo.dev/blog/2048px-Rusty_chain_in_fishing_boat.jpg">
    
      <figcaption>© Tomas Castelazo, www.tomascastelazo.com / Wikimedia Commons / CC BY-SA 4.0</figcaption>
    
  </figure>

<p>Linked lists are <a href="https://rust-unofficial.github.io/too-many-lists/" target="_blank">taught</a> as fundamental data structures in programming courses, but they are more commonly encountered in tech interviews than in real-world projects.</p>
<p>In this post, I'll demonstrate a practical use case where a linked list significantly outperforms <code>Vec</code>. 
We will build a simple data validation library that shows the exact error location within invalid input, showcasing how a linked list can be used in graph traversals.</p>
<p>Starting with a naive approach, we’ll progressively implement various optimizations and observe their impact on performance. </p>
<p>Readers are expected to have a basic understanding of Rust, common data structures, and the concept of memory allocations (stack vs. heap).</p>
<blockquote>
<p>To follow along with the implementation steps and explore the code, check out the accompanying <a href="https://github.com/Stranger6667/article-linked-lists" target="_blank">repository</a></p>
</blockquote>
<h2 id="validation-api">Validation API</h2>
<p>Our library is fairly minimal, and follows <a href="https://json-schema.org/specification#specification-documents" target="_blank">JSON Schema</a> semantics:</p>
<pre data-lang="rust"><code data-lang="rust"><span>use </span><span>serde_json::json;
</span><span>
</span><span>fn </span><span>main</span><span>() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
</span><span>    jsonschema::validate(
</span><span>      </span><span>// JSON instance to validate
</span><span>      &amp;json!({
</span><span>          "</span><span>name</span><span>": "</span><span>John</span><span>",
</span><span>          "</span><span>location</span><span>": {
</span><span>               "</span><span>country</span><span>": </span><span>404
</span><span>          }
</span><span>      }),
</span><span>      </span><span>// JSON schema
</span><span>      &amp;json!({
</span><span>          "</span><span>properties</span><span>": {
</span><span>              "</span><span>name</span><span>": {
</span><span>                  "</span><span>type</span><span>": "</span><span>string</span><span>"
</span><span>              },
</span><span>              "</span><span>location</span><span>": {
</span><span>                  "</span><span>properties</span><span>": {
</span><span>                      "</span><span>country</span><span>": {
</span><span>                          "</span><span>type</span><span>": "</span><span>string</span><span>"
</span><span>                      }
</span><span>                  }
</span><span>              }
</span><span>          }
</span><span>      }),
</span><span>    ).</span><span>expect_err</span><span>("</span><span>Should fail</span><span>");
</span><span>    Ok(())
</span><span>}
</span></code></pre>
<p>In this example, <code>404</code> is not a string and this code should result in an error like this:</p>
<pre><code><span>404 is not of type ‘string’ at /location/country
</span><span> |                             |               |
</span><span> |                              ---------------
</span><span> |                                     |
</span><span> |                                     Location within the JSON instance
</span><span> |
</span><span>  Failing value
</span></code></pre>
<blockquote>
<p>This library and optimization ideas are derived from my <a href="https://github.com/Stranger6667/jsonschema-rs" target="_blank">jsonschema</a> crate</p>
</blockquote>
<p>The validation process boils down to graph traversal. The input instance is traversed based on rules defined in the schema. At any traversal step, we should know the current location within the JSON instance to potentially report a meaningful error.</p>

  <p><img src="https://dygalo.dev/blog/validation-process.png"></p><p>Our primary goal is to implement location tracking while minimizing its impact on the library's performance.</p>
<p>Without diving too deep into the <code>Validator</code> and <code>Node</code> implementations, let's see a simplified version of the validation process without location tracking:</p>
<pre data-lang="rust"><code data-lang="rust"><span>type </span><span>ValidationResult = Result&lt;(), ValidationError&gt;;
</span><span>
</span><span>fn </span><span>validate</span><span>(</span><span>instance</span><span>: &amp;Value, </span><span>schema</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>    Validator::new(schema)
</span><span>        .</span><span>expect</span><span>("</span><span>Invalid schema</span><span>")
</span><span>        .</span><span>validate</span><span>(instance)
</span><span>}
</span><span>
</span><span>struct </span><span>ValidationError {
</span><span>    </span><span>message</span><span>: String,
</span><span>}
</span><span>
</span><span>impl </span><span>Validator {
</span><span>    </span><span>/// Validate JSON instance against this validator.
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>        </span><span>self</span><span>.node.</span><span>validate</span><span>(instance)
</span><span>    }
</span><span>}
</span><span>
</span><span>trait </span><span>Node {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult;
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>        </span><span>if let </span><span>Value::Object(object) = instance {
</span><span>            </span><span>// Iterate over properties and validate them if they are present.
</span><span>            </span><span>for </span><span>(key, value) in &amp;</span><span>self</span><span>.properties {
</span><span>                </span><span>if let </span><span>Some(instance) = object.</span><span>get</span><span>(key) {
</span><span>                    </span><span>// Delegate validation to the child validator.
</span><span>                    value.</span><span>validate</span><span>(instance)?;
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>        Ok(())
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>        </span><span>// ... 
</span><span>    }
</span><span>}
</span></code></pre>
<p>The <code>validate</code> function creates a new <code>Validator</code> instance (that is also a graph) from the provided schema and then calls its <code>validate</code> method with the JSON instance.
The <code>Node</code> trait defines the <code>validate</code> method that each validation rule must implement.</p>
<p>While this version provides error messages without location tracking, it serves as an upper bound for subsequent optimizations within the <code>validate</code> function.</p>
<h2 id="benchmark-setup">Benchmark setup</h2>
<p>To ensure the optimizations are relevant to the library's typical usage scenarios, we select inputs from different groups - valid and invalid instances of varying sizes. </p>
<p>The <a href="https://github.com/Stranger6667/article-linked-lists/blob/main/benches/data.json#L2" target="_blank">schema</a> contains 10 levels of nesting and is deliberately restricted to only the <code>properties</code> and <code>type</code> keywords, which are sufficient to demonstrate the overhead of path-tracking behavior while simplifying benchmarking and keeping our focus on performance rather than JSON Schema semantics. It's worth noting that the path-tracking behavior will remain largely the same for other keywords as well.</p>
<pre data-lang="json"><code data-lang="json"><span>{
</span><span>    "</span><span>properties</span><span>":{
</span><span>        "</span><span>another</span><span>":{
</span><span>            "</span><span>type</span><span>":"</span><span>string</span><span>"
</span><span>        },
</span><span>        "</span><span>inner</span><span>":{
</span><span>            "</span><span>properties</span><span>":{
</span><span>                "</span><span>another</span><span>":{
</span><span>                    "</span><span>type</span><span>":"</span><span>string</span><span>"
</span><span>                },
</span><span>                "</span><span>inner</span><span>":{
</span><span>                    "</span><span>properties</span><span>":{
</span><span>                        </span><span>// And so on for up to 10 levels
</span><span>                    }
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>The instances have 0, 5, or 10 levels of nesting, following the schema's structure. Valid instances have a string value for the "another" property at the deepest level, while invalid instances have an integer.</p>
<pre data-lang="json"><code data-lang="json"><span>// Valid - 5 levels
</span><span>{
</span><span>    "</span><span>inner</span><span>":{
</span><span>        "</span><span>inner</span><span>":{
</span><span>            "</span><span>inner</span><span>":{
</span><span>                "</span><span>inner</span><span>":{
</span><span>                    "</span><span>another</span><span>":"</span><span>hello</span><span>"
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span><span>// Invalid - 5 levels
</span><span>{
</span><span>    "</span><span>inner</span><span>":{
</span><span>        "</span><span>inner</span><span>":{
</span><span>            "</span><span>inner</span><span>":{
</span><span>                "</span><span>inner</span><span>":{
</span><span>                    "</span><span>another</span><span>":</span><span>1
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>To focus on the performance of the validation process itself, the schema is hardcoded in <code>Validator::new</code>, and <code>Validator</code> is built once and then reused.</p>
<p>Let’s measure performance with <a href="https://bheisler.github.io/criterion.rs/book/criterion_rs.html" target="_blank">criterion</a> by running the following validation routine:</p>
<pre data-lang="rust"><code data-lang="rust"><span>const </span><span>NUMBER_OF_ITERATIONS</span><span>: </span><span>usize </span><span>= </span><span>10000</span><span>;
</span><span>
</span><span>fn </span><span>benchmarks</span><span>(</span><span>c</span><span>: &amp;</span><span>mut</span><span> Criterion) {
</span><span>    </span><span>// snip ... 
</span><span>    </span><span>for</span><span> instance in &amp;benchmark.instances {
</span><span>        c.</span><span>bench_with_input</span><span>(
</span><span>            BenchmarkId::new(instance.kind, &amp;instance.name),
</span><span>            &amp;instance.value,
</span><span>            |</span><span>b</span><span>: &amp;</span><span>mut</span><span> Bencher, </span><span>value</span><span>| {
</span><span>                b.</span><span>iter</span><span>(|| {
</span><span>                    </span><span>for </span><span>_ in </span><span>0</span><span>..</span><span>NUMBER_OF_ITERATIONS </span><span>{
</span><span>                        </span><span>let </span><span>_ = validator.</span><span>validate</span><span>(value);
</span><span>                    }
</span><span>                });
</span><span>            },
</span><span>        );
</span><span>    }
</span><span>}
</span></code></pre>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/a030dcb18448555efa1a8f63f8b5ccebef7d2f59" target="_blank">a030dcb</a></td>
  <td>36.3 µs</td>
  <td>553.8 µs</td>
  <td>1.11 ms</td>
  <td>475.2 µs</td>
  <td>914.8 µs</td>
  <td>1.48 ms</td>
</tr>
  </tbody>
</table>
<blockquote>
<p>The numbers in these microbenchmarks are not absolute and may vary depending on the hardware and the environment. Generally, the observed changes could be explained by stack traces in flame graphs, but you always need to check the benchmarks yourself.</p>
</blockquote>
<h2 id="naive-approach">Naive approach</h2>
<p>Let's start from collecting traversed path segments in a vector adding a new segment each time validation goes one level deeper:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>    </span><span>// Start with an empty vector
</span><span>    </span><span>self</span><span>.node.</span><span>validate</span><span>(instance, vec![])
</span><span>}
</span><span>
</span><span>trait </span><span>Node {
</span><span>    </span><span>// Add `path` parameter to track the current location in the JSON instance
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vec&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult;
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vec&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult {
</span><span>        </span><span>if let </span><span>Value::Object(object) = instance {
</span><span>            </span><span>for </span><span>(key, value) in &amp;</span><span>self</span><span>.properties {
</span><span>                </span><span>if let </span><span>Some((key, instance)) = object.</span><span>get_key_value</span><span>(key) {
</span><span>                    </span><span>// Create a new path and pass it to the child node
</span><span>                    </span><span>let mut</span><span> path = path.</span><span>clone</span><span>();
</span><span>                    path.</span><span>push</span><span>(key);
</span><span>                    value.</span><span>validate</span><span>(instance, path)?;
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>        Ok(())
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vec&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult {
</span><span>        </span><span>match </span><span>(</span><span>self</span><span>, instance) {
</span><span>            </span><span>// ... Compare `instance` type with expected type
</span><span>            _ =&gt; Err(ValidationError::new(
</span><span>                format!("</span><span>{instance}</span><span> is not of type '</span><span>{self}</span><span>'</span><span>"),
</span><span>                </span><span>// Convert path to an iterator
</span><span>                path.</span><span>into_iter</span><span>(),
</span><span>            )),
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>The <code>ValidationError</code> struct now stores this path:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>ValidationError {
</span><span>    </span><span>message</span><span>: String,
</span><span>    </span><span>/// Error location within the input instance.
</span><span>    </span><span>location</span><span>: Vec&lt;String&gt;,
</span><span>}
</span><span>
</span><span>impl </span><span>ValidationError {
</span><span>    </span><span>/// Create new validation error.
</span><span>    </span><span>fn </span><span>new</span><span>(
</span><span>        </span><span>message</span><span>: impl Into&lt;String&gt;,
</span><span>        </span><span>// Accept an iterator and convert it to `Vec&lt;String&gt;`
</span><span>        </span><span>location</span><span>: impl Iterator&lt;Item = impl Into&lt;String&gt;&gt;,
</span><span>    ) -&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self </span><span>{
</span><span>            message: message.</span><span>into</span><span>(),
</span><span>            location: location.</span><span>map</span><span>(Into::into).</span><span>collect</span><span>(),
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>If you've been writing Rust for a while, you'll likely recognize the <code>clone()</code> call as a common "solution" to lifetime and mutability issues. While it is acceptable in certain situations, depending on your performance and maintainability constraints, it often signals an opportunity for optimization. Cloning a <code>Vec</code> can be costly, especially in performance-critical code.</p>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/9ef7b4c56c8ca2ba3dcd15681daff6951aa64c2c" target="_blank">9ef7b4c</a></td>
  <td>40.9 µs<br>(<strong>+12%</strong>)</td>
  <td>2.61 ms<br>(<strong>+369.4%</strong>)</td>
  <td>6.69 ms<br>(<strong>+499.6%</strong>)</td>
  <td>961.2 µs<br>(<strong>+100.8%</strong>)</td>
  <td>4.11 ms<br>(<strong>+346.8%</strong>)</td>
  <td>9.07 ms<br>(<strong>+502.7%</strong>)</td>
</tr>
  </tbody>
</table>
<p>This feature makes validation up to 6 times slower! </p>
<blockquote>
<p>You may note that <code>path</code> is only used when one of the validators returns an error. Can we leverage this observation for optimizations?</p>
</blockquote>
<p>Let’s visualize the slowest "valid" benchmark using <code>cargo flamegraph</code> to understand what is going on. As expected, the memory reallocations show up in the flame graph:</p>
<pre data-lang="shell"><code data-lang="shell"><span>cargo flamegraph --bench jsonschema -o naive-10.svg -- --bench "^valid/10 levels"
</span></code></pre>

  <p><img src="https://dygalo.dev/blog/naive-valid-10.png"></p><blockquote>
<p>Flame graphs are amazing for visualizing stack traces, see more details <a href="https://github.com/flamegraph-rs/flamegraph" target="_blank">here</a> </p>
</blockquote>
<h2 id="idea-1-cheaper-clones">Idea 1: Cheaper clones</h2>
<p>There are a couple of ways to deal with clones. First, let's try a different data structure that offers cheaper clones. The <a href="https://docs.rs/imbl/latest/imbl/" target="_blank">imbl</a> crate provides the <code>Vector</code> type, which is based on the <a href="https://infoscience.epfl.ch/record/213452/files/rrbvector.pdf">Relaxed-Radix-Balanced tree</a>.</p>
<p>RRB trees are a type of immutable data structure that allows for efficient structural sharing. This concept allows most memory to be shared among multiple mostly identical data structures, and extra memory is only allocated when modifications occur, thus requiring memory only to record the difference. With most operations being O(log n), <code>Vector </code> offers decent performance in many scenarios.</p>
<pre data-lang="rust"><code data-lang="rust"><span>use </span><span>imbl::Vector;
</span><span>
</span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>    </span><span>self</span><span>.node.</span><span>validate</span><span>(instance, Vector::new())
</span><span>}
</span><span>
</span><span>trait </span><span>Node {
</span><span>    </span><span>// Replace `Vec` with `imbl::Vector`
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vector&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult;
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vector&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult 
</span><span>        </span><span>// ...
</span><span>                    </span><span>let mut</span><span> path = path.</span><span>clone</span><span>();
</span><span>                    </span><span>// Use `push_back` instead of `push`
</span><span>                    path.</span><span>push_back</span><span>(key);
</span><span>                    value.</span><span>validate</span><span>(instance, path)?;
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>path</span><span>: Vector&lt;&amp;</span><span>str</span><span>&gt;) -&gt; ValidationResult 
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span></code></pre>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/77adb2c34ef95b978e90429c80bad59a422caa39" target="_blank">77adb2c</a></td>
  <td>47.1 µs<br>(<strong>+13.6%</strong>)</td>
  <td>2.25 ms<br>(<strong>-15.6%</strong>)</td>
  <td>6.49 ms<br>(<strong>-3.7%</strong>)</td>
  <td>904.3 µs<br>(<strong>-6.6%</strong>)</td>
  <td>4.09 ms<br>(<strong>-1.2%</strong>)</td>
  <td>9.77 ms<br>(<strong>+6.7%</strong>)</td>
</tr>
  </tbody>
</table>
<p>Interesting! In some cases, <code>Vector</code> outperforms the naive approach, while in others, it introduces slight overhead.  While <code>Vector</code> can be faster for certain data &amp; usage patterns due to structural sharing, it may introduce overhead for other patterns because of its more complex internal structure.</p>
<blockquote>
<p>In some scenarios, where modifications occur way less often than clones, you can consider using Arc as explained in this <a href="https://www.youtube.com/watch?v=A4cKi7PTJSs">video</a> . You may also try the <a href="https://docs.rs/rpds/latest/rpds/" target="_blank">rpds</a> crate which provides similar data structures with structural sharing.</p>
</blockquote>
<h2 id="idea-2-reuse-allocations">Idea 2: Reuse allocations</h2>
<p>However, you may note that we don't have to clone the data - what if we mutate the same vector, pushing and popping segments as we traverse?</p>
<pre data-lang="rust"><code data-lang="rust"><span>trait </span><span>Node {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: &amp;</span><span>mut </span><span>Vec&lt;&amp;</span><span>'a str</span><span>&gt;,
</span><span>    ) -&gt; ValidationResult;
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: &amp;</span><span>mut </span><span>Vec&lt;&amp;</span><span>'a str</span><span>&gt;,
</span><span>    ) -&gt; ValidationResult {
</span><span>        </span><span>// ...
</span><span>                    path.</span><span>push</span><span>(key);
</span><span>                    value.</span><span>validate</span><span>(instance, path)?;
</span><span>                    path.</span><span>pop</span><span>();
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: &amp;</span><span>mut </span><span>Vec&lt;&amp;</span><span>'a str</span><span>&gt;,
</span><span>    ) -&gt; ValidationResult {
</span><span>        </span><span>match </span><span>(</span><span>self</span><span>, instance) {
</span><span>            </span><span>// ... Compare `instance` type with expected type
</span><span>            _ =&gt; Err(ValidationError::new(
</span><span>                format!("</span><span>{instance}</span><span> is not of type '</span><span>{self}</span><span>'</span><span>"),
</span><span>                path.</span><span>iter</span><span>().</span><span>copied</span><span>(),
</span><span>            )),
</span><span>        }
</span><span>    }
</span></code></pre>
<p>The lifetime annotations (<code>'a</code>) are needed here because the path parameter is a mutable reference to a <code>Vec</code> that contains references to the <code>instance</code> parameter. The lifetime <code>'a</code> ensures that the references in <code>path</code> do not outlive the <code>instance</code> they refer to.</p>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/7c9473689bf24b90c8e0c45f700ad985b536a73e" target="_blank">7c94736</a></td>
  <td>40.2 µs<br>(<strong>-13.1%</strong>)</td>
  <td>1.24 ms<br>(<strong>-46.0%</strong>)</td>
  <td>2.46 ms<br>(<strong>-62.3%</strong>)</td>
  <td>951.7 µs<br>(<strong>+3.0%</strong>)</td>
  <td>2.39 ms<br>(<strong>-42.2%</strong>)</td>
  <td>4.16 ms<br>(<strong>-58.7%</strong>)</td>
</tr>
  </tbody>
</table>
<p>Indeed, using <code>&amp;mut Vec</code> can significantly improve performance compared to the naive approach, by reusing a single heap allocation instead of creating multiple clones. However, this approach requires more bookkeeping and somewhat more lifetime annotations, which can increase code complexity.</p>
<h2 id="idea-3-linked-list">Idea 3: Linked list</h2>
<p>However, is it even necessary to allocate heap memory for a vector during traversal? Consider this: for each traversed node in the input value, there's a corresponding <code>validate</code> function call with its own stack frame. As a result, path segments can be stored in these stack frames, eliminating the need for heap allocations completely.</p>

  <p><img src="https://dygalo.dev/blog/function-call-frames.png"></p><blockquote>
<p>Taking a step back and looking from a different angle can uncover ideas that may not be apparent at a lower level.</p>
</blockquote>
<p>By storing all segments on the stack, when an error happens, the previous segments can be traced back. This approach involves connecting each segment to form a path and collecting them when necessary. This sounds like a linked list:</p>
<pre data-lang="rust"><code data-lang="rust"><span>/// A node in a linked list representing a JSON pointer.
</span><span>struct </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>segment</span><span>: Option&lt;&amp;</span><span>'a str</span><span>&gt;,
</span><span>    </span><span>parent</span><span>: Option&lt;&amp;</span><span>'b </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt;&gt;,
</span><span>}
</span><span>impl</span><span>&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>/// Create a root node of a JSON pointer.
</span><span>    </span><span>const fn </span><span>new</span><span>() -&gt; </span><span>Self </span><span>{
</span><span>        JsonPointerNode {
</span><span>            segment: None,
</span><span>            parent: None,
</span><span>        }
</span><span>    }
</span><span>    </span><span>/// Push a new segment to the JSON pointer.
</span><span>    </span><span>fn </span><span>push</span><span>(&amp;</span><span>'a </span><span>self</span><span>, </span><span>segment</span><span>: &amp;</span><span>'a str</span><span>) -&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>        JsonPointerNode {
</span><span>            segment: Some(segment),
</span><span>            parent: Some(</span><span>self</span><span>),
</span><span>        }
</span><span>    }
</span><span>    </span><span>/// Convert the JSON pointer node to a vector of path segments.
</span><span>   </span><span>fn </span><span>to_vec</span><span>(&amp;</span><span>'a </span><span>self</span><span>) -&gt; Vec&lt;&amp;</span><span>'a str</span><span>&gt; {
</span><span>        </span><span>// Callect the segments from the head to the tail
</span><span>        </span><span>let mut</span><span> buffer = Vec::new();
</span><span>        </span><span>let mut</span><span> head = </span><span>self</span><span>;
</span><span>        </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>            buffer.</span><span>push</span><span>(*segment);
</span><span>        }
</span><span>        </span><span>while let </span><span>Some(next) = head.parent {
</span><span>            head = next;
</span><span>            </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>                buffer.</span><span>push</span><span>(*segment);
</span><span>            }
</span><span>        }
</span><span>        </span><span>// Reverse the buffer to get the segments in the correct order
</span><span>        buffer.</span><span>reverse</span><span>();
</span><span>        buffer
</span><span>    }
</span><span>}
</span></code></pre>
<p>Now we can replace <code>&amp;mut Vec</code>:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>    </span><span>self</span><span>.node.</span><span>validate</span><span>(instance, JsonPointerNode::new())
</span><span>}
</span><span>
</span><span>trait </span><span>Node {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: JsonPointerNode&lt;</span><span>'a</span><span>, '_&gt;,
</span><span>    ) -&gt; ValidationResult;
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: JsonPointerNode&lt;</span><span>'a</span><span>, '_&gt;,
</span><span>    ) -&gt; ValidationResult {
</span><span>        </span><span>// ...
</span><span>                    value.</span><span>validate</span><span>(instance, path.</span><span>push</span><span>(key.</span><span>as_str</span><span>()))?;
</span><span>        </span><span>// ...
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: JsonPointerNode&lt;</span><span>'a</span><span>, '_&gt;,
</span><span>    ) -&gt; ValidationResult {
</span><span>        </span><span>match </span><span>(</span><span>self</span><span>, instance) {
</span><span>            </span><span>// ... Compare `instance` type with expected type
</span><span>            _ =&gt; Err(ValidationError::new(
</span><span>                format!("</span><span>{instance}</span><span> is not of type '</span><span>{self}</span><span>'</span><span>"),
</span><span>                path.</span><span>to_vec</span><span>().</span><span>into_iter</span><span>(),
</span><span>            )),
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre>
<p>No heap allocations during traversal! Does it help?</p>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/91ec92c757d3948a2a032a55d035e6fadc63fdcf" target="_blank">91ec92c</a></td>
  <td>35.0 µs<br>(<strong>-14.8%</strong>)</td>
  <td>663.5 µs<br>(<strong>-46.4%</strong>)</td>
  <td>1.32 ms<br>(<strong>-46.6%</strong>)</td>
  <td>958.9 µs<br>(<strong>+1.8%</strong>)</td>
  <td>2.54 ms<br>(<strong>+5.1%</strong>)</td>
  <td>4.58 ms<br>(<strong>+9.9%</strong>)</td>
</tr>
  </tbody>
</table>
<p>Woah! That is significantly better for valid inputs! Invalid ones are roughly the same, however, we have not optimized the linked list implementation yet.</p>
<p>In our case, we are leveraging the fact, that the path is only needed when an error occurs. This allows us to avoid the overhead of maintaining the path during the entire traversal process and heap allocate only when necessary.</p>
<blockquote>
<p>Note that linked lists have worse cache locality compared to vectors, which can lead to slower performance in some scenarios.</p>
</blockquote>
<h2 id="idea-4-precise-memory-allocation">Idea 4: Precise memory allocation</h2>
<p>Let's find out why the linked list implementation is not as performant for invalid inputs by looking at <code>JsonPointerNode</code> first:</p>

  <p><img src="https://dygalo.dev/blog/linked-list-invalid-10.png"></p><p>Apparently, the problem is in memory reallocations inside <code>JsonPointerNode::to_vec</code>. We can avoid them by allocating the exact amount of memory needed. This will require an extra linked list traversal to calculate the capacity, but the performance gain from avoiding reallocations outweighs the cost of the extra traversal:</p>
<pre data-lang="rust"><code data-lang="rust"><span>impl</span><span>&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>pub</span><span>(</span><span>crate</span><span>) </span><span>fn </span><span>to_vec</span><span>(&amp;</span><span>'a </span><span>self</span><span>) -&gt; Vec&lt;&amp;</span><span>'a str</span><span>&gt; {
</span><span>        </span><span>// Walk the linked list to calculate the capacity
</span><span>        </span><span>let mut</span><span> capacity = </span><span>0</span><span>;
</span><span>        </span><span>let mut</span><span> head = </span><span>self</span><span>;
</span><span>        </span><span>while let </span><span>Some(next) = head.parent {
</span><span>            head = next;
</span><span>            capacity += </span><span>1</span><span>;
</span><span>        }
</span><span>        </span><span>// Callect the segments from the head to the tail
</span><span>        </span><span>let mut</span><span> buffer = Vec::with_capacity(capacity);
</span><span>        </span><span>let mut</span><span> head = </span><span>self</span><span>;
</span><span>        </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>            buffer.</span><span>push</span><span>(*segment);
</span><span>        }
</span><span>        </span><span>while let </span><span>Some(next) = head.parent {
</span><span>            head = next;
</span><span>            </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>                buffer.</span><span>push</span><span>(*segment);
</span><span>            }
</span><span>        }
</span><span>        </span><span>// Reverse the buffer to get the segments in the correct order
</span><span>        buffer.</span><span>reverse</span><span>();
</span><span>        buffer
</span><span>    }
</span><span>}
</span></code></pre>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/10ae4f100935c757bb7707defcf122c179aee2dc" target="_blank">10ae4f1</a></td>
  <td>39.1 µs<br>(<strong>+11.2%</strong>)</td>
  <td>667.9 µs<br>(<strong>+0.5%</strong>)</td>
  <td>1.30 ms<br>(<strong>-1.7%</strong>)</td>
  <td>899.7 µs<br>(<strong>-7.5%</strong>)</td>
  <td>1.96 ms<br>(<strong>-23.3%</strong>)</td>
  <td>3.49 ms<br>(<strong>-24.3%</strong>)</td>
</tr>
  </tbody>
</table>
<p>Great! Precise memory allocation improves performance for invalid inputs, bringing it closer to the performance of valid ones.
Allocate exactly as needed, whenever possible, to avoid the overhead of memory reallocations.</p>
<h2 id="idea-5-avoid-temporary-vec">Idea 5: Avoid temporary <code>Vec</code></h2>
<p>At this point, the most significant slowdown is for invalid cases. If we take a closer look at the <code>ValidationError</code> implementation we’ll see the <code>collect</code> call, which means that first, we build <code>Vec&lt;&amp;str&gt;</code> in <code>JsonPointerNode::to_vec</code> and then almost immediately build <code>Vec&lt;String&gt;</code> from it, which means allocating <code>Vec</code> twice. Why don’t we just build <code>Vec&lt;String&gt;</code> in the first place:</p>
<pre data-lang="rust"><code data-lang="rust"><span>impl </span><span>ValidationError {
</span><span>    </span><span>fn </span><span>new</span><span>(</span><span>message</span><span>: impl Into&lt;String&gt;, </span><span>location</span><span>: Vec&lt;String&gt;) -&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self </span><span>{
</span><span>            message: message.</span><span>into</span><span>(),
</span><span>            location,
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>&lt;</span><span>'a</span><span>&gt;(
</span><span>        &amp;</span><span>self</span><span>,
</span><span>        </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value,
</span><span>        </span><span>path</span><span>: JsonPointerNode&lt;</span><span>'a</span><span>, '_&gt;,
</span><span>    ) -&gt; ValidationResult {
</span><span>        </span><span>match </span><span>(</span><span>self</span><span>, instance) {
</span><span>            </span><span>// ... Compare `instance` type with expected type
</span><span>            _ =&gt; Err(ValidationError::new(
</span><span>                format!("</span><span>{instance}</span><span> is not of type '</span><span>{self}</span><span>'</span><span>"),
</span><span>                path.</span><span>to_vec</span><span>(),
</span><span>            )),
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span>impl</span><span>&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>pub</span><span>(</span><span>crate</span><span>) </span><span>fn </span><span>to_vec</span><span>(&amp;</span><span>self</span><span>) -&gt; Vec&lt;String&gt; {
</span><span>        </span><span>// ...
</span><span>        </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>            buffer.</span><span>push</span><span>((*segment).</span><span>to_string</span><span>());
</span><span>        }
</span><span>        </span><span>while let </span><span>Some(next) = head.parent {
</span><span>            head = next;
</span><span>            </span><span>if let </span><span>Some(segment) = &amp;head.segment {
</span><span>                buffer.</span><span>push</span><span>((*segment).</span><span>to_string</span><span>());
</span><span>            }
</span><span>        }
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span></code></pre>
<p>This optimization leads to a visible performance improvement for invalid cases:</p>
<table>
  <thead>
    <tr>
      <th rowspan="2">Commit</th>
      <th colspan="3">Valid</th>
      <th colspan="3">Invalid</th>
    </tr>
    <tr>
      <th>0</th>
      <th>5</th>
      <th>10</th>
      <th>0</th>
      <th>5</th>
      <th>10</th>
    </tr>
  </thead>
  <tbody>
<tr>
  <td><a href="https://github.com/Stranger6667/article-linked-lists/commit/d3d2182e00aba996134475b90e87d565dfe47ac3" target="_blank">d3d2182</a></td>
  <td>39.7 µs<br>(<strong>-0.2%</strong>)</td>
  <td>652.3 µs<br>(<strong>-2.7%</strong>)</td>
  <td>1.35 ms<br>(<strong>+2.2%</strong>)</td>
  <td>765.1 µs<br>(<strong>-14.2%</strong>)</td>
  <td>1.83 ms<br>(<strong>-6.9%</strong>)</td>
  <td>3.33 ms<br>(<strong>-5.9%</strong>)</td>
</tr>
  </tbody>
</table>
<h2 id="idea-6-struct-size-optimization">Idea 6: Struct size optimization</h2>
<p>Sometimes it is worth trying to reduce struct sizes, especially when the struct is passed by value frequently. 
Smaller structs lead to less memory usage and faster function calls, as less data needs to be copied on the stack.</p>
<p>If we were to track not only keys in JSON objects but also indexes in arrays, we would need to use an enum like this:</p>
<pre data-lang="rust"><code data-lang="rust"><span>enum </span><span>Segment&lt;'a&gt; {
</span><span>    </span><span>/// Property name within a JSON object.
</span><span>    Property(&amp;</span><span>'a str</span><span>),
</span><span>    </span><span>/// Index within a JSON array.
</span><span>    Index(</span><span>usize</span><span>),
</span><span>}
</span><span>
</span><span>struct </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>segment</span><span>: Option&lt;Segment&lt;</span><span>'a</span><span>&gt;&gt;,
</span><span>    </span><span>parent</span><span>: Option&lt;&amp;</span><span>'b </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt;&gt;,
</span><span>}
</span></code></pre>
<p>Then, the <code>JsonPointerNode</code> struct would occupy 32 bytes:</p>
<pre data-lang="rust"><code data-lang="rust"><span>assert_eq!(std::mem::size_of::&lt;JsonPointerNode&gt;(), </span><span>32</span><span>);
</span></code></pre>
<p>However, by avoiding <code>Option</code> in the <code>segment</code> field, we can reduce its size to 24 bytes. The idea is to put some cheap value in the root node and never read it:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>segment</span><span>: Segment&lt;</span><span>'a</span><span>&gt;,
</span><span>    </span><span>parent</span><span>: Option&lt;&amp;</span><span>'b </span><span>JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt;&gt;,
</span><span>}
</span><span>impl</span><span>&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>    </span><span>/// Create a root node of a JSON pointer.
</span><span>    </span><span>const fn </span><span>new</span><span>() -&gt; </span><span>Self </span><span>{
</span><span>        JsonPointerNode {
</span><span>            </span><span>// The value does not matter, it will never be used
</span><span>            segment: Segment::Index(</span><span>0</span><span>),
</span><span>            parent: None,
</span><span>        }
</span><span>    }
</span><span>   </span><span>fn </span><span>push</span><span>(&amp;</span><span>'a </span><span>self</span><span>, </span><span>segment</span><span>: Segment&lt;</span><span>'a</span><span>&gt;) -&gt; JsonPointerNode&lt;</span><span>'a</span><span>, </span><span>'b</span><span>&gt; {
</span><span>        JsonPointerNode {
</span><span>            segment,
</span><span>            parent: Some(</span><span>self</span><span>),
</span><span>        }
</span><span>    }
</span><span>    </span><span>/// Convert the JSON pointer node to a vector of path segments.
</span><span>    </span><span>pub</span><span>(</span><span>crate</span><span>) </span><span>fn </span><span>to_vec</span><span>(&amp;</span><span>self</span><span>) -&gt; Vec&lt;String&gt; {
</span><span>        </span><span>// ...
</span><span>        </span><span>if</span><span> head.parent.</span><span>is_some</span><span>() {
</span><span>            buffer.</span><span>push</span><span>(head.segment.</span><span>to_string</span><span>())
</span><span>        }
</span><span>        </span><span>while let </span><span>Some(next) = head.parent {
</span><span>            head = next;
</span><span>            </span><span>if</span><span> head.parent.</span><span>is_some</span><span>() {
</span><span>                buffer.</span><span>push</span><span>(head.segment.</span><span>to_string</span><span>());
</span><span>            }
</span><span>        }
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span></code></pre>
<p>This technique is directly used in the <a href="https://github.com/Stranger6667/jsonschema-rs" target="_blank">jsonschema</a> crate to reduce the size of the <code>JsonPointerNode</code> struct, but not used here for simplicity.</p>
<h2 id="more-ideas-that-didn-t-make-it">More ideas that didn't make it</h2>
<p>I think that we can also gain a bit more performance by avoiding the <code>reverse</code> call in <code>JsonPointerNode::to_vec</code>, as it moves the data around. One way to achieve this is by assigning segments starting from the back of a vector filled with default values. However, the extra bookeeping needed for writing in the reverse order could outweigh the gains, so it's important to profile and benchmark any changes to ensure they provide measurable benefits for your use case.</p>
<p>Another idea is to store references to path segments inside <code>ValidationError</code> instead of cloning the strings:</p>
<pre data-lang="rust"><code data-lang="rust"><span>struct </span><span>ValidationError&lt;</span><span>'a</span><span>&gt; {
</span><span>    </span><span>message</span><span>: String,
</span><span>    </span><span>location</span><span>: Vec&lt;&amp;</span><span>'a str</span><span>&gt;,
</span><span>}
</span></code></pre>
<p>This way, we can avoid cloning the path segments and instead store references to them. This could lead to performance improvements, especially when dealing with long paths or large numbers of errors. However, this approach would make <code>ValidationError</code> less flexible, as it would be tied to the lifetime of the input JSON data.</p>
<h2 id="bonus-idea-maybe-you-don-t-need-a-linked-list">Bonus idea: Maybe you don't need a linked list?</h2>
<p>This idea was suggested by <a href="https://github.com/kobzol" target="_blank">@Kobzol</a>, who noted that the error path could be collected lazily from the call stack in the error propagation path. I've implemented the idea based on the suggestion and the original code snippet:</p>
<pre data-lang="rust"><code data-lang="rust"><span>impl </span><span>ValidationError {
</span><span>    </span><span>pub</span><span>(</span><span>crate</span><span>) </span><span>fn </span><span>push_segment</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>segment</span><span>: String) {
</span><span>        </span><span>self</span><span>.location.</span><span>push</span><span>(segment);
</span><span>    }
</span><span>    </span><span>pub</span><span>(</span><span>crate</span><span>) </span><span>fn </span><span>finish</span><span>(</span><span>mut </span><span>self</span><span>) -&gt; ValidationError {
</span><span>        </span><span>self</span><span>.location.</span><span>reverse</span><span>();
</span><span>        </span><span>self
</span><span>    }
</span><span>}
</span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value) -&gt; ValidationResult {
</span><span>    </span><span>if let </span><span>Err(error) = </span><span>self</span><span>.node.</span><span>validate</span><span>(instance, </span><span>0</span><span>) {
</span><span>        </span><span>// Reverse the path segments in the `finish` method
</span><span>        Err(error.</span><span>finish</span><span>())
</span><span>    } </span><span>else </span><span>{
</span><span>        Ok(())
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Properties {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;Value, </span><span>level</span><span>: </span><span>u32</span><span>) -&gt; ValidationResult {
</span><span>        </span><span>// ... 
</span><span>            </span><span>for </span><span>(key, value) in &amp;</span><span>self</span><span>.properties {
</span><span>                </span><span>if let </span><span>Some(instance) = object.</span><span>get</span><span>(key) {
</span><span>                    </span><span>if let </span><span>Err(</span><span>mut</span><span> error) = value.</span><span>validate</span><span>(instance, level + </span><span>1</span><span>) {
</span><span>                        error.</span><span>push_segment</span><span>(key.</span><span>to_string</span><span>());
</span><span>                        </span><span>return </span><span>Err(error);
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span><span>
</span><span>impl </span><span>Node </span><span>for </span><span>Type {
</span><span>    </span><span>fn </span><span>validate</span><span>(&amp;</span><span>self</span><span>, </span><span>instance</span><span>: &amp;</span><span>'a</span><span> Value, </span><span>level</span><span>: </span><span>u32</span><span>) -&gt; ValidationResult {
</span><span>        </span><span>// ...
</span><span>            _ =&gt; Err(ValidationError::new(
</span><span>                format!("</span><span>{instance}</span><span> is not of type '</span><span>{self}</span><span>'</span><span>"),
</span><span>                Vec::with_capacity(level as </span><span>usize</span><span>)
</span><span>        </span><span>// ...
</span><span>    }
</span><span>}
</span></code></pre>
<p>However, I was not able to get a stable improvement in benchmarks yet :(</p>
<blockquote>
<p>Small improvement may come from the fact that we no longer use the <code>?</code> operator as it involves the <code>From/Into</code> conversion, but we only have a single error type and don't need to convert it. This is the reason why <code>serde</code> has its own <code>tri!</code> <a href="https://github.com/serde-rs/serde/blob/3202a6858a2802b5aba2fa5cf3ec8f203408db74/serde/src/lib.rs#L287" target="_blank">macro</a> that is used instead of <code>?</code>;</p>
</blockquote>
<h2 id="conclusion">Conclusion</h2>
<p>In the end, we achieved ~4.5x / ~2.2x improvements from the naive implementation for valid / invalid scenarios. Overall this feature adds 18% / 95% on top of the path-less version!</p>

  <p><img src="https://dygalo.dev/blog/performance-comparison.png"></p><p>Some optimizations in this article may not seem immediately beneficial, especially if you already know where the bottlenecks are. However, exploring simpler optimizations can sometimes reveal unexpected opportunities for improvement. Even if an optimization doesn't directly pay off or even makes your code slower in some cases, it may open up new possibilities for further optimizations.</p>
<p><strong>Takeaways</strong>:</p>
<ol>
<li>A naive approach could be good enough</li>
<li>Try alternative data structures such as immutable <code>Vector</code></li>
<li>Consider simpler stdlib variations like <code>Arc</code></li>
<li>Look at the problem at different scales</li>
<li>Search for a data structure that fits your problem</li>
<li>Allocate exactly as needed and when necessary</li>
<li>Reduce the size of values you pass around a lot</li>
</ol>
<p>If you have any more ideas to improve this use case or have any suggestions, please let me know!</p>
<p>In the next article, I will dive into HTML trees and why you should try to build your own data structure for it.</p>
<p>Thank you for your attention!</p>
<p>Dmitry</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tech companies are flocking to the Middle East (132 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2024/05/14/middle-east-ai-tech-companies-saudi-arabia-uae/</link>
            <guid>40355126</guid>
            <pubDate>Tue, 14 May 2024 13:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2024/05/14/middle-east-ai-tech-companies-saudi-arabia-uae/">https://www.washingtonpost.com/technology/2024/05/14/middle-east-ai-tech-companies-saudi-arabia-uae/</a>, See on <a href="https://news.ycombinator.com/item?id=40355126">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2024/05/14/middle-east-ai-tech-companies-saudi-arabia-uae/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[New gel breaks down alcohol in the body (117 pts)]]></title>
            <link>https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body.html</link>
            <guid>40354130</guid>
            <pubDate>Tue, 14 May 2024 11:46:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body.html">https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body.html</a>, See on <a href="https://news.ycombinator.com/item?id=40354130">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
                
                    
    
    <!-- Panorama header -->
    

    <!-- Blog header -->
    
    <!-- Tags when not blog -->
    
        
    
    
    

    <!-- Articleheader -->
    <div>
    <p>
            Researchers at ETH Zurich have developed a protein-based gel that breaks down alcohol in the gastrointestinal tract without harming the body. In the future, people who take the gel could reduce the harmful and intoxicating effects of alcohol.
        </p>
    

</div>

    <!-- Nav & News images -->
    

    <!-- Details -->
    <div>
        <p><span>
            <time datetime="2024-05-13T00:00:00Z">13.05.2024</time>
            
                by
                
                    <a href="https://ethz.ch/en/news-and-events/eth-news/news.html?AUTHOR=Q2hyaXN0b3BoIEVsaGFyZHQ&amp;path=L2NvbnRlbnQvbWFpbi9lbi9uZXdzLXVuZC12ZXJhbnN0YWx0dW5nZW4vZXRoLW5ld3MvbmV3cy9qY3I6Y29udGVudA" title="Christoph Elhardt">
                
                Christoph Elhardt
                
                    </a>
                
            
            
            
        </span></p><ul>
            <li>
                <a id="newsCommentsLink" href="#comment-system">
                    
                    <span>Number of comments</span>
                </a>
            </li>
            <!-- Socialsharing (configurable) -->
            
    
        
            
                <li>
            
            
            
                </li>
            
        
        
    

        </ul>
    </div>

    <!-- ArticleLeadImage -->
    
        <div>
            <figure>
            <img alt="A man is sitting at a table in a bar. In one hand he is holding a glass with a brown liquid, in the other hand he is holding a small bowl with a white gel." src="https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body/_jcr_content/articleLeadImage/image.imageformat.carousel.587127758.jpg">
			<figcaption>
			    <p>
			      The gel could prevent the blood alcohol level from rising.&nbsp;(Adobe Stock, edited with AI)</p>
			  </figcaption>
			</figure>
    
          </div>
    

    <!-- Parsys 1 --> 
    <div>

<div>
                
                	<h2>In brief</h2>
                
                
                <ul> 
 <li>Researchers at ETH Zurich have developed a gel made from whey protein fibrils that uses individual iron atoms to convert alcohol in the intestine into harmless acetic acid before it enters the bloodstream.</li> 
 <li>They showed that in mice, the gel reduces blood alcohol levels by up to 50 percent and protects the body from damage.</li> 
 <li>While further tests are necessary before the gel can be used in humans, the researchers are confident that these will be a success and have already applied to patent the gel.</li> 
</ul>
            </div>
<div>
                
                
                <p>Most alcohol enters the bloodstream via the mucous membrane layer of the stomach and the intestines. These days, the consequences of this are undisputed: even small amounts of alcohol impair people’s ability to concentrate and to react, increasing the risk of accidents. Drinking large quantities on a regular basis is detrimental to one’s health: common consequences include liver disease, inflammation of the gastrointestinal tract and cancer. According to the World Health Organization, around 3 million people die every year from excessive alcohol consumption.</p>
<p>Researchers at ETH Zurich have now developed a protein gel that breaks down alcohol in the gastrointestinal tract. In a study recently published in the journal <i>Nature Nanotechnology</i>, they show that in mice, the gel converts alcohol quickly, efficiently and directly into harmless acetic acid before it enters the bloodstream, where it would normally develop its intoxicating and harmful effects.</p>
<h2><b>Reducing health damage caused by alcohol</b></h2>
<p>“The gel shifts the breakdown of alcohol from the liver to the digestive tract. In contrast to when alcohol is metabolised in the liver, no harmful acetaldehyde is produced as an intermediate product,” explains Professor Raffaele Mezzenga from the Laboratory of Food &amp; Soft Materials at ETH Zurich. Acetaldehyde is toxic and is responsible for many health problems caused by excessive alcohol consumption.</p>
<p>In the future, the gel could be taken orally before or during alcohol consumption to prevent blood alcohol levels from rising and acetaldehyde from damaging the body. In contrast to many products available on the market, the gel combats not only the symptoms of harmful alcohol consumption but also its causes. Yet, the gel is only effective as long as there is still alcohol in the gastrointestinal tract. This means it can do very little to help with alcohol poisoning, once the alcohol has crossed into the bloodstream. Nor does it help to reduce alcohol consumption in general. “It’s healthier not to drink alcohol at all. However, the gel could be of particular interest to people who don’t want to give up alcohol completely, but don’t want to put a strain on their bodies and aren’t actively seeking the effects of alcohol,” Mezzenga says.</p>

            </div>
<div>
                        <figure>
            <a href="https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body/_jcr_content/wide_content/image/image.imageformat.lightbox.29241854.jpg" data-caption="Alcohol degradation in the body with and without the new gel." data-size="5313x2989" aria-label="Enlarged view: The illustration shows how the alcohol is broken down in the stomach or intestine via the protein gel. Without the protein gel, the alcohol reaches the liver via the blood and is broken down there.">
	<img alt="Enlarged view: The illustration shows how the alcohol is broken down in the stomach or intestine via the protein gel. Without the protein gel, the alcohol reaches the liver via the blood and is broken down there." src="https://ethz.ch/en/news-and-events/eth-news/news/2024/05/press-release-new-gel-breaks-down-alcohol-in-the-body/_jcr_content/wide_content/image/image.imageformat.1286.29241854.jpg">
			<span></span>
                        </a>
                <figcaption>
			    <p>
			      Alcohol degradation in the body with and without the new gel.&nbsp;(Visualisations: ETH Zurich / Adobe Stock)</p>
			  </figcaption>
			</figure>
    
                    </div>
<div>
                
                	<h2><b>Main ingredients: Whey, iron and gold</b></h2>
                
                
                <p>The researchers used ordinary whey proteins to produce the gel. They boiled them for several hours to form long, thin fibrils. Adding salt and water as a solvent then causes the fibrils to cross-link and form a gel. The advantage of a gel over other delivery systems is that it is digested very slowly. But to break down the alcohol, the gel needs several catalysts.</p>
<p>The researchers used individual iron atoms as the main catalyst, which they distributed evenly over the surface of the long protein fibrils. “We immersed the fibrils in an iron bath, so to speak, so that they can react effectively with the alcohol and convert it into acetic acid,” says ETH researcher Jiaqi Su, the first author of the study. Tiny amounts of hydrogen peroxide are needed to trigger this reaction in the intestine. These are generated by an upstream reaction between glucose and gold nanoparticles. Gold was chosen as a catalyst for hydrogen peroxide because the precious metal is not digested and therefore stays effective for longer in the digestive tract. The researchers packed all these substances – iron, glucose and gold – into the gel. This resulted in a multi-stage cascade of enzymatic reactions that ultimately converts alcohol into acetic acid.</p>
<h2><b>Gel works in mice</b></h2>
<p>The researchers tested the effectiveness of the new gel on mice that were given alcohol just once as well as on mice that were given alcohol regularly for ten days. Thirty minutes after the single dose of alcohol, the prophylactic application of the gel reduced the alcohol level in the mice by 40 percent. Five hours after alcohol intake, their blood alcohol level had dropped by as much as 56 percent compared to the control group. Harmful acetaldehyde accumulated less in these mice, and they exhibited greatly reduced stress reactions in their livers, which was reflected in better blood values.</p>
<p>In the mice that were given alcohol for ten days, the researchers were able to demonstrate not only a lower alcohol level but also a lasting therapeutic effect of the gel: the mice that were given the gel daily in addition to alcohol showed significantly less weight loss, less liver damage and hence better fat metabolism in the liver as well as better blood values. Other organs in the mice, such as the spleen or the intestine, as well as their tissues also showed much less damage caused by alcohol.</p>
<h2><b>Patent pending</b></h2>
<p>In an earlier study of administering iron through whey protein fibrils, the researchers had discovered that iron reacts with alcohol to form acetic acid. As this process was too slow and too ineffective at the time, they changed the form in which they attached the iron to the protein fibrils. “Instead of using larger nanoparticles, we opted for individual iron atoms, which can be distributed more evenly on the surface of the fibrils and therefore react more effectively and quickly with the alcohol,” Mezzenga says.</p>
<p>The researchers have already applied for a patent for the gel. While several clinical tests are still required before it can be authorised for human use, the researchers are confident that this step will also be successful, as they already showed that the whey protein fibrils that make up the gel are edible.&nbsp;</p>
            </div>
<div>
                
                	<h2><b>Reference</b></h2>
                
                
                <p>Su J, Wang P, Zhou W, Peydayesh M, Zhou J, Jin T, Donat F, Jin C, Xia L, Wang K, Ren F, Van der Meeren P, García de Arquer P, and Mezzenga R. Single-site iron-anchored amyloid hydrogels as catalytic platforms 1 for alcohol detoxification.&nbsp;Nature&nbsp;Nanotechnology. DOI: <a href="https://www.nature.com/articles/s41565-024-01657-7"><span>external page</span>10.1038/s41565-024-01657-7</a><br> </p>
            </div>
<div>
            <p>
                
                	<h2>Contact</h2>
                
                
                
            </p>
        </div>




</div>
    <!-- Socialsharing (display only) -->
    
    
        
            
            
            
        
        
    


    <!-- Parsys 2 -->
    
    <!-- Taglist -->
    
        
            
        
    

    <!-- Comments -->
    
    	
	    
    

                
                
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My VM is lighter (and safer) than your container (2017) (162 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/3132747.3132763</link>
            <guid>40353963</guid>
            <pubDate>Tue, 14 May 2024 11:24:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/3132747.3132763">https://dl.acm.org/doi/10.1145/3132747.3132763</a>, See on <a href="https://news.ycombinator.com/item?id=40353963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav></nav><div><!-- abstract content --><div><p><h2 id="d9093262e1">ABSTRACT</h2></p><div>
		<p>Containers are in great demand because they are lightweight when compared to virtual machines. On the downside, containers offer weaker isolation than VMs, to the point where people run containers in virtual machines to achieve proper isolation. In this paper, we examine whether there is indeed a strict tradeoff between isolation (VMs) and efficiency (containers). We find that VMs can be as nimble as containers, as long as they are small and the toolstack is fast enough.</p> <p>We achieve lightweight VMs by using unikernels for specialized applications and with Tinyx, a tool that enables creating tailor-made, trimmed-down Linux virtual machines. By themselves, lightweight virtual machines are not enough to ensure good performance since the virtualization control plane (the toolstack) becomes the performance bottleneck. We present LightVM, a new virtualization solution based on Xen that is optimized to offer fast boot-times regardless of the number of active VMs. LightVM features a complete redesign of Xen's control plane, transforming its centralized operation to a distributed one where interactions with the hypervisor are reduced to a minimum. LightVM can boot a VM in 2.3ms, comparable to fork/exec on Linux (1ms), and two orders of magnitude faster than Docker. LightVM can pack thousands of LightVM guests on modest hardware with memory and CPU usage comparable to that of processes.</p>
	</div></div><!-- /abstract content --><p><a href="#SEC_refrences" id="SEC_suppl">Skip Supplemental Material Section</a></p><div data-rel="videos"><p><h2 id="sec-supp">Supplemental Material</h2></p></div><div data-sectionname="References"><div><h2 id="sec-ref">
                    References
                </h2></div><ol><li id="ref-00001"><span>Amazon Web Services {n. d.}. Amazon EC2 Container Service. https://aws.amazon.com/ecs/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Amazon+Web+Services+%7Bn.+d.%7D.+Amazon+EC2+Container+Service.+https%3A%2F%2Faws.amazon.com%2Fecs%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00002"><span>Amazon Web Services {n. d.}. AWS Lambda - Serverless Compute. https://aws.amazon.com/lambda. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Amazon+Web+Services+%7Bn.+d.%7D.+AWS+Lambda+-+Serverless+Compute.+https%3A%2F%2Faws.amazon.com%2Flambda.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00003"><span>Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, and Andrew Warfield. 2003. Xen and the Art of Virtualization. SIGOPS Open Syst. Rev. 37, 5 (Oct. 2003), 164--177.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Paul+Barham%2C+Boris+Dragovic%2C+Keir+Fraser%2C+Steven+Hand%2C+Tim+Harris%2C+Alex+Ho%2C+Rolf+Neugebauer%2C+Ian+Pratt%2C+and+Andrew+Warfield.+2003.+Xen+and+the+Art+of+Virtualization.+SIGOPS+Open+Syst.+Rev.+37%2C+5+%28Oct.+2003%29%2C+164%2D%2D177.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/1165389.945462" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00004"><span>J. Clark. {n. d.}. Google: "EVERYTHING at Google runs in a container". http//:www.theregister.co.uk/2014/05/23/google_containerizationtwobillion/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=J.+Clark.+%7Bn.+d.%7D.+Google%3A+%22EVERYTHING+at+Google+runs+in+a+container%22.+http%2F%2F%3Awww.theregister.co.uk%2F2014%2F05%2F23%2Fgoogle_containerizationtwobillion%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00005"><span>Patrick Colp, Mihir Nanavati, Jun Zhu, William Aiello, George Coker, Tim Deegan, Peter Loscocco, and Andrew Warfield. 2011. Breaking Up is Hard to Do: Security and Functionality in a Commodity Hypervisor. In Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles (SOSP '11). ACM, New York, NY, USA, 189--202.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Patrick+Colp%2C+Mihir+Nanavati%2C+Jun+Zhu%2C+William+Aiello%2C+George+Coker%2C+Tim+Deegan%2C+Peter+Loscocco%2C+and+Andrew+Warfield.+2011.+Breaking+Up+is+Hard+to+Do%3A+Security+and+Functionality+in+a+Commodity+Hypervisor.+In+Proceedings+of+the+Twenty-Third+ACM+Symposium+on+Operating+Systems+Principles+%28SOSP+%2711%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+189%2D%2D202.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/2043556.2043575" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00006"><span>Docker {n. d.}. The Docker Containerization Platform. https://www.docker.com/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Docker+%7Bn.+d.%7D.+The+Docker+Containerization+Platform.+https%3A%2F%2Fwww.docker.com%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00007"><span>John R. Douceur, Jeremy Elson, Jon Howell, and Jacob R. Lorch. 2008. Leveraging Legacy Code to Deploy Desktop Applications on the Web. In Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation (OSDI'08). USENIX Association, Berkeley, CA, USA, 339--354. http://dl.acm.org/citation.cfm?id=1855741.1855765 <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=John+R.+Douceur%2C+Jeremy+Elson%2C+Jon+Howell%2C+and+Jacob+R.+Lorch.+2008.+Leveraging+Legacy+Code+to+Deploy+Desktop+Applications+on+the+Web.+In+Proceedings+of+the+8th+USENIX+Conference+on+Operating+Systems+Design+and+Implementation+%28OSDI%2708%29.+USENIX+Association%2C+Berkeley%2C+CA%2C+USA%2C+339%2D%2D354.+http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1855741.1855765+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/1855741.1855765" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00008"><span>D. R. Engler, M. F. Kaashoek, and J. O'Toole, Jr. 1995. Exokernel: An Operating System Architecture for Application-level Resource Management. In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles (SOSP '95). ACM, New York, NY, USA, 251--266.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=D.+R.+Engler%2C+M.+F.+Kaashoek%2C+and+J.+O%27Toole%2C+Jr.+1995.+Exokernel%3A+An+Operating+System+Architecture+for+Application-level+Resource+Management.+In+Proceedings+of+the+Fifteenth+ACM+Symposium+on+Operating+Systems+Principles+%28SOSP+%2795%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+251%2D%2D266.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/224056.224076" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00009"><span>Erlang on Xen 2012. Erlang on Xen. http://erlangonxen.org/. (July 2012).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Erlang+on+Xen+2012.+Erlang+on+Xen.+http%3A%2F%2Ferlangonxen.org%2F.+%28July+2012%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00010"><span>Google Cloud Platform {n. d.}. The Google Cloud Platform Container Engine. https://cloud.google.com/container-engine. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Google+Cloud+Platform+%7Bn.+d.%7D.+The+Google+Cloud+Platform+Container+Engine.+https%3A%2F%2Fcloud.google.com%2Fcontainer-engine.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00011"><span>A. Grattafiori. {n. d.}. Understanding and Hardening Linux Containers. https://www.nccgroup.trust/us/our-research/understanding-and-hardening-linux-containers/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=A.+Grattafiori.+%7Bn.+d.%7D.+Understanding+and+Hardening+Linux+Containers.+https%3A%2F%2Fwww.nccgroup.trust%2Fus%2Four-research%2Funderstanding-and-hardening-linux-containers%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00012"><span>Cameron Hamilton-Rich. {n. d.}. axTLS Embedded SSL. http://axtls.sourceforge.net. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Cameron+Hamilton-Rich.+%7Bn.+d.%7D.+axTLS+Embedded+SSL.+http%3A%2F%2Faxtls.sourceforge.net.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00013"><span>Poul henning Kamp and Robert N. M. Watson. 2000. Jails: Confining the omnipotent root. In In Proc. 2nd Intl. SANE Conference.<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Poul+henning+Kamp+and+Robert+N.+M.+Watson.+2000.+Jails%3A+Confining+the+omnipotent+root.+In+In+Proc.+2nd+Intl.+SANE+Conference." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00014"><span>J. Hertz. {n. d.}. Abusing Privileged and Unprivileged Linux Containers. https://www.nccgroup.tmst/uk/our-research/abusing-privileged-and-unprivileged-linux-containers/, ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=J.+Hertz.+%7Bn.+d.%7D.+Abusing+Privileged+and+Unprivileged+Linux+Containers.+https%3A%2F%2Fwww.nccgroup.tmst%2Fuk%2Four-research%2Fabusing-privileged-and-unprivileged-linux-containers%2F%2C+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00015"><span>Jon Howell, Bryan Parno, and John R. Douceur. 2013. Embassies: Radically Refactoring the Web. In Presented as part of the 10th USENTX Symposium on Networked Systems Design and Implementation (NSDI13). USENIX, Lombard, IL, 529--545. https://www.usenix.org/conference/nsdil3/technical-sessions/presentation/howell <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Jon+Howell%2C+Bryan+Parno%2C+and+John+R.+Douceur.+2013.+Embassies%3A+Radically+Refactoring+the+Web.+In+Presented+as+part+of+the+10th+USENTX+Symposium+on+Networked+Systems+Design+and+Implementation+%28NSDI13%29.+USENIX%2C+Lombard%2C+IL%2C+529%2D%2D545.+https%3A%2F%2Fwww.usenix.org%2Fconference%2Fnsdil3%2Ftechnical-sessions%2Fpresentation%2Fhowell+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/2482626.2482676" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00016"><span>Yun Chao Hu, Milan Patel, Dario Sabella, Nurit Sprecher, and Valerie Young. 2015. Mobile Edge Computing - A key technology towards 5G. ETSI White Paper No. 11, First edition (2015).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Yun+Chao+Hu%2C+Milan+Patel%2C+Dario+Sabella%2C+Nurit+Sprecher%2C+and+Valerie+Young.+2015.+Mobile+Edge+Computing+-+A+key+technology+towards+5G.+ETSI+White+Paper+No.+11%2C+First+edition+%282015%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00017"><span>IBM. {n. d.}. Docker at insane scale on IBM Power Systems. https://www.ibm.com/blogs/bluemix/2015/ll/docker-insane-scale-on-ibm-power-systems. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=IBM.+%7Bn.+d.%7D.+Docker+at+insane+scale+on+IBM+Power+Systems.+https%3A%2F%2Fwww.ibm.com%2Fblogs%2Fbluemix%2F2015%2Fll%2Fdocker-insane-scale-on-ibm-power-systems.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00018"><span>IBM developerWorks Open {n. d.}. Solo5 Unikernel. https://developer.ibm.com/open/openprojects/solo5-unikernel/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=IBM+developerWorks+Open+%7Bn.+d.%7D.+Solo5+Unikernel.+https%3A%2F%2Fdeveloper.ibm.com%2Fopen%2Fopenprojects%2Fsolo5-unikernel%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00019"><span>Intel. {n. d.}. Intel Clear Containers: A Breakthrough Combination of Speed and Workload Isolation. https://clearlinux.org/sites/default/files/vmscontainers_wp_v5.pdf. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Intel.+%7Bn.+d.%7D.+Intel+Clear+Containers%3A+A+Breakthrough+Combination+of+Speed+and+Workload+Isolation.+https%3A%2F%2Fclearlinux.org%2Fsites%2Fdefault%2Ffiles%2Fvmscontainers_wp_v5.pdf.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00020"><span>Avi Kivity, Yaniv Kamay, Dor Laor, Uri Lublin, and Anthony Liguori. 2007. KVM: the Linux Virtual Machine Monitor. In In Proc. 2007 Ottawa Linux Symposium (OLS '07).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Avi+Kivity%2C+Yaniv+Kamay%2C+Dor+Laor%2C+Uri+Lublin%2C+and+Anthony+Liguori.+2007.+KVM%3A+the+Linux+Virtual+Machine+Monitor.+In+In+Proc.+2007+Ottawa+Linux+Symposium+%28OLS+%2707%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00021"><span>Avi Kivity, Dor Laor, Glauber Costa, Pekka Enberg, Nadav Har'El, Don Marti, and Vlad Zolotarov. 2014. OSv---Optimizing the Operating System for Virtual Machines. In Proceedings of the 2014 USENTX Annual Technical Conference (USENIX ATC '14). USENIX Association, Philadelphia, PA, 61--72. https://www.usenix.org/conference/atcl4/technical-sessions/presentation/kivity <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Avi+Kivity%2C+Dor+Laor%2C+Glauber+Costa%2C+Pekka+Enberg%2C+Nadav+Har%27El%2C+Don+Marti%2C+and+Vlad+Zolotarov.+2014.+OSv%2D%2D-Optimizing+the+Operating+System+for+Virtual+Machines.+In+Proceedings+of+the+2014+USENTX+Annual+Technical+Conference+%28USENIX+ATC+%2714%29.+USENIX+Association%2C+Philadelphia%2C+PA%2C+61%2D%2D72.+https%3A%2F%2Fwww.usenix.org%2Fconference%2Fatcl4%2Ftechnical-sessions%2Fpresentation%2Fkivity+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/2643634.2643642" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00022"><span>E. Kovacs. {n. d.}. Docker Fixes Vulnerabilities, Shares Plans For Making Platform Safer. http//:www.securityweek.com/docker-fixes-vulnerabilities-shares-plans-making-platform-safer. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=E.+Kovacs.+%7Bn.+d.%7D.+Docker+Fixes+Vulnerabilities%2C+Shares+Plans+For+Making+Platform+Safer.+http%2F%2F%3Awww.securityweek.com%2Fdocker-fixes-vulnerabilities-shares-plans-making-platform-safer.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00023"><span>Simon Kuenzer, Anton Ivanov, Filipe Manco, Jose Mendes, Yuri Volchkov, Florian Schmidt, Kenichi Yasukata, Michio Honda, and Felipe Huici. 2017. Unikernels Everywhere: The Case for Elastic CDNs. In Proceedings of the 13th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments (VEE '17). ACM, New York, NY, USA, 15--29.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Simon+Kuenzer%2C+Anton+Ivanov%2C+Filipe+Manco%2C+Jose+Mendes%2C+Yuri+Volchkov%2C+Florian+Schmidt%2C+Kenichi+Yasukata%2C+Michio+Honda%2C+and+Felipe+Huici.+2017.+Unikernels+Everywhere%3A+The+Case+for+Elastic+CDNs.+In+Proceedings+of+the+13th+ACM+SIGPLAN%2FSIGOPS+International+Conference+on+Virtual+Execution+Environments+%28VEE+%2717%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+15%2D%2D29.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/3050748.3050757" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00024"><span>Horacio Andrés Lagar-Cavilla, Joseph Andrew Whitney, Adin Matthew Scannell, Philip Patchin, Stephen M. Rumble, Eyal de Lara, Michael Brudno, and Mahadev Satyanarayanan. 2009. SnowFlock: Rapid Virtual Machine Cloning for Cloud Computing. In Proceedings of the 4th ACM European Conference on Computer Systems (EuroSys '09). ACM, New York, NY, USA, 1--12.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Horacio+Andr%C3%A9s+Lagar-Cavilla%2C+Joseph+Andrew+Whitney%2C+Adin+Matthew+Scannell%2C+Philip+Patchin%2C+Stephen+M.+Rumble%2C+Eyal+de+Lara%2C+Michael+Brudno%2C+and+Mahadev+Satyanarayanan.+2009.+SnowFlock%3A+Rapid+Virtual+Machine+Cloning+for+Cloud+Computing.+In+Proceedings+of+the+4th+ACM+European+Conference+on+Computer+Systems+%28EuroSys+%2709%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+1%2D%2D12.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/1519065.1519067" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00025"><span>LinuxContainers.org {n. d.}. LinuxContainers.org. https://linuxcontainers.org. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=LinuxContainers.org+%7Bn.+d.%7D.+LinuxContainers.org.+https%3A%2F%2Flinuxcontainers.org.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00026"><span>Anil Madhavapeddy, Thomas Leonard, Magnus Skjegstad, Thomas Gazagnaire, David Sheets, Dave Scott, Richard Mortier, Amir Chaudhry, Balraj Singh, Jon Ludlam, Jon Crowcroft, and Ian Leslie. 2015. Jitsu: Just-In-Time Summoning of Unikernels. In 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI '15). USENIX Association, Oakland, CA, 559--573. https://www.usenix.org/conference/nsdil5/technical-sessions/presentation/madhavapeddy <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Anil+Madhavapeddy%2C+Thomas+Leonard%2C+Magnus+Skjegstad%2C+Thomas+Gazagnaire%2C+David+Sheets%2C+Dave+Scott%2C+Richard+Mortier%2C+Amir+Chaudhry%2C+Balraj+Singh%2C+Jon+Ludlam%2C+Jon+Crowcroft%2C+and+Ian+Leslie.+2015.+Jitsu%3A+Just-In-Time+Summoning+of+Unikernels.+In+12th+USENIX+Symposium+on+Networked+Systems+Design+and+Implementation+%28NSDI+%2715%29.+USENIX+Association%2C+Oakland%2C+CA%2C+559%2D%2D573.+https%3A%2F%2Fwww.usenix.org%2Fconference%2Fnsdil5%2Ftechnical-sessions%2Fpresentation%2Fmadhavapeddy+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/2789770.2789809" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00027"><span>Anil Madhavapeddy and David J. Scott. 2013. Unikernels: Rise of the Virtual Library Operating System. Queue 11, 11, Article 30 (Dec. 2013), 15 pages.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Anil+Madhavapeddy+and+David+J.+Scott.+2013.+Unikernels%3A+Rise+of+the+Virtual+Library+Operating+System.+Queue+11%2C+11%2C+Article+30+%28Dec.+2013%29%2C+15+pages.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/2557963.2566628" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00028"><span>Y. Mao, J. Zhang, and K. B. Letaief. 2016. Dynamic Computation Offloading for Mobile-Edge Computing With Energy Harvesting Devices. IEEE Journal on Selected Areas in Communications 34, 12 (Dec 2016), 3590--3605.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Y.+Mao%2C+J.+Zhang%2C+and+K.+B.+Letaief.+2016.+Dynamic+Computation+Offloading+for+Mobile-Edge+Computing+With+Energy+Harvesting+Devices.+IEEE+Journal+on+Selected+Areas+in+Communications+34%2C+12+%28Dec+2016%29%2C+3590%2D%2D3605.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1109/JSAC.2016.2611964" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00029"><span>Joao Martins, Mohamed Ahmed, Costin Raiciu, Vladimir Olteanu, Michio Honda, Roberto Bifulco, and Felipe Huici. 2014. ClickOS and the Art of Network Function Virtualization. In 11th USENIX Symposium on Networked Systems Design and Implementation (NSDI '14). USENIX Association, Seattle, WA, 459--473. https://www.usenix.org/conference/nsdil4/technical-sessions/presentation/martins <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Joao+Martins%2C+Mohamed+Ahmed%2C+Costin+Raiciu%2C+Vladimir+Olteanu%2C+Michio+Honda%2C+Roberto+Bifulco%2C+and+Felipe+Huici.+2014.+ClickOS+and+the+Art+of+Network+Function+Virtualization.+In+11th+USENIX+Symposium+on+Networked+Systems+Design+and+Implementation+%28NSDI+%2714%29.+USENIX+Association%2C+Seattle%2C+WA%2C+459%2D%2D473.+https%3A%2F%2Fwww.usenix.org%2Fconference%2Fnsdil4%2Ftechnical-sessions%2Fpresentation%2Fmartins+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/2616448.2616491" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00030"><span>McAffee. 2016. Mobile Threat Report. https://www.mcafee.com/us/resources/reports/rp-mobile-threat-report-2016.pdf. (2016).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=McAffee.+2016.+Mobile+Threat+Report.+https%3A%2F%2Fwww.mcafee.com%2Fus%2Fresources%2Freports%2Frp-mobile-threat-report-2016.pdf.+%282016%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00031"><span>MicroPython {n. d.}. MicroPython. https://micropython.org/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=MicroPython+%7Bn.+d.%7D.+MicroPython.+https%3A%2F%2Fmicropython.org%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00032"><span>Microsoft. {n. d.}. Azure Container Service. https://azure.microsoft.com/en-us/services/container-service/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Microsoft.+%7Bn.+d.%7D.+Azure+Container+Service.+https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fservices%2Fcontainer-service%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00033"><span>Microsoft Research. {n. d.}. Drawbridge. https://www.microsoft.com/en-us/research/project/drawbridge/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Microsoft+Research.+%7Bn.+d.%7D.+Drawbridge.+https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fproject%2Fdrawbridge%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00034"><span>minios {n. d.}. Mini-OS. https://wiki.xenproject.org/wiki/Mini-OS. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=minios+%7Bn.+d.%7D.+Mini-OS.+https%3A%2F%2Fwiki.xenproject.org%2Fwiki%2FMini-OS.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00035"><span>A. Mourat. {n. d.}. 5 security concerns when using Docker. https://www.oreilly.com/ideas/five-security-concerns-when-using-docker. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=A.+Mourat.+%7Bn.+d.%7D.+5+security+concerns+when+using+Docker.+https%3A%2F%2Fwww.oreilly.com%2Fideas%2Ffive-security-concerns-when-using-docker.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00036"><span>Vlad Nitu, Pierre Olivier, Alain Tchana, Daniel Chiba, Antonio Barbalace, Daniel Hagimont, and Binoy Ravindran. 2017. Swift Birth and Quick Death: Enabling Fast Parallel Guest Boot and Destruction in the Xen Hypervisor. In Proceedings of the 13th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments (VEE '17). ACM, New York, NY, USA, 1--14.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Vlad+Nitu%2C+Pierre+Olivier%2C+Alain+Tchana%2C+Daniel+Chiba%2C+Antonio+Barbalace%2C+Daniel+Hagimont%2C+and+Binoy+Ravindran.+2017.+Swift+Birth+and+Quick+Death%3A+Enabling+Fast+Parallel+Guest+Boot+and+Destruction+in+the+Xen+Hypervisor.+In+Proceedings+of+the+13th+ACM+SIGPLAN%2FSIGOPS+International+Conference+on+Virtual+Execution+Environments+%28VEE+%2717%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+1%2D%2D14.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/3050748.3050758" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00037"><span>MAN page. {n. d.}. Linux system calls list. http://man7.org/linux/man-pages/man2/syscalls.2.html. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=MAN+page.+%7Bn.+d.%7D.+Linux+system+calls+list.+http%3A%2F%2Fman7.org%2Flinux%2Fman-pages%2Fman2%2Fsyscalls.2.html.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00038"><span>Rumpkernel.org {n. d.}. Rump Kernels. http://rumpkernel.org/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Rumpkernel.org+%7Bn.+d.%7D.+Rump+Kernels.+http%3A%2F%2Frumpkernel.org%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00039"><span>Sandvine. {n. d.}. Internet traffic encryption. https://www.sandvine.com/trends/encryption.html. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Sandvine.+%7Bn.+d.%7D.+Internet+traffic+encryption.+https%3A%2F%2Fwww.sandvine.com%2Ftrends%2Fencryption.html.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00040"><span>Mahadev Satyanarayanan, Paramvir Bahl, Ramón Caceres, and Nigel Davies. 2009. The Case for VM-Based Cloudlets in Mobile Computing. IEEE Pervasive Computing 8, 4 (Oct. 2009), 14--23.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Mahadev+Satyanarayanan%2C+Paramvir+Bahl%2C+Ram%C3%B3n+Caceres%2C+and+Nigel+Davies.+2009.+The+Case+for+VM-Based+Cloudlets+in+Mobile+Computing.+IEEE+Pervasive+Computing+8%2C+4+%28Oct.+2009%29%2C+14%2D%2D23.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1109/MPRV.2009.82" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00041"><span>Justine Sherry, Shaddi Hasan, Colin Scott, Arvind Krishnamurthy, Sylvia Ratnasamy, and Vyas Sekar. 2012. Making Middleboxes Someone Else's Problem: Network Processing As a Cloud Service. In Proceedings of the ACM SIGCOMM 2012 Conference on Computer Communication (SIGCOMM '12). ACM, New York, NY, USA, 13--24.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Justine+Sherry%2C+Shaddi+Hasan%2C+Colin+Scott%2C+Arvind+Krishnamurthy%2C+Sylvia+Ratnasamy%2C+and+Vyas+Sekar.+2012.+Making+Middleboxes+Someone+Else%27s+Problem%3A+Network+Processing+As+a+Cloud+Service.+In+Proceedings+of+the+ACM+SIGCOMM+2012+Conference+on+Computer+Communication+%28SIGCOMM+%2712%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+13%2D%2D24.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/2342356.2342359" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00042"><span>Stephen Soltesz, Herbert Pötzl, Marc E. Fiuczynski, Andy Bavier, and Larry Peterson. 2007. Container-based Operating System Virtualization: A Scalable, High-performance Alternative to Hypervisors. SIGOPS Oper. Syst. Rev. 41, 3 (March 2007), 275--287.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Stephen+Soltesz%2C+Herbert+P%C3%B6tzl%2C+Marc+E.+Fiuczynski%2C+Andy+Bavier%2C+and+Larry+Peterson.+2007.+Container-based+Operating+System+Virtualization%3A+A+Scalable%2C+High-performance+Alternative+to+Hypervisors.+SIGOPS+Oper.+Syst.+Rev.+41%2C+3+%28March+2007%29%2C+275%2D%2D287.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/1272998.1273025" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00043"><span>S. Stabellini. {n. d.}. Xen on ARM. http//:www.slideshare.net/xen_com_mgr/alsf13-stabellini. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=S.+Stabellini.+%7Bn.+d.%7D.+Xen+on+ARM.+http%2F%2F%3Awww.slideshare.net%2Fxen_com_mgr%2Falsf13-stabellini.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00044"><span>Udo Steinberg and Bernhard Kauer. 2010. NOVA: A Microhypervisorbased Secure Virtualization Architecture. In Proceedings of the 5th European Conference on Computer Systems (EuroSys '10). ACM, New York, NY, USA, 209--222.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Udo+Steinberg+and+Bernhard+Kauer.+2010.+NOVA%3A+A+Microhypervisorbased+Secure+Virtualization+Architecture.+In+Proceedings+of+the+5th+European+Conference+on+Computer+Systems+%28EuroSys+%2710%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+209%2D%2D222.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/1755913.1755935" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00045"><span>A. van de Ven. {n. d.}. An introduction to Clear Containers. https://lwn.net/Articles/644675/. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=A.+van+de+Ven.+%7Bn.+d.%7D.+An+introduction+to+Clear+Containers.+https%3A%2F%2Flwn.net%2FArticles%2F644675%2F.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00046"><span>Akshat Verma, Gargi Dasgupta, Tapan Kumar Nayak, Pradipta De, and Ravi Kothari. 2009. Server Workload Analysis for Power Minimization Using Consolidation. In Proceedings of the 2009 USENIX Annual Technical Conference (USENIX ATC '09). USENIX Association, Berkeley, CA, USA, 28--28. http://dl.acm.org/citation.cfm?id=1855807.1855835 <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Akshat+Verma%2C+Gargi+Dasgupta%2C+Tapan+Kumar+Nayak%2C+Pradipta+De%2C+and+Ravi+Kothari.+2009.+Server+Workload+Analysis+for+Power+Minimization+Using+Consolidation.+In+Proceedings+of+the+2009+USENIX+Annual+Technical+Conference+%28USENIX+ATC+%2709%29.+USENIX+Association%2C+Berkeley%2C+CA%2C+USA%2C+28%2D%2D28.+http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1855807.1855835+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/1855807.1855835" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00047"><span>VMWare. {n. d.}. vSphere ESXi Bare-Metal Hypervisor. http//:www.vmware.com/products/esxi-and-esx.html. ({n. d.}).<span><a href="http://scholar.google.com/scholar?hl=en&amp;q=VMWare.+%7Bn.+d.%7D.+vSphere+ESXi+Bare-Metal+Hypervisor.+http%2F%2F%3Awww.vmware.com%2Fproducts%2Fesxi-and-esx.html.+%28%7Bn.+d.%7D%29." target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span></span></li><li id="ref-00048"><span>Michael Vrable, Justin Ma, Jay Chen, David Moore, Erik Vandekieft, Alex C. Snoeren, Geoffrey M. Voelker, and Stefan Savage. 2005. Scalability, Fidelity, and Containment in the Potemkin Virtual Honey-farm. SIGOPS Oper. Syst. Rev. 39, 5 (Oct. 2005), 148--162.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Michael+Vrable%2C+Justin+Ma%2C+Jay+Chen%2C+David+Moore%2C+Erik+Vandekieft%2C+Alex+C.+Snoeren%2C+Geoffrey+M.+Voelker%2C+and+Stefan+Savage.+2005.+Scalability%2C+Fidelity%2C+and+Containment+in+the+Potemkin+Virtual+Honey-farm.+SIGOPS+Oper.+Syst.+Rev.+39%2C+5+%28Oct.+2005%29%2C+148%2D%2D162.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/1095809.1095825" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00049"><span>Andrew Whitaker, Marianne Shaw, and Steven D. Gribble. 2002. Scale and Performance in the Denali Isolation Kernel. SIGOPS Oper. Syst. Rev. 36, SI (Dec. 2002), 195--209.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Andrew+Whitaker%2C+Marianne+Shaw%2C+and+Steven+D.+Gribble.+2002.+Scale+and+Performance+in+the+Denali+Isolation+Kernel.+SIGOPS+Oper.+Syst.+Rev.+36%2C+SI+%28Dec.+2002%29%2C+195%2D%2D209.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/844128.844147" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00050"><span>Dan Williams and Ricardo Koller. 2016. Unikernel Monitors: Extending Minimalism Outside of the Box. In 8th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud '16). USENIX Association, Denver, CO. https://www.usenix.org/conference/hotcloud16/workshop-program/presentation/williams <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Dan+Williams+and+Ricardo+Koller.+2016.+Unikernel+Monitors%3A+Extending+Minimalism+Outside+of+the+Box.+In+8th+USENIX+Workshop+on+Hot+Topics+in+Cloud+Computing+%28HotCloud+%2716%29.+USENIX+Association%2C+Denver%2C+CO.+https%3A%2F%2Fwww.usenix.org%2Fconference%2Fhotcloud16%2Fworkshop-program%2Fpresentation%2Fwilliams+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.5555/3027041.3027053" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li><li id="ref-00051"><span>Wei Zhang, Jinho Hwang, Shriram Rajagopalan, K.K. Ramakrishnan, and Timothy Wood. 2016. Flurries: Countless Fine-Grained NFs for Flexible Per-Flow Customization. In Proceedings of the 12th International on Conference on Emerging Networking EXperiments and Technologies (CoNEXT '16). ACM, New York, NY, USA, 3--17.  <span></span><span><a href="http://scholar.google.com/scholar?hl=en&amp;q=Wei+Zhang%2C+Jinho+Hwang%2C+Shriram+Rajagopalan%2C+K.K.+Ramakrishnan%2C+and+Timothy+Wood.+2016.+Flurries%3A+Countless+Fine-Grained+NFs+for+Flexible+Per-Flow+Customization.+In+Proceedings+of+the+12th+International+on+Conference+on+Emerging+Networking+EXperiments+and+Technologies+%28CoNEXT+%2716%29.+ACM%2C+New+York%2C+NY%2C+USA%2C+3%2D%2D17.+" target="_blank"><span>Google Scholar</span><img src="https://dl.acm.org/specs/products/acm/images/googleScholar.svg" alt="Google Scholar"></a></span><span><a href="https://dl.acm.org/doi/10.1145/2999572.2999602" target="_blank"><span>Digital Library</span><img data-title="Digital Library" alt="Digital Library" src="https://dl.acm.org/templates/jsp/_ux3/_acm/images/DL_icon.svg"></a></span></span></li></ol></div>









    
    
        <div data-widget-def="UX3TagWidget" data-widget-id="2a75f978-170a-4843-8722-e878a1b77fbc">
        



        
        









    
    
        <p data-widget-def="graphQueryWidget" data-widget-id="4ca2ed65-717e-4e67-bbb5-6578b8c6acac">
        



        
        <h2 id="sec-terms">Index Terms</h2>

        </p>
    


<ol><li><p>My VM is Lighter (and Safer) than your Container</p><ol><li><ol><li><ol><li><ol><li><ol></ol></li><li><ol><li><ol></ol></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol>

        </div>
    











    
    
        
    





        
        <p> <h2 id="sec-recommendations">Recommendations</h2> </p>




        
        










    
    
        
    





        
        
</div><div><div id="pill-access"><div><h3>Login options</h3><div><p>Check if you have access through your login credentials or your institution to get full access on this article.</p><p><a href="https://dl.acm.org/action/showLogin?redirectUri=/doi/10.1145/3132747.3132763" title="Sign in">Sign in</a></p></div></div><div><h3>Full Access</h3></div></div><div id="pill-information"><ul role="tablist"><li role="presentation"><a id="pill-information__contentcon" href="#pill-information__content" aria-controls="pill-information__content" role="tab" data-toggle="tab" title="Information" aria-selected="true" data-simple-tab-id="" tabindex="0">Information</a></li><li role="presentation"><a id="pill-authors__contentcon" href="#pill-authors__content" aria-controls="pill-authors__content" role="tab" data-toggle="tab" title="Authors" aria-selected="false" data-simple-tab-id="" tabindex="-1">Contributors</a></li></ul><ul><li id="pill-information__content" aria-labelledby="pill-information__contentcon" role="tabpanel" aria-hidden="false" tabindex="0"><div><div><h3>Published in</h3><div>









    
    
        <div data-widget-def="UX3CoverImage" data-widget-id="7b8bd09e-8112-4266-b136-2f71ab2b109c"><p><img src="https://dl.acm.org/cms/asset/40e846f1-617d-4920-9978-476aa73fcd0f/3132747.cover.jpg" data-src="/cms/asset/40e846f1-617d-4920-9978-476aa73fcd0f/3132747.cover.jpg" alt="cover image ACM Conferences"></p><div><p>SOSP '17: Proceedings of the 26th Symposium on Operating Systems Principles</p><p>October 2017</p><p>677  pages</p></div></div>
    

<p>Copyright © 2017 Owner/Author</p><p>This work is licensed under a Creative Commons Attribution International 4.0 License.</p></div></div><div><h3>Publisher</h3><div><p>Association for Computing Machinery</p><p>New York, NY, United States</p></div></div>









    
    
        <div data-widget-def="contentItemHistory" data-widget-id="6eba30da-4023-4f09-bb08-f98cf09d5aa0">
        



        
            <h3>
                Publication History
            </h3>
        
        <div><ul><li><span>Published:</span> 14 October 2017</li></ul></div>

        </div>
    





        
        <!-- rightslink drop zone-->



        
        

<div><h3>Check for updates</h3><p><a data-target="crossmark"><img alt="Check for updates on crossmark" src="https://dl.acm.org/specs/products/acm/releasedAssets/images/CrossMarkIcon-d6fb3282a56d93dd889e4259d1cf4bd1.svg"></a></p></div>

<div><h3>Author Tags</h3></div><div><h3>Qualifiers</h3><ul><li>research-article</li><li>Research</li><li>Refereed limited</li></ul></div><p><h3>Conference</h3></p>









    
    
        <div data-widget-def="UX3AcceptanceRatesWidget" data-widget-id="daac1568-1d03-438e-a4c9-c9df280908b7"><h2 id="acceptance-rates" aria-expanded="true">Acceptance Rates</h2><div><p><span>Overall Acceptance Rate<span>131</span>of<span>716</span>submissions,<span>18%</span></span></p></div></div>
    











    
    
        <div data-widget-def="UX3UpcomingConferencesWidget" data-widget-id="452ce022-9919-435e-ab40-1386965a30bd">
<h3>Upcoming Conference</h3>
    
</div>
    

</div></li></ul></div><div id="pill-metric"><ul role="tablist"><li role="presentation"><a id="pill-bibliometrics__contentcon" href="#pill-bibliometrics__content" aria-controls="pill-bibliometrics__content" role="tab" data-toggle="tab" title="Bibliometrics" aria-selected="true" data-simple-tab-id="" tabindex="0">Bibliometrics</a></li><li role="presentation"><a id="pill-citations__contentcon" href="#pill-citations__content" data-ajaxurl="/action/ajaxShowCitedBy?widgetId=f69d88a8-b404-4aae-83a9-9acea4426d78&amp;ajax=true&amp;doi=10.1145%2F3132747.3132763&amp;pbContext=%3Btaxonomy%3Ataxonomy%3Aconference-collections%3Bissue%3Aissue%3Adoi%5C%3A10.1145%2F3132747%3Bwgroup%3Astring%3AACM+Publication+Websites%3BgroupTopic%3Atopic%3Aacm-pubtype%26gt%3Bproceeding%3Bctype%3Astring%3ABook+Content%3Barticle%3Aarticle%3Adoi%5C%3A10.1145%2F3132747.3132763%3Btopic%3Atopic%3Aconference-collections%26gt%3Bsosp%3Bpage%3Astring%3AArticle%2FChapter+View%3BsubPage%3Astring%3AAbstract%3Bcsubtype%3Astring%3AConference+Proceedings%3Bwebsite%3Awebsite%3Adl-site%3Bjournal%3Ajournal%3Aacmconferences%3BpageGroup%3Astring%3APublication+Pages&amp;widgetKey=ux3-publicationContent-widget_f69d88a8-b404-4aae-83a9-9acea4426d78_1498_en" data-component="pubAjaxContent" data-ajaxtarget="#pill-citations__content .citedBy" aria-controls="pill-citations__content" role="tab" data-toggle="tab" title="Citations" aria-selected="false" data-simple-tab-id="" tabindex="-1">Citations<span>182</span></a></li></ul><ul><li id="pill-bibliometrics__content" aria-labelledby="pill-bibliometrics__contentcon" role="tabpanel" aria-hidden="false" tabindex="0"><div><div><h3>Article Metrics</h3><div><ul><li><a href="#pill-citations__contentcon" data-tab="pill-citations__content" data-slide-target="#pill-metric" data-full-screen="false" data-ctrl-res="screen-xlg">View Citations</a></li><li></li></ul><ul><li><span>Downloads (Last 12 months)</span><span>1,905</span></li><li><span>Downloads (Last 6 weeks)</span><span>280</span></li></ul></div></div><div><h3>Other Metrics</h3></div></div></li></ul></div><div id="pill-formats"><div><h3>PDF Format</h3><div><p>View or Download as a PDF file.</p><p><a href="https://dl.acm.org/doi/pdf/10.1145/3132747.3132763" title="View or Download as a PDF file">PDF</a></p></div></div><div><h3>eReader</h3><div><p>View online with eReader.</p><p><a href="https://dl.acm.org/doi/epdf/10.1145/3132747.3132763" title="View online with eReader">eReader</a></p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Notifier Pattern for Applications That Use Postgres (176 pts)]]></title>
            <link>https://brandur.org/notifier</link>
            <guid>40352686</guid>
            <pubDate>Tue, 14 May 2024 07:56:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brandur.org/notifier">https://brandur.org/notifier</a>, See on <a href="https://news.ycombinator.com/item?id=40352686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                <p><a href="https://www.postgresql.org/docs/current/sql-listen.html">Listen/notify in Postgres</a> is an incredible feature that makes itself useful in all kinds of situations. I’ve been using it a long time, started taking it for granted long ago, and was somewhat shocked recently looking into MySQL and SQLite to learn that even in 2024, no equivalent exists.</p>

<p>In a basic sense, listen/notify is such a simple concept that it needs little explanation. Clients subscribe on topics and other clients can send on topics, passing a message to each subscribed client. The idea takes only three seconds to demonstrate using nothing more than a psql shell:</p>

<pre><code>=# LISTEN test_topic;
LISTEN
Time: 2.828 ms

=# SELECT pg_notify('test_topic', 'test_message');
 pg_notify
-----------

(1 row)

Time: 17.892 ms
Asynchronous notification "test_topic" with payload "test_message" received from server process with PID 98481.
</code></pre>

<p>But despite listen/notify’s relative simplicity, when it comes to applications built on top of Postgres, it’s common to use it less than optimally, eating through scarce Postgres connections and with little regard to failure cases.</p>

<hr>

<p>Here’s where the <strong>notifier pattern for Postgres</strong> comes in. It’s an extremely simple idea, but in my experience, one that’s rarely seen in practice. Let’s start with these axioms:</p>

<ul>
<li><p><code>LISTEN</code>s are affixed to specific connections. After listening, the original connection must still be available somewhere to successfully receive messages.</p></li>

<li><p>There may be many components within an application that’d like to listen on topics for completely orthogonal uses.</p></li>

<li><p>Despite optimizations over the years, connections in Postgres are still somewhat of a precious, limited resource, and should be conserved. We’d like to minimize the number of them required for listen/notify use.</p></li>

<li><p>A single connection can listen on any number of topics.</p></li>
</ul>

<p>With those stated, we can explain the role of the notifier. Its job is to <strong>hold a single Postgres connection per process, allow other components in the same program to use it to subscribe to any number of topics, wait for notifications, and distribute them to listening components as they’re received</strong>.</p>

<p>The “single Postgres connection per process” piece is key. Use of a notifier keeps the number of Postgres connections dedicated to use with listen/notify down to <strong>one per program</strong>, a major advantage compared to the naive version, which is <em>one connection per topic per program</em>. Especially for languages like Go that make a in-process concurrency easy and cheap, the notifier reduces listen/notify connection overhead to practically nil.</p>

<p><img src="https://brandur.org/assets/images/notifier/notifier.svg" alt="Notifier distributing notifications to program components"></p>

<h2 id="implementation"><a href="#implementation">A few implementation details</a></h2>

<p>From a conceptual standpoint, the notifier’s not difficult to understand, and with only this high level description, most readers would be able to implement it themselves. I’m not going to go through an implementation in full detail, but let’s look at a few important aspects of one. (For a complete reference, you can take a look <a href="https://github.com/riverqueue/river/tree/master/internal/notifier">at River’s notifier</a>, which is quite well vetted.)</p>

<p>Here’s a listen function to establish a new subscription:</p>

<pre><code>// Listen returns a subscription that lets a caller receive values from a
// notification channel.
func (l *Notifier) Listen(channel string) *Subscription {
    l.mu.Lock()
    defer l.mu.Unlock()

    existingSubs := l.subscriptions[channel]

    sub := &amp;Subscription{
        channel:        channel,
        listenChan:     make(chan string, 100),
        notifyListener: l,
    }
    l.subscriptions[channel] = append(existingSubs, sub)

    if len(existingSubs) &gt; 0 {
        // If there's already another subscription for this channel, reuse its
        // established channel. It may already be closed (to indicate that the
        // connection is established), but that's okay.
        sub.establishedChan = existingSubs[0].establishedChan
        sub.establishedChanClose = func() {} // no op since not channel owner

        return sub
    }

    // The notifier will close this channel after it's successfully established
    // `LISTEN` for the given channel. Gives subscribers a way to confirm a
    // listen before moving on, which is especially useful in tests.
    sub.establishedChan = make(chan struct{})
    sub.establishedChanClose = sync.OnceFunc(func() { close(sub.establishedChan) })

    l.channelChanges = append(l.channelChanges,
        channelChange{channel, sub.establishedChanClose, channelChangeOperationListen})

    // Cancel out of blocking on WaitForNotification so changes can be processed
    // immediately.
    l.waitForNotificationCancel() 

    return sub
}
</code></pre>

<p>A few key details to notice:</p>

<ul>
<li><p>Subscriptions use a <strong>buffered channel</strong> like <code>make(chan string, 100)</code> and <strong>non-blocking sends</strong> (using <code>select</code> with <code>default</code>). A notifier may receive a high volume of notifications, and if it were to block on every component successfully receiving and processing each one, it could easily fall behind. Instead, a received notification is sent into the channel using a non-blocking send. The non-blocking send means that the send operation will never block: instead the notification is discarded if the channel is full. The buffer provides a tunable amount of slack to make sure this won’t happen too easily. It’s each component’s job to make sure its processing its inbox in a timely manner. This is important because even in the event of one component falling behind, the system as a whole stays healthy.</p></li>

<li><p>Multiple components may want to subscribe to the same topic. Since only one connection is in use, the notifier only needs to issue one <code>LISTEN</code> per topic. Internally, it organizes subscriptions by topic, and if it notices that a topic already exists, a new subscription is added without issuing <code>LISTEN</code>.</p></li>

<li><p>Subscriptions provide an <strong>established channel</strong> that’s closed when a <code>LISTEN</code> has been successfully issued and the notifier is up and listening. This isn’t strictly necessary for most production uses, but it’s invaluable for use in testing. If a test case issues <code>pg_notify</code> before the notifier has started listening, that notification is lost – a problem that can lead to tortuous test intermittency <sup id="footnote-1-source"><a href="#footnote-1">1</a></sup>. Instead, a test case tells the notifier to listen, <em>waits for the listen to succeed</em>, then moves on to send <code>pg_notify</code>.</p></li>
</ul>

<pre><code>// EstablishedC is a channel that's closed after the notifier's successfully
// established a connection. This is especially useful in test cases, where it
// can be used to wait for confirmation that not only that the listener is
// started, but that it's successfully established started listening on a
// channel before continuing. For a new subscription on an already established
// channel, EstablishedC is already closed, so it's always safe to wait on it.
//
// There's no full guarantee that the notifier can ever successfully establish a
// listen, so callers will usually want to `select` on it combined with a
// context done, a stop channel, and/or a timeout.
//
// The channel is always closed as a notifier is stopping.
func (s *Subscription) EstablishedC() &lt;-chan struct{} { return s.establishedChan }
</code></pre>

<h3 id="interruptible-receives"><a href="#interruptible-receives">Interruptible receives</a></h3>

<p>There’s no standard SQL for waiting for a notification. Typically, it’s accomplished using a special driver-level function like <a href="https://pkg.go.dev/github.com/jackc/pgx/v5#Conn.WaitForNotification">Pgx’s <code>WaitForNotification</code></a>.</p>

<p>These commonly block until receiving a notification, which can be problem since we’re only using a single connection. What if the notifier is in a blocking receive loop, but another component wants to add a new subscription that requires <code>LISTEN</code> be issued?</p>

<p>You’ll want to handle this case by making sure that the wait loop is interruptible. Here’s one way to accomplish that in Go:</p>

<pre><code>func (l *Notifier) runOnce(ctx context.Context) error {
    if err := l.processChannelChanges(ctx); err != nil {
        return err
    }

    // WaitForNotification is a blocking function, but since we want to wake
    // occasionally to process new `LISTEN`/`UNLISTEN` operations, we put a
    // context deadline on the listen, and as it expires don't treat it as an
    // error unless it
    notification, err := func() (*pgconn.Notification, error) {
        const listenTimeout = 30 * time.Second

        ctx, cancel := context.WithTimeout(ctx, listenTimeout)
        defer cancel()

        // Provides a way for the blocking wait to be cancelled in case a new
        // subscription change comes in.
        l.mu.Lock()
        l.waitForNotificationCancel = cancel
        l.mu.Unlock()

        notification, err := l.conn.WaitForNotification(ctx)
        if err != nil {
            return nil, xerrors.Errorf("error waiting for notification: %w", err)
        }

        return notification, nil
    }()
    if err != nil {
        // If the error was a cancellation or the deadline being exceeded but
        // there's no error in the parent context, return no error.
        if (errors.Is(err, context.Canceled) ||
            errors.Is(err, context.DeadlineExceeded)) &amp;&amp; ctx.Err() == nil {
            return nil
        }

        return err
    }

    l.mu.RLock()
    defer l.mu.RUnlock()

    subs := l.subscriptions[notification.Channel]

    if len(subs) &lt; 1 {
        return nil
    }

    for _, sub := range subs {
        sub.listenChan &lt;- notification.Payload
    }

    return nil
}
</code></pre>

<p>The inner closure calls into <code>WaitForNotification</code>, but has a default context timeout of 30 seconds that automatically cycles the function periodically. It also stores the special context cancellation function <code>l.waitForNotificationCancel</code>.</p>

<p>When <code>Listen</code> is invoked and a new subscription needs to be added, <code>l.waitForNotificationCancel</code> is called. The wait is cancelled immediately, new subscriptions are processed, and the closure is reentered to wait anew.</p>

<h3 id="let-it-crash"><a href="#let-it-crash">Let it crash</a></h3>

<p>Given there’s now a single master connection that’s handling all notifications for a program, it’s fairly critical that its health be monitored, and the notifier reacts appropriately. If not, all uses of listen/notify would degrade simultaneously.</p>

<p>The obvious way to react would be to close the connection, use a connection pool to procure a new connection, reissue <code>LISTEN</code>s for each active subscription, then reenter the wait loop.</p>

<p>It can be a little tricky sometimes to guarantee that state is reset cleanly, so another possibility is to adhere to the “let it crash” school of thought. If the connection becomes irreconcilably unhealthy, stop the program, and have it come back to a healthy state by virtue of its normal start up.</p>

<pre><code>// If the notifier gets unhealthy, restart the worker. This will generally
// never happen as the notifier has a built-in retry loop that try its best
// to keep established before giving up.
notifier.AddUnhealthyCallback(closeShutdown)
</code></pre>

<p>We’ve found this sort of edge to be so rare (I’ve only seen it happen once in a year+ of use) that letting the program crash when it does happen hasn’t produced any undue disruption.</p>

<h2 id="pgbouncer"><a href="#pgbouncer">PgBouncer</a></h2>

<p>Using <a href="https://www.pgbouncer.org/features.html">PgBouncer</a>, <code>LISTEN</code> is only supported using session pooling (as opposed to transaction pooling) because notifications are only sent to the original session that issued a <code>LISTEN</code> for them.</p>

<p>Use of a notifier requires an app to dedicate a single connection per program for listen/notify, but every other part of the application is free to use PgBouncer in transaction pooling or statement pooling mode, thereby maximizing the efficiency of connection use.</p>



            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using ARG in a Dockerfile – beware the gotcha (126 pts)]]></title>
            <link>https://qmacro.org/blog/posts/2024/05/13/using-arg-in-a-dockerfile-beware-the-gotcha/</link>
            <guid>40352426</guid>
            <pubDate>Tue, 14 May 2024 07:05:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qmacro.org/blog/posts/2024/05/13/using-arg-in-a-dockerfile-beware-the-gotcha/">https://qmacro.org/blog/posts/2024/05/13/using-arg-in-a-dockerfile-beware-the-gotcha/</a>, See on <a href="https://news.ycombinator.com/item?id=40352426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today I learned about the subtleties of <a href="https://docs.docker.com/build/guide/build-args/">build arguments</a> in Dockerfile definitions, specifically how the <code>ARG</code> instruction relates to - and is affected by - the <code>FROM</code> instruction. It's not entirely like a constant or a variable, in the way that I had thought.</p><h2>The problem with empty ARG values</h2><p>I spent more than a coffee's worth of time trying to understand why my custom builds of a CAP Node.js container image weren't of the CAP version I was specifying, either implicitly with the default value I'd declared in the <code>ARG</code> instruction in the Dockerfile, or even explicitly with the <code>--build-arg</code> option on the command line.</p><p>To illustrate the problem, here's a vastly simplified version of the Dockerfile I was building with:</p><pre><code><span># syntax=docker/dockerfile:1</span><p><span><span>ARG</span> DEBVER=<span>"10"</span></span><br><span><span>ARG</span> CAPVER=<span>"7.8"</span></span><br><span><span>FROM</span> debian:<span>${DEBVER}</span></span></p><p><span><span>RUN</span> printf <span>"DEB=${DEBVER}\nCAP=${CAPVER}\n"</span> &gt; /tmp/log</span></p></code></pre><p>The first variable declared with <code>ARG</code> here is <code>DEBVER</code> and represents a fairly common use case of allowing for different versions of a base image, illustrated here in being able to start from different versions of the Debian distribution, where the default version is to be 10.</p><p>The second variable <code>CAPVER</code> was something similar that I was using later in the build instructions (i.e. further on in the Dockerfile), to specify the particular version of CAP that I wanted to install. The actual instruction in my Dockerfile looked like this: <code>RUN npm install -g @sap/cds-dk@{CAPVER}</code>.</p><p>After building the image based on this simplified Dockerfile, without specifying any values explicitly with <code>--build-arg</code>, like this:</p><pre><code><span>;</span> <span>docker</span> build <span>-t</span> argtest <span>.</span></code></pre><p>I could successfully confirm that the version of Debian in containers created from this image was 10:</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>grep</span> VERSION_ID /etc/os-release<br><span>VERSION_ID</span><span>=</span><span>"10"</span></code></pre><p>But what of the content of <code>/tmp/log</code>?</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>cat</span> /tmp/log<br><span>DEB</span><span>=</span><br><span>CAP</span><span>=</span></code></pre><p>Hmm.</p><p>How about when I use <code>--build-arg</code> options?</p><pre><code><span>;</span> <span>docker</span> build <span>\</span><br>  --build-arg<span>=</span><span>"DEBVER=11"</span> <span>\</span><br>  --build-arg<span>=</span><span>"CAPVER=7.9"</span> <span>\</span><br>  <span>-t</span> argtest <span>.</span></code></pre><p>The build completes successfully, and I can see that containers now are Debian 11 based:</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>grep</span> VERSION_ID /etc/os-release<br><span>VERSION_ID</span><span>=</span><span>"11"</span></code></pre><p>but the problem with the empty values for <code>DEBVER</code> and <code>CAPVER</code> in <code>/tmp/log</code> remains.</p><p>Not only is the value for <code>CAPVER</code> empty when we reference it in the <code>RUN</code> instruction, but also, and this is the most mysterious thing thus far, while <code>DEBVER</code> was certainly recognised and set to 11 for the Debian distribution in the <code>FROM</code> instruction, it's empty when we reference it later in the <code>RUN</code> instruction.</p><h2>The subtleties of how ARG relates to FROM</h2><p>The cause is the rather subtle relationship between <code>ARG</code> and <code>FROM</code>, the explanation for which is brief and a little hidden in the main <a href="https://docs.docker.com/reference/dockerfile/">Dockerfile reference</a>. I certainly missed it when I went straight to the <a href="https://docs.docker.com/reference/dockerfile/#arg">reference for <code>ARG</code></a>, as it's not mentioned, and only explained at the end of the <a href="https://docs.docker.com/reference/dockerfile/#from">reference for <code>FROM</code></a> which is earlier on the page.</p><p>The key section is here: <a href="https://docs.docker.com/reference/dockerfile/#understand-how-arg-and-from-interact">Understand how ARG and FROM react</a>, and includes this line:</p><blockquote><p>"<em>An <code>ARG</code> declared before a <code>FROM</code> is outside of a build stage, so it can't be used in any instruction after a <code>FROM</code>.</em>"</p></blockquote><p>In other words, variables declared with <code>ARG</code> look like variables in, say, a shell script, variables which are also often declared at the start, and then used throughout the script.</p><p>But they're not.</p><h2>The solution</h2><p>What must be done to the Dockerfile above is to modify it so it looks like this:</p><pre><code><span># syntax=docker/dockerfile:1</span><p><span><span>ARG</span> DEBVER=<span>"10"</span></span><br><span><span>FROM</span> debian:<span>${DEBVER}</span></span><br><span><span>ARG</span> DEBVER</span><br><span><span>ARG</span> CAPVER=<span>"7.8"</span></span></p><p><span><span>RUN</span> printf <span>"DEB=${DEBVER}\nCAP=${CAPVER}\n"</span> &gt; /tmp/log</span></p></code></pre><p>Moving the <code>ARG</code> instruction for <code>CAPVER</code> so that it comes after the <code>FROM</code> instruction gives it life and validity.</p><p>And the <code>ARG</code> instruction for <code>DEBVER</code> must stay where it is (as it's referenced in the <code>FROM</code> instruction details of course) but if it needs to be referred to after the <code>FROM</code> instruction it must be referenced again - hence the <code>ARG DEBVER</code> line.</p><p>From a container image built using this new version of the Dockerfile, with no <code>--build-arg</code> options specified, we can see that the values for <code>DEBVER</code> and <code>CAPVER</code> are available after the <code>FROM</code> instruction:</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>cat</span> /tmp/log<br><span>DEB</span><span>=</span><span>10</span><br><span>CAP</span><span>=</span><span>7.8</span></code></pre><p>And this works of course if we set values for build arguments on the command line too, testing a container built using the same <code>docker build --build-arg ...</code> invocation as before:</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>cat</span> /tmp/log<br><span>DEB</span><span>=</span><span>11</span><br><span>CAP</span><span>=</span><span>7.9</span></code></pre><p>and</p><pre><code><span>;</span> <span>docker</span> run <span>--rm</span> argtest <span>grep</span> VERSION_ID /etc/os-release<br><span>VERSION_ID</span><span>=</span><span>"11"</span></code></pre><h2>Wrapping up</h2><p>Perhaps I should have read the entire reference document for all the Dockerfile instructions first. Then I would have at least read about this relationship, and I may also have remembered it too. But for those of you like me who jump directly to consult the reference documentation on the thing they're trying to use, perhaps this will help.</p><p>Happy building!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude is now available in Europe (142 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-europe</link>
            <guid>40352204</guid>
            <pubDate>Tue, 14 May 2024 06:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-europe">https://www.anthropic.com/news/claude-europe</a>, See on <a href="https://news.ycombinator.com/item?id=40352204">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><article><div><figure><img loading="eager" width="1778" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F791c1c121225ef3e3a368279926c12552ddb075c-1778x1000.jpg&amp;w=1920&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F791c1c121225ef3e3a368279926c12552ddb075c-1778x1000.jpg&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F791c1c121225ef3e3a368279926c12552ddb075c-1778x1000.jpg&amp;w=3840&amp;q=75"></figure><p>We’re excited to announce that <a href="https://www.anthropic.com/claude">Claude</a>, Anthropic’s trusted AI assistant, is now available for people and businesses across Europe to enhance their productivity and creativity. Starting today, they will be able to use:</p><ul><li><a href="http://claude.ai/">Claude.ai</a>: the web-based version of our next-generation AI assistant</li><li>The <a href="https://apps.apple.com/app/claude/id6473753684">Claude iOS app</a>: a free version of Claude that offers the same intuitive experience as mobile web</li><li>The <a href="https://www.anthropic.com/news/team-plan-and-ios">Claude Team plan</a>: the best way for every business to provide teams with secure access to Claude's state-of-the-art AI capabilities and the <a href="https://www.anthropic.com/news/claude-3-family">Claude 3 model family</a></li></ul><p>Today’s release follows the Europe launch of the Claude API earlier this year, which allows developers to integrate Anthropic’s state-of-the-art AI models into their own applications, websites, or services.</p><p>Claude has strong levels of comprehension and fluency in French, German, Spanish, Italian, and other European languages, allowing users to converse with Claude in multiple languages. Claude’s intuitive, user-friendly interface makes it easy for anyone to seamlessly integrate our advanced AI models into their workflows.</p><p>Both Claude.ai and the Claude iOS app are available for free. The Claude app is available for download in the Apple App Store. For €18 + VAT per month (or local currency equivalent), users can subscribe to Claude Pro and unlock all models, including Claude 3 Opus, one of the most advanced models on the market. The Team plan is €28 + VAT per user per month (or local currency equivalent), with a minimum of 5 seats.</p><p>At Anthropic, we're dedicated to creating AI systems that put people first. We look forward to bringing the unique capabilities of the Claude 3 model family to more people throughout Europe.</p><p><em>Read this post in <a href="https://cdn.sanity.io/files/4zrzovbb/website/bfbafc8f692634001f9f5fb7d05d12a4ef71ad24.pdf">French</a>, <a href="https://cdn.sanity.io/files/4zrzovbb/website/397335b3ce79aff658ba1a35f73c26cce0ea5490.pdf">German</a>, <a href="https://cdn.sanity.io/files/4zrzovbb/website/c2e15095e05250d9feecef8a1b9e9fd319acd7c7.pdf">Italian</a>, or <a href="https://cdn.sanity.io/files/4zrzovbb/website/5686521fb5eaa65ae0a3e79c7d7713760942e6d2.pdf">Spanish</a>.</em></p></div></article></div></div>]]></description>
        </item>
    </channel>
</rss>