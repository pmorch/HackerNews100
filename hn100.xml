<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 04 Jul 2024 03:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Origins of DS_store (2006) (186 pts)]]></title>
            <link>https://www.arno.org/on-the-origins-of-ds-store</link>
            <guid>40870357</guid>
            <pubDate>Wed, 03 Jul 2024 21:55:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.arno.org/on-the-origins-of-ds-store">https://www.arno.org/on-the-origins-of-ds-store</a>, See on <a href="https://news.ycombinator.com/item?id=40870357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article">


  <header>
    <h2>
      
      <span itemprop="section">Apple Lore</span>
      
      On the origins of DS_store
      
    </h2>
  </header>


  <section itemprop="articleBody">
    <p>If you are a Mac user, or if you have transferred files from Mac to Windows,
you’re probably familiar with <kbd>.DS_Store</kbd> files. But where does this
name come from?</p>

<p>Back in 1999 I was the technical lead for the Mac OS X Finder at Apple. At that
time the Finder code base was some 8 years old and had reached the end of its
useful life. Making any changes to it require huge engineering effort, and any
changes usually broke two or three seemingly unrelated features. For Mac OS X we
decided to rewrite the Finder from scratch.</p>

<p>Part of the work involved separating its user interface and its core
functionality, the back-end. The back-end of the Finder enumerates files, watch
for changes in the file system, deals with metadata, including icon locations
and folder settings. Internally, those two components were known as Finder_FE
and Finder_BE (Frontend and Backend).</p>

<p>However, we soon started realizing that the Finder backend would be useful
outside of the Finder. Therefore, a plan was hatched to someday make it
available as a public API. Since I had previously been responsible for naming
Icon Services and Navigation Services, we decided to go with Desktop Services
(at the time, we were also considering renaming the Finder to “Desktop”).
Hence the name of the <kbd>.DS_Store</kbd>, for “Desktop Services Store”. We
added a “.” in front of it so that it would be considered as an invisible file
by Unix OS, including Mac OS.</p>

<p>Personally, I don’t think it’s a great name and I wish we had gone with
something a bit more descriptive, but it’s too late for that :-)</p>

<p>There is also an unfortunate bug that is not fixed to this day that result in an
excessive creation of <kbd>.DS_Store</kbd> file. Those files should only be
created if the user actually makes adjustments to the view settings or set a
manual location for icons in a folder. That’s unfortunately not what happens and
visiting a folder pretty much guarantees that a <kbd>.DS_Store</kbd> file will
get created</p>

<p>Incidentally, Finder_BE aka Desktop Services did end up being used by more than
just the Finder: Navigation Services (the Open/Save dialog) now also make use of
it, although it didn’t in the initial release of Mac OS. However, the Desktop
Services API has still not been fully released.</p>

  </section>



  <hr>
  <section>
    <p itemprop="datePublished" datetime="2006-10-01 00:00:00 -0700">Published Oct 1, 2006</p>
  </section>

  <section>
    
    <p>By 
    </p>
    <p>Published by <span itemprop="publisher" itemscope="" itemtype="http://schema.org/Publisher">
      <span itemprop="name">Arno Gourdol</span></span>
    </p>
    <img itemprop="image" src="">
  </section>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Joy of Reading Books You Don't Understand (105 pts)]]></title>
            <link>https://reactormag.com/the-joy-of-reading-books-you-dont-entirely-understand/</link>
            <guid>40870280</guid>
            <pubDate>Wed, 03 Jul 2024 21:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reactormag.com/the-joy-of-reading-books-you-dont-entirely-understand/">https://reactormag.com/the-joy-of-reading-books-you-dont-entirely-understand/</a>, See on <a href="https://news.ycombinator.com/item?id=40870280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>At present, I have an alarming number of tabs open. I’m absolutely not going to tell you how many, or how many are open on my phone. There are 15 pages of notes in my now-finished notebook that are about the same subject that led to all these tabs. A lot of these tabs concern the history of a country I don’t live in. Some are mythology. It’s a real cornucopia of delights, and it’s also very distracting. There are so many rich and fascinating rabbit holes a person might fall down.&nbsp;</p>
<p>This is all because I’ve been reading a book that I don’t entirely understand, and frankly, it’s wonderful.</p>
<p>A very long time ago, I read <a href="https://bookshop.org/p/books/quicksilver-volume-one-of-the-baroque-cycle-neal-stephenson/1517020?ean=9780060593087" target="_blank" rel="noreferrer noopener" title=" opens in a new window">Neal Stephenson’s Baroque Cycle</a>, one at a time, as the books came out. I am—I cannot stress this enough—<em>very</em> bad at remembering historical details. Part of this I blame on high school. Part of this is just the way my brain works. I can tell you the basic plot of most books I’ve ever read, but I cannot tell you the names and dates involved with specific moments in the world’s past. While I read Stephenson’s sprawling series, I spent a lot of time referencing the encyclopedia, because I did not know, necessarily, which characters were based on real humans and which were entirely made up. It was really quite educational. (I also learned about kidney stones, which was less pleasant. But still kind of interesting.)</p>
<p>I could have just let it go, let the books roll me along in blissful ignorance. I understood the story structure and the characters just fine. I knew what he was getting at. It was just all that history that kept throwing me: Who? When? <em>Why</em>? But what happened, as I looked up names and places and dates and wars, is that I began to take almost as much joy in that process as I did in reading the books. The two things remain twined in my head, all these years later, and maybe some part of me is always looking for something else like that—something that will offer me a book, a story to read and inhabit, but also an adventure in not-knowing.</p>
<p>In recent years, I feel like it has been less common to find books to challenge me, and by me I mean their readers, and by “books” what I really mean is “publishing,” which can feel very focused on the sure thing, the brand name, the splashy debut that somehow speaks to millions and millions of people. Still, there are challenging, mystifying, weird-ass books being published all the time. To be fair, a weird-ass, mystifying, challenging book isn’t inherently a good book, or a book you want to spend your finite reading time on. We only get to read so many books in a month, or a year, or a life. There is value in escapism and familiarity and comfort.</p>
<p>But I still want to advocate for <em>sometimes</em>, at least sometimes, going out on a limb, out on a genre vacation, or just out into the wilds of a tale you don’t feel like you entirely understand.&nbsp;</p>
<p>It can feel, too often, like these books bobble and vanish in the big world of Book Discourse. I have searched weird corners of the internet for people talking about <a href="https://bookshop.org/p/books/the-library-of-broken-worlds/18383203?ean=9781338290622" target="_blank" rel="noreferrer noopener" title=" opens in a new window">Alaya Dawn Johnson’s <em>The Library of Broken Worlds</em></a>, which requires patience, and a willingness to trust her incredible, vivid, dizzying worldbuilding. I think sometimes about how many books there are that American, English-language readers will never get to see, simply because they were too <em>something</em> to get translated here. I think about how lucky we are that Riverhead keeps publishing the great and unmatched <a href="https://bookshop.org/contributors/helen-oyeyemi-7311fcee-faa8-4cb9-a4b1-f8ae71227fae" target="_blank" rel="noreferrer noopener" title=" opens in a new window">Helen Oyeyemi</a>, whose books are works of art that I can’t ever quite fit my head around—which is as it should be, for there is always something else to find in them. I think about how lucky we are that we get to read trippy and furious books like <a href="https://bookshop.org/p/books/jonathan-abernathy-you-are-kind-molly-mcghee/19674051?ean=9781662602115" target="_blank" rel="noreferrer noopener" title=" opens in a new window">Molly McGhee’s <em>Jonathan Abernathy You Are Kind</em></a>, which is both deceptively easy to read and hard to fully fathom. Or perhaps what’s “hard” about it is that it’s hard to accept exactly how clearly it speaks to this moment in time.&nbsp;</p>
<p>McGhee’s Twitter bio used to say something about how literary and genre fiction ought to touch tongues more often, and I think about that, too: About the science fiction and fantasy that appears in the other section of bookstore, about all the SFF writers overlooked by the mainstream even as their prose is crystalline, elegant, looping, rich, just stunning. We build so many walls for ourselves about what we do and don’t do, read and don’t read. Some of it is simply practical: We’re back to the question of time, and how much of it we do or don’t have. When someone says “I am only reading X kinds of books,” they are drawing boundaries around their time as much as their taste.</p>
<p>I want, though, for us to have the time, the space, the mental bandwidth to welcome uncertainty, to crank up our curiosity and give the weird or confusing or just slightly unexpected books a chance. And I want it to be totally okay and acceptable and normal to say “I don’t entirely understand what I just read, but I loved it.”</p>
<p>When I started writing reviews, in the mid-2000s, there was a real pressure to be authoritative. To speak with your whole chest, even if you didn’t really know what you were on about. I’ve always been a little suspicious of this tendency—of an unwillingness to be transparent about the fact that every reader (and writer!) is coming from their own specific background and none of us knows everything about everything. Subjectivity is inevitable.&nbsp;</p>
<p>Maybe, just maybe, this requirement that we all pretend to know what we’re talking about at all times is a limiting thing. On today’s bookternet, a lot of us can go off about tropes and western story structure and the hero’s journey and probably also several other kinds of story structure we read about once or twice and maybe even there’s some of that Save the Cat guy baked in there, too. So it’s easy, in a way, to keep reading books from this sort of narrative tradition, because we know a bit of what we’re talking about. I can pick up a retelling of a Greek myth and know the basic beats because I grew up steeped in those stories.</p>
<p>But there are so many other stories, and so many other ways to tell them.</p>
<p>What set me off on this path of delirious not-knowing is that I read <a href="https://bookshop.org/p/books/rakesfall-vajra-chandrasekera/20464409?ean=9781250847683" target="_blank" rel="noreferrer noopener" title=" opens in a new window">Vajra Chandrasekera’s <em>Rakesfall</em></a>. I read it on a plane, and I felt, later, like I dreamed it. Whole scenes existed in my mind stripped of any context, the way you might remember dreams.</p>
<p>And then I read it again, with a pen and a notebook and my phone and laptop at hand. I opened a million tabs, and revisited the general outline of the <em>Ramayana</em>, which I know as a Penguin Classic I read in book group some years back, not at all the way I know the stories and myths I met in textbooks as a child. I put off drafting a review of the book in favor of reading every interview with the author I could find. I put pieces together and, outside of my airplane dream-state, began to see where the story restarted, where it looped, where it ate its own tail and then birthed itself again.</p>
<p>There is so much I don’t entirely understand in this book, because I <em>can’t</em>; I’m a white American who does not have the cultural context to fully understand all the things that this story encompasses. And what I’m saying is: Good. Good, let me bask in that. Good, let me <em>admit</em> to that.</p>
<p>There is real joy to be found in not immediately understanding exactly what a book is doing. Joy in seeing that something outside of the narrative structure we’re familiar with is at play; joy in discovering a different sense of vastness and fluidity. Joy in waiting, patiently, with rich anticipation, for the seemingly disparate pieces of a narrative to mesh, to become something huge and beautiful. Joy in realizing, several chapters into a book, that you could not possibly say what it was “about” until reading to the end, and maybe not even then.<svg width="31" height="13" viewBox="0 0 31 13" fill="none" xmlns="http://www.w3.org/2000/svg" aria-labelledby="icon-paragraph-end">
<title id="icon-paragraph-end">icon-paragraph-end</title>
<path d="M15.0891 10.4122C15.138 10.2591 15.186 10.128 15.221 9.99444C15.256 9.86009 15.278 9.72248 15.3114 9.55963C15.1217 9.57836 14.9621 9.59546 14.8025 9.6093C13.871 9.69154 12.9387 9.73796 12.0039 9.68096C11.8313 9.67037 11.7222 9.7119 11.6261 9.86824C11.5463 9.9977 11.4177 10.1068 11.2906 10.1948C11.1498 10.2925 10.9853 10.2794 10.82 10.2241C10.7484 10.2004 10.6555 10.198 10.5847 10.2216C10.3722 10.2933 10.1645 10.3804 9.9569 10.4651C9.50336 10.6491 8.98712 10.4521 8.82427 10.1093C8.80799 10.0759 8.73389 10.0555 8.68667 10.0547C8.62234 10.0547 8.55801 10.0816 8.49369 10.093C8.2543 10.1361 8.06865 10.0457 7.9343 9.85195C7.77877 9.62722 7.73643 9.37398 7.77959 9.10772C7.8032 8.96523 7.8944 8.87811 8.03282 8.83169C8.20137 8.77551 8.20056 8.76492 8.16392 8.59393C8.14437 8.50355 8.12972 8.41154 8.12646 8.31953C8.11669 8.0093 8.22906 7.83993 8.5173 7.73653C8.86906 7.6095 9.22407 7.49144 9.57583 7.3636C9.63364 7.34243 9.69389 7.3009 9.72972 7.25205C9.82173 7.12665 9.94224 7.06884 10.0855 7.11525C10.3233 7.19261 10.4446 7.13072 10.5814 6.9011C10.7076 6.69021 10.6881 6.54283 10.5936 6.35963C10.5309 6.2383 10.4813 6.10884 10.4056 5.99647C10.3176 5.86782 10.2215 5.73754 10.1051 5.63657C9.65562 5.24736 9.19639 4.86955 8.73959 4.48848C8.67934 4.43799 8.61501 4.39239 8.55231 4.34435C8.56127 4.32888 8.56941 4.31423 8.57837 4.29876C8.64595 4.27107 8.71354 4.2442 8.7803 4.21652C10.3396 3.57407 11.8973 2.92756 13.4582 2.29163C14.2203 1.98058 14.9898 1.68338 15.8024 1.52704C16.2519 1.44073 16.7013 1.40165 17.1427 1.58567C17.1809 1.60195 17.2501 1.57264 17.2925 1.54577C17.9406 1.14272 18.601 0.75839 19.3208 0.500273C20.372 0.123274 21.4574 -0.0859885 22.577 0.0337065C23.4971 0.132231 24.3333 0.491316 25.0759 1.03686C25.4497 1.31127 25.7745 1.65325 26.1198 1.96755C26.2338 2.07096 26.347 2.17682 26.4512 2.29C26.6955 2.55707 27.013 2.63035 27.3444 2.5758C28.1522 2.44308 28.955 2.28104 29.7603 2.13203C29.8686 2.11168 29.9769 2.09295 30.0868 2.08236C30.1186 2.07911 30.1536 2.10679 30.1878 2.12063C30.1699 2.1532 30.1609 2.20124 30.1332 2.21671C30.042 2.26883 29.9468 2.31687 29.8474 2.35269C29.2221 2.57743 28.5943 2.79646 27.9681 3.02038C27.8232 3.07249 27.6807 3.13112 27.5382 3.18975C27.2768 3.29723 27.0961 3.48288 26.9853 3.74506C26.4276 5.05845 25.5384 6.09092 24.3341 6.85143C24.1257 6.98253 23.9034 7.09082 23.6892 7.21378C23.6469 7.2382 23.5915 7.27566 23.5818 7.31637C23.493 7.68686 23.2553 7.95393 22.9866 8.20146C22.6641 8.49948 22.2668 8.67129 21.8816 8.86671C20.946 9.34141 19.9356 9.55475 18.9137 9.73551C17.7607 9.93907 16.6085 10.1516 15.4564 10.3592C15.3407 10.3804 15.2243 10.3934 15.0883 10.4138L15.0891 10.4122ZM23.6819 1.54414C23.6078 1.53193 23.55 1.51646 23.4906 1.51239C22.5925 1.45132 21.7041 1.52134 20.8247 1.71269C19.8883 1.91626 18.9764 2.19636 18.0913 2.56359C18.0497 2.58069 17.9602 2.57743 17.9488 2.55463C17.9105 2.48216 17.9463 2.42028 18.0253 2.38852C18.0457 2.38038 18.0652 2.37061 18.0856 2.36084C18.93 1.97244 19.8118 1.70048 20.7197 1.51076C20.955 1.4619 21.1936 1.42445 21.4509 1.37804C21.1667 0.944854 21.3133 0.576812 21.6235 0.234827C21.582 0.221799 21.5698 0.216099 21.5575 0.215285C21.5266 0.213656 21.4957 0.212842 21.4655 0.21447C20.854 0.238898 20.2588 0.354522 19.6799 0.549128C18.9747 0.786075 18.3079 1.11096 17.6809 1.50424C16.8381 2.03351 16.0182 2.59778 15.1901 3.14985C15.1323 3.18812 15.0867 3.24593 15.0134 3.31514C15.072 3.31107 15.0932 3.31025 15.1144 3.307C15.5679 3.24104 16.019 3.1645 16.4742 3.10995C17.4334 2.99514 18.3942 2.90639 19.3607 3.01712C19.8843 3.07656 20.3972 3.17672 20.8646 3.43728C20.9151 3.46496 20.9607 3.5016 21.025 3.54639C20.9656 3.56756 20.9338 3.57977 20.9013 3.59117C20.0951 3.85906 19.2833 4.11148 18.4846 4.39891C16.6191 5.06904 14.7341 5.67647 12.8206 6.19433C12.6097 6.25133 12.4005 6.31566 12.1863 6.37754C12.1383 6.27087 12.1008 6.17235 12.0503 6.08034C11.9876 5.96716 11.9168 5.95169 11.8118 6.02578C11.7116 6.09744 11.6155 6.17479 11.5203 6.25377C11.197 6.52248 10.8843 6.80502 10.6897 7.18446C10.6164 7.32777 10.5822 7.49958 10.5692 7.66161C10.557 7.81144 10.6083 7.82935 10.7451 7.76502C11.0366 7.62904 11.3257 7.48818 11.6188 7.35708C13.8075 6.37835 16.0613 5.56655 18.329 4.79382C19.4429 4.41438 20.5699 4.07809 21.7318 3.88023C21.8767 3.8558 22.029 3.86476 22.1772 3.87534C22.2195 3.8786 22.257 3.94211 22.2969 3.97875C22.2529 4.00237 22.2122 4.03982 22.1658 4.04715C21.025 4.23524 19.9071 4.51453 18.8078 4.87117C16.6997 5.55515 14.6217 6.31891 12.5723 7.16166C11.9616 7.41245 11.3615 7.69011 10.7557 7.95312C10.649 7.99953 10.6409 8.06385 10.6783 8.16401C10.7207 8.278 10.7825 8.23566 10.8534 8.20553C11.5764 7.90182 12.2897 7.5753 13.0242 7.30171C14.6584 6.69428 16.2983 6.10069 17.9447 5.52746C19.5105 4.98273 21.1146 4.57153 22.7439 4.26619C22.8253 4.25071 22.8384 4.21977 22.8408 4.14649C22.8489 3.8558 22.8498 3.5643 22.8823 3.27606C22.9515 2.65234 23.1616 2.08643 23.6184 1.63371C23.6388 1.61335 23.6526 1.58567 23.6803 1.54414H23.6819ZM14.5713 8.99373C14.5761 9.01164 14.581 9.03037 14.5859 9.04828C14.6315 9.05154 14.6779 9.05887 14.7235 9.05643C14.9043 9.04991 15.0842 9.04096 15.265 9.03119C16.4001 8.97012 17.5351 8.90986 18.6588 8.72747C19.0936 8.65663 19.526 8.57358 19.9144 8.34477C20.3223 8.10457 20.6871 7.81876 20.9281 7.40187C20.9867 7.3009 21.012 7.18121 21.0527 7.06965C21.0397 7.06151 21.0275 7.05337 21.0144 7.04523C20.9298 7.06558 20.8443 7.08187 20.7612 7.10711C19.6888 7.42385 18.6173 7.74141 17.5457 8.0606C16.6769 8.31871 15.8073 8.57765 14.9401 8.83984C14.8131 8.87811 14.6934 8.94243 14.5713 8.99373ZM26.0343 2.38526C25.5368 2.05305 25.01 1.69722 24.3455 1.63208C24.0605 1.6044 23.8236 1.68419 23.6371 1.90079C23.3456 2.24033 23.1877 2.64257 23.1014 3.07575C23.0769 3.19789 23.1062 3.21906 23.2276 3.17997C24.0361 2.92104 24.8683 2.83147 25.7135 2.83717C25.8079 2.83717 25.9016 2.83717 25.9708 2.83717C25.9903 2.69387 26.0091 2.56114 26.0335 2.38526H26.0343ZM11.0521 5.29947C11.1473 5.26364 11.2288 5.23352 11.3094 5.20176C12.3956 4.77916 13.485 4.36552 14.6266 4.11229C14.7895 4.07646 14.9548 4.04389 15.1119 3.99097C15.1657 3.97306 15.2341 3.89244 15.2316 3.8444C15.2292 3.79718 15.1478 3.72145 15.0948 3.71575C14.9572 3.7011 14.8131 3.69865 14.6779 3.72471C13.9109 3.87534 13.1797 4.14323 12.4501 4.41519C12.0121 4.57886 11.5878 4.76939 11.1978 5.03077C11.1115 5.08858 11.0358 5.15046 11.0504 5.29866L11.0521 5.29947ZM25.8625 3.93967C25.8576 3.92909 25.8527 3.91769 25.8478 3.9071C25.7811 3.91524 25.711 3.91361 25.6483 3.93397C25.0205 4.13509 24.3944 4.3411 23.7666 4.54222C23.6705 4.57316 23.651 4.63504 23.6836 4.71402C23.7275 4.81906 23.7772 4.92247 23.8374 5.01937C23.9262 5.16268 23.9865 5.18548 24.1273 5.09754C24.6566 4.76614 25.1801 4.42741 25.7045 4.08786C25.764 4.04959 25.8104 3.99015 25.8625 3.94048V3.93967ZM9.18336 8.61347C8.81287 8.73724 8.45786 8.84961 8.10855 8.97663C7.98478 9.02141 7.94732 9.16798 7.98234 9.31699C8.00351 9.40655 8.05318 9.43587 8.13542 9.40818C8.50427 9.28116 8.87313 9.15169 9.25257 9.01897C9.22977 8.88706 9.2086 8.76004 9.18336 8.61347ZM9.56606 7.59077C9.20534 7.70965 8.8544 7.82365 8.5059 7.94172C8.40168 7.97673 8.33979 8.05245 8.33328 8.16726C8.32677 8.28777 8.36585 8.32197 8.47903 8.2837C8.76565 8.18518 9.05064 8.0834 9.33644 7.98243C9.51883 7.9181 9.57909 7.82039 9.56687 7.59077H9.56606ZM22.1047 0.752691C22.3026 0.702207 22.4874 0.665566 22.6641 0.605311C22.7219 0.585769 22.805 0.49783 22.7968 0.457117C22.7838 0.396048 22.7097 0.319509 22.647 0.303224C22.5053 0.265768 22.3539 0.242969 22.2073 0.247855C22.1202 0.251112 22.0225 0.302409 21.9525 0.360221C21.867 0.431875 21.8059 0.552385 21.8694 0.652538C21.9069 0.711978 22.0241 0.720935 22.1039 0.751876L22.1047 0.752691ZM9.76636 8.18843C9.82336 8.35454 9.88443 8.5638 9.96993 8.76248C9.98947 8.80727 10.0921 8.84472 10.1515 8.83821C10.2394 8.82925 10.2541 8.74375 10.2419 8.66233C10.2378 8.63627 10.2346 8.61022 10.2305 8.58416C10.1971 8.38141 10.1686 8.17785 10.1279 7.97673C10.1132 7.90263 10.0855 7.82202 10.0383 7.76502C9.96667 7.67871 9.88606 7.69581 9.85104 7.80248C9.81603 7.90996 9.80138 8.02396 9.76636 8.18843ZM26.6686 3.09773C26.7671 3.06924 26.8697 3.04969 26.9634 3.00817C27.0016 2.99107 27.0407 2.92837 27.0407 2.88684C27.0407 2.85672 26.9813 2.80868 26.9406 2.79972C26.7997 2.76878 26.6564 2.74435 26.5131 2.73295C26.4219 2.72562 26.3836 2.79728 26.382 2.88196C26.3779 3.03911 26.4325 3.07575 26.6694 3.09773H26.6686ZM23.208 1.14923C23.5028 1.19401 23.5663 1.16552 23.6469 0.964396C23.6762 0.891113 23.721 0.814574 23.6111 0.764904C23.5052 0.716049 23.3375 0.744548 23.3049 0.828416C23.2658 0.929383 23.2422 1.03524 23.2088 1.14923H23.208Z" fill="#CA3624"></path>
<path d="M7.43167 10.071C7.46669 10.0995 7.51473 10.1223 7.53101 10.1589C7.53834 10.176 7.49111 10.2363 7.45773 10.2493C7.21101 10.3438 6.96348 10.4342 6.7135 10.5197C4.56876 11.2517 2.42321 11.9821 0.27766 12.7124C0.219034 12.732 0.161222 12.7564 0.100967 12.7662C0.0692112 12.7711 0.0333843 12.7499 0 12.7401C0.0154708 12.7027 0.0211704 12.6522 0.048855 12.6302C0.087939 12.5984 0.143308 12.5846 0.192978 12.5675C1.97945 11.9584 3.76673 11.3502 5.55401 10.7411C6.07024 10.5653 6.58648 10.3886 7.1019 10.2086C7.20938 10.1712 7.31198 10.1207 7.43167 10.0702V10.071Z" fill="#CA3624"></path>
<path d="M0.537992 12.0546C0.528221 12.0196 0.509494 11.9846 0.511936 11.9504C0.514379 11.9162 0.527407 11.8673 0.552649 11.8527C0.603947 11.8217 0.666644 11.8079 0.724456 11.7875C2.77718 11.0832 4.8291 10.3781 6.88182 9.67374C6.93964 9.65339 6.99501 9.61593 7.05445 9.60942C7.10086 9.60453 7.15134 9.63466 7.2002 9.6485C7.16926 9.68758 7.14564 9.74703 7.10574 9.76168C6.67012 9.91639 6.23205 10.0638 5.79561 10.2144C4.11418 10.7942 2.43357 11.3739 0.752955 11.9536C0.699214 11.9724 0.644659 11.9895 0.590104 12.0074C0.573005 12.0229 0.555906 12.0383 0.538807 12.0546H0.537992Z" fill="#CA3624"></path>
<path d="M7.47241 8.79712C7.49277 8.8134 7.53755 8.83213 7.53755 8.85249C7.53755 8.88994 7.52452 8.94368 7.49684 8.96323C7.45205 8.9958 7.39261 9.00801 7.33806 9.02511C5.94569 9.48272 4.5525 9.94033 3.16013 10.3988C3.06405 10.4305 2.97041 10.4696 2.87433 10.4997C2.82059 10.5168 2.74161 10.5632 2.72695 10.4663C2.72125 10.4297 2.77906 10.3597 2.82141 10.3442C3.14385 10.2261 3.46874 10.1154 3.79444 10.0071C4.9637 9.6187 6.1346 9.23193 7.30468 8.84516C7.35434 8.82888 7.40564 8.81585 7.4716 8.79712H7.47241Z" fill="#CA3624"></path>
<path d="M8.55146 10.4764C8.50586 10.5098 8.46515 10.557 8.41385 10.5749C7.74046 10.8078 7.06545 11.0358 6.39125 11.2662C6.03786 11.3875 5.68529 11.5121 5.33191 11.6334C5.28712 11.6489 5.23827 11.6611 5.19186 11.6595C5.17394 11.6595 5.13649 11.6082 5.14219 11.5968C5.16091 11.5577 5.1886 11.5089 5.22443 11.495C5.42555 11.4177 5.62992 11.3485 5.83349 11.2776C6.60702 11.0114 7.38056 10.7459 8.1541 10.4788C8.23716 10.4503 8.31451 10.4023 8.39838 10.3836C8.44316 10.3738 8.4969 10.408 8.54657 10.4226C8.5482 10.4406 8.54983 10.4585 8.55146 10.4756V10.4764Z" fill="#CA3624"></path>
<path d="M4.88158 5.90776C4.86203 5.89391 4.82376 5.88089 4.81969 5.86053C4.81318 5.83122 4.82051 5.78399 4.84086 5.76689C4.87995 5.73351 4.93043 5.71071 4.97847 5.69279C5.96534 5.31661 6.95303 4.94205 7.9399 4.56668C7.94805 4.56343 7.957 4.5561 7.96433 4.55773C8.01563 4.56587 8.06611 4.57646 8.1166 4.58623C8.0881 4.63182 8.06937 4.70267 8.02866 4.71976C7.81858 4.81015 7.6028 4.88669 7.38866 4.9673C6.60616 5.26287 5.82448 5.55844 5.04198 5.85402C4.99313 5.87274 4.94264 5.88821 4.88076 5.90857L4.88158 5.90776Z" fill="#CA3624"></path>
<path d="M7.25558 5.73729C7.23197 5.721 7.18963 5.70472 7.19044 5.69006C7.19207 5.64609 7.19696 5.58747 7.22545 5.56222C7.26942 5.52233 7.33131 5.50115 7.38912 5.47998C7.7596 5.33993 8.1309 5.20151 8.5022 5.06472C8.56083 5.04355 8.64144 4.99306 8.66424 5.09077C8.67319 5.13067 8.61701 5.21454 8.57141 5.23327C8.28235 5.35133 7.98759 5.45556 7.69528 5.56629C7.55115 5.62085 7.40866 5.67785 7.25558 5.7381V5.73729Z" fill="#CA3624"></path>
<path d="M23.6822 1.54485C23.6537 1.58557 23.6406 1.61325 23.6203 1.63442C23.1635 2.08715 22.9534 2.65386 22.8842 3.27677C22.8524 3.56501 22.8516 3.85651 22.8427 4.1472C22.8402 4.22048 22.8272 4.25143 22.7458 4.2669C21.1156 4.57306 19.5124 4.98344 17.9466 5.52817C16.3002 6.10141 14.6602 6.69499 13.026 7.30243C12.2916 7.5752 11.5783 7.90253 10.8553 8.20625C10.7844 8.23556 10.7225 8.27871 10.6802 8.16472C10.6427 8.06375 10.6509 7.99942 10.7575 7.95383C11.3633 7.69082 11.9634 7.41398 12.5741 7.16237C14.6236 6.31962 16.7016 5.55586 18.8097 4.87189C19.9089 4.51524 21.0269 4.23596 22.1676 4.04786C22.2141 4.04053 22.2556 4.00308 22.2987 3.97947C22.2588 3.94364 22.2214 3.87931 22.179 3.87606C22.0317 3.86547 21.8786 3.85651 21.7337 3.88094C20.5709 4.07962 19.444 4.41509 18.3309 4.79453C16.0632 5.56726 13.8102 6.37906 11.6206 7.35779C11.3275 7.48889 11.0376 7.62894 10.747 7.76574C10.6102 7.83006 10.5589 7.81215 10.5711 7.66233C10.5849 7.50029 10.6183 7.32767 10.6916 7.18517C10.8854 6.80573 11.1981 6.52319 11.5221 6.25448C11.6174 6.1755 11.7135 6.09815 11.8136 6.02649C11.9187 5.9524 11.9895 5.96787 12.0522 6.08105C12.1027 6.17306 12.1401 6.27158 12.1882 6.37825C12.4023 6.31637 12.6116 6.25204 12.8225 6.19504C14.736 5.67799 16.621 5.06975 18.4864 4.39962C19.2852 4.11219 20.097 3.86059 20.9031 3.59188C20.9357 3.5813 20.9674 3.56908 21.0269 3.5471C20.9617 3.50231 20.9161 3.46567 20.8665 3.43799C20.3991 3.17743 19.8861 3.07809 19.3626 3.01783C18.396 2.9071 17.4352 2.99585 16.476 3.11066C16.0217 3.16521 15.5698 3.24175 15.1162 3.30771C15.0951 3.31097 15.0731 3.31097 15.0153 3.31585C15.0885 3.24664 15.1341 3.18883 15.192 3.15056C16.02 2.59931 16.8408 2.03422 17.6828 1.50496C18.3097 1.11167 18.9766 0.786786 19.6817 0.549838C20.2607 0.355232 20.8559 0.238794 21.4674 0.215181C21.4983 0.214367 21.5293 0.215181 21.5594 0.215995C21.5716 0.215995 21.5838 0.223324 21.6254 0.235537C21.3151 0.577523 21.1686 0.945565 21.4527 1.37875C21.1954 1.42516 20.9569 1.46261 20.7215 1.51147C19.8136 1.70119 18.9318 1.97396 18.0874 2.36155C18.0671 2.3705 18.0475 2.38028 18.0272 2.38923C17.9482 2.42099 17.9124 2.48287 17.9506 2.55534C17.9629 2.57814 18.0516 2.5814 18.0931 2.5643C18.9782 2.19707 19.8902 1.91697 20.8266 1.7134C21.706 1.52205 22.5943 1.45203 23.4924 1.5131C23.5511 1.51717 23.6097 1.53183 23.6838 1.54485H23.6822ZM20.8111 0.933351C20.7891 0.895081 20.7696 0.845412 20.737 0.807956C20.6018 0.654877 20.2941 0.696404 20.1605 0.882053C20.0604 1.02129 20.1133 1.17274 20.2778 1.22241C20.3926 1.25661 20.7272 1.1247 20.7834 1.0221C20.7956 1.00012 20.7989 0.972435 20.8111 0.934165V0.933351ZM19.0092 1.59615C19.2217 1.59778 19.3821 1.49111 19.3862 1.34455C19.3894 1.22404 19.3145 1.15157 19.1867 1.1532C19.0116 1.15483 18.8292 1.29569 18.8317 1.4276C18.8333 1.52938 18.9025 1.59534 19.0092 1.59615Z" fill="white"></path>
<path d="M14.5713 8.99404C14.6942 8.94192 14.8131 8.87841 14.9401 8.84014C15.8081 8.57714 16.6769 8.31902 17.5457 8.0609C18.6173 7.74253 19.6889 7.42497 20.7612 7.10742C20.8443 7.08299 20.9298 7.06589 21.0145 7.04553C21.0275 7.05367 21.0397 7.06182 21.0527 7.06996C21.012 7.18151 20.9868 7.30121 20.9281 7.40217C20.6871 7.81826 20.3215 8.10487 19.9144 8.34508C19.526 8.57388 19.0936 8.65775 18.6588 8.72778C17.5352 8.91017 16.4001 8.97042 15.265 9.03149C15.0851 9.04126 14.9043 9.05022 14.7236 9.05673C14.678 9.05836 14.6315 9.05103 14.5859 9.04859C14.5811 9.03068 14.5762 9.01195 14.5713 8.99404Z" fill="white"></path>
<path d="M26.0348 2.38542C26.0103 2.5613 25.9916 2.69484 25.9721 2.83733C25.9029 2.83733 25.8092 2.83733 25.7148 2.83733C24.8696 2.83082 24.0374 2.9212 23.2289 3.18013C23.1075 3.21922 23.0782 3.19805 23.1027 3.07591C23.189 2.64273 23.3469 2.24049 23.6384 1.90094C23.8249 1.68435 24.0618 1.60456 24.3468 1.63224C25.0113 1.69738 25.5381 2.05321 26.0356 2.38542H26.0348Z" fill="white"></path>
<path d="M11.0518 5.29969C11.0364 5.15149 11.1121 5.08961 11.1992 5.0318C11.5892 4.77042 12.0135 4.57908 12.4515 4.41623C13.1811 4.14427 13.9123 3.87556 14.6793 3.72574C14.8145 3.69968 14.9586 3.70131 15.0962 3.71678C15.1491 3.72248 15.2297 3.79821 15.233 3.84543C15.2354 3.89348 15.1671 3.97409 15.1133 3.992C14.9562 4.04574 14.7909 4.0775 14.628 4.11332C13.4856 4.36574 12.397 4.7802 11.3108 5.20279C11.2301 5.23455 11.1487 5.26386 11.0535 5.3005L11.0518 5.29969Z" fill="white"></path>
<path d="M25.8625 3.93866C25.8104 3.98833 25.7639 4.04695 25.7045 4.08604C25.1809 4.42558 24.6566 4.76431 24.1273 5.09571C23.9873 5.18365 23.927 5.16166 23.8374 5.01754C23.778 4.92065 23.7275 4.81724 23.6835 4.7122C23.651 4.63321 23.6705 4.57133 23.7666 4.54039C24.3944 4.33927 25.0205 4.13326 25.6483 3.93214C25.711 3.91179 25.781 3.91342 25.8478 3.90527C25.8527 3.91586 25.8576 3.92726 25.8625 3.93784V3.93866Z" fill="white"></path>
<path d="M9.18325 8.61365C9.20849 8.76021 9.22966 8.88724 9.25246 9.01914C8.8722 9.15187 8.50416 9.28133 8.1353 9.40836C8.05307 9.43686 8.0034 9.40754 7.98223 9.31716C7.94721 9.16897 7.98467 9.0224 8.10843 8.9768C8.45775 8.84978 8.81276 8.73741 9.18325 8.61365Z" fill="white"></path>
<path d="M9.56532 7.59131C9.57754 7.82093 9.5181 7.91782 9.33489 7.98296C9.04909 8.08393 8.7641 8.18571 8.47748 8.28424C8.36512 8.32251 8.32522 8.28831 8.33173 8.1678C8.33825 8.05299 8.40013 7.97726 8.50435 7.94225C8.85367 7.82418 9.2038 7.711 9.56451 7.59131H9.56532Z" fill="white"></path>
<path d="M22.1045 0.752621C22.0247 0.721679 21.9075 0.712723 21.87 0.653282C21.8065 0.553129 21.8676 0.43262 21.9531 0.360966C22.0223 0.303154 22.1208 0.251042 22.2079 0.248599C22.3545 0.243714 22.5051 0.265698 22.6476 0.303968C22.7103 0.320253 22.7844 0.396793 22.7975 0.457862C22.8056 0.49776 22.7234 0.586514 22.6647 0.606056C22.488 0.66631 22.3032 0.702952 22.1053 0.753435L22.1045 0.752621Z" fill="white"></path>
<path d="M9.76562 8.18845C9.80064 8.02397 9.81448 7.90998 9.85031 7.8025C9.88532 7.69583 9.96593 7.67873 10.0376 7.76504C10.0848 7.82204 10.1117 7.90265 10.1272 7.97675C10.1671 8.17787 10.1964 8.38143 10.2297 8.58418C10.2338 8.61023 10.2371 8.63629 10.2411 8.66235C10.2534 8.74377 10.2387 8.82927 10.1508 8.83822C10.0913 8.84474 9.98792 8.80728 9.96919 8.7625C9.88451 8.56382 9.82262 8.35537 9.76562 8.18845Z" fill="white"></path>
<path d="M26.6685 3.09762C26.4315 3.07563 26.377 3.03899 26.3811 2.88184C26.3835 2.79797 26.4218 2.72632 26.5122 2.73283C26.6555 2.74423 26.7988 2.76948 26.9396 2.7996C26.9795 2.80856 27.0398 2.8566 27.0398 2.88673C27.0398 2.92825 27.0007 2.99095 26.9624 3.00805C26.8696 3.04876 26.767 3.06912 26.6677 3.09762H26.6685Z" fill="white"></path>
<path d="M23.2078 1.14955C23.2412 1.03555 23.2657 0.928887 23.3039 0.828734C23.3365 0.744867 23.505 0.717182 23.6101 0.765223C23.72 0.815706 23.6752 0.892246 23.6459 0.964714C23.5661 1.16502 23.5018 1.19433 23.207 1.14955H23.2078Z" fill="white"></path>
<path d="M20.8109 0.934089C20.7995 0.973173 20.7954 1.00004 20.7832 1.02203C20.727 1.12544 20.3923 1.25653 20.2775 1.22233C20.1122 1.17266 20.0601 1.02203 20.1603 0.881977C20.293 0.695514 20.6016 0.654801 20.7368 0.80788C20.7701 0.845336 20.7889 0.895819 20.8109 0.933275V0.934089Z" fill="#CA3624"></path>
<path d="M19.0076 1.5963C18.9009 1.5963 18.8317 1.52953 18.8301 1.42775C18.8277 1.29584 19.0101 1.15579 19.1851 1.15335C19.3138 1.15172 19.3887 1.22337 19.3846 1.3447C19.3805 1.49045 19.2201 1.59711 19.0076 1.5963Z" fill="#CA3624"></path>
</svg></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Xcapture-BPF – like Linux top, but with Xray vision (186 pts)]]></title>
            <link>https://0x.tools/</link>
            <guid>40869877</guid>
            <pubDate>Wed, 03 Jul 2024 20:52:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://0x.tools/">https://0x.tools/</a>, See on <a href="https://news.ycombinator.com/item?id=40869877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <h2><a href="https://0x.tools/">0x.tools</a></h2>
      

      
<p><em>By <a href="https://tanelpoder.com/">Tanel Poder</a></em></p>

<p><strong>0x.tools</strong> (<a href="https://github.com/tanelpoder/0xtools">GitHub</a>) is a set of open-source utilities for analyzing application performance on Linux. It has a goal of deployment simplicity and minimal dependencies, to reduce friction of systematic troubleshooting. There’s no need to upgrade the OS, install kernel modules, heavy monitoring frameworks, Java agents or databases. Some of the tools even work on over-decade-old Linux kernels, like version 2.6.18 from 18 years ago.</p>

<p><strong>0x.tools</strong> allow you to measure individual thread level activity, like thread sleep states, currently executed system calls and kernel wait locations. Additionally, you can drill down into CPU usage of any thread or the system as a whole. You can be <em>systematic</em> in your troubleshooting - no need for guessing or genius wizard magic based on secondary metrics like system utilization stats.</p>



<h2 id="xcapture-bpf-202-beta">xcapture-bpf 2.0.2 beta</h2>

<p><strong>xcapture-bpf</strong> (and <strong>xtop</strong>) are like the Linux <code>top</code> tool, but extended with x-ray vision and ability to view your performance data from any chosen angle (that eBPF allows to instrument). You can use it for system level overview and drill down into indivual threads’ activity and soon even into individual kernel events like lock waits or memory stalls. eBPF is not only customizable, it’s completely programmable and I plan to take full advantage of it. I have so far implemented less than 5% of everything this method and the new tool is capable of, stay tuned for more!</p>

<p>This (2-minute) asciicast box below is pretty high for a reason, play it and you’ll see, command line nerds should love it ;-)<br>
</p>

<h3 id="xcapture-bpf-terminal-highlighting-and-stacktiles-in-action">xcapture-bpf terminal highlighting and stacktiles in action</h3>

<p>I included a screenshot image below, to show how the terminal text search/highlighting <em>and scrolling</em> capabilities work nicely together with my new <em>stacktiles</em> formatting method, this way you can fit more relevant things on your screen and not have to switch windows or scroll around that much, while keeping some structure and sanity in place with all the stack traces.</p>

<p><img src="https://0x.tools/images/xcapture-bpf-stacktiles.png" alt="xcapture-bpf and stacktiles in terminal"></p>

<p>The stacktiles do not have to contain only stacks of function names, but could contain other things, like filenames or any other thing, like top memory allocation reasons (and amounts) done under a code location reported below, etc.</p>

<h3 id="xcapture-bpf-installation">xcapture-bpf installation</h3>

<p><code>xcapture-bpf</code> is still in beta, don’t run it on busy production systems yet. As it uses eBPF (and currently BCC with python3 as a reporting frontend), you’d need to be at least on RHEL 8.1 (or a clone) or Ubuntu 24.04 (Ubuntu 22.04’s BCC has some kernel header compatibility issue and the 20.04 kernel does not have the required eBPF features available. These are the only versions I’ve tested with so far, on x86_64 and arm64 platforms.</p>

<p>On RHEL8, you can install the prerequisites with this:</p>

<div><pre><code>$ sudo dnf install bcc bcc-tools python3 python3-bcc
$ git clone git@github.com:tanelpoder/0xtools.git

$ ls -l 0xtools/bin/xcapture-bpf*
-rwxrwxr-x. 1 tanel tanel 25724 Jul  2 22:04 0xtools/bin/xcapture-bpf
-rw-rw-r--. 1 tanel tanel 12127 Jul  2 15:34 0xtools/bin/xcapture-bpf.c

$ cat 0xtools/bin/xtop 
#!/usr/bin/bash

CURDIR="$(dirname "$(realpath "$0")")"

${CURDIR}/xcapture-bpf --xtop --clear-screen $*

$ cd 0xtools/bin
$ sudo ./xtop
</code></pre></div>

<p>If you don’t want to clone/download the whole 0xtools repository, then for <code>xcapture-bpf</code>, you only need the 2 xcapture-bpf* files listed above. No need to compile the .c file as the BCC toolset takes care of it on the fly. <code>xtop</code> is just a simple shell wrapper for convenience (and now there’s an “xtop” in the Linux command line namespace! ;-)</p>

<p><code>bcc-tools</code> are not really needed for xcapture-bpf itself, but they’re worth checking out, if you’re gonna play with eBPF tools anyway.</p>

<h3 id="xcapture-bpf-launch-video-2024-06-25">xcapture-bpf launch video (2024-06-25)</h3>
<p>I have uploaded my 0xtools v2 beta (with eBPF) nerd-launch video here:</p>

<iframe width="980" height="614" src="https://www.youtube.com/embed/_nLAdkDhaI0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""> </iframe>

<p>Slides, code, discussion here:</p>
<ul>
  <li><a href="https://github.com/tanelpoder/0xtools/discussions/38">https://github.com/tanelpoder/0xtools/discussions/38</a></li>
</ul>

<p>The details about the rest of the 0xtools are below (all the other tools just read various /proc files, no eBPF needed for them).</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li><a href="#included-tools">Included Tools</a></li>
  <li><a href="#usage--example-output">Example Output</a></li>
  <li><a href="#installation--usage">Installation &amp; Usage</a></li>
  <li><a href="#faq">FAQ</a></li>
  <li><a href="#whats-next">What’s next</a></li>
  <li><a href="#articles">Articles</a></li>
</ol>



<p>You get two classes of utilities:</p>

<ol>
  <li>Real-time interactive tools for analyzing current system behavior as it is happening.</li>
  <li>Low-overhead thread activity samplers for <strong>always-on low-frequency profiling of production systems</strong>. The continuously captured data allows you to “go back in time” and systematically troubleshoot even intermittent problems right after (or during) their first occurrence.</li>
</ol>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>psn</td>
      <td>Show current top thread activity by sampling /proc files</td>
    </tr>
    <tr>
      <td>xcapture</td>
      <td>Low-overhead thread state sampler reading /proc files</td>
    </tr>
    <tr>
      <td>xcapture-bpf</td>
      <td><a href="https://github.com/tanelpoder/0xtools/discussions/38">Low-overhead programmable thread state sampler build with eBPF</a> (beta)</td>
    </tr>
    <tr>
      <td>syscallargs</td>
      <td><a href="https://tanelpoder.com/posts/list-linux-system-call-arguments-with-syscallargs/">List all system calls with their arguments</a></td>
    </tr>
    <tr>
      <td>schedlat</td>
      <td>Show single process’es CPU scheduling latency as a % of its runtime</td>
    </tr>
    <tr>
      <td>run_xcapture.sh</td>
      <td>A simple “daemon” script for keeping xcapture running</td>
    </tr>
    <tr>
      <td>run_xcpu.sh</td>
      <td>Low-frequency continuous stack sampling for threads on CPU (using perf)</td>
    </tr>
  </tbody>
</table>

<p><code>xcapture</code> is written in C for efficiency reasons and it consists of just a single C source file and a single header file for system call name translation. All other tools are Python or shell scripts.</p>

<h2 id="usage--example-output">Usage &amp; Example Output</h2>

<p>Sample Linux thread activity and show fixed-width output on screen:</p>

<div><pre><code>$ xcapture

0xTools xcapture v1.0 by Tanel Poder [https://0x.tools]

Sampling /proc...

DATE       TIME             PID     TID USERNAME        ST COMMAND                   SYSCALL                   WCHAN                    
2020-10-17 12:01:50.583    6404    7524 mysql           R  (mysqld)                  fsync                     wait_on_page_bit          
2020-10-17 12:01:50.583    6404    8944 mysql           D  (mysqld)                  fsync                     wait_on_page_bit          
2020-10-17 12:01:50.583    6404    8946 mysql           D  (mysqld)                  fsync                     wait_on_page_bit          
2020-10-17 12:01:50.583    6404   76046 mysql           D  (mysqld)                  fsync                     wait_on_page_bit          
2020-10-17 12:01:50.583    6404   76811 mysql           D  (mysqld)                  fdatasync                 xfs_log_force_lsn         
2020-10-17 12:01:50.583    6404   76815 mysql           D  (mysqld)                  fsync                     blkdev_issue_flush        
2020-10-17 12:01:50.583    8803    8803 root            R  (md10_resync)             [running]                 0                         

DATE       TIME             PID     TID USERNAME        ST COMMAND                   SYSCALL                   WCHAN                    
2020-10-17 12:01:51.623    6404    7521 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404    7524 mysql           D  (mysqld)                  fsync                     xfs_log_force_lsn         
2020-10-17 12:01:51.623    6404    7767 mysql           D  (mysqld)                  fsync                     xfs_log_force_lsn         
2020-10-17 12:01:51.623    6404    8398 mysql           D  (mysqld)                  fsync                     call_rwsem_down_read_failed 
2020-10-17 12:01:51.623    6404    5446 mysql           D  (mysqld)                  fsync                     xfs_log_force_lsn         
2020-10-17 12:01:51.623    6404    8941 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404    8944 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404    8945 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404   76045 mysql           D  (mysqld)                  fsync                     call_rwsem_down_read_failed 
2020-10-17 12:01:51.623    6404   76046 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404   76810 mysql           D  (mysqld)                  pwrite64                  xfs_file_buffered_aio_write 
2020-10-17 12:01:51.623    6404   76811 mysql           D  (mysqld)                  fdatasync                 xfs_log_force_lsn         
2020-10-17 12:01:51.623    6404   76812 mysql           D  (mysqld)                  fsync                     wait_on_page_bit          
2020-10-17 12:01:51.623    8803    8803 root            D  (md10_resync)             [no_syscall]              msleep                    
</code></pre></div>

<details>
  <summary>Watch a SVG video of xcapture in action!</summary>
  <p><img src="https://0x.tools/images/xcapture-example.svg">
  </p>
</details>

<hr>

<p>Sample threads in all states (including Sleeping) and write output into hourly CSV files:</p>

<div><pre><code>$ xcapture -a -o /data/xcap &amp;

$ head 2020-10-16.21.csv
TS,PID,TID,USERNAME,ST,COMMAND,SYSCALL,WCHAN,EXE,CMDLINE,KSTACK
2020-10-16 21:00:00.001,5335,5335,root,R,(collectl),[running],0,perl,/usr/bin/perl,
2020-10-16 21:00:00.001,8803,8803,root,D,(md10_resync),[no_syscall],msleep,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()-&gt;msleep()
2020-10-16 21:00:01.038,8803,8803,root,R,(md10_resync),[no_syscall],md_do_sync,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()
2020-10-16 21:00:02.075,8803,8803,root,D,(md10_resync),[no_syscall],md_do_sync,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()
2020-10-16 21:00:02.075,16762,16762,oracle,R,(ora_m000_lin19c),[running],0,oracle,ora_m000_LIN19C,-&gt;do_blockdev_direct_IO()-&gt;dio_complete()
2020-10-16 21:00:03.112,8803,8803,root,R,(md10_resync),[no_syscall],md_do_sync,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()
2020-10-16 21:00:04.149,8803,8803,root,D,(md10_resync),[no_syscall],msleep,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()-&gt;msleep()
2020-10-16 21:00:05.186,8803,8803,root,D,(md10_resync),[no_syscall],md_do_sync,-,-,-&gt;ret_from_fork_nospec_begin()-&gt;kthread()-&gt;md_thread()-&gt;md_do_sync()
2020-10-16 21:00:05.186,65913,65913,oracle,D,(ora_ckpt_lin122),pwrite64,blkdev_issue_flush,oracle,ora_ckpt_LIN122,-&gt;system_call_fastpath()-&gt;SyS_pwrite64()-&gt;vfs_write()-&gt;do_sync_write()-&gt;xfs_file_aio_write()-&gt;generic_write_sync()-&gt;xfs_file_fsync()-&gt;xfs_blkdev_issue_flush()-&gt;blkdev_issue_flush()
</code></pre></div>

<p>You can “Query” the thread activity history for performance analysis on the command line (or just load the CSV into any database):</p>

<p>Query CSV files with standard Linux text processing tools. It’s like SQL but with different keywords: <code>grep</code> for filtering, <code>cut</code>, <code>awk</code> for column projection, <code>uniq</code> for group by and <code>sort</code> for ordering. Filename patterns like <code>cat 2020-10-??.0[89].csv</code> could be used for scanning through only the files of interest (partition pruning):</p>

<div><pre><code>$ cat 2020-10-13.01.csv | awk -F, '{ printf("%2s %-20s %-20s %s\n",$5,$4,$7,$10) }' | sort | uniq -c | sort -nbr | head -20
   2303  D root                 read                 -
   1761  R tanel                [running]            stress
   1384  D postgres             pread64              postgres: tanel pgbench [local] UPDATE
    894  R root                 [running]            -
    229  R root                 read                 -
    229  D mysql                fsync                /usr/sbin/mysqld
    144  R tanel                [running]            -
    115  - -                    -                    -
    110  D oracle               io_submit            ora_ckpt_LINPRD
    101  D root                 [running]            -
     73  D root                 read                 dd
     58  R root                 [running]            /opt/oracle.ahf/jre/bin/java
     55  R mysql                [running]            /usr/sbin/mysqld
     52  D tanel                [no_syscall]         stress
     51  R oracle               [running]            oracleLIN19C
     50  R root                 [running]            dd
     35  R oracle               [running]            xe_mz01_XE
     32  R tanel                [running]            /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java
     29  R oracle               [running]            pidstat
     27  D oracle               pread64              oracleLIN19C
</code></pre></div>

<p>Or you can query CSV files with <code>q-text-as-data</code>:</p>

<div><pre><code>$ q -d, -bTH '
select count(*) avgthr, username,st,syscall,wchan
from 2020-10-13.01.csv
group by username,st,syscall,wchan
order by 1 desc' | head -20
1955	tanel   	R	[running]   	0                               
1384	postgres	D	pread64     	generic_file_read_iter          
1084	root    	D	read        	raise_barrier                   
1041	root    	R	[running]   	0                               
712 	root    	D	read        	msleep                          
341 	oracle  	R	[running]   	0                               
317 	root    	D	read        	md_super_wait                   
123 	mysql   	D	fsync       	__xfs_log_force_lsn             
115 	-       	-	-           	-                               
92  	oracle  	D	io_submit   	md_write_start                  
92  	root    	R	read        	raise_barrier                   
79  	root    	D	read        	wait_barrier                    
66  	oracle  	R	nanosleep   	hrtimer_nanosleep               
66  	root    	D	[running]   	0                               
52  	mysql   	R	[running]   	0                               
51  	root    	R	read        	worker_thread                   
48  	mysql   	D	fsync       	submit_bio_wait                 
48  	root    	D	read        	0                               
41  	tanel   	D	[no_syscall]	rq_qos_wait                     
39  	root    	D	read        	md_bitmap_cond_end_sync         
</code></pre></div>

<p>Or you can do tabular data analysis in your terminal with the awesome <a href="https://www.visidata.org/">VisiData</a> tool. Note that the video below does not have sound (it’s not your computer :-)</p>

<iframe width="980" height="614" src="https://www.youtube.com/embed/hW9fVLOjB10" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>

<p><em>This brings me back memories of Lotus 1-2-3 on a crappy 286 with floppy drives and MS-DOS!</em></p>

<h2 id="installation--usage">Installation &amp; Usage</h2>

<p><code>xcapture</code>, <code>schedlat</code> and <code>psn</code> sample the Linux <em>/proc filesystem</em> just like standard tools like <code>ps</code>, <code>top</code> and <code>lsof</code> do. The /proc filesystem is essentially Linux kernel presenting useful metrics into userspace as user-readable files. So, you do not need any additional Linux configuration or anything fancy to be installed on your hosts. 0x.tools require Linux kernel version 2.6 or later, so they will work even on your legacy installations (like RHEL 5, CentOS 5) from 15 years ago.</p>

<p>For running <code>psn</code> on CentOS 5 (RHEL 5 clones), you need to have Python 2.6+ on it (it can be installed from EPEL repo).</p>

<div><pre><code>$ git clone https://github.com/tanelpoder/0xtools
$ make
$ sudo make install
</code></pre></div>

<p>Running 0xTools utilities:</p>

<h3 id="xcapture">xCapture</h3>

<div><pre><code>$ xcapture

0x.Tools xcapture v1.0 by Tanel Poder [https://0x.tools]

Usage:
  xcapture [options]

  By default, sample all /proc tasks in states R, D every second and print to stdout

  Options:
    -a             capture tasks in additional states, even the ones Sleeping (S)
    -A             capture tasks in All states, including Zombie (Z), Exiting (X), Idle (I)
    -c &lt;c1,c2&gt;     print additional columns (for example: -c exe,cmdline,kstack)
    -d &lt;N&gt;         seconds to sleep between samples (default: 1)
    -E &lt;string&gt;    custom task state Exclusion filter (default: XZIS)
    -h             display this help message
    -o &lt;dirname&gt;   write wide output into hourly CSV files in this directory instead of stdout


$ xcapture -c exe,kstack
$ xcapture -o .
$ xcapture -o /data/perf_archive/xcap

</code></pre></div>

<h3 id="linux-process-snapper">Linux Process Snapper</h3>

<p>Linux Process Snapper is a Python script meant for troubleshooting currently on-going issues (no historical capture). It currently reports more fields directly from /proc than xcapture captures (like filenames accessed by IO system calls). I plan to improve this tool so that it could use xcapture CSV files as an input, in addition to current real-time monitoring.</p>

<p>IO bottleneck example: My “pipeline” is bottlenecked by writes to the output file, not input reads:</p>

<div><pre><code>$ psn -p 18286 -G syscall,filename

Linux Process Snapper v0.14 by Tanel Poder [https://0x.tools]
Sampling /proc/stat, syscall for 5 seconds... finished.


=== Active Threads ==================================================================================

 samples | avg_threads | comm | state                  | syscall   | filename                        
-----------------------------------------------------------------------------------------------------
      79 |        0.79 | (dd) | Disk (Uninterruptible) | write     | /backup/tanel/test (stdout)
       7 |        0.07 | (dd) | Disk (Uninterruptible) | [running] |                                 
       5 |        0.05 | (dd) | Running (ON CPU)       | write     | /backup/tanel/test (stdout)     
       4 |        0.04 | (dd) | Disk (Uninterruptible) | read      | /reco/fio/mmapfile.0.0 (stdin)  
       3 |        0.03 | (dd) | Running (ON CPU)       | [running] |                                 
       2 |        0.02 | (dd) | Running (ON CPU)       | read      | /reco/fio/mmapfile.0.0 (stdin)  ```
</code></pre></div>

<p>MySQL I/O bottleneck example: there’s some OS kernel inode level semaphore contention due to frequent use of fsync():</p>

<div><pre><code>$ sudo psn -p "mysqld|kwork" -G syscall,wchan

Linux Process Snapper v0.14 by Tanel Poder [https://0x.tools]
Sampling /proc/syscall, stat, wchan for 5 seconds... finished.


=== Active Threads ========================================================================================

 samples | avg_threads | comm          | state                  | syscall   | wchan                        
-----------------------------------------------------------------------------------------------------------
      25 |        3.12 | (mysqld)      | Disk (Uninterruptible) | fsync     | _xfs_log_force_lsn
      16 |        2.00 | (mysqld)      | Running (ON CPU)       | [running] | 0                            
      14 |        1.75 | (mysqld)      | Disk (Uninterruptible) | pwrite64  | call_rwsem_down_write_failed
       8 |        1.00 | (mysqld)      | Disk (Uninterruptible) | fsync     | submit_bio_wait              
       4 |        0.50 | (mysqld)      | Disk (Uninterruptible) | pread64   | io_schedule                  
       4 |        0.50 | (mysqld)      | Disk (Uninterruptible) | pwrite64  | io_schedule                  
       3 |        0.38 | (mysqld)      | Disk (Uninterruptible) | pread64   | 0                            
       3 |        0.38 | (mysqld)      | Running (ON CPU)       | [running] | io_schedule                  
       3 |        0.38 | (mysqld)      | Running (ON CPU)       | pread64   | 0                            
       2 |        0.25 | (mysqld)      | Disk (Uninterruptible) | [running] | 0                            
       1 |        0.12 | (kworker/*:*) | Running (ON CPU)       | read      | worker_thread                
       1 |        0.12 | (mysqld)      | Disk (Uninterruptible) | fsync     | io_schedule                  
       1 |        0.12 | (mysqld)      | Disk (Uninterruptible) | futex     | call_rwsem_down_write_failed 
       1 |        0.12 | (mysqld)      | Disk (Uninterruptible) | poll      | 0                            
       1 |        0.12 | (mysqld)      | Disk (Uninterruptible) | pwrite64  | _xfs_log_force_lsn           
       1 |        0.12 | (mysqld)      | Running (ON CPU)       | fsync     | submit_bio_wait              
       1 |        0.12 | (mysqld)      | Running (ON CPU)       | futex     | futex_wait_queue_me      
</code></pre></div>

<p>More info and examples are available at Tanel Poder’s <a href="https://tanelpoder.com/psnapper">Linux Performance Troubleshooting Page</a></p>

<h3 id="schedlat">SchedLat</h3>

<div><pre><code>$ ./schedlat.py 29801
SchedLat by Tanel Poder [https://0x.tools]

PID=29801 COMM=oracle_29801_li

TIMESTAMP              %CPU   %LAT   %SLP
2020-02-26 23:17:35   100.0    0.0    0.0   &lt;&lt;-- no CPU shortage, process 100% on CPU
2020-02-26 23:17:36   100.0    0.0    0.0
2020-02-26 23:17:37   100.0    0.0    0.0
2020-02-26 23:17:38   100.0    0.0    0.0   &lt;&lt;-- %SLP = 100-(%CPU+%LAT), when Linux reports slightly
2020-02-26 23:17:39    98.0    0.0    2.0        more than "100%" of CPU+LAT, then the derived
2020-02-26 23:17:40     0.0    0.0  100.0        "remaining time" SLP% may show a negative value
2020-02-26 23:17:41     0.0    0.0  100.0
2020-02-26 23:17:42     0.0    0.0  100.0   &lt;&lt;-- no CPU shortage, process sleeping
2020-02-26 23:17:43     0.4    0.0   99.6
2020-02-26 23:17:44    33.5    0.2   66.3   &lt;&lt;-- no CPU shortage, process doing synchronous I/Os 
2020-02-26 23:17:45    55.5    0.2   44.2        in a loop (thus taken off CPU frequently by scheduler)
2020-02-26 23:17:46    53.9    0.2   45.9
2020-02-26 23:17:47    54.5    0.2   45.3
2020-02-26 23:17:48    59.1    0.2   40.7
2020-02-26 23:17:49     4.4    0.0   95.6
2020-02-26 23:17:50    58.5    0.1   41.4
2020-02-26 23:17:51    95.7    0.0    4.3
2020-02-26 23:17:52     0.3    0.0   99.7 
2020-02-26 23:17:53     0.1    0.0   99.9
2020-02-26 23:17:54     0.1    0.0   99.9
2020-02-26 23:17:55     0.3    1.1   98.6
2020-02-26 23:17:56     0.1    6.0   93.9
2020-02-26 23:17:57     0.1   15.0   84.9
2020-02-26 23:17:58     0.1   13.8   86.1
2020-02-26 23:17:59     9.6   61.4   29.0   &lt;&lt;-- CPU shortage + process doing synchronous I/Os in a loop
2020-02-26 23:18:00    14.6   83.9    1.5   &lt;&lt;-- and spending more time in CPU runqueue after every I/O
2020-02-26 23:18:01    31.4   59.7    8.9
2020-02-26 23:18:02    13.0   13.9   73.1
2020-02-26 23:18:03     0.3    5.3   94.4
</code></pre></div>

<p>There are more details in my <a href="https://tanelpoder.com/posts/schedlat-low-tech-script-for-measuring-cpu-scheduling-latency-on-linux/">Measuring Linux CPU Scheduling Latency</a> blog entry.</p>

<h2 id="cpu-profiling">CPU profiling</h2>

<p>When you look into the <code>run_xcpu.sh</code>, you’ll see that I’m currently using just <code>perf</code> under the hood with 1 Hz frequency. You can have it <em>always-on</em> no noticeable performance overhead!</p>

<div><pre><code>$ cat bin/run_xcpu.sh
...
perf record -g -F 1 -a \
            --switch-output=1m \
            --timestamp-filename \
            --timestamp \
            -o $1/xcpu

...
</code></pre></div>

<p>With the above arguments, perf writes the sampled on-CPU stack traces into 1-minute granularity files.</p>

<p>Then all you need to do is run perf on the file with the right timestamp, to zoom in to the time of your performance problem:</p>

<div><pre><code>$ perf report -s sym,dso -i xcpu.2020101619323791
</code></pre></div>

<p><img src="https://0x.tools/images/perf-example.png">
<em>Perf CPU usage profile, including kernel-mode and interrupts CPU usage</em></p>

<h2 id="faq">FAQ</h2>

<h3 id="how-is-the-0xtools-toolset-licensed">How is the 0x.tools toolset licensed?</h3>
<p>0x.tools is an open source, GPL v3-licensed product, so you can use it like most other standard command line tools in your Linux distribution.</p>

<h3 id="what-is-the-measurement-overhead">What is the measurement overhead?</h3>
<p>0x.tools <code>xcapture</code> is designed to have very low overhead, well under 1% of your server’s CPU capacity, even when sampling every second. Note that xcapture does not invoke any tracing, but samples already built-in kernel instrumentation from /proc file system asynchronously and independently. Therefore it won’t slow any of your existing applications down, but uses a small percentage of one CPU in the system for its sampling. In extreme cases (with tens of thousands of active threads), you can reduce sampling frequency to reduce xcapture CPU usage.</p>

<p>The <code>run_xcpu.sh</code> CPU sampling script uses standard Linux <code>perf</code> utility under the hood, with just 1 Hz sampling rate by default. Thanks to the low-frequency sampling, perf will not cause noticeable overhead for your applications.</p>

<h3 id="is-it-safe-to-use-in-production">Is it safe to use in production?</h3>
<p>0x.tools are <em>designed</em> to be safely used in production, including traditional enterprise environments where you can’t just upgrade to latest OS version at will or load custom kernel modules. All the code is open source, without any dependencies outside the standard Linux utilities and libraries, skimming through a few hundred lines of 0x.tools C and Python code should be doable in matter of minutes.</p>

<p>As with all software and tools, I recommend to try them first on a test system (ideally similar to production) and see how it works, before deploying to production.</p>

<h3 id="why-not-just-use-perf-for-everything-including-xcapture">Why not just use perf for everything (including xcapture)?</h3>
<p>Perf sampling captures only on-CPU activity by default. If you have 32 CPUs, it will check what code is running on them at every sample, but does not aim to walk through the hundreds (or thousands) of OS threads that happen to be sleeping. While it is possible to enable tracing for <a href="http://www.brendangregg.com/offcpuanalysis.html">off-cpu events</a> in Perf, it comes with a high tracing overhead (and later, overhead of post-processing these high-frequency events).</p>

<h3 id="why-not-just-use-bpf-instead-of-proc-sampling">Why not just use BPF instead of /proc sampling?</h3>
<p>In short, eBPF is not available for wide-scale production use in traditional enterprises (think banks, telcos and other Fortune 500s with decades of IT history). This may come as a surprise if you’ve worked only for startups running latest ephemeral Ubuntu containers in the cloud :-) For example RedHat started actually supporting eBPF in RHEL 8.1 (Released Nov 2019). The enterprises I work with, still have RHEL6 (kernel 2.6.32) as their mostly widely used OS version, with RHEL7 (and CentOS 7) gaining traction. So “let’s just do a major OS upgrade” for troubleshooting this performance spike is out of the question.</p>

<p>Nevertheless, I have written an eBPF sampler prototype already, it combines both thread state and CPU usage profiling into one tool. But I wanted to productionize the simpler, widely available /proc file-based profiler first, for practical reasons.</p>

<h3 id="why-not-just-use-distributed-tracing-like-opentracing-zipkin-jaeger">Why not just use distributed tracing like OpenTracing, Zipkin, Jaeger?</h3>

<p>These powerful, but complex frameworks are high level end-to-end tracers of request flow through application layers and components. They are designed to point out in which component of your distributed multi-tier system most of the user response was spent, but they do not drill down into the reason why. 0x.tools are designed to fill that gap.</p>

<h3 id="why-not-just-use-something-like-prometheus">Why not just use something like Prometheus?</h3>

<p>Prometheus is designed for shipping, storing and serving system &amp; appliction time-series metrics captured from a large fleet of servers &amp; applications. You can plot nice dashboards with charts showing various latency, request count and system utilization metrics over time. Such time-series metrics are useful background info, but do not allow you to drill down into the low level <em>reasons</em> of increased system activity, application resource usage or misbehavior of the OS kernel itself.</p>

<h2 id="whats-next">What’s next?</h2>

<p>There are a lot of new features and utilities that can be added to 0xTools suite. Before I go there, I will work on some packaging &amp; productionization things first (scripts for automatic compression &amp; archiving of the captured files, installation via a RPM/DEB package, built-in data visualization). Feel free to submit ideas and issues in the <a href="https://github.com/tanelpoder/0xtools">0x.Tools GitHub repo</a>.</p>

<ul>
  <li>
    <p>I also deliver <a href="https://tanelpoder.com/consulting">consulting</a> and <a href="https://tanelpoder.com/seminar">training</a> around systematic Linux troubleshooting &amp; tuning, including helping you to come up with a strategy for rolling out <strong>always-on profiling for production systems</strong> in your company.</p>
  </li>
  <li>
    <p>Get 0x.Tools updates via Twitter <a href="https://twitter.com/0xtools">@0xtools</a>.</p>
  </li>
</ul>

<h3 id="articles">Articles</h3>

<ul>
  <li>
    <p><a href="https://tanelpoder.com/categories/linux/">Linux performance &amp; troubleshooting</a> articles by Tanel Poder</p>
  </li>
  <li>
    <p><a href="https://youtu.be/YEWp3O7Kem8">Profiling Linux Activity for Performance And Troubleshooting</a> video by Tanel Poder</p>
  </li>
  <li>
    <p><a href="http://mysqlentomologist.blogspot.com/2021/01/linux-proc-filesystem-for-mysql-dbas_8.html">Using 0xtools with MySQL</a> series by <a href="https://twitter.com/mysqlbugs">Valerii Kravchuk</a></p>
  </li>
</ul>

<p><a href="https://0x.tools/#">Back to top</a></p>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI's $600B Question (223 pts)]]></title>
            <link>https://www.sequoiacap.com/article/ais-600b-question/</link>
            <guid>40869461</guid>
            <pubDate>Wed, 03 Jul 2024 19:55:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sequoiacap.com/article/ais-600b-question/">https://www.sequoiacap.com/article/ais-600b-question/</a>, See on <a href="https://news.ycombinator.com/item?id=40869461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
		<article>
	
<section><p>The AI bubble is reaching a tipping point. Navigating what comes next will be essential.</p></section>



<section>
<p>In September 2023, I published <a href="https://www.sequoiacap.com/article/follow-the-gpus-perspective/">AI’s $200B Question</a>. The goal of the piece was to ask the question: “Where is all the revenue?”&nbsp;</p>



<p>At that time, I noticed a big gap between the revenue expectations implied by the AI infrastructure build-out, and actual revenue growth in the AI ecosystem, which is also a proxy for end-user value. I described this as a “$125B hole that needs to be filled <em>for each year of CapEx at today’s levels</em>.”&nbsp;</p>



<p>This week, Nvidia completed its ascent to become the most valuable company in the world. In the weeks leading up to this, I’ve received numerous requests for the updated math behind my analysis. Has AI’s $200B question been solved, or exacerbated?</p>



<p>If you run this analysis again today, here are the results you get: AI’s $200B question is now AI’s $600B question.</p>
</section>



<figure><img fetchpriority="high" decoding="async" width="2410" height="785" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png" alt="" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png 2410w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=300,98 300w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=768,250 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=1024,334 1024w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=1536,500 1536w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=2048,667 2048w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=220,72 220w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=1920,625 1920w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=680,221 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=930,303 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=1440,469 1440w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/06/600B-table-1.png?resize=480,156 480w" sizes="(max-width: 2410px) 100vw, 2410px"></figure>



<section>
<p>Note: It’s easy to calculate this metric directly. All you have to do is to take Nvidia’s run-rate revenue forecast and multiply it by 2x to reflect the total cost of AI data centers (GPUs are half of the total cost of ownership—the other half includes energy, buildings, backup generators, etc)<sup>1</sup>. Then you multiply by 2x again, to reflect a 50% gross margin for the end-user of the GPU, (e.g., the startup or business buying AI compute from Azure or AWS or GCP, who needs to make money as well).</p>



<p>What has changed since September 2023?&nbsp;</p>



<ol>
<li><strong>The supply shortage has subsided: </strong>Late 2023 was the peak of the GPU supply shortage. Startups were calling VCs, calling anyone that would talk to them, asking for help getting access to GPUs. Today, that concern has been almost entirely eliminated. For most people I speak with, it’s relatively easy to get GPUs now with reasonable lead times.</li>



<li><strong>GPU stockpiles are growing:</strong> Nvidia reported in Q4 that about half of its data center revenue came from the large cloud providers. Microsoft alone likely represented approximately <a href="https://platformonomics.com/2024/02/follow-the-capex-triangulating-nvidia/comment-page-1/">22% of Nvidia’s Q4 revenue</a>. Hyperscale CapEx is reaching historic levels. These investments were a major theme of Big Tech Q1 ‘24 earnings, with CEOs effectively telling the market: “We’re going to invest in GPUs whether you like it or not.” Stockpiling hardware is not a new phenomenon, and the catalyst for a reset will be once the stockpiles are large enough that demand decreases.</li>



<li><strong>OpenAI still has the lion’s share of AI revenue:</strong> The Information recently reported that OpenAI’s revenue is now <a href="https://www.theinformation.com/articles/openais-annualized-revenue-doubles-to-3-4-billion-since-late-2023?rc=0uxjjk">$3.4B</a>, up from $1.6B in late 2023. While we’ve seen a handful of startups scale revenues into the &lt;$100M range, the gap between OpenAI and everyone else continues to loom large. Outside of ChatGPT, how many AI products are consumers really using today? Consider how much value you get from Netflix for $15.49/month or Spotify for $11.99. Long term, AI companies will need to deliver significant value for consumers to continue opening their wallets.&nbsp;&nbsp;</li>



<li><strong>The $125B hole is now a $500B hole: </strong>In the last analysis, I generously assumed that each of Google, Microsoft, Apple and Meta will be able to generate $10B annually from new AI-related revenue. I also assumed $5B in new AI revenue for each of Oracle, ByteDance, Alibaba, Tencent, X, and Tesla. Even if this remains true and we add a few more companies to the list, the $125B hole is now going to become a $500B hole.&nbsp;</li>



<li><strong>It’s not over—the B100 is coming</strong>:<strong> </strong>Earlier this year, Nvidia announced their B100 chip, which will have <a href="https://www.nextplatform.com/2024/03/18/with-blackwell-gpus-ai-gets-cheaper-and-easier-competing-with-nvidia-gets-harder/">2.5x better performance</a> for only 25% more cost. I expect this will lead to a final surge in demand for NVDA chips. The B100 represents a dramatic cost vs. performance improvement over the H100, and there will likely be yet another supply shortage as everyone tries to get their hands on B100s later this year.</li>
</ol>



<p>One of the major rebuttals to my last piece was that “GPU CapEx is like building railroads” and eventually the trains will come, as will the destinations—the new agriculture exports, amusement parks, malls, etc. I actually agree with this, but I think it misses a few points:</p>



<ol>
<li><strong>Lack of pricing power:</strong> In the case of physical infrastructure build outs, there is some intrinsic value associated with the infrastructure you are building. If you own the tracks between San Francisco and Los Angeles, you likely have some kind of monopolistic pricing power, because there can only be so many tracks laid between place A and place B. In the case of GPU data centers, there is much less pricing power. GPU computing is increasingly turning into a commodity, metered per hour. Unlike the CPU cloud, which became an oligopoly, new entrants building dedicated AI clouds continue to flood the market. Without a monopoly or oligopoly, high fixed cost + low marginal cost businesses almost always see prices competed down to marginal cost (e.g., airlines).</li>



<li><strong>Investment incineration: </strong>Even in the case of railroads—and in the case of many new technologies—speculative investment frenzies often lead to high rates of capital incineration. <a href="https://www.amazon.com/Engines-That-Markets-Alisdair-Nairn/dp/0857195999">The Engines that Moves Markets</a> is one of the best textbooks on technology investing, and the major takeaway—indeed, focused on railroads—is that a lot of people lose a lot of money during speculative technology waves. It’s hard to pick winners, but much easier to pick losers (canals, in the case of railroads).</li>



<li><strong>Depreciation: </strong>We know from the history of technology that semiconductors tend to get better and better. Nvidia is going to keep producing better next-generation chips like the B100. This will lead to more rapid depreciation of the last-gen chips. Because the market under-appreciates the B100 and the rate at which next-gen chips will improve, it overestimates the extent to which H100s purchased today will hold their value in 3-4 years. Again, this parallel doesn’t exist for physical infrastructure, which does not follow any “Moore’s Law” type curve, such that cost vs. performance continuously improves.&nbsp;</li>



<li><strong>Winners vs. losers:</strong> I think we need to look carefully at winners and losers—there are always winners during periods of excess infrastructure building. AI is likely to be the next transformative technology wave, and as I mentioned in the last piece, declining prices for GPU computing is actually good for long-term innovation and good for startups. If my forecast comes to bear, it will cause harm primarily to investors. Founders and company builders will continue to build in AI—and they will be more likely to succeed, because they will benefit both from lower costs and from learnings accrued during this period of experimentation.&nbsp;</li>
</ol>



<p>A huge amount of economic value is going to be created by AI. Company builders focused on delivering value to end users will be rewarded handsomely. We are living through what has the potential to be a generation-defining technology wave. Companies like Nvidia deserve enormous credit for the role they’ve played in enabling this transition, and are likely to play a critical role in the ecosystem for a long time to come.</p>



<p>Speculative frenzies are part of technology, and so they are not something to be afraid of. Those who remain level-headed through this moment have the chance to build extremely important companies. But we need to make sure not to believe in the delusion that has now spread from Silicon Valley to the rest of the country, and indeed the world. That delusion says that we’re all going to get rich quick, because AGI is coming tomorrow, and we all need to stockpile the only valuable resource, which is GPUs.&nbsp;</p>



<p>In reality, the road ahead is going to be a long one. It will have ups and downs. But almost certainly it will be worthwhile.</p>



<p><em>If you are building in this space, we’d love to hear from you. Please reach out at </em><a href="mailto:dcahn@sequoiacap.com"><em>dcahn@sequoiacap.com</em></a></p>



<ol>
<li>Some commenters challenged my 50% assumption on non-GPU data center costs, which I summarized as energy costs. Nvidia actually came to the exact same metric, which you can see on <a href="https://s201.q4cdn.com/141608511/files/doc_presentations/2023/Oct/01/ndr_presentation_oct_2023_final.pdf">Page 14 of their October 2023</a> analyst day presentation, published a few days after my last piece.</li>
</ol>
</section>











<div data-columns="12">

					<p>
						JOIN OUR MAILING LIST					</p>

					<h2>
						Get the best stories from the Sequoia community.					</h2>

					
					
					

				</div>


</article>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Voice Isolator: Strip background noise for film, podcast, interview production (142 pts)]]></title>
            <link>https://elevenlabs.io/voice-isolator</link>
            <guid>40869421</guid>
            <pubDate>Wed, 03 Jul 2024 19:51:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elevenlabs.io/voice-isolator">https://elevenlabs.io/voice-isolator</a>, See on <a href="https://news.ycombinator.com/item?id=40869421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2>Extract vocals</h2><p>Enhance your audio and clean up vocals with our AI Voice Isolator. Simply upload a file and remove street noise, mic feedback, and any other unwanted background noise. </p></div><div><p><h2>Frequently asked questions</h2></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Luakit: A fast, extensible, and customizable web browser (120 pts)]]></title>
            <link>https://luakit.github.io/</link>
            <guid>40868425</guid>
            <pubDate>Wed, 03 Jul 2024 17:58:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://luakit.github.io/">https://luakit.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40868425">Hacker News</a></p>
<div id="readability-page-1" class="page">
	<nav>
		<a href="#">Home</a>
		<a href="https://luakit.github.io/news/">Releases</a>
		<a href="#sec-download">Download</a>
		<a href="https://luakit.github.io/docs/">Documentation</a>
		<a href="https://luakit.github.io/help/">Help &amp; Support</a>
		<a href="https://luakit.github.io/contributing/">Contributing</a>
		<a href="https://github.com/luakit/luakit" target="_blank">GitHub</a>
	</nav>
	<header>
		<div>
			
			<p>
				A fast, extensible, and<br> customizable web browser
			</p>
		</div>
	</header>
	<section id="sec-description">
		<p>Luakit is a highly configurable browser framework based on the <a href="http://webkit.org/" target="_blank">WebKit</a> web content engine and the <a href="http://gtk.org/" target="_blank">GTK+</a> toolkit. It is very fast, extensible with <a href="http://lua.org/" target="_blank">Lua</a>, and licensed under the <a href="https://raw.github.com/luakit/luakit/develop/COPYING.GPLv3" target="_blank">GNU GPLv3</a>
			license.  It is primarily targeted at power users, developers and anyone who wants to have fine-grained control over their web browser’s behaviour and
			interface.</p>
	</section>
	<section id="sec-release">
		<p>
			<h2>Latest release — <a href="https://luakit.github.io/news/luakit-2.3.6.html">Luakit 2.3.6</a></h2>
			<h3>... or view the <a href="https://luakit.github.io/news/index.html">list of older releases</a></h3>
		</p>
	</section>
	<div id="sec-screenshots">
			<h2>Screenshots</h2>

			<div><div>
					<p><a href="https://luakit.github.io/screenshots/1.png"><img src="https://luakit.github.io/thumbs/1.png" alt="Screenshot of Luakit."></a></p><p>Luakit in normal mode when reading a web page.</p>
				</div><div>
					<p><a href="https://luakit.github.io/screenshots/2.png"><img src="https://luakit.github.io/thumbs/2.png" alt="Screenshot of Luakit."></a></p><p>Luakit in follow mode with several link hints visible.</p>
				</div><div>
					<p><a href="https://luakit.github.io/screenshots/3.png"><img src="https://luakit.github.io/thumbs/3.png" alt="Screenshot of Luakit."></a></p><p>Luakit showing the ad blocker settings page, listing currently active filter lists.</p>
				</div><div>
					<p><a href="https://luakit.github.io/screenshots/4.png"><img src="https://luakit.github.io/thumbs/4.png" alt="Screenshot of Luakit."></a></p><p>Luakit with a different theme and with vertical tabs enabled.</p>
			</div></div>
		</div>
	<div id="sec-download">
			<h2>Downloading Luakit</h2>

			<h3>Supported Operating Systems</h3>

			
                        <p><small><sup>*</sup>Not actively supported, but known to work.</small>
		</p></div>

	<div id="security-notice">
			<h3>Important WebKit Security Notice</h3>

			<p>While switching to the
			WebKit 2 API means a vastly improved security situation, not all distributions of Linux package the
			most up-to-date version of WebKitGTK+, and several package very outdated versions that
			have many known vulnerabilities. As of September 2019, Arch, Debian, Fedora,
			Gentoo, and Ubuntu all have the latest version of WebKitGTK+, but
			OpenSUSE ships an outdated and vulnerable version in their
			stable channel.

			</p><p>If you use Luakit for browsing, it is <i>your</i> responsibility to ensure that
			your distribution packages an up-to-date version of WebKitGTK+!</p>
		</div>

	<div>
			<h3>Installing on Windows 10</h3>
			<ol>
				<li><p>First, install the <a href="https://msdn.microsoft.com/en-us/commandline/wsl/install_guide" target="_blank">Windows Subsystem for Linux</a> if you have not already done so, as WebKitGTK+ does not natively support Windows.
				</p></li><li><p>Download, build, and install luakit from source, following the instructions below.
			</p></li></ol>
		</div>


	<div>
			<h3>Installing on Linux</h3>
			<ul>
				<li><p>Arch Linux users can install the <a href="https://archlinux.org/packages/community/x86_64/luakit/">luakit</a> community package or the
					<a href="https://aur.archlinux.org/packages/luakit-git/" target="_blank">luakit-git</a> package from the AUR.
				</p></li><li><p>Other users will need to download and build from source. A Debian package is in the works. Luakit contains only around 9000 lines of code, so this process is usually very fast.
			</p></li></ul>
		</div>

	<div>
			<h3>Installing on BSD</h3>
			<p>FreeBSD and OpenBSD users can install the <code>luakit</code> package.</p>
			<p>When installing from source, OpenBSD users should build with clang instead of GCC, as the GCC version shipped with OpenBSD is outdated and its use will result in compilation errors.</p>
		</div>

	<div>
			<h3>Installing from source</h3>
			<ol>
				<li><p>Ensure you have the following required dependencies installed:</p>
				<ul>
					<li><a href="https://www.gtk.org/" target="_blank">GTK 3</a></li>
					<li><a href="https://webkitgtk.org/" target="_blank">WebKitGTK+</a> (webkit2gtk)</li>
					<li><a href="https://www.lua.org/" target="_blank">Lua 5.1</a> or <a href="http://luajit.org/" target="_blank">LuaJIT</a></li>
					<li><a href="https://keplerproject.github.io/luafilesystem/" target="_blank">lfs (Lua File System)</a></li>
					<li><a href="https://sqlite.org/" target="_blank">SQLite 3</a></li>
				</ul>
				</li><li><p>Download the latest development version:
				<a href="https://github.com/luakit/luakit/zipball/develop">zip</a>,
				<a href="https://github.com/luakit/luakit/tarball/develop">tar</a>.
				Alternatively, clone the project with <a href="http://git-scm.com/" target="_blank">Git</a>
				by running:</p><pre>git clone git://github.com/luakit/luakit</pre>
				</li><li><p>Change into the target directory and run <code>make install</code>. You will probably also want to customize the prefix, which is <code>/usr/local</code> by default.
				Full instructions on building Luakit are available in the <code>README.md</code> file.</p>
				</li><li><p>After successfully building and installing luakit, run <code>luakit</code> from the command line or launch luakit from your application launcher.</p>
			</li></ol>
		</div>

	


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A practical introduction to constraint programming using CP-SAT and Python (171 pts)]]></title>
            <link>https://pganalyze.com/blog/a-practical-introduction-to-constraint-programming-using-cp-sat</link>
            <guid>40867746</guid>
            <pubDate>Wed, 03 Jul 2024 16:48:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pganalyze.com/blog/a-practical-introduction-to-constraint-programming-using-cp-sat">https://pganalyze.com/blog/a-practical-introduction-to-constraint-programming-using-cp-sat</a>, See on <a href="https://news.ycombinator.com/item?id=40867746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine you're an e-commerce giant that would like to build a new warehouse to improve service to your customers, but you need to know what is the best location for it. Or you're a global shipping company that assigns packages to their delivery trucks and has to choose the best routes in order to save gas and reduce driver overtime. Or an airline that is looking to offer service to a new location, and needs to know which types of planes they should use and on what schedule, to maximize the resulting revenue.</p>
<p>These kinds of problems mentioned above are known as <strong>discrete optimization problems</strong>. There exist several methods that can be used to tackle such problems. In this article, we will discuss the theory and practice for one of them, called <strong><a href="https://en.wikipedia.org/wiki/Constraint_programming">constraint programming</a></strong>.</p>
<p>This is the first part in a two part series on constraint programming, used inside <a href="https://pganalyze.com/docs/indexing-engine/cp-model">pganalyze Indexing Engine</a> and <a href="https://pganalyze.com/docs/index-advisor/getting-started">pganalyze Index Advisor</a>. We're sharing this knowledge to help the wider programming community become familiar with how to utilize solvers like <a href="https://developers.google.com/optimization/cp/cp_solver">CP-SAT</a> in practice.</p>
<div>
<ul>
<li>
<p><a href="#a-declarative-paradigm">A declarative paradigm</a></p>
</li>
<li>
<p><a href="#the-basics-of-constraint-programming-cp">The basics of constraint programming (CP)</a></p>
</li>
<li>
<p><a href="#a-practical-example-with-python-and-cp-sat">A practical example with Python and CP-SAT</a></p>
<ul>
<li><a href="#an-empty-model">An empty model</a></li>
<li><a href="#the-data">The data</a></li>
<li><a href="#the-variables">The variables</a></li>
<li><a href="#the-constraints">The constraints</a></li>
<li><a href="#solving-the-model">Solving the model</a></li>
<li><a href="#adding-more-constraints">Adding more constraints</a></li>
<li><a href="#interlude-the-solver-status">Interlude: The solver status</a></li>
<li><a href="#sorry-emma">"Sorry, Emma"</a></li>
<li><a href="#objective-distributing-the-shifts-more-evenly">Objective: Distributing the shifts more evenly</a></li>
</ul>
</li>
<li>
<p><a href="#concluding-remarks">Concluding remarks</a></p>
</li>
</ul>
</div>
<h2 id="a-declarative-paradigm"><a href="#a-declarative-paradigm" aria-label="a declarative paradigm permalink"></a>A declarative paradigm</h2>
<p>Constraint programming (CP) is a declarative paradigm used to solve discrete optimization problems. This contrasts with the imperative paradigm that we are generally used to. When programming imperatively, we describe the steps necessary to reach a result. For example, suppose that we want to know who the adults are from a given list of people:</p>








<table><colgroup>
<col></colgroup><colgroup><col>
</colgroup><thead><tr><th scope="col">Name</th><th scope="col">Age</th></tr></thead><tbody><tr><td>Phil</td><td>20</td></tr><tr><td>Emma</td><td>17</td></tr><tr><td>David</td><td>11</td></tr><tr><td>Thomas</td><td>51</td></tr><tr><td>Sarah</td><td>45</td></tr><tr><td>Rebecca</td><td>6</td></tr></tbody></table>
<p>A typical imperative approach would explain the sequence of operations required to get the desired result:</p>
<div data-language="python"><pre><code>adult_people <span>=</span> <span>[</span><span>]</span>
<span>for</span> person <span>in</span> people<span>:</span>
    <span>if</span> person<span>.</span>Age <span>&gt;=</span> <span>18</span><span>:</span>
        adult_people <span>+=</span> person<span>.</span>Name</code></pre></div>

<p>Meanwhile, the same result can be described declaratively as:</p>
<div data-language="sql"><pre><code><span>SELECT</span> person_name <span>FROM</span> people <span>WHERE</span> age <span>&gt;=</span> <span>18</span><span>;</span></code></pre></div>

<p>Both approaches are equivalent in their outcome, but the two processes are different. In the imperative case, the program follows each step in sequence in order to reach the result. In the declarative case, the program is given a description of the desired result (using the available constructs of the language) and gets there by itself.</p>
<h2 id="the-basics-of-constraint-programming-cp"><a href="#the-basics-of-constraint-programming-cp" aria-label="the basics of constraint programming cp permalink"></a>The basics of constraint programming (CP)</h2>
<p>Similarly to the declarative example mentioned above, with CP we describe the desired result to a problem. This description is called a <strong>model</strong>. The main components of a model are variables and constraints. Variables represent <strong>what</strong> we are looking for, and each variable has an associated <strong>domain</strong> which is the set of values that this variable is allowed to take. Constraints describe <strong>relationships</strong> between variables.</p>
<p>A solution is an assignment of values to the variables (from their domains) such that the constraints are satisfied. Let's jump straight in with a simple example:</p>
<blockquote>
<div><p>Alice, Bob, and Carol each have $20, and they want to pool their money to purchase a candy bar worth $50 (yes, inflation is running wild). Alice has stated that she will put in at least as much money as Bob. Carol only has $5 bills, so her contribution will be a multiple of that. None of them want to contribute the exact same amount as any other.
</p><p>
How much should each of them chip in?</p></div>
</blockquote>
<p>Here, we are looking for the amount of money each person should contribute to the purchase of the candy bar. This means that we need one variable per person, indicating the amount of money that this person should contribute toward the purchase (<code>a</code> for Alice, <code>b</code> for Bob, and <code>c</code> for Carol). We start by setting the domains of these variables (the symbol <code>∈</code> means "in"):</p>
<div data-language="text"><pre><code>a ∈ {0, ..., 20}
b ∈ {0, ..., 20}
c ∈ {0, ..., 20}</code></pre></div>
<p>These domains ensure that the final values of the variables represent amounts of money that the contributors actually have in their pockets (that is, a maximum of $20). Next, we want to make sure that the combined contributions are enough to cover the price of the candy bar, so we add the constraint:</p>

<p>Alice will contribute at least as much as Bob, so we translate this into:</p>

<p>Carol's contribution must be a multiple of 5:</p>

<p>Finally, the amount of each of their contributions must be unique. We could model this using the following constraints:</p>

<p>We only have a handful of people in this example so these disequalities would work well. But what if they were hundreds, or thousands? It turns out that CP has a rich catalogue of expressive constraints that can encapsulate complex concepts, called <strong>global constraints</strong>. An alternative to the above would be to use the so-called <code>alldifferent</code> constraint, which ensures that a set of variables are all assigned different values:</p>

<p>This completes the model of this problem. You will note that we have not assigned any values to <code>a</code>, <code>b</code>, or <code>c</code> ourselves. We have simply defined three variables and their domains, and described the properties of the problem using constraints on those variables. Our job is done.</p>
<p>The piece of software that interprets this model and returns a solution is called a <strong>solver</strong>. The inner workings of a solver are outside the scope of this article, so for our purposes we will consider the solver as a black box that takes a model as input, and returns a valid solution:</p>

<p>The solution returned is valid as each variable takes a value from its domain and all the constraints are satisfied. However, we see that Carol contributes almost twice Bob's amount. Perhaps there exists another valid solution where all parties contribute more equally to the purchase?</p>
<p>We can add an <strong>objective</strong> to our CP model to try to reach this goal. Adding an objective to a model allows us to minimize or maximize an expression, without compromising the validity of the resulting solution (with respect to the constraints). If we can somehow minimize the amount of money spent by the largest contributor, this should push the three contributions closer together. Our objective will then be to find a valid solution where this value is minimal:</p>
<div data-language="text"><pre><code>x ∈ {0, ..., 20}
maximum(x, [a, b, c])
minimize: x</code></pre></div>
<p>To achieve this, we create a new variable <code>x</code> representing the amount of the largest contribution. The <code>maximum</code> constraint takes care of assigning to <code>x</code> the largest value from <code>[a, b, c]</code>. The objective is then to minimize <code>x</code>. The solution returned by the solver is now:</p>
<div data-language="text"><pre><code>a = 18
b = 17
c = 15
x = 18</code></pre></div>
<p>Previously there was a $9 difference between the largest and smallest contributions. With the objective we introduced this has now been reduced to $3, and this is as fair as this is going to get. Now that the basic concepts are cleared up, let's move on to a more challenging problem.</p>
<h2 id="a-practical-example-with-python-and-cp-sat"><a href="#a-practical-example-with-python-and-cp-sat" aria-label="a practical example with python and cp sat permalink"></a>A practical example with Python and CP-SAT</h2>
<p>Let's use this new CP knowledge to solve a more complex real-world example: the scheduling of employees for a small business.</p>
<blockquote>
<div><p>A store owner wishes to create the weekly work schedule for its employees. The store is open from 8AM to 8PM every day, and each day is divided into three shifts of 4 hours: morning, afternoon, and evening. There are two roles in the store: cashier and restocker.
</p></div>
<ul>
<li>
<p>Some employees are qualified to do either role, but others can only be a cashier, or a restocker.</p>
</li>
<li>
<p>There has to be a cashier scheduled at all times, but restocking only takes about 4 hours every day. Hence, for the restocking task we only need to schedule an employee for a single shift every day. This can be any shift, but two restocking shifts cannot be scheduled one after the other. If a restocking is scheduled on the evening shift on Tuesday, for example, we cannot schedule the Wednesday restocking on the morning shift.</p>
</li>
<li>
<p>An employee that is qualified in both roles can still only be assigned to one role per shift.</p>
</li>
<li>
<p>Employees cannot work more than 8 hours per day, which is 2 shifts. If they do work 2 shifts in a day, we must ensure that there is no idle time between these shifts—for example, we can't schedule them on both the morning and the evening shifts of the same day, as they would be idle for 4 hours during the afternoon shift.</p>
</li>
</ul>
</blockquote>
<p>This is the basic premise of the problem. Let's break this down into manageable parts.</p>
<h3 id="an-empty-model"><a href="#an-empty-model" aria-label="an empty model permalink"></a>An empty model</h3>
<p>We first start by creating an empty model using <a href="https://developers.google.com/optimization/cp/cp_solver">CP-SAT</a>, an open-source CP solver developed by Google as part of it's <a href="https://developers.google.com/optimization">OR-Tools</a> project.</p>
<div data-language="python"><pre><code><span>from</span> ortools<span>.</span>sat<span>.</span>python <span>import</span> cp_model

model <span>=</span> cp_model<span>.</span>CpModel<span>(</span><span>)</span></code></pre></div>
<h3 id="the-data"><a href="#the-data" aria-label="the data permalink"></a>The data</h3>
<blockquote>
<p>A store owner wishes to create the <span>weekly work schedule</span> for its <span>employees</span>. The store is open from 8AM to 8PM every day, and each day is divided into <span>three shifts</span> of 4 hours: <span>morning, afternoon, and evening</span>. There are <span>two roles</span> in the store: <span>cashier and restocker</span>. Some employees are <span>qualified</span> to do either role, but others can only be a cashier, or a restocker.</p>
</blockquote>
<p>Let's create a list of employees and the roles they are qualified for:</p>
<div data-language="python"><pre><code>employees <span>=</span> <span>{</span><span>"Phil"</span><span>:</span> <span>[</span><span>"Restocker"</span><span>]</span><span>,</span>
             <span>"Emma"</span><span>:</span> <span>[</span><span>"Cashier"</span><span>,</span> <span>"Restocker"</span><span>]</span><span>,</span>
             <span>"David"</span><span>:</span> <span>[</span><span>"Cashier"</span><span>,</span> <span>"Restocker"</span><span>]</span><span>,</span>
             <span>"Rebecca"</span><span>:</span> <span>[</span><span>"Cashier"</span><span>]</span><span>}</span></code></pre></div>
<p>The schedule is said to span a week, and we are told that there are three types of shifts, and two types of roles:</p>
<div data-language="python"><pre><code>days <span>=</span> <span>[</span><span>"Monday"</span><span>,</span>
        <span>"Tuesday"</span><span>,</span>
        <span>"Wednesday"</span><span>,</span>
        <span>"Thursday"</span><span>,</span>
        <span>"Friday"</span><span>,</span>
        <span>"Saturday"</span><span>,</span>
        <span>"Sunday"</span><span>]</span>

shifts <span>=</span> <span>[</span><span>"Morning"</span><span>,</span>
          <span>"Afternoon"</span><span>,</span>
          <span>"Evening"</span><span>]</span>

roles <span>=</span> <span>[</span><span>"Cashier"</span><span>,</span>
         <span>"Restocker"</span><span>]</span></code></pre></div>
<h3 id="the-variables"><a href="#the-variables" aria-label="the variables permalink"></a>The variables</h3>
<p>Now, let's define <strong>what</strong> we are looking for. To describe the schedule, we need to refer to employees, roles, days, and shifts: <strong>Does Emma work as a restocker on the Monday evening shift?</strong> This can be achieved using boolean variables. A boolean variable is a variable with a domain of <code>{0, 1}</code>.</p>
<div data-language="python"><pre><code>schedule <span>=</span> <span>{</span>e<span>:</span>
             <span>{</span>r<span>:</span>
               <span>{</span>d<span>:</span>
                 <span>{</span>s<span>:</span> model<span>.</span>new_bool_var<span>(</span><span><span>f"schedule_</span><span><span>{</span>e<span>}</span></span><span>_</span><span><span>{</span>r<span>}</span></span><span>_</span><span><span>{</span>d<span>}</span></span><span>_</span><span><span>{</span>s<span>}</span></span><span>"</span></span><span>)</span>
                   <span>for</span> s <span>in</span> shifts<span>}</span>
                 <span>for</span> d <span>in</span> days<span>}</span>
               <span>for</span> r <span>in</span> roles<span>}</span>
             <span>for</span> e <span>in</span> employees<span>}</span></code></pre></div>
<p>The function <code>model.new_bool_var()</code> creates and then returns a boolean variable, which we store in <code>schedule</code>. Within this structure, <code>schedule["Emma"]["Restocker"]["Monday"]["Evening"]</code> refers to one of those boolean variables. This variable is equal to <code>1</code> if Emma <strong>does</strong> work as a restocker on the Monday evening shift, or to <code>0</code> if she <strong>doesn't</strong>.</p>
<p>Our <code>schedule</code> variables are currently unconstrained. By following the problem description presented earlier and constraining these variables accordingly, we should be able to get a schedule that satisfies the requirements of the store owner.</p>
<h3 id="the-constraints"><a href="#the-constraints" aria-label="the constraints permalink"></a>The constraints</h3>
<p>Let's go through the rest of the problem description to correctly constrain the <code>schedule</code> variables. To add a new constraint to the model, we simply use <code>model.add(...)</code>.</p>
<blockquote>
<p>There has to be a <span>cashier</span> scheduled at <span>all times</span>.</p>
</blockquote>
<p>Since the schedule is comprised of boolean variables, it's easy to see how we can put limits on subsets of these variables by summing them and enforcing constraints on these sums:</p>
<div data-language="python"><pre><code><span>for</span> d <span>in</span> days<span>:</span>
    <span>for</span> s <span>in</span> shifts<span>:</span>
        model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span><span>"Cashier"</span><span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> e <span>in</span> employees<span>)</span> <span>==</span> <span>1</span><span>)</span></code></pre></div>
<p>If we need a cashier at all times, this means that for every day-shift pair, the sum of employees assigned the <code>"Cashier"</code> role has to be equal to <code>1</code>.</p>
<blockquote>
<p>For the <span>restocking</span> task we only need to schedule an employee for <span>a single shift every day</span>.</p>
</blockquote>
<p>Similarly to the previous constraint, we now want the sum of all employees assigned the <code>"Restocker"</code> role for all shifts of a given day to be equal to <code>1</code>:</p>
<div data-language="python"><pre><code><span>for</span> d <span>in</span> days<span>:</span>
    model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span><span>"Restocker"</span><span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> e <span>in</span> employees <span>for</span> s <span>in</span> shifts<span>)</span> <span>==</span> <span>1</span><span>)</span></code></pre></div>
<blockquote>
<p>This [restocking] can be any shift, but <span>two restocking shifts cannot be scheduled one after the other</span>.</p>
</blockquote>
<p>Because of the previous constraint, we already know that two restocking shifts cannot take place on the same day. The only way two restocking shifts could be scheduled one after the other would be to assign one on the evening shift of a day, and another one on the morning shift of the next day. By enforcing that the sum of restocking shifts for each evening-morning pair is not greater than <code>1</code>, we ensure that <strong>at most one</strong> restocking shift is scheduled for those pairs:</p>
<div data-language="python"><pre><code><span>for</span> i <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span>days<span>)</span><span>-</span><span>1</span><span>)</span><span>:</span>
    model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span><span>"Restocker"</span><span>]</span><span>[</span>days<span>[</span>i<span>]</span><span>]</span><span>[</span><span>"Evening"</span><span>]</span> <span>+</span> schedule<span>[</span>e<span>]</span><span>[</span><span>"Restocker"</span><span>]</span><span>[</span>days<span>[</span>i<span>+</span><span>1</span><span>]</span><span>]</span><span>[</span><span>"Morning"</span><span>]</span> <span>for</span> e <span>in</span> employees<span>)</span> <span>&lt;=</span> <span>1</span><span>)</span></code></pre></div>
<blockquote>
<p>An <span>employee</span> that is qualified in both roles can still <span>only be assigned to one role per shift</span>.</p>
</blockquote>
<p>For every employee, the sum of all assigned roles for all day-shift pairs is either going to be <code>1</code> (they work a <em>single</em> role on this day-shift slot), or <code>0</code> (they don't work on that day-shift slot):</p>
<div data-language="python"><pre><code><span>for</span> e <span>in</span> employees<span>:</span>
    <span>for</span> d <span>in</span> days<span>:</span>
        <span>for</span> s <span>in</span> shifts<span>:</span>
            model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles<span>)</span> <span>&lt;=</span> <span>1</span><span>)</span></code></pre></div>
<blockquote>
<p>Some employees are qualified to do either role, but <span>others can only be a cashier, or a restocker</span>.</p>
</blockquote>
<p>To prevent an employee from being assigned a role that they are not qualified for, we simply match the value of that role to 0 (or put differently, we're adding a constraint asserting that it's zero) everywhere for that employee:</p>
<div data-language="python"><pre><code><span>for</span> e <span>in</span> employees<span>:</span>
    <span>for</span> r <span>in</span> roles<span>:</span>
        <span>for</span> d <span>in</span> days<span>:</span>
            <span>for</span> s <span>in</span> shifts<span>:</span>
                <span>if</span> r <span>not</span> <span>in</span> employees<span>[</span>e<span>]</span><span>:</span>
                    model<span>.</span>add<span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>==</span> <span>0</span><span>)</span></code></pre></div>
<blockquote>
<p><span>Employees cannot work more</span> than 8 hours per day, which is <span>2 shifts</span>. If they do work 2 shifts in a day, we must ensure that there is <span>no idle time between these shifts</span>—in other words, we can't schedule them on both the morning and the evening shifts of the same day, as they would be idle for 4 hours during the afternoon shift.</p>
</blockquote>
<p>It turns out that a single constraint can take care of both of these requirements: An employee can work <strong>either</strong> the morning shift, <strong>or</strong> the evening shift, <strong>or</strong> neither of these shifts:</p>
<div data-language="python"><pre><code><span>for</span> e <span>in</span> employees<span>:</span>
    <span>for</span> d <span>in</span> days<span>:</span>
        model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span><span>"Morning"</span><span>]</span> <span>+</span> schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span><span>"Evening"</span><span>]</span> <span>for</span> r <span>in</span> roles<span>)</span> <span>&lt;=</span> <span>1</span><span>)</span></code></pre></div>
<p>Note that the above constraint does not need to specify anything about the afternoon shift. If the employee works in the morning, they can't work in the evening, and vice-versa. This both ensures that the employee works a maximum of two shifts per day, and also that there is no idle time, since there can only be idle time if the employee works both the morning <strong>and</strong> the evening shift.</p>
<p>The modeling of the problem is now complete. Let's see what the results are.</p>
<h3 id="solving-the-model"><a href="#solving-the-model" aria-label="solving the model permalink"></a>Solving the model</h3>
<p>To solve the model, we simply call a solver, with the model as an argument:</p>
<div data-language="python"><pre><code>solver <span>=</span> cp_model<span>.</span>CpSolver<span>(</span><span>)</span>

solver<span>.</span>solve<span>(</span>model<span>)</span></code></pre></div>
<p>After the solving process, we can get the resulting values of the <code>schedule</code> variables with <code>solver.value(...)</code>. We have organized these values in the schedule shown below:</p>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   7   |
Emma       |   |   |   | C |   |   | C |   |   | C |   |   | C |   |   | C |   |   | C |   |   |   6   |
David      | C |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   1   |
Rebecca    |   | C | C |   | C | C |   | C | C |   | C | C |   | C | C |   | C | C |   | C | C |  14   |</code></pre></div>
<p>The resulting schedule satisfies the constraints of the problem. Now let's think of additional real-world constraints that would make this more interesting.</p>
<h3 id="adding-more-constraints"><a href="#adding-more-constraints" aria-label="adding more constraints permalink"></a>Adding more constraints</h3>
<p>We see that Rebecca works 14 shifts for that week. The store owner is not keen on paying overtime wages, so they wish to cap each employee's schedule to a maximum of 40 hours per week (10 work shifts):</p>
<div data-language="python"><pre><code><span>for</span> e <span>in</span> employees<span>:</span>
    model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> days <span>for</span> s <span>in</span> shifts<span>)</span> <span>&lt;=</span> <span>10</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   | R |   |   7   |
Emma       |   | C | C |   | C | C | C |   |   | C |   |   | C |   |   | C |   |   | C |   |   |   9   |
David      | C |   |   | C |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   2   |
Rebecca    |   |   |   |   |   |   |   | C | C |   | C | C |   | C | C |   | C | C |   | C | C |  10   |</code></pre></div>
<p>Phil is a full-time student and would like to work exactly 4 shifts per week. He also cannot work the morning and afternoon shifts during the week, in order to attend his classes.</p>
<div data-language="python"><pre><code>model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span><span>"Phil"</span><span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> days <span>for</span> s <span>in</span> shifts<span>)</span> <span>==</span> <span>4</span><span>)</span>

model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span><span>"Phil"</span><span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> days <span>if</span> d <span>not</span> <span>in</span> <span>[</span><span>"Saturday"</span><span>,</span> <span>"Sunday"</span><span>]</span> <span>for</span> s <span>in</span> shifts <span>if</span> s <span>in</span> <span>[</span><span>"Morning"</span><span>,</span> <span>"Afternoon"</span><span>]</span><span>)</span> <span>==</span> <span>0</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   |   |   |   |   | R |   |   | R |   |   | R |   |   |   |   | R |   |   |   |   |   4   |
Emma       | C | R |   |   |   | C | C |   |   | C |   |   | C | R |   | C |   |   | C | R |   |  10   |
David      |   | C | C | C | C |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   4   |
Rebecca    |   |   |   |   |   |   |   | C | C |   | C | C |   | C | C |   | C | C |   | C | C |  10   |</code></pre></div>
<p>Phil and Emma do not get along very well, and as such we don't want them working the same shifts.</p>
<div data-language="python"><pre><code><span>for</span> d <span>in</span> days<span>:</span>
    <span>for</span> s <span>in</span> shifts<span>:</span>
        model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> e <span>in</span> <span>[</span><span>"Phil"</span><span>,</span> <span>"Emma"</span><span>]</span> <span>for</span> r <span>in</span> roles<span>)</span> <span>&lt;=</span> <span>1</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   |   | R |   |   | R |   |   | R |   |   | R |   |   |   |   |   |   |   |   |   |   4   |
Emma       | C |   |   | C | C |   | C | C |   | C | C |   | C | C |   |   | C |   |   |   |   |  10   |
David      |   | C | C |   |   | C |   |   | C |   |   | C |   | R |   |   | R | C | C | R |   |  10   |
Rebecca    |   |   |   |   |   |   |   |   |   |   |   |   |   |   | C | C |   |   |   | C | C |   4   |</code></pre></div>
<p>No employee really likes to work on the weekend, so we would like to distribute these shifts equally between all employees. There are 8 such shifts (3 cashier shifts and 1 restocker shift on each day), and since we have 4 employees, we can give them all 2 shifts each for the weekend.</p>
<div data-language="python"><pre><code><span>for</span> e <span>in</span> employees<span>:</span>
    model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> <span>[</span><span>"Saturday"</span><span>,</span> <span>"Sunday"</span><span>]</span> <span>for</span> s <span>in</span> shifts<span>)</span> <span>==</span> <span>2</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   |   |   |   |   | R |   |   | R |   |   |   |   |   |   | R |   |   | R |   |   |   4   |
Emma       | R | C |   | C | C |   | C |   |   |   |   | C |   | C | C |   |   |   |   | C | C |  10   |
David      | C |   |   |   |   | C |   | C | C | C | R |   | C | R |   |   |   | C | C |   |   |  10   |
Rebecca    |   |   | C |   |   |   |   |   |   |   | C |   |   |   |   | C | C |   |   |   |   |   4   |</code></pre></div>
<p>Emma would like to take Monday to Friday off, and asks us if this is possible. Let's see:</p>
<div data-language="python"><pre><code>model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span><span>"Emma"</span><span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> <span>[</span><span>"Monday"</span><span>,</span> <span>"Tuesday"</span><span>,</span> <span>"Wednesday"</span><span>,</span> <span>"Thursday"</span><span>,</span> <span>"Friday"</span><span>]</span> <span>for</span> s <span>in</span> shifts<span>)</span> <span>==</span> <span>0</span><span>)</span></code></pre></div>

<p>The solver returns a status of "infeasible". What does this mean?</p>
<h3 id="interlude-the-solver-status"><a href="#interlude-the-solver-status" aria-label="interlude the solver status permalink"></a>Interlude: The solver status</h3>
<p>The solver takes as input a model, and returns a status and a solution. Consider this simple case:</p>
<div data-language="text"><pre><code>x ∈ {0, ..., 10}
y ∈ {0, ..., 10}
x + y &gt;= 5
minimize: x + y

Status: OPTIMAL
x = 5
y = 0</code></pre></div>
<p>The variables <code>x</code> and <code>y</code> both have the domain <code>{0, ..., 10}</code>. The sum of the values assigned to them must be 5 or greater, and the objective is to minimize this sum. The solution <code>(x, y) = (5, 0)</code> is called <strong>optimal</strong>. A solution is optimal when there does not exist another solution that is <strong>strictly better</strong> than it. For instance, the solution <code>(x, y) = (3, 2)</code> would also be optimal.</p>
<p>Now consider the case:</p>
<div data-language="text"><pre><code>x ∈ {0, ..., 10}
x &gt;= 15

Status: INFEASIBLE</code></pre></div>
<p>An <strong>infeasible</strong> status means that there exists no assignment of values to the variables such that the constraints are satisfied. In the above example, it is not possible to assign a value to <code>x</code> that is at least as large as 15, since the largest value in its domain is 10.</p>
<p>There are also other possibilities. Let's take a look at this last example:</p>
<div data-language="text"><pre><code>x ∈ {0, ..., 10}
y ∈ {0, ..., 10}
...  // Many more variables
x + y &lt;= 12
x &gt;= 5
... // Many more constraints
minimize: x - 3*y + ...  // Very complex objective</code></pre></div>
<p>Sometimes, a problem is so large and complex, and takes so much time to solve, that we must interrupt the solver due to time constraints. In such a case, the solver will return one of two statuses:</p>
<ul>
<li>If a solution has been found, the status returned is <strong>feasible</strong>. A feasible solution means that the solution satisfies the constraints, but the solver does not know if that solution is optimal. In other words, we have a solution that works, but there may still exist a better one.</li>
<li>If no solution has been found, the status returned is <strong>unknown</strong>. This means that while the solver has not found a solution, it does not know whether one exists (feasible) or if the problem has no solution (infeasible).</li>
</ul>
<p>Let's get back to our schedule.</p>
<h3 id="sorry-emma"><a href="#sorry-emma" aria-label="sorry emma permalink"></a>"Sorry, Emma"</h3>
<p>With the infeasible status returned to us previously, we are forced to inform Emma that she can't take the whole week off, otherwise it would be impossible to fill the schedule without violating some of the other constraints. She decides to only take Monday to Wednesday off instead:</p>
<div data-language="python"><pre><code>model<span>.</span>add<span>(</span><span>sum</span><span>(</span>schedule<span>[</span><span>"Emma"</span><span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> <span>[</span><span>"Monday"</span><span>,</span> <span>"Tuesday"</span><span>,</span> <span>"Wednesday"</span><span>]</span> <span>for</span> s <span>in</span> shifts<span>)</span> <span>==</span> <span>0</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   |   | R |   |   |   |   |   | R |   |   |   |   |   |   | R |   |   | R |   |   |   4   |
Emma       |   |   |   |   |   |   |   |   |   |   | R | C |   | R | C |   |   |   |   | C | C |   6   |
David      | C |   |   | C | R |   | C |   |   | C | C |   | C | C |   |   |   | C | C |   |   |  10   |
Rebecca    |   | C | C |   | C | C |   | C | C |   |   |   |   |   |   | C | C |   |   |   |   |   8   |</code></pre></div>
<p>Phil works exactly 4 shifts as he wants, but the other shifts are not very well distributed: Emma gets 6, David gets 10, and Rebecca gets 8. Let's see if we can improve this by adding an objective.</p>
<h3 id="objective-distributing-the-shifts-more-evenly"><a href="#objective-distributing-the-shifts-more-evenly" aria-label="objective distributing the shifts more evenly permalink"></a>Objective: Distributing the shifts more evenly</h3>
<p>We would like to distribute the shifts as fairly as possible between Emma, David, and Rebecca. We will recall that an objective allows us to minimize the value of an expression. We could, for example, minimize the shift difference between the employee who is assigned the fewest shifts, and the one who is assigned the most. Currently, Emma is assigned 6 shifts to David's 10, so this difference stands at 4 shifts.</p>
<p>We start by creating integer variables to track the number of shifts assigned to each employee, and enforcing the values of these variables:</p>
<div data-language="python"><pre><code><span># total_shifts[e] indicates the number of shifts worked by employee `e`</span>
total_shifts <span>=</span> <span>{</span>e<span>:</span> model<span>.</span>new_int_var<span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span><span>f"total_shifts_</span><span><span>{</span>e<span>}</span></span><span>"</span></span><span>)</span>
                <span>for</span> e <span>in</span> employees<span>}</span>

<span>for</span> e <span>in</span> employees<span>:</span>
    model<span>.</span>add<span>(</span>total_shifts<span>[</span>e<span>]</span> <span>==</span> <span>sum</span><span>(</span>schedule<span>[</span>e<span>]</span><span>[</span>r<span>]</span><span>[</span>d<span>]</span><span>[</span>s<span>]</span> <span>for</span> r <span>in</span> roles <span>for</span> d <span>in</span> days <span>for</span> s <span>in</span> shifts<span>)</span><span>)</span></code></pre></div>
<p>Integer variables are created with <code>model.new_int_var(...)</code>, and the parameters allow us to specify the lower and upper bounds of the domain (in this case, the domain is <code>{0, ..., 10}</code>). We then create variables to track the highest and lowest number of shifts assigned to any employee (with the exception of Phil, who works part-time):</p>
<div data-language="python"><pre><code>min_shifts <span>=</span> model<span>.</span>new_int_var<span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>"min_shifts"</span><span>)</span>
model<span>.</span>add_min_equality<span>(</span>min_shifts<span>,</span> <span>[</span>total_shifts<span>[</span>e<span>]</span> <span>for</span> e <span>in</span> employees <span>if</span> e <span>!=</span> <span>"Phil"</span><span>]</span><span>)</span>

max_shifts <span>=</span> model<span>.</span>new_int_var<span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>"max_shifts"</span><span>)</span>
model<span>.</span>add_max_equality<span>(</span>max_shifts<span>,</span> <span>[</span>total_shifts<span>[</span>e<span>]</span> <span>for</span> e <span>in</span> employees <span>if</span> e <span>!=</span> <span>"Phil"</span><span>]</span><span>)</span></code></pre></div>
<p>The constraints <code>model.add_min_equality(...)</code> and <code>model.add_max_equality(...)</code> work in the same fashion as the <code>maximum(...)</code> constraint presented in the candy bar example (with Alice, Bob, and Carol). For example, <code>model.add_min_equality(var, list)</code> assigns to integer variable <code>var</code> the smallest value among the integer variables in <code>list</code>.</p>
<p>Finally, we minimize the difference between <code>max_shifts</code> and <code>min_shifts</code>:</p>
<div data-language="python"><pre><code>model<span>.</span>minimize<span>(</span>max_shifts <span>-</span> min_shifts<span>)</span></code></pre></div>
<div data-language="text"><pre><code>           |  Monday   |  Tuesday  | Wednesday | Thursday  |  Friday   | Saturday  |  Sunday   | Total |
           | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E | M | A | E |       |
Phil       |   |   | R |   |   |   |   |   | R |   |   |   |   |   |   | R |   |   | R |   |   |   4   |
Emma       |   |   |   |   |   |   |   |   |   |   | R | C |   | R | C |   |   |   |   | C | C |   6   |
David      | C |   |   | C | R |   | C |   |   |   | C |   | C | C |   |   |   | C | C |   |   |   9   |
Rebecca    |   | C | C |   | C | C |   | C | C | C |   |   |   |   |   | C | C |   |   |   |   |   9   |</code></pre></div>
<p>This looks pretty good. David and Rebecca both get 9 shifts. Emma only gets 6, but that is understandable as she is taking 3 days off that week. Phil gets exactly 4 shifts, as he is supposed to. Hopefully, everyone will be happy with this schedule.</p>

<p>We have introduced the basics of constraint programming and discussed its main components. We have built a model to generate work schedules that can take into account the types of constraints that one could reasonably expect to be faced with in the real world.</p>
<p>Thanks to this model, we could easily see that it would not be possible for Emma to take five days off as she initially wanted, and we were able to distribute the work shifts as fairly as possible between the employees. In the end, we created a schedule that satisfied both the requiremends of the store owner, as well as the needs of the employees.</p>
<p>In the next article, we will discuss how to use constraint programming for index selection in Postgres.</p>
<p><strong>The code presented in this article can be found on the <a href="https://github.com/pganalyze/cp-sat-python-example">pganalyze GitHub</a>.</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cheapest NAS (173 pts)]]></title>
            <link>https://sigwait.org/~alex/blog/2024/07/01/the-cheapest-nas.html</link>
            <guid>40867709</guid>
            <pubDate>Wed, 03 Jul 2024 16:45:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sigwait.org/~alex/blog/2024/07/01/the-cheapest-nas.html">https://sigwait.org/~alex/blog/2024/07/01/the-cheapest-nas.html</a>, See on <a href="https://news.ycombinator.com/item?id=40867709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<section>
<article data-file="2024/07/01/the-cheapest-nas.md">

  <nav>
    <span id="nbe_post--next"></span>
    <span id="nbe_post--prev"></span>
  </nav>

  <h2>The cheapest NAS</h2>

  <p>Latest update: <time datetime="2024-07-03T16:09:11.072Z">2024-07-03 19:09:11</time></p>

  

  <p>I wanted to replace my old trusty 'router' (with an attached
HDD)--that was not working as a router, but as a network drive after
flashing OpenWRT onto it--I wanter to replace it with an SBC+HDD
combo.</p>
<p>This new device should not only preserve all the services the old one
provided (samba, git, rsyncd, a dnf repo), but also perform faster,
for having a potato instead of a CPU, the ex-router struggled with
rsync over ssh &amp;, being gravely RAM limited, choked when I did 'git
push' commits containing binaries &gt; 15MB.</p>
<p>Searching for a suitable SBC led me to libre.computer, a company I had
never heard of before. At first glance, they had the el cheapo
<a href="https://libre.computer/products/aml-s805x-ac/">AML-S805X-AC</a> board I needed:</p>
<ul>
<li>LAN port (but 100 Mb only);</li>
<li>2 USB-A (but 2.0 only);</li>
<li>4-core ARM Cortex-A53;</li>
<li>1 GB RAM;</li>
<li>booting from an USB;</li>
<li>up-to-date Debian;</li>
<li>easy to buy without hunting it down.</li>
</ul>
<p>100Mb may seem like a joke nowadays, but the main purpose of such a
toy NAS for me is to keep a copy of a directory with ~200K small
files. Having 1Gb would only marginally improve the syncing speed even
if the SBC supported USB 3.0.</p>
<p>But this is just a board. I also needed an hdd enclosure with an
external power supply (for the device provides up to 900mA for
each USB-A), at least 3A power supply &amp; a micro-USB cable that can
handle 3A.</p>
<table id="tcnagcb-1">
<thead>
<tr><th>Item</th><th>Price, €</th><th>Comment</th></tr>
</thead>
<tbody>
<tr><td>SBC</td><td>20</td><td></td></tr>
<tr><td>HDD enclosure</td><td>12</td><td></td></tr>
<tr><td>3A Power Supply</td><td>5</td><td></td></tr>
<tr><td>Micro-USB cable</td><td>3</td><td></td></tr>
<tr><td>4 bolts, 12 nuts</td><td>0</td><td>I think the ones I found are older than me</td></tr>
<tr><td>TTL to USB dongle</td><td>3</td><td>Optional, the board has an HDMI output</td></tr>
<tr><th>Total</th><td>43</td><td></td></tr>
</tbody>
</table>



<p>(I didn't include an HDD in the table, for I presume everyone has a
couple of them lying around.)</p>
<p>When I bought the HDD enclosure, I didn't read the description
carefully &amp; thought it was going to be a small plastic container for
2.5-inch drives, but when the package arrived, it turned out to be a
box for 3.5-inch ones. Hence, I decided to shove the SBC into it too.</p>
<img alt="" src="https://sigwait.org/~alex/blog/2024/07/01/innards.avif">
<img alt="" src="https://sigwait.org/~alex/blog/2024/07/01/rear.avif">

<p>After connecting the TTL-to-USB dongle to the board's GPIO</p>
<img alt="" src="https://sigwait.org/~alex/blog/2024/07/01/gpio.avif">

<p>&amp; typing</p>
<pre><code>$ sudo screen /dev/ttyUSB0 115200
</code></pre>
<p>one of the 1st readouts appeared as:</p>
<pre><code>U-Boot 2023.07+ (Nov 03 2023 - 15:10:36 -0400) Libre Computer AML-S805X-AC

Model: Libre Computer AML-S805X-AC
SoC:   Amlogic Meson GXL (S805X) Revision 21:d (34:2)
DRAM:  512 MiB (effective 1 GiB)
</code></pre>
<p>What does the last line mean exactly? After I dd'ed Debian-12 onto a
flash drive, free(1) said it saw 1GB. Anyway, libre.computer has an
official OS image, based on stock Debian:</p>
<pre><code>$ fdisk debian-12-base-arm64+arm64.img -l
Disk debian-12-base-arm64+arm64.img: 2.25 GiB, 2415919104 bytes, 4718592 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x71f3f7cf

Device                          Boot  Start     End Sectors  Size Id Type
debian-12-base-arm64+arm64.img1 *      2048  524287  522240  255M ef EFI (FAT-12/16/32)
debian-12-base-arm64+arm64.img2      524288 4718591 4194304    2G 83 Linux
</code></pre>
<p>Yes, it has an EFI partition with the MBR layout! The 2nd partition is
btrfs (supposedly it's faster &amp; more gentle to flash storage than
ext4; no idea if both claims are true). You can examine its contents via:</p>
<pre><code>$ sudo mount -o loop,offset=$((524288*512)) debian-12-base-arm64+arm64.img ~/mnt/misc
</code></pre>
<p>This partition gets auto-resized on the 1st boot to fill the rest of
the free space available on the drive. Doing this on USB dongles
proved to be a miserable experience: of the 3 I had available, one
permanently got stuck on resizing, and another, despite finishing the
operation, became so sluggish afterwards that a 20-year-old PC would've
felt snappier.</p>
<p>This is I didn't like at all. There is no repo with from which the OS
image gets generated. The explanation is <a href="https://hub.libre.computer/t/source-code-git-repository-for-bootloaders-and-firmwares/2743/6">bizarre</a>:</p>
<blockquote>
<p>"The distribution builder is a proprietary commercial offering as it
involves a lot of customer IP and integrations so it cannot be
public."</p>
</blockquote>
<p>but with an consolation advice:</p>
<blockquote>
<p>"If you want to study them [images], bootstrap and do a diff. We
don't make any changes to the standard distros outside of setting a
few configs since we're not distro maintainers."</p>
</blockquote>
<p>Make of it what you will.</p>
<p>Then I connected the HDD enclosure to the board. This time, the
process went much, much faster (though there were still some
unexpected delays in random places). Right after logging in, I started
getting <code>uas_eh_abort_handler</code> errors from the kernel. It turns out I
got one of the worst HDD enclosure innards possible, if you believe
reviews from the interwebs:</p>
<pre><code>$ lsusb
Bus 001 Device 002: ID 152d:0578 JMicron Technology Corp. / JMicron USA Technology Corp. JMS578 SATA 6Gb/s
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
</code></pre>
<p>The remedy is to turn UAS off via adding
<code>usb-storage.quirks=152d:0578:u</code> to the kernel cmdline. It did help,
the delays went away, although 'benchmarks' became hardly thrilling:</p>
<pre><code>$ lsusb -t
/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci-hcd/2p, 480M
    |__ Port 2: Dev 2, If 0, Class=Mass Storage, Driver=usb-storage, 480M
$ sync; time sh -c "dd if=/dev/urandom of=1 bs=500k count=1k &amp;&amp; sync"; rm 1
1024+0 records in
1024+0 records out
524288000 bytes (524 MB, 500 MiB) copied, 15.1014 s, 34.7 MB/s

real    0m21.876s
user    0m0.001s
sys     0m7.976s
</code></pre>
<p>which means <math alttext="524/21.876 = 23.95">
<mfrac><mn>524</mn><mn>21.876</mn></mfrac><mo>=</mo><mn>23.95</mn>
</math> MB/s on an ext4 partition.</p>
<p>Would I recommend this setup? I wouldn't. One of the reasons I've
chosen the path with an SBC instead of a common micro-ITX route is to
save on <a href="https://sigwait.org/~alex/blog/2024/07/01/imf.html">power consumption</a>. If you don't have similar
problems, I see 0 reasons to struggle with such a finicky Chinese
device.</p>


  <br>Tags: <a href="https://sigwait.org/~alex/blog/t/da44800a6e351c6e94a3d3b6060d2be1.html">ойті</a>
  <br>Authors: <a href="https://sigwait.org/~alex/blog/a/4e42f7dd43ecbfe104de58610557c5ba.html">ag</a>

</article>
</section>

  <nav>
    

    
  </nav>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making a Linux-managed network switch (149 pts)]]></title>
            <link>https://blog.brixit.nl/making-a-linux-managed-network-switch/</link>
            <guid>40866442</guid>
            <pubDate>Wed, 03 Jul 2024 14:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.brixit.nl/making-a-linux-managed-network-switch/">https://blog.brixit.nl/making-a-linux-managed-network-switch/</a>, See on <a href="https://news.ycombinator.com/item?id=40866442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Network switches are simple devices, packets go in, packets go out. Luckily people have figured out how to make it complicated instead and invented managed switches.</p>

<p>Usually this is done by adding a web-interface for configuring the settings and see things like port status. If you have more expensive switches then you'd even get access to some alternate interfaces like telnet and serial console ports.</p>

<p>There is a whole second category of managed switches though that people don't initially think of. These are the network switches that are inside consumer routers. These routers are little Linux devices that have a switch chip inside of them, one or more ports are internally connected to the CPU and the rest are on the outside as physical ports.</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1719959978/RB2011UiAS-160620170256_160656.png"><figcaption>Mikrotik RB2011 block diagram from mikrotik.com</figcaption></figure>

<p>Here is an example of such a device that actually has this documented. I always thought that the configuration of these switch connected ports was just a nice abstraction by the webinterface but I was suprised to learn that with the DSA and switchdev subsystem in Linux these ports are actually fully functioning "local" network ports. Due to this practically only being available inside integrated routers It's pretty hard to play around with unfortunately.</p>

<p>What is shown as a single line on this diagram is actually the connection of the SoC of the router and the switch over the SGMII bus (or maybe RGMII in this case) and a management bus that's either SMI or MDIO. Network switches have a lot of these fun acronyms that even with the full name written out make little sense unless you know how all of this  fits together.</p>

<p>Controlling your standard off-the-shelf switch using this system simply isn't possible because the required connections of  the switch chip aren't exposed for this. So there's only one option left...</p>

<h2>Making my own gigabit network switch</h2>

<p>Making my own network switch can't be <i>that</i> hard right? Those things are available for the price of a cup of coffee and are most likely highly integrated to reach that price point. Since I don't see any homemade switches around on the internet I guess the chips for those must be pretty hard to get...</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1719960715/image.png"></figure>

<p>Nope, very easy to get. There's even a datasheet available for these. So I created a new KiCad project and started creating some footprints and symbols.</p>

<p>I'm glad there's any amount of datasheet available for this chip since that's not usually the case for Realtek devices, but it's still pretty minimal. I resorted to finding any devices that has schematics available for similar Realtek chips to find out how to integrate it and looking at a lot of documentation for how to implement ethernet in a design at all.</p>

<p>The implementation for the chip initially looked very complicated, there's about 7 different power nets it requires and there are several pretty badly documented communication interfaces. After going through other implementations it seem like the easiest way to power it is just connect all the nets with overlapping voltage ranges together and you're left with only needing a 3.3V and 1.1V regulator.</p>

<p>The extra communication busses are for all the extra ports I don't seem to need. The switch chip I selected is the RTL8367S which is a very widely used 5-port gigabit switch chip, but it's actually not a 5-port chip. It's a 7 port switch chip where 5 ports have an integrated PHY and two are for CPU connections.</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1719961532/image.png"><figcaption>CPU connection block diagram from the RTL8367S datasheet</figcaption></figure>

<p>My plan is different though, while there are these CPU ports available there is actually nothing in the Linux switchdev subsystem that requires the CPU connection to be to those ports. Instead I'll be connecting to port 0 on the switch with a network cable and as far  as the switchdev driver knows there's no ethernet PHY in between.</p>

<p>The next hurdle is the configuration of the switch chip, there's several configuration systems available and the datasheet does not really describe what is the minimum required setup to actually get it to function as a regular dumb switch. To sum up the configuration options of the chip:</p>

<ul><li>There's 8 pins on the chip that are read when it's starting up. These pins are shared with the led pins for the ports so that makes designing pretty annoying. Switching the setting from pull-up to pull-down also requires the led to be connected in the different orientation.</li>
<li>There's an i2c bus that can be connected to an eeprom chip. The pins for this are shared with the SMI bus that I require to make this chip talk to Linux though. There is pin configuration to select from one of two eeprom size ranges but does not further specify what this setting actually changes.</li>
<li>There's a SPI bus that supports connecting a NOR flash chip to it. This can store either configuration registers or firmware for the embedded 8051 core depending on the configuration of the bootup pins. The SPI bus pins are also shared with one of the CPU network ports.</li>
<li>There is a serial port available but from what I guess it probably does nothing at all unless there's firmware loaded in the 8051.</li>
</ul>

<p>My solution to figuring out is to just order a board and solder connections differently until it works. I've added a footprint for a flash chip that I ended up not needing and for all the configuration pins I added solder jumpers. I left out all the leds since making that configurable would be pretty hard.</p>

<p>The next step is figuring out how to do ethernet properly. There has been a lot of documentation written about this and they all make it sound like gigabit ethernet requires perfect precision engineering, impedance managed boards and a blessing from the ethernet gods themselves to work. This does not seem to match up with the reality that these switches are very very cheaply constructed and seem to work just fine. So I decided to open up a switch to check how many of these coupling capacitors and impedance matching planes are actually used in a real design. The answer seems to be that it doesn't matter that much.</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1719962591/image.png"></figure>

<p>This is the design I have ended up with now but it is not what is on my test PCB. I got it almost right the first time though :D</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1719962813/image.png"></figure>

<p>The important parts seem to be matching the pair skew but matching the length of the 4 network pairs is completely useless, this is mainly because network cables don't have the same twisting rate for the 4 pairs and so the length of these are already significantly different inside the cable.</p>

<p>The pairs between the transformer and the RJ45 jack has it's own ground plane that's coupled to the main ground through a capacitor. The pairs after the transformer are  just on the main board ground fill.</p>

<p>What I did wrong on my initial board revision was forgetting the capacitor that connects the center taps of the transformer on the switch side to ground making the signals on that side referenced to board ground. This makes ethernet very much not work anymore so I had to manually cut tiny traces on the board to disconnect that short to ground. In my test setup the capacitor just doesn't exist and all the center taps float. This seems to work just fine but the final design does have that capacitor added.</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1720003020/fixed.JPG"><figcaption>Cut ground traces on the ethernet transformer</figcaption></figure>

<p>The end result is this slightly weird gigabit switch. It has 4 ports facing one direction and one facing backwards and it is powered over a 2.54mm pinheader. I have also added a footprint for a USB Type-C connector to have an easy way to power it without bringing out the DuPont wires.</p>

<figure><img src="https://blog.brixit.nl/image/w1000//static/files/blog.brixit.nl/1720007603/IMG_20240626_221246.jpg"></figure>

<h2>Connecting it to Linux</h2>

<p>For my test setup I've picked the PINE64 A64-lts board since it has the connectors roughly in the spots where I want them. It not being an x86 platform is also pretty important because configuration requires a device tree change, can't do that on a platform that doesn't use device trees.</p>

<p>The first required thing was rebuilding the kernel for the board since most kernels simply don't have these kernel modules enabled. For this I enabled these options:</p>

<ul><li><code>CONFIG_NET_DSA</code> for the Distributed Switch Architecture system</li>
<li><code>CONFIG_NET_DSA_TAG_RTL8_4</code> for having port tagging for this Realtek switch chip</li>
<li><code>CONFIG_NET_SWITCHDEV</code> the driver system for network switches</li>
<li><code>CONFIG_NET_DSA_REALTEK</code>, <code>CONFIG_NET_DSA_REALTEK_SMI</code>, <code>CONFIG_NET_DSA_REALTEK_RTL8365MB</code> for the actual switch chip driver</li>
</ul>

<p>Then the more complicated part was figuring out how to actually get this all loaded. In theory it is possible to create a device tree overlay for this and get it loaded by U-Boot. I decided to not do that and patch the device tree for the A64-lts board instead since I'm rebuilding the kernel anyway. The device tree change I ended up with is this:</p>

<pre><code>diff --git a/arch/arm64/boot/dts/allwinner/sun50i-a64-pine64-lts.dts b/arch/arm64/boot/dts/allwinner/sun50i-a64-pine64-lts.dts
index 596a25907..10c1a5187 100644
--- a/arch/arm64/boot/dts/allwinner/sun50i-a64-pine64-lts.dts
+++ b/arch/arm64/boot/dts/allwinner/sun50i-a64-pine64-lts.dts
@@ -18,8 +18,78 @@ led {
 			gpios = &lt;&amp;r_pio 0 7 GPIO_ACTIVE_LOW&gt;; /* PL7 */
 		};
 	};
+
+switch {
+	compatible = "realtek,rtl8365rb";
+	mdc-gpios = &lt;&amp;pio 2 5 GPIO_ACTIVE_HIGH&gt;; // PC5
+	mdio-gpios = &lt;&amp;pio 2 7 GPIO_ACTIVE_HIGH&gt;; // PC7
+	reset-gpios = &lt;&amp;pio 8 5 GPIO_ACTIVE_LOW&gt;; // PH5
+	realtek,disable-leds;
+
+	mdio {
+		compatible = "realtek,smi-mdio";
+		#address-cells = &lt;1&gt;;
+		#size-cells = &lt;0&gt;;
+
+		ethphy0: ethernet-phy@0 {
+			reg = &lt;0&gt;;
+		};
+
+		ethphy1: ethernet-phy@1 {
+			reg = &lt;1&gt;;
+		};
+
+		ethphy2: ethernet-phy@2 {
+			reg = &lt;2&gt;;
+		};
+
+		ethphy3: ethernet-phy@3 {
+			reg = &lt;3&gt;;
+		};
+
+		ethphy4: ethernet-phy@4 {
+			reg = &lt;4&gt;;
+		};
+	};
+
+	ports {
+		#address-cells = &lt;1&gt;;
+		#size-cells = &lt;0&gt;;
+
+		port@0 {
+			reg = &lt;0&gt;;
+			label = "cpu";
+			ethernet = &lt;&amp;emac&gt;;
+		};
+
+		port@1 {
+			reg = &lt;1&gt;;
+			label = "lan1";
+			phy-handle = &lt;&amp;ethphy1&gt;;
+		};
+
+		port@2 {
+			reg = &lt;2&gt;;
+			label = "lan2";
+			phy-handle = &lt;&amp;ethphy2&gt;;
+		};
+
+		port@3 {
+			reg = &lt;3&gt;;
+			label = "lan3";
+			phy-handle = &lt;&amp;ethphy3&gt;;
+		};
+
+		port@4 {
+			reg = &lt;4&gt;;
+			label = "lan4";
+			phy-handle = &lt;&amp;ethphy4&gt;;
+		};
+	};
+};
 };
 </code></pre>

<p>It loads the driver for the switch with the <code>realtek,rtl8365rb</code>, this driver supports a whole range of Realtek switch chips including the RTL8367S I've used in this design. I've removed the CPU ports from the documentation example and just added the definitions of the 5 regular switch ports.</p>

<p>The important part is in <code>port@0</code>, this is the port that is facing backwards on my switch and is connected to the A64-lts, I've linked it up to <code>&amp;emac</code> which is a reference to the ethernet port of the computer.  The rest of the ports are  linked up to their respective PHYs in the switch chip. </p>

<p>In the top of the code there's also 3 GPIOs defined, these link up to SDA/SCL and Reset on the switch PCB to make the communication work. After booting up the system the result is this:</p>

<pre><code>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu 1508 qdisc noop state DOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
3 lan1@eth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
4 lan2@eth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
5 lan3@eth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
6 lan4@eth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff</code></pre>

<p>I have the <code>eth0</code> device here like normal and then I have the 4 interfaces for the ports on the switch I defined in the device tree. To make it actually do something the interfaces actually need to be brought online first:</p>

<pre><code>$ ip link set eth0 up
$ ip link set lan1 up
$ ip link set lan2 up
$ ip link set lan3 up
$ ip link set lan4 up
$ ip link
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1508 qdisc mq state UP qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
3: lan1@eth0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
4: lan2@eth0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
5: lan3@eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff
6: lan4@eth0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN qlen 1000
    link/ether 02:ba:6f:0c:21:c4 brd ff:ff:ff:ff:ff:ff</code></pre>

<p>Now the switch is up you can see I have a cable plugged into the third port. This system hooks into a lot of the Linux networking so it Just Works(tm) with a lot of tooling. Some examples:</p>

<ul><li>Add a few of the lan ports into a standard Linux bridge and the switchdev system will bridge those ports together in the switch chip so Linux doesn't have to forward that traffic.</li>
<li>Thinks like <code>ethtool lan3</code> just work to get information about the link. and with <code>ethtool -S lan3</code> all the standard status return info which includes packets that have been fully handled by the switch.</li>
</ul>

<h2>Limitations</h2>

<p>There's a few things that makes this not very nice to work with. First of all the requirement of either building a custom network switch or tearing open an existing one and finding the right connections. </p>

<p>It's not really possible  to use this system on regular computers/servers since you need device trees to configure the kernel for this and most computers don't have kernel-controlled GPIO pins available to hook up a switch.</p>

<p>As far as I can find there's also no way to use this with a network port on the computer side that's not fixed, USB network interfaces don't have a device tree node handle to refer to to set the conduit port.</p>

<p>There is a chance some of these limitations are possible to work around, maybe there's some weird USB device that exposes pins on the GPIO subsystem, maybe there's a way to load switchdev without being on an ARM device but that would certainly take a bit more documentation...</p>


                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do not taunt happy fun branch predictor (2023) (220 pts)]]></title>
            <link>https://www.mattkeeter.com/blog/2023-01-25-branch/</link>
            <guid>40866374</guid>
            <pubDate>Wed, 03 Jul 2024 14:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mattkeeter.com/blog/2023-01-25-branch/">https://www.mattkeeter.com/blog/2023-01-25-branch/</a>, See on <a href="https://news.ycombinator.com/item?id=40866374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<!-- End header -->






<p>I've been writing a lot of AArch64 assembly, for <em>reasons</em>.</p>
<p>I recently came up with a "clever" idea to eliminate one jump from an inner
loop, and was surprised to find that it slowed things down.  Allow me to explain
my terrible error, so that you don't fall victim in the future.</p>
<p>A toy model of the relevant code looks something like this:</p>
<pre><code>float run(const float* data, size_t n) {
    float g = 0.0;
    while (n) {
        n--;
        const float f = *data++;
        foo(f, &amp;g);
    }
    return g;
}

static void foo(float f, float* g) {
    // do some stuff, modifying g
}
</code></pre>
<p>(eliding headers and the forward declaration of <code>foo</code> for space)</p>
<p>A simple translation into AArch64 assembly gives something like this:</p>
<pre><code>// x0: const float* data
// x1: size_t n
// Returns a single float in s0

// Prelude: store frame and link registers
stp   x29, x30, [sp, #-16]!

// Initialize g = 0.0
fmov s0, #0.0

loop:
    cmp x1, #0
    b.eq exit
    sub x1, x1, #1
    ldr s1, [x0], #4

    bl foo   // call the function
    b loop   // keep looping

foo:
    // Do some work, reading from s1 and accumulating into s0
    // ...
    ret

exit: // Function exit
    ldp   x29, x30, [sp], #16
    ret
</code></pre>
<p>Here, <code>foo</code> is kinda like a <a href="https://github.com/rust-lang/rfcs/blob/master/text/1201-naked-fns.md">naked
function</a>:
it uses the same stack frame and registers as the parent function, reads from
<code>s1</code>, and writes to <code>s0</code>.</p>
<p>The call to <code>foo</code> uses the the <code>bl</code> instruction, which is "branch and link":
it jumps to the given label, and stores the <strong>next</strong> instruction address in the
link register (<code>lr</code> or <code>x30</code>).</p>
<p>When <code>foo</code> is done, the <code>ret</code> instruction jumps to the address in the link
register, which is the instruction following the original <code>bl</code>.</p>
<p>Looking at this code, I was struck by the fact that it does two branches,
one after the other.  Surely, it would be more efficient to only branch once.</p>
<p>I had the clever idea to do so <strong>without changing <code>foo</code></strong>:</p>
<pre><code>stp   x29, x30, [sp, #-16]!
fmov s0, #0.0

bl loop // Set up x30 to point to the loop entrance
loop:
    cmp x1, #0
    b.eq exit
    sub x1, x1, #1
    ldr s1, [x0], #4

foo:
    // Do some work, accumulating into `s0`
    // ...
    ret

exit: // Function exit
    ldp   x29, x30, [sp], #16
    ret
</code></pre>
<p>This is a little subtle:</p>
<ul>
<li>The first call to <code>bl loop</code> stores the beginning of the <code>loop</code> block in <code>x30</code></li>
<li>After checking for loop termination, we fall through into the <code>foo</code> function
(without a branch!)</li>
<li><code>foo</code> still ends with <code>ret</code>, which returns to the <code>loop</code> block (because
that's what's in <code>x30</code>).</li>
</ul>
<p>Within the body of the loop, we never change <code>x30</code>, so the repeated <code>ret</code>
instructions always return to the same place.</p>
<p>I set up a benchmark using a very simple <code>foo</code>:</p>
<pre><code>foo:
    fadd s0, s0, s1
    ret
</code></pre>
<p>With this <code>foo</code>, the function as a whole sums the incoming array of <code>float</code>
values.</p>
<p>Benchmarking with <a href="https://docs.rs/criterion/latest/criterion/"><code>criterion</code></a>
(on an M1 Max CPU),
with a 1024-element array:</p>
<table>
<tbody><tr><th>Program</th><th>Time
</th></tr><tr><td>Original </td><td>969 ns
</td></tr><tr><td>"Optimized"</td><td>3.85 µs
</td></tr></tbody></table>
<p>The "optimized" code with one jump per loop is about <strong>4x slower</strong>
than the original version with two jumps per loop!</p>
<p>I found this surprising, so I asked a few colleagues about it.</p>
<p>Between <a href="https://hachyderm.io/@cliffle">Cliff</a> and
<a href="https://discuss.systems/@cross">Dan</a>,
the consensus was that mismatched <code>bl</code> / <code>ret</code>
pairs were confusing the
<a href="https://en.wikipedia.org/wiki/Branch_predictor">branch predictor</a>.</p>
<p>The <a href="https://developer.arm.com/documentation/102374/0101/Function-calls">ARM documentation</a> agrees:</p>
<blockquote>
<p>Why do we need a special function return instruction? Functionally, BR LR
would do the same job as RET. Using RET tells the processor that this is a
function return. Most modern processors, and all Cortex-A processors, support
branch prediction. Knowing that this is a function return allows processors to
more accurately predict the branch.</p>
<p>Branch predictors guess the direction the program flow will take across
branches. The guess is used to decide what to load into a pipeline with
instructions waiting to be processed. If the branch predictor guesses
correctly, the pipeline has the correct instructions and the processor does
not have to wait for instructions to be loaded from memory.</p>
</blockquote>
<p>More specifically, the branch predictor probably keeps an internal stack of
function return addresses, which is pushed to whenever a <code>bl</code> is executed. When
the branch predictor sees a <code>ret</code> coming down the pipeline, it assumes that
you're returning to the address associated with the most recent <code>bl</code> (and begins
prefetching / speculative execution / whatever), then pops that top address from
its internal stack.</p>
<p>This works if you've got matched <code>bl</code> / <code>ret</code> pairs, but the prediction will
fail if the same address is used by multiple <code>ret</code> instructions; you'll end up
with (<em>vague handwaving</em>) useless prefetching, incorrect speculative execution,
and pipeline stalls / flushes</p>
<p>Dan made the great suggestion of replacing <code>ret</code> with <code>br x30</code> to test this
theory.  Sure enough, this fixes the performance regression:</p>
<table>
<tbody><tr><th>Program</th><th>Time
</th></tr><tr><td>Matched <code>bl</code> / <code>ret</code> </td><td>969 ns
</td></tr><tr><td>One <code>bl</code>, many <code>ret</code></td><td>3.85 µs
</td></tr><tr><td>One <code>bl</code>, many <code>br x30</code></td><td>913 ns
</td></tr></tbody></table>
<p>In fact, it's slightly faster, probably because it's only doing one branch
per loop instead of two!</p>
<p>To further test the "branch predictor" theory, I opened up Instruments and
examined performance counters for the first two programs. Picking out the worst
offenders, the results seem conclusive:</p>
<table>
<tbody><tr><th>Counter</th><th>Matched <code>bl</code> / <code>ret</code></th><th>One <code>bl</code>, many <code>ret</code>
</th></tr><tr><td><code>BRANCH_RET_INDIR_MISPRED_NONSPECIFIC</code></td><td>92</td><td>928,644,975
</td></tr><tr><td><code>FETCH_RESTART</code></td><td>61,121</td><td>987,765,276
</td></tr><tr><td><code>MAP_DISPATCH_BUBBLE</code></td><td>1,155,632</td><td>7,350,085,139
</td></tr><tr><td><code>MAP_REWIND</code></td><td>6,412,734</td><td>2,789,499,545
</td></tr></tbody></table>
<p>These measurements are captured while summing an array of 1B elements.  We see
that with mismatched <code>bl</code> / <code>ret</code> pairs, the return branch predictor fails about
93% of the time!</p>
<p>Apple doesn't fully document these counters, but I'm guessing that the other
counters are downstream effects of bad branch prediction:</p>
<ul>
<li><code>FETCH_RESTART</code> is presumably bad prefetching</li>
<li><code>MAP_DISPATCH_BUBBLE</code> probably refers to <a href="https://en.wikipedia.org/wiki/Pipeline_stall">pipeline stalls</a></li>
<li><code>MAP_REWIND</code> might be bad speculative execution that needs to be rewound</li>
</ul>
<p>In conclusion,
<a href="https://www.youtube.com/watch?v=GmqeZl8OI2M">do not taunt happy fun branch predictor</a>
with asymmetric usage of <code>bl</code> and <code>ret</code> instructions.</p>
<hr>
<h2>Appendix: Going Fast</h2>
<p>Take a second look at this program:</p>
<pre><code>stp   x29, x30, [sp, #-16]!
fmov s0, #0.0

loop:
    cmp x1, #0
    b.eq exit
    sub x1, x1, #1
    ldr s1, [x0], #4

    bl foo   // call the function
    b loop   // keep looping

foo:
    fadd s0, s0, s1
    ret

exit: // Function exit
    ldp   x29, x30, [sp], #16
    ret
</code></pre>
<p>Upon seeing this program, it's a common reaction to ask "why is <code>foo</code> a
subroutine at all?"</p>
<p>The answer is "because this is a didactic example, not code that's trying
to go as fast as possible".</p>
<p>Still, it's a fair question.  You wanna go fast?  Let's go fast.</p>
<p>If we know the contents of <code>foo</code> when building this
function (and it's shorter than the maximum jump distance), we can remove the
<code>bl</code> and <code>ret</code> entirely:</p>
<pre><code>loop:
    cmp x1, #0
    b.eq exit
    sub x1, x1, #1
    ldr s1, [x0], #4

    // foo is completely inlined here
    fadd s0, s0, s1

    b loop

exit: // Function exit
    ldp   x29, x30, [sp], #16
    ret
</code></pre>
<p>This is a roughly 6% speedup: from 969 ns to 911 ns.</p>
<p>We can get faster still by trusting the compiler:</p>
<pre><code>pub fn sum_slice(f: &amp;[f32]) -&gt; f32 {
    f.iter().sum()
}
</code></pre>
<p>This brings us down to 833 ns, a significant improvement!</p>
<p><a href="https://godbolt.org/z/Kv77abW6c">Looking at the assembly</a>,
it's doing some loop unrolling.
However, even when compiled with <code>-C target-cpu=native</code>, it's not generating
<a href="https://developer.arm.com/Architectures/Neon">NEON SIMD instructions</a>.
Can we beat it?</p>
<p><strong>We sure can!</strong></p>
<pre><code>stp   x29, x30, [sp, #-16]!

fmov s0, #0.0
dup v1.4s, v0.s[0]
dup v2.4s, v0.s[0]

loop:  // 1x per loop
    ands xzr, x1, #3
    b.eq simd

    sub x1, x1, #1
    ldr s3, [x0], #4

    fadd s0, s0, s3
    b loop

simd:  // 4x SIMD per loop
    ands xzr, x1, #7
    b.eq simd2

    sub x1, x1, #4
    ldp d3, d4, [x0], #16
    mov v3.d[1], v4.d[0]

    fadd v1.4s, v1.4s, v3.4s

    b simd

simd2:  // 2 x 4x SIMD per loop
    cmp x1, #0
    b.eq exit

    sub x1, x1, #8

    ldp d3, d4, [x0], #16
    mov v3.d[1], v4.d[0]
    fadd v1.4s, v1.4s, v3.4s

    ldp d5, d6, [x0], #16
    mov v5.d[1], v6.d[0]
    fadd v2.4s, v2.4s, v5.4s

    b simd2

exit: // function exit
    fadd v2.4s, v2.4s, v1.4s
    mov s1, v2.s[0]
    fadd s0, s0, s1
    mov s1, v2.s[1]
    fadd s0, s0, s1
    mov s1, v2.s[2]
    fadd s0, s0, s1
    mov s1, v2.s[3]
    fadd s0, s0, s1

    ldp   x29, x30, [sp], #16
    ret
</code></pre>
<p>This code includes three different loops:</p>
<ul>
<li>The first loop (<code>loop</code>) sums individual values
into <code>s0</code> until we have a multiple of four values remaining</li>
<li>The second loop (<code>simd</code>) uses SIMD instructions to sum 4 values at a time
into the vector register <code>v1</code>, until we have a multiple of 8 values remaining</li>
<li>The last loop (<code>simd2</code>) is the same as <code>simd</code>, but is unrolled 2x so it
handles 8 values per loop iteration, summing into <code>v1</code> and <code>v2</code></li>
</ul>
<p>At the function exit, we accumulate the values in the vector registers <code>v1</code>/<code>v2</code>
into <code>s0</code>, which is returned.</p>
<p>The type punning here is particularly cute:</p>
<pre><code>ldp d3, d4, [x0], #16
mov v3.d[1], v4.d[0]
fadd v1.4s, v1.4s, v3.4s
</code></pre>
<p>Remember, <code>x0</code> holds a <code>float*</code>.  We pretend that it's a <code>double*</code> to load 128
bits (i.e. 4x <code>float</code> values) into <code>d3</code> and <code>d4</code>.  Then, we move the "double" in <code>d4</code>
to occupy the top 64 bits of the <code>v3</code> vector register (of which <code>d3</code> is the
<em>lower</em> 64 bits).</p>
<p>Of course, each "double" is two floats, but that doesn't matter when shuffling
them around.  When summing with <code>fadd</code>, we tell the processor to treat them as
four floats (the <code>.4s</code> suffix), and everything works out fine.</p>
<p>How fast are we now?</p>
<p>This runs in 94 ns, or about <strong>8.8x faster</strong> than our previous best.</p>
<p>Here's a summary of performance:</p>
<table>
<tbody><tr><th>Program</th><th>Time
</th></tr><tr><td>Matched <code>bl</code> / <code>ret</code> </td><td>969 ns
</td></tr><tr><td>One <code>bl</code>, many <code>ret</code></td><td>3.85 µs
</td></tr><tr><td>One <code>bl</code>, many <code>br x30</code></td><td>913 ns
</td></tr><tr><td>Plain loop with <code>b</code></td><td>911 ns
</td></tr><tr><td>Rewrite it in Rust</td><td>833 ns
</td></tr><tr><td>SIMD + manual loop unrolling</td><td>94 ns
</td></tr></tbody></table>
<p>Could we get even faster?  I'm sure it's possible; I make no claims to being
the <a href="https://www.agner.org/optimize/">Agner Fog</a> of AArch64 assembly.</p>
<p>Still, this is a reasonable point to wrap up: we've demystified the initial
performance regression, and had some fun hand-writing assembly to go very
fast indeed.</p>
<p>The SIMD code does come with one asterisk, though: because floating-point
addition is not associative, and it performs the summation in a different
order, it <strong>may not get the same result</strong> as straight-line code.  In retrospect,
this is likely why the compiler doesn't generate SIMD instructions to compute
the sum!</p>
<p>Does this matter for your use case?  Only you can know!</p>
<hr>
<p>All of the code from this post is
<a href="https://github.com/mkeeter/arm64-test">published to GitHub</a>.</p>
<p>You can reproduce benchmarks by running <code>cargo bench</code> on an ARM64 machine.</p>

<!-- Begin footer -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Has anyone successfully pivoted from web dev to AI/ML development? (124 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40866311</link>
            <guid>40866311</guid>
            <pubDate>Wed, 03 Jul 2024 14:35:13 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40866311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40866311">
      <td><span></span></td>      <td><center><a id="up_40866311" href="https://news.ycombinator.com/vote?id=40866311&amp;how=up&amp;goto=item%3Fid%3D40866311"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40866311">Ask HN: Has anyone successfully pivoted from web dev to AI/ML development?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40866311">106 points</span> by <a href="https://news.ycombinator.com/user?id=ent_superpos">ent_superpos</a> <span title="2024-07-03T14:35:13"><a href="https://news.ycombinator.com/item?id=40866311">4 hours ago</a></span> <span id="unv_40866311"></span> | <a href="https://news.ycombinator.com/hide?id=40866311&amp;goto=item%3Fid%3D40866311">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Has%20anyone%20successfully%20pivoted%20from%20web%20dev%20to%20AI%2FML%20development%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40866311&amp;auth=1344ad73a11754902765b72c2daad9533241ef0b">favorite</a> | <a href="https://news.ycombinator.com/item?id=40866311">65&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I am currently working as a senior full-stack web software engineer. I have a BSc in Computer Science, and on my own, I've been learning more about AI/ML/deep learning. I really enjoy working with it, and I'd love to find a way to work on AI stuff professionally. The problem is that I've been working as a web developer professionally for about 10 years now, and I have no idea how I would pivot to more of a AI/data science role.</p><p>Does anyone have an experience of making this transition? As a web dev, I am senior level, but I'm sure I'd have to start from scratch on some things in the AI space. At least I have a good foundation of programming in general, math, and computer science.</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Living in a Lucid Dream (113 pts)]]></title>
            <link>https://www.noemamag.com/living-in-a-lucid-dream/</link>
            <guid>40866155</guid>
            <pubDate>Wed, 03 Jul 2024 14:18:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noemamag.com/living-in-a-lucid-dream/">https://www.noemamag.com/living-in-a-lucid-dream/</a>, See on <a href="https://news.ycombinator.com/item?id=40866155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="article">

        <div role="group">
    <p>Credits</p>
    <p>Claire L. Evans is a writer and musician exploring ecology, technology and culture.</p>
</div>

<p>The first time it happened, it was an accident. But every dream is.</p>



<p>It would have been my last REM cycle of the night, had I been able to sleep. Instead, for the previous six hours, I had counted sheep, had dressed for imaginary occasions in my mind, had tried the Army sleep techniques, alternately imagined myself in a black velvet hammock and in a canoe on a calm, still lake. I’d meditated. I’d thought of my mother, a lifelong insomniac who has rarely slept more than four hours a night in her life. I’d tried everything and given up. All I could do was wait for morning.</p>







<p>The dream grabbed my ankles first, pulled at me like someone dislodging a drain. Out it tossed me through my sliding glass window, over the garden, over my quiet street, over the dark sleeping skyline, a ragdoll flung into the Santa Anas. I soared high enough to see Los Angeles’s motherboard of electric light. I could see the city in perfect detail below. I was asleep — no, I was awake! I <em>felt</em> the cold whipping through my hair as I tumbled like a deflating balloon through the sky. I felt the miles beneath me. I felt the warm pillow beneath my cheek. I dove, flew, dipped, conscious of it all.</p>



<p>So <em>this</em> is a lucid dream, I thought.</p>



<p>More than half of adults will have this <a href="https://pubmed.ncbi.nlm.nih.gov/27337287/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">experience</a> or one like it at some point in their lives. They’ll go to sleep, and as their REM cycles accumulate, as night shades into morning, as their sports car turns into a banana, they will suddenly realize, as I did: This is not real. This is a dream.</p>



<p>The flash of lucidity can come as quite a shock, enough to startle a novice into waking. But if you can hang on and stay conscious, you’ll be in for the ride of your life.</p>



<p>After the first one, my curiosity was piqued. I started lurking in online forums, reading accounts of similar experiences from communities of “<a href="https://www.reddit.com/r/Oneironauts/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">oneironauts</a>,” or dream explorers. From them I learned that lucid dreams need not be a fluke experience: I could cultivate and, with some practice, control them.</p>



<p>The first thing I needed to do was establish a baseline awareness of the difference between waking and dreaming using a technique called “critical state testing.” This is how it works: Several times a day, ask yourself if what you are experiencing is a dream. To make sure you’re awake, count your fingers. Plug your nose. Look at your watch, then look again to see if the numbers have moved.</p>



<p>If you do this often enough, the habit will spill over into your dreams. And when it does, you’ll find that your fingers are jelly. That you can breathe with your nose plugged. That your watch is unreadable. “dream standard time,” the psychophysiologist Stephen LaBerge called it in his 1990 manual, “Exploring the World of Lucid Dreaming”:asleep and awake at once.</p>



<h2 id="h-glimpses-from-the-dreamworld"><strong>Glimpses From The Dreamworld</strong></h2>



<p>Lucid dreams are as ancient as the mind. They’ve long been central to the Vajrayana Buddhist tradition, which teaches the cultivation of conscious awareness even in deep sleep. In the West, the philosophical literature of lucidity reaches back to <a href="https://classics.mit.edu/Aristotle/dreams.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Aristotle</a>. René Descartes, in his first “<a href="https://yale.learningu.org/download/041e9642-df02-4eed-a895-70e472df2ca4/H2665_Descartes'%2520Meditations.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Meditation</a>,” famously proposed that it’s impossible to prove the difference between dreaming and wakefulness on empirical grounds alone. Friedrich Nietzsche <a href="https://www.themarginalian.org/2016/04/21/nietzsche-on-dreams/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">wrote</a> accounts of his own lucid dreams.</p>



<p>But in the modern sciences, the subject remained unexplored well into the 20th century. Even by the late 1970s, most scientists and psychologists believed that lucid dreams were the product of fleeting awakenings during sleep, misremembered in the morning. The very idea of conscious awareness during sleep was considered impossible to measure. After all, subjective accounts of dreamers couldn’t be quantified — how could a dreamer really know the difference between <em>dreaming </em>that they were conscious and actually <em>being </em>conscious?</p>



<p>Anyone who has ever had a lucid dream knows this difference intuitively, but without a measurable physiological sign, lucidity was relegated to the anecdotal, subjective experience of dreamers. That is, until someone thought to dig deeper, and look — as though lifting a veil — behind their eyelids.</p>



<p>In the early 1950s, a graduate student named <a href="https://www.smithsonianmag.com/science-nature/the-stubborn-scientist-who-unraveled-a-mystery-of-the-night-91514538/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Eugene Aserinsky</a> hooked his 8-year-old son Armond up to a rudimentary brain-wave machine he had dragged up from the basement of a University of Chicago building. Aserinksy did not relish sleep research, at the time on the fringes of science, and the prospect of spending his nights awake, observing sleeping subjects, seemed “as exciting as warm milk.”</p>



<p>In the bleary morning, looking over a half-mile of polygraph paper, he despaired. The ink pens had drawn jagged lines that looked suspiciously like the <span data-note="The movement of the eye between fixation points.">saccades</span> his son’s eyes made when they’d calibrated the machine. They showed the eye movements of a waking person. But his son had been out cold on the lab’s army cot all night. “The research project was blowing up before me,” he later recalled.</p>


<!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “The dream grabbed my ankles first, pulled at me like someone dislodging a drain. Out it tossed me through my sliding glass window, over the garden, over my quiet street, over the dark sleeping skyline, a ragdoll flung into the Santa Anas.”    </p>

    
    
  </blockquote>
</figure>




<p>As it turned out, there was nothing wrong with the machine. Following further study, Aserinsky discovered that his son’s sleeping brain was not — as believed by practically everyone, particularly his thesis advisor, the venerable sleep scientist Nathaniel Kleitman — simply <em>off. </em>Rather, brains roar to life in the darkness, in periods of active, “paradoxical” sleep that seemed to coincide with dreaming. Aserinsky considered naming the phenomenon “jerky eye movements” but, hoping to avoid being called a jerk himself, opted instead for “<a href="https://www.science.org/doi/10.1126/science.118.3062.273" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">rapid eye movements</a>,” or REM.</p>



<p>When Aserinsky left dream science behind in 1953, he passed the baton to a medical student, William C. Dement, who’d go on to establish the world’s first sleep disorders clinic at Stanford University. Years later, during a Stanford sleep study, Dement woke a subject during a period of unusually consistent back-and-forth eye movements. As LaBerge, once a student of Dement’s, recounted it, the subject had been dreaming about a ping-pong match. His eye movements during REM sleep had corresponded to his dream-gaze: left, right, left, right, following the phantom ball.</p>



<p>This anecdote sparked an idea in LaBerge. The study of lucid dreaming had always been stymied by its dependence on subjective self-reports. But eye movements are measurable. If a subject could <em>deliberately</em> move their eyes in a dream, LaBerge reasoned, then they could signal to outside observers, in real-time, that they were <em>awake</em> in there.</p>



<p>He designed an experiment around this premise, tucking a group of experienced lucid dreamers into bed at the Stanford sleep lab and asking them to make a series of prearranged eye movements the moment they became lucid. The eye measurements, unmistakable ping-pong volleys on the polygraph paper, corresponded precisely with the dreamers’ waking reports — all in the depths of REM sleep.</p>



<p>These “signal-verified” lucid dreams changed sleep research forever. Modern lucid dream studies rely on left-right-left-right eye signals to time-stamp experimental tasks and receive messages from the dreamworld. Lucid dreamers have been asked to signal before and after counting to 10, to measure if time unspools in dreams at the same speed as in waking life. (<a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2013.01013/full" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">It does</a>.) They’ve been tasked to signal, with their eyes alone, the answers to simple math problems piped into speakers in the sleep room to establish if two-way communication is possible between a dreamer and a waking experimenter. (<a href="https://www.cell.com/current-biology/fulltext/S0960-9822(21)00059-2?_returnURL=https://linkinghub.elsevier.com/retrieve/pii/S0960982221000592?showall=true" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">It is</a>.) Eyes, windows of the soul, open the door to dreams too.</p>



<p>But what is <em>behind</em> that door, exactly? And what is it the lucid dreamers see in there?</p>



<h2 id="h-alive-and-mystically-beautiful"><strong>Alive And Mystically Beautiful</strong></h2>



<p>I began my critical state testing without much expectation of what it might bring. At first, I felt weird counting my fingers. Would my friends think I’d had a stroke? Had I been Reddit-brained? Was I no better than one of those people who believes life is a simulation? But the ritual was a good reminder to put down my phone. I began enjoying the blips of mindfulness it brought to my otherwise scatterbrained existence. My own hands took on the trippy quality that I remembered from being on mushrooms in college. It only took a few days for the habit to show up in my dreams.</p>



<p>Dreams are almost always phenomenally embodied. We look out onto the dreamscape and experience its uncanny forms and flavors largely from within an immersed, first-person perspective. Philosophers like to say that a dream is a “self-in-a-world” experience. Even as its fantastical physics support impossible actions like flying, it can never quite succeed in tearing mind from limb. You can never witness your own death in a dream, for example, because if you did, there would be no <em>you</em> left to dream it. As the philosopher <a href="https://press.princeton.edu/books/hardcover/9780691220093/when-animals-dream" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">David M. Peña-Guzmán</a> has written, “There is no dream without a dream ego, no dream ego without a dream body, and no dream body without a dream body-image.”</p>



<p>But our dream bodies are only loose sketches of the real thing. When I’m awake, my hands have ink stains and nagging splinters. I have 10 fingers, and the signet ring I wear on my right hand reads “JB,” my husband’s initials. The first time I thought to examine my hands in a dream, though, they looked like a bouquet of wilting fingers. The signet ring was etched with unreadable glyphs. It’s difficult to put into words the feeling this gave me. One of the key attributes of dreams is that they feel real in the moment. When I looked at my hands and saw the mutant flippers of a Midjourney hallucination, I felt the walls drop. My whole body flushed. Nothing was real here — least of all <em>me</em>.</p>



<p>The imprecise texture of the dream-body is a marked contrast to the dream landscape, which can be extraordinarily detailed, even growing in complexity under close examination. One of the earliest written accounts of a lucid dream in medical literature, <a href="https://dreamscience.ca/en/documents/New%2520content/lucid%2520dreaming%2520pdfs/vanEeden_PSPR_26_1-12_1913.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">recorded</a> by the Dutch psychiatrist Frederik van Eeden in the late 19th century, highlights this phenomenon:</p>



<div>
<p>I was floating through a landscape with bare trees, knowing that it was April, and I remarked that the perspective of the branches and twigs changed quite naturally. Then I made the reflection, during sleep, that my fancy would never be able to invent or to make an image as intricate as the perspective movement of little twigs seen in floating by.
          </p>
        


<!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “Lucid dreams are as ancient as the mind.”    </p>

    
    
  </blockquote>
</figure>

</div>



<p>In his dream, van Eeden experienced a moment of reflection as he observed the remarkable naturalness of each little branch and twig passing beneath his flying body. The trees didn’t appear to him as imprecise, or “dreamlike” — quite the opposite. He even thought to himself that such a landscape, although fantastic, <em>must</em> be real because there was no way his own mind could have rendered those spare branches in such detail. Such reflections are considered “pre-lucid” because they signal the dreamer’s stirring awareness — their nagging feeling that something is <em>off.</em></p>



<p>In another classic dream <a href="https://www.biblio.com/book/astral-projection-record-out-body-experiences/d/1459779131" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">report</a>, the early 20th-century occultist and researcher Hugh Callaway recounted observing that the paving stones outside his home had changed orientation, turning parallel to the curb. This act of noticing brought the true nature of his dream into focus:</p>



<div><p>Then the solution flashed upon me: though this glorious summer morning seemed as real as it could be, I was dreaming! … Instantly, the vividness of life increased a hundred fold. Never had sea and sky and trees shone with such glamorous beauty; even the commonplace houses seemed alive and mystically beautiful.</p></div>



<p>In dreams as in waking life, attention makes the world alive. As many oneironauts have by now realized, critical state testing is not very different from mindfulness, meditation or similar practices of closely examining, sensing and being present with the world. These practices don’t only help us distinguish between waking and dreaming; they enrich our experience of both states.</p>



<p>In my own lucid dreams, a ripe, summer stone-fruit from the market explodes with flavor. The sensation of someone licking my belly feels wet. Pain and pleasure unfold in their phenomenal fullness. But this is always the case. The sea and sky always shine with their glamorous beauty. The world is detailed and rich. How often do I really <em>taste </em>a peach? How often do I take the time to examine the paving stones? Of course it’s trippy to examine my own hands: I never do it. I rarely look at <em>anything</em> so closely.</p>



<h2 id="h-higher-consciousness"><strong>Higher Consciousness</strong></h2>



<p>As the philosophers <a href="https://psycnet.apa.org/record/2007-09897-009" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Jennifer Windt and Thomas Metzinger</a> have observed, we travel through our lives as “naive realists,” assuming that as we perceive, touch and taste the world, we’re interfacing directly with some external, stable reality. But in truth, all experience, including our conscious experience of selfhood, relies on input from a chaotic world and is mediated by our limited sensory organs and shaped by our subjective internal landscape. Our model of reality is, in philosophical terms, “transparent,” so convincing as to be invisible. In this sense, dreams aren’t so different from waking experience: They’re both illusions we take, falsely, to be real.</p>



<p>“In normal experience, we give ourselves over to the world without really questioning whether it holds at the seams or not,” explained Peña-Guzmán, whose work explores the dreaming lives of animals. “What happens in lucidity is that you begin to attend to the seams and to the cracks — you begin attending to the fact that this is a constructed space, a model, a simulation.”</p>



<p>The process of attending to the seams is what cognitive scientists call <em>metacognition</em>: the ability to think about thinking. Many philosophers believe that metacognition in dreams requires the capacity for language, since one cannot make the judgement “I am in a dream” without a subject and a predicate. But Peña-Guzmán argues that animals may be able to recognize the oddness of their dreams in a more affective and embodied way — to feel, without forming a linguistic judgement, that their world’s gone weird. As with lucidity in people, this is above all a matter of <em>noticing.</em></p>



<p>That’s why techniques to cultivate lucid dreams, like counting fingers or examining the numbers on a clock, ask us to scrutinize the world. In people&nbsp;— and I sincerely hope in animals too — close attention sparks sudden clarity. This may take many forms. As Peña-Guzmán said, a dog may dream in smell, a bird in song. “Think about an electric eel that senses and produces electricity,” he said. “It’s conceivable that eel will have electric dreams, and there’s no way for us to even imagine what that is, because we don’t know what it means to experience electricity as meaningful. But they do.”</p>



<p>For humans, this phenomenal feast has another, more specifically cognitive flavor, too: the pleasure of awareness itself. Dreaming and waking perception are both illusory; they’re models constructed by our brains that turn sensory stimulus, or its absence, into meaning. In waking life, short of a heavy psychedelic experience, that illusion is all-encompassing; there’s no other level of consciousness to “wake up” into.</p>


<!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “In dreams as in waking life, attention makes the world alive.”    </p>

    
    
  </blockquote>
</figure>




<p>But in lucid dreams, we can examine the construction closely. Does this make a lucid dream <em>more </em>conscious than waking? Is it something, perhaps, just shy of enlightenment?</p>



<p>I asked the philosopher Jennifer Windt these questions when I reached her across the sleep-wake divide; as Los Angeles shaded into night, it was already the next morning in Melbourne, where Windt is senior lecturer of philosophy at Monash University. She winced. “I would struggle with that description,” she said. “I think that really assumes that consciousness can be neatly ordered in levels.” Windt is part of a school of philosophers painting a far less hierarchical, more multidimensional portrait of consciousness, one informed by close study of edge cases like out-of-body experiences, lucid dreams, mind-wanderings and hyper-realistic false awakenings.</p>



<p>“Traditionally, it’s been thought that not only are sleep and waking opposites, but that they impose a kind of rift, a sharp distinction between conscious states,” she explained. But recent empirical and theoretical work supports the idea that consciousness takes many forms along a spectrum between sleep and waking. Daydreams and mind-wanderings, for example, may be caused by spells of “local sleep” in the waking brain, and lucid dreams, which are linked to the reactivation of the dorsolateral prefrontal cortex — the seat of executive ego function, which is turned off during normal REM sleep — can be thought of as shades of waking consciousness in the gradient of sleep.</p>



<p>According to Windt’s work, a dream is an immersive, spatiotemporal hallucination, an experience of being present in a world where thoughts constitute reality. But perhaps such experiences can happen when we’re awake, too. “I think we should remain open to the possibility that if we define these states phenomenologically,” Windt said, “we might find them occurring in different behavioral states as well.”</p>



<h2 id="h-what-a-good-hologram"><strong>What A Good Hologram</strong></h2>



<p>Every time I go to sleep, I think a new world into being and put myself at its center. I used to take this nightly miracle for granted because in dreams we all think with an immediacy and directness that leaves no room for distanced self-awareness. When the lucidity comes on, however, autobiographical memories come rushing back. I can compare the dream to waking life or to previous dreams. I can see clearly that the dream phone in my dream hand is made of Jell-O because I have access to “<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2737577/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">secondary consciousness</a>,” or the meta-awareness of my own state.</p>



<p>I can’t say I’m putting that secondary consciousness to much use yet; mostly, I look for the seams. I find myself at a party in an unfamiliar house and I touch the walls, raid the fridge. What’s in there? Do the vegetables vanish when I close the door or do they have a little hoedown, like in an old cartoon? I wander into the den and turn on the TV. On the news, there’s a map of a country called “Orovno.” Did I name this country, draw this map? <em>Borges would love this shit</em>, I think. I ask a dream-character his name, trying to ascertain if he is, in some sense, me. He says: “Jeremy Allen White.” Ok, maybe not.</p>



<p>Lucidity advocates like LaBerge, who parlayed his early Stanford lucidity research into a long career as a dream guru, advise their acolytes that dream-control is a learned skill. With time, they promise, I can become a master of my dream domain, commanding characters to my will and redecorating the landscape to my tastes. I can stock my own fridge, draw my own maps, use the dream as a rehearsal space, perfect my tennis backhand, conquer my fear of public speaking. This emphasis on control and optimization doesn’t entice me much. It seems to diminish some of what makes dreams interesting to begin with — their weirdness and mystery, their associative logic.</p>



<p>“The thing that makes a dream exciting, at least for me, is that it’s <em>not</em> the waking world,” said Adam Haar Horowitz, a dream researcher and cognitive scientist who, when I reached him over Zoom at his home in rural Alaska, is fittingly curled up on his bed. Horowitz is the co-inventor of the <a href="https://www.media.mit.edu/projects/sleep-creativity/overview/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Dormio</a>, a dream engineering device that makes it possible to intentionally incubate specific dreams. The Dormio takes advantage of the moments between being awake and falling asleep known as the hypnagogic state; just as visions begin to form in the darkness and you sense yourself falling, the device whispers prompts into your ear, like “dream of a tree.”</p>



<p>Hypnagogia is when the full-fledged visions of the dreamworld begin to appear against the background of perception. As they coalesce into immersive hallucinations, they are remarkably suggestible. Horowitz’s technique involves waking sleepers at precise intervals, helping narrate the dream as it takes shape; he does so to foster creativity, treat recurrent nightmares in veterans and incubate bereavement dreams for people who have lost loved ones.</p>



<p>In these, he explained, lucidity would spoil the experience. Imagine sitting across the kitchen table from your deceased parent. “You don’t know it’s a dream,” Horowitz said. “That’s the beautiful thing. You’re sitting with them. Why would I want to be in a dream and <em>know</em> it’s a dream? I want to be in the room and want to have the conversation with the person. I don’t want to poke them and say, ‘Wow, what a good hologram.’”</p>


<!-- Quote Block Template -->

<figure>

  <blockquote>

    <p>
      “No wonder so many cultures have rituals of group dreaming.”    </p>

    
    
  </blockquote>
</figure>




<p>Horowitz finds the culture of lucid dreaming, with its emphasis on individuality and self-optimization, to be somewhat suspect. He asks me, rhetorically: What do people <em>do</em> in lucid dreams? They fulfill fantasies of control, seek personal thrills like flying, have sex with Jeremy Allen White.</p>



<p>The Dormio system is the only dream incubation tool of its type in experimental use, but there are plenty of consciousness-hacking <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6517539/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">devices</a> on the market intended to induce lucid dreams on demand. LaBerge has developed several over the decades with names like the DreamLight and the NovaDreamer. A well-funded AI startup,<a href="https://www.prophetic.com/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer"> Prophetic</a>, is currently training machine learning models on EEG and fMRI lucid dream data, hoping to beam their findings via transcranial-focused ultrasound directly into willing brains; their Halo device, “the most advanced consumer neurotechnology wearable ever created,” will soon be available.</p>



<p>As the media scholar Aleena Chia has <a href="https://openpublishing.library.umass.edu/cpo/article/id/53/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">written</a>, such technologies promise a “youtopia of automatized dream entertainment.” In certain sectors of Silicon Valley, lucid dreaming is talked about like virtual reality without a headset. “What a lame way to relate to your own consciousness,” said Horowitz.</p>



<p>Dream incubation, on the other hand, he said, “is a really holy, really humble, really hands-off tradition” with ancient roots. In classical Greek antiquity, dream-seekers traveled to dedicated temples in order to seek specific dreams of healing or guidance; after rituals of purification and supplication, they slept, communally, in sanctuaries dedicated to this purpose. As the religious scholar Kimberley C. Patton has proposed in her work, these temples were “god-haunted” places where the gods used dreams to speak between worlds. In the tradition of incubation, she has written, “Gods and human beings are the co-creators of dreams in the darkness of our mutual sleep.”</p>



<p>In the morning, the temple dreamers interpreted their visions with the guidance of priests. Nothing about the dream was private; it was something to be plumbed in public alongside others upon waking with the morning. The dream’s prescriptions, a cure proffered by the gods, were enacted in waking life, with the full support of the dreamers’ communities. It is from this tradition, far more ancient than Freud, that we get dream interpretation. Similar rituals of public dream incubation have existed throughout history and all over the world, in medieval Japanese Buddhism, in Shia and Sufi Islamic traditions, in Bengal, among the ancient and modern highland Maya, and in many North American Indigenous cultures.</p>



<p>I’ve had a few flying dreams since my first lucid dream. I’ve taken swan dives off fire escapes, soared over fields of wildflowers, been pulled into the sun itself. It can feel exhilarating to fly, to feel velocity amid total stillness. To linger in the light of an imagined sky. But it’s cold up there, too, trapped inside the dream. I can see it all, but I have nobody to share it with. No wonder so many cultures have rituals of group dreaming. No wonder they traveled far and wide to dream together, to seek succor and interpretation from oneiromantic priests. It makes the night less lonely.</p>

          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proton launches its own version of Google Docs (337 pts)]]></title>
            <link>https://www.engadget.com/proton-launches-its-own-version-of-google-docs-100044471.html</link>
            <guid>40864914</guid>
            <pubDate>Wed, 03 Jul 2024 11:25:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/proton-launches-its-own-version-of-google-docs-100044471.html">https://www.engadget.com/proton-launches-its-own-version-of-google-docs-100044471.html</a>, See on <a href="https://news.ycombinator.com/item?id=40864914">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/protons-windows-and-macos-mail-app-is-out-of-beta-and-available-now-110010822.html" data-ylk="slk:Proton;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">Proton</a> now has its own version of Google Docs in its Drive cloud storage service, and like the company's other products, it comes with end-to-end encryption. The company says its flavor of Docs "offers a unique solution in a market where most popular products neglect privacy" and recommends it for use in the healthcare, media, finance and legal industries. <a data-i13n="elm:affiliate_link;sellerN:;elmt:;cpos:2;pos:1" href="https://shopping.yahoo.com/rdlw?siteId=us-engadget&amp;pageId=1p-autolink&amp;featureId=text-link&amp;custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3Byb3Rvbi5tZS9ibG9nL2RvY3MtcHJvdG9uLWRyaXZlIiwiY29udGVudFV1aWQiOiJjMmYyMGEyYS05ZGEzLTQyZmMtYjhmMC03MGI3ZDRlMGFhNmYifQ&amp;signature=AQAAAWZaQ6nJO7zP4rH3JS2Y44qB7q_HbbOpt8RRVvU6nYbn&amp;gcReferrer=https%3A%2F%2Fproton.me%2Fblog%2Fdocs-proton-drive" rel="nofollow noopener" target="_blank" data-ylk="slk:Proton Docs;elm:affiliate_link;sellerN:;elmt:;cpos:2;pos:1;itc:0;sec:content-canvas">Proton Docs</a> has advanced formatting and image embed options like Google Docs has and can create, open and edit documents in multiple formats, including Microsoft .docx.</p><p>It has collaboration tools similar to Google Docs', as well. Users can invite anyone to view and edit their documents, though those without a Proton account will be prompted to create one first. The free tier of Proton Drive includes essential document features so people don't have to pay for the service if they don't want to. Participants will be able to add comments to the document, reply to them and resolve them. And users will see other participants' presence and their cursor placements in real time, so that they know who's working on which part of the document and so that their edits don't clash.</p><p>Proton didn't say whether the launch of Docs means it's going to roll out analogues of Google's other Workspace apps in the future, but the company did <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/proton-encrypted-email-vpn-calendar-rebrand-103024950.html" data-ylk="slk:expand its offerings;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas">expand its offerings</a> with several different products over the last few years. In addition to Drive cloud storage — and, of course, its email service — the company has a VPN, an encrypted calendar and even a <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/proton-launches-its-own-password-manager-115039870.html" data-ylk="slk:password manager;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas">password manager</a>. Docs will make its way to Proton users over the coming days.</p><p>This article contains affiliate links; if you click such a link and make a purchase, we may earn a commission.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Jb / json.bash – Command-line tool (and bash library) that creates JSON (131 pts)]]></title>
            <link>https://github.com/h4l/json.bash</link>
            <guid>40864541</guid>
            <pubDate>Wed, 03 Jul 2024 10:18:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/h4l/json.bash">https://github.com/h4l/json.bash</a>, See on <a href="https://news.ycombinator.com/item?id=40864541">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><code>$ jb name=json.bash creates=JSON</code></h2><a id="user-content--jb-namejsonbash-createsjson" aria-label="Permalink: $ jb name=json.bash creates=JSON" href="#-jb-namejsonbash-createsjson"></a></p>
<p dir="auto"><code>json.bash</code> is a command-line tool and bash library that creates JSON.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb name=json.bash creates=JSON dependencies:[,]=Bash,Grep
{&quot;name&quot;:&quot;json.bash&quot;,&quot;creates&quot;:&quot;JSON&quot;,&quot;dependencies&quot;:[&quot;Bash&quot;,&quot;Grep&quot;]}

$ # Values are strings unless explicitly typed
$ jb id=42 size:number=42 surname=null data:null
{&quot;id&quot;:&quot;42&quot;,&quot;size&quot;:42,&quot;surname&quot;:&quot;null&quot;,&quot;data&quot;:null}

$ # Reference variables with @name
$ id=42 date=2023-06-23 jb @id created@date modified@date
{&quot;id&quot;:&quot;42&quot;,&quot;created&quot;:&quot;2023-06-23&quot;,&quot;modified&quot;:&quot;2023-06-23&quot;}

$ # Pull data from files
$ printf hunter2 > /tmp/password; jb @/tmp/password
{&quot;password&quot;:&quot;hunter2&quot;}

$ # Pull data from shell pipelines
$ jb sizes:number[]@<(seq 1 4)
{&quot;sizes&quot;:[1,2,3,4]}

$ # Nest jb calls
$ jb type=club members:json[]@<(jb name=Bob; jb name=Alice)
{&quot;type&quot;:&quot;club&quot;,&quot;members&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}

$ # The Bash API can reference arrays and create JSON efficiently — without forking
$ source json.bash
$ out=people json name=Bob; out=people json name=Alice; sizes=(42 91 2)
$ id=&quot;abc.123&quot; json @id @sizes:number[] @people:json[]
{&quot;id&quot;:&quot;abc.123&quot;,&quot;sizes&quot;:[42,91,2],&quot;people&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}"><pre>$ <span>jb name=json.bash creates=JSON dependencies:[,]=Bash,Grep</span>
<span>{"name":"json.bash","creates":"JSON","dependencies":["Bash","Grep"]}</span>

$ <span><span><span>#</span> Values are strings unless explicitly typed</span></span>
$ <span>jb id=42 size:number=42 surname=null data:null</span>
<span>{"id":"42","size":42,"surname":"null","data":null}</span>

$ <span><span><span>#</span> Reference variables with @name</span></span>
$ <span>id=42 date=2023-06-23 jb @id created@date modified@date</span>
<span>{"id":"42","created":"2023-06-23","modified":"2023-06-23"}</span>

$ <span><span><span>#</span> Pull data from files</span></span>
$ <span><span>printf</span> hunter2 <span>&gt;</span> /tmp/password<span>;</span> jb @/tmp/password</span>
<span>{"password":"hunter2"}</span>

$ <span><span><span>#</span> Pull data from shell pipelines</span></span>
$ <span>jb sizes:number[]@<span><span>&lt;(</span>seq 1 4<span>)</span></span></span>
<span>{"sizes":[1,2,3,4]}</span>

$ <span><span><span>#</span> Nest jb calls</span></span>
$ <span>jb type=club members:json[]@<span><span>&lt;(</span>jb name=Bob<span>;</span> jb name=Alice<span>)</span></span></span>
<span>{"type":"club","members":[{"name":"Bob"},{"name":"Alice"}]}</span>

$ <span><span><span>#</span> The Bash API can reference arrays and create JSON efficiently — without forking</span></span>
$ <span><span>source</span> json.bash</span>
$ <span>out=people json name=Bob<span>;</span> out=people json name=Alice<span>;</span> sizes=(42 91 2)</span>
$ <span>id=<span><span>"</span>abc.123<span>"</span></span> json @id @sizes:number[] @people:json[]</span>
<span>{"id":"abc.123","sizes":[42,91,2],"people":[{"name":"Bob"},{"name":"Alice"}]}</span></pre></div>
<p dir="auto"><code>json.bash</code>'s <em><a href="https://en.wikipedia.org/wiki/Unix_philosophy" rel="nofollow">one thing</a></em> is to get shell-native data (environment variables,
files, program output) to somewhere else, using JSON encapsulate it robustly.</p>
<p dir="auto">Creating JSON from the command line or a shell script can be useful when:</p>
<ul dir="auto">
<li>You need some ad-hoc JSON to interact with a JSON-consuming application</li>
<li>You need to bundle up some data to share or move elsewhere. JSON can a good
alternative to base64-encoding or a file archive.</li>
</ul>
<p dir="auto">It does no transformation or filtering itself, instead it pulls data from things
you <strong>already know how to use</strong>, like files, command-line arguments, environment
variables, shell pipelines and shell scripts. It glues together data from these
sources, giving it enough structure to make the data easy to consume reliably in
downstream programs.</p>
<p dir="auto">It's something like a reverse <code>tee</code> — it pulls together data sources, using JSON
to represent the aggregation. It's not an alternative to to data-processing
tools like <code>jq</code>, rather it helps assemble JSON to send into JSON-consuming tools
like <code>jq</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ol dir="auto">
<li><a href="#install">Install</a></li>
<li><a href="#how-to-guides">How-to guides</a></li>
<li><a href="#background--performance-notes">Background &amp; performance notes</a></li>
<li><a href="#credits">Credits</a></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Container image</h3><a id="user-content-container-image" aria-label="Permalink: Container image" href="#container-image"></a></p>
<p dir="auto">We publish the container image
<a href="https://github.com/h4l/json.bash/pkgs/container/json.bash%2Fjb"><code>ghcr.io/h4l/json.bash/jb</code></a>
with <code>jb-*</code> and <code>json.bash</code>, perhaps useful to try without installing.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ docker container run --rm ghcr.io/h4l/json.bash/jb msg=Hi
{&quot;msg&quot;:&quot;Hi&quot;}

$ # Get a bash shell to try things interactively
$ docker container run --rm -it ghcr.io/h4l/json.bash/jb
bash-5.2# jb os-release:{}@<(xargs < /etc/os-release env -i)
{&quot;os-release&quot;:{&quot;NAME&quot;:&quot;Alpine Linux&quot;,&quot;ID&quot;:&quot;alpine&quot;,&quot;VERSION_ID&quot;:&quot;3.18.2&quot;,&quot;PRETTY_NAME&quot;:&quot;Alpine Linux v3.18&quot;,&quot;HOME_URL&quot;:&quot;https://alpinelinux.org/&quot;,&quot;BUG_REPORT_URL&quot;:&quot;https://gitlab.alpinelinux.org/alpine/aports/-/issues&quot;}}"><pre>$ <span>docker container run --rm ghcr.io/h4l/json.bash/jb msg=Hi</span>
<span>{"msg":"Hi"}</span>

$ <span><span><span>#</span> Get a bash shell to try things interactively</span></span>
$ <span>docker container run --rm -it ghcr.io/h4l/json.bash/jb</span>
<span>bash-5.2# jb os-release:{}@&lt;(xargs &lt; /etc/os-release env -i)</span>
<span>{"os-release":{"NAME":"Alpine Linux","ID":"alpine","VERSION_ID":"3.18.2","PRETTY_NAME":"Alpine Linux v3.18","HOME_URL":"https://alpinelinux.org/","BUG_REPORT_URL":"https://gitlab.alpinelinux.org/alpine/aports/-/issues"}}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">OS Packages</h3><a id="user-content-os-packages" aria-label="Permalink: OS Packages" href="#os-packages"></a></p>
<p dir="auto">Package-manager files are available for any package manager supported by
<a href="https://fpm.readthedocs.io/" rel="nofollow"><code>fpm</code></a> (at least apk, deb, freebsd, rpm, sh (self extracting), tar,
possibly more).</p>
<p dir="auto">We publish the container image
<a href="https://github.com/h4l/json.bash/pkgs/container/json.bash%2Fpkg"><code>ghcr.io/h4l/json.bash/pkg</code></a>
that can generate a package file in whichever format you like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ docker container run --rm -v &quot;$(pwd):/pkg&quot; ghcr.io/h4l/json.bash/pkg deb
Generating: /pkg/json.bash_0.2.2-dev.deb

$ ls
json.bash_0.2.2-dev.deb
$ dpkg -i /pkg/json.bash_0.2.2-dev.deb"><pre>$ <span>docker container run --rm -v <span><span>"</span><span><span>$(</span>pwd<span>)</span></span>:/pkg<span>"</span></span> ghcr.io/h4l/json.bash/pkg deb</span>
<span>Generating: /pkg/json.bash_0.2.2-dev.deb</span>

$ <span>ls</span>
<span>json.bash_0.2.2-dev.deb</span>
$ <span>dpkg -i /pkg/json.bash_0.2.2-dev.deb</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Manual install</h3><a id="user-content-manual-install" aria-label="Permalink: Manual install" href="#manual-install"></a></p>
<p dir="auto">Installing manually is quite straightforward.</p>
<details>
  <summary>Expand this for instructions</summary>
<div dir="auto" data-snippet-clipboard-copy-content="# Alternatively, use /usr/local/bin to install system-wide
cd ~/.local/bin
curl -fsSL -O &quot;https://raw.githubusercontent.com/h4l/json.bash/HEAD/json.bash&quot;
chmod +x json.bash
ln -s json.bash jb
ln -s json.bash jb-array

# If your shell is bash, you can alias jb and jb-array to the bash functions for
# better performance. You should add this line to your ~/.bashrc
source json.bash; alias jb=json jb-array=json.array

# Optional: if you'd also like jb-echo, jb-cat, jb-stream
for name in jb-echo jb-cat jb-stream; do
  curl -fsSL -O &quot;https://raw.githubusercontent.com/h4l/json.bash/HEAD/bin/${name:?}&quot;
  chmod +x &quot;${name:?}&quot;
done"><pre><span><span>#</span> Alternatively, use /usr/local/bin to install system-wide</span>
<span>cd</span> <span>~</span>/.local/bin
curl -fsSL -O <span><span>"</span>https://raw.githubusercontent.com/h4l/json.bash/HEAD/json.bash<span>"</span></span>
chmod +x json.bash
ln -s json.bash jb
ln -s json.bash jb-array

<span><span>#</span> If your shell is bash, you can alias jb and jb-array to the bash functions for</span>
<span><span>#</span> better performance. You should add this line to your ~/.bashrc</span>
<span>source</span> json.bash<span>;</span> <span>alias</span> jb=json jb-array=json.array

<span><span>#</span> Optional: if you'd also like jb-echo, jb-cat, jb-stream</span>
<span>for</span> <span>name</span> <span>in</span> jb-echo jb-cat jb-stream<span>;</span> <span>do</span>
  curl -fsSL -O <span><span>"</span>https://raw.githubusercontent.com/h4l/json.bash/HEAD/bin/<span>${name<span>:?</span>}</span><span>"</span></span>
  chmod +x <span><span>"</span><span>${name<span>:?</span>}</span><span>"</span></span>
<span>done</span></pre></div>
<p dir="auto">To uninstall, remove <code>json.bash</code>, <code>jb</code>, <code>jb-array</code>, <code>jb-echo</code>, <code>jb-cat</code> and
<code>jb-stream</code> from the directory you installed them to (run <code>which -a json.bash</code>
to find where it is).</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">How-to guides</h2><a id="user-content-how-to-guides" aria-label="Permalink: How-to guides" href="#how-to-guides"></a></p>
<ol dir="auto">
<li><a href="#the-jsonbash-commands">The <code>json.bash</code> commands</a></li>
<li><a href="#object-keys">Object keys</a></li>
<li><a href="#object-values">Object values</a></li>
<li><a href="#arrays-mixed-types-fixed-length">Arrays (mixed types, fixed length)</a></li>
<li><a href="#argument-types">Argument types</a></li>
<li><a href="#array-values-uniform-types-variable-length">Array values (uniform types, variable length)</a></li>
<li><a href="#object-values-uniform-types-variable-length">Object values (uniform types, variable length)</a></li>
<li><a href="#-arguments-merge-entries-into-the-host-objectarray"><code>...</code> arguments (merge entries into the host object/array)</a></li>
<li><a href="#missing--empty-values">Missing / empty values</a></li>
<li><a href="#nested-json-with-json-and-raw-types">Nested JSON with <code>:json</code> and <code>:raw</code> types</a></li>
<li><a href="#file-references">File references</a></li>
<li><a href="#argument-structure">Argument structure</a></li>
<li><a href="#error-handling">Error handling</a></li>
<li><a href="#security-and-correctness">Security and correctness</a></li>
<li><a href="#jb-cat-jb-echo-jb-stream-utility-programs"><code>jb-cat</code>, <code>jb-echo</code>, <code>jb-stream</code> utility programs</a></li>
<li><a href="#streaming-output">Streaming output</a></li>
</ol>
<p dir="auto">These examples mostly use <code>jb</code>, which is the <code>json.bash</code> library run as a
stand-alone program. From within a bash script you get better performance by
running <code>source json.bash</code> and using the <code>json</code> bash function, which is a
superset of stand-alone <code>jb</code> and much faster because it doesn't execute new
child processes when called. See the
<a href="#background--performance-notes">Background &amp; performance notes</a> section for
more.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The <code>json.bash</code> commands</h3><a id="user-content-the-jsonbash-commands" aria-label="Permalink: The json.bash commands" href="#the-jsonbash-commands"></a></p>
<p dir="auto"><code>jb</code> / <code>jb-array</code> / <code>json</code> / <code>json.array</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # The jb program creates JSON objects
$ jb
{}

$ # The jb-array creates arrays, but otherwise works like jb.
$ jb-array :number=4
[4]

$ # From a bash shell or bash script, use the json and json.array functions
$ source json.bash  # no path is needed if json.bash is on $PATH
$ json
{}

$ # json.array creates arrays, but otherwise works like json
$ json.array
[]"><pre>$ <span><span><span>#</span> The jb program creates JSON objects</span></span>
$ <span>jb</span>
<span>{}</span>

$ <span><span><span>#</span> The jb-array creates arrays, but otherwise works like jb.</span></span>
$ <span>jb-array :number=4</span>
<span>[4]</span>

$ <span><span><span>#</span> From a bash shell or bash script, use the json and json.array functions</span></span>
$ <span><span>source</span> json.bash  <span><span>#</span> no path is needed if json.bash is on $PATH</span></span>
$ <span>json</span>
<span>{}</span>

$ <span><span><span>#</span> json.array creates arrays, but otherwise works like json</span></span>
$ <span>json.array</span>
<span>[]</span></pre></div>
<p dir="auto">Each argument defines an entry in the object or array. Arguments can contain a
key, type and value in this structure:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/h4l/json.bash/blob/main/docs/syntax-diagrams/minimal-argument.svg"><img width="100%" src="https://github.com/h4l/json.bash/raw/main/docs/syntax-diagrams/minimal-argument.svg" alt="A railroad syntax diagram showing a high-level summary of the key, type and value structure of an argument." title="Minimal Argument Structure Diagram"></a></p>
<p dir="auto">The <a href="#argument-structure">Argument structure</a> section has more details.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Object keys</h3><a id="user-content-object-keys" aria-label="Permalink: Object keys" href="#object-keys"></a></p>
<p dir="auto">Each argument creates an entry in the JSON object. The first part of each
argument defines the key.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb msg=hi
{&quot;msg&quot;:&quot;hi&quot;}

$ # Keys can contain most characters (except @:=, unless escaped)
$ jb &quot;🐚&quot;=JSON
{&quot;🐚&quot;:&quot;JSON&quot;}

$ # Key values can come from variables
$ key=&quot;The Message&quot; jb @key=hi
{&quot;The Message&quot;:&quot;hi&quot;}

$ # Key variables can contain any characters
$ key=&quot;@key:with=reserved-chars&quot; jb @key=hi
{&quot;@key:with=reserved-chars&quot;:&quot;hi&quot;}

$ # Each argument defines a key
$ var=c jb a=X b=Y @var=Z
{&quot;a&quot;:&quot;X&quot;,&quot;b&quot;:&quot;Y&quot;,&quot;c&quot;:&quot;Z&quot;}

$ # Keys may be reused, but should not be, because JSON parser behaviour for
$ # duplicate keys is undefined.
$ jb a=A a=B a=C
{&quot;a&quot;:&quot;A&quot;,&quot;a&quot;:&quot;B&quot;,&quot;a&quot;:&quot;C&quot;}

$ # The reserved characters can be escaped by doubling them
$ jb =@@handle=ok a::z=ok 1+1==2=ok
{&quot;@handle&quot;:&quot;ok&quot;,&quot;a:z&quot;:&quot;ok&quot;,&quot;1+1=2&quot;:&quot;ok&quot;}"><pre>$ <span>jb msg=hi</span>
<span>{"msg":"hi"}</span>

$ <span><span><span>#</span> Keys can contain most characters (except @:=, unless escaped)</span></span>
$ <span>jb <span><span>"</span>🐚<span>"</span></span>=JSON</span>
<span>{"🐚":"JSON"}</span>

$ <span><span><span>#</span> Key values can come from variables</span></span>
$ <span>key=<span><span>"</span>The Message<span>"</span></span> jb @key=hi</span>
<span>{"The Message":"hi"}</span>

$ <span><span><span>#</span> Key variables can contain any characters</span></span>
$ <span>key=<span><span>"</span>@key:with=reserved-chars<span>"</span></span> jb @key=hi</span>
<span>{"@key:with=reserved-chars":"hi"}</span>

$ <span><span><span>#</span> Each argument defines a key</span></span>
$ <span>var=c jb a=X b=Y @var=Z</span>
<span>{"a":"X","b":"Y","c":"Z"}</span>

$ <span><span><span>#</span> Keys may be reused, but should not be, because JSON parser behaviour for</span></span>
$ <span><span><span>#</span> duplicate keys is undefined.</span></span>
$ <span>jb a=A a=B a=C</span>
<span>{"a":"A","a":"B","a":"C"}</span>

$ <span><span><span>#</span> The reserved characters can be escaped by doubling them</span></span>
$ <span>jb =@@handle=ok a::z=ok 1+1==2=ok</span>
<span>{"@handle":"ok","a:z":"ok","1+1=2":"ok"}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Object values</h3><a id="user-content-object-values" aria-label="Permalink: Object values" href="#object-values"></a></p>
<p dir="auto">The last part of each argument after a <code>=</code> or <code>@</code> defines the value. Values can
contain their value directly, or reference a variable or file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb message=&quot;Hello World&quot;
{&quot;message&quot;:&quot;Hello World&quot;}

$ greeting=&quot;Hi there&quot; jb message@greeting
{&quot;message&quot;:&quot;Hi there&quot;}

$ # Variable references without a value define the key and value in one go.
$ greeting=&quot;Hi&quot; name=Bob jb @greeting @name
{&quot;greeting&quot;:&quot;Hi&quot;,&quot;name&quot;:&quot;Bob&quot;}

$ # This also applies (less usefully) to inline entries.
$ jb message
{&quot;message&quot;:&quot;message&quot;}

$ # Inline values following a `=` have no content restrictions.
$ jb message=@value:with=reserved-chars
{&quot;message&quot;:&quot;@value:with=reserved-chars&quot;}

$ # @ values that begin with / or ./ are references to files
$ printf hunter2 > /tmp/password; jb secret@/tmp/password
{&quot;secret&quot;:&quot;hunter2&quot;}

$ # File references without a value define the key and value in one go.
$ jb @/tmp/password
{&quot;password&quot;:&quot;hunter2&quot;}"><pre>$ <span>jb message=<span><span>"</span>Hello World<span>"</span></span></span>
<span>{"message":"Hello World"}</span>

$ <span>greeting=<span><span>"</span>Hi there<span>"</span></span> jb message@greeting</span>
<span>{"message":"Hi there"}</span>

$ <span><span><span>#</span> Variable references without a value define the key and value in one go.</span></span>
$ <span>greeting=<span><span>"</span>Hi<span>"</span></span> name=Bob jb @greeting @name</span>
<span>{"greeting":"Hi","name":"Bob"}</span>

$ <span><span><span>#</span> This also applies (less usefully) to inline entries.</span></span>
$ <span>jb message</span>
<span>{"message":"message"}</span>

$ <span><span><span>#</span> Inline values following a `=` have no content restrictions.</span></span>
$ <span>jb message=@value:with=reserved-chars</span>
<span>{"message":"@value:with=reserved-chars"}</span>

$ <span><span><span>#</span> @ values that begin with / or ./ are references to files</span></span>
$ <span><span>printf</span> hunter2 <span>&gt;</span> /tmp/password<span>;</span> jb secret@/tmp/password</span>
<span>{"secret":"hunter2"}</span>

$ <span><span><span>#</span> File references without a value define the key and value in one go.</span></span>
$ <span>jb @/tmp/password</span>
<span>{"password":"hunter2"}</span></pre></div>
<p dir="auto">File references are more powerful than they might first appear, as they enable
all sorts of dynamic content to be pulled into JSON data, including nested <code>jb</code>
calls. See <a href="#file-references">File references</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Arrays (mixed types, fixed length)</h3><a id="user-content-arrays-mixed-types-fixed-length" aria-label="Permalink: Arrays (mixed types, fixed length)" href="#arrays-mixed-types-fixed-length"></a></p>
<p dir="auto">Creating arrays is much like creating objects — arguments hold values, either
directly, or referencing variables or files.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb-array Hi &quot;Bob Bobson&quot;
[&quot;Hi&quot;,&quot;Bob Bobson&quot;]

$ message=Hi name=&quot;Bob Bobson&quot; jb-array @message @name
[&quot;Hi&quot;,&quot;Bob Bobson&quot;]

$ printf 'Bob Bobson' > /tmp/name
$ jb-array Hi @/tmp/name
[&quot;Hi&quot;,&quot;Bob Bobson&quot;]

$ # Array values in arguments cannot contain @:= characters (unless escaped by
$ # doubling them), because they would clash with @variable and :type syntax.
$ # However, values following a = can contain anything, so long as they follow a
$ # key or type section.
$ jb-array :='@foo:bar=baz' :='{&quot;not&quot;:&quot;parsed&quot;}' =@@es::cap==ed
[&quot;@foo:bar=baz&quot;,&quot;{\&quot;not\&quot;:\&quot;parsed\&quot;}&quot;,&quot;@es:cap=ed&quot;]

$ # Values from variables have no restrictions. Arrays use the same argument
$ # syntax as objects, so values in the key or value position work the same.
$ s1='@foo:bar=baz' s2='{&quot;not&quot;:&quot;parsed&quot;}' jb-array @s1: :@s2
[&quot;@foo:bar=baz&quot;,&quot;{\&quot;not\&quot;:\&quot;parsed\&quot;}&quot;]

$ # It's possible to set a key as well as value for array entries, but the key
$ # is ignored.
$ a=A b=B jb-array @a@a @b=B c=C
[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;]"><pre>$ <span>jb-array Hi <span><span>"</span>Bob Bobson<span>"</span></span></span>
<span>["Hi","Bob Bobson"]</span>

$ <span>message=Hi name=<span><span>"</span>Bob Bobson<span>"</span></span> jb-array @message @name</span>
<span>["Hi","Bob Bobson"]</span>

$ <span><span>printf</span> <span><span>'</span>Bob Bobson<span>'</span></span> <span>&gt;</span> /tmp/name</span>
$ <span>jb-array Hi @/tmp/name</span>
<span>["Hi","Bob Bobson"]</span>

$ <span><span><span>#</span> Array values in arguments cannot contain @:= characters (unless escaped by</span></span>
$ <span><span><span>#</span> doubling them), because they would clash with @variable and :type syntax.</span></span>
$ <span><span><span>#</span> However, values following a = can contain anything, so long as they follow a</span></span>
$ <span><span><span>#</span> key or type section.</span></span>
$ <span>jb-array :=<span><span>'</span>@foo:bar=baz<span>'</span></span> :=<span><span>'</span>{"not":"parsed"}<span>'</span></span> =@@es::cap==ed</span>
<span>["@foo:bar=baz","{\"not\":\"parsed\"}","@es:cap=ed"]</span>

$ <span><span><span>#</span> Values from variables have no restrictions. Arrays use the same argument</span></span>
$ <span><span><span>#</span> syntax as objects, so values in the key or value position work the same.</span></span>
$ <span>s1=<span><span>'</span>@foo:bar=baz<span>'</span></span> s2=<span><span>'</span>{"not":"parsed"}<span>'</span></span> jb-array @s1: :@s2</span>
<span>["@foo:bar=baz","{\"not\":\"parsed\"}"]</span>

$ <span><span><span>#</span> It's possible to set a key as well as value for array entries, but the key</span></span>
$ <span><span><span>#</span> is ignored.</span></span>
$ <span>a=A b=B jb-array @a@a @b=B c=C</span>
<span>["A","B","C"]</span></pre></div>
<p dir="auto"><code>jb-array</code> is best for creating tuple-like arrays with a fixed number of entries
with a mix of types. Use
<a href="#value-arrays-uniform-types-variable-length">value arrays</a> to create
variable-length arrays containing the same type.</p>
<p dir="auto"><code>json.array</code> is the Bash API equivalent of <code>jb-array</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Argument types</h3><a id="user-content-argument-types" aria-label="Permalink: Argument types" href="#argument-types"></a></p>
<p dir="auto">Values are strings unless explicitly typed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # These arguments are strings because they don't use a type
$ jb data=42 surname=null favourite_word=true
{&quot;data&quot;:&quot;42&quot;,&quot;surname&quot;:&quot;null&quot;,&quot;favourite_word&quot;:&quot;true&quot;}

$ # Non-string values need explicit types
$ jb size:number=42
{&quot;size&quot;:42}

$ # true/false/null have types which don't require redundant values
$ jb active:true enabled:false data:null
{&quot;active&quot;:true,&quot;enabled&quot;:false,&quot;data&quot;:null}

$ # Regardless, they can be given values if desired
$ jb active:true=true enabled:false=false data:null=null
{&quot;active&quot;:true,&quot;enabled&quot;:false,&quot;data&quot;:null}

$ # The bool type allows either true or false values.
$ active=true jb @active:bool enabled:bool=false
{&quot;active&quot;:true,&quot;enabled&quot;:false}

$ # The auto type outputs true/false/null and number values.
$ jb a:auto=42 b:auto=Hi c:auto=true d:auto=false e:auto=null f:auto=[] g:auto={}
{&quot;a&quot;:42,&quot;b&quot;:&quot;Hi&quot;,&quot;c&quot;:true,&quot;d&quot;:false,&quot;e&quot;:null,&quot;f&quot;:&quot;[]&quot;,&quot;g&quot;:&quot;{}&quot;}

$ # auto can be used selectively like other types
$ data=42 jb a=42 b:auto=42 c:auto@data
{&quot;a&quot;:&quot;42&quot;,&quot;b&quot;:42,&quot;c&quot;:42}

$ # In the Bash API (but not yet the jb CLI), the default type can be changed
$ # using the json_defaults option. First you create a named defaults set:
$ source json.bash
$ json.define_defaults num :number

$ # Then use the name with json_defaults when calling json to use your defaults
$ json_defaults=num json data=42
{&quot;data&quot;:42}

$ # In which case strings need to be explicitly typed
$ json_defaults=num json data=42 msg=Hi
json.encode_number(): not all inputs are numbers: 'Hi'
json(): Could not encode the value of argument 'msg=Hi' as a 'number' value. Read from inline value.
�␘

$ json_defaults=num json data=42 msg:string=Hi
{&quot;data&quot;:42,&quot;msg&quot;:&quot;Hi&quot;}"><pre>$ <span><span><span>#</span> These arguments are strings because they don't use a type</span></span>
$ <span>jb data=42 surname=null favourite_word=true</span>
<span>{"data":"42","surname":"null","favourite_word":"true"}</span>

$ <span><span><span>#</span> Non-string values need explicit types</span></span>
$ <span>jb size:number=42</span>
<span>{"size":42}</span>

$ <span><span><span>#</span> true/false/null have types which don't require redundant values</span></span>
$ <span>jb active:true enabled:false data:null</span>
<span>{"active":true,"enabled":false,"data":null}</span>

$ <span><span><span>#</span> Regardless, they can be given values if desired</span></span>
$ <span>jb active:true=true enabled:false=false data:null=null</span>
<span>{"active":true,"enabled":false,"data":null}</span>

$ <span><span><span>#</span> The bool type allows either true or false values.</span></span>
$ <span>active=true jb @active:bool enabled:bool=false</span>
<span>{"active":true,"enabled":false}</span>

$ <span><span><span>#</span> The auto type outputs true/false/null and number values.</span></span>
$ <span>jb a:auto=42 b:auto=Hi c:auto=true d:auto=false e:auto=null f:auto=[] g:auto={}</span>
<span>{"a":42,"b":"Hi","c":true,"d":false,"e":null,"f":"[]","g":"{}"}</span>

$ <span><span><span>#</span> auto can be used selectively like other types</span></span>
$ <span>data=42 jb a=42 b:auto=42 c:auto@data</span>
<span>{"a":"42","b":42,"c":42}</span>

$ <span><span><span>#</span> In the Bash API (but not yet the jb CLI), the default type can be changed</span></span>
$ <span><span><span>#</span> using the json_defaults option. First you create a named defaults set:</span></span>
$ <span><span>source</span> json.bash</span>
$ <span>json.define_defaults num :number</span>

$ <span><span><span>#</span> Then use the name with json_defaults when calling json to use your defaults</span></span>
$ <span>json_defaults=num json data=42</span>
<span>{"data":42}</span>

$ <span><span><span>#</span> In which case strings need to be explicitly typed</span></span>
$ <span>json_defaults=num json data=42 msg=Hi</span>
<span>json.encode_number(): not all inputs are numbers: 'Hi'</span>
<span>json(): Could not encode the value of argument 'msg=Hi' as a 'number' value. Read from inline value.</span>
<span>�␘</span>

$ <span>json_defaults=num json data=42 msg:string=Hi</span>
<span>{"data":42,"msg":"Hi"}</span></pre></div>
<details>
  <summary>Why does <code>json.bash</code> require explicit types?</summary>
  <p dir="auto"><h4 tabindex="-1" dir="auto">Why does <code>json.bash</code> require explicit types?</h4><a id="user-content-why-does-jsonbash-require-explicit-types" aria-label="Permalink: Why does json.bash require explicit types?" href="#why-does-jsonbash-require-explicit-types"></a></p>
  <p dir="auto">Type coercion can look good in demos, but my opinion is that in practice,
  fields are more commonly of a specific type than a union of several options,
  so coercing types by default makes it harder to achieve correct behaviour in
  the common case. The <a href="https://hitchdev.com/strictyaml/why/implicit-typing-removed/" rel="nofollow">Norway Problem</a>
  is worth reading about if you're not familiar with it.</p>
  <p dir="auto">Regardless, you can make the <code>:auto</code> type the default by using <code>json_defaults</code> when calling <code>json</code> from the
  Bash API (as demonstrated above). (This isn't yet exposed through the
  <code>jb</code> CLI.)</p>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Array values (uniform types, variable length)</h3><a id="user-content-array-values-uniform-types-variable-length" aria-label="Permalink: Array values (uniform types, variable length)" href="#array-values-uniform-types-variable-length"></a></p>
<p dir="auto">Arrays of values can be created using <code>[]</code> after the <code>:</code> type marker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb sizes:number[]=42
{&quot;sizes&quot;:[42]}

$ # The value is split on the character inside the []
$ jb names:[,]=&quot;Alice,Bob,Dr Chris&quot;
{&quot;names&quot;:[&quot;Alice&quot;,&quot;Bob&quot;,&quot;Dr Chris&quot;]}

$ # Using a newline \n as the split character makes each line an array
$ # element. This integrates with line-oriented command-line tools:
$ jb sizes:number[$'\n']=&quot;$(seq 3)&quot;
{&quot;sizes&quot;:[1,2,3]}"><pre>$ <span>jb sizes:number[]=42</span>
<span>{"sizes":[42]}</span>

$ <span><span><span>#</span> The value is split on the character inside the []</span></span>
$ <span>jb names:[,]=<span><span>"</span>Alice,Bob,Dr Chris<span>"</span></span></span>
<span>{"names":["Alice","Bob","Dr Chris"]}</span>

$ <span><span><span>#</span> Using a newline \n as the split character makes each line an array</span></span>
$ <span><span><span>#</span> element. This integrates with line-oriented command-line tools:</span></span>
$ <span>jb sizes:number[<span><span>$'</span><span>\n</span><span>'</span></span>]=<span><span>"</span><span><span>$(</span>seq 3<span>)</span></span><span>"</span></span></span>
<span>{"sizes":[1,2,3]}</span></pre></div>
<p dir="auto"><a href="#file-references">File references</a> with process substitution are the a better
way to get the output of other programs into JSON though.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # The default type is used if the type name is left out
$ jb sizes:[,]=&quot;1,2,3&quot;
{&quot;sizes&quot;:[&quot;1&quot;,&quot;2&quot;,&quot;3&quot;]}

$ # [:] is shorthand for /collection=array,split=:/
$ jb names:/collection=array,split=:/=&quot;Alice:Bob:Dr Chris&quot;
{&quot;names&quot;:[&quot;Alice&quot;,&quot;Bob&quot;,&quot;Dr Chris&quot;]}

$ # To split on null bytes, use split= (empty string). When used with inline and
$ # bash values this effectively inhibits splitting, because bash variables
$ # can't contain null bytes.
$ printf 'AB\nCD\x00EF\nGH\n\x00' | jb nullterm:[]/split=/@/dev/stdin
{&quot;nullterm&quot;:[&quot;AB\nCD&quot;,&quot;EF\nGH\n&quot;]}

$ # When using the Bash API, @var references can be bash arrays
$ source json.bash
$ names=(&quot;Bob Bobson&quot; &quot;Alice Alison&quot;) sizes=(42 55)
$ json @names:string[] @sizes:number[]
{&quot;names&quot;:[&quot;Bob Bobson&quot;,&quot;Alice Alison&quot;],&quot;sizes&quot;:[42,55]}

$ # json.array values can be arrays too
$ json.array @names:string[] @sizes:number[] :null[] :bool[]=true
[[&quot;Bob Bobson&quot;,&quot;Alice Alison&quot;],[42,55],[null],[true]]

$ # And jb-array values can be arrays as well
$ jb-array :[,]=&quot;Bob Bobson,Alice Alison&quot; :number[,]=42,55 :null[] :bool[]=true
[[&quot;Bob Bobson&quot;,&quot;Alice Alison&quot;],[42,55],[null],[true]]"><pre>$ <span><span><span>#</span> The default type is used if the type name is left out</span></span>
$ <span>jb sizes:[,]=<span><span>"</span>1,2,3<span>"</span></span></span>
<span>{"sizes":["1","2","3"]}</span>

$ <span><span><span>#</span> [:] is shorthand for /collection=array,split=:/</span></span>
$ <span>jb names:/collection=array,split=:/=<span><span>"</span>Alice:Bob:Dr Chris<span>"</span></span></span>
<span>{"names":["Alice","Bob","Dr Chris"]}</span>

$ <span><span><span>#</span> To split on null bytes, use split= (empty string). When used with inline and</span></span>
$ <span><span><span>#</span> bash values this effectively inhibits splitting, because bash variables</span></span>
$ <span><span><span>#</span> can't contain null bytes.</span></span>
$ <span><span>printf</span> <span><span>'</span>AB\nCD\x00EF\nGH\n\x00<span>'</span></span> <span>|</span> jb nullterm:[]/split=/@/dev/stdin</span>
<span>{"nullterm":["AB\nCD","EF\nGH\n"]}</span>

$ <span><span><span>#</span> When using the Bash API, @var references can be bash arrays</span></span>
$ <span><span>source</span> json.bash</span>
$ <span>names=(<span><span>"</span>Bob Bobson<span>"</span></span> <span><span>"</span>Alice Alison<span>"</span></span>) sizes=(42 55)</span>
$ <span>json @names:string[] @sizes:number[]</span>
<span>{"names":["Bob Bobson","Alice Alison"],"sizes":[42,55]}</span>

$ <span><span><span>#</span> json.array values can be arrays too</span></span>
$ <span>json.array @names:string[] @sizes:number[] :null[] :bool[]=true</span>
<span>[["Bob Bobson","Alice Alison"],[42,55],[null],[true]]</span>

$ <span><span><span>#</span> And jb-array values can be arrays as well</span></span>
$ <span>jb-array :[,]=<span><span>"</span>Bob Bobson,Alice Alison<span>"</span></span> :number[,]=42,55 :null[] :bool[]=true</span>
<span>[["Bob Bobson","Alice Alison"],[42,55],[null],[true]]</span></pre></div>
<p dir="auto">Arrays can be created from existing JSON arrays using the <code>[:json]</code> array
format:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb tags:[:json]=&quot;$(jb-array foo bar baz)&quot;
{&quot;tags&quot;:[&quot;foo&quot;,&quot;bar&quot;,&quot;baz&quot;]}

$ # The type of values in the argument's array must match the argument type
$ jb measures:number[:json]='[1,2,3,4]'
{&quot;measures&quot;:[1,2,3,4]}

$ # Otherwise an error occurs
$ jb measures:number[:json]='[1,2,&quot;oops&quot;]'
json.encode_array_entries_from_json(): provided entries are not all valid JSON arrays with 'number' values — '[1,2,&quot;oops&quot;]'
json(): Could not encode the value of argument 'measures:number[:json]=[1,2,&quot;oops&quot;]' as an array with 'number' values. Read from inline value, without splitting (one chunk), interpreted chunks with 'json' format.
�␘"><pre>$ <span>jb tags:[:json]=<span><span>"</span><span><span>$(</span>jb-array foo bar baz<span>)</span></span><span>"</span></span></span>
<span>{"tags":["foo","bar","baz"]}</span>

$ <span><span><span>#</span> The type of values in the argument's array must match the argument type</span></span>
$ <span>jb measures:number[:json]=<span><span>'</span>[1,2,3,4]<span>'</span></span></span>
<span>{"measures":[1,2,3,4]}</span>

$ <span><span><span>#</span> Otherwise an error occurs</span></span>
$ <span>jb measures:number[:json]=<span><span>'</span>[1,2,"oops"]<span>'</span></span></span>
<span>json.encode_array_entries_from_json(): provided entries are not all valid JSON arrays with 'number' values — '[1,2,"oops"]'</span>
<span>json(): Could not encode the value of argument 'measures:number[:json]=[1,2,"oops"]' as an array with 'number' values. Read from inline value, without splitting (one chunk), interpreted chunks with 'json' format.</span>
<span>�␘</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Object values (uniform types, variable length)</h3><a id="user-content-object-values-uniform-types-variable-length" aria-label="Permalink: Object values (uniform types, variable length)" href="#object-values-uniform-types-variable-length"></a></p>
<p dir="auto">Variable-length JSON objects can be created using <code>{}</code> after the <code>:</code> type
marker. Object values use the same <code>key=value</code> syntax used in arguments'
attributes section (<code>:/a=b,c=d/</code>).</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # The default type is used if the type name is left out
$ jb sizes:{}=small=s,medium=m,large=l
{&quot;sizes&quot;:{&quot;small&quot;:&quot;s&quot;,&quot;medium&quot;:&quot;m&quot;,&quot;large&quot;:&quot;l&quot;}}

$ jb measurements:number{}=small=5,medium=10,large=15
{&quot;measurements&quot;:{&quot;small&quot;:5,&quot;medium&quot;:10,&quot;large&quot;:15}}"><pre>$ <span><span><span>#</span> The default type is used if the type name is left out</span></span>
$ <span>jb sizes:{}=small=s,medium=m,large=l</span>
<span>{"sizes":{"small":"s","medium":"m","large":"l"}}</span>

$ <span>jb measurements:number{}=small=5,medium=10,large=15</span>
<span>{"measurements":{"small":5,"medium":10,"large":15}}</span></pre></div>
<p dir="auto">Like array values (<code>[]</code>), object values consume multiple lines of input when
reading files</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # env is a command-line tool that prints environment variables
$ env -i small=s medium=m large=l
small=s
medium=m
large=l

$ # We can encode variables from env as a JSON object
$ env -i small=s medium=m large=l | jb sizes:{}@/dev/stdin
{&quot;sizes&quot;:{&quot;small&quot;:&quot;s&quot;,&quot;medium&quot;:&quot;m&quot;,&quot;large&quot;:&quot;l&quot;}}"><pre>$ <span><span><span>#</span> env is a command-line tool that prints environment variables</span></span>
$ <span>env -i small=s medium=m large=l</span>
<span>small=s</span>
<span>medium=m</span>
<span>large=l</span>

$ <span><span><span>#</span> We can encode variables from env as a JSON object</span></span>
$ <span>env -i small=s medium=m large=l <span>|</span> jb sizes:{}@/dev/stdin</span>
<span>{"sizes":{"small":"s","medium":"m","large":"l"}}</span></pre></div>
<p dir="auto">As with array values, JSON data can be used as values:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb user=h4l repo=json.bash >> info
$ jb @./info:{:json}
{&quot;info&quot;:{&quot;user&quot;:&quot;h4l&quot;,&quot;repo&quot;:&quot;json.bash&quot;}}

$ jb file_types:string[,]=bash,md,hcl year_created:number=2023 >> info
$ # The values of the JSON objects are validated to match the argument's type,
$ # so the :json type must be used to consume arbitrary JSON
$ jb @./info:json{:json}
{&quot;info&quot;:{&quot;user&quot;:&quot;h4l&quot;,&quot;repo&quot;:&quot;json.bash&quot;,&quot;file_types&quot;:[&quot;bash&quot;,&quot;md&quot;,&quot;hcl&quot;],&quot;year_created&quot;:2023}}"><pre>$ <span>jb user=h4l repo=json.bash <span>&gt;&gt;</span> info</span>
$ <span>jb @./info:{:json}</span>
<span>{"info":{"user":"h4l","repo":"json.bash"}}</span>

$ <span>jb file_types:string[,]=bash,md,hcl year_created:number=2023 <span>&gt;&gt;</span> info</span>
$ <span><span><span>#</span> The values of the JSON objects are validated to match the argument's type,</span></span>
$ <span><span><span>#</span> so the :json type must be used to consume arbitrary JSON</span></span>
$ <span>jb @./info:json{:json}</span>
<span>{"info":{"user":"h4l","repo":"json.bash","file_types":["bash","md","hcl"],"year_created":2023}}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>...</code> arguments (merge entries into the host object/array)</h3><a id="user-content--arguments-merge-entries-into-the-host-objectarray" aria-label="Permalink: ... arguments (merge entries into the host object/array)" href="#-arguments-merge-entries-into-the-host-objectarray"></a></p>
<p dir="auto">An argument prefixed with <code>...</code> (commonly called splat, spread or unpacking in
programming languages) results in the argument's entries being merged directly
into the object or array being created.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ jb id=ab12 ...:=user=h4l,repo=json.bash ...:number=year=2023,min_radish_count=3
{&quot;id&quot;:&quot;ab12&quot;,&quot;user&quot;:&quot;h4l&quot;,&quot;repo&quot;:&quot;json.bash&quot;,&quot;year&quot;:2023,&quot;min_radish_count&quot;:3}

$ seq 5 8 | jb-array :number=0 ...:number[,]=1,2,3,4 ...:number@/dev/stdin
[0,1,2,3,4,5,6,7,8]"><pre>$ <span>jb id=ab12 ...:=user=h4l,repo=json.bash ...:number=year=2023,min_radish_count=3</span>
<span>{"id":"ab12","user":"h4l","repo":"json.bash","year":2023,"min_radish_count":3}</span>

$ <span>seq 5 8 <span>|</span> jb-array :number=0 ...:number[,]=1,2,3,4 ...:number@/dev/stdin</span>
<span>[0,1,2,3,4,5,6,7,8]</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Missing / empty values</h3><a id="user-content-missing--empty-values" aria-label="Permalink: Missing / empty values" href="#missing--empty-values"></a></p>
<p dir="auto">References to undefined variables, missing files or unreadable files are missing
values. Empty array variables, empty string variables, empty files and empty
argument values are empty values.</p>
<p dir="auto">Missing or empty keys or values are errors by default, apart from empty argument
values, like <code>foo=</code>.</p>
<p dir="auto">The flags <code>+</code> <code>~</code> <code>?</code> and <code>??</code> alter how missing/empty values behave.</p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Name</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>+</code></td>
<td>strict</td>
<td>All missing/empty values are errors.</td>
</tr>
<tr>
<td><code>~</code></td>
<td>optional</td>
<td>Missing files/variables are treated as empty.</td>
</tr>
<tr>
<td><code>?</code></td>
<td>substitute empty</td>
<td>Empty values are substituted with a default.</td>
</tr>
<tr>
<td><code>??</code></td>
<td>omit empty</td>
<td>Entries with an empty key or value are omitted.</td>
</tr>
</tbody>
</table>
<div dir="auto" data-snippet-clipboard-copy-content="$ # empty argument values are substituted by default
$ jb str= num:number= bool:bool= arr:[]= obj:{}=
{&quot;str&quot;:&quot;&quot;,&quot;num&quot;:0,&quot;bool&quot;:false,&quot;arr&quot;:[],&quot;obj&quot;:{}}

$ # Using ? substitutes the empty var for the default string, which is &quot;&quot;
$ empty= jb @empty?
{&quot;empty&quot;:&quot;&quot;}

$ # The empty attribute controls the default value. It's interpreted as JSON.
$ CI=true jb ci:bool/empty=false/?@CI
{&quot;ci&quot;:true}

$ CI= jb ci:true/empty=false/?@CI
{&quot;ci&quot;:false}

$ # empty_key controls the default value for empty keys
$ PROP= jb ?@PROP:true/empty_key='&quot;🤷&quot;'/
{&quot;🤷&quot;:true}

$ # The type= can be used to encode a raw value as JSON for empty attributes
$ PROP=👌 jb ?@PROP:true/empty_key=string=🤷/
{&quot;👌&quot;:true}

$ # ?? causes an empty value to be omitted entirely
$ CI= jb ci:bool??@CI
{}

$ # ~ causes a missing value to be empty. A ? is needed to prevent the empty
$ # value being an error.
$ jb github_actions:bool~?@GITHUB_ACTION
{&quot;github_actions&quot;:false}

$ # Empty variables are errors if ? isn't used.
$ empty= jb @empty
json.apply_empty_action(): The value of argument '@empty' must be non-empty but is empty.
json(): Could not encode the value of argument '@empty' as a 'string' value. Read from variable $empty. (Use the '?' flag after the :type to substitute the entry's empty value with a default, or the '??' flag to omit the entry when it has an empty value.)
�␘

$ # (Only the json Bash function, not the jb executable can access bash array variables.)
$ . json.bash
$ empty_array=()

$ # Using ? substitutes the empty array for the default, which is []
$ json @empty_array:[]?
{&quot;empty_array&quot;:[]}

$ # Empty arrays are errors without ?.
$ json @empty_array:[]
json.apply_empty_action(): The value of argument '@empty_array:[]' must be non-empty but is empty.
json(): Could not encode the value of argument '@empty_array:[]' as an array with 'string' values. Read from array-variable $empty_array. (Use the '?' flag after the :type to substitute the entry's empty value with a default, or the '??' flag to omit the entry when it has an empty value.)
�␘

$ # Missing / empty files work like variables
$ jb @./config:/empty=null/~?
{&quot;config&quot;:null}"><pre>$ <span><span><span>#</span> empty argument values are substituted by default</span></span>
$ <span>jb str= num:number= bool:bool= arr:[]= obj:{}=</span>
<span>{"str":"","num":0,"bool":false,"arr":[],"obj":{}}</span>

$ <span><span><span>#</span> Using ? substitutes the empty var for the default string, which is ""</span></span>
$ <span>empty= jb @empty<span>?</span></span>
<span>{"empty":""}</span>

$ <span><span><span>#</span> The empty attribute controls the default value. It's interpreted as JSON.</span></span>
$ <span>CI=true jb ci:bool/empty=false/<span>?</span>@CI</span>
<span>{"ci":true}</span>

$ <span>CI= jb ci:true/empty=false/<span>?</span>@CI</span>
<span>{"ci":false}</span>

$ <span><span><span>#</span> empty_key controls the default value for empty keys</span></span>
$ <span>PROP= jb <span>?</span>@PROP:true/empty_key=<span><span>'</span>"🤷"<span>'</span></span>/</span>
<span>{"🤷":true}</span>

$ <span><span><span>#</span> The type= can be used to encode a raw value as JSON for empty attributes</span></span>
$ <span>PROP=👌 jb <span>?</span>@PROP:true/empty_key=string=🤷/</span>
<span>{"👌":true}</span>

$ <span><span><span>#</span> ?? causes an empty value to be omitted entirely</span></span>
$ <span>CI= jb ci:bool<span>??</span>@CI</span>
<span>{}</span>

$ <span><span><span>#</span> ~ causes a missing value to be empty. A ? is needed to prevent the empty</span></span>
$ <span><span><span>#</span> value being an error.</span></span>
$ <span>jb github_actions:bool~<span>?</span>@GITHUB_ACTION</span>
<span>{"github_actions":false}</span>

$ <span><span><span>#</span> Empty variables are errors if ? isn't used.</span></span>
$ <span>empty= jb @empty</span>
<span>json.apply_empty_action(): The value of argument '@empty' must be non-empty but is empty.</span>
<span>json(): Could not encode the value of argument '@empty' as a 'string' value. Read from variable $empty. (Use the '?' flag after the :type to substitute the entry's empty value with a default, or the '??' flag to omit the entry when it has an empty value.)</span>
<span>�␘</span>

$ <span><span><span>#</span> (Only the json Bash function, not the jb executable can access bash array variables.)</span></span>
$ <span><span>.</span> json.bash</span>
$ <span>empty_array=()</span>

$ <span><span><span>#</span> Using ? substitutes the empty array for the default, which is []</span></span>
$ <span>json @empty_array:[]<span>?</span></span>
<span>{"empty_array":[]}</span>

$ <span><span><span>#</span> Empty arrays are errors without ?.</span></span>
$ <span>json @empty_array:[]</span>
<span>json.apply_empty_action(): The value of argument '@empty_array:[]' must be non-empty but is empty.</span>
<span>json(): Could not encode the value of argument '@empty_array:[]' as an array with 'string' values. Read from array-variable $empty_array. (Use the '?' flag after the :type to substitute the entry's empty value with a default, or the '??' flag to omit the entry when it has an empty value.)</span>
<span>�␘</span>

$ <span><span><span>#</span> Missing / empty files work like variables</span></span>
$ <span>jb @./config:/empty=null/~<span>?</span></span>
<span>{"config":null}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nested JSON with <code>:json</code> and <code>:raw</code> types</h3><a id="user-content-nested-json-with-json-and-raw-types" aria-label="Permalink: Nested JSON with :json and :raw types" href="#nested-json-with-json-and-raw-types"></a></p>
<p dir="auto">Nested objects and arrays are created using the <code>:json</code> or <code>:raw</code> types. The
<code>:json</code> type validates the provided value(s) and fails if they're not actually
JSON, whereas the <code>:raw</code> type allow <em>any</em> value to be inserted (even invalid
JSON).</p>
<p dir="auto">The reason for both is that <code>:json</code> depends on grep (with PCRE) being present,
so <code>:raw</code> can be used in situations where only bash is available, and validation
isn't necessary (e.g. when passing the output of one <code>json.bash</code> call into
another). <code>:raw</code> also supports <a href="#streaming-output">streaming output</a>, which
<code>:json</code> does not.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Like other types, :json and :raw values can be directly embedded in arguments
$ jb user:json='{&quot;name&quot;:&quot;Bob Bobson&quot;}'
{&quot;user&quot;:{&quot;name&quot;:&quot;Bob Bobson&quot;}}

$ # Or come from variable references
$ user='{&quot;name&quot;:&quot;Bob Bobson&quot;}' jb @user:json
{&quot;user&quot;:{&quot;name&quot;:&quot;Bob Bobson&quot;}}

$ # Or files
$ jb name=&quot;Bob Bobson&quot; > /tmp/user; jb @/tmp/user:json
{&quot;user&quot;:{&quot;name&quot;:&quot;Bob Bobson&quot;}}

$ # Arrays of JSON work the same way as other types.
$ jb users:json[$'\n']=&quot;$(jb name=Bob; jb name=Alice)&quot;
{&quot;users&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}

$ # :json and :raw values are not formatted — whitespace in them is preserved
$ jb user:json=$'{\n  &quot;name&quot;: &quot;Bob Bobson&quot;\n}'
{&quot;user&quot;:{
  &quot;name&quot;: &quot;Bob Bobson&quot;
}}

$ # :json detects invalid JSON and fails with an error
$ jb oops:json='{&quot;truncated&quot;:'
json.encode_json(): not all inputs are valid JSON: '{&quot;truncated&quot;:'
json(): Could not encode the value of argument 'oops:json={&quot;truncated&quot;:' as a 'json' value. Read from inline value.
�␘

$ # However :raw performs no validation, so it must only be used with great care
$ # 🚨 This emits invalid JSON without failing! 🚨
$ jb broken:raw='{&quot;truncated&quot;:'
{&quot;broken&quot;:{&quot;truncated&quot;:}"><pre>$ <span><span><span>#</span> Like other types, :json and :raw values can be directly embedded in arguments</span></span>
$ <span>jb user:json=<span><span>'</span>{"name":"Bob Bobson"}<span>'</span></span></span>
<span>{"user":{"name":"Bob Bobson"}}</span>

$ <span><span><span>#</span> Or come from variable references</span></span>
$ <span>user=<span><span>'</span>{"name":"Bob Bobson"}<span>'</span></span> jb @user:json</span>
<span>{"user":{"name":"Bob Bobson"}}</span>

$ <span><span><span>#</span> Or files</span></span>
$ <span>jb name=<span><span>"</span>Bob Bobson<span>"</span></span> <span>&gt;</span> /tmp/user<span>;</span> jb @/tmp/user:json</span>
<span>{"user":{"name":"Bob Bobson"}}</span>

$ <span><span><span>#</span> Arrays of JSON work the same way as other types.</span></span>
$ <span>jb users:json[<span><span>$'</span><span>\n</span><span>'</span></span>]=<span><span>"</span><span><span>$(</span>jb name=Bob<span>;</span> jb name=Alice<span>)</span></span><span>"</span></span></span>
<span>{"users":[{"name":"Bob"},{"name":"Alice"}]}</span>

$ <span><span><span>#</span> :json and :raw values are not formatted — whitespace in them is preserved</span></span>
$ <span>jb user:json=<span><span>$'</span>{<span>\n</span>  "name": "Bob Bobson"<span>\n</span>}<span>'</span></span></span>
<span>{"user":{</span>
<span>  "name": "Bob Bobson"</span>
<span>}}</span>

$ <span><span><span>#</span> :json detects invalid JSON and fails with an error</span></span>
$ <span>jb oops:json=<span><span>'</span>{"truncated":<span>'</span></span></span>
<span>json.encode_json(): not all inputs are valid JSON: '{"truncated":'</span>
<span>json(): Could not encode the value of argument 'oops:json={"truncated":' as a 'json' value. Read from inline value.</span>
<span>�␘</span>

$ <span><span><span>#</span> However :raw performs no validation, so it must only be used with great care</span></span>
$ <span><span><span>#</span> 🚨 This emits invalid JSON without failing! 🚨</span></span>
$ <span>jb broken:raw=<span><span>'</span>{"truncated":<span>'</span></span></span>
<span>{"broken":{"truncated":}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">File references</h3><a id="user-content-file-references" aria-label="Permalink: File references" href="#file-references"></a></p>
<p dir="auto">The <code>@ref</code> syntax can be used to reference the content of files. If an <code> @ref</code>
starts with <code>/</code> or <code>./</code> it's taken to be a file (rather than a shell variable).</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ printf 'orange #3\nblue #5\n' > colours

$ jb my_colours@./colours
{&quot;my_colours&quot;:&quot;orange #3\nblue #5\n&quot;}

$ # The final path segment is used as the key if a key isn't set.
$ jb @./colours
{&quot;colours&quot;:&quot;orange #3\nblue #5\n&quot;}

$ # Array values split on newlines
$ jb @./colours:[]
{&quot;colours&quot;:[&quot;orange #3&quot;,&quot;blue #5&quot;]}

$ printf 'apple:pear:grape' > fruit

$ # The file can be split on a different character by naming it in the []
$ jb @./fruit:[:]
{&quot;fruit&quot;:[&quot;apple&quot;,&quot;pear&quot;,&quot;grape&quot;]}

$ # Which is shorthand for
$ jb @./fruit:/collection=array,split=:/
{&quot;fruit&quot;:[&quot;apple&quot;,&quot;pear&quot;,&quot;grape&quot;]}

$ # Split on null by setting split to the empty string
$ printf 'foo\nbar\n\x00bar baz\n\x00' > nullterminated
$ jb @./nullterminated:[]/split=/
{&quot;nullterminated&quot;:[&quot;foo\nbar\n&quot;,&quot;bar baz\n&quot;]}

$ # Read from stdin using the special /dev/stdin file
$ seq 3 | jb counts:number[]@/dev/stdin
{&quot;counts&quot;:[1,2,3]}"><pre>$ <span><span>printf</span> <span><span>'</span>orange #3\nblue #5\n<span>'</span></span> <span>&gt;</span> colours</span>

$ <span>jb my_colours@./colours</span>
<span>{"my_colours":"orange #3\nblue #5\n"}</span>

$ <span><span><span>#</span> The final path segment is used as the key if a key isn't set.</span></span>
$ <span>jb @./colours</span>
<span>{"colours":"orange #3\nblue #5\n"}</span>

$ <span><span><span>#</span> Array values split on newlines</span></span>
$ <span>jb @./colours:[]</span>
<span>{"colours":["orange #3","blue #5"]}</span>

$ <span><span>printf</span> <span><span>'</span>apple:pear:grape<span>'</span></span> <span>&gt;</span> fruit</span>

$ <span><span><span>#</span> The file can be split on a different character by naming it in the []</span></span>
$ <span>jb @./fruit:[:]</span>
<span>{"fruit":["apple","pear","grape"]}</span>

$ <span><span><span>#</span> Which is shorthand for</span></span>
$ <span>jb @./fruit:/collection=array,split=:/</span>
<span>{"fruit":["apple","pear","grape"]}</span>

$ <span><span><span>#</span> Split on null by setting split to the empty string</span></span>
$ <span><span>printf</span> <span><span>'</span>foo\nbar\n\x00bar baz\n\x00<span>'</span></span> <span>&gt;</span> nullterminated</span>
$ <span>jb @./nullterminated:[]/split=/</span>
<span>{"nullterminated":["foo\nbar\n","bar baz\n"]}</span>

$ <span><span><span>#</span> Read from stdin using the special /dev/stdin file</span></span>
$ <span>seq 3 <span>|</span> jb counts:number[]@/dev/stdin</span>
<span>{"counts":[1,2,3]}</span></pre></div>
<p dir="auto">File references become especially powerful when combined with process
substitution — a shell feature that provides a dynamic, temporary file
containing the output of another program.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Use process substitution to nest jb calls and pull multiple shell pipelines
$ # into one JSON output.
$ jb counts:number[]@<(seq 3) \
>    people:json[]@<(jb name=Bob; jb name=Alice)
{&quot;counts&quot;:[1,2,3],&quot;people&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}"><pre>$ <span><span><span>#</span> Use process substitution to nest jb calls and pull multiple shell pipelines</span></span>
$ <span><span><span>#</span> into one JSON output.</span></span>
$ <span>jb counts:number[]@<span><span>&lt;(</span>seq 3<span>)</span></span> \</span>
&gt;    <span>people:json[]@<span><span>&lt;(</span>jb name=Bob<span>;</span> jb name=Alice<span>)</span></span></span>
<span>{"counts":[1,2,3],"people":[{"name":"Bob"},{"name":"Alice"}]}</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Aside: Process substitution 101</h4><a id="user-content-aside-process-substitution-101" aria-label="Permalink: Aside: Process substitution 101" href="#aside-process-substitution-101"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # What's going on when we use process substitution? The <(...) syntax.
$ jb msg@<(printf &quot;Hi!&quot;)
{&quot;msg&quot;:&quot;Hi!&quot;}

$ # The shell replaces <(...) with a file path. That file contains the output of
$ # the command inside the <(...) when read. (But the catch is, the file only
$ # exists while the command runs, and it's not a normal file, so the contents
$ # isn't stored on disk.)

$ # We can see this if we echo the the substitution:
$ echo This is the substitution result: <(printf &quot;Hi!&quot;)
This is the substitution result: /dev/fd/...

$ # If we cat the substitution instead of echoing it, we read the file contents:
$ cat <(printf &quot;Hi!&quot;)
Hi!

$ # So when we use this with jb, it's as if we ran:  jb msg@/dev/fd/...

$ # We can see this in action by enabling tracing in Bash:
$ set -o xtrace;  jb msg@<(printf &quot;Hi!&quot;);  set +o xtrace
+ jb msg@/dev/fd/...
++ printf 'Hi!'
{&quot;msg&quot;:&quot;Hi!&quot;}
+ set +o xtrace"><pre>$ <span><span><span>#</span> What's going on when we use process substitution? The &lt;(...) syntax.</span></span>
$ <span>jb msg@<span><span>&lt;(</span>printf <span><span>"</span>Hi!<span>"</span></span><span>)</span></span></span>
<span>{"msg":"Hi!"}</span>

$ <span><span><span>#</span> The shell replaces &lt;(...) with a file path. That file contains the output of</span></span>
$ <span><span><span>#</span> the command inside the &lt;(...) when read. (But the catch is, the file only</span></span>
$ <span><span><span>#</span> exists while the command runs, and it's not a normal file, so the contents</span></span>
$ <span><span><span>#</span> isn't stored on disk.)</span></span>

$ <span><span><span>#</span> We can see this if we echo the the substitution:</span></span>
$ <span><span>echo</span> This is the substitution result: <span><span>&lt;(</span>printf <span><span>"</span>Hi!<span>"</span></span><span>)</span></span></span>
<span>This is the substitution result: /dev/fd/...</span>

$ <span><span><span>#</span> If we cat the substitution instead of echoing it, we read the file contents:</span></span>
$ <span>cat <span><span>&lt;(</span>printf <span><span>"</span>Hi!<span>"</span></span><span>)</span></span></span>
<span>Hi!</span>

$ <span><span><span>#</span> So when we use this with jb, it's as if we ran:  jb msg@/dev/fd/...</span></span>

$ <span><span><span>#</span> We can see this in action by enabling tracing in Bash:</span></span>
$ <span><span>set</span> -o xtrace<span>;</span>  jb msg@<span><span>&lt;(</span>printf <span><span>"</span>Hi!<span>"</span></span><span>)</span></span><span>;</span>  <span>set</span> +o xtrace</span>
<span>+ jb msg@/dev/fd/...</span>
<span>++ printf 'Hi!'</span>
<span>{"msg":"Hi!"}</span>
<span>+ set +o xtrace</span></pre></div>
<p dir="auto">Because <code>&lt;(...)</code> becomes a path, you don't <em>have</em> to quote it, which makes
forming commands a bit easier than using <em>command substitution</em> to do the same
thing (<code>echo "$(printf like this)"</code>). And you only pass a short file path as an
argument, not a potentially huge string.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Back to file references</h4><a id="user-content-back-to-file-references" aria-label="Permalink: Back to file references" href="#back-to-file-references"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Process substitution can nest multiple times
$ jb owners:json@<(
>   jb people:json[]@<(jb name=Bob; jb name=Alice)
> )
{&quot;owners&quot;:{&quot;people&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}}

$ # Files can be referenced indirectly using a shell variable.
$ # If @var is used and $var is not set, but $var_FILE is, the filename is read
$ # from $var_FILE and the content of the file is used.
$ printf 'secret123' > db_password
$ db_password_FILE=./db_password jb @db_password
{&quot;db_password&quot;:&quot;secret123&quot;}"><pre>$ <span><span><span>#</span> Process substitution can nest multiple times</span></span>
$ <span>jb owners:json@<span><span>&lt;(</span></span></span>
&gt;   <span>jb people:json[]@<span><span>&lt;(</span>jb name=Bob<span>;</span> jb name=Alice<span>)</span></span></span>
&gt; <span>)</span>
<span>{"owners":{"people":[{"name":"Bob"},{"name":"Alice"}]}}</span>

$ <span><span><span>#</span> Files can be referenced indirectly using a shell variable.</span></span>
$ <span><span><span>#</span> If @var is used and $var is not set, but $var_FILE is, the filename is read</span></span>
$ <span><span><span>#</span> from $var_FILE and the content of the file is used.</span></span>
$ <span><span>printf</span> <span><span>'</span>secret123<span>'</span></span> <span>&gt;</span> db_password</span>
$ <span>db_password_FILE=./db_password jb @db_password</span>
<span>{"db_password":"secret123"}</span></pre></div>
<p dir="auto">(This pattern is often used to securely pass secrets via environment variables,
<a href="#environment-variable-exposure">without directly exposing the secret's value itself in the environment</a>,
to avoid accidental exposure.)</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Nesting lots of process substitution levels can become unwieldy, but we can
$ # flatten the nesting by holding the process substitution filenames in shell
$ #&nbsp;variables, using the _FILE var feature to reference them:
$ people_FILE=<(jb name=Bob; jb name=Alice) \
> owners_FILE=<(jb @people:json[]) \
> jb @owners:json
{&quot;owners&quot;:{&quot;people&quot;:[{&quot;name&quot;:&quot;Bob&quot;},{&quot;name&quot;:&quot;Alice&quot;}]}}"><pre>$ <span><span><span>#</span> Nesting lots of process substitution levels can become unwieldy, but we can</span></span>
$ <span><span><span>#</span> flatten the nesting by holding the process substitution filenames in shell</span></span>
$ <span><span><span>#</span>&nbsp;variables, using the _FILE var feature to reference them:</span></span>
$ <span>people_FILE=<span><span>&lt;(</span>jb name=Bob<span>;</span> jb name=Alice<span>)</span></span> \</span>
&gt; <span>owners_FILE=<span><span>&lt;(</span>jb @people:json[]<span>)</span></span> \</span>
&gt; <span>jb @owners:json</span>
<span>{"owners":{"people":[{"name":"Bob"},{"name":"Alice"}]}}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Argument structure</h3><a id="user-content-argument-structure" aria-label="Permalink: Argument structure" href="#argument-structure"></a></p>
<p dir="auto">Arguments have 3 main parts: a key, type and value. The structure (omitting some
details for clarity) is:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/h4l/json.bash/blob/main/docs/syntax-diagrams/approximate-argument.svg"><img width="100%" src="https://github.com/h4l/json.bash/raw/main/docs/syntax-diagrams/approximate-argument.svg" alt="A railroad syntax diagram showing the key, type and value structure of an argument, in more detail than the minimal argument diagram, but still omitting some details." title="Approximate Argument Structure Diagram"></a></p>
<p dir="auto">The <a href="https://github.com/h4l/json.bash/blob/main/docs/syntax.md">Argument syntax</a> page has more detail.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Error handling</h3><a id="user-content-error-handling" aria-label="Permalink: Error handling" href="#error-handling"></a></p>
<p dir="auto"><code>json.bash</code> aims to fail quickly, cleanly and clearly when problems happen.</p>
<blockquote>
<p dir="auto">Please open an issue if you discover a case where an error goes unreported, is
not reported clearly, or you find it's not easy to prevent incorrect data
getting generated.</p>
</blockquote>
<p dir="auto">Invalid values in typed arguments will cause an error — values are not coerced
if a type is specified. <code>:bool</code> and <code>:null</code> are pedantic — values must be
exactly <code>true</code> / <code>false</code> / <code>null</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ active=tRuE jb @active:bool
json.encode_bool(): not all inputs are bools: 'tRuE'
json(): Could not encode the value of argument '@active:bool' as a 'bool' value. Read from variable $active.
�␘"><pre>$ <span>active=tRuE jb @active:bool</span>
<span>json.encode_bool(): not all inputs are bools: 'tRuE'</span>
<span>json(): Could not encode the value of argument '@active:bool' as a 'bool' value. Read from variable $active.</span>
<span>�␘</span></pre></div>
<p dir="auto">Errors are reported with specific exit statuses:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Errors in user-provided data fail with status 1
$ jb data:json='invalid'; echo status=$?
json.encode_json(): not all inputs are valid JSON: 'invalid'
json(): Could not encode the value of argument 'data:json=invalid' as a 'json' value. Read from inline value.
�␘
status=1

$ # Errors in developer-provided arguments fail with status 1
$ jb bad_arg:cheese; echo status=$?
json.parse_argument(): type name must be one of auto, bool, false, json, null, number, raw, string or true, but was 'cheese'
json(): Could not parse argument 'bad_arg:cheese'. Argument is not structured correctly, see --help for examples.
�␘
status=2

$ # Arguments referencing variables that don't exist fail with status 3
$ jb @missing; echo status=$?
json(): Could not process argument '@missing'. Its value references unbound variable $missing. (Use the '~' flag after the :type to treat a missing value as empty.)
�␘
status=3

$ # Arguments referencing files that don't exist fail with status 4
$ jb @/does/not/exist; echo status=$?
/.../bin/jb: line ...: /does/not/exist: No such file or directory
json(): Could not open the file '/does/not/exist' referenced as the value of argument '@/does/not/exist'.
�␘
status=4"><pre>$ <span><span><span>#</span> Errors in user-provided data fail with status 1</span></span>
$ <span>jb data:json=<span><span>'</span>invalid<span>'</span></span><span>;</span> <span>echo</span> status=<span>$?</span></span>
<span>json.encode_json(): not all inputs are valid JSON: 'invalid'</span>
<span>json(): Could not encode the value of argument 'data:json=invalid' as a 'json' value. Read from inline value.</span>
<span>�␘</span>
<span>status=1</span>

$ <span><span><span>#</span> Errors in developer-provided arguments fail with status 1</span></span>
$ <span>jb bad_arg:cheese<span>;</span> <span>echo</span> status=<span>$?</span></span>
<span>json.parse_argument(): type name must be one of auto, bool, false, json, null, number, raw, string or true, but was 'cheese'</span>
<span>json(): Could not parse argument 'bad_arg:cheese'. Argument is not structured correctly, see --help for examples.</span>
<span>�␘</span>
<span>status=2</span>

$ <span><span><span>#</span> Arguments referencing variables that don't exist fail with status 3</span></span>
$ <span>jb @missing<span>;</span> <span>echo</span> status=<span>$?</span></span>
<span>json(): Could not process argument '@missing'. Its value references unbound variable $missing. (Use the '~' flag after the :type to treat a missing value as empty.)</span>
<span>�␘</span>
<span>status=3</span>

$ <span><span><span>#</span> Arguments referencing files that don't exist fail with status 4</span></span>
$ <span>jb @/does/not/exist<span>;</span> <span>echo</span> status=<span>$?</span></span>
<span>/.../bin/jb: line ...: /does/not/exist: No such file or directory</span>
<span>json(): Could not open the file '/does/not/exist' referenced as the value of argument '@/does/not/exist'.</span>
<span>�␘</span>
<span>status=4</span></pre></div>
<p dir="auto"><code>jb</code> can detect errors in upstream <code>jb</code> calls that are pulled into a downstream
<code>jb</code> process, such as when several <code>jb</code> calls are fed into each other using
<a href="#file-references">process substitution</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # The jb call 3 levels deep reading the missing file ./not-found fails
$ jb club:json@<(
>   jb name=&quot;jb Users&quot; members:json[]@<(
>     jb name=h4l; jb name@./not-found
>   )
> )
...: ./not-found: No such file or directory
json(): Could not open the file './not-found' referenced as the value of argument 'name@./not-found'.
json.encode_json(): not all inputs are valid JSON: '{&quot;name&quot;:&quot;h4l&quot;}' $'\030'
json(): Could not encode the value of argument 'members:json[]@/dev/fd/...' as an array with 'json' values. Read from file /dev/fd/..., split into chunks on $'\n', interpreted chunks with 'raw' format.
json.encode_json(): not all inputs are valid JSON: $'\030'
json(): Could not encode the value of argument 'club:json@/dev/fd/...' as a 'json' value. Read from file /dev/fd/..., up to the first 0x00 byte or end-of-file.
�␘"><pre>$ <span><span><span>#</span> The jb call 3 levels deep reading the missing file ./not-found fails</span></span>
$ <span>jb club:json@<span><span>&lt;(</span></span></span>
&gt;   <span>jb name=<span><span>"</span>jb Users<span>"</span></span> members:json[]@<span><span>&lt;(</span></span></span>
&gt;     <span>jb name=h4l<span>;</span> jb name@./not-found</span>
&gt;   <span>)</span>
&gt; <span>)</span>
<span>...: ./not-found: No such file or directory</span>
<span>json(): Could not open the file './not-found' referenced as the value of argument 'name@./not-found'.</span>
<span>json.encode_json(): not all inputs are valid JSON: '{"name":"h4l"}' $'\030'</span>
<span>json(): Could not encode the value of argument 'members:json[]@/dev/fd/...' as an array with 'json' values. Read from file /dev/fd/..., split into chunks on $'\n', interpreted chunks with 'raw' format.</span>
<span>json.encode_json(): not all inputs are valid JSON: $'\030'</span>
<span>json(): Could not encode the value of argument 'club:json@/dev/fd/...' as a 'json' value. Read from file /dev/fd/..., up to the first 0x00 byte or end-of-file.</span>
<span>�␘</span></pre></div>
<p dir="auto">Notice the <a href="https://en.wikipedia.org/wiki/Unicode_control_characters" rel="nofollow">␘</a> symbol in the output? It's the Unicode symbol for
the <a href="https://en.wikipedia.org/wiki/Cancel_character" rel="nofollow">Cancel control character</a>.</p>
<p dir="auto"><code>jb</code> propagates errors by emitting a <a href="https://en.wikipedia.org/wiki/Cancel_character" rel="nofollow">Cancel control character</a> when it
fails, which causes its output to be invalid JSON, which prevents the erroneous
output from being parsed by downstream JSON-consuming programs (<code>jb</code> or
otherwise). We call this Stream Poisoning, because the Cancel control character
poisons the output, and this poisoned output flows downstream until it's
detected.</p>
<p dir="auto">The result of this is that it's safe to pipe the output of a <code>jb</code> program into
another JSON-consuming program, with the knowledge that you'll get an error if
something has failed upstream, without needing to meticulously collect and check
the every exit status of every program contributing to the output.</p>
<p dir="auto">See <a href="https://github.com/h4l/json.bash/blob/main/docs/stream-poisoning.md">docs/stream-poisoning.md</a> for more on how this
works.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security and correctness</h3><a id="user-content-security-and-correctness" aria-label="Permalink: Security and correctness" href="#security-and-correctness"></a></p>
<p dir="auto"><code>jb</code> can safely generate JSON from untrusted user input, but there are some ways
to get this wrong.</p>
<p dir="auto">It's safe to use untrusted input in:</p>
<ul dir="auto">
<li>
<p dir="auto">Inline values — after the value's <code>=</code> in an argument.</p>
<p dir="auto">With argument <code>key:type=value</code> Anything after the value's <code>=</code> in an argument
is used as-is and not interpreted/unescaped, so it can contain untrusted
input.</p>
<p dir="auto">The <code>=</code> must be preceded by a key or <code>:</code> (type section marker), otherwise an
argument starting with a <code>=</code> such as <code>=foo</code> is parsed as a key, which could
allow text inserted into the argument to be parsed as the value if not escaped
correctly.</p>
</li>
<li>
<p dir="auto">Variable references — the <em>value</em> held in a variable referenced by an
argument.</p>
<p dir="auto">With argument <code>@foo</code>, the value of <code>$foo</code> is is used as-is and not
interpreted/unescaped, so it can contain untrusted input.</p>
</li>
<li>
<p dir="auto">File references — the contents of a file referenced by a argument.</p>
<p dir="auto">The contents of files is not interpreted/unescaped, so they can contain
untrusted input.</p>
</li>
</ul>
<p dir="auto">In general, avoid inserting user-provided input into the argument string passed
to jb before the value's <code>=</code>. To create dynamic object property names from user
input, store the user-provided value in a variable or file, and use an <code>@ref</code> to
reference it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ dynamic_prop='Untrusted' jb @dynamic_prop=value
{&quot;Untrusted&quot;:&quot;value&quot;}"><pre>$ <span>dynamic_prop=<span><span>'</span>Untrusted<span>'</span></span> jb @dynamic_prop=value</span>
<span>{"Untrusted":"value"}</span></pre></div>
<p dir="auto">If you format user-input into an argument string, they could insert an <code>@ref</code> of
their choice, and pull in a file or variable they shouldn't have access to. You
can escape special characters in argument values by doubling characters, but
it's safer to use an <code>@ref</code> — if you get an <code>@ref</code> wrong you get an error,
whereas if you get escaping wrong, you may create a vulnerability.</p>
<p dir="auto">References are not supported when specifying argument attributes, like
<code>/empty=x/</code>, so <code>,</code> in these values needs to be escaped by doubling it. E.g. to
use a comma as a split char, use <code>/empty=string='Why,, yes.'/</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ empty= jb msg:/empty=string='Why,, yes.'/??@empty
{&quot;msg&quot;:&quot;Why, yes.&quot;}"><pre>$ <span>empty= jb msg:/empty=string=<span><span>'</span>Why,, yes.<span>'</span></span>/<span>??</span>@empty</span>
<span>{"msg":"Why, yes."}</span></pre></div>
<p dir="auto">To pass a dynamic file location, use a <code>_FILE</code> variable reference or read the
file with a normal shell construct and redirect the input. You must also
separately validate that the referenced file should be accessible.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ printf 'Example\nContent\n' > /tmp/example
$ user_file=/tmp/example

$ user_specified_FILE=$user_file jb user_file_content@user_specified
{&quot;user_file_content&quot;:&quot;Example\nContent\n&quot;}

$ jb user_file_content@<(cat &quot;$user_file&quot;)
{&quot;user_file_content&quot;:&quot;Example\nContent\n&quot;}

$ jb user_file_content=&quot;$(<&quot;$user_file&quot;)&quot;  # $() strips the trailing newline
{&quot;user_file_content&quot;:&quot;Example\nContent&quot;}"><pre>$ <span><span>printf</span> <span><span>'</span>Example\nContent\n<span>'</span></span> <span>&gt;</span> /tmp/example</span>
$ <span>user_file=/tmp/example</span>

$ <span>user_specified_FILE=<span>$user_file</span> jb user_file_content@user_specified</span>
<span>{"user_file_content":"Example\nContent\n"}</span>

$ <span>jb user_file_content@<span><span>&lt;(</span>cat <span><span>"</span><span>$user_file</span><span>"</span></span><span>)</span></span></span>
<span>{"user_file_content":"Example\nContent\n"}</span>

$ <span>jb user_file_content=<span><span>"</span><span><span>$(</span><span>&lt;</span><span><span>"</span><span>$user_file</span><span>"</span></span><span>)</span></span><span>"</span></span>  <span><span>#</span> $() strips the trailing newline</span></span>
<span>{"user_file_content":"Example\nContent"}</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Environment variable exposure</h4><a id="user-content-environment-variable-exposure" aria-label="Permalink: Environment variable exposure" href="#environment-variable-exposure"></a></p>
<p dir="auto"><code>jb</code> <code>@var</code> refs have the advantage over normal shell <code>$var</code> refs in that they
are not expanded by the shell before executing the command, so sensitive values
in shell variables are not exposed as process arguments when using <code>@var</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ password=hunter2

$ # shell $var — secret's value is in process arguments
$ jb password=&quot;$password&quot; visible_args:[]/split=/@/proc/self/cmdline
{&quot;password&quot;:&quot;hunter2&quot;,&quot;visible_args&quot;:[&quot;bash&quot;,&quot;/.../bin/jb&quot;,&quot;password=hunter2&quot;,&quot;visible_args:[]/split=/@/proc/self/cmdline&quot;]}

$ # jb @var — only the variable name is in process arguments
$ password=$password jb @password visible_args:[]/split=/@/proc/self/cmdline
{&quot;password&quot;:&quot;hunter2&quot;,&quot;visible_args&quot;:[&quot;bash&quot;,&quot;/.../bin/jb&quot;,&quot;@password&quot;,&quot;visible_args:[]/split=/@/proc/self/cmdline&quot;]}"><pre>$ <span>password=hunter2</span>

$ <span><span><span>#</span> shell $var — secret's value is in process arguments</span></span>
$ <span>jb password=<span><span>"</span><span>$password</span><span>"</span></span> visible_args:[]/split=/@/proc/self/cmdline</span>
<span>{"password":"hunter2","visible_args":["bash","/.../bin/jb","password=hunter2","visible_args:[]/split=/@/proc/self/cmdline"]}</span>

$ <span><span><span>#</span> jb @var — only the variable name is in process arguments</span></span>
$ <span>password=<span>$password</span> jb @password visible_args:[]/split=/@/proc/self/cmdline</span>
<span>{"password":"hunter2","visible_args":["bash","/.../bin/jb","@password","visible_args:[]/split=/@/proc/self/cmdline"]}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>jb-cat</code>, <code>jb-echo</code>, <code>jb-stream</code> utility programs</h3><a id="user-content-jb-cat-jb-echo-jb-stream-utility-programs" aria-label="Permalink: jb-cat, jb-echo, jb-stream utility programs" href="#jb-cat-jb-echo-jb-stream-utility-programs"></a></p>
<p dir="auto"><code>json.bash</code> has a few single-purpose utility programs that were originally demo
programs for the Bash API, but could be use useful by themselves:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # jb-echo is like echo, but each argument becomes a string element in a JSON array
$ jb-echo foo &quot;bar baz&quot; boz
[&quot;foo&quot;,&quot;bar baz&quot;,&quot;boz&quot;]

$ printf 'The Cat\nsat on\nthe mat.\n' > catmat
$ printf 'The Bat\nhid in\nthe hat.\n' > bathat

$ # jb-cat is like cat, but the output is stream-encoded as a single JSON string
$ jb-cat catmat bathat
&quot;The Cat\nsat on\nthe mat.\nThe Bat\nhid in\nthe hat.\n&quot;

$ # jb-stream is a filter program that encodes each input line as a JSON string
$ cat catmat bathat | jb-stream
&quot;The Cat&quot;
&quot;sat on&quot;
&quot;the mat.&quot;
&quot;The Bat&quot;
&quot;hid in&quot;
&quot;the hat.&quot;"><pre>$ <span><span><span>#</span> jb-echo is like echo, but each argument becomes a string element in a JSON array</span></span>
$ <span>jb-echo foo <span><span>"</span>bar baz<span>"</span></span> boz</span>
<span>["foo","bar baz","boz"]</span>

$ <span><span>printf</span> <span><span>'</span>The Cat\nsat on\nthe mat.\n<span>'</span></span> <span>&gt;</span> catmat</span>
$ <span><span>printf</span> <span><span>'</span>The Bat\nhid in\nthe hat.\n<span>'</span></span> <span>&gt;</span> bathat</span>

$ <span><span><span>#</span> jb-cat is like cat, but the output is stream-encoded as a single JSON string</span></span>
$ <span>jb-cat catmat bathat</span>
<span>"The Cat\nsat on\nthe mat.\nThe Bat\nhid in\nthe hat.\n"</span>

$ <span><span><span>#</span> jb-stream is a filter program that encodes each input line as a JSON string</span></span>
$ <span>cat catmat bathat <span>|</span> jb-stream</span>
<span>"The Cat"</span>
<span>"sat on"</span>
<span>"the mat."</span>
<span>"The Bat"</span>
<span>"hid in"</span>
<span>"the hat."</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Streaming output</h3><a id="user-content-streaming-output" aria-label="Permalink: Streaming output" href="#streaming-output"></a></p>
<p dir="auto">By default <code>jb</code> collects output in a buffer and outputs it all at once at the
end. This has the advantage that it does not emit partial output if an error
occurs mid-way through.</p>
<p dir="auto">However, setting the <code>JSON_BASH_STREAM=true</code> makes <code>jb</code> output content
incrementally. <code>jb</code> can stream-encode values it's pulling from file references:</p>
<ul dir="auto">
<li>Single string values from files are stream-encoded</li>
<li>Arrays of any type coming from files are stream-encoded (individual elements
are fully buffered), but elements are emitted incrementally</li>
<li><code>:raw</code> values from files are streamed</li>
</ul>
<p dir="auto"><code>:json</code> values can't be streamed unfortunately — <code>jb</code> (ab)uses grep to validate
JSON using PCRE's recursive matching features, but sadly grep buffers complete
inputs, even when backtracking and matched-region output are disabled.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Argument syntax details</h3><a id="user-content-argument-syntax-details" aria-label="Permalink: Argument syntax details" href="#argument-syntax-details"></a></p>
<p dir="auto">The full syntax of <code>jb</code> arguments is documented in a (pseudo) grammar in
<a href="https://github.com/h4l/json.bash/blob/main/hack/syntax_patterns.bash">hack/syntax_patterns.bash</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Background &amp; performance notes</h2><a id="user-content-background--performance-notes" aria-label="Permalink: Background &amp; performance notes" href="#background--performance-notes"></a></p>
<p dir="auto">Quite reasonably, you may be wondering why anyone would use Bash to implement a
JSON encoder. Won't that be ridiculously slow? I thought so too. Initially, I
just wanted to encode JSON strings from Bash without needing to depend on a
separate program. My initial few attempts at this were indeed hideously slow.
But after a few iterations I was able to get decent performance by operating
only on entire strings (or arrays of strings) (not byte-by-byte, or
string-by-string for arrays), and absolutely avoiding any forking of subshells.</p>
<p dir="auto">If you don't fork, and minimise the number of Bash-level operations, Bash can do
surprisingly well. Of course, performance still can't compare with a C program.
Well, that depends what you're measuring. Because starting a new process can be
surprisingly slow. So a race between <code>json.bash</code> and program like <a href="https://github.com/jqlang/jq"><code>jq</code></a> or
<a href="https://github.com/jpmens/jo"><code>jo</code></a> is a bit like a 100m race between a tortoise and a hare, where the
tortoise gets a 1 hour headstart.</p>
<p dir="auto">If you care about latency rather than throughput, calling <code>json</code> from an
already-running Bash script is a little faster than running a separate <code>jo</code>
process. And significantly faster than running <code>jq</code>, which is really slow to
start.</p>
<p dir="auto">There's a very basic benchmark script at
<a href="https://github.com/h4l/json.bash/blob/main/hack/hot_loop.bash">hack/hot_loop.bash</a>:</p>
<div data-snippet-clipboard-copy-content="$ time hack/hot_loop.bash json.bash 10000 > /dev/null
json.bash

real    0m8.193s
user    0m8.174s
sys     0m0.019s

$ time hack/hot_loop.bash jo 10000 > /dev/null
jo

real    0m9.393s
user    0m2.566s
sys     0m7.386s

$ # Note: 1000 not 10_000
$ time hack/hot_loop.bash jq 1000 > /dev/null
jq

real    0m20.453s
user    0m19.127s
sys     0m1.386s"><pre><code>$ time hack/hot_loop.bash json.bash 10000 &gt; /dev/null
json.bash

real    0m8.193s
user    0m8.174s
sys     0m0.019s

$ time hack/hot_loop.bash jo 10000 &gt; /dev/null
jo

real    0m9.393s
user    0m2.566s
sys     0m7.386s

$ # Note: 1000 not 10_000
$ time hack/hot_loop.bash jq 1000 &gt; /dev/null
jq

real    0m20.453s
user    0m19.127s
sys     0m1.386s
</code></pre></div>
<p dir="auto">If we just use <code>json.bash</code>'s <code>json.encode_string</code> encoding function to manually
construct the JSON (not the full argument parsing stuff) we can do a lot better
still:</p>
<div data-snippet-clipboard-copy-content="$ time hack/hot_loop.bash custom-json.bash 10000 > /dev/null
custom-json.bash

real    0m1.901s
user    0m1.891s
sys     0m0.011s"><pre><code>$ time hack/hot_loop.bash custom-json.bash 10000 &gt; /dev/null
custom-json.bash

real    0m1.901s
user    0m1.891s
sys     0m0.011s
</code></pre></div>
<p dir="auto">This kind of purpose-specific encoding is what I had in mind when I started
this. I was calling <code>jq</code> lots of times from a Bash script, finding it to be very
slow, and wondering if I could start a single <code>jq</code> process and make a kind of
tiny RPC protocol, sending it JSON from the Bash script to avoid the startup
delay on each operation. That would require some ability to encode JSON from
Bash.</p>
<p dir="auto">I wasn't planning to write something comparable to <code>jo</code> when I started, but idea
of a <code>jo</code>-like program that only depends on bash kind of appealed to me. Maybe I
should port it to a more suitable language though. The program is a now a lot
larger in size and scope than I originally anticipated when starting, I
certainly wouldn't have written it in bash if I'd known how large it'd become.
🙃</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li><a href="https://github.com/jpmens/jo">jo</a> for the general idea of a command-line program that generates JSON</li>
<li><a href="https://github.com/OceanSprint/tesh">tesh</a> which automatically runs and tests the command-line output examples
here — it would not be at all practical to maintain these kind of examples
without it. With tesh the examples become a beneficial second layer of tests,
rather than a maintenance burdon.</li>
<li><a href="https://github.com/jqlang/jq">jq</a> for making it pleasant to use with JSON on the command-line and in shell
scripts</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Man-Computer Symbiosis (1960) (118 pts)]]></title>
            <link>https://groups.csail.mit.edu/medg/people/psz/Licklider.html</link>
            <guid>40864249</guid>
            <pubDate>Wed, 03 Jul 2024 09:26:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groups.csail.mit.edu/medg/people/psz/Licklider.html">https://groups.csail.mit.edu/medg/people/psz/Licklider.html</a>, See on <a href="https://news.ycombinator.com/item?id=40864249">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center>
<span size="6"><b>Man-Computer Symbiosis</b></span>
<p><b>J. C. R. Licklider</b><br>
IRE Transactions on Human Factors in Electronics,<br>
volume HFE-1, pages 4-11, March 1960
</p></center>
<h2>Summary</h2>
<blockquote>Man-computer symbiosis is an expected development in cooperative interaction between men and electronic computers. It will involve very close coupling between the human and the electronic members of the partnership. The main aims are 1) to let computers facilitate formulative thinking as they now facilitate the solution of formulated problems, and 2) to enable men and computers to cooperate in making decisions and controlling complex situations without inflexible dependence on predetermined programs. In the anticipated symbiotic partnership, men will set the goals, formulate the hypotheses, determine the criteria, and perform the evaluations. Computing machines will do the routinizable work that must be done to prepare the way for insights and decisions in technical and scientific thinking. Preliminary analyses indicate that the symbiotic partnership will perform intellectual operations much more effectively than man alone can perform them. Prerequisites for the achievement of the effective, cooperative association include developments in computer time sharing, in memory components, in memory organization, in programming languages, and in input and output equipment.</blockquote>
<h2>1 Introduction</h2>

<p>The fig tree is pollinated only by the insect <i>Blastophaga grossorun</i>. The larva of the insect lives in the ovary of the fig tree, and there it gets its food. The tree and the insect are thus heavily interdependent: the tree cannot reproduce without the insect; the insect cannot eat without the tree; together, they constitute not only a viable but a productive and thriving partnership. This cooperative "living together in intimate association, or even close union, of two dissimilar organisms" is called symbiosis [27].
</p><p>"Man-computer symbiosis is a subclass of man-machine systems. There are many man-machine systems. At present, however, there are no man-computer symbioses. The purposes of this paper are to present the concept and, hopefully, to foster the development of man-computer symbiosis by analyzing some problems of interaction between men and computing machines, calling attention to applicable principles of man-machine engineering, and pointing out a few questions to which research answers are needed. The hope is that, in not too many years, human brains and computing machines will be coupled together very tightly, and that the resulting partnership will think as no human brain has ever thought and process data in a way not approached by the information-handling machines we know today.
</p><h2>1.2	Between "Mechanically Extended Man" and "Artificial Intelligence"</h2>
<p>As a concept, man-computer symbiosis is different in an important way from what North [21] has called "mechanically extended man." In the man-machine systems of the past, the human operator supplied the initiative, the direction, the integration, and the criterion. The mechanical parts of the systems were mere extensions, first of the human arm, then of the human eye. These systems certainly did not consist of "dissimilar organisms living together..." There was only one kind of organism-man-and the rest was there only to help him.
</p><p>In one sense of course, any man-made system is intended to help man, to help a man or men outside the system. If we focus upon the human operator within the system, however, we see that, in some areas of technology, a fantastic change has taken place during the last few years. "Mechanical extension" has given way to replacement of men, to automation, and the men who remain are there more to help than to be helped. In some instances, particularly in large computer-centered information and control systems, the human operators are responsible mainly for functions that it proved infeasible to automate. Such systems ("humanly extended machines," North might call them) are not symbiotic systems. They are "semi-automatic" systems, systems that started out to be fully automatic but fell short of the goal.
</p><p>Man-computer symbiosis is probably not the ultimate paradigm for complex technological systems. It seems entirely possible that, in due course, electronic or chemical "machines" will outdo the human brain in most of the functions we now consider exclusively within its province. Even now, Gelernter's IBM-704 program for proving theorems in plane geometry proceeds at about the same pace as Brooklyn high school students, and makes similar errors.[12] There are, in fact, several theorem-proving, problem-solving, chess-playing, and pattern-recognizing programs (too many for complete reference [1, 2, 5, 8, 11, 13, 17, 18, 19, 22, 23, 25]) capable of rivaling human intellectual performance in restricted areas; and Newell, Simon, and Shaw's [20] "general problem solver" may remove some of the restrictions. In short, it seems worthwhile to avoid argument with (other) enthusiasts for artificial intelligence by conceding dominance in the distant future of cerebration to machines alone. There will nevertheless be a fairly long interim during which the main intellectual advances will be made by men and computers working together in intimate association. A multidisciplinary study group, examining future research and development problems of the Air Force, estimated that it would be 1980 before developments in artificial intelligence make it possible for machines alone to do much thinking or problem solving of military significance. That would leave, say, five years to develop man-computer symbiosis and 15 years to use it. The 15 may be 10 or 500, but those years should be intellectually the most creative and exciting in the history of mankind.
</p><h2>2 Aims of Man-Computer Symbiosis</h2>
<p>Present-day computers are designed primarily to solve preformulated problems or to process data according to predetermined procedures. The course of the computation may be conditional upon results obtained during the computation, but all the alternatives must be foreseen in advance. (If an unforeseen alternative arises, the whole process comes to a halt and awaits the necessary extension of the program.) The requirement for preformulation or predetermination is sometimes no great disadvantage. It is often said that programming for a computing machine forces one to think clearly, that it disciplines the thought process. If the user can think his problem through in advance, symbiotic association with a computing machine is not necessary.
</p><p>However, many problems that can be thought through in advance are very difficult to think through in advance. They would be easier to solve, and they could be solved faster, through an intuitively guided trial-and-error procedure in which the computer cooperated, turning up flaws in the reasoning or revealing unexpected turns in the solution. Other problems simply cannot be formulated without computing-machine aid. Poincare anticipated the frustration of an important group of would-be computer users when he said, "The question is not, 'What is the answer?' The question is, 'What is the question?'" One of the main aims of man-computer symbiosis is to bring the computing machine effectively into the formulative parts of technical problems.
</p><p>The other main aim is closely related. It is to bring computing machines effectively into processes of thinking that must go on in "real time," time that moves too fast to permit using computers in conventional ways. Imagine trying, for example, to direct a battle with the aid of a computer on such a schedule as this. You formulate your problem today. Tomorrow you spend with a programmer. Next week the computer devotes 5 minutes to assembling your program and 47 seconds to calculating the answer to your problem. You get a sheet of paper 20 feet long, full of numbers that, instead of providing a final solution, only suggest a tactic that should be explored by simulation. Obviously, the battle would be over before the second step in its planning was begun. To think in interaction with a computer in the same way that you think with a colleague whose competence supplements your own will require much tighter coupling between man and machine than is suggested by the example and than is possible today.
</p><h2>3 Need for Computer Participation in Formulative and Real-Time Thinking</h2>
<p>The preceding paragraphs tacitly made the assumption that, if they could be introduced effectively into the thought process, the functions that can be performed by data-processing machines would improve or facilitate thinking and problem solving in an important way. That assumption may require justification.
</p><h2>3.1	A Preliminary and Informal Time-and-Motion Analysis of Technical Thinking</h2>
<p>Despite the fact that there is a voluminous literature on thinking and problem solving, including intensive case-history studies of the process of invention, I could find nothing comparable to a time-and-motion-study analysis of the mental work of a person engaged in a scientific or technical enterprise. In the spring and summer of 1957, therefore, I tried to keep track of what one moderately technical person actually did during the hours he regarded as devoted to work. Although I was aware of the inadequacy of the sampling, I served as my own subject.
</p><p>It soon became apparent that the main thing I did was to keep records, and the project would have become an infinite regress if the keeping of records had been carried through in the detail envisaged in the initial plan. It was not. Nevertheless, I obtained a picture of my activities that gave me pause. Perhaps my spectrum is not typical--I hope it is not, but I fear it is.
</p><p>About 85 per cent of my "thinking" time was spent getting into a position to think, to make a decision, to learn something I needed to know. Much more time went into finding or obtaining information than into digesting it. Hours went into the plotting of graphs, and other hours into instructing an assistant how to plot. When the graphs were finished, the relations were obvious at once, but the plotting had to be done in order to make them so. At one point, it was necessary to compare six experimental determinations of a function relating speech-intelligibility to speech-to-noise ratio. No two experimenters had used the same definition or measure of speech-to-noise ratio. Several hours of calculating were required to get the data into comparable form. When they were in comparable form, it took only a few seconds to determine what I needed to know.
</p><p>Throughout the period I examined, in short, my "thinking" time was devoted mainly to activities that were essentially clerical or mechanical: searching, calculating, plotting, transforming, determining the logical or dynamic consequences of a set of assumptions or hypotheses, preparing the way for a decision or an insight. Moreover, my choices of what to attempt and what not to attempt were determined to an embarrassingly great extent by considerations of clerical feasibility, not intellectual capability.
</p><p>The main suggestion conveyed by the findings just described is that the operations that fill most of the time allegedly devoted to technical thinking are operations that can be performed more effectively by machines than by men. Severe problems are posed by the fact that these operations have to be performed upon diverse variables and in unforeseen and continually changing sequences. If those problems can be solved in such a way as to create a symbiotic relation between a man and a fast information-retrieval and data-processing machine, however, it seems evident that the cooperative interaction would greatly improve the thinking process.
</p><p>It may be appropriate to acknowledge, at this point, that we are using the term "computer" to cover a wide class of calculating, data-processing, and information-storage-and-retrieval machines. The capabilities of machines in this class are increasing almost daily. It is therefore hazardous to make general statements about capabilities of the class. Perhaps it is equally hazardous to make general statements about the capabilities of men. Nevertheless, certain genotypic differences in capability between men and computers do stand out, and they have a bearing on the nature of possible man-computer symbiosis and the potential value of achieving it.
</p><p>As has been said in various ways, men are noisy, narrow-band devices, but their nervous systems have very many parallel and simultaneously active channels. Relative to men, computing machines are very fast and very accurate, but they are constrained to perform only one or a few elementary operations at a time. Men are flexible, capable of "programming themselves contingently" on the basis of newly received information. Computing machines are single-minded, constrained by their " pre-programming." Men naturally speak redundant languages organized around unitary objects and coherent actions and employing 20 to 60 elementary symbols. Computers "naturally" speak nonredundant languages, usually with only two elementary symbols and no inherent appreciation either of unitary objects or of coherent actions.
</p><p>To be rigorously correct, those characterizations would have to include many qualifiers. Nevertheless, the picture of dissimilarity (and therefore potential supplementation) that they present is essentially valid. Computing machines can do readily, well, and rapidly many things that are difficult or impossible for man, and men can do readily and well, though not rapidly, many things that are difficult or impossible for computers. That suggests that a symbiotic cooperation, if successful in integrating the positive characteristics of men and computers, would be of great value. The differences in speed and in language, of course, pose difficulties that must be overcome.
</p><h2>4 Separable Functions of Men and Computers in the Anticipated Symbiotic Association</h2>
<p>It seems likely that the contributions of human operators and equipment will blend together so completely in many operations that it will be difficult to separate them neatly in analysis. That would be the case it; in gathering data on which to base a decision, for example, both the man and the computer came up with relevant precedents from experience and if the computer then suggested a course of action that agreed with the man's intuitive judgment. (In theorem-proving programs, computers find precedents in experience, and in the SAGE System, they suggest courses of action. The foregoing is not a far-fetched example. ) In other operations, however, the contributions of men and equipment will be to some extent separable.
</p><p>Men will set the goals and supply the motivations, of course, at least in the early years. They will formulate hypotheses. They will ask questions. They will think of mechanisms, procedures, and models. They will remember that such-and-such a person did some possibly relevant work on a topic of interest back in 1947, or at any rate shortly after World War II, and they will have an idea in what journals it might have been published. In general, they will make approximate and fallible, but leading, contributions, and they will define criteria and serve as evaluators, judging the contributions of the equipment and guiding the general line of thought.
</p><p>In addition, men will handle the very-low-probability situations when such situations do actually arise. (In current man-machine systems, that is one of the human operator's most important functions. The sum of the probabilities of very-low-probability alternatives is often much too large to neglect. ) Men will fill in the gaps, either in the problem solution or in the computer program, when the computer has no mode or routine that is applicable in a particular circumstance.
</p><p>The information-processing equipment, for its part, will convert hypotheses into testable models and then test the models against data (which the human operator may designate roughly and identify as relevant when the computer presents them for his approval). The equipment will answer questions. It will simulate the mechanisms and models, carry out the procedures, and display the results to the operator. It will transform data, plot graphs ("cutting the cake" in whatever way the human operator specifies, or in several alternative ways if the human operator is not sure what he wants). The equipment will interpolate, extrapolate, and transform. It will convert static equations or logical statements into dynamic models so the human operator can examine their behavior. In general, it will carry out the routinizable, clerical operations that fill the intervals between decisions.
</p><p>In addition, the computer will serve as a statistical-inference, decision-theory, or game-theory machine to make elementary evaluations of suggested courses of action whenever there is enough basis to support a formal statistical analysis. Finally, it will do as much diagnosis, pattern-matching, and relevance-recognizing as it profitably can, but it will accept a clearly secondary status in those areas.
</p><h2>5	Prerequisites for Realization of Man-Computer Symbiosis</h2>
<p>The data-processing equipment tacitly postulated in the preceding section is not available. The computer programs have not been written. There are in fact several hurdles that stand between the nonsymbiotic present and the anticipated symbiotic future. Let us examine some of them to see more clearly what is needed and what the chances are of achieving it.
</p><h2>5.1	Speed Mismatch Between Men and Computers</h2>
<p>Any present-day large-scale computer is too fast and too costly for real-time cooperative thinking with one man. Clearly, for the sake of efficiency and economy, the computer must divide its time among many users. Timesharing systems are currently under active development. There are even arrangements to keep users from "clobbering" anything but their own personal programs.
</p><p>It seems reasonable to envision, for a time 10 or 15 years hence, a "thinking center" that will incorporate the functions of present-day libraries together with anticipated advances in information storage and retrieval and the symbiotic functions suggested earlier in this paper. The picture readily enlarges itself into a network of such centers, connected to one another by wide-band communication lines and to individual users by leased-wire services. In such a system, the speed of the computers would be balanced, and the cost of the gigantic memories and the sophisticated programs would be divided by the number of users.
</p><h2>5.2	Memory Hardware Requirements</h2>
<p>When we start to think of storing any appreciable fraction of a technical literature in computer memory, we run into billions of bits and, unless things change markedly, billions of dollars.
</p><p>The first thing to face is that we shall not store all the technical and scientific papers in computer memory. We may store the parts that can be summarized most succinctly-the quantitative parts and the reference citations-but not the whole. Books are among the most beautifully engineered, and human-engineered, components in existence, and they will continue to be functionally important within the context of man-computer symbiosis. (Hopefully, the computer will expedite the finding, delivering, and returning of books.)
</p><p>The second point is that a very important section of memory will be permanent: part indelible <i>memory</i> and part <i>published memory</i>. The computer will be able to write once into indelible memory, and then read back indefinitely, but the computer will not be able to erase indelible memory. (It may also over-write, turning all the 0's into l's, as though marking over what was written earlier.) Published memory will be "read-only" memory. It will be introduced into the computer already structured. The computer will be able to refer to it repeatedly, but not to change it. These types of memory will become more and more important as computers grow larger. They can be made more compact than core, thin-film, or even tape memory, and they will be much less expensive. The main engineering problems will concern selection circuitry.
</p><p>In so far as other aspects of memory requirement are concerned, we may count upon the continuing development of ordinary scientific and business computing machines There is some prospect that memory elements will become as fast as processing (logic) elements. That development would have a revolutionary effect upon the design of computers.
</p><h2>5.3	Memory Organization Requirements</h2>
<p>Implicit in the idea of man-computer symbiosis are the requirements that information be retrievable both by name and by pattern and that it be accessible through procedure much faster than serial search. At least half of the problem of memory organization appears to reside in the storage procedure. Most of the remainder seems to be wrapped up in the problem of pattern recognition within the storage mechanism or medium. Detailed discussion of these problems is beyond the present scope. However, a brief outline of one promising idea, "trie memory," may serve to indicate the general nature of anticipated developments.
</p><p>Trie memory is so called by its originator, Fredkin [10], because it is designed to facilitate retrieval of information and because the branching storage structure, when developed, resembles a tree. Most common memory systems store functions of arguments at locations designated by the arguments. (In one sense, they do not store the arguments at all. In another and more realistic sense, they store all the possible arguments in the framework structure of the memory.) The trie memory system, on the other hand, stores both the functions and the arguments. The argument is introduced into the memory first, one character at a time, starting at a standard initial register. Each argument register has one cell for each character of the ensemble (e.g., two for information encoded in binary form) and each character cell has within it storage space for the address of the next register. The argument is stored by writing a series of addresses, each one of which tells where to find the next. At the end of the argument is a special "end-of-argument" marker. Then follow directions to the function, which is stored in one or another of several ways, either further trie structure or "list structure" often being most effective.
</p><p>The trie memory scheme is inefficient for small memories, but it becomes increasingly efficient in using available storage space as memory size increases. The attractive features of the scheme are these: 1) The retrieval process is extremely simple. Given the argument, enter the standard initial register with the first character, and pick up the address of the second. Then go to the second register, and pick up the address of the third, etc. 2) If two arguments have initial characters in common, they use the same storage space for those characters. 3) The lengths of the arguments need not be the same, and need not be specified in advance. 4) No room in storage is reserved for or used by any argument until it is actually stored. The trie structure is created as the items are introduced into the memory. 5) A function can be used as an argument for another function, and that function as an argument for the next. Thus, for example, by entering with the argument, "matrix multiplication," one might retrieve the entire program for performing a matrix multiplication on the computer. 6) By examining the storage at a given level, one can determine what thus-far similar items have been stored. For example, if there is no citation for Egan, J. P., it is but a step or two backward to pick up the trail of Egan, James ... .
</p><p>The properties just described do not include all the desired ones, but they bring computer storage into resonance with human operators and their predilection to designate things by naming or pointing.
</p><h2>5.4	The Language Problem</h2>
<p>The basic dissimilarity between human languages and computer languages may be the most serious obstacle to true symbiosis. It is reassuring, however, to note what great strides have already been made, through interpretive programs and particularly through assembly or compiling programs such as FORTRAN, to adapt computers to human language forms. The "Information Processing Language" of Shaw, Newell, Simon, and Ellis [24] represents another line of rapprochement. And, in ALGOL and related systems, men are proving their flexibility by adopting standard formulas of representation and expression that are readily translatable into machine language.
</p><p>For the purposes of real-time cooperation between men and computers, it will be necessary, however, to make use of an additional and rather different principle of communication and control. The idea may be highlighted by comparing instructions ordinarily addressed to intelligent human beings with instructions ordinarily used with computers. The latter specify precisely the individual steps to take and the sequence in which to take them. The former present or imply something about incentive or motivation, and they supply a criterion by which the human executor of the instructions will know when he has accomplished his task. In short: instructions directed to computers specify courses; instructions-directed to human beings specify goals.
</p><p>Men appear to think more naturally and easily in terms of goals than in terms of courses. True, they usually know something about directions in which to travel or lines along which to work, but few start out with precisely formulated itineraries. Who, for example, would depart from Boston for Los Angeles with a detailed specification of the route? Instead, to paraphrase Wiener, men bound for Los Angeles try continually to decrease the amount by which they are not yet in the smog.
</p><p>Computer instruction through specification of goals is being approached along two paths. The first involves problem-solving, hill-climbing, self-organizing programs. The second involves real-time concatenation of preprogrammed segments and closed subroutines which the human operator can designate and call into action simply by name.
</p><p>Along the first of these paths, there has been promising exploratory work. It is clear that, working within the loose constraints of predetermined strategies, computers will in due course be able to devise and simplify their own procedures for achieving stated goals. Thus far, the achievements have not been substantively important; they have constituted only "demonstration in principle." Nevertheless, the implications are far-reaching.
</p><p>Although the second path is simpler and apparently capable of earlier realization, it has been relatively neglected. Fredkin's trie memory provides a promising paradigm. We may in due course see a serious effort to develop computer programs that can be connected together like the words and phrases of speech to do whatever computation or control is required at the moment. The consideration that holds back such an effort, apparently, is that the effort would produce nothing that would be of great value in the context of existing computers. It would be unrewarding to develop the language before there are any computing machines capable of responding meaningfully to it.
</p><h2>5.5	Input and Output Equipment</h2>
<p>The department of data processing that seems least advanced, in so far as the requirements of man-computer symbiosis are concerned, is the one that deals with input and output equipment or, as it is seen from the human operator's point of view, displays and controls. Immediately after saying that, it is essential to make qualifying comments, because the engineering of equipment for high-speed introduction and extraction of information has been excellent, and because some very sophisticated display and control techniques have been developed in such research laboratories as the Lincoln Laboratory. By and large, in generally available computers, however, there is almost no provision for any more effective, immediate man-machine communication than can be achieved with an electric typewriter.
</p><p>Displays seem to be in a somewhat better state than controls. Many computers plot graphs on oscilloscope screens, and a few take advantage of the remarkable capabilities, graphical and symbolic, of the charactron display tube. Nowhere, to my knowledge, however, is there anything approaching the flexibility and convenience of the pencil and doodle pad or the chalk and blackboard used by men in technical discussion.
</p><p>1)	<i>Desk-Surface Display and Control:</i> Certainly, for effective man-computer interaction, it will be necessary for the man and the computer to draw graphs and pictures and to write notes and equations to each other on the same display surface. The man should be able to present a function to the computer, in a rough but rapid fashion, by drawing a graph. The computer should read the man's writing, perhaps on the condition that it be in clear block capitals, and it should immediately post, at the location of each hand-drawn symbol, the corresponding character as interpreted and put into precise type-face. With such an input-output device, the operator would quickly learn to write or print in a manner legible to the machine. He could compose instructions and subroutines, set them into proper format, and check them over before introducing them finally into the computer's main memory. He could even define new symbols, as Gilmore and Savell [14] have done at the Lincoln Laboratory, and present them directly to the computer. He could sketch out the format of a table roughly and let the computer shape it up with precision. He could correct the computer's data, instruct the machine via flow diagrams, and in general interact with it very much as he would with another engineer, except that the "other engineer" would be a precise draftsman, a lightning calculator, a mnemonic wizard, and many other valuable partners all in one.
</p><p>2)	<i>Computer-Posted Wall Display:</i> In some technological systems, several men share responsibility for controlling vehicles whose behaviors interact. Some information must be presented simultaneously to all the men, preferably on a common grid, to coordinate their actions. Other information is of relevance only to one or two operators. There would be only a confusion of uninterpretable clutter if all the information were presented on one display to all of them. The information must be posted by a computer, since manual plotting is too slow to keep it up to date.
</p><p>The problem just outlined is even now a critical one, and it seems certain to become more and more critical as time goes by. Several designers are convinced that displays with the desired characteristics can be constructed with the aid of flashing lights and time-sharing viewing screens based on the light-valve principle.
</p><p>The large display should be supplemented, according to most of those who have thought about the problem, by individual display-control units. The latter would permit the operators to modify the wall display without leaving their locations. For some purposes, it would be desirable for the operators to be able to communicate with the computer through the supplementary displays and perhaps even through the wall display. At least one scheme for providing such communication seems feasible.
</p><p>The large wall display and its associated system are relevant, of course, to symbiotic cooperation between a computer and a team of men. Laboratory experiments have indicated repeatedly that informal, parallel arrangements of operators, coordinating their activities through reference to a large situation display, have important advantages over the arrangement, more widely used, that locates the operators at individual consoles and attempts to correlate their actions through the agency of a computer. This is one of several operator-team problems in need of careful study.
</p><p>3)	<i>Automatic Speech Production and Recognition:</i> How desirable and how feasible is speech communication between human operators and computing machines? That compound question is asked whenever sophisticated data-processing systems are discussed. Engineers who work and live with computers take a conservative attitude toward the desirability. Engineers who have had experience in the field of automatic speech recognition take a conservative attitude toward the feasibility. Yet there is continuing interest in the idea of talking with computing machines. In large part, the interest stems from realization that one can hardly take a military commander or a corporation president away from his work to teach him to type. If computing machines are ever to be used directly by top-level decision makers, it may be worthwhile to provide communication via the most natural means, even at considerable cost.
</p><p>Preliminary analysis of his problems and time scales suggests that a corporation president would be interested in a symbiotic association with a computer only as an avocation. Business situations usually move slowly enough that there is time for briefings and conferences. It seems reasonable, therefore, for computer specialists to be the ones who interact directly with computers in business offices.
</p><p>The military commander, on the other hand, faces a greater probability of having to make critical decisions in short intervals of time. It is easy to overdramatize the notion of the ten-minute war, but it would be dangerous to count on having more than ten minutes in which to make a critical decision. As military system ground environments and control centers grow in capability and complexity, therefore, a real requirement for automatic speech production and recognition in computers seems likely to develop. Certainly, if the equipment were already developed, reliable, and available, it would be used.
</p><p>In so far as feasibility is concerned, speech production poses less severe problems of a technical nature than does automatic recognition of speech sounds. A commercial electronic digital voltmeter now reads aloud its indications, digit by digit. For eight or ten years, at the Bell Telephone Laboratories, the Royal Institute of Technology (Stockholm), the Signals Research and Development Establishment (Christchurch), the Haskins Laboratory, and the Massachusetts Institute of Technology, Dunn [6], Fant [7], Lawrence [15], Cooper [3], Stevens [26], and their co-workers, have demonstrated successive generations of intelligible automatic talkers. Recent work at the Haskins Laboratory has led to the development of a digital code, suitable for use by computing machines, that makes an automatic voice utter intelligible connected discourse [16].
</p><p>The feasibility of automatic speech recognition depends heavily upon the size of the vocabulary of words to be recognized and upon the diversity of talkers and accents with which it must work. Ninety-eight per cent correct recognition of naturally spoken decimal digits was demonstrated several years ago at the Bell Telephone Laboratories and at the Lincoln Laboratory [4], [9]. To go a step up the scale of vocabulary size, we may say that an automatic recognizer of clearly spoken alpha-numerical characters can almost surely be developed now on the basis of existing knowledge. Since untrained operators can read at least as rapidly as trained ones can type, such a device would be a convenient tool in almost any computer installation.
</p><p>For real-time interaction on a truly symbiotic level, however, a vocabulary of about 2000 words, e.g., 1000 words of something like basic English and 1000 technical terms, would probably be required. That constitutes a challenging problem. In the consensus of acousticians and linguists, construction of a recognizer of 2000 words cannot be accomplished now. However, there are several organizations that would happily undertake to develop an automatic recognize for such a vocabulary on a five-year basis. They would stipulate that the speech be clear speech, dictation style, without unusual accent.
</p><p>Although detailed discussion of techniques of automatic speech recognition is beyond the present scope, it is fitting to note that computing machines are playing a dominant role in the development of automatic speech recognizers. They have contributed the impetus that accounts for the present optimism, or rather for the optimism presently found in some quarters. Two or three years ago, it appeared that automatic recognition of sizeable vocabularies would not be achieved for ten or fifteen years; that it would have to await much further, gradual accumulation of knowledge of acoustic, phonetic, linguistic, and psychological processes in speech communication. Now, however, many see a prospect of accelerating the acquisition of that knowledge with the aid of computer processing of speech signals, and not a few workers have the feeling that sophisticated computer programs will be able to perform well as speech-pattern recognizes even without the aid of much substantive knowledge of speech signals and processes. Putting those two considerations together brings the estimate of the time required to achieve practically significant speech recognition down to perhaps five years, the five years just mentioned.
</p><h2>References</h2>
<p>[1]	A. Bernstein and M. deV. Roberts, "Computer versus chess-player," <i>Scientific American</i>, vol. 198, pp. 96-98; June, 1958.</p>
<p>[2]	W. W. Bledsoe and I. Browning, "Pattern Recognition and Reading by Machine," presented at the Eastern Joint Computer Conf, Boston, Mass., December, 1959.</p>
<p>[3]	F. S. Cooper, et al., "Some experiments on the perception of synthetic speech sounds," <i>J. Acoust Soc. Amer.</i>, vol.24, pp.597-606; November, 1952.</p>
<p>[4]	K. H. Davis, R. Biddulph, and S. Balashek, "Automatic recognition of spoken digits," in W. Jackson, <i>Communication Theory</i>, Butterworths Scientific Publications, London, Eng., pp. 433-441; 1953.</p>
<p>[5]	G. P. Dinneen, "Programming pattern recognition," <i>Proc. WJCC</i>, pp. 94-100; March, 1955.</p>
<p>[6]	H. K. Dunn, "The calculation of vowel resonances, and an electrical vocal tract," <i>J. Acoust Soc. Amer.</i>, vol. 22, pp.740-753; November, 1950.</p>
<p>[7] 	G. Fant, "On the Acoustics of Speech," paper presented at the Third Internatl. Congress on Acoustics, Stuttgart, Ger.; September, 1959.</p>
<p>[8]	B. G. Farley and W. A. Clark, "Simulation of self-organizing systems by digital computers." <i>IRE Trans. on Information Theory</i>, vol. IT-4, pp.76-84; September, 1954</p>
<p>[9]	J. W. Forgie and C. D. Forgie, "Results obtained from a vowel recognition computer program," <i>J. Acoust Soc. Amer.</i>, vol. 31, pp. 1480-1489; November, 1959</p>
<p>[10]	E. Fredkin, "Trie memory," <i>Communications of the ACM</i>, Sept. 1960, pp. 490-499</p>
<p>[11]	R. M. Friedberg, "A learning machine: Part I," <i>IBM J. Res. &amp; Dev.</i>, vol.2, pp.2-13; January, 1958.</p>
<p>[12]	H. Gelernter, "Realization of a Geometry Theorem Proving Machine." Unesco, NS, ICIP, 1.6.6, Internatl. Conf. on Information Processing, Paris, France; June, 1959.</p>
<p>[13]	P. C. Gilmore, "A Program for the Production of Proofs for Theorems Derivable Within the First Order Predicate Calculus from Axioms," Unesco, NS, ICIP, 1.6.14, Internatl. Conf. on Information Processing, Paris, France; June, 1959.</p>
<p>[14]	J. T. Gilmore and R. E. Savell, "The Lincoln Writer," Lincoln Laboratory, M. I. T., Lexington, Mass., Rept. 51-8; October, 1959.</p>
<p>[15]	W. Lawrence, et al., "Methods and Purposes of Speech Synthesis," Signals Res. and Dev. Estab., Ministry of Supply, Christchurch, Hants, England, Rept. 56/1457; March, 1956.</p>
<p>[16]	A. M. Liberman, F. Ingemann, L. Lisker, P. Delattre, and F. S. Cooper, "Minimal rules for synthesizing speech," <i>J. Acoust Soc. Amer.</i>, vol. 31, pp. 1490-1499; November, 1959.</p>
<p>[17]	A. Newell, "The chess machine: an example of dealing with a complex task by adaptation," <i>Proc. WJCC</i>, pp. 101-108; March, 1955.</p>
<p>[18]	A. Newell and J. C. Shaw, "Programming the logic theory machine." <i>Proc. WJCC</i>, pp. 230-240; March, 1957.</p>
<p>[19]	A. Newell, J. C. Shaw, and H. A. Simon, "Chess-playing programs and the problem of complexity," <i>IBM J. Res &amp; Dev.</i>, vol.2, pp. 320-33.5; October, 1958.</p>
<p>[20]	A. Newell, H. A. Simon, and J. C. Shaw, "Report on a general problem-solving program," Unesco, NS, ICIP, 1.6.8, Internatl. Conf. on Information Processing, Paris, France; June, 1959.</p>
<p>[21]	J. D. North, "The rational behavior of mechanically extended man", Boulton Paul Aircraft Ltd., Wolverhampton, Eng.; September, 1954.</p>
<p>[22]	0. G. Selfridge, "Pandemonium, a paradigm for learning," <i>Proc. Symp. Mechanisation of Thought Processes</i>, Natl. Physical Lab., Teddington, Eng.; November, 1958.</p>
<p>[23]	C. E. Shannon, "Programming a computer for playing chess," <i>Phil. Mag.</i>, vol.41, pp.256-75; March, 1950.</p>
<p>[24]	J. C. Shaw, A. Newell, H. A. Simon, and T. O. Ellis, "A command structure for complex information processing," <i>Proc. WJCC</i>, pp. 119-128; May, 1958.</p>
<p>[25]	H. Sherman, "A Quasi-Topological Method for Recognition of Line Patterns," Unesco, NS, ICIP, H.L.5, Internatl. Conf. on Information Processing, Paris, France; June, 1959</p>
<p>[26] K. N. Stevens, S. Kasowski, and C. G. Fant, "Electric analog of the vocal tract," <i>J. Acoust. Soc. Amer.</i>, vol. 25, pp. 734-742; July, 1953.</p>
<p>[27] <i>Webster's New International Dictionary</i>, 2nd e., G. and C. Merriam Co., Springfield, Mass., p. 2555; 1958.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Received an AI Email (656 pts)]]></title>
            <link>https://timharek.no/blog/i-received-an-ai-email</link>
            <guid>40862865</guid>
            <pubDate>Wed, 03 Jul 2024 05:05:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timharek.no/blog/i-received-an-ai-email">https://timharek.no/blog/i-received-an-ai-email</a>, See on <a href="https://news.ycombinator.com/item?id=40862865">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>