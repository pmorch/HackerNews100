<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 11 Nov 2023 02:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Trading bot that buys stocks bought by politicians is up 20% since May 2022 (121 pts)]]></title>
            <link>https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow</link>
            <guid>38226404</guid>
            <pubDate>Sat, 11 Nov 2023 00:38:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow">https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow</a>, See on <a href="https://news.ycombinator.com/item?id=38226404">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Apple discriminated against US citizens in hiring, DOJ says (240 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/</link>
            <guid>38224950</guid>
            <pubDate>Fri, 10 Nov 2023 21:45:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/">https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/</a>, See on <a href="https://news.ycombinator.com/item?id=38224950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Hiring discrimination
    —
</h4>
            
            <h2 itemprop="description">Apple deterred US citizens from positions open to foreign workers, DOJ found.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/apple-store-logo-800x517.jpg" alt="An Apple corporate logo hangs above the front door of a company store">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/apple-store-logo.jpg" data-height="1617" data-width="2500">Enlarge</a> <span>/</span> Apple Store at Garden State Plaza mall on November 4, 2023, in Paramus, New Jersey.  </p><p>Getty Images | Gary Hershorn </p></figcaption>  </figure>

  




<!-- cache hit 127:single/related:757acc1f958c8af5276c06bb0dc05b7f --><!-- empty -->
<p>Apple illegally discriminated against US citizens and other US residents in its hiring and recruitment practices for certain types of positions that went to foreign workers, the US Department of Justice <a href="https://www.justice.gov/opa/pr/justice-department-secures-25-million-landmark-agreement-apple-resolve-employment">said yesterday</a>. Apple agreed to pay up to $25 million in back pay and civil penalties to settle the DOJ allegations.</p>
<p>Apple discriminated "against US citizens and certain non-US citizens whose permission to live in and work in the United States does not expire," the agency said. The $25 million payment was called the largest ever collected by the Justice Department under the anti-discrimination provision of the Immigration and Nationality Act (INA).</p>
<p>Apple is required to pay $6.75 million in civil penalties and create an $18.25 million fund to provide back pay to those harmed by its hiring practices. Apple did not admit guilt in the <a href="https://www.justice.gov/d9/2023-11/ier-apple_settlement_agreement_signed_2023-11-08_fully_executed.pdf">settlement</a>. But the company acknowledged in a statement that it had "unintentionally not been following the DOJ standard," <a href="https://www.reuters.com/technology/apple-agrees-25-million-settlement-with-us-over-hiring-immigrants-2023-11-09/">according to Reuters</a>.</p>
<p>"We have implemented a robust remediation plan to comply with the requirements of various government agencies as we continue to hire American workers and grow in the US," Apple said. We contacted Apple and will update this article if it provides any further statement.</p>
<p>As Reuters noted, "Foreign labor can often be cheaper than hiring US workers, and immigrants who rely on their employers for green card sponsorship are seen as less likely to leave for a different job."</p>                                            
                                                        
<h2>DOJ investigation</h2>
<p>The DOJ said it began investigating in February 2019 and determined "that Apple violated the INA's anti-discrimination requirements during Apple's recruitment for positions falling under the permanent labor certification program (PERM)." The agency said the discrimination began no later than January 1, 2018, and continued until at least December 31, 2019.</p>
<p><span>Under this program, a "permanent labor certification issued by the Department of Labor (DOL) allows an employer to hire a foreign worker to work permanently in the United States," the DOL </span><span><a href="https://www.dol.gov/agencies/eta/foreign-labor/programs/permanent"><span>says</span></a></span><span>. But the employer must also obtain a certification "that there are not sufficient US workers able, willing, qualified and available to accept the job opportunity in the area of intended employment and that employment of the foreign worker will not adversely affect the wages and working conditions of similarly employed US workers."</span></p>
<p>The DOJ said its investigation "found that Apple engaged in a pattern or practice of citizenship status discrimination in recruitment for positions it hired through PERM, and that the company's unlawful discrimination prejudiced US citizens, US nationals, lawful permanent residents, and those granted asylum or refugee status. These less effective recruitment practices deterred protected workers from applying to positions that Apple preferred to fill instead with PERM beneficiaries."</p>
<p>Apple did not advertise PERM positions on its external job website like it does with other positions, the DOJ said. "It also required all PERM position applicants to mail paper applications, even though the company permitted electronic applications for other positions," the DOJ said.</p>
<p>In some cases, "Apple did not consider certain applications for PERM positions from Apple employees if those applications were submitted electronically, as opposed to paper applications submitted through the mail," the agency said. "These less effective recruitment procedures nearly always resulted in few or no applications to PERM positions from applicants whose permission to work does not expire."</p>
<h2>Apple changes hiring practices</h2>
<p>The settlement requires Apple to make its PERM recruitment practices match its standard recruitment practices more closely. Apple will have to "conduct more expansive recruitment for all PERM positions, including posting PERM positions on its external job website, accepting electronic applications, and enabling applicants to PERM positions to be searchable in its applicant tracking system."</p>
<p>Apple has already implemented some of the changes and agreed to "train its employees on the INA's anti-discrimination requirements and be subject to departmental monitoring for the three-year period of the agreement," the DOJ said.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The hijacking of rare Japanese KitKats (133 pts)]]></title>
            <link>https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats</link>
            <guid>38224810</guid>
            <pubDate>Fri, 10 Nov 2023 21:30:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats">https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats</a>, See on <a href="https://news.ycombinator.com/item?id=38224810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-wrapper">
              <main id="content" role="main">
                <section>
                  <a id="main-content" tabindex="-1"></a>
                    


  <div>
      

    
            
  


<div>
            <div>
            <p>Updated</p>
  
                          <p>
      November 9, 2023 at 5:39 PM</p>
      
  
    </div>

      <div>
            <p>Published</p>
  
                          <p>
      November 9, 2023 at 3:15 PM</p>
      
  
    </div>


  </div>

<div>
      

<div>
<p>NEW YORK – Mr Danny Taing’s 55,000 Kit Kats began their long, twisted, and sometimes obscure journey in Japan.</p>
<p>Mr Taing is the founder of Bokksu, a New York company that sells Japanese snacks in subscription boxes, and he intended to make a tidy sum by flipping the sweets in the United States. </p>
<p>The KitKat shipment, which included sought-after flavours such as melon, matcha latte, and daifuku mochi, had cost US$110,000 (S$149,000), but Bokksu expected to make about US$250,000 in total revenue.</p>

<p>“You can fit a lot of KitKats into two containers,” Mr Taing said.</p>
<p>And they are a booming business. In Japan, enthusiasts clamour for the rarer flavours, with some sold for just a few weeks or only in a specific region. In the United States, obsessives fawn over the collectibles, comparing reviews on Japanese snack blogs and shelling out for limited editions.</p>
<p>These particular KitKats would become key players in an ultimately frustrating saga of shell e-mail accounts, phantom truckers, supply-chain fraud and one seriously bewildered cargo freight broker.</p>


<p>Interviews and e-mails shared with The New York Times tell the story of just one instance of “strategic theft”, a growing corner of the criminal world that the Federal Bureau of Investigation has said accounts for some US$30 billion in losses a year – with food being among the top targets.</p>

<p>The precious sweets landed safely enough in California, and were trucked about 48km across Los Angeles County to a temporary storage facility in South El Monte, run by a company called Japan Crate Acquisition.</p>
<p>After weeks of chugging across the Pacific Ocean, they just needed to make the remaining leg of their journey to Bokksu’s warehouse in Carlstadt, New Jersey, and then into the hands of avid candy fans.</p>
<p>That was where Mr Shane Black came in.</p>

<p>Mr Black, who runs a freight brokering company called Freight Rate Central in Sarasota, Florida, is part of an invisible army of professionals who coordinate and marshal the fleets of trucks that criss-cross the country, carrying everything from chickens to smartphones. For this job, Bokksu would pay him about US$13,000.</p>
<p>Mr Black got to it. He posted the job on a trucking board that is something like a Craigslist for freight. Someone named Tristan with HCH Trucking accepted the job (though he was using a Gmail account), and said he would have the shipment picked up shortly.</p>
<p>On Aug 9, Tristan wrote in an e-mail: “Hey man, The first one is loaded and rolling, the second one we’ll pick it up tomorrow first thing in the morning.”</p>
<p>“There was nothing out of the ordinary,” Mr Black said in an interview.</p>
<h2>Coming clean</h2>
</div>

    <div>
<p>When the shipments failed to reach New Jersey days after any cross-country trip should have been completed, Mr Black started to have visions of KitKats melting in the summer heat.</p>
<p>“Please tell me the freight is in good order and has been refrigerated this whole time?” he e-mailed Tristan.</p>
<p>Tristan replied that one of the trucks had broken down in Washington, Pennsylvania, a small city just south-west of Pittsburgh. Tristan reassured him that the Kit Kats were cool and intact, but “if it’s not fixed by today we will have to head back to the shipper and re-unload them there”.</p>
<p>That sent up all kinds of red flags for Mr Black. If the truck was in good enough shape to drive over 3,800km back to California, why could it not make it fewer than 650km to New Jersey? So Mr Black called HCH Trucking.</p>
<p>“That’s when everything kind of hit the fan,” he said.</p>
<p>When he reached the HCH headquarters in Jersey City, New Jersey, he heard chaos in the background, sounds of panic. The representative told him that their information appeared to have been compromised. They had never heard of any Tristan.</p>
<p>If Mr Black was not dealing with HCH Trucking, who was he dealing with? And most important, where were the six figures’ worth of KitKats?</p>
<p>Seemingly on cue, Tristan followed up. “Time for some coming clean,” he confessed. “I’m actually a scammer and the owner of HCH doesn’t have anything to do with this.”</p>
<p>“Why though?” Mr Black replied plaintively. “What would you stand to gain? Can I please get access to the loads so I can get them to New Jersey? We’re not a big company at all. It‘s just me... I’m the owner and everything else.”</p>
<p>Tristan wrote back: “We’re trying to make money sir, I told you we’re scammers, really sorry I didn’t know your story, and hopefully the loads get to New Jersey.”</p>
<p>Tristan included the addresses of two warehouses, both just east of Los Angeles, where he had dropped the loads.</p>
</div>

  
  <div>
<p>The strange thing was that Mr Black had never paid Tristan any money; the shipping fee was due on delivery. If this was a con, so far it did not seem to be a very profitable one. In any case, Mr Black couldn’t believe his luck.</p>
<p>“When I found out they were at a cold-storage facility, I mean, I was just so happy,” he said. “I thought, ‘OK, we got the freight.’”</p>
<h2>Out of service</h2>
<p>Mr Black spun back into action. According to Tristan, one load was at Inland Empire Cold Storage in Jurupa Valley, California. The other was nearby, at Anytime Crossdock in Ontario, California. Tristan then went silent, and did not respond to repeated e-mails from NYTimes seeking comment.</p>
<p>Anytime was eager to get the load out of its warehouse and to be paid for nearly two weeks of storage.</p>
<p>It turned out that the KitKats had never left California. They had simply been driven about 50km east, put on ice and left to rack up storage fees.</p>
<p>“We would like to know when you are going to get this picked up,” Anytime wrote, “as we anticipated this to be a short-term storage request.”</p>
</div>

    <div>
<p>The outstanding balance for the storage was US$3,830. Mr Black said he paid US$2,000 of that out of his own pocket to secure the release of the freight, with the promise to pay the rest later. Anytime did not respond to repeated requests for comment from NYTimes.</p>
<p>Daunted but determined, he started the process over, posting the job again on the freight board. This time he said he got a bite from ‘Manny’ from MVK Transport.</p>
<p>According to Mr Black, Manny had the KitKats picked up. At least this half of the shipment was on its way to New Jersey, Mr Black believed. After a few days, though, communications turned spotty.</p>
<p>“I’ve been writing you for days now,” Mr Black e-mailed a few days later. “I called yesterday and you hung up and now your phone says it’s out of service.”</p>
<p>The next morning, he followed up, now furious: “How do you make money on this??? Are you going to sell KitKats on the corner???”</p>
<p>He had been had again. This time, the KitKats had disappeared for good into the expanse of Southern California’s freewayland. Requests for comment sent to MVK went unanswered.</p>
<h2>‘We cannot release the freight’</h2>
</div>

    <div>
<p>Inland Cold Empire Storage, at least, still had the other half of the KitKats, and Mr Black, by now frantic to salvage what he could of the candy, was still on the case.</p>
<p>“This load was stolen from us, and placed in your storage facility,” he wrote to Inland on Aug 21. Inland replied that its contract was with a man named Harry Centa.</p>
<p>“There is no ‘Harry’,” Mr Black explained. Bokksu, cc’ed on the e-mail, was the rightful owner. “‘Harry’ is a fictitious name.”</p>
<p>Harry Centa, however, is not a fictitious name. Mr Harry Centa lives in Ohio, and works in shipping. But the entire KitKat affair was news to him. “This is totally fraudulent and not me,” Mr Centa said in an e-mail to the NYTimes. “Good luck and hope they find the KitKats LOL.”</p>
<p>Nevertheless, Inland was unmoved: “Without proof that you are the rightful owner and payment for storage we cannot release the freight.”</p>
<p>Mr Black said he reached out to the sheriff’s departments of Riverside and San Bernardino counties, but said he was told<strong> </strong>jurisdictional issues kept them from getting involved, and no reports were filed.</p>
<p>He also turned to the team at Bokksu. Did they have anything that he could use to prove their ownership?</p>
<p>But Bokksu had essentially fired Mr Black in the meantime, stopped payment on his fee, filed a report with the Los Angeles County Sheriff’s Department for insurance purposes, and decided to move on. The KitKats were dead to them.</p>
</div>

    <div>
<p>“I don’t know if I would be comfortable selling these to customers,” said Mr Taing, Bokksu’s founder. “What if something actually happens to customers that eat this, and we get sued?”</p>
<p>Meanwhile, the KitKats are still at Inland, according to the company’s chief executive officer Kevin Sacalas.</p>
<p>“We have no use for this product and would happily release it to anyone who would show proof of proper ownership and pay the storage fees,” Mr Sacalas wrote in an e-mail to NYTimes.</p>
</div>

  
  <div>
<h2>Chess v checkers</h2>
<p>The Bokksu KitKats are just one instance of an increasingly common computer-based form of fraud that some experts call “fictitious pickups” or “strategic theft”. It is part identity theft, part extortion. The freight, sometimes called a “hostage load”, can vanish if the extortion demands are not met.</p>
<p>“The more you unpeel the onion, the worse it gets,” said Mr Keith Lewis, vice-president of operations at CargoNet, which is part of the global data analytics and technology provider Verisk. He said that strategic cargo theft is up 700 per cent in 2023.</p>
<p>“The supply chain is moving at the speed of light,” he said, adding: “The bad guys are playing chess and we’re playing checkers. We’re two or three steps behind them.”</p>
<p>As for Bokksu, its insurance claim has been denied. So the blame is now flowing backward along that supply chain.</p>
<p>Bokksu holds Mr Black responsible. He fell for an obvious scam, they said, and the Gmail addresses should have been a red flag.</p>
<p>Mr Black said truckers do not always use company domains. Ultimately, he blames Japan Crate Acquisition, which originally released the KitKats to ‘Tristan’.</p>
<p>“Obviously it didn’t go to an HCH truck,” Mr Black said, and whoever loaded the shipment “should’ve been suspicious.”</p>
<p>In possibly the strangest twist on the KitKat trail, Bokksu announced in September that it had acquired Japan Crate. But NYTimes discovered that the acquisition had actually been completed back in June. So Bokksu, through a wholly owned subsidiary, had in effect overseen the loading of its own KitKats onto the original two fraudulent trucks.</p>
<p>“I’ve been doing this for over two decades now, and I’ve never come across anything like this, anything of this magnitude,” Mr Black said. “It’s beyond crazy, it really is. Because there’s no answers.”</p>
<p>“I do feel cheated,” he added. “I just don’t know who is doing the cheating.” NYTIMES</p>
</div>

  


</div>

            
      
    </div>



                </section>
              </main>
                                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft pulls OneDrive update that would quiz you before letting you quit (114 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/</link>
            <guid>38224435</guid>
            <pubDate>Fri, 10 Nov 2023 20:58:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/">https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/</a>, See on <a href="https://news.ycombinator.com/item?id=38224435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      wish i knew how to quit you    —
</h4>
            
            <h2 itemprop="description">Change affected a "small subset" of users and has (thankfully) been reverted.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/neowin-onedrive-800x450.jpg" alt="Microsoft briefly tested a drop-down survey that you would need to fill out before you could quit the OneDrive app.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/neowin-onedrive.jpg" data-height="720" data-width="1280">Enlarge</a> <span>/</span> Microsoft briefly tested a drop-down survey that you would need to fill out before you could quit the OneDrive app.</p></figcaption>  </figure>

  




<!-- cache hit 127:single/related:15fc7c8fc96caed1d16d965b9ba42d94 --><!-- empty -->
<p>Modern versions of Windows <a href="https://arstechnica.com/gadgets/2023/08/windows-11-has-made-the-clean-windows-install-an-oxymoron/">have become more annoying</a> as time has gone on, pushing additional Microsoft products and services on users who are just trying to turn on their computers and get something done. Often, as we've covered, these notifications and reminders ignore or actively push back against user intent—prompting you to sign up for Microsoft 365 if you already said no, or trying to make you use Edge or Bing after you've already installed Chrome.</p>

<p>Microsoft took another step down this path this week when it began testing a new addition to the Windows OneDrive app that would force users to explain themselves when quitting the app. <a href="https://www.neowin.net/news/microsoft-wont-let-you-close-onedrive-in-windows-without-you-explaining-it-first/">Initially spotted by NeoWin</a>, the survey took the form of a drop-down menu, not unlike the ones you sometimes see when you try to unsubscribe from marketing or fundraising mailing lists.</p>
<p>Until you chose an answer from the drop-down, the "quit" button would be grayed out, preventing you from actually closing OneDrive.</p>
<p>This was an escalation from the previous behavior, which would ask you if you were sure before allowing you to quit but allowing you to actually click the "quit" button without interacting with any other menus. The old prompt was an explanation; the newer one was an imposition.</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old.jpeg" data-height="800" data-width="1280" alt="The former (and current) prompt was more informational and would allow you to click the quit button without further interaction."><img alt="The former (and current) prompt was more informational and would allow you to click the quit button without further interaction." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old-980x613.jpeg" width="980" height="613"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old.jpeg" data-height="800" data-width="1280">Enlarge</a> <span>/</span> The former (and current) prompt was more informational and would allow you to click the quit button without further interaction.</p><p>Andrew Cunningham</p></figcaption></figure>
<p>For its part, Microsoft <a href="https://www.theverge.com/2023/11/8/23952878/microsoft-onedrive-windows-close-app-notification">told The Verge</a> that the new prompt was a test that was only rolled out to a subset of OneDrive users and that the change has been reverted as of a couple of days ago.</p>
<p>"Between Nov. 1 and 8, a small subset of consumer OneDrive users were presented with a dialog box when closing the OneDrive sync client, asking for feedback on the reason they chose to close the application," reads Microsoft's statement. "This type of user feedback helps inform our ongoing efforts to enhance the quality of our products."</p>
<p>Reverted or not, the OneDrive prompt is of a piece with other things Microsoft does to encourage the usage of Edge, Bing, OneDrive, Microsoft 365, Game Pass, and its other services in Windows. You can always choose to avoid this kind of thing by declining to sign in to OneDrive or by uninstalling the app entirely. But it's just one more annoying default you need to change to make sure that modern Windows stays out of your way.</p>

        <p><em>Listing image by Microsoft</em></p>
                                                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon gives Apple 'massive preferential treatment' in secret deal report claims (120 pts)]]></title>
            <link>https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/</link>
            <guid>38224217</guid>
            <pubDate>Fri, 10 Nov 2023 20:39:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/">https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/</a>, See on <a href="https://news.ycombinator.com/item?id=38224217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?quality=82&amp;strip=all&amp;w=1600" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1600" height="900" alt="apple amazon lawsuit" fetchpriority="high">
	
	</figure>

<p>Apple and Amazon are once again facing scrutiny for their 2018 agreement that saw Apple finally establish an <a href="https://amzn.to/3sm9MUy">official Amazon storefront</a>. A report <a href="https://www.businessinsider.com/amazon-gives-apple-special-treatment-while-others-suffer-junk-ads-2023-11">from <em>Insider</em> today</a> goes in-depth on the details of this agreement, with one source saying that Apple is getting “massive preferential treatment” from Amazon.</p>



<p>The deal between Apple and Amazon has <a href="https://9to5mac.com/2019/08/02/apple-amazon/">faced quite a bit</a> of regulatory pushback over the <a href="https://9to5mac.com/2020/10/29/apple-amazon-deal-germany/">past several years</a>. The two companies are also <a href="https://9to5mac.com/2022/11/09/apple-amazon-lawsuit-price-fixing/">battling a price-fixing lawsuit</a> that alleges they colluded to raise iPhone and iPad prices.</p>



<p>As detailed by today’s report, the agreement between Apple and Amazon includes a carveout that reduces the number of ads and recommendations that appear on product pages for Apple devices. While Amazon product pages are generally full of ads, sponsored results, and recommendations, Apple’s product pages show only one banner ad at the very bottom of the page.</p>



<p>In contrast, product pages for Apple competitors like Samsung are riddled with ads from competitors, recommendations, and other sponsored banners. <em>Insider</em> says that other companies, including Samsung, have complained about the preferential treatment given to Apple.</p>



<p>It’s unclear whether Amazon has made similar offers to companies like Samsung. <em>Insider</em> cites “least half a dozen salespeople on Amazon’s advertising team” who say that “they were not able to extend this Apple-style special treatment to their clients.”</p>



<p>Emails revealed as part of an FTC lawsuit against Amazon reveal that the company initially pushed back against Apple’s demands for special treatment before eventually caving in. In a statement today, Apple explained:</p>



<blockquote>
<p>Apple also told Insider that the 2018 agreement with Amazon “sought to address significant counterfeit and safety issues” on Amazon’s marketplace. Prior to the deal, Apple sent “hundreds of thousands of take-down notices” to Amazon to reduce counterfeits, and the company conducted test purchases on Amazon that “consistently returned high counterfeit rates,” Apple added.</p>



<p>By providing “accurate, relevant and qualitative content on Apple Product pages,” Apple has been able to address much of the counterfeit issues on Amazon, the iPhone maker said.</p>



<p>“The 2018 Agreements significantly reduced the sale of counterfeit and unsafe Apple products on Amazon’s marketplaces and have materially improved customer experience,” Apple also wrote in a statement to Insider.</p>
</blockquote>



<p>The <a href="https://www.businessinsider.com/amazon-gives-apple-special-treatment-while-others-suffer-junk-ads-2023-11">full report at <em>Insider</em></a> includes additional details on the early negotiations between Apple and Amazon. For instance, at one point, Amazon insisted that Apple “compensate Amazon for the lost ad revenue” from the deal. Still, it’s unclear if that was included in the final agreement.</p>



<p><strong>Follow Chance</strong>:&nbsp;<a href="https://www.threads.net/@ChanceHMiller">Threads</a>,&nbsp;<a href="https://twitter.com/chancehmiller">Twitter</a>,&nbsp;<a href="https://www.instagram.com/chancehmiller/">Instagram</a>, and&nbsp;<a href="https://mastodon.social/@ChanceHMiller">Mastodon</a>.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/3shtH6M"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2023/10/integration_1.webp" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rare egg-laying mammal (echidna) rediscovered in Indonesia (120 pts)]]></title>
            <link>https://www.cbc.ca/news/science/echidna-video-1.7024966</link>
            <guid>38223660</guid>
            <pubDate>Fri, 10 Nov 2023 19:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/science/echidna-video-1.7024966">https://www.cbc.ca/news/science/echidna-video-1.7024966</a>, See on <a href="https://news.ycombinator.com/item?id=38223660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Scientists have rediscovered a long-lost species of mammal described as having the spines of a hedgehog, the snout of an anteater and the feet of a mole, in Indonesia's Cyclops Mountains more than 60 years after it was last recorded.</p><p>Attenborough's long-beaked echidna, named after British naturalist David Attenborough, was photographed for the first time by a trail camera on the last day of a four-week expedition led by Oxford University scientists.</p><p>Having descended from the mountains at the end of the trip, biologist James Kempton found the images of the small creature walking through the forest undergrowth on the last memory card retrieved from more than 80 remote cameras.</p><p>"There was a great sense of euphoria, and also relief having spent so long in the field with no reward until the very final day," he said, describing the moment he first saw the footage with collaborators from Indonesian conservation group YAPPENDA.</p><p>"I shouted out to my colleagues that were still remainin g... and said 'we found it, we found it' —&nbsp;I ran in from my desk to the living room and hugged the guys."</p><p>Echidnas share their name with a half-woman, half-serpent Greek mythological creature, and were described by the team as shy, nocturnal burrow-dwellers who are notoriously difficult to find.</p><p>"The reason it appears so unlike other mammals is because it is a member of the monotremes —&nbsp;an egg-laying group that separated from the rest of the mammal tree-of-life about 200 million years ago," Kempton said.</p><h2>Species only recorded once before</h2><p>The species has only been scientifically recorded once before, by a Dutch botanist in 1961. A different echidna species is found throughout Australia and lowland New Guinea.</p><div><ul><li><a href="https://www.cbc.ca/news/science/chevrotain-rediscovered-1.5356202" text="Rare, fanged deer-like species rediscovered after 30 years" flag="" data-contentid=""><span>Rare, fanged deer-like species rediscovered after 30 years</span></a></li></ul><ul><li><a href="https://www.cbc.ca/news/science/mammal-believed-extinct-found-in-mossy-forest-1.758476" text="Mammal believed extinct found in mossy forest" flag="" data-contentid=""><span>Mammal believed extinct found in mossy forest</span></a></li></ul></div><p>Kempton's team survived an earthquake, malaria and even a leech attached to an eyeball during their trip. They worked with the local village Yongsu Sapari to navigate and explore the remote terrain of northeastern Papua.</p><p>The echidna is embedded in the local culture, including a tradition that states conflicts are resolved by sending one party to a disagreement into the forest to search for the mammal and another to the ocean to find a marlin, according to Yongsu Sapari elders cited by the university.</p><p>Both creatures were seen as so difficult to find that it would often take decades or a generation to locate them. But&nbsp;once found, the animals symbolized the end of the conflict and a return to harmonious relationships.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unix timestamp will begin with 17 this Tuesday (172 pts)]]></title>
            <link>https://www.unixtimestamp.com/</link>
            <guid>38222909</guid>
            <pubDate>Fri, 10 Nov 2023 18:54:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unixtimestamp.com/">https://www.unixtimestamp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38222909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <h2>What is the unix time stamp?</h2>
    <p>The unix time stamp is a way to track time as a running total of seconds. This count starts at the Unix Epoch on January 1st, 1970 at UTC. Therefore, the unix time stamp is merely the number of seconds between a particular date and the Unix Epoch. It should also be pointed out (thanks to the comments from visitors to this site) that this point in time technically does not change no matter where you are located on the globe.  This is very useful to computer systems for tracking and sorting dated information in dynamic and distributed applications both online and client side.</p>

<table>
<thead>
<tr>
	<th>Human Readable Time</th>
	<th>Seconds</th>
</tr>
</thead>
<tbody>
<tr>
	<td>1 Hour</td>
	<td>3600 Seconds</td>
</tr>
<tr>
	<td>1 Day</td>
	<td>86400 Seconds</td>
</tr>
<tr>
	<td>1 Week</td>
	<td>604800 Seconds</td>
</tr>
<tr>
	<td>1 Month (30.44 days)</td>
	<td>2629743 Seconds</td>
</tr>
<tr>
	<td>1 Year (365.24 days)</td>
	<td>31556926 Seconds</td>
</tr>
</tbody>
</table>

  <h2>What happens on January 19, 2038?</h2>
    <p>On this date the Unix Time Stamp will cease to work due to a 32-bit overflow. Before this moment millions of applications will need to either adopt a new convention for time stamps or be migrated to 64-bit systems which will buy the time stamp a "bit" more time. </p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git cherry-pick and revert use 3-way merge (162 pts)]]></title>
            <link>https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/</link>
            <guid>38222596</guid>
            <pubDate>Fri, 10 Nov 2023 18:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/">https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/</a>, See on <a href="https://news.ycombinator.com/item?id=38222596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! I was trying to explain to someone how <code>git cherry-pick</code> works the other
day, and I found myself getting confused.</p>

<p>What went wrong was: I thought that <code>git cherry-pick</code> was basically applying a
patch, but when I tried to actually do it that way, it didn’t work!</p>

<p>Let’s talk about what I thought <code>cherry-pick</code> did (applying a patch), why
that’s not quite true, and what it actually does instead (a “3-way merge”).</p>

<p>This post is extremely in the weeds and you definitely don’t need to understand
this stuff to use git effectively. But if you (like me) are curious about git’s
internals, let’s talk about it!</p>

<h3 id="cherry-pick-isn-t-applying-a-patch">cherry-pick isn’t applying a patch</h3>

<p>The way I previously understood <code>git cherry-pick COMMIT_ID</code> is:</p>

<ul>
<li>calculate the diff for <code>COMMIT_ID</code>, like <code>git show COMMIT_ID --patch &gt; out.patch</code></li>
<li>Apply the patch to the current branch, like <code>git apply out.patch</code></li>
</ul>

<p>Before we get into this – I want to be clear that this model is mostly
right, and if that’s your mental model that’s fine. But it’s wrong in some
subtle ways and I think that’s kind of interesting, so let’s see how it works.</p>

<p>If I try to do the “calculate the diff and apply the patch” thing in a case
where there’s a merge conflict, here’s what happens:</p>

<pre><code>$ git show 10e96e46 --patch &gt; out.patch
$ git apply out.patch
error: patch failed: content/post/2023-07-28-why-is-dns-still-hard-to-learn-.markdown:17
error: content/post/2023-07-28-why-is-dns-still-hard-to-learn-.markdown: patch does not apply
</code></pre>

<p>This just fails – it doesn’t give me any way to resolve the conflict or figure
out how to solve the problem.</p>

<p>This is quite different from what actually happens when run <code>git cherry-pick</code>,
which is that I get a merge conflict:</p>

<pre><code>$ git cherry-pick 10e96e46
error: could not apply 10e96e46... wip
hint: After resolving the conflicts, mark them with
hint: "git add/rm &lt;pathspec&gt;", then run
hint: "git cherry-pick --continue".
</code></pre>

<p>So it seems like the “git is applying a patch” model isn’t quite right. But the
error message literally does say “could not <strong>apply</strong> 10e96e46”, so it’s not quite
<em>wrong</em> either. What’s going on?</p>

<h3 id="so-what-is-cherry-pick-doing">so what is cherry-pick doing?</h3>

<p>I went digging through git’s source code to see how <code>cherry-pick</code> works, and
ended up at <a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/sequencer.c#L2353-L2358">this line of code</a>:</p>

<pre><code>res = do_recursive_merge(r, base, next, base_label, next_label, &amp;head, &amp;msgbuf, opts);
</code></pre>

<p>So a cherry-pick is a… merge? What? How? What is it even merging? And how does merging even work in the first place?</p>

<p>I realized that I didn’t really know how git’s merge worked, so I googled it
and found out that git does a thing called “3-way merge”. What’s that?</p>

<h3 id="how-git-merges-files-the-3-way-merge">how git merges files: the 3-way merge</h3>

<p>Let’s say I want to merge these 2 files. We’ll call them <code>v1.py</code> and <code>v2.py</code>.</p>

<pre><code>def greet():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<pre><code>def say_hello():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name
</code></pre>

<p>There are two lines that differ: we have</p>

<ul>
<li><code>def greet()</code> and <code>def say_hello</code></li>
<li><code>name = "aanya"</code> and <code>name = "julia"</code></li>
</ul>

<p>How do we know what to pick? It seems impossible!</p>

<p>But what if I told you that the original function was this (<code>base.py</code>)?</p>

<pre><code>def say_hello():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<p>Suddenly it seems a lot clearer! <code>v1</code> changed the function’s name to <code>greet</code>
and <code>v2</code> set <code>name = "aanya"</code>. So to merge, we should make both those changes:</p>

<pre><code>def greet():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name
</code></pre>

<p>We can ask git to do this merge with <code>git merge-file</code>, and it gives us exactly
the result we expected: it picks <code>def greet()</code> and <code>name = "aanya"</code>.</p>

<pre><code>$ git merge-file v1.py base.py v2.py -p
def greet():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name⏎
</code></pre>

<p>This way of merging where you merge 2 files + their original version is called
a <strong>3-way merge</strong>.</p>

<p>If you want to try it out yourself in a browser, I made a little playground at
<a href="https://jvns.ca/3-way-merge/">jvns.ca/3-way-merge/</a>. I made it very quickly so it’s not mobile friendly.</p>

<h3 id="git-merges-changes-not-files">git merges changes, not files</h3>

<p>The way I think about the 3-way merge is – git merges <strong>changes</strong>, not files.
We have an original file and 2 possible changes to it, and git tries to combine
both of those changes in a reasonable way. Sometimes it can’t (for example if
both changes change the same line), and then you get a merge conflict.</p>

<p>Git can also merge more than 2 possible changes: you can have an original file
and 8 possible changes, and it can try to reconcile all of them. That’s called
an octopus merge but I don’t know much more than that, I’ve never done one.</p>

<h3 id="how-git-uses-3-way-merge-to-apply-a-patch">how git uses 3-way merge to apply a patch</h3>

<p>Now let’s get a little weird! When we talk about git “applying a patch” (as you
do in a <code>rebase</code> or <code>revert</code> or <code>cherry-pick</code>), it’s not actually creating a
patch file and applying it. Instead, it’s doing a 3-way merge.</p>

<p>Here’s how applying commit <code>X</code> as a patch to your current commit corresponds to
this <code>v1</code>, <code>v2</code>, and <code>base</code> setup from before:</p>

<ol>
<li>The version of the file <strong>in your current commit</strong> is <code>v1</code>.</li>
<li>The version of the file <strong>before commit X</strong> is <code>base</code></li>
<li>The version of the file <strong>in commit X</strong>. Call that <code>v2</code></li>
<li>Run <code>git merge-file v1 base v2</code> to combine them (technically git does not
actually run <code>git merge-file</code>, it runs a C function that does it)</li>
</ol>

<p>Together, you can think of <code>base</code> and <code>v2</code> as being the “patch”: the diff between
them is the change that you want to apply to <code>v1</code>.</p>

<h3 id="how-cherry-pick-works">how cherry-pick works</h3>

<p>Let’s say we have this commit graph, and we want to cherry-pick <code>Y</code> on to <code>main</code>:</p>

<pre><code>A - B (main)
 \
  \
   X - Y - Z
</code></pre>

<p>How do we turn that into a 3-way merge? Here’s how it translates into our <code>v1</code>, <code>v2</code> and <code>base</code> from earlier:</p>

<ul>
<li><code>B</code> is v1</li>
<li><code>X</code> is the base, <code>Y</code> is v2</li>
</ul>

<p>So together <code>X</code> and <code>Y</code> are the “patch”.</p>

<p>And <code>git rebase</code> is just like <code>git cherry-pick</code>, but repeated a bunch of times.</p>

<h3 id="how-revert-works">how revert works</h3>

<p>Now let’s say we want to run <code>git revert Y</code> on this commit graph</p>

<pre><code>X - Y - Z - A - B
</code></pre>

<ul>
<li><code>B</code> is v1</li>
<li><code>Y</code> is the base, <code>X</code> is v2</li>
</ul>

<p>This is exactly like a cherry-pick, but with <code>X</code> and <code>Y</code> reversed. We have to
flip them because we want to apply a “reverse patch”.</p>

<p>Revert and cherry-pick are so closely related in git that they’re actually
implemented in the same file:
<a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/builtin/revert.c">revert.c</a>.</p>

<h3 id="this-3-way-patch-is-a-really-cool-trick">this “3-way patch” is a really cool trick</h3>

<p>This trick of using a 3-way merge to apply a commit as a patch seems really
clever and cool and I’m surprised that I’d never heard of it before! I don’t
know of a name for it, but I kind of want to call it a “3-way patch”.</p>

<p>The idea is that with a 3-way patch, you specify the patch as 2 files: the file
before the patch and after (<code>base</code> and <code>v2</code> in our language in this post).</p>

<p>So there are 3 files involved: 1 for the original and 2 for the patch.</p>

<p>The point is that the 3-way patch is a much better way to patch than a normal
patch, because you have a lot more context for merging when you have
both full files.</p>

<p>Here’s more or less what a normal patch for our example looks like:</p>

<pre><code>@@ -1,1 +1,1 @@:
- def greet():
+ def say_hello():
    greeting = "hello"
</code></pre>

<p>and a 3-way patch. This “3-way patch” is not a real file format, it’s just
something I made up.</p>

<pre><code>BEFORE: (the full file)
def greet():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
AFTER: (the full file)
def say_hello():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<h3 id="building-git-talks-about-this">“Building Git” talks about this</h3>

<p>The book <a href="https://shop.jcoglan.com/building-git/">Building Git</a> by James Coglan
is the only place I could find other than the git source code explaining how
<code>git cherry-pick</code> actually uses 3-way merge under the hood (I thought Pro Git might
talk about it, but it didn’t seem to as far as I could tell).</p>

<p>I actually went to buy it and it turned out that I’d already bought it in 2019
so it was a good reference to have here :)</p>

<h3 id="merging-is-actually-much-more-complicated-than-this">merging is actually much more complicated than this</h3>

<p>There’s more to merging in git than the 3-way merge – there’s something
called a “recursive merge” that I don’t understand, and there are a bunch of
details about how to deal with handling file deletions and moves, and there are
also multiple merge algorithms.</p>

<p>My best idea for where to learn more about this stuff is Building Git, though I
haven’t read the whole thing.</p>

<h3 id="so-what-does-git-apply-do">so what does <code>git apply</code> do?</h3>

<p>I also went looking through git’s source to find out what <code>git apply</code> does, and it
seems to (unsurprisingly) be in <code>apply.c</code>. That code parses a patch file, and
then hunts through the target file to figure out where to apply it. The core logic
seems to be <a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/apply.c#L2684">around here</a>:
I think the idea is to start at the line number that the patch suggested and
then hunt forwards and backwards from there to try to find it:</p>

<pre><code>	/*
	 * There's probably some smart way to do this, but I'll leave
	 * that to the smart and beautiful people. I'm simple and stupid.
	 */
	backwards = current;
	backwards_lno = line;
	forwards = current;
	forwards_lno = line;
	current_lno = line;
  for (i = 0; ; i++) {
     ...
</code></pre>

<p>That all seems pretty intuitive and about what I’d naively expect.</p>

<h3 id="that-s-all">that’s all!</h3>

<p>I was pretty surprised to learn that I didn’t actually understand the core way
that git applies patches internally – it was really cool to learn about!</p>

<p>I have <a href="https://jvns.ca/blog/2023/11/01/confusing-git-terminology/">lots of issues</a> with git’s UI but I think this particular thing is not
one of them. The 3-way merge seems like a nice unified way to solve a bunch of
different problems, it’s pretty intuitive for people (the idea of “applying a
patch” is one that a lot of programmers are used to thinking about, and the
fact that it’s implemented as a 3-way merge under the hood is an implementation
detail that nobody actually ever needs to think about).</p>

<p><small>
Also a very quick plug: I’m working on writing a
<a href="https://wizardzines.com/">zine</a> about git, if you’re interested in getting an email when it comes out you can
sign up to my <a href="https://wizardzines.com/zine-announcements/">very infrequent announcements mailing list</a>.
</small></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Build AI Products the Way Everyone Else Is Doing It (320 pts)]]></title>
            <link>https://www.builder.io/blog/build-ai</link>
            <guid>38221552</guid>
            <pubDate>Fri, 10 Nov 2023 17:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.builder.io/blog/build-ai">https://www.builder.io/blog/build-ai</a>, See on <a href="https://news.ycombinator.com/item?id=38221552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div builder-type="blocks" data-builder-component="blog-article" data-builder-content-id="525874563ff643cab87e1e24b64b631b" builder-content-id="525874563ff643cab87e1e24b64b631b" builder-model="blog-article" data-name="blog-article" data-source="Rendered by Builder.io"><p><span><p>If you want to build AI products that are unique, valuable, and fast, don't do what everybody else is doing. I'll show you what to do instead.</p></span></p><p builder-id="builder-981e3200fea5451e914944395327b5ae"><a href="#what-not-to-do" id="what-not-to-do"><span><h3>What not to do</h3></span></a></p><p><span><p>The vast majority of AI products being built right now are just wrappers over other models, such as those that essentially involve calling ChatGPT over an API.</p></span></p><div builder-id="builder-ee917abbd620463f8d65a32f297d7beb"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram of code that simply hits OpenAI and does nothing else" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>While that's incredibly easy — you send natural language in and get natural language out — and it can do some really cool things, there are some major problems with this approach that people are running into.</p><p>But, there's a solution for them that I'll show you.</p></span></p><p builder-id="builder-d6ed2738276a4f76b7633d2b18710a42"><a href="#issue-1-lack-of-differentiation" id="issue-1-lack-of-differentiation"><span><h3>Issue #1: lack of differentiation</h3></span></a></p><p><span><p>The first major issue is this is not differentiated technology.</p><p>If you've noticed that one person creates a chat with a PDF app, and then another dozen people do too, and then OpenAI builds that into ChatGPT directly, it's because nobody there actually built something differentiated.</p><p>They use a simple technique, with a pre-trained model, which anyone can copy in a very short period of time.</p><p>When building a product whose unique value proposition is some type of advanced AI technology, it's a very risky position to be so easy to copy.</p><p>Now, of course, there's a whole spectrum here.</p></span></p><div builder-id="builder-0863de009fc34a1286aaed4e81a28324"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=503 503w" type="image/webp"><img alt="Sliding scale with &quot;chatgpt did all the work&quot; on the right and &quot;chatgpt did a bit of work&quot; on the left" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>If you're on the right side of the spectrum, where all you made was a button that sends something to ChatGPT and gets a response back that you showed your end users — where ChatGPT basically did all the work —you're at the highest risk here.</p><p>On the other end, if you actually built some substantial technology and LLMs where OpenAI has only assisted with a small but crucial piece, then you may be in a better position, but you're still going to run into two other major issues.</p></span></p><p builder-id="builder-06838a9809ca4e5da934bb9e4af517a8"><a href="#issue-2-ll-ms-are-very-expensive" id="issue-2-ll-ms-are-very-expensive"><span><h3>Issue #2: LLMs are very expensive</h3></span></a></p><p><span><p>The first major issue you'll run into is cost. The best part of a large language model is their broad versatility, but they achieve this by being exceptionally large and complex, which makes them incredibly costly to run.</p><p>As an example, per the Wall Street Journal, recently GitHub Copilot was <a href="https://www.wsj.com/tech/ai/ais-costly-buildup-could-make-early-products-a-hard-sell-bdd29b9f" rel="noopener noreferrer" target="_blank">losing money per user</a>, charging $10, but on average cost $20, and some users cost GitHub up to $80 <span><span><em>per month</em></span></span>.</p><p>And the worst part is you probably don't need such a large model. Your use case probably doesn't need a model trained on the entirety of the Internet because 99.9% of that training covers topics that have nothing to do with your use case.</p><p>So, while the ease of this approach might be tempting, you could run into this common issue where what your users want to pay is less than what it costs to run your service on top of large language models.</p></span></p><p builder-id="builder-51387a2017d64e1ba34cee8b2d0577fd"><a href="#issue-3-ll-ms-are-painfully-slow" id="issue-3-ll-ms-are-painfully-slow"><span><h3>Issue #3: LLMs are painfully slow</h3></span></a></p><p><span><p>Even if you're the rare case where the cost economics might work out okay for you, you're still going to hit one more major issue: LLMs are painfully slow.</p><p>Now, this isn't a huge problem for all applications. For use cases such as ChatGPT, where reading one word at a time is the norm, this might be okay.</p></span></p><p><span><p><span>However, in applications where text isn't meant to be read word-for-word, and the entire response is expected before proceeding to the next step in the workflow, this can pose a significant issue.</span><br></p><p>As an example, when we started working on Builder's <a href="https://www.builder.io/blog/figma-to-code-visual-copilot" rel="noopener noreferrer" target="_blank">Visual Copilot</a>, where we wanted one button click to turn any design into high-quality code, one of the approaches we explored was using an LLM for the conversion.</p></span></p><p><span><p><span>One of the key issues we encountered was the significant time delay. When passing an entire design specification into an LLM and receiving a new representation token by token, generating a response would take several minutes, making it impractical.</span><br></p><p>And because the representation returned by the LLM is not what a human would perceive, the loading state was just a spinner — not ideal.</p></span></p><p builder-id="builder-8b2942d781514858b7c538ba5b6fa773"><a href="#issue-4-ll-ms-cannot-be-customized-strong-that-strong-much" id="issue-4-ll-ms-cannot-be-customized-strong-that-strong-much"><span><h3>Issue #4: LLMs cannot be customized <strong>that</strong> much</h3></span></a></p><p><span><p>If for some reason, performance still isn't an issue for you, and your users don't care about having a slow and expensive product that's easy for your competitors to copy, you're still likely to run into another major issue — LLMs can't be customized that much.</p><p>Yes, they all support fine-tuning, and fine-tuning can incrementally help the model get closer to what you need. But in our case, we tried using fine-tuning to provide Figma designs and get code out the other side.</p><p>But no matter how many examples we gave the model, it didn't improve. We were left with something slow, expensive, and inferior quality. And that's when we realized we had to take a different approach.</p></span></p><p builder-id="builder-88d0ae6c15e04a0280eafb3a98df99e3"><a href="#the-solution-create-your-own-toolchain" id="the-solution-create-your-own-toolchain"><span><h2>The solution: create your own toolchain</h2></span></a></p><p><span><p>What did we have to do instead? We had to create our own toolchain.</p></span></p><div builder-id="builder-7fb58077a7a74b12964f2b8986b186f0"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing our toolchain that involves a custom built AI, a fine-tuned LLM, and our Mitosis compiler" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>In this case, we combined a fine-tuned LLM, a <a href="https://github.com/builderio/mitosis" rel="noopener noreferrer" target="_blank">custom compiler</a> that we wrote, and a custom-trained model.</p><p>And it wasn't as hard as it might seem.These days, you don't have to be a data scientist or a Ph.D. in machine learning to train your own model.</p><p>Any moderately experienced developer can do it. This way, you can build something that is way faster, way more reliable, far cheaper, and far more differentiated. You won't have to worry about copycat products or open-source clones spawning overnight, either.</p><p>And this isn't just a theory. Most, if not all, advanced AI products are built like this.</p></span></p><p builder-id="builder-c13376088c4243629cdcfefa9386b37f"><a href="#a-common-misconception-about-ai-products" id="a-common-misconception-about-ai-products"><span><h3>A common misconception about AI products</h3></span></a></p><p><span><p>A lot of people have a major misconception about how AI products are built. I've noticed that they often think that all the core tech is handled by one super smart model,  trained with tons of inputs to give exactly the right output.</p></span></p><div builder-id="builder-0c51c5144a11487fb9a0bd52f209565c"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram with one big model that has just a single stream of inputs and outputs" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>Take self-driving cars, for example. A lot of people have the impression that there's a giant model that takes in all these different inputs like cameras, sensors, GPS, and so on, and that it crunches it through the AI, and then out comes the action on the other side, such as a right turn.</p></span></p><div builder-id="builder-0653ffed833647328a5744a9758b8086"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing &quot;Autonomous Vehicle Model&quot; with several inputs and one output &quot;turn right&quot;" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>But this could not be farther from the truth.That car driving itself is not one big AI brain.</p><p>Instead of a whole toolchain of specialized models, all connected with normal code — such as models for computer vision to find and identify objects, predictive decision-making, anticipating the actions of others, or natural language processing for understanding voice commands — all of these specialized models are combined with tons of just normal code and logic that creates the end result — a car that can drive itself.</p></span></p><div builder-id="builder-db06450b64ef405ab655af9f87ccc976"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing normal code connecting everal different types of models" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>Now, keep in mind, autonomous vehicles is a highly complex example that includes many more models than I've mentioned here.</p><p>For building your own product, you won't need something nearly this complex, especially when starting out.</p><p>Remember, self-driving cars didn't spawn overnight. My 2018 Prius is capable of parking itself, stopping automatically when too close to an object, and many other things using little to no AI.</p><p>Over time, more and more layers were added to cars to do more and more advanced things, like correcting lane departure, or eventually making entire decisions to drive from one place to another.</p><p>But like all software, these things are built in layers, one on top of the next.</p></span></p><p builder-id="builder-917d1c0b6c18458197f7f9cf234d9f5b"><a href="#where-to-start-building-real-ai" id="where-to-start-building-real-ai"><span><h3>Where to start building real AI</h3></span></a></p><p><span><p>I highly recommend you explore the approach we used for Visual Copilot for your own AI solutions. It's a straightforward but counterintuitive approach.</p><p>The most important thing is to not use AI at first.</p><p>Explore the problem space using normal programming practices to determine what areas need a specialized model in the first place.</p><p>Remember, making “supermodels” is generally not the right approach. We don't want to send tons of Figma data into a model and get finished code out the other side.</p><p>That would be an outrageously complex problem to solve with just one model. And when you factor in all the different frameworks we support, and styling options and customizations, it would be unfeasible to retrain this model with all this additional data.</p></span></p><p><span><p><span>It likely would have become so complex, slow, and expensive that our product might never have even shipped.</span><br></p><p>Instead, we considered the problem and said, well, how can we solve this without AI? How far can we get before it gets impossible without the types of specialized decision-making AI is best at?</p><p>So we broke the problem down and said, okay, we need to convert each of these nodes to things we can represent in code.</p><p>We needed to understand, in detail, working with elements such as images, backgrounds, and foregrounds. And most importantly, we needed to intricately understand how to make any input responsive.</p><p>After that, we started considering more complex examples and realized there are lots of cases where many, many layers would need to be turned into one image.</p></span></p><p builder-id="builder-10e3c9ac5da441f780cefc684e17f111"><a href="#hand-code-the-logic-first" id="hand-code-the-logic-first"><span><h3>Hand-code the logic first</h3></span></a></p><p><span><p>We started writing hand-coded logic to say if a set of items is in a vertical stack that should probably be a flex column, and items that are side by side should probably be a flex row.</p><p>We got as far as we could creating all these different types of sophisticated algorithms to automatically transform designs to responsive code before we started hitting limits.</p><p>In my experience, wherever you think the limit is, it's probably a lot further. But, at a certain point, you'll find some things are just near impossible to do with standard code.</p><p>For example, automatically detecting which layers should turn into one image, is something that human perception is really good at understanding, but this isn't necessarily normal imperative code. In our case, we wrote all this in JavaScript.</p></span></p><p builder-id="builder-b2d4b78316a844f1af12d8b6165daf71"><a href="#add-specialized-ai-to-fill-in-the-gaps" id="add-specialized-ai-to-fill-in-the-gaps"><span><h3>Add specialized AI to fill in the gaps</h3></span></a></p><p><span><p>Lucky for us, training your own object detection model to solve this need with AI is not that hard. For example, products like Google's Vertex AI has a range of common types of models that you can efficiently train yourself — one of which is object detection.</p><p>I can choose that with a GUI and then prepare data and just upload it as a file.</p></span></p><p><span><p><span>For a well-established type of model like this, all it comes down to is creating the data.</span><br></p><p>Now, where things get interesting is finding creative ways of generating the data you need.</p><p>One awesome, massive free resource for generating data is simply the Internet.</p><p>One way we explored approaching this was using puppeteer to automate opening websites in a web browser, taking a screenshot of the site, and  traversing the HTML to find the <code>img</code> tags.</p><p>We then used the location of the images as the output data and the screenshot of the webpage as the input data. And now we have exactly what we need — a source image and coordinates of where all the sub-images are to train this AI model.</p></span></p><div builder-id="builder-ccea16bced6347a0921eda0f9bfe2b27"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=503 503w" type="image/webp"><img alt="Builder.io website screenshot with drawings overlaying where each of the images are" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p builder-id="builder-dbe51ff78bbb4f7684e5f7b6df0c2ddf"><a href="#combine-code-ai-models-for-a-finished-complete-solution" id="combine-code-ai-models-for-a-finished-complete-solution"><span><h3>Combine code + AI models for a finished complete solution</h3></span></a></p><p><span><p>Using these techniques where we fill in the unknowns with specialized AI models and combine them is how we're able to produce end results like this: I can just select my design, click <strong>Generate code</strong>, wait only about one second, and launch into Builder.io.</p><p>Then in Builder, we get a completely responsive website with high-quality code that you can customize completely. It supports a wide variety of frameworks and options, and it's all super fast because all of our models are specially built just for this purpose.</p><p>We offer this at an exceptionally low cost, providing a generous free tier, and it's tremendously valuable for our customers, helping them save lots of time.</p></span></p><p builder-id="builder-33a15ef7844947beb9ad328cce482100"><a href="#the-benefits-of-controlling-your-own-models" id="the-benefits-of-controlling-your-own-models"><span><h2>The benefits of controlling your own models</h2></span></a></p><p><span><p>The best part is that this is only the beginning.</p></span></p><p builder-id="builder-ffbd66a65c9c41e2ae54ea36a3e766b1"><a href="#benefit-1-you-control-your-own-destiny" id="benefit-1-you-control-your-own-destiny"><span><h3>Benefit #1: you control your own destiny</h3></span></a></p><p><span><p>One of the best parts of this approach is that we completely own the models so we can constantly improve them. We aren't just wrapping somebody else's model.</p><p>If you're fully dependent only on someone else's model, like OpenAI, there's no guarantee it's going to get smarter, faster, or cheaper for your use case in any guaranteed timeline. And your ability to control that with prompt engineering and fine-tuning is severely limited.</p><p>But since we own our own model, we're making significant improvements every day.</p><p>When new designs come in that don't import well — which still happens as it's in beta — we rely on user feedback to improve at a rapid cadence, shipping improvements every single day.</p></span></p><p builder-id="builder-cbae2fe07d9b4985942d8bcbba828ffe"><a href="#benefit-2-you-control-privacy" id="benefit-2-you-control-privacy"><span><h3>Benefit #2: you control privacy</h3></span></a></p><p><span><p>With this approach, we never have to worry about a lack of control. For instance, when we started talking to some large and privacy-focused companies as potential early beta customers, one of the most common pieces of feedback was that they were not able to use OpenAI or any products using OpenAI.</p><p>Their privacy requirements prioritize making sure their data never goes into systems that they don't allow.</p><p>In our case, because we control the entire technology, we can hold our models to an extremely high privacy bar. Thank goodness, because we would’ve lost out on some serious business had we been dependent on other companies (like many others are).</p><p>And for the LLM step, we can either turn it off (because it's purely nice to have) or companies can plug in their own LLM. Those LLMs might be an entirely in-house built model, a fork of <code>llama2</code>, their own enterprise instance of OpenAI, or something else entirely.</p></span></p><p builder-id="builder-6ac7cf62e70d4d348c50a07599a499d9"><a href="#conclusion" id="conclusion"><span><h3>Conclusion</h3></span></a></p><p><span><p>So, if you want to build AI products, I highly recommend taking a similar approach as Builder.</p><p>As strange as it sounds, avoid using AI for as long as possible in your project. Then, when you start finding particular problems that standard coding doesn't solve well — but well-established AI models can — start generating your own data and training your own models with a wide variety of tools you can find off-the-shelf.</p><p>Connect your model(s) to your code only where they're needed.</p><p>And I want to emphasize this: use AI for as <em>little</em> as possible. At the end of the day, “normal” code is the fastest, most reliable, most deterministic, most easy to debug, easy to fix, easy to manage, and easy to test code you will ever have.</p><p>But the magic will come from the small but critical areas you use AI models for.</p><p>Can’t wait to see the awesome things you build.</p></span></p><div data-name="symbol" data-source="Rendered by Builder.io" data-model="symbol" builder-id="builder-cd61df2407824553be2497e03d87073a" builder-type="blocks" data-builder-component="symbol" data-builder-content-id="02714711c4b647959d015e34679ca6ee" builder-content-id="02714711c4b647959d015e34679ca6ee" builder-model="symbol"><template data-template-variant-id="6d0b491a00e64dce9781e3c0a9839b71"><div class="builder-content" builder-content-id="6d0b491a00e64dce9781e3c0a9839b71" builder-model="symbol"><div data-builder-component="symbol" data-builder-content-id="de784470c6884829b5e7c7603f4c51ed"><div class="builder-blocks css-h47494" builder-type="blocks"><style data-emotion-css="kf99zz">.css-kf99zz.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-left:-130px;margin-right:-260px;margin-top:10px;z-index:11px;}@media only screen and (max-width:991px){.css-kf99zz.builder-block{margin-left:0;margin-right:0;}}</style><div class="builder-block builder-7c77e4f236f848b48c79a96f49072518 css-kf99zz" builder-id="builder-7c77e4f236f848b48c79a96f49072518"><style data-emotion-css="jgc6i5">.css-jgc6i5.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:50px;width:100%;min-height:20px;min-width:20px;overflow:hidden;mix-blend-mode:multiply;margin-left:auto;margin-right:auto;max-width:405px;}@media only screen and (max-width:991px){.css-jgc6i5.builder-block{margin-top:10px;}}</style><div class="builder-block builder-661f4bd90a3547fa85f50126d1418c87 dark-mode-invert css-jgc6i5" builder-id="builder-661f4bd90a3547fa85f50126d1418c87"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=405 405w" type="image/webp"></picture><style data-emotion-css="1sn22t4">.css-1sn22t4{width:100%;padding-top:35.4%;pointer-events:none;font-size:0;}</style><div class="builder-image-sizer css-1sn22t4"> </div></div><div class="builder-block builder-296e83c56835496a896d380e22d2fbd9 builder-has-component css-logohe" builder-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="1fuo4gk">.css-1fuo4gk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}@media (max-width:991px){.css-1fuo4gk{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}}</style><div class="builder-columns css-1fuo4gk"><style data-emotion-css="15p9q9i">.css-15p9q9i{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(58.333% - 15px);margin-left:0;}.css-15p9q9i > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}@media (max-width:991px){.css-15p9q9i{width:100%;margin-left:0;}}</style><div class="builder-column css-15p9q9i"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="8r3wet">.css-8r3wet.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;min-height:20px;min-width:20px;width:100%;border-radius:5px;overflow:hidden;margin-right:auto;}</style><div class="builder-block builder-50cefa294545480a96166693c05e207d css-8r3wet" builder-id="builder-50cefa294545480a96166693c05e207d"><div class="css-79elbk"><video autoplay="" muted="" loop="" class="builder-video css-cz4v3a"></video><style data-emotion-css="m5569v">.css-m5569v{width:100%;padding-top:58.41%;pointer-events:none;font-size:0;}</style><div class="css-m5569v"></div></div></div></div></div><style data-emotion-css="1xaxpyc">.css-1xaxpyc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(41.667% - 15px);margin-left:30px;}.css-1xaxpyc > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}@media (max-width:991px){.css-1xaxpyc{width:100%;margin-left:0;}}</style><div class="builder-column css-1xaxpyc"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="9f7tx5">.css-9f7tx5.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:auto;margin-bottom:auto;}</style><div class="builder-block builder-2487409df20c4d6ea916563459503bd5 css-9f7tx5" builder-id="builder-2487409df20c4d6ea916563459503bd5"><style data-emotion-css="1718vnj">.css-1718vnj.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;height:auto;font-size:24px;}@media only screen and (max-width:991px){.css-1718vnj.builder-block{margin-top:28px;}}</style><div class="builder-block builder-01c085f9d331407291e18ae00c2e705f builder-has-component css-1718vnj" builder-id="builder-01c085f9d331407291e18ae00c2e705f"><span class="builder-text css-1qggkls"><p style="">Visually build with your components</p></span></div><style data-emotion-css="1mbueh1">.css-1mbueh1.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:12px;height:auto;}@media only screen and (max-width:991px){.css-1mbueh1.builder-block{margin-top:13px;}}</style><div class="builder-block builder-522f74098b38447289e1bbe3e525c9d6 fix-line-height builder-has-component css-1mbueh1" builder-id="builder-522f74098b38447289e1bbe3e525c9d6"><span class="builder-text css-1qggkls"><p style=""><a href="https://www.builder.io/m/developers" rel="noopener noreferrer" target="_blank">Builder.io</a>&nbsp;is a visual editor that connects to any site or app and lets you&nbsp;<a href="https://www.builder.io/m/products" rel="noopener noreferrer" target="_blank">drag and drop</a>&nbsp;with&nbsp;<a href="https://www.builder.io/m/developers" rel="noopener noreferrer" target="_blank">your components</a>.<br></p>
</span></div><style data-emotion-css="etaca8">.css-etaca8.builder-block{position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;margin-right:auto;margin-top:22px;}@media only screen and (max-width:991px){.css-etaca8.builder-block{margin-top:16px;}}@media only screen and (max-width:640px){.css-etaca8.builder-block{margin-top:17px;}}</style><div class="builder-block builder-04ce70c139f74cba9ce6b77cd2b59966 builder-has-component css-etaca8" builder-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="builder-columns css-k008qs"><style data-emotion-css="1ki2g2t">.css-1ki2g2t{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(50% - 10px);margin-left:0;}.css-1ki2g2t > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="builder-column css-1ki2g2t"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="e9su4y">.css-e9su4y.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;-webkit-appearance:none;-moz-appearance:none;appearance:none;padding-top:10px;padding-bottom:10px;padding-left:35px;padding-right:35px;background-color:rgba(0,0,0,1);color:white;border-radius:8px;text-align:center;cursor:pointer;width:auto;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;font-family:"Poppins",sans-serif;font-size:16px;line-height:26px;-webkit-letter-spacing:.5px;-moz-letter-spacing:.5px;-ms-letter-spacing:.5px;letter-spacing:.5px;margin-right:auto;white-space:nowrap;}@media only screen and (max-width:991px){.css-e9su4y.builder-block{font-size:16px;line-height:18px;padding-left:23px;padding-right:23px;margin-top:0px;padding-top:13px;padding-bottom:13px;}}</style><a role="button" href="https://builder.io/signup" target="_blank" class="builder-block builder-bbfd1a8be4e54fa0bc8f887da6d8a83c builder-has-component css-e9su4y" builder-id="builder-bbfd1a8be4e54fa0bc8f887da6d8a83c">Try it out</a></div></div><style data-emotion-css="1q570rn">.css-1q570rn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(50% - 10px);margin-left:20px;}.css-1q570rn > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="builder-column css-1q570rn"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="1t30id">.css-1t30id.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;-webkit-appearance:none;-moz-appearance:none;appearance:none;padding-top:10px;padding-bottom:10px;padding-left:0px;padding-right:0px;color:rgba(0,0,0,1);border-radius:8px;text-align:center;cursor:pointer;width:auto;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;font-family:"Poppins",sans-serif;font-size:16px;line-height:26px;-webkit-letter-spacing:.5px;-moz-letter-spacing:.5px;-ms-letter-spacing:.5px;letter-spacing:.5px;margin-right:auto;margin-left:15px;}@media only screen and (max-width:991px){.css-1t30id.builder-block{font-size:16px;line-height:18px;padding-left:0px;padding-right:18px;margin-top:auto;margin-left:2px;min-width:110px;margin-bottom:auto;}}</style><a role="button" href="/m/developers" target="_blank" class="builder-block builder-b73a1d9611ee46b180da86ffdd53fa77 builder-has-component css-1t30id" builder-id="builder-b73a1d9611ee46b180da86ffdd53fa77">Learn more</a></div></div></div></div><style data-emotion-css="nwuw40">.css-nwuw40.builder-block{margin-top:20px;padding-left:20px;border-radius:4px;padding-right:20px;background-color:rgba(40,44,52,1);box-shadow:0 2px 6px 0 rgba(0,0,0,0.27);}</style><div class="builder-block builder-dde61f974a184a338de6b5e43b675061 builder-has-component css-nwuw40" builder-id="builder-dde61f974a184a338de6b5e43b675061"><style data-emotion="css 1ijwl8d">.css-1ijwl8d{position:relative;border-radius:3px;}.css-1ijwl8d:hover .copy-to-clipboard{display:block!important;}.css-1ijwl8d code{font-size:14px;}</style><div class="code-block css-1ijwl8d"><style data-emotion="css 185ibg">.css-185ibg{position:absolute!important;top:0;right:0;display:none!important;z-index:10;}</style><button class="MuiButtonBase-root MuiIconButton-root copy-to-clipboard css-185ibg" tabindex="0" type="button" title="Copy code to clipboard"><span class="MuiIconButton-label"><style data-emotion="css joy3r2">.css-joy3r2{color:white;opacity:0.7;}</style><svg class="MuiSvgIcon-root css-joy3r2" focusable="false" viewBox="0 0 24 24" aria-hidden="true"><path d="M19 3h-4.18C14.4 1.84 13.3 1 12 1c-1.3 0-2.4.84-2.82 2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-7 0c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1zm2 14H7v-2h7v2zm3-4H7v-2h10v2zm0-4H7V7h10v2z"></path></svg></span></button><div class=""><pre style="display:block;overflow-x:auto;padding:0.5em;color:#ddd;background:#282c34;font-family:Menlo, Monaco, &quot;Courier New&quot;, monospace;line-height:1em;font-size:1.2em"><code class="language-jsx">// Dynamically render your components
export function MyPage({ json }) {
  return &lt;BuilderComponent content={json} /&gt;
}

registerComponents([MyHero, MyProducts])</code></pre></div></div></div></div></div></div></div></div></div><style data-emotion-css="1mvsfya">.css-1mvsfya.builder-block{height:0;width:0;display:inline-block;opacity:0;overflow:hidden;pointer-events:none;}</style><img role="presentation" aria-hidden="true" src="https://cdn.builder.io/api/v1/pixel?apiKey=YJIGb4i01jvw0SRdL5Bt" class="builder-block builder-pixel-e86nycc5tdw css-1mvsfya" builder-id="builder-pixel-e86nycc5tdw"></div></div></div></template><div builder-id="builder-7fd4bfcb2f3540cca129a9e10d1254f5" builder-type="blocks" builder-parent-id="builder-fd60c008f44a4c46be618e21afe30be5" data-builder-component="symbol" data-builder-content-id="de784470c6884829b5e7c7603f4c51ed" builder-content-id="de784470c6884829b5e7c7603f4c51ed" builder-model="symbol"><p><span><div><p>Introducing Visual Copilot: a new AI model to convert Figma designs to high quality code in a click.</p><p>No setup needed. 100% free. Supports all popular frameworks.</p></div>
</span></p><p><a role="button" href="https://builder.io/signup" target="_blank" builder-id="builder-a85aff888e7849f98193f66bd662f27e">Try Visual Copilot</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texture Healing for Monospace Fonts (150 pts)]]></title>
            <link>https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md</link>
            <guid>38221379</guid>
            <pubDate>Fri, 10 Nov 2023 17:07:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md">https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md</a>, See on <a href="https://news.ycombinator.com/item?id=38221379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:githubnext/monaspace" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TPvN7MsNCXIuV6vVQV5rcQHaD_7Vp6kjJhj-jxdU2XW_d9K5Cg5poUOO_olxMkI27Ms_Ki6qU2_NnDxqVeUODw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="githubnext/monaspace" data-current-org="githubnext" data-current-owner="" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=githubnext%2Fmonaspace" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b5e9e72f7999e9104da59519413a9f6f6970d8cf0b3d3ecd52abd892b386905c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dungeon KeeperFX 1.0.0 has been released (185 pts)]]></title>
            <link>https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released</link>
            <guid>38220982</guid>
            <pubDate>Fri, 10 Nov 2023 16:39:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released">https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released</a>, See on <a href="https://news.ycombinator.com/item?id=38220982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Numerous volunteers have put in a lot of work to deliver a long list of features and fixes. Notably, with this release, there is a jump from version 0.x to version 1.x, coinciding with the removal of the link to the keeperfx.dll file. </p><p>This means that all original Dungeon Keeper code has been rewritten, establishing KeeperFX as a true open-source standalone game. Ownership of the original game is still and will always be required for copyright reasons. When installing KeeperFX 1.0, perform a fresh installation without overwriting any previous versions. Saved games cannot be migrated. There is a <a href="https://github.com/dkfans/keeperfx/wiki">wiki</a> that holds answers to most of the questions you may have, and we have a large and friendly <a href="https://discord.gg/hE4p7vy2Hb">discord community</a> where we welcome all friendly new members. </p><p><strong>What’s new in KeeperFX 1.0.0:</strong> </p><ul><li>All remaining legacy functionality from the Dungeon Keeper executable has been moved to KeeperFX. <ul><li>This means we are no longer limited by the original game in what we can change </li><li>There can now be more than 2048 things on the map at the same time</li></ul> </li><li>Maps are no longer limited to being 85x85, they can be larger or smaller </li><li>New units: Time Mage and Druid (are not used in old campaigns, but wait to see them in new maps) </li><li>Higher frame rates </li><li>Fixed crashes when playing in 4k resolution </li><li>Improved bridge building and digging for enemy computers </li><li>Stopped the best computer players from instantly dropping their entire army on you </li><li>Removed the lowest rated campaigns that were bundled, to give new users a positive first impression </li><li>Bundled campaigns got higher quality landview speeches </li><li>Added more translations for included maps and campaigns </li><li>Objects can have a direction (so face east for example) </li><li>More customization options for mapmakers and modders. <ul><li>Add new creatures </li><li>Level scripts can be larger, resulting in more complex scenarios </li><li>Add new shots </li><li>New script commands </li><li>Custom music and sounds </li><li>Fully configurable traps </li><li>New decorative objects</li></ul> </li><li>New map textures </li><li>Orcs got an eating animation and the Avatar a torture animation </li><li>Maps can have larger hero parties </li><li>Improved multiplayer stability </li><li>Multiplayer map numbers can go past 255 </li><li>Gems are now purple on the minimap to distinguish them from gold </li><li>Units visible on minimap no longer jump around</li></ul> <p>For the full change list see <a href="https://github.com/dkfans/keeperfx/compare/Release050...Release1.0.0">here</a>. </p><p>- KeeperFX Team</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York restaurants fight back against reservations by bots (109 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots</link>
            <guid>38220892</guid>
            <pubDate>Fri, 10 Nov 2023 16:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots">https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots</a>, See on <a href="https://news.ycombinator.com/item?id=38220892">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gigantic heat caverns in Mustikkamaa have now been filled with water (2021) (144 pts)]]></title>
            <link>https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled</link>
            <guid>38220288</guid>
            <pubDate>Fri, 10 Nov 2023 15:46:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled">https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled</a>, See on <a href="https://news.ycombinator.com/item?id=38220288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    News / 11.5.2021
                </p>
                <h2>Gigantic heat caverns in Mustikkamaa have now been filled with water</h2>
                <div>
    <p>The filling of underground heat caverns in Mustikkamaa with water has been completed this week, and the use of the heat caverns for heating homes in Helsinki is a step closer.</p>
</div>
                
            </div><div>
<p>Helen started to fill the heat caverns with tap water in early December. The filling of the caverns took more than three months due to their enormous total volume of 320 million litres. The caverns have such a large capacity that filling them from an ordinary kitchen tap would have taken more than 50 years.</p>
<p>The current estimated temperature of the water storage facility is about +30 degrees. Slow heating of the bedrock has started, and actual heating of water in the heat cavern will start in April. The aim is to connect the heat caverns into the current district heating system of Helsinki in July.</p>
<p>The heat caverns balance the consumption peaks in the district heating network throughout the year. For example, waste heat from waste waters and properties can be stored in the heat cavern and released for use as and when required. In future, the temperature of the water in the heat cavern will vary between +45 and +100 degrees according to usage situation.</p>
<p>- Helen is proceeding fast towards a carbon-neutral future, and the underground heat caverns are an important step on this path. The use of old oil caverns as an energy storage facility is a good example of Finnish innovation that is unique even on a global scale. The emission-free energy system of the future is made up of many pieces, and storage is an important element in the system. The heat caverns support all heat production forms, says Helen’s Director Timo Aaltonen.</p>
<p>Carbon-neutral production is also currently built at Helen’s heating and cooling plant in Sörnäinen with the arrival of two new heat pumps. A seawater heat pump and a bioenergy heating plant are being built in Vuosaari. The construction of the geothermal heating plant in Ruskeasuo will start this spring. Helen is also investigating, for example, waste heat from the Kilpilahti industrial area and extensive utilisation of seawater heat pumps.</p>
<p><strong> Facts</strong></p>
<ul>
<li>The heat contained in the water in the Mustikkamaa cavern heat storage facility corresponds to the heating of 25,000 one-bedroom apartments all year round.</li>
<li>Heat will not escape from the heat caverns because the bedrock that is tens of metres deep acts as an excellent insulator.</li>
<li>The rock caverns will decrease Helen’s carbon dioxide emissions by 21,000 tonnes per year.</li>
</ul>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Svalbard fibre optic cable connection (143 pts)]]></title>
            <link>https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/</link>
            <guid>38219998</guid>
            <pubDate>Fri, 10 Nov 2023 15:26:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/">https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/</a>, See on <a href="https://news.ycombinator.com/item?id=38219998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Svalbard has an ideal geographical location for downloading data from satellites in polar orbits. SvalSat, the Svalbard satellite ground station at 78 degrees north, is the northernmost ground station in the world and started operation in 1997. However, development of the business depended on efficient transfer of large volumes of data to the mainland.</p>







<p>The station is located at Platåberget outside Longyearbyen. Satellite data were initially transmitted to customers via a geostationary satellite. However, small capacity for data transmission via satellite was a limiting factor. Around 2001, it became clear that SvalSat’s future development was entirely dependent on the efficient transfer of large volumes of data to the mainland.</p>







<figure><img src="https://spacenorway.no/wp-content/uploads/2021/09/DJI_0709_web-768x1024.jpg" alt="KSATs stasjon på Svalbard, SvalSat har i dag over 100 operative antenner.
Foto: KSAT" width="501" height="668"><figcaption><sup>SvalSat, KSAT’s station on Svalbard, currently has more than 100 operational antennas. Photo: KSAT</sup></figcaption></figure>



<p>At this time, SvalSat was part of Norsk Romsenter Eiendom AS (later renamed Space Norway AS), a company owned by Stiftelsen Norsk Romsenter (NRS). NRS was concerned that SvalSat would lose out on commercial opportunities because of the lack of fibre connection to mainland Norway. NRS believed that a subsea fibre connection would be essential to ensure the future development of SvalSat’s activities. The telecommunications operator at Svalbard saw no commercial basis for investing in an approximately 1,400-kilometre subsea fibre optic cable connection. In 2002, NRS initiated its own assessment and planning of a fibre connection from Longyearbyen to the mainland, with the objective of establishing such connection without any government financing.</p>







<p>With Space Norway as a tool, NRS succeeded in this project. Financing was secured through a combination of long-term contracts, debt, prepayments from key customers, and funding from Space Norway. Customers and partners included NASA, NOAA, KSAT, Andøya Rocket Range (today Andøya Space Center), Telenor and Uninett8. The construction was done in 2003 and the fibre connection became operational in January 2004.</p>







<figure><img src="https://spacenorway.no/wp-content/uploads/2021/12/18%E2%80%A2NH0160021-1024x683.jpg" alt="" width="840" height="560"><figcaption>Jens Olav Frorud and Dag H. Stølan in Space Norway. Foto: Nina Holtan</figcaption></figure>







<p>The fibre connection has been of important strategic value for the growth and development of KSAT. SvalSat is now the world’s largest ground station for downloading data from satellites in polar orbits. Today, both KSAT and Space Norway are two successful spin-off businesses from NRS (Norwegian Space Agency).</p>







<p>The fibre connection consists of two separate cables that connect Longyearbyen to mainland Norway. The distance of approx. 1,400 km corresponds roughly to the distance between Oslo and Paris. The cables are buried approximately 2 metres in selected areas to protect against destruction by fish trawling and anchoring of ships. The sea depth reaches as much as 1,670 metres just west of Svalbard. At the time of construction, it was the world’s deepest fibre-optic cable. Tyco Communications (now SubCom) was the contractor for the project. The anticipated technical service life of the cables is 25 years. It is now 17 years since the cables became operational. The operating track record of the Svalbard connection has been excellent with few incidents that have led to interruptions of the service. During the period 2018-20, Space Norway carried out significant security related upgrades to the fibre connection.</p>







<p>The primary motivation for establishing the fibre-optic cable in 2004 was to ensure the growth and development of the satellite business at SvalSat. Today, the fibre connection also represents a critical resource for the society at Svalbard and enables modern electronic communication services. These are services necessary to maintain and develop society as well as Norwegian presence on the archipelago. The fibre connection is considered part of the national critical infrastructure.</p>






<div>
<figure><img src="https://spacenorway.no/wp-content/uploads/2021/09/Fiberforbindelse_Longyearbyen_bakgrunn-768x1024.jpg" alt="" width="511" height="681"><figcaption><sup>Illustration of the fibre optic cable enabling efficient transfer of large volumes of data to the mainland.</sup></figcaption></figure></div>






<p>National and international companies and entities depend on a functioning fibre connection to Svalbard. Information downloaded at SvalSat and distributed via the fibre connection is important for a number of purposes such as weather forecasting services, surveillance of ship traffic, environmental monitoring, development of ice maps for the Arctic and communication services in the critical phases of rocket launches9. The connection is also important for KSAT’s contribution to Galileo, Europe’s satellite-based navigation system10. Space Norway offer transmission capacity at wholesale level to a small number of customers, who in turn provide communication services in the retail and commercial markets. End customers and users of the fibre connection include a wide spectre of businesses: the society in general, the coastal radio service, Helsenett, Avinor, the Governor of Svalbard, including police and SAR (Search And Rescue) resources, local government in Longyearbyen, the Norwegian Coastal Administration with services for maritime security, EUMETSAT11, NASA, NOAA, Galileo, Iridium, ESA, the Norwegian Mapping Authority as well as university and research units on the archipelago such as UNIS, the Nansen Environmental and Remote Sensing Center and the Norwegian Institute of Marine Research etc.</p>







<p><strong>Sources:</strong></p>



<p><sup>8 NASA is the National Aeronautics and Space Administration, and NOAA is the National Oceanic and Atmospheric Administration, a department under the United States Department of Trade. KSAT is Kongsberg Satellite Services.</sup></p>



<p><sup>9 LEOP, Launch and early operations phase.</sup></p>



<p><sup>10 Galileo is a satellite navigation system set up by the European Union and the European Space Agency. The system has been designed as an alternative to the military and American-controlled Global Positioning System (GPS) and the Russian GLONASS.</sup></p>



<p><sup>11 EUMETSAT is the European organisation for meteorological satellites.</sup></p>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeff Geerling (183 pts)]]></title>
            <link>https://www.raspberrypi.com/news/meet-jeff-geerling/</link>
            <guid>38219926</guid>
            <pubDate>Fri, 10 Nov 2023 15:20:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raspberrypi.com/news/meet-jeff-geerling/">https://www.raspberrypi.com/news/meet-jeff-geerling/</a>, See on <a href="https://news.ycombinator.com/item?id=38219926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p><strong><em>Andrew Gregory of <a href="https://hackspace.raspberrypi.com/">HackSpace magazine</a> sat down with the one and only Jeff Geerling to chat about the wholesome corner of the internet he created. </em></strong></p>


<div>
<figure><img decoding="async" loading="lazy" width="965" height="643" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45.png" alt="jeff in a blue anti static jacket pointing at raspberry pi awards inside the sony factory" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45.png 965w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-768x512.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-800x533.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-900x600.png 900w" sizes="(max-width: 965px) 100vw, 965px"><figcaption>Jeff exploring the Sony factory where Raspberry Pis are baked</figcaption></figure></div>


<p>If you want to cut through the buzzwords and find out what tech actually does, you could do a lot worse than listen to Jeff Geerling. He’s built an utterly wholesome corner of the internet in which he explains, demonstrates, and demystifies the latest thing that everybody else pretends to know about. Linux, single-board computers, open source, developer tools, home automation – Jeff does the lot, and he wants to teach you how to do it, too. We thought we’d talk to him about what he’s been getting up to with his new Raspberry Pi 5. </p>



<h3><strong>HackSpace:&nbsp; Morning Jeff! You’ve done loads of Pi projects over the last couple of years. What do you still have running at the moment?</strong></h3>



<p><strong>Jeff Geerling</strong>:&nbsp; Things that are practical, really. I have Pis running all of my home network stuff, all the home lab-type things; I have a Pi running internet monitoring, so I can keep my ISP honest. I have a Pi running my VPN.&nbsp;</p>



<p>I have no cloud services for my light bulbs, or for my HVAC or anything. It’s all running through Pis. I don’t have any cloud account tie-in. If the internet goes down here, the only thing is I can’t access it remotely, but everything’s still running. I love the privacy aspects of it. And I love the ability to learn new things through it – industrial automations, and controls, and APIs with these different systems.&nbsp;</p>



<p>I think one of the things that fascinates me the most is all these different IOT devices. Before I knew much about Pis and microcontrollers, I always thought IoT was magic. And then you open one of these up, and you just see a little microcontroller inside. It might just be an ESP board, or a Pico, or something else. But I know that I could hack it, and that opens up a new world. You could build one of those on your own to just about the same quality; you can’t get injection-moulded plastic, but everything else you can do on your own, and 3D printing has made it so that enclosures can be so much nicer. It’s just cool to see. It’s like taking down the wall of magic that you thought existed between really cool products and your own abilities.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="571" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-1024x571.png" alt="jeff wearing a mask and soldering towards the camera" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-1024x571.png 1024w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-300x167.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-768x429.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-800x446.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-450x251.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-900x502.png 900w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33.png 1145w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Jeff describes himself as an electronics beginner; something tells us he’s being modest</figcaption></figure></div>


<p>The projects that I do are typically rehashes of what other people have done; I might make the documentation a little better or I might package it up a little nicer. But really, I would say that I’m beginner-level electronics and beginner-level microcontrollers. I just have the ability to relate what I’m doing a little better than a lot of people who are experts at it.</p>



<p>A year or two ago, I talked to [Linux YouTuber] NetworkChuck about recording a podcast episode. He does a lot of stuff with Raspberry Pis, too, with red hat hacking and black hat stuff. And, you know, fun things. So we recorded the podcast. And it never went up because one of the microphones was messed up, and it sounded terrible. I didn’t hear from him for a while, and then on 01 March this year, he’s just like, ‘Hey, Jeff, do you want to work with me on a Mr. Beast project? At like, 9 am, right now?’ I had no travel planned and no deadlines, so I said yes.&nbsp;</p>



<p>And that was terrible, but also awesome. So many people who make things, especially if you make it for production use, want to make sure it actually works. So there’s a deadline attached to it. There are problems; there are always challenges, things you didn’t even think about. And that’s what happened on the Mr. Beast project. But that’s also kind of the addiction that drives us forward. Because while I would say I don’t want to ever do that again, I also say that was a fun experience. And getting to meet all the people there. And all of us going through that at the same time, solving all the challenges. It’s a weird kind of addiction that we have, I think, building software, building hardware, and working on something so big as well.&nbsp;</p>



<p>Any time we solved a problem with a five-minute fix, the sheer number of computers we were using turned that into a multiple-hour fix.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="642" height="532" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02.png" alt="jeff in a red t shirt holding a bowling ball" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02.png 642w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02-300x249.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02-450x373.png 450w" sizes="(max-width: 642px) 100vw, 642px"><figcaption>Testing hardware by dropping a bowling ball on to it. Always wear eye protection!</figcaption></figure></div>


<h3><strong>HS:&nbsp; Why Raspberry Pi? What’s so good about it?</strong></h3>



<p><strong>JG:&nbsp;</strong> Raspberry Pi devotes a lot of time to testing and to making sure manufacturing is better. And manufacturing in the UK is a pretty cool thing. How many computer companies manufacture things in their home country – there’s not many, and Raspberry Pi does on a huge scale. So there’s a lot of those things that some people don’t assign value to – not just the bits and the little circuits on the board and all that.&nbsp;</p>



<p>Open source is another balance that Raspberry Pi has to offer. There’s the Broadcom chip [which isn’t open-source] versus you’re building the operating system based on Debian, which is like one of the most open-source Linux distributions. And it’s a weird balance. In the hardware world, it seems like there’s a lot less open source, because if you put out an open-source design and someone else makes it, all of a sudden you have zero revenue. Versus software, there’s sales and support and services, and there’s a lot more revenue opportunities that can’t just be immediately consumed by another company. Although, recently we’ve seen Amazon doing that sometimes, and leading to licences like the BSL, which is not really open-source.</p>


<div>
<figure><img decoding="async" loading="lazy" width="968" height="642" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54.png" alt="jeff in a red shirt looking into the camera holding a pi cluster next to his face" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54.png 968w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-300x199.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-768x509.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-800x531.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-450x298.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-900x597.png 900w" sizes="(max-width: 968px) 100vw, 968px"><figcaption>Jeff’s fascinated by factories. And he loves open source software and hardware</figcaption></figure></div>


<h3><strong>HS:&nbsp; I’ve heard of the BSD licence, but not BSL.</strong></h3>



<p><strong>JG:&nbsp;</strong> Most open-source licences don’t care if you’re a government or a spy or a bad person or a good person – it’s free. It’s unencumbered. But the BSL imposes a restriction: if you’re a big business, you can’t use it. Philosophically I can understand that stance, but don’t call it </p>



<p>open source: call it ‘source available’ or, you know, ‘maker friendly’. But on the flip side, there’s so many companies that start as a maker, somebody who designs a little thing, that thing becomes popular, and all of a sudden you’re a big business and your licence is void, just because you hit a revenue number. And it doesn’t matter if it’s 50 bucks or $5 billion, it’s a restriction and it’s a philosophical thing that’s not compatible with my understanding of the term ‘open source’.&nbsp;</p>



<p>I think Raspberry Pi offers a little bit of a different take on it. Early on, a lot of the hardware was super locked down and there weren’t datasheets. And one by one, they start making things better at release. So, you know, my hope is that someday we could get more open firmware and stuff for the Broadcom chips. I don’t know if that’ll ever happen. But it would be cool. Unlike many companies, where they start out open source and then start closing things, Raspberry Pi has always gotten better, even if it’s not perfect.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="966" height="640" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24.png" alt="jeff crouched next to a table with a massive pi cluster on it" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24.png 966w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-300x199.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-768x509.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-800x530.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-450x298.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-900x596.png 900w" sizes="(max-width: 966px) 100vw, 966px"><figcaption>The Petabyte Pi: a Raspberry Pi with 1024 terabytes of storage</figcaption></figure></div>


<h3><strong>HS:&nbsp; Hopefully people will like the new power button.&nbsp;</strong></h3>



<p><strong>JG:</strong> For me, the power button on the Pi 5 is the most appreciated new feature. It’s just so handy. Like, if I’m running a Raspberry Pi headless, with no keyboard, I can just do a quick shut down. I mean, I put power buttons on GPIO before, but it’s cumbersome. This is nice to have it on the board.&nbsp;</p>



<h3><strong>HS:&nbsp; And have you looked into the dual camera possibilities?</strong>&nbsp;</h3>



<p><strong>JG:&nbsp;</strong> So machine vision has gotten really interesting in the past year, to the point where there are open-source tools to do so many things that used to require tons of expensive I/O. You can do stereo camera depth vision with all open-source tools, and [I’m] hoping to use Google Coral TPU to do some of this stuff.&nbsp;</p>



<p>Again, it breaks down that barrier between you and the magic. You pick up an iPhone 15 and it can do depth mapping with whatever that sensor is. And you’re like, man, I’ll never be able to do that.&nbsp;</p>



<p>And then you get a Pi 5 with Wi-Fi and two cameras, and you’re like, oh, I can plug these open-source libraries together. And we get this – it might not be as high resolution, and it might not be 60 frames per second, but you could do depth mapping and 3D stuff with a little board, and everything’s under 200 bucks, all in, including power supplies and everything. That’s a big difference.&nbsp;</p>



<p>When I was a kid, you could go to RadioShack and buy an electronics hobbyist kit. And that’s how I learned the basics of resistors and all that. You put them together with little spring contacts, and it was really fun. And you could make buzzers and radios and all kinds of stuff – they don’t really exist anymore. All those hobbies that were big when I was a kid, a lot of them are superseded just by how amazing the technology we have today is. But the Raspberry Pi brings that back.</p>


<div>
<figure><img decoding="async" loading="lazy" width="966" height="643" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51.png" alt="jeff geerling in a shirt in front of a regency period looking building" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51.png 966w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-768x511.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-800x533.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-900x599.png 900w" sizes="(max-width: 966px) 100vw, 966px"></figure></div>


<p>What’s funny is that the Raspberry Pi is actually better at IoT stuff than most IoT companies. Mostly because of the open source philosophy. If we all work together, all these individuals around the world can write plug-ins and do stuff where you can put home assistant at your house. And you can interact with any light bulb, any doorbell, any camera, any washing-machine controller. Whereas if you get Philips, you get the Philips stuff and if you get Sony, you get the Sony stuff.&nbsp;</p>



<p>It’s like the tool world: I use DEWALT mostly, because the first tool I bought was a DEWALT. So you gotta use the DEWALT battery, and then you’re like, well, I could buy this cheaper tool, it’s better. But then it won’t work with my battery. So now I have something like 25 DEWALT tools. I think that’s dumb. It’s ridiculous. And that’s how IoT people want to be: you have the smart hub from this company, and you buy all their stuff. But we’ve already seen companies fail, and then all of your smart stuff becomes dumb. And it’s worse than dumb because you can’t even turn on a light bulb, you know – their server goes down and your lights turn off.&nbsp;</p>



<p>This is an area where instead of just seeing behind the curtain how it’s done, you can do it better. That’s one thing that I love about the Raspberry Pi ecosystem and the open-source ecosystem together.</p>



<h3><strong>HS:&nbsp; A slightly less practical, though no less awesome build of yours is the Pi cluster. Just one question: why?&nbsp;</strong></h3>



<p><strong>JG:&nbsp;</strong> For me, it’s fun. You get something out of it when you’re doing all this work on a cluster. And the first time you see all the nodes come up together, that’s kind of magic. And then also seeing the fact that, like, you can actually program things to scale. It’s useful for a job, especially if you’re gonna build software for the web.&nbsp;</p>



<p>It was a springboard for learning. And for a lot of us, we love that. We love hacking with things, and a Pi cluster is just a fun thing to do it. It also has the side benefit of being able to develop skills that might be incredibly useful. There are still a lot of companies that will pay good money for Kubernetes developers, and a lot of people have learned Kubernetes on Raspberry Pi. The shortage really built into that. And a lot of people started using small PCs that they got on eBay, which is perfectly fine. I think that’s awesome. The hard thing was, like, the reason the Pi was great was because it’s a $35 computer –&nbsp;now a $60 computer – but you can still get the Pi 4, and hopefully there’ll be more available now that Pi 5 has been announced. But it was a quick way to get into that whole ecosystem of learning. And, you know, it’s not necessary at all for a home lab. But it’s fun.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-1024x576.png" alt="jeff kneeling on gravel in front of a massive folded out solar panel" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-1024x576.png 1024w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-300x169.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-768x432.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-800x450.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-450x253.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-900x506.png 900w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13.png 1143w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>And it translated into me getting a better job and doing consulting, which also helped me with that opportunity that I got in the pandemic: I was consulting and making extra money from doing all the work I was doing on Pis, learning clustering, because the clustering skills got me a better-paying job. And it gave me the opportunity to save up some money over the next year. I went to full-time YouTube in 2021, so maybe the Pi cluster was the reason I got into it.&nbsp;</p>



<p>I did my first Pi cluster in 2016. And I had a cluster running from 2016 to 2020 24/7 at my house, and I think had something like two hours of downtime in that time period.&nbsp;</p>



<h3><strong>HS:&nbsp; You said that you’re not a hardware guy. Does that mean that you have a background in software?&nbsp;</strong></h3>



<p><strong>JG:&nbsp;</strong> I started off doing web design. The first ever project I did was helping a radio station. They just transitioned to computers instead of CDs for their music playback, and in their system it had a file that would write to with the current song. My dad had the idea of taking this data and putting the song name on the website, so people could be listening, go to the website, on their laptop, or in an office, back then people did not have smartphones. It was ahead of its time. So I built a little interface that had, like, a car radio with the song title in it in a little, I think it was in Courier font or something, because there were only ten or so fonts that you could use back then. It worked for five or six years, until they got a real website. But, that was my first-ever project.&nbsp;</p>



<p>I learned electronics from my dad, who’s a radio engineer. And I, you know, I soldered together an FM radio. I still have the voltmeter that I soldered together when I was, like, eight years old or something. It still works, and I keep using it, even though it’s not as accurate as it could be. And I’m excited to do more of that since the Pico came out. I’ve done some more projects: I built a garage door sensor thing, and I’m working on some software for the Pimoroni Galactic Unicorn to write some stuff on the wall. And now I have a new office that I’m gonna go into. So there’s a lot of opportunities to build stuff for that.</p>



<h3><strong>HS:&nbsp; That’s a majestic piece of kit.</strong></h3>



<p><strong>JG:&nbsp;</strong> Yeah. And they put in little things like a button. You know, it’s nice to have a button here – now you can do, like, modes for the display. And you can even make a little game on the LEDs matrix. That’s the other thing that I love about the Pi ecosystem: Raspberry Pi works directly with some of these companies to make things better for everyone. And these companies work back with them. It’s a relationship that has been built up over the course of the past decade. It’s bearing more fruit with the Pico, and I think the Pi 5 will drive some of that, too. I’m really excited to see what people come up with with HATs for the Pi 5 with PCI Express. If anybody comes out with a dual 2.5 gigabit network cat, I’m gonna buy that thing the second I see it.</p>



<h2>HackSpace magazine issue 72 out NOW!</h2>



<p>Each month,&nbsp;<a href="https://www.raspberrypi.com/news/tag/hackspace-magazine/">HackSpace magazine</a>&nbsp;brings you the best projects, tips, tricks and tutorials from the makersphere. You can get HackSpace from the&nbsp;<a href="https://store.rpipress.cc/collections/hackspace-magazine">Raspberry Pi Press online store</a>&nbsp;or your local newsagents.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="1024" src="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-1024x1024.png" alt="Hackspace magazine 72 cover" srcset="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-1024x1024.png 1024w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-300x300.png 300w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-150x150.png 150w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-768x768.png 768w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-800x800.png 800w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-100x100.png 100w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-450x450.png 450w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-900x900.png 900w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54.png 1236w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS to start charging for IPv4 usage, but critical services don't support IPv6 (189 pts)]]></title>
            <link>https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/</link>
            <guid>38219882</guid>
            <pubDate>Fri, 10 Nov 2023 15:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/">https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/</a>, See on <a href="https://news.ycombinator.com/item?id=38219882">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>AWS wants to start charging for all allocated IPv4 usage, yet many of their critical services don't support native IPv6</p>

<p>Examples include:</p>

<p>- AWS Cloudformation (cannot signal success/failure)</p>

<p>- AWS systems manager (ssm sessions not possible)</p>

<p>The above cannot be used without an IPv4 address allocated or a NAT gateway. NAT gateways can become quite pricey.</p>

<p>I would love to become complete IPv6 native, but AWS needs to provide IPv6 endpoints for all their major services.</p>

<p>Making this post to raise visibility before IPv4 fees start next year.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU lawmakers scolded for concealing identities of content-scanning experts (152 pts)]]></title>
            <link>https://www.theregister.com/2023/11/09/eu_casm_expert_identities/</link>
            <guid>38219644</guid>
            <pubDate>Fri, 10 Nov 2023 14:59:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/09/eu_casm_expert_identities/">https://www.theregister.com/2023/11/09/eu_casm_expert_identities/</a>, See on <a href="https://news.ycombinator.com/item?id=38219644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Europe's government watchdog has found that the European Commission's refusal to disclose which experts it consulted on the proposal to scan encrypted communication for child sexual abuse material amounted to maladministration.</p>
<p>The decision by the European ombudsman, made last month and <a target="_blank" rel="nofollow" href="https://www.ombudsman.europa.eu/en/decision/en/176658">published</a> this week, stems from a complaint filed in December 2022 by the Irish Council for Civil Liberties (ICCL), an advocacy organization.</p>
<p>The European Commission has been trying to formulate rules for preventing the sharing of online child sexual abuse material, rules known as the <a target="_blank" rel="nofollow" href="https://ec.europa.eu/home-affairs/proposal-regulation-laying-down-rules-prevent-and-combat-child-sexual-abuse_en">Regulation on Child Sexual Abuse</a> (CSA). But critics contend the proposed legislation would have to compromise private encrypted communication.</p>

    

<p>"The commission’s legislation would enable member states to compel online platforms, including those offering end-to-end encrypted messaging, to scan users' content and metadata for CSA images or 'grooming' conversations and behavior, and where appropriate report them to public authorities and delete them from their platforms," a coalition of advocacy groups, technology companies, and technical experts explained in <a target="_blank" rel="nofollow" href="https://www.globalencryption.org/2022/05/joint-statement-on-the-dangers-of-the-eus-proposed-regulation-for-fighting-child-sexual-abuse-online/">an open letter</a> last year.</p>

        


        

<p>"Such a requirement is fundamentally incompatible with end-to-end encrypted messaging because platforms that offer such service cannot access communications content."</p>
<p>Apple came to a similar conclusion when it <a target="_blank" href="https://www.theregister.com/2022/12/08/apple_encryption_icloud/">abandoned</a> its own <a target="_blank" href="https://www.theregister.com/2021/10/15/clientside_side_scanning/">proposal</a> to implement a system to scan for CSA material on its devices. The UK, meanwhile, passed its own Online Safety Bill that authorizes telecom regulator Ofcom <a target="_blank" href="https://www.theregister.com/2023/09/20/uk_online_safety_bill_passes/">to demand decryption</a> – even as officials have acknowledged that's not technically feasible at the moment.</p>
<ul>

<li><a href="https://www.theregister.com/2022/10/13/clientside_scanning_csam_anderson/">Scanning phones to detect child abuse evidence is harmful, 'magical' thinking</a></li>

<li><a href="https://www.theregister.com/2023/03/29/eu_mandated_messaging_interop_paper/">EU mandated messaging platform love-in is easier said than done: Cambridge boffins</a></li>

<li><a href="https://www.theregister.com/2018/05/29/crypto_wars_fipr/">GCHQ bod tells privacy advocates: Most of our work is making sure we operate within the law</a></li>

<li><a href="https://www.theregister.com/2023/11/08/europe_eidas_browser/">Bad eIDAS: Europe ready to intercept, spy on your encrypted HTTPS connections</a></li>
</ul>
<p>Yet the European Commission still appears to believe there's a way to have bypassable strong end-to-end encryption while respecting privacy rights and maintaining operational security, <a target="_blank" href="https://www.theregister.com/2015/04/28/us_politicians_complain_that_silicon_valley_cant_create_encryption_unicorn/">flying in the face</a> of mathematics. And it has evidently persisted in that belief based on consultations with so-called experts.</p>
<p>But the commission refused to identify the experts who helped draft the text related to scanning encrypted communications – which prompted the ICCL complaint.</p>

        

<p>"Numerous experts have warned that it is not technically feasible," the ICCL <a target="_blank" rel="nofollow" href="https://www.iccl.ie/news/ombudsman-european-commissions-concealment-of-secret-expert-list-on-csam-regulation-constitutes-maladministration/">said</a> in response to the Ombudsman's decision.</p>
<p>"Public <a target="_blank" rel="nofollow" href="https://cdt.org/wp-content/uploads/2023/05/2023-05-16-Letter-from-Public-Interest-Technologists.pdf">interest technologists</a> and more than <a target="_blank" rel="nofollow" href="https://docs.google.com/document/d/13Aeex72MtFBjKhExRTooVMWN9TC-pbH-5LEaAbMF91Y/edit">450 academics</a> have warned in public that 'technology to detect CSAM in encrypted content is currently not mature and will not be mature in the next two to five years.' This is in stark contrast to the views put forward by experts relied upon by the Commission, whose names the Commission is refusing to reveal."</p>
<p>The ICCL expressed concern about the commission's lack of transparency because of allegations about ties between the commission and commercial lobbyists.</p>

        

<p>In September, <a target="_blank" rel="nofollow" href="https://balkaninsight.com/2023/09/25/who-benefits-inside-the-eus-fight-over-scanning-for-child-sex-content/">a report</a> from Balkan Insight – an investigative non-governmental organization – traced how the European CASM proposal has been supported by organizations like <a target="_blank" rel="nofollow" href="https://www.thorn.org/">Thorn</a> that stand to benefit by providing content-scanning software.</p>
<p>On Tuesday, the commission's coyness became less of an obstacle. Member of the European Parliament Patrick Breyer published <a href="https://digitalcourage.social/@echo_pbreyer/111364497308411817" rel="nofollow">the list</a> of experts on Mastodon, and Berlin-based advocacy group Netzpolitik <a target="_blank" rel="nofollow" href="https://netzpolitik.org/2023/geheime-liste-wie-der-sicherheitsapparat-die-chatkontrolle-praegt/#dokument">also did so</a>.</p>
<p>The list of consultants includes five individuals from an organization providing CSAM scanning tools. It also features academics from the Stanford Internet Observatory; industry technologists from Google and Microsoft; representatives from the National Center for Missing and Exploited Children (NCMEC); and agents of the Australian Federal Police, the Spanish Civil Guard, the UK's National Cyber Security Center (NCSC) and Government Communications Headquarters (GCHQ), and Europol.</p>
<p>Pointing to the findings of the Balkan Insights report, Ross Anderson, professor of security engineering at the UK's University of Cambridge, characterized the European Commission's refusal to publish the names of consulting experts as part of an broad attempt to undermine encryption by businesses that would benefit from content scanning contracts. This was aided by government intelligence services that fear being unable to listen in on important conversations happening through encrypted communications tools, such as Signal.</p>
<p>"We now have crypto war 3.0 coming upon us," Anderson told <em>The Register</em> in an interview, "because His Majesty the King advanced yesterday in his speech from the throne that there's going to be an Investigatory Powers Bill amendments act which, among other things, will give his majesty's ministers the powers to demand that … if you want to sell your wares in Britain and you propose to include any see new security features, <a target="_blank" href="https://www.theregister.com/2023/11/07/ukgov_wants_prior_notice_of/">you've got to</a> disclose them to His Majesty's government first." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeBSD 14.0 has reached – RELEASE (189 pts)]]></title>
            <link>https://lists.freebsd.org/archives/dev-commits-src-all/2023-November/033349.html</link>
            <guid>38219578</guid>
            <pubDate>Fri, 10 Nov 2023 14:54:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.freebsd.org/archives/dev-commits-src-all/2023-November/033349.html">https://lists.freebsd.org/archives/dev-commits-src-all/2023-November/033349.html</a>, See on <a href="https://news.ycombinator.com/item?id=38219578">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="main">
    <label for="invert"></label>
    <header>
    
    <ul>
    
    
    <li><strong><i>Go to: </i></strong> [ <a href="#footer">bottom of page</a> ] [ <a href="https://lists.freebsd.org/archives/dev-commits-src-all/index.html">top of archives</a> ] [ <a href="https://lists.freebsd.org/archives/dev-commits-src-all/2023-November/index.html">this month</a> ] </li>
    </ul>
    </header>
    <strong><i>From:</i></strong> Glen Barber  &lt;gjb_at_FreeBSD.org&gt;<br>
    <strong><i>Date:</i></strong> Fri, 10 Nov 2023 00:03:03 UTC <br>
    <pre>The branch releng/14.0 has been updated by gjb:

URL: https://cgit.FreeBSD.org/src/commit/?id=f9716eee8ab45ad906d9b5c5233ca20c10226ca7

commit f9716eee8ab45ad906d9b5c5233ca20c10226ca7
Author:     Glen Barber &lt;gjb@FreeBSD.org&gt;
AuthorDate: 2023-11-09 23:38:09 +0000
Commit:     Glen Barber &lt;gjb@FreeBSD.org&gt;
CommitDate: 2023-11-09 23:38:09 +0000

    release: update releng/14.0 to -RELEASE
    
    - Add UPDATING entry anticipating the announcement date.
    - Set a static __FreeBSD_version in crtbrand.S.
    - Update BRANCH to reflect RELEASE.
    
    Approved by:    re (implicit)
    Sponsored by:   GoFundMe https://www.gofundme.com/f/gjbbsd
    Sponsored by:   PayPal https://paypal.me/gjbbsd
---
 UPDATING                  | 3 +++
 lib/csu/common/crtbrand.S | 2 +-
 sys/conf/newvers.sh       | 2 +-
 3 files changed, 5 insertions(+), 2 deletions(-)

diff --git a/UPDATING b/UPDATING
index 58eeafa44bba..c32c3b7ec940 100644
--- a/UPDATING
+++ b/UPDATING
@@ -12,6 +12,9 @@ Items affecting the ports and packages system can be found in
 /usr/ports/UPDATING.  Please read that file before updating system packages
 and/or ports.
 
+20231114:
+	FreeBSD 14.0-RELEASE.
+
 20231108:
 	14.0-RC4-p1 SA-23:15.stdio
 		    SA-23:16.cap_net
diff --git a/lib/csu/common/crtbrand.S b/lib/csu/common/crtbrand.S
index 0ed86bfba2b2..9ed2d10f5210 100644
--- a/lib/csu/common/crtbrand.S
+++ b/lib/csu/common/crtbrand.S
@@ -43,7 +43,7 @@
 	.4byte		NT_FREEBSD_ABI_TAG
 1:	.asciz		NOTE_FREEBSD_VENDOR
 2:	.p2align	2
-3:	.4byte		__FreeBSD_version
+3:	.4byte		1400097
 4:
 
 	.section .note.GNU-stack,"",%progbits
diff --git a/sys/conf/newvers.sh b/sys/conf/newvers.sh
index b40c56ae759c..a2b89f3caca7 100644
--- a/sys/conf/newvers.sh
+++ b/sys/conf/newvers.sh
@@ -53,7 +53,7 @@
 
 TYPE="FreeBSD"
 REVISION="14.0"
-BRANCH="RC4-p1"
+BRANCH="RELEASE"
 if [ -n "${BRANCH_OVERRIDE}" ]; then
 	BRANCH=${BRANCH_OVERRIDE}
 fi
</pre>
    
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft lays hands on login data: Beware of the new Outlook (215 pts)]]></title>
            <link>https://www.heise.de/news/Microsoft-lays-hands-on-login-data-Beware-of-the-new-Outlook-9358925.html</link>
            <guid>38219568</guid>
            <pubDate>Fri, 10 Nov 2023 14:54:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/news/Microsoft-lays-hands-on-login-data-Beware-of-the-new-Outlook-9358925.html">https://www.heise.de/news/Microsoft-lays-hands-on-login-data-Beware-of-the-new-Outlook-9358925.html</a>, See on <a href="https://news.ycombinator.com/item?id=38219568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        





<a-collapse has-indicator="">
  
  <div data-collapse-target="">
      
  <nav>
    <ol>
        

        <li>

          
            <span aria-current="page">
              Microsoft lays hands on login data: Beware of the new Outlook
            </span>

            
              <ul>
              
                <li>
                
                  <a href="#nav_new_outlook__0" title="New Outlook: Warning about data transfers" data-google-interstitial="false">
                    New Outlook: Warning about data transfers
                  </a>
                
                </li>
              
                <li>
                
                  <a href="#nav_other_accounts_1" title="Other accounts" data-google-interstitial="false">
                    Other accounts
                  </a>
                
                </li>
              
                <li>
                
                  <a href="#nav_eu_data__2" title="EU Data Protection Institutions get involved" data-google-interstitial="false">
                    EU Data Protection Institutions get involved
                  </a>
                
                </li>
              
              </ul>
            

          

        </li>
    </ol>

    

    

  </nav>

    </div>
  
</a-collapse>


      

      <p>(This is a translation of <a href="https://www.heise.de/news/Microsoft-krallt-sich-Zugangsdaten-Achtung-vorm-neuen-Outlook-9357691.html">this german article.</a>)</p>

    
  

  
  <a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
    

  
    
    
  

  </a-paternoster>



<p>The new Outlook is not what it seems at first glance: a replacement for Microsoft Office Outlook - at least not yet. What it definitely is, however: way too curious.</p>
<p>Microsoft is singing the praises of the new Outlook and wants to persuade users to switch. But beware: if you try out the new Outlook, you risk transferring your IMAP and SMTP credentials of mail accounts and all your emails to Microsoft servers. Although Microsoft explains that it is possible to switch back to the previous apps at any time, the data will already be stored by the company. This allows Microsoft to read the emails.</p>





  

<a-lightbox src="/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png">
      



<img alt="Start menu shows new Outlook as recommendet app" decoding="async" height="725" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/639/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png 1008w,
    https://heise.cloudimg.io/width/639/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png 639w,
    https://heise.cloudimg.io/width/1278/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/startmenue-09ab35eabcf56344.png 1278w
  " width="639" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>The Windows Start menu shows new Outlook as recommendet App after installing Win11 2023 update.</p>
      
        <p>
      (Bild:&nbsp;Screenshot / rei)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<p>The new Outlook now appears as a recommended app in the Windows Start menu of Windows 11 devices with the 2023 update. The Outlook client itself also offers to test the new Outlook version with a "The new Outlook" switch. This is still under development, but is set to replace the mail program and the calendar included in Windows in 2024. In a <a href="https://techcommunity.microsoft.com/t5/outlook-blog/things-to-look-forward-to-in-the-new-outlook-for-windows/ba-p/3975602" rel="external noopener" target="_blank">recent tech community article, Microsoft employee Caitlin Hart</a> also explains that it will also replace the classic Outlook. However, unlike the Windows Mail and Calendar apps, the timetable for this has not yet been set.</p>

  





<h3 id="nav_new_outlook__0">New Outlook: Warning about data transfers</h3>
<p>When adding a mail account in the new Outlook that is not hosted by Microsoft but is located on company mail servers, for example, the program displays a message. It <a href="https://support.microsoft.com/en-us/office/sync-your-account-in-outlook-to-the-microsoft-cloud-985f9e19-d308-4e85-9d1d-0c6f32f8e981" rel="external noopener" target="_blank">links to a support article</a> that simply states that non-Microsoft accounts are synchronized with the Microsoft cloud, whereby Gmail, Yahoo, iCloud and IMAP accounts are currently supported. The new Outlook also does this in the versions for Android, iOS and Mac. This means that copies "of your email, calendar, and contacts will be synchronized between your email provider and Microsoft data center". This gives the company full access to all emails and allows it to read and analyze them. Microsoft wants to provide functions that way that Gmail and IMAP do not offer.</p>








  

<a-lightbox src="/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png">
      



<img alt="Warning message of the new Outlook version when adding a non-Microsoft account" decoding="async" height="549" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/477/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png 1008w,
    https://heise.cloudimg.io/width/477/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png 477w,
    https://heise.cloudimg.io/width/954/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/01-Outlook-warning-10fec3fb04175d74.png 954w
  " width="477" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>The new Outlook shows a message that it sends data to Microsoft Cloud servers.</p>
      
        <p>
      (Bild:&nbsp;Screenshot / rei)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<p>The note makes you wonder: What does Microsoft transfer where? When creating an IMAP account, c't was able to sniff the traffic between new Outlook and the Microsoft servers. It contained the target server, log-in name and password which were sent to those Servers of Microsoft. Although TLS-protected, the data is sent to Microsoft in plain text within the tunnel. Without informing or inquiring about this, Microsoft grants itself access to the IMAP and SMTP login data of users of the new Outlook.</p>





  

<a-lightbox src="/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png">
      



<img alt="Traffic snippet which went from new Outlook to Microsoft servers" decoding="async" height="465" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/594/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png 1008w,
    https://heise.cloudimg.io/width/594/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png 594w,
    https://heise.cloudimg.io/width/1188/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/6/5/5/02-outlook-en-11-cut-34652a663a7f018d.png 1188w
  " width="594" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>When adding an IMAP account, new Outlook sent login data and server information to Microsoft.</p>
      
        <p>
      (Bild:&nbsp;Screenshot)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<h3 id="nav_other_accounts_1">Other accounts</h3>
<p>When switching from the old Outlook to the new one, it is installed the new software in parallel. Previously set up IMAP accounts are not automatically transferred, but the account stored in Windows is. During the test with Google accounts, authentication with OAuth2 was used. Users receive an authentication request and Microsoft does not receive any specific access data, but only an access token that users can revoke again.</p>
<p>An answer to our request for a statement from Microsoft is still pending. At this point in time, however, we must warn against trying out the new Outlook without thinking. In addition to all the emails, some credentials may even end up with Microsoft.</p>
<p>Microsoft already attracted attention with such data redirections at the beginning of the year. After Office updates were applied on Mac computers, Outlook redirected the data to Microsoft's cloud servers without any user notification. At that time, the remedy was to delete IMAP accounts and set them up again. However, this is obviously no longer helpful with the new Outlook.</p>
<h3 id="nav_eu_data__2">EU Data Protection Institutions get involved</h3>
<p>The Federal Commissioner for Data Protection and Freedom of Information of Germany, Professor Ulrich Kelber, is alarmed by the data detour in Microsoft's new Outlook. <a href="https://social.bund.de/@bfdi/111381793883035665" rel="external noopener" target="_blank">He posted on Mastodon that he wants</a> to ask for a report from the Irish Data Protection Commissioner, who is responsible for companies like Microsoft, during a meeting of the European data protection supervisory authorities on Tuesday of the coming week.</p>



<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:dmk@heise.de" title="Dirk Knop">dmk</a>)</span>
<!-- RSPEAK_START -->
</p>

      <!-- RSPEAK_STOP -->

      

      

      

      <!-- RSPEAK_STOP -->

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nordic Is Getting Involved in RISC-V (287 pts)]]></title>
            <link>https://blog.nordicsemi.com/getconnected/why-nordic-is-getting-involved-in-risc-v</link>
            <guid>38218667</guid>
            <pubDate>Fri, 10 Nov 2023 13:42:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nordicsemi.com/getconnected/why-nordic-is-getting-involved-in-risc-v">https://blog.nordicsemi.com/getconnected/why-nordic-is-getting-involved-in-risc-v</a>, See on <a href="https://news.ycombinator.com/item?id=38218667">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-column">
          
          
          <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><img src="https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=1000&amp;height=563&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png" width="1000" height="563" loading="lazy" alt="Nordic chip" srcset="https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=500&amp;height=282&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 500w, https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=1000&amp;height=563&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 1000w, https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=1500&amp;height=845&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 1500w, https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=2000&amp;height=1126&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 2000w, https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=2500&amp;height=1408&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 2500w, https://blog.nordicsemi.com/hs-fs/hubfs/Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png?width=3000&amp;height=1689&amp;name=Why%20Nordic%20is%20getting%20involved%20with%20RISC-V.png 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p>Nordic recently <span><a href="https://www.nordicsemi.com/Nordic-news/2023/08/Leading-Semiconductor-Industry-Players-Join-Forces-to-Accelerate-RISC-V" rel="noopener" target="_blank">announced</a></span> that it is joining an industry consortium of semiconductor companies to drive the adoption of an open source chip architecture called RISC-V. Why?</p>
<h2><!--more--><strong>RISC-V versus Arm</strong></h2>
<p>At first glance, Nordic announcing that it is putting its full technological and commercial weight behind the development and adoption of an open-source chip architecture might raise questions about how strong the company’s on-going relationship with Arm is.</p>
<p>After all, Arm provides a commercial chip architecture that is anything but open source, and has been used on Nordic's semiconductor wireless connectivity products since the 2012 launch of Nordic's nRF51 Series Systems-on-Chip (SoCs).</p>
<p>The nRF51 Series redefined the leading-edge of the Bluetooth LE market once and for all. And one of the biggest innovations was the inclusion of a powerful on-board Arm processor for the very first time on a Bluetooth chip. Nothing like it had ever been seen before in the Bluetooth LE market. In fact, the nRF51 Series literally sent Nordic's competitors scrambling back to the drawing board when it came to how to design a Bluetooth LE chip.</p>
<h2><strong>RISC-V will complement Arm</strong></h2>
<p>RISC-V was developed about 10 years ago at <span><a href="https://bar.eecs.berkeley.edu/projects/riscv.html" rel="noopener" target="_blank">UC Berkeley</a></span> in the U.S. and at first glance would seem to be competitive with Arm.</p>
<p>But I think this is way too narrow a view. I see RISC-V in a similar way to how I see the proliferation of wireless IoT connectivity standards: no one technology can be all things to (solve) all application problems. So does Bluetooth LE really compete with Thread or cellular IoT ? Of course not. Each is designed to do different things well, but not everything.</p>
<p>What RISC-V is in reality, therefore, is a complimentary alternative to Arm, and not a threat. And this is particularly true in power consumption-critical mobile and IoT applications where Arm has traditionally been dominant.</p>
<h2><strong>Optimizing for lowest power</strong></h2>
<p>At its heart, RISC-V is all about promoting innovation by giving users the ability to develop leading-edge, customized hardware based on an open-source chip architecture.</p>
<p>What RISC-V will do for Nordic's customers is give them the freedom and flexibility, in certain specific and highly specialized applications, to strip down the instruction set to ensure extreme levels of low power consumption.</p>
<p>To me, this is no different to how you can strip down a 2.4GHz proprietary wireless protocol to optimize for the ultra lowest power consumption in a way you simply could not match at such extremes with a standards-based protocol such as Bluetooth low energy.</p>
<p>Now RISC-V isn't of course proprietary. But just like a Nordic proprietary 2.4GHz protocol, if you are the developer behind it, you get far more control over every line of code to customize for the specific needs of your specific application.</p>
<h2><strong>Lowest power counts at the edge</strong></h2>
<p>So where might the ability to develop an ultra lowest power instruction set really come into its own?</p>
<p>To me it's at the edge in, for example, simpler embedded chips for sensors that require a small bit of processing power in order to deliver localized machine learning.</p>
<p>In such applications having an Arm core would be complete overkill. But that sensor may still need to communicate with and work alongside an Arm core-based Nordic device.</p>
<h2><strong>More options</strong></h2>
<p>What RISC-V will do is give our customers an extra option when seeking to minimize power consumption in certain applications where the (many) tradeoffs of not using an Arm-based core are acceptable.</p>
<p>RISC-V will also lower the barriers-to-entry and level the playing field when it comes to developing IoT applications. This will encourage even greater innovation in the IoT market.</p>
<p>What RISC-V will not do is conflict with Nordic's long-established use of Arm cores in its wireless IoT connectivity devices.</p>
<p>RISC-V will simply further enhance the design options for Nordic customers and particularly in simpler, ultra lowest power applications where every Joule and Watt counts.</p>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-2fcdd921-231d-4a6f-95b3-541ff0c6e70a"><span id="hs-cta-2fcdd921-231d-4a6f-95b3-541ff0c6e70a"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/1961165/2fcdd921-231d-4a6f-95b3-541ff0c6e70a"><img id="hs-cta-img-2fcdd921-231d-4a6f-95b3-541ff0c6e70a" src="https://no-cache.hubspot.com/cta/default/1961165/2fcdd921-231d-4a6f-95b3-541ff0c6e70a.png" alt="Subscribe to&nbsp; The Get Connected Blog"></a></span></span><!-- end HubSpot Call-to-Action Code --></p></span>
          </p>
    </div><div id="blogg-sidekolonne">
      <!-- RELATED ARTICLES -->
      <div id="rel-articles">
        <h3>Related articles</h3>
        
      </div>
      <!-- SUBSCRIBE -->
      <div id="subscribe">
        <h3>Subscribe to the blog</h3>
        
      </div>
      <!-- DEV-ZONE -->
      <div id="devzone">
        <p><img src="https://blog.nordicsemi.com/hubfs/Logo/DevZone_splash%20page.png" alt="DevZone-logo uten bakgrunn"></p><p>If you are a Developer, you may want to check out our blogs and Developer guides in the DevZone</p>
        <a href="https://devzone.nordicsemi.com/" rel="external" target="_blank"><p><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path>
        </svg>Explore DevZone</p></a>
      </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We're sorry we created the Torment Nexus (271 pts)]]></title>
            <link>http://www.antipope.org/charlie/blog-static/2023/11/dont-create-the-torment-nexus.html</link>
            <guid>38218580</guid>
            <pubDate>Fri, 10 Nov 2023 13:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.antipope.org/charlie/blog-static/2023/11/dont-create-the-torment-nexus.html">http://www.antipope.org/charlie/blog-static/2023/11/dont-create-the-torment-nexus.html</a>, See on <a href="https://news.ycombinator.com/item?id=38218580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="more">
            <p>Obviously, I'm talking about Elon Musk. (He named SpaceX's drone ships after Iain M. Banks spaceships, thereby proving that irony is dead). But he's not the only one. There's Peter Thiel (who funds research into artificial intelligence, life extension, and seasteading. <a href="https://www.vanityfair.com/news/2016/08/peter-thiel-wants-to-inject-himself-with-young-peoples-blood">when he's not getting blood transfusions from 18 year olds</a> in hope of living forever). Marc Andreesen of Venture Capitalists Andreesen Horowitz recently published a self-proclaimed "<a href="https://a16z.com/the-techno-optimist-manifesto/">techno-optimist manifesto</a>" promoting the bizarre accelerationist philosophy of Nick Land, among other weirdos, and hyping the current grifter's fantasy of large language models as "artificial intelligence". Jeff Bezos, founder of Amazon, is another. He's another space colonization enthusiast like Elon Musk, but while Musk wants to homestead Mars, Bezos is a fan of Gerard K. O'Neill's 1970s plan to build giant orbital habitat cylinders at the Earth-Moon L5 libration point. And no tour of the idiocracy is complete without mentioning Mark Zuckerberg, billionaire CEO of Facebook, who blew through ten billion dollars trying to create the Metaverse from Neal Stephenson's novel <em>Snow Crash</em>, only for it to turn out that his ambitious commercial virtual reality environment had no legs.</p>

<p>(That was a deliberate pun.)</p>

<p>It'd be amusing if these guys didn't have a combined net worth somewhere in the region of half a trillion euros and the desire to change the human universe, along with a load of unexamined prejudices and a bunch of half-baked politics they absorbed from the predominantly American SF stories they read in their teens. I grew up reading the same stuff but as I also write the modern version of the same stuff for a living I've spent a lot of time lifting up the rocks in the garden of SF to look at what's squirming underneath.</p>

<p>Science fiction influences everything this century, both our media and our physical environment. Media first: about 30% of the big budget movies coming out of the US film industry these days are science fiction or fantasy blockbusters, a massive shift since the 1970s. Computer games are wall-to-wall fantasy and SF—probably a majority of the field, outside of sports and simulation games. (Written fiction is another matter, and SF/F combined amount to something in the range 5-10% of books sold. But reading novels is a minority recreation this century, having to compete with the other media I just named. The golden age of written fiction was roughly 1850 to 1950, give or take a few decades: I make my living in an ageing field, kind of like being a classical music composer or an 8-bit games programmer today.)</p>

<p>Meanwhile the influence of science fiction on our environment seems to have been gathering pace throughout my entire life. The future is a marketing tool. Back in the early 20th century it was anything associated with speed—recall the fad for streamlining everything from railway locomotives to toasters, or putting fins on cars. Since about 1970 it becme more tightly associated with communication and computers. </p>

<p>For an example of the latter trend:  a decade or two ago there was a fad for cellular phones designed to resemble the original Star Trek communicator. The communicator was movie visual shorthand for "a military two-way radio, but make it impossibly small". But it turns out that enough people <em>wanted</em> an impossibly small clamshell telephone that once semiconductor and battery technology got good enough to make one, they made the Motorola Razr a runaway bestseller. </p>

<p>"Artificial intelligence" and "computer controlled" became marketing buzzwords decades ago. They're used to mis-sell cars described as "self-driving" and technologies like Tesla's so-called "autopilot". In reality, aircraft autopilots don't do what most people think they do (they require constant monitoring by pilots). And self-driving car software is dangerously insufficient to do the job, as witness the recent revelation that self-driving taxi firm Cruise—recently banned from San Fracisco after a pedestrian was dragged under one of their cars—requires constant human supervision. But as long as it sells cars to customers who think it means they can relax and watch a movie while they commute, why should Elon Musk care? Science fictional TV shows like "Knight Rider" in the 1980s primed those of us who grew up in the 1970s and 1980s to expect intelligent self-driving cars in the near future, and there has been a gold rush to sell self-driving cars, even though the technology isn't ready yet and has lethal failure modes. Because anything that tastes of the future is marketing gold.</p>

<p>It's becoming increasingly unusual to read a report of a new technology or scientific discovery that <em>doesn't</em> breathlessly use the phrase "it seems like science fiction".  The news cycle is currently dominated by hype about artificial intelligence (a gross mis-characterisation of machine learning algorithms and large language models). A couple of years ago it was breathless hype about cryptocurrency and blockchain technologies—which turned out to be a financial services bubble that drained a lot of small investors' savings accounts into the pockets of people like convicted fraudster Sam Bankman-Fried. </p>

<p>It's also driving politics and law. Recently in the UK, Elon Musk paid a visit to Prime Minister Rishi Sunak. Last week we were given a preview of the government's legislative program for the coming year, and guess what it contained? Yes: new laws to permit self-driving vehicles on the roads, and regulation of artificial intelligence. And while some degree of government monitoring and regulation of these sectors is welcome, the UK has much bigger problems right now—and I'd rather the laws weren't drafted by an Elon Musk fanboy.</p>

<p>Now I've shouted as passing clouds for a bit—or dangerous marketing fads based on popular entertainment of decades past—I'd like to talk about something that I personally find much more worrying: a political ideology common among silicon valley billionaires of a certain age—known by the acronym TESCREAL—that is built  on top of a shaky set of assumptions about the future of humanity. It comes straight out of an uncritical reading of the bad science fiction of decades past, and it's really dangerous. </p>

<p>TESCREAL stands for "transhumanism, extropianism, singularitarianism, cosmism, rationalism (in a very specific context), Effective Altruism, and longtermism." It was identified by Timnit Gebru, former technical co-lead of the Ethical Artificial Intelligence Team at Google and founder of the Distributed Artificial Intelligence Research Institute (DAIR), and Émile Torres, a philosopher specialising in existential threats to humanity. These are separate but overlapping beliefs that are particularly common in the social and academic circles associated with big tech in California. Prominent advocates on the transhumanist and AI side include Ray Kurzweil, a notable technology evangelist and AI researcher at Google, philosophers Nick Bostrom and Eliezer Yudkowsky, and going back a long way earlier, Russian rocket scientist Konstantin Tsiolkovsky, whose writings brought Russian Cosmism to America. Sam Bankman-Fried is an outspoken advocate of Effective Altruism, another element of this overlapping web of beliefs. Elon Musk and Jeff Bezos, as noted, both seem to be heavily influenced by Tsiolkovsky's advocacy of space colonization. Musk's Neuralink venture, attempting to pioneer human brain-computer interfaces, seems intent on making mind uploading workable, which in turn points to the influences of Kurzweil and other singularitarians. And hiding behind these 20th and early 21st century thinkers are older influences—notably the theological speculation of 19th century Russian Orthodox priest Nikolai Fedorovich Fedorov.</p>

<p>How did this ideology come about, and why do I think it's dangerous?</p>

<p>(Longtermism is the belief that we should discount short-term harms to real existing human beings—such as human-induced climate change—if it brings us closer to the goal of colonizing the universe, because the needs of trillions of future people <em>who don't actually exist yet</em> obviously outweigh the needs of today's global poor. If you accept that it's our destiny as a species to take over the cosmos, then it follows that longtermist entrepreneurs are perfectly justified in moving fast, breaking things, and ruthlessly maximizing profit extraction, as long as they spend their wealth on colonizing Mars. Which is just the first step on the road to conquering the galaxy and a bunch of other stuff like mind uploading, becoming immortal, creating artificial intelligences to do all the tedious work, resurrecting the dead, and taking over the universe. It posits a destiny for humanity, which of necessity makes it a secular religion. It means that if you don't believe in their plans, then you're some kind of anti-science backsliding reactionary heretic. And if this sounds just slightly insane to you, well, that's probably because you're not Elon Musk or Peter Thiel.)</p>

<p>Speaking as a science fiction writer, I'd like to offer a heartfelt apology for my part in the silicon valley oligarchy's rise to power. And I'd like to examine the toxic role of science fiction in providing justifications for the craziness.</p>

<p>So, here's the thing: science fiction is <em>fiction</em>. And while we can dress it up in fancy clothes and declare that fiction is an artistic form for exploring the human condition, we're tip-toeing past the slaughterhouse with attached sausage factory—the industry that takes the raw material and puts it in front of us. As an editor once told me, "you can write anything you want, but we don't have to publish it." And without publishers, or some mechanism for replicating and advertising the existence of your text, you won't have any readers.</p>

<p>[[ 
Publishers, incidentally, are not monolithic. They're hives of human activity where people working in different departments each do their bit to try and turn the product they're taking in at one end—raw book manuscripts are about as appetizing as a raw animal carcass, they take a lot of work to make them appealing—into saleable books or tasty-looking sausages. I'm not going to get into the minutiae of trade publishing or we'd be here for the rest of the year, but as an author, my job is to convince an editor to buy my book. The editor's job is then to convince the marketing department that this book is commercially viable. And the marketing department try to push it in the very specific media channels that bookshop staff read to decide what products to order in next month. So there's a long chain of whispers between the author and the reader, and because a book that doesn't sell will cost each intermediary money, and there are hundreds of books per month to choose between, it's easier for them to say "no" than to say "yes".</p>

<p>I'm focussing here on a very specific channel, namely novels that are written and sold via traditional big publishing companies. Different constraints apply to different formats and different sales channels -- say, short fiction or web serials, sold via anthologies or self-published direct to Kindle or other ebook storefronts. But there's almost always a middle-man, even if you're self-publishing (the middle-man in this case is Patreon or Ko-Fi or Amazon an ad exchange somewhere: it's whoever processes payments for you). The only way to completely avoid middle-men is to give your work away for free. </p>

<p>The same is true of other media, such as film, TV, music, and games. If you refuse to compromise with your audience's expectations they will put the book down, flip channel, or leave a one-star review on Steam.</p>

<p>So I exist in a symbiotic relationship with my readers. They keep buying my books as long as they remain enjoyable. And my publishers keep publishing my books as long as the readers keep buying them. So like other SF writers I've got a financial incentive to write books that readers find enjoyable, and that usually means conforming to their pre-existing biases. Which are rooted in the ideas they absorbed previously. Science fiction as a genre has <em>inertia</em>, and it's hard to get new ideas to stick if they force the readers out of their comfort zone. </p>

<p>The science fiction genre that today's billionaires grew up with—the genre of the 1970s—has a history going back to an American inventor and publisher called Hugo Gernsback. Gernsback founded the first magazine about electronics and radio in the United States, <em>Modern Electrics</em>, in 1908, but today he's best remembered as the founder of the pulp science fiction magazine <em>Amazing Stories</em> in 1926. </p>

<p>The early 1908 issues of <em>Modern Electrics</em> would be instantly recognizable to a teenage personal computing enthusiast of the 1970s and early 1980s—the same generation as the tech billionaires this talk is really about. The first two decades of the 20th century saw a huge explosion of interest in the field of wireless—radio broadcasting as we know it today, but also amateur radio. Radio sets back then were hand-built and repaired by local enthusiasts, much like many early personal computers. Gernsback founded <em>Modern Electrics</em> to carry adverts for radio components and to promote the amateur radio hobby. He curated a directory of amateur radio users and their call signs and equipment, published articles about building and operating your own wireless set, and editorialized  about the future of radio. Amateur radio grew explosively in the nineteen-teens, and just like computer hobbyists half a century later, many of the radio hobbyists ended up working in the industry. </p>

<p>Gernsback began to publish general articles about science and technology, then fiction  with a focus on the science—including some of his own stories—culminating in starting the magazine <em>Amazing Stories</em> as a vehicle for fantastic tales about a technological future. And as a runaway commercial success, <em>Amazing Stories</em> spawned imitators and, eventually, an industry.</p>

<p>(We can skip over the details of how SF publishing developed from the earnest technophiliac visions of Gernsback to the two-fisted planetary romances of the pulp magazines in the 1920s, survived the collapse of the pulp magazine distribution network in the 1950s and migrated to paperback novels sold in wire racks in supermarkets, then colonized the heights of the publishing industry bestseller lists from the 1960s onwards.)</p>

<p>American SF was bootstrapped by a publisher feeding an engineering subculture with adverts for tools and components. There was an implicit ideology attached to this strain of science fiction right from the outset: the American Dream of capitalist success, mashed up with progress through modern technology, and a side-order of frontier colonialism. It's not a coincidence that the boom in planetary romances occured shortly after the American frontier was finally closed: the high frontier had a natural appeal and gradually replaced the western frontier in the popular imagination.</p>

<p>(As futurist and SF author Karl Schroeder remarks, every technology has political implications. If you have automobiles you will inevitably find out that you need speed limits, drunk driving laws, vehicle and driver licensing to ensure the cars and their drivers are safe ... and then jaywalking laws, the systematic segregation of pedestrians and <em>non</em>-automotive traffic from formerly public spaces, air pollution, and an ongoing level of deaths and injuries comparable to a small war. You also get diversion of infrastructure spending from railways to road building, and effective limits on civil participation by non-drivers.</p>

<p>The new radio enthusiast magazine readers Gernsback was cultivating didn't ask about the politics of radio, although it would come back to bite them in the 1930s with increased  regulation, then state censorship and the use of wireless broadcasts for wartime propaganda. They were just having fun and maybe trying to build a local radio repair shop. But there's been a tendency in American SF, ever since those early days, to be wilfully blind to the political implications of the shiny toys.)</p>

<p>There is a darker element to this era of science fiction. Gernsback's publishing empire arose around the time the Italian poet Filippo Tommaso Marinetti published his Manifesto of Futurism (in 1909). Futurism <em>was</em> an explicitly ideological program—an artistic movement that  rejected of the past and celebrated speed, machinery, violence, youth and industry, and argued for the modernization and cultural rejuvenation of the Italian state. In 1918 Marinetti founded a Futurist Party, but a year later it merged with Benito Mussolini's movement, and Marinetti is credited as the co-author of the Fascist Manifesto of 1919. </p>

<p>Hugo Gernsback didn't consciously bring fascism into American SF, but the field was open to it by the 1930s. Possibly the most prominent contributor to far right thought in American science fiction was the editor John W. Campbell. Campbell edited <em>Astouding Science Fiction</em>, one of <em>Amazing Stories</em> rivals, from 1937 until 1971. (<em>Astounding</em> is still with us today, having changed its name to <em>Analog</em> in 1960.) Campbell discovered or promoted many now-famous authors, including Robert Heinlein, Isaac Asimov, E. E. Smith, and Jack Williamson. But Campbell was also an anti-communist red-baiter. He was overtly racist, an anti-feminist, and left his imprint on the genre as much by what he <em>didn't</em> publish as by what he did—and how he edited it. For example, Tom Godwin's classic short story <em>The Cold Equations</em> was sent back with editorial change requests three times before Godwin finally gave Campbell the ending he wanted: one that, as Cory Doctorow put it, turned the story "into a parable about the foolishness of women and the role of men in guiding them to accept the cold, hard facts of life". </p>

<p>Later in his career, Campbell fell victim to just about every pseudoscientific grift that was going. (If he was alive today he'd probably be selling NFTs.) He had a weakness for perpetual motion machines, was an enthusiast for Dianetics (which L. Ron Hubbard later turned into the Church of Scientology), and he was a firm believer in paranormal powers -- telepathy, telekinesis, and astral projection, (all now thoroughly disproven by research at the Koestler Institute of Parapsychology). </p>

<p>(Confirmation bias may have been at work here: a belief in psi powers implicitly supports an ideology of racial supremacy, and indeed, that's about the only explanation I can see for Campbell's publication of the weirder stories of A. E. Van Vogt.)</p>

<p>Campbell wasn't the only wellspring of right-wing thought in golden age SF. No quick tour would be complete without mentioning Ayn Rand, the Russian emigre and bestselling author who invented the far right philosophy of Objectivism. This centred (quote) "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute". Reason which, of course, was positioned as emotionless, neutral, factually grounded, and thereby  exempt from accusations of bias and subjectivity. Rand held that the only social system compatible with this obviously-correct philosophy was laissez-faire capitalism: you can probably see why this appeals to sociopathic billionaires and their fans.</p>

<p>Perhaps the weirdest ingredient in the mix of ideas that gave rise to what became known in the 1990s as the Californian Ideology is Russian Cosmism, the post-1917 stepchild of the mystical theological speculation of a Russian Orthodox theologian, Nikolai Fyodorovitch Fyodorov. </p>

<p>The Internet Encyclopaedia of Philosophy is your one-stop shop for batshit philosophers who unduly influenced the space program and gave rise to modern Transhumanism. As it notes: "Nikolai Fedorovich Fedorov (born 1829, died 1903), was founder of an immortalist (anti-death) philosophy emphasizing "the common task" of resurrecting the dead through scientific means."</p>

<p>The illegitimate son of a Russian prince, Federov grew up a devout Russian Orthodox Christian. He worked as a librarian and as a teacher, and through his writings he was the formative influence on the Russian cosmists, a Russian philosophical movement that prefigured transhumanism (and specifically extropianism). The cosmists in turn influenced Tsiolkovsky, who was a major inspiration for Soviet attitudes to space exploration.</p>

<blockquote>
  <p>"Fedorov found the widespread lack of love among people appalling. He divided these non-loving relations into two kinds. One is alienation among people: 'non-kindred relations of people among themselves.' The other is isolation of the living from the dead: 'nature's non-kindred relation to men.'" ... "A citizen, a comrade, or a team-member can be replaced by another. However a person loved, one's kin, is irreplaceable. Moreover, memory of one's dead kin is not the same as the real person. Pride in one's forefathers is a vice, a form of egotism. On the other hand, love of one's forefathers means sadness in their death, requiring the literal raising of the dead."</p>
</blockquote>

<p>Federov believed in a teleological explanation for evolution, that mankind was on a path to perfectibility determined by god: human mortality was the biggest sign of our imperfection. He argued that the struggle against death would give all humanity a common enemy -- and a victory condition that could be established, in the shape of (a) achieving immortality for all, and (b) resurrecting the dead to share in that immortality. Quite obviously immortality and resurrection for all would lead to an overcrowded world, so Federov also advocated colonisation of the oceans and space: indeed, part of the holy mission would inevitably be to bring life (and immortal human life at that) to the entire cosmos.</p>

<p>(The wikipedia article on Federov discusses his transhumanist program in somewhat more detail than the IEP entry.)</p>

<p>The final word probably deserves to go to Nicholas Berdyaev (secondary source here) who in 1928 wrote, in a collection of liturgical essays on the Orthodox church:</p>

<blockquote>
  <p>The novelty of Fedorov's idea, one which frightens so many people, lies in the fact that it affirms an activity of man incommensurably greater than any that humanism and progressivism believe in. Resurrection is an act not only of God's grace but also of human activity. We now come to the most grandiose and bewildering idea of N. Fedorov. He had a completely original and unprecedented attitude towards apocalyptic prophecies, and his doctrine represents a totally new phenomenon in Russian consciousness and Russian apocalyptic expectation. Never before in the Christian world had there been expressed such an audacious, such an astounding concept, concerning the possibility of avoiding the Last Judgement and its irrevocable consequences, by dint of the active participation of man. If what Fedorov calls for is achieved, then there will be no end to the world. Mankind, with a transformed and definitively regulated nature, will move directly into the life eternal.</p>
</blockquote>

<p>I'm going to confess, at this point, to having in my youth read translations of Tsiolkovsy's writing, but not Federov—he was relatively obscure in the west until recently. The forebears of the American space program—Robert Goddard, Jack Parsons, and of course Wernher Von Braun—also read Tsiolkovsky. And through their writings, his plans for space colonization (and the ideas of Russian cosmism) leaked directly into the minds of science fiction authors like Robert Heinlein, Hal Clement, and Arthur C. Clarke.</p>

<p>Finally, I haven't really described Rationalism. It's a rather weird internet mediated cult that has congealed around philosopher of AI Eliezer Yudkowski over the past decade or so. Yudkowski has taken on board the idea of the AI Singularity—that we will achieve human-equivalent intelligence in a can, and it will rapidly bootstrap itself to stratospheric heights of competence and render us obsolete—and terrified himself with visions of paperclip maximizers, AIs programmed to turn the entire universe into paperclips (or something equally inhospitable to human life) with maximum efficiency. He and his followers then dived into a philosophical rabbit maze of trying to reason their way into minimizing harms arising from a technology that does not yet exist and may not even be possible. (In contrast, Nick Bostrom focussed on the philosophical implications of digitizing human brains so we can all be raptured up to live in the great cloud computer in the sky, a very modern riff on the Christian eschatological theory of resurrection.)</p>

<p>American SF from the 1950s to the 1990s contains all the raw ingredients of what has been identified as the Californian ideology (evangelized through the de-facto house magazine, WIRED). It's rooted in uncritical technological boosterism and the desire to get rich quick. Libertarianism and it's even more obnoxious sibling Objectivism provide a fig-leaf of philosophical legitimacy for cutting social programs and advocating the most ruthless variety of dog-eat-dog politics. Longtermism advocates overlooking the homeless person on the sidewalk in front of you in favour of maximizing good outcomes from charitable giving in the far future. And it gels neatly with the Extropian and Transhumanist agendas of  colonizing space, achieving immortality, abolishing death, and bringing about the resurrection (without reference to god). These are all far more fun to contemplate than near-term environmental collapse and starving poor people. Finally, there's accelerationism: the right wing's version of Trotskyism, the idea that we need to bring on a cultural crisis as fast as possible in order to tear down the old and build a new post-apocalyptic future. (Tommasso Marinetti and Nick Land are separated by a century and a paradigm shift in the definition of technological progress they're obsessed with, but hold the existing world in a similar degree of contempt.)</p>

<p>The hype and boosterism of the AI marketers collided with the Rationalist obsession in the public perception a couple of weeks ago, in the Artificial Intelligence Safety Summit at Bletchley Park. This conference hatched the Bletchley Declaration, calling for international co-operation to manage the challenges and risks of artificial intelligence. It featured Elon Musk being interviewed by Rishi Sunak on stage, and was attended by Kamala Harris, vice-president of the United States, among other leading politicians. And the whole panicky agenda seems to be driven by an agenda that has emerged from science fiction stories written by popular entertainers like me, writers trying to earn a living.</p>

<p>Anyway, for what my opinion is worth: I think this is bullshit. There are very rich people trying to manipulate investment markets into giving them even more money, using shadow puppets they dreamed up on the basis of half-remembered fictions they read in their teens. They are inadvertently driving state-level policy making on subjects like privacy protection, data mining, face recognition, and generative language models, on the basis of assumptions about how society <em>should</em> be organized that are frankly misguided and crankish, because there's no crank like a writer idly dreaming up fun thought experiments in fictional form. They're building space programs—one of them is up front about wanting to colonize Mars, and he was briefly the world's richest man, so we ought to take him as seriously as he deserves—and throwing medical resources at their own personal immortality rather than, say, a wide-spectrum sterilizing vaccine against COVID19. Meanwhile our public infrastructure is rotting, national assets are being sold off and looted by private equity companies, their social networks are spreading hatred and lies in order to farm advertising clicks, and other billionaires are using those networks to either buy political clout or suck up ever more money from the savings of the poor.</p>

<p>Did you ever wonder why the 21st century feels like we're living in a bad cyberpunk novel from the 1980s?</p>

<p>It's because these guys read those cyberpunk novels and mistook a dystopia for a road map. They're rich enough to bend reality to reflect their desires. But we're not futurists, we're entertainers! We like to spin yarns about the Torment Nexus because it's a cool setting for a noir detective story, not because we think Mark Zuckerberg or Andreesen Horowitz should actually pump several billion dollars into creating it. And that's why I think you should always be wary of SF writers bearing ideas.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swedish painters trade union to stop all work with Tesla brand cars (142 pts)]]></title>
            <link>https://www.malarna.nu/om-oss/nyheter/20232/pressmeddelande-malarna-stoppar-lackering-av-tesla-bilar/</link>
            <guid>38218346</guid>
            <pubDate>Fri, 10 Nov 2023 13:08:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.malarna.nu/om-oss/nyheter/20232/pressmeddelande-malarna-stoppar-lackering-av-tesla-bilar/">https://www.malarna.nu/om-oss/nyheter/20232/pressmeddelande-malarna-stoppar-lackering-av-tesla-bilar/</a>, See on <a href="https://news.ycombinator.com/item?id=38218346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Idag har Målarna beslutat att i sympati och solidaritet med IF Metall varsla om blockad mot allt arbete på Teslabilar vid Lackverkstäder som är knutna till Lackavtalet. Blockaden berör samtliga billackeringsföretag och kommer att genomföras i två steg, 53 företag varslas idag den 10 november 2023 och om inget avtal mellan Tesla och IF Metall kommit på plats läggs ytterligare varsel på 56 företag under måndag till tisdag den 13-14 november. (109st sammanlagt).</p>
<p>För Målarna är det en självklarhet att stå sida vid sida med våra systrar och bröder i IF Metall och vi ser även faran i att en så stor och etablerad arbetsgivare utmanar den svenska kollektivavtalsmodellen, därför lägger vi dessa massiva varsel utan motstycke på avtalsområdet.</p>
<p>Målarnas Ordförande Mikael Johansson:” IF Metall företräder oss alla i den här konflikten, det är därför oerhört viktigt att hela fackföreningsrörelsen sluter upp som en och tillsammans tar den här fighten”.</p>
<p><a title="Sympativarsel Tesla 10 november (002).pdf" href="https://www.malarna.nu/siteassets/nyheter/sympativarsel-tesla-10-november-002.pdf?ts=8dbe1fc29104f00">Sympativarsel Tesla 10 november (002).pdf</a></p>
<p>Presskontakt<br>Johan Redén <br>070-309 83 97 <br>johan.reden@malarna.nu</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We used to build steel mills near cheap power. Now we build datacenters (102 pts)]]></title>
            <link>https://danluu.com/datacenter-power/</link>
            <guid>38218114</guid>
            <pubDate>Fri, 10 Nov 2023 12:37:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danluu.com/datacenter-power/">https://danluu.com/datacenter-power/</a>, See on <a href="https://news.ycombinator.com/item?id=38218114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Why are people so concerned with hardware power consumption nowadays? Some common answers to this question are that <a href="http://www.vox.com/2015/3/9/8178213/apple-macbook-all-batteries">power is critically important for phones, tablets, and laptops</a> and that <a href="ftp://ftp.cs.utexas.edu/pub/dburger/papers/ISCA11.pdf">we can put more silicon on a modern chip than we can effectively use</a>. In 2001 <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=912412&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D912412">Patrick Gelsinger observed that if scaling continued at then-current rates</a>, chips would have the power density of a nuclear reactor by 2005, a rocket nozzle by 2010, and the surface of the sun by 2015. Needless to say, that didn't happen. The importance of portables and scaling limits are both valid and important reasons, but since they're widely discussed, I'm going to talk about an underrated reason.</p> <p>People often focus on the portable market because it's cannibalizing desktop market, but that's not the only growth market -- servers are also becoming more important than desktops, and power is really important for servers. To see why power is important for servers, let's look at some calculations about how what it costs to run a datacenter from <a href="http://www.amazon.com/gp/product/012383872X/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=012383872X&amp;linkCode=as2&amp;tag=abroaview-20&amp;linkId=Y6Z2OBCUCR72ALEB">Hennessy &amp; Patterson</a>.</p>  <p>One of the issues is that you pay for power multiple times. Some power is lost at the substation, although we might not have to pay for that directly. Then we lose more storing energy in a UPS. This figure below states 6%, but smaller scale datacenters can easily lose twice that. After that, we lose more power stepping down the power to a voltage that a server can accept. That's over a 10% loss for a setup that's pretty efficient.</p> <p>After that, we lose more power in the server's power supply, stepping down the voltage to levels that are useful inside a computer, which is often about another 10% loss (not pictured in the figure below).</p> <p><img src="https://danluu.com/images/datacenter-power/power_conversion.png" alt="Power conversion figure from Hennessy &amp; Patterson, which reproduced the figure from Hamilton" width="640" height="383"></p> <p>And then once we get the power into servers, it gets turned into waste heat. To keep the servers from melting, we have to pay for power to cool them. <a href="http://www.morganclaypool.com/doi/abs/10.2200/S00193ED1V01Y200905CAC006">Barroso and Holzle</a> estimated that 30%-50% of the power drawn by a datacenter is used for chillers, and that an additional 10%-20% is for the <a href="http://www.dchuddle.com/2011/crac-v-crah/">CRAC</a> (air circulation). That means for every watt of power used in the server, we pay for another 1-2 watts of support power.</p> <p>And to actually get all this power, we have to pay for the infrastructure required to get the power into and throughout the datacenter. Hennessy &amp; Patterson estimate that of the $90M cost of an example datacenter (just the facilities -- not the servers), 82% is associated with power and cooling<sup id="fnref:E"><a rel="footnote" href="#fn:E">1</a></sup>. The servers in the datacenter are estimated to only cost $70M. It's not fair to compare those numbers directly since servers need to get replaced more often than datacenters; once you take into account the cost over the entire lifetime of the datacenter, the amortized cost of power and cooling comes out to be 33% of the total cost, when servers have a 3 year lifetime and infrastructure has a 10-15 year lifetime.</p> <p>If we look at all the costs, the breakdown is:</p>  <table> <tbody><tr> <th>category</th><th>%</th></tr> <tr> <td>server machines</td><td>53</td></tr> <tr> <td>power &amp; cooling infra</td><td>20</td></tr> <tr> <td>power use</td><td>13</td></tr> <tr> <td>networking</td><td>8</td></tr> <tr> <td>other infra</td><td>4</td></tr> <tr> <td>humans</td><td>2</td></tr> </tbody></table> <p>Power use and people are the cost of operating the datacenter (OPEX), whereas server machines, networking, power &amp; cooling infra, and other infra are capital expenditures that are amortized across the lifetime of the datacenter (CAPEX).</p> <p>Computation uses a lot of power. <a href="http://www.datacenterknowledge.com/archives/2010/05/19/microsoft-building-new-data-center-in-quincy/">We used to build steel mills near cheap sources of power</a>, but <a href="http://www.datacenterknowledge.com/archives/2010/05/19/microsoft-building-new-data-center-in-quincy/">now that's where we build datacenters</a>. As companies start considering the full cost of applications, we're seeing a lot more power optimized solutions<sup id="fnref:1"><a rel="footnote" href="#fn:1">2</a></sup>. Unfortunately, this is really hard. On the software side, with the exceptions of toy microbenchmark examples, <a href="http://arcade.cs.columbia.edu/energy-oopsla14.pdf">best practices for writing power efficient code still aren't well understood</a>. On the hardware side, Intel recently released a new generation of chips with significantly improved performance per watt that doesn't have much better absolute performance than the previous generation. On the hardware accelerator front, some large companies are building dedicated power-efficient hardware for specific computations. But with existing tools, hardware accelerators are costly enough that dedicated hardware only makes sense for the largest companies. There isn't an easy answer to this problem.</p> <p><small> If you liked this post, you'd probably like chapter 6 of <a href="http://www.amazon.com/gp/product/012383872X/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=012383872X&amp;linkCode=as2&amp;tag=abroaview-20&amp;linkId=Y6Z2OBCUCR72ALEB">Hennessy &amp; Patterson</a>, which walks through not only the cost of power, but a number of related back of the envelope calculations relating to datacenter performance and cost.</small></p> <p>Apologies for the quickly scribbled down post. I jotted this down shortly before signing an NDA for an interview where I expected to learn some related information and I wanted to make sure I had my thoughts written down before there was any possibility of being contaminated with information that's under NDA. </p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[World Population Estimated at 8 Billion (102 pts)]]></title>
            <link>https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion.html</link>
            <guid>38217602</guid>
            <pubDate>Fri, 10 Nov 2023 11:27:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion.html">https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion.html</a>, See on <a href="https://news.ycombinator.com/item?id=38217602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div id="textcore-aa1eae23b3">
    <p>Using data from the <a href="https://www.census.gov/data-tools/demo/idb">International Database</a>, the U.S. Census Bureau estimates the world population hit 8 billion on September 26.</p>
<p>Emphasis on the word <i>estimates</i>.<br>
</p>
<p>There are many sources of uncertainty in estimating the global population, and it’s unlikely this population milestone was reached on that exact date.</p>
<p>For example, the United Nations (U.N.) Population Division estimates the world population <a href="https://www.un.org/en/dayof8billion" target="_blank">reached 8 billion on November 15, 2022</a>.&nbsp;</p>

</div>
<div>
<p>Only around 4% of the world population (all in Africa) lives in a country with very high fertility — above 5 children per woman. Even in countries with very high fertility, fertility is generally lower than it was in the past.</p>

    

</div>
<div id="textcore-55f540f016">
    <p>Why the discrepancy? Many of the world’s most populous countries (such as India and Nigeria), haven’t conducted a census in over 10 years, and many countries lack civil registration and vital statistics systems that accurately record births and deaths among their population.</p>
<p>Given the lack of precise population data worldwide, the U.N. and Census Bureau estimates are not that far apart, and both imply similar overall trends.&nbsp;</p>

</div>
<div>
  <p id="titlecore-0ed5cb1042">
 <h3>Population Growing at Slower Pace</h3>
</p>

    

</div>
<div id="textcore-d1f3f15fdd">
    <p>The rate of growth peaked decades ago in the 1960s and has been declining since and is projected to continue declining.</p>
<p>While it took 12.5 years for the world to go from 7 billion to 8 billion people, we project it will likely take 14.1 years to go from 8 billion to 9 billion, and another 16.4 years to go from 9 billion to 10 billion.</p>
<p>Despite a slowdown, we project the world population will reach 10.2 billion by 2060.&nbsp;</p>

</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1596535887/imagecore.coreimg{.width}.jpeg/1698870043746/figure-1a.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-1a.jpg" data-asset-id="b77c5e3d-bea3-4aef-bf4b-c0fabbbdd1e2" data-title="Figure 1a. Estimated and Projected World Population: 1950-2060" id="imagecore-497f6a95c9" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-1a.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1596535887/imagecore.coreimg.jpeg/1698870043746/figure-1a.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 1a. Estimated and Projected World Population: 1950-2060" title="Figure 1a. Estimated and Projected World Population: 1950-2060">
            
        
    </a></p><meta itemprop="caption" content="Figure 1a. Estimated and Projected World Population: 1950-2060">
</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_1971482390/imagecore.coreimg{.width}.jpeg/1698870059406/figure-1b.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-1b.jpg" data-asset-id="b664d95a-d1dd-47e5-b89b-3a5e84a98186" data-title="Figure 1b. Estimated and Projected Annual Population Growth Rate: 1950-2060" id="imagecore-0a9f4fbb1d" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-1b.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_1971482390/imagecore.coreimg.jpeg/1698870059406/figure-1b.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 1b. Estimated and Projected Annual Population Growth Rate: 1950-2060" title="Figure 1b. Estimated and Projected Annual Population Growth Rate: 1950-2060">
            
        
    </a></p><meta itemprop="caption" content="Figure 1b. Estimated and Projected Annual Population Growth Rate: 1950-2060">
</div>
<div>
<p>These broad global trends mask wide diversity. Population growth is the result of fertility, mortality, migration and the share of the population at certain ages. These trends all differ from country to country and, as a result, population growth varies around the world.</p>

    

</div>
<div>
  <p id="titlecore-cd72ba0e0c">
 <h3>Declining Fertility Continues </h3>
</p>

    

</div>
<div id="textcore-aa2d2fe088">
    <p>Nearly three quarters (74%) of the earth’s population reside in countries where fertility is around or below the replacement level.&nbsp;</p>
<p>It is widely believed that 2.1 is the replacement-level fertility rate — the number of births a woman would need to have in her lifetime to replace herself and the father. However, the precise level of fertility necessary for long-term replacement varies between countries due to different mortality rates.</p>
<p>Around 33% of the world population — approximately 1 in 3 people — lives in a country with a fertility rate close to replacement, including diverse countries such as India, Tunisia and Argentina. &nbsp;&nbsp;</p>
<p>Demographers once assumed fertility would stop declining once it reached replacement levels. But it has continued to decline below replacement levels in many countries.</p>
<p>Around 15% of the world’s population lives in a country with low fertility of 1.6 to 1.8 children per woman. This includes a diverse range of countries like Brazil, Mexico, the United States and Sweden.</p>
<p>Another 26% — about 1 in 4 people — lives in a country with very low fertility at 1.5 children or fewer per woman. Such countries include China, South Korea and Spain.</p>
<p>Another 23% lives in a country with moderately high fertility between 2.3 and 5.0 children.&nbsp;This broad category includes a diverse range of countries like Papua New Guinea, Israel and Ethiopia.</p>
<p>Only around 4% of the world population (all in Africa) lives in a country with very high fertility — above 5 children per woman. Even in countries with very high fertility, fertility is generally lower than it was in the past.</p>

</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714/imagecore.coreimg{.width}.jpeg/1698870071844/figure-2.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-2.jpg" data-asset-id="e7da8568-ab15-4ba8-bf7a-a3d2fac9b679" data-title="Figure 2. Distribution of World Population by Total Fertility Rate: 2023" id="imagecore-327c17ffb2" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-2.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714/imagecore.coreimg.jpeg/1698870071844/figure-2.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 2. Distribution of World Population by Total Fertility Rate: 2023" title="Figure 2. Distribution of World Population by Total Fertility Rate: 2023">
            
        
    </a></p><meta itemprop="caption" content="Figure 2. Distribution of World Population by Total Fertility Rate: 2023">
</div>
<div id="textcore-a9713965b0">
    <p>And we project that by 2060, no country will have an average of four or more children per woman, let alone five or six children per woman.</p>
<p>It’s projected that Benin will have the world’s highest projected total fertility rate (3.8) in 2060. There will, of course, still be women who have four or more children, but it is unlikely entire countries will average four or more children per woman.&nbsp;</p>

</div>
<div>
  <p id="titlecore-ca82b64818">
 <h3>Most Growth Will Come From Adult Populations </h3>
</p>

    

</div>
<div id="textcore-bb6bbc0140">
    <p>The world population is projected to keep growing despite declining fertility rates. In fact, we estimate the number of infants already peaked in 2017. Instead, population growth in the future will come from larger groups of people at adult ages. Demographers call this phenomenon population momentum.</p>
<p>Figure 3 shows the world population by age in 2023 and the projected population by age in 2060. Population growth between now and 2060 will be from the population pyramid “filling up” previously sparse older age groups, not from growing numbers of births.&nbsp;</p>

</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_531273015/imagecore.coreimg{.width}.jpeg/1698870088050/figure-3a.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-3a.jpg" data-asset-id="aaa749ba-2821-45b3-9647-0945f43e4b29" data-title="Figure 3a. Global Population Pyramid by Age Group: 2023" id="imagecore-dd8308393a" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-3a.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_531273015/imagecore.coreimg.jpeg/1698870088050/figure-3a.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 3a. Global Population Pyramid by Age Group: 2023" title="Figure 3a. Global Population Pyramid by Age Group: 2023">
            
        
    </a></p><meta itemprop="caption" content="Figure 3a. Global Population Pyramid by Age Group: 2023">
</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1384273560/imagecore.coreimg{.width}.jpeg/1698870111955/figure-3b.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-3b.jpg" data-asset-id="883cc4c8-12fb-4e42-852a-3d9b4bfa7ebb" data-title="Figure 3b. Projected Global Population Pyramid by Age Group: 2060" id="imagecore-1ee516a13d" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-3b.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1384273560/imagecore.coreimg.jpeg/1698870111955/figure-3b.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 3b. Projected Global Population Pyramid by Age Group: 2060" title="Figure 3b. Projected Global Population Pyramid by Age Group: 2060">
            
        
    </a></p><meta itemprop="caption" content="Figure 3b. Projected Global Population Pyramid by Age Group: 2060">
</div>
<div>
<p>Figure 4 shows how the growth of the older-adult population is projected to make up most of the population growth between now and 2060. Future population growth will be coincident with population aging.&nbsp;</p>

    

</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1331298842/imagecore.coreimg{.width}.jpeg/1698941086157/figure-4.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-4.jpg" data-asset-id="a64e698d-da45-4d58-a7a3-fe7d378e9019" data-title="Figure 4. Estimated and Projected World Population by Age Group: 2010-2060" id="imagecore-671b168146" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/figure-4.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1331298842/imagecore.coreimg.jpeg/1698941086157/figure-4.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Figure 4. Estimated and Projected World Population by Age Group: 2010-2060" title="Figure 4. Estimated and Projected World Population by Age Group: 2010-2060">
            
        
    </a></p><meta itemprop="caption" content="Figure 4. Estimated and Projected World Population by Age Group: 2010-2060">
</div>
<div>
  <p id="titlecore-139083242d">
 <h3>Global Aging</h3>
</p>

    

</div>
<div id="textcore-3f3e606aa6">
    <p>As fertility declines, there are proportionally fewer younger people and more older people.</p>
<p>The share of the population at young ages has been declining. Today, 32% of people are 19 or younger. By 2060, that number is projected to slip to 26%.</p>
<p>As the share of young people declines, the proportion of people at older ages increases. Today, 10% of the world is 65 or older and their share is projected to double to 20% by 2060.</p>
<p>As a result, the median age is changing. Today, the global median age is 32 (half the population is younger and half older). By 2060, however, the global median age is projected to climb to 39 years.&nbsp;</p>
<p>These general trends vary by country. Niger is the world’s youngest country, with a median age of 15 in 2023. Monaco, by contrast, is the oldest, with a median age of 56 in 2023.&nbsp;</p>

</div>
<div data-cmp-is="image" data-cmp-src="/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1174557226/imagecore.coreimg{.width}.jpeg/1698870151088/table-1.jpeg" data-asset="/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/table-1.jpg" data-asset-id="2423a6d0-e145-40bc-960d-7f4234c5e67e" data-title="Table 1. Countries or Areas With Lowest and Highest Median Ages: 2023" id="imagecore-deebc098ee" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><a href="https://www.census.gov/content/dam/Census/library/stories/2023/11/world-population-estimated-at-8-billion/table-1.jpg" data-cmp-hook-image="link">
        
            
            <img src="https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion/_jcr_content/root/responsivegrid/responsivegrid_19714_1174557226/imagecore.coreimg.jpeg/1698870151088/table-1.jpeg" itemprop="contentUrl" data-cmp-hook-image="image" alt="Table 1. Countries or Areas With Lowest and Highest Median Ages: 2023" title="Table 1. Countries or Areas With Lowest and Highest Median Ages: 2023">
            
        
    </a></p><meta itemprop="caption" content="Table 1. Countries or Areas With Lowest and Highest Median Ages: 2023">
</div>
<div>
  <p id="titlecore-07bb77a3e4">
 <h3>Increasing Life Expectancy </h3>
</p>

    

</div>
<div id="textcore-564af52f88">
    <p>In many countries where young-age mortality is already low, gains in life expectancy come from improving conditions at older ages.</p>
<p>Canada, for instance, did not experience big declines in <a href="https://www.census.gov/data-tools/demo/idb/#/table?YR_ANIM=2020&amp;COUNTRY_YEAR=2023&amp;COUNTRY_YR_ANIM=2023&amp;menu=tableViz&amp;quickReports=CUSTOM&amp;CUSTOM_COLS=E0,MR0_4&amp;FIPS=CA&amp;TABLE_RANGE=2000,2023&amp;TABLE_YEARS=2000,2023&amp;TABLE_USE_RANGE=N&amp;TABLE_USE_YEARS=Y&amp;TABLE_STEP=1&amp;TABLE_ADD_YEARS=2000,2023&amp;CCODE=CA&amp;CCODE_SINGLE=CA">young-age mortality</a> between 2000 and 2023, but its total life expectancy increased by an average of about 4 years, largely from reduced mortality at older ages. &nbsp;</p>
<p>For many other countries, however, life expectancy trends are driven more by dramatic declines in child mortality. In Niger, for example, <a href="https://www.census.gov/data-tools/demo/idb/#/table?COUNTRY_YEAR=2023&amp;COUNTRY_YR_ANIM=2023&amp;CCODE_SINGLE=NE&amp;CCODE=NE&amp;menu=tableViz&amp;quickReports=CUSTOM&amp;CUSTOM_COLS=MR0_4&amp;TABLE_YEARS=2000,2023&amp;TABLE_USE_RANGE=N&amp;TABLE_USE_YEARS=Y&amp;TABLE_STEP=1&amp;TABLE_ADD_YEARS=2000,2023">child mortality declined</a> from around 224 deaths of children under 5 per 1,000 births in 2000 to 103 deaths per 1,000 births in 2023.</p>
<p>As a result, the country’s average life expectancy at birth increased from 45 years in 2000 to 60 years in 2023. We project that Niger will continue this trend and that child mortality will drop to 45 deaths per 1,000 births by 2060.</p>
<p>Life expectancy gains from reducing mortality at young ages make populations younger. As fewer children die, there are more children in the population.</p>
<p>While life expectancy is generally increasing, there are some exceptions. Many countries saw a decline in life expectancy due to the COVID-19 pandemic. We are gradually incorporating COVID-19 mortality into the population estimates available in the <a href="https://www.census.gov/data-tools/demo/idb/#/country?COUNTRY_YEAR=2023">International Database (IDB)</a> as more recent mortality data become available.&nbsp;</p>

</div>
<div>
<p><b><i>Anne Morse is a demographer with the Census Bureau’s International Programs Center.&nbsp;</i></b></p>

    

</div>

<div id="List_504117436" name="list_copy">

	<p>
			<h3>Related Statistics</h3>
		</p>

		
		
	  	
	
	    
	
		
	
		
		    
	
			
	
			

			
			
			
			
			
            
			<div id="listArticlesContainer_List_504117436">
							
								
									
    <a href="https://www.census.gov/newsroom/stories/world-population-day.html" onclick="linkClick(this, 'Census List Component');" title="World Population Day: July 11, 2023" tabindex="0">

        <div>
            <hr>

            
                
	<p><span>Stats for Stories</span></p><p>World Population Day: July 11, 2023</p>
            
            

            <p>The U.S. Census Bureau’s International Database projects that the world population will reach 8 billion in October 2023.  </p>

            <hr>

            
        </div>
    </a>

								
		
								
		
								
							
								
									
    <a href="https://www.census.gov/newsroom/stories/new-years-day.html" onclick="linkClick(this, 'Census List Component');" title="New Year's Day 2023: January 1, 2023" tabindex="0">

        <div>
            <hr>

            
                
	<p><span>Stats for Stories</span></p><p>New Year's Day 2023: January 1, 2023</p>
            
            

            <p>The U.S. Census Bureau projects the U.S. population will be 334,233,854 on Jan. 1, 2023. This is an annual increase of 1,571,393, or 0.47%, from Jan. 1, 2022.</p>

            <hr>

            
        </div>
    </a>

								
		
								
		
								
							
						</div>
			
			
	
			
	
			
	
			<!-- /* View All Link section */ -->
			
		
		
</div>
<div id="bc1542108121">
            
            <div>
  <p id="titlecore-c95939e9e8">
 <h2>Subscribe</h2>
</p>

    

</div>
<div>
<p>Our email newsletter is sent out on the day we publish a story. Get an alert directly in your inbox to read, share and blog about our newest stories.</p>

    

</div>

<div id="textcore-b0376f928d">
    <p>Contact our&nbsp;<a href="https://www.census.gov/newsroom/about.html">Public Information Office</a>&nbsp;for media inquiries or interviews.</p>

</div>

            
        </div>

    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[At SpaceX, worker injuries soar in Elon Musk's rush to Mars (106 pts)]]></title>
            <link>https://www.reuters.com/investigates/special-report/spacex-musk-safety/</link>
            <guid>38217545</guid>
            <pubDate>Fri, 10 Nov 2023 11:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/investigates/special-report/spacex-musk-safety/">https://www.reuters.com/investigates/special-report/spacex-musk-safety/</a>, See on <a href="https://news.ycombinator.com/item?id=38217545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="paragraph-0">One windy night at Elon Musk’s SpaceX facility in McGregor, Texas, Lonnie LeBlanc and his co-workers realized they had a problem.</p>
<p id="paragraph-1">They needed to transport foam insulation to the rocket company’s main hangar but had no straps to secure the cargo. LeBlanc, a relatively new employee, offered&nbsp;a solution to hold down the load: He sat on it.</p>
<p id="paragraph-2">After the truck drove away, a gust blew LeBlanc and the insulation off the trailer, slamming him headfirst into the pavement. LeBlanc, 38, had retired nine months&nbsp;earlier from the U.S. Marine Corps. He was <a href="https://www.legacy.com/funeral-homes/obituaries/name/lonnie-leblanc-obituary?pid=171515410&amp;v=batesville&amp;view=guestbook" id="article-link-0">pronounced dead</a> from head trauma at the scene.</p>

    <figure id="3MDV3GA4SO_0" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption">Lonnie LeBlanc died after a wind gust blew him off a truck that was moving insulation at SpaceX’s McGregor, Texas, facility. U.S. regulators cited the company for “serious” safety lapses contributing to the accident. This photo, posted with his obituary, was provided by the family to a funeral home and a local newspaper. </figcaption>
    </figure>
<p id="paragraph-4">Federal inspectors with the U.S. Occupational Safety and Health Administration (OSHA) later determined&nbsp;that SpaceX had failed to protect LeBlanc from a clear hazard, noting the gravity and severity of the violation.&nbsp;LeBlanc’s co-workers told OSHA that SpaceX had no convenient access to tie-downs and no process or oversight for handling such loads. SpaceX acknowledged the problems, and the agency instructed the company to make seven specific safety improvements, including more training and equipment, according to the inspection report.</p>
<p id="paragraph-5">It was hardly the last serious accident at SpaceX. Since LeBlanc’s death in June 2014, which hasn’t been previously reported, Musk’s rocket company has disregarded worker-safety regulations and standard practices at its inherently dangerous rocket and satellite facilities&nbsp;nationwide, with workers paying a heavy price, a Reuters investigation found. Through interviews and government records, the news organization documented at least 600 injuries of SpaceX workers since 2014.</p>
<p id="paragraph-6">Many were serious or disabling. The records included reports of more than 100 workers suffering cuts or lacerations, 29 with broken bones or dislocations, 17 whose hands or fingers were “crushed,” and nine with head injuries, including one skull fracture, four concussions and one traumatic brain injury. The cases also included five burns, five electrocutions, eight accidents that led to amputations,&nbsp;12 injuries involving multiple unspecified body parts, and seven workers with eye injuries. Others were relatively minor, including more than 170 reports of strains or sprains.</p>
<p id="paragraph-7">Current and former employees said such injuries reflect a chaotic workplace where often under-trained and overtired staff routinely skipped basic safety procedures as they raced to meet Musk’s aggressive deadlines for space missions. SpaceX, founded by Musk more than two decades ago, takes the stance that workers are responsible for protecting themselves, according to more than a dozen current and former employees, including a former senior executive.</p>
<p id="paragraph-8">Musk himself at times appeared cavalier about safety on visits to SpaceX sites: Four employees said he sometimes played with a novelty flamethrower and discouraged workers from wearing safety yellow&nbsp;because he dislikes bright colors.</p>
<p id="paragraph-9">The lax safety culture, more than a dozen current and former&nbsp;employees said, stems in part from Musk’s disdain for perceived bureaucracy and a belief inside SpaceX that it’s leading an urgent quest to create a refuge in space from a dying Earth.</p>
<p id="paragraph-10">“Elon’s concept that SpaceX is on this mission to go to Mars as fast as possible and save humanity permeates every part of the company,” said Tom Moline, a former SpaceX senior avionics engineer who was among a group of employees fired after raising workplace complaints. “The company justifies casting aside anything that could stand in the way of accomplishing that goal, including worker safety.”</p>

    
<p id="paragraph-12">One severe injury in January 2022 resulted from a series of safety failures that illustrate systemic problems at SpaceX, according to eight former&nbsp;SpaceX employees familiar with the accident. In that case, a part flew off during pressure testing of a Raptor V2 rocket engine – fracturing the skull of employee Francisco Cabada and putting him in a coma.</p>
<p id="paragraph-13">The sources told Reuters that senior managers at the Hawthorne, California site were repeatedly warned about the dangers of rushing the engine’s development, along with inadequate training of staff and testing of components. The part that failed and struck the worker had a flaw that was discovered, but not fixed, before the testing, two of the employees said.</p>
<p id="paragraph-14">Cabada’s wife told Reuters the company has ignored the family’s attempts to find out why he wasn’t protected.&nbsp;“It would have been nice to get a call from Elon Musk,” Ydy Cabada said. “But I guess workers are just disposable to them.”</p>
<p id="paragraph-15">In all, Reuters interviewed more than three dozen people with knowledge of SpaceX safety practices, including more than two dozen current or former employees. Many of the sources spoke on condition of anonymity, citing concerns about career or legal repercussions.</p>
<p id="paragraph-16">SpaceX did not respond to questions from Reuters and a detailed description of this article’s findings.</p>
<p id="paragraph-17">The more than 600 SpaceX injuries Reuters documented&nbsp;represent only a portion of the total case count, a figure that is not publicly available. OSHA has required companies to report their total number of injuries annually since 2016, but SpaceX facilities failed to submit reports for most of those years. About two-thirds of the injuries Reuters uncovered came in years when SpaceX did not report that annual data, which OSHA collects to help prioritize on-site inspections of potentially dangerous workplaces.</p>

    <blockquote id="1OL66Q324O_2">
        <p>“Elon’s concept that SpaceX is on this mission to go to Mars as fast as possible and save humanity permeates every part of the company. The company justifies casting aside anything that could stand in the way of accomplishing that goal, including worker safety.”</p>
        
    </blockquote>
<p id="paragraph-19">Reuters unearthed details about the 600-plus injuries by examining court documents in worker lawsuits, employee medical records, state workers’ compensation claims and emergency-call records. The news agency also obtained, through public records requests, internal SpaceX injury logs that the company turned over to federal and state&nbsp;safety inspectors following serious safety incidents. Such logs are rarely made public. Regulators require companies to keep the records, which include descriptions of individual injuries, and to produce them upon request.</p>
<p id="paragraph-20">After years of failing to report annual injury-and-illness statistics to regulators, some SpaceX sites started filing the data in 2021 or 2022. The data for 2022, which are more complete, reveal injury rates at three major SpaceX industrial facilities that far exceeded the space-industry average.</p>
<div id="0X4SUIHW4I_3">
<p id="paragraph-22">SpaceX injury data reporting failures</p>
<p id="paragraph-23">SpaceX facilities failed to submit injury data annually, as required by regulators, for most years since 2016.&nbsp;When they did report, three major sites’ injury rates far exceeded industry averages. <strong id="5XH6WGIWWM_4">The average was 0.8 injuries per 100 workers for 2022</strong>&nbsp;and has been relatively stable for many years.</p>

    
</div>
<p id="paragraph-26">The 2022 injury rate at the company’s manufacturing-and-launch facility near Brownsville, Texas, was 4.8 injuries or illnesses per 100 workers – six times higher than the space-industry average of 0.8. Its rocket-testing facility in McGregor, Texas, where LeBlanc died, had a rate of 2.7, more than three times the average. The rate at its Hawthorne, California, manufacturing facility was more than double the average at 1.8 injuries per 100 workers. The company’s facility in Redmond, Washington, had a rate of 0.8, the same as the industry average.</p>

    <figure id="JQRB9PJCZU_8" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption">A portion of the OSHA report on an inspection that uncovered safety failures contributing to the 2014 death of worker Lonnie LeBlanc.</figcaption>
    </figure>
<p id="paragraph-28">Two other SpaceX facilities in Florida, at Kennedy Space Center and Cape Canaveral, could not be compared to the industry average in 2022. Kennedy didn’t report injury data that year. And the company labeled Cape Canaveral as part of a different industry subcategory for which the government doesn’t calculate an average rate.</p>
<p id="paragraph-29">The Kennedy site did report injury data for 2016, the first year it was required to do so – but hasn’t reported since. For that year, the facility reported data amounting to an injury rate of 21.5 injuries per 100 workers, about 27 times the industry average. The facility employed only 50 people at the time; it had just taken over a launch pad from the U.S. National Aeronautics and Space Administration (NASA). Sixteen of those workers were injured, SpaceX reported. By 2021, employment at Kennedy had grown to more than 1,100 workers, NASA said.</p>
<p id="paragraph-30">(See <a href="#methodology">related story</a> on how Reuters analyzed SpaceX’s safety record.)</p>

    <figure id="video-title" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption"> SpaceX staffers at the company’s manufacturing site near Brownsville, Texas, inspect a rocket high above the ground. REUTERS/Evan Garcia.&nbsp;</figcaption>
    </figure>
<p id="paragraph-32">A dozen worker-safety experts said SpaceX’s poor safety record underscores the perils of working in the lightly regulated and fast-expanding U.S. space industry. Other major space companies have also failed to report annual injury data to OSHA in some recent years.</p>
<p id="paragraph-33">Reuters reviewed state and federal safety violation records&nbsp;on SpaceX and found no sanctions for its data-reporting failures. For safety&nbsp;violations that inspectors found after SpaceX worker accidents, state and federal regulators levied only small fines, typically ranging from a few hundred to a few thousand dollars.</p>
<p id="paragraph-34">In a written response to questions from Reuters, OSHA did not comment on SpaceX’s worker safety record or its enforcement decisions involving the company. The agency did not address why it never cited SpaceX for failing to report injury data for many years, saying it would be “unfair to draw a conclusion” because it didn’t know “the specifics.” Reuters documented the safety reporting lapses using the agency’s own records.</p>
<p id="paragraph-35">The agency did say it has recently increased inspections of companies generally and issued more of its stiffest penalties in egregious cases.</p>
<p id="paragraph-36">California OSHA, a state-run workplace safety regulator, did not comment in response to Reuters’ questions.</p>

    <blockquote id="KRU4RKID0P_10">
        <p>Current and former employees said SpaceX’s high injury rates reflect a chaotic workplace where often under-trained and overtired staff routinely skipped basic safety procedures as they raced to meet Musk’s aggressive deadlines for space missions.</p>
        
    </blockquote>
<p id="paragraph-38">NASA said it has paid SpaceX $11.8 billion to date as a private space contractor. The agency did not comment on the company’s safety record but said it has the option of enforcing contract provisions that require SpaceX to “have a robust and effective safety program and culture.”</p>
<p id="paragraph-39">SpaceX has defended its safety practices in written responses to OSHA and CalOSHA. In response to an inquiry into the Cabada accident, SpaceX argued to CalOSHA that it shouldn’t be held responsible for such injuries because it provides extensive safety training and the malfunction was not reasonably foreseeable. Accountability for such part failures and any resulting injuries falls instead on a cadre of employees known as “responsible engineers,” or REs, the company wrote.</p>
<p id="paragraph-40">“REs are ultimately responsible for all aspects of their components and systems,” including safety, the company wrote.&nbsp;“Put simply, the RE is the delegated SpaceX representative.”</p>
<p id="paragraph-41">Safety specialists dismissed SpaceX’s contention that it can off-load the company’s duty to ensure worker safety to specific engineers it employs. Jordan Barab, who served as an OSHA deputy assistant secretary between 2009 and 2017, called the notion “ludicrous.”</p>
<p id="paragraph-42">OSHA told Reuters that employers, not designated employees, are responsible for ensuring a hazard-free workplace.</p>
<p id="paragraph-43">Travis Carson, a former Brownsville welder and production&nbsp;supervisor, said SpaceX generally left staffers in charge of their own safety, with little training or oversight.</p>
<p id="paragraph-44">“SpaceX’s idea of safety is: ‘We’ll let you decide what’s safe for you,’ which really means there was no accountability,” said Carson, who has worked for more than two decades in dangerous jobs such as building submarines. “That’s a terrible approach to take in industrial environments.”</p>

    
<p id="paragraph-46">‘No accountability’</p>
<p id="paragraph-47">Since Musk co-founded SpaceX in 2002, his free-wheeling entrepreneurism has proved a powerful draw for young skilled workers. Some SpaceX employees described eagerly joining the company as it outpaced competitors and offered perks including in-house medical clinics and private company stock that has shot up in value. The company, which employs 13,000 workers, had an estimated value of $150 billion as of earlier this year. Musk has a 42% stake and 79% of the company’s voting power, according to a company filing.</p>
<p id="paragraph-48">SpaceX has achieved major breakthroughs. It was the first private company to send humans into orbit. Its Starlink unit is now the world’s largest satellite operator. Competitors including Jeff Bezos’ Blue Origin&nbsp;have struggled to keep pace with SpaceX’s reusable rockets, which have slashed launch costs.</p>
<p id="paragraph-49">Some SpaceX engineers say they relish collaborating with creative coworkers in an environment with little bureaucracy. “There’s a certain amount of red tape that SpaceX avoids, which allows it to move faster” than NASA or private competitors, said Chris Cunnington, a former engineer in McGregor, Texas. He said he believed SpaceX struck a good balance between speed and safety.</p>
<p id="paragraph-50">Other current and former employees at the company’s Brownsville site, which had the highest 2022 injury rate, said the company’s disdain for structured processes came at a high cost to workers.</p>
<p id="paragraph-51">SpaceX started building its Brownsville site in 2014, and it has since become the epicenter of Musk’s Mars mission. The facility employs more than 1,600 workers on the Texas-Mexico border and combines manufacturing, testing and launching. It’s the base of SpaceX’s Starship program, a project aiming to build cheaper rockets faster.</p>

    
<p id="paragraph-53">Brownsville managers, many of them in their 20s, worked grueling hours trying to meet Musk’s deadlines, according to six current or former&nbsp;employees familiar with the site’s operations, including Moline and Carson. Some workers slept overnight at the facility at times so they could work more than 80 hours a week, according to four of those employees.</p>
<p id="paragraph-54">Carson worked at the Brownsville site as a welder in 2019 and 2020 and returned as a production supervisor in 2021 and 2022. He said some employees took Adderall, the stimulant typically used to treat attention-deficit disorder, without a prescription. Others fell asleep in bathrooms, said Carson and three other current or former Brownsville workers.</p>
<p id="paragraph-55">To speed work and cut costs, SpaceX started manufacturing rockets in tents next to an undeveloped Gulf of Mexico beach. Workers welded rocket parts up to 12 hours a day, six days a week, often in temperatures over 100 degrees Fahrenheit, the SpaceX workers said. When overcome by heat, they were given IV fluids and sent back to work.</p>
<p id="paragraph-56">When high winds disrupted the work, supervisors shut the tents, closing off ventilation that is essential for safe welding, according to the six current and former workers. <a href="https://www.osha.gov/sites/default/files/publications/OSHA_FS-3647_Welding.pdf" id="article-link-2">OSHA warns</a> that welding stainless steel can generate a highly toxic, cancer-causing dust. The agency told Reuters it requires companies to assess the danger of such environments through air sampling and to implement a “respiratory protection program” when needed. One former welder, Phillip Fruge, said he asked managers for respirators commonly used to protect welders’ lungs, but they weren’t provided.</p>
<p id="paragraph-57">“We could see the clouds of the dust filling the tent,” Fruge recalled. “Everyone was just breathing it in, day after day.”</p>

    
<p id="paragraph-59">Carson said he pressed superiors for better safety measures but was ignored. He recalled stepping into the interior of a rocket under construction in 2021 on his first day as a supervisor. Another manager, working 20 feet above him, carelessly dropped a nearly 100-pound hoist, barely missing Carson.</p>
<p id="paragraph-60">“That’s like a firing offense at other places, but not at SpaceX,” Carson said. “They needed bodies, and Elon needed stuff done.”</p>
<p id="paragraph-61">Carson himself eventually was fired in January 2022 after getting into a scuffle with a boss. Carson, who is African American, said he shoved the manager, a younger man, because he had repeatedly called Carson “boy,” despite Carson’s requests that he stop. “Boy” is widely considered a racial epithet by Americans when used to refer to a Black man. The supervisor, who could not be reached for comment, was not disciplined, according to Carson. Reuters could not independently confirm how SpaceX handled the incident.</p>
<p id="paragraph-62">SpaceX sometimes rushed to hire workers and regularly failed to properly train or equip new recruits, more than a dozen current and former employees said. Workers with no experience, for instance,&nbsp;were handed welding tools without training, they said. Four of these employees, who were managers fresh out of college, described making tough calls on the safety of dangerous activities with little guidance.</p>
<p id="paragraph-63">In November 2021, two Brownsville technicians were moving square steel tubing weighing 500 pounds, using a crane with a lifting magnet, according to OSHA inspection records. The tubing fell and crushed a worker’s hand because the crane was only designed to hoist 300 pounds, OSHA concluded.</p>
<p id="paragraph-64">The employee, whose name was redacted in the inspection report the agency gave Reuters, required long-term treatment after surgery, including the partial amputation of the worker’s ring finger, according to the report. The agency faulted the company for failing to ensure employees tested whether the crane could lift the load.&nbsp;SpaceX appealed the resulting $43,506 fine and got it knocked down to $8,701 after agreeing to remedy the worker-safety problems identified in the report.</p>

    <figure id="2504IPFVJW_14" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption">Florentino Rios said he was struck in the eye with a chain while working at SpaceX. He lost sight in the eye and is now legally blind, according to medical and workers’ compensation records. Handout via REUTERS</figcaption>
    </figure>
<p id="paragraph-66">Florentino Rios suffered a severe eye injury at SpaceX’s Brownsville site one summer night in 2021, as he worked about 25 feet off the ground attaching two beams to a launch pad. A crane operator missed a hand signal from Rios and mistakenly tried to move the beams after they were fixed in place, Rios said in an interview. That error caused a chain connecting the crane to the beams to snap and strike Rios in the face. Another worker who was present confirmed Rios’ account.</p>
<p id="paragraph-67">The team should have had walkie-talkies, Rios said, and had previously asked management for better lighting.</p>
<p id="paragraph-68">As blood trickled down his face, Rios inched along a beam to a platform where he was lowered down, he said. SpaceX employees who examined him at an on-site medical clinic told him he could return to work on the next shift, although he still couldn’t see well, said his attorney, Richard Hinojosa. Reuters could not independently confirm the SpaceX medical clinic’s assessment.</p>
<p id="paragraph-69">Rios went to the hospital that night. A medical scan revealed a traumatic injury in his swollen left eye, according to medical and workers’ compensation records reviewed by Reuters.&nbsp;He continued to work anyway for a few days.&nbsp;When he sought further treatment, doctors told him he had lost vision in the eye and was legally blind, the records show.</p>
<p id="paragraph-70">Rios, 55, said he can no longer drive or work construction. He sued SpaceX alleging its negligence caused the injury by failing to implement or follow worker-safety procedures. “It wasn’t safe,” Rios said, adding that management never addressed the problems.</p>
<p id="paragraph-71">The company, in court records, argued that Rios’ own negligence was to blame. The case is ongoing.</p>
<p id="paragraph-72">“I used to be someone who didn’t like sitting around,” said Rios. “I worked day and night to give my children what they needed. And now, I can’t.”</p><figure id="video-title" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption">Florentino Rios explains how he suffered a severe eye injury while doing dangerous work at SpaceX without the proper equipment.&nbsp;</figcaption>
    </figure>
<p id="paragraph-74">Shortcutting safety</p>
<p id="paragraph-75">On Jan. 18 of last year, part of a Raptor V2 engine broke away during pressure testing at the SpaceX facility in Hawthorne, California. The part, a fuel-controller assembly cover, careened into the head of Cabada, a SpaceX technician. Nearly two years later, the father of three young children remains in a coma with a hole in his skull, family members said.</p>
<p id="paragraph-76">The accident generated <a href="https://www.semafor.com/article/10/18/2022/space-x-technician-accident" id="article-link-3">news</a> last year but little has emerged until now about the causes. The incident stemmed from several safety lapses at the Hawthorne site, according to Reuters interviews with eight former SpaceX employees familiar with the incident and the testing preparations.</p>
<p id="paragraph-77">Two of the employees said the mishap resulted in part from a simple mistake: An engineer started the test when Cabada was still too close to the engine and unprotected from explosions or flying debris.</p>
<p id="paragraph-78">Senior managers were repeatedly warned for at least a year before the accident that pressure-testing crews were not following standard worker-safety protocols, such as providing protective barriers or clearing personnel from the testing area, according to a former employee&nbsp;familiar with the matter. Such testing should be conducted with a “boom box” covering the whole engine to protect workers, the employee said.&nbsp;At one point, managers rejected a new training program, written and proposed by pressure-testing staff, on the grounds that it would cause delays, according to the source and a document reviewed by Reuters.</p>
<p id="paragraph-79">Another key contributing factor: SpaceX senior managers, in the months leading up to the accident, had instructed engineers to end or limit the testing of individual rocket parts before they are assembled into an engine, two staffers said. The managers were reacting to Musk’s demands for&nbsp;faster progress on the Raptor engine program, the workers said.</p>
<p id="paragraph-80">The team normally would have conducted more extensive testing on the cover that malfunctioned and struck Cabada, they said.</p>

    
<p id="paragraph-82">The limited testing nonetheless revealed a potentially dangerous flaw in the cover, according to two sources familiar with the matter. The component was redesigned to correct the problem, they said, but the new part wasn’t ready before the pressure testing that hurt Cabada. Reuters could not determine the precise nature of the flaw.</p>
<p id="paragraph-83">SpaceX’s rejection of a more rigorous training program, its moves to limit testing, and the discovery of the cover’s defect before the accident haven’t been previously reported.</p> 
<p id="paragraph-89">In a written response to CalOSHA’s inspection, SpaceX said it had conducted ample analysis and testing of the part before it failed.</p>
<p id="paragraph-90">More than a dozen current and former workers said SpaceX’s willingness to cut corners and skip some worker safeguards has helped keep it well ahead of competitors and score lucrative government contracts. SpaceX last year surpassed Boeing to become NASA’s second-largest vendor.</p>
<p id="paragraph-91">The company also boosts development speed through a structure that gives managers high levels of autonomy but raises safety risks, the dozen current and former SpaceX workers said. The company is split into three teams: engineering, manufacturing, and testing. The engineering leadership includes the “responsible engineers” SpaceX designates as accountable for safety in manufacturing.&nbsp;But those engineers have little control of other teams, including the one that stress-tests the engines and parts they develop, according to two staffers with knowledge of the matter.</p>
<p id="paragraph-92">In the case of the test that injured Cabada, this loose structure meant the testing team never coordinated with the responsible engineer team, the workers said.</p>
<p id="paragraph-93">After the Cabada accident, CalOSHA&nbsp;inspectors detailed other safety lapses. One employee involved in the pressure checks told them that the company generally didn’t do full safety inspections before such testing, agency records show. Another said the engine should have undergone more testing “without personnel around,” according to the records.</p>
<p id="paragraph-94">SpaceX pushed back on the agency’s finding&nbsp;that the company failed to protect Cabada, the records show. The company blamed a particular responsible engineer, who it said was accountable for the safety of the defective cover “through the lifecycle of development, testing and production.” SpaceX fired the engineer and a manager on the same team over the incident, according to&nbsp;three employees with knowledge of the situation.</p>

    
<p id="paragraph-96">Cabada’s wife, Ydy,&nbsp;said SpaceX hasn’t responded to the family’s attempts to find out how he was injured. Michael Sanchez, a Los Angeles attorney representing her, said the company has never answered his inquiries, including a March 2022 certified letter requesting a copy of any surveillance footage of the accident and advising SpaceX to preserve any other relevant records. Ydy Cabada has considered a lawsuit but has not filed one.</p>
<p id="paragraph-97">“SpaceX has not returned a single call,” Sanchez said.</p>
<p id="paragraph-98">Francisco’s sister, Evelyn Cabada, said the accident devastated the family.&nbsp;In addition to the severe head injury, she said, her brother caught pneumonia and meningitis in the hospital.</p>
<p id="paragraph-99">Ydy Cabada said the family still holds out hope he’ll emerge from the coma.</p>
<p id="paragraph-100">“The doctors keep saying nothing has changed,” she said. “It’ll take a miracle for him to get out of that bed.”</p>
<p id="paragraph-101">Flamethrowers and safety yellow</p>
<p id="paragraph-102">Musk is well-known as a hands-on manager. He was directly involved in handing down sometimes unrealistic deadlines, said current and former employees. Musk’s heavy involvement in scheduling resulted in “significantly more unsafe working conditions than would have existed otherwise,” said Moline, the engineer.</p>
<p id="paragraph-103">One former SpaceX executive defended Musk, saying he would listen to employees who were willing to go “toe-to-toe” with him on safety issues and took them seriously.</p>
<p id="paragraph-104">Another former executive said Musk cared about his workers and was bothered when they got hurt, but that safety was not one of Musk’s priorities. Musk, the ex-manager said, thought that “workers take care of their safety themselves.”</p>
<p id="paragraph-105">This former executive said that top company officials knew its injury rates ran high but attributed the problem to employing a largely young&nbsp;workforce in a dangerous industry. SpaceX leaders also believed the company shouldn’t be held to the same standard as competitors because SpaceX oversees more missions and manufacturing, the two former executives said.</p>
<p id="paragraph-106">That attitude is a red flag that a company is rationalizing a fundamentally unsafe environment, according to four worker-safety experts interviewed by Reuters, including Barab, the former OSHA deputy assistant secretary.</p>
<p id="paragraph-107">“SpaceX shouldn’t be exempt from protecting workers from being injured or killed,” Barab said, “just because they’re doing innovative work.”</p>

    <figure id="video-flamethrower" itemscope="" itemtype="http://schema.org/ImageObject">
        
        <figcaption itemprop="caption">A video posted widely online shows Elon Musk playing with a novelty flamethrower produced by his tunneling firm, the Boring Company.</figcaption>
    </figure>
<p id="paragraph-109">Four SpaceX employees told Reuters they were disturbed by Musk’s habit of playing with a flamethrower when he visited the SpaceX site in Hawthorne. The device was marketed to the public&nbsp;in 2018 as a $500 novelty item by Musk’s tunnel-building firm, the Boring Company. Videos posted online show it can <a href="https://www.youtube.com/watch?v=vMPR7k9DWlw" id="article-link-4">shoot a thick flame</a> more than five feet long. Boring later renamed the device the “Not-A-Flamethrower” amid reports of <a href="https://techcrunch.com/2021/01/19/elon-musk-said-it-was-not-a-flamethrower/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACtBIGuSTxh0ThWaD78TfHNKtEyblgoZ5PfRP--M-Ooc3ozDYISB2m87XA0dpV3Djx6gSE_MU4u0bi13SWiEgwqbwT9yPtvjHlUj-7AUAkih3BH7mQHoXh9oeIcUnRvy8X9o4LMI0B_XPuejKcm2Iksv0J8kG68pp_NEy5COwdEB" id="article-link-5">confiscations by authorities</a>.</p>
<p id="paragraph-110">For years, Musk and his deputies found it “hilarious” to wave the flamethrower around, firing it near other people and giggling “like they were in middle school,” one engineer said. Musk tweeted in 2018 that the flamethrower was “guaranteed to liven up any party!” At SpaceX, Musk played with the device in close-quarters office settings, said the engineer, who at one point feared Musk would set someone’s hair&nbsp;on fire.</p>
<p id="paragraph-111">Musk also became known in California and Texas&nbsp;for ordering machinery that was painted in industrial safety yellow to&nbsp;be repainted black or blue because of his aversion to bright colors, according to three former SpaceX supervisors. Managers also sometimes told workers to avoid wearing safety-yellow vests around Musk, or to replace yellow safety tape with red, the supervisors said.</p>
<p id="paragraph-112">Workers often walked too close to engine-testing and rocket-building facilities because the company failed to cordon off areas or put up&nbsp;warning signs, said Paige Holland-Thielen, a former operations and automation&nbsp;engineer in Hawthorne.</p>
<p id="paragraph-113">“One time I walked out the door of my building, and there was a giant crane there,” she recalled. “A bunch of people in hard hats started screaming at me to get back inside.”</p>
<p id="paragraph-114">Holland-Thielen and Moline, who also worked in Hawthorne, were among nine workers fired in the summer of 2022 after raising workplace complaints in an open letter that was ultimately signed by hundreds of employees. The letter criticized Musk’s flippant social-media responses to sexual-harassment allegations against him, which he denied. It also criticized a management culture of dismissing employee concerns and unevenly enforcing discipline policies. Eight workers who drafted the letter have since filed a complaint with the National Labor Relations Board against SpaceX alleging unfair labor practices.</p>
<p id="paragraph-115">Moline said SpaceX Chief Operating Officer Gwynne Shotwell told him he was being fired for distracting workers from getting to Mars. “Please focus on your job and the mission of SpaceX – to get humanity to Mars as quickly as possible,” Shotwell told him and Holland-Thielen, among others, in an email reviewed by Reuters.</p>
<p id="paragraph-116">Shotwell did not respond to a request for comment.</p>
<p id="paragraph-117">A death and a $7,000 fine</p>
<p id="paragraph-118">SpaceX has faced few consequences from safety regulators for its failure to report annual safety data and to protect workers in incidents reviewed by federal and state inspectors, agency records show.</p>
<p id="paragraph-119">OSHA and CalOSHA&nbsp;have fined the billionaire’s rocket company a total of&nbsp;$50,836&nbsp;for violations stemming from one worker’s death and seven serious safety incidents, regulatory records show.</p>
<p id="paragraph-120">OSHA did not comment on the modest penalties that resulted from inspections of SpaceX.</p>
<p id="paragraph-121">SpaceX’s history of injuries and regulatory run-ins in California underscores the limits of worker-safety regulation. Fines are capped by law and pose little deterrent for major companies,&nbsp;experts in U.S. worker safety regulation said. Federal and state regulators also suffer from chronic understaffing of inspectors, they said. OSHA did not address questions about staffing levels but said it “focuses its resources on hazardous workplaces.”</p>
<p id="paragraph-122">CalOSHA levied a fine of $18,475 for the violation that resulted in Cabada’s skull fracture. SpaceX unsuccessfully disputed the agency’s classification of the violation as “serious” and appealed the penalty as excessive, asking for a reduction to $475.</p>
<p id="paragraph-123">In another case, CalOSHA never inspected the company following a serious accident resulting in a leg amputation. But the agency may not have known the accident happened at all: A Reuters review of agency documents indicated it had no record of the 2016 incident.</p>
<p id="paragraph-124">Federal and state law require companies to immediately report all employee deaths, amputations and injuries resulting in hospital admissions.&nbsp;It isn’t clear whether SpaceX ever reported the injury. Neither the company nor CalOSHA commented on why the agency had no report on it.</p>
<p id="paragraph-125">If SpaceX didn’t report the case, “I don’t think they have any excuse,” said Ann Rosenthal, a former OSHA associate solicitor, who handled legal matters for the agency until 2018.</p>
<p id="paragraph-126">The incident resulted in Steven Trollinger’s leg being crushed during a mission to recover a rocket that landed in the Pacific Ocean, according to records in a lawsuit Trollinger filed. The accident occurred when he and other SpaceX employees were being transferred between two vessels. SpaceX knew that one of the vessels wasn’t properly equipped with a transfer platform designed to ensure the workers’ safety, but proceeded anyway, Trollinger’s lawsuit alleges.</p>
<p id="paragraph-127">Trollinger, who declined to comment, settled with SpaceX for an undisclosed sum, court records show.</p>
<p id="paragraph-128">In inspections following two other serious California injuries – the amputation of two fingers in 2017 and a serious knee injury in 2021 – CalOSHA levied fines of $750 and $5,060, respectively. When a worker’s finger was amputated this March, inspectors took no action and did not visit the site, records show.</p>
<p id="paragraph-129">After Texas worker Lonnie LeBlanc&nbsp;fell off a trailer and died in 2014, OSHA came to what it called an informal settlement with the company after inspectors found the safety lapses, OSHA records show. The settlement allowed SpaceX to pay a $7,000 fine.</p>
<p id="paragraph-130">LeBlanc’s brother, Chris Weimer, and an uncle, Ron Weimer, said the family didn’t know that OSHA had investigated the death and found violations until Reuters told them.</p>
<p id="paragraph-131">Ron Weimer said the hazardous nature of rocket-building is no excuse for his nephew’s death.</p>
<p id="paragraph-132">“There’s a way to do dangerous work,” he said, “without people dying.”</p>

    
</div><div data-id="RXHWDQ9IIA_36">
<p id="paragraph-155"><strong id="YZMW0S7GDT_37">Unsafe Space</strong></p>
<p id="paragraph-156">By Marisa Taylor</p>
<p id="paragraph-157">Additional reporting: Joey Roulette</p>
<p id="paragraph-158">Photo editing: Corinne Perkins</p>
<p id="paragraph-159">Video production: Evan Garcia, Olivia Zollino, Jane Ross, Ilan Rubens, Lucy Ha</p>
<p id="paragraph-160">Art direction: John Emerson</p>
<p id="paragraph-161">Edited by Michele Gershberg and&nbsp;Brian Thevenot</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft steals access data: Beware of the new Outlook (German) (144 pts)]]></title>
            <link>https://www.heise.de/news/Microsoft-krallt-sich-Zugangsdaten-Achtung-vorm-neuen-Outlook-9357691.html</link>
            <guid>38217457</guid>
            <pubDate>Fri, 10 Nov 2023 11:03:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/news/Microsoft-krallt-sich-Zugangsdaten-Achtung-vorm-neuen-Outlook-9357691.html">https://www.heise.de/news/Microsoft-krallt-sich-Zugangsdaten-Achtung-vorm-neuen-Outlook-9357691.html</a>, See on <a href="https://news.ycombinator.com/item?id=38217457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      <p>Das neue Outlook ist nicht, was es auf den ersten Blick scheint: ein Ersatz für das Outlook von Microsoft Office – jedenfalls noch nicht. Was es aber auf jeden Fall ist: entschieden zu neugierig.</p>

    
  

  
  <a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
    

  
    
    
  

  </a-paternoster>



<p>Microsoft lobt das neue Outlook in höchsten Tönen und will Nutzerinnen und Nutzer zum Umstieg bewegen. Doch Achtung: Wer das neue Outlook ausprobiert, riskiert die Übertragung seiner IMAP- und SMTP-Zugangsdaten zu Mailkonten sowie sämtlicher Mails an Microsoft-Server. Zwar erklärt Microsoft, der Wechsel zurück auf die bisherigen Apps sei jederzeit möglich – die Daten liegen dann aber schon beim Unternehmen. Microsoft kann dadurch die Mails mitlesen.</p>





  

<a-lightbox src="/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png">
      



<img alt="Screenshot vom Startmenü mit Empfehlung des neuen Outlooks." decoding="async" height="725" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/639/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png 1008w,
    https://heise.cloudimg.io/width/639/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png 639w,
    https://heise.cloudimg.io/width/1278/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/startmenue-09ab35eabcf56344.png 1278w
  " width="639" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>Nach dem 2023-Update von Windows 11 findet sich als empfohlene App das neue Outlook im Startmenü.</p>
      
        <p>
      (Bild:&nbsp;Screenshot / rei)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<p>Im Windows-Startmenü von <a href="https://www.heise.de/news/Jetzt-da-Windows-11-2023-Update-fuer-alle-oder-auch-nicht-9350212.html">Windows-11-Geräten mit 2023-Update</a> taucht inzwischen das neue Outlook als empfohlene App auf. Auch der Outlook-Client selbst bietet den Test der neuen Outlook-Version mit einem Schalter "Das neue Outlook" an. Die befindet sich noch in der Entwicklung, soll aber 2024 in Windows etwa das Mail-Programm und den mitgelieferten Kalender in Windows ersetzen. In einem <a href="https://techcommunity.microsoft.com/t5/outlook-blog/things-to-look-forward-to-in-the-new-outlook-for-windows/ba-p/3975602" rel="external noopener" target="_blank">aktuellen Techcommunity-Beitrag erklärt die Microsoft</a>-Angestellte Caitlin Hart zudem, dass auch das klassische Outlook damit ersetzt werden soll. Anders als bei den Windows-Apps Mail und Kalender steht der Zeitplan dafür jedoch noch nicht.</p>




<h3 id="nav_neues_outlook__0">Neues Outlook: Warnung vor Datenübertragungen</h3>
<p>Beim Hinzufügen eines Mail-Kontos im neuen Outlook, das nicht von Microsoft gehostet wird, sondern etwa auf Firmen-Mail-Servern liegt, zeigt das Programm einen Hinweis. Er <a href="https://support.microsoft.com/de-de/office/synchronisieren-ihres-kontos-in-outlook-mit-der-microsoft-cloud-985f9e19-d308-4e85-9d1d-0c6f32f8e981?ui=de-de&amp;rs=de-de&amp;ad=de" rel="external noopener" target="_blank">verlinkt auf einen Support-Artikel</a>, der lediglich ausformuliert, dass Nicht-Microsoft-Konten mit der Microsoft-Cloud synchronisiert werden, wobei bislang Gmail-, Yahoo-, iCloud- und IMAP-Konten unterstützt werden. Das macht das neue Outlook auch in den Fassungen für Android, iOS und Mac. Das bedeutet demnach, dass Kopien der "E-Mails, Kalender und Kontakte zwischen Ihrem E-Mail-Anbieter und Microsoft-Rechenzentren synchronisiert" werden. Damit erhält das Unternehmen vollen Zugriff auf alle Mails und kann diese lesen und auswerten. Damit wolle Microsoft Funktionen bereitstellen, die Gmail und IMAP nicht bieten würden.</p>





  

<a-lightbox src="/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png">
      



<img alt="Warnhinweis des neuen Outlooks" decoding="async" height="549" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/476/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png 1008w,
    https://heise.cloudimg.io/width/476/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png 476w,
    https://heise.cloudimg.io/width/952/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/outlook-warnung-e147ccf7fd4368f4.png 952w
  " width="476" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>Das neue Outlook liefert einen Warnhinweis, dass es Daten an Microsofts Cloud-Server überträgt.</p>
      
        <p>
      (Bild:&nbsp;Screenshot / rei)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<p>Der Hinweis macht stutzig: Was überträgt Microsoft dadurch wohin? Beim Anlegen eines IMAP-Kontos konnte die c't mitschneiden, dass Ziel-Server, Log-in-Name und Passwort an Microsofts Server übertragen werden. Zwar TLS-geschützt, aber im Tunnel laufen die Daten im Klartext zu Microsoft. Ohne darüber zu informieren oder nachzufragen, genehmigt sich Microsoft selbst Vollzugriff auf die IMAP- und SMTP-Zugangsdaten von Nutzern des neuen Outlooks.</p>








  

<a-lightbox src="/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png" tabindex="1">
  
    

<figure>

  <p><a href="https://www.heise.de/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png">
      



<img alt="Mitegschnittener Traffic zu MIcrosoft-Servern" decoding="async" height="369" loading="lazy" onload="this.style=null;" sizes="" src="https://heise.cloudimg.io/width/696/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png" srcset="
    https://heise.cloudimg.io/width/336/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png 336w,
    https://heise.cloudimg.io/width/1008/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png 1008w,
    https://heise.cloudimg.io/width/696/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png 696w,
    https://heise.cloudimg.io/width/1392/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/18/4/3/3/1/0/1/1/01-Traffic_Mitschnitt-330ad3a100639b8c.png 1392w
  " width="696" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">



      </a>
    

  </p>
    

<figcaption>    <p>Beim Einrichten von IMAP-Konten schickt das neue Outlook die Zugangsdaten und Serverinformationen an Microsoft.</p>
      
        <p>
      (Bild:&nbsp;Screenshot)
    </p>
</figcaption>

</figure>

  
</a-lightbox>





  





<h3 id="nav_andere_zugänge_1">Andere Zugänge</h3>
<p>Bei dem Schwenk vom alten Outlook auf das neue wird es parallel dazu installiert. Bislang eingerichtete IMAP-Konten werden nicht übernommen, aber das in Windows hinterlegte Konto schon. Bei der Prüfung mit Google-Konten kam die Authentifizierung mit OAuth2 zum Zuge. Dabei erhalten Nutzerinnen und Nutzer eine Authentifizierungsrückfrage und es landen immerhin keine konkreten Zugangsdaten bei Microsoft, sondern ein Zugriffstoken, den Nutzer auch wieder zurückziehen können.</p>
<p>Die Antwort auf unsere Anfrage zu einer Stellungnahme von Microsoft steht noch aus. Zum jetzigen Zeitpunkt müssen wir jedoch davor warnen, unbedacht das neue Outlook auszuprobieren. Neben den ganzen Mails landen dadurch teils sogar Zugangsdaten bei Microsoft.</p>
<p>Microsoft fiel bereits <a href="https://www.heise.de/news/Microsoft-IMAP-Umleitung-in-Outlook-nach-Office-Update-jetzt-auch-auf-Macs-7477743.html">Anfang des Jahres mit solchen dreisten Datenumleitungen auf.</a> Nach Office-Updates auf Mac-Rechnern leitete das Outlook dort die Daten ohne etwaige Rückfragen auf Microsofts Cloud-Server um. Damals schaffte Abhilfe, IMAP-Konten zu löschen und neu einzurichten. Das ist mit dem neuen Outlook derzeit offensichtlich jedoch nicht mehr hilfreich.</p>








<a-collapse media="(min-width: 993px)" sneak-peek="" toggle-class-on-media="a-box--full-bordered">
  
  <div data-collapse-content="" data-collapse-target="">
    
      <figure>
        
  <img alt="" src="https://heise.cloudimg.io/width/571/q50.png-lossy-50.webp-lossy-50.foil1/_www-heise-de_/imgs/71/2/3/9/0/2/9/8/tn_heise-investigativ_bg_SO-ac7d9bc452deac94.jpg" srcset="https://heise.cloudimg.io/width/1142/q30.png-lossy-30.webp-lossy-30.foil1/_www-heise-de_/imgs/71/2/3/9/0/2/9/8/tn_heise-investigativ_bg_SO-ac7d9bc452deac94.jpg 2x" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='696px' height='391px' viewBox='0 0 696 391'%3E%3Crect x='0' y='0' width='696' height='391' fill='%23f2f2f2'%3E%3C/rect%3E%3C/svg%3E">

  


        
      </figure>
    

    <div>

      

      
        <p>
          Viele Investigativ-Recherchen sind nur möglich dank Informationen, die Leser und Hinweisgeber direkt oder anonym an uns übermitteln. Wenn Sie selbst Kenntnis von einem Missstand haben, von dem die Öffentlichkeit erfahren sollte, können Sie uns einen anonymen Hinweis oder brisantes Material zukommen lassen. Nutzen Sie dafür bitte unseren anonymen und sicheren Briefkasten.
        </p>
      

      

        
          <ul>
        

          
            

            
              <li>
            

              
              
                <a href="https://heise.de/investigativ" title="zum anonymen Briefkasten">
                  zum anonymen Briefkasten
                </a>
              
            </li>
          
        </ul>
      

    </div>
  </div>
  
</a-collapse>


<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:dmk@heise.de" title="Dirk Knop">dmk</a>)</span>
<!-- RSPEAK_START -->
</p>

      <!-- RSPEAK_STOP -->

      

      

      

      <!-- RSPEAK_STOP -->

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moving our Encrypted DNS servers to run in RAM (279 pts)]]></title>
            <link>https://mullvad.net/en/blog/moving-our-encrypted-dns-servers-to-run-in-ram</link>
            <guid>38217355</guid>
            <pubDate>Fri, 10 Nov 2023 10:51:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mullvad.net/en/blog/moving-our-encrypted-dns-servers-to-run-in-ram">https://mullvad.net/en/blog/moving-our-encrypted-dns-servers-to-run-in-ram</a>, See on <a href="https://news.ycombinator.com/item?id=38217355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><time datetime="2023-11-10T09:03:20.562804Z">November 10, 2023</time> <a href="https://mullvad.net/en/blog/tag/system-transparency">System Transparency</a>&nbsp;</p>  <p>We recently <a href="https://mullvad.net/blog/2023/9/20/we-have-successfully-completed-our-migration-to-ram-only-vpn-infrastructure/">announced the completion</a> of our migration to remove all traces of disks in use on our VPN infrastructure.</p>

<p>Today we can announce more steps forward - our Encrypted DNS service has also been converted to run from RAM!</p>

<h2>Encrypted DNS for all - paying customers or not</h2>

<p>Encrypted DNS (also known as DNS over TLS and DNS over HTTPS) protects your DNS queries from being snooped on by third parties when <strong>not</strong> connected to our VPN service. DNS queries are encrypted between your device and our DNS servers.</p>

<p>Primarily as a service to be used when not connected to our VPN servers, this service is completely cost-free, and available to anyone that wishes to have a trustworthy, audited Encrypted DNS service with <a href="http://github.com/mullvad/dns-blocklists">optional content blocking</a>. This service is available from servers located worldwide, and can be configured by using the <a href="https://mullvad.net/help/dns-over-https-and-dns-over-tls/">following guide</a> on our website.</p>

<p>This service can be used in conjunction with our VPN service, but is discouraged, as it will always be slower than using the DNS resolver on the VPN server that you are connected to.</p>

<p>All of these Encrypted DNS servers are configured using the same Linux kernel, with the same level of security and privacy as the as our VPN infrastructure. This is the next step towards running our stateless infrastructure from RAM.</p><!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Write Your Own Terminal (119 pts)]]></title>
            <link>https://flak.tedunangst.com/post/write-your-own-terminal</link>
            <guid>38216400</guid>
            <pubDate>Fri, 10 Nov 2023 08:15:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flak.tedunangst.com/post/write-your-own-terminal">https://flak.tedunangst.com/post/write-your-own-terminal</a>, See on <a href="https://news.ycombinator.com/item?id=38216400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>What’s next after you write your own text editor and mail client? How about a terminal? In fact, as a practice exercise or to learn some new skills, I’d say a terminal emulator makes for a much better target. It’s composed of many parts, but at an approachable level, making it easy to make tangible progress. In this way, I think it makes for a good introductory project. At the same time, there’s a very long tail of features that can be added to keep things interesting.</p><p>Compared to some other make your own projects, I think it’s possible to get a terminal up to self hosting status very quickly, after which one can whittle away at the rest. But the missing features don’t hamper progress, and one can get the satisfaction of using it for real. When I think about the experience of using my own text editor for anything but demo purposes, it does not spark joy.<br></p><h3>outline</h3><p>There are many ways to choose your own adventure, but here’s one way to break it down.</p><p>The most obvious thing to notice about a terminal is it consists of a window of text on the screen. So getting some basic text, like the word hello, on the screen would be one first objective.</p><p>This could be as simple as a text area in Qt, which would let you get moving pretty quickly.</p><p>A more challenging option might be to use OpenGL and render everything manually. This certainly opens the door for fooling around with some hilariously useless graphics effects later on. A terminal is not usually one’s first thought for an example 3D application, but that possibly makes it even better as an introduction to shaders, etc. The OpenGL pipeline is easier to understand without also trying to absorb all the matrix math at the same time. This is admittedly a big step to undertake for the first time. Some more notes below.</p><p>The <a href="https://freetype.org/freetype2/docs/tutorial/step1.html">FreeType tutorial</a> is easy to follow and mostly sufficient for a terminal. We don’t need to worry about kerning and ligatures, etc.</p><p>It’s also possible to write a terminal in a terminal, like tmux, but I’d save this for my second attempt. It’s very helpful to have a place to dump logging info that’s not also the screen we’re writing to.</p><p>Next we need an input handler for the keyboard. Press any key, see any key appear in the text area.</p><p>Once we can draw and update some text, we can try reading output from a simple command, like ls. We read from a file, and put the contents on the screen. As long as the text is legible, it’s good enough. Always time to adjust the font size later.</p><p>But what’s a terminal without a psuedo terminal? The <a href="https://man.openbsd.org/openpty">forkpty</a> function will probably be of interest.</p><p>At this point, we should be pretty close to running a shell. Change ls to sh.  Does it work? At this point, if not done yet, we may need to figure out scrolling when we run ls -l /usr/bin. This is already starting to become useful for basic shell tasks.</p><p>Time to handle some subset of vt100/ansi/xterm escape sequences. This is certainly easier to handle if you’ve written a terminal app, or even just a basic printf(“^<a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.txt">32m“) to get green text. This is a huge rabbit hole, but it’s easy to take one step at a time. Colors are a simple starting point.</a></p><p><a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.txt">A slightly more complicated application is top. It uses some of the basic cursor movement and screen clearing functions. Just implementing the H, J, K commands is enough to see visible progress.</a></p><p><a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.txt">The most complete documentation for escape sequences is the [xterm reference</a> although it’s not an easy document to read top to bottom. The <a href="https://wezfurlong.org/wezterm/escape-sequences.html">wezterm</a> documentation focuses a lot on colors, with an empty section for cursor movement, but also contains some useful links such as to the <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">ANSI escape code</a> on wikipedia. There’s many ways of explaining the same archaic concepts, so it helps to skim a few resources.</p><p>With a few more sequences implemented, (r to set scroll region being a notable one), more programs like vi should start to work.</p><p>And that’s a terminal emulator.<br></p><h3>long tail</h3><p>There’s still so much more to do, compared to any terminal widely used, but ticking off more boxes is pretty easy in isolation. There’s a hundred more escape sequences, but usually only a few minutes work each. Many of them end up being duplicates or variations of other codes, the result of a long twisted history.</p><p>Similarly one can add scroll back. Copy and paste just the way you like it.</p><p>I didn’t think selecting and copying text would be difficult, but I was quite surprised at how easy it came together. And the same for some other features I’d put off while I poked around trying to find more escape sequences to implement. In the end, I decided <br>let’s just use this thing, add my required features, and it all came together.</p><p>Special keys like arrows require specific handling and weird retro encodings. Another example of a feature which one can get by without, but which also only takes a minute to implement when you finally need it.</p><p>Endless work remaining, but it’s already very useful. I alternate my time between fixing up xterm conformance, improving the performance of the scrollback, and fine tuning the font size selection algorithm.</p><p>And just now there’s <a href="https://monaspace.githubnext.com/">monaspace</a> which promises to challenge the simplicity of font rendering.</p><p>Overall, what I really liked about this project was that I could defer work, but without compromising the project with hacks. For a long time, I didn’t even have my character glyphs properly aligned to the baseline. I simply wrote that code a bit later, but it was the same code I would have written at any earlier point. And in the mean time, I got to see what’s over the next hill.<br></p><h3>opengl</h3><p>Selecting the OpenGL option opens up a pretty long side quest. It’s overkill for a simple terminal emulator, but also way more fun once you get going. I think it’s worthwhile, we’re here to learn after all, but not at all necessary.</p><p>A good place to start would be something really basic like the glfw triangle demo, and then manipulate it to get textures. Alas, raw OpenGL code is very heavy on boiler plate and repetition.</p><p>It really helps if you can start with an abandoned game engine that provides helpful abstractions. It’s pretty long, but this video on <a href="https://www.youtube.com/watch?v=BwCqRqqbB1Y">renderer abstraction</a> and some others from the cherno’s game engine series help. There’s plenty of other resources; I like this series from a few years ago because of the focus on practical realities of programming, not just graphical demos.</p><p>It’s possible to skip writing the abstraction, or use something else entirely (like godot maybe?), but I found the experience very informative. And now I have some code that lets me get any other OpenGL project up and running much faster. (Although technically, I already had it and this is my other project.)</p><p>In contrast to traditional OpenGL starter projects, this one doesn’t plunge down into the rabbit hole of materials and shadow maps, etc. Unless you want it to. You can be very inefficient to start, but there’s still room to then later refine and use better techniques like instancing.</p><p>Most importantly, I don’t think learning to do 2D in OpenGL will teach you anything that won’t help you learn 3D later, if you haven’t done so.</p><p>Or go hard mode and do it in Vulkan.
</p></div><p>
Posted 10 Nov 2023 07:44 by tedu Updated: 10 Nov 2023 07:44 
<br>Tagged: <a href="https://flak.tedunangst.com/t/programming">programming</a> <a href="https://flak.tedunangst.com/t/software">software</a>
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Albert Einstein in 1939 composed a message for the people of AD 6939 (229 pts)]]></title>
            <link>https://www.futilitycloset.com/2023/11/10/comment-8/</link>
            <guid>38216353</guid>
            <pubDate>Fri, 10 Nov 2023 08:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.futilitycloset.com/2023/11/10/comment-8/">https://www.futilitycloset.com/2023/11/10/comment-8/</a>, See on <a href="https://news.ycombinator.com/item?id=38216353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<main id="main" role="main">

		
			
<article id="post-66173">
	
	<div>
			<p>Preparing a time capsule in 1939, the Westinghouse Electric &amp; Manufacturing Company asked Albert Einstein to compose a message for the people of AD 6939. He sent this:</p>
<blockquote><p>
Our time is rich in inventive minds, the inventions of which could facilitate our lives considerably. We are crossing the seas by power and utilize power also in order to relieve humanity from all tiring muscular work. We have learned to fly and we are able to send messages and news without any difficulty over the entire world through electric waves.</p>
<p>However, the production and distribution of commodities is entirely unorganized so that everybody must live in fear of being eliminated from the economic cycle, in this way suffering for the want of everything. Furthermore, people living in different countries kill each other at irregular time intervals, so that also for this reason any one who thinks about the future must live in fear and terror. This is due to the fact that the intelligence &amp; character of the masses are incomparably lower than the intelligence and character of the few who produce some thing valuable for the community.</p>
<p>I trust that posterity will read these statements with a feeling of proud and justified superiority.
</p></blockquote>
<p>The message was recorded on microfilm and resides 50 feet below Flushing Meadows–Corona Park in New York City.</p>
<p>(<a href="https://en.wikisource.org/wiki/Book_of_Record_of_the_Time_Capsule_of_Cupaloy">“Book of Record of the Time Capsule of Cupaloy,”</a> 1939.)</p>

					</div><!-- .entry-content -->
</article><!-- #post-## -->
				<!-- .navigation -->
	
			
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Skipped to the Ending (506 pts)]]></title>
            <link>https://danangell.com/blog/posts/i-skipped-to-the-ending/</link>
            <guid>38216196</guid>
            <pubDate>Fri, 10 Nov 2023 07:39:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danangell.com/blog/posts/i-skipped-to-the-ending/">https://danangell.com/blog/posts/i-skipped-to-the-ending/</a>, See on <a href="https://news.ycombinator.com/item?id=38216196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>When I was 8 years old I started making websites with my friend. His grandmother had purchased him a domain name and web hosting. It was 2003 and the world was whispering of Web 2.0. Books I checked out of the library talked about DHTML (dynamic HTML, basically what any web app is today). There was no mobile app market, native application development had a high barrier to entry, and the most exciting things happening with computers were websites like eBay and Google.</p>
<p>Together my friend and I would make silly web pages. Basic things like choose-your-own-adventures were fun and easy to make. All you needed were some links to the next pages and you’ve made a game! We of course had the most offensive color schemes imaginable. We had 24-bit JPEG backgrounds of landscapes and tropical coasts. They were the most beautiful images I could find online, so why <em>shouldn’t</em> they be the backing for my red 12pt Times New Roman text?</p>
<p>At some point I saw a picture in the Philadelphia Inquirer of a slide in an office building and an all-you-can-eat <em>free</em> candy dispenser. Google was becoming the first “web scale” company in real time. And they were rewarding the employees handsomely for reshaping the world. Every year they would release a reality-altering product. Google Earth blew my mind. I could spend hours scanning around in the American deserts finding interesting canyons and mountains. In high school I had my own personal site that functioned mostly as a blog. It was a major point of pride that I wrote the HTML and CSS by hand - I even made the graphics myself in Paint. At least one post showcased the highlights of my discoveries in the satellite imagery of Google Earth.</p>
<p>My family would all talk about how some day I’d work for Google. I believed them and considered Google to be the apex of a programmer’s career. They paid the most, got the most done, and their employees held the most respect.</p>
<p>So when I graduated with my Bachelor’s in CS and got a cold email from a recruiter I was ecstatic! Soon they flew me off to interview on-site in Seattle. I can only guess why, but I did not make the cut. My fall-back was to go work in startups in Silicon Valley. I already had a few good projects, co-ops, and part time jobs under my belt. My experience earned me a few competing job offers. I picked the better of the two and moved across the country.</p>
<p>What shocked me was how healthy the startup job was. There was no grinding, a good work-life balance, and a set of 20 kind and knowledgeable co-workers. Everyone was there because they <em>wanted</em> to be there. We all wanted to build something, together. I sat next to the founding engineer for a year and learned more per day than I ever had before or have since. The guy was notoriously blunt. His bluntness honed my edge.</p>
<p>During the pandemic I switched jobs to work at a rapidly growing startup in the emerging AI/LLM space. I had dropped into a runaway success. After only 8 months the founders had achieved thousands of signups per day, millions in ARR, and I was here to rewrite everything from scratch. We shipped the rewrite after a couple of months and used the fire hose of new users to iterate on on-boarding and product functionality. Being able to go from ticket to PR, LGTM, release, and get metrics in a hour is an amazing way to learn. Consistent, fast feedback is one of the <a href="https://www.youtube.com/watch?v=5eW6Eagr9XA">key aspects</a> to becoming an expert.</p>
<p>But for all of the team’s virtues we also had our failings. Soon it became clear that we didn’t have a strong direction in the face of a rapidly changing landscape. A GPT-3 app could not stand still, certainly not one with VC funding. I started to grow uncertain of the value of my time spent there. Then I got another cold email from Google. They wanted me to interview again. I gave it a shot and got an offer for an L4 SWE position. After almost 20 years I had gotten into the magic place with slides and free candy.</p>
<p>Figuring I might as well take the opportunity to try some different work, I joined a team working on phone firmware. After a couple of weeks the tech lead quit. My manager would often not reply to my emails. They told me I didn’t need to do any work for the first couple of months. This is the last thing I wanted to hear. When I did get work assigned I was immediately thrown into the jaws of bureaucracy. A project to help us track errors in production would take months. Most of that time got allocated to getting Privacy Council approval because we would be logging strings. My team all lived nearby but rarely came in to the office. Virtual meetings were held with cameras off. Co-workers started quitting left and right.</p>
<p>I came to realize that I had joined the wrong version of the team. There was one team working on this product specifically for first-party phones, and another for the platform at large. But because Google refused to offer support to 3rd party OEMs, even at a price, none would sign on. Hiring got frozen so I couldn’t switch to the “real” team.</p>
<p>And so my new skip manager told me he would have the team shut down and I switched to an adjacent team managing a certificate authority. This would be web-based work. After my failed entry into Rust firmware development I was glad to go back to my roots.</p>
<p>As it turned out, the web side of this project was maintained by another department. I was on loan to them. I got assigned a “dotted-line manager”. When I first met him he gave me a speech about how he didn’t want to hear anything about my working on 20% projects - “they always end up being more than 20%”. He didn’t want me to get pulled into work by my direct manager. He felt he owned me.</p>
<p>After finishing my first project I made the mistake of picking up new work because I had nothing else to do. Mr. Dotted-Line and his team had put together a list of tasks for the next few quarters without me. I picked the first unassigned item in the document and sent out a design document for what would end up being 200-300 lines of code. Big mistake - I was going rogue. Dotted-Line contacted my skip manager demanding I be reined in. My skip and direct managers had my back, but I still felt awful. Was I not supposed to be learning? Building?</p>
<p>Not that my other managers were amazing to be around. My direct manager would fantasize about monetizing male loneliness through futuristic sex robots. Later, when my skip manager was staging a coup to steal Dotted-Line’s project he pulled the other guy into a call. During the call he opened up a group chat with my team, writing:</p>
<blockquote>
<p><strong>Skip</strong>: He is fighting it</p>
<p><strong>Skip</strong>: But he also looks like his dog got shot</p>
<p><strong>Skip</strong>: He is now pitching for us to work better together</p>
<p><strong>Skip</strong>: Feels like a breakup lol</p>
</blockquote>
<p>…no one responded.</p>
<p>“Those guys over there are so toxic” was a favorite phrase for him.</p>
<p>As I realized this project was no better than the last one I made my complaints clear to my direct manager. I told him my issues were with the company itself and had no optimism that working on yet another project would fix things.</p>
<p>He told me (paraphrasing) “Well, you know it’s really a lot of paper-work to fire you. You could just get away with doing nothing for 12 months.” Again, not what I wanted to hear. Why tell me this? Presumably for him this was a way to pad his head-count. One of the primary metrics for leadership success at Google is how many people you have under you. It doesn’t matter if one, two, or more aren’t working - as long as you are meeting your self-defined OKRs you’ll look good.</p>
<p>It’s the same motivator for why my dotted-line manager wanted to steal me. Hiring got frozen - the only way to get that sweet sweet head-count is to take it from someone else.</p>
<p>So after 15 months I was out of there. I learned that I don’t care about the money Google pays. I don’t care about the high scale of influence your work can have. I skipped from series A startup to mature IPO’d company and cheated myself out of the experiences you get in-between. I want to <em>earn</em> the scale through hard work. For me FAANG was not a place to learn, it was a way to get paid. But I didn’t come to Silicon Valley to get paid.</p>
<hr>
<p><sup>
    <i>
        P.S: I want to be clear that all of the ICs I worked with were great. If any of them read this they should know I appreciated their time spent working with me.
    </i>
</sup>

        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust – Faster compilation with the parallel front-end in nightly (331 pts)]]></title>
            <link>https://blog.rust-lang.org/2023/11/09/parallel-rustc.html</link>
            <guid>38216176</guid>
            <pubDate>Fri, 10 Nov 2023 07:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.rust-lang.org/2023/11/09/parallel-rustc.html">https://blog.rust-lang.org/2023/11/09/parallel-rustc.html</a>, See on <a href="https://news.ycombinator.com/item?id=38216176">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>The Rust compiler's front-end can now use parallel execution to significantly
reduce compile times. To try it, run the nightly compiler with the <code>-Z threads=8</code> option. This feature is currently experimental, and we aim to ship
it in the stable compiler in 2024.</p>
<p>Keep reading to learn why a parallel front-end is needed and how it works, or
just skip ahead to the <a href="https://blog.rust-lang.org/2023/11/09/parallel-rustc.html#how-to-use-it">How to use it</a>
section.</p>
<h2>Compile times and parallelism</h2>
<p>Rust compile times are a perennial concern. The <a href="https://www.rust-lang.org/governance/teams/compiler#Compiler%20performance%20working%20group">Compiler Performance Working
Group</a>
has continually improved compiler performance for several years. For example,
in the first 10 months of 2023, there were mean reductions in compile time of
<a href="https://perf.rust-lang.org/compare.html?start=2023-01-01&amp;end=2023-10-31&amp;stat=wall-time&amp;nonRelevant=true">13%</a>,
in peak memory use of
<a href="https://perf.rust-lang.org/compare.html?start=2023-01-01&amp;end=2023-10-31&amp;stat=max-rss&amp;nonRelevant=true">15%</a>,
and in binary size of
<a href="https://perf.rust-lang.org/compare.html?start=2023-01-01&amp;end=2023-10-31&amp;stat=size%3Alinked_artifact&amp;nonRelevant=true">7%</a>,
as measured by our performance suite.</p>
<p>However, at this point the compiler has been heavily optimized and new
improvements are hard to find. There is no low-hanging fruit remaining.</p>
<p>But there is one piece of large but high-hanging fruit: parallelism. Current
Rust compiler users benefit from two kinds of parallelism, and the newly
parallel front-end adds a third kind.</p>
<h3>Existing interprocess parallelism</h3>
<p>When you compile a Rust program, Cargo launches multiple rustc processes,
compiling multiple crates in parallel. This works well. Try compiling a large
Rust program with the <code>-j1</code> flag to disable this parallelization and it will
take a lot longer than normal.</p>
<p>You can visualise this parallelism if you build with Cargo's
<a href="https://doc.rust-lang.org/cargo/reference/timings.html"><code>--timings</code></a> flag,
which produces a chart showing how the crates are compiled. The following image
shows the timeline when building <a href="https://crates.io/crates/ripgrep">ripgrep</a> on
a machine with 28 virtual cores.</p>
<p><img src="https://blog.rust-lang.org/images/2023-11-09-parallel-rustc/cargo-build-timings.png" alt="cargo build --timings output when compiling ripgrep"></p>
<p>There are 60 horizontal lines, each one representing a distinct process. Their
durations range from a fraction of a second to multiple seconds. Most of them
are rustc, and the few orange ones are build scripts. The first twenty processes all
start at the same time. This is possible because there are no dependencies
between the relevant crates. But further down the graph, parallelism reduces as
crate dependencies increase. Although the compiler can overlap compilation of
dependent crates somewhat thanks to a feature called <a href="https://github.com/rust-lang/rust/issues/60988">pipelined
compilation</a>, there is much
less parallel execution happening towards the end of compilation, and this is
typical for large Rust programs. Interprocess parallelism is not enough to take
full advantage of many cores. For more speed, we need parallelism within each process.</p>
<h3>Existing intraprocess parallelism: the back-end</h3>
<p>The compiler is split into two halves: the front-end and the back-end.</p>
<p>The front-end does many things, including parsing, type checking, and borrow
checking. Until this week, it could not use parallel execution.</p>
<p>The back-end performs code generation. It generates code in chunks called
"codegen units" and then LLVM processes these in parallel. This is a form of
coarse-grained parallelism.</p>
<p>We can visualize the difference between the serial front-end and the parallel
back-end. The following image shows the output of a profiler called
<a href="https://github.com/mstange/samply/">Samply</a> measuring rustc as it does a
release build of the final crate in Cargo. The image is superimposed with
markers that indicate front-end and back-end execution.</p>
<p><img src="https://blog.rust-lang.org/images/2023-11-09-parallel-rustc/samply-serial.png" alt="Samply output when compiling Cargo, serial"></p>
<p>Each horizontal line represents a thread. The main thread is labelled "rustc"
and is shown at the bottom. It is busy for most of the execution. The other 16
threads are LLVM threads, labelled "opt cgu.00" through to "opt cgu.15". There
are 16 threads because 16 is the default number of codegen units for a release
build.</p>
<p>There are several things worth noting.</p>
<ul>
<li>Front-end execution takes 10.2 seconds.</li>
<li>Back-end execution occurs takes 6.2 seconds, and the LLVM threads are running
for 5.9 seconds of that.</li>
<li>The parallel code generation is highly effective. Imagine if all those LLVM
executed one after another!</li>
<li>Even though there are 16 LLVM threads, at no point are all 16 executing at
the same time, despite this being run on a machine with 28 cores. (The peak
is 14 or 15.) This is because the main thread translates its internal code
representation (MIR) to LLVM's code representation (LLVM IR) in serial. This
takes a brief period for each codegen unit, and explains the staircase shape
on the left-hand side of the code generation threads. There is some room for
improvement here.</li>
<li>The front-end is entirely serial. There is a lot of room for improvement
here.</li>
</ul>
<h3>New intraprocess parallelism: the front-end</h3>
<p>The front-end is now capable of parallel execution. It uses
<a href="https://crates.io/crates/rayon">Rayon</a> to perform compilation tasks using
fine-grained parallelism. Many data structures are synchronized by mutexes and
read-write locks, atomic types are used where appropriate, and many front-end
operations are made parallel. The addition of parallelism was done by modifying
a relatively small number of key points in the code. The vast majority of the
front-end code did not need to be changed.</p>
<p>When the parallel front-end is enabled and configured to use eight threads, we
get the following Samply profile when compiling the same example as before.</p>
<p><img src="https://blog.rust-lang.org/images/2023-11-09-parallel-rustc/samply-parallel.png" alt="Samply output when compiling Cargo, parallel"></p>
<p>Again, there are several things worth noting.</p>
<ul>
<li>Front-end execution takes 5.9 seconds (down from 10.2 seconds).</li>
<li>Back-end execution takes 5.3 seconds (down from 6.2 seconds), and the LLVM
threads are running for 4.9 seconds of that (down from 5.9 seconds).</li>
<li>There are seven additional threads labelled "rustc" operating in the
front-end. The reduced front-end time shows they are reasonably effective,
but the thread utilization is patchy, with the eight threads all having
periods of inactivity. There is room for significant improvement here.</li>
<li>Eight of the LLVM threads start at the same time. This is because the eight
"rustc" threads create the LLVM IR for eight codegen units in parallel. (For
seven of those threads that is the only work they do in the back-end.) After
that, the staircase effect returns because only one "rustc" thread does LLVM
IR generation while seven or more LLVM threads are active. If the number of
threads used by the front-end was changed to 16 the staircase shape would
disappear entirely, though in this case the final execution time would barely
change.</li>
</ul>
<h3>Putting it all together</h3>
<p>Rust compilation has long benefited from interprocess parallelism, via Cargo,
and from intraprocess parallelism in the back-end. It can now also benefit from
intraprocess parallelism in the front-end.</p>
<p>You might wonder how interprocess parallelism and intraprocess parallelism
interact. If we have 20 parallel rustc invocations and each one can have up to
16 threads running, could we end up with hundreds of threads on a machine with
only tens of cores, resulting in inefficient execution as the OS tries its best
to schedule them?</p>
<p>Fortunately no. The compiler uses the <a href="https://www.gnu.org/software/make/manual/html_node/POSIX-Jobserver.html">jobserver
protocol</a>
to limit the number of threads it creates. If a lot of interprocess parallelism
is occuring, intraprocess parallelism will be limited appropriately, and
the number of threads will not exceed the number of cores.</p>
<h2>How to use it</h2>
<p>The nightly compiler is now <a href="https://github.com/rust-lang/rust/pull/117435">shipping with the parallel front-end
enabled</a>. However, <strong>by default
it runs in single-threaded mode</strong> and won't reduce compile times.</p>
<p>Keen users can opt into multi-threaded mode with the <code>-Z threads</code> option. For
example:</p>
<pre><code>$ RUSTFLAGS="-Z threads=8" cargo build --release
</code></pre>
<p>Alternatively, to opt in from a
<a href="https://doc.rust-lang.org/cargo/reference/config.html">config.toml</a> file (for
one or more projects), add these lines:</p>
<pre><code>[build]
rustflags = ["-Z", "threads=8"]
</code></pre>
<p>It may be surprising that single-threaded mode is the default. Why parallelize
the front-end and then run it in single-threaded mode? The answer is simple:
caution. This is a big change! The parallel front-end has a lot of new code.
Single-threaded mode exercises most of the new code, but excludes the
possibility of threading bugs such as deadlocks that can affect multi-threaded
mode. Even in Rust, parallel programs are harder to write correctly than serial
programs. For this reason the parallel front-end also won't be shipped in beta
or stable releases for some time.</p>
<h3>Performance effects</h3>
<p>When the parallel front-end is run in single-threaded mode, compilation times
are typically 0% to 2% slower than with the serial front-end. This should be
barely noticeable.</p>
<p>When the parallel front-end is run in multi-threaded mode with <code>-Z threads=8</code>,
our <a href="https://github.com/rust-lang/compiler-team/issues/681">measurements on real-world
code</a> show that compile
times can be reduced by up to 50%, though the effects vary widely and depend on
the characteristics of the code and its build configuration. For example, dev
builds are likely to see bigger improvements than release builds because
release builds usually spend more time doing optimizations in the back-end. A
small number of cases compile more slowly in multi-threaded mode than
single-threaded mode. These are mostly tiny programs that already compile
quickly.</p>
<p>We recommend eight threads because this is the configuration we have tested the
most and it is known to give good results. Values lower than eight will see
smaller benefits, but are appropriate if your hardware has fewer than eight
cores. Values greater than eight will give diminishing returns and may even
give worse performance.</p>
<p>If a 50% improvement seems low when going from one to eight threads, recall
from the explanation above that the front-end only accounts for part of compile
times, and the back-end is already parallel. You can't beat <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's
Law</a>.</p>
<p>Memory usage can increase significantly in multi-threaded mode. We have seen
increases of up to 35%. This is unsurprising given that various parts of
compilation, each of which requires a certain amount of memory, are now
executing in parallel.</p>
<h3>Correctness</h3>
<p>Reliability in single-threaded mode should be high.</p>
<p>In multi-threaded mode there are some known bugs, including deadlocks. If
compilation hangs, you have probably hit one of them.</p>
<p>The binaries produced by the compiler are expected to be the same no matter
which front-end is being used. Any differences will be considered a bug.</p>
<h3>Feedback</h3>
<p>If you have any problems with the parallel front-end, please <a href="https://github.com/rust-lang/rust/labels/WG-compiler-parallel">check the issues
marked with the "WG-compiler-parallel"
label</a>.
If your problem does not match any of the existing issues, please file a new
issue.</p>
<p>For more general feedback, please start a discussion on the <a href="https://rust-lang.zulipchat.com/#narrow/stream/187679-t-compiler.2Fwg-parallel-rustc">wg-parallel-rustc
Zulip
channel</a>.
We are particularly interested to hear the performance effects on the code you
care about.</p>
<h2>Future work</h2>
<p>We are working to improve the performance of the parallel front-end. As the
graphs above showed, there is room to improve the utilization of the threads in
the front-end. We are also ironing out the remaining bugs in multi-threaded
mode.</p>
<p>We aim to stabilize the <code>-Z threads</code> option and ship the parallel front-end
running by default in multi-threaded mode on stable releases in 2024.</p>
<h2>Acknowledgments</h2>
<p>The parallel front-end has been under development for a long time. It was
started by <a href="https://github.com/Zoxc/">@Zoxc</a>, who also did most of the work for
several years. After a period of inactivity, the project was revived this year
by <a href="https://github.com/sparrowlii/">@SparrowLii</a>, who led the effort to get it
shipped. Other members of the Parallel Rustc Working Group have also been
involved with reviews and other activities. Many thanks to everyone involved.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What process created this X11 window? (102 pts)]]></title>
            <link>https://unix.stackexchange.com/questions/5478/what-process-created-this-x11-window</link>
            <guid>38215545</guid>
            <pubDate>Fri, 10 Nov 2023 05:57:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unix.stackexchange.com/questions/5478/what-process-created-this-x11-window">https://unix.stackexchange.com/questions/5478/what-process-created-this-x11-window</a>, See on <a href="https://news.ycombinator.com/item?id=38215545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>Unless your X-server supports <code>XResQueryClientIds</code> from <a href="http://www.x.org/releases/X11R7.7/doc/resourceproto/resproto.txt" rel="noreferrer">X-Resource v1.2 extension</a> I know no <em>easy</em> way to <em>reliably</em> request process ID. There're other ways however.</p>

<p>If you just have a window in front of you and don't know its ID yet — it's easy to find it out. Just open a terminal next to the window in question, run <code>xwininfo</code> there and click on that window. <code>xwininfo</code> will show you the window-id.</p>

<p>So let's assume you know a window-id, e.g. 0x1600045, and want to find, what's the process owning it.</p>

<p>The easiest way to check who that window belongs to is to run XKillClient for it i.e.:</p>

<pre><code>xkill -id 0x1600045
</code></pre>

<p>and see which process just died. But only if you don't mind killing it of course!</p>

<p>Another easy but unreliable way is to check its <code>_NET_WM_PID</code> and <code>WM_CLIENT_MACHINE</code> properties:</p>

<pre><code>xprop -id 0x1600045
</code></pre>

<p>That's what tools like <code>xlsclients</code> and <a href="http://www.freedesktop.org/wiki/Software/xrestop/" rel="noreferrer"><code>xrestop</code></a> do.</p>

<p>Unfortunately this information may be incorrect not only because the process was evil and changed those, but also because it was buggy. For example after some firefox crash/restart I've seen orphaned windows (from flash plugin, I guess) with <code>_NET_WM_PID</code> pointing to a process, that died long time ago.</p>

<p>Alternative way is to run</p>

<pre><code>xwininfo -root -tree
</code></pre>

<p>and check properties of parents of the window in question. That may also give you some hints about window origins.</p>

<p>But! While you may not find what process have created that window, there's still a way to find where that process have connected to X-server from. And that way is for real hackers. :)</p>

<p>The window-id 0x1600045 that you know with lower bits zeroed (i.e. 0x1600000) is a "client base". And all resource IDs, allocated for that client are "based" on it (0x1600001, 0x1600002, 0x1600003, etc). X-server stores information about its clients in clients[] array, and for each client its "base" is stored in clients[i]-&gt;clientAsMask variable. To find X-socket, corresponding to that client, you need to attach to X-server with <code>gdb</code>, walk over clients[] array, find client with that <code>clientAsMask</code> and print its socket descriptor, stored in ((OsCommPtr)(clients[i]-&gt;osPrivate))-&gt;fd.</p>

<p>There may be many X-clients connected, so in order to not check them all manually, let's use a gdb function:</p>

<pre><code>define findclient
  set $ii = 0
  while ($ii &lt; currentMaxClients)
    if (clients[$ii] != 0 &amp;&amp; clients[$ii]-&gt;clientAsMask == $arg0 &amp;&amp; clients[$ii]-&gt;osPrivate != 0)
      print ((OsCommPtr)(clients[$ii]-&gt;osPrivate))-&gt;fd
    end
    set $ii = $ii + 1
  end
end
</code></pre>

<p>When you find the socket, you can check, who's connected to it, and finally find the process.</p>

<p><strong>WARNING</strong>: Do NOT attach gdb to X-server from INSIDE the X-server. gdb suspends the process it attaches to, so if you attach to it from inside X-session, you'll freeze your X-server and won't be able to interact with gdb. You must either switch to text terminal (<code>Ctrl+Alt+F2</code>) or connect to your machine over ssh.</p>

<h2>Example:</h2>

<ol>
<li><p>Find the PID of your X-server:</p>

<pre><code>$ ps ax | grep X
 1237 tty1     Ssl+  11:36 /usr/bin/X :0 vt1 -nr -nolisten tcp -auth /var/run/kdm/A:0-h6syCa
</code></pre></li>
<li><p>Window id is 0x1600045, so client base is 0x1600000. Attach to X-server and find client socket descriptor for that client base. You'll need debug information
installed for X-server (-debuginfo package for rpm-distributions or -dbg package for deb's).</p>

<pre><code>$ sudo gdb
(gdb) define findclient
Type commands for definition of "findclient".
End with a line saying just "end".
&gt;  set $ii = 0
&gt;  while ($ii &lt; currentMaxClients)
 &gt;   if (clients[$ii] != 0 &amp;&amp; clients[$ii]-&gt;clientAsMask == $arg0 &amp;&amp; clients[$ii]-&gt;osPrivate != 0)
  &gt;     print ((OsCommPtr)(clients[$ii]-&gt;osPrivate))-&gt;fd
  &gt;     end
 &gt;   set $ii = $ii + 1
 &gt;   end
&gt;  end
(gdb) attach 1237
(gdb) findclient 0x1600000
$1 = 31
(gdb) detach
(gdb) quit
</code></pre></li>
<li><p>Now you know that client is connected to a server socket 31. Use <code>lsof</code> to find what that socket is:</p>

<pre><code>$ sudo lsof -n | grep 1237 | grep 31
X        1237    root   31u   unix 0xffff810008339340       8512422 socket
</code></pre>

<p>(here "X" is the process name, "1237" is its pid, "root" is the user it's running from, "31u" is a socket descriptor)</p>

<p>There you may see that the client is connected over TCP, then you can go to the machine it's connected from and check <code>netstat -nap</code> there to find the process. But most probably you'll see a unix socket there, as shown above, which means it's a local client.</p></li>
<li><p>To find a pair for that unix socket you can use the <a href="https://serverfault.com/a/417946">MvG's technique</a>
(you'll also need debug information for your kernel installed):</p>

<pre><code>$ sudo gdb -c /proc/kcore
(gdb) print ((struct unix_sock*)0xffff810008339340)-&gt;peer
$1 = (struct sock *) 0xffff810008339600
(gdb) quit
</code></pre></li>
<li><p>Now that you know client socket, use <code>lsof</code> to find PID holding it:</p>

<pre><code>$ sudo lsof -n | grep 0xffff810008339600
firefox  7725  username  146u   unix 0xffff810008339600       8512421 socket
</code></pre></li>
</ol>

<p>That's it. The process keeping that window is "firefox" with process-id 7725</p>

<hr>

<p><strong>2017 Edit</strong>: There are more options now as seen at <a href="https://unix.stackexchange.com/q/16300">Who's got the other end of this unix socketpair?</a>. With Linux 3.3 or above and with <code>lsof</code> 4.89 or above, you can replace points 3 to 5 above with:</p>

<pre><code>lsof +E -a -p 1237 -d 31
</code></pre>

<p>to find out who's at the other end of the socket on fd 31 of the X-server process with ID 1237.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple has a memory problem and we're all paying for it (208 pts)]]></title>
            <link>https://www.macworld.com/article/2130071/m3-macbook-pro-8gb-memory-too-little.html</link>
            <guid>38215413</guid>
            <pubDate>Fri, 10 Nov 2023 05:32:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macworld.com/article/2130071/m3-macbook-pro-8gb-memory-too-little.html">https://www.macworld.com/article/2130071/m3-macbook-pro-8gb-memory-too-little.html</a>, See on <a href="https://news.ycombinator.com/item?id=38215413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="link_wrapped_content">




<p>It should probably not be a controversial opinion that, in late 2023 (and surely through most of 2024), one should not sell a pricey “Pro” computer with only 8GB of RAM. And yet here we are.</p>



<p>The least-expensive new MacBook Pro you can get costs $1,599 and includes only 8GB of RAM, an insultingly miserly amount for this day and age. Want more? That will be at least $200, take it or leave it.</p>



<p>Apple has a long history of providing less RAM than it should for the price of its laptops and overcharging to get more, but it’s reached ridiculous proportions. The <em>cheapest</em> standard configuration with more than 8GB of RAM is 2 grand! The cheapest MacBook Pro you can <em>configure</em> with more than 8GB is $1,800!</p>



<h2 id="yes-you-need-more-than-8gb">Yes, you need more than 8GB</h2>



<p>I will be the first chip nerd on the block to sing the praises of Apple’s M-series memory management. A big on-chip system-level cache and a fast SSD, along with some really smart code, means that a Mac with Apple Silicon doesn’t feel nearly as hamstrung with 8GB of RAM as, say, a Windows laptop.</p>

		
			
			


<p>That does not mean that 8GB is “enough,” though. Even relatively casual users who load up on browser tabs and inefficient <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.electronjs.org/apps&amp;xcust=1-1-2130071-1-0-0&amp;sref=https://www.macworld.com/article/2130071/m3-macbook-pro-8gb-memory-too-little.html" rel="nofollow">Electron apps</a> (household names like Slack, Teams, Discord, etc.) can find performance compromised by running out of RAM.</p>


<div><figure><img decoding="async" loading="lazy" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?quality=50&amp;strip=all&amp;w=1200" alt="space black macbook pro" srcset="https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?quality=50&amp;strip=all 3000w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=300%2C200&amp;quality=50&amp;strip=all 300w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=768%2C512&amp;quality=50&amp;strip=all 768w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=1200%2C800&amp;quality=50&amp;strip=all 1200w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=1536%2C1024&amp;quality=50&amp;strip=all 1536w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=2048%2C1365&amp;quality=50&amp;strip=all 2048w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=1240%2C826&amp;quality=50&amp;strip=all 1240w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-steep-angle.jpg?resize=150%2C100&amp;quality=50&amp;strip=all 150w" width="1200" height="800" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><p>Any MacBook with Pro branding should have a minimum of 16G of RAM.</p></figcaption></figure><p>Foundry</p></div>



<p>As I write this, with just a handful of browser tabs open, Slack, and a distraction-free writing app (<a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://ia.net/writer&amp;xcust=1-1-2130071-1-0-0&amp;sref=https://www.macworld.com/article/2130071/m3-macbook-pro-8gb-memory-too-little.html" rel="nofollow">iA Writer</a>—it’s great), I’m consuming just about 11GB on my M2 MacBook Air.</p>



<p>Is it a problem to sell a Mac with 8GB in 2023-2024? No. Is it a problem to sell a <em>MacBook Pro</em> for $1,600 with only 8GB of RAM? Oh god, yes. If 8GB will be a bottleneck for many today, imagine the performance of that non-upgradeable laptop in a few years’ time.</p>



<p>Not that Windows laptops and Macs are directly comparable, but comparably-priced Microsoft Surface, HP Envy, Alienware, Dell XP, and Lenovo Thinkpad laptops all have 16GB of RAM or more, standard. You can spend all day mired in laptop configurations (and I have) but the bottom line is this: 16GB is standard at prices over $1,000 even in laptops with premium displays and other high-end features. Apple is <em>way</em> off base with its RAM here, more so than usual, especially in products that carry the “Pro” name.</p>



<h2 id="the-upgrade-extortion">The upgrade extortion</h2>



<p>If you want more than 8GB, you have to pay for it. Either with a big $400 upgrade to the M3 Pro—which is not even an option in the just-released <a href="https://www.macworld.com/article/2126614/24-inch-imac-m3-review.html">M3 iMac</a>—or by paying Apple $200 for another 8GB.</p>



<p>To be clear, 8GB of LPDDR5-6400 (the RAM used in these products) costs Apple a tiny fraction of that amount. Nobody knows precisely what Apple pays its suppliers, but the going price for 64Gbits (8GB) of that sort of RAM is less than $40 in quantity. Apple’s deal likely has them paying $30 or less.</p>


<div><figure><img decoding="async" loading="lazy" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?quality=50&amp;strip=all&amp;w=1200" alt="Space Black MacBook Pro ports: SDXC Card slot, Thunderbolt, HDMI" srcset="https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?quality=50&amp;strip=all 3000w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=300%2C200&amp;quality=50&amp;strip=all 300w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=768%2C512&amp;quality=50&amp;strip=all 768w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=1200%2C800&amp;quality=50&amp;strip=all 1200w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=1536%2C1024&amp;quality=50&amp;strip=all 1536w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=2048%2C1365&amp;quality=50&amp;strip=all 2048w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=1240%2C826&amp;quality=50&amp;strip=all 1240w, https://b2c-contenthub.com/wp-content/uploads/2023/11/space-black-macbook-pro-hdmi.jpg?resize=150%2C100&amp;quality=50&amp;strip=all 150w" width="1200" height="800" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><p>The M3 MacBook Pro has a great screen and a nice selection of ports—but 8GB of RAM is a joke.</p></figcaption></figure><p>Foundry</p></div>



<p>There’s nothing special about Apple’s RAM. It’s high quality, and it’s integrated on a very wide memory bus very close to the M3 chip, but those manufacturing complexities don’t make the RAM cost more. Apple’s charging you $200 for RAM it buys for $30.</p>



<p>Here’s a fun experiment: Configure a MacBook Pro with the M3 Max, the full 16-core CPU version. Every additional 16GB of RAM costs $200, the same as 8GB of RAM on the lower configurations.</p>



<p>Any time an upgrade carries a perfectly round price–<em>exactly</em> $200–you should be wary of it. Some product manager priced it by what “looks good” and what they think customers will pay.</p>



<p>In Apple’s case, you have no choice. You can’t upgrade later. You can’t pay anyone else’s price. You have to pay Apple’s exorbitant $200-for-8GB upgrade cost. Make no mistake: the true starting cost of a M3 MacBook Pro is $1,699 because to buy one with only 8GB of RAM is crazy.</p>



<h2 id="we-shouldnt-accept-this">We shouldn’t accept this</h2>



<p>Are the new M3 Macs great computers? Sure. Are they expensive? You betcha. Does any excuse for Apple’s stingy 8GB RAM configurations or highway-robbery RAM upgrade prices? Absolutely not. This is pure corporate greed from the world’s biggest and richest technology company, and as Apple customers, we shouldn’t stand for it.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cursorless is alien magic from the future (686 pts)]]></title>
            <link>https://xeiaso.net/notes/cursorless-alien-magic/</link>
            <guid>38214915</guid>
            <pubDate>Fri, 10 Nov 2023 04:04:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xeiaso.net/notes/cursorless-alien-magic/">https://xeiaso.net/notes/cursorless-alien-magic/</a>, See on <a href="https://news.ycombinator.com/item?id=38214915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            



<article>
    
    <p>
        Published on 11/09/2023, 1396 words, 6 minutes to read
    </p>

    

    <p>Just in time for me to start a new job at a new place, my RSI has decided to flare up.</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>For the record, I'm fine, I've known this has been coming for a while. The
flare-up is on its exit anyways. I've gotten lucky and I'm going to be fine.
But it's still a bit of a bummer.</p></div></div>
<p>The last time this happened, I was able to get by by doing mostly writing about technology things, but I think I'm going to need to be able to program again. I know I'm a bit of an emacs user, but for this I've been using visual studio code because of one extension in particular: <a href="https://marketplace.visualstudio.com/items?itemName=pokey.cursorless">Cursorless</a>.</p>
<p>Cursorless is a plugin that integrates with voice control software to let you do AST level code editing with your voice. This is crazy alien magic from the future.</p>
<p>I've talked about cursorless before on my blog, but I have decided to really get deep into it this time around. The last time I used it, I didn't actually use it for much more than moving around the screen, but this time I'm going to try to use it for everything.</p>
<p>I wish I had this as an input method for slack and discord messages.</p>
<p>The most magic parts about this are the ideas of destinations and targets when it comes to cursorless inputs. Targets are individual anchors in a document and destinations are places relative to individual targets. Every single token in a document is given a hat over a letter with a color. These hats act as anchors that let you give commands based off of locations, destinations, and paths between them. Here's a simple example. Consider this code:</p>
<pre><code><span><span>function</span> <span>fetchBlog</span><span>(</span><span>)</span> <span>{</span>
</span><span>  <span>fetch</span><span>(</span><span>"https://xeiaso.net/blog.json"</span><span>)</span>
</span><span>    <span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>      <span>if</span> <span>(</span><span>!</span>response<span>.</span><span>ok</span><span>)</span> <span>{</span>
</span><span>        <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"Network response was not ok"</span><span>)</span><span>;</span>
</span><span>      <span>}</span>
</span><span>      <span>return</span> response<span>.</span><span>json</span><span>(</span><span>)</span><span>;</span>
</span><span>    <span>}</span><span>)</span>
</span><span>    <span>.</span><span>then</span><span>(</span><span>(</span><span>data</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span>data<span>)</span><span>)</span>
</span><span>    <span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>error</span><span>(</span><span>"Error:"</span><span>,</span> error<span>)</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre>
<p>This is a fairly standard looking JavaScript function. But, cursorless puts a bunch of hats over all of the code so it may look something like this:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.webp"><img loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.jpg"></picture></a></figure>
<div><p><img alt="Aoi is wut" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/wut/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>So that's why your editor is full of random video artifacts?</p></div></div>
<div><p><img alt="Cadey is enby" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/enby/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>They're not artifacts, they're targets!</p></div></div>
<p>Take a good look at that picture again:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.webp"><img loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-hats.jpg"></picture></a></figure>
<p>The hats are color coded above individual letters. The position tells you the name and the color tells you how to disambiguate it. For example, That word <code>function</code> would be referred to as <code>green urge</code> because the hat is green over the letter u. If I wanted to delete that word for some reason or if I wanted to move it somewhere else, I could use <code>green urge</code> as the target for that action.</p>
<p>By itself, this gives you some pretty powerful actions and effectively lets you do spoken vim motions. But, that is only thinking in terms of simple actions that you can do with your editor. The real power of cursorless comes in from not only the idea of paths (such as <code>green urge past green bat</code> to select the <code>function fetchBlog</code> in that screenshot), but the fact that cursorless knows what the AST of the language is doing. This means that you can do things across the entire function, like deleting it or moving it somewhere else. As an example, here are the lambdas of this function visualized separately (with the "visualize lambdas" command):</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-lambda.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-lambda.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-lambda.webp"><img loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/cursorless-lambda.jpg"></picture></a></figure>
<p>These AST units are also targets. This means that I can do things like select the body of a definition and then work off of that. So if I want to refactor this into an asynchronous function, the refactoring becomes trivial:</p>
<p><img src="https://cdn.xeiaso.net/file/christine-static/blog/2023/cl-note/async-refactor.gif" alt="a gif of doing the process of refactoring a synchronous function to an async function by writing it all using talon commands"></p>
<div><p><img alt="Aoi is grin" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/grin/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>That's pretty cool, but I don't think I'd be able to remember all of those
commands.</p></div></div>
<div><p><img alt="Cadey is enby" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/enby/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>After a while, they just become second nature like Vim commands do. I have
been forcing myself to use this over and over again for the past few days and
it's starting to become second nature. I'm introducing individual commands at
one of the time and building up into bigger and better things.</p></div></div>
<p>The real magic comes when you start writing your own commands with the full power of Cursorless and Talon. In that example I just showed you, I have a action for inserting <code>"async "</code> before the function definition. Here is the code for that:</p>
<pre><code><span>[state] async &lt;user.cursorless_destination&gt;:
</span><span>    user.cursorless_insert(cursorless_destination, "async")
</span></code></pre>
<p>You can break talon commands into two basic parts: patterns and captures. Patterns are the spoken words that you say and captures are the things that you want to extract out of what you say. In this case, the pattern is just the word <code>async</code> and the capture is the destination that you want to insert the word <code>async</code> before. The <code>&lt;user.cursorless_destination&gt;</code> capture is a special capture lets you specify if you want something before or after a target. Of course, this is just a very simple example and it can get way more intricate than this.</p>
<p>Here is the most complicated Talon rule I've written so far:</p>
<pre><code><span>(method|meth) &lt;user.letter&gt; [&lt;user.go_pointer&gt;] [&lt;user.go_visibility&gt;] &lt;user.text&gt; [over] [&lt;user.go_visibility&gt;] named &lt;user.text&gt; [over]:
</span><span>    user.go_method(go_pointer or "", letter, go_visibility_1 or "public", text_1, go_visibility_2 or "public", text_2)
</span></code></pre>
<div><p><img alt="Aoi is wut" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/wut/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>What the heck is going on there?</p></div></div>
<p>This looks like a lot, but it is actually really simple. This lets you declare a method in Go. In Go, a method looks like this:</p>
<pre><code><span><span>func</span> <span>(</span>reciever <span>*</span>Type<span>)</span> <span>MethodName</span><span>(</span><span>)</span> <span>{</span>
</span><span>    <span>// function body here or something</span>
</span><span><span>}</span>
</span></code></pre>
<p>Pedantically, Go doesn't have methods in the traditional sense, it just has functions that take structs as the receiver (read: a hidden first argument but in a way that is namespaced to that struct in particular). Without something to automate writing this for you, you would have to say something like this:</p>
<blockquote>
<p>state funk args word reciever space star hammer type over go right space hammer method name args go right brack enter</p>
</blockquote>
<p>That's a lot of words to say. But, with this talon rule, you can just say:</p>
<blockquote>
<p>meth r raised type named method name over</p>
</blockquote>
<div><p><img alt="Aoi is wut" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/wut/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>That's still a lot of words.</p></div></div>
<div><p><img alt="Cadey is enby" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/enby/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>Well, yes, you're not going to be able to get over that. But this is at least
more efficient and it makes more sense. I'm not going to be able to get rid of
all of the words, but I can at least make it so that it's close to how I
conceptualize it in my head.</p></div></div>
<div><p><img alt="Aoi is wut" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/wut/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>I guess that makes sense, but what do you mean by raised? I don't think go has
raised types I know it has pointers but not "raising". What is raising?</p></div></div>
<p>I'm glad you asked! This is something that I'm experimenting with to try to find a different way to explain the concept of pointers in Go. I think that one of the oversights in the Go language is that pointers use C-style syntax. This specifically has you use an <code>*</code> to lower a value from a pointer value to a normal value and <code>&amp;</code> to raise the value from a normal value into a pointer value.</p>
<p>Since I'm taking the opportunity to radically redesign the Talon bindings for Go, I want to try unifying the syntax of pointer values into the idea of raising and lowering to see how it makes it easier to understand Go programs. I don't know if this is a good idea, but you have to fuck around in order to find out.</p>
<p>Maybe some parts of our industry are actually good. I really hope that I get led into the <a href="https://githubnext.com/projects/copilot-voice/">GitHub copilot voice beta</a> soon, I want to compare how Talon does voice coding versus how copilot voice does it.</p>

    

    

    <p>Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear.</p>

    <p>Tags: cursorless, vscode</p>
</article>
        </div><div>
            <p>Copyright 2012-2023 Xe Iaso (Christine Dodrill). Any and all opinions listed here are my own and
                not representative of any of my employers, past, future, and/or present.</p>
            
            <p>Served by xesite v4 (/nix/store/hbfma2zzmqix0v1a78jl63s7i9vm98vc-xesite_v4-20231028/bin/xesite) with site version <a href="https://github.com/Xe/site/commit/78edfd198f62f1f37f91101c9c3cc91a301e9ff2">78edfd19</a>, source code available <a href="https://github.com/Xe/site">here</a>.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPU advancements in M3 and A17 Pro [video] (177 pts)]]></title>
            <link>https://developer.apple.com/videos/play/tech-talks/111375</link>
            <guid>38214806</guid>
            <pubDate>Fri, 10 Nov 2023 03:42:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/videos/play/tech-talks/111375">https://developer.apple.com/videos/play/tech-talks/111375</a>, See on <a href="https://news.ycombinator.com/item?id=38214806">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-supplement-id="transcript" data-shortcut-base-url="/videos/play/tech-talks/111375/">
								<p><span id="get-transcript">Download</span></p>
								<p><span><span data-start="0.0">Welcome, my name is Jedd Haberstro, </span></span><span><span data-start="3.0">and I'm an Engineer in Apple's GPU, Graphics, </span></span><span><span data-start="6.0">and Displays Software Group.</span></span></p><p><span><span data-start="9.0">I'm excited to tell you </span></span><span><span data-start="10.0">about the new Apple family 9 GPU architecture </span></span><span><span data-start="14.0">in A17 Pro and the M3 family of chips, </span></span><span><span data-start="17.0">which are at the heart of iPhone 15 Pro and the new Max.</span></span></p><p><span><span data-start="23.0">Across Apple's product line, </span></span><span><span data-start="25.0">the GPU powers many of the rich user experiences </span></span><span><span data-start="28.0">our customers love. </span></span><span><span data-start="30.0">Whether it be gaming on the go with the new iPhone 15 Pro, </span></span><span><span data-start="36.0">delivering silky smooth UI animations for your apps </span></span><span><span data-start="39.0">on the new iMac, </span></span><span><span data-start="41.0">or leveraging machine learning </span></span><span><span data-start="43.0">to perform advanced video and image processing </span></span><span><span data-start="46.0">on the new MacBook Pros, </span></span><span><span data-start="49.0">the GPU plays a critical role in enabling these apps.</span></span></p><p><span><span data-start="55.0">The Metal API is used to harness the computing capabilities </span></span><span><span data-start="59.0">of Apple's GPUs, </span></span><span><span data-start="60.0">and collectively, these apps run a diverse set </span></span><span><span data-start="63.0">of Metal Shading Language programs. </span></span><span><span data-start="66.0">These shader programs can range from small, simple shaders </span></span><span><span data-start="70.0">that execute just a handful of lines of code </span></span><span><span data-start="73.0">to large complex shaders </span></span><span><span data-start="75.0">that spend hundreds of thousands of lines of code, </span></span><span><span data-start="78.0">frameworks, and libraries. </span></span><span><span data-start="80.0">What all these shaders share in common </span></span><span><span data-start="83.0">is massive data parallelism, </span></span><span><span data-start="86.0">which is the opportunity </span></span><span><span data-start="87.0">to greatly improve the performance of an app </span></span><span><span data-start="89.0">by running it in parallel. </span></span><span><span data-start="91.0">This parallelism is achieved </span></span><span><span data-start="93.0">by running Metal shader programs many times over in parallel </span></span><span><span data-start="97.0">on different inputs </span></span><span><span data-start="98.0">such as each vertex in a 3D rendered scene </span></span><span><span data-start="102.0">or each pixel of the screen.</span></span></p><p><span><span data-start="106.0">It is the GPU, ultimately, </span></span><span><span data-start="108.0">which is responsible for executing these shaders </span></span><span><span data-start="111.0">in parallel.</span></span></p><p><span><span data-start="114.0">At the heart of every GPU are its shader cores. </span></span><span><span data-start="117.0">Each shader core can run thousands of threads in parallel. </span></span><span><span data-start="121.0">And to scale performance even further, </span></span><span><span data-start="123.0">a GPU will have many shader cores </span></span><span><span data-start="125.0">that can also run in parallel, </span></span><span><span data-start="127.0">giving an app tens of thousands </span></span><span><span data-start="129.0">of parallel threads of execution.</span></span></p><p><span><span data-start="132.0">Already, the GPUs in today's existing iPhones, iPads, </span></span><span><span data-start="136.0">and Macs, have incredible performance.</span></span></p><p><span><span data-start="140.0">As well as a powerful suite of developer tools </span></span><span><span data-start="143.0">to allow app developers to maximize the GPU's potential. </span></span><span><span data-start="147.0">But with the new Apple family 9 GPUs, </span></span><span><span data-start="150.0">we are increasing performance to unprecedented levels </span></span><span><span data-start="153.0">thanks to several new exciting advancements.</span></span></p><p><span><span data-start="157.0">First is a brand new shader core architecture </span></span><span><span data-start="161.0">that improves the performance and power efficiency </span></span><span><span data-start="163.0">of your existing apps, </span></span><span><span data-start="165.0">which, right away, benefits the experience you deliver </span></span><span><span data-start="168.0">while also meeting the demanding challenges </span></span><span><span data-start="171.0">of the next-generation of apps that you will build.</span></span></p><p><span><span data-start="175.0">Hardware-accelerated ray tracing transparently benefits apps </span></span><span><span data-start="180.0">that already use Metal's ray tracing APIs, </span></span><span><span data-start="183.0">as well as expands the opportunities to use ray tracing </span></span><span><span data-start="186.0">to achieve rich rendering effects with great performance.</span></span></p><p><span><span data-start="191.0">And with hardware-accelerated mesh shading, </span></span><span><span data-start="193.0">apps can build advanced geometry processing pipelines </span></span><span><span data-start="196.0">like never before.</span></span></p><p><span><span data-start="199.0">Before we discuss these in more detail, </span></span><span><span data-start="201.0">let's look at the incredible performance </span></span><span><span data-start="204.0">apps are already able to achieve </span></span><span><span data-start="206.0">with no changes on the new Apple family 9 GPUs. </span></span><span><span data-start="210.0">This is "Baldur's Gate 3" by Larian Studios, </span></span><span><span data-start="214.0">running on the new MacBook Pro with M3 Max pictured on top, </span></span><span><span data-start="218.0">and a MacBook Pro with M2 Max pictured on bottom. </span></span><span><span data-start="221.0">Each rendering with ultra video quality settings at 1800p. </span></span><span><span data-start="226.0">The M3 Max is able to deliver </span></span><span><span data-start="228.0">significant performance improvements, </span></span><span><span data-start="230.0">thanks to the next-generation shader core's ability </span></span><span><span data-start="233.0">to run the game's Metal shaders </span></span><span><span data-start="234.0">with higher thread occupancy. </span></span><span><span data-start="237.0">Here is Blender rendering an image of a barbershop scene </span></span><span><span data-start="241.0">using the Cycles Path Tracer, </span></span><span><span data-start="243.0">which leverages Metal Ray Tracing on M3 Max. </span></span><span><span data-start="246.0">Both Renders were started at the same exact time, </span></span><span><span data-start="249.0">but thanks to hardware-accelerated ray tracing </span></span><span><span data-start="252.0">and the next-generation shader core, </span></span><span><span data-start="254.0">the Render on the M3 Max converges significantly faster.</span></span></p><p><span><span data-start="260.0">This is a real-time visualization </span></span><span><span data-start="263.0">of the "Toy Story 4" Antiques Mall USD </span></span><span><span data-start="266.0">rendered by Pixar's Hydra Storm. </span></span><span><span data-start="269.0">Hydra Storm uses Metal mesh shading on M3 Max, </span></span><span><span data-start="272.0">which when combined with hardware-accelerated mesh shading </span></span><span><span data-start="276.0">runs faster than ever before.</span></span></p><p><span><span data-start="279.0">Let's now look at each of these features in more detail, </span></span><span><span data-start="282.0">starting with the next generation shader core.</span></span></p><p><span><span data-start="286.0">The Apple family 9 GPUs are composed </span></span><span><span data-start="289.0">of several building blocks </span></span><span><span data-start="291.0">such as compute and vertex command processors </span></span><span><span data-start="294.0">that parse your Metal command buffers, </span></span><span><span data-start="296.0">a rasterizer that dispatches fragment shaders for execution, </span></span><span><span data-start="302.0">and a hierarchy of caches, </span></span><span><span data-start="304.0">including the GPU last level cache </span></span><span><span data-start="306.0">that services all GPU memory traffic.</span></span></p><p><span><span data-start="310.0">But central to any GPU are its shader cores. </span></span><span><span data-start="314.0">These are the building blocks </span></span><span><span data-start="315.0">that execute your app's Metal shaders.</span></span></p><p><span><span data-start="319.0">The shader core is also paired with a texture unit </span></span><span><span data-start="322.0">that can sample and write your texture resources, </span></span><span><span data-start="325.0">as well as a brand new ray tracing unit </span></span><span><span data-start="327.0">that accelerates ray intersection requests.</span></span></p><p><span><span data-start="333.0">A shader core can be further subdivided </span></span><span><span data-start="335.0">into its constituent parts.</span></span></p><p><span><span data-start="338.0">Each shader core has an array of execution pipelines </span></span><span><span data-start="341.0">that execute different types of instructions, </span></span><span><span data-start="343.0">such as FP32, FP16, and Integer math, </span></span><span><span data-start="347.0">which correspond to operations on variables in your shaders </span></span><span><span data-start="351.0">with Metal data types such as float, half, and int, </span></span><span><span data-start="354.0">as well as memory pipelines for read and write operations </span></span><span><span data-start="357.0">to textures and buffers.</span></span></p><p><span><span data-start="360.0">Keeping all of these execution pipelines busy </span></span><span><span data-start="362.0">usually requires executing instructions </span></span><span><span data-start="365.0">from multiple SIMDgroups. </span></span><span><span data-start="367.0">So there's a pool that keeps track of the SIMDgroups </span></span><span><span data-start="370.0">that are running on a shader core, </span></span><span><span data-start="372.0">and a scheduler that chooses which SIMDgroup </span></span><span><span data-start="374.0">to execute instructions from next.</span></span></p><p><span><span data-start="377.0">Typically, there's also a handful of on-chip memories </span></span><span><span data-start="380.0">for storing the different types of data </span></span><span><span data-start="382.0">a shader program may use, </span></span><span><span data-start="384.0">such as registers for storing the values of variables, </span></span><span><span data-start="388.0">threadgroup and tile memory </span></span><span><span data-start="389.0">for storing data shared across a compute threadgroup </span></span><span><span data-start="392.0">or color attachment data shared across the tile, </span></span><span><span data-start="397.0">and a cache to improve the performance of accesses </span></span><span><span data-start="399.0">to the stack and to buffers.</span></span></p><p><span><span data-start="403.0">With this understanding of what a shader core does </span></span><span><span data-start="405.0">and its constituent pieces, </span></span><span><span data-start="407.0">I'd like to explain three new exciting advancements </span></span><span><span data-start="410.0">in the Apple family 9 GPU shader core. </span></span><span><span data-start="413.0">These advancements will increase the performance </span></span><span><span data-start="416.0">of your shaders with no changes to your app. </span></span><span><span data-start="419.0">But by better understanding how this new shader core works, </span></span><span><span data-start="422.0">you'll be able to benefit from it to an even greater degree.</span></span></p><p><span><span data-start="428.0">The first change is dynamic shader core memory, </span></span><span><span data-start="432.0">which allows an app to achieve better thread occupancy, </span></span><span><span data-start="435.0">and as a result, often better performance.</span></span></p><p><span><span data-start="438.0">The second change is the flexible on-chip memory. </span></span><span><span data-start="442.0">This will increase the efficiency </span></span><span><span data-start="444.0">by which your shaders access buffer, stack, threadgroup, </span></span><span><span data-start="447.0">and tile memory.</span></span></p><p><span><span data-start="450.0">The last change is the shader core's </span></span><span><span data-start="452.0">high-performance ALU pipelines, </span></span><span><span data-start="455.0">which have increased their ability to execute in parallel. </span></span><span><span data-start="458.0">This will improve the performance of apps </span></span><span><span data-start="460.0">that perform a combination of floating point </span></span><span><span data-start="462.0">or integer math.</span></span></p><p><span><span data-start="465.0">Before further exploring these new features, </span></span><span><span data-start="467.0">let's dive into more detail </span></span><span><span data-start="469.0">about how a shader core keeps its execution pipelines busy </span></span><span><span data-start="472.0">and the importance of thread occupancy in this endeavor.</span></span></p><p><span><span data-start="477.0">Suppose your Metal shader, </span></span><span><span data-start="479.0">after executing some math operations </span></span><span><span data-start="481.0">using the ALU pipelines, reads a buffer </span></span><span><span data-start="484.0">whose result will be used immediately after. </span></span><span><span data-start="487.0">Accessing the buffer </span></span><span><span data-start="488.0">may require going all the way to device memory, </span></span><span><span data-start="491.0">which is a long latency operation. </span></span><span><span data-start="494.0">During this time, </span></span><span><span data-start="495.0">the SIMDgroup can't execute other operations, </span></span><span><span data-start="498.0">which causes the ALU pipelines to go unused.</span></span></p><p><span><span data-start="502.0">To mitigate this, the shader core can execute instructions </span></span><span><span data-start="505.0">from a different SIMDgroup, </span></span><span><span data-start="507.0">which may have some ALU instructions of its own. </span></span><span><span data-start="510.0">This reduces the amount of time the ALUs go and used </span></span><span><span data-start="513.0">and allows the SIMDgroups to run in parallel, </span></span><span><span data-start="516.0">thus improving performance.</span></span></p><p><span><span data-start="520.0">If there are additional SIMDgroups </span></span><span><span data-start="522.0">running on the shader core, </span></span><span><span data-start="523.0">this can be done many times over </span></span><span><span data-start="525.0">until the ALUs and other execution pipelines </span></span><span><span data-start="528.0">are never starved of instructions to execute.</span></span></p><p><span><span data-start="531.0">The number of SIMDgroups </span></span><span><span data-start="532.0">that are concurrently running on a shader core </span></span><span><span data-start="535.0">is called its thread occupancy.</span></span></p><p><span><span data-start="538.0">But you may be asking yourself, </span></span><span><span data-start="539.0">what dictates how many SIMDgroups </span></span><span><span data-start="541.0">will be running concurrently on a shader core? </span></span><span><span data-start="545.0">To answer that question, let's look at an example. </span></span><span><span data-start="549.0">This is a prototypical ray tracing compute kernel </span></span><span><span data-start="552.0">that intersects a ray with an acceleration structure, </span></span><span><span data-start="557.0">inspects the intersection result, </span></span><span><span data-start="561.0">and then executes a different shading function </span></span><span><span data-start="564.0">based on the material of the primitive intersected. </span></span><span><span data-start="566.0">In this example, </span></span><span><span data-start="567.0">it supports shading both glass and leather materials.</span></span></p><p><span><span data-start="573.0">Each line of code will use some amount of registers </span></span><span><span data-start="575.0">to store the program's variables. </span></span><span><span data-start="577.0">At different points of the program, </span></span><span><span data-start="579.0">more or fewer registers will be used </span></span><span><span data-start="581.0">depending on what the code does. </span></span><span><span data-start="584.0">In this particular example, </span></span><span><span data-start="586.0">the implementation of the shadeGlass function </span></span><span><span data-start="588.0">uses many more registers than the rest of the program.</span></span></p><p><span><span data-start="593.0">Prior to the Apple family 9 GPU, </span></span><span><span data-start="596.0">a SIMDgroup could not begin execution on a shader core </span></span><span><span data-start="599.0">until it allocated registers from the on-chip register file. </span></span><span><span data-start="603.0">The amount allocated would be equal </span></span><span><span data-start="605.0">to the maximum register usage at any point in the program. </span></span><span><span data-start="609.0">The SIMDgroup would keep that many registers allocated </span></span><span><span data-start="612.0">for the entire duration of the SIMDgroup, </span></span><span><span data-start="615.0">even though most of those registers may go unused </span></span><span><span data-start="618.0">in large sections of the program. </span></span><span><span data-start="620.0">Thus, based on the maximum register usage, </span></span><span><span data-start="623.0">we may only be able to run, for example, </span></span><span><span data-start="626.0">four SIMDgroups at a time on a shader core </span></span><span><span data-start="628.0">because any more would require </span></span><span><span data-start="629.0">more on-chip register filed memory than exists. </span></span><span><span data-start="633.0">However, thanks to the Apple family 9 GPU's </span></span><span><span data-start="636.0">new dynamic shader core memory feature, </span></span><span><span data-start="639.0">the maximum register usage no longer dictates </span></span><span><span data-start="642.0">how many SIMDgroups can be run. </span></span><span><span data-start="645.0">On-chip register memory is now dynamically allocated </span></span><span><span data-start="648.0">and deallocated over the lifetime of the shader </span></span><span><span data-start="651.0">according to what each part of the program actually uses. </span></span><span><span data-start="655.0">This allows SIMDgroups to make much more efficient use </span></span><span><span data-start="659.0">of the on-chip register file, freeing up space </span></span><span><span data-start="662.0">that would not have been available otherwise. </span></span><span><span data-start="665.0">This can have a profound impact </span></span><span><span data-start="666.0">on your app's thread occupancy, </span></span><span><span data-start="668.0">and ultimately, its performance </span></span><span><span data-start="671.0">by allowing many more SIMDgroups to run concurrently.</span></span></p><p><span><span data-start="675.0">As I just mentioned, </span></span><span><span data-start="677.0">registers are now dynamically allocated and deallocated </span></span><span><span data-start="679.0">over the course of a SIMDgroup's lifetime. </span></span><span><span data-start="682.0">This is in part possible </span></span><span><span data-start="685.0">because the register file is now a cache </span></span><span><span data-start="687.0">instead of the permanent storage for the registers, </span></span><span><span data-start="690.0">meaning more registers can be used </span></span><span><span data-start="692.0">that can be stored on chip.</span></span></p><p><span><span data-start="695.0">The flexible on-chip memory feature extends this treatment </span></span><span><span data-start="698.0">to the rest of the shader core's memory types, </span></span><span><span data-start="700.0">such as threadgroup and tile memory, </span></span><span><span data-start="703.0">making that a cache too.</span></span></p><p><span><span data-start="706.0">And now that register, threadgroup, tile, stack, </span></span><span><span data-start="711.0">and buffer data are all cached on chip, </span></span><span><span data-start="713.0">this has allowed us to redesign the on-chip memories </span></span><span><span data-start="716.0">into fewer larger caches </span></span><span><span data-start="719.0">that service all these memory types. </span></span><span><span data-start="721.0">This flexibility will benefit shaders </span></span><span><span data-start="723.0">that don't make heavy use of each memory type. </span></span><span><span data-start="727.0">In the past, if a compute kernel didn't use, for example, </span></span><span><span data-start="730.0">threadgroup memory, its corresponding on-chip storage </span></span><span><span data-start="733.0">would go completely unused. </span></span><span><span data-start="736.0">Now, the on-chip storage will be dynamically assigned </span></span><span><span data-start="739.0">to the memory types that are used by your shaders, </span></span><span><span data-start="742.0">giving them more on-chip storage than they had in the past, </span></span><span><span data-start="745.0">and ultimately, better performance.</span></span></p><p><span><span data-start="749.0">For example, for shaders with heavy register usage, </span></span><span><span data-start="752.0">that may mean higher occupancy.</span></span></p><p><span><span data-start="755.0">For shaders that repeatedly access a large working set </span></span><span><span data-start="759.0">of buffer data, that will mean better cache hit rates, </span></span><span><span data-start="762.0">lower buffer access latency, and thus, better performance. </span></span><span><span data-start="767.0">And for apps that make heavy use of non-inline functions, </span></span><span><span data-start="770.0">such as function pointers, visible function tables, </span></span><span><span data-start="774.0">and dynamically linked shader libraries, </span></span><span><span data-start="776.0">this means more on-chip stack space </span></span><span><span data-start="778.0">to pass function parameters, </span></span><span><span data-start="780.0">and thus, faster function calls.</span></span></p><p><span><span data-start="784.0">But what happens if your app still uses more memory </span></span><span><span data-start="787.0">than there is on-chip storage for? </span></span><span><span data-start="790.0">Unmitigated, that data will spill to the next cache level </span></span><span><span data-start="793.0">or even to main memory. </span></span><span><span data-start="796.0">Fortunately, the shader core will dynamically monitor </span></span><span><span data-start="799.0">your shaker's behavior and adjust the occupancy level </span></span><span><span data-start="802.0">to prevent this from occurring. </span></span><span><span data-start="804.0">This keeps data on chip. </span></span><span><span data-start="806.0">And ultimately, the execution pipelines busy.</span></span></p><p><span><span data-start="810.0">This does mean, however, </span></span><span><span data-start="812.0">that your shader's occupancy will be impacted </span></span><span><span data-start="815.0">by how your shader's access threadgroup, tile, </span></span><span><span data-start="817.0">stack, and buffer memory </span></span><span><span data-start="819.0">in addition to its dynamic register usage.</span></span></p><p><span><span data-start="823.0">These new hardware capabilities </span></span><span><span data-start="825.0">improve the occupancy of many apps, </span></span><span><span data-start="827.0">meaning you, the developer, need to optimize occupancy </span></span><span><span data-start="831.0">a lot less often than in the past. </span></span><span><span data-start="833.0">But if you do need to optimize occupancy further </span></span><span><span data-start="837.0">on Apple family 9 GPUs, </span></span><span><span data-start="839.0">we have developed a suite of profiling tools to help you. </span></span><span><span data-start="842.0">To learn more about how to diagnose and optimize occupancy, </span></span><span><span data-start="846.0">please refer to these talks.</span></span></p><p><span><span data-start="850.0">The last feature of the Apple family 9 GPU shader core </span></span><span><span data-start="853.0">I'd like to discuss is its high-performance ALU pipelines.</span></span></p><p><span><span data-start="859.0">Apple GPU shader cores have separate ALU pipelines </span></span><span><span data-start="862.0">for different instruction types, </span></span><span><span data-start="864.0">including FP16 instructions. </span></span><span><span data-start="867.0">Apple GPUs are highly optimized to execute FP16 arithmetic. </span></span><span><span data-start="872.0">And we recommend that you'll use FP16 data types </span></span><span><span data-start="876.0">wherever possible.</span></span></p><p><span><span data-start="878.0">FP16 math instructions execute at peak throughput.</span></span></p><p><span><span data-start="883.0">They use fewer registers than their FP32 equivalents. </span></span><span><span data-start="888.0">They reduce memory bandwidth </span></span><span><span data-start="889.0">if your buffers store data natively in FP16. </span></span><span><span data-start="893.0">And for situations where the source </span></span><span><span data-start="895.0">or destination variable of a math operation </span></span><span><span data-start="898.0">is not FP16 already, </span></span><span><span data-start="900.0">it can be converted to and from at no cost.</span></span></p><p><span><span data-start="904.0">But if your app still performs other math operations, </span></span><span><span data-start="908.0">such as FP32 and integer, </span></span><span><span data-start="910.0">the Apple family 9 GPU shader core can execute instructions </span></span><span><span data-start="913.0">from all three data types in parallel </span></span><span><span data-start="916.0">to a greater degree than ever before. </span></span><span><span data-start="919.0">This can deliver up to 2x ALU performance </span></span><span><span data-start="922.0">compared to prior Apple GPUs. </span></span><span><span data-start="925.0">In order to take advantage of this extra parallelism, </span></span><span><span data-start="928.0">instructions must be executed from multiple SIMDgroups, </span></span><span><span data-start="931.0">which means increasing occupancy </span></span><span><span data-start="934.0">can improve the utilization of the ALU pipelines. </span></span><span><span data-start="938.0">Let's consider an example. </span></span><span><span data-start="940.0">Imagine there are two SIMDgroups running concurrently, </span></span><span><span data-start="943.0">both executing ALU instructions. </span></span><span><span data-start="946.0">In the past, these SIMDgroups may have had to run </span></span><span><span data-start="949.0">one after another.</span></span></p><p><span><span data-start="952.0">But if they have FP32 and FP16 instructions </span></span><span><span data-start="956.0">to execute at different points in time, as depicted here, </span></span><span><span data-start="960.0">then their executions can be overlapped, </span></span><span><span data-start="963.0">increasing parallelism and performance.</span></span></p><p><span><span data-start="967.0">To recap what's new in the next-generation shader core, </span></span><span><span data-start="972.0">it will dynamically allocate and deallocate registers </span></span><span><span data-start="975.0">over the lifetime of a shader, </span></span><span><span data-start="976.0">which improves its thread occupancy.</span></span></p><p><span><span data-start="980.0">It has a large on-chip cache </span></span><span><span data-start="982.0">that services registers, threadgroup, tile, stack, </span></span><span><span data-start="986.0">and buffer memory, which improves the performance </span></span><span><span data-start="989.0">of accessing those memory types.</span></span></p><p><span><span data-start="993.0">The shader core will dynamically adjust occupancy </span></span><span><span data-start="995.0">to keep data on chip and the execution pipelines busy.</span></span></p><p><span><span data-start="1000.0">And finally, FP16, FP32 and integer operations </span></span><span><span data-start="1005.0">can execute in parallel more than ever, </span></span><span><span data-start="1007.0">increasing ALU performance.</span></span></p><p><span><span data-start="1012.0">Next, let's take a look at hardware-accelerated ray tracing.</span></span></p><p><span><span data-start="1019.0">With Metal ray tracing, </span></span><span><span data-start="1020.0">apps can leverage the massive parallelism of Apple GPUs </span></span><span><span data-start="1024.0">to intersect rays with their scene geometry. </span></span><span><span data-start="1027.0">If you're not familiar with Metal ray tracing </span></span><span><span data-start="1029.0">and would like to learn more, </span></span><span><span data-start="1031.0">please watch Your guide to Metal ray tracing </span></span><span><span data-start="1034.0">and Enhance your app with Metal ray tracing.</span></span></p><p><span><span data-start="1040.0">At the heart of the Metal ray chasing API </span></span><span><span data-start="1043.0">is the intersector object </span></span><span><span data-start="1044.0">that is responsible for determining </span></span><span><span data-start="1046.0">the intersection point of a ray </span></span><span><span data-start="1048.0">with the primitives contained in an acceleration structure. </span></span><span><span data-start="1052.0">It is often invoked many times over </span></span><span><span data-start="1054.0">by ray tracing app's GPU functions, also known as shaders, </span></span><span><span data-start="1058.0">and thus, is central to the app's performance.</span></span></p><p><span><span data-start="1062.0">Earlier, I showed such AGPU function </span></span><span><span data-start="1065.0">when I looked at the register usage </span></span><span><span data-start="1067.0">of this raytracingKernel. </span></span><span><span data-start="1069.0">It creates an intersector object </span></span><span><span data-start="1072.0">and finds an intersection </span></span><span><span data-start="1074.0">by calling the object's intersect method.</span></span></p><p><span><span data-start="1079.0">To determine the intersection point, </span></span><span><span data-start="1081.0">the intersector performs a few key stages. </span></span><span><span data-start="1085.0">First, it traverses the acceleration structure </span></span><span><span data-start="1088.0">to find a candidate primitive. </span></span><span><span data-start="1090.0">It then invokes an intersection function, </span></span><span><span data-start="1093.0">which may be provided by the app, </span></span><span><span data-start="1095.0">to determine if the rate intersects the primitive.</span></span></p><p><span><span data-start="1099.0">If it does, </span></span><span><span data-start="1100.0">the intersection is compared to previous intersections </span></span><span><span data-start="1103.0">and the process is repeated until the closest is found.</span></span></p><p><span><span data-start="1107.0">The closest intersection is then returned </span></span><span><span data-start="1109.0">to the calling GPU function </span></span><span><span data-start="1111.0">for further app-specific processing.</span></span></p><p><span><span data-start="1115.0">New in Apple family 9 GPUs, </span></span><span><span data-start="1118.0">the implementation of the intersector object </span></span><span><span data-start="1120.0">is hardware-accelerated, </span></span><span><span data-start="1122.0">which greatly increases the performance </span></span><span><span data-start="1124.0">of this critical operation.</span></span></p><p><span><span data-start="1128.0">The hardware-accelerated intersection </span></span><span><span data-start="1130.0">does not execute in line with the GPU function. </span></span><span><span data-start="1133.0">Thus, to facilitate the communication of the ray </span></span><span><span data-start="1136.0">and the ray payload between the two, </span></span><span><span data-start="1138.0">data is read and written to on-chip memory, </span></span><span><span data-start="1141.0">which you can observe </span></span><span><span data-start="1142.0">using the RT scratch performance counters in the new Xcode.</span></span></p><p><span><span data-start="1146.0">Now that I've discussed the role </span></span><span><span data-start="1148.0">and responsibilities of the intersector, </span></span><span><span data-start="1150.0">let's dissect the performance characteristics </span></span><span><span data-start="1153.0">of onetime through this intersector loop using an example.</span></span></p><p><span><span data-start="1158.0">Imagine our app is executing two SIMDgroups </span></span><span><span data-start="1161.0">that each wish to intersect four rays </span></span><span><span data-start="1163.0">with an acceleration structure.</span></span></p><p><span><span data-start="1167.0">In this example, </span></span><span><span data-start="1168.0">our acceleration structure contains </span></span><span><span data-start="1170.0">the classic kernel boxing, </span></span><span><span data-start="1172.0">with one box object and one sphere object.</span></span></p><p><span><span data-start="1176.0">The rays are cast into the scene </span></span><span><span data-start="1177.0">by calling the intersect method, </span></span><span><span data-start="1179.0">passing it the ray, the acceleration structure, </span></span><span><span data-start="1182.0">and the intersection function table. </span></span><span><span data-start="1185.0">Each SIMDgroup has two rays that intersect the box </span></span><span><span data-start="1188.0">and two the intersect the sphere. </span></span><span><span data-start="1191.0">In this example, </span></span><span><span data-start="1192.0">the box is defined as opaque triangle primitives </span></span><span><span data-start="1196.0">by using the MTLAccelerationStructure </span></span><span><span data-start="1199.0">TriangleGeometryDescriptor </span></span><span><span data-start="1201.0">and setting its opaque property to yes, </span></span><span><span data-start="1203.0">thus, the intersection can compute the intersections </span></span><span><span data-start="1206.0">using Metal's built-in intersection function.</span></span></p><p><span><span data-start="1211.0">However, the sphere is defined procedurally </span></span><span><span data-start="1213.0">using a custom bounding box intersection function </span></span><span><span data-start="1216.0">that the intersection must invoke.</span></span></p><p><span><span data-start="1220.0">The custom BoundingBoxIntersection function is declared </span></span><span><span data-start="1223.0">using the intersection attribute </span></span><span><span data-start="1224.0">with the bounding_box parameter.</span></span></p><p><span><span data-start="1228.0">As I mentioned before, </span></span><span><span data-start="1230.0">the intersect method is called by each thread </span></span><span><span data-start="1232.0">that is testing a ray against the acceleration structure. </span></span><span><span data-start="1235.0">So with this example in mind, </span></span><span><span data-start="1237.0">let's look at how each intersect calls traversal </span></span><span><span data-start="1241.0">and intersection test are executed </span></span><span><span data-start="1243.0">in a traditional implementation.</span></span></p><p><span><span data-start="1247.0">In typical usage, </span></span><span><span data-start="1248.0">not all traversals will take the same amount of time </span></span><span><span data-start="1250.0">to locate a primitive to test the ray against. </span></span><span><span data-start="1254.0">This creates what is called execution divergence, </span></span><span><span data-start="1257.0">which causes each thread in a SIMDgroup </span></span><span><span data-start="1259.0">to wait for the longest traversal from that SIMDgroup </span></span><span><span data-start="1261.0">before proceeding to the next stage.</span></span></p><p><span><span data-start="1265.0">And as it turns out, </span></span><span><span data-start="1266.0">the same overhead compounds </span></span><span><span data-start="1268.0">when executing the intersection functions too. </span></span><span><span data-start="1271.0">Execution divergence causes each type </span></span><span><span data-start="1274.0">of intersection function to run one after another, </span></span><span><span data-start="1276.0">further reducing parallelism. </span></span><span><span data-start="1279.0">An aggregate across both stages, </span></span><span><span data-start="1282.0">each thread spends a large proportion of its runtime idle, </span></span><span><span data-start="1285.0">waiting on the other threads in the SIMDgroup to complete, </span></span><span><span data-start="1288.0">which is a major performance bottleneck.</span></span></p><p><span><span data-start="1293.0">With that picture of a traditional implementation in mind, </span></span><span><span data-start="1296.0">let's discuss how hardware-accelerated ray tracing </span></span><span><span data-start="1299.0">optimizes those inefficiencies.</span></span></p><p><span><span data-start="1303.0">The first major improvement </span></span><span><span data-start="1304.0">is that the hardware intersector </span></span><span><span data-start="1306.0">is able to run each traversal completely independently </span></span><span><span data-start="1310.0">using fixed function hardware. </span></span><span><span data-start="1312.0">This is possible in part </span></span><span><span data-start="1314.0">because the arrays are sent to the hardware intersector </span></span><span><span data-start="1316.0">for processing </span></span><span><span data-start="1317.0">instead of executing in line with the GPU function. </span></span><span><span data-start="1321.0">This greatly decreases the time spent traversing </span></span><span><span data-start="1325.0">and also removes the overhead </span></span><span><span data-start="1326.0">of the traditional traversal's execution divergence.</span></span></p><p><span><span data-start="1333.0">On the other hand, the intersection functions </span></span><span><span data-start="1335.0">are Metal shading language code, </span></span><span><span data-start="1337.0">so they still must be grouped into SIMDgroups </span></span><span><span data-start="1339.0">to be run on the shader core. </span></span><span><span data-start="1342.0">However, because the hardware intersector </span></span><span><span data-start="1344.0">executes each ray independently, </span></span><span><span data-start="1347.0">it is free to group together the intersection function calls </span></span><span><span data-start="1350.0">from rays that originated from separate SIMDgroups.</span></span></p><p><span><span data-start="1355.0">This is the role of the reorder stage. </span></span><span><span data-start="1358.0">When rays reach this stage within close proximity and time, </span></span><span><span data-start="1362.0">the intersection function calls </span></span><span><span data-start="1364.0">will be grouped into coherent SIMDgroups, </span></span><span><span data-start="1366.0">such that the execution divergence overhead </span></span><span><span data-start="1369.0">present in the traditional implementation is reduced </span></span><span><span data-start="1372.0">or even completely eliminated.</span></span></p><p><span><span data-start="1376.0">So now that I've shown you </span></span><span><span data-start="1377.0">how hardware-accelerated ray tracing </span></span><span><span data-start="1380.0">improves the performance </span></span><span><span data-start="1381.0">of your app's ray intersector calls, </span></span><span><span data-start="1383.0">let's review some best practices </span></span><span><span data-start="1385.0">that your apps can implement to maximize its benefits.</span></span></p><p><span><span data-start="1390.0">Our first suggestion is to use the intersector object API </span></span><span><span data-start="1394.0">whenever possible. </span></span><span><span data-start="1395.0">Metal also allows ray tracing </span></span><span><span data-start="1397.0">to be performed using the intersection query API, </span></span><span><span data-start="1401.0">but this API increases </span></span><span><span data-start="1403.0">the amount of ray trace scratch memory </span></span><span><span data-start="1404.0">that must be read and written, </span></span><span><span data-start="1406.0">as well as disables the reorder stage.</span></span></p><p><span><span data-start="1410.0">We also recommend </span></span><span><span data-start="1411.0">when authoring custom intersection functions </span></span><span><span data-start="1414.0">to avoid creating one uber function </span></span><span><span data-start="1417.0">that is capable of executing </span></span><span><span data-start="1418.0">many different logical intersection routines. </span></span><span><span data-start="1422.0">Instead, create one Metal intersection function </span></span><span><span data-start="1425.0">for each logical intersection routine. </span></span><span><span data-start="1428.0">This increases the benefits of the reorder stage.</span></span></p><p><span><span data-start="1433.0">It is also important to try to minimize </span></span><span><span data-start="1435.0">the size of the ray payload structure that has passed to </span></span><span><span data-start="1438.0">and return from the intersector object. </span></span><span><span data-start="1441.0">This will decrease your shader's latency </span></span><span><span data-start="1443.0">and potentially increase its thread occupancy.</span></span></p><p><span><span data-start="1448.0">For more details and guidance </span></span><span><span data-start="1450.0">about how to optimize your ray tracing apps, </span></span><span><span data-start="1452.0">please watch these talks.</span></span></p><p><span><span data-start="1456.0">To recap, the Apple family 9 GPUs </span></span><span><span data-start="1459.0">greatly improved the performance of ray tracing </span></span><span><span data-start="1462.0">through new hardware acceleration </span></span><span><span data-start="1464.0">that features fixed function traversal blocks </span></span><span><span data-start="1466.0">and an intersection function reorder stage.</span></span></p><p><span><span data-start="1470.0">And although this new hardware </span></span><span><span data-start="1471.0">will improve the performance of all Metal ray tracing apps, </span></span><span><span data-start="1475.0">to maximize the benefits your app derives from it, </span></span><span><span data-start="1478.0">it's best to use the intersection API </span></span><span><span data-start="1481.0">instead of the intersection query API whenever possible.</span></span></p><p><span><span data-start="1486.0">The last advancement in the Apple family 9 GPUs </span></span><span><span data-start="1489.0">that I'd like to talk to you about </span></span><span><span data-start="1491.0">is hardware-accelerated mesh shading.</span></span></p><p><span><span data-start="1495.0">Mesh shading is a flexible, </span></span><span><span data-start="1497.0">GPU-driven geometry processing stage </span></span><span><span data-start="1499.0">in the rendering pipeline </span></span><span><span data-start="1501.0">that replaces the traditional vertex shader stage </span></span><span><span data-start="1504.0">with two compute-like shaders.</span></span></p><p><span><span data-start="1507.0">Object shaders execute in the first stage </span></span><span><span data-start="1509.0">and can be used to perform coarse grain processing </span></span><span><span data-start="1512.0">of app-specific inputs such as entire mesh objects. </span></span><span><span data-start="1516.0">Each object threadgroup can choose to spawn a mesh group </span></span><span><span data-start="1519.0">to perform subsequent finer grain processing. </span></span><span><span data-start="1523.0">Mesh shaders comprise the second stage. </span></span><span><span data-start="1526.0">Typically, a mesh threadgroup will process </span></span><span><span data-start="1528.0">a constituent piece of the parent object, </span></span><span><span data-start="1530.0">often referred to as a meshlet.</span></span></p><p><span><span data-start="1534.0">The output of the mesh threadgroup </span></span><span><span data-start="1536.0">is a Metal mesh object that encapsulates </span></span><span><span data-start="1539.0">a list of vertices and primitives </span></span><span><span data-start="1541.0">to be processed by the remainder </span></span><span><span data-start="1543.0">of the traditional graphics pipeline.</span></span></p><p><span><span data-start="1546.0">Mesh shading has numerous applications, </span></span><span><span data-start="1549.0">such as fine-grained geometry calling, </span></span><span><span data-start="1553.0">procedural geometry generation, </span></span><span><span data-start="1555.0">custom app-specific geometry representations, </span></span><span><span data-start="1559.0">such as compressed formats. </span></span><span><span data-start="1561.0">And for porting geometry and tessellation shaders </span></span><span><span data-start="1564.0">from other graphics APIs.</span></span></p><p><span><span data-start="1567.0">If you're unfamiliar with mesh shading in Metal, </span></span><span><span data-start="1569.0">I recommend that you check out the two talks below.</span></span></p><p><span><span data-start="1574.0">With hardware-accelerated mesh shading </span></span><span><span data-start="1576.0">on Apple family 9 GPUs, </span></span><span><span data-start="1578.0">the most notable improvement you'll observe </span></span><span><span data-start="1580.0">is much improved performance </span></span><span><span data-start="1582.0">of your existing mesh shading code..</span></span></p><p><span><span data-start="1585.0">Apple family 9 GPUs </span></span><span><span data-start="1586.0">are able to much more efficiently schedule object </span></span><span><span data-start="1589.0">and mesh threadgroups </span></span><span><span data-start="1590.0">to keep intermediate meshlet data on chip. </span></span><span><span data-start="1593.0">Thus, reducing memory traffic.</span></span></p><p><span><span data-start="1596.0">With the new hardware </span></span><span><span data-start="1597.0">also comes several Metal API enhancements. </span></span><span><span data-start="1601.0">The first is support for encoding draw mesh commands </span></span><span><span data-start="1604.0">into indirect command buffers. </span></span><span><span data-start="1607.0">This allows GPU-driven rendering pipelines </span></span><span><span data-start="1609.0">to make use of mesh shading </span></span><span><span data-start="1611.0">in addition to traditional vertex shaders.</span></span></p><p><span><span data-start="1615.0">The second API enhancement </span></span><span><span data-start="1617.0">expands the maximum number of threadgroups per mesh grid </span></span><span><span data-start="1620.0">from 1,024 to over 1 million.</span></span></p><p><span><span data-start="1624.0">Let's now review a couple of best practices </span></span><span><span data-start="1627.0">to ensure optimal mesh shading performance.</span></span></p><p><span><span data-start="1632.0">The metal::mesh object output by a mesh threadgroup </span></span><span><span data-start="1635.0">has several template parameters </span></span><span><span data-start="1636.0">whose size are important to keep as small as possible.</span></span></p><p><span><span data-start="1641.0">For the mesh's vertex and primitive data types, </span></span><span><span data-start="1644.0">this can be done, for example, by removing unused attributes </span></span><span><span data-start="1649.0">that may be present due to sharing those data types </span></span><span><span data-start="1651.0">with other unrelated vertex or mesh functions. </span></span><span><span data-start="1654.0">The mesh type must also specify </span></span><span><span data-start="1656.0">the maximum number of primitives and vertices </span></span><span><span data-start="1659.0">that may be output. </span></span><span><span data-start="1661.0">These should not be set any larger </span></span><span><span data-start="1663.0">than what your app's geometry, pipeline, and assets </span></span><span><span data-start="1666.0">actually need. </span></span><span><span data-start="1668.0">Being mindful of these sizes will reduce memory traffic </span></span><span><span data-start="1672.0">and may increase occupancy.</span></span></p><p><span><span data-start="1675.0">If performing per primitive calling in a mesh shader, </span></span><span><span data-start="1678.0">we don't recommend writing vertex positions </span></span><span><span data-start="1680.0">to the mesh object </span></span><span><span data-start="1682.0">just to be called by the hardware subsequent calling stage. </span></span><span><span data-start="1686.0">Instead, it is best to completely omit </span></span><span><span data-start="1689.0">writing such primitives </span></span><span><span data-start="1690.0">as that can save substantial processing time </span></span><span><span data-start="1693.0">in the remainder </span></span><span><span data-start="1694.0">of the hardware's geometry processing stages.</span></span></p><p><span><span data-start="1699.0">All right, let's recap what I covered </span></span><span><span data-start="1701.0">about the Apple family 9 GPUs.</span></span></p><p><span><span data-start="1705.0">The next-generation shader core </span></span><span><span data-start="1707.0">increases on-chip memory utilization </span></span><span><span data-start="1710.0">for better thread occupancy and performance </span></span><span><span data-start="1712.0">by dynamically allocating register storage </span></span><span><span data-start="1715.0">and sharing on-chip memory across many memory types.</span></span></p><p><span><span data-start="1720.0">Hardware-accelerated ray tracing </span></span><span><span data-start="1722.0">greatly improves the performance of apps </span></span><span><span data-start="1724.0">using the Metal ray tracing APIs, </span></span><span><span data-start="1726.0">enabling new high-fidelity visual effects. </span></span><span><span data-start="1730.0">And finally, mesh shading performance is greatly improved </span></span><span><span data-start="1734.0">thanks to hardware acceleration, </span></span><span><span data-start="1736.0">enabling more apps to customize </span></span><span><span data-start="1738.0">their geometry processing pipeline.</span></span></p><p><span><span data-start="1742.0">Thank you for watching.</span></span></p>
							</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Switching to Elixir (303 pts)]]></title>
            <link>https://www.leemeichin.com/posts/switching-to-elixir.html</link>
            <guid>38214644</guid>
            <pubDate>Fri, 10 Nov 2023 03:11:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.leemeichin.com/posts/switching-to-elixir.html">https://www.leemeichin.com/posts/switching-to-elixir.html</a>, See on <a href="https://news.ycombinator.com/item?id=38214644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<header>

</header><p>
A few months ago I started a new job at a company that uses Elixir as its main language on the backend. I've never written a line of Elixir or Erlang before in my life, but I've heard a lot about it and Erlang is familiar because I've played around with Prolog for a bit.
</p>

<p>
Thanks to the heavily Ruby-inspired syntax, Elixir was a synch to pick up. I might not be an expert on best practices, architecture, and lower level Erlang concepts yet, but none of this has been a barrier to entry.
</p>

<p>
In fact, I might go as far as saying that Elixir gives you a fun language (like Ruby) while leaving out the stateful footguns OOP languages give you. There are no classes, no instances, no inheritance…it's immutable and functional and you're not bogged down by a static type system.
</p>

<p>
I see this as a benefit because code that holds mutable state is immensely harder to maintain than code that doesn't, and it isn't always clear to a developer if state should be local to a function, to an instance, or to a class. In Ruby you'll tend to get a mix of all three in an attempt to build an intuitive DSL, because literally everything is an object and therefore every object can hold state. It's called an Eigenclass, which is like a class of a class, and every class has one (and is how one instance of a class can mutate the state of every other instance, without knowing about them, by modifying the eigenclass).
</p>

<p>
Speaking of which, Elixir mimics Ruby in its support for DSLs (Domain Specific Languages) too, with a very familiar syntax. The key difference is that Elixir DSLs are compile-time macros and they generate runtime code, whereas Ruby DSLs depend on modifying the runtime by defining objects and methods dynamically.
</p>

<p>
I like this because I don't need to write a test to confirm that I used a library correctly. Either I used the macro wrong and I get an error from the library, or the generated macro was wrong and I get an error from the compiler. All of this happens at compile time, so I can just focus on writing tests on my actual application logic.
</p>

<p>
The pipeline syntax is nice, but I like Clojure's 'threading' operators a lot. They're not related to concurrency, you just have two operators: <code>-&gt;</code> is the same as Elixir's <code>|&gt;</code>, and it inserts the result of the previous expression into the first argument of the next function; <code>-&gt;&gt;</code> in Clojure inserts the same result into the <i>last</i> argument. It seems minor but works great with interop without having to write an anonymous function.
</p>

<p>
I love the <code>with</code> expression, if only because it reminds me of Haskell and Lisp with <code>let</code>, while baking in <code>otherwise</code>. This basically lets you split a complex function in half, with the happy path in the top part and the error handling at the bottom. It works best with a <code>Result</code> tuple because if you can't pattern match on <code>{:ok, result}</code> then you have a recoverable error.
</p>

<p>
Exceptions, then! In Ruby it's common to use exceptions for control flow. It often feels cleaner to do that because it's not common to return explicit error types; usually you either get a successful result or <code>nil</code> or <code>false</code>, and if you're lucky the error state was actually stored in one of the objects you were using. If you call <code>model.update(params)</code> in Ruby, then it returns <code>false</code> if it fails and updates <code>model.errors</code> with what went wrong. Mutable state.
</p>

<p>
I'm happy to see the <code>Result</code> / <code>Either</code> monad get mainstream traction compared to that. Exceptions for exceptional stuff, and a tuple that gives you <code>ok</code> and <code>error</code> as a return value (or <code>left</code> and <code>right</code> with the <code>Either</code> type).
</p>

<p>
I've only scratched the surface really, and I'm sure I'll have more thoughts as I continue to work, but after 3 months of Elixir I have to say that I <i>genuinely</i> enjoy writing it and it carries Ruby's torch of programming being fun.
</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>