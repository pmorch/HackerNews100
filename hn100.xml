<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 21 Dec 2024 15:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Ugly Truth About Spotify Is Finally Revealed (157 pts)]]></title>
            <link>https://www.honest-broker.com/p/the-ugly-truth-about-spotify-is-finally</link>
            <guid>42478107</guid>
            <pubDate>Sat, 21 Dec 2024 07:45:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.honest-broker.com/p/the-ugly-truth-about-spotify-is-finally">https://www.honest-broker.com/p/the-ugly-truth-about-spotify-is-finally</a>, See on <a href="https://news.ycombinator.com/item?id=42478107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png" width="1057" height="352" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b230059-81df-4830-9363-090897fa95c0_1057x352.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:352,&quot;width&quot;:1057,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:27483,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b230059-81df-4830-9363-090897fa95c0_1057x352.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>In early 2022, I started noticing something strange in Spotify’s jazz playlists.</p><p>I listen to jazz every day, and pay close attention to new releases. But these Spotify playlists were filled with artists I’d never heard of before.</p><p>Who were they? Where did they come from? Did they even exist?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp" width="1062" height="786" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:786,&quot;width&quot;:1062,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37124,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ec525-ba8d-4708-b6e5-a1ff891b2451_1062x786.webp 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>In April 2022, I finally felt justified in sharing my concerns with readers. So I published an article here called </span><a href="https://www.honest-broker.com/p/the-fake-artists-problem-is-much" rel="">“The Fake Artists Problem Is Much Worse Than You Realize.”</a></p><p>I was careful not to make accusations I couldn’t prove. But I pointed out some puzzling facts.</p><p>Many of these artists live in Sweden—where Spotify has its headquarters. According to one source, a huge amount of streaming music originates from just 20 people, who operate under 500 different names.</p><p><span>Some of them were generating supersized numbers. An obscure Swedish jazz musician got more plays than most of the tracks on Jon Batiste’s </span><em>We Are</em><span>—which had just won the Grammy for Album of the Year (not just the best jazz album, but the best album in </span><em>any</em><span> genre).</span></p><p>How was that even possible?</p><p><span>I continued to make inquiries, and brooded over this strange situation. But</span><a href="https://www.honest-broker.com/p/spotify-gives-49-different-names" rel=""> something even stranger happened a few months later</a><span>.</span></p><p>A listener noticed that he kept hearing the same track over and over on Spotify. But when he checked the name of the song, it was always different. Even worse, these almost identical tracks were attributed to different artists and composers.</p><p><span>He </span><a href="https://open.spotify.com/playlist/3wLm5nlYrHkbd29ilMRq89?si=e6f3299113e34bb9" rel="">created a playlist</a><span>, and soon had 49 different versions of this song under various names. The titles sounded as if they had come out of a random text generator—almost as if the goal was to make them hard to remember. </span></p><ul><li><p>Trumpet Bumblefig</p></li><li><p>Bumble Mistywill</p></li><li><p>Whomping Clover</p></li><li><p>Qeazpoor</p></li><li><p>Swiftspark</p></li><li><p>Vattio Bud</p></li></ul><p><a href="https://www.honest-broker.com/p/spotify-gives-49-different-names" rel="">I reported on this odd situation</a><span>. Others joined in the hunt, and </span><a href="https://open.spotify.com/playlist/2haHwyJ3pT5COriXW9z0dT?si=b9GjincIRYuiV5j1lXcE4w" rel="">found more versions</a><span> of the track under still different names. </span></p><p>The track itself was boring and non-descript, but it was showing up everywhere on the platform. </p><p>Around this same time, I started hearing jazz piano playlists on Spotify that disturbed me. Every track sounded like it was played on the same instrument with the exact same touch and tone. Yet the names of the artists were all different.</p><p>Were these AI generated? Was Spotify doing this to avoid paying royalties to human musicians?</p><p><span>Spotify </span><a href="https://www.billboard.com/music/music-news/spotify-fake-artist-allegations-response-7858015/" rel="">issued a statement</a><span> in the face of these controversies. But I couldn’t find any denial that they were playing games with playlists in order to boost profits.</span></p><p>By total coincidence, Spotify’s profitability started to improve markedly around this time. </p><p>A few months ago, I spoke with an editor at one of the largest newspapers in the world. I begged him to put together a team of investigative journalists to get to the bottom of this. </p><p>“You need to send people to Sweden. You need to find sources. You need to find out what’s really going on.”</p><p>He wasn’t interested in any of that. He just wanted a spicy opinon piece. I declined his invitation to write it.</p><p>We now finally have the ugly truth on these fake artists—but no thanks to Spotify. Or to that prestigious newspaper whose editor I petitioned. </p><p><span>Instead journalist </span><a href="https://harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/" rel="">Liz Pelly has conducted an in-depth investigation, and published her findings in </a><em><a href="https://harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/" rel="">Harper’s</a></em><span>—they are part of her forthcoming book </span><em><a href="https://lizpelly.info/book" rel="">Mood Machine: The Rise of Spotify and the Costs of the Perfect Playlist</a></em><span>. </span></p><p><em>Mood Machine</em><span> will show up in bookstores in January and may finally wake up the music industry to the dangers it faces.</span></p><p>Pelly started by knocking on the doors of these mysterious viral artists in Sweden.</p><p>Guess what? Nobody wanted to talk. At least not at first. </p><p>But Pelly kept pursuing this story for a year. She convinced former employees to reveal what they knew. She got her hands on internal documents. She read Slack messages from the company. And she slowly put the pieces together. </p><p><a href="https://harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/" rel="">Now she writes</a><span>:</span></p><blockquote><p>What I uncovered was an elaborate internal program. Spotify, I discovered, not only has partnerships with a web of production companies, which, as one former employee put it, provide Spotify with “music we benefited from financially,” but also a team of employees working to seed these tracks on playlists across the platform. In doing so, they are effectively working to grow the percentage of total streams of music that is cheaper for the platform. </p></blockquote><p>In other words, Spotify has gone to war against musicians and record labels. </p><p>At Spotify they call this the “Perfect Fit Content” (PFC) program. Musicians who provide PFC tracks “must often give up control of certain royalty rights that, if a track becomes popular, could be highly lucrative.”</p><p>Spotify apparently targeted genres where they could promote passive consumption. They identified situations in which listeners use playlists for background music. That’s why I noticed the fake artists problem first in my jazz listening.</p><p>According to Pelly, the focal points of PFC were “ambient, classical, electronic, jazz, and lo-fi beats.”</p><p><span>When some employees expressed concerns about this, Spotify managers replied (</span><a href="https://harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/" rel="">according to Pelly’s sources</a><span>) that “listeners wouldn’t know the difference.”</span></p><p>They called it payola in the 1950s. The public learned that radio deejays picked songs for airplay based on cash kickbacks, not musical merit.</p><p>Music fans got angry and demanded action. In 1959, both the US Senate and House launched investigations. Famous deejay Alan Freed got fired from WABC after refusing to sign a statement claiming that he had never taken bribes.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png" width="912" height="626" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f629fd47-74e7-4346-99ac-b78e383e6621_912x626.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:626,&quot;width&quot;:912,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:559897,&quot;alt&quot;:&quot;News headline from 1959&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="News headline from 1959" title="News headline from 1959" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff629fd47-74e7-4346-99ac-b78e383e6621_912x626.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>They called it Payola, and people got fired</figcaption></figure></div><p>Transactions nowadays are handled more delicately—and seemingly in full compliance with the laws. Nobody gives Spotify execs an envelope filled with cash.</p><p><a href="https://www.sec.gov/edgar/browse/?CIK=1639920&amp;owner=exclude" rel="">But this is better than payola</a><span>:</span></p><ul><li><p><span>On February 7, Spotify’s CEO sold</span><a href="https://www.musicbusinessworldwide.com/daniel-ek-cashes-out-another-57-5m-in-spotify-stock-after-selling-64m-months-earlier/" rel=""> 250K shares for $57.5 million</a><span>.</span></p></li><li><p><span>On April 24, Spotify’s CEO sold </span><a href="https://www.musicbusinessworldwide.com/spotifys-daniel-ek-cashes-out-118-8-million-in-shares/" rel="">400K shares for $118.8 million</a><span>.</span></p></li><li><p><span>On November 15, Spotify’s CEO sold </span><a href="https://www.musicbusinessworldwide.com/daniel-ek-just-cashed-out-35-cashed-in-384-million/" rel="">75K shares for $35.8 million</a><span>.</span></p></li><li><p><span>On November 20, Spotify’s CEO sold </span><a href="https://www.musicbusinessworldwide.com/key-spotify-executives-have-cashed-out-more-than-1-billion-in-stock-this-year-including-283-million-for-daniel-ek/" rel="">75K shares for $34.8 million</a><span>.</span></p></li><li><p><span>On November 26, Spotify’s CEO sold </span><a href="https://www.musicbusinessworldwide.com/key-spotify-executives-have-cashed-out-more-than-1-billion-in-stock-this-year-including-283-million-for-daniel-ek/" rel="">75K shares for $36.1 million</a><span>.</span></p></li><li><p><span>On December 4, Spotify’s CEO sold </span><a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001639920/2df85ff7-808d-4889-a79f-bbce7aa19236.pdf" rel="">75K shares for $37 million</a><span>.</span></p></li><li><p><span>On December 11, Spotify’s CEO sold </span><a href="https://www.edmtunes.com/2024/12/spotify-ceo-sells-millions-stock/" rel="">60K shares for $28.3 million</a><span>.</span></p></li></ul><p>Deejay Alan Freed couldn’t dream of such riches. In fact, nobody in the history of music has made more money than the CEO of Spotify. </p><p>Taylor Swift doesn’t earn that much. Even after fifty years of concertizing, Paul McCartney and Mick Jagger can’t match this kind of wealth. </p><p>At this point, I need to complain about the stupid major record labels who have empowered and supported Spotify during its long history. At some junctures, they have even been shareholders.</p><p>I’ve warned repeatedly that this is a huge mistake. Spotify is their adversary, not their partner. The longer they avoid admitting this to themselves, the worse things will get. </p><p><span>The music media isn’t much better—these new revelations came from a freelancer publishing in </span><em>Harper’s</em><span>, not from </span><em>Rolling Stone</em><span> or </span><em>Billboard</em><span> or </span><em>Variety.</em><span> </span></p><p><span>And I could say the same for the </span><em>New York Times</em><span> and </span><em>Wall Street Journal</em><span> and </span><em>Washington Post</em><span>. </span></p><p>Why didn’t they investigate this? Why don’t they care?</p><p><span>But I </span><em>am</em><span> grateful for independent journalism, which is now my main hope for the future. </span></p><p>Let’s turn to the bigger question: What do we do about this?</p><p>By all means, let’s name and shame the perpetrators. But we need more than that.</p><p>Congress should investigate ethical violations at music streaming businesses—just like they did with payola. Laws must be passed requiring full transparency. Even better, let’s prevent huge streaming platforms from promoting songs based on financial incentives.</p><p>I don’t do that as a critic. People sometimes try to offer me money for coverage, and I tell them off. It happened again this week, and I got upset. No honest person could take those payoffs.</p><p>Streaming platforms ought to have similar standards. And if they won’t do it voluntarily, legislators and courts should force their hand.</p><p>And let me express a futile wish that the major record labels will find a spine. They need to create an alternative—even if it requires an antitrust exemption from Congress (much like major league sports). </p><p>Our single best hope is a cooperative streaming platform owned by labels and musicians. Let’s reclaim music from the technocrats. They have not proven themselves worthy of our trust. </p><p>If the music industry ‘leaders’ haven’t figured that out by now—especially after the latest revelations—we are in bad shape indeed.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US judge finds Israel's NSO Group liable for hacking journalists via WhatsApp (290 pts)]]></title>
            <link>https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/</link>
            <guid>42476828</guid>
            <pubDate>Sat, 21 Dec 2024 01:38:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/">https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/</a>, See on <a href="https://news.ycombinator.com/item?id=42476828">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Compiling C to Safe Rust, Formalized (234 pts)]]></title>
            <link>https://arxiv.org/abs/2412.15042</link>
            <guid>42476192</guid>
            <pubDate>Fri, 20 Dec 2024 23:30:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.15042">https://arxiv.org/abs/2412.15042</a>, See on <a href="https://news.ycombinator.com/item?id=42476192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.15042">View PDF</a></p><blockquote>
            <span>Abstract:</span>The popularity of the Rust language continues to explode; yet, many critical codebases remain authored in C, and cannot be realistically rewritten by hand. Automatically translating C to Rust is thus an appealing course of action. Several works have gone down this path, handling an ever-increasing subset of C through a variety of Rust features, such as unsafe. While the prospect of automation is appealing, producing code that relies on unsafe negates the memory safety guarantees offered by Rust, and therefore the main advantages of porting existing codebases to memory-safe languages.
<br>We instead explore a different path, and explore what it would take to translate C to safe Rust; that is, to produce code that is trivially memory safe, because it abides by Rust's type system without caveats. Our work sports several original contributions: a type-directed translation from (a subset of) C to safe Rust; a novel static analysis based on "split trees" that allows expressing C's pointer arithmetic using Rust's slices and splitting operations; an analysis that infers exactly which borrows need to be mutable; and a compilation strategy for C's struct types that is compatible with Rust's distinction between non-owned and owned allocations.
<br>We apply our methodology to existing formally verified C codebases: the HACL* cryptographic library, and binary parsers and serializers from EverParse, and show that the subset of C we support is sufficient to translate both applications to safe Rust. Our evaluation shows that for the few places that do violate Rust's aliasing discipline, automated, surgical rewrites suffice; and that the few strategic copies we insert have a negligible performance impact. Of particular note, the application of our approach to HACL* results in a 80,000 line verified cryptographic library, written in pure Rust, that implements all modern algorithms - the first of its kind.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Aymeric Fromherz [<a href="https://arxiv.org/show-email/8fe3c653/2412.15042" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 19 Dec 2024 16:51:29 UTC (92 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Raycaster in Bash (192 pts)]]></title>
            <link>https://github.com/izabera/pseudo3d</link>
            <guid>42475703</guid>
            <pubDate>Fri, 20 Dec 2024 22:25:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/izabera/pseudo3d">https://github.com/izabera/pseudo3d</a>, See on <a href="https://news.ycombinator.com/item?id=42475703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">a raycaster in bash</h2><a id="user-content-a-raycaster-in-bash" aria-label="Permalink: a raycaster in bash" href="#a-raycaster-in-bash"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description wolfenstein-in-bash.mp4">wolfenstein-in-bash.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1572859/397868206-addb77f3-f309-48ab-8609-a8ea3082c952.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ3NTU3MDMsIm5iZiI6MTczNDc1NTQwMywicGF0aCI6Ii8xNTcyODU5LzM5Nzg2ODIwNi1hZGRiNzdmMy1mMzA5LTQ4YWItODYwOS1hOGVhMzA4MmM5NTIubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMjFUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Nzg0YTY2YmM0MzhhNzliZmUxYTU3ODAzMzRiODQzMTJhZDkyMGVkYzI4YWM3NWJiOGEzMWFlZjY2Zjc5ZjIzMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.6c7Jq5sz0dH0ZkjiCzBpIi5gj9WWwB73p7Ac9DdJS0I" data-canonical-src="https://private-user-images.githubusercontent.com/1572859/397868206-addb77f3-f309-48ab-8609-a8ea3082c952.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ3NTU3MDMsIm5iZiI6MTczNDc1NTQwMywicGF0aCI6Ii8xNTcyODU5LzM5Nzg2ODIwNi1hZGRiNzdmMy1mMzA5LTQ4YWItODYwOS1hOGVhMzA4MmM5NTIubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMjFUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Nzg0YTY2YmM0MzhhNzliZmUxYTU3ODAzMzRiODQzMTJhZDkyMGVkYzI4YWM3NWJiOGEzMWFlZjY2Zjc5ZjIzMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.6c7Jq5sz0dH0ZkjiCzBpIi5gj9WWwB73p7Ac9DdJS0I" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">more screenshots/vidoes at <a href="https://imgur.com/a/izas-wolfenstein-bash-journey-bAy5zhp" rel="nofollow">https://imgur.com/a/izas-wolfenstein-bash-journey-bAy5zhp</a></p>
<p dir="auto">largely a port of <a href="https://lodev.org/cgtutor/raycasting.html" rel="nofollow">https://lodev.org/cgtutor/raycasting.html</a></p>
<p dir="auto">use the arrow keys to rotate and move around, and q to quit</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">why this was a bit hard:</h3><a id="user-content-why-this-was-a-bit-hard" aria-label="Permalink: why this was a bit hard:" href="#why-this-was-a-bit-hard"></a></p>
<ul dir="auto">
<li>
<p dir="auto">bash is slow.  this is by far the biggest issue.  it's so slow that you
cannot possibly achieve an acceptable frame rate if you have to execute even
a single command per pixel.  this implies that you also cannot keep the state
of the screen in memory, neither as an array of colours (did you know that
accessing a random element in an array takes linear time?) nor as a single
long string (did you know that accessing the nth character in a string takes
linear time even in LANG=C?), because literally just reading this
representation to dump it to the screen will take longer than a frame</p>
</li>
<li>
<p dir="auto">bash has no floating point support nor access to a library of maths
functions. all the maths is done on integers, scaled up by 100000</p>
</li>
<li>
<p dir="auto">terminals are ugly if you use a full character to represent each pixel, so
this uses unicode half blocks with different foreground and background
colours, which effectively doubles the vertical resolution.  there is
unfortunately no way to update only one of the two colours in a cell, nor any
way to query the current colours of a cell (besides, it would be too slow for
bash), so every time we write a pixel we need to know the colour of an
adjacent pixel.  it would be really convenient if bash could store the state
somehow but alas it cannot</p>
</li>
<li>
<p dir="auto">various misc annoyances:</p>
<ul dir="auto">
<li>
<p dir="auto">making sure all the terminal is updated at once is not trivial with a
slow language like bash</p>
</li>
<li>
<p dir="auto">most terminals are not designed to play video games in (shockingly), so
you cannot test if a key is currently pressed.  instead you can only get
a single key that's being held down, usually really slowly debounced and
with a low limit for continued presses, so you probably get like 5-6
characters a second.  you cannot even get multiple keys pressed at the
same time unless some are modifiers.  the kitty keyboard protocol 100%
fixes all this, and i'm sure it will become a widely implemented standard
by the year 2100</p>
</li>
<li>
<p dir="auto">turns out that filling a terminal with colours takes a lot of data.  at
my normal font size this does ~10mb of i/o per second, which isn't very
much in the grand scheme of things, but, you know, it's bash</p>
</li>
<li>
<p dir="auto">bash will never use a single syscall to print a string with more than one
newline, regardless of the type of file you're writing to.  this is
pointless and dumb, and it's the reason why this never prints \n and
always moves the cursor in other ways.  ultimately this ended up printing
more data than the size your terminal is likely getting in each read, so
it might not matter too much, but it still bothered me</p>
</li>
<li>
<p dir="auto">ecma48/vt100/vt200/xterm... were all designed by insane people who hated
me specifically</p>
</li>
<li>
<p dir="auto">holy shit i'm bad at maths, i went to uni for this what the fuck</p>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">faq:</h3><a id="user-content-faq" aria-label="Permalink: faq:" href="#faq"></a></p>
<ul dir="auto">
<li>
<p dir="auto">q: it fucks things up when i resize the window/it's a flickery mess/it
generally looks like shite on my terminal</p>
</li>
<li>
<p dir="auto">a: open an issue please</p>
</li>
<li>
<p dir="auto">q: my cpu heats up like crazy/my computer from 2005 slows down to a crawl</p>
</li>
<li>
<p dir="auto">a: try to set the env variable FPS to something less than 30</p>
</li>
<li>
<p dir="auto">q: it doesn't work on my bash &lt; 5</p>
</li>
<li>
<p dir="auto">a: yep</p>
</li>
<li>
<p dir="auto">q: is this code all pure bash?</p>
</li>
<li>
<p dir="auto">a: no.  it also calls stty once at startup to disable echo, and once at exit
to re enable it</p>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qualcomm wins licensing fight with Arm over chip designs (194 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs</link>
            <guid>42475228</guid>
            <pubDate>Fri, 20 Dec 2024 21:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs">https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs</a>, See on <a href="https://news.ycombinator.com/item?id=42475228">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DOS APPEND (110 pts)]]></title>
            <link>https://www.os2museum.com/wp/dos-append/</link>
            <guid>42475011</guid>
            <pubDate>Fri, 20 Dec 2024 21:04:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.os2museum.com/wp/dos-append/">https://www.os2museum.com/wp/dos-append/</a>, See on <a href="https://news.ycombinator.com/item?id=42475011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						
<p>For a long time, I couldn’t quite grasp what the DOS APPEND command could possibly be good for. Until I came across a situation which APPEND was made for.</p>



<p>When I worked on organizing and building the <a href="https://www.os2museum.com/wp/dos-2-11-from-scratch/" data-type="post" data-id="5611">DOS 2.11 source code</a>, I tried to place the source files in a tree structure similar to that used by DOS 3.x (this is known from DOS 3.x OAKs):</p>



<pre>C:.<br>└───src<br>    ├───bios<br>    ├───cmd<br>    │   ├───chkdsk<br>    │   ├───command<br>    │   ├───debug<br>    │   ├───diskcopy<br>    │   ├───edlin<br>    │   ├───exe2bin<br>    │   ├───fc<br>    │   ├───find<br>    │   ├───format<br>    │   ├───more<br>    │   ├───print<br>    │   ├───recover<br>    │   ├───sort<br>    │   └───sys<br>    ├───dos<br>    ├───inc<br>    └───msdos<br></pre>



<p>The <code>inc</code> subdirectory unsurprisingly contains shared include files such as <code>DOSSYM.ASM</code>, which are included just about from everywhere. No problem, right?</p>



<p>Except… to get output that most closely matches existing DOS 2.x binaries, it is necessary to use an old version of MASM (version 1.25 seems to do the trick). But MASM 1.25 is designed to run on top of DOS 1.x, and knows nothing whatsoever about directories.</p>



<p>It is possible that back in the day, DOS 2.x was built from a single huge directory on a hard disk. In fact it is known that DOS 2.0 could not be built on PCs at all, and was built on DEC mainframes. Yet DOS 2.11 was also clearly modified such that it <em>could</em> be build on PCs using Microsoft’s development tools.</p>



<p>However it was done back in 1983, lumping 150+ assembler source files into a single directory, and then adding hundreds of object and executable files, did not sound <em>at all</em> appealing. Cloning <code>DOSSYM.ASM</code> to every directory where it was needed seemed even worse.</p>



<p>That’s when I somehow remembered that APPEND exists, and realized that it’s the perfect solution to the problem. Before building, one can run</p>



<pre>APPEND ..\..\INC;..\INC</pre>



<p>and the <code>inc</code> directory becomes accessible from all of its sibling subdirectories and from subdirectories one level deeper. It would have been possible to use an absolute path as well, but this way the build batch file does not need to know where it lives.</p>



<p>With APPEND in place, the old MASM 1.25 which uses FCB I/O will find the centrally located include files, and the source code can be organized into a neat hierarchical structure that’s far easier to work with than one giant blob.</p>



<h3>What is APPEND?</h3>



<p>APPEND is a “DOS extension”, in fact it is a TSR which intercepts INT 21h and adds special handling for several subfunctions. These are primarily:</p>



<ul>
<li><strong>0Fh</strong> FCB File Open</li>



<li><strong>3Dh</strong> Handle File Open</li>



<li><strong>23h</strong> Get File Size</li>
</ul>



<p>If these subfunctions fail to find a file in the current directory, APPEND will retry them using the list of paths it manages.</p>



<p>When building DOS 2.11, MASM 1.25 will try to open DOSSYM.ASM using INT 21h/0Fh (FCB File Open). Because the file does not exist in the current directory, the initial attempt will fail. APPEND will then try opening <code>..\INC\DOSSYM.ASM</code> and, if that is unsuccessful, also <code>..\..\INC\DOSSYM.ASM</code>. Old MASM is thus magically upgraded to handle multiple directories, without actually knowing anything about them.</p>



<p>The working principle of APPEND is not complicated. It primarily serves as a bridge between old DOS applications which have no or poor support for directories, and users who really, really want to organize files and programs in multiple directories and possibly across multiple drive letters. Of course the actual APPEND implementation is anything but straightforward.</p>



<h3>APPEND Evolution and Implementation</h3>



<p>The first DOS version which came with APPEND was DOS 3.3 (1987), not coincidentally the first DOS version developed by IBM.</p>



<p>But APPEND is older than that—it first appeared in the IBM PC Network Program 1.0 in 1985. It is hard to speculate why it was shipped with the PC Network Program (later the PC LAN Program) because APPEND does not <em>really</em> have anything to do with networking. It is plausible that it was especially useful with networking, when users were motivated to store applications on a central network server and data files on their own machines. And that’s a problem for applications which cannot handle directories well.</p>



<p>Now that we can see the <a href="https://github.com/microsoft/MS-DOS/blob/main/v4.0/src/CMD/APPEND/APPEND.ASM">source code for APPEND</a>, some things are clearer. The original PC Network Program version of APPEND was written by someone with initials G. G. A., and in 1986 it was adapted for shipping with DOS by B. A. F., no doubt Barry A. Feigenbaum (best known for developing the SMB protocol).</p>



<p>APPEND by default manages the path list in its own internal storage. But it also has a <code>/E</code> option which instead causes APPEND to look for an eponymous environment variable. This mechanism has a disadvantage in that the <code>APPEND=</code> variable needs space in every newly created environment. On the other hand, it also allows different DOS processes to have different APPEND paths.</p>



<p>It should be noted that OS/2 implements a mechanism analogous to <code>APPEND /E</code> through the <code>DPATH</code> environment variable. Only on OS/2 it’s built in, with no need to load TSRs.</p>



<p>Another APPEND addition was the <code>/X</code> switch, which causes APPEND to hook further DOS subfunctions, most notably Find First and Exec. This effectively allows APPEND to supplant the <code>PATH</code> environment variable.</p>



<p>APPEND is listed in the PC DOS 3.3 reference as both internal and external command. At first glance that doesn’t make any sense, but it’s actually true.</p>



<p>The first time APPEND is run, it is an external command. But when it installs itself as a TSR, it hooks INT 2Fh/AEh. COMMAND.COM, in turn, calls INT 2Fh/AEh when it is asked to execute a command that COMMAND.COM does not know about. This mechanism allows APPEND to function as an internal command once it is installed.</p>



<p>That is, the first time APPEND is run, it must be loaded and executed from disk. But any subsequent attempt to run APPEND through COMMAND.COM, either from the command line or a batch file, will take a shortcut directly to the already installed TSR, effectively turning APPEND into an internal command. The INT 2Fh/AEh interface between COMMAND.COM and a TSR was added in DOS 3.3, quite likely for the benefit of APPEND.</p>



<p>APPEND also has its own programming interface, accessed through INT 2Fh/B7h. This allows programs to control APPEND behavior and query the current APPEND path. How widely this is used isn’t entirely clear.</p>



<h3>Summary</h3>



<p>APPEND is one of the things that are completely irrelevant 99.99% of the time… yet can be extremely useful when the need arises. It is a TSR which allows applications to find files in a directory other than the current one.</p>



<p>The first appearance in APPEND was in the IBM PC Network Program (1985), but since version 3.3 (1987) it was integrated into DOS, with an interesting link to COMMAND.COM which allows APPEND to become an internal command once it is installed.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI O3 breakthrough high score on ARC-AGI-PUB (1441 pts)]]></title>
            <link>https://arcprize.org/blog/oai-o3-pub-breakthrough</link>
            <guid>42473321</guid>
            <pubDate>Fri, 20 Dec 2024 18:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough">https://arcprize.org/blog/oai-o3-pub-breakthrough</a>, See on <a href="https://news.ycombinator.com/item?id=42473321">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            <h2>ARC Prize remains undefeated.<br>New ideas still needed<span>.</span></h2>
        </p><div>


<p>OpenAI's new o3 system - trained on the ARC-AGI-1 Public Training set - has scored a breakthrough <strong>75.7%</strong> on the Semi-Private Evaluation set at our stated public leaderboard $10k compute limit. A high-compute (172x) o3 configuration scored <strong>87.5%</strong>.</p>

<p><img src="https://arcprize.org/media/images/blog/o-series-performance.jpg" alt="o Series Performance"></p>

<p>This is a surprising and important step-function increase in AI capabilities, showing novel task adaptation ability never seen before in the GPT-family models. For context, ARC-AGI-1 took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3.</p>

<p>The mission of ARC Prize goes beyond our first benchmark: to be a North Star towards AGI. And we're excited to be working with the OpenAI team and others next year to continue to design next-gen, enduring AGI benchmarks.</p>

<p>ARC-AGI-2 (same format - verified easy for humans, harder for AI) will launch alongside ARC Prize 2025. We're committed to running the Grand Prize competition until a high-efficiency, open-source solution scoring 85% is created.</p>

<p>Read on for the full testing report.</p>

<hr>

<h2 id="openai-o3-arc-agi-results">OpenAI o3 ARC-AGI Results</h2>

<p>We tested o3 against two ARC-AGI datasets:</p>

<ul>
  <li><strong>Semi-Private Eval</strong>: 100 private tasks used to assess overfitting</li>
  <li><strong>Public Eval</strong>: 400 public tasks</li>
</ul>

<p>At OpenAI's direction, we tested at two levels of compute with variable sample sizes: 6 (high-efficiency) and 1024 (low-efficiency, 172x compute).</p>

<p>Here are the results.</p>

<div>
    <table>
    <thead>
        <tr>
        <th>Set</th>
        <th>Tasks</th>
        <th>Efficiency</th>
        <th>Score</th>
        <th>Retail Cost</th>
        <th>Samples</th>
        <th>Tokens</th>
        <th>Cost/Task</th>
        <th>Time/Task (mins)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
        <td>Semi-Private</td>
        <td>100</td>
        <td>High</td>
        <td>75.7%</td>
        <td>$2,012</td>
        <td>6</td>
        <td>33M</td>
        <td>$20</td>
        <td>1.3</td>
        </tr>
        <tr>
        <td>Semi-Private</td>
        <td>100</td>
        <td>Low</td>
        <td>87.5%</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        </tr>
        <tr>
        <td>Public</td>
        <td>400</td>
        <td>High</td>
        <td>82.8%</td>
        <td>$6,677</td>
        <td>6</td>
        <td>111M</td>
        <td>$17</td>
        <td>N/A</td>
        </tr>
        <tr>
        <td>Public</td>
        <td>400</td>
        <td>Low</td>
        <td>91.5%</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>--</td>
        </tr>
    </tbody>
    </table>
</div>

<ul>
  <li>Note: OpenAI has requested that we not publish the high-compute costs. The amount of compute was roughly 172x the low-compute configuration.</li>
</ul>

<p>Due to variable inference budget, efficiency (e.g., compute cost) is now a required metric when reporting performance. We've documented both the total costs and the cost per task as an initial proxy for efficiency. As an industry, we'll need to figure out <a href="https://x.com/mikeknoop/status/1868760635716386864" target="_blank">what metric best tracks efficiency</a>, but directionally, cost is a solid starting point.</p>

<p>The high-efficiency score of 75.7% is within the budget rules of ARC-AGI-Pub (costs &lt;$10k) and therefore qualifies as 1st place on the public leaderboard!</p>

<p>The low-efficiency score of 87.5% is quite expensive, but still shows that performance on novel tasks does improve with increased compute (at least up to this level.)</p>

<p>Despite the significant cost per task, these numbers aren't just the result of applying brute force compute to the benchmark. OpenAI's new o3 model represents a significant leap forward in AI's ability to adapt to novel tasks. This is not merely incremental improvement, but a genuine breakthrough, marking a qualitative shift in AI capabilities compared to the prior limitations of LLMs. o3 is a system capable of adapting to tasks it has never encountered before, arguably approaching human-level performance in the ARC-AGI domain.</p>

<p>Of course, such generality comes at a steep cost, and wouldn't quite be economical yet: you could pay a human to solve ARC-AGI tasks for roughly $5 per task (we know, we did that), while consuming mere cents in energy. Meanwhile o3 requires $17-20 per task in the low-compute mode. But cost-performance will likely improve quite dramatically over the next few months and years, so you should plan for these capabilities to become competitive with human work within a fairly short timeline.</p>

<p>o3's improvement over the GPT series proves that architecture is everything. You couldn't throw more compute at GPT-4 and get these results. Simply scaling up the things we were doing from 2019 to 2023 – take the same architecture, train a bigger version on more data – is not enough. Further progress is about new ideas.</p>

<hr>

<h3 id="so-is-it-agi">So is it AGI?</h3>

<p>ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI – as we've repeated dozens of times this year. It's a research tool designed to focus attention on the most challenging unsolved problems in AI, a role it has fulfilled well over the past five years.</p>

<p>Passing ARC-AGI does not equate to achieving AGI, and, as a matter of fact, I don't think o3 is AGI yet. o3 still fails on some very easy tasks, indicating fundamental differences with human intelligence.</p>

<p>Furthermore, early data points suggest that the upcoming ARC-AGI-2 benchmark will still pose a significant challenge to o3, potentially reducing its score to under 30% even at high compute (while a smart human would still be able to score over 95% with no training). This demonstrates the continued possibility of creating challenging, unsaturated benchmarks without having to rely on expert domain knowledge. You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.</p>

<h3 id="whats-different-about-o3-compared-to-older-models">What's different about o3 compared to older models?</h3>

<p>Why does o3 score so much higher than o1? And why did o1 score so much higher than GPT-4o in the first place? I think this series of results provides invaluable data points for the ongoing pursuit of AGI.</p>

<p>My mental model for LLMs is that they work as <a href="https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering" target="_blank">a repository of vector programs</a>. When prompted, they will fetch the program that your prompt maps to and "execute" it on the input at hand. LLMs are a way to store and operationalize millions of useful mini-programs via passive exposure to human-generated content.</p>

<p>This "memorize, fetch, apply" paradigm can achieve arbitrary levels of skills at arbitrary tasks given appropriate training data, but it cannot adapt to novelty or pick up new skills on the fly (which is to say that there is no fluid intelligence at play here.) This has been exemplified by the low performance of LLMs on ARC-AGI, the only benchmark specifically designed to measure adaptability to novelty – GPT-3 scored 0, GPT-4 scored near 0, GPT-4o got to 5%. Scaling up these models to the limits of what's possible wasn't getting ARC-AGI numbers anywhere near what basic brute enumeration could achieve years ago (up to 50%).</p>

<p>To adapt to novelty, you need two things. First, you need knowledge – a set of reusable functions or programs to draw upon. LLMs have more than enough of that. Second, you need the ability to recombine these functions into a brand new program when facing a new task – a program that models the task at hand. Program synthesis. LLMs have long lacked this feature. The o series of models fixes that.</p>

<p>For now, we can only speculate about the exact specifics of how o3 works. But o3's core mechanism appears to be natural language program search and execution within token space – at test time, the model searches over the space of possible Chains of Thought (CoTs) describing the steps required to solve the task, in a fashion perhaps not too dissimilar to AlphaZero-style Monte-Carlo tree search. In the case of o3, the search is presumably guided by some kind of evaluator model. To note, Demis Hassabis hinted back in <a href="https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/" target="_blank">a June 2023 interview</a> that DeepMind had been researching this very idea – this line of work has been a long time coming.</p>

<p>So while single-generation LLMs struggle with novelty, o3 overcomes this by generating and executing its own programs, where the program itself (the CoT) becomes the artifact of knowledge recombination. Although this is not the only viable approach to test-time knowledge recombination (you could also do test-time training, or search in latent space), it represents the current state-of-the-art as per these new ARC-AGI numbers.</p>

<p>Effectively, o3 represents a form of <em>deep learning-guided program search</em>. The model does test-time search over a space of "programs" (in this case, natural language programs – the space of CoTs that describe the steps to solve the task at hand), guided by a deep learning prior (the base LLM). The reason why solving a single ARC-AGI task can end up taking up tens of millions of tokens and cost thousands of dollars is because this search process has to explore an enormous number of paths through program space – including backtracking.</p>

<p>There are however two significant differences between what's happening here and what I meant when I previously described "deep learning-guided program search" as the best path to get to AGI. Crucially, the programs generated by o3 are <em>natural language instructions</em> (to be "executed" by a LLM) rather than <em>executable symbolic programs</em>. This means two things. First, that they cannot make contact with reality via execution and direct evaluation on the task – instead, they must be evaluated for fitness via another model, and the evaluation, lacking such grounding, might go wrong when operating out of distribution. Second, the system cannot autonomously acquire the ability to generate and evaluate these programs (the way a system like AlphaZero can learn to play a board game on its own.) Instead, it is reliant on expert-labeled, human-generated CoT data.</p>

<p>It's not yet clear what the exact limitations of the new system are and how far it might scale. We'll need further testing to find out. Regardless, the current performance represents a remarkable achievement, and a clear confirmation that intuition-guided test-time search over program space is a powerful paradigm to build AI systems that can adapt to arbitrary tasks.</p>

<h3 id="what-comes-next">What comes next?</h3>

<p>First of all, open-source replication of o3, facilitated by the ARC Prize competition in 2025, will be crucial to move the research community forward. A thorough analysis of o3's strengths and limitations is necessary to understand its scaling behavior, the nature of its potential bottlenecks, and anticipate what abilities further developments might unlock.</p>

<p>Moreover, ARC-AGI-1 is now saturating – besides o3's new score, the fact is that a large ensemble of low-compute Kaggle solutions can now score 81% on the private eval.</p>

<p>We're going to be raising the bar with a new version – ARC-AGI-2 - which has been in the works since 2022. It promises a major reset of the state-of-the-art. We want it to push the boundaries of AGI research with hard, high-signal evals that highlight current AI limitations.</p>

<p>Our early ARC-AGI-2 testing suggests it will be useful and extremely challenging, even for o3. And, of course, ARC Prize's objective is to produce a <em>high-efficiency</em> and <em>open-source</em> solution in order to win the Grand Prize. We currently intend to launch ARC-AGI-2 alongside ARC Prize 2025 (estimated launch: late Q1).</p>

<p>Going forward, the ARC Prize Foundation will continue to create new benchmarks to focus the attention of researchers on the hardest unsolved problems on the way to AGI. We've started work on a third-generation benchmark which departs completely from the 2019 ARC-AGI format and incorporates some exciting new ideas.</p>

<hr>

<h2 id="get-involved-open-source-analysis">Get Involved: Open-Source Analysis</h2>

<p>Today, we're also releasing high-compute, o3-labeled tasks and would like your help to analyze them. In particular, we are very curious about the ~9% set of Public Eval tasks o3 was unable to solve, even with lots of compute, yet are straightforward for humans.</p>

<p>We invite the community to help us assess the characteristics of both solved and unsolved tasks.</p>

<p>To get your ideas flowing, here are 3 examples of tasks unsolved by high-compute o3.</p>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-c6e1b8da.png" alt="ARC-AGI Task Id: c6e1b8da">
  <figcaption>ARC-AGI Task ID: c6e1b8da</figcaption>
</figure>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-0d87d2a6.png" alt="ARC-AGI Task Id: 0d87d2a6">
  <figcaption>ARC-AGI Task ID: 0d87d2a6</figcaption>
</figure>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-b457fec5.png" alt="ARC-AGI Task Id: b457fec5">
  <figcaption>ARC-AGI Task ID: b457fec5</figcaption>
</figure>

<p><a href="https://github.com/arcprizeorg/model_baseline/tree/main/results" target="_blank">See our full set of o3 testing data.</a></p>

<p>We've also created a new channel in our Discord named <code>oai-analysis</code> and we'd love to hear your analysis and insights there. Or tag us on X/Twitter <a href="https://x.com/arcprize" target="_blank">@arcprize</a>.</p>

<hr>

<h2 id="conclusions">Conclusions</h2>

<p>To sum up – o3 represents a significant leap forward. Its performance on ARC-AGI highlights a genuine breakthrough in adaptability and generalization, in a way that no other benchmark could have made as explicit.</p>

<p>o3 fixes the fundamental limitation of the LLM paradigm – the inability to recombine knowledge at test time – and it does so via a form of LLM-guided natural language program search. This is not just incremental progress; it is new territory, and it demands serious scientific attention.</p>

<p><span></span> <a href="#" data-modal-id="newsletter">Sign up to get updates</a></p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grayjay Desktop App (448 pts)]]></title>
            <link>https://grayjay.app/desktop/</link>
            <guid>42473032</guid>
            <pubDate>Fri, 20 Dec 2024 17:33:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grayjay.app/desktop/">https://grayjay.app/desktop/</a>, See on <a href="https://news.ycombinator.com/item?id=42473032">Hacker News</a></p>
Couldn't get https://grayjay.app/desktop/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why are UK electricity bills so expensive? (179 pts)]]></title>
            <link>https://climate.benjames.io/uk-electricity-bills/</link>
            <guid>42472247</guid>
            <pubDate>Fri, 20 Dec 2024 16:05:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://climate.benjames.io/uk-electricity-bills/">https://climate.benjames.io/uk-electricity-bills/</a>, See on <a href="https://news.ycombinator.com/item?id=42472247">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>I recently built a website that breaks down the cost of a UK electricity bill.</p><figure><a href="https://electricitybills.uk/?ref=climate.benjames.io"><img src="https://climate.benjames.io/content/images/2024/12/image.png" alt="" loading="lazy" width="2000" height="1121" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/image.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/image.png 1000w, https://climate.benjames.io/content/images/size/w1600/2024/12/image.png 1600w, https://climate.benjames.io/content/images/2024/12/image.png 2124w" sizes="(min-width: 720px) 720px"></a><figcaption><a href="http://electricitybills.uk/?ref=climate.benjames.io">electricitybills.uk</a></figcaption></figure><p>It's interactive, and I'd recommend visiting it before reading this post. Check it out here: <a href="http://electricitybills.uk/?ref=climate.benjames.io">electricitybills.uk</a></p><p>Here are three interesting things about the data.</p><h3 id="1-the-wholesale-power-cost-is-only-one-third-of-an-electricity-bill">#1: The wholesale power cost is only one third of an electricity bill.</h3><p>The wholesale price is the actual cost of buying electricity on the open market. But the average bill is <strong>triple</strong> that amount.</p><figure><img src="https://climate.benjames.io/content/images/2024/12/bill_breakdown_full_manual--1-.png" alt="" loading="lazy" width="1204" height="1107" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/bill_breakdown_full_manual--1-.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/bill_breakdown_full_manual--1-.png 1000w, https://climate.benjames.io/content/images/2024/12/bill_breakdown_full_manual--1-.png 1204w" sizes="(min-width: 720px) 720px"></figure><p>The remaining 2/3 of the bill is made up of three parts:</p><ul><li><strong>Network costs:</strong> paying for the wires and substations of the power grid</li><li><strong>Generation costs:</strong> subsidising strategically important generation, like offshore wind, household solar, and firm gas.</li><li><strong>Miscellaneous: </strong>running a utility company customer service department, various taxes, etc.</li></ul><h3 id="2-these-charges-are-about-to-rise-a-lot">#2: These charges are about to rise, a lot.</h3><p><strong>Network costs </strong>are about to skyrocket. Investment in the UK power grid has been stagnant for 20 years, because UK power demand has been flat for 20 years. But now, the UK urgently needs to expand the grid. Energy that used to flow through pipelines will need to flow through wires.</p><p><strong>Contracts for Difference </strong>are the UK's flagship scheme for supporting renewables, and they will add an increasing cost to electricity bills. More than half of the contracts already allocated have yet to be activated, and the next contract allocation round is expected to be the biggest yet.</p><p><em>Note: CfDs do insulate consumers from high wholesale prices (during the energy crisis, CfDs reduced consumer bills), but on average they add cost.</em></p><figure><img src="https://climate.benjames.io/content/images/2024/12/cfd_svg--2-.png" alt="" loading="lazy" width="1087" height="514" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/cfd_svg--2-.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/cfd_svg--2-.png 1000w, https://climate.benjames.io/content/images/2024/12/cfd_svg--2-.png 1087w" sizes="(min-width: 720px) 720px"></figure><p>The <strong>Capacity Market</strong> pays firm generation &amp; demand response to be on standby, to prevent blackouts. Contracts are mostly allocated four years in advance, and the cost will ~<em>triple</em><strong> </strong>to 2028.</p><figure><img src="https://climate.benjames.io/content/images/2024/12/CM-clearing-prices--1-.png" alt="" loading="lazy" width="942" height="427" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/CM-clearing-prices--1-.png 600w, https://climate.benjames.io/content/images/2024/12/CM-clearing-prices--1-.png 942w" sizes="(min-width: 720px) 720px"></figure><h3 id="3-existing-costs-are-locked-in-for-a-long-time">#3: Existing costs are locked in for a long time.</h3><p>The UK ran two pretty expensive green subsidies in the 2010s.</p><p>The <strong>Renewables Obligation</strong> mandates utilities to buy credits from wind and solar farms. It closed to new projects in 2017, but payments to existing projects will continue until 2037. It makes up around 10% of an average bill.</p><div><p>The Renewables Obligation is, in my opinion, wild. Renewable generators who got accredited before 2017 essentially get paid an ever-rising inflation-linked price until 2037, regardless of the market price of electricity.&nbsp;</p></div><p>The <strong>Feed in Tariff</strong> pays households with solar panels a very tasty rate for exported energy. It closed to new applications in 2019, but payments will continue up to 2044 for some projects.</p><p>Being an early adopter of renewables has been expensive for the UK. You might argue that we should have waited an extra decade, since renewables would now be <a href="https://climate.benjames.io/solar-off-grid">much cheaper</a>. But the reality of learning curves means that renewables only got cheap because people built them. If everyone waits for someone else to decarbonise first, we won't get very far.</p><p>But we can learn from policy mistakes in the past. Schemes like the Feed in Tariff did not correct quickly enough when solar prices fell, leading to spiralling policy costs that were completely decoupled from market dynamics.</p><h2 id="the-future-of-cheap-clean-power">The future of cheap, clean power.</h2><p>Let's say that we want electricity to be radically cheap in future - say £50 / MWh.</p><p>Well, network costs are already ~£70 / MWh and will increase steadily. We've missed our target, before we've even paid to generate electricity. There are only two solutions here:</p><ul><li>Ditch the power grid. Use local solar generation, and a lot of batteries. This works well in most of the world, but less so in northern Europe (it's not very sunny).</li><li>Utilise the existing power grid better. Instead of expanding the grid just to service peak demand, improve our grid utilisation by "filling in the rectangle" throughout the day. (This is part of what we're working on at <a href="https://axle.energy/?ref=climate.benjames.io">Axle</a>)</li></ul><p>The UK has achieved the fastest rate of grid decarbonisation among advanced economies. A lot of this progress occurred when renewables were still expensive, so we are stuck with a cost hangover. Luckily, renewables are getting <em>much</em> cheaper, so the tradeoffs in future policy are very different.</p><hr><p>Thanks for reading, I'd love to hear your thoughts on the site. <a href="https://climate.benjames.io/uk-electricity-bills/electricitybills.uk">electricitybills.uk</a></p><p>Warmly,</p><p>Ben</p>
        </div></div>]]></description>
        </item>
    </channel>
</rss>