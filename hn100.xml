<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 11 Aug 2024 11:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Firefox Browser Ported to HaikuOS (116 pts)]]></title>
            <link>https://discuss.haiku-os.org/t/progress-on-porting-firefox/13493?page=7</link>
            <guid>41214762</guid>
            <pubDate>Sun, 11 Aug 2024 08:23:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.haiku-os.org/t/progress-on-porting-firefox/13493?page=7">https://discuss.haiku-os.org/t/progress-on-porting-firefox/13493?page=7</a>, See on <a href="https://news.ycombinator.com/item?id=41214762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Progress on porting Firefox">
      
      <meta itemprop="datePublished" content="2023-05-19T18:35:14Z">
        <meta itemprop="articleSection" content="Development">
      <meta itemprop="keywords" content="">
      

        <meta itemprop="text" content="Hello everyone. 
I am a big fan of Firefox and a long-time watcher of Haiku (and BeOS). 
I love Haiku’s cute UX (inherited and polished from BeOS), so WebPositive looks sweet, but I dreamed also firefox will be available&amp;hellip;">

          <div id="post_133" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-02T15:02:06Z">
                    August 2, 2024,  3:02pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-02T15:02:06Z">
              <span itemprop="position">133</span>
              </span>
            </p></div>
            <p>Amazing! Does it seem more stable than other browsers on haiku?</p>

            

            

          </div>
          <div itemprop="comment" id="post_134" itemscope="" itemtype="http://schema.org/Comment">
              
<p>This is what I call a true BeOS-fan lifestyle. It clearly a work in progress port, but the main question is: it is more stable than what we have right now? <img src="https://discuss.haiku-os.org/images/emoji/twitter/smiley.png?v=12" title=":smiley:" alt=":smiley:" loading="lazy" width="20" height="20"></p>
            </div>
          <div itemprop="comment" id="post_135" itemscope="" itemtype="http://schema.org/Comment">
              <p>Is it wrong to ask about the status? I would just like to know how stable it is.</p>
<p>Seems that the “true BeOS fan lifestyle” is to jump out on people in forums for asking questions? <img src="https://discuss.haiku-os.org/images/emoji/twitter/joy.png?v=12" title=":joy:" alt=":joy:" loading="lazy" width="20" height="20"></p>
            </div>
          <div id="post_136" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/nipos"><span itemprop="name">nipos</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-02T19:31:37Z">
                    August 2, 2024,  7:31pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-02T19:31:37Z">
              <span itemprop="position">136</span>
              </span>
            </p>
            <p>The current status is that no text can be shown due to some rendering issues,so it is not usable at all.<br>
That may now change fast,however,considering the cause is likely something that can be fixed rather easy,now that the rest of this huge monster application seems to be working.</p>

            

            

          </div>
          <div id="post_137" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/Cell"><span itemprop="name">Cell</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-02T20:14:49Z">
                    August 2, 2024,  8:14pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-02T20:14:49Z">
              <span itemprop="position">137</span>
              </span>
            </p>
            <p>X521 did say “somewhat” running. I don’t know if he sent you a personal message or you’re working on it aswell. However, from his given statement I dare to assume that there are other underlying issues aside of the obvious lack of text. I may be wrong but that’s just my theory.</p>

            

            

          </div>
          <div id="post_138" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/humungus"><span itemprop="name">humungus</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-02T21:57:47Z">
                    August 2, 2024,  9:57pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-02T21:57:47Z">
              <span itemprop="position">138</span>
              </span>
            </p>
            <p>what ? people cant ask questions. skjerp deg !</p>

            

            

          </div>
          <div id="post_139" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/X512"><span itemprop="name">X512</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-02T23:39:19Z">
                    August 2, 2024, 11:39pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-02T23:39:19Z">
              <span itemprop="position">139</span>
              </span>
            </p>
            <p>It is currently meaningless to talk about stability before solving Rust problems. New Rust version significantly altered behavior that formally considered undefined and now it trigger failures in various parts. It should be fixed in new Firefox versions. So we need to rebase Haiku patches over new Firefox version that is compatible with new Rust version. Or try to use old Rust version that I think is a bad idea.</p>

            

            

          </div>
          <div id="post_140" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/nipos"><span itemprop="name">nipos</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-03T12:22:28Z">
                    August 3, 2024, 12:22pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-03T16:34:17Z">
              <span itemprop="position">140</span>
              </span>
            </p>
            <div itemprop="text">
              <p>I’m currently trying to patch the latest LibreWolf source archive with the Haiku patches.<br>
I haven’t looked at all patches yet,but those I’ve seen are at places where I don’t think a lot has changed,so that should be rather easy.</p>
<p>Edit: Maybe I was a bit too optimistic with that.<br>
Currently it fails extremely early because it can’t find some Python packages.<br>
I’ll take a break until someone figures out how to fix the Python mess.<br>
Working with Python stuff is always awful,that’s also the point where I failed trying to port Pale Moon some weeks ago.</p>
            </div>

            

            

          </div>
          <div id="post_141" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/mmu_man"><span itemprop="name">mmu_man</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-06T11:26:40Z">
                    August 6, 2024, 11:26am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-06T11:26:40Z">
              <span itemprop="position">141</span>
              </span>
            </p>
            <p>Yay, can remove that from my TODO list \o/ <img src="https://discuss.haiku-os.org/images/emoji/twitter/sweat_smile.png?v=12" title=":sweat_smile:" alt=":sweat_smile:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_142" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/Begasus"><span itemprop="name">Begasus</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-06T17:35:48Z">
                    August 6, 2024,  5:35pm
                  </time>
                  <meta itemprop="dateModified" content="2024-08-06T17:35:48Z">
              <span itemprop="position">142</span>
              </span>
            </p>
            <p>Finaly after about 20 years(?) <img src="https://discuss.haiku-os.org/images/emoji/twitter/stuck_out_tongue.png?v=12" title=":stuck_out_tongue:" alt=":stuck_out_tongue:" loading="lazy" width="20" height="20"> <img src="https://discuss.haiku-os.org/images/emoji/twitter/rofl.png?v=12" title=":rofl:" alt=":rofl:" loading="lazy" width="20" height="20"></p>

            

            

          </div>
          <div id="post_143" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/X512"><span itemprop="name">X512</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2024-08-11T06:33:35Z">
                    August 11, 2024,  6:33am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-11T06:33:35Z">
              <span itemprop="position">143</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Firefox 128:</p>
<div><a href="https://discuss.haiku-os.org/uploads/default/original/2X/0/098a34996ed16051ac906c2ebd5403925d12c3cd.png" data-download-href="https://discuss.haiku-os.org/uploads/default/098a34996ed16051ac906c2ebd5403925d12c3cd" title="screenshot647"><img src="https://discuss.haiku-os.org/uploads/default/optimized/2X/0/098a34996ed16051ac906c2ebd5403925d12c3cd_2_643x500.png" alt="screenshot647" data-base62-sha1="1mooRKxhadwfSaoTeZwFzMDevFz" width="643" height="500" srcset="https://discuss.haiku-os.org/uploads/default/optimized/2X/0/098a34996ed16051ac906c2ebd5403925d12c3cd_2_643x500.png, https://discuss.haiku-os.org/uploads/default/optimized/2X/0/098a34996ed16051ac906c2ebd5403925d12c3cd_2_964x750.png 1.5x, https://discuss.haiku-os.org/uploads/default/optimized/2X/0/098a34996ed16051ac906c2ebd5403925d12c3cd_2_1286x1000.png 2x" data-dominant-color="ECEAE9"></a></div>
<div><a href="https://discuss.haiku-os.org/uploads/default/original/2X/6/65872225661119ee55b9b2f73e1ceb00f2cf9c65.png" data-download-href="https://discuss.haiku-os.org/uploads/default/65872225661119ee55b9b2f73e1ceb00f2cf9c65" title="screenshot648"><img src="https://discuss.haiku-os.org/uploads/default/optimized/2X/6/65872225661119ee55b9b2f73e1ceb00f2cf9c65_2_612x500.png" alt="screenshot648" data-base62-sha1="eu9KhmLThUz9LZesSShIiVW3b9z" width="612" height="500" srcset="https://discuss.haiku-os.org/uploads/default/optimized/2X/6/65872225661119ee55b9b2f73e1ceb00f2cf9c65_2_612x500.png, https://discuss.haiku-os.org/uploads/default/optimized/2X/6/65872225661119ee55b9b2f73e1ceb00f2cf9c65_2_918x750.png 1.5x, https://discuss.haiku-os.org/uploads/default/original/2X/6/65872225661119ee55b9b2f73e1ceb00f2cf9c65.png 2x" data-dominant-color="304143"></a></div>
            </div>

            

            

          </div>
          <div itemprop="comment" id="post_144" itemscope="" itemtype="http://schema.org/Comment">
              <p>How well does it work?<br>
Can it render <a href="http://discuss.haiku-os.org/">discuss.haiku-os.org</a>?</p>
            </div>
          <div id="post_145" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/nipos"><span itemprop="name">nipos</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-11T07:27:28Z">
                    August 11, 2024,  7:27am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-11T07:27:28Z">
              <span itemprop="position">145</span>
              </span>
            </p>
            <div itemprop="text">
              <p>That’s really great news!<br>
Looks like it works perfectly already,I mean at least all screenshots are rendered without issues.<br>
I think I’ll use Haiku <em>a lot</em> more now that this is available.</p>
<p>Reading that “the browser that puts your privacy first” marketing bullshit is a bit funny,however,considering that Mozilla bought an advertising network recently and feeds your browser data to it lol<br>
It’s time to get my hands dirty on porting <a href="https://librewolf.net/">LibreWolf</a> again.</p>
            </div>

            

            

          </div>
          <div id="post_146" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/Cell"><span itemprop="name">Cell</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-11T08:45:28Z">
                    August 11, 2024,  8:45am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-11T08:50:48Z">
              <span itemprop="position">146</span>
              </span>
            </p>
            <p>Finally, a browser that cloudflare doesn’t ruin (I hate cloudflare so much it has no reason to be this annoying.) are there any issues that have to be resolved for it to be called “finished”. Asking since it seems complete based on these screenshots. Aside from the fact that everything is in a serif font.</p>

            

            

          </div>
          <div id="post_147" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/ninos"><span itemprop="name">ninos</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-11T09:00:22Z">
                    August 11, 2024,  9:00am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-11T09:00:22Z">
              <span itemprop="position">147</span>
              </span>
            </p>
            <p>how can I install firefox on my Haiku laptop?</p>

            

            

          </div>
          <div id="post_148" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://discuss.haiku-os.org/u/nipos"><span itemprop="name">nipos</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-08-11T09:03:25Z">
                    August 11, 2024,  9:03am
                  </time>
                  <meta itemprop="dateModified" content="2024-08-11T09:03:25Z">
              <span itemprop="position">148</span>
              </span>
            </p>
            

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenStreetMap Is Turning 20 (196 pts)]]></title>
            <link>https://stevecoast.substack.com/p/the-days-are-long-but-the-years-are</link>
            <guid>41214259</guid>
            <pubDate>Sun, 11 Aug 2024 06:00:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevecoast.substack.com/p/the-days-are-long-but-the-years-are">https://stevecoast.substack.com/p/the-days-are-long-but-the-years-are</a>, See on <a href="https://news.ycombinator.com/item?id=41214259">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Two decades ago, I knew that a wiki map of the world would work. It seemed obvious in light of the success of Wikipedia and Linux. But I didn't know that </span><a href="https://www.openstreetmap.org/" rel="">OpenStreetMap</a><span> would work until much later.</span></p><p>I was showing someone new to OSM how to add data to the map. I would ask for a place they knew well, zoom in to that area and then find something to fix. The key was to get a quick win by showing the map before and after they had made it better. Get a little shot of dopamine for making the world a slightly better place.</p><p>This person asked to look at Cuba.</p><p>This presented a challenge, and I had to manage expectations. OpenStreetMap at the time had okay maps of major Western countries but my expectation, as I explained to them, was that Cuba would be a blank empty slate.</p><p>Cuba was doubly tricky not just because of economic factors that limit peoples free time and ability to contribute to open projects, but also the internet was (effectively if not actually) banned and computers illegal.</p><p>Zooming in to Cuba that day was the last time I was surprised by OSM, and when I stopped worrying about it working as a project: Cuba had roads, parks, hospitals and everything else imaginable already mapped.</p><p>…</p><p>OpenStreetMap has grown exponentially or quadratically over the last twenty years depending on the metric you’re interested in. My involvement has waxed and waned like soul mates oscillating between rapture and, inevitably, wanting the best for each other in our post-relationship new lives.</p><p>The story isn’t so much about the data and technology, and it never was. It’s the people.</p><p>Like John Boyd said, it’s the people then the ideas and then the technology. Not the other way around.</p><p>People: The people that wanted to map just weren’t in the existing camps by definition. They largely didn’t work in geography at all. They just wanted a way to make a map better. Governments, universities and companies had lists of reasons why public mapping wasn’t possible, but no actual solution.</p><p>Ideas: Allowing volunteers to edit a map in 2004 was simply anathema and bordering on unthinkable. Map data was supposed to be controlled, authorized and carefully managed by a priesthood of managers.</p><p>Technology: For those not in the industry, you might not know that OSM essentially did the opposite of what academic and the leading technology platforms at the time advocated. It needed a data model designed for volunteers not paid editors. So, we did tags not ontologies, and nodes and ways, not web feature service.</p><blockquote><p>I do not know what I may appear to the world, but to myself I seem to have been only like a boy playing on the seashore, and diverting myself in now and then finding a smoother pebble or a prettier shell than ordinary, whilst the great ocean of truth lay all undiscovered before me. - Newton</p></blockquote><p>OpenStreetMap managed to map the world and give the data away for free for almost no money at all. It managed to sidestep almost all the problems that Wikipedia has by virtue of only representing facts not opinions.</p><p>The project itself is remarkable. And it’s wonderful that so many are in love with it.</p><p>…</p><p>For me though, I’m far more fascinated with what are the other pebbles on the beach. What else can we make for almost no money that will radically change the world for the better?</p><p>If OpenStreetMap is a medium, what is the message?</p><p>For me it’s that we can go from nothing to something, or zero to one. Many of us love critiquing something that exists or maybe even improving it. But, my boyish naiveté was assuming that there were lots of other people out there also trying to build new things. Tautologically this simply can’t be true, for if everyone was making new things for any period of time we’d be much further along the various technological curves.</p><p>What stops us from doing new things? There seems to be a million reasons and two opposing forces keeping us in inaction: fear and vanity.</p><p><span>Fear of </span><em>actually</em><span> building something and showing it to people will push you from one side, and vainly falling in love with the idea itself will pull you the other way. These forces will perfectly balance like the tides. You’ll be stuck in the gravity well of some dead Lagrange point neither executing on the idea nor killing it.</span></p><p>Not everyone has ideas, but if you do, I encourage you to go do the thing.</p><p>When you do the thing, most likely you’ll have to kill it. New things tend to not work, or you have to change them drastically. OpenStreetMap’s first 4 or so major versions were all radically different from each other and relied on feedback from the world to make it something that would work.</p><p>Killing all the new things means you have to try many of them. This too is reflected in OSM, where I actually started about ten ideas at the time. OSM took off. One was taken over. The rest were strangled to death by reality meeting vanity.</p><p>…</p><p>So, celebrate all that we have achieved. It’s been amazing.</p><p>And then please turn the wheel and look to windward and consider how to kill it, by making something new or better.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Gervais Principle, or the Office According to "The Office" (2009) (111 pts)]]></title>
            <link>https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-or-the-office-according-to-the-office/</link>
            <guid>41214180</guid>
            <pubDate>Sun, 11 Aug 2024 05:35:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-or-the-office-according-to-the-office/">https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-or-the-office-according-to-the-office/</a>, See on <a href="https://news.ycombinator.com/item?id=41214180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>My neighbor introduced me to <em>The Office </em>back in 2005. Since then, I’ve watched every episode of both the British and American versions. I’ve watched the show obsessively because I’ve been unable to figure out what makes it so devastatingly effective, and elevates it so far above the likes of <a href="http://dilbert.com/">Dilbert</a> and <a href="http://en.wikipedia.org/wiki/Office_Space">Office Space</a>.</p>

<p>Until now, that is. Now, after four years, I’ve finally figured the show out.&nbsp; <em>The Office </em>is not a random series of cynical gags aimed at momentarily alleviating the existential despair of low-level grunts. It is a fully realized theory of management that falsifies 83.8% of the business section of the bookstore.&nbsp; The theory begins with Hugh MacLeod’s well-known cartoon, <a href="http://gapingvoid.com/2004/06/27/company-hierarchy/"><em>Company Hierarchy</em></a> (below), and its cornerstone is something I will call The Gervais Principle, which supersedes both the Peter Principle and its successor, The Dilbert Principle. Outside of the comic aisle, the only major and significant works consistent with the Gervais Principle are <em><a href="http://www.amazon.com/gp/product/0812218191?ie=UTF8&amp;tag=ribbonfarmcom-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0812218191">The Organization Man</a> </em>and <em><a href="http://www.amazon.com/gp/product/1412939798?ie=UTF8&amp;tag=ribbonfarmcom-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1412939798">Images of Organization</a>.</em></p>
<p><a href="http://gapingvoid.com/2004/06/27/company-hierarchy/"><img decoding="async" title="hughMcLeodCompanyHierarchy" alt="hughMcLeodCompanyHierarchy" src="https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/hughMcLeodCompanyHierarchy.jpg" width="400" height="218"></a></p>
<p><strong><span id="more-1289"></span></strong>I’ll need to lay just a <em>little </em>bit of groundwork (lest you think this whole post is a riff based on cartoons) before I can get to the principle and my interpretation of <em>The Office. </em>I’ll be basing this entire article on the American version of the show, which is more fully developed than the original British version, though the original is perhaps more satisfyingly bleak. Keep in mind that this is an interpretation of <em>The Office</em> as management science; the truth in the art.&nbsp; Literary/artistic critics don’t really seem to get it.&nbsp;I’ll have some passing comments to offer on the comedy and art of it all, but this is primarily about the truths revealed by the show, pursued with Dwight-like earnestness.</p>
<p><strong>From The Whyte School to The Gervais Principle<br>
</strong></p>
<p>Hugh MacLeod’s cartoon is a pitch-perfect symbol of an unorthodox school of management&nbsp; based on the axiom that organizations don’t suffer pathologies; they are intrinsically pathological constructs.&nbsp; Idealized organizations are not perfect. They are perfectly pathological.&nbsp; So while most most management literature is about striving relentlessly towards an ideal by executing organization theories completely, this school, which I’ll call the Whyte school, would recommend that you do the bare minimum organizing to prevent chaos, and then stop. Let a natural, if declawed, individualist Darwinism operate beyond that point. The result is the MacLeod hierarchy. It may be horrible, but like democracy, it is the best you can do.</p>
<p><a href="http://www.amazon.com/gp/product/B00F9IV64W/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B00F9IV64W&amp;linkCode=as2&amp;tag=ribbonfarmcom-20"><img decoding="async" alt="gpbanner" src="https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/gpbanner.png" width="351" height="74" srcset="https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/gpbanner.png 351w, https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/gpbanner-300x63.png 300w" sizes="(max-width: 351px) 100vw, 351px"></a></p>
<p>The Sociopath (capitalized) layer comprises the Darwinian/Protestant Ethic will-to-power types who drive an organization to function despite itself. The Clueless layer is what Whyte called the “Organization Man,” but the archetype inhabiting the middle has evolved a good deal since Whyte wrote his book (in the fifties).&nbsp; The Losers&nbsp; are not social losers (as in the opposite of “cool”), but people who have struck bad bargains economically – giving up capitalist striving for steady paychecks. I am not making this connection up. Consider this passage from OM:</p>
<p>Of all organization men, the true executive is the one who remains most suspicious of The Organization. If there is one thing that characterizes him, it is a fierce desire to control his own destiny and, deep down, he resents yielding that control to The Organization, no matter how velvety its grip… he wants to dominate, not be dominated…Many people from the great reaches of middle management can become true believers in The Organization…But the most able are not vouchsafed this solace.</p>
<p>Back then, Whyte was extremely pessimistic. He saw signs that in the struggle for dominance between the Sociopaths (whom he admired as the ones actually making the organization effective despite itself) and the middle-management Organization Man, the latter was winning. He was wrong, but not in the way you’d think. The Sociopaths defeated the Organization Men and turned them into The Clueless not by reforming the organization, but by creating a meta-culture of Darwinism in the economy: one based on job-hopping, mergers, acquisitions, layoffs, cataclysmic reorganizations, outsourcing, unforgiving start-up ecosystems, and brutal corporate raiding. In this terrifying meta-world of the Titans, the Organization Man became the Clueless Man. Today, any time an organization grows too brittle, bureaucratic and disconnected from reality, it is simply killed, torn apart and cannibalized, rather than reformed. The result is the modern creative-destructive life cycle of the firm, which I’ll call the <em>MacLeod Life Cycle.<br>
</em></p>
<p><em><img loading="lazy" decoding="async" title="compLifeCycle" alt="compLifeCycle" src="https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/compLifeCycle.JPG" width="366" height="427" srcset="https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/compLifeCycle.JPG 366w, https://ribbonfarm.wpenginepowered.com/wp-content/uploads/2009/10/compLifeCycle-257x300.jpg 257w" sizes="(max-width: 366px) 100vw, 366px"><br>
</em></p>
<p>A Sociopath with an idea recruits just enough Losers to kick off the cycle. As it grows it requires a Clueless layer to turn it into a controlled reaction rather than a runaway explosion. Eventually, as value hits diminishing returns, both the Sociopaths and Losers make their exits, and the Clueless start to dominate. Finally, the hollow brittle shell collapses on itself and anything of value is recycled by the sociopaths according to meta-firm logic.</p>
<p>MacLeod’s Loser layer had me puzzled for a long time, because I was interpreting it in cultural terms: the kind of person you call a “loser.” While some may be losers in that sense too, they are primarily losers in the economic sense: those who have, for various reasons, made (or been forced to make) a bad economic bargain. They’ve given up some potential for long-term economic liberty (as capitalists) for short-term economic stability. Traded freedom for a paycheck in short. They actually produce, but are not compensated in proportion to the value they create (since their compensation is set by Sociopaths operating under conditions of serious <a href="http://en.wikipedia.org/wiki/Moral_hazard">moral hazard</a>). They mortgage their lives away, and hope to die before their money runs out. The good news is that Losers have two ways out, which we’ll get to later: turning Sociopath or turning into bare-minimum performers. The Losers destined for cluelessness do not have a choice.</p>
<p>Based on the MacLeod lifecycle, we can also separate the three layers based on the timing of their entry and exit into organizations. The Sociopaths enter and exit organizations at will, at any stage, and do whatever it takes to come out on top. The contribute creativity in early stages of a organization’s life, neurotic leadership in the middle stages, and cold-bloodedness in the later stages,&nbsp; where they drive decisions like mergers, acquisitions and layoffs that others are too scared or too compassionate to drive. They are also the ones capable of equally impersonally exploiting a young idea for growth in the beginning, killing one good idea to concentrate resources on another at maturity, and milking an end-of-life&nbsp; idea through harvest-and-exit market strategies.</p>
<p>The Losers like to feel good about their lives. They are the happiness seekers, rather than will-to-power players, and enter and exit reactively, in response to the meta-Darwinian trends in the economy. But they have no more loyalty to the firm than the Sociopaths. They <em>do </em>have a loyalty to individual people, and a commitment to finding fulfillment through work when they can, and coasting when they cannot.</p>
<p>The Clueless are the ones who lack the competence to circulate freely through the economy (unlike Sociopaths and Losers), and build up a perverse sense of loyalty to the firm, even when events make it abundantly clear that the firm is not loyal to them. To sustain themselves, they must be capable of fashioning elaborate delusions based on idealized notions of the firm — the perfectly pathological entities we mentioned. Unless squeezed out by forces they cannot resist, they hang on as long as possible, long after both Sociopaths and Losers have left (in Douglas Adams’ vicious history of our planet, humanity was founded by a spaceship full of the Clueless, sent here by scheming Sociopaths). When cast adrift in the open ocean, they are the ones most likely to be utterly destroyed.</p>
<p>Which brings us to our main idea. How both the pyramid and its lifecycle are animated. The dynamics are governed by the Newton’s Law of organizations: the Gervais Principle.</p>
<p><strong>The Gervais Principle and Its Consequences</strong></p>
<p>The Gervais Principle is this:</p>
<p>Sociopaths, in their own best interests, knowingly promote over-performing losers into middle-management, groom under-performing losers into sociopaths, and leave the average bare-minimum-effort losers to fend for themselves.</p>
<p>The Gervais principle differs from the Peter Principle, which it superficially resembles. The Peter Principle states that <em>all </em>people are promoted to the level of their incompetence. It is based on the assumption that future promotions are based on past performance. The Peter Principle is wrong for the simple reason that executives aren’t that stupid, and because there isn’t that much room in an upward-narrowing pyramid. They know what it takes for a promotion candidate to perform at the <em>to</em> level. So if they are promoting people beyond their competence anyway, under conditions of opportunity scarcity, there must be a good reason.</p>
<p>Scott Adams, seeing a different flaw in the Peter Principle, proposed the Dilbert Principle: that companies tend to systematically promote their least-competent employees to middle management to limit the damage they can do. This again is untrue. The Gervais principle predicts the exact opposite: that the <em>most </em>competent ones will be promoted to middle management. Michael Scott was a star salesman before he become a Clueless middle manager. The least competent employees (but not <em>all </em>of them — only certain enlightened incompetents) will be promoted not to middle management, but fast-tracked through to <em>senior </em>management. To the Sociopath level.</p>
<p>And in case you are wondering, the unenlightened under-performers get fired.</p>
<p>Let me illustrate the logic and implications of the principle with examples from the show.</p>
<p><span><em>The Career of the Clueless</em></span></p>
<p>In Season Three, the Dunder-Mifflin executives decide to merge the Stamford and Scranton branches, laying off much of the latter, including Michael Scott.&nbsp; His counterpart, the Sociopath Stamford branch manager, whose promotion is the premise of the re-org, opportunistically leverages his impending promotion into an executive position at a competitor, leaving the c0mpany in disarray. The Dunder-Mifflin executives, forced to deal with the fallout, cynically play out the now-illogical re-org anyway, shutting down Stamford and leaving Michael with the merged branch instead. The executives (David Wallace and Jan Levinson-Gould) are completely aware of Michael’s utter incompetence. Their calculations are obvious:&nbsp; giving Michael the expanded branch allows them to claim short-term success and buy time to maneuver out of having to personally suffer longer-term consequences.</p>
<p>Jim’s remark on the drama is revealing. Comparing Michael to his exiting sociopath peer he says: “Whatever you say about Michael, he would never have done something like this,” a testament to Michael’s determinedly deluded loyalty to the company that will never be loyal to him.&nbsp; We can safely assume that Michael’s previous promotion to regional manager occurred under similar circumstances of callous short-term calculations by sociopaths.</p>
<p>So why is promoting over-performing Losers logical? The simple reason is that if you over-perform at the Loser level, it is clear that you are an idiot. You’ve already made a bad bargain, and now you’re delivering more value than you need to, making your bargain even worse.&nbsp; Unless you very quickly demonstrate that you know your own value by successfully negotiating more money and/or power, you are marked out as an exploitable <em>clueless</em>&nbsp;Loser. At one point, Darryl, angling for a raise, learns to his astonishment that the raise he is asking for would make his salary higher than Michael’s. Michael hasn’t negotiated a better deal in 14 years. Darryl — a minimum-effort Loser with strains of Sociopath — doesn’t miss a step. He convinces and coaches Michael into asking for his own raise, so he can get his.</p>
<p>A Loser who can be suckered into bad bargains is set to become one of the Clueless. That’s why they are promoted: they are worth even more as Clueless pawns in the middle than as direct producers at the bottom, where the average, rationally-disengaged Loser will do. At the bottom, the overperformers can merely add a predictable amount of value. In the middle they can be used by the Sociopaths to escape the consequences of high-risk machinations like re-orgs.</p>
<p><span><em>The Career of the Sociopath</em></span></p>
<p>The example of the “fast-track the under-performing” part of the principle is Ryan, the intern. He tests himself quickly and rapidly learns and accepts that he is incompetent as a salesman. But he is a born pragmatist with the drive, ambition, daring and lack of principles to make it to the top.&nbsp; So rather than waste time trying to get good at sales, he slips into a wait-watch-grab opportunist mode. But he isn’t checked out; he is engaged, but in an experimental way, probing for his opening. The difference between him and the average checked-out Loser is illustrated in one brilliant scene early in his career. He suggests, during a group stacking effort in the warehouse, that they form a bucket brigade to work more efficiently. The minimum-effort Loser Stanley tells him coldly, “this here is a run-out-the-clock situation.” The line could apply to Stanley’s entire life.</p>
<p>Stanley’s response shows both his intelligence and clear-eyed self-awareness of his Loser bargain with the company. He therefore acts according to a mix of self-preservation and minimum-effort coasting instincts. The same is true of everybody else in the Loser layer with the exception of the over-performers: Dwight and Andy (and in his earlier incarnation as a salesperson, Michael).</p>
<p>The future Sociopath <em>must</em> be an under-performer at the bottom. Like the average Loser, he recognizes that the bargain is a really bad one. Unlike the risk-averse loser though, he does not try to make the best of a bad situation by doing enough to get by. He has no intention of just getting by. He very quickly figures out — through experiments and fast failures — that the Loser game is not worth becoming good at. He then severely under-performs in order to free up energy to concentrate on maneuvering an upward exit.&nbsp; He knows his under-performance is not sustainable, but he has no intention of becoming a lifetime-Loser employee anyway. He takes the calculated risk that he’ll find a way up before he is fired for incompetence.</p>
<p>Ryan’s character displays this path brilliantly. When Michael’s boss and dominatrix-lover Jan suffers a psychotic meltdown, <em>her </em>boss, the uber-sociopath David Wallace, has no great hopes of a good outcome. Setting up yet another band-aid move, he calls up Michael for an interview to take up Jan’s spot. But when the rest of the office learns of Michael’s impending interview (during Michael’s farcical attempts at using a <em>Survivor </em>style contest to choose his successor, which predictably, only Dwight takes seriously), the true Sociopaths act. Jim and his Sociopath girlfriend Karen instantly call up David and announce their candidacies for the same position. Unknown to them, Ryan, the intern-turned-rookie, has also spotted the opportunity. The outcome is spectacular: Ryan gets the job, Michael loses, Karen is promoted to manager of the Utica branch, and Jim — who still has not yet completely embraced his inner Sociopath — returns to Scranton.&nbsp; We learn later — as the Gervais principle would predict — that David Wallace never seriously considered Michael more than a temporary last resort. Much later, in a deposition during Jan’s lawsuit against the company, he reveals that Michael was never a serious candidate.</p>
<p><span><em>The Career of the Loser</em></span></p>
<p>The career of the Loser is the easiest to understand. Having made a bad bargain, and not marked for either Clueless or Sociopath trajectories, he or she must make the best of a bad situation.&nbsp; The most rational thing to do is slack off and do the minimum necessary. Doing more would be a Clueless thing to do. Doing less would take the high-energy machinations of the Sociopath, since it sets up self-imposed up-or-out time pressure. So the Loser — really not a loser at all if you think about it — pays his dues, does not ask for much, and finds meaning in his life elsewhere. For Stanley it is crossword puzzles. For Angela it is a colorless Martha-Stewartish religious life. For Kevin, it is his rock band. For Kelly, it is mindless airhead pop-culture distractions. Pam has her painting ambitions. Meredith is an alcoholic slut. Oscar, the ironic-token gay character, has his intellectual posturing. Creed, a walking freak-show, marches to the beat of his own obscure different drum (he is the most rationally checked-out of all the losers).</p>
<p>If you leave out the clear marked-for-Clueless characters, Dwight and Andy, you are left with the two most interesting characters in the show: the will-he-won’t-he Sociopath-in-the-making, Jim, and the strange Toby. Toby is a curious case — intellectually a Sociopath, but without the energy or ambition to be an <em>active </em>sociopath. More about these two later.</p>
<p><span><em>The Emergence of the MacLeod Hierarchy</em></span></p>
<p>Dastardly as all this sounds, it is actually pretty efficient, given the inevitability of the MacLeod hierarchy and life cycle. The Sociopaths know that the only way to make an organization capable of survival is to buffer the intense chemistry between the producer-Losers and the leader-Sociopaths with enough Clueless padding in the middle to mitigate the risks of business. Without it, the company would explode like a nuclear bomb, rather than generate power steadily like a reactor. On the other hand, the business wouldn’t survive very long without enough people actually thinking in cold, calculating ways. The average-performing , mostly-disengaged Losers&nbsp; can create diminishing-margins profitability, but not sustainable performance or growth.&nbsp; You need a steady supply of Sociopaths for that, and you cannot waste time moving them slowly up the ranks, especially since the standard promotion/development path is primarily designed to maneuver the Clueless into position wherever they are needed. The Sociopaths must be freed up as much as possible to actually run the business, with or without official titles.</p>
<p>So Ryan floats directly to the top, where he does what is expected of him — lead a bold strategic gamble by building an online sales channel operation. As with any big strategic move, the operation has its risks, and fails. And here we find that Ryan is still not quite experienced enough as a sociopath. He foolishly goes the Enron route,&nbsp; attempting to cook the books to avoid failure, and is found out and arrested. A true master Sociopath like David Wallace would instead have spotted the impending failure, promoted a Michael to take over (who would obviously be so gratified at being given a new white-elephant title that he would not have seen disaster looming), and have him take the blame for the inevitable failure. Completely legal and efficient.</p>
<p><strong>The Organization as Psychic Prison</strong></p>
<p>Which brings us to the other major management book that is consistent with the Gervais Principle,&nbsp;<em><a href="https://www.ribbonfarm.com/2010/07/13/the-eight-metaphors-of-organization/">Images of Organization</a>, </em>Gareth Morgan’s magisterial study of the metaphors through which we understand organizations. Of the eight systemic metaphors in the book, the one that is most relevant here is the metaphor of an organization as a psychic prison. The image is derived from Plato’s <a href="http://en.wikipedia.org/wiki/Allegory_of_the_cave">allegory of the cave</a>, which I won’t get into here. Suffice it to say that it divides people into those who get how the world really works (the Sociopaths and the self-aware slacker Losers) and those who don’t (the over-performer Losers and the Clueless in the middle).</p>
<p>This is where Gervais has broken new ground, primarily because as an artist, he is interested in the subjective experience of being Clueless (most sitcoms are about Losers). For your everyday Sociopath, it is sufficient to label someone clueless and manipulate them. What Gervais managed to create is a very compelling portrait of the Clueless, a work of art with real business value.</p>
<p>Here is the ultimate explanation of Michael Scott’s (and David Brent’s) careers: they are put into a position of having to explain their own apparent, unexpected and unexamined <em>success. </em>It is easy to explain failure. Random success is harder. Remember, they are promoted primarily as passive pawns to either allow the Sociopaths to escape the risks of their actions, or to make way for the Sociopaths to move up faster. They are presented with an interesting bit of cognitive dissonance: being nominally given greater power, but in reality being safely shunted away from the pathways of power. They must choose to either construct false narratives or decline apparent opportunities.</p>
<p>The Clueless resolve this dissonance by choosing to believe in the reality of the organization. Not everybody is capable of this level of suspension of disbelief. Both Ricky Gervais (David Brent) and Steve Carrel (Michael Scott) play the brilliantly drawn characters perfectly. The most visible sign of their capacity for self-delusion is their complete inability to generate an original thought. They quote movie lines, lyrics and perform terrible impersonations (at one point Michael goes, “You talking to me?” a line he attributes, in a masterful display of confusion, to “Al Pacino, <em>Raging Bull</em>“). For much of what he needs to say, he gropes for empty business phrases, deploying them with staggering incompetence. When Michael talks, he is attempting, like a child, to copy the flawless Powertalk spoken by sociopaths like Jan and David Wallace. He is oblivious to the fact that the Sociopaths use Powertalk as a coded language with which to simultaneously sustain the (necessary) delusions of the Clueless and communicate with each other.</p>
<p>It is not just the Sociopaths who conspire to sustain Michael’s delusions. So do the checked-out Losers, sometimes out of kindness, and sometimes out of self-interest. In one particularly perfect summing up, Oscar describes the impending “Dundies” award ceremony (a veritable monument to the consensual enablement of Michael’s delusions) as “The Dundies are kind of like a kid’s birthday party. And you go, and there’s really nothing for you to do there, but the kid’s having a really good time, so you… You’re kind of there. That’s… That’s kind of what it’s like.”</p>
<p>But Michael isn’t entirely a puppet. Buried under layers of denial is a clear understanding of his own, hopeless, powerless life, which makes him marginally more clued-in than say, Dwight. His response is&nbsp; frenetic and desperate manipulation of the drama of false validation that has been set up for his benefit.&nbsp; Some of this is with the knowing consent of his enablers.&nbsp; Like experienced improv-comics, within limits, the rest of the office follows the rule of agreement in the Theater of Michael (in a brilliant piece of meta-commentary, in one episode we get to see Michael at his own impossibly bad worst in his <em>real </em>improv class, where he ruins every single sketch).</p>
<p>But Michael’s grand narrative requires constant, exhausting work to keep up. He must amplify and rope in even the most minor piece of validation into the service of his script. When, in a moment of weakness, Jim shares a genuine confidence with him, Michael is so thrilled that he turns the moment into a deep imaginary friendship, practically becoming a stalker, even mimicking Jim’s hairstyle.&nbsp; At the other end, he over-represses even the slightest potential dent to his self-image. His is a thin-skinnedness gone crazy. Reality is sealed away with&nbsp; psychotic urgency, but to do so, he must first scout it out with equal urgency. And so, when Jim (in the first true Sociopath move of his career) engineers a private meeting with the visiting David Wallace to carve out a promotion, Michael tries to crash the meeting. When politely turned away, he instantly switches scripts and pretends he is too busy and that <em>he </em>is the one who can’t attend. And then he sneaks into the meeting room anyway, first with various excuses, and finally by hiding in a Trojan-Horse cheese cart.</p>
<p>This sort of ability to work hard to sustain the theater of his own delusions, half-aware that he is doing so, is what makes Michael a genuine candidate for promotion to the ranks of the Clueless. Dwight is interesting precisely because he lacks Michael’s capacity for this pathological meta-cognition, and the ability to offer semi-believable scripts that others can at least help bolster. Dwight is not talented enough at Cluelessness to ever be promoted.</p>
<p><strong>Is There More?</strong></p>
<p>You bet. We haven’t even scratched the surface. Dwight, Jim, and Toby each deserve an entire essay. Michael and Ryan probably deserve one each as well, in addition to my quick sketches here. And there are other principles, lemmas and sundry theoretical constructs. But I’ll hold off. Maybe there aren’t as many <em>Office </em>watchers among this blog’s readers as I imagine.&nbsp; You guys tell me if you want more.</p>
<p>I’ll conclude with one thought: Gervais deserves Nobel prizes in both literature and economics.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rust GUI Library via Flutter (156 pts)]]></title>
            <link>https://cjycode.com/posts/rust-ui-flutter/</link>
            <guid>41213711</guid>
            <pubDate>Sun, 11 Aug 2024 02:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cjycode.com/posts/rust-ui-flutter/">https://cjycode.com/posts/rust-ui-flutter/</a>, See on <a href="https://news.ycombinator.com/item?id=41213711">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><div><picture><source srcset="https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_330x0_resize_q75_h2_box_3.webp 330w,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_660x0_resize_q75_h2_box_3.webp 660w
,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_1024x0_resize_q75_h2_box_3.webp 1024w
,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_1320x0_resize_q75_h2_box_3.webp 1320w" sizes="100vw" type="image/webp"><img width="3000" height="1000" src="https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_660x0_resize_box_3.png" srcset="https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_330x0_resize_box_3.png 330w,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_660x0_resize_box_3.png 660w
,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_1024x0_resize_box_3.png 1024w
,https://cjycode.com/posts/rust-ui-flutter/logo_hua61a7cb5dd2716f4970132bdcd3ffb5e_118466_1320x0_resize_box_3.png 1320w" sizes="100vw"></picture></div></header><div><h2 id="background">Background <span><a href="#background" aria-label="Anchor">#</a></span></h2><p>Rust has been “the most desired programming language” for 8 years (by StackOverflow and GitHub <a href="https://github.blog/2023-08-30-why-rust-is-the-most-admired-language-among-developers/" target="_blank" rel="noreferrer">1</a> <a href="https://survey.stackoverflow.co/2023/#section-admired-and-desired-programming-scripting-and-markup-languages" target="_blank" rel="noreferrer">2</a>), and many people want to write programs with a GUI in Rust.</p><p>Therefore, in this blog, I will share an approach by utilizing Flutter and the <a href="https://github.com/fzyzcjy/flutter_rust_bridge" target="_blank" rel="noreferrer">https://github.com/fzyzcjy/flutter_rust_bridge</a> I made.</p><p>To have a try, please visit the GitHub repo or the demo folder at the end of this article.</p><h2 id="pros-of-the-approach">Pros of the approach <span><a href="#pros-of-the-approach" aria-label="Anchor">#</a></span></h2><p>Firstly, Flutter is popular and mature. It is “the most popular cross-platform mobile SDK” (by StackOverflow <a href="https://stackoverflow.blog/2022/02/21/why-flutter-is-the-most-popular-cross-platform-mobile-sdk/" target="_blank" rel="noreferrer">1</a> <a href="https://survey.stackoverflow.co/2023/#technology-most-popular-technologies" target="_blank" rel="noreferrer">2</a>). In addition, many developers and well-known brands (e.g. see <a href="https://flutter.dev/showcase" target="_blank" rel="noreferrer">this long list</a>) are using it. It is a lot of work to make an engine feature-rich and mature like that.</p><p>Secondly, it also has a large ecosystem, making it easy to implement what we want. For example, even if we want to add some beautiful confetti 🎉 animations, there exists a package for us. Let alone other beautiful widgets and functionalities, and its intrinsic flexibility to control every pixel.</p><p>The “hot-reload” feature makes developing UI much faster, since it happens frequently to tweak the UI. When changing code, as is shown in the gif below, the updated UI can be seen almost instantly, without losing state or wait for a recompilation.</p><p>Flutter is also cross-platform. The same codebase can not only be run on Android and iOS, but also on Linux, MacOS, Windows and Web.</p><video controls="" preload="auto" width="100%" autoplay="" muted="" playsinline="">
<source src="https://cjycode.com/posts/rust-ui-flutter/confetti.mp4" type="video/mp4"><span>Your browser doesn't support embedded videos, but don't worry, you can <a href="https://cjycode.com/posts/rust-ui-flutter/confetti.mp4">download it</a> and watch it with your favorite video player!</span></video><p>Hot-reload to add a confetti to UI</p><h2 id="cons-of-the-approach">Cons of the approach <span><a href="#cons-of-the-approach" aria-label="Anchor">#</a></span></h2><p>Firstly, this approach is not 100% pure Rust (e.g. Rust state/logic, Flutter UI). However, this seems in analogy to many other Rust UIs - write a custom DSL using macros, or another language like HTML/CSS/Slint. Such split also follows separation-of-concerns and is adopted (e.g. <a href="https://michel.codes/blogs/ui-as-an-afterthought" target="_blank" rel="noreferrer">link</a>). In addition, Flutter is easy to learn, especially if understanding Rust.</p><p>Secondly, honestly speaking, I heard some criticism about web platform. It seems more suitable for “apps” on web and other platforms (real-world e.g. Google Earth, Rive’s animation editor, …) than static webpages.</p><p>Last but not least, Flutter has a bunch of boilerplate/scaffold code. My humble understanding is that, for small projects, those files are usually not changed, thus similar to not existing. For large projects, modifiability is indeed customizability.</p><h2 id="whats-flutter_rust_bridge">What’s flutter_rust_bridge? <span><a href="#whats-flutter_rust_bridge" aria-label="Anchor">#</a></span></h2><p>The goal is to make a bridge between the two, seamlessly as if working in one single language. It translates many things automatically, such as arbitrary types,<code>&amp;mut</code>, async, traits, results, closure (callback), lifetimes, etc.</p><p>Therefore, it is quite general-purpose, and “Rust GUI via Flutter” is just one of the many scenarios. Other typical usages include using arbitrary Rust libraries for Flutter, and writing code such as algorithms in Rust while others in Flutter.</p><h2 id="example-a-counter-app">Example: A counter app <span><a href="#example-a-counter-app" aria-label="Anchor">#</a></span></h2><p>Here, I demonstrate <em>one</em> of the many possible ways to integrate Rust with Flutter. Since flutter_rust_bridge is unopinionated and general-purpose, there can be many other approaches, such as a Redux-like or Elm-like one.</p><p><code>flutter_rust_bridge</code> supports quite rich Rust syntax, such as arbitrary types, results, traits, async, streams, etc. But let us keep it simple and define Rust state and logic as:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[frb(ui_state)]</span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>RustState</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>count</span>: <span>i32</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>RustState</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>	</span><span>pub</span><span> </span><span>fn</span> <span>new</span><span>()</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>		</span><span>Self</span><span> </span><span>{</span><span> </span><span>count</span>: <span>100</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>	</span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>	</span><span>#[frb(ui_mutation)]</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>increment</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>	    </span><span>self</span><span>.</span><span>count</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// Indeed flutter_rust_bridge can support something complex such as:
</span></span></span><span><span><span>// impl MyTrait for MyType {
</span></span></span><span><span><span>//     pub fn f(&amp;self, callback: impl Fn(String) -&gt; FancyEnum,
</span></span></span><span><span><span>//              stream: StreamSink&lt;Whatever&gt;) -&gt; Result&lt;(FancyStruct, Hello)&gt; { .. }
</span></span></span><span><span><span>// }
</span></span></span></code></pre></div><p>Remark: The <code>#[frb(ui_state)]</code> and <code>#[frb(ui_mutation)]</code> are very lightweight (only a dozen line of code), and there is no magic hidden.</p><p>Then, the UI is like the following. Flutter is declarative, thus we can naturally translate the sentence “a column with padding, containing a text showing current count, and a button for increment” into:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>Widget</span><span> </span><span>body</span><span>(</span><span>RustState</span><span> </span><span>state</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>
</span></span></span><span><span><span>  </span><span>Text</span><span>(</span><span>'Count</span>: <span>$</span><span>{</span><span>state</span><span>.</span><span>count</span><span>}</span><span>'</span><span>),</span><span>
</span></span></span><span><span><span>  </span><span>TextButton</span><span>(</span><span>onPressed</span>: <span>state</span><span>.</span><span>increment</span><span>,</span><span> </span><span>child</span>: <span>Text</span><span>(</span><span>'</span><span>+</span><span>1</span><span>'</span><span>)),</span><span>
</span></span></span><span><span><span></span><span>].</span><span>toColumn</span><span>().</span><span>padding</span><span>(</span><span>all</span>: <span>16</span><span>);</span><span>
</span></span></span></code></pre></div><p>Remark: Similarly, there are many ways to write a Flutter UI, but here we choose one with simplicity. For larger projects, <code>functional_widget</code> (which adds one-line annotation for widget functions) and many tunable things can be configured.</p><p>Now we can run app and play with it in a command (for full code directory, please refer to the end of article). As a bonus, we can modify the UI and see it immediately shown, thanks to hot-reload.</p><h2 id="optional-a-todo-list-app">(Optional) A todo-list app <span><a href="#optional-a-todo-list-app" aria-label="Anchor">#</a></span></h2><p>Feel free to skip this section, since it mainly serves for completeness.</p><details><p>Todo-list app seems to be quite common when it comes to examples, so let’s also make one, and again it is <em>only</em> one of the many possible approaches that flutter_rust_bridge can support.</p><p>Define the states:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[frb(ui_state)]</span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>RustState</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>items</span>: <span>Vec</span><span>&lt;</span><span>Item</span><span>&gt;</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>input_text</span>: <span>String</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>filter</span>: <span>Filter</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>next_id</span>: <span>i32</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[derive(Clone)]</span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Item</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>id</span>: <span>i32</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>content</span>: <span>String</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>completed</span>: <span>bool</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[derive(Clone, Copy, PartialEq, Eq)]</span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>enum</span> <span>Filter</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>All</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>Active</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>Completed</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>…some actions to update it:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[frb(ui_mutation)]</span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>RustState</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>add</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>next_id</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>next_id</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>items</span><span>.</span><span>push</span><span>(</span><span>Item</span><span> </span><span>{</span><span> </span><span>id</span><span>,</span><span> </span><span>content</span>: <span>self</span><span>.</span><span>input_text</span><span>.</span><span>clone</span><span>(),</span><span> </span><span>completed</span>: <span>false</span><span> </span><span>});</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>input_text</span><span>.</span><span>clear</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>remove</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>id</span>: <span>i32</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>items</span><span>.</span><span>retain</span><span>(</span><span>|</span><span>x</span><span>|</span><span> </span><span>x</span><span>.</span><span>id</span><span> </span><span>!=</span><span> </span><span>id</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>toggle</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>id</span>: <span>i32</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>entry</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>items</span><span>.</span><span>iter_mut</span><span>().</span><span>find</span><span>(</span><span>|</span><span>x</span><span>|</span><span> </span><span>x</span><span>.</span><span>id</span><span> </span><span>==</span><span> </span><span>id</span><span>).</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>entry</span><span>.</span><span>completed</span><span> </span><span>=</span><span> </span><span>!</span><span>entry</span><span>.</span><span>completed</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>…some more business logic:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>impl</span><span> </span><span>RustState</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>new</span><span>()</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>Self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>items</span>: <span>vec</span><span>!</span><span>[],</span><span>
</span></span></span><span><span><span>            </span><span>input_text</span>: <span>""</span><span>.</span><span>to_string</span><span>(),</span><span>
</span></span></span><span><span><span>            </span><span>filter</span>: <span>Filter</span>::<span>All</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>next_id</span>: <span>0</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>base_state</span>: <span>Default</span>::<span>default</span><span>(),</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>filtered_items</span><span>(</span><span>&amp;</span><span>self</span><span>)</span><span> </span>-&gt; <span>Vec</span><span>&lt;</span><span>Item</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>items</span><span>.</span><span>iter</span><span>().</span><span>filter</span><span>(</span><span>|</span><span>x</span><span>|</span><span> </span><span>self</span><span>.</span><span>filter</span><span>.</span><span>check</span><span>(</span><span>x</span><span>)).</span><span>cloned</span><span>().</span><span>collect</span><span>()</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>Filter</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>check</span><span>(</span><span>&amp;</span><span>self</span><span>,</span><span> </span><span>item</span>: <span>&amp;</span><span>Item</span><span>)</span><span> </span>-&gt; <span>bool</span> <span>{</span><span>
</span></span></span><span><span><span>        </span><span>match</span><span> </span><span>self</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>Self</span>::<span>All</span><span> </span><span>=&gt;</span><span> </span><span>true</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>Self</span>::<span>Active</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>item</span><span>.</span><span>completed</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>Self</span>::<span>Completed</span><span> </span><span>=&gt;</span><span> </span><span>item</span><span>.</span><span>completed</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>…and the UI. It is a plain translation of “I want a column of things, the first one is a text field, second one is a list view, etc”, and looks similar to other UI DSLs:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>Widget</span><span> </span><span>body</span><span>(</span><span>RustState</span><span> </span><span>state</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>
</span></span></span><span><span><span>  </span><span>SyncTextField</span><span>(</span><span>
</span></span></span><span><span><span>    </span><span>decoration</span>: <span>InputDecoration</span><span>(</span><span>hintText</span>: <span>'Input</span> <span>text</span><span> </span><span>and</span><span> </span><span>enter</span><span> </span><span>to</span><span> </span><span>add</span><span> </span><span>a</span><span> </span><span>todo</span><span>'</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>text</span>: <span>state</span><span>.</span><span>inputText</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>onChanged</span>: <span>(</span><span>text</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>state</span><span>.</span><span>inputText</span><span> </span><span>=</span><span> </span><span>text</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>onSubmitted</span>: <span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>state</span><span>.</span><span>add</span><span>(),</span><span>
</span></span></span><span><span><span>  </span><span>),</span><span>
</span></span></span><span><span><span>  </span><span>ListView</span><span>(</span><span>children</span>: <span>[</span><span>
</span></span></span><span><span><span>    </span><span>for</span><span> </span><span>(</span><span>final</span><span> </span><span>item</span><span> </span><span>in</span><span> </span><span>state</span><span>.</span><span>filteredItems</span><span>())</span><span> </span><span>todoItem</span><span>(</span><span>state</span><span>,</span><span> </span><span>item</span><span>)</span><span>
</span></span></span><span><span><span>  </span><span>]).</span><span>expanded</span><span>(),</span><span>
</span></span></span><span><span><span>  </span><span>[</span><span>
</span></span></span><span><span><span>    </span><span>for</span><span> </span><span>(</span><span>final</span><span> </span><span>filter</span><span> </span><span>in</span><span> </span><span>Filter</span><span>.</span><span>values</span><span>)</span><span>
</span></span></span><span><span><span>      </span><span>TextButton</span><span>(</span><span>
</span></span></span><span><span><span>        </span><span>onPressed</span>: <span>()</span><span> </span><span>=&gt;</span><span> </span><span>state</span><span>.</span><span>filter</span><span> </span><span>=</span><span> </span><span>filter</span><span>,</span><span>
</span></span></span><span><span><span>        </span><span>child</span>: <span>Text</span><span>(</span><span>filter</span><span>.</span><span>name</span><span>).</span><span>textColor</span><span>(</span><span>state</span><span>.</span><span>filter</span><span> </span><span>==</span><span> </span><span>filter</span><span> </span><span>?</span><span> </span><span>Colors</span><span>.</span><span>blue</span><span> </span>: <span>Colors</span><span>.</span><span>black87</span><span>),</span><span>
</span></span></span><span><span><span>      </span><span>),</span><span>
</span></span></span><span><span><span>  </span><span>].</span><span>toRow</span><span>(),</span><span>
</span></span></span><span><span><span></span><span>].</span><span>toColumn</span><span>().</span><span>padding</span><span>(</span><span>all</span>: <span>16</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>Widget</span><span> </span><span>todoItem</span><span>(</span><span>RustState</span><span> </span><span>state</span><span>,</span><span> </span><span>Item</span><span> </span><span>item</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>
</span></span></span><span><span><span>  </span><span>Checkbox</span><span>(</span><span>value</span>: <span>item</span><span>.</span><span>completed</span><span>,</span><span> </span><span>onChanged</span>: <span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>state</span><span>.</span><span>toggle</span><span>(</span><span>id</span>: <span>item</span><span>.</span><span>id</span><span>)),</span><span>
</span></span></span><span><span><span>  </span><span>Text</span><span>(</span><span>item</span><span>.</span><span>content</span><span>).</span><span>expanded</span><span>(),</span><span>
</span></span></span><span><span><span>  </span><span>IconButton</span><span>(</span><span>icon</span>: <span>Icon</span><span>(</span><span>Icons</span><span>.</span><span>close</span><span>),</span><span> </span><span>onPressed</span>: <span>()</span><span> </span><span>=&gt;</span><span> </span><span>state</span><span>.</span><span>remove</span><span>(</span><span>id</span>: <span>item</span><span>.</span><span>id</span><span>)),</span><span>
</span></span></span><span><span><span></span><span>].</span><span>toRow</span><span>();</span><span>
</span></span></span></code></pre></div><p>(For full code directory, please refer to the end of article.)</p></details><h2 id="conclusion">Conclusion <span><a href="#conclusion" aria-label="Anchor">#</a></span></h2><p>In summary, we see how Flutter can be used when we want to write Rust program that needs a GUI. Feel free to ping me (I check GitHub inbox most frequently) if there are any questions!</p><h2 id="appendix-full-code-and-detailed-commands">Appendix: Full code and detailed commands <span><a href="#appendix-full-code-and-detailed-commands" aria-label="Anchor">#</a></span></h2><p>Full code is in <code>frb_example/rust_ui_counter</code> and <code>frb_example/rust_ui_todo_list</code> of <a href="https://github.com/fzyzcjy/flutter_rust_bridge" target="_blank" rel="noreferrer">https://github.com/fzyzcjy/flutter_rust_bridge</a>. Most are auto-generated boilerplate files (since Flutter has a lot of features), and the interesting files are merely <code>src/app.rs</code> and <code>ui/lib/main.dart</code>. To run the demo, enter <code>ui</code> directory and execute <code>flutter_rust_bridge_codegen generate &amp;&amp; flutter run</code>.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The surveilled society: Who is watching you and how (151 pts)]]></title>
            <link>https://www.rnz.co.nz/news/national/524791/the-surveilled-society-who-is-watching-you-and-how</link>
            <guid>41213151</guid>
            <pubDate>Sun, 11 Aug 2024 00:20:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rnz.co.nz/news/national/524791/the-surveilled-society-who-is-watching-you-and-how">https://www.rnz.co.nz/news/national/524791/the-surveilled-society-who-is-watching-you-and-how</a>, See on <a href="https://news.ycombinator.com/item?id=41213151">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="documentContent" role="main">
      

<div>
    <h3>Navigation for News Categories</h3>
  
</div>

<div>
    <header>
      

      
      
    </header>

    <div>
      <div itemscope="" itemtype="http://schema.org/ImageObject">
<p><img loading="lazy" src="https://media.rnztools.nz/rnz/image/upload/s--3SwYSEBN--/ar_16:10,c_fill,f_auto,g_auto,q_auto,w_1050/v1652047765/4LSQY12_copyright_image_292284?_a=BACCd2AD" width="1050" height="440" alt="No caption"></p><p>
<span itemprop="caption">The wide array of cameras and technology gathering information about our day-to-day life can be hard to get an overview of, says RNZ's Phil Pennington. </span>
<span>Photo: <span itemprop="copyrightHolder">Supplied/ Dan Bailey</span></span>
</p>
</div>
<p><b><i>Analysis - </i></b>Artificial intelligence-enabled cameras on billboards, in bus windshields, on petrol station forecourts and in the checkout at the supermarket - all these are here, or about to be.</p>
<p>The selling of surveillance for safety and security's sake has been very successful around the world, and in New Zealand.</p>
<p>It has proceeded apace, with barely a blip - though just this week a legal challenge to it has been playing out in the Auckland District Court, without any coverage by the media.</p>
<p>In that hearing, expected to involve at least four separate criminal cases <a href="https://www.rnz.co.nz/news/national/522447/police-cameras-multiple-court-challenges-to-use-of-number-plate-identification">challenging police use</a> for evidence of footage gathered without a warrant from CCTV retail cameras linked to automated number plate recognition (ANPR) systems, the ruling was reserved.</p>
<p>Another wee blip came <a href="https://www.rnz.co.nz/news/national/490771/new-billboards-at-wellington-train-stations-have-cameras-in-them-but-they-won-t-be-activated-council-says">after RNZ reported</a> last year that new billboards at Wellington's train stations would sport cameras from the same Swedish company that supplies surveillance products to China. In a quick-about, the billboard company ditched the cameras.</p>
<div itemscope="" itemtype="http://schema.org/ImageObject">
<p><img loading="lazy" src="https://media.rnztools.nz/rnz/image/upload/s--_FMdIRUi--/ar_16:10,c_fill,f_auto,g_auto,q_auto,w_1050/v1685144124/4L8EZER_platform_cam_jpg?_a=BACCd2AD" width="1050" height="496" alt="Wellington train stations are installing large digital billboards with cameras embedded in them. But MetLink says they weren't aware of the cameras and they will not be turned on."></p><p>
<span itemprop="caption">MetLink began installing large digital billboards at Wellington railway stations last year, despite not being aware of the cameras embedded in them. </span>
<span>Photo: <span itemprop="copyrightHolder">RNZ / Phil Pennington</span></span>
</p>
</div>
<p>A third speed bump came just last week, when NZTA deferred <a href="https://www.rnz.co.nz/news/national/524083/nzta-puts-off-installing-number-plate-identifying-cameras">using number-plate spotting cameras</a> on a highway (see below).</p>
<p>The march is mostly one way, though - including to the bank for the tech-makers and marketers, who are known to protest at the media calling their products "surveillance".</p>
<p>Such sensitivities have not put off governments spending on public-private hybrid systems.</p>
<p>New Zealand has its own, used by powerful state agencies, the police and Immigration.</p>
<p>Many of the camera systems could run facial recognition (FR). Sometimes you are just asked to trust the FR function is not switched on.</p>
<p><b>A quick swing-around what we know about the surveilled society:</b></p>
<ul>
<li>
<b>Buses - </b>This is the latest. San Fran company Hayden AI that puts car-identifying cameras in bus windshields and <a href="https://www.rnz.co.nz/news/national/524585/business-to-offer-ai-cameras-for-front-of-buses">has teamed up with big public transport contractor, NEC New Zealand</a>. They are marketing their product to ping drivers crowding bus-stops, bus lanes or cycle lanes, as a road safety tool.</li>
<li>
<b>Automatic Number Plate Recognition CCTV systems -</b> At least 5000, and possibly up to 10,000 or more, privately owned CCTV cameras nationwide are linked in to two separate privately owned AI-enabled systems <a href="https://www.rnz.co.nz/news/national/475342/police-step-up-surveillance-activity-tap-into-cctv-footage-from-other-businesses">for recognising number plates</a>. Police officers tap into this when investigating retail and other crime. Your local council quite likely has some of these. Rollout - since 2015.</li>
<li>
<b>Airports -</b> Customs is regularly upgrading the facial recognition technology at its e-gates, it checks your face against your passport in less than a blink of an eye - though the biometric data is then held for three months. It <a href="https://www.gets.govt.nz/NZCS/ExternalTenderDetails.htm?id=29620471">has just put out a tender</a> to add a biosecurity function.</li>
<li>
<b>ANPR on Transmission Gully - </b>The Transport Agency wanted to put ANPR cameras at either end of Transmission Gully motorway near Wellington, to record vehicle travel times in order to see if the road was being run sweetly by its private operator. The question of the plates captures being matched back to the Motor Vehicle Registry remains open - as does whether NZTA will actually go ahead with this, after <a href="https://www.rnz.co.nz/news/national/524083/nzta-puts-off-installing-number-plate-identifying-cameras">deferring it at the end of July</a>. Rollout - 2024, but deferred.</li>
<li>
<b>Billboards -</b> The latest can watch you as you go by <a href="https://www.rnz.co.nz/news/national/480248/outdoor-advertisers-using-smart-technology-to-reach-more-customers">and tailor their ads to suit</a>. The country had at least 1400 high-tech billboards last year; it had at least 49 that also have number-plate recognition cameras to count cars (not identify their owners, the operators insist). Some malls have smartscreens that can gauge your mood.</li>
<li>
<b>Bodycams</b> - Police still do not have these, but prison guards and checkout operators do. Woolworths <a href="https://www.rnz.co.nz/news/national/518675/software-for-new-supermarket-bodycams-linked-to-police-number-plate-technology">rolled them out at almost 200 stores in April</a>, with footage downloaded and stored by Singaporean company CSE. Rollout - 2024.</li>
<li>
<b>Speed-safety cams - </b>The new speed cams going in on highways are powerful enough to see inside your car, <a href="https://www.rnz.co.nz/news/national/491690/next-generation-speed-cameras-launched-in-northland">and smart enough to send what's wanted back for analysing by AI</a>. Driver on the phone, ping. Not wearing a seatbelt, ping. Waka Kotahi swears this will be used judiciously. Rollout - tests from mid-2023.</li>
<li>
<b>Congestion charging and tolling - </b>The cameras and new back office tech for these will ensure all that data you generate every day moving about is not lost to the ether, but stored, possibly anonymously, somewhere, possibly in a cloud-computer hypercentre in Sydney or Canberra, for help in generating the next business case.</li>
</ul>
<div itemscope="" itemtype="http://schema.org/ImageObject">
<p><img loading="lazy" src="https://media.rnztools.nz/rnz/image/upload/s--h8Tv1jYP--/c_crop,h_1739,w_2783,x_1076,y_961/c_scale,h_1739,w_2783/c_scale,f_auto,q_auto,w_1050/v1723192014/4KLP9WC__t_huhu_CCTV_room_jpg?_a=BACCd2AD" width="1050" height="787" alt="The CCTV room at the Business Association in Ōtāhuhu, in May 2024."></p><p>
<span itemprop="caption">The CCTV room at an Auckland business association, in May. (File photo) </span>
<span>Photo: <span itemprop="copyrightHolder">RNZ/ Finn Blackwell</span></span>
</p>
</div>
<p>Cameras are not quite the least of surveillance, but are only one part of it.</p>
<p>Another is the spread of systems that do not rely on cameras but surveil anyway, collecting data on you about where you go and what you do, and storing it and possibly sharing it, under agreements and contracts aimed at protecting your privacy and keeping your profile from becoming a tradeable commodity, though that has not worked so well elsewhere, such as on social media platforms.</p>
<p><b>Such as:</b></p>
<ul>
<li>
<b>Cobwebs - </b>the virtual equivalent of spying with cameras, this tech has been surveilling people's social media for the Ministry of Business, Innovation and Employment's <a href="https://www.rnz.co.nz/news/national/499349/mbie-expands-intelligence-spy-unit-mi-beyond-immigration">MI intelligence unit</a>, to deter boatpeople smugglers, it says. The ministry <a href="https://www.rnz.co.nz/news/national/519051/mbie-ends-contract-with-spyware-company-but-is-looking-for-a-replacement">is in the market</a> to replace it with similar tech. Rollout - 2020.</li>
<li>
<b>National Ticketing Solution -</b> This will get you on a bus or train anywhere <a href="https://www.rnz.co.nz/news/national/477400/us-firm-contracted-for-national-transport-ticketing-system-involved-in-weapons-manufacturing">by scanning your phone</a>. The quid pro quo of any such convenience is always control - that you pass control of your travelling data over to state agency NZTA, and its contractor, Cubic, which happens to have a defence surveillance and reconnaissance arm.</li>
</ul>
<p>Though it seems there is always room for more surveillance, it is not as if New Zealand has eyes everywhere. Other countries are much closer to blanket coverage.</p>
<p>Of the billion-plus CCTV cameras in the world, China has the most, the US an awful lot, and Africa not many. While by some rough estimates <a href="https://www.nzherald.co.nz/nz/big-brother-is-watching-the-rise-and-rise-of-cctv-in-new-zealand/7DQLTIOHGNYHFYVAR72OZZPY2M/">New Zealand has</a> one camera for every 12 people, Shanghai has one-for-two.</p>
<p>A crucial development is that public agencies used to buy the hardware and run it, and so keep the data in-house; now they often buy in complete packages in a build-operate contract with the tech company that often harvests and stores the data.</p>
<p>Just as there has been software-as-a-service (SaaS) for a while, there is also now surveillance-as-a-service.</p>
<p>Again, it is convenient, and the proliferation of this new type of SaaS did not get in the way of <a href="https://www.rnz.co.nz/news/national/519051/mbie-ends-contract-with-spyware-company-but-is-looking-for-a-replacement">New Zealand</a> recently signing up to a US-led 'Joint statement on efforts to counter the proliferation and misuse of commercial spyware'.</p>



    </div>

    
  </div>
<!-- end content-primary -->

<!-- end content-secondary -->


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Created 175 Fonts Using Rust (310 pts)]]></title>
            <link>https://chevyray.dev/blog/creating-175-fonts/</link>
            <guid>41213053</guid>
            <pubDate>Sat, 10 Aug 2024 23:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chevyray.dev/blog/creating-175-fonts/">https://chevyray.dev/blog/creating-175-fonts/</a>, See on <a href="https://news.ycombinator.com/item?id=41213053">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I decided not to support any Asian or non-Latin based languages because I am not as familiar with those character sets and not only would I not be able to achieve the quality I wanted, but it would also make the fonts take an order of magnitude longer to create. I would still like to create a pixel font family some day that has support for many, many more languages.</p><h3 id="style-variations">Style Variations</h3><p>One thing I noticed with the 40-pack was that people would mix and match the fonts a lot. Games often have a lot of UI, and good UI requires a lot of visual hierarchy. If all the text is the same size and weight, it's hard to make something stand out or recede, and readability suffers. This is more difficult with pixel fonts than regular fonts because they are not vectors and do not scale smoothly.</p><p>So this time around, I didn't just want a big variety of fonts, I also wanted each font to be a <em>family</em> of styles supporting different sizes and weights. So for example, the <a href="https://chevyray.itch.io/pixel-font-virtue" rel="noopener" target="_blank">Virtue</a> font family comes with a whopping 20 styles!</p><p><img alt="Cover image for the Virtue font, displaying its style variations" src="https://chevyray.dev/blog/creating-175-fonts/virtue_cover.webp"></p><p>This way, rather than mixing fonts with completely different styles to add variation, developers could have the variation they wanted while remaining stylistically cohesive.</p><h3 id="kerning-completeness">Kerning Completeness</h3><p>Kerning was a big time hog when making my previous font packs. Because the tools I was using required every kerning pair to be manually entered, it was incredibly time consuming and also extremely error prone.</p><p>Look at it this way—if I have just three characters <code>A B C</code>, these are the following potential kerning pairs: <code>AA</code>, <code>AB</code>, <code>AC</code>, <code>BA</code>, <code>BB</code>, <code>BC</code>, <code>CA</code>, <code>CB</code>, and <code>CC</code>. That's 9 total entries! In fact, you can calculate how many entries you (may) need by just squaring the amount of characters you support.</p><p>My new fonts were going to support 176 characters, meaning I might have to enter as many as <code>176² = 37,976</code> kerning pairs... yeah not going to happen. So this time, since I was (spoiler alert) writing my own tool to generate the fonts, I decided to semi-automate this process to take care of a huge majority of the kerning, and do manual entry when algorithm didn't suffice.</p><h3 id="better-quality-control">Better Quality Control</h3><p>With definitely only a hundred (<em>shh... he doesn't know yet</em>) fonts in the oven, managing them all was going to be a significant task. With the previous font packs, I did it manually. If I found a stray pixel or a bug in the kerning I would fix it, re-export the font, test that the re-export worked and the error was gone, and then re-upload the assets to itch manually.</p><p>Also, I just couldn't evaluate the overall quality of the fonts easily. So this time, I wanted to have a way to generate big sample texts of the font and visualizations of kerning pairs so that as I was working on the fonts I could preview them, easily spot problems, and see my fixes immediately.</p><h3 id="easier-deployment-maintenance">Easier Deployment &amp; Maintenance</h3><p>Making kerning and quality control faster and more automated lead to the obvious conclusion that I should also make the entire upload/deployment process automated as well. My goal was to have it so that adding improvements the fonts, fixing errors, and creating new ones in the future would be simple, painless, reliable, and automatic and error-proof as possible.</p><h2 id="raising-the-bar">Raising the Bar</h2><p>While my previous fonts were well-received and decent quality, if I wanted to produce something that was much more impressive, I had to sit down and improve.</p><h3 id="studying-font-design">Studying Font Design</h3><p>I've been a pixel artist since I was a wee child, and made a lot of pixel fonts, but I hadn't actually <em>studied</em> typeface design before. Ultimately, I was fairly ignorant when it came to both the history and the nature of traditional typeface design. So while I was working on these fonts, I spent a lot of time studying and learning as much as I could about the craft.</p><p>A book that helped me a lot, and I think is great for beginners, is the book <a href="https://www.richardpoulin.net/books/design-school-type" rel="noopener" target="_blank">Design School: Type</a> by Richard Poulin.</p><p><img alt="Cover and preview pages of &quot;Design School: Type&quot; by Richard Poulin" src="https://chevyray.dev/blog/creating-175-fonts/type_book.webp"></p><p>This was a great guide for beginners and acts as a comprehensive dictionary for the huge amount of terminology and conventions that exist in typeface design.</p><h3 id="photo-references">Photo References</h3><p>Another thing I did was started taking and saving photos of text I saw out in the world. I found small shop signs, museums, art galleries, festivals, posters for local events, and book covers to be amazing sources of inspiration. Here's a tiny sample of photos from my reference folder:</p><p><img alt="Twelve reference photos of various signs, books, and other lettering" src="https://chevyray.dev/blog/creating-175-fonts/photo_refs.webp"></p><p>These are not for copying, but rather for studying. Look at some of these shapes, how some of the letters hang below the baseline, how certain letters are really thin while others are wide.</p><p>One of my biggest takeaways from studying a lot of amazing fonts out in the wild is the realization that most "fancy" fonts actually don't go too crazy with all their letters. Usually fanciness is reserved for capital letters, and lowercase letters often get more subtle flair, with the occasional letter that jumps out at you.</p><p>To achieve these lofty goals, and because I wanted to and nobody could stop me, I wrote my own Rust program for creating pixel fonts: <code>pifo</code>!</p><h3 id="how-it-works">How It Works</h3><p>I like using my normal pixel art tools to actually design the fonts. When I make a font, I produce a PNG tilesheet and a config file to provide some metrics and settings to guide the tool. I can then feed these files into <code>pifo</code>:</p><pre data-lang="bat"><code data-lang="bat"><span>pifo --all --output </span><span>"Faraway"</span><span> --input </span><span>"Faraway*"
</span></code></pre><p>It then will chop the tilesheeet into individual glyphs, process and contour them in parallel, gather them into a TTF file and export it (along with several other engine-ready formats).</p><p>In this section I will go over each of these steps.</p><p>It then takes the image, chops it up into individual glyph tiles, generates contours for them, automatically calculates kerning pairs between them, and then gathers them all into a font and exports as a TTF file. It also exports the font in several other engine-ready formats.</p><p>All the work done on individual glyphs is parallelized, making it almost instant for a single font. Running this process on 175 fonts one-by-one takes only a couple of seconds. If these processes were to run in parallel, it would be almost instant again.</p><h3 id="crates-used">Crates Used</h3><p>I didn't need too many special crates for this, but the ones I used were very helpful.</p><ul><li><a href="https://crates.io/crates/clap" rel="noopener" target="_blank">clap</a> for command line argument parsing</li><li><a href="https://crates.io/crates/image" rel="noopener" target="_blank">image</a> for image decoding and encoding</li><li><a href="https://crates.io/crates/rayon" rel="noopener" target="_blank">rayon</a> for parallellization</li><li><a href="https://crates.io/crates/serde" rel="noopener" target="_blank">serde</a> for data serialization</li><li><a href="https://crates.io/crates/glyph-names" rel="noopener" target="_blank">glyph-names</a> which maps char to glyph names</li><li><a href="https://crates.io/crates/ab_glyph" rel="noopener" target="_blank">ab-glyph</a> for loading and rasterizing fonts</li><li><a href="https://crates.io/crates/crunch" rel="noopener" target="_blank">crunch</a> for rectangle packing</li></ul><h2 id="step-1-creating-font-sheets">Step 1: Creating Font Sheets</h2><p>Every font sheet has a tilesheet and config file that look like this:</p><p><img alt="A grid of characters for a pixel font" src="https://chevyray.dev/blog/creating-175-fonts/sheet.png"></p><blockquote><p>TOML</p></blockquote><pre data-lang="toml"><code data-lang="toml"><span>version </span><span>= </span><span>"1.0"          </span><span># font version
</span><span>baseline </span><span>= </span><span>14            </span><span># baseline from the top of a tile
</span><span>line_gap </span><span>= </span><span>0             </span><span># gap between vertical lines of text
</span><span>spacing </span><span>= </span><span>3              </span><span># width of space character
</span><span>metrics </span><span>= []             </span><span># manually assign metrics for glyphs
</span><span>auto_kerning </span><span>= </span><span>true      </span><span># enable automatic kerning
</span><span>auto_kerning_min </span><span>= </span><span>-</span><span>1    </span><span># never kern farther than 1 pixel left
</span><span>manual_kerning </span><span>= []      </span><span># manually kern specific glyph pairs
</span><span>skip_kerning_left </span><span>= </span><span>""   </span><span># don't kern when these glyphs are the L-pair
</span><span>skip_kerning_right </span><span>= </span><span>""  </span><span># don't kern when these glyphs are the R-pair
</span></code></pre><p>The grid size can change, but it must always be a uniform grid and the characters must always be in those positions. Only 100% white pixels will be processed by the tool, so the checkered background and baseline are merely guides that will be discarded when the sheet is processed.</p><h2 id="step-2-contouring-glyphs">Step 2: Contouring Glyphs</h2><p>Once the sheet is ready, contouring can begin. This is the most complex part of the process, and so I'll go over all the steps of the algorithm here.</p><p>TrueType glyphs are created out of one or multiple <em>contours</em>, which are basically closed shapes made out of curves. So for example, the letter <code>i</code> would be one contour for the dot, and a second contour for the rest of the shape.</p><p>Because our fonts are pixel fonts, we need to create a contour for every connected group (or "cluster") of pixels. Using this lowercase <code>t</code> as an example, we need the algorithm to turn it from pixels into two contours <span><strong><code>A</code></strong></span> and <span><strong><code>B</code></strong></span> like so:</p><p><img alt="The contours a pixelated letter should result in" src="https://chevyray.dev/blog/creating-175-fonts/pixels_to_contour.svg"></p><p>It doesn't matter where the contour begins and ends, as long as it's a closed loop.</p><h3 id="gathering-the-pixels">Gathering the Pixels</h3><p>Starting with the glyph's image, we first need to separate out all the pixels of the bitmap, because that's all we'll really be operating on. Rather than working with the image directly, I found it easier to write the algorithms by working with collections of <code>Point</code> structs which look like this:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// these have a bunch of derives, methods, and
</span><span>// contructors, but I won't list them all here
</span><span>#</span><span>[</span><span>derive</span><span>]
</span><span>pub </span><span>struct </span><span>Point </span><span>{
</span><span>    </span><span>pub </span><span>x</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>pub </span><span>y</span><span>: </span><span>i16</span><span>,
</span><span>}
</span><span>
</span><span>impl </span><span>Point </span><span>{
</span><span>    </span><span>fn </span><span>new</span><span>(</span><span>x</span><span>: </span><span>i16</span><span>, </span><span>y</span><span>: </span><span>i16</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self </span><span>{</span><span> x</span><span>,</span><span> y </span><span>}
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>right</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>+ </span><span>1</span><span>, self</span><span>.</span><span>y</span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>left</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>- </span><span>1</span><span>, self</span><span>.</span><span>y</span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>below</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y </span><span>+ </span><span>1</span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>above</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y </span><span>- </span><span>1</span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>left_edge</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>(</span><span>Point, Point</span><span>) {
</span><span>        </span><span>(</span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y </span><span>+ </span><span>1</span><span>)</span><span>, </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y</span><span>))
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>right_edge</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>(</span><span>Point, Point</span><span>) {
</span><span>        </span><span>(
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>+ </span><span>1</span><span>, self</span><span>.</span><span>y</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>+ </span><span>1</span><span>, self</span><span>.</span><span>y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>        </span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>top_edge</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>(</span><span>Point, Point</span><span>) {
</span><span>        </span><span>(</span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y</span><span>)</span><span>, </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>+ </span><span>1</span><span>, self</span><span>.</span><span>y</span><span>))
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>fn </span><span>bottom_edge</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>(</span><span>Point, Point</span><span>) {
</span><span>        </span><span>(
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x </span><span>+ </span><span>1</span><span>, self</span><span>.</span><span>y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>, self</span><span>.</span><span>y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>        </span><span>)
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>pub </span><span>fn </span><span>sign</span><span>(</span><span>self</span><span>) </span><span>-&gt; </span><span>Self </span><span>{
</span><span>        </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>self</span><span>.</span><span>x</span><span>.</span><span>signum</span><span>()</span><span>, self</span><span>.</span><span>y</span><span>.</span><span>signum</span><span>())
</span><span>    </span><span>}
</span><span>}
</span></code></pre><p>Given an <a href="https://docs.rs/image/latest/image/type.RgbaImage.html" rel="noopener" target="_blank"><code>RgbaImage</code></a>, we can collect all the white pixels into a <code>HashSet</code>:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>const </span><span>WHITE</span><span>: </span><span>Rgba&lt;</span><span>u8</span><span>&gt; </span><span>=</span><span> Rgba</span><span>([</span><span>255</span><span>; </span><span>4</span><span>])</span><span>;
</span><span>let</span><span> pixels</span><span>: </span><span>HashSet&lt;Point&gt; </span><span>=</span><span> img
</span><span>    </span><span>.</span><span>enumerate_pixels</span><span>()
</span><span>    </span><span>.</span><span>filter</span><span>(|(</span><span>_</span><span>,</span><span> _</span><span>, </span><span>p</span><span>)| </span><span>*</span><span>p </span><span>== &amp;</span><span>WHITE</span><span>)
</span><span>    </span><span>.</span><span>map</span><span>(|(</span><span>x</span><span>, </span><span>y</span><span>,</span><span> _</span><span>)| </span><span>Point</span><span>::</span><span>new</span><span>(</span><span>x </span><span>as </span><span>i16</span><span>,</span><span> y </span><span>as </span><span>i16</span><span>))
</span><span>    </span><span>.</span><span>collect</span><span>()</span><span>;
</span></code></pre><h3 id="detecting-clusters">Detecting Clusters</h3><p>Now we need to group these pixels together into clusters so we can operate on and create a contour for them separately. So for our letter, we can identify that it should have two clusters.</p><p>To do this we start by choosing a random pixel and "flood filling" it, spreading out into every adjacent pixel until there are no more it can spread to, and then that produces a single cluster. Then, we take the remaining pixels and repeat again, continuing this loop until there are no more unvisited pixels.</p><p><img alt="A letter being divided into separate clusters" src="https://chevyray.dev/blog/creating-175-fonts/clusters.svg"></p><p>The following algorithm does so:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// generate a list of "clusters" of pixels that are connected together
</span><span>let </span><span>mut</span><span> clusters</span><span>: </span><span>Vec</span><span>&lt;HashSet&lt;Point&gt;&gt; </span><span>= </span><span>Vec</span><span>::</span><span>new</span><span>()</span><span>;
</span><span>{
</span><span>    </span><span>// to find clusters, we flood-fill pixels in the image,
</span><span>    </span><span>// removing them, until there are none left
</span><span>    </span><span>let </span><span>mut</span><span> pixels </span><span>=</span><span> pixels</span><span>.</span><span>clone</span><span>()</span><span>;
</span><span>    </span><span>let </span><span>mut</span><span> to_process </span><span>= </span><span>Vec</span><span>::</span><span>new</span><span>()</span><span>;
</span><span>
</span><span>    </span><span>// while there are pixels left
</span><span>    </span><span>while </span><span>let </span><span>Some</span><span>(</span><span>&amp;</span><span>p</span><span>) </span><span>=</span><span> pixels</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>next</span><span>() {
</span><span>        </span><span>// add the pixel to the process list
</span><span>        to_process</span><span>.</span><span>push</span><span>(</span><span>p</span><span>)</span><span>;
</span><span>
</span><span>        </span><span>// create a new cluster
</span><span>        </span><span>let </span><span>mut</span><span> cluster </span><span>= </span><span>HashSet</span><span>::</span><span>new</span><span>()</span><span>;
</span><span>
</span><span>        </span><span>// while there are pixels to be processed
</span><span>        </span><span>while </span><span>let </span><span>Some</span><span>(</span><span>p</span><span>) </span><span>=</span><span> to_process</span><span>.</span><span>pop</span><span>() {
</span><span>            </span><span>// remove the pixel and add it to the cluster
</span><span>            pixels</span><span>.</span><span>remove</span><span>(</span><span>&amp;</span><span>p</span><span>)</span><span>;
</span><span>            cluster</span><span>.</span><span>insert</span><span>(</span><span>p</span><span>)</span><span>;
</span><span>
</span><span>            </span><span>// queue processing for all adjacent pixels
</span><span>            </span><span>// that have not yet been processed
</span><span>            to_process</span><span>.</span><span>extend</span><span>(</span><span>p
</span><span>                </span><span>.</span><span>adjacent</span><span>()
</span><span>                </span><span>.</span><span>into_iter</span><span>()
</span><span>                </span><span>.</span><span>filter</span><span>(|</span><span>p</span><span>| </span><span>pixels</span><span>.</span><span>contains</span><span>(</span><span>p</span><span>))
</span><span>            </span><span>)</span><span>;
</span><span>        </span><span>}
</span><span>
</span><span>        clusters</span><span>.</span><span>push</span><span>(</span><span>cluster</span><span>)</span><span>;
</span><span>    </span><span>}
</span><span>}
</span></code></pre><h3 id="creating-the-edge-list">Creating the Edge List</h3><p>Now we have our clusters, each which represents one "shape" made out of contours. We now need to find the <em>outline</em> of each of them because that's what we'll be creating the contours out of.</p><p><img alt="Outlines around the previous two clusters" src="https://chevyray.dev/blog/creating-175-fonts/edge_lists1.svg"></p><p>To do this, we first make a list of all the exposed edges of all pixels, where "exposed" means there is no adjacent pixel on that side. Just looking at one cluster, it looks like this:</p><p><img alt="Visualizing of all exposed cluster edges" src="https://chevyray.dev/blog/creating-175-fonts/edge_lists2.svg"></p><p>The code to create this list of edges:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>let </span><span>mut</span><span> edges</span><span>: </span><span>Vec</span><span>&lt;</span><span>(</span><span>Point, Point</span><span>)</span><span>&gt; </span><span>=</span><span> cluster
</span><span>    </span><span>.</span><span>iter</span><span>()
</span><span>    </span><span>.</span><span>map</span><span>(|</span><span>p</span><span>| {
</span><span>        </span><span>[
</span><span>            </span><span>(</span><span>!</span><span>cluster</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>p</span><span>.</span><span>above</span><span>()))</span><span>.</span><span>then</span><span>(|| </span><span>p</span><span>.</span><span>top_edge</span><span>())</span><span>,
</span><span>            </span><span>(</span><span>!</span><span>cluster</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>p</span><span>.</span><span>right</span><span>()))</span><span>.</span><span>then</span><span>(|| </span><span>p</span><span>.</span><span>right_edge</span><span>())</span><span>,
</span><span>            </span><span>(</span><span>!</span><span>cluster</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>p</span><span>.</span><span>below</span><span>()))</span><span>.</span><span>then</span><span>(|| </span><span>p</span><span>.</span><span>bottom_edge</span><span>())</span><span>,
</span><span>            </span><span>(</span><span>!</span><span>cluster</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>p</span><span>.</span><span>left</span><span>()))</span><span>.</span><span>then</span><span>(|| </span><span>p</span><span>.</span><span>left_edge</span><span>())</span><span>,
</span><span>        </span><span>]
</span><span>    </span><span>})
</span><span>    </span><span>.</span><span>flatten</span><span>()
</span><span>    </span><span>.</span><span>flatten</span><span>()
</span><span>    </span><span>.</span><span>collect</span><span>()</span><span>;
</span></code></pre><h3 id="chaining-edges">Chaining Edges</h3><p>The next part is tricky. We need to take that list of edges and build a <em>path</em> out of them by attaching them together. If we imagine each point as a <code>(tail, head)</code> tuple representing an edge, then we can write an algorithm that attaches all the overlapping heads to all the overlapping tails to create a contiguous path.</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// each cluster will generate one or more contours
</span><span>let </span><span>mut</span><span> contours</span><span>: </span><span>Vec</span><span>&lt;</span><span>Vec</span><span>&lt;Point&gt;&gt; </span><span>= </span><span>Vec</span><span>::</span><span>new</span><span>()</span><span>;
</span><span>
</span><span>// if we have edges remaining, start a new path
</span><span>while </span><span>let </span><span>Some</span><span>((</span><span>a</span><span>,</span><span> b</span><span>)) </span><span>=</span><span> edges</span><span>.</span><span>pop</span><span>() {
</span><span>    </span><span>// the contour starts with the first edge
</span><span>    </span><span>let </span><span>mut</span><span> contour </span><span>= </span><span>vec!</span><span>[</span><span>a</span><span>,</span><span> b</span><span>]</span><span>;
</span><span>    </span><span>let </span><span>mut</span><span> end </span><span>=</span><span> b</span><span>;
</span><span>    </span><span>let </span><span>mut</span><span> i </span><span>= </span><span>0</span><span>;
</span><span>
</span><span>    </span><span>while</span><span> i </span><span>&lt;</span><span> edges</span><span>.</span><span>len</span><span>() {
</span><span>        </span><span>// check the portion after the last edge for a chain
</span><span>        </span><span>if </span><span>let </span><span>Some</span><span>((</span><span>j</span><span>, </span><span>(</span><span>_</span><span>,</span><span> b</span><span>))) </span><span>=</span><span> edges</span><span>[</span><span>i</span><span>..</span><span>]
</span><span>            </span><span>.</span><span>iter</span><span>()
</span><span>            </span><span>.</span><span>cloned</span><span>()
</span><span>            </span><span>.</span><span>enumerate</span><span>()
</span><span>            </span><span>.</span><span>find</span><span>(|(</span><span>_</span><span>,</span><span> (</span><span>a</span><span>,</span><span> _</span><span>))</span><span>|</span><span> a </span><span>== &amp;</span><span>end)
</span><span>        </span><span>{
</span><span>            edges</span><span>.</span><span>remove</span><span>(</span><span>i </span><span>+</span><span> j</span><span>)</span><span>;
</span><span>            contour</span><span>.</span><span>push</span><span>(</span><span>b</span><span>)</span><span>;
</span><span>            end </span><span>=</span><span> b</span><span>;
</span><span>            i </span><span>+=</span><span> j</span><span>;
</span><span>            </span><span>if</span><span> i </span><span>&gt;=</span><span> edges</span><span>.</span><span>len</span><span>() {
</span><span>                i </span><span>-=</span><span> edges</span><span>.</span><span>len</span><span>()</span><span>;
</span><span>            </span><span>}
</span><span>            </span><span>continue</span><span>;
</span><span>        </span><span>}
</span><span>
</span><span>        </span><span>// check the portion before the last edge for a chain
</span><span>        </span><span>if </span><span>let </span><span>Some</span><span>((</span><span>j</span><span>, </span><span>(</span><span>_</span><span>,</span><span> b</span><span>))) </span><span>=</span><span> edges</span><span>[</span><span>..</span><span>i</span><span>]
</span><span>            </span><span>.</span><span>iter</span><span>()
</span><span>            </span><span>.</span><span>cloned</span><span>()
</span><span>            </span><span>.</span><span>enumerate</span><span>()
</span><span>            </span><span>.</span><span>find</span><span>(|(</span><span>_</span><span>,</span><span> (</span><span>a</span><span>,</span><span> _</span><span>))</span><span>|</span><span> a </span><span>== &amp;</span><span>end)
</span><span>        </span><span>{
</span><span>            edges</span><span>.</span><span>remove</span><span>(</span><span>j</span><span>)</span><span>;
</span><span>            contour</span><span>.</span><span>push</span><span>(</span><span>b</span><span>)</span><span>;
</span><span>            end </span><span>=</span><span> b</span><span>;
</span><span>            i </span><span>=</span><span> j</span><span>;
</span><span>            </span><span>if</span><span> i </span><span>&gt;=</span><span> edges</span><span>.</span><span>len</span><span>() {
</span><span>                i </span><span>-=</span><span> edges</span><span>.</span><span>len</span><span>()</span><span>;
</span><span>            </span><span>}
</span><span>            </span><span>continue</span><span>;
</span><span>        </span><span>}
</span><span>
</span><span>        </span><span>break</span><span>;
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>// the end point is the same as the start point
</span><span>    contour</span><span>.</span><span>pop</span><span>()</span><span>;
</span><span>
</span><span>    </span><span>// add it to our contour list
</span><span>    contours</span><span>.</span><span>push</span><span>(</span><span>contour</span><span>)</span><span>;
</span><span>}
</span></code></pre><p>This will create the following contour from the cluster:</p><p><img alt="The list  of edges with edge vertices removed" src="https://chevyray.dev/blog/creating-175-fonts/chaining.svg"></p><p>You may have noticed that this code assumes that each cluster can produce multiple contours. This is because if you have a cluster with a hole in the middle, that will in fact be the case:</p><p><img alt="A donut-shaped cluster with two contours, one for the cluster and one for the hole" src="https://chevyray.dev/blog/creating-175-fonts/multi_contour.svg"></p><p>Also notice that whenever we have clusters with holes, the winding of the outside of the cluster is clockwise, but the winding of the holes is counter-clockwise. This is an artifact of how edges are provided in clockwise order, and is actually very lucky because that's exactly how TTF contours work! When you want to describe a hole in a glyph, you create an inner contour and wind it in the opposite direction of the outer contour.</p><h3 id="remove-non-corner-points">Remove Non-Corner Points</h3><p>While this will technically work, we can optimize this a bit more. When multiple edges connect in a line, we don't really need them all, do we? If we remove all non-corner points, we can shrink the file size and also increase rasterization speed.</p><p><img alt="The chained edges with non-corner points removed" src="https://chevyray.dev/blog/creating-175-fonts/repeat_sections.svg"></p><p>We do this after chaining, right before adding our contour to the list:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// for every a→b→c sequence of points, if the normal of a→b is equal
</span><span>// to the normal of b→c, then we can remove b and link a→c directly
</span><span>let </span><span>mut</span><span> i </span><span>= </span><span>1</span><span>;
</span><span>while</span><span> i </span><span>&lt;=</span><span> contour</span><span>.</span><span>len</span><span>() {
</span><span>    </span><span>let</span><span> a </span><span>=</span><span> contour</span><span>[</span><span>i </span><span>- </span><span>1</span><span>]</span><span>;
</span><span>    </span><span>let</span><span> b </span><span>=</span><span> contour</span><span>[</span><span>i </span><span>%</span><span> contour</span><span>.</span><span>len</span><span>()]</span><span>;
</span><span>    </span><span>let</span><span> c </span><span>=</span><span> contour</span><span>[(</span><span>i </span><span>+ </span><span>1</span><span>) </span><span>%</span><span> contour</span><span>.</span><span>len</span><span>()]</span><span>;
</span><span>    </span><span>if </span><span>(</span><span>b </span><span>-</span><span> a</span><span>)</span><span>.</span><span>sign</span><span>() </span><span>== </span><span>(</span><span>c </span><span>-</span><span> b</span><span>)</span><span>.</span><span>sign</span><span>() {
</span><span>        contour</span><span>.</span><span>remove</span><span>(</span><span>i </span><span>%</span><span> contour</span><span>.</span><span>len</span><span>())</span><span>;
</span><span>    </span><span>} </span><span>else </span><span>{
</span><span>        i </span><span>+= </span><span>1</span><span>;
</span><span>    </span><span>}
</span><span>}
</span><span>
</span><span>// *now* we can add it to our contour list
</span><span>contours</span><span>.</span><span>push</span><span>(</span><span>contour</span><span>)</span><span>;
</span></code></pre><h2 id="step-3-kerning-tables">Step 3: Kerning Tables</h2><p>Once we have the contours done, we only need one more thing in order to produce our TTF file: kerning tables. This table tells fonts when they are allowed to shift characters left to fit words together more tightly.</p><figure><img alt="Example of the text 'Vault' without and with kerning" src="https://chevyray.dev/blog/creating-175-fonts/kerning_example.svg"><figcaption>Shifting the <b>Va</b> and the <b>lt</b> pairs left by just one pixel looks a lot nicer.</figcaption></figure><h3 id="manual-kerning-alts">Manual Kerning &amp; Alts</h3><p>Kerning can be manually assigned in the font's <code>TOML</code> file. So for the kerning pairs in the example above, we could do this:</p><blockquote><p>TOML</p></blockquote><pre data-lang="toml"><code data-lang="toml"><span>manual_kerning </span><span>= [
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"a"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>    { </span><span>left </span><span>= </span><span>"l"</span><span>, </span><span>right </span><span>= </span><span>"t"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>]
</span></code></pre><p>But our fonts also support accents, so for the letter <code>a</code> we would have to consider all its accented variations..</p><blockquote><p>TOML</p></blockquote><pre data-lang="toml"><code data-lang="toml"><span>manual_kerning </span><span>= [
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"a"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"à"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"á"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"â"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1 </span><span>}</span><span>,
</span><span>    </span><span># ...etc.
</span></code></pre><p>To simplify this, I can use the <code>alts</code> parameter to achieve the same thing:</p><blockquote><p>TOML</p></blockquote><pre data-lang="toml"><code data-lang="toml"><span>manual_kerning </span><span>= [
</span><span>    { </span><span>left </span><span>= </span><span>"V"</span><span>, </span><span>right </span><span>= </span><span>"a"</span><span>, </span><span>kern </span><span>= </span><span>-</span><span>1</span><span>, </span><span>alts </span><span>= </span><span>true </span><span>}
</span><span>]
</span></code></pre><p>This is the map used to identify a character's alts:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// for manual kerning, copy settings for alts/diacritics
</span><span>let</span><span> alt</span><span>: </span><span>HashMap&lt;</span><span>char</span><span>, </span><span>&amp;</span><span>'static </span><span>str</span><span>&gt; </span><span>= </span><span>HashMap</span><span>::</span><span>from_iter</span><span>([
</span><span>    </span><span>(</span><span>'A'</span><span>, </span><span>"ÀÁÂÃÄÅ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'a'</span><span>, </span><span>"àáâãäå"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'C'</span><span>, </span><span>"Ç"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'c'</span><span>, </span><span>"ç"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'E'</span><span>, </span><span>"ÈÉÊË"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'e'</span><span>, </span><span>"èéêë"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'I'</span><span>, </span><span>"ÌÍÎÏ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'I'</span><span>, </span><span>"ÌÍÎÏ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'i'</span><span>, </span><span>"ìíîï"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'N'</span><span>, </span><span>"Ñ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'n'</span><span>, </span><span>"ñ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'O'</span><span>, </span><span>"ÒÓÔÕÖ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'o'</span><span>, </span><span>"òóôõö"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'U'</span><span>, </span><span>"ÙÚÛÜ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'u'</span><span>, </span><span>"ùúûü"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'Y'</span><span>, </span><span>"Ÿ"</span><span>)</span><span>,
</span><span>    </span><span>(</span><span>'y'</span><span>, </span><span>"ÿ"</span><span>)</span><span>,
</span><span>])</span><span>;
</span></code></pre><h3 id="automatic-kerning">Automatic Kerning</h3><p>But manually entering thousands of kerning values is exactly what I wanted to avoid. Instead, most kerning pairs will be automatically calculated, and the manual system is to override the automatic system when it doesn't suffice.</p><p>So how do we find a kerning offset for a pair of letters? Let's use <code>LV</code> as an example.</p><p><img alt="Example of the adjacent letters LV unkerned" src="https://chevyray.dev/blog/creating-175-fonts/kerning_bad.svg"></p><p>To figure out their kerning value, we have to move <code>V</code> to the left pixel-by-pixel until it is as close to <code>L</code> as possible without touching it. So if we move it over one pixel...</p><p><img alt="The 'V' is shifted over one pixel, sitting tidily next to the 'L'" src="https://chevyray.dev/blog/creating-175-fonts/kerning_shift.svg"></p><p><img alt="The 'V' is shifted over one pixel, sitting tidily next to the 'L'" src="https://chevyray.dev/blog/creating-175-fonts/kerning_fixed.svg"></p><p>It's not touching, so a <code>-1</code> is good so far. What happens if we try moving it again?</p><p><img alt="The 'V' is shifted too far, and one of its pixels is touching the T" src="https://chevyray.dev/blog/creating-175-fonts/kerning_overshot.svg"></p><p>Nope! Because two pixels are touching (corners touching counts), <code>-2</code> is too far, so that means our calculated kerning for <code>LV</code> is <code>-1</code>!</p><p>The code to do this looks like so:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>impl </span><span>Point </span><span>{
</span><span>    </span><span>fn </span><span>surrounding</span><span>(</span><span>&amp;</span><span>self</span><span>) </span><span>-&gt; </span><span>[</span><span>Self</span><span>; </span><span>8</span><span>] {
</span><span>        </span><span>let</span><span> Point </span><span>{</span><span> x</span><span>,</span><span> y </span><span>} </span><span>= *</span><span>self;
</span><span>        </span><span>[
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>+ </span><span>1</span><span>,</span><span> y</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>- </span><span>1</span><span>,</span><span> y</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x</span><span>,</span><span> y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x</span><span>,</span><span> y </span><span>- </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>+ </span><span>1</span><span>,</span><span> y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>- </span><span>1</span><span>,</span><span> y </span><span>- </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>+ </span><span>1</span><span>,</span><span> y </span><span>- </span><span>1</span><span>)</span><span>,
</span><span>            </span><span>Self</span><span>::</span><span>new</span><span>(</span><span>x </span><span>- </span><span>1</span><span>,</span><span> y </span><span>+ </span><span>1</span><span>)</span><span>,
</span><span>        </span><span>]
</span><span>    </span><span>}
</span><span>}
</span><span>
</span><span>// calculate the kerning for this glyph and the right-hand glyph
</span><span>pub </span><span>fn </span><span>calculate_kerning</span><span>(
</span><span>    </span><span>left</span><span>: </span><span>&amp;</span><span>BitmapGlyph,
</span><span>    </span><span>right</span><span>: </span><span>&amp;</span><span>BitmapGlyph,
</span><span>    </span><span>min</span><span>: </span><span>i16
</span><span>) </span><span>-&gt; </span><span>Option</span><span>&lt;NonZero&lt;</span><span>i16</span><span>&gt;&gt; </span><span>{
</span><span>    </span><span>// the start position is 2 pixels after the first letter
</span><span>    </span><span>let </span><span>mut</span><span> kern</span><span>: </span><span>i16 </span><span>= </span><span>0</span><span>;
</span><span>    </span><span>let </span><span>mut</span><span> offset</span><span>: </span><span>i16 </span><span>=</span><span> left</span><span>.</span><span>max_pixel</span><span>.</span><span>x </span><span>+ </span><span>2</span><span>;
</span><span>
</span><span>    </span><span>// if the left letter has no pixels blocking, we don't want
</span><span>    </span><span>// to kern into infinity so we stop at zero
</span><span>    </span><span>while</span><span> offset </span><span>&gt; </span><span>0 </span><span>&amp;&amp;</span><span> kern </span><span>&gt;</span><span> min </span><span>{
</span><span>        offset </span><span>-= </span><span>1</span><span>;
</span><span>
</span><span>        </span><span>// translate every pixel in the right-side image by the offset
</span><span>        </span><span>// and then see if that shift would cause any pixels to touch
</span><span>        </span><span>if</span><span> right
</span><span>            </span><span>.</span><span>pixels
</span><span>            </span><span>.</span><span>iter</span><span>()
</span><span>            </span><span>.</span><span>map</span><span>(|</span><span>p</span><span>| </span><span>Point</span><span>::</span><span>new</span><span>(</span><span>p</span><span>.</span><span>x </span><span>+</span><span> offset</span><span>,</span><span> p</span><span>.</span><span>y</span><span>))
</span><span>            </span><span>.</span><span>any</span><span>(|</span><span>p</span><span>| {
</span><span>                </span><span>// after the pixel is translated, check all positions
</span><span>                </span><span>// surrounding it. if any of those positions touch any
</span><span>                </span><span>// pixels on the left glyph, we cannot kern here
</span><span>                p</span><span>.</span><span>surrounding</span><span>()
</span><span>                    </span><span>.</span><span>iter</span><span>()
</span><span>                    </span><span>.</span><span>any</span><span>(|</span><span>adj</span><span>| </span><span>left</span><span>.</span><span>pixels</span><span>.</span><span>contains</span><span>(</span><span>adj</span><span>))
</span><span>            </span><span>})
</span><span>        </span><span>{
</span><span>            </span><span>break</span><span>;
</span><span>        </span><span>}
</span><span>
</span><span>        </span><span>// this shift was safe, so increment the kerning
</span><span>        kern </span><span>-= </span><span>1</span><span>;
</span><span>    </span><span>}
</span><span>
</span><span>    </span><span>NonZero</span><span>::</span><span>new</span><span>(</span><span>kern</span><span>)
</span><span>}
</span></code></pre><p>Given our current manually assigned kerning list, we can now extend it with the automatically calculated ones.</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// ignore manually assigned kerning
</span><span>let</span><span> ignore</span><span>: </span><span>HashSet&lt;</span><span>(</span><span>char</span><span>, </span><span>char</span><span>)</span><span>&gt; </span><span>=</span><span> kerning
</span><span>    </span><span>.</span><span>iter</span><span>()
</span><span>    </span><span>.</span><span>map</span><span>(|</span><span>k</span><span>| (</span><span>k</span><span>.</span><span>left</span><span>,</span><span> k</span><span>.</span><span>right</span><span>))
</span><span>    </span><span>.</span><span>collect</span><span>()</span><span>;
</span><span>let</span><span> skip_left</span><span>: </span><span>HashSet&lt;</span><span>char</span><span>&gt; </span><span>=</span><span> desc
</span><span>    </span><span>.</span><span>skip_kerning_left
</span><span>    </span><span>.</span><span>chars</span><span>()
</span><span>    </span><span>.</span><span>collect</span><span>()</span><span>;
</span><span>let</span><span> skip_right</span><span>: </span><span>HashSet&lt;</span><span>char</span><span>&gt; </span><span>=</span><span> desc
</span><span>    </span><span>.</span><span>skip_kerning_right
</span><span>    </span><span>.</span><span>chars</span><span>()
</span><span>    </span><span>.</span><span>collect</span><span>()</span><span>;
</span><span>
</span><span>// calculate automatic kerning
</span><span>let</span><span> min_kern </span><span>=</span><span> desc</span><span>.</span><span>auto_kerning_min</span><span>.</span><span>unwrap_or</span><span>(</span><span>i16</span><span>::</span><span>MIN</span><span>)</span><span>;
</span><span>kerning</span><span>.</span><span>par_extend</span><span>(
</span><span>    glyphs
</span><span>        </span><span>.</span><span>par_iter</span><span>()
</span><span>        </span><span>.</span><span>filter</span><span>(|</span><span>left</span><span>| </span><span>!</span><span>skip_left</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>left</span><span>.</span><span>chr</span><span>))
</span><span>        </span><span>.</span><span>map</span><span>(|</span><span>left</span><span>| {
</span><span>            glyphs
</span><span>                </span><span>.</span><span>par_iter</span><span>()
</span><span>                </span><span>.</span><span>filter</span><span>(|</span><span>right</span><span>| </span><span>!</span><span>skip_right</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>right</span><span>.</span><span>chr</span><span>))
</span><span>                </span><span>.</span><span>map</span><span>(</span><span>move </span><span>|</span><span>right</span><span>| </span><span>(</span><span>left</span><span>,</span><span> right</span><span>))
</span><span>        </span><span>})
</span><span>        </span><span>.</span><span>flatten</span><span>()
</span><span>        </span><span>.</span><span>filter</span><span>(|(</span><span>left</span><span>, </span><span>right</span><span>)| </span><span>!</span><span>ignore</span><span>.</span><span>contains</span><span>(</span><span>&amp;</span><span>(</span><span>left</span><span>.</span><span>chr</span><span>,</span><span> right</span><span>.</span><span>chr</span><span>)))
</span><span>        </span><span>.</span><span>filter_map</span><span>(|(</span><span>left</span><span>, </span><span>right</span><span>)| {
</span><span>            </span><span>calculate_kerning</span><span>(</span><span>left</span><span>,</span><span> right</span><span>,</span><span> min_kern</span><span>)
</span><span>                </span><span>.</span><span>map</span><span>(|</span><span>kern</span><span>| {
</span><span>                    KerningPair </span><span>{
</span><span>                        left</span><span>:</span><span> left</span><span>.</span><span>chr</span><span>,
</span><span>                        right</span><span>:</span><span> right</span><span>.</span><span>chr</span><span>,
</span><span>                        kern</span><span>:</span><span> kern</span><span>.</span><span>get</span><span>()</span><span>,
</span><span>                        alts</span><span>: </span><span>None</span><span>,
</span><span>                    </span><span>}
</span><span>                </span><span>})
</span><span>        </span><span>})</span><span>,
</span><span>)</span><span>;
</span></code></pre><p>I won't go over every line of this because it's interacting with several other parts of the codebase, and kind of doing a lot. But basically it respects the ignore settings in the font's TOML file, and also calculates all the kerning pairs in parallel using <a href="https://crates.io/crates/rayon" rel="noopener" target="_blank">rayon</a>.</p><p>With all the kerning calculated, we can now create the TTF files.</p><h2 id="step-5-exporting">Step 5: Exporting</h2><p>PIFO doesn't just generate TTF files, it also exports the fonts as tile sheets and packed texture atlases. With each of these, multiple data formats are provided, so you can use whichever you prefer.</p><h3 id="truetype-files">TrueType Files</h3><p>The <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/" rel="noopener" target="_blank">OpenType format</a> is pretty involved, and has a huge amount of features that I do not need for these fonts.</p><p>TTF files are binary files made up of a bunch of blocks of data, called "tables", that each contain different information about the font. The font starts with a table directory which provides the memory location for each table so that font parsers can easily jump around to access the information they want.</p><p>My exporter populates the following tables:</p><table><thead><tr><th>Table</th><th>Description</th></tr></thead><tbody><tr><td><code>head</code></td><td>Global font information</td></tr><tr><td><code>hhea</code></td><td>Horizontal layout information</td></tr><tr><td><code>maxp</code></td><td>Memory requirements</td></tr><tr><td><code>OS/2</code></td><td>OpenType font requirements</td></tr><tr><td><code>hmtx</code></td><td>Horizontal metrics</td></tr><tr><td><code>cmap</code></td><td>Maps characters to glyph index</td></tr><tr><td><code>loca</code></td><td>Maps index to <code>glyf</code> table location</td></tr><tr><td><code>glyf</code></td><td>Glyph data (contours)</td></tr><tr><td><code>kern</code></td><td>Kerning pairs</td></tr><tr><td><code>name</code></td><td>Strings for font, author, style, copyright, etc.</td></tr><tr><td><code>post</code></td><td>Required for valid TTF file</td></tr></tbody></table><p>I won't go over all of it here, but my code to write a table looks like this:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>// `hmtx` table
</span><span>data</span><span>.</span><span>begin_table</span><span>(</span><span>Tag</span><span>::</span><span>Hmtx</span><span>)</span><span>;
</span><span>{
</span><span>    </span><span>// longHorMetric - hMetrics[numberOfHMetrics]
</span><span>    </span><span>for</span><span> g </span><span>in &amp;</span><span>font</span><span>.</span><span>glyphs </span><span>{
</span><span>        </span><span>// advanceWidth -  Advance width, in font design units.
</span><span>        data</span><span>.</span><span>write_u16</span><span>(</span><span>px_to_un</span><span>(</span><span>g</span><span>.</span><span>adv </span><span>as </span><span>i16</span><span>) </span><span>as </span><span>u16</span><span>)</span><span>;
</span><span>
</span><span>        </span><span>// lsb - Glyph left side bearing, in font design units.
</span><span>        data</span><span>.</span><span>write_i16</span><span>(</span><span>px_to_un</span><span>(</span><span>g</span><span>.</span><span>lsb</span><span>))</span><span>;
</span><span>    </span><span>}
</span><span>}
</span><span>data</span><span>.</span><span>end_table</span><span>()</span><span>;
</span></code></pre><p>Every table needs to record its position, length, and <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/otff#calculating-checksums" rel="noopener" target="_blank">checksum</a>, so <code>begin_table()</code> and <code>end_table()</code> help do this.</p><p>The <code>px_to_un()</code> function converts pixels to font units, and looks like this:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>let</span><span> fake_height </span><span>= </span><span>16</span><span>;
</span><span>let</span><span> units_per_em </span><span>= </span><span>(</span><span>2048 </span><span>/</span><span> fake_height</span><span>) </span><span>*</span><span> fake_height</span><span>;
</span><span>let</span><span> scale </span><span>=</span><span> units_per_em </span><span>/</span><span> fake_height</span><span>;
</span><span>let </span><span>px_to_un </span><span>= </span><span>|</span><span>x</span><span>: </span><span>i16</span><span>| </span><span>x </span><span>*</span><span> scale</span><span>;
</span></code></pre><p>Normal fonts can be displayed at any size because they're made of smooth curves, but pixel fonts don't have that luxury because pixels are discrete and so you must always render them at multiples of some base size or you'll get a <em>wobbling</em> effect that looks really bad.</p><p>So I decided that the <em>base size</em> for all my fonts is just <code>16</code>, meaning that rendering a pixel font at that size will always produce pixels that are exactly <code>1 px</code> in size. When you want to scale up the text without wobbling, you can just draw text at multiples of 16, so <code>32</code>, <code>48</code>, <code>64</code>, etc.</p><h3 id="tile-sheets">Tile Sheets</h3><p>Fonts are also exported as tile sheets. Unlike the input sheets that group characters of similarity together, these sheets are ordered by their unicode codepoints:</p><p><img alt="A tile sheet of pixel font characters" src="https://chevyray.dev/blog/creating-175-fonts/export_sheet.png"></p><p>Each comes with a data file with font and glyph metrics:</p><blockquote><p>JSON</p></blockquote><pre data-lang="json"><code data-lang="json"><span>{
</span><span>  </span><span>"cols"</span><span>: </span><span>14</span><span>,
</span><span>  </span><span>"rows"</span><span>: </span><span>13</span><span>,
</span><span>  </span><span>"tile_w"</span><span>: </span><span>8</span><span>,
</span><span>  </span><span>"tile_h"</span><span>: </span><span>17</span><span>,
</span><span>  </span><span>"baseline"</span><span>: </span><span>14</span><span>,
</span><span>  </span><span>"line_gap"</span><span>: </span><span>0</span><span>,
</span><span>  </span><span>"space_w"</span><span>: </span><span>3</span><span>,
</span><span>  </span><span>"glyphs"</span><span>: </span><span>[
</span><span>        </span><span>{
</span><span>            </span><span>"chr"</span><span>: </span><span>"</span><span>\u0000</span><span>"</span><span>,
</span><span>            </span><span>"lsb"</span><span>: </span><span>0</span><span>,
</span><span>            </span><span>"adv"</span><span>: </span><span>8
</span><span>        </span><span>}</span><span>,
</span><span>        </span><span>{
</span><span>            </span><span>"chr"</span><span>: </span><span>"!"</span><span>,
</span><span>            </span><span>"lsb"</span><span>: </span><span>0</span><span>,
</span><span>            </span><span>"adv"</span><span>: </span><span>2
</span><span>        </span><span>}</span><span>,
</span><span>        </span><span>{
</span><span>            </span><span>"chr"</span><span>: </span><span>"</span><span>\"</span><span>"</span><span>,
</span><span>            </span><span>"lsb"</span><span>: </span><span>0</span><span>,
</span><span>            </span><span>"adv"</span><span>: </span><span>4
</span><span>        </span><span>}</span><span>,
</span><span>        </span><span>{
</span><span>            </span><span>"chr"</span><span>: </span><span>"#"</span><span>,
</span><span>            </span><span>"lsb"</span><span>: </span><span>0</span><span>,
</span><span>            </span><span>"adv"</span><span>: </span><span>7
</span><span>        </span><span>}</span><span>,
</span></code></pre><p>This data file also contains a kerning table:</p><blockquote><p>JSON</p></blockquote><pre data-lang="json"><code data-lang="json"><span>    </span><span>"kerning"</span><span>: </span><span>[
</span><span>        </span><span>{
</span><span>            </span><span>"left"</span><span>: </span><span>"i"</span><span>,
</span><span>            </span><span>"right"</span><span>: </span><span>"j"</span><span>,
</span><span>            </span><span>"kern"</span><span>: </span><span>-3
</span><span>        </span><span>}</span><span>,
</span><span>        </span><span>{
</span><span>            </span><span>"left"</span><span>: </span><span>"i"</span><span>,
</span><span>            </span><span>"right"</span><span>: </span><span>"ì"</span><span>,
</span><span>            </span><span>"kern"</span><span>: </span><span>-1
</span><span>        </span><span>}</span><span>,
</span><span>        </span><span>{
</span><span>            </span><span>"left"</span><span>: </span><span>"j"</span><span>,
</span><span>            </span><span>"right"</span><span>: </span><span>"j"</span><span>,
</span><span>            </span><span>"kern"</span><span>: </span><span>-2
</span><span>        </span><span>}</span><span>,
</span></code></pre><p>To do this, I put this data into the following structs and use <code>serde</code> to serialize them into the various supported formats (JSON, XML, TOML, etc).</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>Sheet </span><span>{
</span><span>    </span><span>cols</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>rows</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>tile_w</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>tile_h</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>baseline</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>line_gap</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>space_w</span><span>: </span><span>i16</span><span>,
</span><span>
</span><span>    #</span><span>[</span><span>serde</span><span>(</span><span>skip_serializing_if </span><span>= </span><span>"Vec::is_empty"</span><span>,</span><span> default</span><span>)]
</span><span>    </span><span>glyphs</span><span>: </span><span>Vec</span><span>&lt;Glyph&gt;,
</span><span>
</span><span>    #</span><span>[</span><span>serde</span><span>(</span><span>skip_serializing_if </span><span>= </span><span>"Vec::is_empty"</span><span>,</span><span> default</span><span>)]
</span><span>    </span><span>kerning</span><span>: </span><span>Vec</span><span>&lt;KerningPair&gt;,
</span><span>}
</span><span>
</span><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>Glyph </span><span>{
</span><span>    </span><span>chr</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>lsb</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>adv</span><span>: </span><span>i16</span><span>,
</span><span>}
</span><span>
</span><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>KerningPair </span><span>{
</span><span>    </span><span>left</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>right</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>kern</span><span>: </span><span>i16</span><span>,
</span><span>}
</span></code></pre><h3 id="packed-atlases">Packed Atlases</h3><p>Versions with the glyphs tightly packed into a texture atlas are also exported:</p><p><img alt="Font characters packed tightly into a texture atlas" src="https://chevyray.dev/blog/creating-175-fonts/export_packed.png"></p><p>I use my own rectangle packer crate <a href="https://crates.io/crates/crunch" rel="noopener" target="_blank">crunch</a> to do this:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>let</span><span> PackedItems </span><span>{</span><span> w</span><span>,</span><span> h</span><span>, </span><span>mut</span><span> items </span><span>} </span><span>= </span><span>{
</span><span>    </span><span>let</span><span> items</span><span>: </span><span>Vec</span><span>&lt;Item&lt;</span><span>usize</span><span>&gt;&gt; </span><span>=</span><span> font
</span><span>        </span><span>.</span><span>glyphs
</span><span>        </span><span>.</span><span>iter</span><span>()
</span><span>        </span><span>.</span><span>enumerate</span><span>()
</span><span>        </span><span>.</span><span>filter</span><span>(|(</span><span>_</span><span>, </span><span>g</span><span>)| </span><span>g</span><span>.</span><span>pixels</span><span>.</span><span>len</span><span>() </span><span>&gt; </span><span>0</span><span>)
</span><span>        </span><span>.</span><span>map</span><span>(|(</span><span>i</span><span>, </span><span>g</span><span>)| {
</span><span>            </span><span>let</span><span> w </span><span>= </span><span>((</span><span>g</span><span>.</span><span>max_pixel</span><span>.</span><span>x </span><span>-</span><span> g</span><span>.</span><span>min_pixel</span><span>.</span><span>x</span><span>) </span><span>+ </span><span>2</span><span>) </span><span>as </span><span>usize</span><span>;
</span><span>            </span><span>let</span><span> h </span><span>= </span><span>((</span><span>g</span><span>.</span><span>max_pixel</span><span>.</span><span>y </span><span>-</span><span> g</span><span>.</span><span>min_pixel</span><span>.</span><span>y</span><span>) </span><span>+ </span><span>2</span><span>) </span><span>as </span><span>usize</span><span>;
</span><span>            </span><span>Item</span><span>::</span><span>new</span><span>(</span><span>i</span><span>,</span><span> w</span><span>,</span><span> h</span><span>, </span><span>Rotation</span><span>::</span><span>None</span><span>)
</span><span>        </span><span>})
</span><span>        </span><span>.</span><span>collect</span><span>()</span><span>;
</span><span>    </span><span>crunch</span><span>::</span><span>pack_into_po2</span><span>(</span><span>2048</span><span>,</span><span> items</span><span>)</span><span>.</span><span>unwrap</span><span>()
</span><span>}</span><span>;
</span></code></pre><p>Because positioning info is lossed in a tighly packed atlas, the data files for these have a bit more information to help you render text correctly:</p><blockquote><p>JSON</p></blockquote><pre data-lang="json"><code data-lang="json"><span>{
</span><span>    </span><span>"size"</span><span>: </span><span>12</span><span>,
</span><span>    </span><span>"line_gap"</span><span>: </span><span>1</span><span>,
</span><span>    </span><span>"space_w"</span><span>: </span><span>3</span><span>,
</span><span>    </span><span>"glyphs"</span><span>: </span><span>[
</span><span>    </span><span>{
</span><span>        </span><span>"chr"</span><span>: </span><span>"</span><span>\u0000</span><span>"</span><span>,
</span><span>        </span><span>"x"</span><span>: </span><span>0</span><span>,
</span><span>        </span><span>"y"</span><span>: </span><span>0</span><span>,
</span><span>        </span><span>"w"</span><span>: </span><span>7</span><span>,
</span><span>        </span><span>"h"</span><span>: </span><span>9</span><span>,
</span><span>        </span><span>"off_x"</span><span>: </span><span>0</span><span>,
</span><span>        </span><span>"off_y"</span><span>: </span><span>-8</span><span>,
</span><span>        </span><span>"adv"</span><span>: </span><span>8
</span><span>    </span><span>}</span><span>,
</span><span>    </span><span>{
</span><span>        </span><span>"chr"</span><span>: </span><span>"!"</span><span>,
</span><span>        </span><span>"x"</span><span>: </span><span>118</span><span>,
</span><span>        </span><span>"y"</span><span>: </span><span>36</span><span>,
</span><span>        </span><span>"w"</span><span>: </span><span>1</span><span>,
</span><span>        </span><span>"h"</span><span>: </span><span>7</span><span>,
</span><span>        </span><span>"off_x"</span><span>: </span><span>0</span><span>,
</span><span>        </span><span>"off_y"</span><span>: </span><span>-7</span><span>,
</span><span>        </span><span>"adv"</span><span>: </span><span>2
</span><span>    </span><span>}</span><span>,
</span></code></pre><p>These are serialized and exported into different formats in the same way as sheets:</p><blockquote><p>Rust code</p></blockquote><pre data-lang="rust"><code data-lang="rust"><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>Atlas </span><span>{
</span><span>    </span><span>size</span><span>: </span><span>u32</span><span>,
</span><span>    </span><span>line_gap</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>space_w</span><span>: </span><span>i16</span><span>,
</span><span>
</span><span>    #</span><span>[</span><span>serde</span><span>(</span><span>skip_serializing_if </span><span>= </span><span>"Vec::is_empty"</span><span>,</span><span> default</span><span>)]
</span><span>    </span><span>glyphs</span><span>: </span><span>Vec</span><span>&lt;Glyph&gt;,
</span><span>
</span><span>    #</span><span>[</span><span>serde</span><span>(</span><span>skip_serializing_if </span><span>= </span><span>"Vec::is_empty"</span><span>,</span><span> default</span><span>)]
</span><span>    </span><span>kerning</span><span>: </span><span>Vec</span><span>&lt;KerningPair&gt;,
</span><span>}
</span><span>
</span><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>Glyph </span><span>{
</span><span>    </span><span>chr</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>x</span><span>: </span><span>usize</span><span>,
</span><span>    </span><span>y</span><span>: </span><span>usize</span><span>,
</span><span>    </span><span>w</span><span>: </span><span>usize</span><span>,
</span><span>    </span><span>h</span><span>: </span><span>usize</span><span>,
</span><span>    </span><span>off_x</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>off_y</span><span>: </span><span>i16</span><span>,
</span><span>    </span><span>adv</span><span>: </span><span>i16</span><span>,
</span><span>}
</span><span>
</span><span>#</span><span>[</span><span>derive</span><span>(</span><span>Debug</span><span>,</span><span> Serialize</span><span>)]
</span><span>struct </span><span>KerningPair </span><span>{
</span><span>    </span><span>left</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>right</span><span>: </span><span>char</span><span>,
</span><span>    </span><span>kern</span><span>: </span><span>i16</span><span>,
</span><span>}
</span></code></pre><h2 id="step-6-quality-testing">Step 6: Quality Testing</h2><p>If I wanted to achieve the quality of fonts I desired, I knew there would have to be some kind of system to make quality evaluation quick and easy. Once PIFO was up and running, I added one more feature to it: the ability to generate gigantic sample images.</p><p>First, I start with displaying all the letters and a few test sentences. The sentences are an excerpt from the short story <a href="https://www.mit.edu/people/dpolicar/writing/prose/text/thinkingMeat.html" rel="noopener" target="_blank">They're Made out of Meat</a> by Terry Bisson.</p><p><img alt="Sample text with test sentences" src="https://chevyray.dev/blog/creating-175-fonts/sample_start.webp"></p><p>This is followed by a collection of test words. These words aren't random, and are taken from <a href="https://www.typography.com/blog/text-for-proofing-fonts" rel="noopener" target="_blank">Text for Proofing Fonts: A farewell to The Quick Brown Fox</a>, a very useful strategy for improving font quality testing.</p><p><img alt="Sample text with a bunch of random test words" src="https://chevyray.dev/blog/creating-175-fonts/sample_words.webp"></p><p>I want all combinations of digits to look nice, so next up I render all possible pairings of those, as well as currency symbols:</p><p><img alt="Sample text with paired numbers and currency symbols" src="https://chevyray.dev/blog/creating-175-fonts/sample_numbers.webp"></p><p>Then I render a huge row of uppercase, lowercase, and mixed-case kerning pairs:</p><p><img alt="Sample text of uppercase kerning pairs" src="https://chevyray.dev/blog/creating-175-fonts/sample_kerning1.webp"></p><p><img alt="Sample text of lowercase kerning pairs" src="https://chevyray.dev/blog/creating-175-fonts/sample_kerning2.webp"></p><p><img alt="Sample text of mixed-case kerning pairs" src="https://chevyray.dev/blog/creating-175-fonts/sample_kerning3.webp"></p><p>This last one continues for awhile. Finally, I render a bunch of test punctuation:</p><p><img alt="Sample text of letter/punctuation combos" src="https://chevyray.dev/blog/creating-175-fonts/sample_punc1.webp"></p><p><img alt="Sample text of letter/punctuation combos" src="https://chevyray.dev/blog/creating-175-fonts/sample_punc2.webp"></p><p><img alt="Sample text of letter/punctuation combos" src="https://chevyray.dev/blog/creating-175-fonts/sample_punc3.webp"></p><p>With PIFO immediately generating these sample images as I was working on the fonts, I was able to improve and tweak them very quickly, greatly increasing the overall quality and polish level of nearly 200 fonts!</p><h2 id="step-7-deployment">Step 7: Deployment</h2><p>With my original goal of 100 fonts massively overshot, I now had a whopping <strong>175 PIXEL FONTS</strong> to find a way to put up online for download. There are many places to sell things online, but I decided to stick to my tried-and-true, <a href="https://itch.io/" rel="noopener" target="_blank">itch.io</a>.</p><figure><img alt="Itch.io logo" src="https://chevyray.dev/blog/creating-175-fonts/itch_io.png"><figcaption>itch.io is an open marketplace for indie creators</figcaption></figure><h3 id="creating-itch-io-projects">Creating itch.io Projects</h3><p>The most tedious part of deployment was having to create an individual itch project for each of the fonts.</p><p><img alt="A sample of my pixel font itch projects page" src="https://chevyray.dev/blog/creating-175-fonts/itch_projects.webp"></p><p>Luckily, I only had to do this once for each font. Once it was done, uploading and maintaining them could be done completely via command line scripts.</p><h3 id="building-uploading">Building &amp; Uploading</h3><p>My deployment script has three steps:</p><ul><li>make sure PIFO itself is compiled</li><li>build the font assets</li><li>update each font's itch project with the new assets</li></ul><p>The first step is simple, I compile PIFO itself in release mode so it is as fast as possible:</p><blockquote><p>deploy.bat</p></blockquote><pre data-lang="bat"><code data-lang="bat"><span>cd</span><span> pifo
</span><span>cargo build --release </span><span>|| </span><span>exit</span><span> /b </span><span>%errorlevel%
</span></code></pre><p>Next, I use PIFO to build the font I want.</p><blockquote><p>deploy.bat</p></blockquote><pre data-lang="bat"><code data-lang="bat"><span>cd</span><span> ..\input
</span><span>..\pifo\target\release\pifo --output </span><span>"../distro/faraway"</span><span> --all --input </span><span>"Faraway*"
</span></code></pre><p>The <code>--input "Faraway*"</code> means that it will find <em>every</em> font that starts with that text and compile/package them all together. So in this example, there is <code>Faraway - Regular</code>, <code>Faraway - Bold</code>, etc. and they all get put together into a single package for the "Faraway" font family.</p><p>Finally, for deployment, I use <a href="https://itch.io/docs/butler/" rel="noopener" target="_blank"><code>butler</code></a>, which is a super handy command-line deployment tool provided by itch for exactly this purpose.</p><pre data-lang="bat"><code data-lang="bat"><span>butler push ../distro/faraway chevyray/pixel-font-faraway:assets
</span></code></pre><p>Butler tracks changed files and only updates the parts it needs to, so I don't have to do any file hashing or special versioning to save data.</p><h2 id="conclusion">Conclusion</h2><p>Phew, and that's how I shipped 175 pixel fonts on itch.io created using my own Rust tools!</p><p>I hope this was interesting, informative, or even helpful to people who are learning Rust or are curious about what might go into a project of this scale. I really wanted to start my new site off with a really high quality post, and I thought this would be a great subject.</p><p>If you'd like to see more content like this, a great way to support me is to <a href="https://chevyray.itch.io/" rel="noopener" target="_blank">buy my pixel fonts</a> on itch.io, or share them around with others!</p><p><img alt="Preview of 40 of my pixel font families" src="https://chevyray.dev/blog/creating-175-fonts/families.png"></p><p>If you find errors or have suggestions, you can visit the <a href="https://github.com/ChevyRay/chevyray.dev/tree/main/content/blog/2024-08-09-shipping-175-pixel-fonts/index.md" target="_blank"><i></i> source code for this post</a> directly to file an issue or submit a pull request.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Entropic Engineering DEFCON 32 Statement (173 pts)]]></title>
            <link>https://www.entropicengineering.com/defcon-32-statement</link>
            <guid>41212899</guid>
            <pubDate>Sat, 10 Aug 2024 23:10:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.entropicengineering.com/defcon-32-statement">https://www.entropicengineering.com/defcon-32-statement</a>, See on <a href="https://news.ycombinator.com/item?id=41212899">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-6ff038cd2a62cd1f78af">
  <h2>A statement from Entropic Engineering on the developing Badge situation at DEFCON 32 (2024)</h2><h3><strong><br>August 10, 2024</strong></h3><p>Entropic Engineering was approached in January ‘24 by the DEFCON Badge Team, who were looking for a small company to partner with. They expressed that they specifically wanted to work with us as a woman-owned, queer- and POC-driven engineering firm to develop an electronic badge with a gaming element for this year’s conference.</p><p>The specifics of what they requested in January were extremely difficult / almost impossible, but we had been working with Raspberry Pi as a Design Partner and had early access to the unreleased Raspberry Pi RP 2350, a chip that would enable exactly the kind of device DEFCON was requesting. Dmitry and Entropic had already been working on a GB emulator and were thrilled to be able to contribute our work to a project directly for and by the community.</p><p>We then approached Raspberry Pi with the idea of collaborating to launch this chip at DEFCON. All negotiations, liaising, and access to RPi was orchestrated by EE. Like us, RPi was really excited about getting this tech into the hands of some of their most enthusiastic community members, especially packaged as a retro handheld gaming device. In many ways, this was a dream project.</p><p>Despite the near impossibly short timeline to achieve 30k unit mass production, our team of 5 worked tirelessly alongside Dmitry. He handled all of the emulator software while we sourced components, designed all of the hardware, wrote production test software, and organized all circuit board manufacturing, prototype manufacturing, facilitated large volume production manufacturing and logistics, and general project coordination. Through this period, Defcon’s responsibility was the game-specific software, badge accessories (i.e.: plastic case and lanyard), and the printed circuit board artwork including the cat shape, colors, and silkscreen.</p><p>We were clear as early as our first conversation in January that the risk in trying to push to mass production of this size and on this timeline was immense, even advocating for a DEFCON 2025 release of this particular badge. DEFCON’s Badge Team remained confident that they could meet and mitigate this risk.</p><p>Once a month, we billed for our work and submitted an updated estimated per badge final cost - committing as costs built to discount our work as necessary in order to hit DEFCON’s per unit cost targets.</p><p>In June, after 5 months of late night work, badges were fully designed, prototypes were working, and mass production was ongoing with the manufacturers we contracted on behalf of DEFCON. We billed DEFCON for our most recent work, discounting our labor by 25% in order to meet the agreed upon targets. Unfortunately, we were instead met with a work stoppage request and informed we would no longer be paid for services already rendered.&nbsp;</p><p>At this point, all work had been completed except our physically attending the overseas production run and providing ongoing troubleshooting/debugging. In fact, the day we received this surprising news, we were actively working on the SD card debug that became a central concern earlier this week.</p><p>Ultimately, DEFCON chose to send a member of their own team to oversee onsite production while EE and Dmitry continued working for free behind the scenes to ensure that the badges delivered to our community would reflect the care we have for our community, this project, and the Raspberry Pi launch.</p><p>We take responsibility for and ownership of any oversights and mistakes that we have made in this project. We are a small team working with very limited resources trying to accomplish a very difficult project for our community while paying the bills. EE has tried multiple times over the past months to negotiate fair compensation for work completed prior to June 7th, but attempts at resolution have been unsuccessful.</p><p>Once the manufacturing was fully completed, we were offered a one-time “take it or leave it” amount worth well under half of what we were owed pre-stoppage. Given that what we were owed was already discounted by 25% in order to hit agreed upon cost targets, this has had a huge impact on our small team. We are also still owed substantial sums for parts that we purchased on behalf of DEFCON for use in the badge. Again, all subsequent offers to negotiate a settlement in good faith have not received any productive response.<br></p><p>We have also continued to pour lots of time, effort, and love into the project post-stoppage. I want to be clear that we never expected to be paid for this post-stoppage work, but simply did it as a labor of love for the community.</p><p>The DEFCON community is and has always been near and dear to my heart; I started my local DEFCON group as a kid growing up in Malaysia decades ago. We did everything we possibly could in order to make the badge happen this year as a love letter to the community we care about - the whole team poured everything it had, including many sleepless nights for many many months. I’m proud of my team: we weathered exhaustion, illness, robbery (ask Dmitry), and just about every logistical nightmare possible with the attitude that under no circumstances would we let this fail for a community we love and love being part of.&nbsp;</p><p>We’re confused by and extremely disappointed in the decisions made institutionally by the conference this year. In addition to the agreed upon monetary compensation (which we have been only partially provided), we were promised visibility and representation as supporters and contributors to the community. Badges for the team (and conference attendance), participation in the Badge talk, and credit in announcements, signage, and on the Badge case were all promised in return for work rendered.&nbsp;</p><p>We were especially hurt and confused by the conference's choice to revoke all of the above. If, as was offered as explanation, the Badge project was truly out of funds when we were removed, we’re especially curious how many thousands of dollars were then spent on the project of literally and physically erasing our contributions and credit. Modifying a plastic injection mold so late in the game is pricey and additionally risky.</p><p>While we as a company did not ask Dmitry to program the easter egg, the outpouring of support and community for EE has been appreciated and inspiring. We are especially grateful that Dmitry was not hurt in the physical removal he was subjected to as a result of his demonstration of solidarity. We want to extend our thanks to all attendees who have been asking questions, reaching out, attending surprise side-walk cons, displaying the about page badge on the con floor, and, especially, keeping a community eye on law enforcement and conference security to help ensure our friend Dmitry’s safety in the last 48 hours.&nbsp;</p><p>The badge circuit board was partly designed by a young EE engineer in South America (shout out to George!). It had always been Dmitry and EE’s goal to use all proceeds after overhead and payroll (which still are recovering) to finance George’s completion of his engineering degree. In fact - this is why we started work on the original pre-defcon uGB gaming device in the first place.&nbsp;</p><p>Please keep your eyes open in the near future for opportunities to help us meet this goal despite the disappointments and challenges of the past few months.</p><p>In appreciation and solidarity,<br>M Pang on behalf of the Entropic Engineering team</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US FDA approves nasal spray alternative to EpiPen for allergic reactions (150 pts)]]></title>
            <link>https://www.reuters.com/business/healthcare-pharmaceuticals/us-fda-approves-first-nasal-spray-allergic-reactions-2024-08-09/</link>
            <guid>41212364</guid>
            <pubDate>Sat, 10 Aug 2024 21:30:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/healthcare-pharmaceuticals/us-fda-approves-first-nasal-spray-allergic-reactions-2024-08-09/">https://www.reuters.com/business/healthcare-pharmaceuticals/us-fda-approves-first-nasal-spray-allergic-reactions-2024-08-09/</a>, See on <a href="https://news.ycombinator.com/item?id=41212364">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/healthcare-pharmaceuticals/us-fda-approves-first-nasal-spray-allergic-reactions-2024-08-09/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[AMD's Strix Point: Zen 5 Hits Mobile (122 pts)]]></title>
            <link>https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/</link>
            <guid>41212271</guid>
            <pubDate>Sat, 10 Aug 2024 21:18:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/">https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/</a>, See on <a href="https://news.ycombinator.com/item?id=41212271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>AMD’s Zen line has gone a long way since it brought AMD’s CPU efforts back from the dead. Successive Zen generations delivered steady improvements that made AMD an increasingly dangerous competitor to Intel. Zen 5 is the latest member of the Zen line, and hits the market at a point when Intel has plenty of troubles of their own.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30684"><img decoding="async" width="688" height="385" data-attachment-id="30684" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_core_overview_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?fit=1873%2C1049&amp;ssl=1" data-orig-size="1873,1049" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_core_overview_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?fit=1873%2C1049&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?fit=688%2C385&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=688%2C385&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?w=1873&amp;ssl=1 1873w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=1536%2C860&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=1200%2C672&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=1600%2C896&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?resize=1320%2C739&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_core_overview_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Here, we’re analyzing the Zen 5 architecture as implemented in the Ryzen AI 9 HX 370. The HX 370 is a member of AMD’s Strix Point APUs, which combines Zen 5 cores with a RDNA 3.5 iGPU and some AI stuff. Prior Zen generations saw their mobile versions launch well after the architecture debuted in desktop products, so it’s interesting to see Zen 5 do the opposite.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30843"><img decoding="async" width="688" height="459" data-attachment-id="30843" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/_dsf0224/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?fit=5668%2C3782&amp;ssl=1" data-orig-size="5668,3782" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;X-S20&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;29.6&quot;,&quot;iso&quot;:&quot;3200&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="_DSF0224" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?fit=2158%2C1440&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?fit=688%2C459&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=688%2C459&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=3237%2C2160&amp;ssl=1 3237w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=2048%2C1367&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=1200%2C801&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=1600%2C1068&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?resize=1320%2C881&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/DSF0224.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>The test system</figcaption></figure></div>
<h3>Acknowledgments </h3>
<p>We would like to thank ASUS for providing a laptop for review.</p>
<h2>System Level</h2>
<p>Strix Point implements 12 Zen 5 cores in a dual cluster configuration. A high performance cluster has four “regular” Zen 5 cores and 16 MB of L3 cache running at up to 5.15 GHz. A second density optimized cluster has eight Zen 5c cores and 8 MB of L3 running at up to 3.3 GHz. It’s a continuation of <a href="https://chipsandcheese.com/2024/02/12/amds-mild-hybrid-strategy-ryzen-z1-in-asuss-rog-ally/" data-type="link" data-id="https://chipsandcheese.com/2024/02/12/amds-mild-hybrid-strategy-ryzen-z1-in-asuss-rog-ally/">AMD’s mild hybrid strategy</a>, where different cache sizes and physical implementations help the company optimize multithreaded performance while keeping area under control. It contrasts with Intel’s hybrid strategy, which uses different core architectures optimized for high performance and <a href="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/" data-type="link" data-id="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/">high density</a>.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30640"><img decoding="async" width="688" height="414" data-attachment-id="30640" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_sys_level/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?fit=999%2C601&amp;ssl=1" data-orig-size="999,601" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_sys_level" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?fit=999%2C601&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?fit=688%2C414&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?resize=688%2C414&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?w=999&amp;ssl=1 999w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_sys_level.jpg?resize=768%2C462&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>All cores within a cluster cap out at the same clock speed. That should simplify OS scheduling decisions, because any of the high performance cores will reach approximately 5.15 GHz.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30644"><img loading="lazy" decoding="async" width="688" height="331" data-attachment-id="30644" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_clocks/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?fit=800%2C385&amp;ssl=1" data-orig-size="800,385" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_clocks" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?fit=800%2C385&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?fit=688%2C331&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?resize=688%2C331&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?w=800&amp;ssl=1 800w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_clocks.png?resize=768%2C370&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Clusters referred to as P and E for brevity. Clock speed estimated using dependent integer addition latency</figcaption></figure></div>
<p>Intel’s Meteor Lake in contrast benefits from a bit more scheduler awareness because two of its high performance Redwood Cove cores can reach 4.8 GHz. Other Redwood Cove cores cap out at 4.5 GHz. Like Strix Point, all of Meteor Lake’s efficiency cores cap out at the same speed across a cluster.</p>
<figure><img loading="lazy" decoding="async" width="688" height="240" data-attachment-id="30648" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/mtl_clocks/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?fit=1100%2C384&amp;ssl=1" data-orig-size="1100,384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mtl_clocks" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?fit=1100%2C384&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?fit=688%2C240&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?resize=688%2C240&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?w=1100&amp;ssl=1 1100w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/mtl_clocks.png?resize=768%2C268&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>Both of Strix Point’s CPU clusters are tuned for responsiveness, and waste little time getting to their maximum clocks. Even the density optimized Zen 5c cores can reach their modest 3.3 GHz boost speed in less than two milliseconds.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30642"><img loading="lazy" decoding="async" width="688" height="367" data-attachment-id="30642" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_boost/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?fit=930%2C496&amp;ssl=1" data-orig-size="930,496" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_boost" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?fit=930%2C496&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?fit=688%2C367&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?resize=688%2C367&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?w=930&amp;ssl=1 930w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_boost.png?resize=768%2C410&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Asus has opted to give the HX 370 a 128-bit LPDDR5-7500 setup, providing similar theoretical bandwidth to Meteor Lake’s LPDDR5-7467 with the same bus width. Strix Point’s CPU clusters each have 32 byte per cycle ports to the network-on-chip, which AMD calls Infinity Fabric. Infinity Fabric on the Ryzen AI 9 HX 370 runs at up to 2 GHz, much like desktop Zen 4. Per-cluster bandwidth limitations are similar. Read bandwidth from a single cluster caps out at just under 62 GB/s. The memory controller has a bit more bandwidth on tap, but you’ll need to load cores from both clusters to get it.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30715"><img loading="lazy" decoding="async" width="688" height="421" data-attachment-id="30715" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strixpoint_mtl_cluster_bw-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_mtl_cluster_bw-1.png?fit=715%2C438&amp;ssl=1" data-orig-size="715,438" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strixpoint_mtl_cluster_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_mtl_cluster_bw-1.png?fit=715%2C438&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_mtl_cluster_bw-1.png?fit=688%2C421&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_mtl_cluster_bw-1.png?resize=688%2C421&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Unlike desktop Zen 4, Strix Point’s CPU clusters have 32 byte per cycle write links too. Per-cluster write bandwidth is therefore capped at 64 GB/s, rather than 32 GB/s on desktop Zen 4.</p>
<p>Meteor Lake can just about saturate the memory controller from the CPU tile, indicating its link to Intel’s Scalable Fabric has more bandwidth than Strix Point’s CCX to Infinity Fabric link. The bandwidth gap narrows if traffic is evenly mixed in both directions. Still, reading from DRAM using both clusters at the same time gets more bandwidth. These network-on-chip bandwidth limits are unlikely to be a factor, as low-threaded applications tend to need less bandwidth. Meteor Lake’s design also demands more bandwidth from its cross-die link because the bulk of its CPU performance is concentrated on the CPU tile.</p>
<p>Cache coherency operations like <code>lock cmpxchg</code> see higher than expected latency when crossing cluster boundaries. This core to core latency measurement usually returns numbers under 100 ns for desktop CPUs, even when crossing die boundaries. The Ryzen AI 9 HX 370 uses a monolithic setup, so higher latency here is a bit surprising.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30732"><img loading="lazy" decoding="async" width="688" height="359" data-attachment-id="30732" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strix_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?fit=995%2C519&amp;ssl=1" data-orig-size="995,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strix_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?fit=995%2C519&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?fit=688%2C359&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?resize=688%2C359&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?w=995&amp;ssl=1 995w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_c2c.png?resize=768%2C401&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>For comparison, the Ryzen 9 3950X keeps cross-cluster latencies in the 80-90 ns range. Both setups enjoy excellent core to core latency within a cluster.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30734"><img loading="lazy" decoding="async" width="688" height="335" data-attachment-id="30734" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/3950x_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?fit=1392%2C678&amp;ssl=1" data-orig-size="1392,678" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="3950x_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?fit=1392%2C678&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?fit=688%2C335&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?resize=688%2C335&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?w=1392&amp;ssl=1 1392w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?resize=768%2C374&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?resize=1200%2C584&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/3950x_c2c.png?resize=1320%2C643&amp;ssl=1 1320w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<h2>Zen 5 Core, High Level</h2>
<p>Zen 5 is a significant evolution of the Zen line. From the cpuid instruction, Zen 5’s family is 1A in hexidecimal. To use AMD’s typical terminology, Zen 5 is a member of the 1Ah family (h stands for hexidecimal). Zen 3 and Zen 4 were identified as 19h, while Zen 1 and Zen 2 were 17h.</p>
<figure><img loading="lazy" decoding="async" width="688" height="472" data-attachment-id="30851" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5-drawio2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?fit=1726%2C1183&amp;ssl=1" data-orig-size="1726,1183" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5.drawio(2)" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?fit=1726%2C1183&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?fit=688%2C472&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=688%2C472&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?w=1726&amp;ssl=1 1726w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=768%2C526&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=1536%2C1053&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=1200%2C822&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=1600%2C1097&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?resize=1320%2C905&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5.drawio2.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>The CPU family reported by cpuid isn’t always significant. Intel for example identifies everything from the original Pentium Pro to Golden Cove as belonging to the 6h family. In AMD’s case though, Zen 5 sees substantial changes over Zen 4. Giving Zen 5 a different family designation definitely seems appropriate.</p>
<p>While Zen 5 inherits characteristics from Zen 4, just about every part of the CPU’s execution pipeline has changed substantially. The branch predictor is more capable and gets a victim-cache BTB setup. The fetch and decode stages are arranged in two clusters. The out-of-order backend shifts towards unified schedulers on the integer side while doing the opposite for floating point. Memory accesses benefit from larger TLBs and a bigger L1. And of course, Zen 5 is wider and has more reordering capacity than its predecessor.</p>
<h2>Branch Prediction</h2>
<p>AMD had an excellent predictor since Zen 2, and that predictor has gotten even better over time. Zen 5 continues the trend, building on top of Zen 4’s already class leading predictor. AMD needs an accurate branch predictor to make the most of a wider core with more reordering capacity, and Zen 5 doesn’t disappoint. It can recognize extremely long patterns, and is a solid step above Zen 4. Zen 4 is itself a good step above Intel’s current P-Cores.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30658"><img loading="lazy" decoding="async" width="688" height="331" data-attachment-id="30658" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_branchhist/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?fit=1300%2C625&amp;ssl=1" data-orig-size="1300,625" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_branchhist" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?fit=1300%2C625&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?fit=688%2C331&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?resize=688%2C331&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?w=1300&amp;ssl=1 1300w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?resize=768%2C369&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_branchhist.png?resize=1200%2C577&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Branch predictors have to be fast in addition to being accurate, because the whole point of branch prediction is to mitigate frontend stalls caused by branches. A cache of frequently used branch targets (called a BTB, or Branch Target Buffer) helps with speed, and is especially useful if instruction bytes have to be fetched from higher latency L2 or L3 caches.</p>
<figure><img loading="lazy" decoding="async" width="688" height="351" data-attachment-id="30661" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?fit=1136%2C579&amp;ssl=1" data-orig-size="1136,579" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?fit=1136%2C579&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?fit=688%2C351&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?resize=688%2C351&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?w=1136&amp;ssl=1 1136w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_btb.png?resize=768%2C391&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>Zen 5 moves into the company of cores like Golden Cove with giant BTBs. AMD’s latest BTB arrangement is unique because the last level has fewer entries than faster levels. I can’t think of any other CPUs that use such a BTB setup, but it makes sense in the same way having less L3 per core than L2 is fine. BTBs are caches after all, just for branch targets instead of data. AMD and others have used L3 victim caches for data in many CPUs. Now, AMD’s branch target caching works the same way. Targets evicted from the 16384 entry L1 BTB to make room for incoming targets are filled into the L2 BTB in case they have to be used again soon. The net effect is Zen 5 can track 24K branch targets, and sometimes more.</p>
<blockquote>
<p>Each BTB entry can hold up to two branches if the branches reside in the same 64-byte aligned cache line and the first branch is a conditional branch</p>
<p>Software Optimization Guide for AMD Family 17h Models 30h and Greater Processors</p>
</blockquote>
<p>Optimization manuals for prior Zen generations indicated that a single BTB entry could store targets for two branches provided certain conditions were met. Perhaps we’re seeing that capability apply more broadly with Zen 5.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30685"><img loading="lazy" decoding="async" width="688" height="385" data-attachment-id="30685" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_bp_fetch_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?fit=1874%2C1049&amp;ssl=1" data-orig-size="1874,1049" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_bp_fetch_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?fit=1874%2C1049&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?fit=688%2C385&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=688%2C385&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?w=1874&amp;ssl=1 1874w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=1536%2C860&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=1200%2C672&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=1600%2C896&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?resize=1320%2C739&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_bp_fetch_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Besides high branch target caching capacity, Zen 5’s predictor deserves recognition for how fast it can go. The first BTB level can track up to 1024 branches and handle two taken branches per cycle. AMD is not the first to release a core capable of sustaining two taken branches per cycle. Intel did that with <a href="https://chipsandcheese.com/2022/06/07/sunny-cove-intels-lost-generation/">Rocket Lake</a>, and Arm did the same with <a href="https://chipsandcheese.com/2023/10/27/cortex-x2-arm-aims-high/">Cortex X2</a>. But Zen 5 joins that party in style, achieving that speed across a much larger branch footprint than either Neoverse V2 or Golden Cove. As a cherry on top, Zen 5 does that while clocking above 5 GHz in a mobile form factor.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30666"><img loading="lazy" decoding="async" width="688" height="345" data-attachment-id="30666" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_returnstack/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?fit=854%2C428&amp;ssl=1" data-orig-size="854,428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_returnstack" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?fit=854%2C428&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?fit=688%2C345&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?resize=688%2C345&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?w=854&amp;ssl=1 854w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_returnstack.png?resize=768%2C385&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Returns are predicted by a 52 entry return stack, which appears to be duplicated for both SMT threads. It’s substantially larger than the 32 entry return stack in prior Zen generations.</p>
<h2>Clustered Fetch and Decode</h2>
<p>After the branch predictor decides where to go, subsequent frontend stages fetch instructions from memory and decode them into the CPU’s internal format. Zen 5 arranges these fetch and decode stages into two clusters. Each cluster can fetch 32 bytes per cycle from the 32 KB instruction cache and decode up to four instructions per cycle. Together, the decode clusters can handle eight instructions per cycle.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30669"><img loading="lazy" decoding="async" width="688" height="409" data-attachment-id="30669" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/z5_fe/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?fit=788%2C468&amp;ssl=1" data-orig-size="788,468" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="z5_fe" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?fit=788%2C468&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?fit=688%2C409&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?resize=688%2C409&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?w=788&amp;ssl=1 788w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_fe.jpg?resize=768%2C456&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Superficially, Zen 5’s frontend looks like the ones in Intel’s latest E-Cores. However, they don’t work the same way. Each Zen 5 cluster only handles a single thread, and maximum frontend throughput can only be achieved if both SMT threads are loaded. Intel’s scheme has all clusters working in parallel on different parts of a single thread’s instruction stream. Mixing taken branches into the test for Zen 5 doesn’t improve throughput as it did with Intel’s first generation clustered decode implementation in Tremont. Therefore, Zen 5 is likely not using branches to load balance between the two decode clusters.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30671"><img loading="lazy" decoding="async" width="596" height="517" data-attachment-id="30671" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/crestmont_fe/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/crestmont_fe.png?fit=596%2C517&amp;ssl=1" data-orig-size="596,517" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crestmont_fe" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/crestmont_fe.png?fit=596%2C517&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/crestmont_fe.png?fit=596%2C517&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/crestmont_fe.png?resize=596%2C517&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>To further speed up instruction delivery, Zen 5 fills decoded micro-ops into a 6K entry, 16-way set associative micro-op cache. This micro-op cache can service two 6-wide fetches per cycle. Evidently both 6-wide fetch pipes can be used for a single thread.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30675"><img loading="lazy" decoding="async" width="688" height="287" data-attachment-id="30675" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_ifetch4/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?fit=1175%2C491&amp;ssl=1" data-orig-size="1175,491" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_ifetch4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?fit=1175%2C491&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?fit=688%2C287&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?resize=688%2C287&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?w=1175&amp;ssl=1 1175w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch4.png?resize=768%2C321&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Zen 5 can sustain higher instruction throughput than Intel Meteor Lake’s Redwood Cove P-Cores, but only for small instruction footprints or when both SMT threads are loaded. If only a single SMT thread is active, Intel’s larger 64 KB instruction cache and conventional 6-wide decoder can hand it a lead when code spills out of the micro-op cache.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30679"><img loading="lazy" decoding="async" width="688" height="285" data-attachment-id="30679" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_ifetch8/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?fit=1173%2C486&amp;ssl=1" data-orig-size="1173,486" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_ifetch8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?fit=1173%2C486&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?fit=688%2C285&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?resize=688%2C285&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?w=1173&amp;ssl=1 1173w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ifetch8.png?resize=768%2C318&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Because x86 is a variable length instruction set, instruction cache bandwidth can become a limiting factor before the decoders do. Zen 5 and Golden Cove are practically immune to instruction length issues when they hit their respective micro-op caches. AMD’s slides suggest the L1 instruction cache can provide 64 bytes per cycle, but I was only able to get half that even with both SMT threads loaded. If code spills out of L2, Zen 5 can still maintain respectable frontend bandwidth. However, bandwidth is definitely better if you can use both SMT threads, suggesting there’s a limit to how many L1i fill request Zen 5 can queue up for a single thread.</p>
<h2>Rename and Allocate</h2>
<p>Operations from the frontend need backend resources to track them and enable correct out-of-order execution. Zen 5’s renamer is 8-wide, making it 33% wider than Zen 4’s 6-wide renamer. With every other stage in the core at least as wide, that means Zen 5 is an 8-wide core. The renamer is also a good place for tricks like move elimination or zeroing idiom recognition. Both can expose more parallelism to the backend, and even avoid consuming backend resources like register file entries. Like prior Zen generations, Zen 5 does plenty of this.</p>
<figure><table><tbody><tr><td></td><td>Zen 5 IPC</td><td>Zen 4 IPC</td></tr><tr><td>xor r,r</td><td>5.01<br>7.4 (2T)</td><td>5.92</td></tr><tr><td>mov r, 0</td><td>5.5</td><td>3.93</td></tr><tr><td>sub r,r</td><td>5.01<br>7.38 (2T)</td><td>5.94</td></tr><tr><td>xor xmm,xmm</td><td>4.99<br>6 (2T)</td><td>4.16</td></tr><tr><td>sub xmm,xmm</td><td>5.01<br>7.48 (2T)</td><td>5.94</td></tr><tr><td>Independent MOV r,r</td><td>5.01<br>7.44 (2T)</td><td>5.94</td></tr><tr><td>Dependent MOV r,r</td><td>6.65<br>7.3 (2T)</td><td>5.94</td></tr></tbody></table></figure>
<p>Zen 5 can generally pull these optimizations off at 8 per cycle, but not for a single thread. It would be rare for code to zero so many registers or move a lot of values between registers in close proximity, so those renamer restrictions may have let AMD simplify this stage. Two SMT threads will of course have independent instructions, and Zen 5 maintains the ability to blast through that quickly should both threads happen to hit a sequence of zeroing idioms or register-to-register MOVs at the same time.</p>
<h2>Giant Backend, Unified Schedulers</h2>
<p>CPUs use various structures in the backend to let them execute instructions as data becomes available for them while ensuring results are consistent with in-order execution. AMD’s Zen line was often light on these resources compared to contemporary Intel cores, and couldn’t look as far ahead in the instruction stream to hide latency. A lower latency cache hierarchy helped keep AMD’s performance competitive.</p>
<p>Zen 5 continues to have smaller structures compared to Intel, but significantly closes that gap in some areas. Its reorder buffer, FP register file, and load queue sizes are quite close to Golden Cove’s. The integer register file sees less of a size increase, possibly because it’s hard to feed 6 ALU and 4 AGU ports while adding a ton of register file entries. And while AMD’s store queue has grown substantially, entries are still 256 bits. 512-bit stores will take two entries just as with Zen 4.</p>
<figure><table><tbody><tr><td></td><td>Applies if instruction…</td><td>Zen 5<br>(Strix Point)</td><td>Zen 4</td><td>Intel Redwood Cove</td></tr><tr><td>Reorder Buffer</td><td>Exists</td><td>448 entry</td><td>320 entry</td><td>512 entry</td></tr><tr><td>Integer Register File</td><td>Writes to integer registers</td><td>240 entry</td><td>224 entry</td><td>288 entry</td></tr><tr><td>FP Register File</td><td>Writes to FP registers</td><td>384 entry<br>Of which ~234 are available for reordering 512-bit ops</td><td>192x 512-bit entry</td><td>320x 256-bit<br>Some may physically be 512-bit but that’s impossible to verify</td></tr><tr><td>Mask Register File</td><td>Writes to AVX-512 mask registers</td><td>~146 entry</td><td>68 entry</td><td>144 entry<br>Tested via MMX, <a href="https://travisdowns.github.io/blog/2020/05/26/kreg2.html">which has been aliased to the mask RF in the past</a></td></tr><tr><td>Load Queue</td><td>Reads from memory</td><td>202 entry</td><td>136 entry</td><td>240 entry</td></tr><tr><td>Store Queue</td><td>Writes to memory</td><td>104x 256-bit</td><td>64 entry</td><td>112 entry</td></tr></tbody></table></figure>
<p>AMD also made compromises with the FP/vector register file. Testing shows about 234 entries are available for in-flight instructions that write to 512-bit ZMM registers. Zen 5 is not allocating pairs of 256-bit registers to handle a 512-bit operation. AMD’s slides clearly indicate the vector register file has 384 entries, but 234 * 2 would be 468 physical 256-bit registers. Mixing a ZMM write reduces reordering capacity for 256-bit YMM registers by exactly one, implying only a single register was allocated to hold that 512-bit result. However, testing <a href="http://www.numberworld.org/blogs/2024_8_7_zen5_avx512_teardown/#vector_register_file">by Mystical</a> shows that all vector register file entries on desktop Zen 5 are 512-bits wide.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30825"><img loading="lazy" decoding="async" width="688" height="362" data-attachment-id="30825" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strix_vecrf_one_zmm/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?fit=787%2C414&amp;ssl=1" data-orig-size="787,414" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strix_vecrf_one_zmm" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?fit=787%2C414&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?fit=688%2C362&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?resize=688%2C362&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?w=787&amp;ssl=1 787w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_vecrf_one_zmm.png?resize=768%2C404&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>379 in-flight YMM writes with one ZMM write also in flight, 380 without the ZMM. Spikes earlier might indicate Zen 5 has trouble perfectly reclaiming registers when in-flight instructions use both ZMM and YMM registers</figcaption></figure></div>
<p>Zen 5’s rename/allocate stage sometimes handles register allocation poorly. Alternating between writing to ZMM and YMM registers should not reduce reordering capacity for FP/vector results, because more than half of Zen 5’s register file entries are 512 bits wide. Intel’s Golden Cove <a href="https://chipsandcheese.com/2022/12/25/golden-coves-lopsided-vector-register-file/">does exactly that</a>, but Zen 5 stops at 288 registers (144 of each). That’s still more register file capacity allocated than what a hypothetical fully 256-bit register file would have, but it does point to less than optimal allocation.</p>
<p>With Zen 4, AMD used a fully 512-bit vector register file because using wider entries only had a minor area hit compared to increasing register file port count or width. A 512-bit register file with twice as many entries as Zen 4’s might have been impractical for a mobile core. Splitting vector registers into two pools feels like a good compromise, especially considering Zen 5 still has more 512-bit register file entries than Zen 4 had in total.</p>
<h3>FP/Vector Execution</h3>
<p>Across Zen generations, AMD has slowly moved towards a more distributed FP scheduler layout. AMD is adding new scheduling queues while cutting down on port count per queue, but without significantly changing entry count. In Zen tradition, the rename/allocate stage can dump FP/vector ops into a huge non-scheduling queue if the schedulers are full rather than stalling. This queue is even larger now, with 96 entries instead of 64 as in prior generations. 64 entries was already a lot, and Zen 2 would often run out of FP register file entries before filling the schedulers and non-scheduling queue. Zen 5’s giant register file should make things more balanced.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30713"><img loading="lazy" decoding="async" width="641" height="772" data-attachment-id="30713" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_fp_sched-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_fp_sched.drawio.jpg?fit=641%2C772&amp;ssl=1" data-orig-size="641,772" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_fp_sched.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_fp_sched.drawio.jpg?fit=641%2C772&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_fp_sched.drawio.jpg?fit=641%2C772&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_fp_sched.drawio.jpg?resize=641%2C772&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Zen 5’s floating point execution unit layout is immediately recognizable as something from the Zen family. FP math operations use four ports, two of which do floating point multiplies and fused multiply adds (FMAs). The other two handle floating point adds. FP adds and multiplies have 3 cycle latency, while FMAs have 4 cycle latency. All of the FP math units are 256-bits wide, as with Zen 2. AMD is focused on feeding its existing execution units rather than having bigger ones.</p>
<p>Vector integer execution sees changes that are probably geared towards keeping power and area under control. Vector integer addition latency goes up to two cycles, compared to one cycle on Zen 4. Execution rate for 128-bit SSE and 256-bit AVX2 packed integer adds has gone from four per cycle down to two per cycle. Vector integer throughput is still the same at 1024 bits per cycle, but programs will need to use AVX-512 to get there. Having fewer, wider vector integer ports may cut down on power because fewer operations are sent from the schedulers and fewer distinct register file reads happen for the same number of compute operations. But prior Zen generations are just a bit more nimble in that regard.</p>
<h3>Integer Execution</h3>
<p>Scalar integer execution goes in the opposite direction. Zen 5 has one big unified 88 entry scheduler, capable of selecting six operations per cycle to feed the core’s six integer execution ports. It reminds me of big unified schedulers from Intel’s Core line. Meteor Lake’s Redwood Cove uses a 96 entry scheduler to feed six integer execution ports. Zen 5 uses separate ports and schedulers for its vector/FP units, but the size and port count of both schedulers is quite similar.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30719"><img loading="lazy" decoding="async" width="568" height="497" data-attachment-id="30719" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_int_sched-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_int_sched.drawio.jpg?fit=568%2C497&amp;ssl=1" data-orig-size="568,497" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_int_sched.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_int_sched.drawio.jpg?fit=568%2C497&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_int_sched.drawio.jpg?fit=568%2C497&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_int_sched.drawio.jpg?resize=568%2C497&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Prior Zen generations and Intel’s E-Core line use a more distributed scheduling scheme. Using separate schedulers means each scheduler doesn’t have to select as many operations per cycle. But that often makes schedulers more specific to certain operations, which increases the risk of filling up one scheduling queue and causing the renamer to stall, even if scheduling entries are available in other queues.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30722"><img loading="lazy" decoding="async" width="688" height="259" data-attachment-id="30722" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/z5_unified_sch-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?fit=867%2C327&amp;ssl=1" data-orig-size="867,327" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="z5_unified_sch.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?fit=867%2C327&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?fit=688%2C259&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?resize=688%2C259&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?w=867&amp;ssl=1 867w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/z5_unified_sch.drawio.jpg?resize=768%2C290&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Using a unified scheduler also makes it possible to assign operations to execution ports right before they’re issued to those execution units, rather than at the renamer. That can provide additional flexibility, avoiding corner cases where several ops in one scheduler become ready, but all of them experience contention for that scheduler’s port. A unified scheduler <a href="https://stackoverflow.com/questions/40681331/how-are-x86-uops-scheduled-exactly">doesn’t necessarily mean</a> port selection happens right as micro-ops become ready, but AMD did talk about that in an interview so Zen 5 likely does this.</p>
<h3>Address Generation</h3>
<p>Memory operations get their addresses generated by for address generation units (AGUs), which are fed by a unified 58 entry scheduler. Zen 4 could technically give more scheduler capacity to memory operations, but those entries had to be shared by integer math operations.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30729"><img loading="lazy" decoding="async" width="416" height="568" data-attachment-id="30729" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_agu_sched/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_agu_sched.jpg?fit=416%2C568&amp;ssl=1" data-orig-size="416,568" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_agu_sched" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_agu_sched.jpg?fit=416%2C568&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_agu_sched.jpg?fit=416%2C568&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_agu_sched.jpg?resize=416%2C568&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Zen 5 is therefore a bit like Zen 2, with a unified AGU scheduler separate from the integer units. Of course, Zen 5’s AGU scheduler has about twice as much capacity as Zen 2’s, and feeds four ports instead of three. The four AGUs let Zen 5 sustain four scalar integer memory accesses per cycle. All four can be loads, and up to two can be stores.</p>
<h3>Memory Dependencies and Alignment</h3>
<p>After calculating addresses, the load/store unit has to ensure memory operations appear to execute in the correct order. If a program loads data from a memory address that it wrote to soon before, the load might have to get its data from an in-flight store rather than the cache hierarchy. Like prior Zen CPUs, Zen 5 can do fast store forwarding as long as the load is contained within the prior store. The most common and trivial case of an exact address match is handled with zero latency, carrying forward a feature introduced with Zen 3. Because Zen 5 has four AGUs, it can do zero latency forwarding for two dependent load-store pairs. Zen 3 and Zen 4 could only do so for one pair at a time. Intel’s Golden Cove has similar behavior for the exact address match case, but can’t do zero latency forwarding if both the load and store cross a 64B boundary.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30737"><img loading="lazy" decoding="async" width="688" height="334" data-attachment-id="30737" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_stlf/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?fit=2718%2C1321&amp;ssl=1" data-orig-size="2718,1321" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_stlf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?fit=2560%2C1244&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?fit=688%2C334&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=688%2C334&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?w=2718&amp;ssl=1 2718w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=768%2C373&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=1536%2C747&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=2048%2C995&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=1200%2C583&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=1600%2C778&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?resize=1320%2C642&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_stlf.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Store to load forwarding results using Henry Wong’s <a href="https://blog.stuffedcow.net/2014/01/x86-memory-disambiguation/">methodology</a> </figcaption></figure></div>
<p>Cases where the load is contained within the store are handled with 7 cycle latency. Zen 4 was a bit faster because it could occasionally do that with 6 cycle latency. Intel’s Golden Cove could do that with 5 cycle latency, but fares worse if fast store forwarding fails due to a partial overlap. Golden Cove suffers a 19-20 cycle penalty in that case, higher than Zen 4’s 18 cycle penalty and much higher than Zen 5’s 14 cycle penalty.</p>
<div>
<figure><a href="https://chipsandcheese.com/zen4_stlf-2/"><img loading="lazy" decoding="async" width="688" height="301" data-attachment-id="20370" data-permalink="https://chipsandcheese.com/zen4_stlf-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?fit=2718%2C1189&amp;ssl=1" data-orig-size="2718,1189" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_stlf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?fit=2560%2C1120&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?fit=688%2C301&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=688%2C301&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?w=2718&amp;ssl=1 2718w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=768%2C336&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=1536%2C672&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=2048%2C896&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=1200%2C525&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=1600%2C700&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?resize=1320%2C577&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/zen4_stlf.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>And results from Zen 4</figcaption></figure></div>
<p>Looking at independent loads and stores shows that Zen 5’s data cache has 64 byte alignment for both loads and stores. That reduces throughput losses from misaligned stores. AMD used 32 byte store alignment for Zen 2 through Zen 4, and 16 byte store alignment on Zen 1. All Zen generations have 64 byte load alignment.</p>
<p>The penalty for a misaligned store has gone down too, with Zen 5 able to handle a misaligned store every cycle. Maybe Zen 5’s data cache has two write ports.</p>
<h3>Address Translation</h3>
<p>Programs use virtual addresses, which have to be translated on-the-fly to addresses in physical memory. CPUs speed this up by caching recently used translations in TLBs, or translation lookaside buffers. Zen 5 increases TLB sizes to reduce address translation delays. </p>
<p>AMD uses separate TLB hierarchies for instruction and data. Zen 5’s instruction side sees its L2 TLB quadruple in size, while the data side gets 33% TLB capacity increases on both levels.</p>
<figure><table><tbody><tr><td></td><td>Zen 5</td><td>Zen 4</td><td>Intel Redwood Cove</td></tr><tr><td>Instruction TLB</td><td>L1: 64 entry fully associative<br>L2: 2048 entry</td><td>L1: 64 entry fully associative<br>L2: 512 entry</td><td>L1: 128 entry 8-way<br>L2: Shared with L2 Data TLB</td></tr><tr><td>L1 Data TLB</td><td>96 entry fully associative</td><td>72 entry fully associative</td><td>Loads: 96 entry 6-way<br>Stores: 16 entry fully associative</td></tr><tr><td>L2 Data TLB</td><td>4096 entry</td><td>3072 entry 24-way</td><td>2048 entry 8-way<br>Shared with instruction accesses</td></tr></tbody></table></figure>
<p>Getting a translation from Zen 5’s L2 DTLB costs 7 extra cycles, the same as on Zen 4. AMD has therefore managed a substantial L2 TLB size increase with no latency penalty. Intel has a smaller L2 TLB, which is also shared with instruction accesses. Redwood Cove’s L2 TLB latency is also 7 cycles. Intel’s caching capacity for address translations comes up short compared to AMD’s, which can increase memory access latency seen by software.</p>
<h2>Cache and Memory Access</h2>
<p>Good caching is vital to performance. Zen 5 uses a familiar triple level cache hierarchy, but AMD has made the L1 data cache bigger. Even though the L1D grows from 32 to 48 KB, latency remains at 4 cycles. Load bandwidth is still capped at 64 bytes per cycle, but store bandwidth has gone from 32 to 64 bytes per cycle. AMD has thus increased per-cycle L1D bandwidth for the first time since Zen 2.</p>
<figure><img loading="lazy" decoding="async" width="688" height="387" data-attachment-id="30688" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_ldst_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?fit=1918%2C1078&amp;ssl=1" data-orig-size="1918,1078" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_ldst_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?fit=1918%2C1078&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?fit=688%2C387&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?w=1918&amp;ssl=1 1918w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=1536%2C863&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=1200%2C674&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=1600%2C899&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?resize=1320%2C742&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_ldst_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>Bandwidth increases continue to Zen 5’s L2 cache, which has 64 byte per cycle read and write paths. Exercising both paths with a read-modify-write pattern achieves about 85 bytes per cycle with L2-sized arrays. While not quite 128 bytes per cycle, it’s comfortably above the 64 bytes per cycle that Zen 4 is limited to.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30755"><img loading="lazy" decoding="async" width="688" height="308" data-attachment-id="30755" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_st_bw-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?fit=1113%2C499&amp;ssl=1" data-orig-size="1113,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_st_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?fit=1113%2C499&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?fit=688%2C308&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?resize=688%2C308&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?w=1113&amp;ssl=1 1113w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_st_bw-1.png?resize=768%2C344&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>From L3, a single core can achieve 32 bytes per cycle with only reads or only writes, or 64 bytes per cycle with an even mix of both. L3 bandwidth in this case is capped by the core’s 32 byte per cycle interface to the intra-CCX interconnect. It’s a bit better than Zen 4, which couldn’t quite hit 32 bytes per cycle from L3 with a single core active.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30769"><img loading="lazy" decoding="async" width="688" height="385" data-attachment-id="30769" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_cache_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?fit=1277%2C715&amp;ssl=1" data-orig-size="1277,715" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_cache_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?fit=1277%2C715&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?fit=688%2C385&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?resize=688%2C385&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?w=1277&amp;ssl=1 1277w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_cache_slide.png?resize=1200%2C672&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>With all cores in play, Zen 5’s mild hybrid setup gives it a cache bandwidth edge over Intel’s Meteor Lake. Even though Meteor Lake has 16 cores to Strix Point’s 12, all eight of Strix Point’s area optimized cores use the same architecture as their high performance counterparts and have the same 64 bytes per cycle of load bandwidth. Meteor Lake’s Crestmont efficiency cores can only load 32 bytes per cycle from their data caches. The gap widens at lower cache levels, where Intel has four E-Cores share a L2 instance with 64 bytes per cycle of bandwidth.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30756"><img loading="lazy" decoding="async" width="688" height="359" data-attachment-id="30756" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_mt_bw/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?fit=1233%2C644&amp;ssl=1" data-orig-size="1233,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_mt_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?fit=1233%2C644&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?fit=688%2C359&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?resize=688%2C359&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?w=1233&amp;ssl=1 1233w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?resize=768%2C401&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_mt_bw.png?resize=1200%2C627&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>DRAM bandwidth is similar, with Intel’s Core Ultra 7 155H getting 83 GB/s to Strix Point’s 79.9 GB/s. It’s not a big difference, and both chips enjoy plenty of bandwidth from their LPDDR5 setups.</p>
<h3>Latency</h3>
<p>Zen 5’s cache latency characteristics don’t change much compared to Zen 4, which is great because Zen 4 generally does well in that regard. The Zen 5 cluster takes 2-3 extra cycles to access its larger 16 MB L3 cache, but it’s a very minor difference and well worth the extra capacity the cache provides. AMD’s work on the L2 is appreciated too, as they’ve managed to keep latency at 14 cycles despite increasing associativity from 8-way to 16-way.</p>
<figure><img loading="lazy" decoding="async" width="688" height="303" data-attachment-id="30761" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strixpoint_zen5c_latency_cycles/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?fit=1011%2C445&amp;ssl=1" data-orig-size="1011,445" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strixpoint_zen5c_latency_cycles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?fit=1011%2C445&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?fit=688%2C303&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?resize=688%2C303&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?w=1011&amp;ssl=1 1011w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_zen5c_latency_cycles.png?resize=768%2C338&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>Actual latency is of course much better on the high performance Zen 5 cluster thanks to higher clock speeds. Against Intel’s Redwood Cove, Zen 5 enjoys better latency at every level in the memory hierarchy. Sometimes though, Intel can have an advantage because Meteor Lake gives its P-Cores access to more cache capacity. Intel’s L2 is larger of course, at 2 MB versus 1 MB on AMD. And Meteor Lake can give one core access to 24 MB of L3 capacity while Strix Point splits its 24 MB of L3 into separate instances.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30767"><img loading="lazy" decoding="async" width="688" height="309" data-attachment-id="30767" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strixpoint_latency-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?fit=1012%2C455&amp;ssl=1" data-orig-size="1012,455" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strixpoint_latency" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?fit=1012%2C455&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?fit=688%2C309&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?resize=688%2C309&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?w=1012&amp;ssl=1 1012w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strixpoint_latency-1.png?resize=768%2C345&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>DRAM latency is around 128 ns on the Ryzen AI 9 HX 370. It’s better than Intel’s Core Ultra 7 155H, which sees 148 ns of memory latency. Even though both chips use a similar LPDDR5 configuration at first glance and achieve similar bandwidth figures, AMD somehow gets better latency. However, even AMD’s LPDDR5 controller suffers much higher latency than DDR5. The 7950X3D with DDR5-5600 for example has well under 100 ns of DRAM latency.</p>
<h2>Some Light Benchmarking</h2>
<p>Detailed performance benchmarking is best left to mainstream tech outlets, which have more time and resources. Still, it’s interesting to look at how Zen 5 stacks up against Intel’s current Meteor Lake architecture. I’m testing Meteor Lake in my Asus Zenbook 14 OLED. I’ve also run the video encoding test on my Ryzen 7950X3D desktop, locked to the non-VCache die and with clock speeds capped to 5.15 GHz.</p>
<div>
<figure><a href="https://chipsandcheese.com/strix_libx264/"><img loading="lazy" decoding="async" width="688" height="274" data-attachment-id="30789" data-permalink="https://chipsandcheese.com/strix_libx264/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?fit=958%2C382&amp;ssl=1" data-orig-size="958,382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strix_libx264" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?fit=958%2C382&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?fit=688%2C274&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?resize=688%2C274&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?w=958&amp;ssl=1 958w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264.png?resize=768%2C306&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Affinity set to four highest performance cores on the mobile platforms</figcaption></figure></div>
<p>Even with the same core count and maximum clock frequency, desktop Zen 4 comfortably pulls ahead of mobile Zen 5. In a desktop platform, a Zen 4 core has access to twice as much L3 cache and lower latency DDR5. That goes to show how important the memory subsystem is. Against Intel, Strix Point comfortably smashes Meteor Lake in a matched core count test.</p>
<div>
<figure><a href="https://chipsandcheese.com/strix_libx264_ipc/"><img loading="lazy" decoding="async" width="688" height="275" data-attachment-id="30791" data-permalink="https://chipsandcheese.com/strix_libx264_ipc/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?fit=955%2C382&amp;ssl=1" data-orig-size="955,382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strix_libx264_ipc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?fit=955%2C382&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?fit=688%2C275&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?resize=688%2C275&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?w=955&amp;ssl=1 955w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_ipc.png?resize=768%2C307&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>AMD’s AVX-512 support is a factor in this test. Without AVX-512 support, Intel has to execute about 10% more instructions to complete the workload. Intel can’t clock as high as AMD can either. Therefore, Redwood Cove falls behind even though it’s averaging more instructions per cycle. Seeing AMD take the lead with AVX-512 being a factor is weird. Intel released the first AVX-512 capable CPUs on the market, and AMD’s AVX-512 implementation still feels conservative.</p>
<p>AMD has invested a lot of core area into their branch predictor since Zen 2, and <a href="https://chipsandcheese.com/2021/02/22/analyzing-zen-2s-cinebench-r15-lead/">it has paid off in the past</a>. Zen 5 keeps pushing on that area, but might be running into diminishing returns. </p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30794"><img loading="lazy" decoding="async" width="688" height="274" data-attachment-id="30794" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/strix_libx264_bpu_accuracy-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?fit=955%2C380&amp;ssl=1" data-orig-size="955,380" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="strix_libx264_bpu_accuracy" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?fit=955%2C380&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?fit=688%2C274&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?resize=688%2C274&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?w=955&amp;ssl=1 955w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/strix_libx264_bpu_accuracy-1.png?resize=768%2C306&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Zen 5’s branch predictor may be more accurate, but in this workload the difference is so small it’s within margin of error. More capable branch predictors run into diminishing returns.</p>
<h2>Final Words</h2>
<p>Zen 5 makes sweeping changes throughout the pipeline. The core gets wider, boasts more reordering capacity, and improves caching capacity within the core without taking a latency hit. That’s not just for data. Zen 5 can cache more address translations in its TLBs, and more branch targets in its BTBs. Latency has even gone down in some cases. Being able to deal with 1024 branches in flight with effectively 0.5 cycle latency is an impressive achievement. A lower penalty for failed store forwarding suggests AMD was able to cut down pipeline length between address calculation and store retirement, since that’s a straightforward way to fall back when fast store forwarding fails.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30796"><img loading="lazy" decoding="async" width="688" height="386" data-attachment-id="30796" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_overview_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?fit=1277%2C716&amp;ssl=1" data-orig-size="1277,716" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_overview_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?fit=1277%2C716&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?w=1277&amp;ssl=1 1277w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_overview_slide.png?resize=1200%2C673&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Considering other significant changes like a clustered frontend, different scheduler layout, more execution units, and extra cache bandwidth makes me feel like Zen 5 involved a lot of engineering effort. It’s a refreshing contrast compared to Intel Meteor Lake’s Redwood Cove and Crestmont, which made very minor changes over Raptor Lake and Alder Lake’s respective P and E cores.</p>
<p>Another contrast with Intel is AMD’s focus on SMT. Intel has indicated a shift away from SMT, at least for mobile products like their upcoming Lunar Lake. Implementing SMT by itself doesn’t cost a lot of area or power. But optimizing a core for SMT can involve increasing core structure sizes to ensure each thread gets a healthy amount of entries when two SMT threads are active. Intel decided their hybrid strategy could deliver high multithreaded performance without having to chase diminishing returns further than they wanted to for a single thread. </p>
<figure><img loading="lazy" decoding="async" width="688" height="386" data-attachment-id="30798" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/zen5_hybrid/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?fit=1276%2C715&amp;ssl=1" data-orig-size="1276,715" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_hybrid" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?fit=1276%2C715&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?w=1276&amp;ssl=1 1276w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/zen5_hybrid.jpg?resize=1200%2C672&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>AMD takes the opposite approach. Zen 5 seems to be designed with a strong focus on SMT. Certain parts of the core like the renamer and decoders need two threads active to achieve their full potential. AMD still emphasizes single threaded performance of course, but they’re chasing multithreaded performance with a combination of density optimized physical implementations and SMT, rather than different core architectures. That strategy does come with some advantages, like keeping AVX-512 enabled across the company’s CPU lineup. Maybe AMD is wise to twist the knife while Intel inexplicably refuses to add AVX-512 support to its E-Core line.</p>
<p>These contrasting approaches show there’s often no clear right or wrong choice when it comes to CPU architecture. Intel and AMD both have a lot of smart engineers. Both have gone in different directions when choosing between unified and distributed schedulers, whether to prioritize SMT, or how to create a hybrid core setup. Those decisions change even within the same company. AMD went from a 256-bit vector register file, to a fully 512-bit one, and then to a lopsided one with both 256-bit and 512-bit entries. Another choice is how to balance performance per clock gains against clock speed. Zen 5 de-prioritizes the latter, since Strix Point barely clocks higher than Phoenix.</p>
<p>Therefore Zen 5’s performance gains are lower compared to prior Zen generations due to a lack of an increase in clock speed, even though the headline IPC gain is in-line with what those prior generations offered. Hopefully Zen 5 sets a solid foundation for AMD to build future CPUs off.</p>
<div>
<figure><img loading="lazy" decoding="async" width="688" height="464" data-attachment-id="30861" data-permalink="https://chipsandcheese.com/2024/08/10/amds-strix-point-zen-5-hits-mobile/image-91/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?fit=1941%2C1310&amp;ssl=1" data-orig-size="1941,1310" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?fit=1941%2C1310&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?fit=688%2C464&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=688%2C464&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?w=1941&amp;ssl=1 1941w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=768%2C518&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=1536%2C1037&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=1200%2C810&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=1600%2C1080&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?resize=1320%2C891&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/08/image-1.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure></div>
<p>Again, we would like to thank ASUS for sending us over a ProArt PX13 for review and if you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">
<p><span>
<ul>
<li>
<div>
<p><img alt="clamchowder" src="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80"> </p>
</div>

</li>
</ul>
</span>
</p></div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stapler: I remade a 32 year old classic Macintosh app (140 pts)]]></title>
            <link>https://blog.gingerbeardman.com/2024/08/10/stapler-i-remade-a-32-year-old-classic-macintosh-app/</link>
            <guid>41212193</guid>
            <pubDate>Sat, 10 Aug 2024 21:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gingerbeardman.com/2024/08/10/stapler-i-remade-a-32-year-old-classic-macintosh-app/">https://blog.gingerbeardman.com/2024/08/10/stapler-i-remade-a-32-year-old-classic-macintosh-app/</a>, See on <a href="https://news.ycombinator.com/item?id=41212193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

          

          

          <p>A couple of days ago I was <a href="https://news.ycombinator.com/item?id=41192547">reading on Hacker News about a feature in some <em>Linux</em> window managers where they allow collections of tabs from different apps</a>.</p>

<p>This reminded me of <em>BeOS</em>, but at the same time it reminded me of an app from 1992 for classic <em>Macintosh</em> called <a href="https://macintoshgarden.org/apps/stapler-11"><em>Stapler</em></a>, and how <a href="https://twitter.com/gingerbeardman/status/1590051288951443456">I’d talked about that</a> and <a href="https://twitter.com/gingerbeardman/status/1596573654674034691">it’s one-time spiritual successor</a> <a href="http://hasseg.org/launchList/"><em>LaunchList</em></a> on Twitter in the past. These were both similar apps that allowed you to collect and launch all the apps, files, folders, documents, related to a specific task, thus saving time. Or as Ali&nbsp;Rantakari so succinctly put it in 2009: “<a href="http://hasseg.org/blog/post/249/launching-lots-of-stuff-at-once-on-your-mac/">Opening a Bunch of Stuff at Once on Your Mac</a>”.</p>

<p>So over the past day or so I built my own take on this concept for modern macOS!</p>

<p>Whilst my app is inspired by both <em>Stapler</em> (right down to the name) and <em>LaunchList</em>, my app adds improvements and features of its own and is more of a hybrid of both. For example, <em>Stapler</em> didn’t have drag and drop and <em>LaunchList</em> didn’t have zero-click auto-launch. My goal was to keep it as simple as possible, but no simpler. To that end, there are no preferences or settings in the app.</p>

<p>Full details, download, and usage are at the GitHub repo: <a href="https://github.com/gingerbeardman/stapler">github.com/gingerbeardman/stapler</a></p>

<hr>

<p><img src="https://cdn.gingerbeardman.com/images/posts/stapler.png" alt="PNG" title="Stapler, for modern macOS (14.0 or newer)" loading="lazy"></p>

<hr>

<h2 id="tell-me-more">Tell me more</h2>

<p>The idea is you set up a <em>Stapler Document</em> per project containing related apps, files, folders, etc. Then you can open them all at once by launching the single document. Each document contains a list of aliases that can be managed, inspected, launched using the app. The key time-saver is that if you launch a <em>Stapler Document</em> directly, all the items in its list will automatically be launched. Cool!</p>

<ul>
  <li>Work: text editor, run current game, pixel art editor, bitmap font app, todo list</li>
  <li>Play: Music app, Hacker News app, Twitter app, script to position windows</li>
  <li>Movie: run Caffeine to keep your computer on, shortcut to put displays to sleep</li>
</ul>

<p>It’s an odd way of thinking about working on a computer—it’s task-based rather than app-based or document-based. Indeed, some might say it’s an outdated way of approaching things. But I’m always banging the drum about there being so much good stuff that was prematurely left behind along with the memories of System 7 (<a href="https://blog.gingerbeardman.com/2021/04/17/turning-an-ipad-pro-into-the-ultimate-classic-macintosh/">though I still use that</a>), <em>BeOS</em>, <em>OS/2</em>, <em>Amiga</em> <em>Workbench</em>, <em>GEM</em> and the many alternative desktops of <em>Atari ST</em>, etc. So I thought I’d see if I could walk the walk as well as talk the talk.</p>

<h2 id="details">Details</h2>

<p>It’s written in <em>Swift</em> and <em>SwiftUI</em> and weighs in at 640KB, about one third of which is a multitude of icon files at many different sizes and resolutions. By creating a Document-Based App you get a ton of functionality for free, such as document/tab/window management, undo/redo (though I still needed to watch for it and refresh the app window), and much more.</p>

<p>Dealing with files was both cool and annoying, cool that you can get aliases and bookmarks to files so easily, but annoying that you have to jump through so many hoops to work around the security and sandbox protections and end up having to do file requests in a very long-winded way, and then there’s having to tweak plist entries to give the app just the right permissions. I’m using some features of <em>SwiftUI</em> that mean the app can’t run on anything before macOS 14 Sonoma. All-in-all I’d say modern macOS development is a bit of a mixed bag. Take it or leave it.</p>

<h2 id="icon">Icon</h2>

<p>Given that this was a quick weekend project, I kind of lost steam when it came to the icon. I’d love a better app icon, as well as a specific document icon, so any <a href="https://github.com/gingerbeardman/stapler/issues/1">icon designers can step this way</a>.</p>

<blockquote>
  <h2 id="thanks">Thanks</h2>

  <p>My good friend Dave Roberts (Serendipity App Company) for brainstorming why it was so damned difficult to get the app to react differently when a document was opened from Finder. Rip it up and start again! To Dustin Mierau for kickstarting this trend of remaking forgotten old apps for modern macOS. And eternal thanks to <a href="https://twitter.com/chrispatterson/status/1822396663425532259">Chris Patterson</a> and Ali Rantakari for their apps.</p>
</blockquote>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things I Won't Work With: Dimethylcadmium (2013) (214 pts)]]></title>
            <link>https://www.science.org/content/blog-post/things-i-won-t-work-dimethylcadmium</link>
            <guid>41211540</guid>
            <pubDate>Sat, 10 Aug 2024 19:11:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/blog-post/things-i-won-t-work-dimethylcadmium">https://www.science.org/content/blog-post/things-i-won-t-work-dimethylcadmium</a>, See on <a href="https://news.ycombinator.com/item?id=41211540">Hacker News</a></p>
Couldn't get https://www.science.org/content/blog-post/things-i-won-t-work-dimethylcadmium: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DEF CON's response to the badge controversy (232 pts)]]></title>
            <link>https://old.reddit.com/r/Defcon/comments/1ep00ln/def_cons_response_to_the_badge_controversy/</link>
            <guid>41211519</guid>
            <pubDate>Sat, 10 Aug 2024 19:07:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/Defcon/comments/1ep00ln/def_cons_response_to_the_badge_controversy/">https://old.reddit.com/r/Defcon/comments/1ep00ln/def_cons_response_to_the_badge_controversy/</a>, See on <a href="https://news.ycombinator.com/item?id=41211519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>DEF CON thrives on community collaboration and has operated for over 30 years successfully working with hundreds of vendors including the dozens that have helped with our badges over the years. For this year’s Raspberry Pi badges, DEF CON hired Entropic Engineering to do the hardware development and firmware. After going overbudget by more than 60%, several bad-faith charges, and with a product still in preproduction, DEF CON issued a stop work order. Any claims that DEF CON did not pay Entropic Engineering for its hardware or firmware development are false. Unfortunately, we heard that these issues with Entropic Engineering were not unique to DEF CON. We decided at that point to finish the badge on our own. We paid to send engineers to Vietnam to work onsite to finalize and test the badges in order to ensure they would be done on time for the conference. We never removed Entropic Engineering’s logo from our badge, it is still on the PCB. However, Entropic was not involved in the design and production of the case, and we removed their logo we had added as a courtesy.</p>

<p>We were happy to still include one of their contractors on the badge panel session. Unfortunately, shortly before the talk was set to take place DEF CON became aware that unauthorized code had been included in the firmware we had paid Entropic Engineering to produce, claiming credit for the whole badge and promoting their coin wallet to solicit money from DEF CON attendees above and beyond what we had negotiated. When asked about the unauthorized code, the engineer said it had been done as a “joke” two months ago and forgot to remove it, and we decided as an organization not to have him on stage while we kept the slides in the talk giving him credit for his work. We communicated the change in advance of the talk, and this individual decided to show up for the panel anyway. He refused to leave, demanding that our security team remove him. Wanting to ensure that the other people involved in creating the badge were able to deliver their presentation, we complied with his wishes and escorted him off the stage, where he was free to continue attending the conference.</p>

<p>Any issues of non-payment are between him and Entropic Engineering, DEF CON fulfilled its financial obligations.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Jeff Bezos and Amazon tried to imprison my husband" (211 pts)]]></title>
            <link>https://twitter.com/Amy_K_Nelson/status/1822318185556648348</link>
            <guid>41211437</guid>
            <pubDate>Sat, 10 Aug 2024 18:53:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Amy_K_Nelson/status/1822318185556648348">https://twitter.com/Amy_K_Nelson/status/1822318185556648348</a>, See on <a href="https://news.ycombinator.com/item?id=41211437">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Apple. Apple Please (145 pts)]]></title>
            <link>https://digipres.club/@misty/112927898002214724</link>
            <guid>41211235</guid>
            <pubDate>Sat, 10 Aug 2024 18:14:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digipres.club/@misty/112927898002214724">https://digipres.club/@misty/112927898002214724</a>, See on <a href="https://news.ycombinator.com/item?id=41211235">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Pg_replicate – Build Postgres replication applications in Rust (165 pts)]]></title>
            <link>https://github.com/supabase/pg_replicate</link>
            <guid>41209994</guid>
            <pubDate>Sat, 10 Aug 2024 15:00:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/supabase/pg_replicate">https://github.com/supabase/pg_replicate</a>, See on <a href="https://news.ycombinator.com/item?id=41209994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">About <code>pg_replicate</code></h2><a id="user-content-about-pg_replicate" aria-label="Permalink: About pg_replicate" href="#about-pg_replicate"></a></p>
<p dir="auto"><code>pg_replicate</code> is a Rust crate to quickly build replication solutions for Postgres. It provides building blocks to construct data pipelines which can continually copy data from Postgres to other systems. It builds abstractions on top of Postgres's <a href="https://www.postgresql.org/docs/current/protocol-logical-replication.html" rel="nofollow">logical streaming replication protocol</a> and pushes users towards the pit of success without letting them worry about low level details of the protocol.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">To quickly try out <code>pg_replicate</code>, you can run the <code>stdout</code> example, which will replicate the data to standard output. First, create a publication in Postgres which includes the tables you want to replicate:</p>
<div data-snippet-clipboard-copy-content="create publication my_publication
for table table1, table2;"><pre><code>create publication my_publication
for table table1, table2;
</code></pre></div>
<p dir="auto">Then run the <code>stdout</code> example:</p>
<div data-snippet-clipboard-copy-content="cargo run --example stdout -- --db-host localhost --db-port 5432 --db-name postgres --db-username postgres --db-password password cdc my_publication stdout_slot"><pre><code>cargo run --example stdout -- --db-host localhost --db-port 5432 --db-name postgres --db-username postgres --db-password password cdc my_publication stdout_slot
</code></pre></div>
<p dir="auto">In the above example, <code>pg_replicate</code> connects to a Postgres database named <code>postgres</code> running on <code>localhost:5432</code> with a username <code>postgres</code> and password <code>password</code>. The slot name <code>stdout_slot</code> will be created by <code>pg_replicate</code> automatically.</p>
<p dir="auto">Refer to the <a href="https://github.com/imor/pg_replicate/tree/main/pg_replicate/examples">examples</a> folder to run examples for sinks other than <code>stdout</code> (currently only <code>bigquery</code> and <code>duckdb</code> supported). A quick tip: to see all the command line options, run the example wihout any options specified, e.g. <code>cargo run --example bigquery</code> will print the detailed usage instructions for the <code>bigquery</code> sink.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">To use <code>pg_replicate</code> in your Rust project, add it via a git dependency in <code>Cargo.toml</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
pg_replicate = { git = &quot;https://github.com/imor/pg_replicate&quot; }"><pre>[<span>dependencies</span>]
<span>pg_replicate</span> = { <span>git</span> = <span><span>"</span>https://github.com/imor/pg_replicate<span>"</span></span> }</pre></div>
<p dir="auto">The git dependency is needed for now because <code>pg_replicate</code> is not yet published on crates.io. You'd also need to add a dependency to tokio:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
...
tokio = { version = &quot;1.38&quot; }"><pre>[<span>dependencies</span>]
<span>...</span>
<span>tokio</span> = { <span>version</span> = <span><span>"</span>1.38<span>"</span></span> }</pre></div>
<p dir="auto">Now your <code>main.rs</code> can have code like the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use std::error::Error;

use pg_replicate::pipeline::{
    data_pipeline::DataPipeline,
    sinks::stdout::StdoutSink,
    sources::postgres::{PostgresSource, TableNamesFrom},
    PipelineAction,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    let host = &quot;localhost&quot;;
    let port = 5432;
    let database = &quot;postgres&quot;;
    let username = &quot;postgres&quot;;
    let password = Some(&quot;password&quot;.to_string());
    let slot_name = Some(&quot;my_slot&quot;.to_string());
    let table_names = TableNamesFrom::Publication(&quot;my_publication&quot;.to_string());

    // Create a PostgresSource
    let postgres_source = PostgresSource::new(
        host,
        port,
        database,
        username,
        password,
        slot_name,
        table_names,
    )
    .await?;

    // Create a StdoutSink. This sink just prints out the events it receives to stdout
    let stdout_sink = StdoutSink;

    // Create a `DataPipeline` to connect the source to the sink
    let mut pipeline = DataPipeline::new(postgres_source, stdout_sink, PipelineAction::Both);

    // Start the `DataPipeline` to start copying data from Postgres to stdout
    pipeline.start().await?;

    Ok(())
}
"><pre><span>use</span> std<span>::</span>error<span>::</span><span>Error</span><span>;</span>

<span>use</span> pg_replicate<span>::</span>pipeline<span>::</span><span>{</span>
    data_pipeline<span>::</span><span>DataPipeline</span><span>,</span>
    sinks<span>::</span>stdout<span>::</span><span>StdoutSink</span><span>,</span>
    sources<span>::</span>postgres<span>::</span><span>{</span><span>PostgresSource</span><span>,</span> <span>TableNamesFrom</span><span>}</span><span>,</span>
    <span>PipelineAction</span><span>,</span>
<span>}</span><span>;</span>

<span>#<span>[</span>tokio<span>::</span>main<span>]</span></span>
<span>async</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; <span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>,</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>Error</span><span>&gt;</span><span>&gt;</span> <span>{</span>
    <span>let</span> host = <span>"localhost"</span><span>;</span>
    <span>let</span> port = <span>5432</span><span>;</span>
    <span>let</span> database = <span>"postgres"</span><span>;</span>
    <span>let</span> username = <span>"postgres"</span><span>;</span>
    <span>let</span> password = <span>Some</span><span>(</span><span>"password"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> slot_name = <span>Some</span><span>(</span><span>"my_slot"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> table_names = <span>TableNamesFrom</span><span>::</span><span>Publication</span><span>(</span><span>"my_publication"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>// Create a PostgresSource</span>
    <span>let</span> postgres_source = <span>PostgresSource</span><span>::</span><span>new</span><span>(</span>
        host<span>,</span>
        port<span>,</span>
        database<span>,</span>
        username<span>,</span>
        password<span>,</span>
        slot_name<span>,</span>
        table_names<span>,</span>
    <span>)</span>
    <span>.</span><span>await</span>?<span>;</span>

    <span>// Create a StdoutSink. This sink just prints out the events it receives to stdout</span>
    <span>let</span> stdout_sink = <span>StdoutSink</span><span>;</span>

    <span>// Create a `DataPipeline` to connect the source to the sink</span>
    <span>let</span> <span>mut</span> pipeline = <span>DataPipeline</span><span>::</span><span>new</span><span>(</span>postgres_source<span>,</span> stdout_sink<span>,</span> <span>PipelineAction</span><span>::</span><span>Both</span><span>)</span><span>;</span>

    <span>// Start the `DataPipeline` to start copying data from Postgres to stdout</span>
    pipeline<span>.</span><span>start</span><span>(</span><span>)</span><span>.</span><span>await</span>?<span>;</span>

    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span></pre></div>
<p dir="auto">For more examples, please refer to the <a href="https://github.com/imor/pg_replicate/tree/main/pg_replicate/examples">examples</a> folder in the source.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Repository Structure</h2><a id="user-content-repository-structure" aria-label="Permalink: Repository Structure" href="#repository-structure"></a></p>
<p dir="auto">The repository is a cargo workspace. Each of the individual sub-folders are crate in the workspace. A brief explanation of each crate is as follows:</p>
<ul dir="auto">
<li><code>api</code> - REST api used for hosting <code>pg_replicate</code> in a cloud environment.</li>
<li><code>config-types</code> - Common types for configuration used in projects across the workspace.</li>
<li><code>pg_replicate</code> - The main library crate containing the core logic.</li>
<li><code>replicator</code> - A binary crate using <code>pg_replicate</code>. Packaged as a docker container for use in cloud hosting.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto"><code>pg_replicate</code> is still under heavy development so expect bugs and papercuts but overtime we plan to add the following sinks.</p>
<ul>
<li> Add BigQuery Sink</li>
<li> Add DuckDb Sink</li>
<li> Add MotherDuck Sink</li>
<li> Add Snowflake Sink</li>
<li> Add ClickHouse Sink</li>
<li> Many more to come...</li>
</ul>
<p dir="auto">Note: DuckDb and MotherDuck sinks do no use the batched pipeline, hence they currently perform poorly. A batched pipeline version of these sinks is planned.</p>
<p dir="auto">See the <a href="https://github.com/imor/pg_replicate/issues">open issues</a> for a full list of proposed features (and known issues).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Distributed under the Apache-2.0 License. See <code>LICENSE</code> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker</h2><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">To create the docker image for <code>replicator</code> run <code>docker build -f ./replicator/Dockerfile .</code> from the root of the repo. Similarly, to create the docker image for <code>api</code> run <code>docker build -f ./api/Dockerfile .</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design</h2><a id="user-content-design" aria-label="Permalink: Design" href="#design"></a></p>
<p dir="auto">Applications can use data sources and sinks from <code>pg_replicate</code> to build a data pipeline to continually copy data from the source to the sink. For example, a data pipeline to copy data from Postgres to DuckDB takes about 100 lines of Rust.</p>
<p dir="auto">There are three components in a data pipeline:</p>
<ol dir="auto">
<li>A data source</li>
<li>A data sink</li>
<li>A pipline</li>
</ol>
<p dir="auto">The data source is an object from where data will be copied. The data sink is an object to which data will be copied. The pipeline is an object which drives the data copy operations from the source to the sink.</p>
<div data-snippet-clipboard-copy-content=" +----------+                       +----------+
 |          |                       |          |
 |  Source  |---- Data Pipeline --->|   Sink   |
 |          |                       |          |
 +----------+                       +----------+"><pre><code> +----------+                       +----------+
 |          |                       |          |
 |  Source  |---- Data Pipeline ---&gt;|   Sink   |
 |          |                       |          |
 +----------+                       +----------+
</code></pre></div>
<p dir="auto">So roughly you write code like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="let postgres_source = PostgresSource::new(...);
let duckdb_sink = DuckDbSink::new(..);
let pipeline = DataPipeline(postgres_source, duckdb_sink);
pipeline.start();"><pre><span>let</span> postgres_source = <span>PostgresSource</span><span>::</span><span>new</span><span>(</span>..<span>.</span><span></span><span>)</span><span>;</span>
<span>let</span> duckdb_sink = <span>DuckDbSink</span><span>::</span><span>new</span><span>(</span>..<span>)</span><span>;</span>
<span>let</span> pipeline = <span>DataPipeline</span><span>(</span>postgres_source<span>,</span> duckdb_sink<span>)</span><span>;</span>
pipeline<span>.</span><span>start</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Of course, the real code is more than these four lines, but this is the basic idea. For a complete example look at the <a href="https://github.com/imor/pg_replicate/blob/main/pg_replicate/examples/duckdb.rs">duckdb example</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Sources</h3><a id="user-content-data-sources" aria-label="Permalink: Data Sources" href="#data-sources"></a></p>
<p dir="auto">A data source is the source for data which the pipeline will copy to the data sink. Currently, the repository has only one data source: <a href="https://github.com/imor/pg_replicate/blob/main/pg_replicate/src/pipeline/sources/postgres.rs"><code>PostgresSource</code></a>. <code>PostgresSource</code> is the primary data source; data in any other source or sink would have originated from it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Sinks</h3><a id="user-content-data-sinks" aria-label="Permalink: Data Sinks" href="#data-sinks"></a></p>
<p dir="auto">A data sink is where the data from a data source is copied. There are two kinds of data sinks. Those which retain the essential nature of data coming out of a <code>PostgresSource</code> and those which don't. The former kinds of data sinks can act as a data source in future. The latter kind can't act as a data source and are data's final resting place.</p>
<p dir="auto">For instance, <a href="https://github.com/imor/pg_replicate/blob/main/pg_replicate/src/pipeline/sinks/duckdb.rs"><code>DuckDbSink</code></a> ensures that the change data capture (CDC) stream coming in from a source is materialized into tables in a DuckDB database. Once this lossy data transformation is done, it can not be used as a CDC stream again.</p>
<p dir="auto">Contrast this with a potential future sink <code>S3Sink</code> or <code>KafkaSink</code> which just copies the CDC stream as is. The data deposited in the sink can later be used as if it was coming from Postgres directly.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Pipeline</h3><a id="user-content-data-pipeline" aria-label="Permalink: Data Pipeline" href="#data-pipeline"></a></p>
<p dir="auto">A data pipeline encapsulates the business logic to copy the data from the source to the sink. It also orchestrates resumption of the CDC stream from the exact location it was last stopped at. The data sink participates in this by persisting the resumption state and returning it to the pipeline when it restarts.</p>
<p dir="auto">If a data sink is not transactional (e.g. <code>S3Sink</code>), it is not always possible to keep the CDC stream and the resumption state consistent with each other. This can result in these non-transactional sinks having duplicate portions of the CDC stream. Data pipeline helps in deduplicating these duplicate CDC events when the data is being copied over to a transactional store like DuckDB.</p>
<p dir="auto">Finally, the data pipeline reports back the log sequence number (LSN) upto which the CDC stream has been copied in the sink to the <code>PostgresSource</code>. This allows the Postgres database to reclaim disk space by removing WAL segment files which are no longer required by the data sink.</p>
<div data-snippet-clipboard-copy-content=" +----------+                       +----------+
 |          |                       |          |
 |  Source  |<---- LSN Numbers -----|   Sink   |
 |          |                       |          |
 +----------+                       +----------+"><pre><code> +----------+                       +----------+
 |          |                       |          |
 |  Source  |&lt;---- LSN Numbers -----|   Sink   |
 |          |                       |          |
 +----------+                       +----------+
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Kinds of Data Copies</h3><a id="user-content-kinds-of-data-copies" aria-label="Permalink: Kinds of Data Copies" href="#kinds-of-data-copies"></a></p>
<p dir="auto">CDC stream is not the only kind of data a data pipeline performs. There's also full table copy, aka backfill. These two kinds can be performed either together or separately. For example, a one-off data copy can use the backfill. But if you want to regularly copy data out of Postgres and into your OLAP database, backfill and CDC stream both should be used. Backfill to get the intial copies of the data and CDC stream to keep those copies up to date and changes in Postgres happen to the copied tables.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Performance</h3><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">Currently the data source and sinks copy table row and CDC events one at a time. This is expected to be slow. Batching, and other strategies will likely improve the performance drastically. But at this early stage the focus is on correctness rather than performance. There are also zero benchmarks at this stage, so commentary about performance is closer to speculation than reality.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenSnitch is a GNU/Linux interactive application firewall (330 pts)]]></title>
            <link>https://github.com/evilsocket/opensnitch</link>
            <guid>41209688</guid>
            <pubDate>Sat, 10 Aug 2024 14:15:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/evilsocket/opensnitch">https://github.com/evilsocket/opensnitch</a>, See on <a href="https://news.ycombinator.com/item?id=41209688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><p>
  Join the project community on our server!
  </p><p>
  <a href="https://discord.gg/https://discord.gg/btZpkp45gQ" title="Join our community!" rel="nofollow">
    <img src="https://camo.githubusercontent.com/549e93886be3c89143d30b3a80f7b34e8fedee957710c2481953ddde669193c6/68747470733a2f2f646362616467652e6c696d65732e70696e6b2f6170692f7365727665722f68747470733a2f2f646973636f72642e67672f62745a706b7034356751" data-canonical-src="https://dcbadge.limes.pink/api/server/https://discord.gg/btZpkp45gQ">
  </a></p></div>
<hr>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/evilsocket/opensnitch/master/ui/opensnitch/res/icon.png"><img alt="opensnitch" src="https://raw.githubusercontent.com/evilsocket/opensnitch/master/ui/opensnitch/res/icon.png" height="160"></a>
  </p><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/evilsocket/opensnitch/workflows/Build%20status/badge.svg"><img src="https://github.com/evilsocket/opensnitch/workflows/Build%20status/badge.svg"></a>
    <a href="https://github.com/evilsocket/opensnitch/releases/latest"><img alt="Release" src="https://camo.githubusercontent.com/219cfed611036fcac4f1c190954d3d0af9f7d489d2e5d69e10b2415a86f18de2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6576696c736f636b65742f6f70656e736e697463682e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/github/release/evilsocket/opensnitch.svg?style=flat-square"></a>
    <a href="https://github.com/evilsocket/opensnitch/blob/master/LICENSE.md"><img alt="Software License" src="https://camo.githubusercontent.com/d74ecd3c454461cffea50e16ee633e212ab258222b06e5fd630d34c5429c2fa5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c332d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/license-GPL3-brightgreen.svg?style=flat-square"></a>
    <a href="https://goreportcard.com/report/github.com/evilsocket/opensnitch/daemon" rel="nofollow"><img alt="Go Report Card" src="https://camo.githubusercontent.com/6d9060c6e28f36e61ee8e0f59335b109a23f9ce97e9554da72cd553a3efca3dd/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6576696c736f636b65742f6f70656e736e697463682f6461656d6f6e3f7374796c653d666c61742d737175617265" data-canonical-src="https://goreportcard.com/badge/github.com/evilsocket/opensnitch/daemon?style=flat-square"></a>
    <a href="https://repology.org/project/opensnitch/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/24dbb94e706fb18f6b34697db56522fcbe2f6172f058b05710822bd39a45a367/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f74696e792d7265706f732f6f70656e736e697463682e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/tiny-repos/opensnitch.svg"></a>
  </p>

<p dir="auto"><strong>OpenSnitch</strong> is a GNU/Linux application firewall.</p>
<p dir="auto">•• <a href="#key-features">Key Features</a> • <a href="#download">Download</a> • <a href="#installation">Installation</a> • <a href="#opensnitch-in-action">Usage examples</a> • <a href="#in-the-press">In the press</a> ••</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2742953/85205382-6ba9cb00-b31b-11ea-8e9a-bd4b8b05a236.png"><img src="https://user-images.githubusercontent.com/2742953/85205382-6ba9cb00-b31b-11ea-8e9a-bd4b8b05a236.png" alt="OpenSnitch"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key features</h2><a id="user-content-key-features" aria-label="Permalink: Key features" href="#key-features"></a></p>
<ul dir="auto">
<li>Interactive outbound connections filtering.</li>
<li><a href="https://github.com/evilsocket/opensnitch/wiki/block-lists">Block ads, trackers or malware domains</a> system wide.</li>
<li>Ability to <a href="https://github.com/evilsocket/opensnitch/wiki/System-rules">configure system firewall</a> from the GUI (nftables).
<ul dir="auto">
<li>Configure input policy, allow inbound services, etc.</li>
</ul>
</li>
<li>Manage <a href="https://github.com/evilsocket/opensnitch/wiki/Nodes">multiple nodes</a> from a centralized GUI.</li>
<li><a href="https://github.com/evilsocket/opensnitch/wiki/SIEM-integration">SIEM integration</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download</h2><a id="user-content-download" aria-label="Permalink: Download" href="#download"></a></p>
<p dir="auto">Download deb/rpm packages for your system from <a href="https://github.com/evilsocket/opensnitch/releases">https://github.com/evilsocket/opensnitch/releases</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">deb</h4><a id="user-content-deb" aria-label="Permalink: deb" href="#deb"></a></p>
<blockquote>
<p dir="auto">$ sudo apt install ./opensnitch*.deb ./python3-opensnitch-ui*.deb</p>
</blockquote>
<p dir="auto"><h4 tabindex="-1" dir="auto">rpm</h4><a id="user-content-rpm" aria-label="Permalink: rpm" href="#rpm"></a></p>
<blockquote>
<p dir="auto">$ sudo yum localinstall opensnitch-1*.rpm; sudo yum localinstall opensnitch-ui*.rpm</p>
</blockquote>
<p dir="auto">Then run: <code>$ opensnitch-ui</code> or launch the GUI from the Applications menu.</p>
<p dir="auto">Please, refer to <a href="https://github.com/evilsocket/opensnitch/wiki/Installation">the documentation</a> for detailed information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">OpenSnitch in action</h2><a id="user-content-opensnitch-in-action" aria-label="Permalink: OpenSnitch in action" href="#opensnitch-in-action"></a></p>
<p dir="auto">Examples of OpenSnitch intercepting unexpected connections:</p>
<p dir="auto"><a href="https://github.com/evilsocket/opensnitch/discussions/categories/show-and-tell">https://github.com/evilsocket/opensnitch/discussions/categories/show-and-tell</a></p>
<p dir="auto">Have you seen a connection you didn't expect? <a href="https://github.com/evilsocket/opensnitch/discussions/new?category=show-and-tell">submit it!</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">In the press</h2><a id="user-content-in-the-press" aria-label="Permalink: In the press" href="#in-the-press"></a></p>
<ul dir="auto">
<li>2017 <a href="https://twitter.com/pentestmag/status/857321886807605248" rel="nofollow">PenTest Magazine</a></li>
<li>11/2019 <a href="https://itsfoss.com/opensnitch-firewall-linux/" rel="nofollow">It's Foss</a></li>
<li>03/2020 <a href="https://www.linux-magazine.com/Issues/2020/232/Firewalld-and-OpenSnitch" rel="nofollow">Linux Format #232</a></li>
<li>08/2020 <a href="https://linux-magazine.pl/archiwum/wydanie/387" rel="nofollow">Linux Magazine Polska #194</a></li>
<li>08/2021 <a href="https://github.com/evilsocket/opensnitch/discussions/631" data-hovercard-type="discussion" data-hovercard-url="/evilsocket/opensnitch/discussions/631/hovercard">Linux Format #280</a></li>
<li>02/2022 <a href="https://www.linux-community.de/magazine/linuxuser/2022/03/" rel="nofollow">Linux User</a></li>
<li>06/2022 <a href="https://www.linux-magazine.com/Issues/2022/259/OpenSnitch" rel="nofollow">Linux Magazine #259</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Donations</h2><a id="user-content-donations" aria-label="Permalink: Donations" href="#donations"></a></p>
<p dir="auto">If you find OpenSnitch useful and want to donate to the dedicated developers, you can do it from the <strong>Sponsor this project</strong> section on the right side of this repository.</p>
<p dir="auto">You can see here who are the current maintainers of OpenSnitch:
<a href="https://github.com/evilsocket/opensnitch/commits/master">https://github.com/evilsocket/opensnitch/commits/master</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto"><a href="https://github.com/evilsocket/opensnitch/graphs/contributors">See the list</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Translating</h2><a id="user-content-translating" aria-label="Permalink: Translating" href="#translating"></a></p>
<a href="https://hosted.weblate.org/engage/opensnitch/" rel="nofollow">
<img src="https://camo.githubusercontent.com/75c6d0a4c406c1a7802bb3b7283238c3df71084751e7aa00f9822d203876e903/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f6f70656e736e697463682f2d2f676c6f73736172792f6d756c74692d6175746f2e737667" alt="Translation status" data-canonical-src="https://hosted.weblate.org/widgets/opensnitch/-/glossary/multi-auto.svg">
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Live Cam: Real-time face swapping and one-click video deepfake tool (221 pts)]]></title>
            <link>https://deeplive.cam</link>
            <guid>41209181</guid>
            <pubDate>Sat, 10 Aug 2024 13:05:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deeplive.cam">https://deeplive.cam</a>, See on <a href="https://news.ycombinator.com/item?id=41209181">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="hero"><h2>Deep Live Cam<br> <!-- -->The Next Leap in Real-Time Face Swapping and Video Deepfake Technology</h2><p>Deep Live Cam harnesses cutting-edge AI to push the boundaries of real-time face swapping and video deepfakes.<br> <!-- -->Achieve high-quality face replacement with just a single image.</p></section><div><div id="features"><p><h4>editions</h4><h2>Deep Live Cam Supports Multiple Execution Platforms</h2></p></div><div><h2>Deep Live Cam: Bringing Your Ideas to Life</h2><p>Deep Live Cam is a state-of-the-art AI tool that delivers astonishingly accurate real-time face swapping and video deepfakes. Here's what sets it apart:</p><div><div><p>Swap faces in real-time using a single image, with instant preview capabilities.</p></div><div><div><p><span>One-Click Video Deepfakes</span></p></div><p>Generate high-quality deepfake videos quickly and easily with simple operations.</p></div><div><p>Run on various platforms including CPU, NVIDIA CUDA, and Apple Silicon, adapting to different hardware setups.</p></div><div><p>Built-in checks prevent processing of inappropriate content, ensuring legal and ethical use.</p></div><div><p>Leverages optimized algorithms for significantly faster processing, especially on CUDA-enabled NVIDIA GPUs.</p></div><div><p>Benefit from an active community providing ongoing support and improvements, keeping the tool at the cutting edge.</p></div></div></div><div><h2>How Deep Live Cam Works</h2><p>Deep Live Cam employs advanced AI algorithms to achieve real-time face swapping and video deepfakes.</p></div><section><h2>What Users Are Saying About Deep Live Cam on X</h2><p>Explore real experiences and creations shared by developers and users on X. See how Deep Live Cam is inspiring creativity and solving practical problems across various fields, from stunning face-swap effects to innovative applications.</p></section><div id="faq"><div><h2>Frequently Asked Questions About Deep Live Cam</h2><p>Get answers to common questions about Deep Live Cam</p></div><div><div><h3>What is Deep Live Cam?</h3><p>Deep Live Cam is an open-source tool for real-time face swapping and one-click video deepfakes. It can replace faces in videos or images using a single photo, ideal for video production, animation, and various creative projects.</p><hr></div><div><h3>What are the main features of Deep Live Cam?</h3><p>Deep Live Cam's key features include: 1) Real-time face swapping; 2) One-click video deepfakes; 3) Multi-platform support; 4) Ethical use safeguards.</p><hr></div><div><h3>How do I use Deep Live Cam?</h3><p>To use Deep Live Cam: 1) Set up the required environment; 2) Clone the GitHub repository; 3) Download necessary models; 4) Install dependencies; 5) Run the program; 6) Select source image and target; 7) Start the face-swapping process.</p><hr></div><div><h3>Which platforms does Deep Live Cam support?</h3><p>Deep Live Cam supports various execution platforms, including CPU, NVIDIA CUDA, Apple Silicon (CoreML), DirectML (Windows), and OpenVINO (Intel). Users can choose the optimal platform based on their hardware configuration.</p><hr></div><div><h3>How does Deep Live Cam prevent misuse?</h3><p>Deep Live Cam incorporates built-in checks to prevent processing of inappropriate content (e.g., nudity, violence, sensitive material). The developers are committed to evolving the project within legal and ethical frameworks, implementing measures like watermarking outputs when necessary to prevent abuse.</p><hr></div><div><h3>Is Deep Live Cam free to use?</h3><p>Yes, Deep Live Cam is an open-source project and completely free to use. You can access the source code on GitHub and use it freely.</p><hr></div><div><h3>Can I use Deep Live Cam for commercial purposes?</h3><p>While Deep Live Cam is open-source, for commercial use, you should carefully review the project's license terms. Additionally, using deepfake technology may involve legal and ethical considerations. We recommend consulting with legal professionals before any commercial application.</p><hr></div><div><h3>What are the hardware requirements for Deep Live Cam?</h3><p>Deep Live Cam's performance varies with hardware configuration. Basic functionality runs on standard CPUs, but for optimal performance and results, we recommend using CUDA-enabled NVIDIA GPUs or devices with Apple Silicon chips.</p><hr></div><div><h3>Does Deep Live Cam support real-time video stream processing?</h3><p>Yes, Deep Live Cam supports real-time video stream processing. You can use a webcam for real-time face swapping, with the program providing live preview functionality.</p><hr></div><div><h3>How can I improve the face-swapping results in Deep Live Cam?</h3><p>To enhance face-swapping results, try: 1) Using high-quality, clear source images; 2) Choosing source and target images with similar angles and lighting; 3) Adjusting program parameters; 4) Running the program on more powerful hardware.</p><hr></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A wonderful coincidence or an expected connection: why π² ≈ g (417 pts)]]></title>
            <link>https://roitman.io/blog/91</link>
            <guid>41208988</guid>
            <pubDate>Sat, 10 Aug 2024 12:24:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://roitman.io/blog/91">https://roitman.io/blog/91</a>, See on <a href="https://news.ycombinator.com/item?id=41208988">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Let’s take a brief trip back to our school years and recall some lessons in mathematics and physics. Do you remember what the number π equals? And what is π squared? That’s a strange question too. Of course, it’s 9.87. And do you remember the value of the acceleration due to gravity, g? Of course, that number was drilled into our memory so thoroughly that it’s impossible to forget: 9.81 m/s². Naturally, it can vary, but for solving basic school problems, we typically used this value.</p><p>August 9, 2024</p></div><p><span><h2><strong>Mysterious equality</strong></h2><p>And now, here’s the next question: how on earth is it that π² is approximately equal to g? You might say that such questions aren’t asked in polite society. First of all, they aren’t exactly equal. There’s already a difference in the second decimal place. Secondly, π is a dimensionless number, while g is a physical quantity with its own units.</p><p>And yet, no matter how you look at it, this can’t just be a simple coincidence.</p><h2><strong>Not as simple as it seems</strong></h2><p>Let's start by taking a close look at the right side. The value 9.81 is in m/s². But these are far from the only units of measurement. If you express this value in any other units, the magic immediately disappears. So, this is no coincidence—let's dig deeper into the meters and seconds.</p><p>What exactly is a "meter," and how could it be related to π? At first glance, not at all. According to Wikipedia, a "meter is the distance light travels in a vacuum during a time interval of 1/299,792,458 seconds." Great, now we have seconds involved—good! But there's still nothing about π.</p><p>Wait a minute, why exactly 1/299,792,458? Why not, for example, 1/300? Where did this number come from in the first place? It seems we need to delve into the history of the unit of length itself to understand this better.</p><h2>A standard for every honest merchant</h2><p>In the past, people didn't bother much with standards: they only cared about what was convenient for measurement. For example, why not measure length in human cubits? It might not be precise, but it was cheap, reliable, and practical. And the fact that everyone's cubits were of different lengths? Sometimes that was even useful. If you needed to buy more cloth, you'd call the tallest person in the village and have them measure the fabric with their cubits.</p><p>Later on, of course, people began thinking about standardization. They started creating various standards. But this turned out to be inconvenient and cumbersome: you couldn't always run to a single standard for measurement. So, copies of the standards began to appear. And then copies of the copies...</p><p>Serious people decided that such chaos was hindering serious business, so they set a goal: to come up with a definition of a unit of length that wouldn't depend on any arbitrary standards. It should only depend on natural constants, so that anyone with some basic tools could reproduce and measure it.</p><h2>Bright dreams of standardization and insidious gravity</h2><p>A "standard-free" definition for the meter was actually proposed back in the 17th century. The Dutch mechanic, physicist, mathematician, astronomer, and inventor Christiaan Huygens suggested using a simple pendulum for this purpose. You take a small object and suspend it on a string. The length of the string should be such that the pendulum completes a full oscillation (returns to its original position) in exactly two seconds. This length of string was called the "universal measure" or the "Catholic meter." This length differed from the modern meter by about half a centimeter.</p><p>The proposal was well-received and adopted. However, problems soon arose. First, Huygens was dealing with what he called a "mathematical pendulum." This is a "material point suspended on a weightless, inextensible string." A material point and a weightless string are hardly the simple tools that every merchant would have on hand.</p><p>Second, it was quickly discovered that the length of the pendulum's string varied in different parts of the Earth. Gravity cunningly decreased as one approached the equator and did not cooperate with humanity's bright dream of standardization.</p><h2>An astonishing equation</h2><p>But let’s return to our mysterious equation. To find the period of small oscillations of a mathematical pendulum as a function of the length of the suspension, the following formula is used:</p><figure><img src="https://nkjhvudpdnbuifryqtzj.supabase.co/storage/v1/object/public/pictures/public/e6232f8b-513a-46c4-a056-a0537b26f421"><figcaption></figcaption></figure><p>And here it is—our π! Let's substitute the parameters of Huygens’ pendulum into this formula. The length of the string l in Huygens' pendulum equals 1. The T - oscillation equals 2. Plugging these values into the formula, we get π²=g.</p><p>So, have we found the answer to our question? Well, not quite. We already saw that the equality is only approximate. It doesn’t feel right to equate 9.87 and 9.81 exactly. Does this mean that the meter has changed since then?</p><h2>With revolutionary greetings from France</h2><p>Yes, indeed, it did change! This occurred during the reform of the units of measurement initiated by the French Academy of Sciences in 1791. Intelligent people suggested maintaining the definition of the meter through the pendulum, but with the clarification that it should specifically be a French pendulum—at the latitude of 45° N (approximately between Bordeaux and Grenoble).</p><p>However, this did not sit well with the commission in charge of the reform. The problem was that the head of the commission, Jean-Charles de Borda, was a fervent supporter of transitioning to a new (revolutionary) system of angle measurement—using grads (a grad being one-hundredth of a right angle). Each grad was divided into 100 minutes, and each minute into 100 seconds. The method of the seconds pendulum did not fit into this neat concept.</p><h2>The true and final meter</h2><p>In the end, they successfully got rid of the seconds and defined the meter as one forty-millionth of the Paris meridian. Or, alternatively, as one ten-millionth of the distance from the North Pole to the equator along the surface of the Earth’s ellipsoid at the longitude of Paris. This measurement slightly differed from the "pendulum" meter. The commission, without false modesty, dubbed the resulting value as the "true and final meter."</p><p>The idea of a universal standard accessible to everyone waved goodbye and faded into the sunset. Need an accurate standard for the meter? No problem! All you have to do is measure the length of a meridian and divide it by a few million. By the way, the French actually did this—they physically measured a portion of the Paris meridian, the arc from Dunkirk to Barcelona. They laid out a chain of 115 triangles across France and part of Spain. Based on these measurements, they created a brass standard. Incidentally, they made a mistake—they didn't account for the Earth's polar flattening.</p><h2><strong>Conclusion</strong></h2><p>Let's return to our equation once again. Now we know where the inaccuracy comes from: π² and g differ by about 0.06. If it weren't for yet another attempt to reform and improve everything, we would now have a slightly different value for the meter and the elegant equation π² = g. Later, scientists did return to defining the meter through unchanging and reproducible natural constants, but the meter standard was no longer the same.</p></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird browser to start using Swift language this fall (182 pts)]]></title>
            <link>https://twitter.com/awesomekling/status/1822236888188498031</link>
            <guid>41208836</guid>
            <pubDate>Sat, 10 Aug 2024 11:52:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/awesomekling/status/1822236888188498031">https://twitter.com/awesomekling/status/1822236888188498031</a>, See on <a href="https://news.ycombinator.com/item?id=41208836">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>