<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 03 Aug 2024 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Boeing's Starliner proves better at torching cash than reaching orbit (103 pts)]]></title>
            <link>https://www.theregister.com/2024/08/02/boeing_starliner_losses/</link>
            <guid>41147545</guid>
            <pubDate>Sat, 03 Aug 2024 16:28:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/08/02/boeing_starliner_losses/">https://www.theregister.com/2024/08/02/boeing_starliner_losses/</a>, See on <a href="https://news.ycombinator.com/item?id=41147545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Lurking in Boeing's woeful Q2 financials is an admission that while its Starliner spacecraft might be struggling when it comes to burning fuel, it has no problem whatsoever setting fire to dollar bills.</p>
<p>The Calamity Capsule is currently attached to the International Space Station (ISS) while engineers scrutinize test results and finalize procedures for bringing the Boeing spacecraft – and its two crew members – back to Earth.</p>
<p>The word "calamity" might equally apply to the impact of the project on Boeing's <a target="_blank" href="https://www.theregister.com/2024/07/31/boeing_q2_2024/">finances</a>. The troubled aerospace titan's <a target="_blank" rel="nofollow" href="https://www.sec.gov/ix?doc=/Archives/edgar/data/0000012927/000001292724000055/ba-20240630.htm">filing</a> with the US Securities and Exchange Commission (SEC) revealed it would be increasing its "reach-forward loss on the [Starliner] program" by another $125 million.</p>

    

<p>The <a target="_blank" href="https://www.theregister.com/2022/10/27/starliner_losses_closing_in_on/">losses</a> incurred by Boeing thanks to Starliner have comfortably breezed past $1 billion, and will likely surpass $1.6 billion before long. "Risk remains that we may record additional losses in future periods," Boeing observed.</p>

        


        

<p>It is now almost ten years since NASA handed Boeing a <a target="_blank" href="https://www.theregister.com/2015/05/29/nasa_hands_boeing_contract_for_first_commercial_crew_mission_to_iss/">contract</a> to develop a vehicle to transport crew to and from the ISS. John Mulholland, then Boeing VP and Program Manager for Commercial Crew and now Boeing's Program Manager for the ISS, said: "We're on track to fly in 2017, and this critical milestone moves us another step closer in fully maturing the CST-100 design."</p>
<ul>

<li><a href="https://www.theregister.com/2024/07/31/boeing_q2_2024/">Boeing's Q2 nosedive buoyed by appointment of new CEO</a></li>

<li><a href="https://www.theregister.com/2024/07/29/nasa_approves_crew_9_launch/">NASA gives Falcon 9 thumbs-up to launch Crew-9</a></li>

<li><a href="https://www.theregister.com/2024/07/26/starliner_stay_onboard_iss/">Boeing Starliner crew get their ISS sleepover extended</a></li>

<li><a href="https://www.theregister.com/2024/07/11/boeings_starliner/">Boeing's Starliner set for extended stay at the ISS as engineers on Earth try to recreate thruster issues</a></li>
</ul>
<p>After a <a target="_blank" href="https://www.theregister.com/2019/12/20/boeing_starliner_failure/">failed first attempt</a> to reach the ISS, Boeing repeated the non-crewed test flight "<a target="_blank" rel="nofollow" href="https://boeing.mediaroom.com/2020-04-06-Boeing-Statement-on-Starliners-Next-Flight">at no cost to the taxpayer</a>." Despite that second unmanned try at reaching the ISS being successful, the Calamity Capsule was subject to yet more delays before finally getting off the ground in June with two test pilots onboard for a minimum mission duration of eight days. Destination: The space station, and then home.</p>
<p>Almost two months later, the spacecraft and its human duo remain docked to the ISS. Starliner can't get back to Earth within NASA's safety parameters, due to thruster issues and gas leaks. It is cleared for an emergency return, an option American officials aren't willing to take right now.</p>
<p>NASA and Boeing have yet to set a date for the spacecraft's return. In an update issued on August 1, NASA <a target="_blank" rel="nofollow" href="https://blogs.nasa.gov/boeing-crew-flight-test/2024/08/01/nasa-boeing-continue-data-analysis-for-crew-flight-test-evaluation/">noted</a> that the planning for the spacecraft's return was "expected to continue into next week." This includes finalizing undocking procedures and "operational mitigations that could be used in flight, if needed."</p>

        

<p>In its own <a target="_blank" rel="nofollow" href="https://starlinerupdates.com/starliner-return-to-earth-preps-underway/">update</a>, Boeing reported that return-to-Earth preparations were under way, with teams working through simulations and the ISS crew inspecting the exterior of Starliner using the outpost's Canadarm.</p>
<p>Meanwhile, a NASA spokesperson <a target="_blank" rel="nofollow" href="https://arstechnica.com/space/2024/08/yes-nasa-really-could-bring-starliners-astronauts-back-on-crew-dragon/">told Ars</a> the US agency is "evaluating all options." It's thought those possible options include using a SpaceX capsule to do what Starliner right now can't – bring back its pair of pilots.</p>
<p>The next flight of the Starliner is not expected until August 2025, so it seems likely that Boeing's balance sheet will continue to bleed red in the "contracts we wish we'd never signed" column for a while longer. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["We ran out of columns" – The best, worst codebase (601 pts)]]></title>
            <link>https://jimmyhmiller.github.io/ugliest-beautiful-codebase</link>
            <guid>41146239</guid>
            <pubDate>Sat, 03 Aug 2024 12:26:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jimmyhmiller.github.io/ugliest-beautiful-codebase">https://jimmyhmiller.github.io/ugliest-beautiful-codebase</a>, See on <a href="https://news.ycombinator.com/item?id=41146239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>"We ran out of columns" - The best, worst codebase</h2>
<blockquote>
<p>Oh the merchants2 table? Yeah, we ran out of columns on merchants, so we made merchants2</p>
</blockquote>
<p>When I started programming as a kid, I didn't know people were paid to program. Even as I graduated high school, I assumed that the world of "professional development" looked quite different from the code I wrote in my spare time. When I lucked my way into my first software job, I quickly learned just how wrong and how right I had been. My first job was a trial by fire, to this day, that codebase remains the worst and the best codebase I ever had the pleasure of working in. While the codebase will forever remain locked by proprietary walls of that particular company, I hope I can share with you some of its most fun and scary stories.</p>
<h2>The database lives forever</h2>
<p>In a large legacy system, the database is more than a place to store data, it is the culture maker. The database sets the constraints for how the system as a whole operates. It is the point where all code meets. The database is the watering hole. In our case, that watering hole had quite a bit of pollution.</p>
<p>Did you know that SQL Server has a limit on the number of columns you can have in a table? Me neither. At the time it was 1024, today it appears to be 4096. Needless to say, most people don't need to know this. We did. The reason, Merchants (our table to store customer information) ran out of columns a long time ago. Merchants2 was the solution. A table with (if I remember correctly) some 500+ columns itself.&nbsp;</p>
<p>Merchants (and its best friend Merchants2) were the lifeblood of the system. Everything made its way back to Merchants somehow or other. But it wasn't as if Merchants was the solo (or duo) table. There were plenty of properly normalized tables, all with foreign keys to Merchants. But one will always hold a special place in my heart, SequenceKey.</p>
<h3>SequenceKey</h3>
<table><thead><tr><th>SequenceKey</th></tr></thead><tbody><tr><td>1251238 &nbsp; &nbsp;</td></tr></tbody></table>
<p>For ease of understanding, I have recreated the whole of the SequenceKey table above. Yes. You read that correctly, this is the whole table. A table with a single key and a single value. If simplicity is a virtue, then one might declare SequenceKey to be the perfect table. What could be simpler?&nbsp;</p>
<p>But you may be asking yourself, what possible use could you have for a table with one column and row? Generating ids. Now the story I heard at the time was that once upon a time SQL Server didn't support auto-incrementing ids. This was the accepted, correct answer. My search to figure out if this is true was inconclusive. But in practice, it served as much more than that.</p>
<p>SequenceKey was the glue. In every stored procedure that created new entities, you'd first grab a key from SequenceKey, increment it. And then insert that as your ID for N different tables. You now had an implicit join between all these entity tables. If you saw an ID in the system, there was a good chance related tables would have a row with the exact same ID. Honestly kind of clever.</p>
<h3>The Calendar</h3>
<p>A database may live forever, but our login system was limited by the calendar. I don't mean an actual calendar. I mean a database table called calendar. What did it contain? A manually filled-out calendar. When asking our resident shaman (who went by the name Munch), he informed me that when the calendar runs out we can't login to the system. This happened a few years ago. So they had an intern fill out 5 more years to make sure it didn't happen anytime soon. What system used this calendar? No one knew.</p>
<h3>Employees</h3>
<p>Every morning at 7:15 the employees table was dropped. All the data completely gone. Then a csv from adp was uploaded into the table. During this time you couldn't login to the system. Sometimes this process failed. But this wasn't the end of the process. The data needed to be replicated to headquarters. So an email was sent to a man, who every day would push a button to copy the data.</p>
<h3>The replacement database</h3>
<p>You might be thinking to yourself, couldn't someone clean up this database? Make it nicer to work with? Well, the company was way ahead of you. There was a copy of the database. Data in this copy was about 10 minutes out of date. Sync only went one way. But this database was normalized. How normalized? To go from merchants to a phone number was 7 joins.</p>
<h3>The Sales Numbers</h3>
<p>Every salesperson had a quota they needed to meet every month called a "win". The tables that kept this data (not the financial keepings but a sales-specific way of accounting for this), were incredibly complicated. Every day, a job would figure out which rows had been added and updated and sync them with some system at headquarters. This wasn't really a problem until one salesperson figured out they could ask for those records to be manually changed.</p>
<p>This salesperson had already got their win and landed another big sale that month. They wanted it to be moved to next month. An intern was tasked with doing so. Word got out and over the next three years, requests would grow exponentially. At one point we had 3 interns whose full-time job was writing these SQL statements. Writing an application to do this was deemed too difficult. Before I left though, I made sure to help those interns build their own. No idea if it ever took off though.</p>
<h2>The codebase</h2>
<p>But what is a database without a codebase. And what a magnificent codebase it was. When I joined everything was in Team Foundation Server. If you aren't familiar, this was a Microsoft-made centralized source control system. The main codebase I worked in was half VB, half C#. It ran on IIS and used session state for everything. What did this mean in practice? If you navigated to a page via Path A or Path B you'd see very different things on that page.</p>
<p>But to describe this codebase as merely half VB, half C# would be to do it a disservice. Every javascript framework that existed at the time was checked into this repository. Typically, with some custom changes the author believed needed to be made. Most notably, knockout, backbone, and marionette. But of course, there was a smattering of jquery and jquery plugins.</p>
<p>But this codebase didn't stand alone. Next to it were a dozen or so soap services and a handful of native Windows applications. Most notable was the shipping manager. Fable has it the entire application was built in a weekend by a solo developer. Let's call him Gilfoyle. Gilfoyle was by all accounts an incredibly fast programmer. I never met him, but I felt I knew him, not just through his code in the repos, but also through all the code remaining on his hard drives.</p>
<h3>Gilfoyle's Hard Drives</h3>
<p>Munch (yes this was the name he really went by) kept Gilfoyle's hard drive in RAID configuration on his desk years after Gilfoyle had left the company. Why? Because Gilfoyle was known for not checking in code. Not only that, but for building a random one-off windows application for a single user . So it wasn't uncommon to have a user come to us with a bug report for an application that only existed on Gilfoyle's hard drive.</p>
<h3>The Shipping Bug</h3>
<p>Most of my job was tracking down bugs that teams didn't want to dedicate work to. One particularly nasty bug would pop up once every few months. After we shipped things, the shipping queue would have stuck orders in them, that claimed to both be already shipped and not shipped. I went through a series of workarounds (SQL script, windows application, etc) to try and get us out of the broken state. I was advised not to try and track down the root cause. But I couldn't help myself.</p>
<p>Along the way, I learned how Gilfoyle thought. The shipping app pulled down the entire database and then filtered by date, keeping all orders past the go-live date of the application. The app relied on a SOAP service, not to do any servicey things. No, the service was a pure function. It was the client that did all the side effects. In that client, I discovered a massive class hierarchy. 120 classes each with various methods, inheritance going 10 levels deep. The only problem? <strong>ALL THE METHODS WERE EMPTY.</strong> I do not exaggerate here. Not mostly empty. Empty.</p>
<p>That one stumped me for a while. Eventually, I learned this was in service of building a structure he could then use reflection on. That reflection would let him create a pipe-delimited string (whose structure was completely database-driven, but entirely static) that he would send over a socket. Turns out this was all eventually sent to Kewill, the service that talked to shipping carriers. Why did this bug happen? Kewill reused 9-digit long numbers every month, someone had disabled the cron job that deleted the old orders.</p>
<h2>The Beautiful Mess</h2>
<p>There are so many more things to tell from this code base. Like the team of Super Senior developers who were rewriting the whole thing without shipping any code for 5 years. Or the red hat consultants building the one database to rule them all. There were so many crazy corners of this code base. So many reasons why there were whole teams dedicated to starting from scratch on just one bit of its functionality.</p>
<p>But I think the most important story to tell is about Justin's improvement of the Merchants Search page. The Merchants Search page was the entry point into the entire application. Every customer service rep would get on the phone with a merchant and type either their id or name to find their information. That would land you on a massive page with all their information. The page was information-dense in the best way, full of any information you could need and any links you could want to visit. But it was dog slow.</p>
<p>Justin was the sole senior developer in my group. He was bright, snarky, and couldn't care less about the business. He told it like it was, didn't pull punches, and could always solve problems by himself faster than teams around him. One day Justin got tired of hearing about how slow the merchant search page was and went and fixed it. Every box on that screen became its own endpoint. On load, everything above the fold would start fetching, and as one loaded-in, more requests would come in. Took page load time from minutes to sub-second.</p>
<h3>Two ways to decouple</h3>
<p>Why was Justin able to do this? Because this codebase had no master plan. There was no overarching design the system had to fit into. No expected format for APIs. No documented design system. No architectural review board making sure things were coherent. The app was a complete and utter mess. No one could ever fix it, so no one tried to. What did we do instead? We carved out our own little world of sanity.</p>
<p>This monolithic app, due to sheer necessity, had grown to be a microcosm of nice, small apps around its edges. Each person, when tasked with improving some part of that app, would inevitably give up untangling that web, and find some nice little corner to build new things. And then slowly update links to point to their nice new stuff, orphaning the old.</p>
<p>This may sound like a mess to you. But it was remarkably enjoyable to work in. Gone were the concerns of code duplication. Gone were the concerns of consistency. Gone were the concerns of extensibility. Code was written to serve a use, to touch as little of the area around it as possible, and to be easily replaceable. Our code was decoupled, because coupling it was simply harder.</p>
<h2>After</h2>
<p>In my career since, I've never had the privilege of working in such a wonderfully ugly codebase. Every ugly codebase I've encountered since has never transcended its need for consistency. Perhaps it was because the codebase had been abandoned by "serious" developers long before. All that remained were ragtag interns and junior developers. Or perhaps it was because there was no layer between those developers and the users, no translations, no requirements gathering, no cards. Just you standing at the desk of the customer service rep, asking them how you could make their life better.</p>
<p>I miss that direct connection. The fast feedback. The lack of making grand plans. The simple problem and code connection. Perhaps it's simply a naive nostalgia. But just as I find myself laying on a couch longing to go back to some of the worst years of my childhood; when faced with yet another "enterprise design pattern", my mind flashes back to that beautiful, horrible codebase.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Made an Extended Version of Vimtutor – Introducing Vimtutor Sequel (161 pts)]]></title>
            <link>https://github.com/micahkepe/vimtutor-sequel</link>
            <guid>41144843</guid>
            <pubDate>Sat, 03 Aug 2024 05:29:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/micahkepe/vimtutor-sequel">https://github.com/micahkepe/vimtutor-sequel</a>, See on <a href="https://news.ycombinator.com/item?id=41144843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">vimtutor-sequel</h2><a id="user-content-vimtutor-sequel" aria-label="Permalink: vimtutor-sequel" href="#vimtutor-sequel"></a></p>
<p dir="auto">Vimtutor Sequel provides advanced Vim tutor lessons to help users deepen their understanding of Vim.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/micahkepe/vimtutor-sequel/blob/main/images/teaser.png"><img src="https://github.com/micahkepe/vimtutor-sequel/raw/main/images/teaser.png" alt="Teaser image of the tutorial"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Advanced Vim commands and techniques</li>
<li>Step-by-step tutorials</li>
<li>Interactive exercises</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">The easiest way to use <code>vimtutor-sequel</code> is to install it using Homebrew. However, you can also run the tutorial manually by cloning the repository (see <a href="#running-vimtutor-without-homebrew">Running Vimtutor Without Homebrew</a>).</p>
<p dir="auto">If you don't have Homebrew installed, you can install it using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;"><pre>/bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">For New Users</h3><a id="user-content-for-new-users" aria-label="Permalink: For New Users" href="#for-new-users"></a></p>
<p dir="auto">To install <code>vimtutor-sequel</code> for the first time using Homebrew:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Tap the repository</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap micahkepe/vimtutor-sequel"><pre>brew tap micahkepe/vimtutor-sequel</pre></div>
</li>
<li>
<p dir="auto"><strong>Install <code>vimtutor-sequel</code></strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install vimtutor-sequel"><pre>brew install vimtutor-sequel</pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">For Existing Users</h3><a id="user-content-for-existing-users" aria-label="Permalink: For Existing Users" href="#for-existing-users"></a></p>
<p dir="auto">If you have already installed <code>vimtutor-sequel</code> and want to upgrade to the latest version:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Update Homebrew</strong>:</p>

</li>
<li>
<p dir="auto"><strong>Upgrade <code>vimtutor-sequel</code></strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="brew upgrade vimtutor-sequel"><pre>brew upgrade vimtutor-sequel</pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">To run the <code>vimtutor-sequel</code> script, simply type:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Running Vimtutor Without Homebrew</h2><a id="user-content-running-vimtutor-without-homebrew" aria-label="Permalink: Running Vimtutor Without Homebrew" href="#running-vimtutor-without-homebrew"></a></p>
<p dir="auto">If you are on Windows or Linux, you can still run the tutorial by cloning the repository and running the script manually:</p>
<ol dir="auto">
<li><strong>Clone the repository</strong>:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/micahkepe/vimtutor-sequel.git"><pre>git clone https://github.com/micahkepe/vimtutor-sequel.git</pre></div>
<ol start="2" dir="auto">
<li><strong>Navigate to the repository</strong>:</li>
</ol>

<ol start="3" dir="auto">
<li><strong>Make a Copy of the Tutorial</strong>:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="cp vimtutor-sequel.txt vimtutor-sequel-copy.txt"><pre>cp vimtutor-sequel.txt vimtutor-sequel-copy.txt</pre></div>
<ol start="4" dir="auto">
<li><strong>Run Vim with the Custom Configuration</strong>:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="vim -u vimtutor-sequel.vimrc vimtutor-sequel-copy.txt"><pre>vim -u vimtutor-sequel.vimrc vimtutor-sequel-copy.txt</pre></div>
<p dir="auto">This method allows you to easily access and run the Vimtutor Sequel lessons without the need for additional installation steps.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - see the <a href="https://github.com/micahkepe/vimtutor-sequel/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/micahkepe/vimtutor-sequel/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for information on how to contribute to <code>vimtutor-sequel</code>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hanon Pro – piano technique and exercises for the digital age (192 pts)]]></title>
            <link>https://furnacecreek.org/hanon/</link>
            <guid>41144826</guid>
            <pubDate>Sat, 03 Aug 2024 05:21:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://furnacecreek.org/hanon/">https://furnacecreek.org/hanon/</a>, See on <a href="https://news.ycombinator.com/item?id=41144826">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
		<div>
				<p>Hanon Pro is an app for iPhone, iPad, and Mac that offers a fresh, modern take on
						keyboard and piano technique and exercises for the digital age. Just like health and fitness
						apps track your physical health over time, Hanon Pro does the same for piano practice. It
						enables you to get feedback on your playing, visualize trends, and track practice habits over
						time.</p>

				

				<p><img src="https://furnacecreek.org/hanon/images/feedback.png" alt="Hanon Pro - get feedback on piano playing" width="680" height="545">
				</p>

				<p>The app features a catalog of content specifically designed to look great on iPhone, iPad, and
						Mac. We design each book and score with support for responsive layouts, Dark Mode, rich
						metadata, embedded finger numbers, and more. You can listen to each piece, practice with the
						built-in metronome, and adjust the tempo.</p>

				<p><img src="https://furnacecreek.org/hanon/images/library.png" alt="Hanon Pro - manage your music library" width="680" height="422">
				</p>

				<p>The real magic of Hanon Pro is unlocked when you connect your iPhone, iPad, or Mac with a MIDI
						keyboard or piano over a Bluetooth or USB connection. Hanon Pro's intelligence engine can
						analyze your playing, including accuracy, tempo, and dynamics, and even turn pages as you play.
						To help make piano practice a habit, the app lets you sign up for daily practice reminder
						notifications and earn achievements over time with built-in Game Center integration.</p>

				<h3>All Features</h3>

				<div id="featureGrid">
					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/storefront.svg"></span><br><span>Music Store</span></h3>
						<p>Browse our catalog of music scores, each designed with support for interactive features like
							automatic page turning and computer aided evaluation.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/cap.svg"></span><br><span>Repertoire</span></h3>
						<p>Obtain content designed to improve keyboard and piano technique such as scales, technical
							exercises, and repertoire used by exam boards.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/star.svg"></span><br><span>Explore</span></h3>
						<p>Explore music by composer, key, and even exam boards like ABRSM, RCM, and Trinity.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/info.svg"></span><br><span>Metadata</span></h3>
						<p>View rich metadata about each work, including description, composer, key, year of
							composition, and more.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/books.svg"></span><br><span>Library</span></h3>
						<p>Search, sort, and filter your library to find the scores you want.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/cloud.svg"></span><br><span>iCloud Sync</span></h3>
						<p>Sync your music library with your iPhone, iPad, and Mac over iCloud.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/metronome.svg"></span><br><span>Metronome</span></h3>
						<p>Practice with the built-in metronome and adjust the tempo of any score.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/play.svg"></span><br><span>Playback</span></h3>
						<p>Listen to any piece in the catalog with our realistic playback engine.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/piano.svg"></span><br><span>MIDI Support</span></h3>
						<p>Pair the app with a MIDI keyboard or piano, either wirelessly over Bluetooth or with a USB-C
							cable.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/checklist.svg"></span><br><span>Evaluation</span></h3>
						<p>Evaluate your performance and receive feedback on accuracy, tempo, rhythm, style, and more.
						</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/bars.svg"></span><br><span>Charts and Graphs</span></h3>
						<p>View charts and graphs that visualize how your progress improves over time.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/progress.svg"></span><br><span>Progress Tracking</span></h3>
						<p>Track daily practice habits, including time spent practicing.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/trophy.svg"></span><br><span>Game Center</span></h3>
						<p>Unlock achievements as you practice with Game Center integration.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/pages.svg"></span><br><span>Page Turning</span></h3>
						<p>Enjoy automatic and hands-free page turning as you play.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/alert.svg"></span><br><span>Practice Reminders</span></h3>
						<p>Sign up to receive daily practice reminder notifications and customize the time.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/night.svg"></span><br><span>Dark Mode</span></h3>
						<p>Invert scores in Dark Mode to reduce brightness when practicing at night.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/customizable.svg"></span><br><span>Customizability</span>
						</h3>
						<p>Customize the app to your liking with control over metronome volume, finger numbers, playback
							options, MIDI settings, and more.</p>
					</div>

					<div>
						<h3><span><img src="https://furnacecreek.org/static/sf/native.svg"></span><br><span>Native App</span></h3>
						<p>Hanon Pro is a truly native app for iPhone, iPad, and Mac, built with technologies like
							SwiftUI, Swift Charts, Core Audio, Core MIDI, iCloud, Game Center, and more.</p>
					</div>
				</div>

				<div>
					<h3>Content</h3>
					<p>Our music catalog features content commonly used to improve technique such as scales, chords,
						Hanon exercises, Schmitt exercises, works by Bach, Beethoven, Krebs, Mozart, and more. If you'd
						like to request a score, you can do so directly in the app!</p>
				</div>

				<div>
					<h3>Pricing</h3>
					<p>We're committed to maintaining Hanon Pro for years to come. However, it's a niche product and
						each score and book needs to be prepared for the interactive capabilities of the app such as
						automatic page turning, responsive layout, and computer aided evaluation. In other words, it's
						not just a PDF. In order to sustain the development of Hanon Pro, we charge for the content in
						our catalog.</p>
				</div>

				<p><img src="https://furnacecreek.org/hanon/images/progress.png" alt="Hanon Pro - track your progress over time" width="680" height="545">
				</p>

				<div>
					<h3>Reviews</h3>
					<p>★★★★★</p>
					<p><em>Since trying Hanon Pro, I've
							practiced playing the piano every day this week, which almost never happened before. The
							gamification of practicing piano technique with feedback, charts, achievements, and
							reminders keeps me coming back. Looking forward to seeing more content over time!</em></p>
					<p>- App Store Review</p>
				</div>

				

				<p>Hanon Pro is compatible with iOS 17.<br> *Requires a Bluetooth or USB MIDI
					keyboard or piano (sold separately)</p>

				




			</div>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[p5.js (327 pts)]]></title>
            <link>https://p5js.org/</link>
            <guid>41144755</guid>
            <pubDate>Sat, 03 Aug 2024 04:53:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://p5js.org/">https://p5js.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41144755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Lauren Lee McCarthy reading the Processing Community Catalog. Photo credit: Maximo Xtravaganza.</p><p>Coding Club for people aged 50+ in Korea, led by Inhwa Yeom.</p><p>Qianqian Ye introducing 600+ p5.js contributors at p5.js Community Salon. Photo credit: Ziyuan Lin.</p><p>p5.js workshop at CC Fest NYC at ITP-NYU in November 2018.</p><p>p5.js workshop at Tunapanda Institute in Nairobi. Photo credit: Tunapanda Institute.</p><p>p5.js will not add any new features except those that increase access.</p><p>p5.js Contributors Conference 2015.</p><p>p5.js Contributors Conference 2019.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers develop treatment that can kill glioblastoma cells in brain pathway (137 pts)]]></title>
            <link>https://medicalxpress.com/news/2024-08-therapy-treatment-glioblastoma-cells-newly.html</link>
            <guid>41144021</guid>
            <pubDate>Sat, 03 Aug 2024 01:24:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2024-08-therapy-treatment-glioblastoma-cells-newly.html">https://medicalxpress.com/news/2024-08-therapy-treatment-glioblastoma-cells-newly.html</a>, See on <a href="https://news.ycombinator.com/item?id=41144021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2015/glioblastoma.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2015/glioblastoma.jpg" data-sub-html="Glioblastoma (histology slide). Credit: Wikipedia/CC BY-SA 3.0">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2015/glioblastoma.jpg" alt="glioblastoma" title="Glioblastoma (histology slide). Credit: Wikipedia/CC BY-SA 3.0" width="500" height="376">
             <figcaption>
                Glioblastoma (histology slide). Credit: Wikipedia/CC BY-SA 3.0
            </figcaption>        </figure>
    </div><p>A new pathway that is used by cancer cells to infiltrate the brain has been discovered by a team of Canadian and American research groups led by the Singh Lab at McMaster University. The research also reveals a new therapy that shows promise in blocking and killing these tumors.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>The research, published in <i>Nature Medicine</i> on Aug. 2, 2024, offers new hope and potential treatments for glioblastoma, the most aggressive form of brain cancer.</p>
<p>With existing treatments like surgery, <a href="https://medicalxpress.com/tags/radiation+therapy/" rel="tag">radiation therapy</a> and chemotherapy, the tumors often return, and patient survival is limited to only a few months. With this new treatment, the returning cancer cells were destroyed at least 50% of the time in two of the three diseases tested in preclinical animal models.</p>
<p>To discover the pathway cancer cells use to infiltrate the brain, researchers used large-scale gene editing technology to compare gene dependencies in glioblastoma when it was initially diagnosed and after it returned following standard treatments. By doing this, researchers discovered a new pathway used for axonal guidance—a signaling axis that helps establish normal brain architecture—that can become overrun by cancer cells.</p>
<p>"In glioblastoma, we believe that the tumor hijacks this signaling pathway and uses it to invade and infiltrate the brain," says co-senior author Sheila Singh, professor with McMaster's Department of Surgery and director of the Center for Discovery in Cancer Research. The research was also co-led by Jason Moffat, head of the Genetics and Genome Biology program at The Hospital for Sick Children (SickKids).</p>
<p>"If we can block this pathway, the hope is that we can block the invasive spread of glioblastoma and kill tumor cells that cannot be removed surgically," says Singh.</p>

                                                                                                                                                         
                                                                                                                                                                                                <h2>Promising new therapeutic</h2>
<p>To stop the invasion of cancer cells, researchers targeted the hijacked signaling pathway using different strategies including a drug developed by John Lazo's group at the University of Virginia, and also by developing a <a href="https://medicalxpress.com/tags/new+therapy/" rel="tag">new therapy</a> with help from Kevin Henry and Martin Rossotti at the National Research Council Canada using CAR T cells to target the pathway in the brain.</p>
<p>They honed in on a protein called Roundabout Guidance Receptor 1 (ROBO1) that helps guide certain cells, similar to a GPS.</p>
<p>"We created a type of cell therapy where cells are taken from a patient, edited and then put back in with a new function. In this case, the CAR T cells were genetically edited to have the knowledge and ability to go and find ROBO1 on <a href="https://medicalxpress.com/tags/tumor+cells/" rel="tag">tumor cells</a> in animal models," says lead author Chirayu Chokshi, a former Ph.D. student who worked alongside Singh at McMaster University.</p>
<p>Singh and Chokshi say the treatment can also apply to other invasive brain cancers. In the study, researchers examined models for three different types of cancer including adult glioblastoma, adult lung-to-brain metastasis, and pediatric medulloblastoma. In all three models, treatment led to a doubling of survival time. In two of the three diseases, it led to tumor eradication in at least 50% of the mice.</p>

                                                                                                                                            <p>"In this study, we present a new CAR T therapy that is showing very promising preclinical results in multiple malignant <a href="https://medicalxpress.com/tags/brain/" rel="tag">brain</a> cancer models, including recurrent glioblastoma. We believe our new CAR T therapy is poised for further development and clinical trials," Singh says.</p>
<p>Work on the study was performed with samples derived from patients treated by neurosurgeons with Hamilton Health Sciences. Proteomics discovery which helped to elucidate the new glioblastoma targets was done in collaboration with Thomas Kilinger at Princess Margaret Cancer Center and University of Toronto.</p>
<p>The research was made possible through collaboration with the National Research Council Canada, University of Virginia, University of Pittsburgh and the Princess Margaret Cancer Center.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    <i>Nature Medicine</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1038/s41591-024-03138-9" target="_blank">DOI: 10.1038/s41591-024-03138-9</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Researchers develop promising therapy treatment that can kill glioblastoma cells in newly-discovered brain pathway (2024, August 2)
                                                 retrieved 3 August 2024
                                                 from https://medicalxpress.com/news/2024-08-therapy-treatment-glioblastoma-cells-newly.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The future of kdb+? (199 pts)]]></title>
            <link>https://www.timestored.com/b/the-future-of-kdb/</link>
            <guid>41143764</guid>
            <pubDate>Sat, 03 Aug 2024 00:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.timestored.com/b/the-future-of-kdb/">https://www.timestored.com/b/the-future-of-kdb/</a>, See on <a href="https://news.ycombinator.com/item?id=41143764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-111834">
				
				<p> July 24th, 2024 by admin </p>			
				<p>It’s been 2 years since I worked full time in kdb+ but people seem to always want to talk to me about kdb+ and where I think it’s going, so to save rehashing the same debates I’m going to put it here and refer to it in future. Please leave a comment if you want and I will reply.</p>
<p>Let’s first look at the use cases for kdb+, then consider the alternatives, then which I think will win for each use-case and why.</p>
<h2>Use Cases</h2>
<p>A. <strong>Historical market data storage and analysis</strong>. – e.g. MS Horizon, Citi CloudKDB, UBS Krypton (3 I worked on).<br>
B. <strong>Local quant analysis</strong> – e.g. Liquidity analysis, PnL analysis, profitability per client.<br>
C. <strong>Real-time Streaming Calcuation Engines</strong> – e.g. Streaming VWAP, Streaming TCA…<br>
D. <strong>Distributed Computing</strong> – e.g. Margin calculations for stock portfolios or risk analysis. Spread data out, perform costly calcs, recombine.</p>
<h2>Alternatives</h2>
<h3>Historical Market Data – kdb+ Alternatives</h3>
<p>A large number of users want to query big data to get minute bars, perform asof joins or more advanced time-series analysis.</p>
<ul>
<li>New Database Technologies – Clickhouse, QuestDB.</li>
<li>Cloud Vendors – Bigquery / redshift</li>
<li>Market Data as a Service</li>
</ul>
<p>Let me tell you three secrets, 1. Most users don’t need the “speed” of kdb+. 2. Most internal bank platforms don’t fully unleash the speed of kdb+. 3. The competitors are now fast enough. I mean clickbench are <a href="https://www.timestored.com/data/time-series-database-benchmarks">totally transparent on benchmarking.</a>.</p>
<p><b>Likely Outcome: – Kdb+ can hold their existing clients</b> but haven’t and won’t get the 2nd tier firms as they either want cloud native or something else. The previous major customers for this had to invest heavily to build their own platform. As far as I’m hearing the kdb cloud platform still needs work.</p>
<h3>Local Quant Analysis – Alternatives</h3>
<ul>
<li><strong>Python </strong>– with DuckDB</li>
<li><strong>Python </strong>– with Polars</li>
<li><strong>Python </strong>– with PyKX</li>
<li><strong>Python </strong>– with dataframe/modin/….</li>
</ul>
<p>Now I’m exaggerating slightly but the local quant analysis game is over and everyone has realised Python has won. The only question is who will provide the speedy add-on. In one corner we have widely popular free community tools that know how to generate interest at huge scale, are fast and well funded. In the other we have a niche company that never spread outside finance, wants to charge $300K to get started and has an exotic syntax.</p>
<p><b>Likely Outcome: DuckDB or Polars</b>. Why? It’s free. People at Uni will start with it and not change. Any sensible quant currently in a firm will want to use a free tool so that they are guaranteed to be able to use similar analytics at their next firm. WIthout that ability they can only go places that have kdb+ else face losing a large percentage of their skillset.</p>
<h4>Real-time Streaming / Distributed Computing</h4>
<p>These were always the less popular cases for kdb+ and never the ones that “won” the contract. The ironic thing is, combining streaming with historical data in one model is kdbs largest strength. However the few times I’ve seen it done, it’s either taken someone very experienced and skillful or it has become a mess. These messes have been so bad it’s put other parts of the firm off adopting kdb+ for other use cases.</p>
<p><b>Likely Outcome: Unsure which will win but not kdb+</b>. Kafka has won mindshare and is deployed at scale but flink/risingwave etc. are upcoming stars.</p>
<h3>Summary</h3>
<p>Kdb+ is an absolutely amazing technology but it’s about the same amazing today as it was 15 years ago when I started. In that time the world has moved on. <b>The best open source companies have stolen the best kdb+ ideas<b>:</b></b></p>
<ul>
<li>Parquet/Iceberg is basically kdb+ on disk format for optimized column storage.</li>
<li>Apache Arrow – in-memory format is kdb+ in memory column format.</li>
<li>Even Kafka log/replay/ksql concept could be viewed as similar to a tplog viewed from a certain angle.</li>
<li>QuestDB / DuckDB / Clickhouse all have asof joins</li>
</ul>
<p>Not only have the competitors learnt and taken the best parts of kdb+ but they have standardised on them. e.g. Snowflake, Dremio, Confluent, Databricks are all going to support Apache Iceberg/parquet. QuestDB / DuckDB / Python are all going to natively support parquet. This means in comparisons <b>it’s no longer KX against one competitor, it’s KX against many competitors at once</b>. If your data is parquet, you can run any of them against your data.</p>
<p>As many at KX would agree I’ve talked to them for years on issues around this and to be fair they have changed but they are not changing quick enough.<br>
They need to do four things:</p>
<ol>
<li><b>Get a free version out there that can be used for many things</b> and have an easy reasonable license for customers with less money to use.</li>
<li><b>Focus on making the core product great.</b> – For years we had Delta this and now it’s kdb.ai. In the meantime mongodb/influxdb won huge contracts with a good database alone.</li>
<li><b>Reduce the steep learning curve</b>. Make kdb+ easier to learn by even changing the language and technology if need be.</li>
<li><b>You must become more popular else it’s a slow death</b></li>
</ol>
<p>This is focussing on the core tech product.<br>
Looking more widely at their financials and other huge costs/initiatives such as AI and massive marketing spending, wider changes at the firm should also be considered.</p>
<p>Author: <a href="https://www.linkedin.com/in/justryanhamilton/">Ryan Hamilton</a></p>
				
								<!-- <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.timestored.com/b/the-future-of-kdb/"
    dc:identifier="https://www.timestored.com/b/the-future-of-kdb/"
    dc:title="The Future of kdb+?"
    trackback:ping="https://www.timestored.com/b/the-future-of-kdb/trackback/" />
</rdf:RDF> -->
				
				
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Common I/O Tasks in Modern Java (128 pts)]]></title>
            <link>https://dev.java/learn/modernio/</link>
            <guid>41142737</guid>
            <pubDate>Fri, 02 Aug 2024 21:12:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dev.java/learn/modernio/">https://dev.java/learn/modernio/</a>, See on <a href="https://news.ycombinator.com/item?id=41142737">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
                
<h2 id="introduction">Introduction</h2>
<p>This article focuses on tasks that application programmers are likely to encounter, particularly in web applications, such as: </p>
<ul>
<li>Reading and writing text files</li>
<li>Reading text, images, JSON from the web</li>
<li>Visiting files in a directory</li>
<li>Reading a ZIP file</li>
<li>Creating a temporary file or directory</li>
</ul>
<p>The Java API supports many other tasks, which are explained in detail in the <a href="https://dev.java/learn/java-io/">Java I/O API tutorial</a>.</p>
<p>This article focuses on API improvements since Java 8. In particular:</p>
<ul>
<li>UTF-8 is the default for I/O since Java 18 (since <a href="https://openjdk.org/jeps/400" target="_blank" rel="noopener noreferrer">JEP 400: UTF-8 by Default</a>)</li>
<li>The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html" target="_blank" rel="noopener noreferrer"><code>java.nio.file.Files</code></a> class, which first appeared in Java 7, added useful methods in Java 8, 11, and 12</li>
<li><a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/InputStream.html" target="_blank" rel="noopener noreferrer"><code>java.io.InputStream</code></a> gained useful methods in Java 9, 11, and 12</li>
<li>The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/File.html" target="_blank" rel="noopener noreferrer"><code>java.io.File</code></a> and <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/BufferedReader.html" target="_blank" rel="noopener noreferrer"><code>java.io.BufferedReader</code></a> classes are now thoroughly obsolete, even though they appear frequently in web searches and AI chats.</li>
</ul>

<h2 id="reading-text-files">Reading Text Files</h2>
<p>You can read a text file into a string like this:</p>
<pre><code>String content = Files.readString(path);
</code></pre>
<p>Here, <code>path</code> is an instance of <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Path.html" target="_blank" rel="noopener noreferrer"><code>java.nio.Path</code></a>, obtained like this:</p>
<pre><code>var path = Path.of("/usr/share/dict/words");
</code></pre>
<p>Before Java 18, you were strongly encouraged to specify the character encoding with any file operations that read or write strings. Nowadays, by far the most common character encoding is UTF-8, but for backwards compatibility, Java used the "platform encoding", which can be a legacy encoding on Windows. To ensure portability, text I/O operations needed parameters <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/charset/StandardCharsets.html#UTF_8" target="_blank" rel="noopener noreferrer"><code>StandardCharsets.UTF_8</code></a>. This is no longer necessary.</p>
<p>If you want the file as a sequence of lines, call</p>
<pre><code>List&lt;String&gt; lines = Files.readAllLines(path);
</code></pre>
<p>If the file is large, process the lines lazily as a <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/stream/Stream.html" target="_blank" rel="noopener noreferrer"><code>Stream&lt;String&gt;</code></a>:</p>
<pre><code>try (Stream&lt;String&gt; lines = Files.lines(path)) {
    . . .
}
</code></pre>
<p>Also use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#lines(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.lines</code></a> if you can naturally process lines with stream operations (such as <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/stream/Stream.html#map(java.util.function.Function)" target="_blank" rel="noopener noreferrer"><code>map</code></a>, <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/stream/Stream.html#filter(java.util.function.Predicate)" target="_blank" rel="noopener noreferrer"><code>filter</code></a>). Note that the stream returned by <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#lines(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.lines</code></a> needs to be closed. To ensure that this happens, use a <em>try-with-resources</em> statement, as in the preceding code snippet.</p>
<p>There is no longer a good reason to use the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/BufferedReader.html#readLine()" target="_blank" rel="noopener noreferrer"><code>readLine</code></a> method of <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/BufferedReader.html" target="_blank" rel="noopener noreferrer"><code>java.io.BufferedReader</code></a>.</p>
<p>To split your input into something else than lines, use a <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/Scanner.html" target="_blank" rel="noopener noreferrer"><code>java.util.Scanner</code></a>. For example, here is how you can read words, separated by non-letters:</p>
<pre><code>Stream&lt;String&gt; tokens = new Scanner(path).useDelimiter("\\PL+").tokens();
</code></pre>
<p>The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/Scanner.html" target="_blank" rel="noopener noreferrer"><code>Scanner</code></a> class also has methods for reading numbers, but it is generally simpler to read the input as one string per line, or a single string, and then parse it. </p>
<p>Be careful when parsing numbers from text files, since their format may be locale-dependent. For example, the input <code>100.000</code> is 100.0 in the US locale but 100000.0 in the German locale. Use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/text/NumberFormat.html" target="_blank" rel="noopener noreferrer"><code>java.text.NumberFormat</code></a> for locale-specific parsing. Alternatively, you may be able to use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/lang/Integer.html#parseInt(java.lang.String)" target="_blank" rel="noopener noreferrer"><code>Integer.parseInt</code></a>/<a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/lang/Double.html#parseDouble(java.lang.String)" target="_blank" rel="noopener noreferrer"><code>Double.parseDouble</code></a>.</p>

<h2 id="writing-text-files">Writing Text Files</h2>
<p>You can write a string to a text file with a single call:</p>
<pre><code>String content = . . .;
Files.writeString(path, content);
</code></pre>
<p>If you have a list of lines rather than a single string, use:</p>
<pre><code>List&lt;String&gt; lines = . . .;
Files.write(path, lines);
</code></pre>
<p>For more general output, use a <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html" target="_blank" rel="noopener noreferrer"><code>PrintWriter</code></a> if you want to use the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html#printf(java.lang.String,java.lang.Object...)" target="_blank" rel="noopener noreferrer"><code>printf</code></a> method:</p>
<pre><code>var writer = new PrintWriter(path.toFile());
writer.printf(locale, "Hello, %s, next year you'll be %d years old!%n", name, age + 1);
</code></pre>
<p>Note that <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html#printf(java.lang.String,java.lang.Object...)" target="_blank" rel="noopener noreferrer"><code>printf</code></a> is locale-specific. When writing numbers, be sure to write them in the appropriate format. Instead of using <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html#printf(java.lang.String,java.lang.Object...)" target="_blank" rel="noopener noreferrer"><code>printf</code></a>, consider <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/text/NumberFormat.html" target="_blank" rel="noopener noreferrer"><code>java.text.NumberFormat</code></a> or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/lang/Integer.html#toString()" target="_blank" rel="noopener noreferrer"><code>Integer.toString</code></a>/<a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/lang/Double.html#Double.html#toString(double)" target="_blank" rel="noopener noreferrer"><code>Double.toString</code></a>.</p>
<p>Weirdly enough, as of Java 21, there is no <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html" target="_blank" rel="noopener noreferrer"><code>PrintWriter</code></a> constructor with a <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Path.html" target="_blank" rel="noopener noreferrer"><code>Path</code></a> parameter.</p>
<p>If you don't use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/PrintWriter.html#printf(java.lang.String,java.lang.Object...)" target="_blank" rel="noopener noreferrer"><code>printf</code></a>, you can use the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/BufferedWriter.html" target="_blank" rel="noopener noreferrer"><code>BufferedWriter</code></a> class and write strings with the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/BufferedWriter.html#write(int)" target="_blank" rel="noopener noreferrer"><code>write</code></a> method. </p>
<pre><code>var writer = Files.newBufferedWriter(path);
writer.write(line); // Does not write a line separator
writer.newLine(); 
</code></pre>
<p>Remember to close the <code>writer</code> when you are done.</p>

<h2 id="reading-from-an-input-stream">Reading From an Input Stream</h2>
<p>Perhaps the most common reason to use a stream is to read something from a web site.</p>
<p>If you need to set request headers or read response headers, use the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.net.http/java/net/http/HttpClient.html" target="_blank" rel="noopener noreferrer"><code>HttpClient</code></a>:</p>
<pre><code>HttpClient client = HttpClient.newBuilder().build();
HttpRequest request = HttpRequest.newBuilder()
    .uri(URI.create("https://horstmann.com/index.html"))
    .GET()
    .build();
HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString());
String result = response.body();
</code></pre>
<p>That is overkill if all you want is the data. Instead, use:</p>
<pre><code>InputStream in = new URI("https://horstmann.com/index.html").toURL().openStream();
</code></pre>
<p>Then read the data into a byte array and optionally turn them into a string:</p>
<pre><code>byte[] bytes = in.readAllBytes();
String result = new String(bytes);
</code></pre>
<p>Or transfer the data to an output stream:</p>
<pre><code>OutputStream out = Files.newOutputStream(path);
in.transferTo(out);
</code></pre>
<p>Note that no loop is required if you simply want to read all bytes of an input stream. </p>
<p>But do you really need an input stream? Many APIs give you the option to read from a file or URL. </p>
<p>Your favorite JSON library is likely to have methods for reading from a file or URL. For example, with <a href="https://github.com/FasterXML/jackson-jr">Jackson jr</a>:</p>
<pre><code>URL url = new URI("https://dog.ceo/api/breeds/image/random").toURL();
Map&lt;String, Object&gt; result = JSON.std.mapFrom(url);
</code></pre>
<p>Here is how to read the dog image from the preceding call:</p>
<pre><code>URL url = new URI(result.get("message").toString()).toURL();
BufferedImage img = javax.imageio.ImageIO.read(url);
</code></pre>
<p>This is better than passing an input stream to the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.desktop/javax/imageio/ImageIO.html#read(java.net.URL)" target="_blank" rel="noopener noreferrer"><code>read</code></a> method, because the library can use additional information from the URL to determine the image type.</p>

<h2 id="the-files-api">The Files API</h2>
<p>The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html" target="_blank" rel="noopener noreferrer"><code>java.nio.file.Files</code></a> class provides a comprehensive set of file operations, such as creating, copying, moving, and deleting files and directories. The <a href="https://dev.java/learn/java-io/file-system/">File System Basics</a> tutorial provides a thorough description. In this section, I highlight a few common tasks.</p>
<h3 id="traversing-entries-in-directories-and-subdirectories">Traversing Entries in Directories and Subdirectories</h3>
<p>For most situations you can use one of two methods. The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#list(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.list</code></a> method visits all entries (files, subdirectories, symbolic links) of a directory.</p>
<pre><code>try (Stream&lt;Path&gt; entries = Files.list(pathToDirectory)) {
    . . .
}
</code></pre>
<p>Use a <em>try-with-resources</em> statement to ensure that the stream object, which keeps track of the iteration, will be closed.</p>
<p>If you also want to visit the entries of descendant directories, instead use the method <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walk(java.nio.file.Path,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.walk</code></a></p>
<pre><code>Stream&lt;Path&gt; entries = Files.walk(pathToDirectory);
</code></pre>
<p>Then simply use stream methods to home in on the entries that you are interested in, and to collect the results:</p>
<pre><code>try (Stream&lt;Path&gt; entries = Files.walk(pathToDirectory)) {
    List&lt;Path&gt; htmlFiles = entries.filter(p -&gt; p.toString().endsWith("html")).toList();
    . . .
}
</code></pre>
<p>Here are the other methods for traversing directory entries:</p>
<ul>
<li>An overloaded version of <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walk(java.nio.file.Path,int,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.walk</code></a> lets you limit the depth of the traversed tree.</li>
<li>Two <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walkFileTree(java.nio.file.Path,java.nio.file.FileVisitor)" target="_blank" rel="noopener noreferrer"><code>Files.walkFileTree</code></a> methods provide more control over the iteration process, by notifying a <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/FileVisitor.html" target="_blank" rel="noopener noreferrer"><code>FileVisitor</code></a> when a directory is visited for the first and last time. This can be occasionally useful, in particularly for emptying and deleting a tree of directories. See the tutorial <a href="https://dev.java/learn/java-io/file-system/walking-tree/">Walking the File Tree</a> for details. Unless you need this control, use the simpler <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walk(java.nio.file.Path,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.walk</code></a> method.</li>
<li>The <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#find(java.nio.file.Path,int,java.util.function.BiPredicate,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.find</code></a> method is just like <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walk(java.nio.file.Path,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.walk</code></a>, but you provide a filter that inspects each path and its <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/attribute/BasicFileAttributes.html" target="_blank" rel="noopener noreferrer"><code>BasicFileAttributes</code></a>. This is slightly more efficient than reading the attributes separately for each file.</li>
<li>Two <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#newDirectoryStream(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.newDirectoryStream(Path)</code></a> methods yields <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/DirectoryStream.html" target="_blank" rel="noopener noreferrer"><code>DirectoryStream</code></a> instances, which can be used in enhanced <code>for</code> loops. There is no advantage over using <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#list(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.list</code></a>. </li>
<li>The legacy <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/File.html#list()" target="_blank" rel="noopener noreferrer"><code>File.list</code></a> or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/File.html#listFiles()" target="_blank" rel="noopener noreferrer"><code>File.listFiles</code></a> methods return file names or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/File.html" target="_blank" rel="noopener noreferrer"><code>File</code></a> objects. These are now obsolete.</li>
</ul>
<h3 id="working-with-zip-files">Working with ZIP Files</h3>
<p>Ever since Java 1.1, the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/zip/ZipInputStream.html" target="_blank" rel="noopener noreferrer"><code>ZipInputStream</code></a> and <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/zip/ZipOutputStream.html" target="_blank" rel="noopener noreferrer"><code>ZipOutputStream</code></a> classes provide an API for processing ZIP files. But the API is a bit clunky. Java 8 introduced a much nicer <em>ZIP file system</em>:</p>
<pre><code>try (FileSystem fs = FileSystems.newFileSystem(pathToZipFile)) {
    . . .
}
</code></pre>
<p>The <em>try-with-resources</em> statement ensures that the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/lang/AutoCloseable.html#close()" target="_blank" rel="noopener noreferrer"><code>close</code></a> method is called after the ZIP file operations. That method updates the ZIP file to reflect any changes in the file system.</p>
<p>You can then use the methods of the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html" target="_blank" rel="noopener noreferrer"><code>Files</code></a> class. Here we get a list of all files in the ZIP file:</p>
<pre><code>try (Stream&lt;Path&gt; entries = Files.walk(fs.getPath("/"))) {
    List&lt;Path&gt; filesInZip = entries.filter(Files::isRegularFile).toList();
}
</code></pre>
<p>To read the file contents, just use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#readString(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.readString</code></a> or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#readAllBytes(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.readAllBytes</code></a>:</p>
<pre><code>String contents = Files.readString(fs.getPath("/LICENSE"));
</code></pre>
<p>You can remove files with <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#delete(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.delete</code></a>. To add or replace files, simply use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#writeString(java.nio.file.Path,java.lang.CharSequence,java.nio.file.OpenOption...)" target="_blank" rel="noopener noreferrer"><code>Files.writeString</code></a> or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#write(java.nio.file.Path,byte%5B%5D,java.nio.file.OpenOption...)" target="_blank" rel="noopener noreferrer"><code>Files.write</code></a>.</p>
<h3 id="creating-temporary-files-and-directories">Creating Temporary Files and Directories</h3>
<p>Fairly often, I need to collect user input, produce files, and run an external process. Then I use temporary files, which are gone after the next reboot, or a temporary directory that I erase after the process has completed.</p>
<p>I use the two methods <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#createTempFile(java.lang.String,java.lang.String,java.nio.file.attribute.FileAttribute...)" target="_blank" rel="noopener noreferrer"><code>Files.createTempFile</code></a> and <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#createTempDirectory(java.nio.file.Path,java.lang.String,java.nio.file.attribute.FileAttribute...)" target="_blank" rel="noopener noreferrer"><code>Files.createTempDirectory</code></a> for that. </p>
<pre><code>Path filePath = Files.createTempFile("myapp", ".txt");
Path dirPath = Files.createTempDirectory("myapp");
</code></pre>
<p>This creates a temporary file or directory in a suitable location (<code>/tmp</code> in Linux) with the given prefix and, for a file, suffix.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Web searches and AI chats can suggest needlessly complex code for common I/O operations. There are often better alternatives:</p>
<ol>
<li>You don't need a loop to read or write strings or byte arrays.</li>
<li>You may not even need a stream, reader or writer.</li>
<li>Become familiar with the <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html" target="_blank" rel="noopener noreferrer"><code>Files</code></a> methods for creating, copying, moving, and deleting files and directories.</li>
<li>Use <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#list(java.nio.file.Path)" target="_blank" rel="noopener noreferrer"><code>Files.list</code></a> or <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/nio/file/Files.html#walk(java.nio.file.Path,java.nio.file.FileVisitOption...)" target="_blank" rel="noopener noreferrer"><code>Files.walk</code></a> to traverse directory entries.</li>
<li>Use a ZIP file system for processing ZIP files.</li>
<li>Stay away from the legacy <a href="https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/io/File.html" target="_blank" rel="noopener noreferrer"><code>File</code></a> class.</li>
</ol>


                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judges suspends FCC net neutrality restoration rule (125 pts)]]></title>
            <link>https://www.inc.com/bruce-crumley/judges-suspend-fcc-net-neutrality-restoration-rule.html</link>
            <guid>41142710</guid>
            <pubDate>Fri, 02 Aug 2024 21:09:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inc.com/bruce-crumley/judges-suspend-fcc-net-neutrality-restoration-rule.html">https://www.inc.com/bruce-crumley/judges-suspend-fcc-net-neutrality-restoration-rule.html</a>, See on <a href="https://news.ycombinator.com/item?id=41142710">Hacker News</a></p>
Couldn't get https://www.inc.com/bruce-crumley/judges-suspend-fcc-net-neutrality-restoration-rule.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Towards userspaceification of POSIX – part I: signal handling and IO (112 pts)]]></title>
            <link>https://www.redox-os.org/news/kernel-11/</link>
            <guid>41142686</guid>
            <pubDate>Fri, 02 Aug 2024 21:07:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.redox-os.org/news/kernel-11/">https://www.redox-os.org/news/kernel-11/</a>, See on <a href="https://news.ycombinator.com/item?id=41142686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
    
  
  
    <h5>By Jacob Lorentzon (4lDO2)
      
        on <time datetime="2024-07-09 00:22:00 +0200 +0200">Tuesday, July 9, 2024</time>
      
    </h5>
  
  <h2 id="introduction">Introduction</h2>
<p>I’m very exited to announce that Redox has been selected as <a href="https://nlnet.nl/news/2024/20240618-Call-announcement.html">one of the 45
projects receiving new NGI Zero
grants</a>, with me as
primary developer for <a href="https://nlnet.nl/project/RedoxOS-Signals/">Redox’s POSIX signals
project</a>! The goal of this project
it to implement proper POSIX signal handling and process management, and to do
this in userspace to the largest reasonable extent. This grant is obviously
highly beneficial for Redox, and will allow me to dedicate significantly more
time to work on the Redox kernel and related components for one year.</p>
<p>As this announcement came roughly a week after RSoC started, I spent the
first week preparing the kernel for new IPC changes, by investing some time
into changing the scheme packet format, improving both performance and the
possible set of IPC messages.</p>
<p>Since then, I’ve been working on replacing the current signal implementation
with a mostly userspace-based one, initially keeping the same level of support
without adding new features. This has almost been merged.</p>
<h2 id="improved-userspace-scheme-protocol-and-stateless-io">Improved userspace scheme protocol, and stateless IO</h2>
<p>TL;DR <strong>As announced in the June report, an improved scheme packet format and
two new syscalls have improved RedoxFS copy performance by 63%!</strong></p>
<p>The Redox kernel implements IO syscalls, such as SYS_READ, by mapping affected
memory ranges directly into the handler process, and by queueing <code>Packet</code>s
containing metadata of those scheme calls. The <code>Packet</code> struct has existed, and
had zero changes to the format, since <a href="https://gitlab.redox-os.org/redox-os/syscall/-/commit/0e7fec4adf35c9092b8c26c684bcb67ef5145a46">this commit from
2016</a>. It is defined as follows:</p>
<div><pre tabindex="0"><code data-lang="rust"><span>#[repr(packed)]</span>
<span>struct</span> <span>Packet</span> {
    id: <span>u64</span>, <span>// unique (among in-flight reqs) tag
</span><span></span>    pid: <span>usize</span>, <span>// caller context id
</span><span></span>    uid: <span>u32</span>, <span>// caller effective uid
</span><span></span>    gid: <span>u32</span>, <span>// caller effective gid
</span><span></span>    a: <span>usize</span>, <span>// SYS_READ
</span><span></span>    b: <span>usize</span>, <span>// fd
</span><span></span>    c: <span>usize</span>, <span>// buf.as_mut_ptr()
</span><span></span>    d: <span>usize</span>, <span>// buf.len()
</span><span></span>    <span>// 56 bytes on 64-bit platforms
</span><span></span>}
</code></pre></div><p>While this struct is sufficient for implementing most syscalls, the obvious
limitation of at most 3 arguments has resulted in accumulated technical debt
among many different Redox components. For example, since <code>pread</code> requires at
least 4 args, almost all schemes previously implemented boilerplate roughly of the
form</p>
<div><pre tabindex="0"><code data-lang="rust"><span>fn</span> <span>seek</span>(<span>&amp;</span><span>mut</span> self, fd: <span>usize</span>, pos: <span>isize</span>, whence: <span>usize</span>) -&gt; Result<span>&lt;</span><span>isize</span><span>&gt;</span> {
    <span>let</span> handle <span>=</span> self.handles.get_mut(<span>&amp;</span>fd).ok_or(Error::new(EBADF))<span>?</span>;
    <span>let</span> file <span>=</span> self
        .filesystem
        .files
        .get_mut(<span>&amp;</span>handle.inode)
        .ok_or(Error::new(EBADFD))<span>?</span>;

    <span>let</span> old <span>=</span> handle.offset;
    handle.offset <span>=</span> <span>match</span> whence {
        SEEK_SET <span>=&gt;</span> cmp::max(<span>0</span>, pos),
        SEEK_CUR <span>=&gt;</span> cmp::max(
            <span>0</span>,
            pos <span>+</span> <span>isize</span>::try_from(handle.offset).or(Err(Error::new(EOVERFLOW)))<span>?</span>,
        ),
        SEEK_END <span>=&gt;</span> cmp::max(
            <span>0</span>,
            pos <span>+</span> <span>isize</span>::try_from(file.data.size()).or(Err(Error::new(EOVERFLOW)))<span>?</span>,
        ),
        _ <span>=&gt;</span> <span>return</span> Err(Error::new(EINVAL)),
    } <span>as</span> <span>usize</span>;
    Ok(handle.offset <span>as</span> <span>isize</span>) <span>// why isize???
</span><span></span>}
</code></pre></div><p>as well as requiring all schemes to store the file cursor for all handles
(which on GNU Hurd similarly is considered a ‘questionable design choice’ in
<a href="http://walfield.org/papers/200707-walfield-critique-of-the-GNU-Hurd.pdf">the
critique</a>).
This cursor unfortunately cannot be stored in userspace without complex
coordination, since POSIX allows file descriptors to be shared by an arbitrary
number of processes, after e.g. forks or SCM_RIGHTS transfers (even though this
use case is most likely very rare, so it’s not entirely impossible for this
state to be moved to userspace).</p>
<p>The new format, similar to <a href="https://kernel.dk/io_uring.pdf">io_uring</a>, is now
defined as:</p>
<div><pre tabindex="0"><code data-lang="rust"><span>#[repr(C)]</span>
<span>struct</span> <span>Sqe</span> {
    opcode: <span>u8</span>,
    sqe_flags: <span>SqeFlags</span>,
    _rsvd: <span>u16</span>, <span>// TODO: priority
</span><span></span>    tag: <span>u32</span>,
    args: [<span>u64</span>; <span>6</span>],
    caller: <span>u64</span>,
}
<span>#[repr(C)]</span>
<span>struct</span> <span>Cqe</span> {
    flags: <span>u8</span>, <span>// bits 3:0 are CqeOpcode
</span><span></span>    extra_raw: [<span>u8</span>; <span>3</span>],
    tag: <span>u32</span>,
    result: <span>u64</span>,
}
</code></pre></div><p>SQEs and CQEs are the Submission/Completion Queue entries, where schemes read
and process SQEs, and respond to the kernel by sending corresponding CQEs.
These new types both nicely fit into 1, and 1/4th of a cache line,
respectively, and some unnecessarily large fields have been shortened.
<code>SYS_PREAD2</code> and <code>SYS_PWRITE2</code> have been added to the scheme API, that now
allow passing both offsets and per-syscall flags (like <code>RWF_NONBLOCK</code>). The
<code>args</code> member is opcode-dependent, and for <code>SYS_PREAD2</code> for example, is
populated as follows:</p>
<div><pre tabindex="0"><code data-lang="rust"><span>// { ... }
</span><span></span><span>let</span> inner <span>=</span> self.inner.upgrade().ok_or(Error::new(ENODEV))<span>?</span>;
<span>let</span> address <span>=</span> inner.capture_user(buf)<span>?</span>;
<span>let</span> result <span>=</span> inner.call(Opcode::Read, [file <span>as</span> <span>u64</span>, address.base() <span>as</span> <span>u64</span>, address.len() <span>as</span> <span>u64</span>, offset, <span>u64</span>::from(call_flags)]);
address.release()<span>?</span>;
<span>// { ... }
</span></code></pre></div><p>The last <code>args</code> element currently contains the UID and GID of the caller, but
this will eventually be replaced by a cleaner interface. The kernel currently
emulates these new syscalls as using <code>lseek</code> and then regular <code>read</code>/<code>write</code>
for legacy scheme, but for new schemes <code>lseek</code> can be ignored if the
application uses more modern APIs. For instance, in <code>redoxfs</code>:</p>
<div><pre tabindex="0"><code data-lang="diff">// This is the disk interface, which groups bytes into logical 4096-blocks.
// The interface doesn't support byte-granular IO size and offset, since the underlying disk drivers don't.

unsafe fn read_at(&amp;mut self, block: u64, buffer: &amp;mut [u8]) -&gt; Result&lt;usize&gt; {
<span>--  try_disk!(self.file.seek(SeekFrom::Start(block * BLOCK_SIZE)));
</span><span>--  let count = try_disk!(self.file.read(buffer));
</span><span>--  Ok(count)
</span><span></span><span>++  self.file.read_at(buffer, block * BLOCK_SIZE).or_eio()
</span><span></span>}

unsafe fn write_at(&amp;mut self, block: u64, buffer: &amp;[u8]) -&gt; Result&lt;usize&gt; {
<span>--  try_disk!(self.file.seek(SeekFrom::Start(block * BLOCK_SIZE)));
</span><span>--  let count = try_disk!(self.file.write(buffer));
</span><span>--  Ok(count)
</span><span></span><span>++  self.file.write_at(buffer, block * BLOCK_SIZE).or_eio()
</span><span></span>}
</code></pre></div><p>Jeremy Soller previously used the file copy utility <code>dd</code> as a benchmark when tuning the most efficient block size,
taking into account both context switch and virtual memory overhead. The
throughput for reading a 277 MiB file using <code>dd</code> with a <code>4 MiB</code> buffer size,
was thus increased from <a href="https://www.redox-os.org/news/this-month-240229">170 MiB/s</a>, for the previous optimizations, to 277 MiB/s with the new interface,
roughly a 63% improvement. There is obviously a lot more nuance in how this
would affect performance depending on parameters, but this (low-hanging)
optimization is indeed noticeable!</p>
<p>For comparison, running the same command on Linux, with the same virtual machine configuration,
gives a throughput of roughly 2 GiB/s, which is obviously a significant
difference. Both RedoxFS (which is currently fully sequential) and raw context
switch performance will need to be improved. (Copying disks directly is done at
2 GiB/s on Linux and 0.8 GiB/s on Redox).</p>
<h3 id="todo">TODO</h3>
<ul>
<li>There are still many schemes currently using the old packet format. They will need to be converted, allowing the kernel to remove the overhead of supporting the old format.</li>
<li>The <code>Event</code> struct can similarly be improved.</li>
<li>Both scheme SQEs and events should be accessible to handlers from a ring buffer (like io_uring), rather than the current mechanism where they are read as messages using SYS_READ. And syscall overhead, although strictly faster than context switching, is still noticeable, which is also why io_uring exists in the first place on Linux.</li>
</ul>
<h2 id="signal-handling">Signal handling</h2>
<p>The internal kernel signal implementation improved <a href="https://gitlab.redox-os.org/redox-os/kernel/-/merge_requests/283">earlier in
March</a>, to
address the earlier <a href="https://gitlab.redox-os.org/redox-os/kernel/-/issues/117">quite serious
shortcomings</a>.
However, even after the changes, signal support was still very limited, e.g. lacking support
for sigprocmask, sigaltstack, and most of sigaction.</p>
<h2 id="the-problem">The problem</h2>
<p>Over the past year, I have been working to a large extent on migrating most Redox components away from using <code>redox_syscall</code>, our direct system call interface, to <a href="https://gitlab.redox-os.org/redox-os/libredox"><code>libredox</code></a>, a more stable API.
<code>libredox</code> provides the common OS interfaces normally part of POSIX, but allows us to place much more of the functionality in userspace, with a written-in-Rust implementation (even this is currently done by <code>relibc</code>, which also implements the C standard library).
This migration is now virtually complete.</p>
<p>Normally, monolithic kernels will expose a stable syscall ABI, sometimes guaranteed (e.g. Linux), and otherwise stable in practice (FreeBSD), with the most notable exception being OpenBSD (in the Unix world).
This makes sense on monolithic kernels, since they are large enough to ‘afford’ compatibility with older interfaces, and also because much of the actual performance-critical stack is fully in kernel mode, avoiding the user/kernel transition cost.
On a microkernel however, the kernel is meant to be as minimal as possible, and because the syscall interface on most successful microkernels differs from monolithic kernels' syscalls, that often match POSIX 1:1, this means our POSIX implementation will need to implement more POSIX logic in userspace.
The primary example is currently the program loader, which along with <code>fork()</code> was fully moved to userspace during RSoC 2022.
Along with possibly significant optimization opportunities, this is the rationale behind our <a href="https://www.redox-os.org/news/development-priorities-2023-09/">stable ABI policy</a> introduced last year, where the stable ABI boundary will be present in userspace rather than at the syscall ABI.</p>
<p>The initial architecture will be roughly the following:</p>
<hr>
<p><img src="https://www.redox-os.org/img/signals-project/abi.svg" alt="Redox ABI diagram"></p>
<p>A simple example of what <code>relibc</code> defers to userspace is the current working directory (changed during my <a href="https://www.redox-os.org/news/drivers-and-kernel-7">RSoC 2022</a>).
This requires relibc to enter a <code>sigprocmask</code> critical section in order to lock the CWD, when implementing async-signal-safe <em>open(3)</em> (in this particular case there are workarounds, but in general such critical sections will be necessary):</p>
<div><pre tabindex="0"><code data-lang="rust"><span>// relibc/src/platform/redox/path.rs
</span><span></span><span>pub</span> <span>fn</span> <span>canonicalize</span>(path: <span>&amp;</span><span>str</span>) -&gt; Result<span>&lt;</span>String<span>&gt;</span> {
    <span>// calls sigprocmask to disable signals
</span><span></span>    <span>let</span> _siglock <span>=</span> SignalMask::lock();
    <span>let</span> cwd <span>=</span> CWD.lock();
    canonicalize_using_cwd(cwd.as_deref(), path).ok_or(Error::new(ENOENT))
    <span>// sigprocmask is called again when _siglock goes out of scope
</span><span></span>}
</code></pre></div><p>If more kernel state is moved to relibc, such as the <code>O_CLOEXEC</code> and
<code>O_CLOFORK</code> (added in POSIX 2024) bits, or say, some type of file descriptors
were to take shortcuts in relibc (like pipes using ring buffers), the overhead
of two <code>sigprocmask</code> syscalls, wrapping each critical section, will make lots of
POSIX APIs unnecessarily slow. Thus, it would be useful if signals could be
disabled quickly in userspace, using memory shared with the kernel.</p>
<h2 id="userspace-signals">Userspace Signals</h2>
<p>The currently proposed solution is to implement <code>sigaction</code>, <code>sigprocmask</code>, and
signal delivery (including <code>sigreturn</code>) only using shared atomic memory
accesses. The secret sauce is to use two <code>AtomicU64</code> bitsets (even i686
supports that, via <code>CMPXCHG8B</code>) stored in the TCB, one for standard signals and
one for realtime signals, where the low 32 bits are the pending bits, and the
high 32 bits are the allowset bits (logical NOT of the signal mask). This
allows, for signals directed at threads, changing the signal mask while
simultaneously checking what the pending bits were at the time, making
<code>sigprocmask</code> wait-free (if <code>fetch_add</code> is).</p>
<p>Not all technical details have been finalized yet, but there is a
<a href="https://gitlab.redox-os.org/4lDO2/rfcs/-/blob/signals/text/0000-userspace-signals.md">preliminary
RFC</a>.
Signals targeting whole processes is not yet implemented, since <a href="https://gitlab.redox-os.org/redox-os/kernel/-/issues/153">Redox’s
kernel does not yet distinguish between processes and
threads</a>. Once that
has been fixed, work will continue to implement <code>siginfo_t</code> for both regular
and queued signals, and to add the <code>sigqueue</code> API for realtime signals.</p>
<p>This implementation proposal focuses primarily on optimizing the
receive-related signal APIs, as opposed to <code>kill</code>/<code>pthread_kill</code> and
<code>sigqueue</code>, which need exclusive access (which will probably not change), currently
kept in the kernel. A <a href="https://gitlab.redox-os.org/redox-os/kernel/-/issues/152">userspace process
manager</a> has also
been proposed, where the <code>kill</code> and (future) <code>sigqueue</code> syscalls can be
converted to IPC calls to that manager. The idea is for all POSIX ambient
authority, such as absolute paths, UID/GID/PID/…s, to be represented using
file descriptors (capabilities). This is one piece of the work that needs to be done to
fully support sandboxing.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So far, the signals project has been going according to plan, and hopefully,
POSIX support for signals will be mostly complete by the end of summer, with in-kernel improvements to process management. After
that, work on the userspace process manager will begin, possibly including new
kernel performance and/or functionality improvements to facilitate this.</p>


</div></div>]]></description>
        </item>
    </channel>
</rss>