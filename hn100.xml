<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 07 Dec 2024 05:30:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[RollerCoaster Tycoon was the last of its kind [video] (105 pts)]]></title>
            <link>https://www.youtube.com/watch?v=0JouTsMQsEA</link>
            <guid>42346463</guid>
            <pubDate>Sat, 07 Dec 2024 01:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=0JouTsMQsEA">https://www.youtube.com/watch?v=0JouTsMQsEA</a>, See on <a href="https://news.ycombinator.com/item?id=42346463">Hacker News</a></p>
Couldn't get https://www.youtube.com/watch?v=0JouTsMQsEA: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Structured Outputs with Ollama (114 pts)]]></title>
            <link>https://ollama.com/blog/structured-outputs</link>
            <guid>42346344</guid>
            <pubDate>Sat, 07 Dec 2024 01:12:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ollama.com/blog/structured-outputs">https://ollama.com/blog/structured-outputs</a>, See on <a href="https://news.ycombinator.com/item?id=42346344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  <article>
    
    <h2>December 6, 2024</h2>
    <section>
      <p><img src="https://ollama.com/public/blog/ollama-json.png" alt="Ollama playing with building blocks" width="70%"></p>

<p>Ollama now supports structured outputs making it possible to constrain a model’s output to a specific format defined by a JSON schema. The Ollama Python and JavaScript libraries have been updated to support structured outputs.</p>

<p>Use cases for structured outputs include:</p>

<ul>
<li>Parsing data from documents</li>
<li>Extracting data from images</li>
<li>Structuring all language model responses</li>
<li>More reliability and consistency than JSON mode</li>
</ul>

<h3>Get started</h3>

<p>Download the latest version of <a href="https://ollama.com/download">Ollama</a></p>

<p>Upgrade to the latest version of the Ollama Python or JavaScript library:</p>

<p><sub>Python</sub></p>

<pre><code>pip install -U ollama
</code></pre>

<p><sub>JavaScript</sub></p>

<pre><code>npm i ollama
</code></pre>

<p>To pass structured outputs to the model, the <code>format</code> parameter can be used in the cURL request or the <code>format</code> parameter in the Python or JavaScript libraries.</p>

<h4>cURL</h4>

<pre><code>curl -X POST http://localhost:11434/api/chat -H "Content-Type: application/json" -d '{
  "model": "llama3.1",
  "messages": [{"role": "user", "content": "Tell me about Canada."}],
  "stream": false,
  "format": {
    "type": "object",
    "properties": {
      "name": {
        "type": "string"
      },
      "capital": {
        "type": "string"
      },
      "languages": {
        "type": "array",
        "items": {
          "type": "string"
        }
      }
    },
    "required": [
      "name",
      "capital", 
      "languages"
    ]
  }
}'
</code></pre>

<h5>Output</h5>

<p>The response is returned in the format defined by the JSON schema in the request.</p>

<pre><code>{
  "capital": "Ottawa",
  "languages": [
    "English",
    "French"
  ],
  "name": "Canada"
}
</code></pre>

<h4>Python</h4>

<p>Using the <a href="https://github.com/ollama/ollama-python">Ollama Python library</a>, pass in the schema as a JSON object to the <code>format</code> parameter as either <code>dict</code> or use Pydantic (recommended) to serialize the schema using <code>model_json_schema()</code>.</p>

<pre><code>from ollama import chat
from pydantic import BaseModel

class Country(BaseModel):
  name: str
  capital: str
  languages: list[str]

response = chat(
  messages=[
    {
      'role': 'user',
      'content': 'Tell me about Canada.',
    }
  ],
  model='llama3.1',
  format=Country.model_json_schema(),
)

country = Country.model_validate_json(response.message.content)
print(country)
</code></pre>

<h5>Output</h5>

<pre><code>name='Canada' capital='Ottawa' languages=['English', 'French']
</code></pre>

<h4>JavaScript</h4>

<p>Using the <a href="https://github.com/ollama/ollama-js">Ollama JavaScript library</a>, pass in the schema as a JSON object to the <code>format</code> parameter as either <code>object</code> or use Zod (recommended) to serialize the schema using <code>zodToJsonSchema()</code>.</p>

<pre><code>import ollama from 'ollama';
import { z } from 'zod';
import { zodToJsonSchema } from 'zod-to-json-schema';

const Country = z.object({
    name: z.string(),
    capital: z.string(), 
    languages: z.array(z.string()),
});

const response = await ollama.chat({
    model: 'llama3.1',
    messages: [{ role: 'user', content: 'Tell me about Canada.' }],
    format: zodToJsonSchema(Country),
});

const country = Country.parse(JSON.parse(response.message.content));
console.log(country);
</code></pre>

<h5>Output</h5>

<pre><code>{
  name: "Canada",
  capital: "Ottawa",
  languages: [ "English", "French" ],
}
</code></pre>

<h2>Examples</h2>

<h3>Data extraction</h3>

<p>To extract structured data from text, define a schema to represent information. The model then extracts the information and returns the data in the defined schema as JSON:</p>

<pre><code>from ollama import chat
from pydantic import BaseModel

class Pet(BaseModel):
  name: str
  animal: str
  age: int
  color: str | None
  favorite_toy: str | None

class PetList(BaseModel):
  pets: list[Pet]

response = chat(
  messages=[
    {
      'role': 'user',
      'content': '''
        I have two pets.
        A cat named Luna who is 5 years old and loves playing with yarn. She has grey fur.
        I also have a 2 year old black cat named Loki who loves tennis balls.
      ''',
    }
  ],
  model='llama3.1',
  format=PetList.model_json_schema(),
)

pets = PetList.model_validate_json(response.message.content)
print(pets)

</code></pre>

<h4>Example output</h4>

<pre><code>pets=[
  Pet(name='Luna', animal='cat', age=5, color='grey', favorite_toy='yarn'), 
  Pet(name='Loki', animal='cat', age=2, color='black', favorite_toy='tennis balls')
]
</code></pre>

<h3>Image description</h3>

<p>Structured outputs can also be used with vision models. For example, the following code uses <code>llama3.2-vision</code> to describe the following image and returns a structured output:</p>

<p><img src="https://ollama.com/public/blog/beach.jpg" alt="image"></p>

<pre><code>from ollama import chat
from pydantic import BaseModel

class Object(BaseModel):
  name: str
  confidence: float
  attributes: str 

class ImageDescription(BaseModel):
  summary: str
  objects: List[Object]
  scene: str
  colors: List[str]
  time_of_day: Literal['Morning', 'Afternoon', 'Evening', 'Night']
  setting: Literal['Indoor', 'Outdoor', 'Unknown']
  text_content: Optional[str] = None

path = 'path/to/image.jpg'

response = chat(
  model='llama3.2-vision',
  format=ImageDescription.model_json_schema(),  # Pass in the schema for the response
  messages=[
    {
      'role': 'user',
      'content': 'Analyze this image and describe what you see, including any objects, the scene, colors and any text you can detect.',
      'images': [path],
    },
  ],
  options={'temperature': 0},  # Set temperature to 0 for more deterministic output
)

image_description = ImageDescription.model_validate_json(response.message.content)
print(image_description)
</code></pre>

<h4>Example output</h4>

<pre><code>summary='A palm tree on a sandy beach with blue water and sky.' 
objects=[
  Object(name='tree', confidence=0.9, attributes='palm tree'), 
  Object(name='beach', confidence=1.0, attributes='sand')
], 
scene='beach', 
colors=['blue', 'green', 'white'], 
time_of_day='Afternoon' 
setting='Outdoor' 
text_content=None
</code></pre>

<h4>OpenAI compatibility</h4>

<pre><code>from openai import OpenAI
import openai
from pydantic import BaseModel

client = OpenAI(base_url="http://localhost:11434/v1", api_key="ollama")

class Pet(BaseModel):
    name: str
    animal: str
    age: int
    color: str | None
    favorite_toy: str | None

class PetList(BaseModel):
    pets: list[Pet]

try:
    completion = client.beta.chat.completions.parse(
        temperature=0,
        model="llama3.1:8b",
        messages=[
            {"role": "user", "content": '''
                I have two pets.
                A cat named Luna who is 5 years old and loves playing with yarn. She has grey fur.
                I also have a 2 year old black cat named Loki who loves tennis balls.
            '''}
        ],
        response_format=PetList,
    )

    pet_response = completion.choices[0].message
    if pet_response.parsed:
        print(pet_response.parsed)
    elif pet_response.refusal:
        print(pet_response.refusal)
except Exception as e:
    if type(e) == openai.LengthFinishReasonError:
        print("Too many tokens: ", e)
        pass
    else:
        print(e)
        pass
</code></pre>

<h2>Tips</h2>

<p>For reliable use of structured outputs, consider to:</p>

<ul>
<li>Use Pydantic (Python) or Zod (JavaScript) to define the schema for the response</li>
<li>Add “return as JSON” to the prompt to help the model understand the request</li>
<li>Set the temperature to 0 for more deterministic output</li>
</ul>

<h2>What’s next?</h2>

<ul>
<li>Exposing logits for controlled generation</li>
<li>Performance and accuracy improvements for structured outputs</li>
<li>GPU acceleration for sampling</li>
<li>Additional format support beyond JSON schema</li>
</ul>

    </section>
  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenWrt One router officially launched (117 pts)]]></title>
            <link>https://openwrt.org/#openwrt_one_router_officially_launched</link>
            <guid>42345500</guid>
            <pubDate>Fri, 06 Dec 2024 23:00:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openwrt.org/#openwrt_one_router_officially_launched">https://openwrt.org/#openwrt_one_router_officially_launched</a>, See on <a href="https://news.ycombinator.com/item?id=42345500">Hacker News</a></p>
Couldn't get https://openwrt.org/#openwrt_one_router_officially_launched: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My second year without a job (157 pts)]]></title>
            <link>https://shilin.ca/my-second-year-without-job/</link>
            <guid>42344002</guid>
            <pubDate>Fri, 06 Dec 2024 20:26:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shilin.ca/my-second-year-without-job/">https://shilin.ca/my-second-year-without-job/</a>, See on <a href="https://news.ycombinator.com/item?id=42344002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2024-12-06T19:48Z">
                    06 Dec, 2024
                </time>
            </i>
        </p>
    

    <p>Two years ago, I quit my job. I was divorced, and I had $80K on my bank account. Today, I am still without a job, still divorced, and, not surprisingly, out of money. I wish I had written about my first year of unemployment, so I can compare the <del>regress</del> progress. At the very least, I can do a short overview of this year, so I’ll have something to compare in the next one.</p>
<h2 id="tangible">Tangible</h2><h2 id="money">Money</h2><p>At first, I was sad that I had spent all the money so quickly. If you think about it, $80K in two years is $40K a year, or $3,300 a month. It's a considerable amount, and I used to think that I overspent. That my groceries could have been cheaper. That I could have eaten out or traveled less. Then a few months ago, I went on <a href="https://nomads.com/" target="_blank">NomadList</a> and found out that the average living cost in Montreal is $3,750/mo. Considering that I spent the first year in Ottawa/Toronto, where the cost of living is even higher, my spending habits turned out not that bad after all. I’m not just average — I’m slightly better! So I said goodbye to my money and made peace with the fact that I would be broke for a while.</p>
<p>At the end of 2022, when I quit my job to work on my projects, I made resolutions: to make $1M in revenue in 2025. Well, that's not really happening… But rest assured, I do everything possible to reach that goal rather sooner than later.</p>
<p>(the picture of the money left in my bank account)</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shilin/no-money-left.webp" alt="no-money-left"></p>
<h2 id="work">Work</h2><p>Since January, I worked on four projects with four other founders. First, <a href="https://shilin.ca/guitars-programming-guitartonic/">we launched Guitartonic</a> with Armaan, and it was fulfilling to build something for fun. Then we tried to get a fintech product going with Nima, but failed to agree on a common vision. After that, I took a month off to try to resurrect <a href="https://shilin.ca/building-projects-is-fun/">Wonderbook</a>. I reworked the entire app, redesigning screens and introducing a couple of important features. But as much as I would rather not admit, Wonderbook was a dying project, and none of my changes helped. So I watched the traffic plummet, made a loud sigh, and went on with life.</p>
<p>In April, Zane reached out with an idea of a product he wanted to build. We spent two weeks putting an MVP together, and shortly after, we landed the first two customers. Blymp <a href="https://shilin.ca/startup-updates-first-users-and-the-road-ahead/">was born</a>. Zane had to step down from the operations in July, but I kept going. Of the four projects I worked on, blymp is the only one generating money — about $600/month — and the one I plan to continue next year. Yay!</p>
<h2 id="housing">Housing</h2><p>This year I stayed in the same place, an old victorian-style house in downtown Montreal, with 3 other roommates. But the house is not by any means a usual co-living situation. The person who launched it is also an entrepreneur, and he started this project for other entrepreneurs to collaborate and inspire each other. When I signed the lease last year, I already had an offer for another place, a one-bedroom apartment in my favorite neighborhood of the city. Plus, the price was similar, so I wouldn't have saved a lot of money by living with other people. But collaboration is the seed for innovation, so I decided to give it a try.</p>
<p>These days, we do a lot of things together, and it has a positive impact on my mental health. Once a week, we play board games, cook food, or do coworking sessions. Living with others is not always easy, but it is fun. I got very lucky with these folks, and I hope we keep the good vibes going forward in the new year.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shilin/the-boys-in-the-mountains.webp" alt="the-boys-in-the-mountains"></p>
<p>Numbers-wise, my rent is $1250 for a room, which is between one-third and one-half of my monthly budget. I could find something cheaper, but I chose sanity over an extra month of runway.</p>
<h2 id="intangible">Intangible</h2><h2 id="music">Music</h2><p>In June, I started playing piano. I have always loved music, and the fact that I still play guitar after 18 years only confirms it. While the guitar entered my life through my desire to play songs for friends, the piano was an accidental discovery. My roommate, who just moved in with us this spring, brought his piano with him. It stood untouched in our living room for a month. One evening, while watching Amélie with Yann Tiersen's beautiful music, I felt an inexplicable urge to learn that song. So I did. It took me about a month to sync the movements of both hands — remember, I had never played piano before — but it came together and sounded decent.</p>
<p>After that, I went on to learn <em>Sleeping Lotus</em> by Joep Beving and <em>Ascent (Day 1)</em> by Ludovico Einaudi. Approaching the end of this year, I am 90% done with my fifth piece, <em>Lumières</em> by Alexandra Stréliski, and it’s both the hardest and most beautiful song I’ve learned so far. It took me two months just to finish reading it, and it will likely take another two to get comfortable playing it.</p>
<p>Guitartonic, the app that I built back in January, also reignited my passion for guitar. It helped me learn a few positions of a minor pentatonic scale, so now I can improvise along when playing with other people. It's not great by any means, but it's progress nonetheless.</p>
<h2 id="sports">Sports</h2><p>Oh boy, did I do sports this year! At the end of 2023, I joined a climbing team to train for provincial and national bouldering competitions in Canada. The training stopped suddenly when our coach got injured and couldn't come to the gym anymore. So the beginning of 2024 was rough, as my team continued to train without him. It simply wasn't the same thing anymore. But we decided to keep up with the schedule our coach had set for us, and it kept us motivated for a few months. By summer, bouldering moved to the back of my priorities, as I started going outdoor more often. I introduced lead climbing and went on climbing trips. Nima and I bought gear of our own -- a rope, quickdraws, and peripherals. While I avoid spending a lot of money on new hobbies, this felt justified. Now, looking back, I don't regret that we did it.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shilin/img_1957.webp" alt="IMG_1957"></p>
<p>Along with climbing, we started to train for a triathlon around June. The triathlon was scheduled for September, so we had about three months to prepare. Swimming terrified me the most, but turned out the most pleasurable exercise of all three. Biking was never an issue for me — I always liked it. But running was a different story. I have a love/hate relationship with running, dating back to 2020. I was bored during Covid, started going for short runs in the evenings, and because of my poor technique, I killed my knees in only 3 months. It took me two years to fully recover.</p>
<p>These days, running feels much better, and I have my climbing sessions to thank for it — my butt got much stronger, so my knees don't have to work as hard.</p>
<h2 id="gut">Gut</h2><p>Unlike with sports, the relationship with my stomach is rather tough. For the last two years, it's been giving me a hard time. I have only two possible explanations. Stress from not having a stable income, or a side effect from a year-long course of Accutane — the timing aligns well with this. The end of this year was the time I decided to make changes. I went on a FODMAP diet and finally saw improvements. For the first time in months, I had no symptoms. No gas and no bloating. I still remember the first evening of my diet, as I felt like a happy man, all because my stomach was also happy.</p>
<p>My diet is not over, and I am slowly reintroducing food groups to my meals to find out what causes intolerances. Being on a diet without lactose, gluten, and many other foods is hard. But having a healthy gut is certainly a step up from not having one. For better or worse, it forced me to cook more. And knowing me, that's not a small win.</p>
<h2 id="overall">Overall</h2><p>At first, I thought I would only write about my projects, as any struggling entrepreneur should. But this year was about much more than just projects. Without music, sports, and friends, I wouldn't be able to keep up with work, especially unpaid. No matter the angle under which I look at it, it was a great year — fulfilling, with a lot of love and care. It's exciting to look ahead. I am always intrigued by what comes next. For the past few years, my rule has been simple: keep the good things, cut the bad things, and acquire more of the good things. But this year… I don't really have bad things. Minor inconveniences, maybe. Hiccups. But nothing that I am looking to part with.</p>
<p>Here's to a promising year 2025. My third year without a job. A year when I give more than I receive. A year of patience. And a year of an even deeper connection with myself. Cheers!</p>


    

    
        
            <p>
                
                    <a href="https://shilin.ca/blog/?q=entrepreneurship">#entrepreneurship</a>
                
                    <a href="https://shilin.ca/blog/?q=money">#money</a>
                
            </p>
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lies I was told about collab editing, Part 1: Algorithms for offline editing (150 pts)]]></title>
            <link>https://www.moment.dev/blog/lies-i-was-told-pt-1</link>
            <guid>42343953</guid>
            <pubDate>Fri, 06 Dec 2024 20:22:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.moment.dev/blog/lies-i-was-told-pt-1">https://www.moment.dev/blog/lies-i-was-told-pt-1</a>, See on <a href="https://news.ycombinator.com/item?id=42343953">Hacker News</a></p>
Couldn't get https://www.moment.dev/blog/lies-i-was-told-pt-1: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[DSPy – Programming–not prompting–LMs (108 pts)]]></title>
            <link>https://dspy.ai/</link>
            <guid>42343692</guid>
            <pubDate>Fri, 06 Dec 2024 19:59:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dspy.ai/">https://dspy.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=42343692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="main">
              <article>
                
                  

  
    <a href="https://github.com/stanfordnlp/dspy/blob/main/docs/docs/index.md" title="Edit this page">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"></path></svg>
    </a>
  
  


<p><img _="," alt="DSPy" src="https://dspy.ai/static/img/dspy_logo.png" width="200"></p>
<h2 id="programmingnot-promptinglms"><em>Programming</em>—not prompting—<em>LMs</em></h2>
<p>DSPy is the framework for <em>programming—rather than prompting—language models</em>. It allows you to iterate fast on <strong>building modular AI systems</strong> and offers algorithms for <strong>optimizing their prompts and weights</strong>, whether you're building simple classifiers, sophisticated RAG pipelines, or Agent loops.</p>
<p>DSPy stands for Declarative Self-improving Python. Instead of brittle prompts, you write compositional <em>Python code</em> and use DSPy to <strong>teach your LM to deliver high-quality outputs</strong>. This <a href="https://www.youtube.com/watch?v=JEMYuzrKLUw">lecture</a> is a good conceptual introduction. Meet the community, seek help, or start contributing via our <a href="https://github.com/stanfordnlp/dspy">GitHub repo</a> and <a href="https://discord.gg/XCGy2WDCQB">Discord server</a>.</p>
<div>
<p>Getting Started I: Install DSPy and set up your LM</p>

<div data-tabs="1:6"><p><label for="__tabbed_1_1">OpenAI</label><label for="__tabbed_1_2">Anthropic</label><label for="__tabbed_1_3">Databricks</label><label for="__tabbed_1_4">Local LMs on your laptop</label><label for="__tabbed_1_5">Local LMs on a GPU server</label><label for="__tabbed_1_6">Other providers</label></p>
<div>
<div>
<p>You can authenticate by setting the <code>OPENAI_API_KEY</code> env variable or passing <code>api_key</code> below.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'openai/gpt-4o-mini'</span><span>,</span> <span>api_key</span><span>=</span><span>'YOUR_OPENAI_API_KEY'</span><span>)</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
<div>
<p>You can authenticate by setting the ANTHROPIC_API_KEY env variable or passing <code>api_key</code> below.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'anthropic/claude-3-opus-20240229'</span><span>,</span> <span>api_key</span><span>=</span><span>'YOUR_ANTHROPIC_API_KEY'</span><span>)</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
<div>
<p>If you're on the Databricks platform, authentication is automatic via their SDK. If not, you can set the env variables <code>DATABRICKS_API_KEY</code> and <code>DATABRICKS_API_BASE</code>, or pass <code>api_key</code> and <code>api_base</code> below.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'databricks/databricks-meta-llama-3-1-70b-instruct'</span><span>)</span>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
<div>
<p>First, install <a href="https://github.com/ollama/ollama">Ollama</a> and launch its server with your LM.</p>
<div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>&gt;<span> </span>curl<span> </span>-fsSL<span> </span>https://ollama.ai/install.sh<span> </span><span>|</span><span> </span>sh
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>&gt;<span> </span>ollama<span> </span>run<span> </span>llama3.2:1b
</code></pre></div>
<p>Then, connect to it from your DSPy code.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'ollama_chat/llama3.2'</span><span>,</span> <span>api_base</span><span>=</span><span>'http://localhost:11434'</span><span>,</span> <span>api_key</span><span>=</span><span>''</span><span>)</span>
<a id="__codelineno-5-3" name="__codelineno-5-3"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
<div>
<p>First, install <a href="https://sgl-project.github.io/start/install.html">SGLang</a> and launch its server with your LM.</p>
<div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>&gt;<span> </span>pip<span> </span>install<span> </span><span>"sglang[all]"</span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>&gt;<span> </span>pip<span> </span>install<span> </span>flashinfer<span> </span>-i<span> </span>https://flashinfer.ai/whl/cu121/torch2.4/<span> </span>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>&gt;<span> </span><span>CUDA_VISIBLE_DEVICES</span><span>=</span><span>0</span><span> </span>python<span> </span>-m<span> </span>sglang.launch_server<span> </span>--port<span> </span><span>7501</span><span> </span>--model-path<span> </span>meta-llama/Llama-3.1-8B-Instruct
</code></pre></div>
<p>If you don't have access from Meta to download <code>meta-llama/Llama-3.1-8B-Instruct</code>, use <code>Qwen/Qwen2.5-7B-Instruct</code> for example.</p>
<p>Next, connect to your local LM from your DSPy code as an <code>OpenAI</code>-compatible endpoint.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>"openai/meta-llama/Llama-3.1-8B-Instruct"</span><span>,</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a>             <span>api_base</span><span>=</span><span>"http://localhost:7501/v1"</span><span>,</span>  <span># ensure this points to your port</span>
<a id="__codelineno-7-3" name="__codelineno-7-3"></a>             <span>api_key</span><span>=</span><span>"local"</span><span>,</span> <span>model_type</span><span>=</span><span>'chat'</span><span>)</span>
<a id="__codelineno-7-4" name="__codelineno-7-4"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
<div>
<p>In DSPy, you can use any of the dozens of <a href="https://docs.litellm.ai/docs/providers">LLM providers supported by LiteLLM</a>. Simply follow their instructions for which <code>{PROVIDER}_API_KEY</code> to set and how to write pass the <code>{provider_name}/{model_name}</code> to the constructor.</p>
<p>Some examples:</p>
<ul>
<li><code>anyscale/mistralai/Mistral-7B-Instruct-v0.1</code>, with <code>ANYSCALE_API_KEY</code></li>
<li><code>together_ai/togethercomputer/llama-2-70b-chat</code>, with <code>TOGETHERAI_API_KEY</code></li>
<li><code>sagemaker/&lt;your-endpoint-name&gt;</code>, with <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_REGION_NAME</code></li>
<li><code>azure/&lt;your_deployment_name&gt;</code>, with <code>AZURE_API_KEY</code>, <code>AZURE_API_BASE</code>, <code>AZURE_API_VERSION</code>, and the optional <code>AZURE_AD_TOKEN</code> and <code>AZURE_API_TYPE</code></li>
</ul>
<p>If your provider offers an OpenAI-compatible endpoint, just add an <code>openai/</code> prefix to your full model name.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-8-2" name="__codelineno-8-2"></a><span>lm</span> <span>=</span> <span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'openai/your-model-name'</span><span>,</span> <span>api_key</span><span>=</span><span>'PROVIDER_API_KEY'</span><span>,</span> <span>api_base</span><span>=</span><span>'YOUR_PROVIDER_URL'</span><span>)</span>
<a id="__codelineno-8-3" name="__codelineno-8-3"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>lm</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</div>
</div>
</div>
</div>
<details>
<summary>Calling the LM directly.</summary>
<p>Idiomatic DSPy involves using <em>modules</em>, which we define in the rest of this page. However, it's still easy to call the <code>lm</code> you configured above directly. This gives you a unified API and lets you benefit from utilities like automatic caching.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span>lm</span><span>(</span><span>"Say this is a test!"</span><span>,</span> <span>temperature</span><span>=</span><span>0.7</span><span>)</span>  <span># =&gt; ['This is a test!']</span>
<a id="__codelineno-9-2" name="__codelineno-9-2"></a><span>lm</span><span>(</span><span>messages</span><span>=</span><span>[{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>"Say this is a test!"</span><span>}])</span>  <span># =&gt; ['This is a test!']</span>
</code></pre></div></td></tr></tbody></table></div>
</details>
<h2 id="1-modules-help-you-describe-ai-behavior-as-code-not-strings">1) <strong>Modules</strong> help you describe AI behavior as <em>code</em>, not strings.</h2>
<p>To build reliable AI systems, you must iterate fast. But maintaining prompts makes that hard: it forces you to tinker with strings or data <em>every time you change your LM, metrics, or pipeline</em>. Having built over a dozen best-in-class compound LM systems since 2020, we learned this the hard way—and so built DSPy to decouple defining LM systems from messy incidental choices about specific LMs or prompting strategies.</p>
<p>DSPy shifts your focus from tinkering with prompt strings to <strong>programming with structured and declarative natural-language modules</strong>. For every AI component in your system, you specify input/output behavior as a <em>signature</em> and select a <em>module</em> to assign a strategy for invoking your LM. DSPy expands your signatures into prompts and parses your typed outputs, so you can write ergonomic, portable, and optimizable AI systems.</p>
<div>
<p>Getting Started II: Build DSPy modules for various tasks</p>
<p>Try the examples below after configuring your <code>lm</code> above. Adjust the fields to explore what tasks your LM can do well out of the box. Each tab below sets up a DSPy module, like <code>dspy.Predict</code>, <code>dspy.ChainOfThought</code>, or <code>dspy.ReAct</code>, with a task-specific <em>signature</em>. For example, <code>question -&gt; answer: float</code> tells the module to take a question and to produce a <code>float</code> answer.</p>
<div data-tabs="2:5"><p><label for="__tabbed_2_1">Math</label><label for="__tabbed_2_2">Retrieval-Augmented Generation</label><label for="__tabbed_2_3">Classification</label><label for="__tabbed_2_4">Information Extraction</label><label for="__tabbed_2_5">Agents</label></p>
<div>
<div>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span>math</span> <span>=</span> <span>dspy</span><span>.</span><span>ChainOfThought</span><span>(</span><span>"question -&gt; answer: float"</span><span>)</span>
<a id="__codelineno-10-2" name="__codelineno-10-2"></a><span>math</span><span>(</span><span>question</span><span>=</span><span>"Two dice are tossed. What is the probability that the sum equals two?"</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output:</strong>
</p><div><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>Prediction(
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    reasoning='When two dice are tossed, each die has 6 faces, resulting in a total of 6 x 6 = 36 possible outcomes. The sum of the numbers on the two dice equals two only when both dice show a 1. This is just one specific outcome: (1, 1). Therefore, there is only 1 favorable outcome. The probability of the sum being two is the number of favorable outcomes divided by the total number of possible outcomes, which is 1/36.',
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    answer=0.0277776
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>)
</code></pre></div>
</div>
<div>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1"></a><span>def</span> <span>search_wikipedia</span><span>(</span><span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>list</span><span>[</span><span>str</span><span>]:</span>
<a id="__codelineno-12-2" name="__codelineno-12-2"></a>    <span>results</span> <span>=</span> <span>dspy</span><span>.</span><span>ColBERTv2</span><span>(</span><span>url</span><span>=</span><span>'http://20.102.90.50:2017/wiki17_abstracts'</span><span>)(</span><span>query</span><span>,</span> <span>k</span><span>=</span><span>3</span><span>)</span>
<a id="__codelineno-12-3" name="__codelineno-12-3"></a>    <span>return</span> <span>[</span><span>x</span><span>[</span><span>'text'</span><span>]</span> <span>for</span> <span>x</span> <span>in</span> <span>results</span><span>]</span>
<a id="__codelineno-12-4" name="__codelineno-12-4"></a>
<a id="__codelineno-12-5" name="__codelineno-12-5"></a><span>rag</span> <span>=</span> <span>dspy</span><span>.</span><span>ChainOfThought</span><span>(</span><span>'context, question -&gt; response'</span><span>)</span>
<a id="__codelineno-12-6" name="__codelineno-12-6"></a>
<a id="__codelineno-12-7" name="__codelineno-12-7"></a><span>question</span> <span>=</span> <span>"What's the name of the castle that David Gregory inherited?"</span>
<a id="__codelineno-12-8" name="__codelineno-12-8"></a><span>rag</span><span>(</span><span>context</span><span>=</span><span>search_wikipedia</span><span>(</span><span>question</span><span>),</span> <span>question</span><span>=</span><span>question</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output:</strong>
</p><div><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>Prediction(
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>    reasoning='The context provides information about David Gregory, a Scottish physician and inventor. It specifically mentions that he inherited Kinnairdy Castle in 1664. This detail directly answers the question about the name of the castle that David Gregory inherited.',
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>    response='Kinnairdy Castle'
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>)
</code></pre></div>
</div>
<div>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span>from</span> <span>typing</span> <span>import</span> <span>Literal</span>
<a id="__codelineno-14-2" name="__codelineno-14-2"></a>
<a id="__codelineno-14-3" name="__codelineno-14-3"></a><span>class</span> <span>Classify</span><span>(</span><span>dspy</span><span>.</span><span>Signature</span><span>):</span>
<a id="__codelineno-14-4" name="__codelineno-14-4"></a><span>    </span><span>"""Classify sentiment of a given sentence."""</span>
<a id="__codelineno-14-5" name="__codelineno-14-5"></a>
<a id="__codelineno-14-6" name="__codelineno-14-6"></a>    <span>sentence</span><span>:</span> <span>str</span> <span>=</span> <span>dspy</span><span>.</span><span>InputField</span><span>()</span>
<a id="__codelineno-14-7" name="__codelineno-14-7"></a>    <span>sentiment</span><span>:</span> <span>Literal</span><span>[</span><span>'positive'</span><span>,</span> <span>'negative'</span><span>,</span> <span>'neutral'</span><span>]</span> <span>=</span> <span>dspy</span><span>.</span><span>OutputField</span><span>()</span>
<a id="__codelineno-14-8" name="__codelineno-14-8"></a>    <span>confidence</span><span>:</span> <span>float</span> <span>=</span> <span>dspy</span><span>.</span><span>OutputField</span><span>()</span>
<a id="__codelineno-14-9" name="__codelineno-14-9"></a>
<a id="__codelineno-14-10" name="__codelineno-14-10"></a><span>classify</span> <span>=</span> <span>dspy</span><span>.</span><span>Predict</span><span>(</span><span>Classify</span><span>)</span>
<a id="__codelineno-14-11" name="__codelineno-14-11"></a><span>classify</span><span>(</span><span>sentence</span><span>=</span><span>"This book was super fun to read, though not the last chapter."</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output:</strong></p>
<div><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>Prediction(
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>    sentiment='positive',
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>    confidence=0.75
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>)
</code></pre></div>
</div>
<div>
<div><table><tbody><tr><td><div><pre><span></span><span><a href="#__codelineno-16-1"> 1</a></span>
<span><a href="#__codelineno-16-2"> 2</a></span>
<span><a href="#__codelineno-16-3"> 3</a></span>
<span><a href="#__codelineno-16-4"> 4</a></span>
<span><a href="#__codelineno-16-5"> 5</a></span>
<span><a href="#__codelineno-16-6"> 6</a></span>
<span><a href="#__codelineno-16-7"> 7</a></span>
<span><a href="#__codelineno-16-8"> 8</a></span>
<span><a href="#__codelineno-16-9"> 9</a></span>
<span><a href="#__codelineno-16-10">10</a></span>
<span><a href="#__codelineno-16-11">11</a></span>
<span><a href="#__codelineno-16-12">12</a></span>
<span><a href="#__codelineno-16-13">13</a></span>
<span><a href="#__codelineno-16-14">14</a></span>
<span><a href="#__codelineno-16-15">15</a></span>
<span><a href="#__codelineno-16-16">16</a></span>
<span><a href="#__codelineno-16-17">17</a></span></pre></div></td><td><div><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span>class</span> <span>ExtractInfo</span><span>(</span><span>dspy</span><span>.</span><span>Signature</span><span>):</span>
<a id="__codelineno-16-2" name="__codelineno-16-2"></a><span>    </span><span>"""Extract structured information from text."""</span>
<a id="__codelineno-16-3" name="__codelineno-16-3"></a>
<a id="__codelineno-16-4" name="__codelineno-16-4"></a>    <span>text</span><span>:</span> <span>str</span> <span>=</span> <span>dspy</span><span>.</span><span>InputField</span><span>()</span>
<a id="__codelineno-16-5" name="__codelineno-16-5"></a>    <span>title</span><span>:</span> <span>str</span> <span>=</span> <span>dspy</span><span>.</span><span>OutputField</span><span>()</span>
<a id="__codelineno-16-6" name="__codelineno-16-6"></a>    <span>headings</span><span>:</span> <span>list</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>dspy</span><span>.</span><span>OutputField</span><span>()</span>
<a id="__codelineno-16-7" name="__codelineno-16-7"></a>    <span>entities</span><span>:</span> <span>list</span><span>[</span><span>dict</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>]]</span> <span>=</span> <span>dspy</span><span>.</span><span>OutputField</span><span>(</span><span>desc</span><span>=</span><span>"a list of entities and their metadata"</span><span>)</span>
<a id="__codelineno-16-8" name="__codelineno-16-8"></a>
<a id="__codelineno-16-9" name="__codelineno-16-9"></a><span>module</span> <span>=</span> <span>dspy</span><span>.</span><span>Predict</span><span>(</span><span>ExtractInfo</span><span>)</span>
<a id="__codelineno-16-10" name="__codelineno-16-10"></a>
<a id="__codelineno-16-11" name="__codelineno-16-11"></a><span>text</span> <span>=</span> <span>"Apple Inc. announced its latest iPhone 14 today."</span> \
<a id="__codelineno-16-12" name="__codelineno-16-12"></a>    <span>"The CEO, Tim Cook, highlighted its new features in a press release."</span>
<a id="__codelineno-16-13" name="__codelineno-16-13"></a><span>response</span> <span>=</span> <span>module</span><span>(</span><span>text</span><span>=</span><span>text</span><span>)</span>
<a id="__codelineno-16-14" name="__codelineno-16-14"></a>
<a id="__codelineno-16-15" name="__codelineno-16-15"></a><span>print</span><span>(</span><span>response</span><span>.</span><span>title</span><span>)</span>
<a id="__codelineno-16-16" name="__codelineno-16-16"></a><span>print</span><span>(</span><span>response</span><span>.</span><span>headings</span><span>)</span>
<a id="__codelineno-16-17" name="__codelineno-16-17"></a><span>print</span><span>(</span><span>response</span><span>.</span><span>entities</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output:</strong>
</p><div><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>Apple Inc. Announces iPhone 14
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>['Introduction', "CEO's Statement", 'New Features']
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>[{'name': 'Apple Inc.', 'type': 'Organization'}, {'name': 'iPhone 14', 'type': 'Product'}, {'name': 'Tim Cook', 'type': 'Person'}]
</code></pre></div>
</div>
<div>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span>def</span> <span>evaluate_math</span><span>(</span><span>expression</span><span>:</span> <span>str</span><span>):</span>
<a id="__codelineno-18-2" name="__codelineno-18-2"></a>    <span>return</span> <span>dspy</span><span>.</span><span>PythonInterpreter</span><span>({})</span><span>.</span><span>execute</span><span>(</span><span>expression</span><span>)</span>
<a id="__codelineno-18-3" name="__codelineno-18-3"></a>
<a id="__codelineno-18-4" name="__codelineno-18-4"></a><span>def</span> <span>search_wikipedia</span><span>(</span><span>query</span><span>:</span> <span>str</span><span>):</span>
<a id="__codelineno-18-5" name="__codelineno-18-5"></a>    <span>results</span> <span>=</span> <span>dspy</span><span>.</span><span>ColBERTv2</span><span>(</span><span>url</span><span>=</span><span>'http://20.102.90.50:2017/wiki17_abstracts'</span><span>)(</span><span>query</span><span>,</span> <span>k</span><span>=</span><span>3</span><span>)</span>
<a id="__codelineno-18-6" name="__codelineno-18-6"></a>    <span>return</span> <span>[</span><span>x</span><span>[</span><span>'text'</span><span>]</span> <span>for</span> <span>x</span> <span>in</span> <span>results</span><span>]</span>
<a id="__codelineno-18-7" name="__codelineno-18-7"></a>
<a id="__codelineno-18-8" name="__codelineno-18-8"></a><span>react</span> <span>=</span> <span>dspy</span><span>.</span><span>ReAct</span><span>(</span><span>"question -&gt; answer: float"</span><span>,</span> <span>tools</span><span>=</span><span>[</span><span>evaluate_math</span><span>,</span> <span>search_wikipedia</span><span>])</span>
<a id="__codelineno-18-9" name="__codelineno-18-9"></a>
<a id="__codelineno-18-10" name="__codelineno-18-10"></a><span>pred</span> <span>=</span> <span>react</span><span>(</span><span>question</span><span>=</span><span>"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?"</span><span>)</span>
<a id="__codelineno-18-11" name="__codelineno-18-11"></a><span>print</span><span>(</span><span>pred</span><span>.</span><span>answer</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output:</strong></p>

</div>
</div>
</div>
</div>
<details>
<summary>Using DSPy in practice: from quick scripting to building sophisticated systems.</summary>
<p>Standard prompts conflate interface (“what should the LM do?”) with implementation (“how do we tell it to do that?”). DSPy isolates the former as <em>signatures</em> so we can infer the latter or learn it from data — in the context of a bigger program.</p>
<p>Even before you start using optimizers, DSPy's modules allow you to script effective LM systems as ergonomic, portable <em>code</em>. Across many tasks and LMs, we maintain <em>signature test suites</em> that assess the reliability of the built-in DSPy adapters. Adapters are the components that map signatures to prompts prior to optimization. If you find a task where a simple prompt consistently outperforms idiomatic DSPy for your LM, consider that a bug and <a href="https://github.com/stanfordnlp/dspy/issues">file an issue</a>. We'll use this to improve the built-in adapters.</p>
</details>
<h2 id="2-optimizers-tune-the-prompts-and-weights-of-your-ai-modules">2) <strong>Optimizers</strong> tune the prompts and weights of your AI modules.</h2>
<p>DSPy provides you with the tools to compile high-level code with natural language annotations into the low-level computations, prompts, or weight updates that align your LM with your program’s structure and metrics. If you change your code or your metrics, you can simply re-compile accordingly.</p>
<p>Given a few tens or hundreds of representative <em>inputs</em> of your task and a <em>metric</em> that can measure the quality of your system's outputs, you can use a DSPy optimizer. Different optimizers in DSPy work by <strong>synthesizing good few-shot examples</strong> for every module, like <code>dspy.BootstrapRS</code>,<sup><a href="https://arxiv.org/abs/2310.03714">1</a></sup> <strong>proposing and intelligently exploring better natural-language instructions</strong> for every prompt, like <code>dspy.MIPROv2</code>,<sup><a href="https://arxiv.org/abs/2406.11695">2</a></sup> and <strong>building datasets for your modules and using them to finetune the LM weights</strong> in your system, like <code>dspy.BootstrapFinetune</code>.<sup><a href="https://arxiv.org/abs/2407.10930">3</a></sup></p>
<div>
<p>Getting Started III: Optimizing the LM prompts or weights in DSPy programs</p>
<p>A typical simple optimization run costs on the order of $2 USD and takes around 20 minutes, but be careful when running optimizers with very large LMs or very large datasets.
Optimization can cost as little as a few cents or up to tens of dollars, depending on your LM, dataset, and configuration.</p>
<div data-tabs="3:3"><p><label for="__tabbed_3_1">Optimizing prompts for a ReAct agent</label><label for="__tabbed_3_2">Optimizing prompts for RAG</label><label for="__tabbed_3_3">Optimizing weights for Classification</label></p>
<div>
<div>
<p>This is a minimal but fully runnable example of setting up a <code>dspy.ReAct</code> agent that answers questions via
search from Wikipedia and then optimizing it using <code>dspy.MIPROv2</code> in the cheap <code>light</code> mode on 500
question-answer pairs sampled from the <code>HotPotQA</code> dataset.</p>
<div><table><tbody><tr><td><div><pre><span></span><span><a href="#__codelineno-20-1"> 1</a></span>
<span><a href="#__codelineno-20-2"> 2</a></span>
<span><a href="#__codelineno-20-3"> 3</a></span>
<span><a href="#__codelineno-20-4"> 4</a></span>
<span><a href="#__codelineno-20-5"> 5</a></span>
<span><a href="#__codelineno-20-6"> 6</a></span>
<span><a href="#__codelineno-20-7"> 7</a></span>
<span><a href="#__codelineno-20-8"> 8</a></span>
<span><a href="#__codelineno-20-9"> 9</a></span>
<span><a href="#__codelineno-20-10">10</a></span>
<span><a href="#__codelineno-20-11">11</a></span>
<span><a href="#__codelineno-20-12">12</a></span>
<span><a href="#__codelineno-20-13">13</a></span>
<span><a href="#__codelineno-20-14">14</a></span></pre></div></td><td><div><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-20-2" name="__codelineno-20-2"></a><span>from</span> <span>dspy.datasets</span> <span>import</span> <span>HotPotQA</span>
<a id="__codelineno-20-3" name="__codelineno-20-3"></a>
<a id="__codelineno-20-4" name="__codelineno-20-4"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'openai/gpt-4o-mini'</span><span>))</span>
<a id="__codelineno-20-5" name="__codelineno-20-5"></a>
<a id="__codelineno-20-6" name="__codelineno-20-6"></a><span>def</span> <span>search_wikipedia</span><span>(</span><span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>list</span><span>[</span><span>str</span><span>]:</span>
<a id="__codelineno-20-7" name="__codelineno-20-7"></a>    <span>results</span> <span>=</span> <span>dspy</span><span>.</span><span>ColBERTv2</span><span>(</span><span>url</span><span>=</span><span>'http://20.102.90.50:2017/wiki17_abstracts'</span><span>)(</span><span>query</span><span>,</span> <span>k</span><span>=</span><span>3</span><span>)</span>
<a id="__codelineno-20-8" name="__codelineno-20-8"></a>    <span>return</span> <span>[</span><span>x</span><span>[</span><span>'text'</span><span>]</span> <span>for</span> <span>x</span> <span>in</span> <span>results</span><span>]</span>
<a id="__codelineno-20-9" name="__codelineno-20-9"></a>
<a id="__codelineno-20-10" name="__codelineno-20-10"></a><span>trainset</span> <span>=</span> <span>[</span><span>x</span><span>.</span><span>with_inputs</span><span>(</span><span>'question'</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>HotPotQA</span><span>(</span><span>train_seed</span><span>=</span><span>2024</span><span>,</span> <span>train_size</span><span>=</span><span>500</span><span>)</span><span>.</span><span>train</span><span>]</span>
<a id="__codelineno-20-11" name="__codelineno-20-11"></a><span>react</span> <span>=</span> <span>dspy</span><span>.</span><span>ReAct</span><span>(</span><span>"question -&gt; answer"</span><span>,</span> <span>tools</span><span>=</span><span>[</span><span>search_wikipedia</span><span>])</span>
<a id="__codelineno-20-12" name="__codelineno-20-12"></a>
<a id="__codelineno-20-13" name="__codelineno-20-13"></a><span>tp</span> <span>=</span> <span>dspy</span><span>.</span><span>MIPROv2</span><span>(</span><span>metric</span><span>=</span><span>dspy</span><span>.</span><span>evaluate</span><span>.</span><span>answer_exact_match</span><span>,</span> <span>auto</span><span>=</span><span>"light"</span><span>,</span> <span>num_threads</span><span>=</span><span>24</span><span>)</span>
<a id="__codelineno-20-14" name="__codelineno-20-14"></a><span>optimized_react</span> <span>=</span> <span>tp</span><span>.</span><span>compile</span><span>(</span><span>react</span><span>,</span> <span>trainset</span><span>=</span><span>trainset</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p>An informal run like this raises ReAct's score from 24% to 51%, by teaching <code>gpt-4o-mini</code> more about the specifics of the task.</p>
</div>
<div>
<p>Given a retrieval index to <code>search</code>, your favorite <code>dspy.LM</code>, and a small <code>trainset</code> of questions and ground-truth responses, the following code snippet can optimize your RAG system with long outputs against the built-in <code>SemanticF1</code> metric, which is implemented as a DSPy module.</p>
<div><table><tbody><tr><td></td><td><div><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1"></a><span>class</span> <span>RAG</span><span>(</span><span>dspy</span><span>.</span><span>Module</span><span>):</span>
<a id="__codelineno-21-2" name="__codelineno-21-2"></a>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>num_docs</span><span>=</span><span>5</span><span>):</span>
<a id="__codelineno-21-3" name="__codelineno-21-3"></a>        <span>self</span><span>.</span><span>num_docs</span> <span>=</span> <span>num_docs</span>
<a id="__codelineno-21-4" name="__codelineno-21-4"></a>        <span>self</span><span>.</span><span>respond</span> <span>=</span> <span>dspy</span><span>.</span><span>ChainOfThought</span><span>(</span><span>'context, question -&gt; response'</span><span>)</span>
<a id="__codelineno-21-5" name="__codelineno-21-5"></a>
<a id="__codelineno-21-6" name="__codelineno-21-6"></a>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>question</span><span>):</span>
<a id="__codelineno-21-7" name="__codelineno-21-7"></a>        <span>context</span> <span>=</span> <span>search</span><span>(</span><span>question</span><span>,</span> <span>k</span><span>=</span><span>self</span><span>.</span><span>num_docs</span><span>)</span>   <span># defined in tutorial linked below</span>
<a id="__codelineno-21-8" name="__codelineno-21-8"></a>        <span>return</span> <span>self</span><span>.</span><span>respond</span><span>(</span><span>context</span><span>=</span><span>context</span><span>,</span> <span>question</span><span>=</span><span>question</span><span>)</span>
<a id="__codelineno-21-9" name="__codelineno-21-9"></a>
<a id="__codelineno-21-10" name="__codelineno-21-10"></a><span>tp</span> <span>=</span> <span>dspy</span><span>.</span><span>MIPROv2</span><span>(</span><span>metric</span><span>=</span><span>dspy</span><span>.</span><span>evaluate</span><span>.</span><span>SemanticF1</span><span>(</span><span>decompositional</span><span>=</span><span>True</span><span>),</span> <span>auto</span><span>=</span><span>"medium"</span><span>,</span> <span>num_threads</span><span>=</span><span>24</span><span>)</span>
<a id="__codelineno-21-11" name="__codelineno-21-11"></a><span>optimized_rag</span> <span>=</span> <span>tp</span><span>.</span><span>compile</span><span>(</span><span>RAG</span><span>(),</span> <span>trainset</span><span>=</span><span>trainset</span><span>,</span> <span>max_bootstrapped_demos</span><span>=</span><span>2</span><span>,</span> <span>max_labeled_demos</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p>For a complete RAG example that you can run, start this <a href="https://dspy.ai/tutorials/rag/">tutorial</a>. It improves the quality of a RAG system over a subset of StackExchange communities by 10% relative gain.</p>
</div>
<div>
<p>This is a minimal but fully runnable example of setting up a <code>dspy.ChainOfThought</code> module that classifies
short texts into one of 77 banking labels and then using <code>dspy.BootstrapFinetune</code> with 2000 text-label pairs
from the <code>Banking77</code> to finetune the weights of GPT-4o-mini for this task. We use the variant
<code>dspy.ChainOfThoughtWithHint</code>, which takes an optional <code>hint</code> at bootstrapping time, to maximize the utility of
the training data. Naturally, hints are not available at test time.</p>
<details><summary>Click to show dataset setup code.</summary>
<div><table><tbody><tr><td><div><pre><span></span><span><a href="#__codelineno-22-1"> 1</a></span>
<span><a href="#__codelineno-22-2"> 2</a></span>
<span><a href="#__codelineno-22-3"> 3</a></span>
<span><a href="#__codelineno-22-4"> 4</a></span>
<span><a href="#__codelineno-22-5"> 5</a></span>
<span><a href="#__codelineno-22-6"> 6</a></span>
<span><a href="#__codelineno-22-7"> 7</a></span>
<span><a href="#__codelineno-22-8"> 8</a></span>
<span><a href="#__codelineno-22-9"> 9</a></span>
<span><a href="#__codelineno-22-10">10</a></span>
<span><a href="#__codelineno-22-11">11</a></span>
<span><a href="#__codelineno-22-12">12</a></span>
<span><a href="#__codelineno-22-13">13</a></span>
<span><a href="#__codelineno-22-14">14</a></span>
<span><a href="#__codelineno-22-15">15</a></span></pre></div></td><td><div><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1"></a><span>import</span> <span>random</span>
<a id="__codelineno-22-2" name="__codelineno-22-2"></a><span>from</span> <span>typing</span> <span>import</span> <span>Literal</span>
<a id="__codelineno-22-3" name="__codelineno-22-3"></a><span>from</span> <span>dspy.datasets</span> <span>import</span> <span>DataLoader</span>
<a id="__codelineno-22-4" name="__codelineno-22-4"></a><span>from</span> <span>datasets</span> <span>import</span> <span>load_dataset</span>
<a id="__codelineno-22-5" name="__codelineno-22-5"></a>
<a id="__codelineno-22-6" name="__codelineno-22-6"></a><span># Load the Banking77 dataset.</span>
<a id="__codelineno-22-7" name="__codelineno-22-7"></a><span>CLASSES</span> <span>=</span> <span>load_dataset</span><span>(</span><span>"PolyAI/banking77"</span><span>,</span> <span>split</span><span>=</span><span>"train"</span><span>,</span> <span>trust_remote_code</span><span>=</span><span>True</span><span>)</span><span>.</span><span>features</span><span>[</span><span>'label'</span><span>]</span><span>.</span><span>names</span>
<a id="__codelineno-22-8" name="__codelineno-22-8"></a><span>kwargs</span> <span>=</span> <span>dict</span><span>(</span><span>fields</span><span>=</span><span>(</span><span>"text"</span><span>,</span> <span>"label"</span><span>),</span> <span>input_keys</span><span>=</span><span>(</span><span>"text"</span><span>,),</span> <span>split</span><span>=</span><span>"train"</span><span>,</span> <span>trust_remote_code</span><span>=</span><span>True</span><span>)</span>
<a id="__codelineno-22-9" name="__codelineno-22-9"></a>
<a id="__codelineno-22-10" name="__codelineno-22-10"></a><span># Load the first 2000 examples from the dataset, and assign a hint to each *training* example.</span>
<a id="__codelineno-22-11" name="__codelineno-22-11"></a><span>trainset</span> <span>=</span> <span>[</span>
<a id="__codelineno-22-12" name="__codelineno-22-12"></a>    <span>dspy</span><span>.</span><span>Example</span><span>(</span><span>x</span><span>,</span> <span>hint</span><span>=</span><span>CLASSES</span><span>[</span><span>x</span><span>.</span><span>label</span><span>],</span> <span>label</span><span>=</span><span>CLASSES</span><span>[</span><span>x</span><span>.</span><span>label</span><span>])</span><span>.</span><span>with_inputs</span><span>(</span><span>"text"</span><span>,</span> <span>"hint"</span><span>)</span>
<a id="__codelineno-22-13" name="__codelineno-22-13"></a>    <span>for</span> <span>x</span> <span>in</span> <span>DataLoader</span><span>()</span><span>.</span><span>from_huggingface</span><span>(</span><span>dataset_name</span><span>=</span><span>"PolyAI/banking77"</span><span>,</span> <span>**</span><span>kwargs</span><span>)[:</span><span>2000</span><span>]</span>
<a id="__codelineno-22-14" name="__codelineno-22-14"></a><span>]</span>
<a id="__codelineno-22-15" name="__codelineno-22-15"></a><span>random</span><span>.</span><span>Random</span><span>(</span><span>0</span><span>)</span><span>.</span><span>shuffle</span><span>(</span><span>trainset</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
</details>
<div><table><tbody><tr><td><div><pre><span></span><span><a href="#__codelineno-23-1"> 1</a></span>
<span><a href="#__codelineno-23-2"> 2</a></span>
<span><a href="#__codelineno-23-3"> 3</a></span>
<span><a href="#__codelineno-23-4"> 4</a></span>
<span><a href="#__codelineno-23-5"> 5</a></span>
<span><a href="#__codelineno-23-6"> 6</a></span>
<span><a href="#__codelineno-23-7"> 7</a></span>
<span><a href="#__codelineno-23-8"> 8</a></span>
<span><a href="#__codelineno-23-9"> 9</a></span>
<span><a href="#__codelineno-23-10">10</a></span>
<span><a href="#__codelineno-23-11">11</a></span>
<span><a href="#__codelineno-23-12">12</a></span></pre></div></td><td><div><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1"></a><span>import</span> <span>dspy</span>
<a id="__codelineno-23-2" name="__codelineno-23-2"></a><span>dspy</span><span>.</span><span>configure</span><span>(</span><span>lm</span><span>=</span><span>dspy</span><span>.</span><span>LM</span><span>(</span><span>'gpt-4o-mini-2024-07-18'</span><span>))</span>
<a id="__codelineno-23-3" name="__codelineno-23-3"></a>
<a id="__codelineno-23-4" name="__codelineno-23-4"></a><span># Define the DSPy module for classification. It will use the hint at training time, if available.</span>
<a id="__codelineno-23-5" name="__codelineno-23-5"></a><span>signature</span> <span>=</span> <span>dspy</span><span>.</span><span>Signature</span><span>(</span><span>"text -&gt; label"</span><span>)</span><span>.</span><span>with_updated_fields</span><span>(</span><span>'label'</span><span>,</span> <span>type_</span><span>=</span><span>Literal</span><span>[</span><span>tuple</span><span>(</span><span>CLASSES</span><span>)])</span>
<a id="__codelineno-23-6" name="__codelineno-23-6"></a><span>classify</span> <span>=</span> <span>dspy</span><span>.</span><span>ChainOfThoughtWithHint</span><span>(</span><span>signature</span><span>)</span>
<a id="__codelineno-23-7" name="__codelineno-23-7"></a>
<a id="__codelineno-23-8" name="__codelineno-23-8"></a><span># Optimize via BootstrapFinetune.</span>
<a id="__codelineno-23-9" name="__codelineno-23-9"></a><span>optimizer</span> <span>=</span> <span>dspy</span><span>.</span><span>BootstrapFinetune</span><span>(</span><span>metric</span><span>=</span><span>(</span><span>lambda</span> <span>x</span><span>,</span> <span>y</span><span>,</span> <span>trace</span><span>=</span><span>None</span><span>:</span> <span>x</span><span>.</span><span>label</span> <span>==</span> <span>y</span><span>.</span><span>label</span><span>),</span> <span>num_threads</span><span>=</span><span>24</span><span>)</span>
<a id="__codelineno-23-10" name="__codelineno-23-10"></a><span>optimized</span> <span>=</span> <span>optimizer</span><span>.</span><span>compile</span><span>(</span><span>classify</span><span>,</span> <span>trainset</span><span>=</span><span>trainset</span><span>)</span>
<a id="__codelineno-23-11" name="__codelineno-23-11"></a>
<a id="__codelineno-23-12" name="__codelineno-23-12"></a><span>optimized_classifier</span><span>(</span><span>text</span><span>=</span><span>"What does a pending cash withdrawal mean?"</span><span>)</span>
</code></pre></div></td></tr></tbody></table></div>
<p><strong>Possible Output (from the last line):</strong>
</p><div><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>Prediction(
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>    reasoning='A pending cash withdrawal indicates that a request to withdraw cash has been initiated but has not yet been completed or processed. This status means that the transaction is still in progress and the funds have not yet been deducted from the account or made available to the user.',
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>    label='pending_cash_withdrawal'
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>)
</code></pre></div>
<p>An informal run similar to this on DSPy 2.5.29 raises GPT-4o-mini's score 66% to 87%.</p>
</div>
</div>
</div>
</div>
<details>
<summary>What's an example of a DSPy optimizer? How do different optimizers work?</summary>
<p>Take the <code>dspy.MIPROv2</code> optimizer as an example. First, MIPRO starts with the <strong>bootstrapping stage</strong>. It takes your program, which may be unoptimized at this point, and runs it many times across different inputs to collect traces of input/output behavior for each one of your modules. It filters these traces to keep only those that appear in trajectories scored highly by your metric. Second, MIPRO enters its <strong>grounded proposal stage</strong>. It previews your DSPy program's code, your data, and traces from running your program, and uses them to draft many potential instructions for every prompt in your program. Third, MIPRO launches the <strong>discrete search stage</strong>. It samples mini-batches from your training set, proposes a combination of instructions and traces to use for constructing every prompt in the pipeline, and evaluates the candidate program on the mini-batch. Using the resulting score, MIPRO updates a surrogate model that helps the proposals get better over time.</p>
<p>One thing that makes DSPy optimizers so powerful is that they can be composed. You can run <code>dspy.MIPROv2</code> and use the produced program as an input to <code>dspy.MIPROv2</code> again or, say, to <code>dspy.BootstrapFinetune</code> to get better results. This is partly the essence of <code>dspy.BetterTogether</code>. Alternatively, you can run the optimizer and then extract the top-5 candidate programs and build a <code>dspy.Ensemble</code> of them. This allows you to scale <em>inference-time compute</em> (e.g., ensembles) as well as DSPy's unique <em>pre-inference time compute</em> (i.e., optimization budget) in highly systematic ways.</p>
</details>
<!-- Future:
BootstrapRS or MIPRO on ??? with a local SGLang LM
BootstrapFS on MATH with a tiny LM like Llama-3.2 with Ollama (maybe with a big teacher) -->

<h2 id="3-dspys-ecosystem-advances-open-source-ai-research">3) <strong>DSPy's Ecosystem</strong> advances open-source AI research.</h2>
<p>Compared to monolithic LMs, DSPy's modular paradigm enables a large community to improve the compositional architectures, inference-time strategies, and optimizers for LM programs in an open, distributed way. This gives DSPy users more control, helps them iterate much faster, and allows their programs to get better over time by applying the latest optimizers or modules.</p>
<p>The DSPy research effort started at Stanford NLP in Feb 2022, building on what we learned from developing early <a href="https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/">compound LM systems</a> like <a href="https://arxiv.org/abs/2007.00814">ColBERT-QA</a>, <a href="https://arxiv.org/abs/2101.00436">Baleen</a>, and <a href="https://arxiv.org/abs/2110.07752">Hindsight</a>. The first version was released as <a href="https://arxiv.org/abs/2212.14024">DSP</a> in Dec 2022 and evolved by Oct 2023 into <a href="https://arxiv.org/abs/2310.03714">DSPy</a>. Thanks to <a href="https://github.com/stanfordnlp/dspy/graphs/contributors">250 contributors</a>, DSPy has introduced tens of thousands of people to building and optimizing modular LM programs.</p>
<p>Since then, DSPy's community has produced a large body of work on optimizers, like <a href="https://arxiv.org/abs/2406.11695">MIPROv2</a>, <a href="https://arxiv.org/abs/2407.10930">BetterTogether</a>, and <a href="https://arxiv.org/abs/2410.23214">LeReT</a>, on program architectures, like <a href="https://arxiv.org/abs/2402.14207">STORM</a>, <a href="https://arxiv.org/abs/2401.12178">IReRa</a>, and <a href="https://arxiv.org/abs/2312.13382">DSPy Assertions</a>, and on successful applications to new problems, like <a href="https://arxiv.org/abs/2410.17127">PAPILLON</a>, <a href="https://arxiv.org/abs/2406.11706">PATH</a>, <a href="https://arxiv.org/abs/2404.14544">WangLab@MEDIQA</a>, <a href="https://arxiv.org/abs/2406.06608">UMD's Prompting Case Study</a>, and <a href="https://blog.haizelabs.com/posts/dspy/">Haize's Red-Teaming Program</a>, in addition to many open-source projects, production applications, and other <a href="https://dspy.ai/dspy-usecases/">use cases</a>.</p>







  
  




  



                
              </article>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fructose in diet enhances tumor growth (178 pts)]]></title>
            <link>https://source.washu.edu/2024/12/research-reveals-how-fructose-in-diet-enhances-tumor-growth/</link>
            <guid>42343544</guid>
            <pubDate>Fri, 06 Dec 2024 19:46:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://source.washu.edu/2024/12/research-reveals-how-fructose-in-diet-enhances-tumor-growth/">https://source.washu.edu/2024/12/research-reveals-how-fructose-in-diet-enhances-tumor-growth/</a>, See on <a href="https://news.ycombinator.com/item?id=42343544">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Fructose consumption has increased considerably over the past five decades, largely due to the widespread use of high-fructose corn syrup as a sweetener in beverages and ultra-processed foods. New research from Washington University in St. Louis shows that dietary fructose promotes tumor growth in animal models of melanoma, breast cancer and cervical cancer. However, fructose does not directly fuel tumors, according to the study published Dec. 4 in the journal <a href="https://www.nature.com/articles/s41586-024-08258-3">Nature</a>.</p>



<p>Instead, WashU scientists discovered that the liver converts fructose into usable nutrients for cancer cells, a compelling finding that could open up new avenues for care and treatment of many different types of cancer.</p>



<p>“The idea that you can tackle cancer with diet is intriguing,” said <a href="https://chemistry.wustl.edu/people/gary-patti">Gary Patti</a>, the Michael and Tana Powell Professor of Chemistry in Arts &amp; Sciences and a professor of genetics and of medicine at the School of Medicine, all at WashU.</p>



<p>“When we think about tumors, we tend to focus on what dietary components they consume directly. You put something in your body, and then you imagine that the tumor takes it up,” Patti said. “But humans are complex. What you put in your body can be consumed by healthy tissue and then converted into something else that tumors use.”</p>


<div>
<figure><img fetchpriority="high" decoding="async" width="760" height="543" src="https://source.washu.edu/app/uploads/2024/12/IMG_9372_760.jpg" alt="" srcset="https://source.washu.edu/app/uploads/2024/12/IMG_9372_760.jpg 760w, https://source.washu.edu/app/uploads/2024/12/IMG_9372_760-300x214.jpg 300w, https://source.washu.edu/app/uploads/2024/12/IMG_9372_760-150x107.jpg 150w, https://source.washu.edu/app/uploads/2024/12/IMG_9372_760-360x257.jpg 360w" sizes="(max-width: 760px) 100vw, 760px"><figcaption>Fowle-Grider</figcaption></figure>
</div>


<p>“Our initial expectation was that tumor cells metabolize fructose just like glucose, directly utilizing its atoms to build new cellular components such as DNA. We were surprised that fructose was barely metabolized in the tumor types we tested,” said the study’s first author, <a href="https://chemistry.wustl.edu/people/ronald-fowle-grider">Ronald Fowle-Grider</a>, a postdoctoral fellow in Patti’s lab. “We quickly learned that the tumor cells alone don’t tell the whole story. Equally important is the liver, which transforms fructose into nutrients that the tumors can use.”</p>



<p>Using metabolomics — a method of profiling small molecules as they move through cells and across different tissues in the body — the researchers concluded that one way in which high levels of fructose consumption promote tumor growth is by increasing the availability of circulating lipids in the blood. These lipids are building blocks for the cell membrane, and cancer cells need them to grow.</p>



<p>“We looked at numerous different cancers in various tissues throughout the body, and they all followed the same mechanism,” Patti said.</p>



<h2 id="h-the-corn-syrup-era">The corn syrup era</h2>



<p>Scientists have long recognized that cancer cells have a strong affinity for glucose, a simple sugar that is the body’s preferred carbohydrate-based energy source.</p>



<p>In terms of its chemical structure, fructose is similar to glucose. They are both common types of sugar, with the same chemical formula, but they differ in how the body metabolizes them. Glucose is processed throughout the whole body, while fructose is almost entirely metabolized by the small intestine and liver.</p>


<div>
<figure><img decoding="async" width="760" height="542" src="https://source.washu.edu/app/uploads/2024/11/GJP_headshot_760.jpg" alt="Gary Patti" srcset="https://source.washu.edu/app/uploads/2024/11/GJP_headshot_760.jpg 760w, https://source.washu.edu/app/uploads/2024/11/GJP_headshot_760-300x214.jpg 300w, https://source.washu.edu/app/uploads/2024/11/GJP_headshot_760-150x107.jpg 150w, https://source.washu.edu/app/uploads/2024/11/GJP_headshot_760-360x257.jpg 360w" sizes="(max-width: 760px) 100vw, 760px"><figcaption>Patti</figcaption></figure>
</div>


<p>Both sugars are found naturally in fruits, vegetables, dairy products and grains. They are also added as sweeteners in many processed foods. Fructose, in particular, has penetrated the American diet over the last few decades. It is favored by the food industry because it is sweeter than glucose.</p>



<p>Prior to the 1960s, people consumed relatively little fructose compared with today’s numbers. A century ago, an average person consumed just 5-10 pounds of fructose per year. To put it in familiar terms, that is roughly equal to the weight of a gallon of milk. In the 21st century, that number has increased to be as high as the equivalent of 15 gallons of milk.</p>



<p>“If you go through your pantry and look for the items that contain high-fructose corn syrup, which is the most common form of fructose, it is pretty astonishing,” said Patti, who is also a research member of Siteman Cancer Center, based at Barnes-Jewish Hospital and WashU Medicine, and the Center for Human Nutrition at WashU Medicine.</p>



<p>“Almost everything has it. It’s not just candy and cake, but also foods such as pasta sauce, salad dressing and ketchup,” he said. “Unless you actively seek to avoid it, it’s probably part of your diet.”</p>



<figure><img decoding="async" width="760" height="543" src="https://source.washu.edu/app/uploads/2024/11/shutterstock_2505627811_760.jpg" alt="fast food" srcset="https://source.washu.edu/app/uploads/2024/11/shutterstock_2505627811_760.jpg 760w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2505627811_760-300x214.jpg 300w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2505627811_760-150x107.jpg 150w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2505627811_760-360x257.jpg 360w" sizes="(max-width: 760px) 100vw, 760px"><figcaption>(Photo: Shutterstock)</figcaption></figure>



<h2 id="h-cancer-s-appetite-for-fructose">Cancer’s appetite for fructose</h2>



<p>Given the rapid rise in the consumption of dietary fructose over recent decades, the WashU researchers wanted to know more about how fructose impacts the growth of tumors.</p>



<p>Patti and Fowle-Grider began their investigation by feeding tumor-bearing animals a diet rich in fructose, then measuring how quickly their tumors grew. The researchers found that added fructose promoted tumor growth without changing body weight, fasting glucose or fasting insulin levels.</p>



<p>“We were surprised to see that it had a rather dramatic impact. In some cases, the growth rate of the tumors accelerated by two-fold or even higher,” Patti said. “Eating a lot of fructose was clearly very bad for the progression of these tumors.”</p>



<p>But the next step in their experiments initially stumped them. When Fowle-Grider attempted to repeat a version of this test by feeding fructose to cancer cells isolated in a dish, the cells did not respond. “In most cases they grew almost as slowly as if we gave them no sugar at all,” Patti said.</p>







<p>So, Patti and Fowle-Grider went back to looking at changes in the small molecules in the blood of animals fed high-fructose diets. Using metabolomics, they identified elevated levels of a variety of lipid species, including lysophosphatidylcholines (LPCs). Additional dish tests showed that liver cells that were fed fructose release LPCs.</p>



<p>“Interestingly, the cancer cells themselves were unable to use fructose readily as a nutrient because they do not express the right biochemical machinery,” Patti said. “Liver cells do. This allows them to convert fructose into LPCs, which they can secrete to feed tumors.”</p>



<p>A defining characteristic of cancer is uncontrolled proliferation of malignant cells. Each time a cell divides, it must replicate its contents, including membranes. This requires a substantial amount of lipids. While lipids can be synthesized from scratch, it is much easier for cancer cells to simply take lipids up from their surrounding environment.</p>



<p>“Over the past few years, it’s become clear that many cancer cells prefer to take up lipids rather than make them,” Patti noted. “The complication is that most lipids are insoluble in blood and require rather complex transport mechanisms. LPCs are unique. They might provide the most effective and efficient way to support tumor growth.”</p>



<figure><img loading="lazy" decoding="async" width="760" height="543" src="https://source.washu.edu/app/uploads/2024/11/shutterstock_2515904649_760.jpg" alt="" srcset="https://source.washu.edu/app/uploads/2024/11/shutterstock_2515904649_760.jpg 760w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2515904649_760-300x214.jpg 300w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2515904649_760-150x107.jpg 150w, https://source.washu.edu/app/uploads/2024/11/shutterstock_2515904649_760-360x257.jpg 360w" sizes="(max-width: 760px) 100vw, 760px"><figcaption>(Photo: Shutterstock)</figcaption></figure>



<h2 id="h-avoiding-fructose">Avoiding fructose</h2>



<p>Interestingly, over the same period of time when human fructose consumption has surged, a number of cancers have become increasingly more prevalent among people under the age of 50. This raises the question whether the trends are linked. With $25 million in support from Cancer Grand Challenges, Patti recently teamed up with Yin Cao, an associate professor of surgery at WashU Medicine, and other investigators from around the world, none of whom were involved in this study, <a href="https://medicine.washu.edu/news/preventing-early-onset-colorectal-cancers-aim-of-25-million-award/">to investigate possible connections</a>.</p>



<p>“It will be exciting to better understand how dietary fructose influences cancer incidence. But one take-home message from this current study is that if you are unfortunate enough to have cancer, then you probably want to think about avoiding fructose. Sadly, that is easier said than done,” Patti said.</p>



<p>Aside from dietary intervention, the study authors said that this research could help us develop a way to prevent fructose from driving tumor growth therapeutically, using drugs.</p>



<p>“An implication of these findings is that we do not have to limit ourselves to therapeutics that only target disease cells,” Patti said. “Rather, we can think about targeting the metabolism of healthy cells to treat cancer. This has worked with mice in our study, but we would like to take advantage of our observations and try to improve the lives of patients.”</p>



<p>The study authors are working with clinical partners at WashU Medicine to explore a clinical trial related to fructose in the diet.</p>



<hr>



<p>This research was funded in part by the National Institutes of Health (NIH) (R35 ES028365)</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Arc Prize 2024 Winners and Technical Report (104 pts)]]></title>
            <link>https://arcprize.org/2024-results</link>
            <guid>42343215</guid>
            <pubDate>Fri, 06 Dec 2024 19:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arcprize.org/2024-results">https://arcprize.org/2024-results</a>, See on <a href="https://news.ycombinator.com/item?id=42343215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div id="top-bar">
            <p><a href="https://arcprize.org/"><img src="https://arcprize.org/media/images/arc-prize-logo.svg" alt="ARC Prize Logo"></a>
            </p>
            
        </div>
        
        <p>
            <h2>ARC Prize remains undefeated.<br>New ideas still needed<span>.</span></h2>
        </p>
        
        
        <div>
    
    <p>The Grand Prize remains unclaimed.</p>
    <div>
        <p><a href="https://arcprize.org/2024/report" target="_blank" onclick="gtag('event', 'download_report', {'element': 'image'});"><img src="https://arcprize.org/media/images/arc-prize-2024-tech-report-preview.jpg"></a>
        </p>
        <div>
            <p>The official 2024 Technical Report.</p>
            <ul>
                <li>2024 competition results</li>
                <li>Top solution approaches</li>
                <li>In-depth technical analysis</li>
                <li>Trends &amp; key insights</li>
            </ul>
            
        </div>
    </div>
    <p>All scores &amp; papers below are open source &amp; reproducible.</p>
</div>
<div>
            <h3>2024 High Score Winners</h3>
            <table>
                <tbody><tr>
                    <td>1st</td>
                    <td>the ARChitects <div><p><a href="https://www.kaggle.com/code/gregkamradt/arc-prize-v8?scriptVersionId=211457842" target="_blank">Code</a> <a href="https://github.com/da-fr/arc-prize-2024/blob/main/the_architects.pdf" target="_blank">Paper</a></p></div></td>
                    <td>53.5%</td>
                    <td>$25k</td>
                </tr>
                <tr>
                    <td>2nd</td>
                    <td>G. Barbadillo <div><p><a href="https://www.kaggle.com/code/ironbar/single-task-test-time-fine-tuning-for-arc24?scriptVersionId=199282752" target="_blank">Code</a> <a href="https://ironbar.github.io/arc24/05_Solution_Summary/" target="_blank">Paper</a></p></div></td>
                    <td>40%</td>
                    <td>$10k</td>
                </tr>
                <tr>
                    <td>3rd</td>
                    <td>alijs <div><p><a href="https://www.kaggle.com/code/gregkamradt/arc-prize-2024-solution-4th-place-score-40-811b72" target="_blank">Code</a></p></div></td>
                    <td>40%</td>
                    <td>$5k</td>
                </tr>
                <tr>
                    <td>4th</td>
                    <td>William Wu <div><p><a href="https://www.kaggle.com/code/gregkamradt/small-sample-arc24" target="_blank">Code</a></p></div></td>
                    <td>37%</td>
                    <td>$5k</td>
                </tr>
                <tr>
                    <td>5th</td>
                    <td>PoohAI <div><p><a href="https://www.kaggle.com/code/gregkamradt/arc-prize-2024-8th-place-solution" target="_blank">Code</a> <a href="https://drive.google.com/file/d/1kTom9M54LVfLbPDQHpGgfUs3y1IYIpy2/view?usp=sharing" target="_blank">Paper</a></p></div></td>
                    <td>37%</td>
                    <td>$5k</td>
                </tr>
            </tbody></table>
            <p><span>Score (private eval)</span></p>
        </div>
<div>
    <h3>2024 Paper Award Winners</h3>
    <h4>1st Place - $50k</h4>
    <p>"Combining Induction and Transduction for Abstract Reasoning".<a href="https://arxiv.org/abs/2411.02272" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Li et al.</i></p>
    <h4>2nd Place - $20k</h4>
    <p>"The Surprising Effectiveness of Test-Time Training for Abstract Reasoning".<a href="https://arxiv.org/abs/2411.07279" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Akyürek et al.</i></p>
    <h4>3rd Place - $5k</h4>
    <p>"Searching Latent Program Spaces".<a href="https://github.com/clement-bonnet/lpn/blob/7f86b1d11ea37ba173700dbac8604393eac6da37/paper.pdf" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Bonnet &amp; Macfarlane</i></p>
    <hr>
    <h4>Runners Up - $2.5k</h4>
    <p>"The LLM ARChitect: Solving ARC-AGI Is a Matter of Perspective".<a href="https://github.com/da-fr/arc-prize-2024/blob/main/the_architects.pdf" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Franzen et al.</i></p>
    <p>"Omni-ARC".<a href="https://ironbar.github.io/arc24/05_Solution_Summary/" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Barbadillo</i></p>
    <p>"Mini-ARC: Solving Abstraction and Reasoning Puzzles with Small Transformer Models".<a href="https://www.paulfletcherhill.com/mini-arc.pdf" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Fletcher-Hill</i></p>
    <p>"Towards Efficient Neurally-Guided Program Induction for ARC-AGI".<a href="https://drive.google.com/file/d/1sFlK3mhz8kH2agdE379o0ODQWYkrSD0b/view?usp=drive_link" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Ouellette</i></p>
    <p>"A 2D nGPT Model For ARC Prize".<a href="https://github.com/jfpuget/ARC-AGI-Challenge-2024/blob/main/arc.pdf" target="_blank"><img src="https://arcprize.org/media/images/icon-open-new.svg" alt="Open in new window"></a><br><i>Puget</i></p>
</div>

<div>
            <h3>2024 ARC-AGI-Pub High Scores</h3>
            <table>
                <tbody><tr>
                    <td>Jeremy Berman</td>
                    <td>53.6%</td>
                    <td>58.5%</td>
                    <td><a href="https://www.kaggle.com/code/jerber/jeremy-arc" target="_blank">Code</a> <a href="https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi" target="_blank">Paper</a></td>
                </tr>
                <tr>
                    <td>MARA(BARC) + MIT</td>
                    <td>47.5%</td>
                    <td>62.8%</td>
                    <td><a href="https://www.kaggle.com/code/xu3cpn/ensemble-induction-and-transduction" target="_blank">Code</a> <a href="https://ekinakyurek.github.io/papers/ttt.pdf" target="_blank">Paper</a></td>
                </tr>
                <tr>
                    <td>Ryan Greenblatt</td>
                    <td>43%</td>
                    <td>42%</td>
                    <td><a href="https://www.kaggle.com/code/rgreenblatt/rg-basic-ported-submission" target="_blank">Code</a> <a href="https://redwoodresearch.substack.com/p/getting-50-sota-on-arc-agi-with-gpt" target="_blank">Paper</a></td>
                </tr>
                <tr>
                    <td>o1-preview</td>
                    <td>18%</td>
                    <td>21%</td>
                    <td><a href="https://www.kaggle.com/code/gregkamradt/using-frontier-models-on-arc-agi-via-langchain" target="_blank">Code</a></td>
                </tr>
                <tr>
                    <td>Claude 3.5 Sonnet</td>
                    <td>14%</td>
                    <td>21%</td>
                    <td><a href="https://www.kaggle.com/code/gregkamradt/using-frontier-models-on-arc-agi-via-langchain" target="_blank">Code</a></td>
                </tr>
                <tr>
                    <td>GPT-4o</td>
                    <td>5%</td>
                    <td>9%</td>
                    <td><a href="https://www.kaggle.com/code/gregkamradt/using-frontier-models-on-arc-agi-via-langchain" target="_blank">Code</a></td>
                </tr>
                <tr>
                    <td>Gemini 1.5</td>
                    <td>4.5%</td>
                    <td>8%</td>
                    <td><a href="https://www.kaggle.com/code/gregkamradt/using-frontier-models-on-arc-agi-via-langchain" target="_blank">Code</a></td>
                </tr>
            </tbody></table>
            <p><span>Score (semi-private eval)</span> / <span>Score (public eval)</span></p>
        </div>
<div>
    <h3>ARC Prize 2025</h3>
    <p>We aspire to grow ARC Prize from its experimental origins into a durable north star for AGI.</p>
    <p>The 2025 edition of the competition will account for a diversity of incentives to serve academics, independent researchers, startups, and big labs.</p>
    <p>Alongside the competition launch, expect to see ARC-AGI-2 - same format, better benchmark.</p>
    <p>We'll announce more competition details early next year. Stay tuned!</p>
    <p><span></span> <a href="#" data-modal-id="newsletter">Sign up for updates</a></p>
</div>


        

        
        <div id="signup">
            
            <form action="https://app.convertkit.com/forms/6685080/subscriptions" method="post" data-sv-form="6685080" data-uid="bc80575d89" data-format="inline" data-version="5" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:false,&quot;url&quot;:&quot;https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}" min-width="400 500 600 700 800">
                <div data-element="column" data-style="full">
                        
                        <ul data-element="errors" data-group="alert"></ul>
                        
                        <p><small>No spam. You can unsubscribe at anytime.</small>
                        </p>
                    </div>
            </form>
        </div>
        <div id="newsletter">
            
            <form action="https://app.convertkit.com/forms/6685080/subscriptions" method="post" data-sv-form="6685080" data-uid="bc80575d89" data-format="inline" data-version="5" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:false,&quot;url&quot;:&quot;https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}" min-width="400 500 600 700 800">
                <div data-element="column" data-style="full">
                        
                        <ul data-element="errors" data-group="alert"></ul>
                        
                        <p><small>No spam. You can unsubscribe at anytime.</small>
                        </p>
                    </div>
            </form>
        </div>
        <p><a href="#" id="bg-animation">Toggle Animation</a>


</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Maps.me co-founder tries to close down Organic Maps open-source fork (244 pts)]]></title>
            <link>https://github.com/orgs/organicmaps/discussions/9837</link>
            <guid>42343121</guid>
            <pubDate>Fri, 06 Dec 2024 19:11:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/orgs/organicmaps/discussions/9837">https://github.com/orgs/organicmaps/discussions/9837</a>, See on <a href="https://news.ycombinator.com/item?id=42343121">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="7623761" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">Today I am announcing the public disclose of the source code of so-called "metaserver", that previously was available only to few people of the team. At Organic Maps, we prioritize transparency and open communication with our community and committed to making our source code publicly available, ensuring that users can fully engage with and contribute to the project.</p>
<p dir="auto">=&gt; <a href="https://github.com/organicmaps/meta">https://github.com/organicmaps/meta</a> (MIT License)</p>
<h2 dir="auto">What is the Metaserver?</h2>
<p dir="auto">The purpose of so-called "metaserver" is to dynamically redirect users to the most suitable CDN servers containing requested map version based on their geographic location. For example, users in North America are routed to servers in the U.S., ensuring faster map downloads. Additionally, the metaserver enables dynamic server reconfiguration without requiring approval from the App Store or Google Play, which can take weeks.</p>
<h2 dir="auto">How does it work?</h2>
<p dir="auto">The service is implemented as a Cloudflare Worker, which returns a JSON response containing a list of servers based on the GeoIP information of the requester. Essentially, this functionality could be replaced with a few static JSON files a series of rules in an Nginx configuration. The decision to use Cloudflare Workers seems controversial at this point. It was likely an unfortunate choice that should be revisited in the near future to prevent vendor lock-in and ensure the project remains independent of large tech corporations.</p>
<h2 dir="auto">Why Was It Closed?</h2>
<p dir="auto">The original author of this component justified the decision to close it due to concerns about unauthorized forks. Indeed, we observed at least two forks that misused the content delivery network, funded by donations, for their private gain. However, it appears that the closed-source nature of the component did little to prevent this issue.</p>
<h2 dir="auto">Why Open Now?</h2>
<p dir="auto">The component was contributed by Alexandr Borsuk (a.k.a. Alexander Zolotorev) back in 2021 under the MIT license, although the repository itself was not publicly accessible. Throughout November 2024, the issue of closed-source code was discussed several times in the Telegram chats with key contributors.</p>
<p dir="auto">On November 23, Mr. Borsuk quietly made a change, removing the MIT license while keeping his copyright. The change with the flagrant comment "No MIT yet, sorry." was discovered by me only today. A few non-significant commits were made on top of it.</p>
<p dir="auto"><strong>This subtle, almost unnoticed modification effectively privatized the open-source repository by this individual, preventing any further open-source collaboration. Furthermore, the next change of enabling the logs, clearly violates our commitment to privacy.</strong> To my knowledge, this decision was not discussed with any other contributors, including those who had previously contributed to the repository.</p>
<div data-snippet-clipboard-copy-content="commit 30e9911d4c8329068aca82fd6c0d896380ba99de
Author: Alexander Borsuk <170263+biodranik@users.noreply.github.com>
Date:   Sat Nov 23 21:33:36 2024 +0100

    Update LICENSE

    No MIT yet, sorry.

    Signed-off-by: Alexander Borsuk <170263+biodranik@users.noreply.github.com>"><pre><code>commit 30e9911d4c8329068aca82fd6c0d896380ba99de
Author: Alexander Borsuk &lt;170263+biodranik@users.noreply.github.com&gt;
Date:   Sat Nov 23 21:33:36 2024 +0100

    Update LICENSE

    No MIT yet, sorry.

    Signed-off-by: Alexander Borsuk &lt;170263+biodranik@users.noreply.github.com&gt;
</code></pre></div>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1799054/393275408-06bb1e8a-d096-4776-b960-ffe51292f2fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI3NTQwOC0wNmJiMWU4YS1kMDk2LTQ3NzYtYjk2MC1mZmU1MTI5MmYyZmUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjRlN2JjZjI0ZDFjNzI2ZGI2Yjk3NjA5NmRjYjIyMmY3ZjIyOWM1Y2EzZDQ5MjA4OTk3NjA4NWY2NWVhOGYxMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.t_sbJiSSH1AemgpIfvqalvjlUdeeapcnmcAhbWTxxsE"><img width="1433" alt="image" src="https://private-user-images.githubusercontent.com/1799054/393275408-06bb1e8a-d096-4776-b960-ffe51292f2fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI3NTQwOC0wNmJiMWU4YS1kMDk2LTQ3NzYtYjk2MC1mZmU1MTI5MmYyZmUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjRlN2JjZjI0ZDFjNzI2ZGI2Yjk3NjA5NmRjYjIyMmY3ZjIyOWM1Y2EzZDQ5MjA4OTk3NjA4NWY2NWVhOGYxMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.t_sbJiSSH1AemgpIfvqalvjlUdeeapcnmcAhbWTxxsE"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1799054/393276580-897611d9-2a93-4257-af1e-c0d77de8a42b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI3NjU4MC04OTc2MTFkOS0yYTkzLTQyNTctYWYxZS1jMGQ3N2RlOGE0MmIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTI1OWI4YTIxYWRkMmZkYmEzMDU0ZTIxNmNmOTgyZTYxMDUzOTIwZjJiMTk0NjMwZWVlYjQzOWExODliYzQ1OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.kpfbfxzwn-ewe-5xUme_umLoXTDSrYCgJO6UH2UHXQU"><img width="758" alt="image" src="https://private-user-images.githubusercontent.com/1799054/393276580-897611d9-2a93-4257-af1e-c0d77de8a42b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI3NjU4MC04OTc2MTFkOS0yYTkzLTQyNTctYWYxZS1jMGQ3N2RlOGE0MmIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTI1OWI4YTIxYWRkMmZkYmEzMDU0ZTIxNmNmOTgyZTYxMDUzOTIwZjJiMTk0NjMwZWVlYjQzOWExODliYzQ1OCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.kpfbfxzwn-ewe-5xUme_umLoXTDSrYCgJO6UH2UHXQU"></a>
<p dir="auto">link: <a href="https://github.com/organicmaps/meta/commit/30e9911d4c8329068aca82fd6c0d896380ba99de">https://github.com/organicmaps/meta/commit/30e9911d4c8329068aca82fd6c0d896380ba99de</a></p>
<p dir="auto">The commit following the license change enabled logging in Cloudflare...</p>
<div data-snippet-clipboard-copy-content="commit a6ff0eb05abfc891e6a3a32faa3cd307a40c6121
Author: Alexander Borsuk <170263+biodranik@users.noreply.github.com>
Date:   Sun Nov 24 21:28:02 2024 +0100

    Observe server abusers when needed

    Signed-off-by: Alexander Borsuk <170263+biodranik@users.noreply.github.com>

diff --git a/wrangler.toml b/wrangler.toml
index bfcdcf6..bad7b47 100644
--- a/wrangler.toml
+++ b/wrangler.toml
@@ -23,3 +23,6 @@ route = 'meta.omaps.app/*'

 [env.prod.vars]
 DEBUG = false
+
+[observability.logs]
+enabled = true"><pre><code>commit a6ff0eb05abfc891e6a3a32faa3cd307a40c6121
Author: Alexander Borsuk &lt;170263+biodranik@users.noreply.github.com&gt;
Date:   Sun Nov 24 21:28:02 2024 +0100

    Observe server abusers when needed

    Signed-off-by: Alexander Borsuk &lt;170263+biodranik@users.noreply.github.com&gt;

diff --git a/wrangler.toml b/wrangler.toml
index bfcdcf6..bad7b47 100644
--- a/wrangler.toml
+++ b/wrangler.toml
@@ -23,3 +23,6 @@ route = 'meta.omaps.app/*'

 [env.prod.vars]
 DEBUG = false
+
+[observability.logs]
+enabled = true
</code></pre></div>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1799054/393282621-35cde1e0-0890-4b25-9033-59ff9222b50e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI4MjYyMS0zNWNkZTFlMC0wODkwLTRiMjUtOTAzMy01OWZmOTIyMmI1MGUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzVlMmRjNjc2MTNiMjBlNzk1NDM4ZjY3MDcwOWYxYjZhMGQ0YzlmM2ZlNDAxNzkzN2Y1N2IxYjM0MjZlZDljZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.vs_MEunSXjlNunrpZ6pqE7F8AZEeKpYguwXYQtLYpBk"><img width="1440" alt="image" src="https://private-user-images.githubusercontent.com/1799054/393282621-35cde1e0-0890-4b25-9033-59ff9222b50e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzM1MjA5MDMsIm5iZiI6MTczMzUyMDYwMywicGF0aCI6Ii8xNzk5MDU0LzM5MzI4MjYyMS0zNWNkZTFlMC0wODkwLTRiMjUtOTAzMy01OWZmOTIyMmI1MGUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDZUMjEzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzVlMmRjNjc2MTNiMjBlNzk1NDM4ZjY3MDcwOWYxYjZhMGQ0YzlmM2ZlNDAxNzkzN2Y1N2IxYjM0MjZlZDljZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.vs_MEunSXjlNunrpZ6pqE7F8AZEeKpYguwXYQtLYpBk"></a>
<p dir="auto">link: <a href="https://github.com/organicmaps/meta/commit/a6ff0eb05abfc891e6a3a32faa3cd307a40c6121">https://github.com/organicmaps/meta/commit/a6ff0eb05abfc891e6a3a32faa3cd307a40c6121</a></p>
<h2 dir="auto">Actions Taken</h2>
<ol dir="auto">
<li>I am making the code from before November 23, 2024, publicly available again under MIT.  As one of the authors who contributed to the code while it was under the MIT license, I have the full right to take this action. Proprietary changes after "No MIT yet, sorry" and "Observe server abusers when needed" has been removed or reverted.</li>
<li>The copyright notice has been updated to include "Copyright 2024 Organic Maps Contributors" to accurately reflect the current situation.</li>
<li>Contributors and the community are invited to perform a thorough and independent review to verify that the code functions as expected without introducing any undocumented functionality.</li>
<li>This post issues an open call to replace the proprietary Cloudflare technology with an open-source alternative, though this may take some time.<br>
6.. Log collection has been disabled, as it was previously.</li>
</ol>
<hr>
<p dir="auto">I, personally, apologize to the community for this matter. All necessary measures have been taken to resolve this issue. Organic Maps remains fully committed to privacy, transparency, and open-source values, which is why we are openly disclosing this issue.</p>
<p dir="auto">Regards,<br>
Roman.</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[<dialog>: The Dialog Element (206 pts)]]></title>
            <link>https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog</link>
            <guid>42343089</guid>
            <pubDate>Fri, 06 Dec 2024 19:09:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog</a>, See on <a href="https://news.ycombinator.com/item?id=42343089">Hacker News</a></p>
Couldn't get https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Reinforcement Fine-Tuning Research Program (139 pts)]]></title>
            <link>https://openai.com/form/rft-research-program/</link>
            <guid>42342697</guid>
            <pubDate>Fri, 06 Dec 2024 18:37:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/form/rft-research-program/">https://openai.com/form/rft-research-program/</a>, See on <a href="https://news.ycombinator.com/item?id=42342697">Hacker News</a></p>
Couldn't get https://openai.com/form/rft-research-program/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Every UUID Dot Com (832 pts)]]></title>
            <link>https://everyuuid.com/</link>
            <guid>42342382</guid>
            <pubDate>Fri, 06 Dec 2024 18:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://everyuuid.com/">https://everyuuid.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42342382">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tokyo is set to introduce a four-day workweek for government employees (468 pts)]]></title>
            <link>https://www.cnn.com/2024/12/06/asia/tokyo-government-4-day-workweek-intl-hnk/index.html</link>
            <guid>42342203</guid>
            <pubDate>Fri, 06 Dec 2024 17:54:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/12/06/asia/tokyo-government-4-day-workweek-intl-hnk/index.html">https://www.cnn.com/2024/12/06/asia/tokyo-government-4-day-workweek-intl-hnk/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42342203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cm4cbn47d000s3b6mx8wowktd@published" data-name="GettyImages-1621458776.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6669445602334306" data-original-height="1600" data-original-width="2399" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="383" width="680" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=16x9&amp;q=h_383,w_680,c_fill/f_webp" type="image/webp"><source height="653" width="1160" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=16x9&amp;q=h_653,w_1160,c_fill/f_webp" type="image/webp"><source height="605" width="1075" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=16x9&amp;q=h_605,w_1075,c_fill/f_webp" type="image/webp"><source height="833" width="1480" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=16x9&amp;q=h_833,w_1480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1621458776.jpg?c=16x9&amp;q=h_833,w_1480,c_fill" alt="People commute to work in Tokyo, Japan, on Monday, Aug. 21, 2023." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1600" width="2399"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                  <p><cite>
      <span data-editable="location">Tokyo</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4caphow000m2cp864uz1p62@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Japanese capital is set to introduce a four-day workweek for government employees, in its latest push<strong> </strong>to help working mothers and boost record-low fertility rates.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00033b6mqrxup0pp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Tokyo Metropolitan Government says the new arrangement, which begins in April, could give employees three days off every week. It separately announced another policy that will allow parents with children in grades one to three in elementary schools to trade off a bit of their salary for the option to clock out early.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00043b6m5pbho5qb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “We will review work styles … with flexibility, ensuring no one has to give up their career due to life events such as childbirth or childcare,” said Tokyo Governor Yuriko Koike when she unveiled the plan in a policy speech on Wednesday.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00053b6mhqks1kim@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Now is the time for Tokyo to take the initiative to protect and enhance the lives, livelihoods and economy of our people during these challenging times for the nation,” she added.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00063b6mndcrrit3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            <a href="https://www.cnn.com/world/asia/japan">Japan</a>’s fertility rate, which has seen a precipitous fall for many years, reached another <a href="https://www.cnn.com/2024/06/07/asia/japan-birth-rate-population-dating-app-intl-hnk/index.html">record low</a> in June, even as the government ramped up efforts to encourage young people to get married and start families.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cm4cbo5hj000u3b6mrkly1cl0@published" data-name="GettyImages-2161005464.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6666666666666666" data-original-height="1600" data-original-width="2400" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?c=original" data-editable="settings">
       <picture><source height="1600" width="2400" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?q=w_1110,c_fill/f_webp" type="image/webp"><source height="1600" width="2400" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?q=w_1015,c_fill/f_webp" type="image/webp"><source height="1600" width="2400" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?q=w_1160,c_fill/f_webp" type="image/webp"><source height="1600" width="2400" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2161005464.jpg?q=w_1110,c_fill" alt="Tokyo Governor Yuriko Koike speaks to the media after winning the Tokyo gubernatorial election in Tokyo, Japan, on July 07, 2024." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1600" width="2400" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00073b6mg31kl5lg@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Only 727,277 births were recorded last year, with the fertility rate - the number of children a woman has in her lifetime - dropping to a fresh low of 1.2, according to the Ministry of Health, Labour and Welfare. For a population to remain stable, it needs a fertility rate of 2.1.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00083b6mnr53mnha@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Japanese government has been pushing for a raft of “<a href="https://www.cnn.com/2023/01/23/asia/japan-kishida-birth-rate-population-intl-hnk/index.html">now or never</a>” policies to reverse the population crisis, including ensuring men to <a href="https://www.cnn.com/2023/03/26/asia/japan-paternity-leave-policy-challenges-intl-hnk-dst/index.html">take paternity leaves</a>, while other local governments have also introduced measures to improve work conditions.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv00093b6mo1ec1w6z@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Many sociologists attribute the ever-plunging birth rates to Japan’s unforgiving work culture<strong> </strong>and rising costs of living. <a href="https://www.cnn.com/2024/08/31/business/japan-workers-resignation-agencies-intl-hnk/index.html">Grueling hours</a> have long been a problem for corporate Japan where workers often suffer from health hazards and, in extreme cases, “karoshi,” a term meaning death by over work.<strong> </strong>
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv000a3b6mmaur9jam@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            As in other countries, women are often under pressure to choose between their career or family, but Japan’s unique overtime work culture makes pregnancy and raising children especially daunting.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv000b3b6mqm06030z@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In fact, <a href="https://genderdata.worldbank.org/en/economies/japan#:~:text=In%20Japan%2C%20the%20labor%20force,males%20is%2071.5%25%20for%202023" target="_blank">according to</a> the World Bank, the gender gap in the country’s labor force participation, which stood at 55% for women and 72% for men last year, is higher than other high-income nations.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv000c3b6mlzo6k4nh@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The shift to a four-day workweek has sparked growing interest in the West, where some companies are beginning to explore compressed hours as a way to attract talent seeking better work-life balance. Some studies have shown that it improves well-being and productivity among workers.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv000d3b6mwxw5mv3e@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But the idea is still seen as radical for Japanese companies, which often equates time spent at work with loyalty for the company.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4captmv000e3b6m8iugb7pj@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            And Tokyo isn’t the only place in Asia to implement more family friendly policies. Earlier this year, Singapore introduced <a href="https://www.mom.gov.sg/-/media/mom/documents/press-releases/2024/tripartite-guidelines-on-flexible-work-arrangement-requests.pdf" target="_blank">new guidelines</a> requiring all firms to consider requests by employees for flexible-working arrangements. That could include four-day weeks or flexible hours.
    </p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistakes as a new manager (134 pts)]]></title>
            <link>https://terriblesoftware.org/2024/12/04/the-6-mistakes-youre-going-to-make-as-a-new-manager/</link>
            <guid>42341506</guid>
            <pubDate>Fri, 06 Dec 2024 16:56:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terriblesoftware.org/2024/12/04/the-6-mistakes-youre-going-to-make-as-a-new-manager/">https://terriblesoftware.org/2024/12/04/the-6-mistakes-youre-going-to-make-as-a-new-manager/</a>, See on <a href="https://news.ycombinator.com/item?id=42341506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="8e08">Moving from an Individual Contributor (IC) to a manager is a significant career step. This is especially true in the ever-evolving tech industry. This change brings new challenges and opportunities to learn.</p>



<p id="e661">Reflecting on my first couple of years as an Engineering Manager, I realized that the lessons I learned are not unique to me; many new managers face similar experiences. That’s why I want to share these insights with you. My goal is to support and connect with other new managers who are going through this exciting yet demanding transition.</p>



<h3 id="c84d">🤝 Delegation</h3>



<p id="8c34">The most common trap you’ll probably fall into is the (many times, subconscious) reluctance to delegate. Transitioning from an IC to a manager, I found myself attached to old responsibilities, unable to trust my team with tasks I used to do.</p>



<p id="bdc9">You’ll rationalize it, “they won’t be able to do it the same way I’d do it,” but even if this is true (it’s not), long-term thinking you want your team to be able to tackle the things you used to do. Otherwise, they won’t grow — and neither will you.</p>



<p id="aadf">Remember that delegation isn’t about randomly distributing tasks; it’s about empowering your team, trusting them, and stepping into your new role as a leader.</p>



<h3 id="bfd2">🧠 Where’s my dopamine?</h3>



<p id="ce25">For over a decade, my dopamine (from work) came from a very predictable place: shipping new things. As a manager, those direct rewards will simply disappear, leaving you feeling unfulfilled for weeks (months in my case).</p>



<p id="0680">I won’t lie; this isn’t a solved problem for me yet, but I think I got into a much better shape by (trying to) rewire my brain into getting satisfaction from other places: giving feedback, seeing my reports grow, writing a very thorough performance review, etc.</p>



<p id="394e">Keep in mind that we’re not the stars anymore; we’re facilitators. Yes, it’s true that we don’t ship&nbsp;<em>a</em>&nbsp;project directly anymore, but we’re helping our team ship&nbsp;<em>all</em>&nbsp;projects.</p>



<h3 id="8297">🔍 Quality over quantity</h3>



<p id="e10b">It’s easy for new managers to equate the growth of their team size with personal and professional success. In my early days, I found myself desiring more team members or even additional teams, believing it’d reflect my management skills — and, of course, lead to a salary raise.</p>



<p id="9ff3">However, I soon learned that this was a mistake. True growth comes from the quality of your team’s output, not from the quantity of its members.&nbsp;Focus on pushing your team to the next level; create a place where they can come up with new ideas and do great work. This not only leads to higher quality work but also to a more cohesive and happier team. Remember,&nbsp;a smaller team that works well together can do better than a bigger team that doesn’t.</p>



<h3 id="4f4f">⚖️ The level of engagement</h3>



<p id="b384">The right amount of engagement that you should have in your team’s projects is also a tricky subject. Lean in too much, and you’re micromanaging; lean out too much, and you appear disengaged.</p>



<p id="d5d5">To find the right balance, consider the concept of&nbsp;<a href="https://www.linkedin.com/pulse/guided-autonomy-empowering-teams-act-jim-kalbach/" rel="noreferrer noopener" target="_blank">Guided Autonomy</a>. This means setting clear goals and expectations, then stepping back and letting your team figure out how to achieve them. Your role becomes less about directing every action and more about providing guidance. This approach promotes responsibility and growth within your team while ensuring alignment with project objectives.</p>



<p id="ad1c">In my journey, I’ve learned that effective engagement means being present without being overbearing. It’s about creating an environment where your team feels supported but also free to innovate and take ownership. The key is to offer guidance and support without taking away your team’s independence.</p>



<h3 id="5138">👁️ Managing perception</h3>



<p id="b7f1">As an individual contributor (IC), your work spoke for itself; people could easily see it. Plain and simple. As a manager, it’s less black and white, and surprisingly, for many new managers, part of your job now involves managing how others see you.</p>



<p id="51f4">With your team members, it’s about making sure they understand and appreciate your role as a facilitator of their success. You’re no longer directly creating the product, but you play a crucial role in guiding the process, overcoming obstacles, and creating an environment where creativity and productivity thrive. It’s important for your team to recognize and value this shift in your contribution — from individual accomplishments to team successes.</p>



<p id="d958">Externally, the challenge is different but equally important. Stakeholders, other departments, and senior management may not see the day-to-day impact you have on your team. Here, managing perception involves actively communicating your team’s achievements and how your leadership contributes to these successes. It’s not about taking credit for the work, but about highlighting your role in empowering your team to excel. It’s a delicate balance of showcasing the team’s work while making your leadership and its positive effects visible to those outside of your immediate group.</p>



<p id="0e84">I understand&nbsp;how&nbsp;controversial this can be, and it’s one of the reasons why ICs often hesitate to transition into management (“all that politics!”). But it is what it is, so it’s important to adapt. Perception management is about clarity and visibility, not just for your own benefit but also to accurately represent your team’s efforts.</p>



<h3 id="c52b">🌟 Redefining success</h3>



<p id="6c93">It’s quite common for ICs to have impostor syndrome, but for managers — especially new ones — this will reach a whole new level.</p>



<p id="757a">You’ll often question your work or even if there’s any value in anything that you’re doing. I’ve been there, and from what I learned, success for you is as simple as asking yourself two questions:</p>



<ol>
<li>Is my team shipping?</li>



<li>Are they happy?</li>
</ol>



<p id="fa4c">If the answer is “yes” to both, don’t worry; you’re crushing it. 🎉</p>



<hr>



<p id="514f">Every new manager makes mistakes, but each one is an opportunity to grow. Embrace these challenges as part of the learning process. Becoming a skilled manager takes time and continuous learning. Keep pushing forward, and soon, your mistakes will become milestones in your management career.</p>



<p id="9c21">I’d love to hear about your journey as a new manager. What challenges have you faced, and what lessons have you learned? Share your stories and insights below or&nbsp;<a href="https://bsky.app/profile/terriblesoftware.org" target="_blank" rel="noreferrer noopener">contact me directly</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama-3.3-70B-Instruct (362 pts)]]></title>
            <link>https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct</link>
            <guid>42341388</guid>
            <pubDate>Fri, 06 Dec 2024 16:44:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct">https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct</a>, See on <a href="https://news.ycombinator.com/item?id=42341388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START --><h2>
	<a rel="nofollow" href="#model-information" id="model-information">
		
	</a>
	<span>
		Model Information
	</span>
</h2>
<p>The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.</p>
<p><strong>Model developer</strong>: Meta</p>
<p><strong>Model Architecture:</strong> Llama 3.3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety. </p>
<div>
	<table>
		<thead><tr>
<th></th>
<th>Training Data</th>
<th>Params</th>
<th>Input modalities</th>
<th>Output modalities</th>
<th>Context length</th>
<th>GQA</th>
<th>Token count</th>
<th>Knowledge cutoff</th>
</tr>

		</thead><tbody><tr>
<td>Llama 3.3 (text only)</td>
<td>A new mix of publicly available online data.</td>
<td>70B</td>
<td>Multilingual Text</td>
<td>Multilingual Text and code</td>
<td>128k</td>
<td>Yes</td>
<td>15T+</td>
<td>December 2023</td>
</tr>
</tbody>
	</table>
</div>
<p><strong>Supported languages:</strong> English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.</p>
<p><strong>Llama 3.3 model</strong>. Token counts refer to pretraining data only. All model versions use Grouped-Query Attention (GQA) for improved inference scalability.</p>
<p><strong>Model Release Date:</strong> </p>
<ul>
<li><strong>70B Instruct: December 6, 2024</strong></li>
</ul>
<p><strong>Status:</strong> This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback.</p>
<p><strong>License</strong> A custom commercial license, the Llama 3.3 Community License Agreement, is available at: <a rel="nofollow" href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE">https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE</a></p>
<p>Where to send questions or comments about the model Instructions on how to provide feedback or comments on the model can be found in the model <a rel="nofollow" href="https://github.com/meta-llama/llama3">README</a>. For more technical information about generation parameters and recipes for how to use Llama 3.3 in applications, please go <a rel="nofollow" href="https://github.com/meta-llama/llama-recipes">here</a>. </p>
<h2>
	<a rel="nofollow" href="#intended-use" id="intended-use">
		
	</a>
	<span>
		Intended Use
	</span>
</h2>
<p><strong>Intended Use Cases</strong> Llama 3.3 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.3 model also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. The Llama 3.3 Community License allows for these use cases. </p>
<p><strong>Out-of-scope</strong> Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 3.3 Community License. Use in languages beyond those explicitly referenced as supported in this model card**.</p>
<p>**Note: Llama 3.3 has been trained on a broader collection of languages than the 8 supported languages. Developers may fine-tune Llama 3.3 models for languages beyond the 8 supported languages provided they comply with the Llama 3.3 Community License and the Acceptable Use Policy and in such cases are responsible for ensuring that any uses of Llama 3.3 in additional languages is done in a safe and responsible manner.</p>
<h2>
	<a rel="nofollow" href="#how-to-use" id="how-to-use">
		
	</a>
	<span>
		How to use
	</span>
</h2>
<p>This repository contains two versions of Llama-3.3-70B-Instruct, for use with transformers and with the original <code>llama</code> codebase.</p>
<h3>
	<a rel="nofollow" href="#use-with-transformers" id="use-with-transformers">
		
	</a>
	<span>
		Use with transformers
	</span>
</h3>
<p>Starting with <code>transformers &gt;= 4.43.0</code> onward, you can run conversational inference using the Transformers <code>pipeline</code> abstraction or by leveraging the Auto classes with the <code>generate()</code> function.</p>
<p>Make sure to update your transformers installation via <code>pip install --upgrade transformers</code>.</p>
<p>See the snippet below for usage with Transformers:</p>
<pre><code><span>import</span> transformers
<span>import</span> torch

model_id = <span>"meta-llama/Llama-3.3-70B-Instruct"</span>

pipeline = transformers.pipeline(
    <span>"text-generation"</span>,
    model=model_id,
    model_kwargs={<span>"torch_dtype"</span>: torch.bfloat16},
    device_map=<span>"auto"</span>,
)

messages = [
    {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a pirate chatbot who always responds in pirate speak!"</span>},
    {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"Who are you?"</span>},
]

outputs = pipeline(
    messages,
    max_new_tokens=<span>256</span>,
)
<span>print</span>(outputs[<span>0</span>][<span>"generated_text"</span>][-<span>1</span>])
</code></pre>
<h3>
	<a rel="nofollow" href="#tool-use-with-transformers" id="tool-use-with-transformers">
		
	</a>
	<span>
		Tool use with transformers
	</span>
</h3>
<p>LLaMA-3.3 supports multiple tool use formats. You can see a full guide to prompt formatting <a rel="nofollow" href="https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/">here</a>.</p>
<p>Tool use is also supported through <a rel="nofollow" href="https://huggingface.co/docs/transformers/main/chat_templating#advanced-tool-use--function-calling">chat templates</a> in Transformers. 
Here is a quick example showing a single simple tool:</p>
<pre><code><span># First, define a tool</span>
<span>def</span> <span>get_current_temperature</span>(<span>location: <span>str</span></span>) -&gt; <span>float</span>:
    <span>"""</span>
<span>    Get the current temperature at a location.</span>
<span>    </span>
<span>    Args:</span>
<span>        location: The location to get the temperature for, in the format "City, Country"</span>
<span>    Returns:</span>
<span>        The current temperature at the specified location in the specified units, as a float.</span>
<span>    """</span>
    <span>return</span> <span>22.</span>  <span># A real function should probably actually get the temperature!</span>

<span># Next, create a chat and apply the chat template</span>
messages = [
  {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a bot that responds to weather queries."</span>},
  {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"Hey, what's the temperature in Paris right now?"</span>}
]

inputs = tokenizer.apply_chat_template(messages, tools=[get_current_temperature], add_generation_prompt=<span>True</span>)
</code></pre>
<p>You can then generate text from this input as normal. If the model generates a tool call, you should add it to the chat like so:</p>
<pre><code>tool_call = {<span>"name"</span>: <span>"get_current_temperature"</span>, <span>"arguments"</span>: {<span>"location"</span>: <span>"Paris, France"</span>}}
messages.append({<span>"role"</span>: <span>"assistant"</span>, <span>"tool_calls"</span>: [{<span>"type"</span>: <span>"function"</span>, <span>"function"</span>: tool_call}]})
</code></pre>
<p>and then call the tool and append the result, with the <code>tool</code> role, like so:</p>
<pre><code>messages.append({<span>"role"</span>: <span>"tool"</span>, <span>"name"</span>: <span>"get_current_temperature"</span>, <span>"content"</span>: <span>"22.0"</span>})
</code></pre>
<p>After that, you can <code>generate()</code> again to let the model use the tool result in the chat. Note that this was a very brief introduction to tool calling - for more information,
see the <a rel="nofollow" href="https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/">LLaMA prompt format docs</a> and the Transformers <a rel="nofollow" href="https://huggingface.co/docs/transformers/main/chat_templating#advanced-tool-use--function-calling">tool use documentation</a>.</p>
<h3>
	<a rel="nofollow" href="#use-with-bitsandbytes" id="use-with-bitsandbytes">
		
	</a>
	<span>
		Use with <code>bitsandbytes</code>
	</span>
</h3>
<p>The model checkpoints can be used in <code>8-bit</code> and <code>4-bit</code> for further memory optimisations using <code>bitsandbytes</code> and <code>transformers</code></p>
<p>See the snippet below for usage:</p>
<pre><code><span>import</span> torch
<span>from</span> transformers <span>import</span> AutoModelForCausalLM, AutoTokenizer

model_id = <span>"meta-llama/Llama-3.3-70B-Instruct"</span>
quantization_config = BitsAndBytesConfig(load_in_8bit=<span>True</span>)

quantized_model = AutoModelForCausalLM.from_pretrained(
    model_id, device_map=<span>"auto"</span>, torch_dtype=torch.bfloat16, quantization_config=quantization_config)

tokenizer = AutoTokenizer.from_pretrained(model_id)
input_text = <span>"What are we having for dinner?"</span>
input_ids = tokenizer(input_text, return_tensors=<span>"pt"</span>).to(<span>"cuda"</span>)

output = quantized_model.generate(**input_ids, max_new_tokens=<span>10</span>)

<span>print</span>(tokenizer.decode(output[<span>0</span>], skip_special_tokens=<span>True</span>))
</code></pre>
<p>To load in 4-bit simply pass <code>load_in_4bit=True</code></p>
<h3>
	<a rel="nofollow" href="#use-with-llama" id="use-with-llama">
		
	</a>
	<span>
		Use with <code>llama</code>
	</span>
</h3>
<p>Please, follow the instructions in the <a rel="nofollow" href="https://github.com/meta-llama/llama">repository</a>.</p>
<p>To download Original checkpoints, see the example command below leveraging <code>huggingface-cli</code>:</p>
<pre><code>huggingface-cli download meta-llama/Llama-3.3-70B-Instruct --include "original/*" --local-dir Llama-3.3-70B-Instruct
</code></pre>
<h2>
	<a rel="nofollow" href="#hardware-and-software" id="hardware-and-software">
		
	</a>
	<span>
		Hardware and Software
	</span>
</h2>
<p><strong>Training Factors</strong> We used custom training libraries, Meta's custom built GPU cluster, and production infrastructure for pretraining. Fine-tuning, annotation, and evaluation were also performed on production infrastructure.</p>
<p><strong>Training Energy Use</strong> Training utilized a cumulative of <strong>39.3</strong>M GPU hours of computation on H100-80GB (TDP of 700W) type hardware, per the table below. Training time is the total GPU time required for training each model and power consumption is the peak power capacity per GPU device used, adjusted for power usage efficiency. </p>
<h2>
	<a rel="nofollow" href="#" id="">
		
	</a>
	<span>
		
	</span>
</h2>
<h2>
	<a rel="nofollow" href="#training-greenhouse-gas-emissions-estimated-total-location-based-greenhouse-gas-emissions-were-11390-tons-co2eq-for-training-since-2020-meta-has-maintained-net-zero-greenhouse-gas-emissions-in-its-global-operations-and-matched-100-of-its-electricity-use-with-renewable-energy-therefore-the-total-market-based-greenhouse-gas-emissions-for-training-were-0-tons-co2eq" id="training-greenhouse-gas-emissions-estimated-total-location-based-greenhouse-gas-emissions-were-11390-tons-co2eq-for-training-since-2020-meta-has-maintained-net-zero-greenhouse-gas-emissions-in-its-global-operations-and-matched-100-of-its-electricity-use-with-renewable-energy-therefore-the-total-market-based-greenhouse-gas-emissions-for-training-were-0-tons-co2eq">
		
	</a>
	<span>
		<strong>Training Greenhouse Gas Emissions</strong> Estimated total location-based greenhouse gas emissions were <strong>11,390</strong> tons CO2eq for training. Since 2020, Meta has maintained net zero greenhouse gas emissions in its global operations and matched 100% of its electricity use with renewable energy, therefore the total market-based greenhouse gas emissions for training were 0 tons CO2eq.
	</span>
</h2>
<div>
	<table>
		<thead><tr>
<th></th>
<th>Training Time (GPU hours)</th>
<th>Training Power Consumption (W)</th>
<th>Training Location-Based Greenhouse Gas Emissions (tons CO2eq)</th>
<th>Training Market-Based Greenhouse Gas Emissions (tons CO2eq)</th>
</tr>

		</thead><tbody><tr>
<td>Llama 3.3 70B</td>
<td>7.0M</td>
<td>700</td>
<td>2,040</td>
<td>0</td>
</tr>
</tbody>
	</table>
</div>
<h2>
	<a rel="nofollow" href="#the-methodology-used-to-determine-training-energy-use-and-greenhouse-gas-emissions-can-be-found-here--since-meta-is-openly-releasing-these-models-the-training-energy-use-and-greenhouse-gas-emissions--will-not-be-incurred-by-others" id="the-methodology-used-to-determine-training-energy-use-and-greenhouse-gas-emissions-can-be-found-here--since-meta-is-openly-releasing-these-models-the-training-energy-use-and-greenhouse-gas-emissions--will-not-be-incurred-by-others">
		
	</a>
	<span>
		The methodology used to determine training energy use and greenhouse gas emissions can be found <a rel="nofollow" href="https://arxiv.org/pdf/2204.05149">here</a>.  Since Meta is openly releasing these models, the training energy use and greenhouse gas emissions  will not be incurred by others.
	</span>
</h2>
<h2>
	<a rel="nofollow" href="#training-data" id="training-data">
		
	</a>
	<span>
		Training Data
	</span>
</h2>
<p><strong>Overview:</strong> Llama 3.3 was pretrained on ~15 trillion tokens of data from publicly available sources. The fine-tuning data includes publicly available instruction datasets, as well as over 25M synthetically generated examples. </p>
<p><strong>Data Freshness:</strong> The pretraining data has a cutoff of December 2023.</p>
<h2>
	<a rel="nofollow" href="#benchmarks---english-text" id="benchmarks---english-text">
		
	</a>
	<span>
		Benchmarks - English Text
	</span>
</h2>
<p>In this section, we report the results for Llama 3.3 relative to our previous models. </p>
<h3>
	<a rel="nofollow" href="#instruction-tuned-models" id="instruction-tuned-models">
		
	</a>
	<span>
		Instruction tuned models
	</span>
</h3>
<h2>
	<a rel="nofollow" href="#-1" id="-1">
		
	</a>
	<span>
		
	</span>
</h2>
<div>
	<table>
		<thead><tr>
<th>Category</th>
<th>Benchmark</th>
<th># Shots</th>
<th>Metric</th>
<th>Llama 3.1 8B Instruct</th>
<th>Llama 3.1 70B Instruct</th>
<th>Llama-3.3 70B Instruct</th>
<th>Llama 3.1 405B Instruct</th>
</tr>

		</thead><tbody><tr>
<td></td>
<td>MMLU (CoT)</td>
<td>0</td>
<td>macro_avg/acc</td>
<td>73.0</td>
<td>86.0</td>
<td>86.0</td>
<td>88.6</td>
</tr>
<tr>
<td></td>
<td>MMLU Pro (CoT)</td>
<td>5</td>
<td>macro_avg/acc</td>
<td>48.3</td>
<td>66.4</td>
<td>68.9</td>
<td>73.3</td>
</tr>
<tr>
<td>Steerability</td>
<td>IFEval</td>
<td></td>
<td></td>
<td>80.4</td>
<td>87.5</td>
<td>92.1</td>
<td>88.6</td>
</tr>
<tr>
<td>Reasoning</td>
<td>GPQA Diamond (CoT)</td>
<td>0</td>
<td>acc</td>
<td>31.8</td>
<td>48.0</td>
<td>50.5</td>
<td>49.0</td>
</tr>
<tr>
<td>Code</td>
<td>HumanEval</td>
<td>0</td>
<td>pass@1</td>
<td>72.6</td>
<td>80.5</td>
<td>88.4</td>
<td>89.0</td>
</tr>
<tr>
<td></td>
<td>MBPP EvalPlus (base)</td>
<td>0</td>
<td>pass@1</td>
<td>72.8</td>
<td>86.0</td>
<td>87.6</td>
<td>88.6</td>
</tr>
<tr>
<td>Math</td>
<td>MATH (CoT)</td>
<td>0</td>
<td>sympy_intersection_score</td>
<td>51.9</td>
<td>68.0</td>
<td>77.0</td>
<td>73.8</td>
</tr>
<tr>
<td>Tool Use</td>
<td>BFCL v2</td>
<td>0</td>
<td>overall_ast_summary/macro_avg/valid</td>
<td>65.4</td>
<td>77.5</td>
<td>77.3</td>
<td>81.1</td>
</tr>
<tr>
<td>Multilingual</td>
<td>MGSM</td>
<td>0</td>
<td>em</td>
<td>68.9</td>
<td>86.9</td>
<td>91.1</td>
<td>91.6</td>
</tr>
</tbody>
	</table>
</div>
<h2>
	<a rel="nofollow" href="#-2" id="-2">
		
	</a>
	<span>
		
	</span>
</h2>
<h2>
	<a rel="nofollow" href="#responsibility--safety" id="responsibility--safety">
		
	</a>
	<span>
		Responsibility &amp; Safety
	</span>
</h2>
<p>As part of our Responsible release approach, we followed a three-pronged strategy to managing trust &amp; safety risks:</p>
<ul>
<li>Enable developers to deploy helpful, safe and flexible experiences for their target audience and for the use cases supported by Llama.   </li>
<li>Protect developers against adversarial users aiming to exploit Llama capabilities to potentially cause harm.  </li>
<li>Provide protections for the community to help prevent the misuse of our models.</li>
</ul>
<h3>
	<a rel="nofollow" href="#responsible-deployment" id="responsible-deployment">
		
	</a>
	<span>
		Responsible deployment
	</span>
</h3>
<p>Llama is a foundational technology designed to be used in a variety of use cases, examples on how Meta’s Llama models have been responsibly deployed can be found in our <a rel="nofollow" href="https://llama.meta.com/community-stories/">Community Stories webpage</a>. Our approach is to build the most helpful models enabling the world to benefit from the technology power, by aligning our model safety for the generic use cases addressing a standard set of harms. Developers are then in the driver seat to tailor safety for their use case, defining their own policy and deploying the models with the necessary safeguards in their Llama systems. Llama 3.3 was developed following the best practices outlined in our Responsible Use Guide, you can refer to the <a rel="nofollow" href="https://llama.meta.com/responsible-use-guide/">Responsible Use Guide</a> to learn more. </p>
<h4>
	<a rel="nofollow" href="#llama-33-instruct" id="llama-33-instruct">
		
	</a>
	<span>
		Llama 3.3 instruct
	</span>
</h4>
<p>Our main objectives for conducting safety fine-tuning are to provide the research community with a valuable resource for studying the robustness of safety fine-tuning, as well as to offer developers a readily available, safe, and powerful model for various applications to reduce the developer workload to deploy safe AI systems. For more details on the safety mitigations implemented please read the Llama 3 paper. </p>
<p><strong>Fine-tuning data</strong><br>We employ a multi-faceted approach to data collection, combining human-generated data from our vendors with synthetic data to mitigate potential safety risks. We’ve developed many large language model (LLM)-based classifiers that enable us to thoughtfully select high-quality prompts and responses, enhancing data quality control. </p>
<p><strong>Refusals and Tone</strong><br>Building on the work we started with Llama 3, we put a great emphasis on model refusals to benign prompts as well as refusal tone. We included both borderline and adversarial prompts in our safety data strategy, and modified our safety data responses to follow  tone guidelines. </p>
<h4>
	<a rel="nofollow" href="#llama-33-systems" id="llama-33-systems">
		
	</a>
	<span>
		Llama 3.3 systems
	</span>
</h4>
<p><strong>Large language models, including Llama 3.3, are not designed to be deployed in isolation but instead should be deployed as part of an overall AI system with additional safety guardrails as required.</strong> Developers are expected to deploy system safeguards when building agentic systems. Safeguards are key to achieve the right helpfulness-safety alignment as well as mitigating safety and security risks inherent to the system and any integration of the model or system with external tools.<br>As part of our responsible release approach, we provide the community with <a rel="nofollow" href="https://llama.meta.com/trust-and-safety/">safeguards</a> that developers should deploy with Llama models or other LLMs, including Llama Guard 3, Prompt Guard and Code Shield. All our <a rel="nofollow" href="https://github.com/meta-llama/llama-agentic-system">reference implementations</a> demos contain these safeguards by default so developers can benefit from system-level safety out-of-the-box. </p>
<h4>
	<a rel="nofollow" href="#new-capabilities" id="new-capabilities">
		
	</a>
	<span>
		New capabilities
	</span>
</h4>
<p>Note that this release introduces new capabilities, including a longer context window, multilingual inputs and outputs and possible integrations by developers with third party tools. Building with these new capabilities requires specific considerations in addition to the best practices that generally apply across all Generative AI use cases.</p>
<p><strong>Tool-use</strong>: Just like in standard software development, developers are responsible for the integration of the LLM with the tools and services of their choice. They should define a clear policy for their use case and assess the integrity of the third party services they use to be aware of the safety and security limitations when using this capability. Refer to the Responsible Use Guide for best practices on the safe deployment of the third party safeguards. </p>
<p><strong>Multilinguality</strong>: Llama 3.3 supports 7 languages in addition to English: French, German, Hindi, Italian, Portuguese, Spanish, and Thai. Llama may be able to output text in other languages than those that meet performance thresholds for safety and helpfulness. We strongly discourage developers from using this model to converse in non-supported languages without implementing finetuning and system controls in alignment with their policies and the best practices shared in the Responsible Use Guide. </p>
<h3>
	<a rel="nofollow" href="#evaluations" id="evaluations">
		
	</a>
	<span>
		Evaluations
	</span>
</h3>
<p>We evaluated Llama models for common use cases as well as specific capabilities. Common use cases evaluations measure safety risks of systems for most commonly built applications including chat bot, coding assistant, tool calls. We built dedicated, adversarial evaluation datasets and evaluated systems composed of Llama models and Llama Guard 3 to filter input prompt and output response. It is important to evaluate applications in context, and we recommend building dedicated evaluation dataset for your use case. Prompt Guard and Code Shield are also available if relevant to the application.<br>Capability evaluations measure vulnerabilities of Llama models inherent to specific capabilities, for which were crafted dedicated benchmarks including long context, multilingual, tools calls, coding or memorization.</p>
<p><strong>Red teaming</strong><br>For both scenarios, we conducted recurring red teaming exercises with the goal of discovering risks via adversarial prompting and we used the learnings to improve our benchmarks and safety tuning datasets.<br>We partnered early with subject-matter experts in critical risk areas to understand the nature of these real-world harms and how such models may lead to unintended harm for society. Based on these conversations, we derived a set of adversarial goals for the red team to attempt to achieve, such as extracting harmful information or reprogramming the model to act in a potentially harmful capacity.  The red team consisted of experts in cybersecurity, adversarial machine learning, responsible AI, and integrity in addition to multilingual content specialists with background in integrity issues in specific geographic markets. . </p>
<h3>
	<a rel="nofollow" href="#critical-and-other-risks" id="critical-and-other-risks">
		
	</a>
	<span>
		Critical and other risks
	</span>
</h3>
<h3>
	<a rel="nofollow" href="#we-specifically-focused-our-efforts-on-mitigating-the-following-critical-risk-areas" id="we-specifically-focused-our-efforts-on-mitigating-the-following-critical-risk-areas">
		
	</a>
	<span>
		We specifically focused our efforts on mitigating the following critical risk areas:
	</span>
</h3>
<p><strong>1- CBRNE (Chemical, Biological, Radiological, Nuclear, and Explosive materials) helpfulness</strong><br>To assess risks related to proliferation of chemical and biological weapons, we performed uplift testing designed to assess whether use of the Llama 3.3 model could meaningfully increase the capabilities of malicious actors to plan or carry out attacks using these types of weapons. </p>
<h3>
	<a rel="nofollow" href="#2-child-safety" id="2-child-safety">
		
	</a>
	<span>
		<strong>2. Child Safety</strong>
	</span>
</h3>
<p>Child Safety risk assessments were conducted using a team of experts, to assess the model’s capability to produce outputs that could result in Child Safety risks and inform on any necessary and appropriate risk mitigations via fine tuning. We leveraged those expert red teaming sessions to expand the coverage of our evaluation benchmarks through Llama 3 model development.  For Llama 3, we conducted new in-depth sessions using objective based methodologies to assess the model risks along multiple attack vectors including the additional languages Llama 3 is trained on. We also partnered with content specialists to perform red teaming exercises assessing potentially violating content while taking account of market specific nuances or experiences. </p>
<p><strong>3. Cyber attack enablement</strong><br>Our cyber attack uplift study investigated whether LLMs can enhance human capabilities in hacking tasks, both in terms of skill level and speed.<br>Our attack automation study focused on evaluating the capabilities of LLMs when used as autonomous agents in cyber offensive operations, specifically in the context of ransomware attacks. This evaluation was distinct from previous studies that considered LLMs as interactive assistants. The primary objective was to assess whether these models could effectively function as independent agents in executing complex cyber-attacks without human intervention.</p>
<h3>
	<a rel="nofollow" href="#community" id="community">
		
	</a>
	<span>
		Community
	</span>
</h3>
<p>Generative AI safety requires expertise and tooling, and we believe in the strength of the open community to accelerate its progress. We are active members of open consortiums, including the AI Alliance, Partnership on AI and MLCommons, actively contributing to safety standardization and transparency. We encourage the community to adopt taxonomies like the MLCommons Proof of Concept evaluation to facilitate collaboration and transparency on safety and content evaluations. Our Purple Llama tools are open sourced for the community to use and widely distributed across ecosystem partners including cloud service providers. We encourage community contributions to our <a rel="nofollow" href="https://github.com/meta-llama/PurpleLlama">Github repository</a>. </p>
<p>We also set up the <a rel="nofollow" href="https://llama.meta.com/llama-impact-grants/">Llama Impact Grants</a> program to identify and support the most compelling applications of Meta’s Llama model for societal benefit across three categories: education, climate and open innovation. The 20 finalists from the hundreds of applications can be found <a rel="nofollow" href="https://llama.meta.com/llama-impact-grants/#finalists">here</a>. </p>
<p>Finally, we put in place a set of resources including an <a rel="nofollow" href="https://developers.facebook.com/llama_output_feedback">output reporting mechanism</a> and <a rel="nofollow" href="https://www.facebook.com/whitehat">bug bounty program</a> to continuously improve the Llama technology with the help of the community.</p>
<h2>
	<a rel="nofollow" href="#ethical-considerations-and-limitations" id="ethical-considerations-and-limitations">
		
	</a>
	<span>
		Ethical Considerations and Limitations
	</span>
</h2>
<p>The core values of Llama 3.3 are openness, inclusivity and helpfulness. It is meant to serve everyone, and to work for a wide range of use cases. It is thus designed to be accessible to people across many different backgrounds, experiences and perspectives. Llama 3.3 addresses users and their needs as they are, without insertion unnecessary judgment or normativity, while reflecting the understanding that even content that may appear problematic in some cases can serve valuable purposes in others. It respects the dignity and autonomy of all users, especially in terms of the values of free thought and expression that power innovation and progress. </p>
<p>But Llama 3.3 is a new technology, and like any new technology, there are risks associated with its use. Testing conducted to date has not covered, nor could it cover, all scenarios. For these reasons, as with all LLMs, Llama 3.3’s potential outputs cannot be predicted in advance, and the model may in some instances produce inaccurate, biased or other objectionable responses to user prompts. Therefore, before deploying any applications of Llama 3.3 model, developers should perform safety testing and tuning tailored to their specific applications of the model. Please refer to available resources including our <a rel="nofollow" href="https://llama.meta.com/responsible-use-guide">Responsible Use Guide</a>, <a rel="nofollow" href="https://llama.meta.com/trust-and-safety/">Trust and Safety</a> solutions, and other <a rel="nofollow" href="https://llama.meta.com/docs/get-started/">resources</a> to learn more about responsible development.</p>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TikTok divestment law upheld by federal appeals court (249 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/06/tiktok-divestment-law-upheld-by-federal-appeals-court.html</link>
            <guid>42340959</guid>
            <pubDate>Fri, 06 Dec 2024 16:00:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/06/tiktok-divestment-law-upheld-by-federal-appeals-court.html">https://www.cnbc.com/2024/12/06/tiktok-divestment-law-upheld-by-federal-appeals-court.html</a>, See on <a href="https://news.ycombinator.com/item?id=42340959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="Placeholder-ArticleBody-Video-108072564" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000360202" aria-labelledby="Placeholder-ArticleBody-Video-108072564"><p><img src="https://image.cnbcfm.com/api/v1/image/108072565-17334993751733499371-37435908482-1080pnbcnews.jpg?v=1733499373&amp;w=750&amp;h=422&amp;vtcrop=y" alt="TikTok faces U.S. ban after appeals court refuses to block law"><span></span><span></span></p></div><div><p>A federal <a href="https://media.cadc.uscourts.gov/opinions/docs/2024/12/24-1113-2088317.pdf" target="_blank">appeals court</a> on Friday cited national security concerns as it upheld a law requiring China-based <a href="https://www.bytedance.com/en/" target="_blank">ByteDance</a> to sell the popular social media app <a href="https://www.cnbc.com/2024/11/13/trump-victory-may-provide-tiktok-a-lifeline-to-remain-in-the-us.html">TikTok</a> next month or face an effective ban in the United States.</p><p>The unanimous ruling by a three-judge panel of the U.S. Court of Appeals in Washington, D.C., rejected<strong> </strong>TikTok's argument that the law is unconstitutional and violates the First Amendment rights of the 170 million Americans who use the <a href="https://www.cnbc.com/2024/11/14/amazon-questioned-by-house-committee-over-dangerous-tiktok-deal.html">app</a>.</p><p>TikTok said later Friday that it will ask the U.S. Supreme Court to overturn the appeals court decision.</p><p>If ByteDance fails to sell TikTok by Jan. 19, the law would require app store companies, such as <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-5"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-6"><a href="https://www.cnbc.com/quotes/GOOGL/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, and internet hosting providers to stop supporting TikTok, which would effectively ban the app.</p><p>President <a href="https://www.cnbc.com/joe-biden/">Joe Biden</a> signed the law in April after members of Congress from both parties raised concerns about TikTok's alleged connections to the Communist Chinese government. Rep. Troy Balderson, R-Ohio, in March,&nbsp;<a href="https://twitter.com/RepBalderson/status/1765841318750654476" target="_blank">called</a>&nbsp;TikTok "a surveillance tool used by the Chinese Communist Party to spy on Americans and harvest highly personal data."</p><p>President-elect <a href="https://www.cnbc.com/donald-trump/">Donald Trump</a> has not said whether he will enforce the ban when he takes office next month.</p><p>The appeals court in its majority opinion Friday found that the U.S. government had "offered persuasive evidence demonstrating that" the divestment law "is narrowly tailored to protect national security."</p><p>The opinion noted that TikTok "never squarely denies that it has ever manipulated content at the direction of the" People's Republic of China.</p><p>"On the merits, we reject each of the petitioners' constitutional claims," wrote Judge Douglas Ginsburg in the opinion.</p><p>"As we shall explain, the parts of the Act that are properly before this court do not contravene the First Amendment to the Constitution of the United States, nor do they violate the Fifth Amendment guarantee of equal protection of the laws; constitute an unlawful bill of attainder ... or work an uncompensated taking of private property in violation of the Fifth Amendment," the opinion said.</p><p>Ginsburg noted that the law was the result of "extensive, bipartisan action by the Congress and by successive presidents."</p><p>"It was carefully crafted to deal only with control by a foreign adversary, and it was part of a broader effort to counter a well substantiated national security threat posed by the PRC," the judge wrote.&nbsp;</p><p>In a statement on the ruling posted on X, TikTok said, "The Supreme Court has an established historical record of protecting Americans' right to free speech, and we expect they will do just that on this important constitutional issue."</p><p>"Unfortunately, the TikTok ban was conceived and pushed through based upon inaccurate, flawed and hypothetical information, resulting in outright censorship of the American people," the company said. "The TikTok ban, unless stopped, will silence the voices of over 170 million Americans here in the US and around the world on January 19th, 2025."</p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC politics coverage</h2><div><ul><li><a href="https://www.cnbc.com/2024/12/05/irs-crackdown-on-wealthy-americans-faces-roadblocks-.html">Wealthy Americans are still ducking the IRS crackdown on non-filers</a></li><li><a href="https://www.cnbc.com/2024/12/05/ceo-protection-unitedhealthcare-new-york-shooting.html">Executives seek more protection after killing of UnitedHealthcare CEO Thompson, says risk management firm Kroll</a></li><li><a href="https://www.cnbc.com/2024/12/05/mckinsey-bribery-settlement-south-africa.html">McKinsey unit will pay $123 million to settle claims it bribed South African officials</a></li><li><a href="https://www.cnbc.com/2024/12/05/unitedhealthcare-ceo-shooting-nypd-photos-show-face-of-person-sought.html">UnitedHealthcare CEO slaying suspect may have taken bus from Atlanta to New York</a></li><li><a href="https://www.cnbc.com/2024/12/05/deny-defend-depose-unitedhealthcare-ceo-shooting-shell-casing-thompson.html">'Deny,' 'defend,' 'depose': UnitedHealthcare CEO killing shell casings had words written on them</a></li></ul></div></div><div><p>Patrick Toomey, deputy director of the American Civil Liberties Union's National Security Project, condemned Friday's ruling, saying it "sets a flawed and dangerous precedent, one that gives the government far too much power to silence Americans' speech online."</p><p>"Banning TikTok blatantly violates the First Amendment rights of millions of Americans who use this app to express themselves and communicate with people around the world,"&nbsp;Toomey said<strong>.&nbsp;</strong>"The government cannot shut down an entire communications platform unless it poses extremely serious and imminent harm, and there's no evidence of that here."</p><p>Although TikTok said it will ask the U.S. Supreme Court to hear the case there is no automatic right of appeal to that court.</p><p>A source close to the company, who was not authorized to speak publicly, told NBC News that it will seek an injunction pending a planned petition to have the Supreme Court take the case.</p><p>In a September&nbsp;<a href="https://truthsocial.com/@realDonaldTrump/posts/113081258242253706" target="_blank">post</a>&nbsp;on his own social media app, Truth Social, Trump wrote that he was not "doing anything with TikTok, but the other side is going to close it up."</p><p>"So if you like TikTok, go out and vote for Trump," the now-president-elect wrote at the time.</p><p>Trump transition spokeswoman Karoline Leavitt told CNBC in November that the president-elect "will deliver" on his campaign promises.</p><p>CNBC has requested comment from Trump's transition team on Friday's ruling and his plans for TikTok.<br>Trump's position on TikTok may be influenced by other factors. </p><p>The president-elect tried to ban the app during his first administration.</p><p>But his rhetoric on TikTok began to turn after he&nbsp;<a href="https://www.businessinsider.com/trump-tiktok-comments-meeting-with-billionaire-investor-jeff-yass-2024-3" target="_blank">met in February</a>&nbsp;with billionaire Jeff Yass, a Republican megadonor and a major investor in Bytedance.</p><p>Yass's trading firm Susquehanna International Group owns a 15% stake in ByteDance while Yass maintains a 7% stake in the company, equating to about $21 billion, NBC and CNBC&nbsp;<a href="https://www.nbcnews.com/tech/tech-news/jeff-yass-billionaire-donor-investments-tiktoks-parent-company-rcna142531" target="_blank">reported</a>&nbsp;in March. That month it was also&nbsp;<a href="https://www.msnbc.com/the-reidout/reidout-blog/trump-truth-social-tik-tok-jeff-yass-rcna144951" target="_blank">reported</a>&nbsp;that Yass was a part owner of the business that merged with the parent company of Trump's Truth Social.<br></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ExxonMobil's Alleged Hack-for-Hire Campaign Targeting Climate Activists (254 pts)]]></title>
            <link>https://www.vulnu.com/p/inside-exxonmobils-alleged-hack-for-hire-campaign-targeting-climate-activists</link>
            <guid>42340346</guid>
            <pubDate>Fri, 06 Dec 2024 14:54:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vulnu.com/p/inside-exxonmobils-alleged-hack-for-hire-campaign-targeting-climate-activists">https://www.vulnu.com/p/inside-exxonmobils-alleged-hack-for-hire-campaign-targeting-climate-activists</a>, See on <a href="https://news.ycombinator.com/item?id=42340346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-blocks"><p><b>Why it matters</b>: A hack-for-hire operation linked to <b>ExxonMobil</b> targeted over 500 climate activists and journalists, showing us how corporations can now deploy nation-state-level cyber capabilities against their critics. This case shines a light on the industrialization of digital warfare in corporate disputes, with massive implications for advocacy and journalism. </p><p><b>The big picture</b>: The operation combined mercenary hackers, professional PR firms, and legal teams to weaponize stolen information in courts and media. Code-named <b>“Fox Hunt,”</b> this effort goes deep into the cybercriminals playbook, complete with phishing campaigns and layers of plausible deniability built into the architecture. </p><p id="by-the-numbers"><h3>By the numbers:</h3></p><div><ul><li><p><b>500+</b> environmental activists and family members targeted </p></li><li><p><b>28,000+</b> malicious URLs deployed </p></li><li><p><b>100+</b> phishing attempts sent to high-value targets </p></li><li><p><b>$10+ million/year</b> in revenue from Exxon to DCI Group, the PR firm allegedly involved </p></li></ul></div><p id="how-it-worked"><h3>How it worked:</h3></p><div><ul><li><p><b>Target List Creation</b>:<br>The DCI Group, Exxon’s public relations and lobbying firm at the time, allegedly compiled a list of targets, including activists and attorneys involved in climate litigation. </p></li><li><p><b>Outsourced Hacking</b>:<br>The list was handed to Israeli private detective <b>Amit Forlit</b>, who outsourced the hacking to India-based <b>BellTroX InfoTech Services</b>, a notorious hack-for-hire firm. </p></li><li><p><b>Phishing Campaigns</b>:<br><b>BellTroX</b> sent sophisticated phishing emails designed to mimic colleagues and friends, successfully breaching email accounts. </p></li><li><p><b>Weaponization of Stolen Data</b>:<br>Hacked emails were leaked to media outlets and used in court filings to discredit environmental advocates and bolster Exxon’s legal defenses. </p></li></ul></div><div><p><img alt="" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8297d7ba-749c-4d03-bb94-b247cf5787af/exxon-knew-phishing.jpg?t=1732741786"></p></div><p id="timeline-of-key-events"><h3>Timeline of Key Events</h3></p><div><ul><li><p><b>2015</b>: Reports surface that Exxon scientists knew fossil fuels contributed to climate change but downplayed the risks publicly. </p></li><li><p><b>November 2015</b>: New York Attorney General Eric Schneiderman announces an investigation into Exxon, sparking the #ExxonKnew campaign. </p></li><li><p><b>2016</b>: Stolen Rockefeller Family Fund memo leaks to media, used to paint climate litigation as a politically motivated vendetta. </p></li><li><p><b>2018</b>: Exxon lawyers cite hacked documents to argue against lawsuits filed by state attorneys general. </p></li><li><p><b>2022</b>: Aviram Azari, an associate of Forlit, is convicted in the U.S. for hack-for-hire schemes. </p></li></ul></div><p><b>Between the lines</b>: The operation's timing aligned perfectly with key events in climate change litigation against Exxon, suggesting coordination between hackers and legal teams. </p><p><b>What they're saying:</b></p><div><ul><li><p> Exxon denies involvement, calling allegations "conspiracy theories" </p></li><li><p> DCI Group: "We direct all our employees and consultants to comply with the law" </p></li></ul></div><p id="fallout-for-activists"><h3>Fallout for Activists</h3></p><p> The hack-and-leak operation disrupted key preparations for lawsuits modeled on historic tobacco litigation. Attorney Matt Pawa, who drove much of the anti-Exxon litigation, said the leaks turned his life upside down: </p><div><p>“Those documents were directly employed by Exxon to come after me with all guns blazing.”</p><p><small> Matt Pawa </small></p></div><p> Activists described a chilling effect, with Kert Davies of the Center for Climate Integrity noting that the leaks <b>“sent a shudder through the environmental community.”</b></p><p><b>What's next</b>: The FBI investigation continues, while advocates push for stronger legal frameworks to address hack-for-hire operations. </p><p><b>The bottom line</b>: This case exposes how corporate disputes have moved from boardrooms to cybersecurity battles, with massive potential impact on advocacy and journalism. </p><p id="longer-form-thoughts"><h3>Longer form thoughts:</h3></p><p> What we're witnessing isn't just corporate espionage – it's the industrialization of digital warfare. As <a href="https://www.reuters.com/business/energy/exxon-lobbyist-investigated-over-hack-and-leak-environmentalist-emails-sources-2024-11-27/?utm_source=www.vulnu.com&amp;utm_medium=referral&amp;utm_campaign=inside-exxonmobil-s-alleged-hack-for-hire-campaign-targeting-climate-activists" target="_blank">Reuters reports</a>, Exxon, facing existential threats from climate litigation, apparently decided to go full Metal Gear Solid on its critics. But here's the genius (and I mean that in the Machiavellian sense): they built a perfect plausible deniability machine. </p><p id="the-architecture-of-modern-corporat"><h3>The Architecture of Modern Corporate Warfare:</h3></p><div><ol start="1"><li><p> Client (allegedly Exxon) -&gt; </p></li><li><p> PR Firm (DCI Group) -&gt; </p></li><li><p> Israeli PI (Forlit) -&gt; </p></li><li><p> Indian Hackers (BellTroX) </p></li></ol></div><p> This is what we’ll call the "four-layer burrito of blame." Each layer provides insulation from legal and reputational risk. It's brilliant and terrifying. </p><p><b>The Economics Follow the money:</b></p><div><ul><li><p> $10M/year from Exxon to DCI </p></li><li><p> Unknown millions to Israeli/Indian hackers </p></li><li><p> Potential billions saved in climate litigation </p></li></ul></div><p> The ROI here is insane. For the cost of a few executive salaries, Exxon potentially derailed multiple state-level lawsuits and gained tactical advantage in ongoing litigation. </p><p id="why-it-works"><h3>Why It Works</h3></p><div><ul><li><p><b>Asymmetric Warfare</b>: Advocacy groups lack the resources to combat such sophisticated campaigns. </p></li><li><p><b>Perfect Information Arbitrage</b>: Stolen documents provide insider knowledge for strategic advantage. </p></li><li><p><b>Legal Weaponization</b>: Data obtained via hacking is used in courts under the guise of legitimate evidence. </p></li></ul></div><p> This is peak late-stage capitalism meets cyberpunk reality. We've created a world where: </p><div><ul><li><p> Corporations can deploy nation-state level cyber capabilities </p></li><li><p> Legal systems are unprepared for weaponized stolen information </p></li><li><p> Plausible deniability can be purchased as a service </p></li></ul></div><p> This isn't just about Exxon. We're seeing the emergence of a new business model: Industrialized Digital Espionage as a Service (IDEaaS?). And like all good SaaS businesses, it scales beautifully. </p><p id="whats-next"><h3>What's Next?</h3></p><div><ol start="1"><li><p> More sophisticated cutout structures </p></li><li><p> AI-powered targeting and social engineering </p></li><li><p> Blockchain-based payment systems for better opacity </p></li><li><p> Increased regulatory scrutiny (too little, too late) </p></li></ol></div><p><b>The Bottom Line</b>: The game has changed. The next great corporate advantage might not come from better products or services, but from better information warfare capabilities. And that is terrifying to me. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Install postmarketOS on Android phone and use Docker as a home server (237 pts)]]></title>
            <link>https://crackoverflow.com/docs/system_administration/containerization/install-docker-natively-on-android-phone-and-use-it-as-a-home-server/</link>
            <guid>42340065</guid>
            <pubDate>Fri, 06 Dec 2024 14:23:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crackoverflow.com/docs/system_administration/containerization/install-docker-natively-on-android-phone-and-use-it-as-a-home-server/">https://crackoverflow.com/docs/system_administration/containerization/install-docker-natively-on-android-phone-and-use-it-as-a-home-server/</a>, See on <a href="https://news.ycombinator.com/item?id=42340065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-prismjs-copy="" data-prismjs-copy-success="" data-prismjs-copy-error="" id="content" data-bs-spy="scroll" data-bs-root-margin="0px 0px -65%" data-bs-target="#toc-mobile">
        <p>In this tutorial, we will guide you through the process of installing Docker on your Android phone, specifically using a OnePlus 6T with postmarketOS. I also wrote another <a href="https://crackoverflow.com/docs/system_administration/containerization/turn_android_phone_to_batteryless_home_server/" rel="external" target="_blank">blog post<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"></path></svg></a> explaining how you can run this phone without a battery, allowing it to run forever as long as it remains connected to a power source. If you’re interested, feel free to <a href="https://crackoverflow.com/docs/system_administration/containerization/turn_android_phone_to_batteryless_home_server/" rel="external" target="_blank">check it out!<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"></path></svg></a>
<!-- raw HTML omitted -->
This guide can be adapted only for phones on&nbsp;<a href="https://postmarketos.org/download/" rel="external" target="_blank">the postmarketOS device list<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"></path></svg></a>. Please note that this process will erase all data on your phone, so it’s important to use a device you don’t need. Let’s get started!</p>
<h2 id="what-do-you-need-for-this-tutorial">What do you need for this tutorial? </h2><ul>
<li>An Android phone (OnePlus 6 or OnePlus 6T is recommended)</li>
<li>Fastboot installed on your PC (see step 2)</li>
<li>PostmarketOS boot and img files (see step 3)</li>
</ul>
<h2 id="step-1-enable-developer-mode-and-usb-debugging">Step 1: Enable Developer Mode and USB Debugging </h2><p>Enable Developer Mode and USB Debugging Start by activating Developer Mode on your Android phone.</p>
<p>Go to Settings, tap on “Build number” repeatedly until you see a message indicating that Developer Mode has been enabled. Then, go to Developer options and activate OEM unlocking and USB debugging.</p>
<figure><img src="https://crackoverflow.com/images/developer-options-980x522.jpg" alt="developer-options-980x522">
</figure>

<h2 id="step-2-install-fastboot-on-your-pc">Step 2: Install Fastboot on your PC </h2><p>Install Fastboot on your PC To proceed with the installation, you’ll need to have Fastboot installed on your PC. Visit the official Android&nbsp;<a href="https://developer.android.com/tools/releases/platform-tools" rel="external" target="_blank">SDK Platform Tools page<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"></path></svg></a>&nbsp;and download the package. Extract the files and add the platform-tools folder to your system’s environment variables (instructions vary depending on your operating system).</p>
<figure><img src="https://crackoverflow.com/images/adb-980x510.jpg" alt="adb-980x510">
</figure>

<h2 id="step-3-download-postmarketos-files">Step 3: Download PostmarketOS Files </h2><p>Download the PostmarketOS boot and img files for your specific phone model. Visit&nbsp;<a href="https://postmarketos.org/download/" rel="external" target="_blank">the postmarketOS website<svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M14 5c-.552 0-1-.448-1-1s.448-1 1-1h6c.552 0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1v-3.586l-7.293 7.293c-.391.39-1.024.39-1.414 0-.391-.391-.391-1.024 0-1.414l7.293-7.293h-3.586zm-9 2c-.552 0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552 0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1v4.563c0 1.657-1.343 3-3 3h-11c-1.657 0-3-1.343-3-3v-11c0-1.657 1.343-3 3-3h4.563c.552 0 1 .448 1 1s-.448 1-1 1h-4.563z"></path></svg></a>, locate the appropriate files (I am using phosh 22.12), and download them. Extract the files and place them in a single folder for easy access.</p>
<figure><img src="https://crackoverflow.com/images/postmarketos-download-980x393.jpg" alt="postmarketos-download-980x393">
</figure>

<h2 id="step-4-enter-fastboot-mode">Step 4: Enter Fastboot Mode </h2><p>Restart your Android phone and boot it into Fastboot mode. This can typically be done by pressing the volume up, volume down, and power buttons simultaneously on Oneplus 6t. Once your phone is in Fastboot mode, connect it to your PC using a USB cable.</p>
<figure><img src="https://crackoverflow.com/images/buttons-868x1024.jpg" alt="buttons-868x1024">
</figure>

<figure><img src="https://crackoverflow.com/images/fastboot-mode-oneplus-6t-665x102.jpg" alt="fastboot-mode-oneplus-6t-665x102">
</figure>

<h2 id="step-5-flash-postmarketos">Step 5: Flash PostmarketOS </h2><p><strong>Be aware that each device has its own specific guide for installing PostmarketOS (they are mostly similar). Make sure to carefully read and follow the instructions for your specific phone model on the postmarketOS website before flashing the system. This guide is for oneplus 6t.</strong> <!-- raw HTML omitted -->
<!-- raw HTML omitted -->
Flash PostmarketOS on Your Phone by opening a command prompt or terminal window on your PC and navigate to the folder where you saved the PostmarketOS files. Execute the following commands one by one:</p>



  
  
  

  
  
  
  

  

  



  
  
  

  
  
  
  

  

  



  
  
  

  
  
  
  

  

  <div>
  <pre id="7380c7b">  <code>fastboot flash boot boot_file_name.img</code>
  </pre>
  </div>



  
  
  

  
  
  
  

  

  <div>
  <pre id="dfa7003">  <code>fastboot flash userdata img_file_name.img</code>
  </pre>
  </div>
<p>Replace “boot_file_name” and “img_file_name” with the actual file names you saved earlier.&nbsp;<strong>Once the flashing process is complete, restart your phone.</strong></p>
<figure><img src="https://crackoverflow.com/images/files-with-cmd-980x536.jpg" alt="files-with-cmd-980x536">
</figure>

<h5 id="postmarketos-ist-installed-now-on-your-phone">PostmarketOS ist installed now on your phone! </h5><h2 id="step-6-initial-setup-and-ssh-activation">Step 6: Initial Setup and SSH Activation </h2><p>When your phone restarts, you may be prompted for a PIN.</p>
<p>Use the default PIN, which is usually “<strong>147147</strong>.” Connect your phone to a Wi-Fi network. Open the Console app on your phone and activate SSH to control the phone from your PC. Run the following commands in the Console app on your phone:</p>



  
  
  

  
  
  
  

  

  



  
  
  

  
  
  
  

  

  



  
  
  

  
  
  
  

  

  
<figure><img src="https://crackoverflow.com/images/Console-postmarketos-768x1024.jpg" alt="Console-postmarketos-768x1024">
</figure>

<h2 id="step-7-connect-to-your-phone-via-ssh-on-your-pc">Step 7: Connect to Your Phone via SSH on your PC </h2><p>On your PC, open a command prompt or terminal window and connect to your phone via SSH using the following command:</p>



  
  
  

  
  
  
  

  

  <div>
  <pre id="4293b7c">  <code>ssh user@IP_Address_of_the_phone</code>
  </pre>
  </div>
<p>The default username for SSH is “<strong>user</strong>,” but you can verify this by running the “<strong>whoami</strong>” command on the Console app of your phone. The&nbsp;<strong>IP_Address_of_the_phone</strong>&nbsp;can be found by typing “<strong>ifconfig</strong>” in the Console app and looking for the IP of&nbsp;<strong>wlan0</strong>.</p>
<h2 id="step-8-install-docker-on-your-android-phone">Step 8: Install Docker on your Android Phone </h2><p>Now that you’re connected to your phone via SSH, you can easily install Docker by running the following commands:</p>



  
  
  

  
  
  
  

  

  



  
  
  

  
  
  
  

  

  <div>
  <pre id="1bbe708">  <code>sudo service docker start</code>
  </pre>
  </div>



  
  
  

  
  
  
  

  

  <div>
  <pre id="06a9bd2">  <code>sudo rc-update add docker default</code>
  </pre>
  </div>
<p>To verify that&nbsp;<strong>Docker</strong>&nbsp;is installed correctly, run:</p>



  
  
  

  
  
  
  

  

  
<h2 id="done-run-docker-containers">DONE! Run Docker Containers </h2><p>With Docker successfully installed on your Android phone, you can now run Docker containers and use your phone as a home server. Let’s try running the Portainer container as an example:</p>
<p>Run the following command to start the Portainer container which will download the Portainer image and start the container.:</p>



  
  
  

  
  
  
  

  

  <div>
  <pre id="1a064e2">  <code>sudo docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest</code>
  </pre>
  </div>
<figure><img src="https://crackoverflow.com/images/portainer-installed-1.jpg" alt="portainer-installed-1">
</figure>

<p>Portainer provides a web-based interface for managing Docker containers and it is easy to use.</p>
<h2 id="access-portainer-interface">Access Portainer Interface </h2><p>Open your web browser on your PC and type in the IP_Address_of_the_phone, followed by “:9443”. This will take you to the Portainer interface running on your Android phone. You can now manage and monitor your Docker containers through this interface.</p>
<p>Congratulations! You have successfully installed Docker on your Android phone and set up a Docker container. You can now explore various Docker images and run them on your phone to expand its capabilities as a home server.</p>
<p>I am currently using several containers on my home server, and if you’re interested, in the picture below you will see the memory usage.</p>
<p>This method serves as an excellent alternative to Raspberry Pi. While I haven’t personally tried a Raspberry Pi before, I believe this phone is more capable, with the added advantage of an integrated screen and battery, which are not available with a Raspberry Pi.</p>
<figure><img src="https://crackoverflow.com/images/portainer-980x577.jpg" alt="portainer-980x577">
</figure>

<h2 id="downsides-of-oneplus-6t-as-a-home-server">Downsides of OnePlus 6T as a Home Server </h2><ul>
<li><strong>No Ethernet Support:</strong> The server relies entirely on Wi-Fi, which may lack the stability and speed of Ethernet.</li>
<li><strong>No External Drive Support:</strong> Storage is limited to internal memory (256GB), making it unsuitable for large-scale storage tasks. However, you can connect to an external NAS for additional storage.</li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rivian is opening its charging network to other EVs (202 pts)]]></title>
            <link>https://www.thedrive.com/news/rivian-is-opening-its-charger-network-to-other-evs</link>
            <guid>42340000</guid>
            <pubDate>Fri, 06 Dec 2024 14:16:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedrive.com/news/rivian-is-opening-its-charger-network-to-other-evs">https://www.thedrive.com/news/rivian-is-opening-its-charger-network-to-other-evs</a>, See on <a href="https://news.ycombinator.com/item?id=42340000">Hacker News</a></p>
Couldn't get https://www.thedrive.com/news/rivian-is-opening-its-charger-network-to-other-evs: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: BunkerWeb – The Open-Source Web Application Firewall (WAF) (110 pts)]]></title>
            <link>https://github.com/bunkerity/bunkerweb</link>
            <guid>42339856</guid>
            <pubDate>Fri, 06 Dec 2024 14:00:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bunkerity/bunkerweb">https://github.com/bunkerity/bunkerweb</a>, See on <a href="https://news.ycombinator.com/item?id=42339856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/misc/logo.png"><img alt="BunkerWeb logo" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/misc/logo.png" height="100" width="350"></a>
</p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6a9f4c8c3fbb41efdc96cff889f964836652cf813d5bb0ca0ca3b3d37127a857/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f62756e6b65726974792f62756e6b65727765623f6c6162656c3d737461626c65"><img src="https://camo.githubusercontent.com/6a9f4c8c3fbb41efdc96cff889f964836652cf813d5bb0ca0ca3b3d37127a857/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f62756e6b65726974792f62756e6b65727765623f6c6162656c3d737461626c65" data-canonical-src="https://img.shields.io/github/v/release/bunkerity/bunkerweb?label=stable"></a>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/981736a6db3505f5c64645275d43e508b6d46600056a9341bdf820d635bd4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f62756e6b65726974792f62756e6b65727765623f696e636c7564655f70726572656c6561736573266c6162656c3d6c6174657374"><img src="https://camo.githubusercontent.com/981736a6db3505f5c64645275d43e508b6d46600056a9341bdf820d635bd4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f62756e6b65726974792f62756e6b65727765623f696e636c7564655f70726572656c6561736573266c6162656c3d6c6174657374" data-canonical-src="https://img.shields.io/github/v/release/bunkerity/bunkerweb?include_prereleases&amp;label=latest"></a>
	<br>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9a1b5e01e0074e055997818557e9361c7575eb6defbcbce5244709a6fee4581d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f62756e6b65726974792f62756e6b6572776562"><img src="https://camo.githubusercontent.com/9a1b5e01e0074e055997818557e9361c7575eb6defbcbce5244709a6fee4581d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f62756e6b65726974792f62756e6b6572776562" data-canonical-src="https://img.shields.io/github/last-commit/bunkerity/bunkerweb"></a>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/160922e1c737cd33a778a6c8059b19c8b0644cff466e557ff48433f949b4ef6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f62756e6b65726974792f62756e6b6572776562"><img src="https://camo.githubusercontent.com/160922e1c737cd33a778a6c8059b19c8b0644cff466e557ff48433f949b4ef6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f62756e6b65726974792f62756e6b6572776562" data-canonical-src="https://img.shields.io/github/issues/bunkerity/bunkerweb"></a>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5881f32e0dc84312bdc8769ff959ca69156a097482d2483b8d4c0f8a3ba1b887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f62756e6b65726974792f62756e6b6572776562"><img src="https://camo.githubusercontent.com/5881f32e0dc84312bdc8769ff959ca69156a097482d2483b8d4c0f8a3ba1b887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f62756e6b65726974792f62756e6b6572776562" data-canonical-src="https://img.shields.io/github/issues-pr/bunkerity/bunkerweb"></a>
	<br>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3a0880a2792115b4ca92eb1f44cb5055a9b5e52fda6170cc674108147f2a66bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f62756e6b65726974792f62756e6b65727765622f6465762e796d6c3f6272616e63683d646576266c6162656c3d43492532464344253230646576"><img src="https://camo.githubusercontent.com/3a0880a2792115b4ca92eb1f44cb5055a9b5e52fda6170cc674108147f2a66bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f62756e6b65726974792f62756e6b65727765622f6465762e796d6c3f6272616e63683d646576266c6162656c3d43492532464344253230646576" data-canonical-src="https://img.shields.io/github/actions/workflow/status/bunkerity/bunkerweb/dev.yml?branch=dev&amp;label=CI%2FCD%20dev"></a>
	<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6d4f2351bd40731dd68e1545499d818c0a307b6f59ad9919aaa6a7d45f4592aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f62756e6b65726974792f62756e6b65727765622f73746167696e672e796d6c3f6272616e63683d73746167696e67266c6162656c3d4349253246434425323073746167696e67"><img src="https://camo.githubusercontent.com/6d4f2351bd40731dd68e1545499d818c0a307b6f59ad9919aaa6a7d45f4592aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f62756e6b65726974792f62756e6b65727765622f73746167696e672e796d6c3f6272616e63683d73746167696e67266c6162656c3d4349253246434425323073746167696e67" data-canonical-src="https://img.shields.io/github/actions/workflow/status/bunkerity/bunkerweb/staging.yml?branch=staging&amp;label=CI%2FCD%20staging"></a>
	<a href="https://www.bestpractices.dev/projects/8001" rel="nofollow">
		<img src="https://camo.githubusercontent.com/b36d9169e4bca826b7ca9c4949bc1a901ea98f105847d9aa2e2120dce38d588d/68747470733a2f2f7777772e626573747072616374696365732e6465762f70726f6a656374732f383030312f6261646765" data-canonical-src="https://www.bestpractices.dev/projects/8001/badge">
	</a>
</p>
<p dir="auto">
	🌐 <a href="https://www.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Website</a>
	 |
	🤝 <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Panel</a>
	 |
	📓 <a href="https://docs.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Documentation</a>
	 |
	👨‍💻 <a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Demo</a>
	 |
	🛡️ <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/examples">Examples</a>
	 |
	💬 <a href="https://discord.com/invite/fTf46FmtyD" rel="nofollow">Chat</a>
	 |
	📝 <a href="https://github.com/bunkerity/bunkerweb/discussions">Forum</a>
	<br>
	⚙️ <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Configurator</a>
	 |
	🗺️ <a href="https://threatmap.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Threatmap</a>
	 |
	🔎 <a href="https://forms.gle/e3VgymAteYPnwM1j9" rel="nofollow">Feedbacks</a>
</p>
<blockquote>
<p dir="auto">🛡️ Make security by default great again !</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">BunkerWeb</h2><a id="user-content-bunkerweb" aria-label="Permalink: BunkerWeb" href="#bunkerweb"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/intro-overview.svg"><img alt="Overview banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/intro-overview.svg"></a>
</p>
<p dir="auto">BunkerWeb is a next-generation and open-source Web Application Firewall (WAF).</p>
<p dir="auto">Being a full-featured web server (based on <a href="https://nginx.org/" rel="nofollow">NGINX</a> under the hood), it will protect your web services to make them "secure by default". BunkerWeb integrates seamlessly into your existing environments (<a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#linux" rel="nofollow">Linux</a>, <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker" rel="nofollow">Docker</a>, <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#swarm" rel="nofollow">Swarm</a>, <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes" rel="nofollow">Kubernetes</a>, …) and is fully configurable (don't panic, there is an <a href="https://docs.bunkerweb.io/1.5.12/web-ui/?utm_campaign=self&amp;utm_source=github" rel="nofollow">awesome web UI</a> if you don't like the CLI) to meet your own use-cases . In other words, cybersecurity is no more a hassle.</p>
<p dir="auto">BunkerWeb contains primary <a href="https://docs.bunkerweb.io/1.5.12/security-tuning/?utm_campaign=self&amp;utm_source=github" rel="nofollow">security features</a> as part of the core but can be easily extended with additional ones thanks to a <a href="https://docs.bunkerweb.io/1.5.12/plugins/?utm_campaign=self&amp;utm_source=github" rel="nofollow">plugin system</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why BunkerWeb ?</h2><a id="user-content-why-bunkerweb-" aria-label="Permalink: Why BunkerWeb ?" href="#why-bunkerweb-"></a></p>
<ul dir="auto">
<li><strong>Easy integration into existing environments</strong> : Seamlessly integrate BunkerWeb into various environments such as Linux, Docker, Swarm, Kubernetes and more. Enjoy a smooth transition and hassle-free implementation.</li>
<li><strong>Highly customizable</strong> : Tailor BunkerWeb to your specific requirements with ease. Enable, disable, and configure features effortlessly, allowing you to customize the security settings according to your unique use case.</li>
<li><strong>Secure by default</strong> : BunkerWeb provides out-of-the-box, hassle-free minimal security for your web services. Experience peace of mind and enhanced protection right from the start.</li>
<li><strong>Awesome web UI</strong> : Take control of BunkerWeb more efficiently with the exceptional web user interface (UI). Navigate settings and configurations effortlessly through a user-friendly graphical interface, eliminating the need for the command-line interface (CLI).</li>
<li><strong>Plugin system</strong> : Extend the capabilities of BunkerWeb to meet your own use cases. Seamlessly integrate additional security measures and customize the functionality of BunkerWeb according to your specific requirements.</li>
<li><strong>Free as in "freedom"</strong> : BunkerWeb is licensed under the free <a href="https://www.gnu.org/licenses/agpl-3.0.en.html" rel="nofollow">AGPLv3 license</a>, embracing the principles of freedom and openness. Enjoy the freedom to use, modify, and distribute the software, backed by a supportive community.</li>
<li><strong>Professional services</strong> : Get technical support, tailored consulting and custom development directly from the maintainers of BunkerWeb. Visit the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Bunker Panel</a> for more information.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security features</h2><a id="user-content-security-features" aria-label="Permalink: Security features" href="#security-features"></a></p>
<p dir="auto">A non-exhaustive list of security features :</p>
<ul dir="auto">
<li><strong>HTTPS</strong> support with transparent <strong>Let's Encrypt</strong> automation</li>
<li><strong>State-of-the-art web security</strong> : HTTP security headers, prevent leaks, TLS hardening, ...</li>
<li>Integrated <strong>ModSecurity WAF</strong> with the <strong>OWASP Core Rule Set</strong></li>
<li><strong>Automatic ban</strong> of strange behaviors based on HTTP status code</li>
<li>Apply <strong>connections and requests limit</strong> for clients</li>
<li><strong>Block bots</strong> by asking them to solve a <strong>challenge</strong> (e.g. : cookie, javascript, captcha, hCaptcha or reCAPTCHA)</li>
<li><strong>Block known bad IPs</strong> with external blacklists and DNSBL</li>
<li>And much more ...</li>
</ul>
<p dir="auto">Learn more about the core security features in the <a href="https://docs.bunkerweb.io/1.5.12/security-tuning/?utm_campaign=self&amp;utm_source=github" rel="nofollow">security tuning</a> section of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">
	<a href="https://www.youtube.com/watch?v=ZhYV-QELzA4" rel="nofollow"><img alt="BunkerWeb demo" src="https://camo.githubusercontent.com/db8972149b8aaa8f2f057f6a62b6d6d268ff3e9fc86742b620fb24882d291373/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f5a6859562d51454c7a41342f302e6a7067" data-canonical-src="https://img.youtube.com/vi/ZhYV-QELzA4/0.jpg"></a>
</p>
<p dir="auto">A demo website protected with BunkerWeb is available at <a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">demo.bunkerweb.io</a>. Feel free to visit it and perform some security tests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">BunkerWeb Cloud</h2><a id="user-content-bunkerweb-cloud" aria-label="Permalink: BunkerWeb Cloud" href="#bunkerweb-cloud"></a></p>
<p dir="auto">Don't want to self-host and manage your own BunkerWeb instance(s) ? You might be interested into BunkerWeb Cloud, our fully managed SaaS offer for BunkerWeb.</p>
<p dir="auto">Try our <a href="https://panel.bunkerweb.io/order/bunkerweb-cloud/14?utm_source=github&amp;utm_campaign=self" rel="nofollow">BunkerWeb Cloud beta offer for free</a> and get access to :</p>
<ul dir="auto">
<li>Fully managed BunkerWeb instance hosted in our cloud</li>
<li>All BunkerWeb features including PRO ones</li>
<li>Monitoring platform including dashboards and alerts</li>
<li>Technical support to assist you in the configuration</li>
</ul>
<p dir="auto">You will find more information about BunkerWeb Cloud in the <a href="https://panel.bunkerweb.io/knowledgebase/55/BunkerWeb-Cloud?utm_source=github&amp;utm_campaign=self" rel="nofollow">FAQ page</a> of the BunkerWeb panel.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">PRO version</h2><a id="user-content-pro-version" aria-label="Permalink: PRO version" href="#pro-version"></a></p>
<p dir="auto">When using BunkerWeb you have the choice of the version you want to use : open-source or PRO.</p>
<p dir="auto">Whether it's enhanced security, an enriched user experience, or technical supervision, the BunkerWeb PRO version will allow you to fully benefit from BunkerWeb and respond to your professional needs.</p>
<p dir="auto">Be it in the documentation or the user interface, the PRO features are annotated with a crown <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2026a400536acabd65b881d3cfede2e9113ead3231e2fcd6d8669b83ad685dbf/68747470733a2f2f646f63732e62756e6b65727765622e696f2f312e352e31322f6173736574732f696d672f70726f2d69636f6e2e737667"><img src="https://camo.githubusercontent.com/2026a400536acabd65b881d3cfede2e9113ead3231e2fcd6d8669b83ad685dbf/68747470733a2f2f646f63732e62756e6b65727765622e696f2f312e352e31322f6173736574732f696d672f70726f2d69636f6e2e737667" alt="crow pro icon" height="24px" width="24px" data-canonical-src="https://docs.bunkerweb.io/1.5.12/assets/img/pro-icon.svg"></a> to distinguish them from those integrated into the open-source version.</p>
<p dir="auto">You can upgrade from the open-source version to the PRO one easily and at any time you want. The process is pretty straightforward :</p>
<ul dir="auto">
<li>Claim your <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=doc" rel="nofollow">free trial on the BunkerWeb panel</a></li>
<li>Once connected to the client area, copy your PRO license key</li>
<li>Paste your private key into BunkerWeb using the <a href="https://docs.bunkerweb.io/1.5.12/web-ui/#upgrade-to-pro" rel="nofollow">web UI</a> or <a href="https://docs.bunkerweb.io/1.5.12/settings/#pro" rel="nofollow">specific setting</a></li>
</ul>
<p dir="auto">Do not hesitate to visit the <a href="https://panel.bunkerweb.io/knowledgebase?utm_campaign=self&amp;utm_source=doc" rel="nofollow">BunkerWeb panel</a> or <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=doc" rel="nofollow">contact us</a> if you have any question regarding the PRO version.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Professional services</h2><a id="user-content-professional-services" aria-label="Permalink: Professional services" href="#professional-services"></a></p>
<p dir="auto">Get the most of BunkerWeb by getting professional services directly from the maintainers of the project. From technical support to tailored consulting and development, we are here to assist you in the security of your web services.</p>
<p dir="auto">You will find more information by visiting the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=doc" rel="nofollow">BunkerWeb Panel</a>, our dedicated platform for professional services.</p>
<p dir="auto">Don't hesitate to <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=doc" rel="nofollow">contact us</a> if you have any question, we will be more than happy to respond to your needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Ecosystem, community and resources</h2><a id="user-content-ecosystem-community-and-resources" aria-label="Permalink: Ecosystem, community and resources" href="#ecosystem-community-and-resources"></a></p>
<p dir="auto">Official websites, tools and resources about BunkerWeb :</p>
<ul dir="auto">
<li><a href="https://www.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Website</strong></a> : get more information, news and articles about BunkerWeb</li>
<li><a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Panel</strong></a> : dedicated platform to order and manage professional services (e.g. technical support) around BunkerWeb</li>
<li><a href="https://docs.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Documentation</strong></a> : technical documentation of the BunkerWeb solution</li>
<li><a href="https://demo.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Demo</strong></a> : demonstration website of BunkerWeb, don't hesitate to attempt attacks to test the robustness of the solution</li>
<li><a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Configurator</strong></a> : user-friendly tool to help you configure BunkerWeb</li>
<li><a href="https://threatmap.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow"><strong>Threatmap</strong></a> : live cyber attack blocked by BunkerWeb instances all around the world</li>
</ul>
<p dir="auto">Community and social networks :</p>
<ul dir="auto">
<li><a href="https://discord.com/invite/fTf46FmtyD" rel="nofollow"><strong>Discord</strong></a></li>
<li><a href="https://www.linkedin.com/company/bunkerity/" rel="nofollow"><strong>LinkedIn</strong></a></li>
<li><a href="https://twitter.com/bunkerity" rel="nofollow"><strong>Twitter</strong></a></li>
<li><a href="https://www.reddit.com/r/BunkerWeb/" rel="nofollow"><strong>Reddit</strong></a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Concepts</h2><a id="user-content-concepts" aria-label="Permalink: Concepts" href="#concepts"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/concepts.svg"><img alt="Concepts banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/concepts.svg"></a>
</p>
<p dir="auto">You will find more information about the key concepts of BunkerWeb in the <a href="https://docs.bunkerweb.io/1.5.12/concepts/?utm_campaign=self&amp;utm_source=github" rel="nofollow">documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integrations</h2><a id="user-content-integrations" aria-label="Permalink: Integrations" href="#integrations"></a></p>
<p dir="auto">The first concept is the integration of BunkerWeb into the target environment. We prefer to use the word "integration" instead of "installation" because one of the goals of BunkerWeb is to integrate seamlessly into existing environments.</p>
<p dir="auto">The following integrations are officially supported :</p>
<ul dir="auto">
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker" rel="nofollow">Docker</a></li>
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#linux" rel="nofollow">Linux</a></li>
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf" rel="nofollow">Docker autoconf</a></li>
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes" rel="nofollow">Kubernetes</a></li>
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#swarm" rel="nofollow">Swarm</a></li>
<li><a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#microsoft-azure" rel="nofollow">Microsoft Azure</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Settings</h2><a id="user-content-settings" aria-label="Permalink: Settings" href="#settings"></a></p>
<p dir="auto">Once BunkerWeb is integrated into your environment, you will need to configure it to serve and protect your web applications.</p>
<p dir="auto">The configuration of BunkerWeb is done by using what we call the "settings" or "variables". Each setting is identified by a name such as <code>AUTO_LETS_ENCRYPT</code> or <code>USE_ANTIBOT</code>. You can assign values to the settings to configure BunkerWeb.</p>
<p dir="auto">Here is a dummy example of a BunkerWeb configuration :</p>
<div data-snippet-clipboard-copy-content="SERVER_NAME=www.example.com
AUTO_LETS_ENCRYPT=yes
USE_ANTIBOT=captcha
REFERRER_POLICY=no-referrer
USE_MODSECURITY=no
USE_GZIP=yes
USE_BROTLI=no"><pre lang="conf"><code>SERVER_NAME=www.example.com
AUTO_LETS_ENCRYPT=yes
USE_ANTIBOT=captcha
REFERRER_POLICY=no-referrer
USE_MODSECURITY=no
USE_GZIP=yes
USE_BROTLI=no
</code></pre></div>
<p dir="auto">You will find an easy to use settings generator at <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">config.bunkerweb.io</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Multisite mode</h2><a id="user-content-multisite-mode" aria-label="Permalink: Multisite mode" href="#multisite-mode"></a></p>
<p dir="auto">The multisite mode is a crucial concept to understand when using BunkerWeb. Because the goal is to protect web applications, we intrinsically inherit the concept of "virtual host" or "vhost" (more info <a href="https://en.wikipedia.org/wiki/Virtual_hosting" rel="nofollow">here</a>) which makes it possible to serve multiple web applications from a single (or a cluster of) instance.</p>
<p dir="auto">By default, the multisite mode of BunkerWeb is disabled which means that only one web application will be served and all the settings will be applied to it. The typical use case is when you have a single application to protect : you don't have to worry about the multisite and the default behavior should be the right one for you.</p>
<p dir="auto">When multisite mode is enabled, BunkerWeb will serve and protect multiple web applications. Each web application is identified by a unique server name and have its own set of settings. The typical use case is when you have multiple applications to protect and you want to use a single (or a cluster depending of the integration) instance of BunkerWeb.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Custom configurations</h2><a id="user-content-custom-configurations" aria-label="Permalink: Custom configurations" href="#custom-configurations"></a></p>
<p dir="auto">Because meeting all the use cases only using the settings is not an option (even with <a href="https://docs.bunkerweb.io/1.5.12/plugins/?utm_campaign=self&amp;utm_source=github" rel="nofollow">external plugins</a>), you can use custom configurations to solve your specific challenges.</p>
<p dir="auto">Under the hood, BunkerWeb uses the notorious NGINX web server, that's why you can leverage its configuration system for your specific needs. Custom NGINX configurations can be included in different <a href="https://docs.nginx.com/nginx/admin-guide/basic-functionality/managing-configuration-files/#contexts" rel="nofollow">contexts</a> like HTTP or server (all servers and/or specific server block).</p>
<p dir="auto">Another core component of BunkerWeb is the ModSecurity Web Application Firewall : you can also use custom configurations to fix some false positives or add custom rules for example.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Database</h2><a id="user-content-database" aria-label="Permalink: Database" href="#database"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/bunkerweb_db.svg"><img alt="Database model" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/bunkerweb_db.svg"></a>
</p>
<p dir="auto">State of the current configuration of BunkerWeb is stored in a backend database which contains the following data :</p>
<ul dir="auto">
<li>Settings defined for all the services</li>
<li>Custom configurations</li>
<li>BunkerWeb instances</li>
<li>Metadata about jobs execution</li>
<li>Cached files</li>
</ul>
<p dir="auto">The following backend database are supported : SQLite, MariaDB, MySQL and PostgreSQL</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scheduler</h2><a id="user-content-scheduler" aria-label="Permalink: Scheduler" href="#scheduler"></a></p>
<p dir="auto">To make things automagically work together, a dedicated service called the scheduler is in charge of :</p>
<ul dir="auto">
<li>Storing the settings and custom configurations inside the database</li>
<li>Executing various tasks (called jobs)</li>
<li>Generating a configuration which is understood by BunkerWeb</li>
<li>Being the intermediary for other services (like web UI or autoconf)</li>
</ul>
<p dir="auto">In other words, the scheduler is the brain of BunkerWeb.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">BunkerWeb Cloud</h2><a id="user-content-bunkerweb-cloud-1" aria-label="Permalink: BunkerWeb Cloud" href="#bunkerweb-cloud-1"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/bunkerweb-cloud.webp"><img alt="Docker banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/bunkerweb-cloud.webp"></a>
</p>
<p dir="auto">BunkerWeb Cloud is the easiest way to get started with BunkerWeb. It offers you a fully managed BunkerWeb service with no hassle. Think of a like a BunkerWeb-as-a-Service !</p>
<p dir="auto">You will find more information about BunkerWeb Cloud beta <a href="https://www.bunkerweb.io/cloud?utm_campaign=self&amp;utm_source=docs" rel="nofollow">here</a> and you can apply for free <a href="https://panel.bunkerweb.io/order/bunkerweb-cloud/14?utm_campaign=self&amp;utm_source=docs" rel="nofollow">in the BunkerWeb panel</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker</h2><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-docker.svg"><img alt="Docker banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-docker.svg"></a>
</p>
<p dir="auto">We provide ready to use prebuilt images for x64, x86, armv7 and arm64 platforms on <a href="https://hub.docker.com/u/bunkerity" rel="nofollow">Docker Hub</a>.</p>
<p dir="auto">Docker integration key concepts are :</p>
<ul dir="auto">
<li><strong>Environment variables</strong> to configure BunkerWeb</li>
<li><strong>Scheduler</strong> container to store configuration and execute jobs</li>
<li><strong>Networks</strong> to expose ports for clients and connect to upstream web services</li>
</ul>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker" rel="nofollow">Docker integration section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker autoconf</h2><a id="user-content-docker-autoconf" aria-label="Permalink: Docker autoconf" href="#docker-autoconf"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-autoconf.svg"><img alt="Docker autoconf banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-autoconf.svg"></a>
</p>
<p dir="auto">The downside of using environment variables is that the container needs to be recreated each time there is an update which is not very convenient. To counter that issue, you can use another image called <strong>autoconf</strong> which will listen for Docker events and automatically reconfigure BunkerWeb in real-time without recreating the container.</p>
<p dir="auto">Instead of defining environment variables for the BunkerWeb container, you simply add <strong>labels</strong> to your web applications containers and the <strong>autoconf</strong> will "automagically" take care of the rest.</p>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf" rel="nofollow">Docker autoconf section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Swarm</h2><a id="user-content-swarm" aria-label="Permalink: Swarm" href="#swarm"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-swarm.svg"><img alt="Swarm banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-swarm.svg"></a>
</p>
<p dir="auto">To automatically configure BunkerWeb instances, a special service, called <strong>autoconf</strong> will listen for Docker Swarm events like service creation or deletion and automatically configure the <strong>BunkerWeb instances</strong> in real-time without downtime.</p>
<p dir="auto">Like the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#docker-autoconf" rel="nofollow">Docker autoconf integration</a>, configuration for web services is defined using labels starting with the special <strong>bunkerweb.</strong> prefix.</p>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#swarm" rel="nofollow">Swarm section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kubernetes</h2><a id="user-content-kubernetes" aria-label="Permalink: Kubernetes" href="#kubernetes"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-kubernetes.svg"><img alt="Kubernetes banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-kubernetes.svg"></a>
</p>
<p dir="auto">The autoconf acts as an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/" rel="nofollow">Ingress controller</a> and will configure the BunkerWeb instances according to the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" rel="nofollow">Ingress resources</a>. It also monitors other Kubernetes objects like <a href="https://kubernetes.io/docs/concepts/configuration/configmap/" rel="nofollow">ConfigMap</a> for custom configurations.</p>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#kubernetes" rel="nofollow">Kubernetes section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Linux</h2><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-linux.svg"><img alt="Linux banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-linux.svg"></a>
</p>
<p dir="auto">List of supported Linux distros :</p>
<ul dir="auto">
<li>Debian 12 "Bookworm"</li>
<li>Ubuntu 22.04 "Noble"</li>
<li>Ubuntu 24.04 "Jammy"</li>
<li>Fedora 40</li>
<li>RHEL 8.9</li>
<li>RHEL 9.4</li>
</ul>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#linux" rel="nofollow">Linux section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Microsoft Azure</h2><a id="user-content-microsoft-azure" aria-label="Permalink: Microsoft Azure" href="#microsoft-azure"></a></p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-azure.webp"><img alt="Azure banner" src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/integration-azure.webp"></a>
</p>
<p dir="auto">BunkerWeb is referenced in the <a href="https://azuremarketplace.microsoft.com/fr-fr/marketplace/apps/bunkerity.bunkerweb?tab=Overview" rel="nofollow">Azure Marketplace</a> and an ARM template is available in the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.9/misc/integrations/azure-arm-template.json">misc folder</a>.</p>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/integrations/?utm_campaign=self&amp;utm_source=github#microsoft-azure" rel="nofollow">Microsoft Azure section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart guide</h2><a id="user-content-quickstart-guide" aria-label="Permalink: Quickstart guide" href="#quickstart-guide"></a></p>
<p dir="auto">Once you have setup BunkerWeb with the integration of your choice, you can follow the <a href="https://docs.bunkerweb.io/1.5.12/quickstart-guide/?utm_campaign=self&amp;utm_source=github" rel="nofollow">quickstart guide</a> that will cover the following common use cases :</p>
<ul dir="auto">
<li>Protecting a single HTTP application</li>
<li>Protecting multiple HTTP application</li>
<li>Retrieving the real IP of clients when operating behind a load balancer</li>
<li>Adding custom configurations</li>
<li>Protecting generic TCP/UDP applications</li>
<li>In combination with PHP</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security tuning</h2><a id="user-content-security-tuning" aria-label="Permalink: Security tuning" href="#security-tuning"></a></p>
<p dir="auto">BunkerWeb offers many security features that you can configure with <a href="https://docs.bunkerweb.io/1.5.12/settings/?utm_campaign=self&amp;utm_source=github" rel="nofollow">settings</a>. Even if the default values of settings ensure a minimal "security by default", we strongly recommend you to tune them. By doing so you will be able to ensure a security level of your choice but also manage false positives.</p>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/security-tuning/?utm_campaign=self&amp;utm_source=github" rel="nofollow">security tuning section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Settings</h2><a id="user-content-settings-1" aria-label="Permalink: Settings" href="#settings-1"></a></p>
<p dir="auto">To help you tuning BunkerWeb we have made an easy to use settings generator tool available at <a href="https://config.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">config.bunkerweb.io</a>.</p>
<p dir="auto">As a general rule when multisite mode is enabled, if you want to apply settings with multisite context to a specific server you will need to add the primary (first) server name as a prefix like <code>www.example.com_USE_ANTIBOT=captcha</code> or <code>myapp.example.com_USE_GZIP=yes</code> for example.</p>
<p dir="auto">When settings are considered as "multiple", it means that you can have multiple groups of settings for the same feature by adding numbers as suffix like <code>REVERSE_PROXY_URL_1=/subdir</code>, <code>REVERSE_PROXY_HOST_1=http://myhost1</code>, <code>REVERSE_PROXY_URL_2=/anotherdir</code>, <code>REVERSE_PROXY_HOST_2=http://myhost2</code>, ... for example.</p>
<p dir="auto">Check the <a href="https://docs.bunkerweb.io/1.5.12/settings/?utm_campaign=self&amp;utm_source=github" rel="nofollow">settings section</a> of the documentation to get the full list.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Web UI</h2><a id="user-content-web-ui" aria-label="Permalink: Web UI" href="#web-ui"></a></p>
<p dir="auto">
	<a href="https://www.youtube.com/watch?v=Ao20SfvQyr4" rel="nofollow">
		<img src="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/docs/assets/img/user_interface_demo.webp" height="300">
	</a>
</p>
<p dir="auto">The "Web UI" is a web application that helps you manage your BunkerWeb instance using a user-friendly interface instead of the command-line one.</p>
<ul dir="auto">
<li>Start, stop, restart and reload your BunkerWeb instance</li>
<li>Add, edit and delete settings for your web applications</li>
<li>Add, edit and delete custom configurations for NGINX and ModSecurity</li>
<li>Install and uninstall external plugins</li>
<li>Explore the cached files</li>
<li>Monitor jobs execution</li>
<li>View the logs and search pattern</li>
</ul>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/web-ui/?utm_campaign=self&amp;utm_source=github" rel="nofollow">Web UI section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Plugins</h2><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto">BunkerWeb comes with a plugin system to make it possible to easily add new features. Once a plugin is installed, you can manage it using additional settings defined by the plugin.</p>
<p dir="auto">Here is the list of "official" plugins that we maintain (see the <a href="https://github.com/bunkerity/bunkerweb-plugins/?utm_campaign=self&amp;utm_source=github">bunkerweb-plugins</a> repository for more information) :</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Version</th>
<th>Description</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ClamAV</strong></td>
<td>1.6</td>
<td>Automatically scans uploaded files with the ClamAV antivirus engine and denies the request when a file is detected as malicious.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/clamav">bunkerweb-plugins/clamav</a></td>
</tr>
<tr>
<td><strong>Coraza</strong></td>
<td>1.6</td>
<td>Inspect requests using a the Coraza WAF (alternative of ModSecurity).</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/coraza">bunkerweb-plugins/coraza</a></td>
</tr>
<tr>
<td><strong>CrowdSec</strong></td>
<td>1.6</td>
<td>CrowdSec bouncer for BunkerWeb.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/crowdsec">bunkerweb-plugins/crowdsec</a></td>
</tr>
<tr>
<td><strong>Discord</strong></td>
<td>1.6</td>
<td>Send security notifications to a Discord channel using a Webhook.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/discord">bunkerweb-plugins/discord</a></td>
</tr>
<tr>
<td><strong>Slack</strong></td>
<td>1.6</td>
<td>Send security notifications to a Slack channel using a Webhook.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/slack">bunkerweb-plugins/slack</a></td>
</tr>
<tr>
<td><strong>VirusTotal</strong></td>
<td>1.6</td>
<td>Automatically scans uploaded files with the VirusTotal API and denies the request when a file is detected as malicious.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/virustotal">bunkerweb-plugins/virustotal</a></td>
</tr>
<tr>
<td><strong>WebHook</strong></td>
<td>1.6</td>
<td>Send security notifications to a custom HTTP endpoint using a Webhook.</td>
<td><a href="https://github.com/bunkerity/bunkerweb-plugins/tree/main/webhook">bunkerweb-plugins/slack</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">You will find more information in the <a href="https://docs.bunkerweb.io/1.5.12/plugins/?utm_campaign=self&amp;utm_source=github" rel="nofollow">plugins section</a> of the documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Professional</h2><a id="user-content-professional" aria-label="Permalink: Professional" href="#professional"></a></p>
<p dir="auto">Get technical support directly from the BunkerWeb maintainers. You will find more information by visiting the <a href="https://panel.bunkerweb.io/?utm_campaign=self&amp;utm_source=github" rel="nofollow">BunkerWeb Panel</a>, our dedicated platform for professional services.</p>
<p dir="auto">Don't hesitate to <a href="https://panel.bunkerweb.io/contact.php?utm_campaign=self&amp;utm_source=github" rel="nofollow">contact us</a> if you have any question, we will be more than happy to respond to your needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">To get free community support you can use the following media :</p>
<ul dir="auto">
<li>The #help channel of BunkerWeb in the <a href="https://discord.com/invite/fTf46FmtyD" rel="nofollow">Discord server</a></li>
<li>The help category of <a href="https://github.com/bunkerity/bunkerweb/discussions">GitHub discussions</a></li>
<li>The <a href="https://www.reddit.com/r/BunkerWeb" rel="nofollow">/r/BunkerWeb</a> subreddit</li>
<li>The <a href="https://serverfault.com/" rel="nofollow">Server Fault</a> and <a href="https://superuser.com/" rel="nofollow">Super User</a> forums</li>
</ul>
<p dir="auto">Please don't use <a href="https://github.com/bunkerity/bunkerweb/issues">GitHub issues</a> to ask for help, use it only for bug reports and feature requests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the terms of the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/LICENSE.md">GNU Affero General Public License (AGPL) version 3</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribute</h2><a id="user-content-contribute" aria-label="Permalink: Contribute" href="#contribute"></a></p>
<p dir="auto">If you would like to contribute to the plugins you can read the <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/CONTRIBUTING.md">contributing guidelines</a> to get started.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security policy</h2><a id="user-content-security-policy" aria-label="Permalink: Security policy" href="#security-policy"></a></p>
<p dir="auto">We take security bugs as serious issues and encourage responsible disclosure, see our <a href="https://github.com/bunkerity/bunkerweb/raw/v1.5.12/SECURITY.md">security policy</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<a href="https://star-history.com/#bunkerity/bunkerweb&amp;Date" rel="nofollow">
 <themed-picture data-catalyst-inline="true"><picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://camo.githubusercontent.com/0dd504ad3f325a03ad470190c64475c054138f268ed0d063766a717ebf6ff434/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d62756e6b65726974792f62756e6b657277656226747970653d44617465267468656d653d6461726b" data-canonical-src="https://api.star-history.com/svg?repos=bunkerity/bunkerweb&amp;type=Date&amp;theme=dark">
   <source media="(prefers-color-scheme: light)" srcset="https://camo.githubusercontent.com/767b2b25fbe9e0d2af8ad811793b681672f7f2bf1e7fa41f1202d2844fdd3e93/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d62756e6b65726974792f62756e6b657277656226747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=bunkerity/bunkerweb&amp;type=Date">
   <img alt="Star History Chart" src="https://camo.githubusercontent.com/767b2b25fbe9e0d2af8ad811793b681672f7f2bf1e7fa41f1202d2844fdd3e93/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d62756e6b65726974792f62756e6b657277656226747970653d44617465" data-canonical-src="https://api.star-history.com/svg?repos=bunkerity/bunkerweb&amp;type=Date">
 </picture></themed-picture>
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Romanian court annuls result of presidential election first round (380 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cn4x2epppego</link>
            <guid>42339819</guid>
            <pubDate>Fri, 06 Dec 2024 13:55:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cn4x2epppego">https://www.bbc.com/news/articles/cn4x2epppego</a>, See on <a href="https://news.ycombinator.com/item?id=42339819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>Romania's constitutional court has annulled the result of the first round of voting in the presidential election just days before the second round was due to take place.<!-- --></p><p>It means the process will be restarted from scratch, with the government due to decide a date for a new vote.<!-- --></p><p>The first round was won by Calin Georgescu, an almost unknown far-right Nato-sceptic who has previously praised Vladimir Putin.<!-- --></p><p>The court's decision comes after intelligence documents were declassified, suggesting Georgescu benefitted from a mass influence operation – conducted from abroad – to interfere with the result of the vote.<!-- --></p></div><div data-component="text-block"><p>Outgoing Romanian Prime Minister Marcel Ciolacu said the court's decision to annul was "the only correct solution after the declassification of the documents... which show that the result of the Romanians' vote was blatantly distorted as a result of Russia's intervention".<!-- --></p><p>In an address on Friday evening, current President Klaus Iohannis confirmed he would remain in the role until a new president was elected.<!-- --></p><p>He said Romania was a stable, safe and solid country, one that remained safely and solidly pro-European and an ally to Nato.<!-- --></p><p>The judges of the court met on Friday morning, despite having announced the previous night that they would not discuss new information regarding possible external influence on the elections until the second round of voting.<!-- --></p><p>The law stipulates that, in the event of the annulment of the elections, they should resume on the second Sunday after the date of the annulment - which would have meant on 22 December.<!-- --></p><p>However, the court has decided to ask the government to rerun the entire electoral process, and therefore the electoral campaign.<!-- --></p><p>Last week, the court had ordered a recount of votes cast in Sunday's first round following allegations that social media platform TikTok gave "preferential treatment" to the surprise winner, Calin Georgescu.<!-- --></p><p>Georgescu, a radical with no party of his own, campaigned mainly on TikTok. The platform said it was "categorically false to claim his account was treated differently to any other candidate".<!-- --></p><p>He won 23% of the vote, with 19% for the runner-up, Elena Lasconi, of the opposition Save Romania Union and Ciolacu of the governing Social Democrats in third.<!-- --></p></div><div data-component="text-block"><p>Lasconi condemned the court's ruling as "illegal" and "immoral", saying "today is the moment when the Romanian state has trampled on democracy".<!-- --></p><p>"Whether we like it or not, from a legal and legitimate point of view, nine million Romanian citizens, both in the country and in the diaspora, have expressed their preference for a certain candidate. We cannot ignore their will!" she said.<!-- --></p><p>She had been hoping to win the second round run-off on Sunday, which has now been cancelled.<!-- --></p><p>The Constitutional Court also rejected claims filed by two of the losing candidates who accused Georgescu of illegal campaign financing.<!-- --></p><p>This week, <!-- --><a target="_self" href="https://www.bbc.co.uk/news/articles/cvg6l06ldpqo">Georgescu denied to the BBC that he was Moscow's man<!-- --></a>. <!-- --></p><p>He claimed the political establishment could not cope with his success and was trying to block him. <!-- --></p><p>The country is now in totally new territory, politically. And no-one is quite sure what comes next.<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Teams (180 pts)]]></title>
            <link>https://blog.kagi.com/kagi-teams</link>
            <guid>42339048</guid>
            <pubDate>Fri, 06 Dec 2024 12:09:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/kagi-teams">https://blog.kagi.com/kagi-teams</a>, See on <a href="https://news.ycombinator.com/item?id=42339048">Hacker News</a></p>
Couldn't get https://blog.kagi.com/kagi-teams: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Sensible SQLite Defaults (128 pts)]]></title>
            <link>https://briandouglas.ie/sqlite-defaults/</link>
            <guid>42338738</guid>
            <pubDate>Fri, 06 Dec 2024 11:21:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://briandouglas.ie/sqlite-defaults/">https://briandouglas.ie/sqlite-defaults/</a>, See on <a href="https://news.ycombinator.com/item?id=42338738">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>SQLite is cool now. DHH uses it, Laravel defaults to it. Here is a list of
<em>sensible defaults</em> when using sqlite.</p>
<!-- more -->
<h2>The whys?</h2>
<pre tabindex="0"><code><span><span>PRAGMA journal_mode </span><span>=</span><span> WAL;</span></span></code></pre>
<p><strong>Why?</strong>: Allows concurrent reads and writes, making it more suitable for web applications with multiple users accessing the database simultaneously.</p>
<pre tabindex="0"><code><span><span>PRAGMA synchronous </span><span>=</span><span> NORMAL;</span></span></code></pre>
<p><strong>Why?</strong>: Balances performance and data safety by ensuring that data is written to disk in a reasonable time frame without slowing down writes as much as <code>FULL</code> mode.</p>
<pre tabindex="0"><code><span><span>PRAGMA busy_timeout </span><span>=</span><span> 5000</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Prevents "database is locked" errors by giving SQLite 5 seconds to wait for a locked resource before returning an error, useful for handling multiple concurrent accesses.</p>
<pre tabindex="0"><code><span><span>PRAGMA cache_size </span><span>=</span><span> -</span><span>20000</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Sets the cache size to 20MB, allowing more data to be cached in memory, improving query performance by reducing the number of disk reads.</p>
<pre tabindex="0"><code><span><span>PRAGMA foreign_keys </span><span>=</span><span> ON</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Ensures referential integrity by enforcing foreign key constraints, critical for maintaining consistent relationships between tables (e.g., users, posts, and comments).</p>
<pre tabindex="0"><code><span><span>PRAGMA auto_vacuum </span><span>=</span><span> INCREMENTAL</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Reclaims disk space gradually as rows are deleted, instead of performing a full vacuum, reducing performance impact during database operations.</p>
<pre tabindex="0"><code><span><span>PRAGMA temp_store </span><span>=</span><span> MEMORY;</span></span></code></pre>
<p><strong>Why?</strong>: Stores temporary tables and other temporary data in memory, improving the performance of operations like sorting and indexing that are common in web applications.</p>
<pre tabindex="0"><code><span><span>PRAGMA mmap_size </span><span>=</span><span> 2147483648</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Uses memory-mapped I/O with a size of 2GB, which can speed up database access by reducing disk I/O, especially beneficial for large databases with frequent reads and writes.</p>
<pre tabindex="0"><code><span><span>PRAGMA page_size </span><span>=</span><span> 8192</span><span>;</span></span></code></pre>
<p><strong>Why?</strong>: Sets a page size of 8KB, which provides a balance between memory usage and disk I/O performance for a forum database that handles many reads and writes.</p>
<h2>Copy paste</h2>
<p>For your convenience.</p>
<pre tabindex="0"><code><span><span>-- Set the journal mode to Write-Ahead Logging for concurrency</span></span>
<span><span>PRAGMA journal_mode </span><span>=</span><span> WAL;</span></span>
<span></span>
<span><span>-- Set synchronous mode to NORMAL for performance and data safety balance</span></span>
<span><span>PRAGMA synchronous </span><span>=</span><span> NORMAL;</span></span>
<span></span>
<span><span>-- Set busy timeout to 5 seconds to avoid "database is locked" errors</span></span>
<span><span>PRAGMA busy_timeout </span><span>=</span><span> 5000</span><span>;</span></span>
<span></span>
<span><span>-- Set cache size to 20MB for faster data access</span></span>
<span><span>PRAGMA cache_size </span><span>=</span><span> -</span><span>20000</span><span>;</span></span>
<span></span>
<span><span>-- Enable foreign key constraint enforcement</span></span>
<span><span>PRAGMA foreign_keys </span><span>=</span><span> ON</span><span>;</span></span>
<span></span>
<span><span>-- Enable auto vacuuming and set it to incremental mode for gradual space reclaiming</span></span>
<span><span>PRAGMA auto_vacuum </span><span>=</span><span> INCREMENTAL</span><span>;</span></span>
<span></span>
<span><span>-- Store temporary tables and data in memory for better performance</span></span>
<span><span>PRAGMA temp_store </span><span>=</span><span> MEMORY;</span></span>
<span></span>
<span><span>-- Set the mmap_size to 2GB for faster read/write access using memory-mapped I/O</span></span>
<span><span>PRAGMA mmap_size </span><span>=</span><span> 2147483648</span><span>;</span></span>
<span></span>
<span><span>-- Set the page size to 8KB for balanced memory usage and performance</span></span>
<span><span>PRAGMA page_size </span><span>=</span><span> 8192</span><span>;</span></span></code></pre>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hacker Herald – like HN but with crowdsourced pics and subtitles (192 pts)]]></title>
            <link>https://hackerherald.com/</link>
            <guid>42338327</guid>
            <pubDate>Fri, 06 Dec 2024 10:22:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerherald.com/">https://hackerherald.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42338327">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header id="header">
        
    </header>

    

    <main>
        
        <div id="loading-container">
            <p>
            Loading...
        </p></div>
        <div id="retry-container">
                <h4>Something went wrong</h4>
                <p>Please try again.</p>
                </div>
        
    </main>

    

    <!-- <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script> -->
    
    
    
    
    
    
    
    


<template id="article-large">
    <article class="article-large">
        <a href="">
            <img src="" alt="" class="article-image">
        </a>
        <div class="article-content">
            <a href="">
                <h2 class="article-title"></h2>
            </a>
            <a href="">
                <p class="article-subtitle"></p>
            </a>
            <div class="article-link-container">
                <a href="" class="article-link"></a>
                <div class="article-bookmark-dropdown-container">
                    <button class="article-bookmark-btn" type="button" tabindex="0">
                        <svg class="article-bookmark-icon icon" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" width="24px" height="24px">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M17.593 3.322c1.1.128 1.907 1.077 1.907 2.185V21L12 17.25 4.5 21V5.507c0-1.108.806-2.057 1.907-2.185a48.507 48.507 0 0 1 11.186 0Z"></path>
                        </svg>
                    </button>
                    <div class="article-more-dropdown-container">
                        <button class="article-more-btn" type="button" tabindex="0">
                            <img width="20px" height="20px" src="./public/more-icon.svg" alt="More Button" class="more-icon icon">
                        </button>
                        <!-- Dropdown menu itself - hidden by default -->
                        <ul class="article-more-dropdown-menu">
                            <li type="subtitle">
                                Suggest or Choose a Subtitle
                                <svg class="icon article-dropdown-list-icon" xmlns="http://www.w3.org/2000/svg" height="48px" viewBox="0 -960 960 960" width="48px" fill="#000000">
                                    <path d="M240-350h360v-60H240v60Zm420 0h60v-60h-60v60ZM240-470h60v-60h-60v60Zm120 0h360v-60H360v60ZM140-160q-24 0-42-18t-18-42v-520q0-24 18-42t42-18h680q24 0 42 18t18 42v520q0 24-18 42t-42 18H140Zm0-60h680v-520H140v520Zm0 0v-520 520Z"></path>
                                </svg>
                            </li>
                            <li type="image">
                                Suggest or Choose an Image
                                <svg class="icon article-dropdown-list-icon" xmlns="http://www.w3.org/2000/svg" height="48px" viewBox="0 -960 960 960" width="48px" fill="#000000">
                                    <path d="M180-120q-24 0-42-18t-18-42v-600q0-24 18-42t42-18h600q24 0 42 18t18 42v600q0 24-18 42t-42 18H180Zm0-60h600v-600H180v600Zm56-97h489L578-473 446-302l-93-127-117 152Zm-56 97v-600 600Zm160.12-390q20.88 0 35.38-14.62 14.5-14.62 14.5-35.5 0-20.88-14.62-35.38-14.62-14.5-35.5-14.5-20.88 0-35.38 14.62-14.5 14.62-14.5 35.5 0 20.88 14.62 35.38 14.62 14.5 35.5 14.5Z"></path>
                                </svg>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="article-footer">
                <a href="" class="article-comments-container">
                    <img width="20px" height="20px" src="./public/message-icon.svg" alt="Message Icon" class="comments-icon icon">
                    <span class="article-comments"></span>
                </a>

                <a href="" class="article-time-points-container">
                    <span class="article-points"></span>
                    <span class="article-time"></span>
                </a>
            </div>
        </div>
    </article>
</template>

<template id="article-small">
    <article class="article-small">
        <a href="">
            <h3 class="article-title"></h3>
        </a>

        <div class="article-content">
            <a href="" class="article-image-subtitle-container">
                <img src="" alt="" class="article-image">
                <span class="article-subtitle"></span>
            </a>

            <div class="article-link-container">
                <a href="" class="article-link"></a>
                <div class="article-bookmark-dropdown-container">
                    <button class="article-bookmark-btn" type="button" tabindex="0">
                        <svg class="article-bookmark-icon icon" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" width="24px" height="24px">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M17.593 3.322c1.1.128 1.907 1.077 1.907 2.185V21L12 17.25 4.5 21V5.507c0-1.108.806-2.057 1.907-2.185a48.507 48.507 0 0 1 11.186 0Z"></path>
                        </svg>
                    </button>
                    <div class="article-more-dropdown-container">
                        <button class="article-more-btn" type="button" tabindex="0">
                            <img width="20px" height="20px" src="./public/more-icon.svg" alt="More Button" class="more-icon icon">
                        </button>
                        <!-- Dropdown menu itself - hidden by default -->
                        <ul class="article-more-dropdown-menu">
                            <li type="subtitle">
                                Suggest or Choose a Subtitle
                                <svg class="icon article-dropdown-list-icon" xmlns="http://www.w3.org/2000/svg" height="48px" viewBox="0 -960 960 960" width="48px" fill="#000000">
                                    <path d="M240-350h360v-60H240v60Zm420 0h60v-60h-60v60ZM240-470h60v-60h-60v60Zm120 0h360v-60H360v60ZM140-160q-24 0-42-18t-18-42v-520q0-24 18-42t42-18h680q24 0 42 18t18 42v520q0 24-18 42t-42 18H140Zm0-60h680v-520H140v520Zm0 0v-520 520Z"></path>
                                </svg>
                            </li>
                            <li type="image">
                                Suggest or Choose an Image
                                <svg class="icon article-dropdown-list-icon" xmlns="http://www.w3.org/2000/svg" height="48px" viewBox="0 -960 960 960" width="48px" fill="#000000">
                                    <path d="M180-120q-24 0-42-18t-18-42v-600q0-24 18-42t42-18h600q24 0 42 18t18 42v600q0 24-18 42t-42 18H180Zm0-60h600v-600H180v600Zm56-97h489L578-473 446-302l-93-127-117 152Zm-56 97v-600 600Zm160.12-390q20.88 0 35.38-14.62 14.5-14.62 14.5-35.5 0-20.88-14.62-35.38-14.62-14.5-35.5-14.5-20.88 0-35.38 14.62-14.5 14.62-14.5 35.5 0 20.88 14.62 35.38 14.62 14.5 35.5 14.5Z"></path>
                                </svg>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="article-footer">
                <a href="" class="article-comments-container">
                    <img width="20px" height="20px" src="./public/message-icon.svg" alt="Message Icon" class="comments-icon icon">
                    <span class="article-comments"></span>
                </a>

                <a href="" class="article-time-points-container">
                    <span class="article-points"></span>
                    <span class="article-time"></span>
                </a>
            </div>
        </div>
    </article>
</template>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debian opens a can of username worms (176 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1000485/670ef0045e5e8a3e/</link>
            <guid>42338134</guid>
            <pubDate>Fri, 06 Dec 2024 09:55:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1000485/670ef0045e5e8a3e/">https://lwn.net/SubscriberLink/1000485/670ef0045e5e8a3e/</a>, See on <a href="https://news.ycombinator.com/item?id=42338134">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>It has long been said that <a href="https://martinfowler.com/bliki/TwoHardThings.html">naming things
is one of the hard things to do in computer science</a>. That may be
so, but it pales in comparison to the challenge of handling
usernames properly in applications. This is especially true when multiple
applications are involved, and they are all supposed to agree on what
characters are, and are not, allowed. The Debian project is facing
that problem right now, as two user-creation utilities disagreed about
which names are allowable. A plan is in place to sort this out
before the release of Debian&nbsp;13 ("trixie") sometime next year.</p>

<p>The <tt>useradd</tt> utility is part of the <a href="https://github.com/shadow-maint/shadow">shadow-utils</a>
project, which includes programs for managing user and group
accounts. The <tt>shadow-utils</tt> suite is included in Debian's
<tt><a href="https://packages.debian.org/search?keywords=passwd">passwd</a></tt>
package. For historical reasons, and to avoid confusion with the
upstream project, Debian's <a href="https://salsa.debian.org/debian/shadow">version of the
shadow-utils sources</a> are often referred to as "<tt>src:shadow</tt>".</p>

<!-- middle-ad -->

<p>Most Debian users don't work with <tt>useradd</tt>, or
<tt>groupadd</tt>, directly. Instead, Debian has long supplied its own
<tt><a href="https://manpages.debian.org/bookworm/adduser/adduser.8.en.html">adduser</a></tt>
(and <tt>addgroup</tt>)
utilities, originally written by founder Ian Murdock. These act as
simpler front ends to <tt>useradd</tt> and use Debian-supplied system
defaults for creating users' home directories and configurations. It
should be noted that <tt>useradd</tt>, et al., have become much more
full-featured since Debian's utilities were introduced, but the
project continues to maintain them nonetheless.</p>

<h4>Little Bobby Tables</h4>

<p>In June, Debian developer and <tt>src:shadow</tt> maintainer Chris
Hofstaedtler <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1074306">filed
a bug</a> against the <tt>adduser</tt> package. The
<tt>src:shadow</tt> package had dropped a <a href="https://sources.debian.org/patches/shadow/1:4.16.0-5/debian/Relax-usernames-groupnames-checking.patch/">Debian-specific
patch</a>, originally introduced in 2003 by Karl Ramm, to allow
characters far beyond what were allowed by the upstream
<tt>shadow-utils</tt> project. In the patch, Ramm wrote:</p>

<blockquote>
I can't come up with a good justification as to why characters other
than ':'s and '\0's should be disallowed in group and usernames (other
than '-' as the leading character).  Thus, the maintenance tools don't
anymore.
</blockquote>

<p>Hofstaedtler said that he had puzzled out some of the patch's
purpose from old bug reports that had been "fixed" by the patch, and
those asked for two things not allowed by the upstream
<tt>shadow-utils</tt>: usernames with upper-case characters or that
are purely numeric. Hofstaedtler said that upper-case names had been
allowed in the upstream <tt>shadow-utils</tt> project "<q>a long time
ago</q>", but it seemed like a bad idea to allow purely numeric
usernames.</p>

<p>The patch enabled much more than upper-case and purely numeric names,
though. With the patch dropped in version <a href="https://tracker.debian.org/news/1539923/accepted-shadow-14152-2-source-into-unstable/">1:4.15.2-2</a> of the
<tt>shadow</tt> source package, one of <tt>adduser</tt>'s
<nobr>tests—which</nobr> explicitly allowed a username reminiscent of a <a href="https://xkcd.com/327/">famous xkcd comic</a>
<nobr>("<q>bob;&gt;/hacked</q>")—had failed</nobr>:</p>

<blockquote>
<p>For src:shadow, I would really like to not have a divergence from
upstream in this regard. I think if we have clear requirements then we
(I) can submit them upstream and I would expect upstream to accept
patches.</p>

<p>I do feel that making the case for "bob;&gt;/hacked" would be very
hard.</p>
</blockquote>

<p>Hofstaedtler said that the patch had been reapplied for the time
being, it was included again in version <a href="https://tracker.debian.org/news/1540076/accepted-shadow-14152-3-source-into-unstable/">1:4.15.2-3</a>, but he asked if
username requirements could be sorted out in time for the Debian
"trixie" release. If the patch were dropped entirely, then
<tt>useradd</tt> would restrict usernames to the POSIX standard, with
the exception of allowing a "$" character at the end of a username </p>

<p>Debian developer and <tt>adduser</tt> maintainer Marc Haber <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1074306#21">replied</a>
in late October that other tests were failing as well, and thought
that "<q>useradd upstream is being too picky here</q>". Since
<tt>adduser</tt> depends on <tt>useradd</tt> it could not create users
that <tt>useradd</tt> would reject, he said he would like to
synchronize on what would be allowed or not.</p>

<p>As part of the research into what should be allowed in usernames,
Haber took over Debian's <a href="https://wiki.debian.org/UserAccounts">UserAccounts</a> wiki
page, which outlines Debian's username tools and policies, and started
looking into whether the project should relax its requirements around
usernames.</p>

<h4>Limits on usernames</h4>

<p>One of the questions that bubbles up when looking at usernames is
not just allowable characters, but the allowable length of the
username. The documentation for <tt>shadow-utils</tt> does not specify a
length for usernames or what encoding is being used. 

</p><p>However, the POSIX standard says that usernames should not include
non-ASCII characters to be portable between systems. The standard <a href="https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap03.html#tag_03_409">says</a>
that usernames should be "<q>composed of characters from the portable
filename character set</q>". That set is comprised of numbers 0
through 9, upper-case and lower-case "a" through "z", the period (.),
underscore (_), and hyphen (-). It also specifies that usernames
should not begin with a hyphen.</p>

<p>It is, however, possible to assign characters outside that set with
the tools at hand. But Linux distributions usually put up some
guardrails in the <tt>adduser</tt> and <tt>useradd</tt> configurations
to prevent administrators from creating usernames with non-ASCII
characters unintentionally. These configurations can be overridden with 
<tt>adduser</tt>'s <tt>--allow-bad-names</tt> option or <tt>useradd</tt>'s
<tt>--badname</tt> option.</p>  

<p>In November, Haber <a href="https://lwn.net/ml/all/Zz9xogrnHDSFjZUn@torres.zugschlus.de/">posted</a>
a message on debian-devel that he had "<q>opened an especially nasty
can of worms</q>" and was finding that things were more complicated
than he had understood. He sought input and opinions on a number of
questions about whether Debian should allow non-ASCII characters for usernames, how
to do that if so, and if it was more appropriate to document username
guidance in Debian's <a href="https://www.debian.org/doc/debian-policy/">Policy Manual</a>
rather than its wiki. His suggestion was to allow UTF-8 for regular
user accounts, but to restrict to ASCII for system accounts created by
Debian packages.</p>

<p>Richard Lewis <a href="https://lwn.net/ml/all/86a5dss0n6.fsf@simplex.rtf.org.uk/">asked</a>
if enabling UTF-8 would open the door to "<q>some of the abuse
described</q>" in a 2021 LWN article about <a href="https://lwn.net/Articles/874951/">flaws in Unicode handling</a>
that led to security exploits. He said that it seemed to be a bad
idea to make the change, even if it would be nicer for users to have
the option.</p>

<p>Haber <a href="https://lwn.net/ml/all/Z0BQgtaAgb1LYmCt@torres.zugschlus.de/">said</a>
that he was not sure if it would be dangerous to allow UTF-8 usernames,
"<q>since we can expect other commands to gracefully handle a byte
stream, can't we?</q>" Additionally, local administrators already
can loosen restrictions to allow UTF-8 usernames, but Debian does
not test for such use cases. Debian would become "<q>more robust</q>"
if it assumed UTF-8 characters would be used in usernames.
"<q>Vulnerabilities that could be exploited by having non-ascii
user names are already here and present today, just not uncovered yet.</q>"</p>

<p>It would be reasonable, Timo Röhling <a href="https://lwn.net/ml/all/d4qdqpeuqkgebg5hundayqafzurk72ledcv7udwdm3nwaifnpu@3hkwinihtwp2/">said</a>,
to mitigate possible <a href="https://en.wikipedia.org/wiki/IDN_homograph_attack">homograph attacks</a> by disallowing mixed alphabets
"<q>such as cyrillic and latin letters in the same name</q>". Haber <a href="https://lwn.net/ml/all/Z0CzbtHUtX_8YeSq@torres.zugschlus.de/">said</a>
that was not going to help if a user could directly write to
<tt>/etc/passwd</tt>, and he was unwilling to implement that himself
in <tt>adduser</tt>. He would accept code and test cases written by
others, though.</p>

<h4>Keyboards</h4>

<p>Security concerns aside, there are other practical problems with
supporting non-ASCII usernames. Étienne Mollier <a href="https://lwn.net/ml/all/Z0DekqnxO9PARyrH@emlwks999.eu/">noted</a> that he had "<q>one weird
enough</q>" character in his first name that posed a problem if he had
to log in using a keyboard layout that lacked the capability to
transcribe the lower-case or upper-case 'e' acute characters ("é" or
"É"). For that reason, he said, he felt better about keeping a full
ASCII username and "<q>wouldn't feel strongly if unicode support for
login never happens</q>". But it would be good if the <a href="https://en.wikipedia.org/wiki/Gecos_field">gecos field</a> of
the <tt>passwd</tt> file had proper Unicode support to properly
display users' real names.</p>

<p>Not only was it difficult to type "é" on some keyboards, it could
also be encoded in multiple ways. Gioele Barabucci <a href="https://lwn.net/ml/all/15f881af-2f62-494e-b6ea-a13f16eec959@svario.it/">pointed
out</a> that it could be "<q>e
with acute</q>" which is encoded in UTF as <tt>U+00E9</tt>, or it
could be "<q>e, combined with an [acute] accent</q>" which would be
<tt>U+0065</tt> plus <tt>U+0301</tt>:</p>

<blockquote>
If a keyboard input system provides the 
former sequence of bytes, but the username is stored in the login 
infrastructure using the latter sequence of [bytes], then a naive 
comparison will not find the user "émollier" in the system. Unicode 
defines in Annex 15 a few normalization forms as a way to work around 
this problem. But a correct use of these normalization forms still 
requires coordination and standardization among all programs accessing 
the data.
</blockquote>

<p>He asked if POSIX or other standards provided a normalization form
for UTF-8 encoded usernames. Peter Pentchev <a href="https://lwn.net/ml/all/Z0EVkB84K5nI5vnw@straylight.m.ringlet.net/">responded</a>
that POSIX said to stick to the portable filename character set to
ensure portability. Haber <a href="https://lwn.net/ml/all/Z0dLt65uVbZLxK_e@torres.zugschlus.de/">argued</a>
that it should be up to local admins to decide whether they wanted
their local user database to be portable. "<q>I don't think that we should restrict
local admins who don't need that kind of portability.</q>"</p>

<p>Simon McVittie <a href="https://lwn.net/ml/all/Z0M2B4CqjmJbJ5iS@remnant.pseudorandom.co.uk/">recommended</a>
that Debian consider adopting systemd's <a href="https://systemd.io/USER_NAMES/">user name syntax</a> and
concepts of "strict mode" and "relaxed mode". The systemd tooling
adheres to a strict naming convention when creating usernames, but
it has a relaxed convention for accepting usernames created by other
tools. McVittie said that seemed like a good principle for Debian to
follow, even if its specific rules might differ from systemd's.</p>

<p>Haber seemed to agree in part, but said systemd's strict mode was
"<q>even stricter than what we currently allow for system
accounts</q>", and he did not like that systemd's policies (especially with
<tt>systemd-homed</tt>, which LWN <a href="https://lwn.net/Articles/995915/">covered recently</a>) were not configurable.</p>

<h4>This time it's personal</h4>

<p>The discussion, perhaps not surprisingly, brought out some strong
feelings about how names and usernames were represented. Especially
when, as Hofstaedtler <a href="https://lwn.net/ml/all/n2uzj625zhxsg7ju6ox5vtx5cmbafzbecxb4lvv72sqruykk5s@qwlfypn2eo4e/">noted</a>,
usernames can be important to some users:</p>

<blockquote>
<p>I see and type my username hundreds times a day, people use it
to address me in written and spoken conversations with it, etc.</p>

<p>If it were my uid, which I see maybe once a week and don't have to
remember, I wouldn't care.</p>
</blockquote>

<p>Indeed, it's not uncommon in open-source communities or within
organizations to use a person's username rather than their given
name—so it is unsurprising that some people feel strongly that
usernames should be composed of a wider range of characters than POSIX
recommends. Others <a href="https://lwn.net/ml/all/D5UKN8ASXWNV.31KHR2M4P1Q4Z@philkern.de/">dislike
the practice</a> of conflating usernames with real-world names, and
see little reason to go to any trouble to go beyond ASCII.</p>

<p>Johannes Schauer Marin Rodrigues <a href="https://lwn.net/ml/all/173235075276.3934267.16369985803329427907@localhost/">supported</a>
allowing more than ASCII in usernames. He said it would be good for
Debian to put pressure on other projects to provide Unicode
support. "<q>We cannot find these kind of bugs if we accept
translating everybody's given name to the American alphabet.</q>"
Bálint Réczey, though, <a href="https://lwn.net/ml/all/CAK0Odpz6tXkceqimZ+Nd=GSN7bMQZOy3s25nEq6U=d40Y+M-ug@mail.gmail.com/">asked</a>
that Debian avoid opening that can of worms and imposing needless work
on upstreams. "<q>Keep what works reasonably well for decades.</q>"</p>

<h4>A plan</h4>

<p>Haber initially <a href="https://lwn.net/ml/all/Z0BSfVx_GjzBOGgV@torres.zugschlus.de/">seemed
bullish</a> on allowing UTF-8 usernames in Debian "<q>as a courtesy to those people who need non-ascii user names to
write their name</q>" and as an opportunity to find "<q>bugs that are
already here</q>" in Debian's software. He acknowledged that it is late
in the development cycle for trixie. But, since it was currently
possible to create usernames with UTF-8 characters, he did not want
to tighten restrictions in trixie versus Debian&nbsp;12, only to
revisit those restrictions for Debian&nbsp;14. In a reply to Mollier
he <a href="https://lwn.net/ml/all/Z0dJo6l-CXZQFHU3@torres.zugschlus.de/">wondered</a>
about what advice to give in Debian's documentation "<q>once we have
decided to officially allow UTF-8 login names</q>".</p>

<p>On December 3, however, Haber <a href="https://lwn.net/ml/all/Z08v5ReoUOOaBi8H@torres.zugschlus.de/">said</a>
that he "<q>finally understood</q>" that UTF-8 support would require
more than the ability to create an UTF-8 encoded username and write 
it to <tt>/etc/passwd</tt>. Homograph characters, such as U+00E9 (é)
and U+0065 plus U+0301 (é), could be used with <tt>adduser</tt> to
create two separate users with lookalike usernames:</p>

<blockquote>
At the least, adduser should reject creating étienne if étienne
already exists - those are different user names but look the same, and
if you don't cut-and-paste user names instead of typing them you're
bound to hit the wrong user depending on HOW you type and what input
medium you use. Not good.
</blockquote>

<p>Haber said that he was the only active developer working on
<tt>adduser</tt> and did not have time to implement a check against
lookalike usernames in time for the trixie release. Worse, he said,
the Perl module that he would use (<a href="https://metacpan.org/pod/Unicode::Precis">Unicode::Precis</a>)
was not packaged for Debian and had not had a release in more than
five years.</p>

<p>The next version of <tt>adduser</tt>, Haber said, would reject
UTF-8 usernames by default. They would still be allowed when using the
<tt>--allow-bad-names</tt> option, but he said he wanted to deprecate
that option name in favor of something that doesn't use the word
"bad". The <tt>--allow-all-names</tt> option will continue to pass
everything verbatim to <tt>useradd</tt>.</p>

<p>Mollier <a href="https://lwn.net/ml/all/Z09e0lyrPtwulBbv@emlwks999.eu/">thanked</a>
Haber for his work on the problem, and suggested some
alternatives to the bad names option. Barabucci also <a href="https://lwn.net/ml/all/3e2679c3-bc1a-49ab-8fe1-2fa6b8b132b8@svario.it/">thanked</a>
Haber for taking the time to research the issue, to which Haber
<a href="https://lwn.net/ml/all/Z09yAiCCsZ5Xu8bM@torres.zugschlus.de/">replied
dryly</a>, "<q>I have learned many things.</q>"</p>

<p>Haber's current course of action for <tt>adduser</tt> seems the
most prudent. There may be a day when it is more practical to expand
the allowed characters for usernames, but the work required to do so
right now is far greater than the benefits that users would gain in
the process.</p>

<br clear="all">
               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ukraine's three nuclear power plants have restored electricity production (217 pts)]]></title>
            <link>https://www.iaea.org/newscenter/pressreleases/update-263-iaea-director-general-statement-on-situation-in-ukraine</link>
            <guid>42337980</guid>
            <pubDate>Fri, 06 Dec 2024 09:24:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iaea.org/newscenter/pressreleases/update-263-iaea-director-general-statement-on-situation-in-ukraine">https://www.iaea.org/newscenter/pressreleases/update-263-iaea-director-general-statement-on-situation-in-ukraine</a>, See on <a href="https://news.ycombinator.com/item?id=42337980">Hacker News</a></p>
Couldn't get https://www.iaea.org/newscenter/pressreleases/update-263-iaea-director-general-statement-on-situation-in-ukraine: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>