<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Dec 2024 07:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Jeju Air accident in South Korea kills at least 47 (129 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</link>
            <guid>42536647</guid>
            <pubDate>Sun, 29 Dec 2024 01:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap">https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</a>, See on <a href="https://news.ycombinator.com/item?id=42536647">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fish 4.0: The Fish of Theseus (491 pts)]]></title>
            <link>https://fishshell.com/blog/rustport/</link>
            <guid>42535217</guid>
            <pubDate>Sat, 28 Dec 2024 22:07:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fishshell.com/blog/rustport/">https://fishshell.com/blog/rustport/</a>, See on <a href="https://news.ycombinator.com/item?id=42535217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>About two years ago, our head maintainer @ridiculousfish opened what quickly became our most-read pull request:</p>

<ul>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/9512">#9512 - Rewrite it in Rust</a></li>
</ul>

<p>Truth be told, we did not quite expect that to be as popular as it was.
It was written as a bit of an in-joke for the fish developers first, and not really as a press release to be shared far and wide.
We didn’t post it anywhere, but other people did, and we got a lot of reactions.</p>

<p>Observant readers will note that the PR was a proposal to rewrite the entirety of fish in Rust, from C++.</p>

<p>Fish is no stranger to language changes - it was ported from pure C to C++ earlier in its life,
but this was a much bigger project, porting to a much more different language that didn’t even exist when fish was started in 2007.</p>

<p>Now that we’ve released the beta of fish 4.0, containing 0% C++ and almost 100% pure Rust, let’s look back to see what we’ve learned, what went well, what could have gone better and what we can do now.</p>

<p>We’re writing this so others can learn from our experience, but it is <em>our</em> experience and not an exhaustive study.
We hope that you’ll be able to follow along even if you have never written any rust, but
experience with a roughly C++-shaped language should help.</p>

<h2 id="why-are-we-doing-this-again">Why are we doing this again?</h2>

<p>We’ve experienced some pain with C++. In short:</p>

<ul>
  <li>tools and compiler/platform differences</li>
  <li>ergonomics and (thread) safety</li>
  <li>community</li>
</ul>

<p>Frankly, the tooling around the language isn’t good, and we had to take on some additional pain in order to support our users.
We want to provide up-to-date fish packages for systems that aren’t up-to-date, like LTS Linux and older macOS.
But there is no ‘rustup’ for C++, no standard way to install recent C++ compilers on these operating systems.
This means adopting recent C++ standards would complicate the lives of packagers and would-be contributors<sup id="fnref:Contributions"><a href="#fn:Contributions" rel="footnote" role="doc-noteref">1</a></sup>.
For example, we started using C++11 in 2016, and yet we still needed to upgrade the compilers on our build machines until 2020.</p>

<p>Fish also uses threads for its award-winning (<em>note to editor</em>: find an actual award) autosuggestions and syntax highlighting,
and one long-term project is to add concurrency to the language.</p>

<p>Here’s a dirty secret: while external commands run in parallel, fish’s execution of internal commands (builtins and functions) is currently serial and can’t be backgrounded. Lifting this limitation will enable features like asynchronous prompts or non-blocking completions, as well as performance gains.</p>

<p>POSIX shells use subshells to get around this, but subshells are a leaky abstraction that can bite you in the behind when you least expect it.
For instance, you can’t set variables from inside a pipe (except on some shells, but only in the last part of the pipe, maybe, if you have enabled the correct option).
We would like to avoid that, and so the heavy hand of forking off a process isn’t appealing.</p>

<p>We prototyped true multithreaded execution in C++, but it just didn’t work out. For example, it was too easy to accidentally share objects across threads, with only post-hoc tools like Thread Sanitizer to prevent it.</p>

<p>The ergonomics of C++ are also simply not good - header files are annoying, templates are complicated, you can easily cause a compile error that throws <em>pages</em> of overloads in the standard library at you. Many functions are unsafe to use. C++ string handling is very verbose with
easily confusable overloads of many methods, making it attractive to drop down to C-style char pointers, which are quite unsafe.</p>

<p>And the standard prioritizes performance over ergonomics. Consider for instance string_view, which provides a non-owning slice of a string. This is an extremely modern, well-liked feature that C++ programmers often claim is a great reason to switch to C++17. And it is extremely easy to run into use-after-free bugs with it, because the ergonomics weren’t a priority.</p>

<p>One good case study of the deficiencies of C++-in-practice is a C library: curses. This is a venerable library to access terminal features, and we use it to access the terminfo database, which describes differences in terminal features and behavior.</p>

<p>This not only caused us grief by being unsafe to use in weird ways - the “cur_term” pointer (or sometimes macro!) can be NULL, and it is dereferenced in surprising places, but also caused a surprisingly high number of issues when building from source. This was either because there are multiple implementations of it with differences as useless as “this function takes a char on system X but an int on system Y”, but also because users kept coming to us with new and exciting(ly terrible) ways to package and install it. The dependency system is the system package manager.</p>

<p>Finally, subjectively, C++ isn’t drawing in the crowds. We have never had a lot of C++ contributors. Over the 11 years fish used C++, only 17 people have at least 10 commits to the C++ code. We also don’t know a lot of people who would love to work on a C++ codebase in their free time.</p>

<p>Some parting thoughts we can give the C++ community: We would like to see improvements to ergonomics and safety of the language and the tools prioritized over performance, and we would like to see efforts to make C++ compilers easier to upgrade on real systems.</p>

<h2 id="why-rust">Why Rust?</h2>

<p>We need to get one thing out of the way: Rust is cool. It’s fun.</p>

<p>It’s tempting to try to sweep this under the rug because it feels gauche to say, but it’s actually important for a number of reasons.</p>

<p>For one, fish is a hobby project, and that means we want it to be fun for us. Nobody is being paid to work on fish, so we <em>need</em> it to be fun.
Being fun and interesting also attracts contributors.</p>

<p>Rust also has great tooling. The tools have really paid a lot of attention to use, and the compiler errors are terrific. Not even “compared to C++”, they just actually rule. And as we have tried to pay attention to our own error messages (fish has a bespoke error for if it thinks a file you told it to run has Windows line endings),
we like it.</p>

<p>And it is <em>easy</em> to get that tooling installed - <code>rustup</code> is magic, and allows people to get started quickly, with minimal fuss or root permissions.
When the answer to “how to upgrade C++ compiler” is “find a repository (with root permissions), compile it yourself, install some <em>other</em> repository or a docker image”,
it is amazing how the Rust answer can just be “use rustup”.</p>

<p>Rust has great ergonomics - the difference between C++’s pointers (which can always be NULL) and Rust’s Options are apparent very quickly even to those of us who had never used it before. We did have a backport of C++’s optional, and liked using it, but it was never as integrated as Rust’s Options were.</p>

<p>Having an explicit <code>use</code> system where you know exactly which function comes from which module is a great improvement over <code>#include</code>.</p>

<p>Rust makes it nice to add dependencies. We don’t want to go overboard with it, but we do want to change our history format from our homegrown “I can’t believe it’s not YAML” to something specified that other tools can actually read, and Rust makes it easy to add support for YAML/JSON/KDL.</p>

<p>But the killer feature of Rust, from fish-shell’s perspective, is Send and Sync, statically enforcing rules around threading. “Fearless concurrency” is too strong - you can still blow your leg off with fork or signal handlers - but Send and Sync will be the key to unlocking fully multithreaded execution, with confidence in its correctness.</p>

<p>We did not do a comprehensive survey of other languages. We were confident Rust was up to the task and either already knew it or wanted to learn it, so we picked it.</p>

<h2 id="platform-support">Platform Support</h2>

<p>A lot of hay has also been made online about Rust’s platform support (e.g. <a href="https://lwn.net/Articles/998115/">in the git project</a>). We don’t see a big problem here - all of our big platforms (macOS, Linux, the BSDs) are supported, as are Opensolaris/Illumos and Haiku. We have never heard of anyone trying to run fish on NonStop.</p>

<p>Architecture support is even less of a problem - going by <a href="https://popcon.debian.org/">Debian’s popcon</a>, 99.9995% (the actual result, not an exaggeration) of machines run an architecture that has Rust packages in Debian. Given that fish is <a href="https://qa.debian.org/popcon.php?package=fish">installed on 1.92% of Debian systems</a>, we would project two (2) or three (3) machines of the quarter million responses to have fish on an unsupported architecture <sup id="fnref:stats"><a href="#fn:stats" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Unlike what some online have assumed, a native Windows port was not a reason for switching to Rust as it was never in the cards. Fish is, at heart, a UNIX shell that relies not only on UNIX APIs but also their semantics, and exposes them in the scripting language. What would <code>test -x</code> say on Windows, which has no executable bit? These are issues that <em>could</em> be solved with a lot of work, but we’re unix nerds making a unix shell, not one for Windows.</p>

<p>The one platform we care about a bit that it does not currently seem to have enough support for is Cygwin, which is sad, but we have to make a cut somewhere.</p>

<h2 id="the-story-of-the-port">The Story Of The Port</h2>

<p>We had decided we were gonna do a “Fish <a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">Of Theseus</a>” port - we would move over, component by component, until no C++ was left.
And at every stage of that process, it would remain a working fish.</p>

<p>This was a necessity - if we didn’t, we would not have a working program for months, which is not only demoralizing but would also have precluded us from
using most of our test suite - which is end-to-end tests that run a script or fake a terminal interaction. We would also not have been able to do another C++ release,
putting some cool improvements into the hands of our users.</p>

<p>Had we chosen to disappear into a hole we might not have finished at all, and we would have to re-do a bunch of work once it became testable.
We also mostly kept the structure of the C++ code intact - if a function is in the “env” subsystem, it would stay there. Resisting the temptation to
clean up allowed us to compare the before and after to find places where we had mistranslated something.</p>

<p>So we used <a href="https://google.github.io/autocxx/">autocxx</a> to generate bindings between C++ and Rust code, allowing us to port one component at a time.</p>

<p>We started<sup id="fnref:technically"><a href="#fn:technically" rel="footnote" role="doc-noteref">3</a></sup> by porting the builtins. These are essentially little self-contained programs, with their own arguments, streams, exit code, etc.
That means it’s easy to port them separately from the rest of the shell once you have a way to call a Rust builtin from C++, which we had as part of the initial pull request.</p>

<p>Where they connected to the main shell, we used one of three approaches:</p>

<ol>
  <li>Add some FFI glue to the C++ to make it callable from Rust, port the caller and leave the callee for later</li>
  <li>Move the callee to Rust and, if necessary, make it callable from C++</li>
  <li>Write a Rust version of the callee and call it from the ported caller, but leave the C++ version around</li>
</ol>

<p>For instance, almost every builtin needs to parse its options. We have our own implementation of getopt, that we reimplemented in Rust in the initial PR,
but the C++ version stuck around until it had no more callers remaining. Otherwise we would have had to write a C++-to-Rust bridge and adjust the C++ callers to use it.</p>

<p>Or the <code>builtin</code> builtin (the builtin called <code>builtin</code>) needs access to the names of all builtins to print them for <code>builtin --get-names</code>. In that case we bridged some access to what amounts to a constant vector of strings in the C++, and eventually moved it over once the users were in Rust.</p>

<p>That’s how it went for a while, but we finally hit the more entangled systems, where porting larger chunks felt more productive,
since that reduced the amount of tricky FFI code to be written only to be thrown away. These were ported in solo efforts.
This includes the input/output “reader”, which is, unsurprisingly, one of fish’s biggest parts, ending up at about 13000 lines of Rust.</p>

<p>During the port, we hit a bunch of snags with (auto)cxx. Sometimes it would just not understand a particular C++ construct, and we spent a lot of time trying to figure out ways to please it. As an example, we introduced a struct on the C++ side that wrapped C++’s <code>vector</code>, because for some reason autocxx liked to complain about <code>vector&lt;wstring&gt;</code>. We had to fork it to add support for wstring/wchar, which is understandable because using wchar is a horrible decision - we only do it because it’s a historical mistake.</p>

<p>Similarly, we had to wrap some C++ variables in <code>unique_ptr</code> and similar to make the ownership rules understandable to (auto)cxx, or copy values that didn’t strictly need to be copied. This caused the performance during the port to go down quite a bit, but we regained all of it in most spots, and even beat the C++ version in some.</p>

<p>We also patched autocxx to remove the requirement to use <code>unsafe</code> to invoke any C++ API, because that would have obscured uses of <code>unsafe</code> that wouldn’t disappear just by porting the callee. We were building something temporary, so sometimes it is okay to do something a little underhanded.
If you used this for a permanent bridge between Rust and C++ in a few parts of your code, the <code>unsafe</code> markers might be useful, but in our case they were noise.</p>

<p>Because autocxx generated a lot of code, some tools also were less helpful than they’d usually be. rust-analyzer for instance was extremely slow.</p>

<p>So, even though our codebase was fairly amenable to being moved to Rust because we didn’t use exceptions or a lot of templates, autocxx isn’t the easiest to work with.
It is absolutely magical that it works at all, and it enabled us to do this port, but it has a hard task to perform and isn’t perfect at it.</p>

<h3 id="the-timeline">The Timeline</h3>

<ul>
  <li>
    <p>The initial PR was opened on 28th January 2023, merged on 19th February 2023</p>
  </li>
  <li>
    <p>fish 3.7.0, another release in the C++ branch to flush out some accumulated improvements, was released in January 2024</p>
  </li>
  <li>
    <p>The last C++ code was removed in January 2024 (and some additional test code was ported from C++ to C 12th of June 2024)</p>
  </li>
  <li>
    <p>The first beta was released 17th of December 2024</p>
  </li>
</ul>

<p>The initial PR had a timeline of “handwaving, half a year”. It was clear to all of us that it might very well be entirely off, and we’re not
disappointed that it was. Frankly, 14 months was still a pretty good pace, especially considering that we made a C++ release in-between, so it did not throw off our usual release cadence.</p>

<p>Most of the work was done by 7 people (going by those with at least 10 commits to “.rs” files), but we got a lot of help from interested community members.</p>

<p>The delay after that was down to a few reasons:</p>

<ol>
  <li>The “second 90%” - testing that everything worked. We flushed out a lot of bugs in this time, and if we made a release at that time it would have been a bad one.</li>
  <li>Having something to release that’s visible to users - there’s no point in making a release that does the same thing in new code, you need it to do different things.
So we held off until we had something.</li>
  <li>Simple availability - sometimes, some of us took time off.</li>
</ol>

<p>So if you are trying to draw any conclusions from this, consider the context: A group of people working on a thing in their free time,
diverting some effort to work on something else, <em>and</em> deciding that after the work is finished it actually isn’t.</p>

<h2 id="the-gripes">The Gripes</h2>

<p>It won’t surprise anyone who has spent any time on this world of ours that Rust is not, in fact, perfect. We have some gripes with it.</p>

<p>Chief among them is how Rust handles portability. While it offers many abstractions over systems, allowing you to target a variety of systems with the same code,
when it comes to <em>adapting</em> your code to systems at a lower-level, it’s all based on enumerating systems by hand, using checks like <code>#[cfg(any(target_os = "freebsd", target_os = "netbsd", target_os = "openbsd"))]</code>.</p>

<p>This is an imperfect solution, allowing you to miss systems and ignoring version differences entirely. From what we can tell, if FreeBSD 12 gains a function that we want to use, libc would add it, but calling it would then fail on FreeBSD 11 without a good way to check, at the moment.</p>

<p>But listing targets in our code is also fundamentally duplicating work that the libc crate (in our case) has already done. If you want to call libc::X, which is only defined on systems A, B and C, you need to put in that check for A, B and C yourself and if libc adds system D you need to add it as well. Instead of doing that, we are using our own <a href="https://github.com/mqudsi/rsconf">rsconf</a> crate to do compile-time feature detection in build.rs.</p>

<p>Most of this would be solved if Rust had some form of saying “compile this if that function exists” - <code>#[cfg(has_fn = "fstatat")]</code>. With that, the libc crate could do whatever checks it wants and fish would just follow what it did, and we could remove a lot of the use for rsconf. It would not really help support older distributions that lack some features, tho. That could be solved by something like the <a href="https://github.com/rust-lang/rfcs/pull/3036">min_target_API_version</a> cfg.</p>

<p>While we’re on portability, the tools also sometimes fail to consider other targets - clippy may warn about a conversion being useless when it isn’t on another system, it is often better to use <code>if cfg!(...)</code> instead of <code>#[cfg(...)]</code> because code behind the latter is eliminated very early, so it may be entirely wrong and only shows up when building on the affected system.</p>

<p>We’ve also had issues with localization - a lot of the usual Rust relies on format strings that are checked at compile-time, but unfortunately they aren’t translatable.
We ported printf from musl, which we required for our own <code>printf</code> builtin anyway, which allows us to reuse our preexisting format strings at runtime.</p>

<h3 id="the-mistakes">The Mistakes</h3>

<p>We’ve hit some false starts, dead ends and other kinds of mistakes. For instance we originally used a fancy macro to allow us to write our strings as <code>"foo"L</code>, but that did not end up carrying its weight and we removed it in favor of a regular <code>L!("foo")</code> macro call.</p>

<p>We were confused by a deprecation warning in the libc crate, which explains that “time_t” will be switched to 64-bit on musl in the future.
We initially tried to work around it, adding a lot of wrappers to try to stay agnostic on that size, but only later figured out that it does not affect us,
as we do not pass a time_t we get from one C library to another. (https://github.com/fish-shell/fish-shell/issues/10634)</p>

<p>Some bugs appeared because we missed subtleties of the original code.
Often this turned into a crash because we used asserts or assert’s modern cousin “.unwrap()”. This was often the easiest way to translate the C++,
and sometimes it simply turned out to be not accurate, and had to be replaced with different error handling.</p>

<p>But overall most of these were, once found, pretty shallow - “it panics here, why would it do that? oh, this can be an Err? Okay, what leads to that? Ah, okay, let’s handle that in this way”.</p>

<p>We’ve also caused some friction by turning on link-time-optimization combined with having release builds as the default in CMake (currently needed to run the full test suite),
which makes it easy to accidentally have very long build time.</p>

<h2 id="the-good">The Good</h2>

<p>A lot of the benefits of porting to Rust will appear over time, but some are already here.</p>

<p>Remember our issues with (n)curses? We will no longer have any, because we no longer use curses. Instead we switched to <a href="https://github.com/meh/rust-terminfo">a Rust crate</a> that gives us just what we need, which is access to terminfo and expanding its sequences. This removes some awkward global state, and means those building from source no longer need to ensure that curses is installed “correctly” on their system - cargo just downloads a crate and builds it.</p>

<p>We do still read terminfo, which means users need to install that, but that can be done at runtime, is preinstalled on all mainstream systems <em>and</em> if it can’t be found we just use an included copy of the xterm-256color definitions<sup id="fnref:terminfo"><a href="#fn:terminfo" rel="footnote" role="doc-noteref">4</a></sup>.</p>

<p>We have also managed to create “self-installable” fish packages that include all the functions, completions and other asset files in the fish binary to be written out at runtime.
That allowed us to create statically linked versions of fish (for linux this uses musl, because glibc has unavoidable crashes!), so for the first time we have <em>one file</em> you can download and run on <em>any linux</em> (the only requirement being that the architecture matches!).</p>

<p>This is a pretty big boon for people who want to use fish but sometimes ssh to servers, where they might not have root access to install a package. So they can just <code>scp</code> a single file and it’s available.</p>

<p>This might be possible with C23’s <code>#embed</code>, but Rust allowed us to do it now and, overall, pretty easily.</p>

<h2 id="the-sad">The Sad</h2>

<p>The one goal of the port we did not succeed in was removing CMake.</p>

<p>That’s because, while <code>cargo</code> is great at <em>building</em> things, it is very simplistic at <em>installing</em> them. Cargo wants everything in a few neat binaries,
and that isn’t our use case. Fish has about 1200 .fish scripts (961 completions, 217 associated functions), as well as about 130 pages of documentation (as html and man pages),
and the web-config tool and the man page generator (both written in python).</p>

<p>It also has a test suite that is light on unit tests but heavy on end-to-end script and interactive tests. The scripted tests run through our own littlecheck tool,
which runs a script and compares its output to embedded comments. The interactive tests are driven by pexpect, which fakes terminal interaction and checks that the right thing happens when you press buttons.</p>

<p>We kept cmake, in a simplified form, for these tasks, but let it hand over the responsibility of <em>building</em> to cargo.</p>

<p>It would be possible to switch all that to a simpler task runner like Just or even plain old makefiles, but since we already have this system we’re keeping it for now.
The upside is that the build process hasn’t really changed for packagers.</p>

<p>We’re also losing Cygwin as a supported platform for the time being, because there is no Rust target for Cygwin and so no way to build binaries targeting it.
We hope that this situation changes in future, but we had also hoped it would improve during the almost two years of the port.
For now, the only way to run fish on Windows is to use WSL.</p>

<h2 id="the-present--the-future">The Present &amp; The Future</h2>

<p>We’ve succeeded. This was a gigantic project and <em>we made it</em>. The sheer scale of this is perhaps best expressed in numbers:</p>

<ul>
  <li>1155 files changed, 110247 insertions(+), 88941 deletions(-) (excluding translations)</li>
  <li>2604 commits by over 200 authors</li>
  <li>498 issues</li>
  <li>Almost 2 years of work</li>
  <li>57K Lines of C++ to 75K Lines of Rust <sup id="fnref:formatting"><a href="#fn:formatting" rel="footnote" role="doc-noteref">5</a></sup> (plus 400 lines of C <sup id="fnref:ccode"><a href="#fn:ccode" rel="footnote" role="doc-noteref">6</a></sup>)</li>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/10564">C++–</a></li>
</ul>

<p>The beta works very well. Performance is usually slightly better in terms of time taken, memory use has a slightly higher floor but a lower ceiling - it will use 8M instead of 7M at rest, but e.g. globbing a big directory won’t make it go up as much. These things can all be improved, of course, but for a first result it is encouraging.</p>

<p>Fish is still a bit of an odd duck…fish as a Rust program. It has some bits that smell like C spirit, directly using the C API and e.g. passing around file descriptors instead of File objects. It still uses UTF-32 strings - which is why we are using a fork of the pcre2 crate because we couldn’t convince the pcre2-crate maintainer to add UTF-32 support. We hope to find a nicer solution here, but it wasn’t necessary for the first release.</p>

<p>The port wasn’t without challenges, and it did not all go <em>entirely</em> as planned. But overall, it went pretty dang well. We’re now left with a codebase that we like a lot more, that has already gained some features that would have been much more annoying to add with C++,
with more on the way, and we did it while creating a separate 3.7 release that also included some cool stuff.</p>

<p>And we had fun doing it.</p>

<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's $475M error: the silicon behind the Pentium division bug (198 pts)]]></title>
            <link>https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</link>
            <guid>42535071</guid>
            <pubDate>Sat, 28 Dec 2024 21:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html">https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</a>, See on <a href="https://news.ycombinator.com/item?id=42535071">Hacker News</a></p>
Couldn't get https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Family of OpenAI whistleblower Suchir Balaji demand FBI investigate death (222 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</link>
            <guid>42535057</guid>
            <pubDate>Sat, 28 Dec 2024 21:46:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji">https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</a>, See on <a href="https://news.ycombinator.com/item?id=42535057">Hacker News</a></p>
Couldn't get https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Anki AI Utils (106 pts)]]></title>
            <link>https://github.com/thiswillbeyourgithub/AnkiAIUtils</link>
            <guid>42534931</guid>
            <pubDate>Sat, 28 Dec 2024 21:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/thiswillbeyourgithub/AnkiAIUtils">https://github.com/thiswillbeyourgithub/AnkiAIUtils</a>, See on <a href="https://news.ycombinator.com/item?id=42534931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Anki AI Utils</h2><a id="user-content-anki-ai-utils" aria-label="Permalink: Anki AI Utils" href="#anki-ai-utils"></a></p>
<p dir="auto">A powerful suite of AI-powered tools to enhance your <a href="https://en.wikipedia.org/wiki/Anki_(software)" rel="nofollow">Anki</a> flashcard learning experience by automatically improving cards you struggle with, tested through medical school. For example think of it like this: every time you fail a card you get a ChatGPT explanation, a Dall-E illustration, mnemonics, etc but supporting your own mnemonics.</p>
<p dir="auto"><strong>Check out my other Anki and AI related projects on my <a href="https://github.com/thiswillbeyourgithub">GitHub profile</a>!</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simple example</h3><a id="user-content-simple-example" aria-label="Permalink: Simple example" href="#simple-example"></a></p>
<p dir="auto"><strong>Those scripts make it so that every failed note will automatically have new fields containing explanations, mnemonics, and illustrations.</strong> This is done in a way that respects <strong>your own mnemonics</strong>, can even use the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">major system</a>, and has <strong>many</strong> more features.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developer's note / call for help</h2><a id="user-content-developers-note--call-for-help" aria-label="Permalink: Developer's note / call for help" href="#developers-note--call-for-help"></a></p>
<p dir="auto">This collection of scripts is the culmination of my efforts to contributes the AI features I wish existed when I started medical school. All scripts should be working but I released them hastily after documenting them heavily with the help of <a href="https://aider.chat/" rel="nofollow">aider</a>. It is possible that some aspects of the documentation is slightly off or imprecise. It is also possible that some of the scripts where slighly broken during the release process. In any case, <strong>by releasing this project made with love and care my hope is to motivate others to package it into addons.</strong> I have too little time to learn how to package those scripts into addons and make the appropriate GUI so any help is absolutely welcome.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Adaptive Learning</strong>: Uses <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> to dynamically match your cards with the most relevant examples from your training datasets. The more examples you add, the better it gets!</p>
</li>
<li>
<p dir="auto"><strong>Personalized Memory Hooks</strong>: Reuses consistent mnemonics from your custom collection, building a personalized memory system. Includes a dedicated tool to help create and manage your mnemonic library.</p>
</li>
<li>
<p dir="auto"><strong>Automation Ready</strong>: Run programmatically - for example, use cron to automatically enhance cards you struggled with yesterday, making them easier to remember through images, mnemonics, and explanations.</p>
</li>
<li>
<p dir="auto"><strong>Universal Compatibility</strong>: Modifies Anki notes directly in-place, working seamlessly across all Anki clients (Windows, Mac, Linux, Android, iOS). Extensive logging ensures you can track changes and rollback if needed.</p>
</li>
<li>
<p dir="auto"><strong>Provider Agnostic</strong>: Supports all LLM providers and models through LiteLLM, letting you choose the best option for your needs.</p>
</li>
<li>
<p dir="auto"><strong>Infinitely Extensible</strong>: Add as many examples as you want to your training datasets - the semantic filtering automatically picks the most relevant ones for each card.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator" aria-label="Permalink: Illustrator" href="#illustrator"></a></p>
<p dir="auto">Creates custom mnemonic images for your cards using AI image generation. It:</p>
<ul dir="auto">
<li>Analyzes card content to identify key concepts</li>
<li>Generates creative visual memory hooks</li>
<li>Preserves a history of generated images</li>
<li>Supports both DALL-E2, DALL-E3 and Stable Diffusion</li>
<li>Automatically formats images for optimal display (centered, proper sizing)</li>
<li>Handles multiple images per card with consistent layout</li>
</ul>
<p dir="auto">Perfect for visual learners or complex topics that benefit from imagery.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, I had this French flashcard:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever.png" alt=""></a></p>
<details>
<summary>Click here if you can't read French</summary>
<p dir="auto">Here's the note content translated to English:</p>
<div data-snippet-clipboard-copy-content="Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total"><pre><code>Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total
</code></pre></div>
</details>
<p dir="auto"><code>illustrator.py</code> generated to me this image:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever_generated.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever_generated.png" alt=""></a></p>
<p dir="auto">As well as this text content to understand its thought process: (Note that this part is always in English no matter the original language)</p>
<div data-snippet-clipboard-copy-content="Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]"><pre><code>Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]
</code></pre></div>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator" aria-label="Permalink: Reformulator" href="#reformulator"></a></p>
<p dir="auto">An intelligent tool that rephrases your flashcards while preserving their core meaning and structure. It helps when:</p>
<ul dir="auto">
<li>Cards are poorly worded or unclear</li>
<li>You want to vary the phrasing to strengthen recall</li>
<li>Cards need to be more concise or natural sounding</li>
<li>Your preferred card format has evolved over time</li>
</ul>
<p dir="auto">The tool uses LLMs to reformulate content while carefully preserving cloze deletions and media. This is especially valuable for long-term Anki users - for example, during medical school, your idea of what makes a "perfect" flashcard often evolves after a few semesters. The Reformulator lets you easily update all your older cards to match your current preferred format and style.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, given this poorly worded flashcard:</p>
<div data-snippet-clipboard-copy-content="bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}"><pre><code>bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}
</code></pre></div>
<p dir="auto">The reformulator would improve it to:</p>
<div data-snippet-clipboard-copy-content="What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}"><pre><code>What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}
</code></pre></div>
<p dir="auto">Note how the reformulation:</p>
<ul dir="auto">
<li>Makes the question grammatically complete and clear</li>
<li>Structures it as a proper question</li>
<li>Makes the answer self-contained by repeating key context</li>
<li>Preserves the exact medical terminology</li>
<li>Maintains the cloze deletion format</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator"></a></p>
<p dir="auto">Generates memorable mnemonics tailored to your cards by:</p>
<ul dir="auto">
<li>Creating multiple mnemonic options per card</li>
<li>Using proven memory techniques like the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a></li>
<li>Incorporating your existing memory anchors</li>
<li>Preserving context and accuracy</li>
</ul>
<p dir="auto">Helps create lasting memory connections, especially for numbers and sequences.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiMnemonics field:</p>
<hr>
<ol dir="auto">
<li>'Heureux Hephaistos fébrile tend sa banane unique près du feu'<br>* <b>Heureux </b> Âge supérieur à 1 an  Heureux évoque la maturité et donc un âge déjà avancé, supérieur à 1 an <br>* <b>Hephaistos fébrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  Hephaistos évoque la fièvre du fait de son rôle de forgeron et fébrile réitère ce concept <br>* <b>tend sa banane unique </b> 1 unique crise par épisode fébrile donné  banane unique évoque une seule occurrence, ici la crise unique par épisode fébrile <br>* <b>près du feu </b> Moins de 3 épisodes au total  feu évoque la fièvre et sa proximité suggère une limite, ici moins de 3 épisodes en tout <p>2.  'Un enfant trébuche dans le feu, danse symétriquement, a un seul coup et moins de trois feux'<br>* <b>Un enfant trébuche </b> Âge supérieur à 1 an  l'idée d'un enfant qui commence juste à marcher évoque l'âge juste après un an <br>* <b>dans le feu, </b> Survenue de la crise avec une fièvre supérieure à 38°C  le feu évoque la chaleur, donc la fièvre <br>* <b>danse symétriquement, </b> Manifestations motrices symétriques  danser évoque le mouvement, et symétriquement évoque les deux côtés du corps bougeant de la même manière <br>* <b>a un seul coup </b> 1 unique crise par épisode fébrile donné  un seul coup évoque l'unicité de la crise pendant l'épisode fébrile <br>* <b>et moins de trois feux </b> Moins de 3 épisodes au total  moins de trois feux évoque le nombre total d'épisodes, utilisant l'analogie avec la fièvre comme feu </p><p>3.  'Un enfant febrile symetrique forge une unique bulle dans la prairie'<br>* <b>Un enfant </b> Âge supérieur à 1 an  enfant indique que le sujet concerne un jeune individu, donc plus d'un an <br>* <b>febrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  fébrile se lie à la notion de fièvre <br>* <b>symetrique </b> Manifestations motrices symétriques  directement lié à symétrique <br>* <b>forge </b> durant moins de 15 minutes et sans déficit  forger évoque une action courte et intense, comme la crise qui dure moins de 15 minutes sans laisser de séquelles <br>* <b>une unique </b> 1 unique crise par épisode fébrile donné  unique précise le nombre de crises <br>* <b>bulle </b> Moins de 3 épisodes au total  une bulle évoque quelque chose de rare et limité, semblable à moins de 3 épisodes au total <br>* <b>dans la prairie </b> hyperthermique  la prairie évoque un espace ouvert et naturel, hyperthermique évoque la chaleur comme celle du soleil sur une prairie </p><p>[DATE:09/04/2024 VERSION:2.1 MODEL:openai/gpt-4-0125-preview]</p></li>
</ol>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Explainer</h3><a id="user-content-explainer" aria-label="Permalink: Explainer" href="#explainer"></a></p>
<p dir="auto">Provides clear, detailed explanations when you struggle with cards by:</p>
<ul dir="auto">
<li>Breaking down complex concepts</li>
<li>Highlighting key relationships</li>
<li>Adding helpful context</li>
<li>Using analogies and examples</li>
</ul>
<p dir="auto">Particularly useful for understanding why you got a card wrong and filling knowledge gaps.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiExplainer field (I translated it french to English for universal documentation):</p>
<hr>
<ul dir="auto">
<li><b>EXPLANATION</b> A simple febrile seizure is characterized by its uniqueness and brevity during a febrile episode, which helps distinguish it from complex seizures or other neurological disorders.<br>* <b>MECHANISM</b> Fever can lower the seizure threshold in certain children, which explains why an elevation in body temperature can trigger a seizure in predisposed individuals.<p>[DATE:09/04/2024 VERSION:1.7 LLMMODEL:openai/gpt-4-0125-preview]</p></li>
</ul>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Helper</h3><a id="user-content-mnemonics-helper" aria-label="Permalink: Mnemonics Helper" href="#mnemonics-helper"></a></p>
<p dir="auto">A lightweight interactive CLI tool for quick mnemonic generation that:</p>
<ul dir="auto">
<li>Takes a concept and finds semantically similar existing mnemonics</li>
<li>Generates multiple new mnemonic options using LLMs</li>
<li>Lets you choose from generated options with vim-style navigation</li>
<li>Automatically saves selected mnemonics for future reference</li>
<li>Works independently of Anki, perfect for brainstorming sessions</li>
</ul>
<p dir="auto">Unlike the Mnemonics Creator which processes Anki cards in batch, this tool provides an interactive interface for generating mnemonics one concept at a time. Those new mnemonics can automatically be added to a dataset file that can readily be used by the other tools. This allows rapidly tailoring the scripts to your own imagination.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are the core benefits of those tools?</h3><a id="user-content-what-are-the-core-benefits-of-those-tools" aria-label="Permalink: What are the core benefits of those tools?" href="#what-are-the-core-benefits-of-those-tools"></a></p>
<p dir="auto">Basically if you run these tools each evening on cards you failed that day it will steadily improve your deck quality and learning effectiveness:</p>
<ul dir="auto">
<li>Automatically enhance cards you struggle with</li>
<li>Save time on manual card improvements</li>
<li>Create stronger memory connections</li>
<li>Track improvements with detailed history</li>
<li>Preserve card structure while enhancing content</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What is the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a>?</h3><a id="user-content-what-is-the-major-system" aria-label="Permalink: What is the Major System?" href="#what-is-the-major-system"></a></p>
<p dir="auto">The Major System is a powerful memory technique that converts numbers into consonant sounds, which can then be turned into memorable words. For example:</p>
<ul dir="auto">
<li>0 = S sound (as in "sea")</li>
<li>1 = T sound (as in "tea")</li>
<li>2 = N sound (as in "new")</li>
<li>etc.</li>
</ul>
<p dir="auto">This makes it easier to remember numbers by turning them into words. For example, "92" could become "pen" (P=9, N=2).</p>
<p dir="auto">You can read more about it <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">on wikipedia</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are Memory Anchors?</h3><a id="user-content-what-are-memory-anchors" aria-label="Permalink: What are Memory Anchors?" href="#what-are-memory-anchors"></a></p>
<p dir="auto">Memory anchors are existing associations you already know well that can be used to create new memories. For example, if you already strongly associate "Napoleon" with "France", you can use Napoleon as an anchor when learning new facts about French history.</p>
<p dir="auto">The tools can use your personal set of memory anchors to generate mnemonics that build on your existing knowledge.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Which LLM providers are supported?</h3><a id="user-content-which-llm-providers-are-supported" aria-label="Permalink: Which LLM providers are supported?" href="#which-llm-providers-are-supported"></a></p>
<p dir="auto">The tools use <a href="https://docs.litellm.ai/docs/" rel="nofollow">LiteLLM</a> which provides a unified interface to virtually any LLM provider including:</p>
<ul dir="auto">
<li>OpenAI</li>
<li>Anthropic</li>
<li>Google</li>
<li>OpenRouter</li>
<li>Azure</li>
<li>AWS Bedrock</li>
<li>Local models</li>
<li>And many more</li>
</ul>
<p dir="auto">Just specify the model in LiteLLM format (e.g. "openai/gpt-4" or "anthropic/claude-3-opus") and it will handle the rest.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What languages are supported?</h3><a id="user-content-what-languages-are-supported" aria-label="Permalink: What languages are supported?" href="#what-languages-are-supported"></a></p>
<p dir="auto">The tools work in any language supported by the LLM you choose to use. Since these scripts support virtually all LLM providers through LiteLLM, you can use any model that works well with your language. For example:</p>
<ul dir="auto">
<li>OpenAI's models support 100+ languages</li>
<li>Anthropic's Claude supports 100+ languages</li>
<li>You can use local models specifically trained for your language</li>
<li>etc.</li>
</ul>
<p dir="auto">The tools will preserve all language-specific formatting, including:</p>
<ul dir="auto">
<li>Right-to-left text</li>
<li>Special characters and diacritics</li>
<li>Language-specific punctuation</li>
<li>etc.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do the Mnemonics Work?</h3><a id="user-content-how-do-the-mnemonics-work" aria-label="Permalink: How do the Mnemonics Work?" href="#how-do-the-mnemonics-work"></a></p>
<p dir="auto">The mnemonics tools use several proven memory techniques:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a> for numbers</li>
<li>Vivid imagery and visualization</li>
<li>Personal memory anchors</li>
<li>Phonetic similarities</li>
<li>Humor and absurdity</li>
<li>Story-based connections</li>
</ul>
<p dir="auto">This creates memorable associations that help strengthen recall while preserving accuracy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where can I find example datasets for each tool?</h3><a id="user-content-where-can-i-find-example-datasets-for-each-tool" aria-label="Permalink: Where can I find example datasets for each tool?" href="#where-can-i-find-example-datasets-for-each-tool"></a></p>
<p dir="auto">The <code>examples/</code> folder contains training datasets and example files for each tool. While these were originally written in French and hastily translated to English, they provide good templates for creating your own datasets. Check the Example Files section below for details on each file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the future of this project?</h3><a id="user-content-whats-the-future-of-this-project" aria-label="Permalink: What's the future of this project?" href="#whats-the-future-of-this-project"></a></p>
<p dir="auto">This toolkit was developed and battle-tested while studying tens of thousands of Anki cards during medical school. It proved invaluable for maintaining and enhancing a large flashcard collection during intense study periods.</p>
<p dir="auto">However, as research commitments have grown, I now have limited time to transform these scripts into a more user-friendly package. The tools work well but need:</p>
<ul dir="auto">
<li>Packaging as a proper Anki addon</li>
<li>Installation via PyPI</li>
<li>Code deduplication and cleanup</li>
<li>Better documentation</li>
</ul>
<p dir="auto">I'm actively looking for contributors of all skill levels to help make these tools more accessible to the wider Anki community. Whether you're a seasoned developer or just getting started, all contributions are welcome! I can provide guidance and direction based on extensive experience with the codebase, while you help with the technical aspects of packaging and distribution.</p>
<p dir="auto">Check out the detailed roadmap below to see what needs improving. If you're interested in helping transform these battle-tested scripts into a polished Anki addon, please don't hesitate to reach out - I'm always happy to chat and help you get started!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why is there code duplication across the tools?</h3><a id="user-content-why-is-there-code-duplication-across-the-tools" aria-label="Permalink: Why is there code duplication across the tools?" href="#why-is-there-code-duplication-across-the-tools"></a></p>
<p dir="auto">This project evolved organically alongside my Python skills while solving real needs during medical school. Each tool was developed independently when needed, prioritizing functionality over code elegance. While they all work reliably, there's significant opportunity to unify their codebases around a common API.</p>
<p dir="auto">I can provide detailed guidance on refactoring and consolidating the code, but lack the time to implement these changes myself. Check the roadmap below if you're interested in helping streamline the codebase while preserving its battle-tested functionality.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">When Should I Use Each Tool?</h3><a id="user-content-when-should-i-use-each-tool" aria-label="Permalink: When Should I Use Each Tool?" href="#when-should-i-use-each-tool"></a></p>
<ul dir="auto">
<li><strong>Mnemonics Creator</strong>: Best for memorizing numbers, sequences, lists, and abstract concepts</li>
<li><strong>Illustrator</strong>: Ideal for visual learners and complex topics that benefit from imagery</li>
<li><strong>Reformulator</strong>: Use when card wording is unclear or you want variety in phrasing. Don't worry about running it on well-formatted cards - the LLM is trained to recognize and preserve cards that already follow best practices, avoiding unnecessary changes that could disrupt your learning</li>
<li><strong>Explainer</strong>: Great for understanding why you got a card wrong and filling knowledge gaps</li>
<li><strong>Mnemonics Helper</strong>: Simple script to quickly ask an LLM to come up with new mnemonics by taking into accountsthe <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> of the new subject vs your previous mnemonics.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What happens if I run a script multiple times on the same card?</h3><a id="user-content-what-happens-if-i-run-a-script-multiple-times-on-the-same-card" aria-label="Permalink: What happens if I run a script multiple times on the same card?" href="#what-happens-if-i-run-a-script-multiple-times-on-the-same-card"></a></p>
<p dir="auto">For most tools (Mnemonics Creator, Illustrator, Explainer), the previous content will be preserved in a collapsible HTML section using the <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code> tags. The new content appears above this section. This makes it easy to:</p>
<ul dir="auto">
<li>See the latest generated content first</li>
<li>Access previous versions by expanding the collapsible sections</li>
<li>Track how the card evolved over time</li>
</ul>
<p dir="auto">The Reformulator works differently - it replaces the content of the original field directly, but saves all previous versions and metadata in a separate <code>AnkiReformulator</code> field. This preserves the card's readability while maintaining a complete history.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I track which cards were modified?</h3><a id="user-content-how-can-i-track-which-cards-were-modified" aria-label="Permalink: How can I track which cards were modified?" href="#how-can-i-track-which-cards-were-modified"></a></p>
<p dir="auto">Each tool meticulously tracks modifications through tags and metadata to ensure transparency and reversibility. For example, when a tool processes a card, it adds a dated tag like <code>AnkiIllustrator::done::02/07/2023</code>. This makes it easy to:</p>
<ul dir="auto">
<li>Quickly identify which cards were modified by each tool</li>
<li>Track when modifications were made</li>
<li>Find cards that haven't been processed yet</li>
<li>Rollback changes if needed (especially with the Reformulator)</li>
</ul>
<p dir="auto">You can use these tags in the Anki browser to assess how many cards could benefit from each tool and review the modifications made. Note that notes for which a script failed will have a tag added to it. For example <code>AnkiI ::failed</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How much does it cost to run these tools?</h3><a id="user-content-how-much-does-it-cost-to-run-these-tools" aria-label="Permalink: How much does it cost to run these tools?" href="#how-much-does-it-cost-to-run-these-tools"></a></p>
<p dir="auto">The cost depends on your usage patterns and which features you enable:</p>
<ul dir="auto">
<li>Start small with a few cards to get comfortable with each tool</li>
<li>Built-in safeguards prevent accidental overspending:
<ul dir="auto">
<li>Maximum cards per run can be limited</li>
<li>Cost tracking per script is stored in the database</li>
<li>Failed API calls don't count towards your quota</li>
<li>You can set hard spending limits</li>
</ul>
</li>
<li>Typical costs per card:
<ul dir="auto">
<li>Reformulator: ~$0.02-0.04 (text only)</li>
<li>Mnemonics: ~$0.02-0.04 (text only)</li>
<li>Explainer: ~$0.03-0.06 (more complex reasoning)</li>
<li>Illustrator: ~$0.02 + image cost ($0.04-0.12 per image)</li>
</ul>
</li>
</ul>
<p dir="auto">The database tracks total spending per script, making it easy to budget and monitor costs. You can also use cheaper models for initial testing before scaling up to more capable ones.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I use these tools on mobile?</h3><a id="user-content-can-i-use-these-tools-on-mobile" aria-label="Permalink: Can I use these tools on mobile?" href="#can-i-use-these-tools-on-mobile"></a></p>
<p dir="auto">While you need to run the scripts themselves from a computer (not your phone), all changes are made directly to your Anki notes. This means:</p>
<ul dir="auto">
<li>Run the scripts from your computer/server</li>
<li>Sync Anki on your computer</li>
<li>The improved cards will appear on AnkiMobile/AnkiDroid after syncing</li>
<li>All generated content (reformulations, mnemonics, images, etc.) works perfectly on mobile</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Files</h3><a id="user-content-example-files" aria-label="Permalink: Example Files" href="#example-files"></a></p>
<p dir="auto">The <code>examples/</code> folder contains example files to help you get started. Note that these examples were originally written in French (except for system prompts) and were quickly translated to English - some examples may not make perfect sense but should still demonstrate the basic usage:</p>
<ul dir="auto">
<li><code>anki_ai_utils_tmux_launcher.sh</code>: A tmux-based launcher script I used every morning to automatically process cards I struggled with the previous day</li>
<li><code>anchors.json</code>: Example memory anchors mapping file</li>
<li><code>dataset_anchors.txt</code>: Training examples for memory anchor processing</li>
<li><code>explainer_dataset.txt</code>: Examples for the Explainer tool</li>
<li><code>illustrator_dataset.txt</code>: Training data for image generation</li>
<li><code>illustrator_sanitize_dataset.txt</code>: Examples for sanitizing image prompts</li>
<li><code>mnemonics_dataset.txt</code>: Training data for mnemonic generation</li>
<li><code>reformulator_dataset.txt</code>: Examples for card reformulation</li>
<li><code>string_formatting.py</code>: Handles cloze deletions and text formatting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the format of dataset files?</h3><a id="user-content-whats-the-format-of-dataset-files" aria-label="Permalink: What's the format of dataset files?" href="#whats-the-format-of-dataset-files"></a></p>
<p dir="auto">Dataset files (like <code>explainer_dataset.txt</code>, <code>reformulator_dataset.txt</code>, etc.) are simple text files where messages are separated by <code>----</code>. The first message is assumed to be a system prompt, followed by alternating user and assistant messages. This format mirrors a typical LLM conversation flow while remaining easy to read and edit.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Reformulator</h4><a id="user-content-reformulator-1" aria-label="Permalink: Reformulator" href="#reformulator-1"></a></p>
<p dir="auto">The Reformulator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python reformulator.py \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/reformulator_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --main_field_index 0 \
    --llm &quot;openai/gpt-4&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --max_token 4000 \
    --llm_temp 0"><pre>python reformulator.py \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/reformulator_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --main_field_index 0 \
    --llm <span><span>"</span>openai/gpt-4<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --max_token 4000 \
    --llm_temp 0</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for reformulation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>main_field_index</code>: Index of the field to reformulate (0 for first field)</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>max_token</code>: Maximum tokens per query</li>
<li><code>llm_temp</code>: LLM temperature (0 for consistent output)</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if already reformulated</li>
<li><code>--print_db_then_exit</code>: Display database contents and exit</li>
<li><code>--parallel</code>: Number of parallel processes (default 4)</li>
<li><code>--exclude_media</code>: Skip cards containing media</li>
<li><code>--mode</code>: Either 'reformulate' or 'reset' to restore original content. Note that the 'reset' feature is not absolutely guaranteed to work, but if things go wrong there are tons of logs on purpose to make sure you don't lose anything.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics</h4><a id="user-content-mnemonics" aria-label="Permalink: Mnemonics" href="#mnemonics"></a></p>
<p dir="auto">The Mnemonics Creator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/mnemonics_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --n_mnemonic 1"><pre>python mnemonics.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/mnemonics_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --n_mnemonic 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for mnemonic generation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>n_mnemonic</code>: Number of mnemonics to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have mnemonics</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics Creator CLI</h4><a id="user-content-mnemonics-creator-cli" aria-label="Permalink: Mnemonics Creator CLI" href="#mnemonics-creator-cli"></a></p>
<p dir="auto">The Mnemonics Creator CLI provides an interactive interface for generating mnemonics:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embed_model &quot;openai/text-embedding-3-small&quot;"><pre>python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embed_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span></pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>top_k</code>: Number of similar existing mnemonics to use as examples (default: 100)</li>
<li><code>n_gen</code>: Number of new mnemonics to generate per query (default: 10)</li>
<li><code>model</code>: LLM model to use in litellm format</li>
<li><code>embed_model</code>: Model for semantic similarity search</li>
<li><code>query</code>: Optional initial query to process</li>
<li><code>gui</code>: Enable GUI interface (not yet implemented)</li>
</ul>
<p dir="auto">The CLI provides an interactive interface where you can:</p>
<ul dir="auto">
<li>Enter concepts to generate mnemonics for</li>
<li>See similar existing mnemonics as context</li>
<li>Choose from multiple generated options</li>
<li>Navigate with vim-style keys (j/k) or numbers</li>
<li>Save selected mnemonics to your collection</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Explainer</h4><a id="user-content-explainer-1" aria-label="Permalink: Explainer" href="#explainer-1"></a></p>
<p dir="auto">The Explainer can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python explainer.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/explainer_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --llm_max_token 3000"><pre>python explainer.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/explainer_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --llm_max_token 3000</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for generating explanations</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>llm_max_token</code>: Maximum tokens per query</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have explanations</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Illustrator</h4><a id="user-content-illustrator-1" aria-label="Permalink: Illustrator" href="#illustrator-1"></a></p>
<p dir="auto">The Illustrator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python illustrator.py \
    --field_names &quot;front,back&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/illustrator_dataset.txt&quot; \
    --dataset_sanitize_path &quot;data/illustrator_sanitize.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --n_image 1"><pre>python illustrator.py \
    --field_names <span><span>"</span>front,back<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/illustrator_dataset.txt<span>"</span></span> \
    --dataset_sanitize_path <span><span>"</span>data/illustrator_sanitize.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --n_image 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for image generation</li>
<li><code>dataset_sanitize_path</code>: Examples for sanitizing unsafe prompts</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>n_image</code>: Number of images to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have illustrations</li>
<li><code>--disable_notif</code>: Disable ntfy.sh notifications</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Roadmap</h3><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><i>This TODO list is maintained automatically by <a href="https://github.com/thiswillbeyourgithub/MdXLogseqTODOSync">MdXLogseqTODOSync</a></i></p>

<ul dir="auto">
<li>turn those scripts into addons</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Applies to all tools</h3><a id="user-content-applies-to-all-tools" aria-label="Permalink: Applies to all tools" href="#applies-to-all-tools"></a></p>
</li>
<li>use beartype everywhere</li>
<li>add an arg to include tags or not in the LLM context for a given note, as otherwise the LLM can get confused by some acronyms
<ul dir="auto">
<li>but with a regex arg to keep only the tags that match the regex. This way we can keep only a portion of them for the LLM</li>
</ul>
</li>
<li>store all inference in a compressed sqlite db instead of a json. It gets too large</li>
<li>add check that we indeed removed all the done tags</li>
<li>actually there's no need to store the "Done" tags because all important info is stored in the field</li>
<li>use xml formatting for the examples
<ul dir="auto">
<li>make use of  tags too</li>
</ul>
</li>
<li>make it installable with a setup.py on pypi</li>
<li>add images to illustrate the benefits of using each</li>
<li>do a unique class that could be used to unify all those codes
<ul dir="auto">
<li>arguments:
<ul dir="auto">
<li>name (to differentiate each children: for example "illustrator")</li>
<li>string_format (can be overloaded)</li>
<li>in the init, check that indeed there is a version attribute</li>
</ul>
</li>
</ul>
</li>
<li>use toml instead of json, it allows setting comments too</li>
<li>tell user how much time each answer took</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator-1" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator-1"></a></p>
<ul dir="auto">
<li>Add keybindings
<ul dir="auto">
<li>binding e to edit a proposition</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator-2" aria-label="Permalink: Illustrator" href="#illustrator-2"></a></p>
</li>
<li>use an llm to extract numbers
<ul dir="auto">
<li>ask it to do quick transformations like turn 48h into 2 days, modify units, etc,</li>
</ul>
</li>
<li>add support for note containing media like audio, images etc</li>
<li>add a mode without actually creating images. This could be used like a mnemonics after all.</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator-2" aria-label="Permalink: Reformulator" href="#reformulator-2"></a></p>
</li>
<li>Add 5 to 10 example for the LLM of how to manage media like iimages etc then add support for them</li>
<li>make it work with specific fstring template for field replacement. Otherwise it can only reformulate a single field
<ul dir="auto">
<li>better: add an arg to specify the single output field, and an arg to specify a comma separated list of input fields</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">explainer</h3><a id="user-content-explainer-2" aria-label="Permalink: explainer" href="#explainer-2"></a></p>
</li>
<li>compute all embeddings at the start, making it faster</li>
<li>it's actually quite terrible. Use one LLM call to ask for which follow up questions to ask, then another LLM call to answer each using async
<ul dir="auto">
<li>save each new question answer as a <details> tag to make it easy to access on phones by touching the field</details></li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ankimnemonics</h3><a id="user-content-ankimnemonics" aria-label="Permalink: Ankimnemonics" href="#ankimnemonics"></a></p>
</li>
<li>comment out the mnemonics that dont respect the rule of adding the subject first</li>
<li>understand why it sometimes hangs during a run</li>
<li>make it distinguish 'has to appear in plain' vs 'has to appear as mnemonic'?</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">AnkiAiFilter</h3><a id="user-content-ankiaifilter" aria-label="Permalink: AnkiAiFilter" href="#ankiaifilter"></a></p>
</li>
<li>use an eval llm like in <a href="https://wdoc.readthedocs.io/en/latest/" rel="nofollow">wdoc</a> to better filer an anki query
<ul dir="auto">
<li>actually wdoc can already be used for that! Maybe it should be converted into an addon?</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tagger (In project)</h2><a id="user-content-tagger-in-project" aria-label="Permalink: Tagger (In project)" href="#tagger-in-project"></a></p>
</li>
<li>always prepend tags by ankitagger: but customizable</li>
<li>always sort those tags by alphabetical order</li>
<li>add modes:
<ul dir="auto">
<li>mode "predefined": the user gives a list of tags and the LLM finds which to apply to each note given a query
<ul dir="auto">
<li>loop over each note and ask it to generate tags</li>
</ul>
</li>
</ul>
</li>
<li>arg for image support if media found
<ul dir="auto">
<li>if the card contains an image, it should be hashed, then a cached call to a func that asks a vision model to describe the type of image, then use the embedding of this answer to suggest the appropriate tags to suggest to the LLM for classification</li>
</ul>
</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">This project makes heavy use of <a href="https://git.foosoft.net/alex/anki-connect" rel="nofollow">AnkiConnect</a> to interact with Anki.</p>
</details>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU law mandating universal chargers for devices comes into force (173 pts)]]></title>
            <link>https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</link>
            <guid>42534851</guid>
            <pubDate>Sat, 28 Dec 2024 21:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force">https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</a>, See on <a href="https://news.ycombinator.com/item?id=42534851">Hacker News</a></p>
Couldn't get https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Photos phones home on iOS 18 and macOS 15 (600 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2024/12/3.html</link>
            <guid>42533685</guid>
            <pubDate>Sat, 28 Dec 2024 19:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2024/12/3.html">https://lapcatsoftware.com/articles/2024/12/3.html</a>, See on <a href="https://news.ycombinator.com/item?id=42533685">Hacker News</a></p>
Couldn't get https://lapcatsoftware.com/articles/2024/12/3.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Google's Results Are Infested, Open AI Is Using Their Playbook from the 2000s (391 pts)]]></title>
            <link>https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</link>
            <guid>42532441</guid>
            <pubDate>Sat, 28 Dec 2024 17:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook">https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</a>, See on <a href="https://news.ycombinator.com/item?id=42532441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You know when you go on a picnic, sometimes there's a fly that decides to join you.</p>
<p>You wave your hand to shoo it away from the tasty lunch you're about to enjoy and think nothing more of it.</p>
<p>But it returns, only for you to swipe again, and that tinge of frustration starts to bloom. It returns, and now your lunch is no longer the focus, but this annoying fly whose buzzing is now an obstacle to a perfectly nice picnic.</p>
<h2>The 2000s were a picnic</h2>
<p>When Google came onto the scene, I credit its success to the tried and true paradigm that makes companies successful: <strong>simple and easy to use</strong>.</p>
<p>Yahoo was dominant back then, and it tried to put everyone and everything in front of you. Then we learned about the paralysis of choice. Too many choices, the mental fatigue weighed in, and the product became difficult to use.</p>
<p><img src="https://chuckwnelson.com/images/yahoo-vs-google.jpg" alt="Yahoo vs Google"></p>
<p>Enter Google, and it was <strong>Feeling Lucky</strong>. Just a search input, logo, and some minor text. The next step was clear. And the search results were a simple list. Sequential to avoid mental fatigue, and just enough description to make an informed choice.</p>
<p><img src="https://chuckwnelson.com/images/google-serp.jpg" alt="Trustworthy Google"></p>
<p>Then a fly came buzzing to the picnic.</p>
<h2>Enter the buzz</h2>
<p>Google added advertising. Their first iteration was clearly marked and outside the search list. Trust in the organic results mattered to Google, and it would be off-brand to show you could pay to be at the top of that list.</p>
<p>And even these ads weren't that bad. What made Google successful was showing ads you wanted to see. I'm searching for a bottle of wine, and ads for bottles of wine were shown to me. This is okay because it's not interrupting the picnic. Google's success is from active intent advertising.</p>
<p>But then ads were placed over search results, still clearly marked, but pushing down organic results. Buzz.</p>
<p>Then the SEO industry got its footing. Organic results are now optimized advertorials, or aggregation websites like Yelp and Pinterest, which have their own ad models.</p>
<p>It's a layer cake of ads all the way down the list.</p>
<p>Google lost its credibility.</p>
<h2>Google is infested with these little annoyances</h2>
<p>Enter 2024 with AI. The top 20% of search results are a wall of text from AI, then a Google product such as maps or shopping listings (with ads), then search ads, then YouTube videos, then search results (hidden ads), then some sprinkling of what you are looking for.</p>
<p>I don't want to watch a 10-minute video for a quick answer.</p>
<p>No longer can you flip back and forth from search results quickly to find the answer.</p>
<p>You need a machete to cut through the visual noise in order to find even a website that may have your lunch.</p>
<p>We are back to Yahoo in the 2000s, choice paralysis, visual clutter, and no trust in the results I do see.</p>
<p>I'm no longer feeling lucky.</p>
<p><img src="https://chuckwnelson.com/images/google-serp-today.jpg" alt="Google Search Results Today"></p>
<h2>OpenAI's search is becoming Google in the 2000s, if it can remain trustworthy.</h2>
<p>Open AI's ChatGPT search results have entered the scene. It's not perfect, but it's not Google.</p>
<p>The visual clutter is not there because it's a conversation, not a list. It's one answer instead of 10.</p>
<p>It's active intent searching, the thing that made Google successful. Plus, it's conversational. We are trained monkeys to be able to keep asking questions, with the context of the information that came before. It's simple because we are use to it.</p>
<p><strong>Active intent conversations</strong> is just a overly fancy way to say "recommendations." Just like a friend would recommend a restaurant to you based on what you ask for. But we trust our friends.</p>
<p><img src="https://chuckwnelson.com/images/openai-serp.jpg" alt="Open AI Search Results"></p>
<p>Does ChatGPT Search have trust? Open AI isn't monetizing its search just yet, but AI has its own issues with hallucinations.</p>
<p>If Open AI can build its brand and its trust with the consumer, it can dethrone the king.</p>
<p>They know this is important as well. Their website is littered with media quotes stating <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT's search</a> links to trustworthy sources, and bringing premium journalism.</p>
<p>This is the fork in the road. There are entire industries waiting to see the direction this goes in. If Open AI goes the way of Google with tons of choices and mental fatigue, it can still be successful, but will be battling to be king of the hill.</p>
<p>But if it can keep it simple <strong>and trustworthy</strong>, it can own the most valuable digital real estate as the sidekick with the single answer.</p>
<p>Google is losing trust with all these buzzing results, and its answer is to throw more spaghetti at the wall to see what sticks. But this just attracts more problems.</p>
<p>In order for Google to keep its crown, it needs to remember what it was in the 2000s and a bit of luck.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. homelessness jumps to record high amid affordable housing shortage (105 pts)]]></title>
            <link>https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</link>
            <guid>42532311</guid>
            <pubDate>Sat, 28 Dec 2024 16:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants">https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</a>, See on <a href="https://news.ycombinator.com/item?id=42532311">Hacker News</a></p>
Couldn't get https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Are you unable to find employment? (244 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42531830</link>
            <guid>42531830</guid>
            <pubDate>Sat, 28 Dec 2024 15:48:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42531830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="42531830">
      <td><span></span></td>      <td><center><a id="up_42531830" href="https://news.ycombinator.com/vote?id=42531830&amp;how=up&amp;goto=item%3Fid%3D42531830"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=42531830">Ask HN: Are you unable to find employment?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_42531830">117 points</span> by <a href="https://news.ycombinator.com/user?id=w4ffl35">w4ffl35</a> <span title="2024-12-28T15:48:02 1735400882"><a href="https://news.ycombinator.com/item?id=42531830">3 hours ago</a></span> <span id="unv_42531830"></span> | <a href="https://news.ycombinator.com/hide?id=42531830&amp;goto=item%3Fid%3D42531830">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Are%20you%20unable%20to%20find%20employment%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=42531830&amp;auth=53e534d335780effb0dc1b295eec39a0de8d5081">favorite</a> | <a href="https://news.ycombinator.com/item?id=42531830">136&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I am seeing many anecdotal experiences shared online on various platforms stating that it is difficult to find employment in tech. I myself have had a difficult time landing an interview over the last year despite having two decades of experience.</p><p>I am attempting to gain some insight into the issue. My situation is somewhat unique in that I am self-taught without a CS degree. I'm a very experienced, diligent worker, etc, but an algorithm doesn't care about this and so getting through the filters is difficult.</p><p>However I see many discussions being posted (primarily on X) stating that it is nearly impossible for people with CS degrees (especially white males) to get an interview let alone a job. There have been mass layoffs, less money being invested etc. 
Many people have claimed AI is taking jobs, or that there aren't as many jobs available, yet at the same time, Elon Musk and others claim there is an engineer shortage and we must increase the number of H-1B visas in order to fill this gap. When I apply to a position on linkedin I can see that even the most Jr positions have over 100 applicants.</p><p>I know that X can be slanted, and really anything posted online must be taken with a grain of salt - but I'm seeing many people claiming to be in the same situation as myself, and most of them claim to be white males.</p><p>Furthermore, in the last two years I experienced two layoffs. In both situations it was white males let go in favor of Indian and KZ foreigners. Again - this is anecdotal and could be a coincidence, but its awfully telling that Vivek and Elon are calling American tech workers uncultured, lazy and stupid in the wake of these experiences and those that I've read about online.</p><p>I don't want to start a war here on hackernews, but I'm looking for people's personal experiences. Do they match up? Are you having a hard time finding employment? Have you been fired in favor of foreign workers? Is this racism / ageism / sexism at play or is that being overblown by political actors?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Automated My Job Application Process (356 pts)]]></title>
            <link>https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</link>
            <guid>42531695</guid>
            <pubDate>Sat, 28 Dec 2024 15:26:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1">https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</a>, See on <a href="https://news.ycombinator.com/item?id=42531695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>Look, I'll be honest - job hunting sucks.</p>
<p>It's this soul-crushing cycle of copying and pasting the same information over and over again, tweaking your resume for the 100th time, and writing cover letters that make you sound desperate without actually sounding desperate.</p>
<p>But here's the thing: repetitive tasks + structured process = perfect automation candidate.</p>
<p>So I did what any sane developer would do - I built a system to automate the whole damn thing. By the end, I had sent out 250 job applications in 20 minutes. (The irony? I got a job offer before I even finished building it. More on that later.)</p>
<p>Let me walk you through how I did it.</p>
<h2 id="heading-the-job-application-process-is-broken">The Job Application Process is Broken</h2>
<p>Think about it - every job application follows the same basic pattern:</p>
<ol>
<li><p>Find job posting</p>
</li>
<li><p>Check if you're qualified</p>
</li>
<li><p>Research company (let's be real, most people skip this)</p>
</li>
<li><p>Submit resume + cover letter</p>
</li>
<li><p>Wait... and wait... and wait...</p>
</li>
</ol>
<p>It's like a really boring video game where you do the same quest over and over, hoping for different results.</p>
<h2 id="heading-building-the-proof-of-concept">Building the Proof of Concept</h2>
<p>I started by writing some quick Python scripts to test if this crazy idea could work. Here's how I broke it down:</p>
<h3 id="heading-step-1-getting-the-job-listings-the-manual-part">Step 1: Getting the Job Listings (The Manual Part)</h3>
<p>First challenge: getting job listings at scale. I tried web scraping but quickly realized something: job boards are like snowflakes - each one is uniquely annoying to scrape.</p>
<p>I tested dumping entire web pages into an LLM to clean the data, but:</p>
<ul>
<li><p>It was expensive as hell</p>
</li>
<li><p>I didn't want the AI hallucinating job requirements (imagine explaining that in an interview)</p>
</li>
</ul>
<p>So I went old school - manual HTML copying. Yes, it's primitive. Yes, it works. Sometimes the simplest solution is the best solution.</p>
<h3 id="heading-step-2-cleaning-the-raw-html">Step 2: Cleaning the Raw HTML</h3>
<p>The raw HTML was a mess, but I needed structured data like this:</p>
<pre><code>{
    <span>"job_link"</span>: <span>"https://example.com/job/12345"</span>,
    <span>"job_id"</span>: <span>"12345"</span>,
    <span>"job_role"</span>: <span>"software developer"</span>,
    <span>"employer"</span>: <span>"Tech Corp Inc"</span>,
    <span>"location"</span>: <span>"San Francisco, CA"</span>,
    <span>"work_arrangement"</span>: <span>"Remote"</span>,
    <span>"salary"</span>: <span>"$150,000"</span>
}
</code></pre>
<p>Pro tip: You can just show ChatGPT a sample of your HTML and the output format you want, and it'll write the parsing script for you. Work smarter, not harder.</p>
<h3 id="heading-step-3-getting-the-full-job-details">Step 3: Getting the Full Job Details</h3>
<p>This part was straightforward but required some finesse. For each job listing, I made a GET request to fetch the full description. Each request returns raw HTML that still has all the website scaffolding - navigation bars, popups, footer junk, the works.</p>
<p>I wrote a simple HTML parser to strip out everything except the actual job description. Sometimes you'll hit extra hurdles - like having to click a button to reveal the recruiter's email or company details. The good news? Since you're working with one job board at a time, you only need to figure out these patterns once.</p>
<p>Pro tip: Always add delays between requests. I set mine to 2-3 seconds. Sure, it makes the process slower, but it's better than getting your IP banned. Don't be that person who DDOSes job boards - I added delays between requests because I'm not a monster.</p>
<h3 id="heading-step-4-converting-raw-html-to-structured-data">Step 4: Converting Raw HTML to Structured Data</h3>
<p>This is where it gets interesting. Job postings are like people - they all have the same basic parts but the organization is chaos. Some list skills at the top, others bury them in paragraphs of corporate speak.</p>
<p>Enter the LLM prompt that saved my sanity:</p>
<pre><code><span>const</span> prompt = <span>`Please analyze these HTML contents from a job posting and extract information into a structured JSON format.

[... HTML content ...]

Format the response as valid JSON object with these exact keys:
- contact_email
- application_instructions
- job_posting_text (in markdown)
- job_posting_link
- additional_info (salary, location, etc.)
- job_title
- job_company
- job_department
- job_location
- job_skills
- job_instructions (how to apply)

optional keys

- hiring_manager_name
- 
- job_portal
`</span>
</code></pre>
<h3 id="heading-step-5-generating-cover-letters-that-dont-suck">Step 5: Generating Cover Letters That Don't Suck</h3>
<p>The secret to good cover letters? Context. I fed my resume into the LLM along with the job details. This way, the AI could match my experience with their requirements. Suddenly, those "I'm excited about this opportunity" letters actually had substance.</p>
<p>Here's the prompt that made it happen:</p>
<pre><code><span>const</span> prompt = <span>`Please help me write a professional job application email based on the following information:

=== MY RESUME ===
<span>${resumeMarkdown}</span>

=== JOB DETAILS ===
Job Title: <span>${job_title}</span>
Company: <span>${job_company}</span>
Department: <span>${job_department || <span>''</span>}</span>
Location: <span>${job_location || <span>''</span>}</span>
Job Description: <span>${job_posting_text }</span>
Required Skills: <span>${job_skills?.join(<span>', '</span>) || <span>''</span>}</span>
Application Instructions: <span>${job_instructions || <span>''</span>}</span>

Additional Context:
- Hiring Manager Name: <span>${hiring_manager_name || <span>''</span>}</span>
- Referral Source: <span>${referral_source || <span>'Job board'</span>}</span>
- Application Portal: <span>${job_portal || <span>''</span>}</span>

Instructions:
1. Create an email that is ready to send without any placeholders or edits needed
2. If any critical information is missing (like company name or job title), respond with an error message instead of generating incomplete content
3. Skip any optional fields if they're empty rather than including placeholder text
4. Use natural sentence structure instead of obvious template language
5. Include specific details from both the resume and job description to show genuine interest and fit
6. Any links or contact information should be properly formatted and ready to use

Format the response as a JSON object with these keys:
{
  "status": "success" or "error",
  "error_message": "Only present if status is error, explaining what critical information is missing",
  "email": {
    "subject": "The email subject line",
    "body_html": "The email body in HTML format with proper formatting",
    "body_text": "The plain text version of the email",
    "metadata": {
      "key_points_addressed": ["list of main points addressed"],
      "skills_highlighted": ["list of skills mentioned"],
      "resume_matches": ["specific experiences/skills from resume that match job requirements"],
      "missing_recommended_info": ["optional fields that were missing but would strengthen the application if available"],
      "tone_analysis": "brief analysis of the email's tone"
    }
  }
}

Critical required fields (will return error if missing):
- Job title
- Company name
- Job description
- Resume content

Recommended but optional fields:
- Hiring manager name
- Department
- Location
- Application instructions
- Referral source
- Required skills list

Please ensure all HTML in body_html is properly escaped for JSON and uses only basic formatting tags (p, br, b, i, ul, li) to ensure maximum email client compatibility.
`</span>
</code></pre>
<p>The prompt does a few clever things:</p>
<ol>
<li><p>Forces structured output - no wishy-washy responses</p>
</li>
<li><p>Tracks which of your skills match the job requirements</p>
</li>
<li><p>Identifies any missing info that could strengthen the application</p>
</li>
<li><p>Generates both HTML and plain text versions (because some job portals hate formatting)</p>
</li>
</ol>
<p>And here's the kicker - it fails fast if critical info is missing. No more generic "I saw your job posting" emails. Either the cover letter has substance, or it doesn't get sent. Period.</p>
<p>(I start all all my prompts with ‘please’, so that when AI eventually takes over, they would consider me friendly 😁)</p>
<h3 id="heading-step-6-sending-the-emails-the-moment-of-truth">Step 6: Sending the Emails (The Moment of Truth)</h3>
<p>Last step - actually sending these beautifully crafted applications. Sounds simple, right? Just hook up an email service and blast away?</p>
<p>Not so fast. I needed a way to:</p>
<ul>
<li><p>Send professional-looking emails</p>
</li>
<li><p>Track what was actually sent</p>
</li>
<li><p>Monitor responses (can't ghost the recruiters)</p>
</li>
<li><p>Not get flagged as spam (crucial!)</p>
</li>
</ul>
<p>For testing, I sent all emails to a test account first. Pro tip: when you do send to actual recruiters, BCC yourself. Nothing worse than wondering "did that email actually go through?"</p>
<p>At this stage of the POC, I just used a simple email provider like Mailgun. Quick, dirty, but effective. Don't worry - in Part 2, I'll tell you about the rabbit hole I went down trying to build a full email management system. (Spoiler: it involves rejected AWS applications and a failed attempt at running my own email server. Good times.)</p>
<h2 id="heading-the-results">The Results</h2>
<p>The proof of concept worked better than expected. I could take a job board, extract listings, parse them, and generate personalized applications - all with a few Python scripts.</p>
<p>But this was just the beginning. The real challenge? Turning these scripts into a proper application that could:</p>
<ul>
<li><p>Handle multiple job boards</p>
</li>
<li><p>Track applications</p>
</li>
<li><p>Manage email responses</p>
</li>
<li><p>Not get me blacklisted from every HR system in existence</p>
</li>
</ul>
<p>In Part 2, I'll show you how I built the actual application, complete with all the technical decisions, trade-offs, and "what was I thinking" moments.</p>
<p>Stay tuned - it gets even better.</p>
<hr>
<p><em>Want to know when Part 2 drops? Follow me on</em> <a target="_blank" href="https://x.com/DavidDodda_"><em>Twitter</em></a> <em>or</em> <a target="_blank" href="https://www.linkedin.com/in/arundavidreddy/"><em>LinkedIn</em></a><em>. And yes, I'll eventually tell you how I got a job offer before finishing this project. It's a good story.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf 2024 Notes (268 pts)]]></title>
            <link>https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</link>
            <guid>42531217</guid>
            <pubDate>Sat, 28 Dec 2024 14:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sachachua.com/blog/2024/12/emacsconf-2024-notes/">https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</a>, See on <a href="https://news.ycombinator.com/item?id=42531217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    <nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav><article id="index0">
<header>
Posted: <time>Dec 27, 2024</time> - Modified: <time>Dec 28, 2024</time>| <span><a href="https://sachachua.com/blog/category/emacs">emacs</a>, <a href="https://sachachua.com/blog/category/emacsconf">emacsconf</a></span>
</header>
<div>
<p>
<span><span>[2024-12-28 Sat]</span></span>: Added talk and Q&amp;A count, added note about BBB max simultaneous users, added note about BBB, added thanks
</p>

<p>
<a href="https://emacsconf.org/2024/talks">The videos have been uploaded</a>, thank-you notes
have been sent, and the kiddo has decided to play
a little Minecraft on her own, so now I get to
write some quick notes on <a href="https://emacsconf.org/2024">EmacsConf 2024</a>.
</p>


<div id="outline-container-emacsconf-2024-notes-stats">
<h2 id="emacsconf-2024-notes-stats">Stats</h2>
<div id="text-emacsconf-2024-notes-stats">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Talks</td>
<td>31</td>
</tr>

<tr>
<td>Hours</td>
<td>10.7</td>
</tr>

<tr>
<td>Q&amp;A web conferences</td>
<td>21</td>
</tr>

<tr>
<td>Hours</td>
<td>7.8</td>
</tr>
</tbody>
</table>


<ul>
<li>Saturday:
<ul>
<li>gen: 177 peak + 14 peak lowres</li>
<li>dev: 226 peak + 79 peak lowres</li>
</ul></li>
<li>Sunday:
<ul>
<li>gen: 89 peak + 10 peak lowres</li>
</ul></li>
</ul>

<p>
Server configuration:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>meet</td>
<td>16GB 8core dedicated</td>
<td>peak 409% CPU (100% is 1 CPU), average 69.4%</td>
</tr>

<tr>
<td>front</td>
<td>32GB 8core shared</td>
<td>peak 70.66% CPU (100% is 1 CPU)</td>
</tr>

<tr>
<td>live</td>
<td>64GB 16core shared</td>
<td>peak 552% CPU (100% is 1 CPU) average 144%</td>
</tr>

<tr>
<td>res</td>
<td>46GB 12core</td>
<td>peak 81.54% total CPU (100% is 12 CPUs); each OBS ~250%), mem 7GB used</td>
</tr>

<tr>
<td>media</td>
<td>3GB 1core</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>

<p>
YouTube livestream stats:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Shift</th>
<th scope="col">Peak</th>
<th scope="col">Avg</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gen Sat AM</td>
<td>46</td>
<td>28</td>
</tr>

<tr>
<td>Gen Sat PM</td>
<td>24</td>
<td>16</td>
</tr>

<tr>
<td>Dev Sat AM</td>
<td>15</td>
<td>7</td>
</tr>

<tr>
<td>Dev Sat PM</td>
<td>20</td>
<td>12</td>
</tr>

<tr>
<td>Gen Sun AM</td>
<td>28</td>
<td>17</td>
</tr>

<tr>
<td>Gen Sun PM</td>
<td>26</td>
<td>18</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-timeline">
<h2 id="emacsconf-2024-notes-timeline">Timeline</h2>
<div id="text-emacsconf-2024-notes-timeline">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Call for proposals</td>
<td><span><span>[2024-06-30 Sun]</span></span></td>
</tr>

<tr>
<td>CFP deadline</td>
<td><span><span>[2024-09-20 Fri]</span></span></td>
</tr>

<tr>
<td>Speaker notifications</td>
<td><span><span>[2024-09-27 Fri]</span></span></td>
</tr>

<tr>
<td>Publish schedule</td>
<td><span><span>[2024-10-25 Fri]</span></span></td>
</tr>

<tr>
<td>Video target date</td>
<td><span><span>[2024-11-08 Fri]</span></span></td>
</tr>

<tr>
<td>EmacsConf</td>
<td><span><span>[2024-12-07 Sat]</span></span>-<span><span>[2024-12-07 Sat]</span></span></td>
</tr>
</tbody>
</table>

<p>
We did early acceptances again this year. That was
nice. I wasn't sure about committing longer
periods of time early in the scheduling process,
so I usually tried to nudge people to plan a
20-minute video with the option of possibly doing
more, and I okayed longer talks once we figured
out what the schedule looked like.
</p>

<p>
There were 82 days between the call for proposals
and the CFP deadline, another 49 days from that to
the video target date, and 29 days between the
video target date and EmacsConf. It felt like
there was a good amount of time for proposals and
videos. Six videos came in before or on the target
date. The rest trickled in afterwards, which was
fine because we wanted to keep things low-pressure
for the speakers. We had enough capacity to
process and caption the videos as they came in.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-data">
<h2 id="emacsconf-2024-notes-data">Data</h2>
<div id="text-emacsconf-2024-notes-data">
<p>
We continued to use an Org file to store the talk information.
It would be great to add some validation functions:
</p>

<ul>
<li>Check permissions and ownership for files</li>
<li>Check case sensitivity for Q&amp;A type detection</li>
<li>Check BBB redirect pages to make sure they exist</li>
<li>Check transcripts for ` because that messes up formatting;
consider escaping for the wiki</li>
<li>Check files are public and readable</li>
<li>Check captioned by comment vs caption status vs captioner</li>
</ul>

<p>
Speakers uploaded their files via <a href="https://github.com/psi-4ward/psitransfer">PsiTransfer</a>
again. I didn't get around to setting up the FTP
server. I should probably rename
ftp-upload.emacsconf.org to upload.emacsconf.org
so that people don't get confused.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-communication">
<h2 id="emacsconf-2024-notes-communication">Communication</h2>
<div id="text-emacsconf-2024-notes-communication">
<p>
As usual, we announced the EmacsConf call for
proposals on <a href="https://lists.gnu.org/archive/html/emacs-tangents/2024-06/msg00004.html">emacs-tangents</a>, <a href="https://sachachua.com/blog/2024/07/2024-07-01-emacs-news/">Emacs News</a>,
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a>, <a href="https://lists.gnu.org/archive/html/emacsconf-org/2024-06/msg00000.html">emacsconf-org</a>,
<a href="https://reddit.com/r/emacs">https://reddit.com/r/emacs</a>. <a href="https://systemcrafters.net/live-streams/july-12-2024/">System Crafters</a>,
<a href="https://irreal.org/blog/?p=12280">Irreal</a>, and <a href="https://emacs-apac.gitlab.io/announcements/november-2024/">Emacs APAC</a>, mentioned it, and people
also posted about EmacsConf on <a href="https://mastodon.social/tags/emacsconf">Mastodon</a>, <a href="https://x.com/search?q=%23emacsconf&amp;src=typed_query&amp;f=live">X</a>,
<a href="https://bsky.app/hashtag/emacsconf">BlueSky</a>, and <a href="https://www.facebook.com/story.php?story_fbid=538504738701826&amp;id=100076269125316&amp;_rdr">Facebook</a>. <a href="https://toot.si/@len/113392360015917614">@len@toot.si suggested</a>
submitting EmacsConf to <a href="https://foss.events/">https://foss.events</a>, so I
did. There was some other <a href="https://www.reddit.com/r/emacs/comments/1h5c778/which_emacsconf_2024_talks_have_your_attention/">EmacsConf-related
discussions</a> in r/emacs. <a href="https://200ok.ch/posts/2024-09-16_announcing_emacsconf__official_swiss_satellite.html">200ok and Ardeo</a> organized
an in-person meetup in Switzerland, and <a href="https://dogodki.kompot.si/events/00a6f9ee-9087-400d-9d9b-d51b98561424">emacs.si got together in Ljubljana</a>.
</p>

<p>
For communicating with speakers and volunteers, I
used lots of mail merge
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-mail.el">emacsconf-mail.el</a>). Most of the
templates only needed a little tweaking from last
year's code. I added a function to help me
double-check delivery, since the batches that I
tried to send via async sometimes ran into errors.
</p>

<p>
Next time, I think it could be interesting to add
more blog posts and Mastodon toots.
</p>

<p>
Also, maybe it would be good to get in touch with podcasts like
</p>

<ul>
<li><a href="https://systemcrafters.net/">System Crafters</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLbFVcOQ-YH_LRP687N0YeN78YZmBp5wqF">This Week in Linux</a></li>
<li><a href="https://linuxunplugged.com/">Linux Unplugged</a></li>
<li><a href="http://asknoahshow.com/">Ask Noah</a></li>
<li><a href="https://linuxafterdark.net/">Linux After Dark</a></li>
<li><a href="https://anonradio.net/">Lispy Gopher Show</a></li>
</ul>

<p>
to give a heads up on EmacsConf before it
happens and also let them know when videos are
available.
</p>

<p>
We continued to use <a href="https://www.mumble.info/">Mumble</a> for backstage coordination. It worked out well.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-schedule">
<h2 id="emacsconf-2024-notes-schedule">Schedule</h2>
<div id="text-emacsconf-2024-notes-schedule">
<p>
The schedule worked out to two days of talks, with
two tracks on the first day, and about 15-20
minutes between each talk. We were able to adapt
to late submissions, last-minute cancellations,
and last-minute switches from Q&amp;A to live.
</p>

<p>
We added an open mic session on Sunday to fill in
the time from a last-minute cancellation. That
worked out nicely and it might be a good idea to
schedule in that time next year. It was also good
to move some of the usual closing remarks earlier.
We were able to wrap up in a timely manner, which
was great for some hosts and participants because
they didn't have to stay up so late.
</p>

<p>
Sunday was single-track, so it was nice and
relaxed. I was a little worried that people might
get bored if the current talk wasn't relevant to
their interests, but everyone managed just fine. I
probably should have remembered that Emacs people
are good at turning extra time into more
configuration tweaks.
</p>

<p>
Most of the scheduling was determined by people's
time constraints, so I didn't worry too much about
making the talks flow logically. I accidentally
forgot to note down one speaker's time
constraints, but he caught it when we e-mailed the
draft schedule and I was able to move things
around for a better time for him.
</p>

<p>
There was a tiny bit of technical confusion
because the automated schedule publishing on res
had case-sensitive matching (<code>case-fold-search</code>
was set to <code>nil</code>), so if a talk was set to "Live"
Q&amp;A, it didn't announce it as a live talk because
it was looking for <code>live</code>. Whoops. I've added that
configuration setting to my
<code>emacsconf-stream-config.el</code>, so the ansible
scripts should get it next time.
</p>

<p>
I asked Leo and Corwin if they wanted to manually
control the talks this year. They opted to leave
it automatically managed by crontab so that they
wouldn't have to worry as much about timekeeping.
It worked reliably. Hooray for automation! The
only scheduling hiccup was because I turned off
the crontab so that we could do Saturday closing
remarks when we wanted to and I forgot to reenable
autopilot the next day. We noticed when the
opening remarks didn't start right on the dot, and
I got everything back on track.
</p>

<p>
Like last year, I scheduled the dev track to start
a little later than the gen track. That made for a
less frantic morning. Also, this year we scheduled
Sunday morning to start with more IRC Q&amp;A instead
of live Q&amp;A. We didn't notice any bandwidth issues
on Sunday morning this time.
</p>

<p>
It would be nice to have Javascript countdowns in
some kind of web interface to make it easier for
hosts, especially if we can update it with the
actual time the current video will end in MPV.
</p>

<p>
I can also update the <a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-stream.el">emacsconf-stream.el</a> code to
make it easier to automatically count down to the
next talk or to a specific talk.
</p>

<p>
We have Javascript showing local time on the
individual talk pages, but it would be nice to
localize the times on all the schedule/watch pages
too.
</p>

<p>
Most of my stuff (scheduling, publishing, etc.) is
handled by automation with just a little bit of
manual nudging every so often, so it might be
possible to organize an event that's more friendly
to Europe/APAC timezones.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-videos">
<h2 id="emacsconf-2024-notes-recorded-videos">Recorded videos</h2>
<div id="text-emacsconf-2024-notes-recorded-videos">
<p>
As usual, we strongly encouraged speakers to
record videos to lower everyone's stress levels
and allow for captioning by volunteers, so that's
what most speakers did. We were able to handle
a few last-minute submissions as well as a
live talk. Getting videos also meant we could
publish them as each talk went live, including
automatically putting the videos and transcripts
on the wiki.
</p>

<p>
We didn't have obvious video encoding cut-offs, so
re-encoding in a screen was a reliable way to
avoid interruptions this year. Also, no one
complained about tiny text or low resolution, so
the talk preparation instructions seem to be
working out.
</p>

<p>
Automatically normalizing the audio with
ffmpeg-normalize didn't work out, so Leo Vivier
did a last-minute scramble to normalize the audio
the day before the conference. Maybe that's
something that volunteers can help with during the
lead-up to the conference, or maybe I can finally
figure out how to fit that into my process. I
don't have much time or patience to listen to
things, but it would be nice to get that sorted
out early.
</p>

<p>
Next year we can try remixing the audio to mono.
One of the talks had some audio moving around,
which was a little distracting. Also, some people
listen to the talks in one ear, so it would be
good to drop things down to mono for them.
</p>

<p>
We think 60fps videos stressed the res server a
bit, resulting in dropped frames. Next year, we
can downsample those to 30fps and add a note to
the talk preparation instructions. The hosts also
suggested looking into setting up streaming from
each host's computer instead of using our shared
VNC sessions.
</p>

<p>
There was some colour smearing and weirdness when
we played some videos with mpv on res. Upgrading
MPV to v0.38 fixed it.
</p>

<p>
Some people requested dark mode (light text on
dark background), so maybe we can experiment with
recommending that next year.
</p>

<p>
I did a last-minute change to the shell scripts to
load resources from the cache directory instead of
the assets/stream directory, but I didn't get all
of the file references, so sometimes the test
videos played or the introductions didn't have
captions. On the plus side, I learned how to use
<code>j</code> in MPV to reload a subtitle file.
</p>

<p>
Sometimes we needed to play the videos manually.
If we get the hang of starting MPV in a screen or
tmux session, it might be easier for hosts to
check how much time is left, or to restart a video
at a specific point if needed. Leo said he'll work
on figuring out the configuration and the Lua
scripts.
</p>

<p>
I uploaded all the videos to YouTube and scheduled
them. That was nice because then I didn't have to
keep updating things during the conference. It
turns out that Toobnix also has a way to schedule
uploads. I just need to upload it as unlisted
first, and then choose Scheduled from the
visibility. I wonder if <a href="https://www.npmjs.com/package/%40peertube%2Fpeertube-cli">peertube-cli</a> can be
extended to schedule things. Anyway, since I
didn't know about that during the conference, I
just used <code>emacsconf-publish-upload-talk</code> function
to upload videos.
</p>

<p>
It was fun playing <a href="https://www.youtube.com/watch?v=urcL86UpqZc">Interview with an Emacs
Enthusiast in 2023 [Colorized] - YouTube</a> at lunch.
I put together some captions for it after the
conference, so maybe we can play it with captions
next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-introductions">
<h2 id="emacsconf-2024-notes-recorded-introductions">Recorded introductions</h2>
<div id="text-emacsconf-2024-notes-recorded-introductions">
<p>
We record introductions so that hosts don't have
to worry about how to say things on air. I should
probably send the intro check e-mail
earlier–maybe on the original video target date,
even if speakers haven't submitted their videos
yet. This will reduce the last-minute scramble to
correct intros.
</p>

<p>
When I switched the shell scripts to use the cache
directory, I forgot to get it to do the intros
from that directory as well, so some of the
uncorrected intros were played.
</p>

<p>
I forgot to copy the intro VTTs to the cache
directory. This should be handled by the
subed-record process for creating intros, so it'll
be all sorted out next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-captioning">
<h2 id="emacsconf-2024-notes-captioning">Captioning</h2>
<div id="text-emacsconf-2024-notes-captioning">
<p>
We used <a href="https://github.com/m-bain/whisperX">WhisperX</a> for speech-to-text this year. It
did a great job at preparing the first drafts of
captions that our wonderful army of volunteer
captioners could then edit. WhisperX's built-in
voice activity detection cut down a lot on the
hallucinations that <a href="https://github.com/openai/whisper">OpenAI Whisper</a> had during
periods of silence in last year's captions, and
there was only one instance of WhisperX missing a
chunk of text from a speaker that I needed to
manually fill in. I upgraded to a Lenovo P52 with
64GB RAM, so I was able to handle last-minute
caption processing on my computer. It might be
handy to have a smaller model ready for those
last-minute requests, or have something ready to
go for the commercial APIs.
</p>

<p>
The timestamps were a little bit off. It was
really helpful that speakers and volunteers used
the backstage area to check video quality. I used
<a href="https://www.readbeyond.it/aeneas/">Aeneas</a> to re-align the text, but Aeneas was also
confused by silences. I've added some code to
<a href="https://github.com/sachac/subed">subed</a> so that I can realign regions of subtitles
using Aeneas or WhisperX timestamps, and I also
wrote some code to <a href="https://sachachua.com/blog/2024/11/checking-caption-timing-by-skimming-with-emacs-lisp-or-js/">skim timestamps for easy
verification</a>.
</p>

<p>
Anush V experimented with using machine learning
for <a href="https://gitlab.com/jun8git/sub-seg">subtitle segmentation</a>, so that might be
something to explore going forward.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-bigbluebutton-web-conference">
<h2 id="emacsconf-2024-notes-bigbluebutton-web-conference">BigBlueButton web conference</h2>
<div id="text-emacsconf-2024-notes-bigbluebutton-web-conference">
<p>
This year we set up a new <a href="https://demo.bigbluebutton.org/">BigBlueButton</a> web conferencing server. The server with our previous BigBlueButton instance had been donated by a defunct nonprofit, so it finally got removed on October 27. After investigating whether Jitsi or Galene might be a good fit for EmacsConf, we decided to continue with BigBlueButton. There were some concerns about <a href="https://github.com/bigbluebutton/bbb-install/issues/261">non-free Mongo</a> for BBB versions &gt;= 2.3 and &lt; 3, so I installed BBB 3.0. This was hard to get working on a Docker on the existing res server. <a href="https://emacsconf.org/2024/organizers-notebook/#bbb">We decided</a> it was worth spinning up an additional Linode virtual private server. It turned out that BBB refused to run on anything smaller than 8GB/4core, so I scaled up to that during testing, scaled back down to 1GB/1core in between, and scaled up to 16GB/8core dedicated during the conference.
</p>

<p>
I'm still not 100% sure I set everything up
correctly or that everything was stable. Maybe
next year BBB 3.0 will be better-tested, someone
more sysad-y can doublecheck the setup, or we can
try <a href="https://galene.org/">Galene</a>.
</p>

<p>
One of the benefits of upgrading to BBB 3.0 was
that we could use the smart layout feature to drag
the webcam thumbnails to the side of the shared
screen. This made shared screens much easier to
read. I haven't automated this yet, but it was
easy enough for us to do via the shared VNC
session.
</p>

<p>
On the plus side, it was pretty straightforward to use the Rails console to create all the rooms. We used moderator access codes to give all the speakers moderator access. Mysteriously, superadmins didn't automatically have moderator access to all the rooms even if they were logged in, so we needed to add host access by hand so that they could start the recordings.
</p>

<p>
Since we self-hosted and were budgeting more for the full-scale node, I didn't feel comfortable scaling it up to production size until a few days before the conference. I sent the access codes with the check-in e-mails to give speakers time to try things out.
</p>

<p>
<a href="https://sachachua.com/blog/2023/12/emacsconf-backstage-figuring-out-our-maximum-number-of-simultaneous-bigbluebutton-users/">Compared to last year's stats</a>:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">2023</th>
<th scope="col">2024</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max number of simultaneous users</td>
<td>62</td>
<td>107</td>
</tr>

<tr>
<td>Max number of simultaneous meetings</td>
<td>6</td>
<td>7</td>
</tr>

<tr>
<td>Max number of people in one meeting</td>
<td>27</td>
<td>25</td>
</tr>

<tr>
<td>Total unique people</td>
<td>84</td>
<td>102</td>
</tr>

<tr>
<td>Total unique talking</td>
<td>36</td>
<td>40</td>
</tr>
</tbody>
</table>

<p>
(Max number of simultaneous users wasn't deduplicated, since we need that number for server load planning)
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-tech-checks-and-hosting">
<h2 id="emacsconf-2024-notes-tech-checks-and-hosting">Tech checks and hosting</h2>
<div id="text-emacsconf-2024-notes-tech-checks-and-hosting">
<p>
FlowyCoder did a great job getting everyone
checked in, especially once I figured out the
right checklist to use. We used people's emergency
contact information a couple of times.
</p>

<p>
Corwin and Leo were able to jump in and out of the
different streams for hosting. Sometimes they were
both in the same Q&amp;A session, which made it more
conversational especially when they were covering
for technical issues. We had a couple of crashes
even though the tech checks went fine, so that was
weird. Maybe something's up with BBB 3.0 or how I
set it up.
</p>

<p>
Next time, we can consider asking speakers what
kind of facilitation style they like. A chatty
host? Someone who focuses on reading the questions
and then gets out of the way? Speakers reading
their own questions and the host focusing on
timekeeping/troubleshooting?
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-streaming">
<h2 id="emacsconf-2024-notes-streaming">Streaming</h2>
<div id="text-emacsconf-2024-notes-streaming">
<p>
I experimented with setting up the live0 streaming
node as a 64GB 32core dedicated CPU server, but
that was overkill, so we went back down to 64GB
16core and it still didn't approach the CPU
limits.
</p>

<p>
The 480p stream seemed stable, hooray! I had set
it up last year to automatically kick in as soon
as I started streaming to Icecast, and that worked
out. I think I changed a loop to be <code>while true</code>
instead of making it try 5 times, so that probably
helped.
</p>

<p>
I couldn't get Toobnix livestreaming to work this
year. On the plus side, that meant that I could
use OBS to directly stream to YouTube instead of
trying to set up multicasting. I set up one
YouTube livestreaming event for each shift and
added the RTMP keys to our shift checklists so
that I could update the settings before starting
the stream. That was pretty straightforward.
</p>

<p>
This year, I wrote a little randomizer function to
display things on the countdown screen. At first I
just dumped in
<a href="https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html">https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html</a>,
but some of those were not quite what I was
looking for. (… Probably should've read them all
first!) Then I added random packages from GNU ELPA
and NonGNU ELPA, and that was more fun. I might
add MELPA next time too. The code for dumping
random packages is probably worth putting into a
different blog post, since it's the sort of thing
people might like to add to their dashboards or
screensavers.
</p>

<p>
I ran into some C-s annoyances in screen even with
flow control turned off, so it might be a good
idea to switch to tmux instead of screen.
</p>

<p>
Next year, I think it might be a good idea to make
intro images for each talk. Then we can use that
as the opening slide in BigBlueButton (unless
they're already sharing something else) as well as
a video thumbnail.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-publishing">
<h2 id="emacsconf-2024-notes-publishing">Publishing</h2>
<div id="text-emacsconf-2024-notes-publishing">
<p>
The automated process for publishing talks and
transcripts to the wiki occasionally needed
nudging when someone else had committed a change
to the wiki. I thought I had a <code>git pull</code> in there
somewhere, but maybe I need to look at it some
more.
</p>

<p>
I forgot to switch the conference publishing phase
and enable the inclusion of Etherpads, but
fortunately Ihor noticed. I did some last-minute
hacking to add them in, and then I remembered the
variables I needed to set. Just need to add it to
our process documentation.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-etherpad">
<h2 id="emacsconf-2024-notes-etherpad">Etherpad</h2>
<div id="text-emacsconf-2024-notes-etherpad">
<p>
We used <a href="https://etherpad.org/">Etherpad</a> 1.9.7 to collect Q&amp;A again this
year. I didn't upgrade to Etherpad v2.x because I
couldn't figure out how to get it running within
the time I set aside for it, but maybe that's
something for next year.
</p>

<p>
I wrote some Elisp to copy the current ERC line
(unwrapped) for easier pasting into Etherpad. That
worked out really well, and it let me keep up with
copying questions from IRC to the pad in between
other bits of running around.
(<code>emacsconf-erc-copy</code> in
<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>)
</p>

<p>
Next year, I'll add pronouns and pronunciations to
the Etherpad template so that hosts can refer to
them easily.
</p>

<p>
If I rejig the template to move the next/previous
links so that notes can be added to the end, I
might be able to use the Etherpad API to add text
from IRC.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-irc">
<h2 id="emacsconf-2024-notes-irc">IRC</h2>
<div id="text-emacsconf-2024-notes-irc">
<p>
We remembered to give the libera.chat people a
heads-up before the conference, so we didn't run
into usage limits for <a href="https://chat.emacsconf.org/">https://chat.emacsconf.org</a>. Yay!
</p>

<p>
Aside from writing <code>emacsconf-erc-copy</code>
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>) to make it easier
to add text from IRC to the Etherpad, I didn't
tinker much with the IRC setup for this year. It
continued to be a solid platform for discussion.
</p>

<p>
I think a keyboard shortcut for inserting a talk's
URL could be handy and should be pretty easy to
add to my Embark keymap.
</p>
</div>
</div>

<div id="outline-container-emacsconf-2024-notes-budget-and-donations">
<h2 id="emacsconf-2024-notes-budget-and-donations">Budget and donations</h2>
<div id="text-emacsconf-2024-notes-budget-and-donations">
<p>
The total hosting cost for the conference was USD
42.92 + tax and the BBB testing in the lead-up to
the conference was USD 3.11 + tax, so a total of
USD 46.03+tax. The web node and the livestreaming
node are kept as 1GB nanodes the rest of the year
(USD 5 x 2 servers + tax, so USD 110). Very
manageable.
</p>

<p>
The Free Software Foundation also provided
<a href="https://media.emacsconf.org/">media.emacsconf.org</a> for serving media files. Ry P
provided res.emacsconf.org for OBS streaming over
VNC sessions.
</p>

<p>
Amin Bandali was away during the conference
weekend and no one else knew how to get the list
of donors and current donation stats from the FSF
Working Together program on short notice. Next
time, we can get that sorted out beforehand so
that we can thank donors properly.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-documentation-and-time">
<h2 id="emacsconf-2024-notes-documentation-and-time">Documentation and time</h2>
<div id="text-emacsconf-2024-notes-documentation-and-time">
<p>
I think my biggest challenge was having less time
to prepare for EmacsConf this year because the
kiddo wanted more of my attention. In many ways,
the automation that I'd been gradually building up
paid off. We were able to pull together EmacsConf
even though I had limited focus time.
</p>

<p>
Here's my Emacs-related time data (including Emacs
News and tweaking my config):
</p>

<table>


<colgroup>
<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Year</th>
<th scope="col">Jan</th>
<th scope="col">Feb</th>
<th scope="col">March</th>
<th scope="col">April</th>
<th scope="col">May</th>
<th scope="col">June</th>
<th scope="col">July</th>
<th scope="col">Aug</th>
<th scope="col">Sept</th>
<th scope="col">Oct</th>
<th scope="col">Nov</th>
<th scope="col">Dec</th>
<th scope="col">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>23.4</td>
<td>15.9</td>
<td>16.2</td>
<td>11.2</td>
<td>4.4</td>
<td>11.5</td>
<td>6.5</td>
<td>13.3</td>
<td>36.6</td>
<td>86.6</td>
<td>93.2</td>
<td>113.0</td>
<td>432</td>
</tr>

<tr>
<td>2024</td>
<td>71.2</td>
<td>12.0</td>
<td>5.6</td>
<td>6.6</td>
<td>3.3</td>
<td>9.6</td>
<td>11.0</td>
<td>4.7</td>
<td>36.0</td>
<td>40.3</td>
<td>52.3</td>
<td>67.7</td>
<td>320</td>
</tr>
</tbody>
</table>

<p>
(and here's a <a href="https://sachachua.com/blog/2023/12/analyzing-my-emacs-time-over-the-last-11-years-or-so/">longer-term analysis going back to 2012</a>.)
</p>

<p>
I spent 92.6 hours total in October and November
2024 doing Emacs-related things, compared to 179.8
hours the previous year – so, around half the
time. Part of the 2023 total was related to
preparing my presentation for EmacsConf, so I was
much more familiar with my scripts then.
Apparently, there was still a lot more that I
needed to document. As I scrambled to get
EmacsConf sorted out, I captured quick tasks/notes
for the things I need to add to our organizers
notebook. Now I get to go through all those notes
in my inbox. Maybe next year will be even
smoother.
</p>

<p>
On the plus side, all the process-related
improvements meant that the other volunteers could
jump in pretty much whenever they wanted,
including during the conference itself. I didn't
want to impose firm commitments on people or bug
them too much by e-mail, so we kept things very
chill in terms of scheduling and planning. If
people were available, we had stuff people could
help with. If people were busy, that was fine, we
could manage. This was nice, especially when I
applied the same sort of chill approach to myself.
</p>

<p>
I'd like to eventually get to the point of being
able to mostly follow my checklists and notes from
the start of the conference planning process to
the end. I've been moving notes from year-specific
organizer notebooks to the main <a href="https://emacsconf.org/organizers-notebook/">organizers'
notebook</a>. I plan to keep that one as the main file
for notes and processes, and then to have specific
dates and notes in the yearly ones.
</p>
</div>
</div>
<div id="outline-container-orgf96c4c3">
<h2 id="orgf96c4c3">Thanks</h2>
<div id="text-orgf96c4c3">
<ul>
<li>Thank you to all the speakers, volunteers, and participants, and to all those other people in our lives who make it possible through time and support.</li>
<li>Thanks to Leo Vivier and Corwin Brust for hosting the sessions, and to FlowyCoder for checking people in.</li>
<li>Thanks to our proposal review volunteers James Howell, JC Helary, and others for helping with the early acceptance process.</li>
<li>Thanks to our captioning volunteers: Mark Lewin, Rodrigo Morales, Anush, annona, and James Howell, and some speakers who captioned their own talks.</li>
<li>Thanks to Leo Vivier for fiddling with the audio to get things nicely synced.</li>
<li>Thanks to volunteers who kept the mailing lists free from spam.</li>
<li>Thanks to Bhavin Gandhi, Christopher Howard, Joseph Turner, and screwlisp for quality-checking.</li>
<li>Thanks to shoshin for the music.</li>
<li>Thanks to Amin Bandali for help with infrastructure and communication.</li>
<li>Thanks to Ry P for the server that we're using for OBS streaming and for processing videos.</li>
<li>Thanks to the Free Software Foundation for Emacs itself, the mailing lists, the media.emacsconf.org server, and handling donations on our behalf through the FSF Working Together program. <a href="https://www.fsf.org/working-together/fund">https://www.fsf.org/working-together/fund</a></li>
<li>Thanks to the many users and contributers and project teams that create all the awesome free software we use, especially: BigBlueButton, Etherpad, Icecast, OBS, TheLounge, libera.chat, ffmpeg, OpenAI Whisper, WhisperX, the aeneas forced alignment tool, PsiTransfer, subed, and many, many other tools and services we used to prepare and host this years conference</li>
<li>Thanks to everyone!</li>
</ul>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-overall">
<h2 id="emacsconf-2024-notes-overall">Overall</h2>
<div id="text-emacsconf-2024-notes-overall">
<p>
Good experience. Lots of fun. I'd love to do it
again next year. EmacsConf feels like a nice, cozy
get-together where people share the cool things
they've been working on and thinking about. People had fun!
They said:
</p>

<ul>
<li>"emacsconf is absolutely knocking it out of the park when it comes to conference logistics"</li>
<li>"I think this conference has defined the terms for a successful online conference."</li>
<li>"EmacsConf is one of the big highlights of my year every year. Thank you a ton for running this 😊"</li>
</ul>

<p>
It's one of the highlights of my year too. =) Looking forward to the next one!
</p>

<p>
In the meantime, y'all can stay connected via <a href="https://sachachua.com/blog/category/emacs-news/">Emacs News</a>, <a href="https://emacs-berlin.org/">meetups (online and in person)</a>, <a href="https://planet.emacslife.com/">Planet Emacslife</a>, and now <a href="https://emacs.tv/">emacs.tv</a>. Enjoy!
</p>

<p>
p.s. I'd love to learn from other people's conference blog posts, EmacsConf or otherwise. I'm particularly interested in virtual conferences and how we can tinker with them to make them even better. I'm having a hard time finding posts; please feel free to send me links to ones you've liked or written!</p>
</div>
</div>

</div>

</article><nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So You Want to Write Java in Neovim (137 pts)]]></title>
            <link>https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</link>
            <guid>42530991</guid>
            <pubDate>Sat, 28 Dec 2024 13:41:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/">https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</a>, See on <a href="https://news.ycombinator.com/item?id=42530991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
        

        

        <section>
            <p>Note: I plan on keeping this post updated if I need to add more content or change something</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-test.png" alt="alt text"></p>
<p>I have been doing Java in Neovim for quite a while at work, and it’s been a very pleasant experience. As Neovim usage grows (especially amongst the younger crowd), I want to share how I do it.</p>
<p>I think historically it's been considered a painful experience, but with guidance, it can be very straightforward!</p>
<p>I’ll preface this by saying that if Neovim isn’t your primary editor, you should first try an IDE specifically for Java (they should all have a Vim plugin):</p>
<ul>
<li>Eclipse</li>
<li>IntelliJ</li>
<li>Apache Netbeans</li>
</ul>
<p>If Neovim is your primary editor, you probably hate opening *insert IDE that turns you into snail* for a specific language, and so did I.</p>
<h2 id="lsp">LSP</h2>
<p>Java has one LSP option for Neovim, and that’s JDTLS (Java Development Tools Language Server) by Eclipse. You should read the project README for a high-level overview on it (including features): <a href="https://github.com/eclipse-jdtls/eclipse.jdt.ls">JDTLS GitHub</a></p>
<p>It’s a great LSP for Java, and I think it’s all you need to work with Java projects. My personal workflow usually involves one tmux window with a project open and another window handling the compiling, testing etc</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-k.png" alt="alt text"></p>
<p>To use JDTLS in Neovim, there are two plugins you can choose from, and which you decide on depends on your preferences.</p>
<h2 id="you-use-a-distro">YOU USE A DISTRO</h2>
<p>If you're happy accepting out-of-the-box, all-in-one setups, then <a href="https://github.com/nvim-java/nvim-java">nvim-java</a> might be for you.
It attempts to be a comprehensive solution with popular defaults, and be hassle-free when it comes to LSP, debugging, testing setups.
It’s not completely flexible, so if you need more control, you should try the next option.</p>
<h2 id="you-read-the-friendly-manual">YOU READ THE FRIENDLY MANUAL</h2>
<p>I expect the majority to fit here, and <a href="https://github.com/mfussenegger/nvim-jdtls">nvim-jdtls</a> is the go-to Java plugin for LSP support in Neovim. You have full access to configure JDTLS, and I highly recommend reading through the available options.</p>
<p>Just remember to install <strong>JDTLS</strong> via <strong>Mason</strong>.</p>
<p>Sometimes you will need to provide a reference JAR that the LSP can hook into loading. I downloaded a Lombok JAR and added it at the JDTLS install path (you will see this in my nvim-jdtls config below), and I at least know this had to be done for Playwright under 'referencedLibraries'.</p>
<h2 id="debugging">DEBUGGING</h2>
<p>Debugging can be done inside Neovim, but again, keep in mind that you <em>may</em> have a better experience in a Java-focused IDE.</p>
<p>I recommend installing <a href="https://github.com/mfussenegger/nvim-dap">nvim-dap</a> and <a href="https://github.com/rcarriga/nvim-dap-ui">nvim-dap-ui</a>.</p>
<p>You will need to install <a href="https://github.com/microsoft/java-debug">java-debug-adapter</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-dap.png" alt="alt text"></p>
<h2 id="testing">TESTING</h2>
<p>Working with tests inside Neovim is also possible, follows a similar setup to the above.</p>
<p>You will need to install <a href="https://github.com/microsoft/vscode-java-test">java-test</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<h2 id="my-setup">MY SETUP</h2>
<p>I will show what I have as a point of reference:</p>
<p>I imagine you are also using treesitter, lspzero etc.</p>
<p><strong>JDTLS</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>java_cmds </span><span>= </span><span>vim</span><span>.api.</span><span>nvim_create_augroup</span><span>('</span><span>java_cmds</span><span>', { </span><span>clear </span><span>= </span><span>true </span><span>})
</span><span>local </span><span>cache_vars </span><span>= {}
</span><span>
</span><span>local </span><span>root_files </span><span>= {
</span><span>    '</span><span>.git</span><span>',
</span><span>    '</span><span>mvnw</span><span>',
</span><span>    '</span><span>gradlew</span><span>',
</span><span>    '</span><span>pom.xml</span><span>',
</span><span>    '</span><span>build.gradle</span><span>',
</span><span>    '</span><span>build.sbt</span><span>'
</span><span>}
</span><span>
</span><span>local </span><span>features </span><span>= {
</span><span>    </span><span>-- change this to `true` to enable codelens
</span><span>    </span><span>codelens </span><span>= </span><span>true</span><span>,
</span><span>
</span><span>    </span><span>-- change this to `true` if you have `nvim-dap`,
</span><span>    </span><span>-- `java-test` and `java-debug-adapter` installed
</span><span>    </span><span>debugger </span><span>= </span><span>true</span><span>,
</span><span>}
</span><span>
</span><span>local function </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>if </span><span>cache_vars</span><span>.paths </span><span>then
</span><span>        </span><span>return </span><span>cache_vars</span><span>.paths
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= {}
</span><span>
</span><span>    </span><span>path</span><span>.data_dir = </span><span>vim</span><span>.fn.</span><span>stdpath</span><span>('</span><span>cache</span><span>') .. '</span><span>/nvim-jdtls</span><span>'
</span><span>
</span><span>    </span><span>local </span><span>jdtls_install </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>jdtls</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>path</span><span>.java_agent = </span><span>jdtls_install </span><span>.. '</span><span>/lombok.jar</span><span>'
</span><span>    </span><span>path</span><span>.launcher_jar = </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>jdtls_install </span><span>.. '</span><span>/plugins/org.eclipse.equinox.launcher_*.jar</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>mac</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_mac</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>unix</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_linux</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>win32</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_win</span><span>'
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>path</span><span>.bundles = {}
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-test bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_test_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-test</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_test_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_test_path </span><span>.. '</span><span>/extension/server/*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_test_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_test_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-debug-adapter bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_debug_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-debug-adapter</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_debug_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_debug_path </span><span>.. '</span><span>/extension/server/com.microsoft.java.debug.plugin-*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_debug_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_debug_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Useful if you're starting jdtls with a Java version that's
</span><span>    </span><span>-- different from the one the project uses.
</span><span>    </span><span>---
</span><span>    </span><span>path</span><span>.runtimes = {
</span><span>        </span><span>-- Note: the field `name` must be a valid `ExecutionEnvironment`,
</span><span>        </span><span>-- you can find the list here:
</span><span>        </span><span>-- https://github.com/eclipse/eclipse.jdt.ls/wiki/Running-the-JAVA-LS-server-from-the-command-line#initialize-request
</span><span>        </span><span>--
</span><span>        </span><span>-- This example assume you are using sdkman: https://sdkman.io
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-21</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/21.0.2-tem</span><span>'),
</span><span>        },
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-23</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/23-tem</span><span>'),
</span><span>        }
</span><span>
</span><span>    }
</span><span>
</span><span>    </span><span>cache_vars</span><span>.paths = </span><span>path
</span><span>
</span><span>    </span><span>return </span><span>path
</span><span>end
</span><span>
</span><span>local function </span><span>enable_codelens</span><span>(bufnr)
</span><span>    </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>
</span><span>    </span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>BufWritePost</span><span>', {
</span><span>        </span><span>buffer </span><span>= </span><span>bufnr</span><span>,
</span><span>        </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>        </span><span>desc </span><span>= '</span><span>refresh codelens</span><span>',
</span><span>        </span><span>callback </span><span>= </span><span>function</span><span>()
</span><span>            </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>        </span><span>end</span><span>,
</span><span>    })
</span><span>end
</span><span>
</span><span>local function </span><span>enable_debugger</span><span>(bufnr)
</span><span>    </span><span>require</span><span>('</span><span>jdtls</span><span>').</span><span>setup_dap</span><span>({ </span><span>hotcodereplace </span><span>= '</span><span>auto</span><span>' })
</span><span>    </span><span>require</span><span>('</span><span>jdtls.dap</span><span>').</span><span>setup_dap_main_class_configs</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;df</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_class()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;dn</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_nearest_method()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_on_attach</span><span>(client, bufnr)
</span><span>    </span><span>--vim.lsp.inlay_hint(bufnr, true)
</span><span>    </span><span>if </span><span>features</span><span>.debugger </span><span>then
</span><span>        </span><span>enable_debugger</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>if </span><span>features</span><span>.codelens </span><span>then
</span><span>        </span><span>enable_codelens</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The following mappings are based on the suggested usage of nvim-jdtls
</span><span>    </span><span>-- https://github.com/mfussenegger/nvim-jdtls#usage
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;A-o&gt;</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').organize_imports()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_variable()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_variable(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_constant()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_constant(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crm</span><span>', "</span><span>&lt;esc&gt;&lt;Cmd&gt;lua require('jdtls').extract_method(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;pjp</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').javap()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_setup</span><span>(event)
</span><span>    </span><span>local </span><span>jdtls </span><span>= </span><span>require</span><span>('</span><span>jdtls</span><span>')
</span><span>    </span><span>local </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities;
</span><span>    </span><span>extendedClientCapabilities</span><span>.onCompletionItemSelectedCommand = "</span><span>editor.action.triggerParameterHints</span><span>"
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>local </span><span>data_dir </span><span>= </span><span>path</span><span>.data_dir .. '</span><span>/</span><span>' .. </span><span>vim</span><span>.fn.</span><span>fnamemodify</span><span>(</span><span>vim</span><span>.fn.</span><span>getcwd</span><span>(), '</span><span>:p:h:t</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>cache_vars</span><span>.capabilities == </span><span>nil </span><span>then
</span><span>        </span><span>jdtls</span><span>.extendedClientCapabilities.resolveAdditionalTextEditsSupport = </span><span>true
</span><span>
</span><span>        </span><span>local </span><span>ok_cmp</span><span>, </span><span>cmp_lsp </span><span>= </span><span>pcall</span><span>(</span><span>require</span><span>, '</span><span>cmp_nvim_lsp</span><span>')
</span><span>        </span><span>cache_vars</span><span>.capabilities = </span><span>vim</span><span>.</span><span>tbl_deep_extend</span><span>(
</span><span>            '</span><span>force</span><span>',
</span><span>            </span><span>vim</span><span>.lsp.protocol.</span><span>make_client_capabilities</span><span>(),
</span><span>            </span><span>ok_cmp </span><span>and </span><span>cmp_lsp</span><span>.</span><span>default_capabilities</span><span>() or {}
</span><span>        )
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The command that starts the language server
</span><span>    </span><span>-- See: https://github.com/eclipse/eclipse.jdt.ls#running-from-the-command-line
</span><span>    </span><span>local </span><span>cmd </span><span>= {
</span><span>        '</span><span>java</span><span>',
</span><span>
</span><span>        '</span><span>-Declipse.application=org.eclipse.jdt.ls.core.id1</span><span>',
</span><span>        '</span><span>-Dosgi.bundles.defaultStartLevel=4</span><span>',
</span><span>        '</span><span>-Declipse.product=org.eclipse.jdt.ls.core.product</span><span>',
</span><span>        '</span><span>-Dlog.protocol=true</span><span>',
</span><span>        '</span><span>-Dlog.level=ALL</span><span>',
</span><span>        '</span><span>-javaagent:</span><span>' .. </span><span>path</span><span>.java_agent,
</span><span>        '</span><span>-Xms1g</span><span>',
</span><span>        '</span><span>--add-modules=ALL-SYSTEM</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.util=ALL-UNNAMED</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.lang=ALL-UNNAMED</span><span>',
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-jar</span><span>',
</span><span>        </span><span>path</span><span>.launcher_jar,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-configuration</span><span>',
</span><span>        </span><span>path</span><span>.platform_config,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-data</span><span>',
</span><span>        </span><span>data_dir</span><span>,
</span><span>    }
</span><span>
</span><span>    </span><span>local </span><span>lsp_settings </span><span>= {
</span><span>        </span><span>java </span><span>= {
</span><span>            </span><span>-- jdt = {
</span><span>            </span><span>--   ls = {
</span><span>            </span><span>--     vmargs = "-XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xmx1G -Xms100m"
</span><span>            </span><span>--   }
</span><span>            </span><span>-- },
</span><span>            </span><span>project </span><span>= {
</span><span>                </span><span>referencedLibraries </span><span>= {
</span><span>                    </span><span>-- add any library jars here for the lsp to pick them up
</span><span>                },
</span><span>            },
</span><span>            </span><span>eclipse </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>configuration </span><span>= {
</span><span>                </span><span>updateBuildConfiguration </span><span>= '</span><span>interactive</span><span>',
</span><span>                </span><span>runtimes </span><span>= </span><span>path</span><span>.runtimes,
</span><span>            },
</span><span>            </span><span>maven </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>implementationsCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>referencesCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>references </span><span>= {
</span><span>                </span><span>includeDecompiledSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>inlayHints </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>--parameterNames = {
</span><span>                </span><span>--   enabled = 'all' -- literals, all, none
</span><span>                </span><span>--}
</span><span>            },
</span><span>            </span><span>format </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>-- settings = {
</span><span>                </span><span>--   profile = 'asdf'
</span><span>                </span><span>-- },
</span><span>            }
</span><span>        },
</span><span>        </span><span>signatureHelp </span><span>= {
</span><span>            </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>completion </span><span>= {
</span><span>            </span><span>favoriteStaticMembers </span><span>= {
</span><span>                '</span><span>org.hamcrest.MatcherAssert.assertThat</span><span>',
</span><span>                '</span><span>org.hamcrest.Matchers.*</span><span>',
</span><span>                '</span><span>org.hamcrest.CoreMatchers.*</span><span>',
</span><span>                '</span><span>org.junit.jupiter.api.Assertions.*</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNull</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNullElse</span><span>',
</span><span>                '</span><span>org.mockito.Mockito.*</span><span>',
</span><span>            },
</span><span>        },
</span><span>        </span><span>contentProvider </span><span>= {
</span><span>            </span><span>preferred </span><span>= '</span><span>fernflower</span><span>',
</span><span>        },
</span><span>        </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities,
</span><span>        </span><span>sources </span><span>= {
</span><span>            </span><span>organizeImports </span><span>= {
</span><span>                </span><span>starThreshold </span><span>= </span><span>9999</span><span>,
</span><span>                </span><span>staticStarThreshold </span><span>= </span><span>9999</span><span>,
</span><span>            }
</span><span>        },
</span><span>        </span><span>codeGeneration </span><span>= {
</span><span>            </span><span>toString </span><span>= {
</span><span>                </span><span>template </span><span>= '</span><span>${object.className}{${member.name()}=${member.value}, ${otherMembers}}</span><span>',
</span><span>            },
</span><span>            </span><span>useBlocks </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>    }
</span><span>
</span><span>    </span><span>-- This starts a new client &amp; server,
</span><span>    </span><span>-- or attaches to an existing client &amp; server depending on the `root_dir`.
</span><span>    </span><span>jdtls</span><span>.</span><span>start_or_attach</span><span>({
</span><span>        </span><span>cmd </span><span>= </span><span>cmd</span><span>,
</span><span>        </span><span>settings </span><span>= </span><span>lsp_settings</span><span>,
</span><span>        </span><span>on_attach </span><span>= </span><span>jdtls_on_attach</span><span>,
</span><span>        </span><span>capabilities </span><span>= </span><span>cache_vars</span><span>.capabilities,
</span><span>        </span><span>root_dir </span><span>= </span><span>jdtls</span><span>.setup.</span><span>find_root</span><span>(</span><span>root_files</span><span>),
</span><span>        </span><span>flags </span><span>= {
</span><span>            </span><span>allow_incremental_sync </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>init_options </span><span>= {
</span><span>            </span><span>bundles </span><span>= </span><span>path</span><span>.bundles,
</span><span>            </span><span>extendedClientCapabilities </span><span>= </span><span>extendedClientCapabilities</span><span>,
</span><span>        },
</span><span>    })
</span><span>end
</span><span>
</span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>FileType</span><span>', {
</span><span>    </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>    </span><span>pattern </span><span>= { '</span><span>java</span><span>' },
</span><span>    </span><span>desc </span><span>= '</span><span>Setup jdtls</span><span>',
</span><span>    </span><span>callback </span><span>= </span><span>jdtls_setup</span><span>,
</span><span>})
</span></code></pre>
<p><strong>DAP</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>dap </span><span>= </span><span>require</span><span>('</span><span>dap</span><span>')
</span><span>
</span><span>dap</span><span>.configurations.java = {
</span><span>    {
</span><span>        </span><span>type </span><span>= '</span><span>java</span><span>',
</span><span>        </span><span>request </span><span>= '</span><span>launch</span><span>',
</span><span>        </span><span>name </span><span>= '</span><span>Launch Java Program</span><span>'
</span><span>    },
</span><span>}
</span><span>
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapBreakpoint</span><span>',
</span><span>    {
</span><span>        </span><span>text </span><span>= '</span><span>🔴</span><span>',
</span><span>        </span><span>texthl </span><span>= '</span><span>DapBreakpointSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>DapBreakpoint</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapStopped</span><span>',
</span><span>    {
</span><span>        </span><span>texthl </span><span>= '</span><span>DapStoppedSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>CursorLine</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F5&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>continue</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F10&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_over</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F11&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_into</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F12&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_out</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;b</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>toggle_breakpoint</span><span>() </span><span>end</span><span>)
</span><span>
</span><span>local </span><span>dapui </span><span>= </span><span>require</span><span>('</span><span>dapui</span><span>')
</span><span>dapui</span><span>.</span><span>setup</span><span>()
</span><span>
</span><span>dap</span><span>.listeners.before.attach.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.launch.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_terminated.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_exited.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;du</span><span>', </span><span>function</span><span>() </span><span>dapui</span><span>.</span><span>toggle</span><span>() </span><span>end</span><span>)
</span><span>
</span></code></pre>
<p>I hope this helps you get started working with Java in Neovim!</p>

        </section>

        

    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify Shuts Down ‘Unwrapped’ Artist Royalty Calculator with Legal Threats (192 pts)]]></title>
            <link>https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/</link>
            <guid>42530410</guid>
            <pubDate>Sat, 28 Dec 2024 12:00:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/">https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/</a>, See on <a href="https://news.ycombinator.com/item?id=42530410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cb-outer-container" role="main"><article id="post-310901" role="article"><section itemprop="articleBody"><div id="attachment_310904"><p><img decoding="async" aria-describedby="caption-attachment-310904" src="https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-1024x576.png" alt="Spotify Unwrapped calculator" width="750" height="422" srcset="https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-1024x576.png 1024w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-300x169.png 300w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-65x37.png 65w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-768x432.png 768w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down.png 1200w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-310904">Photo Credit: Spotify Unwrapped</p></div><h2>Spotify CEO Daniel Ek has been busy selling stock this year, becoming a multi-billionaire worth around $7.3 billion according to Forbes. Now, the calculator for showcasing how relatively little Spotify pays to artists — and the absurd contrast to top-level Spotify executive compensation — has been shut down due to the threat of legal action.</h2><p>Digital Music News reported on the existence of <a href="https://www.digitalmusicnews.com/2024/12/04/spotify-unwrapped-how-much-did-you-pay-your-favorite-artist/" data-wpel-link="internal" rel="follow">Spotify Unwrapped</a> this year as a calculator to show music lovers how little artists are paid from streaming services. Plugging in the data generated by Spotify Wrapped was relatively straight forward; now the calculator is gone with a message in its place.</p><p>“This site used to be a parody of Spotify Wrapped that called the company out for its predatory treatment of artists,” the message begins. “It has been removed at the request of Spotify’s legal team. You can still join our fight for Justice at Spotify at the United musicians and Allied Workers <a href="https://www.unionofmusicians.org/justice-at-spotify" data-wpel-link="external" rel="nofollow external noopener noreferrer">(UMAW) website</a>.”</p><h4>Despite the shutdown, the site still includes the formula behind the calculator for artists and music lovers who are curious. “Artists can multiply their Spotify Wrapped <a href="https://www.digitalmusicnews.com/2023/12/28/how-much-does-spotify-pay-per-stream/" data-wpel-link="internal" rel="follow">total streams by $0.003 to calculate royalties</a> Spotify paid out for music. If you have a label and/or bandmates that share these earnings, you might also want to divide that total appropriately.”</h4><p>Spotify is a money-maker for investors, with the stock popping off this year and reaching nearly $500 per share. Daniel Ek took advantage of the high tide and sold around $350 million in shares according to U.S. Securities and Exchange Commission (SEC) filings. Stock sales accelerated in the month of December with around 20 Spotify insiders dumping stock at its new highs.</p><p>Those new heights were achieved after massive cost-cutting measures last year, including a 25% reduction of the workforce in 2023. Spotify also <a href="https://www.digitalmusicnews.com/2024/06/05/spotify-price-hike-consumer-comments-2024/" data-wpel-link="internal" rel="follow">increased the price of its Spotify Premium subscription</a> across several markets in 2023. The stock sell-off among Spotify insiders has reached $1.25 billion in 2024 alone.</p><h4>How Much Stock Did Spotify Insiders Sell This Year?</h4><ol><li><ol><li><strong>Daniel Ek</strong>, CEO — $350 million</li><li><strong>Martin Lorentzon</strong>, Co-Founder — $550 million</li><li><strong>Gustav Söderström</strong>, Chief Product &amp; Technology Officer — $106 million</li><li><strong>Katarina Berg</strong>, Chief Human Resources Officer — $38 million</li><li><strong>Alex Norström</strong>, Chief Business Officer — $63 million</li><li><strong>Dustee Jenkins</strong>, Head of Public Relations — $6 million</li></ol></li></ol><p><a href="https://www.digitalmusicnews.com/2024/12/10/spotify-stock-cooldown-december-2024/" data-wpel-link="internal" rel="follow">SPOT stock value nearly tripped in 2024</a> and the company is approaching a $100 billion market capitalization. The stock sell-offs by executives accelerated throughout November and December and it comes as music fans were left groaning about the poor state of Spotify Wrapped this year.</p><!-- END .ss-inline-share-wrapper --></section> <!-- end article section --> <!-- end article footer --> <!-- Feature FM	--> <!--<div><center><div id='div-gpt-ad-1505443152192-0' style='height:1px; width:1px;'> <script> googletag.cmd.push(function() { googletag.display('div-gpt-ad-1505443152192-0'); }); </script></div></center></div> --><!-- #respond --></article> <!-- end article --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Where can you go in Europe by train in 8h? (425 pts)]]></title>
            <link>https://www.chronotrains.com/en</link>
            <guid>42530332</guid>
            <pubDate>Sat, 28 Dec 2024 11:43:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chronotrains.com/en">https://www.chronotrains.com/en</a>, See on <a href="https://news.ycombinator.com/item?id=42530332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Where can you go by train in 8h?</h2><p>This map shows you how far you can travel from each station in Europe in less than 8 hours.</p><p>Hover your mouse on the map to see the isochrones from that city, search for a station, or click on one of the examples below.</p></div><div><h2>Discover the Best European Train Routes</h2><p>Traveling by train in Europe offers a blend of speed, convenience, and scenic beauty. Whether you're planning a quick getaway or an extended tour, our interactive map helps you find the best destinations reachable with any time budget around any city in Europe.</p><h3>Why Choose Train Travel in Europe?</h3><p>Efficiency: High-speed trains connect major cities, reducing travel time significantly compared to other modes of transportation.</p><p>Comfort: Enjoy spacious seating, onboard amenities, and the ability to move freely during your journey.</p><p>Sustainability: Trains are an eco-friendly alternative, helping reduce your carbon footprint.</p><h3>FAQs</h3><div><p><strong>Q: How accurate are the travel times on the map?</strong></p><p>A: The map is based on estimated travel times from Deutsche Bahn data, but actual times may vary. Always check the latest schedules before traveling.</p></div><div><p><strong>Q: Can I use this map for planning multi-city trips?</strong></p><p>A: Yes, the map is a great tool for planning extended itineraries, allowing you to explore multiple cities efficiently.</p></div><div><p><strong>Q: Are there any discounts available for railway tickets in Europe?</strong></p><p>A: Many rail services offer discounts for early bookings, youth travelers, and frequent travelers. Check the respective rail service websites for the latest deals. You can access the main train ticket providers from Chronotrains directly.</p></div></div><p>This map is based on estimated travel times, using data from the <a href="https://www.bahn.de/" target="_blank" rel="noopener noreferrer">Deutsche Bahn</a> through <a href="https://direkt.bahn.guru/" target="_blank" rel="noopener noreferrer">Direkt Bahn Guru</a>. Actual timetables may vary.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chess: Magnus Carlsen disqualified in N.Y. after refusing to change out of jeans (104 pts)]]></title>
            <link>https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend</link>
            <guid>42530237</guid>
            <pubDate>Sat, 28 Dec 2024 11:18:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend">https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend</a>, See on <a href="https://news.ycombinator.com/item?id=42530237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Magnus Carlsen, the world No 1, has been disqualified from the World Rapid Championship in New York due to a dress code violation, refusing to change from jeans, after a previous warning. He is also withdrawing from the World Blitz which starts on 30 December.</p><p>Fide (the World Chess Federation) explained its decision <a href="https://www.fide.com/news/3363" data-link-name="in body link">in a statement</a> while Carlsen said: “I said I’ll change tomorrow … but they said you have to change now it became a matter of principle for me so here we are! Honestly I’m too old at this point to care too much. If this is what they want to do I’ll probably set off to somewhere where the weather is a bit nicer.”</p><p>At the time of his default, Carlsen had scored 5/8 and was a point and a half behind the leaders, with little chance of retaining his title.</p><p>After eight of the 13 rounds, Jan-Krzysztof Duda (Poland), Arjun Erigaisi (India) and Alexander Grischuk (Russia) <a href="https://chess-results.com/tnr1074690.aspx?lan=1&amp;art=1&amp;rd=5&amp;flag=30include" data-link-name="in body link">led on 6.5/8</a>. Nine players on 6/8 include Russia’s 18-year-old Volodar Murzin, who <a href="https://lichess.org/broadcast/fide-world-rapid--blitz-championships-2024--rapid-open-1-30/round-2/RZi09iMn/Z6ggMI0K" data-link-name="in body link">beat the No 2 seed</a> and US champion, Fabiano Caruana, and the world No 3 and speed specialist, Hikaru Nakamura.</p><figure id="debf81bb-5011-47b6-a8a7-f87c18f14a3a" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Chess 3952" src="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="444.6051464063886" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span><strong>3952:</strong> Albert Sandrin v Pal Eros, Pula 1972. White to move and win.</span></figcaption></figure><p>The early rounds of the 11-round Women’s World Rapid were a triumph for the <a href="https://www.theguardian.com/sport/2023/jun/23/teenager-alice-lee-sets-new-landmark-for-us-womens-chess-after-online-feats" data-link-name="in body link">rising US star Alice Lee</a>, 15, who won all her four games and was the sole leader. However Lee, who burst into prominence last year, lost to the top seed and reigning world women’s champion, China’s Ju Wenjun, in a crucial fifth-round pairing.</p><p>After six of the 11 rounds Ju had 5.5/6, half a point ahead of Alexandra Kosteniuk (Switzerland) and Kateryna Lagno (Russia), with Lee in the chasing group on 4.5/6.</p><p>The field of 182 for the World Rapid/Blitz <a href="https://chess-results.com/tnr1074690.aspx?lan=1" data-link-name="in body link">includes 30 Americans</a> while China has the top three seeds in the Women’s World Rapid/Blitz, which has 113 entries. The total prize fund is $1m for the open Rapid and Blitz, with $428,500 for the two women’s events.</p><p>This is the first time that the popular speed world championships have been staged on American soil, let alone at the centre of international finance. Rapid is defined as 15 minutes per player per game, plus an increment of 10 seconds a move from move one, while Blitz is three minutes per player per game, plus a two seconds per move increment.</p><p>Carlsen has already won five world rapids and seven world blitzes in his illustrious career, and captured both titles in 2022 and 2023. The <a href="https://x.com/chesscom/status/1870558410925818264" data-link-name="in body link">list of his lifetime victories</a> is impressively long, and underlines the task ahead for the new classical world champion, Gukesh Dommaraju, as the Indian 18-year-old, who is not competing in New York, aims to match the Norwegian’s achievements.</p><p>Carlsen’s chess curriculum vitae lists 64 major titles, all but nine of them over the board. Gukesh so far has just six – one world championship, one Candidates, three Olympiad golds, and one Fide Circuit, albeit with a 16-year age advantage.</p><p>Rapid is now Carlsen’s favourite format, and he scored again in last week’s Champions Tour, where most events were held online while the eight-player final pool was staged across the board in Oslo.</p><p>It ended up with a final between Carlsen and his old rival Ian Nepomniachtchi, whom he defeated in their 2021 world title match, where their <a href="https://www.chessgames.com/perl/chessgame?gid=2127373" data-link-name="in body link">136-move sixth game</a> was the longest in world championship history. This time there was a much faster outcome, as Carlsen won 4-1 including a <a href="https://www.chessgames.com/perl/chessgame?gid=2813014" data-link-name="in body link">23-move crush</a> in the final game.</p><p>Carlsen is always alert to new developments, and his 7 a3 repeated Gukesh’s novelty against Ding Liren from game 13 of the Fide world title match in Singapore, a drawn encounter where the teenager overlooked a win.</p><p>Nepomniachtchi varied from Ding by early castling, but he missed the power of the rook lift 17 Rh3! This is an ancient and strong strategy against the French, which I recall the shock of experiencing as Black at London 1948 against Oliver Penrose. Here, White’s attack on the king quickly proved the irrelevance of the Russian queen excursion on the opposite flank, and Carlsen’s final 23 Qg6! created the unanswerable threat of Ng5 and Qh7 mate.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-15">skip past newsletter promotion</a><p id="EmailSignup-skip-link-15" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><figure id="0e11f979-ce42-448a-9ad0-e54b99f83a09" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:16,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Chess: Gukesh and India celebrate after win but new challenges are emerging&quot;,&quot;elementId&quot;:&quot;0e11f979-ce42-448a-9ad0-e54b99f83a09&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/sport/2024/dec/20/chess-gukesh-and-india-celebrate-after-win-but-new-challenges-are-emerging&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:2}}"></gu-island></figure><p>The World Rapid started on Thursday, and continues at 7pm GMT on Friday and Saturday. You can watch free, with grandmaster and computer commentary and assessments, on <a href="https://lichess.org/broadcast/fide-world-rapid--blitz-championships-2024--rapid-open/round-1/kTmtGlGP#boards" data-link-name="in body link">lichess.org</a> and other major chess sites.</p><p>In between the three-day, 13-round Rapid on 26-28 December and the two-day Blitz on 30-31 December, Fide has organised the Wall Street Gambit, a conference to explore the fusion between chess and finance.</p><p>Its highlight will be a keynote address by the renowned economist and GM Kenneth Rogoff, who will speak on chess, AI, and economics. Caruana and India’s former world champion Vishy Anand will be present. Standard <a href="https://tickets.fide.com/events/fide/1478195" data-link-name="in body link">tickets cost $1,000</a>, while VIP tickets at $5,000, which include a blitz game and selfies with Caruana, are already sold out.</p><p>No UK players have travelled to the World Rapid/Blitz due to the high cost and the low chances of a prize. For England’s experts, the annual £10,000 <a href="https://chess-results.com/tnr1088363.aspx?lan=1from" data-link-name="in body link">Caplin Hastings Masters</a> from 28 December to 5 January is the event of the moment. More than 100 entries range from at least seven 2500+ grandmasters to a long tail where over half the field are rated below 2000.</p><p>England’s youngest-ever GM, 15-year-old Shreyas Royal, is the top home seed, while a likely candidate for an international title is 21-year-old FM Alex Golding, who already has two IM norms and a 2400+ rating and has just won the traditional Richmond pre-Christmas blitz at Orleans Park School from an entry of over 100.</p><p><strong>3952</strong><strong>:</strong> 1 Nh6+ Kf8 2 Nf5! (threat 3 Rh8 mate) g6 3 Qh6+ Kg8 4 Qh7+ Kf8 5 Qh8+! Bxh8 6 Rxh8 mate. Black can sacrifice his bishops and queen at g2 and f2, but this only delays mate.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casual Viewing – Why Netflix looks like that (278 pts)]]></title>
            <link>https://www.nplusonemag.com/issue-49/essays/casual-viewing/</link>
            <guid>42529756</guid>
            <pubDate>Sat, 28 Dec 2024 09:32:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nplusonemag.com/issue-49/essays/casual-viewing/">https://www.nplusonemag.com/issue-49/essays/casual-viewing/</a>, See on <a href="https://news.ycombinator.com/item?id=42529756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>U<span>ntil recently</span></span> no Hollywood studio had ever released two movies with the same name at the same time. At most studios, such a strategy would be unthinkable. Audiences might accidentally buy tickets to the wrong film, and the PR fallout would be disastrous: snipes from trade-magazine writers; angry calls from investors questioning the studios’ business acumen; angrier calls from agents demanding to know why their clients’ images were being intentionally sabotaged.</p><p>Netflix, however, is not most studios. On April Fools’ Day, 2022, the company released a Judd Apatow comedy titled <span><i>The Bubble</i></span>, which takes place on the set of a Hollywood dinosaur franchise that’s forced to quarantine in the middle of the Covid-19 pandemic. Four weeks later, it released an animated film by Tetsurō Araki, director of the popular Japanese anime shows <span><i>Death Note </i></span>and <span><i>Attack on Titan</i></span>, about a postapocalyptic world in which the law of gravity ceases to exist. Araki’s film was called <span><i>Bubble</i></span>.</p><p><span>There were no box office mix-ups, no snipes from the press, no angry calls. The few critics who bothered to write about it panned Apatow’s </span><span><i>Bubble</i></span><span>, an unfunny comedy that’s duller than the blockbuster franchises it makes fun of. Nobody had anything to say about Araki’s </span><span><i>Bubble</i></span><span>, a TV movie better suited to a graveyard slot on a children’s cable network. Like all Netflix movies, </span><span><i>Bubble</i></span><span> and</span><span><i> The Bubble</i></span><span> floated away as quickly as they appeared, becoming tiles in the company’s sprawling mosaic of content, destined to be autoplayed on laptops whose owners have fallen asleep.</span></p><p>For years Ted Sarandos, the Netflix co-CEO who pioneered this distribution strategy, has been hailed by the press as a visionary. Even after the streaming giant faltered in 2022, recording an overall loss of subscribers for the first time in a decade, the podcast impresario Scott Galloway raced to Sarandos’s defense in the <span><i>New York Times</i></span>, comparing him and Netflix cofounder Reed Hastings to “A-Rod and Barry Bonds.” He added, “You don’t want to bet against these guys.” Galloway had apparently forgotten that the two baseball players he named had tested positive for performance-enhancing drugs at the height of their careers. In this way his comparison was more accurate than he intended. Netflix is a steroidal company, pumped up by lies and deceit, and has broken all of Hollywood’s rules.</p><p>For a century, the business of running a Hollywood studio was straightforward. The more people watched films, the more money the studios made. With Netflix, however, audiences don’t pay for individual films. They pay a subscription to watch everything, and this has enabled a strange phenomenon to take root. Netflix’s movies don’t have to abide by any of the norms established over the history of cinema: they don’t have to be profitable, pretty, sexy, intelligent, funny, well-made, or anything else that pulls audiences into theater seats. Netflix’s audiences watch from their homes, on couches, in beds, on public transportation, and on toilets. Often they aren’t even watching.</p><p>Over the past decade, Netflix, which first emerged as a destroyer of video stores, has developed a powerful business model to conquer television, only to unleash its strange and destructive power on the cinema. In doing so, it has brought Hollywood to the brink of irrelevance. Because Netflix doesn’t just survive when no one is watching<span> </span>—<span> </span>it thrives.</p><hr><p><span>A<span>s Reed Hastings</span> tells it,</span> the Netflix eureka moment came in 1997, when he rented a VHS of <span><i>Apollo 13 </i></span>from Blockbuster Video. Some weeks later, he discovered the tape under a pile of papers in his dining room. He had forgotten to return it. When he did return it, Hastings was shocked to learn that he owed $40 in late fees. “I felt so stupid,” he later said of the experience. “I was embarrassed about it.”</p><p><span>Hastings wasn’t alone. In the 1990s, Blockbuster was reviled by its customers. As the journalist Gina Keating found in her 2012 history </span><span><i>Netflixed</i></span><span>, Blockbuster’s own research showed that customers usually had to visit stores for five weekends in a row to get what they wanted. Stores were overstocked with movies no one cared about and employees left empty VHS boxes on shelves, giving the appearance that a store’s inventory was larger than it actually was. Worst of all were the late fees: a late return often tripled the price of a Blockbuster rental, and a lost tape could set you back as much as $200. The system was widely despised</span><span> </span><span>—</span><span> </span><span>customers filed twenty-three separate class-action lawsuits against Blockbuster over unfair late charges</span><span> </span><span>—</span><span> </span><span>but outrageously profitable. In 2000, near the company’s peak, Blockbuster collected nearly $800 million in late fees, accounting for 16 percent of its annual revenue. Internally, company executives described its business model as one of “managed dissatisfaction.”</span></p><blockquote><p><b>Every week Netflix seemed to deliver a new movie no one had ever heard of that somehow broke every viewing record in the world.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Every+week+Netflix+seemed+to+deliver+a+new+movie+no+one+had+ever+heard+of+that+somehow+broke+every+viewing+record+in+the+world.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Every+week+Netflix+seemed+to+deliver+a+new+movie+no+one+had+ever+heard+of+that+somehow+broke+every+viewing+record+in+the+world.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>The year of the <span><i>Apollo 13 </i></span>incident, Hastings sold his software business Pure Atria to another tech company for more than $700 million. His experience at Blockbuster got him thinking. “Was there another model,” he wondered, “to provide the pleasure of watching movies in your own living room without inflicting the pain of paying a lot when you forgot to return them?” Hastings and Marc Randolph, Pure Atria’s chief of product marketing, began to brainstorm a new kind of movie rental business. They had noticed Amazon’s success selling books over the internet. Why not do the same with movies?</p><p>Using $2 million of Hastings’s own money, the duo began testing hundreds of ways to sell and rent DVDs by mail. The model Hastings and Randolph eventually solidified, in 1999, was simple. Netflix would charge customers a fixed monthly fee to rent up to four movies at a time. (This was soon reduced to three.) Customers could keep the discs as long as they wanted<span> </span>—<span> </span>no more late fees<span> </span>—<span> </span>but could only rent new movies after they mailed back the old ones. The open-ended approach was more convenient for customers than Blockbuster’s. But for Hastings and Randolph, customer satisfaction was secondary. The duo was trying to solve a logistical problem.</p><p>Netflix’s DVD catalog was not constrained by the size and shelf space of a brick-and-mortar store. Whereas Blockbuster might have to stock fourteen copies of a “big” title<span> </span>—<span> </span>like Steven Spielberg’s <span><i>A.I.</i></span><span> </span>—<span> </span>at the expense of other options, Netflix could stock <span><i>A.I.</i></span> and Mario Bava’s <span><i>Four Times That Night </i></span>and Richard Lester’s <span><i>The Three Musketeers</i></span>, too. But even with fewer spatial constraints, housing several hundred thousand DVDs in the Netflix warehouse was inefficient. “Reed and I began riffing,” Randolph later explained. “‘It’s kind of a shame that we have all these DVDs sitting here in a warehouse doing no good. I wonder if there was some way to store them in our customers’ houses? Can we let them keep the DVDs? Can they just hold on to them as long as they want?’”</p><p>A decade before Airbnb persuaded homeowners to transform their homes into hotels, Netflix convinced its users to turn theirs into mini Netflix warehouses. Customers who held onto their DVDs for longer meant fewer shipping costs for Netflix, and fewer DVDs for the company to manage and store. Netflix tracked heavy users of its service<span> </span>—<span> </span>labeling them internally as “pigs”<span> </span>—<span> </span>and secretly throttled their deliveries. It didn’t matter if Netflix rented fewer DVDs than Blockbuster, because the company would keep collecting its monthly fee. The difference between Blockbuster and Netflix was this: Blockbuster punished customers for being forgetful; Netflix rewarded them for being mindless.</p><hr><p><span>N<span>etflix grew</span> its business</span> by targeting companies that Americans hated, and the only company that Americans hated more than Blockbuster was their local cable provider. In the early 1990s, cable providers began working with the television networks to push the limits of what they could extort from customers, building on a rich history of viewer-screwing innovations like fees for set-top boxes and annual contracts that were impossible to cancel. Between 1995 and 2005, providers doubled the number of channels in the average cable package and raised prices at three times the rate of inflation. In 2007, FCC chairman Kevin Martin wrote in a letter to advocacy groups that “the average cable subscriber was paying for more than eighty-five channels that she didn’t watch in order to obtain the approximately sixteen channels that she does.” The average cable package cost more than $700 per year.</p><p>Hastings had always wanted to push Netflix toward cable television. Film producer Mynette Louie learned this firsthand in the late ’90s. Before she entered the film industry, Louie worked for a market-research firm that specialized in internet companies. It was the height of the dot-com bubble, and each week different start-up CEOs dropped by Louie’s office to pitch their businesses. She still remembers the day Hastings came in to speak about Netflix. “He said, ‘We’re not in the DVD business. The only reason why we have these DVDs is to scale the customer base for what we ultimately want to do, which is streaming,’” Louie told me in an interview this year.</p><p>Out of all the start-up founders Louie met, Hastings stuck out. “He was so impressive,” she said. “We didn’t know it was going to destroy the film business as we knew it.” During its first decade of operations, Netflix waited patiently for broadband internet speeds to become fast enough to support a streaming platform, draining Blockbuster of its customers and insinuating itself into the homes of millions of Americans in the process. In 2007, the same year Martin wrote his letter, the technology was finally sufficient, and Netflix launched its streaming platform.</p><blockquote><p><b>Blockbuster punished customers for being forgetful; Netflix rewarded them for being mindless.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Blockbuster+punished+customers+for+being+forgetful%3B+Netflix+rewarded+them+for+being+mindless.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Blockbuster+punished+customers+for+being+forgetful%3B+Netflix+rewarded+them+for+being+mindless.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>The service, initially called Watch Now, was primitive. Netflix made just one thousand titles available, which users could access only through Internet Explorer on PCs. Still, long-oppressed cable subscribers immediately recognized Watch Now’s appeal. Netflix’s streaming site offered viewers many of the shows and films they’d find on cable for a fraction of the price, as little as $5 per month. Hollywood studios were happy to license their second-run content to Netflix, which at first seemed incapable of threatening their cable interests. But the studios overlooked that streaming was more convenient than cable, as Netflix beamed images directly onto viewers’ laptops<span> </span>—<span> </span>and, soon enough, televisions and smartphones<span> </span>—<span> </span>with no annual contracts, cancelable at any time. Above all, there were no ads.</p><p>Streaming made perfect sense for Netflix. Since it began shipping DVDs, Netflix had hoarded customer data to improve its recommendation algorithms, and Watch Now gave the company access to granular insights about audience behavior in real time. The streaming platform eventually noted when viewers watched from their computers, televisions, or phones; which scenes they skipped, paused, or rewound; and how long it took them to abandon a show they didn’t like or finish a season that they loved. This proved useful when Netflix produced its first original series, in 2013, <span><i>House of Cards</i></span>. Company executives claimed that they acquired the show, a political thriller starring Kevin Spacey and directed by David Fincher, based on data that showed Netflix users flocked to Spacey and Fincher films. Data helped with the show’s release, too. Netflix engineers had observed that most viewers consumed episodes of television in large batches, often without breaks in between. Company executives called this “binge-watching.” Ted Sarandos, then Netflix’s chief content officer, decided to feed the habit, releasing all thirteen episodes of <span><i>House of Cards </i></span>at once in defiance of the television industry’s model of appointment viewing.</p><p>Netflix argued in its 2013 “Long-Term View” report to shareholders that the company’s “originals” acquisition strategy was just one of many reasons that “the linear TV experience” was “ripe for replacement.” “The data we have on our members’ viewing habits,” Netflix stated, “enables us to avoid overpaying for content” and “do as good or [a] better job than our linear TV peers in choosing projects.” The company explained how its formal advantages<span> </span>—<span> </span>its lack of prime-time slots, its varying episode and season lengths<span> </span>—<span> </span>“provide a platform for more creative storytelling.” “A show that is taking a long time to find its audience is one we can keep nurturing. This allows us to prudently commit to a whole season, rather than just a pilot episode.”</p><p>None of this was true. Netflix did commit to producing two seasons of <span><i>House of Cards </i></span>without seeing a pilot (outbidding HBO and AMC with an up-front offer of over $100 million<span> </span>—<span> </span>the very definition of “overpaying”), but this had little to do with “nurturing” the show. “More creative storytelling” was also a stretch: <span><i>House of Cards</i></span> resembled much of the bland and high-budget television that had dominated premium cable channels since the late 1990s. And it wasn’t clear how much insight into Netflix’s members’ viewing habits was really needed to green-light the show. After all, it didn’t take complex data analysis to know that <span><i>House of Cards</i></span><span> </span>—<span> </span>an adaptation of an already popular British series, remade with Hollywood stars<span> </span>—<span> </span>would find an audience.</p><hr><p><span>F<span>or decades,</span></span> television<span> </span>—<span> </span>with its episodic, high-volume format<span> </span>—<span> </span>had been Hollywood’s most powerful economic engine. With a successful pilot, a television producer could employ actors, directors, writers, and crew for as many as thirty-four episodes over a single season. After a string of successful seasons, the producer could sell the show in foreign territories, screen it in other formats (DVDs, video on demand, airplanes), and eventually syndicate it for reruns. All these sales produced residual payments: shares of the profits for the writers, actors, and directors who worked on the show.</p><p>Residuals had been a fixture of Hollywood since the collapse of the studio system in the 1950s, providing job security for tens of thousands of professional artists. But streamers, which by 2014 included Hulu and Amazon, saw residuals in a new light. They had no intention of rebroadcasting their shows on linear television networks, in foreign territories, or on planes. They already owned exhibition platforms<span> </span>—<span> </span>Netflix.com, Hulu.com, and Amazon.com<span> </span>—<span> </span>that were increasingly accessible from all over the world and from the most common internet-connected devices.</p><p><span>“The philosophy of the guilds was always, ‘If you reuse our material, and you make money off the reuse of our material, then we should be compensated for that,’” a former Writers Guild of America officer told me. The officer recalled a 2014 conversation he had had with a studio executive about streaming. “His response was, ‘I don’t pay my plumber every time I flush my toilet.’” Netflix pioneered a different model. Instead of residuals, the streamer offered producers a payment model known as “cost-plus.” With cost-plus, Netflix offered to pay for an entire season up front</span><span> </span><span>—</span><span> </span><span>as it did with </span><span><i>House of Cards</i></span><span> </span><span>—</span><span> </span><span>plus a “premium” that Netflix calculated, as Sarandos once explained in an interview, “via what we think the back end would have been.”</span></p><blockquote><p><b>Until Netflix, one of cinema’s essential qualities, the thing that distinguished it from television, was the way it commanded an audience’s attention.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Until+Netflix%2C+one+of+cinema%E2%80%99s+essential+qualities%2C+the+thing+that+distinguished+it+from+television%2C+was+the+way+it+commanded+an+audience%E2%80%99s+attention.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Until+Netflix%2C+one+of+cinema%E2%80%99s+essential+qualities%2C+the+thing+that+distinguished+it+from+television%2C+was+the+way+it+commanded+an+audience%E2%80%99s+attention.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>Initially, the guilds didn’t see Netflix as a threat. “The WGA had its head in the sand,” the former guild officer told me. “The guild thought, ‘If and when Netflix becomes a proper studio, we’ll deal with it like how we deal with the other studios.’”</p><p>But the guilds like the WGA and the Screen Actors Guild under-estimated just how quickly Netflix would take over the industry. Suddenly, most of the work in Hollywood was in streaming. And as the journalist Nicole LaPorte found in an investigation for <span><i>Fast Company </i></span>in 2018, little of it paid well. While A-list showrunners like Shonda Rhimes and Ryan Murphy signed nine-figure streaming production deals, everyone else saw their salaries shrink. Writers who were paid per episode noticed that Netflix’s varying season lengths really meant shorter seasons and smaller paychecks overall. Without residuals, small jobs that used to generate reliable income for years became worthless. Some actors learned they were making thirty times less than they would have on a network show. Five years before the WGA and SAG’s historic overlapping strike, which in part sought to redress the streamers’ elimination of back-end payments, LaPorte concluded what it would take major newspapers and magazines years to report: streaming had brought about “the death of Hollywood’s middle class.”</p><p>In the years after <span><i>House of Cards </i></span>debuted, Netflix flooded the market with television shows. Its spending on content ballooned from $2.4 billion in 2013 to $12 billion in 2018. The other streamers<span> </span>—<span> </span>Hulu, Amazon, and Apple<span> </span>—<span> </span>clamored to outspend one another and fill their content pipelines. Studios like Disney withdrew their content licensed to Netflix and started their own streaming services. By 2018, Netflix had taken over television, just as it had taken over the video store. But by the time the other studios followed suit, Netflix already had a new target: the film industry.</p><hr><p><span>A <span>few years</span></span> after Mynette Louie had her run-in with Hastings, she quit her job at the market-research firm and eventually became an independent film producer, shepherding films by Andrew Bujalski and Karyn Kusama. In 2013, she helped launch a financing company called Gamechanger Films that specialized in funding narrative feature films directed by women. By then Netflix had already been streaming for half a decade, and Louie’s timing seemed ideal. While Netflix already had its eye on the mainstream<span> </span>—<span> </span>in 2014 it announced a $250 million four-picture deal with Adam Sandler<span> </span>—<span> </span>much of its film budget was devoted to funding small- to mid-budget projects and aggressively acquiring finished independent films at top American festivals.</p><p>Louie benefited from Netflix’s splurge. In 2015 the company picked up the streaming rights to Kusama’s <span><i>The Invitation</i></span> after the film’s premiere at South by Southwest. Louie sold two more films to the streamer the following year, both for generous fees. “We were made whole by those sales, which was amazing,” Louie told me. “Amazing for our filmmakers, amazing for our investors, and at the time we thought, ‘Great, we’ll just keep making movies.’ We were all very hopeful about indie film having a place.”</p><p><span>It had been a long time since independent film had occupied anything like a prominent place in Hollywood. In the 1990s, the emergence of home video and foreign television outlets provided a rising generation of auteurs</span><span> </span><span>—</span><span> </span><span>Richard Linklater, Allison Anders, Gus Van Sant, and so on</span><span> </span><span>—</span><span> </span><span>with a deluge of new markets that multiplied their commercial success. Ted Hope, a film producer and cofounder of the indie production company Good Machine, recalled how foreign buyers helped his films thrive. “If you picture about one hundred different territories where you could find an audience,” he told me, “and a minimum of five different distributors in each market, you had five hundred different ways to find success. Everybody had a structure where they could take more chances.” The sheer number of buyers meant that indie filmmakers could fund their entire movies through foreign distribution sales alone, all before they shot a single scene. The competitive environment was good for audiences, too, as new indie distributors like Miramax, Fine Line, and October, aiming to make a name for themselves, raced to acquire work made by the most audacious filmmakers from the United States and abroad.</span></p><p>Rather than cultivate this success, the largest Hollywood studios spent the first decade of the new millennium stamping it out. Despite launching and acquiring indie film wings of their own, the Hollywood majors began focusing their resources on IP-driven, family-oriented blockbuster franchises and used their vast resources to book these films on thousands of screens at once, crowding out competition from smaller films. After the 2008 crash, risk-averse executives increasingly gave themselves permission to drop their mid-budget fare entirely and produce predictable blockbusters about superheroes that, when successful, generated billions of dollars in box-office revenue.</p><p>The optimism Louie felt when Netflix and Amazon began acquiring indie films in the mid-2010s was warranted. What Hope described as five hundred ways to find success had always involved a degree of risk. Producing an indie film required cobbling together funding sources, many of which were contingent and could fall through at a moment’s notice. With Netflix and Amazon, there was just one deal for global distribution, and the streamers’ cost-plus premiums guaranteed that investors made a profit. As the streamers increasingly paid enormous sums for the global rights to independent films<span> </span>—<span> </span>like Amazon’s $10 million for Dan Fogelman’s <span><i>Life Itself</i></span>, or Netflix’s $8 million for Marti Noxon’s <span><i>To the Bone</i></span><span> </span>—<span> </span>they simplified the indie film production process and enriched investors all at once.</p><p>And global distribution meant larger audiences, or so the thinking went. Speaking to Business Insider in 2017, Elijah Wood, the star of that year’s Netflix film <span><i>I Don’t Feel at Home in This World Anymore</i></span>, was enthusiastic. “There was a time in the ’90s that this would have been a title that would have gone direct to video, which would have been some certain kind of death,” Wood told his interviewer. “But that’s not the case anymore. If anything, [Netflix] created this equal opportunity for filmmakers.”</p><p>As many journalists have pointed out, Netflix and Amazon weren’t traditional Hollywood studios in any sense. The streamers were tech companies, outsiders whose business models didn’t rely on making a billion dollars at the box office from a single franchise film. “The tech giants have more leeway to experiment,” wrote <span><i>Wired</i></span>’s Julia Greenberg<i> </i>in 2016. “A single movie or show on Netflix and Amazon needn’t appeal to everyone; the key for both platforms is making sure they offer enough of everything to attract anyone.” The streamers could acquire fringe and pathbreaking films that the largest studios had ignored. Perhaps indie cinema could rise once again.</p><p>Netflix took risks on films from distinguished auteurs, like Bong Joon-ho’s <span><i>Okja</i></span>, a science fantasy about ecoterrorists trying to rescue an enormous bioengineered pig, and Alice Rohrwacher’s portrait of an ingenuous sharecropper in the Italian countryside, <span><i>Happy as Lazzaro</i></span>. And it acquired ambitious documentaries, like <span><i>13th</i></span>, Ava DuVernay’s history of the American prison–industrial complex, and <span><i>Icarus</i></span>, Bryan Fogel’s film about a Russian sports scientist who helped his athletes avoid doping regulations for years. (The latter delivered Netflix its first Academy Award for a feature-length film.)</p><p>But its commitment to good filmmaking was short-lived. As with its DVD-rental business and its pivot into streaming, Netflix’s concern was scale, rather than the cinema it was scaling. Movies, as the founder had told Louie, were merely a means to an end: acquiring subscribers who paid for access to Netflix’s entire library of content every month.</p><p><span>The range of indie films on Netflix didn’t resemble the ’90s boom and its cultivation of new auteurs. As the years went on, the streamer picked up lifeless vehicles for A-list talent like </span><span><i>The</i></span> <span><i>Polka King</i></span><span>, a comedy starring Jack Black as Jan Lewan, the real-life Polish immigrant and polka band leader who launched a multimillion-dollar Ponzi scheme; preposterous directorial feature-length debuts like Brie Larson’s </span><span><i>Unicorn Store</i></span><span>, a fantasy-comedy starring Larson as a failing artist who learns that unicorns are real and that Samuel L. Jackson wants to sell her one; and found-object curios not worth remembering, like the 2016 biopic </span><span><i>Barry, </i></span><span>starring</span><i> </i><span>Anya Taylor-Joy as Barack Obama’s white college girlfriend.</span></p><p>Film studios have always released duds: movies that fail to gain traction and are shuttled to the studios’ archives, where they disappear into obscurity. Until recently, for most studios, a forgotten film was a sign of failure. But Netflix, uniquely, seemed to relish making its films vanish as soon as they were released, dumping them onto its platform and doing as little as possible to distinguish one from the next. “Your film ends up as a thumbnail, and culturally it doesn’t make a splash. It’s not the same,” one producer with movies on Netflix told me. “Unless you’re Scorsese or something, the streamers don’t craft custom bespoke marketing campaigns for these films.”</p><p><span>Netflix’s antimarketing strategies made no sense to anyone in the movie business. Marketing had always been part of the lifeblood of cinema, the driving force that raised audience awareness, drove ticket sales, and aided films as they wormed their way through their ancillary windows. It was especially vital to independent films. “In the old days,” Hope told me, “one of the great inefficiencies that existed was when you made a movie, you had to go ahead and tell everyone about it in order to get the small percentage of people that you’d actually be able to drive to become a ticket buyer. Whether your movie was crap or beautiful, you still had to tell everybody.” Print advertising, TV and radio spots, press junkets, magazine interviews and profiles, college screenings, cast appearances on the late-night talk-show circuit: all this was part of the playbook for cementing a small-budget film in the memory of the moviegoing public and turning it into an enduring hit that could generate profits in perpetuity.</span></p><p>None of this mattered to Netflix. All viewing of its movies was confined to its platform, which supplied users with algorithmic recommendations tailored to their every whim. As Sarandos bragged in 2015 during an interview with TV Insider about Netflix’s television series: “A lot of the heavy lifting of getting audiences to the show is done with the user interface.<span> </span>.<span> </span>.<span> </span>. Marketing spends we do mostly to attract subscribers to join Netflix. The actual viewing of shows, the user interface is driving almost all of that.”</p><p>But Netflix’s user interface was hardly a replacement for the traditional marketing distributors once used to get audiences into theaters. Between 2016 and 2017, Netflix spent tens of millions of dollars acquiring indie films and documentaries to fill out its platform: <span><i>The Polka King</i></span> and <span><i>Unicorn Store</i></span>, but also <span><i>The Incredible Jessica James</i></span>, <span><i>The Mars Generation</i></span>, a movie called <span><i>Fun Mom Dinner</i></span>, and many, many more. The vast majority of these films have effectively disappeared, like the thousands of silent films from the 1910s and ’20s that Hollywood studios lost before they standardized film preservation.</p><p>Unlike those films, Netflix’s movies still exist and can be watched on their website. But for the most part they aren’t. If Netflix’s executives learned anything from indie film it was this: on the platform, you didn’t need to make a hit to succeed. You didn’t even need your film to be remembered. You just needed, in Greenberg’s words, “enough of everything to attract anyone.”</p><hr><p><span>I<span>t didn’t</span> <span>take long</span> </span>for the streamers to abandon independent film altogether. Ted Hope learned this the hard way. Back in 2015, when Amazon was first attempting to break into original movies, the streamer hired Hope as the head of development of its film division. It seemed like a natural fit. Amazon was trying to distinguish itself by distributing sophisticated auteurs, the kinds of filmmakers Hope had been producing since the early 1990s. The pairing started off well. In 2016, the studio’s first full year of releases, Hope acquired Kenneth Lonergan’s <span><i>Manchester by the Sea</i></span> and Asghar Farhadi’s <span><i>The Salesman</i></span>, which together collected three Oscars: best screenplay, best actor, and best foreign-language film.</p><p>But as Hope learned, making a successful movie on a streaming platform didn’t necessarily make a streaming platform successful. At Amazon, Hope discovered he was in the customer acquisition business, not the film business. “And the way you win the customer acquisition business,” Hope said, “is by maintaining a regular cadence at a consistent quality in an environment that people trust.” Competition intensified, with Apple, Disney, Paramount, and NBCUniversal all entering the fray, and “it became tougher to keep a customer,” said Hope, “as people would dip in and dip out.”</p><p><span>In an effort to reduce “churn,” the rate at which customers canceled their subscriptions, the streamers began pushing a different kind of production model. Instead of acquiring films by auteurs, which had gotten them into trouble</span><span> </span><span>—</span><span> </span><span>Maïmouna Doucouré’s </span><span><i>Cuties</i></span><span>, a film about preteen dancers in Paris, sparked a baseless right-wing panic that Netflix was sexualizing children</span><span> </span><span>—</span><span> </span><span>they turned to a safer, more uniform product that could be made in-house, and replicated and tailored to the diverse tastes of their enormous subscriber bases. (This also guaranteed they’d keep global distribution rights instead of having to negotiate for them.) “They no longer wanted that outlier,” Hope said. “They wanted someone to have correct expectations: ‘Oh, look at those two couples kissing. One’s wearing pool flippers. That must be a romantic comedy. I get it, do you want to watch a romantic comedy tonight?’ And that’s what it reduced down to. As long as people got what they expected, they stayed in tune.”</span></p><p>In documentaries, too, executives shifted to conventional feed. “It’s not enough to do something that a few million people might really love when you’re trying to reach twenty-five million people or fifty million people,” a former Netflix executive told the journalist Reeves Wiedeman in a 2023 article in <span><i>New York </i></span>about the documentary streaming “boom.” “A lot of documentaries<span> </span>—<span> </span>I would say the majority of documentaries<span> </span>—<span> </span>don’t meet that bar.” So what did? Grisly true crime, garish cult exposés, celebrity hagiography, sports and food miniseries, pop science, and pets. Netflix’s documentary slate quickly became a supermarket aisle of tabloid magazines.<sup id="rf1-54865"><a href="#fn1-54865" title="As Wiedeman reported in his article, the streamers have made once-unthinkable documentary practices commonplace: locking up interview sources to exclusive contracts with six-figure payouts and bringing in reality television producers who tell directors “we need a scene where X happens.” The streamers’ celebrity documentaries, like Netflix’s Beckham or Apple’s Billie Eilish: The World’s a Little Blurry, are particularly egregious, serving as little more than publicity reels for their powerful subjects. The stars of these productions often retain significant creative control and routinely interfere with the cutting of the project.">1</a></sup></p><p>In 2021 Netflix announced that it would start releasing a new original movie every week. A certain style soon began to take shape, a mind-numbing anticinema that anyone who has subscribed to Netflix in recent years knows by sight. I’ll call it the Typical Netflix Movie (TNM). From the outside, the TNM looks algorithmically constructed, as if designed to cater to each of Netflix’s two thousand “taste clusters,” the genre-like groupings Netflix uses to segment its audience, green-light programs, and recommend films and shows to subscribers. The TNM covers every niche interest and identity category in existence, such as a movie about a tall girl, <span><i>Tall Girl</i></span>, but also <span><i>Horse Girl</i></span>, <span><i>Skater Girl</i></span>, <span><i>Sweet Girl</i></span>, <span><i>Lost Girls</i></span>, and<span><i> Nice Girls</i></span>. Seemingly optimized for search engines, the title of a TNM announces exactly what it is<span> </span>—<span> </span>hence a romantic comedy about a wine executive called <span><i>A Perfect Pairing</i></span>, or a murder mystery called <span><i>Murder Mystery</i></span>. The opening credit sequence looks thrown together, as if its designer were playing roulette with Adobe templates in After Effects. A typical shot frames two characters, waist up, in profile as the camera slowly dollies across them, a slow and constant whir meant to inject motion into an otherwise inert frame. There is a preponderance of drone shots. The characters’ dialogue is stilted, filled with overexplanation, clichés, and lingo no human would ever use, like two bots stuck in a loop. “Want to catch a beer?” a buddy asks Adam Sandler in <span><i>Murder Mystery</i></span>:</p><blockquote><p><span>Nick (Adam Sandler)</span>: I can’t<span> </span>. I gotta run a few errands.</p><p><span>Jimmy</span>: What? You don’t want a beer? What’s wrong?</p><p><span>Nick</span>: I got the results back from the detective exam.</p><p><span>Jimmy</span>: You failed again. This is why I never took that test<span> </span>. All the anxiety and disappointment<span> </span>. At some point you have to realize you have hit your ceiling and just give up<span> </span>.</p></blockquote><p>The editors of these films seem to have just given up, too. The cutting between shots is frenetic. The lighting is terrible. The TNM looks both oversaturated and flat, with the blacks brightened and the highlights dulled, a result of Netflix’s insistence that its originals be shot with powerful digital cameras that compress poorly on viewers’ laptops and televisions. (Netflix might be the first studio in Hollywood history to consistently make daylight look bad.) The TNM also never turns down an opportunity to use CGI for shots that don’t need it, such as the kicking of a soccer ball in <span><i>The Kissing Booth</i></span>. Worst of all is the music: in the absence of any mise-en-scène, the TNM pipes in recognizable tunes from expensive, blue-chip artists to create moods, such as the vacuous, third-order use of David Bowie’s “Let’s Dance” in <span><i>Irish Wish</i></span>, the mercilessly random Lindsay Lohan body-swap fantasy in which she schemes to marry a rich Irish novelist who lives in a castle.</p><p>In 2022, after Netflix’s subscriber numbers dipped and its stock tanked, journalists were quick to link the company’s excessive output with a drop in what they tepidly referred to as “quality control.” Responding to claims that Netflix had pursued “drunken sailor spending,” Sarandos provided a justification to Maureen Dowd in the <span><i>New York Times</i></span>: “We were trying to build a library to make up for not having ninety years of storytelling.”</p><p>But high output alone can’t account for Netflix’s garbage quality. In the 1920s and ’30s, studios like Paramount and Warner Bros. put out as many as seventy movies per year. Around its peak in the ’90s, Miramax tried releasing a new film almost every week. The difference between Netflix and its predecessors is that the older studios had a business model that rewarded cinematic expertise and craft. Netflix, on the other hand, is staffed by unsophisticated executives who have no plan for their movies and view them with contempt. Cindy Holland, the first employee Sarandos hired, who eventually served as vice president of original content, once compared Netflix’s rapacious DVD acquisition strategy to “shoveling coal in the side door of the house.” This remained true as Netflix ramped up its original-film production. In researching this essay, I was told by sources about two high-level Netflix executives who have been known to green-light projects without reading the scripts at all.</p><p>Such slipshod filmmaking works for the streaming model, since audiences at home are often barely paying attention. Several screenwriters who’ve worked for the streamer told me a common note from company executives is “have this character announce what they’re doing so that viewers who have this program on in the background can follow along.” (“We spent a day together,” Lohan tells her lover, James, in <span><i>Irish Wish</i></span>. “I admit it was a beautiful day filled with dramatic vistas and romantic rain, but that doesn’t give you the right to question my life choices. Tomorrow I’m marrying Paul Kennedy.” “Fine,” he responds. “That will be the last you see of me because after this job is over I’m off to Bolivia to photograph an endangered tree lizard.”)</p><p>One tag among Netflix’s thirty-six thousand microgenres offers a suitable name for this kind of dreck: “casual viewing.” Usually reserved for breezy network sitcoms, reality television, and nature documentaries, the category describes much of Netflix’s film catalog<span> </span>—<span> </span>movies that go down best when you’re not paying attention, or as the <span><i>Hollywood Reporter</i></span> recently described <span><i>Atlas</i></span>, a 2024 sci-fi film starring Jennifer Lopez, “another Netflix movie made to half-watch while doing laundry.” A high-gloss product that dissolves into air. Tide Pod cinema.</p><hr><p><span>M<span>arc Randolph,</span></span> who quit Netflix in 2002, has explained that his cofounder’s origin story about the Blockbuster late fee for <span><i>Apollo 13</i></span> was made up. “[It was] a lot of crap,” Randolph told the <span><i>Netflixed</i></span> writer Gina Keating. “It never happened.” According to Randolph, the <span><i>Apollo 13</i></span> story began as “a convenient fiction” to explain the benefits of Netflix’s subscription model but took on a life of its own. In the mid-2000s, Blockbuster demanded that Hastings stop repeating the anecdote in public. “Blockbuster had searched its databases after hearing the story,” Keating reported, “and never found such a transaction.”</p><p>Hastings’s lie marked the beginning of a campaign of deception and obfuscation. Despite harvesting large troves of data on users’ viewing habits, Netflix for years refused to release any of it<span> </span>—<span> </span>not even to the producers, directors, and stars of its supposed “hit” movies and shows. Keeping talent in the dark proved to be a useful negotiating tactic when the streamer renewed a television show or green-lit a movie sequel. At the same time, withholding data protected the company from public scrutiny by obscuring how little audiences were watching its original programming in a meaningful way<span> </span>—<span> </span>from start to finish, or even at all.</p><blockquote><p><b>The TNM covers every niche interest and identity category in existence, such as a movie about a tall girl, <em>Tall Girl</em>, but also <em>Horse Girl</em>, <em>Skater Girl</em>, <em>Sweet Girl</em>, <em>Lost Girls</em>, and <em>Nice Girls</em>.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=The+TNM+covers+every+niche+interest+and+identity+category+in+existence%2C+such+as+a+movie+about+a+tall+girl%2C+%3Cem%3ETall+Girl%3C%2Fem%3E%2C+but+also+%3Cem%3EHorse+Girl%3C%2Fem%3E%2C+%3Cem%3ESkater+Girl%3C%2Fem%3E%2C+%3Cem%3ESweet+Girl%3C%2Fem%3E%2C+%3Cem%3ELost+Girls%3C%2Fem%3E%2C+and+%3Cem%3ENice+Girls%3C%2Fem%3E.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=The+TNM+covers+every+niche+interest+and+identity+category+in+existence%2C+such+as+a+movie+about+a+tall+girl%2C+%3Cem%3ETall+Girl%3C%2Fem%3E%2C+but+also+%3Cem%3EHorse+Girl%3C%2Fem%3E%2C+%3Cem%3ESkater+Girl%3C%2Fem%3E%2C+%3Cem%3ESweet+Girl%3C%2Fem%3E%2C+%3Cem%3ELost+Girls%3C%2Fem%3E%2C+and+%3Cem%3ENice+Girls%3C%2Fem%3E.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>Netflix was no different from its competitors. “The number of things that tank on Amazon is remarkable,” a former Amazon Studios executive told me. “There are so many things that people hardly watch and it would be embarrassing to release those streaming numbers. I used to get this daily email, which basically said, ‘here are the one hundred movies that people are watching most on Amazon SVOD today by the minute.’ It was always a lot of Tom Cruise sci-fi movies, action movies from the ’90s and aughts, and <span><i>Talladega Nights</i></span>.”</p><p>That audiences clearly prefer the films of the past has been an inconvenient fact for the streamers who tout themselves as the future of entertainment.<sup id="rf2-54865"><a href="#fn2-54865" title="Netflix and the other streamers are, of course, aware of the appeal of TV and films of the past, and they have pursued remakes, reboots, and reimaginings with a voraciousness even greater than that of Marvel Studios. But for the most part, their sequels and spin-offs are little more than TNMs featuring aging stars. No one assumed Coming 2 America or Fuller House would generate the fandoms of the originals, and they were right.">2</a></sup> But rather than address the problem by improving the quality of their programming and distribution, the streamers obscure the failure of their originals even further with PR bluster. Ever since it moved into original content, Netflix had been making ridiculous claims about its films and shows with little to no pushback from the Hollywood press. In a 2018 article about Netflix published in <span><i>New York</i></span>, Sarandos described <span><i>The Kissing Booth</i></span>, an unmemorable teen romance starring Jacob Elordi and Joey King, as “one of the most-watched movies in the country, and maybe in the world.” His evidence? The rankings of Elordi and King on something called the “Star-o-Meter,” a user-derived measurement for the popularity of celebrities on IMDb.com. “Three weeks ago on the IMDb Star-o-Meter, which is how they rank their popularity, [Elordi] was No. 25,000. Today he is the No. 1 star in the world,” Sarandos claimed. “And Joey King, the female lead, went from like No. 17,000 to No. 6. This is a movie that I bet you’d never heard of until I just mentioned it to you.”</p><p><span>Every week Netflix seemed to deliver a new movie no one had ever heard of that somehow broke every viewing record in the world. There was </span><span><i>Army of the Dead</i></span><span>, Zack Snyder’s 2021 zombie heist film whose ensemble cast included retired wrestler Dave Bautista and the comedian Tig Notaro; according to Netflix’s bottom-of-the-barrel PR organ Tudum, it was “the #1 film around the world and is projected to be one of Netflix’s most popular films ever in its first 4 weeks.” </span><span><i>Airplane Mode</i></span><span>, a 2020 Brazilian comedy about an influencer, wasn’t covered by any major outlet. But on Twitter, Tudum issued a “</span><span>✈</span><span> hit alert </span><span>✈</span><span>” calling it “the most popular non-English film on Netflix” of 2020. A few months later, Tudum announced a new record breaker: </span><span><i>The Old Guard</i></span><span>, an action movie starring Charlize Theron released at the height of the pandemic. No one could claim with a serious face that the film was as popular as the junk television Netflix released during the company’s pandemic boom, like </span><span><i>Tiger King </i></span><span>and </span><span><i>Emily in Paris</i></span><span>. Still, Tudum described </span><span><i>The Old Guard</i></span><span> as a “blockbuster” that was “already among the top 10 most popular Netflix films ever,” and “on track to reach 72M households in its first 4 weeks!” </span></p><p>Reaching seventy-two million households didn’t mean what it sounded like it meant. What it actually meant was that seventy-two million accounts watched at least two minutes of <span><i>The</i></span> <span><i>Old Guard</i></span>. According to Netflix, two minutes was “long enough to indicate the choice was intentional,” even though Netflix designed its viewing experience to be totally <span><i>unintentional</i></span>. An essential part of Netflix’s platform is its autoplay feature, which launches users into the next episode of a television series, or an algorithmically chosen movie, seconds after a program ends and sometimes just before the credits roll.</p><p>In 2023, in response to industry pressure, and as a flex against other less successful streaming platforms, the company began releasing biannual reports that contained the total number of “views” for each of its eighteen-thousand-plus titles over the previous six months. On a conference call with reporters, Sarandos claimed this was the most transparent representation of its data ever shown to the public.</p><p>Netflix’s “views” might look impressive on paper (even <span><i>Sweet Girl</i></span>, the TNM starring Jason Momoa as a vengeance-seeking survivalist whose MMA-trained daughter takes up his cause, was viewed 6.7 million times in the first half of 2024), but these figures remain a sham. To get to 6.7 million, Netflix first tallies the film’s “viewing hours,” the total amount of time that users have spent streaming the movie. Here, Netflix makes no distinction between users who watch <span><i>Sweet Girl</i></span> all the way through, those who watch less than two minutes, and those who watch just a few seconds thanks to autoplay, or skip around, or watch at 1.5x speed. All this distracted, piecemeal activity is rolled into <span><i>Sweet Girl</i></span>’s total viewing hours (12.3 million at last count), which the company then divides by the program’s runtime (110 minutes, or 1.83 hours) to produce those 6.7 million views. According to Netflix’s rubric, two users who watch the first half of <span><i>Sweet Girl </i></span>and close their laptops equal one full “view”<span> </span>—<span> </span>as do 110 users who each watch a single minute.</p><p>Such sleight of hand would be illegal in any other industry. Ford could never tell its shareholders that it sold two hundred thousand F-150 trucks over a single quarter, when in truth the company sold one hundred thousand F-150s to married couples who co-owned their vehicles. But for Netflix, a movie is an accounting trick<span> </span>—<span> </span>a tranche of pixels that allows the company to release increasingly fantastical statements about its viewership, such as the absurd notion that <span><i>Leave the World Behind</i></span>, a dubious Julia Roberts apocalypse movie produced by Barack and Michelle Obama, was “viewed” 121 million times. How could anyone believe that?</p><hr><p><span>“T<span>here’s a movie</span></span> on Paramount+ right now called <span><i>On the Come Up</i></span>,” a Hollywood producer told me in 2022. “I’m sure you haven’t heard about it because you don’t hear about any of these movies. It’s about a Black female rapper in Chicago and her journey in rap battling. It’s like the Black, female <span><i>8 Mile</i></span>. It’s not a great movie, but in another era, it would have been a crowd-pleaser that could cross over and play a few hundred screens, like <span><i>Set It Off </i></span>or <span><i>Down in the Delta</i></span>. That was a film by a major poet in her directorial debut, with Wesley Snipes, and that movie comfortably played on four to five hundred screens, a smallish-medium release from Miramax in 1998. What has happened to that movie is that it has become <span><i>On the Come Up</i></span>, which just disappears into the ether, and the studios put up two billboards in LA because they know the creators live in LA and want some sort of vision that they are being marketed. Like with Amazon<span> </span>—<span> </span>if you drive through Culver City you will see billboards for Amazon movies everywhere. Why? Because the directors who come to the studio lot to take a meeting there to make a movie, they drive there and they’re like, ‘Oh they’re marketing my movie.’ But they’re not.”</p><p>Last winter, while visiting Los Angeles, I went to see the signage for myself. Encircling the intersection of Venice and La Cienega Boulevards were eight towering billboards promoting the latest Amazon original movies and shows. Two advertised <span><i>The Burial</i></span>, a legal drama starring Jamie Foxx and Tommy Lee Jones. I hadn’t heard of it, nor had anyone else I talked to that week. I drove to more studios, down Sunset Boulevard past Netflix’s headquarters, toward Melrose Avenue and the Paramount lot. Every studio had token billboards for their latest pseudomovies, designed to be played but not watched.</p><p>In the past, whenever the movies in Hollywood went stale and executives exerted too much control over artists, the industry had an important hand brake: the audience. If a movie bombed with audiences and box office numbers plummeted, then studios would have to change course. After all, the box office has always been viewed as the gold standard of metrics in Hollywood for a reason: it’s the most distilled and straightforward measurement of audience interest. Moviegoers must choose to buy tickets. They cannot skip around, fast-forward, or order groceries through the Prime app on their phone. No moviegoer enters a theater expecting to leave after two minutes. Until Netflix, one of cinema’s essential qualities, the thing that distinguished it from television, was the way it commanded an audience’s attention. Whether a movie grossed big numbers or bombed, a box office report carried an inadmissible truth: the vast majority of the audience experienced the movie in full, and its taste couldn’t be ignored.</p><p>How to predict the audience’s taste<span> </span>—<span> </span>what will make money and what won’t<span> </span>—<span> </span>is a question that’s plagued Hollywood since its inception. The problem was captured by the screenwriter William Goldman in 1983. “Nobody knows anything,” he wrote in his book <span><i>Adventures in the Screen Trade</i></span>. “Not one person in the entire motion picture field knows for a certainty what’s going to work.” Netflix’s greatest innovation was that it found a way around this uncertainty: it provided a platform on which there are no failures, where everything works.</p><p>This is an important milestone for the largest Hollywood studios as they all set their sights on integrating artificial intelligence into their productions. In March, news outlets reported that OpenAI CEO Sam Altman had held meetings with top studios to showcase his company’s text-to-video generator, Sora. Clips generated by Sora that circulated online alternated between drone shots of cityscapes that look ripped from video-game cut scenes and animals rendered in the 3D animated style common to Hollywood productions today. Streaming platforms are the only place where this garbage makes any sense<span> </span>—<span> </span>a place where it would never be watched at all.</p><p>But by insulating their films from failure, the streamers have destroyed the meaning of success. Thierry Frémaux, head of the Cannes Film Festival and a vocal critic of streamers, understood this well when he presented the dilemma at a Cannes press conference in 2021. “What directors have been discovered by [streaming] platforms?” he asked. It wasn’t a rhetorical question. Frémaux began calling on journalists to name an auteur whose career had been launched by a streamer. By this point, Netflix had released more than seven hundred films in the US alone, with hundreds of directors attached. Yet as the <span><i>Guardian</i></span> later reported of the scene, “nobody could name any at all, in fact.”</p><p><span>Here, streaming platforms have achieved a strange paradox. Never has a group of studios gained so much control over the production, distribution, exhibition, and reception of movies by making movies no one cares about or remembers. Having not only failed to discover a new generation of auteurs, the streamers have also ensured that their filmmakers are little more than precarious content creators, ineligible to share the profits of any hit. It’s a shift that has induced a profound sense of confusion.</span></p><p>“What are these movies?” the Hollywood producer asked me. “Are they successful movies? Are they not? They have famous people in them. They get put out by major studios. And yet because we don’t have any reliable numbers from the streamers, we actually don’t know how many people have watched them. So what are they? If no one knows about them, if no one saw them, are they just something that people who are in them can talk about in meetings to get other jobs? Are we all just trying to keep the ball rolling so we’re just getting paid and having jobs, but no one’s really watching any of this stuff? When does the bubble burst? No one has any fucking clue.”</p><p>Netflix has created a pyramid scheme of attention, with no end in sight. And yet if the streamer admitted how little impact its movies make, it would undermine its long-running pitch to audiences, Hollywood talent, and their business representatives that the company is a grand star-making enterprise that produces great cinema with commercial appeal. This was always the logic behind Netflix’s superficial foray into funding established auteurs like Alfonso Cuarón with <span><i>Roma</i></span>, Jane Campion with <span><i>The</i></span> <span><i>Power of the Dog</i></span>, and Alejandro Iñárritu with <span><i>Bardo</i></span>. Netflix gives these films exclusive theatrical runs for a few weeks<span> </span>—<span> </span>just long enough to qualify them for Academy Awards<span> </span>—<span> </span>in a small number of theaters, a few of which the company owns or operates like the Paris in New York, or the Egyptian in Los Angeles. After that it dumps them on the platform. Some of these films, including Martin Scorsese’s <span><i>The Irishman</i></span>, have been rescued by the Criterion Collection, whose Blu-Ray editions offer an escape route out of Netflix’s walled garden. Most of the auteurs who end up at the streamer, however, simply languish. To Netflix, auteurs are a means of legitimacy, nothing more.</p><blockquote><p><b>“If no one knows about them, if no one saw them, are they just something that people who are in them can talk about in meetings to get other jobs?”</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=%E2%80%9CIf+no+one+knows+about+them%2C+if+no+one+saw+them%2C+are+they+just+something+that+people+who+are+in+them+can+talk+about+in+meetings+to+get+other+jobs%3F%E2%80%9D+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=%E2%80%9CIf+no+one+knows+about+them%2C+if+no+one+saw+them%2C+are+they+just+something+that+people+who+are+in+them+can+talk+about+in+meetings+to+get+other+jobs%3F%E2%80%9D+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>After all, Netflix has a more important coterie of stakeholders to keep happy: Wall Street investors. In an attempt to keep its stock price high, Netflix has moved away from auteurs and embraced big-budget projects that telegraph the company’s supposed mass appeal. Since 2019, Netflix has increasingly funded blockbuster-style event movies with expensive actors like Ryan Reynolds (<span><i>6 Underground</i></span>, <span><i>Red Notice</i></span>, <span><i>The Adam Project</i></span>), Ryan Gosling (<span><i>The Gray Man</i></span>), Mark Wahlberg (<span><i>The Union</i></span>), and Eddie Murphy (<span><i>Beverly Hills Cop: Axel F</i></span>). As giant burning piles of money that barely register in the cultural sphere, these attempts at generating beloved IP make the least sense in the company’s production slate. “Apparently for Netflix, Ryan Reynolds has made $50 million on this movie and $50 million on that movie,” Quentin Tarantino told a Deadline reporter last year at Cannes. “Well, good for him that he’s making so much money. But those movies don’t exist in the zeitgeist. It’s almost like they don’t even exist.” What everyone in Hollywood knows but doesn’t care to admit is that no Netflix film has ever achieved the name recognition of the streamer’s most popular television shows: <span><i>Stranger Things</i></span>, <span><i>Bridgerton</i></span>, and <span><i>Squid Game</i></span>.</p><p>Netflix is first and foremost a television company, one whose recent business strategies have made the company resemble the cable providers it’s tried to make irrelevant. Netflix is no longer the cheap service that freed cable subscribers from the tyranny of the bundle. The company’s standard subscription price has risen almost 100 percent over the past thirteen years, and any cord-cutter who wants access to the major networks’ latest shows must subscribe to several streaming platforms, whose prices have also shot up. Netflix is also no longer ad-free, as the company launched a lower-cost, ad-supported subscription tier in 2022. (When the streamer debuted its ad tier, it sought to charge advertisers around $65 to reach one thousand viewers, an eye-watering sum on par with NFL games. Perhaps an indication that advertisers aren’t buying Netflix’s astounding viewership numbers, this dollar amount has since dropped by more than half.) Netflix is also no longer dedicated to giving subscribers purely on-demand content. Over the past several years, the streamer has flirted with live programming, and this year it made its first big commitment, inking a $5 billion, ten-year deal for the exclusive rights to stream WWE’s live flagship program, <span><i>Raw</i></span>. It won’t be long before Netflix starts packaging shows into preprogrammed “channels” that run synchronously 24/7, and claiming it’s something brand new.</p><p>But if Netflix now occupies a place in the market similar to cable companies, the business it’s most spiritually aligned with is Blockbuster: a widely disliked service staffed by people who know nothing about movies, stocked with thousands of titles to see, few of them worth watching. Even Netflix knows its users can’t find titles that they like. In 2021, the company briefly introduced a new feature on its home page, called “Play Something,” to help in what the streamer called “times when we just don’t want to make decisions.” When clicked, Play Something instantly began playing for users an algorithmically chosen series or film. “Whether you’re in the mood for a new or familiar favorite,” Netflix wrote, “just ‘Play Something’ and let Netflix handle the rest.”</p><p>“Play Something,” as in: play anything. It doesn’t matter if it’s good or bad, if a user is on their phone or cleaning their room. What matters is that it’s on, and that it stays on until Netflix asks its perennial question, a prompt that appears when the platform thinks a user has fallen asleep: “Are you still watching?”</p><ol><li id="fn1-54865"><p>As Wiedeman reported in his article, the streamers have made once-unthinkable documentary practices commonplace: locking up interview sources to exclusive contracts with six-figure payouts and bringing in reality television producers who tell directors “we need a scene where X happens.” The streamers’ celebrity documentaries, like Netflix’s <em>Beckham</em> or Apple’s <em>Billie Eilish: The World’s a Little Blurry</em>, are particularly egregious, serving as little more than publicity reels for their powerful subjects. The stars of these productions often retain significant creative control and routinely interfere with the cutting of the project.&nbsp;<a href="#rf1-54865" title="Jump back to footnote 1 in the text.">↩</a></p></li><li id="fn2-54865"><p>Netflix and the other streamers are, of course, aware of the appeal of TV and films of the past, and they have pursued remakes, reboots, and reimaginings with a voraciousness even greater than that of Marvel Studios. But for the most part, their sequels and spin-offs are little more than TNMs featuring aging stars. No one assumed <em>Coming 2 America</em> or <em>Fuller House</em> would generate the fandoms of the originals, and they were right.&nbsp;<a href="#rf2-54865" title="Jump back to footnote 2 in the text.">↩</a></p></li></ol></div><p>If you like this article, please <a href="https://www.nplusonemag.com/subscribe/?affid=article">subscribe</a> or leave a tax-deductible tip below to support n+1.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Nvidia Way – Review of Tae Kim's New Book (160 pts)]]></title>
            <link>https://thechipletter.substack.com/p/the-nvidia-way</link>
            <guid>42529564</guid>
            <pubDate>Sat, 28 Dec 2024 08:45:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thechipletter.substack.com/p/the-nvidia-way">https://thechipletter.substack.com/p/the-nvidia-way</a>, See on <a href="https://news.ycombinator.com/item?id=42529564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg" width="800" height="1218" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1218,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:615771,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>On the most superficial level, Nvidia’s rapid rise to vie for the title of the world’s most valuable company is easy to explain. AI is emerging as a technology that will be both pervasive and revolutionary. Nvidia makes the best chips for AI. QED.</p><p>Dig a little deeper, though, and there are lots of questions. How did Nvidia, a designer of graphics chips, make its products essential as the engines of AI? Was it luck or foresight? Why are other companies struggling to compete? And perhaps the most crucial question of all: Will Nvidia be able to maintain its lead?</p><p>At the end of his new book on the GPU-turned-AI chip designer, Tae Kim says he had assumed there must already be several books describing Nvidia's rise and the story of its now-famous CEO, Jensen Huang. It turns out that Kim’s new book, ‘The Nvidia Way,’ is the first.</p><p>On reflection, it’s perhaps not surprising, as Nvidia’s ascent and appearance in the wider public consciousness have been sudden and dramatic. As recently as 2019, Nvidia’s stock was trading below $4, a far cry from the $130+ where it stands, with a market capitalization of more than three trillion dollars, at the end of 2024.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg" width="1418" height="988" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:988,&quot;width&quot;:1418,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:116945,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>But Nvidia is a remarkable company with an eventful history. It has a culture and approach to business that are highly distinctive, even compared to its closest peers. At the center of that culture is its founding CEO, Jensen Huang, still leading the firm after more than three decades. It’s a firm that deserves closer inspection, independent of its recent success.</p><p>So does Kim’s book do justice to Nvidia’s remarkable story? Does it help to answer the questions we posed above?</p><p><span>The Nvidia Way is two, intertwined, books in one. The first is a straightforward retelling of Nvidia’s history since it was founded by Huang, Curtis Priem, and Chris Malachowsky at a </span><a href="https://blogs.nvidia.com/blog/nvidia-dennys-trillion/" rel="">Denny’s</a><span> in 1993. There are triumphs and there are (near-fatal) disasters. </span></p><p>The disasters came early.</p><p>Nvidia’s very first design, the NV1 a graphics chip for the PC, was a story of a firm that had badly misjudged what its customers wanted. Put simply, they wanted to play ‘DOOM’ on their PCs and DOOM used VGA graphics:</p><blockquote><p>John Carmack, the game's designer and cofounder of its publisher, id Software. Carmack built the game using the 2-D Video Graphics Array (VGA) standard and leveraged every hardware-level trick he knew for maximum visual impact.</p></blockquote><p>but </p><blockquote><p>… the NV1 chip only partially supported VGA graphics and relied on a software emulator to supplement its VGA capabilities-which resulted in slow performance for gamers playing DOOM.</p></blockquote><p>With audio support for DOOM’s soundtrack that was arguably even worse, gamers shunned the NV1 in favor of one of Nvidia’s competitor’s products.</p><p>The company fared no better with its next product, the NV2 which was abandoned by Sega after a seemingly promising start.</p><p>Nvidia was now quickly running out of cash and had a track record of two failed products. Many CEOs would have been deterred and retreated into, likely fatal, caution.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg" width="1080" height="1080" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:531957,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Nvidia’s RIVA 128 - By © Raimond Spekking / CC BY-SA 4.0 (via Wikimedia Commons), CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=53922955</figcaption></figure></div><p>Not Huang. Nvidia’s next product, the RIVA 128, would be even more ambitious and risky than its predecessors:</p><blockquote><p>"I wasn't worried about my cost," Jensen said years later, when asked to explain his decision-making process. "I built a chip that physically was as large as anyone could build at the time. We just wanted to make sure this is the most powerful chip the world's ever seen."</p></blockquote><p>And the bet wasn’t just on the size of the chip. The company also needed to take huge risks with its schedule:</p><blockquote><p>Given its financial position, Nvidia would have to make the RIVA 128 in record time, and without the safety net of multiple quality-assurance runs. Standard chip development usually spans two years, involving multiple revisions to identify and fix bugs after a chip "tape-out," when a finalized chip design is sent for prototype manufacturing. The NV1, for example, had three or four physical tape-outs. Nvidia could afford just one physical tape-out for the NV3 before the company had to send it to production.</p></blockquote><p>The answer was a novel and expensive machine that enabled the Nvidia team to emulate their new design in software. Using the machine was a painful process:</p><blockquote><p>The emulator did not produce any bug reports automatically. Instead, when a program froze, all Levin could do was take a screenshot and call over one of the hardware engineers to figure out what happened or where the corruption occurred. If it was a significant problem, the engineers would go back to redesign a part of the chip.</p></blockquote><p>But it enabled Nvidia to get the chip working, and to market, in record time. </p><p>Huang would later say that the RIVA 128 was a ‘miracle’. But he was determined to turn it into a repeatable miracle:</p><blockquote><p>“There's got to be a way to solve this problem of the design cycles.”</p></blockquote><p>The answer was again software, but this time running on Nvidia’s chips. Curtis Priem developed the idea of the ‘resource manager’ which was ‘a miniature operating system that sat on top of the hardware itself’:</p><blockquote><p>The resource manager allowed Nvidia's engineers to emulate certain hardware features that normally needed to be physically printed onto chip circuits. This involved a performance cost but accelerated the pace of innovation, because Nvidia's engineers could take more risks. If the new feature wasn't ready to work in the hardware, Nvidia could emulate it in software. At the same time, the engineers could take hardware features out when there was enough leftover computing power, saving chip die area.</p></blockquote><p>The approach gave Nvidia a decisive advantage. Rivals, including the once-market leader 3dfx, struggled to keep up. 3dfx made several mistakes and in 2002 Nvidia was able to buy its patents and other assets out of bankruptcy and hire around a hundred 3dfx employees.</p><p>Even in Nvidia’s early years, the characteristics that would form the foundation of its recent success were visible. The relentless execution, the risk-taking, and the way it combined hardware and software to give it a decisive advantage over its, perhaps more hardware-focused competitors, were all essential components in its later successes.</p><p>A few words about how ‘The Nvidia Way’ handles the most technology-intense parts of Nvidia’s story. Kim does a masterful job. Whilst accessible to the general reader, there is enough detail on Nvidia’s products and technologies to ensure that more technically oriented readers remain engaged.</p><p data-attrs="{&quot;url&quot;:&quot;https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>As ‘The Nvidia Way’ continues the second intertwined book comes to the fore. It’s a book that focuses on Nvidia’s culture and Huang and his approach to management.</p><p>Many aspects of Huang’s unique management style are now well known: his 60+ direct reports; the ‘top five’ emails; the long-hours culture; and the public way he gives negative feedback.</p><p>If you aspire to reproduce ‘Jensen’s Way’ then ‘The Nvidia Way’ might almost be read as a manual for his management style.</p><p>But you’ll probably run into several problems. The approach must be uniquely demanding, both for Huang and his wider Nvidia team. It must take unusual stamina to endure the intensity of the approach over several decades as Huang and several of his senior team have done.</p><p>Then, and it’s a cliche but here it’s true, Nvidia has been ‘an overnight success that has been thirty years in the making’. Huang might have benefited from the scale of the ‘AI boom’ launched by ChatGPT and other LLMs. But it’s taken thirty years to build a company with the characteristics that have made Nvidia uniquely well-positioned to cash in. Who else has the patience and resilience - or the opportunity - to shape an organization over many decades?</p><p>Still, there is more than enough material for readers to understand how Nvidia and Huang operate.</p><p>If ‘The Nvidia Way’ has a gap it’s on Nvidia’s recent corporate strategy. There is nothing on the attempted acquisition of CPU designer Arm. Why did Huang want Arm? What was his reaction to the takeover being thwarted? What is his relationship with Arm owner and Softbank CEO Masayoshi Son? We’ll have to wait for a second book on Nvidia for insights into each of these points and more.</p><p>Let’s return to two of the questions that we started with. How did Nvidia make itself essential to AI and was it luck or foresight?</p><p>Huang has admitted that he didn’t foresee the current LLM-focused AI boom. But Nvidia’s success isn’t luck either. The company positioned itself as the leader in massively parallel computing and ensured that its products were accessible to anyone who wanted to use those capabilities. That positioning has involved heavy investment over almost two decades.</p><p>And then, will Nvidia be able to maintain its lead? </p><p>Here there is a simple point to be made. As the book makes clear, Nvidia gained leadership in the brutally competitive graphics card market against numerous bigger competitors. It did so on the back of a culture that combined risk-taking with a relentless focus on execution. During its early years, it had no moat and often had limited financial resources.</p><p>Today, that culture seems to have largely endured under Huang’s leadership. It has built a strong moat around its ecosystem in the form of CUDA and it now has a scale and resources that no rival can remotely match. </p><p>In these circumstances, it would be brave to bet against Nvidia.</p><p>This takes us to one final question, which, as you read The Nvidia Way, comes to mind repeatedly. What will happen to Nvidia when Huang leaves? </p><p>Huang is 61 and seems as fit and energized by his job as he ever was. Morris Chang was 55 when he founded TSMC and finally retired as CEO at 86. I suspect that a lot will happen between now and Huang’s retirement. Perhaps it’s one question we can leave aside for a few years yet.</p><p data-attrs="{&quot;url&quot;:&quot;https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><strong>The Nvidia Way is highly recommended. It’s an outstanding book that provides a thorough overview of Nvidia’s history and culture whilst also being a great read.</strong></p><p><span>For readers who want more than the book, Tae Kim’s recent interview with </span></p><p><span> in Jon’s Asianometry Newsletter is terrific.</span></p><p><span>Author </span></p><p><span> himself is on Substack: </span></p><p>With links to more on the Nvidia way here:</p><p>Finally, if you like your history in podcast rather than book form, the Acquired team did a great job with their three-part history of Nvidia. The Acquired telling of the Nvidia story is, I think, highly complementary to Kim’s book as it focuses more on strategy than culture. The three parts (with transcripts) are linked below:</p><ul><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-gpu-company-1993-2006" rel="">Part 1: The GPU Company (1993-2006)</a></p></li><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-machine-learning-company-2006-2022" rel="">Part 2: The Machine Learning Company (2006-2022)</a></p></li><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-dawn-of-the-ai-era" rel="">Part 3: Dawn of the AI Era (2022-2023)</a></p></li></ul><p><span>Plus a great </span><a href="https://www.acquired.fm/episodes/jensen-huang" rel="">interview</a><span> with Jensen Huang himself.</span></p><div id="youtube2-y6NfxiemvHg" data-attrs="{&quot;videoId&quot;:&quot;y6NfxiemvHg&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/y6NfxiemvHg?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></div>]]></description>
        </item>
    </channel>
</rss>