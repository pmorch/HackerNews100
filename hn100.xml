<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 17 Oct 2024 00:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AI PCs Aren't Good at AI: The CPU Beats the NPU (206 pts)]]></title>
            <link>https://github.com/usefulsensors/qc_npu_benchmark</link>
            <guid>41863061</guid>
            <pubDate>Wed, 16 Oct 2024 19:44:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/usefulsensors/qc_npu_benchmark">https://github.com/usefulsensors/qc_npu_benchmark</a>, See on <a href="https://news.ycombinator.com/item?id=41863061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet</h2><a id="user-content-benchmarking-qualcomms-npu-on-the-microsoft-surface-tablet" aria-label="Permalink: Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet" href="#benchmarking-qualcomms-npu-on-the-microsoft-surface-tablet"></a></p>
<p dir="auto">TL;DR - We see 1.3% of Qualcomm's NPU 45 Teraops/s claim when benchmarking Windows AI PCs</p>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#python">Python</a></li>
<li><a href="#cmake">Cmake</a></li>
<li><a href="#visual-studio">Visual Studio</a></li>
<li><a href="#pip-packages">Pip Packages</a></li>
</ul>
</li>
<li><a href="#benchmark">Benchmark</a>
<ul dir="auto">
<li><a href="#running">Running</a></li>
<li><a href="#understanding-the-output">Understanding the Output</a></li>
<li><a href="#what-the-benchmark-measures">What the Benchmark Measures</a></li>
<li><a href="#possible-confounding-factors">Possible Confounding Factors</a>
<ul dir="auto">
<li><a href="#compute-bound">Compute Bound</a></li>
<li><a href="#power-settings">Power Settings</a></li>
<li><a href="#model-topology">Model Topology</a></li>
<li><a href="#configuration-errors">Configuration Errors</a></li>
<li><a href="#onnx-framework">Onnx Framework</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#interpreting-the-results">Interpreting the Results</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Microsoft now offers Surface tablets that run Windows on a Qualcomm Arm-based
SoC. These are marketed as AI PCs, due to their ability to run machine learning
models faster and more efficiently than other systems. We are fans of
Qualcomm's hardware, and its NPU in particular, so we've invested a lot of time
and resources into porting our third-party app to this plaform.</p>
<p dir="auto">Unfortunately there  aren't many code examples or benchmarks available to
demonstrate how to achieve fast results as an external developer, so we've put
together a small standalone project to show the performance we're seeing. It's
significantly below what we'd hoped for, so we're publishing this benchmark to
see if we can get ideas on how to achieve lower latency. I'm hopeful there will
be software changes, either at the application, framework, or driver level,
that will improve these results in the future, since I've seen the underlying
hardware perform very effectively on other platforms like Android.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<p dir="auto">We're using Python to run our test scripts, and on Windows <a href="https://docs.python.org/3/using/windows.html" rel="nofollow">there are several ways to install the language</a>.
As of October 2nd, 2024, the Python available on the Microsoft Store doesn't
support the Arm architecture, and so it's not suitable for running the packages
we need to access Qualcomm's NPU. Instead, you should use <a href="https://www.python.org/downloads/" rel="nofollow">the official Python dot org installer</a>.
For the results reported here I used <a href="https://www.python.org/ftp/python/3.11.9/python-3.11.9-arm64.exe" rel="nofollow">version 3.11.9</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cmake</h3><a id="user-content-cmake" aria-label="Permalink: Cmake" href="#cmake"></a></p>
<p dir="auto">We'll also need the cmake build tool to compile Onnx (since prebuilt packages
aren't yet available for Windows on Arm). To do this I ran the following
command from a Powershell:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Visual Studio</h3><a id="user-content-visual-studio" aria-label="Permalink: Visual Studio" href="#visual-studio"></a></p>
<p dir="auto">The build process also requires Visual Studio for the compiler. Download Visual
Studio Community Edition (not Code!) from <a href="https://visualstudio.microsoft.com/downloads/" rel="nofollow">visualstudio.microsoft.com/downloads/</a>.</p>
<p dir="auto">During the installation you will be prompted to select <code>Workload</code> from several options: select <code>Desktop C++ Development</code> checkbox then press install.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pip Packages</h3><a id="user-content-pip-packages" aria-label="Permalink: Pip Packages" href="#pip-packages"></a></p>
<p dir="auto">You can install all the required Python packages by running the following
from within this folder:</p>
<div data-snippet-clipboard-copy-content="py -m pip install -r requirements.txt"><pre><code>py -m pip install -r requirements.txt
</code></pre></div>
<p dir="auto">This includes a couple of custom packages. The first is <a href="https://github.com/petewarden/onnx/tree/rel-1.16.2">my branch of Onnx</a>,
which has <a href="https://github.com/onnx/onnx/pull/6407" data-hovercard-type="pull_request" data-hovercard-url="/onnx/onnx/pull/6407/hovercard">a fix for compiling using the official <code>py</code> launcher</a>
backported to Onnx version 1.16, since the Qualcomm Onnx Runtime doesn't work
with newer Onnx versions (giving an <code>Unsupported model IR version</code> error).</p>
<p dir="auto">I also grab <a href="https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/7982ae20-ed19-4a35-a362-a96ac99897b7/pypi/download/ort-nightly-qnn/1.20.dev20240928001/ort_nightly_qnn-1.20.0.dev20240928001-cp311-cp311-win_arm64.whl#sha256=3b12e3882d1afadf66c2349b2a167dfcbb9ae7a332dc98e0fd51c101d34ddf6e" rel="nofollow">a nightly build</a>
of <a href="https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html" rel="nofollow">Qualcomm's Onnx Runtime package</a>.
If you want to install a more recent version, there's <a href="https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ORT-Nightly/pypi/simple/ort-nightly-qnn/" rel="nofollow">a list here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running</h3><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">To execute the benchmark, run:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding the Output</h3><a id="user-content-understanding-the-output" aria-label="Permalink: Understanding the Output" href="#understanding-the-output"></a></p>
<p dir="auto">The Onnx runtime initially generates a lot of log spam, including:</p>
<div data-snippet-clipboard-copy-content="Error in cpuinfo: Unknown chip model name 'Snapdragon(R) X 12-core X1E80100 @ 3.40 GHz'.
Please add new Windows on Arm SoC/chip support to arm/windows/init.c!
unknown Qualcomm CPU part 0x1 ignored"><pre><code>Error in cpuinfo: Unknown chip model name 'Snapdragon(R) X 12-core X1E80100 @ 3.40 GHz'.
Please add new Windows on Arm SoC/chip support to arm/windows/init.c!
unknown Qualcomm CPU part 0x1 ignored
</code></pre></div>
<p dir="auto">and</p>
<div data-snippet-clipboard-copy-content="Starting stage: Finalizing Graph Sequence
Completed stage: Finalizing Graph Sequence (115919 us)
Starting stage: Completion
Completed stage: Completion (1025 us)"><pre><code>Starting stage: Finalizing Graph Sequence
Completed stage: Finalizing Graph Sequence (115919 us)
Starting stage: Completion
Completed stage: Completion (1025 us)
</code></pre></div>
<p dir="auto">After all those messages, you should see the actual benchmark
results at the end, something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="************ Benchmark Results ************
NPU quantized compute, float I/O accuracy difference is 0.0100
NPU quantized compute and I/O accuracy difference is 0.0060
CPU took 8.42ms, 821,141,860,688 ops per second
NPU (quantized compute, float I/O) took 30.63ms, 225,667,671,183 ops per second
NPU (quantized compute and I/O) took 12.05ms, 573,475,650,364 ops per second"><pre><span>************</span> Benchmark Results <span>************</span>
NPU quantized compute, float I/O accuracy difference is 0.0100
NPU quantized compute and I/O accuracy difference is 0.0060
CPU took 8.42ms, 821,141,860,688 ops per second
NPU (quantized compute, float I/O) took 30.63ms, 225,667,671,183 ops per second
NPU (quantized compute and I/O) took 12.05ms, 573,475,650,364 ops per second</pre></div>
<p dir="auto">The first two lines confirm that the numerical results of the operations match
between the CPU and the NPU. The final three show the latency of the three
approaches to running a simple model. The latency is the wall time it took to
execute the model from start to finish, and the ops per second is calculated
from that latency to indicate the equivalent computational throughput.</p>
<p dir="auto">In this example, we see the CPU is capable of running 821 billion ops/second
(821 Gigaops), the first NPU approach gives us 225 Gigaops, and the second 573
Gigaops.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What the Benchmark Measures</h3><a id="user-content-what-the-benchmark-measures" aria-label="Permalink: What the Benchmark Measures" href="#what-the-benchmark-measures"></a></p>
<p dir="auto">This benchmark is designed to resemble some real world models we depend on,
running 6 large matrix multiplications that are similar to the most
time-consuming layers in transformer models like OpenAI's Whisper. The shapes
are (6, 1500, 256) X (6, 256, 1500), producing a (6, 1500, 1500) result. The
model we running consists of a single MatMul node with two inputs and one
output.</p>
<p dir="auto">The models are created on the fly using the Onnx model framework, and then fed
into the Onnx runtime. The control model is a pure float version that runs
entirely on the CPU.</p>
<p dir="auto">The NPU mostly requires quantized models to run effectively (though it has
limited support for float16). The first approach we took to quantization used
<a href="https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html#static-quantization" rel="nofollow">the official ORT <code>quantize_static()</code> method</a>.
For convenience this leaves the input and output tensors in 32-bit float and
performs runtime conversions at the start and end of the graph so that the rest
of the computation happens in eight-bit.</p>
<p dir="auto">Unfortunately we discovered that the conversion operations as implemented on
the NPU were extremely slow, much slower than the main matrix multiplication
in fact. You can see the results in the <code>npu_quant_profile.csv</code> file in this
repository, with conversions taking over 75% of the time.</p>
<p dir="auto">To work around this, we constructed an equivalent model graph programmatically
with eight-bit inputs and outputs This is the second "quantized compute and
I/O" approach mentioned in the results. This is usually around three times
faster than the float I/O version, and profiling shows most of the time is
going on the matrix multiplication, as we'd hope.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Possible Confounding Factors</h3><a id="user-content-possible-confounding-factors" aria-label="Permalink: Possible Confounding Factors" href="#possible-confounding-factors"></a></p>
<p dir="auto">There are a lot of variables involved in measuring performance. Here are some
of the assumptions we've made:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Compute Bound</h4><a id="user-content-compute-bound" aria-label="Permalink: Compute Bound" href="#compute-bound"></a></p>
<p dir="auto">Modern transformer models are based around large matrix multiplications, unlike
older convolutional models. One potential issue is that accelerators could
become memory bound if the layers start to resemble matrix times vectors, since
that doesn't allow reuse of many of the weights, and performance becomes bottle
necked on fetching values from DRAM. We've tried to avoid that by making both
the input matrices more square, so that tiling and reuse should be possible.</p>
<p dir="auto">The original matrices from the tiny Whisper model had a k dimension of only 64,
so in case that was too small we bumped it up to 256 in this benchmark to give
as much room for SIMD optimizations as possible.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Power Settings</h4><a id="user-content-power-settings" aria-label="Permalink: Power Settings" href="#power-settings"></a></p>
<p dir="auto">Windows has a lot of different configuration options around energy usage, so we
tried to ensure that all of the settings were on "Best Performance" and that we
ran the benchmark with the tablet connected to mains power. There's also a
session option on the Qualcomm Onnx Runtime, <code>htp_performance_mode</code>, that we
set to <code>sustained_high_performance</code>, since that seemed to give the lowest
overall latency in our experiments.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Model Topology</h4><a id="user-content-model-topology" aria-label="Permalink: Model Topology" href="#model-topology"></a></p>
<p dir="auto">We wanted to create a graph of operations that reflected modern AI models, but
was simple enough to easily interpret. We could have added multiple layers, or
used convolutions, or static weights, but settled for a single matrix
multiplication operation with dynamic inputs, since that reflected the
transformer architectures that are widely used for LLMs and other modern
models.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Configuration Errors</h4><a id="user-content-configuration-errors" aria-label="Permalink: Configuration Errors" href="#configuration-errors"></a></p>
<p dir="auto">It's possible that the way we build and run our models causes them to fall off
the fast path of the drivers or accelerator implementation. For example, we're
using unsigned eight-bit quantization, with qdq elements in the graph. We've
attempted to follow best practice from the documentation, but we'd welcome ways
to improve performance, especially since these would improve the performance of
our actual applications.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Onnx Framework</h4><a id="user-content-onnx-framework" aria-label="Permalink: Onnx Framework" href="#onnx-framework"></a></p>
<p dir="auto">There are multiple different ways to access AI acceleration on Windows. We
looked at DirectML, but it only seems to support GPU access. OpenVino doesn't
run on our Arm hardware, as far as we can tell. We've seen similar performance
results to those shown here using the <a href="https://www.qualcomm.com/developer/software/neural-processing-sdk-for-ai" rel="nofollow">Qualcomm QNN SDK</a>
directly. TensorFlow Lite isn't supported on Windows for Arm. From this
research and our experiments, Onnx is supported by both Microsoft and Qualcomm,
and seems to be the best framework to use to get accelerated performance from
the NPU, but we're interested in learning if other APIs would be more
appropriate.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interpreting the Results</h2><a id="user-content-interpreting-the-results" aria-label="Permalink: Interpreting the Results" href="#interpreting-the-results"></a></p>
<p dir="auto">The results shown here are current as of October 2nd, 2024, when running on a
Microsoft Surface Pro 11th Edition, with a Snapdragon(R) X 12-core X1E80100
clocked at 3.40 GHz. The first obvious thing is that the NPU results, even
without float conversion, are slower than the CPU. This is not ideal for an
accelerator, even though it could still potentially offer energy or sustained
performance advantages that make it worth using.</p>
<p dir="auto">The second conclusion is that the measured performance of 573 billion
operations per second is only 1.3% of the 45 trillion ops/s that <a href="https://www.microsoft.com/en-us/surface/devices/surface-pro-11th-edition" rel="nofollow">the marketing material</a>
promises.</p>
<p dir="auto">By contrast, running the same model on an Nvidia Geforce RTX 4080 Laptop GPU
runs in 3.2ms, an equivalent of 2,160 billion operations per second, almost
four times the throughput.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We outsmarted CSGO cheaters with IdentityLogger (126 pts)]]></title>
            <link>https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/</link>
            <guid>41862028</guid>
            <pubDate>Wed, 16 Oct 2024 18:18:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/">https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/</a>, See on <a href="https://news.ycombinator.com/item?id=41862028">Hacker News</a></p>
Couldn't get https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ireland's big school secret: how a year off-curriculum changes teenage lives (134 pts)]]></title>
            <link>https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum</link>
            <guid>41861628</guid>
            <pubDate>Wed, 16 Oct 2024 17:36:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum">https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum</a>, See on <a href="https://news.ycombinator.com/item?id=41861628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>‘I</span>f you know your Flann O’Brien, you’ll know that bike maintenance and philosophy go arse-on-saddle in this country,” Niall Hare, the 63-year-old headteacher at Kishoge community college in Dublin, told me. He was running through what his students do on their “transition year”, which is the missing fourth year (a year 11 in England, Wales, year 12 in Northern <a href="https://www.theguardian.com/world/ireland" data-link-name="in body link" data-component="auto-linked-tag">Ireland</a> or S4 in Scotland) of the Irish education system. Even the way it’s named has a magical, secret-compartment quality, like Platform 9 3/4 in Harry Potter, or the 7 1/2th floor in Being John Malkovich.</p><p>In Ireland, secondary school starts with the three-year junior cycle, beginning at age 12 or 13, and concluding with a Junior Certificate (roughly equivalent to a GCSE in England, Wales and Northern Ireland or Nationals in Scotland). Then you can either go straight into the two-year senior cycle to start preparing for the Leaving Certificate (roughly equivalent to A-levels or the International Baccalaureate), or you can have a transition year (TY) first – so you could think of it as a kind of gap year, halfway through secondary school.</p><p>There’s no curriculum for any part of TY, but core subjects – Irish, English, maths, PE – have to be covered in some form, for two hours a week. Work experience is recommended at two to four weeks a year; career guidance and social, personal and health education (SPHE) for an hour a week. Otherwise, schools decide for themselves what to do.</p><p>Hare canters through what’s going on in his TY for 2024-25: nine weeks each of Chinese, folklore and law; nine weeks of BodyRight, a consent, relationships and friendship workshop devised by Dublin Rape Crisis Centre. Then there’s everything from aviation to arts, coding to car maintenance, political engagement to boxing. There’s a young scientist programme, with two separate blocks of work experience. As part of a Stem module, two former police officers set up a crime scene and show kids how to run an investigation.</p><p>Even though you’re not graded, you do have to participate: Paul Mescal recalled being dragged into musicals on his TY at his Maynooth post-primary. He ended up being cast as the lead in their production of Phantom of the Opera. “I know for a fact I probably wouldn’t have auditioned because of the masculinity that I’d been prescribed by being on a sports team,” he later said. “But since we all <em>had</em> to audition, I was, like, ‘Well, I may as well put my best foot forward.’”</p><p>Cillian Murphy also became an actor during his TY, via a theatre workshop that not only fostered a passion for the stage but introduced him to the artistic director Pat Kiernan, who later cast him in his breakthrough production, Disco Pigs. “I remember loving it,” Murphy <a href="https://www.thesun.ie/tvandshowbiz/5020549/cillian-murphy-raising-kids-peaky-blinders/" data-link-name="in body link">later said</a>. “It felt like a real oasis between the junior cycle and the senior cycle.”</p><figure id="c93c3584-9e57-4a0a-a88a-a48bd4a5414d" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A teacher and three students during a school’s anti-racism week" src="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A teacher and students during anti-racism week.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>It’s not always the razzle-dazzle stuff that students talk about. Kacey, who is 17 and in her final senior year at Kishoge, is studying for her driving theory test. “I’m terrified of the road,” she says. “If I hop in a car, I’m crashing into a wall. But in the modules, seeing that it’s not so easy for everyone else – it’s a slow work-up, knowing how stuff works.” Stuff like: what do you put on a CV? How do you acclimatise your parents to the new reality that you’re a young adult? How do you use a bus timetable? How do you address a citizens’ assembly on the subject of drug abuse? How do you make a burrito? “TY says, ‘OK, you need to know this soon. Sit down, we’re going to teach it to you, we’re not just going to expect you to guess.’”</p><p>Transition year is either 50 years old this year, or 30, depending on whether you date it from the first pilot schools in 1974, or the national rollout in 1994. Now, 99% of schools offer TY programmes, and almost 80% of students choose it.</p><p>It was the brainchild of Richard Burke, a passionate internationalist who joined the Fine Gael party to deepen Ireland’s relationship with <a href="https://www.theguardian.com/world/europe-news" data-link-name="in body link" data-component="auto-linked-tag">Europe</a>, but arguably made his greatest impact with his maverick views on education and child development. “The original idea was to create a space for kids where they could take a year out, and appreciate some of the finer arts – classical music, great literature, that sort of thing,” says Burke’s son David, a barrister. Burke, who died in 2016, had grown up in rural Tipperary in a large, extremely poor family, fatherless as a result of the second world war. What he really wanted to close was the cultural gap between rich and poor – the fact that, as seriously as education has always been taken in Ireland, it had a grindstone quality, every moment maximised for some measurable self-improvement. Gerry Jeffers, a semi-retired researcher and lecturer who was a driving force in rolling out TY in the 90s, said the idea was to “take a break from the treadmill. A bit of the spirit of that lovely poem: ‘What is this life if, full of care, we have no time to stand and stare?’”</p><p>It started in three schools, in Dublin, Limerick and County Galway, and it was a little wild, to be honest. Sheelagh Hare, Niall’s sister who now lives in Australia, did her school’s pilot TY in 1978 and, she says, “We didn’t do anything like they do now. There was none of that zip-lining.” Instead, they did six UK O-levels, when they’d just come out of Junior Certification, so ended up with a bunch of random sort-of duplicated qualifications. “The teachers didn’t really know what to do with us. But I was quite young in my mindset, so I got a lot out of just having an extra year.”</p><p>That, emphatically, would not have been what Burke had in mind. And there would be elements of even the best of a modern transition year which he wouldn’t be thrilled about either, David says: “I think he’d be a little bit disappointed, although not terribly, by the fact that kids are using part of the year for work experience.” If the TY was initially conceived as a pause in the commodification of the human experience, the way it has evolved reveals a lot about our changing expectations of the market, what we’ve surrendered to it and what we still hope to preserve.</p><figure id="23ea7e47-80ff-42f6-ad21-feccc8df5445" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="An overhead shot of students at Kishoge community college" src="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Kishoge community college.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>The pilot scheme was enough of a success that the government put some money behind it in the 1990s – approximately £50 a student, Jeffers remembers – and it was expanded to almost every school, to considerable resistance from educators, who thought parents wouldn’t have it, which initially they didn’t. “Regularly on radio phone-ins in the 90s, people would say, ‘It’s a waste of time,’” says Jeffers. “My attitude was: let people have their say. If this thing is working, parents are soon going to phone in with the other side of the story. When they experienced it, they saw it as fantastic – they could see their youngsters growing and developing and maturing and gaining confidence.”</p><p>What comes up now on those phone-ins is still that it’s a “doss year”, plus objections to the fact that kids can be 19 before they finish school, so – in the memorable image of <a href="https://www.tiktok.com/@newstalkfm/video/7403284261609983265" data-link-name="in body link">one radio DJ</a> – “you see fellas with full beards now in sixth year”. “Every transition year is different,” Niall tells me, walking through the high-ceilinged corridors of his school, which opened in 2014. It’s anti-racism week, and downstairs, mid-morning, people are fixing up a pot luck lunch. Students have brought in the cuisine of their forebears. The place smells delicious. Hare says “it’s a myth that it’s a doss year”, in his experience, and “the second myth is that the kids lose the habit of study”.</p><p>After TY comes two years of the senior cycle culminating in the Leaving Cert, scored out of a maximum of 625 and highly deterministic of what university and course you can apply for (another way to string out your school career until you have a full beard is to retake that for a higher score). An <a href="https://www.esri.ie/publications/the-transition-year-programme-an-assessment" data-link-name="in body link">ESRI study</a>, albeit 20 years old, found that students who did a transition year got an average of 40 more points that those who went straight into the senior cycle, while repeating students only got an average of five more points.</p><p>The data is complicated by the fact that TY is meant to be an escape from “all the pressure on points, points, points”, Jeffers says, exasperated. “Transfer rates to tertiary institutions. What’s a good school? Is it how many of those people went off to Trinity, or did the students discover something about themselves?” (If we want to get “points, points, points” about it, though, Ireland performs far <a href="https://www.oecd.org/en/publications/pisa-2022-results-volume-i-and-ii-country-notes_ed6fbcc5-en/ireland_01173012-en.html" data-link-name="in body link">above the OECD average</a> in maths and science, and in literacy, it is second only to Singapore.)</p><p>Those discoveries students make about themselves are completely idiosyncratic. Scott, 17, went in to TY thinking he wanted to be a coder and came out wanting to study psychology. Jess, 17, says “before TY I was really nose-in-books, always English/theoretical based. I did the coding module, and as a result of that, I’ve ended up doing computer science.” Niamh, 18, discovered hiking is not as bad as it looks. Sive, 18, did a module on drug abuse and has since addressed a citizens’ assembly, and has spoken to the Irish finance minister “to increase the drug prevention budget and try to increase the personal budget”. Oh, also, “I’m changing a tyre, I’m cooking. There was one teacher, I didn’t peep a word in his class. After TY, now I’m in fifth year, I’ll sit in his room and eat my lunch.”</p><figure id="75681756-3111-484d-b754-5c5cd0cdca33" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Learning cycling skills" src="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Learning cycling skills.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>That is echoed in the teachers’ experience: they say TY deepens their relationships with students, and, freed from a curriculum, they can explore their own passions. Dale McCarthy, 37, says he emigrated to Ireland from England, having taught in Manchester and two large London comprehensives. “When I was in the UK, the class’s grades were mine. Now, they don’t feel like my results. They belong to an individual. I was blown away by that: ‘Oh right, the students are in charge of their own learning.’ As teachers, we’re trusted. The levels of bureaucracy are much lower. No one’s checking to see if I taught my lessons. If I was in the room, I taught it.” In London, he was burnt out and doubted he’d be teaching till he was 50; now, he says, he’s probably a lifer. Teaching has a much higher status in Ireland, and transition year both recognises and contributes to that.</p><p>Against all that positivity, though, transition year doesn’t happen in a bell jar. Kishoge is one of 118 “<a href="https://www.educatetogether.ie/" data-link-name="in body link">Educate Together</a>” schools in Ireland – part of a drive to break the stranglehold the Catholic church has had over education. Its founding values are that it’s democratically run, equality-based, learner-centred and co-educational, and it has special educational needs provision where kids with disabilities can dip in and out of mainstream education, including TY. “It’s not that complicated, to go between sensory needs support and horticulture,” Eve Brennan, the SEN coordinator, says.</p><p>Kishoge isn’t, in other words, necessarily representative of the wider social experience. <a href="https://www.oco.ie/app/uploads/2024/09/OCO-In-Focus-Fair-Access-to-Transition-Year-2.pdf" data-link-name="in body link">A report</a> this year by Ireland’s ombudsman for children registered “complaints about equitable access” and “inconsistencies in admission” to TY in schools around the country. Kids could be excluded for behavioural incidents that they had no idea would have major repercussions, for example (in one memorable case study, a boy was refused a place because he’d been bullied in third year).</p><p>Then there is the financial aspect of TY: some parents just can’t afford it. Although the government covers the baseline costs of the teachers, plus offering extra funding per student and grants that are means-tested, the cost to parents can be prohibitive, at anywhere between €100 and €900. The ombudsman has castigated this, saying all children have a right to participate, and calling for “a specific child’s rights framework with guiding principles on how schools should administer admission to this highly desirable and beneficial year in school”.</p><p>Mid-afternoon outside Kishoge, Michael Manners is showing the transition year class how to mend a bike puncture and cycle a roundabout. Their skills vary wildly, and make me think back to the first time I cycled a roundabout, which was a total guess. (I didn’t even know you gave way to the right; I thought the rule was “whoever’s the bravest”.) As much as the principle that all kids have a right to participate might shine an unflattering light on contextual inequalities, the scheme is still a good one. It’s great to find your calling during Phantom of the Opera. It’s also great if you know how to cycle a roundabout.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Winamp deletes entire GitHub source code repo after a rocky few weeks (294 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/</link>
            <guid>41861056</guid>
            <pubDate>Wed, 16 Oct 2024 16:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/">https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/</a>, See on <a href="https://news.ycombinator.com/item?id=41861056">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>Winamp, through its Belgian owner Llama Group, posted the source for its "Legacy Player Code" on September 24 so that developers could "contribute their expertise, ideas, and passion to help this iconic software evolve."</p>
<p>Less than a month later, that <a href="https://github.com/WinampDesktop">repository has been entirely deleted</a>, after it either bumped up against or broke its strange hodgepodge of code licenses, seemingly revealed the source code for other non-open software packages, and made a pretty bad impression on the open-source community.</p>
<h2>"Collaborative" licensing</h2>
<p>Winamp's code was made available in late September, but not very open. Under the "<a href="https://github.com/WinampDesktop/winamp?tab=License-1-ov-file#readme">Winamp Collaborative License (WCL) Version 1.0.1</a>," you may not "distribute modified versions of the software" in source or binary, and "only the maintainers of the official repository are allowed to distribute the software and its modifications." Anyone may contribute, in other words, but only to Winamp's benefit.</p>
<p>Justin Frankel, a key developer of the original Winamp and founder of Nullsoft, which also made SHOUTcast streaming software, was <a href="https://www.askjf.com/index.php?q=7357s">asked on his Q&amp;A site</a> about contributing to the code. Frankel responded that, even if he had some desire, the license terms "are completely absurd in the way they are written." Even taking them "as they are likely intended," Frankel wrote, "they are terrible. No thank you."</p>
<p>Despite how this license would seem to bar forks, or perhaps <em>because</em> of that, the code has been <a href="https://github.com/WinampDesktop/winamp/forks">forked at least 2,600 times as of this writing</a>. In forking and examining the source when first released, coders have noticed some, shall we say, anomalies:</p>
<ul>
<li>Large portions of <a href="https://github.com/WinampDesktop/winamp/issues/265">other projects' code</a>, offered under other, more robust licenses, were seemingly included (<a href="https://github.com/WinampDesktop/winamp/commit/e721b2e039742c12c1f9c93b1b779ca3b7fc061e">if later deleted</a>) from Winamp's repository</li>
<li>The original Winamp code may have <a href="https://github.com/WinampDesktop/winamp/issues/11">leaked the source code for SHOUTcast server software</a></li>
<li>In seeking to remove offending files with a simple deletion instead of a rebase, <a href="https://github.com/WinampDesktop/winamp/issues/11#issuecomment-2371838502">Winamp kept it available</a> to those who know Git mechanics</li>
<li>Proprietary packages from Intel and Microsoft were also seemingly <a href="https://github.com/WinampDesktop/winamp/pull/1378">included</a> in the release's build tools</li>
</ul>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ArchiveBox is evolving: the future of self-hosted internet archives (432 pts)]]></title>
            <link>https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement</link>
            <guid>41860909</guid>
            <pubDate>Wed, 16 Oct 2024 16:18:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement">https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement</a>, See on <a href="https://news.ycombinator.com/item?id=41860909">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <div id="doc">

&lt;center&gt;

&lt;img src="https://docs.monadical.com/uploads/213b6618-e133-4b6b-a74a-267de68606aa.png" style="width: 140px"&gt;

    
# Big changes are coming to ArchiveBox!

*New features coming to the future of self-hosting internet archives: a full plugin ecosystem, P2P sharing between instances, Cloudflare/CAPTCHA solving, auto-logins, and more...*.
    

&lt;/center&gt;
&lt;hr/&gt;

In the wake of the [recent attack](https://www.theverge.com/2024/10/9/24266419/internet-archive-ddos-attack-pop-up-message) against Archive.org, [ArchiveBox](https://archivebox.io) has been getting some increased attention from people wondering how to **self-host their own internet archives**.

![](https://docs.monadical.com/uploads/23a752d2-2a25-4e9b-98e9-81ee6fd94601.png)


ArchiveBox is a strong supporter of Archive.org and their mission to preserve all of human knowledge. We've been donating for years, and we urge you to do the same, they provide an invaluable service for all of humanity. 

We completely condemn the DDoS and defacement of their site, and hope it never happens again. Realistically though, they are an attractive target for people who want to supress information or [start IP lawsuits](https://blog.archive.org/2024/07/01/what-happened-last-friday-in-hachette-v-internet-archive/), and this may not be the last time this happens...

&lt;br/&gt;

![](https://docs.monadical.com/uploads/0fe1c7e3-0788-4cfc-a23e-b1ff02321a7c.png)

&lt;br/&gt;

&gt; We envision a future where the world has both a robust centralized archive through Archive.org, and a widespread network of decentralized ArchiveBox.io instances.

&lt;center&gt;
&lt;a href="https://github.com/ArchiveBox/ArchiveBox"&gt;&lt;img src="https://docs.monadical.com/uploads/bac22f63-0fc9-4634-8fb8-67d29806e49c.png" style="max-width: 380px; border: 4px #915656 solid; border-radius: 15px; box-shadow: 4px 4px 4px rgba(0,0,0,0.09)"/&gt;&lt;/a&gt;
&lt;/center&gt;

&lt;br/&gt;

![](https://docs.monadical.com/uploads/96dbfd23-5592-4ea2-b9a0-5b379da564bf.png)


&lt;br/&gt;

### The Limits of Public Archives

In an era where fear of public scrutiny is very tangible, people are afraid of archiving things for eternity. As a result, people choose not to archive at all, effectively erasing that history forever.

We think people should have the power to archive what *matters to them*, on an individual basis. We also think people should be able to *share* these archives with only the people they want.

The modern web is a different beast than it was in the 90's and people don't necessarily want everything to be public anymore. Internet archiving tooling should keep up with the times and provide solutions to archive private and semi-private content in this changing landscape.

---

#### Who cares about saving stuff?

All of us have content that we care about, that we want to see preserved, but privately:

- families might want to preserve their photo albums off Facebook, Flickr, Instagram
- individuals might want to save their bookmarks, social feeds, or chats from Signal/Discord
- companies might want to save their internal documents, old sites, competitor analyses, etc.

&lt;sub&gt;*Archiving private content like this [has some inherent security challenges](https://news.ycombinator.com/item?id=41861455), and should be done with care.&lt;br/&gt;(e.g. how do you prevent the cookies used to access the content from being leaked in the archive snapshots?)*&lt;/sub&gt;

---

#### What if the content is evil?

There is also content that unfairly benefits from the existence of free public archives like Archive.org, because they act as a mirror/amplifier when original sites get taken down.

There is value in preserving racism, violence, and hate speech for litigation and historical record, but is there a way we can do it without effectively providing free *public* hosting for it?

![](https://docs.monadical.com/uploads/6eb36b1d-7a0f-4ffe-8d4d-20a74683ee04.png)

---

&lt;br/&gt;

&lt;center&gt;

## ✨ Introducing ArchiveBox's New Plugin Ecosystem ✨
    
&lt;/center&gt;

&lt;br/&gt;

[ArchiveBox v0.8](https://github.com/ArchiveBox/ArchiveBox/releases) is shaping up to be the [**biggest release in the project's history**](https://github.com/ArchiveBox/ArchiveBox/pull/1311). We've completely re-architected the internals for speed and performance, and we've opened up access to allow for a new plugin ecosystem to provide community-supported features.

![](https://docs.monadical.com/uploads/e2ae70b1-2c9c-42b7-a2ca-a0a2b1bd1ae1.png)


We want to follow in the footsteps of great projects like [NextCloud](https://apps.nextcloud.com/) and [Home Assistant](https://www.home-assistant.io/addons/), and provide a robust "app store" for functionality around bookmark management, web scraping, capture, and sharing.

#### 🧩 Here's just a taste of some of the first plugins that will be provided:

- `yt-dlp` for video, audio, subtitles, from Youtube, Soundcloud, YouKu, and more...
- `papers-dl` for automatic download of scientific paper PDFs when DOI numbers are seen
- `gallery-dl` to download photo galleries from Flickr, Instagram, and more
- `forum-dl` for download of older forums and deeply nested comment threads
- `readability` for article text extraction to .txt, .md, .epub
- **`ai`** to send page screenshot + text w/ a custom prompt to an LLM + save the response
- **`webhooks`** trigger any external API, ping Slack, N8N, etc. whenever some results are saved
- and [many more...](https://github.com/ArchiveBox/ArchiveBox/tree/dev/archivebox/plugins_extractor)

If you're curious, the plugin system is based on the excellent, well-established libraries [pluggy](https://pluggy.readthedocs.io/en/stable/index.html) and [pydantic](https://pydantic-docs.helpmanual.io/). It was a fun challenge to develop a plugin system without over-engineering it, and it took a few iterations to get right!

&gt; I'm excited for the future this will bring! It will allow us to keep the **core** lean and high-quality while getting community help supporting a **wide periphery** of plugins.

&lt;br/&gt;

#### ✨ Other things in the  works:

- There is an all-new [`REST API`](https://demo.archivebox.io/api) built with `django-ninja`, already [available in BETA](https://github.com/ArchiveBox/ArchiveBox/releases)
- [Support for external storage](https://github.com/ArchiveBox/ArchiveBox/wiki/Setting-Up-Storage) (AWS/B2/GCP/Google Drive/etc.) (via `rclone`) was added
- We've started adding the beginnings of a content-addressable store system with unique "ABID"s (identifiers based on URL + timestamp) that can be shared between instances. This will help us build BitTorrent/IPFS-backed P2P sharing between instances in the future.
- We've added a background job system using [`huey`](https://huey.readthedocs.io/)
- new auto-install system `archivebox install` (no more complex `apt` dependencies)
  *(plugin's cross-platform runtime dependencies are very hard to package and maintain, check out our new [`pydantic-pkgr`](https://github.com/ArchiveBox/pydantic-pkgr) library that solves this and use it in your projects!)*

&gt; ArchiveBox is designed to be local-first with [**SQLite**](https://www.sqlite.org/famous.html), P2P will always be optional.

&lt;br/&gt;


#### 🔢 For the minimalists who just want something simple:

If you're an existing ArchiveBox user and feel like this is more than you need, don't worry, we're also releasing a new tool called `abx-dl` that will work like like `yt-dlp` or `gallery-dl`.

It will provide a one-shot CLI to quickly download *all* the content on any URL you provide it without having to worry about complex configuration, plugins, setting up a collection, etc.

&lt;br/&gt;

---

&lt;br/&gt;

### 🚀 Try out the new BETA now!

```bash
pip install archivebox==0.8.5rc44
archivebox install
# or
docker pull archivebox/archivebox:dev
```
📖 *Read the release notes for the new BETAs on our [Releases](https://github.com/ArchiveBox/ArchiveBox/releases) page on Github.*

💬 *[Join the discussion on HN](https://news.ycombinator.com/item?id=41860909) or over on our [Zulip forum](https://zulip.archivebox.io/).*

💁‍♂️ *Or [hire us](https://github.com/ArchiveBox/archivebox#-professional-integration) to provide digital preservation for your org (we provide CAPTCHA/Cloudflare bypass, popup/ad hiding, on-prem/cloud, SAML/SSO integration, audit logging, and more).*


&lt;br/&gt;&lt;br/&gt;

&lt;img src="https://docs.monadical.com/uploads/a790d511-db5c-49ae-a3d9-db41e4100f20.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/4233a584-3903-4610-9016-06d1b59ac682.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/63a73bfc-f028-40c4-885c-ad011c7e191a.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/e621d80f-87d4-4ade-8fb9-9e0e6ab42a7f.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/26285bd6-f240-41e3-99b7-70d50463e3b7.png" style="width: 19.9%"/&gt;

&lt;center&gt;

[Donate to ArchiveBox](https://hcb.hackclub.com/donations/start/archivebox) &lt;sup&gt;(tax-deductible!)&lt;/sup&gt; to support our open-source development.&lt;br/&gt;&lt;br/&gt;Remember to also donate to [Archive.org](https://help.archive.org/help/how-do-i-donate-to-the-internet-archive/) &lt;sup&gt;(not affiliated)&lt;/sup&gt; to help them with the attack!

&lt;/center&gt;</div>
    
    
    










</div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's not enough for a program to work – it has to work for the right reasons (110 pts)]]></title>
            <link>https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/</link>
            <guid>41860135</guid>
            <pubDate>Wed, 16 Oct 2024 15:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/">https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/</a>, See on <a href="https://news.ycombinator.com/item?id=41860135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                    <date>
                        
                            October 16, 2024
                        </date>
                
                
                
                    <h2>
                        Successful software is buggy software.
                    </h2>
                

                

                
                    
                        <p>From Leslie Lamport's <em>Specifying Systems</em>:</p>
<blockquote>
<p>You should be suspicious if [the model checker] does not find a violation of a liveness property... you should also be suspicious if [it] finds no errors when checking safety properties. </p>
</blockquote>
<p>This is specifically in the context of model-checking a formal specification, but it's a widely applicable software principle. It's not enough for a program to work, it has to work for the <em>right reasons</em>. Code working for the wrong reasons is code that's going to break when you least expect it. And since "correct for right reasons" is a much narrower target than "correct for any possible reason", we can't assume our first success is actually our intended success.</p>
<p>Hence, BSOS: <strong>Be Suspicious of Success</strong>.</p>
<h3>Some useful BSOS practices</h3>
<p>The standard way of dealing with BSOS is verification. Tests, static checks, model checking, etc. We get more confident in our code if our verifications succeed. But then we also have to be suspicious of <em>that</em> success, too! How do I know whether my tests are passing because they're properly testing correct code or because they're failing to test incorrect code?</p>
<p>This is why test-driven development gurus tell people to write a failing test first. Then at least we know the tests are doing <em>something</em> (even if they still might not be testing what they want).</p>
<p>The other limit of verification is that it can't tell us <em>why</em> something succeeds. Mainstream verification methods are good at explaining why things <em>fail</em>— expected vs actual test output, type mismatches, specification error traces. Success isn't as "information-rich" as failure. How do you distinguish a faithful implementation of <a href="https://en.wikipedia.org/wiki/Collatz_conjecture" target="_blank"><code>is_collatz_counterexample</code></a> from <code>return false</code>?</p>
<p>A broader technique I follow is <em>make it work, make it break</em>. If code is working for the right reasons, I should be able to predict how to break it. This can be either a change in the runtime (this will livelock if we 10x the number of connections), or a change to the code itself (commenting out <em>this</em> line will cause property X to fail). <sup id="fnref:superproperties"><a href="#fn:superproperties">1</a></sup> If the code still works even after the change, my model of the code is wrong and it was succeeding for the wrong reasons.</p>
<h3>Happy and Sad Paths</h3>

<p>A related topic (possibly subset?) is "happy and sad paths". The happy path of your code is the behavior when everything's going right: correct inputs, preconditions are satisfied, the data sources are present, etc. The sad path is all of the code that handles things going wrong. Retry mechanisms, insufficient user authority, database constraint violation, etc. In most software, the code supporting the sad paths dwarfs the code in the happy path.</p>
<p>BSOS says that I can't just show code works in the happy path, I also need to check it works in the sad path. </p>
<p>BSOS also says that I have to be suspicious when the sad path works properly, too. </p>
<p>Say I add a retry mechanism to my code to handle the failure mode of timeouts. I test the code and it works. Did the retry code actually <em>run</em>? Did it run <em>regardless</em> of the original response? Is it really doing exponential backoff? Will stop after the maximum retry limit? Is the sad path code <em>after</em> the maximum retry limit working properly?</p>
<p><a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf" target="_blank">One paper</a> found that 35% of catastrophic distributed system failures were caused by "trivial mistakes in error handlers" (pg 9). These were in mature, battle-hardened programs. Be suspicious of success. Be more suspicious of sad path success.</p>
<hr>
<h2>Blog Rec</h2>
<p>This week's blog rec is <a href="https://www.redblobgames.com/" target="_blank">Red Blob Games</a>!<sup id="fnref:blogs-vs-articles"><a href="#fn:blogs-vs-articles">2</a></sup> While primarily about computer game programming, the meat of the content is beautiful, interactive guides to general CS algorithms. Some highlights:</p>
<ul>
<li><a href="https://www.redblobgames.com/pathfinding/a-star/introduction.html" target="_blank">Introduction to the A* Algorithm</a> was really illuminating when I was a baby programmer.</li>
<li>I'm sure this <a href="https://www.redblobgames.com/articles/noise/introduction.html" target="_blank">overview of noise functions</a> will be useful to me <em>someday</em>. Maybe for test data generation?</li>
<li>If you're also an explainer type he has a lot of great stuff on <a href="https://www.redblobgames.com/making-of/line-drawing/" target="_blank">his process</a> and his <a href="https://www.redblobgames.com/making-of/little-things/" target="_blank">little tricks</a> to make things more understandable.</li>
</ul>
<p>(I don't think his <a href="https://www.redblobgames.com/blog/posts.xml" target="_blank">rss feed</a> covers new interactive articles, only the <a href="https://www.redblobgames.com/blog/" target="_blank">blog</a> specifically.)</p>

                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.com/hillelwayne" target="_blank">here</a>. Updates are once a week. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
<p><em>My new book, </em>Logic for Programmers<em>, is now in early access! Get it <a href="https://leanpub.com/logic/" target="_blank">here</a>.</em></p>
                

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Efficient high-resolution image synthesis with linear diffusion transformer (136 pts)]]></title>
            <link>https://nvlabs.github.io/Sana/</link>
            <guid>41859805</guid>
            <pubDate>Wed, 16 Oct 2024 14:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nvlabs.github.io/Sana/">https://nvlabs.github.io/Sana/</a>, See on <a href="https://news.ycombinator.com/item?id=41859805">Hacker News</a></p>
<div id="readability-page-1" class="page">
<!--    <div style="overflow: hidden; background-color: #6699cc;">-->
<!--      <div class="container">-->
<!--        <a href="https://www.nvidia.com/" style="float: left; color: black; text-align: center; padding: 12px 16px; text-decoration: none; font-size: 16px;"><img width="100%" src="https://nv-tlabs.github.io/3DStyleNet/assets/nvidia.svg"></a>-->
<!--        <a href="https://github.com/Efficient-Large-Model/" style="float: left; color: black; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 16px;"><strong>Efficient AI Group</strong></a>-->
<!--      </div>-->
<!--    </div>-->
    <div>
        <div>
            <p><img src="https://nvlabs.github.io/Sana/asset/logo.jpg" alt="Logo"></p>
        </div>
        <h2>Efficient High-Resolution Image Synthesis <br>
            with Linear Diffusion Transformer</h2>
        <p>Exploring the Frontiers of Efficient Generative Foundation Models</p>

        <!-- Add author and institution information -->
        <div>
            <p>
                <a href="https://xieenze.github.io/" target="_blank">Enze Xie</a><sup>1*</sup>,
                <a href="https://lawrence-cj.github.io/" target="_blank">Junsong Chen</a><sup>1*</sup>,
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;user=mWdYMZ8AAAAJ" target="_blank">Junyu Chen</a><sup>2,3</sup>,
                <a href="https://han-cai.github.io//" target="_blank">Han Cai</a><sup>1</sup>,
                <a href="http://kentang.net/" target="_blank">Haotian Tang</a><sup>2</sup>,<br>
                <a href="https://yujunlin.com//" target="_blank">Yujun Lin</a><sup>2</sup>,
                <a href="https://hanlab.mit.edu/team/zhekai-zhang/" target="_blank">Zhekai Zhang</a><sup>2</sup>,
                <a href="https://lmxyy.me//" target="_blank">Muyang Li</a><sup>2</sup>,
                <a href="https://lzhu.me//" target="_blank">Ligeng Zhu</a><sup>1</sup>,
                <a href="https://scholar.google.com/citations?user=OI7zFmwAAAAJ&amp;hl=en/" target="_blank">Yao Lu</a><sup>1</sup>,
                <a href="https://hanlab.mit.edu/songhan/" target="_blank">Song Han</a><sup>1,2</sup>
            </p>
            <p>
                <sup>1</sup>NVIDIA, <sup>2</sup>MIT, <sup>3</sup>Tsinghua University
                <br>
                *Project co-lead
            </p>
        </div>
<!--        <div style="overflow: hidden; background-color: #6699cc;">-->
        

        <p><a href="https://arxiv.org/abs/2410.10629">Paper</a>
        <a href="https://github.com/NVlabs/Sana">Code (Coming soon)</a>
    </p></div>

    

    <!-- The Modal -->
    <div id="modal" onclick="this.style.display='none'">
      <p><img id="modal-img" src=""></p> <!-- Text for description -->
    </div>

    <section>
        <div>
          <h2>About Sana</h2>
          <p>We introduce Sana, a text-to-image framework that can efficiently generate images up to 4096 × 4096 resolution.
                    Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed,
                    deployable on laptop GPU. Core designs include:
                    <strong>Deep compression autoencoder: </strong> unlike traditional AEs, which compress images only 8×,
                        we trained an AE that can compress images 32×, effectively reducing the number of latent tokens.
                    <strong>Linear DiT: </strong> we replace all vanilla attention in DiT with linear attention, which is more efficient at high resolutions without sacrificing quality.
                    <strong>Decoder-only text encoder: </strong> we replaced T5 with modern decoder-only small LLM as the text encoder and designed
                        complex human instruction with in-context learning to enhance the image-text alignment.
                    <strong>Efficient training and sampling: </strong> we propose Flow-DPM-Solver to reduce sampling steps,
                        with efficient caption labeling and selection to accelerate convergence.<br>
                    As a result, Sana-0.6B is very competitive with modern giant diffusion model (e.g. Flux-12B),
                    being 20 times smaller and 100+ times faster in measured throughput.
                    Moreover, Sana-0.6B can be deployed on a 16GB laptop GPU, taking less than 1 second to generate a 1024 × 1024 resolution image.
                    Sana enables content creation at low cost.</p>
        </div>

        <!-- Insert your image here -->
        <p><img src="https://nvlabs.github.io/Sana/asset/content/latency_compare.jpg" alt="latency comparison with SOTA methods">

        </p>

        <div>
          <h2>Several Core Design Details for Efficiency</h2>
          <p>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp;  <strong>Deep Compression Autoencoder: </strong>
              We introduce a new Autoencoder (AE) that aggressively increases the scaling factor to 32.
              Compared with AE-F8, our AE-F32 outputs 16× fewer latent tokens, which is crucial for efficient training
              and generating ultra-high-resolution images, such as 4K resolution.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Efficient Linear DiT: </strong>
              We introduce a new linear DiT, replacing vanilla quadratic attention and reducing complexity from O(N<span><sup>2</sup></span>) to O(N)
              Mix-FFN, with 3×3 depth-wise convolution in MLP, enhances the local information of tokens.
              Linear attention achieves comparable results to vanilla, improving 4K generation by 1.7× in latency.
              Mix-FFN also removes the need for positional encoding (NoPE) without quality loss, marking the first DiT without positional embedding.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Decoder-only Small LLM as Text Encoder: </strong>
              We use Gemma, a decoder-only LLM, as the text encoder to enhance understanding and reasoning in prompts.
              Unlike CLIP or T5, Gemma offers superior text comprehension and instruction-following.
              We address training instability and design complex human instructions (CHI) to leverage Gemma’s in-context learning,
              improving image-text alignment.<br>
          </p>
        </div>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/model-incremental.jpg" alt="pipeline for Sana">
        </p>

        <p>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Efficient Training and Inference Strategy: </strong>
              We propose automatic labeling and training strategies to improve text-image consistency.
              Multiple VLMs generate diverse re-captions, and a CLIPScore-based strategy selects high-CLIPScore captions to enhance convergence and alignment.
              Additionally, our <strong>Flow-DPM-Solver</strong> reduces inference steps from 28-50 to 14-20 compared to the Flow-Euler-Solver, with better performance.
            </p>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/sampler.jpg" alt="flow-dpms vs flow-euler">
        </p>

        <div>
          <h2>Overall Performance</h2>
            <p>We compare Sana with the most advanced text-to-image diffusion models in Table 1. For 512 × 512 resolution,
                Sana-0.6 demonstrates a throughput that is 5× faster than PixArt-Σ, which has a similar model size,
                and significantly outperforms it in FID, Clip Score, GenEval, and DPG-Bench. For 1024 × 1024 resolution,
                Sana is considerably stronger than most models with &lt;3B parameters and excels in inference latency.
                Our models achieve competitive performance even when compared to the most advanced large model FLUX-dev.
                For instance, while the accuracy on DPG-Bench is equivalent and slightly lower on GenEval,
                Sana-0.6B’s throughput is 39× faster, and Sana-1.6B is 23× faster.</p>
        </div>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/performance.jpg" alt="Sana performance">
        </p>

        <!-- Video Section -->
        <p>
            <h2>Sana-0.6B is Deployable on Laptop GPU</h2>
        </p>
        <p>
            <video controls="">
                <source src="https://nvlabs.github.io/Sana/asset/video/Sana-0.6B-laptop.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </p>
        <!-- End Video Section -->

        <div>
            <h2>Our Mission</h2>
            <p>Our mission is to develop <strong>efficient, lightweight, and accelerated</strong>
                AI technologies that address practical challenges and deliver fast, open-source solutions.</p>
        </div>

        <!--BibTex citation -->
        <p>
            <h2>BibTeX</h2>
        </p>
        <div id="BibTeX">
                <pre><code>@misc{xie2024sana,
      title={Sana: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer},
      author={Enze Xie and Junsong Chen and Junyu Chen and Han Cai and Haotian Tang and Yujun Lin and Zhekai Zhang and Muyang Li and Ligeng Zhu and Yao Lu and Song Han},
      year={2024},
      eprint={2410.10629},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.10629},
    }</code></pre>
            </div>

    </section>
    <!--End BibTex citation -->

    <!-- Footer Section -->
    
    <!-- End Footer -->

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Un Ministral, Des Ministraux (171 pts)]]></title>
            <link>https://mistral.ai/news/ministraux/</link>
            <guid>41859466</guid>
            <pubDate>Wed, 16 Oct 2024 14:31:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/ministraux/">https://mistral.ai/news/ministraux/</a>, See on <a href="https://news.ycombinator.com/item?id=41859466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introducing-the-worlds-best-edge-models">Introducing the world’s best edge models</h2><p>On the first anniversary of the release of Mistral 7B, the model that revolutionized independent frontier AI innovation for millions, we are proud to introduce two new state-of-the-art models for on-device computing and at-the-edge use cases. We call them les Ministraux: Ministral 3B and Ministral 8B.</p><p>These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category, and can be used or tuned to a variety of uses, from orchestrating agentic workflows to creating specialist task workers. Both models support up to 128k context length (currently 32k on vLLM) and Ministral 8B has a special interleaved sliding-window attention pattern for faster and memory-efficient inference.</p><h3 id="use-cases">Use cases</h3><p>Our most innovative customers and partners have increasingly been asking for local, privacy-first inference for critical applications such as on-device translation, internet-less smart assistants, local analytics, and autonomous robotics. Les Ministraux were built to provide a compute-efficient and low-latency solution for these scenarios. From independent hobbyists to global manufacturing teams, les Ministraux deliver for a wide variety of use cases.</p><p>Used in conjunction with larger language models such as Mistral Large, les Ministraux are also efficient intermediaries for function-calling in multi-step agentic workflows. They can be tuned to handle input parsing, task routing, and calling APIs based on user intent across multiple contexts at extremely low latency and cost.</p><h3 id="benchmarks">Benchmarks</h3><p>We demonstrate the performance of les Ministraux across multiple tasks where they consistently outperform their peers. We re-evaluated all models with our internal framework for fair comparison.</p><h4 id="pretrained-models">Pretrained Models</h4><p><img src="https://mistral.ai/images/news/ministraux/pretrain_table.png" alt="Pretrained model comparison table" width="80%"></p><p><b>Table 1:</b> Ministral 3B and 8B models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B and Mistral 7B on multiple categories</p><p><img src="https://mistral.ai/images/news/ministraux/pretrain_with_gemma.png" alt="Pretrained model comparison graph" width="80%"></p><p><b>Figure 1:</b> Ministral 3B and 8B base models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B and Mistral 7B</p><h4 id="instruct-models">Instruct Models</h4><p><img src="https://mistral.ai/images/news/ministraux/instruct_table_with_gemma.png" alt="Instruct model comparison table" width="80%"></p><p><b>Table 2:</b> Ministral 3B and 8B Instruct models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B, Gemma 2 9B and Mistral 7B on different evaluation categories.</p><p><img src="https://mistral.ai/images/news/ministraux/instruct_plot_3b_no_qwen_with_mistral_logo.png" alt="3B Instruct model comparison graph" width="80%"></p><p><b>Figure 2:</b> A comparison of the 3B family of Instruct models - Gemma 2 2B, Llama 3.2 3B and Ministral 3B. The figure showcases the improvements of Ministral 3B over the much larger Mistral 7B.</p><p><img src="https://mistral.ai/images/news/ministraux/instruct_plot_8b_with_mistral_logo.png" alt="8B Instruct model comparison graph" width="80%"></p><p><b>Figure 3:</b> A comparison of the 8B family of Instruct models - Gemma 2 9B, Llama 3.1 8B, Mistral 7B and Ministral 8B.</p><h3 id="availability-and-pricing">Availability and pricing</h3><p>Both models are available starting today.</p><table><thead><tr><th>Model</th><th>API</th><th>Pricing on la Plateforme</th><th>License</th></tr></thead><tbody><tr><td>Ministral 8B</td><td>ministral-8b-latest</td><td>$0.1 / M tokens (input and output)</td><td>Mistral Commercial License<br>Mistral Research License</td></tr><tr><td>Ministral 3B</td><td>ministral-3b-latest</td><td>$0.04 / M tokens (input and output)</td><td>Mistral Commercial License</td></tr></tbody></table><p>For self-deployed use, <a href="https://mistral.ai/contact/">please reach out to us</a> for commercial licenses. We will also assist you in lossless quantization of the models for your specific use-cases to derive maximum performance.</p><p>The model weights for <a href="https://huggingface.co/mistralai/Ministral-8B-Instruct-2410">Ministral 8B Instruct</a> are available for research use. Both models will be available from our <a href="https://docs.mistral.ai/deployment/cloud/overview/">cloud partners</a> shortly.</p><h3 id="more-to-come">More to come</h3><p>At Mistral AI, we continue pushing the state-of-the-art for frontier models. It’s been only a year since the release of Mistral 7B, and yet our smallest model today (Ministral 3B) already outperforms it on most benchmarks. We can’t wait for you to try out les Ministraux and give us feedback.</p><p><img src="https://mistral.ai/images/news/ministraux/meme_cropped.png" alt="More to come" width="50%"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Traveling with Apple Vision Pro (320 pts)]]></title>
            <link>https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/</link>
            <guid>41859012</guid>
            <pubDate>Wed, 16 Oct 2024 13:48:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/">https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=41859012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The Vision Pro has quickly become an essential item that I take onto every flight.</p>



<p>It’s a fantastic device to travel with—Be it by train or by plane, it offers an unparalleled opportunity to selectively tune out your environment and sink into an engaging activity like watching a movie or just working on your laptop.&nbsp;</p>



<p>In this blog post, I’ll outline what I’ve learned about the Vision Pro while traveling, explain some of the functionality, shine light onto its drawbacks, as well as assess how it fares against solutions like a phone or a laptop.&nbsp;</p>



<p>For context, most of the traveling where I’ve brought my Vision Pro along has been on airplanes, but this applies to traveling by train as well.&nbsp;</p>



<hr>



<h2 id="table-of-contents">Table of Contents</h2>



<details><summary>Expand </summary>
<ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#table-of-contents">Table of Contents</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#packing-travel-setup">Packing / Travel Setup</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#user-experience">User Experience</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#airport-security-line">Airport Security Line</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#travel-mode">Travel Mode</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#battery-life-charging">Battery Life &amp; Charging</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#physical-comfort">Physical Comfort</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#social-comfort">Social Comfort</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#passthrough">Passthrough</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#ui-interaction">UI Interaction&nbsp;</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#virtual-environment-depth-collision-mitigation">Virtual Environment / Depth Collision Mitigation</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#airpods-pros-vision-pro">AirPods Pros + Vision Pro</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#eating-snacking">Eating/Snacking</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#works-in-complete-darkness">Works in Complete Darkness</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#watching-movies">Watching Movies</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#apps">Apps</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#visuals">Visuals</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#cinema-environment">Cinema Environment</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#benefits-of-privacy">Benefits of Privacy</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#special-film-formats">Special film formats </a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#audio">Audio</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#caveat-when-videos-doesn-t-play">Caveat: when videos doesn’t play</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#mac-virtual-display">Mac Virtual Display</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#no-more-laptop-screen-tilt-limitations">No More Laptop Screen Tilt Limitations </a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#higher-resolution-more-real-estate">Higher Resolution + More Real Estate </a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#privacy">Privacy</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#iphone-mirroring">iPhone Mirroring</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#conclusion">Conclusion</a></li></ol>
</details>



<hr>



<h2 id="packing-travel-setup">Packing / Travel Setup</h2>



<p>First and foremost, space in my suitcase or backpack while traveling is the most valuable commodity. Whenever I’m packing for a trip, anything that adds unnecessary bulk to my setup is immediately discarded.&nbsp;</p>



<p>For that reason, I highly recommend that you <strong>do NOT purchase</strong> the behemoth of the $200 Vision Pro “<a href="https://www.apple.com/shop/product/MW2F3LL/A/apple-vision-pro-travel-case">travel case</a>” from Apple. It’s unnecessarily massive and doesn’t fit into ANYTHING. Avoid it at all costs unless you absolutely need a crazy amount of protection from the elements (but at that point, might as well buy a Pelican case!).</p>



<figure><img loading="lazy" data-attachment-id="239" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-4/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg" data-orig-size="1926,1122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=1024" tabindex="0" role="button" width="1024" height="596" src="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=1024" alt=""><figcaption><em>The size of the official AVP Travel case size is wayy too big. (image credit: <a href="https://twitter.com/DanMillerDev/status/1814320337271583012">Dan Miller on Twitter)</a></em></figcaption></figure>



<p>My travel setup is super simple and minimal. </p>



<p>To protect the front glass, I use the “Vision Pro Cover” that comes by default with the headset and on the inside, I use this affordable, generic <a href="https://www.amazon.com/dp/B0CW9C6WF8?ref=ppx_pop_mob_ap_share">VR lens protector cover</a> to prevent anything from scratching the lenses. I then throw it into my backpack, face-first, sitting above the other items.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img loading="lazy" data-attachment-id="235" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/avp-packing2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AVP Packing2" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=768" tabindex="0" role="button" width="768" height="1024" data-id="235" src="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=768" alt=""><figcaption><em>Side view of my travel setup</em></figcaption></figure>



<figure><img data-attachment-id="234" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/avp-packing/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AVP Packing" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="234" src="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=768" alt=""><figcaption><em>Lens protection</em></figcaption></figure>



<figure><img data-attachment-id="238" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_1702-large/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1727017651&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.7&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;39.876122222222&quot;,&quot;longitude&quot;:&quot;-75.242325&quot;}" data-image-title="IMG_1702 Large" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="238" src="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=768" alt=""><figcaption><em>In my backpack</em></figcaption></figure>
</figure>



<p>I even use the space between the Solo strap and the headset itself as a place to put my rolled up puffer jacket or quarter-zip. This way, the only amount of space that it actually takes up is the thickness of the headset itself!&nbsp;</p>



<p>As for the battery pack, after charging it to 100%, I disconnect the battery, roll up the cord (while being aware of not adding extra stress to the connector) and throw into my backpack (either into a pocket or have it sit on the bottom).&nbsp;</p>



<p><strong>With this setup, I haven’t scratched or damaged the headset itself at all</strong> over the 5-10 flights that I’ve taken it on. Works quite well!</p>



<hr>



<h2 id="user-experience">User Experience</h2>



<h3 id="airport-security-line">Airport Security Line</h3>



<p>At the airport security line, I typically pull out my laptop and the Vision Pro from my backpack. Thankfully, it seems like the Vision Pro doesn’t look suspicious at all while being x-rayed as I haven’t been questioned about it yet.&nbsp;</p>



<h3 id="travel-mode">Travel Mode</h3>



<p>The Vision Pro’s 6DoF tracking system is built on a combination of IMU’s + SLAM cameras (same as any other VR headsets). Unlike other VR headsets, however, it has a native “Travel Mode” which accounts for the fact that using a 6DoF VR headset in a moving vehicle will lead to massive drift and tracking issues.</p>



<p>The Vision Pro’s Travel Mode was specifically designed to account for these tracking issues (essentially relying entirely on the SLAM cameras and ignoring the IMU data).</p>



<p>As I put on the headset, if the plane is a bit unstable, the Vision Pro detects that I’m on a plane and will suggest to turn on Travel Mode with an actionable notification, which is great because it eliminates any need to prepare the headset prior to boarding/take-off! This was a very deliberate design choice by Apple and is a <em>very</em> welcome one.&nbsp;</p>



		<figure>
			
			<figcaption><em>Vision Pro prompting me to activate Travel Mode</em> <em>based on tracking issues</em> <em>in moving vehicle</em>.</figcaption>
			
		</figure>
		


<p>I should mention that since the IMU data is ignored, the way the horizon is determined in Travel Mode tracking is purely by the orientation/rotation of your head. If your head is titled, so will all your virtual apps/windows. To fix this, you can cover your vision pro with your hands (to lock the cameras) and when you re-initialize, recenter your apps so that they adhere to the newly-determined horizon.</p>



<p>This might seem like a minor detail, but I find it immensely annoying if my windows are not parallel to the airplane’s ground plane.&nbsp;</p>



<h3 id="battery-life-charging">Battery Life &amp; Charging</h3>



<p>The 2.5-3 hr battery life of Apple Vision Pro is… fine.</p>



<p>It’s enough to watch a 90-120 minute movie and mayyybe an episode of a TV show. For short flights, this is perfectly adequate but for longer, transatlantic/transpacific flights, it’s obviously very much limited.&nbsp;</p>



<p>The best option to extend its battery life is if your plane seat has a 120/240V power outlet. Given that you have a minimum 30W charging adapter, you’ll be able to keep your Vision Pro charged indefinitely.&nbsp;</p>



<p>The next best option is having a high power output battery bank. I use a single 12k mAh Anker <a href="https://www.anker.com/products/a1335-130w-power-bank?variant=42691850797206">battery bank</a> (which can output up to 60W), so recharging the Vision Pro <em>does</em> eat up the entirety of the battery bank’s capacity. This is something to keep in mind if you need to keep your phone charged as well.</p>



<p>I should mention that I prioritize keeping my phone charged over my Vision Pro. A 12k mAh battery bank will recharge my phone 3-4 times while providing me the ability to watch multiple times more movies/TV shows, listen to podcasts, etc. If I have a long flight and I’m not sure that my seat will have a proper power outlet, I don’t rely on my Vision Pro to be my only form of entertainment for the entirety of the flight.</p>



<p>By the way, I typically place the battery pack in the pouch by my knees. The cable is the perfect length for it to reach my head without it feeling too long or too short. Nice! </p>



<figure><img data-attachment-id="281" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/cable/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728219640&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.019607843137255&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;53.424605555556&quot;,&quot;longitude&quot;:&quot;-6.2563888888889&quot;}" data-image-title="cable" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="768" src="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=1024" alt=""><figcaption><em>The cable is the perfect length when the battery is placed in the seat pouch.</em></figcaption></figure>



<h3 id="physical-comfort">Physical Comfort</h3>



<p>Now, if you’re like me and find the Vision Pro’s ergonomics and weight distribution to be utterly shit, I will highly recommend that you try to find a comfortable setup before you embark on your journey.&nbsp;</p>



<p>Having gone through <a href="https://twitter.com/Azadux/status/1757469190095781900">quite</a> <a href="https://twitter.com/Azadux/status/1771973928526967195">a</a> <a href="https://twitter.com/Azadux/status/1810071506107633870">few</a> <a href="https://twitter.com/Azadux/status/1760097753294942557">head</a> strap setups, I now use the <a href="https://vrcover.com/item/universal-headset-support-strap/">VR Cover Universal Headset Support Strap</a> exclusively. It offers quite a lot of comfort without adding any bulk to the portability of the headset. It helps by removing pressure off your cheeks and distributing the weight onto the front area of the top of your head (similar to a typical VR headset halo strap). It’s not perfect but I find it to be “good enough” for now.&nbsp;</p>



<figure><img data-attachment-id="303" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/cover1-copy/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg" data-orig-size="993,713" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728219440&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.7&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;53.424177777778&quot;,&quot;longitude&quot;:&quot;-6.24665&quot;}" data-image-title="cover1 copy" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=993" tabindex="0" role="button" loading="lazy" width="993" height="713" src="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=993" alt=""><figcaption><em>Using AVP with the <a href="https://vrcover.com/item/universal-headset-support-strap/">VR Cover Support Strap</a></em></figcaption></figure>



<p>While they’re might be better head strap solutions, the <em>bulk </em>that they add to the travel setup is a dealbreaker for me.&nbsp;</p>







<p>Another aspect of comfort is… social comfort. When I’m wearing a VR headset around people, I don’t know whether they’re looking at me, or where they are, what they’re doing, etc. Here, the combination of Passthrough + EyeSight offers a great way of remaining aware of your surroundings.&nbsp;</p>



<h4 id="passthrough">Passthrough</h4>



<p>Thankfully, it seems like one of the few places where it’s currently socially acceptable to wear a Vision Pro <em>is</em> on a plane. Of the 5-10 times that I’ve worn it on planes, I haven’t had the feeling of people staring at me suspiciously, whispering about me (at least to my knowledge), or asking me about what I’m doing. I do typically feel self-conscious about using VR in public (so I almost never do it), so the fact that I feel almost entirely comfortable wearing it on a plane says something. Everyone does something to pass the time on a plane, so people are much more forgiving seeing a nerd wearing a face-computer.&nbsp;</p>



<p>Passthrough + EyeSight, as pitched by Apple in their initial announcement of Apple Vision Pro <em>does</em> work quite well when it comes to staying aware of your surroundings and interacting with others (especially flight attendants for those delicious snacks).&nbsp;</p>



<p>While I’m not entirely sure if EyeSight is active when I’m speaking with the flight attendants, the fact that I see them approaching my aisle, that I turn to look and engage with them, and that they see that I am hearing and seeing them (somehow, despite the fact that both my eyes and ears and covered), means that they treat me as any other passenger.&nbsp;</p>



<figure><figcaption><em>Video of me ordering tea from a flight attendant while wearing a Vision Pro</em>.</figcaption></figure>



<p>I’m serious that I haven’t had any real issues interacting with flight attendants while wearing my Vision Pro.</p>



<p>One caveat is that, out of respect, if the conversation is more than the “what would you like? Tea please” deal, I do remove the headset to make direct eye contact with them. I feel that it would be sort of odd to have a full-on conversation with someone if they’re wearing a headset (like bro, just take it off and let’s talk like humans).</p>



<h4 id="ui-interaction"><strong>UI Interaction&nbsp;</strong></h4>



<p>One underrated aspect of VisionOS’s interaction system is that it requires very minimal “hand wavy-ness” to interact with the system. This is a stark difference when compared Quest’s OS (or as it’s now called Meta Horizon OS) which requires you to either use a controller or your hand to point and aim at a screen.</p>



<p>The fact that you just <em>look</em> at the buttons that you’d like to interact with and pinch your fingers while your hand is resting on your lap is a massive plus for not looking like a dweeb. </p>



		<figure>
			
			<figcaption><em>Interacting with the visionOS via tapping + eye tracking is pretty discrete (compared to other VR headsets).</em> </figcaption>
			
		</figure>
		


<p>I mention this because I <em>have</em> used a Quest on a plane (briefly, to capture <a href="https://twitter.com/PuzzlingPlaces/status/1536726744618639363">marketing footage</a> of Puzzling Places in Passthrough). I <em>really</em> felt self conscious about trying to minimize the amount of arm movements I had to do to navigate the OS, menus, etc. I held my elbow tight against my body and tried to only rotate my wrist around, which was quite uncomfortable.</p>



<p>So once again, the eye+pinch UI interaction system is a wonder when it comes to minimizing the amount of physical movement required to navigate the OS, remaining <em>cool</em> and <em>discrete</em> while wearing a face computer (right? right??). </p>



<h4 id="virtual-environment-depth-collision-mitigation"><strong>Virtual Environment / </strong>Depth Collision Mitigation</h4>



<p>One of the biggest issues of Passthrough Mixed Reality is the fact that depending on where you are, you might have a chair or a wall in front of you that presents a “collision” with a virtual screen in your Vision Pro.</p>



<p>In the case of flying on a plane, the chair in front of you is quite close, so if you’d like to set your virtual movie screen to be large and 10 ft away, the chair and the movie screen create a “depth collision”, which can be quite uncomfortable.</p>



<p>Of course, one way to mitigate this is to immerse yourself into a fully virtual world, but that comes at the expense of spatial awareness.</p>



<p>The wonderful thing about visionOS is that you can use a “partial” virtual environment, carefully dialing in just how much of a virtual environment you’d like to use. </p>



		<figure>
			
			<figcaption><em>Showcasing the incongruity of the “depth collision” between a virtual object (Mac window) and IRL object (chair) and its mitigation with a partial virtual environment.</em></figcaption>
			
		</figure>
		


<p>In this case, it’s a perfect fix for opening a portal or a window to a serene landscape to place your large movie screen in, while still being able to see the plane around you. </p>



<p>It works great and is one of the best features of visionOS for using VR in public. </p>



<h3 id="airpods-pros-vision-pro"><strong>AirPods Pros + Vision Pro</strong></h3>



<p>A match made in heaven. </p>



<p>The AirPod Pros are a fantastic set of earphones to wear with the Vision Pro on a plane, offering top-of-the-line active noise cancellation (ANC) but also, “adaptive” and “transparency” modes which allow you to selectively hear voices/sounds around you, depending on the situation.&nbsp;</p>



<p>I use the AirPods Pro 2 with USB-C, which are special in that they offer uncompressed audio with low latency specifically for the Vision Pro. While they do work quite well, according to audiophile reviews, the difference in audio quality between the regular AirPods Pro 2s and the USB-C version with uncompressed audio <a href="https://youtu.be/eOH33sWgds8?t=1392">is minimal</a>, so keep that in mind if you already own an older pair.&nbsp; &nbsp;</p>



<p>The AirPod Pro 2s also feature “Spatial Audio” which output the surround sound mix of movies in a spatial format. By default, the sound is contextually spatialized and head-tracked, meaning, the Vision Pro tries to simulate the room acoustics of the space that you’re in. Typically, this works well enough in a room, but on a dark plane, I find that the spatial acoustics are a bit too different from the raw audio output of the movie itself. </p>



<p>Thankfully, you <em>can</em> change this by disabling the Spatial Audio output from Control Center while watching a movie, where you get the raw sound mix of the movie piped to your AirPods <em>with</em> surround sound still (meaning, sound cues that are behind you will still sound like they’re behind you). The fact that both virtual surround sound and contextual spatialization are called Spatial Audio is definitely a bit confusing.&nbsp;</p>



<figure><img data-attachment-id="300" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_0805/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png" data-orig-size="472,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_0805" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=472" tabindex="0" role="button" loading="lazy" width="472" height="390" src="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=472" alt=""><figcaption><em>Toggling the contextually spatialized and head-tracked Spatial Audio to hear the pure surround sound mix.</em></figcaption></figure>



<p>Either way, if you have a Vision Pro, get the AirPod Pro 2s!! You will absolutely not regret it.</p>



<h3 id="eating-snacking"><strong>Eating/Snacking</strong></h3>



<p>Speaking of flight attendants, when you’re ready to have your in-flight meal, I find that the Vision Pro’s Travel mode tracking perform at its worst, particularly in dark cabin environments (much less so when it’s bright).</p>



<p>The problem is that for meals that require eyesight to coordinate (aka using a fork to pick up food from a plate), as soon as you look down at your food, the tracking often gets lost. This causes the movie to stop playing and for you to have to look forward for the tracking to re-initialize.</p>



<p>Additionally, the Vision Pro’s field of view is more horizontal than vertical (unlike most other VR headsets) which can make eating challenging, requiring me to fully tilt my head down to look at my food.  </p>



<p>In most cases, unless I have a sandwich in my hand that I can eat without looking at, I take my headset off to eat my meal, then return to my movie.&nbsp;</p>



<h3 id="works-in-complete-darkness">Works in Complete Darkness</h3>



<p>One of the drawbacks of VR systems that use cameras for 6DoF tracking is the need to have the room lights on for the headset to function! </p>



<p>Thankfully, Apple Vision Pro <em>does </em>work in pitch dark environments (albeit with some caveats). </p>



<p>While the 6DoF tracking gets reduced to 3DoF, the OS and all of the UI interactions still function in 6DoF. The hand and finger tracking continue to work in 6DoF (a bit more slowly, as the depth sensor being used to track your hands likely has a slower refresh rate than the cameras), so you can still use the full OS and grab windows to move them closer/further away. </p>



<p>The 3DoF movement limitation isn’t an issue for watching movies and using the Mac Virtual Display.  </p>



<p>This is a very unique feature to the Vision Pro. No other all-in-one headset can natively function in the dark to this extent. </p>



<hr>



<h2 id="watching-movies">Watching Movies</h2>



<p>Once Vision Pros start to become more affordable, I foresee regular travelers buying Vision Pros just to have an amazing in-flight entertainment system. It’s truly that amazing.</p>



		<figure>
			
			<figcaption><em>Watching movies in Apple Vision Pro—The video player is fantastic.</em></figcaption>
			
		</figure>
		


<p>Here are some of the things I’ve learned while watching movies on planes.</p>



<h3 id="apps">Apps</h3>



<p>The way you’ll want to watch movies and shows is through native VisionOS apps (Apple TV, Disney+, Max) as they will play videos in their native aspect ratios, offer the highest quality visuals and audio, and have a much easier UI built for AVP.</p>



<p>Apple TV is my preferred app to watch movies with. In my opinion, it provides the highest quality video and audio playback, the ability to buy or rent movies without needing to subscribe, and overall, has the simplest and cleanest UI. </p>



<p><span>Note</span>: Recently, Apple combined the iTunes Movie Store with the Apple TV streaming service into just “Apple TV”.</p>



<p>As for Prime Video and other video streaming apps which don’t have visionOS apps, you can use their iPad apps. The aspect ratio of the app window, will be the same as an iPad, however, so movies will play in a letterboxed mode with black bars above and below.</p>



<figure><img data-attachment-id="305" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_0814/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png" data-orig-size="1491,948" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_0814" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="651" src="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=1024" alt=""><figcaption><em>Watching videos through iPad apps always have black bars on top and bottom (the video itself was blacked out when capturing the screenshot). </em></figcaption></figure>



<p>It’s obviously not ideal, but hey, at least I was able to watch Rings of Power comfortably on the plane, on a large screen! </p>



<h3 id="visuals">Visuals</h3>



<p>The movies that play in virtual screens are native to the films’ aspect ratios, which can vary movie to movie, eliminating the black bars of “letterboxing” and “pillarboxing” you typically have on iPads, iPhones, or MacBooks.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img data-attachment-id="328" data-permalink="https://azadux.blog/screenshot-10/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg" data-orig-size="1080,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1080" height="1080" data-id="328" src="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg" alt=""><figcaption>4:3 aspect ratio</figcaption></figure>



<figure><img data-attachment-id="324" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-9/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="576" data-id="324" src="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=1024" alt=""><figcaption>16:9 aspect ratio</figcaption></figure>



<figure><img data-attachment-id="329" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-11/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg" data-orig-size="1827,1073" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;1728416249&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="601" data-id="329" src="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=1024" alt=""><figcaption>2.40:1 aspect ratio</figcaption></figure>
</figure>



<p>They make great use of the high-res displays of the Vision Pro, its wide color gamut, and its bright HDR capabilities. In fact, of all the screens and displays in my house, my Vision Pro is hands down the highest quality display that I own, so I very much look forward to watching visually compelling movies in it.</p>



<p>One small detail worth mentioning is that the Vision Pro bumps up the frame rate from 90 to 96 fps to provide a smooth playback for 24 fps movies (4:4 pulldown). I really appreciate that level of detail that Apple has put into providing a quality movie-watching experience.</p>



<p>As all VR headset optics go, Apple Vision Pro’s optics are <em>not</em> perfect in the sense that they’re free of glare. Compared to older Fresnel lenses, Vision Pro’s unique concave pancake lenses are some of the best I’ve seen at mitigating god-rays/lens flaring/smearing from high contrast elements. </p>



<p>My advice here is to <em>not</em> use a pitch black environment like the “Moon” or the “Cinema” but rather, use the Dark version of “White Sands”.</p>



<h4 id="cinema-environment">Cinema Environment</h4>



<p>As mentioned in the Virtual Environment section, Apple has created 8 virtual environments, each with “Light” and “Dark” variants.</p>



<p>What’s special is that every environment even has a unique “Cinema” mode where the video playback window gets pushed back and expanded to become 100ft or so, maximizing the field of view of the headset and give the film the “center stage”. </p>



		<figure>
			
			<figcaption><em>Transitioning to an environment’s cinematic mode.</em></figcaption>
			
		</figure>
		


<p>As of VisionOS2, all video apps can take advantage of the Cinema environments that Apple has provided for each virtual environment. Using them gives you a truly massive, immersive (meaning, no multi-tasking) screen to watch your movies on. The environment is also reactive to the lighting of the video, much like the emission of a projector screen. </p>



<p>While some of the environments like Mount Hood have impressive reflective water features underneath the cinematic video playback window, I find them to be a <em>bit</em> too distracting for my taste.</p>



<p>I always go back to the White Sands environment using either the light or dark environment, depending on my mood or time of day.  </p>



<p>I should mention that I <em>don’t</em> always use the immersive cinematic environments. Although as of VisionOS2, you can recenter to adjust the tilt of the cinematic window, I find that it still doesn’t provides as much granular control as I’d like over where I would like to place my movie window. I find myself just making the normal window bigger, pushing it back, and placing it wherever would be most comfortable for me to look at.   </p>



<h4 id="benefits-of-privacy">Benefits of Privacy</h4>



<p>A big bonus for watching movies in VR on a plane is the fact that you don’t need to conscious about movies that contain graphic scenes. You don’t need to turn down the brightness and rotate the screen away from children! </p>



<p>And speaking of brightness, if you’re on a long red-eye flight with the cabin lights off (with your seat neighbor asleep), you don’t need to worry about the brightness of your movie bothering them. </p>



<h4 id="special-film-formats">Special film formats </h4>



<p>Apple TV also contains the largest catalogue of 3D movies (some that are event entirely exclusive to the service, never released on Blu-Ray). I have an in-depth post about the <a href="https://azadux.blog/2024/09/15/vision-pro-movie-formats/">Vision Pro is a revolution for home video formats</a> by offering stereo 3D movies in 4k + HDR, high frame rate, as well as providing a platform for IMAX to offer films in their native 1.43:1 aspect ratio.</p>



<h3 id="audio">Audio</h3>



<p>Using AirPods Pro 2s with active noice canceling is the best way to watch movies with Vision Pro. </p>



<p>In terms of “Spatial Audio”, I’m still a torn on whether I should use the “contextual spatialization” of the surround sound mix of the movie (which is on by default) as it does change the output quite a bit. I find that it’s quite inaccurate when you’re watching the movie in pitch darkness, as the room scanning that the contextual spatialization is based on isn’t mapping the shape of the plane cabin accurately.</p>



<p>Thankfully, you can turn off Spatial Audio and have the native surround mix piped to your AirPods. I believe this output mode still simulates surround sound too! </p>



<h3 id="caveat-when-videos-doesn-t-play">Caveat: when videos doesn’t play</h3>



<p>Similar to iOS streaming apps, I <em>have</em> encountered issues with downloaded purchased and rented shows and movies not being able to play without a network connection. This is truly a “godfuckingdamnit” situation especially when that movie might’ve been the only form of entertainment that I brought onboard. </p>



<figure><img data-attachment-id="268" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-5/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg" data-orig-size="1170,980" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;1727290669&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="857" src="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=1024" alt=""><figcaption><em>Playback error of a download Prime Video episode on my phone.</em></figcaption></figure>



<p>The only time encountered the error with a purchased item was when I had downloaded a movie months ago (likely a few OS updates ago) and I wanted to watch it on a plane. </p>



<p>Rentals can be tricky, especially because you need to keep track of when they were rented and when you’re trigger the start of its playback. Typically, they have worked fine for me, but I <em>do</em> worry a bit every time I board the plane on whether a rental will play or not (at least on planes without Wifi).</p>



<hr>



<h2 id="mac-virtual-display">Mac Virtual Display</h2>



<p>The other major use case of Apple Vision Pro on plane is… to work! I don’t mean working with the silly little iPad apps but rather, connect it to your MacBook and turn its tiny little screen into a battle-station. </p>



		<figure>
			
			<figcaption><em>Writing this blog post on a plane using a 13in MacBook Air and Mac Virtual Display.</em></figcaption>
			
		</figure>
		


<p>Mac Virtual Display is a native way for your Mac to stream its screen to the Vision Pro wirelessly <em>without</em> needing a Wifi or network connection. This is noteworthy as most virtual desktop software for VR headsets require either a cabled connection or a local network. With Mac Virtual Display, the Mac and Vision Pro connect to each directly (via Apple magic, likely using <a href="https://www.wi-fi.org/discover-wi-fi/wi-fi-direct">Wifi Direct</a>).</p>



<p>Here are a few things worth mentioning about using my Vision Pro as a virtual monitor for my MacBook.</p>



<h3 id="no-more-laptop-screen-tilt-limitations">No More Laptop Screen Tilt Limitations </h3>



<p>if you’ve tried to work on a plane with a laptop, you know just how restricting the angle of the plane seat in front of you can be. Even 13 inch laptops feel “large” when you can barely tilt the screen enough to actually do some work. It’s doubly worse if the seat in front reclines all the way, making it entirely unusable.  </p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img data-attachment-id="277" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/angletight1/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728221693&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;56.234541666667&quot;,&quot;longitude&quot;:&quot;-7.5241472222222&quot;}" data-image-title="angleTight1" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="277" src="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=768" alt=""></figure>



<figure><img data-attachment-id="278" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/angletight2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728221699&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.014285714285714&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;56.234541666667&quot;,&quot;longitude&quot;:&quot;-7.5241472222222&quot;}" data-image-title="angletight2" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="278" src="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=768" alt=""></figure>
<figcaption><em>Not much fun trying to use a laptop when the seat in front has reclined.</em></figcaption></figure>



<p>Here, it doesn’t matter what my front seat neighbor does, I can just tilt my screen down, place the laptop on my lap or tray, pull up a virtual monitor, and get to work.</p>



<h3 id="higher-resolution-more-real-estate">Higher Resolution + More Real Estate </h3>



<p>A very underrated aspect of Mac Virtual Display is that the virtual display isn’t merely a mirror of your laptop screen but an entirely new “display” with its own specifications and attributes.</p>



<p>In my case, using a M2 13 inch MacBook Air, Mac Virtual Display actually <em>increases</em> the resolution of my laptop going from the <em>1710 x 1112</em> to <em>2560 x 1440</em> giving me way more screen real estate to work with!</p>



<p>Here’s what I mean: On the left is what my desktop looks like when I’m writing this blog post on my MacBook by default (I’m even using the highest resolution available). On the right is what my desktop looks like with Mac Virtual Display. Notice how much more real estate there is around my browser window.</p>



<figure><img data-attachment-id="293" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/mac-virt-res-2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg" data-orig-size="2628,1020" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mac virt res" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="397" src="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=1024" alt=""><figcaption><em>Comparing the relative sizes and resolution of my MacBook’s display vs Mac Virtual Display in Vision Pro.</em></figcaption></figure>



<p>With VisionOS2, I’m anxiously waiting for the ultra-wide virtual displays (and higher resolutions) to become available which will only make the experience of using a small laptop to do “big work” more viable. </p>



<p>I do hope that in the future individual apps and windows from a Mac can be streamed into the Vision Pro, allowing each app to take whatever shape and size that it would best benefit from (rather than streaming the full desktop).</p>



<h3 id="privacy">Privacy</h3>



<p>I often see frequent flyers who do sensitive work on planes use privacy filters on their laptop screens to block out others from seeing their work. With it, also comes the cost of screen clarity, text sharpness, color accuracy, and narrow viewing angles (obviously) which hinder the fantastic qualities of MacBook displays.</p>



<p>When using Mac Virtual Display, your MacBook screen is blacked out, allowing only you to be able to see you virtual screen. It’s quite handy for sensitive work! </p>



<h3 id="iphone-mirroring">iPhone Mirroring</h3>



<p>This one’s a little bonus: Apple recently announced that you can stream (screen mirror) your iPhone to Mac and Vision Pro, giving you a smooth, high quality virtual display of your phone.</p>



<p>Unlike on MacOS, however, iPhone screen mirroring isn’t intractable, so you’ll still have to hold the phone in your hand and scroll/type. It also has issues with video playback, so if you’re planning to watch downloaded shows/movies or even YouTube videos on your phone, you’ll encounter AirPlay issues.</p>



<p>The reason you’d stream your phone while watching a movie in Vision Pro is because trying to use your phone via the Passthrough is less than ideal, especially in low light.</p>



<figure><img data-attachment-id="296" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-8/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="576" src="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=1024" alt=""><figcaption><em>Screen mirroring my iPhone to my Vision Pro while watching a video </em></figcaption></figure>



<p>It’s not the most useful feature, but I did enjoy scrolling through Twitter in pitch darkness when my seat-mate was asleep.</p>



<hr>



<h2 id="conclusion">Conclusion</h2>



<p>I’ll try to summarize my thoughts on Apple Vision Pro as as traveling device.</p>



<p>The first generation Vision Pro is an incredibly vivid showcase of how Apple sees its power users connecting all the devices within their ecosystem to provide a high quality, private, immersive experience, especially in environments that are outside of their typical home/work spaces. </p>



<p>As a travel device, it’s a fantastic platform for watching movies and expanding my MacBook workspace. It has many flaws, which power users (like myself) who are motivated enough to make the most out of their device will find ways of alleviating.</p>



<p>As it stands, as a first generation product that’s heavy, very expensive, and has a very underbaked OS and app ecosystem, I have a tough time recommending anyone to go out and buy one. That being said, I’m taking it on every flight I go on.</p>



<p>But damn, based on how well it all works now, you can just tell by the 4th or 5th generation, Apple Vision Pro will be on the face of every frequent flyer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Douglas Hofstadter on Lisp (1983) (294 pts)]]></title>
            <link>https://gist.github.com/jackrusher/5139396</link>
            <guid>41858975</guid>
            <pubDate>Wed, 16 Oct 2024 13:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/jackrusher/5139396">https://gist.github.com/jackrusher/5139396</a>, See on <a href="https://news.ycombinator.com/item?id=41858975">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Hofstadter on Lisp: Atoms and Lists, re-printed in Metamagical Themas.
  </p><div id="file-gistfile1-md">
    <article itemprop="text">
<p dir="auto"><em>In the mid-80s, while reading through my roommate's collection of Scientific American back issues, I encountered this introduction to Lisp written by Douglas Hofstadter. I found it very charming at the time, and provide it here (somewhat illegally) for the edification of a new generation of Lispers.</em></p>
<p dir="auto"><em>In a testament to the timelessness of Lisp, you can still run all the examples below in emacs if you install these aliases:</em></p>
<div dir="auto"><pre>(defalias <span>'</span>plus <span>#'</span><span>+</span>)
(defalias <span>'</span>quotient <span>#'</span><span>/</span>)
(defalias <span>'</span>times <span>#'</span><span>*</span>)
(defalias <span>'</span>difference <span>#'</span><span>-</span>)</pre></div>
<p dir="auto"><h2 dir="auto">Lisp: Atoms and Lists</h2><a id="user-content-lisp-atoms-and-lists" aria-label="Permalink: Lisp: Atoms and Lists" href="#lisp-atoms-and-lists"></a></p>
<p dir="auto">February, 1983</p>
<p dir="auto">IN previous columns I have written quite often about the field of
artificial intelligence - the search for ways to program computers so
that they might come to behave with flexibility, common sense,
insight, creativity, self awareness, humor, and so on. The quest for
AI started in earnest over two decades ago, and since then has
bifurcated many times, so that today it is a very active and
multifaceted research area. In the United States there are perhaps a
couple of thousand people professionally involved in AI, and there are
a similar number abroad. Although there is among these workers a
considerable divergence of opinion concerning the best route to AI,
one thing that is nearly unanimous is the choice of programming
language. Most AI research efforts are carried out in a language
called "Lisp". (The name is not quite an acronym; it stands for "list
processing".)</p>
<p dir="auto">Why is most AI work done in Lisp? There are many reasons, most of
which are somewhat technical, but one of the best is quite simple:
Lisp is crisp. Or as Marilyn Monroe said in The Seven-Year Itch, "I
think it's just elegant!" Every computer language has arbitrary
features, and most languages are in fact overloaded with them. A few,
however, such as Lisp and Algol, are built around a kernel that seems
as natural as a branch of mathematics. The kernel of Lisp has a
crystalline purity that not only appeals to the esthetic sense, but
also makes Lisp a far more flexible language than most others. Because
of Lisp's beauty and centrality in this important area of modern
science, then, I have decided to devote a trio of columns to some of
the basic ideas of Lisp.</p>
<p dir="auto">The deep roots of Lisp lie principally in mathematical logic.
Mathematical pioneers such as Thoralf Skolem, Kurt Godel, and Alonzo
Church contributed seminal ideas to logic in the 1920's and 1930's
that were incorporated decades later into Lisp. Computer programming
in earnest began in the 1940's, but so-called "higher-level"
programming languages (of which Lisp is one) came into existence only
in the 1950's. The earliest list-processing language was not Lisp but
IPL ("Information Processing Language"), developed in the mid-1950's
by Herbert Simon, Allen Newell, and J. C. Shaw. In the years 1956-58,
John McCarthy, drawing on all these previous sources, came up with an
elegant algebraic list-processing language he called Lisp. It caught
on quickly with the young crowd around him at the newly-formed MIT
Artificial Intelligence Project, was implemented on the IBM 704,
spread to other AI groups, infected them, and has stayed around all
these years. Many dialects now exist, but all of them share that
central elegant kernel.</p>
<p dir="auto">Let us now move on to the way Lisp really works. One of the most
appealing features of Lisp is that it is interactive, as contrasted
with most other higher-level languages, which are noninteractive. What
this means is the following. When you want to program in Lisp, you sit
down at a terminal connected to a computer and you type the word
"lisp" (or words to that effect). The next thing you will see on your
screen is a so-called "prompt" - a characteristic symbol such as an
arrow or asterisk. I like to think of this prompt as a greeting spoken
by a special "Lisp genie", bowing low and saying to you, "Your wish is
my command - and now, what is your next wish?" The genie then waits
for you to type something to it. This genie is usually referred to as
the Lisp interpreter, and it will do anything you want but you have to
take great care in expressing your desires precisely, otherwise you
may reap some disastrous effects. Shown below is the prompt, showing
that the Lisp genie is ready to do your bidding:</p>

<p dir="auto">The genie is asking us for our heart's desire, so let us type in a
simple expression:</p>

<p dir="auto">and then a carriage return. (By the way, all Lisp expressions and
words will be printed in Helvetica in this and the following two
chapters.) Even non-Lispers can probably anticipate that the Lisp
genie will print in return. the value 4. Then it will also print a
fresh prompt, so that the screen will now appear this way:</p>

<p dir="auto">The genie is now ready to carry out our next command - or, more
politely stated, our next wish - should we have one. The carrying-out
of a wish expressed as a Lisp statement is called evaluation of that
statement. The preceding short interchange between human and computer
exemplifies the behavior of the Lisp interpreter: it reads a
statement, evaluates it, prints the appropriate value, and then
signals its readiness to read a new statement. For this reason, the
central activity of the Lisp interpreter is referred to as the
read-eval-print loop.</p>
<p dir="auto">The existence of this Lisp genie (the Lisp interpreter) is what makes
Lisp interactive. You get immediate feedback as soon as you have typed
a "wish" - a complete statement - to Lisp. And the way to get a bunch
of wishes carried out is to type one, then ask the genie to carry it
out, then type another, ask the genie again, and so on.</p>
<p dir="auto">By contrast, in many higher-level computer languages you must write
out an entire program consisting of a vast number of wishes to be
carried out in some specified order. What's worse is that later wishes
usually depend strongly on the consequences of earlier wishes - and of
course, you don't get to try them out one by one. The execution of
such a program may, needless to say, lead to many unexpected results,
because so many wishes have to mesh perfectly together. If you've made
the slightest conceptual error in designing your wish list, then a
total foul-up is likely - in fact, almost inevitable. Running a
program of this sort is like launching a new space probe, untested:
you can't possibly have anticipated all the things that might go
wrong, and so all you can do is sit back and watch, hoping that it
will work. If it fails, you go back and correct the one thing the
failure revealed, and then try another launch. Such a gawky, indirect,
expensive way of programming is in marked contrast to the direct,
interactive, one-wish-at-atime style of Lisp, which allows
"incremental" program development and debugging. This is another major
reason for the popularity of Lisp.</p>
<p dir="auto">What sorts of wishes can you type to the Lisp genie for evaluation,
and what sorts of things will it print back to you? Well, to begin
with, you can type arithmetical expressions expressed in a rather
strange way, such as <code>(times (plus 6 3) (difference 6 3))</code>. The answer
to this is 27, since <code>(plus 6 3)</code> evaluates to <code>9</code>, and <code>(difference 6 3)</code>
evaluates to 3, and their product is 27. This notation, in which each
operation is placed to the left of its operands, was invented by the
Polish logician Jan Lukasiewicz before computers existed.
Unfortunately for Lukasiewicz, his name was too formidable-looking for
most speakers of English, and so this type of notation came to be
called Polish notation. Here is a simple problem in this notation for
you, in which you are to play the part of the Lisp genie:</p>
<div dir="auto"><pre><span>&gt;</span> (quotient (plus <span>2113</span>) (difference <span>23</span> (times <span>2</span> (difference <span>7</span> (plus <span>2</span> <span>2</span>)))))</pre></div>
<p dir="auto">Perhaps you have noticed that statements of Lisp involve parentheses.
A profusion of parentheses is one of the hallmarks of Lisp. It is not
uncommon to see an expression that terminates in a dozen right
parentheses! This makes many people shudder at first - and yet once
you get used to their characteristic appearance, Lisp expressions
become remarkably intuitive, even, charming, to the eye, especially
when pretty printed, which means that a careful indentation scheme is
followed that reveals their logical structure. All of the expressions
in displays in this article have been pretty-printed.</p>
<p dir="auto">The heart of Lisp is its manipulable structures. All programs in Lisp
work by creating, modifying, and destroying structures. Structures
come in two types: atomic and composite, or, as they are usually
called, atoms and lists. Thus, every Lisp object is either an atom or
a list (but not both). The only exception is the special object called
nil, which is both an atom and a list. More about nil in a moment.
What are some other typical Lisp atoms? Here are a few:</p>
<p dir="auto"><em>hydrogen, helium, j-s-bach, 1729, 3.14159, pi,
arf, foo, bar, baz, buttons-&amp;-bows</em></p>
<p dir="auto">Lists are the flexible data structures of Lisp. A list is pretty much
what it sounds like: a collection of some parts in a specific order.
The parts of a list are usually called its elements or members. What
can these members be? Well, not surprisingly, lists can have atoms as
members. But just as easily, lists can contain lists as members, and
those lists can in turn contain other lists as members, and so on,
recursively. Oops! I jumped the gun with that word. But no harm done.
You certainly understood what I meant, and it will prepare you for a
more technical definition of the term to come later.</p>
<p dir="auto">A list printed on your screen is recognizable by its parentheses. In
Lisp, anything bounded by matching parentheses constitutes a list. So,
for instance, <code>(zonk blee strill (croak flonk))</code> is a four-element list
whose last element is itself a two-element list. Another short list is
<code>(plus 2 2)</code>, illustrating the fact that Lisp statements themselves are
lists. This is important because it means that the Lisp genie, by
manipulating lists and atoms, can actually construct new wishes by
itself. Thus the object of a wish can be the construction - and
subsequent evaluation - of a new wish!</p>
<p dir="auto">Then there is the empty list - the list with no elements at all. How
is this written down? You might think that an empty pair of
parentheses - () - would work. Indeed, it will work - but there is a
second way of indicating the empty list, and that is by writing nil.
The two notations are synonymous, although nil is more commonly
written than () is. The empty list, nil, is a key concept of Lisp; in
the universe of lists, it is what zero is in the universe of numbers.
To use another metaphor for nil, it is like the earth in which all
structures are rooted. But for you to understand what this means, you
will have to wait a bit.</p>
<p dir="auto">The most commonly exploited feature of an atom is that it has (or can
be given) a value. Some atoms have permanent values, while others are
variables. As you might expect, the value of the atom 1729 is the
integer 1729, and this is permanent. (I am distinguishing here between
the atom whose print name or pname is the four-digit string 1729, and
the eternal Platonic essence that happens to be the sum of two cubes
in two different ways - i.e., the number 1729.) The value of nil is
also permanent, and it is - nil! Only one other atom has itself as its
permanent value, and that is the special atom t.</p>
<p dir="auto">Aside from t, nil, and atoms whose names are numerals, atoms are
generally variables, which means that you can assign values to them
and later change their values at will. How is this done? Well, to
assign the value 4 to the atom pie, you can type to the Lisp genie
<code>(setq pie 4)</code>. Or you could just as well type <code>(setq pie (plus 2 2))</code> -
or even <code>(setq pie (plus 1 1 1 1))</code>. In any of these cases, as soon as
you type your carriage return, pie's value will become 4, and so it
will remain forevermore - or at least until you do another setq
operation on the atom pie.</p>
<p dir="auto">Lisp would not be crisp if the only values atoms could have were
numbers. Fortunately, however, an atom's value can be set to any kind
of Lisp object - any atom or list whatsoever. For instance, we might
want to make the value of the atom pi be a list such as <code>(a b c)</code> or
perhaps <code>(plus 2 2)</code> instead of the number 4. To do the latter, we again
use the setq operation. To illustrate, here follows a brief
conversation with the genie:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> pie (plus <span>2</span> <span>2</span>))
<span>4</span>
<span>&gt;</span> (<span>setq</span> <span>pi</span> <span>'</span>(plus <span>2</span> <span>2</span>))
(plus <span>2</span> <span>2</span>)</pre></div>
<p dir="auto">Notice the vast difference between the values assigned to the atoms
pie and pi as a result of these two wishes asked of the Lisp genie,
which differ merely in the presence or absence of a small but critical
quote mark in front of the inner list <code>(plus 2 2)</code>. In the first wish,
containing no quote mark, that inner <code>(plus 2 2)</code> must be evaluated.
This returns 4, which is assigned to the variable pie as its new
value. On the other hand, in the second wish, since the quote mark is
there, the list <code>(plus 2 2)</code> is never executed as a command, but is
treated merely as an inert lump of Lispstuff, much like meat on a
butcher's shelf. It is ever so close to being "alive", yet it is dead.
So the value of pi in this second case is the list <code>(plus 2 2)</code>, a
fragment of Lisp code. The following interchange with the genie
confirms the values of these atoms.</p>
<div dir="auto"><pre><span>&gt;</span> pie
<span>4</span>
<span>&gt;</span> <span>pi</span>
(plus <span>2</span> <span>2</span>)
<span>&gt;</span> (<span>eval</span> <span>pi</span>)
<span>4</span>
<span>&gt;</span></pre></div>
<p dir="auto">What is this last step? I wanted to show how you can ask the genie to
evaluate the value of an expression, rather than simply printing the
value of that expression. Ordinarily, the genie automatically performs
just one level of evaluation, but by writing eval, you can get a
second stage of evaluation carried out. (And of course, by using eval
over and over again, you can carry this as far as you like.) This
feature often proves invaluable, but it is a little too advanced to
discuss further at this stage.</p>
<p dir="auto">Every list but nil has at least one element. This first element is
called the list's Car. Thus the car of <code>(eval pi)</code> is the atom eval. The
cars of the lists <code>(plus 2 2)</code>, <code>(setq x 17)</code>, <code>(eval pi)</code>, and <code>(car pi)</code> are
all names of operations, or, as they are more commonly called in Lisp,
functions. The car of a list need not be the name of a function; it
need not even be an atom. For instance, <code>((1)(2 2) (3 3 3))</code> is a
perfectly fine list. Its car is the list <code>(1)</code>, whose car in turn is not
a function name but merely a numeral.</p>
<p dir="auto">If you were to remove a list's car, what would remain? A shorter list.
This is called the list's cdr, a word that sounds about halfway
between "kidder" and "could'er". (The words "car" and "cdr" are quaint
relics from the first implementation of Lisp on the IBM 704. The
letters in "car" stand for "Contents of the Address part of Register"
and those in "cdr" for "Contents of the Decrement part of Register
referring to specific hardware features of that machine, now long
since irrelevant.) The cdr of <code>(a b c d)</code> is the list <code>(b c d)</code>, whose cdr
is <code>(c d)</code>, whose cdr is <code>(d)</code>, whose cdr is nil. And nil has no cdr, just
as it has no car. Attempting to take the car or cdr of nil causes (or
should cause) the Lisp genie to cough out an error message, just as
attempting to divide by zero should evoke an error message.</p>
<p dir="auto">Here is a little table showing the car and cdr of a few lists, just to
make sure the notions are unambiguous.</p>
<div dir="auto"><pre><span>list</span>                <span>car</span>          <span>cdr</span>
((a) b (c))         (a)          (b (c))
(plus <span>2</span> <span>2</span>)          plus         (<span>2</span> <span>2</span>)
((<span>car</span> x) (<span>car</span> y))   (<span>car</span> x)      ((<span>car</span> y))
(<span>nil</span> <span>nil</span> <span>nil</span> <span>nil</span>)   <span>nil</span>          (<span>nil</span> <span>nil</span> <span>nil</span>)
(<span>nil</span>)               <span>nil</span>          <span>nil</span>
<span>nil</span>                 **ERROR**    **ERROR**</pre></div>
<p dir="auto">Just as car and cdr are called functions, so the things that they
operate on are called their arguments. Thus in the command <code>(plus pie 2)</code>,
plus is the function name, and the arguments are the atoms pie and
2. In evaluating this command (and most commands), the genie figures
out the values of the arguments, and then applies the function to
those values. Thus, since the value of the atom pie is 4, and the
value of the atom 2 is 2, the genie returns the atom 6.</p>
<hr>
<p dir="auto">Suppose you have a list and you'd like to see a list just like it,
only one element longer. For instance, suppose the value of the atom x
is <code>(cake cookie)</code> and you'd like to create a new list called y just
like x, except with an extra atom-say pie - at the front. You can then
use the function called cons (short for "construct"), whose effect is
to make a new list out of an old list and a suggested car. Here's a
transcript of such a process:</p>
<div dir="auto"><pre><span>&gt;</span>(<span>setq</span> x <span>'</span>(cake cookie))
(cake cookie)
<span>&gt;</span>(<span>setq</span> y (<span>cons</span> <span>'</span>pie x))
(pie cake cookie)
<span>&gt;</span> x
(cake cookie)</pre></div>
<p dir="auto">Two things are worth noticing here. I asked for the value of x to be
printed out after the cons operation, so you could see that x itself
was not changed by the cons. The cons operation created a new list and
made that list be the value of y, but left x entirely alone. The other
noteworthy fact is that I used that quote mark again, in front of the
atom pie. What if I had not used it? Here's what would have happened.</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> z (<span>cons</span> pie x))
(<span>4</span> cake cookie)</pre></div>
<p dir="auto">Remember, after all, that the atom pie still has the value 4, and
whenever the genie sees an unquoted atom inside a wish, it will always
use the value belonging to that atom, rather than the atom's name.
(Always? Well, almost always. I'll explain in a moment. In the
meantime, look for an exception - you've already encountered it.)</p>
<p dir="auto">Now here are a few exercises - some a bit tricky - for you. Watch out
for the quote marks! Oh, one last thing: I use the function reverse,
which produces a list just like its argument, only with its elements
in reverse order. For instance, the genie, upon being told <code>(reverse '((a b) (c d e)))</code> will write <code>((c d e) (a b))</code>. The genie's lines in
this dialogue are given afterward.</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> w (<span>cons</span> pie <span>'</span>(<span>cdr</span> z)))
<span>&gt;</span> (<span>setq</span> v (<span>cons</span> <span>'</span>pie (<span>cdr</span> z)))
<span>&gt;</span> (<span>setq</span> u (<span>reverse</span> v))
<span>&gt;</span> (<span>cdr</span> (<span>cdr</span> u))
<span>&gt;</span> (<span>car</span> (<span>cdr</span> u))
<span>&gt;</span> (<span>cons</span> (<span>car</span> (<span>cdr</span> u)) u)
<span>&gt;</span> u
<span>&gt;</span> (<span>reverse</span> <span>'</span>(<span>cons</span> (<span>car</span> u) (<span>reverse</span> (<span>cdr</span> u))))
<span>&gt;</span> (<span>reverse</span> (<span>cons</span> (<span>car</span> u) (<span>reverse</span> (<span>cdr</span> u))))
<span>&gt;</span> u
<span>&gt;</span> (<span>cons</span> <span>'</span>cookie (<span>cons</span> <span>'</span>cake (<span>cons</span> <span>'</span>pie <span>nil</span>)))</pre></div>
<p dir="auto">Answers (as printed by the genie):</p>
<div dir="auto"><pre>(<span>4</span> <span>cdr</span> z)
(pie cake cookie)
(cookie cake pie)
(pie)
cake
(cake cookie cake pie)
(cookie cake pie)
((<span>reverse</span> (<span>cdr</span> u)) (<span>car</span> u) <span>cons</span>)
(cake pie cookie)
(cookie cake pie)
(cookie cake pie)</pre></div>
<p dir="auto">The last example, featuring repeated use of cons, is often called, in
Lisp slang "consing up a list". You start with nil, and then do
repeated cons operations. It is analogous to building a positive
integer by starting at zero and then performing the successor
operation over and over again. However, whereas at any stage in the
latter process there is a unique way of performing the successor
operation, given any list there are infinitely many different items
you can cons onto it, thus giving rise to a vast branching tree of
lists instead of the unbranching number line. It is on account of this
image of a tree growing out of the ground of nil and containing all
possible lists that I earlier likened nil to "the earth in which all
structures are rooted".</p>
<p dir="auto">As I mentioned a moment ago, the genie doesn't always replace
(unquoted) atoms by their values. There are cases where a function
treats its arguments, though unquoted, as if quoted. Did you go back
and find such a case? It's easy. The answer is the function setq. In
particular, in a setq command, the first atom is taken straight-not
evaluated. As a matter of fact, the q in setq stands for "quote",
meaning that the first argument is treated as if quoted. Things can
get quite tricky when you learn about set, a function similar to setq
except that it does evaluate its first argument. Thus, if the value of
the atom x is the atom k, then saying <code>(set x 7)</code> will not do anything
to x-its value will remain the atom k-but the value of the atom k will
now become 7. So watch closely:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> a <span>'</span>b)
<span>&gt;</span> (<span>setq</span> b <span>'</span>c)
<span>&gt;</span> (<span>setq</span> c <span>'</span>a)
<span>&gt;</span> (<span>set</span> a c)
<span>&gt;</span> (<span>set</span> c b)</pre></div>
<p dir="auto">Now tell me: What are the values of the atoms a, b, and c? Here comes
the answer, so don't peek. They are, respectively: a, a, and a. This
may seem a bit confusing. You may be reassured to know that in Lisp,
set is not very commonly used, and such confusions do not arise that
often.</p>
<p dir="auto">Psychologically, one of the great powers of programming is the ability
to define new compound operations in terms of old ones, and to do this
over and over again, thus building up a vast repertoire of ever more
complex operations. It is quite reminiscent of evolution, in which
ever more complex molecules evolve out of less complex ones, in an
ever-upward spiral of complexity and creativity. It is also quite
reminiscent of the industrial revolution, in which people used very
simple early machines to help them build more complex machines, then
used those in turn to build even more complex machines, and so on,
once again in an ever-upward spiral of complexity and creativity. At
each stage, whether in evolution or revolution, the products get more
flexible and more intricate, more "intelligent" and yet more
vulnerable to delicate "bugs" or breakdowns.</p>
<p dir="auto">Likewise with programming in Lisp, only here the "molecules" or
"machines" are now Lisp functions defined in terms of previously known
Lisp functions. Suppose, for instance, that you wish to have a
function that will always return the last element of a list, just as
car always returns the first element of a list. Lisp does not come
equipped with such a function, but you can easily create one. Do you
see how? To get the last element of a list called lyst, you simply do
a reverse on lyst and then take the car of that: <code>(car (reverse lyst))</code>.
To dub this operation with the name rac (car backwards), we use the
def function, as follows:</p>
<div dir="auto"><pre><span>&gt;</span> (def rac (<span>lambda</span> (lyst) (<span>car</span> (<span>reverse</span> lyst))))</pre></div>
<p dir="auto">Using def this way creates a function definition. In it, the word
lambda followed by (lyst) indicates that the function we are defining
has only one parameter, or dummy variable, to be called lyst. (It
could have been called anything; I just happen to like the atom lyst.)
In general, the list of parameters (dummy variables) must immediately
follow the word lambda. After this "def wish" has been carried out,
the rac function is as well understood by the genie as is car. Thus
<code>(rac '(your brains))</code> will yield the atom <code>brains</code>. And we can use rac
itself in definitions of yet further functions. The whole thing
snowballs rather miraculously, and you can quickly become overwhelmed
by the power you wield.</p>
<p dir="auto">Here is a simple example. Suppose you have a situation where you know
you are going to run into many big long lists and you know it will
often be useful to form, for each such long list, a short list that
contains just its car and rac. We can define a one-parameter function
to do this for you:</p>
<div dir="auto"><pre><span>&gt;</span> (def readers-digest-condensed-version
    (<span>lambda</span> (biglonglist)
     (<span>cons</span> (<span>car</span> biglonglist) (<span>cons</span> (rac biglonglist) <span>nil</span>))))</pre></div>
<p dir="auto">Thus if we apply our new function readers-digest-condensed-version to
the entire text of James Joyce's Finnegans Wake (treating it as a big
long list of words), we will obtain the shorter list <code>(riverrun the)</code>.
Unfortunately, reapplying the condensation operator to this new list
will not simplify it any further.</p>
<p dir="auto">It would be nice as well as useful if we could create an inverse
operation to readers-digest-condensed-version called rejoyce that,
given any two words, would create a novel beginning and ending with
them, respectively - and such that James Joyce would have written it
(had he thought of it). Thus execution of the Lisp statement
<code>(rejoyce 'Stately 'Yes)</code> would result in the Lisp genie generating from
scratch the entire novel Ulysses. Writing this function is left as an
exercise for the reader. To test your program, see what it does with
<code>(rejoyce 'karma 'dharma)</code>.</p>
<p dir="auto">One goal that has seemed to some people to be both desirable and
feasible using Lisp and related programming languages is (1) to make
every single statement return a value and (2) to have it be through
this returned value and only through it that the statement has any
effect. The idea of (1) is that values are handed "upward" from the
innermost function calls to the outermost ones, until the full
statement's value is returned to you. The idea of (2) is that during
all these calls, no atom has its value changed at all (unless the atom
is a dummy variable). In all dialects of Lisp known to me, (1) is
true, but (2) is not necessarily true.</p>
<p dir="auto">Thus if x is bound to <code>(a b c d e)</code> and you say <code>(car (cdr (reverse x)))</code>,
the first thing that happens is that <code>(reverse x)</code> is calculated; then
this value is handed "up" to the cdr function, which calculates the
cdr of that list; finally, this shorter list is handed to the car
function, which extracts one element-namely the atom d-and returns it.
In the meantime, the atom x has suffered no damage; it is still bound
to <code>(a b c d e)</code>.</p>
<p dir="auto">It might seem that an expression such as <code>(reverse x)</code> would change the
value of x by reversing it, just as carrying out the oral command
"Turn your sweater inside out" will affect the sweater. But actually,
carrying out the wish <code>(reverse x)</code> no more changes the value of x than
carrying out the wish <code>(plus 2 2)</code> changes the value of 2. Instead,
executing <code>(reverse x)</code> causes a new (unnamed) list to come into being,
just like x, only reversed. And that list is the value of the
statement; it is what the statement returns. The value of x itself,
however, is untouched. Similarly, evaluating <code>(cons 5 pi)</code> will not
change the list named pi in the slightest; it merely returns a new
list with 5 as its car and whatever pi's value is as its cdr.</p>
<p dir="auto">Such behavior is to be contrasted with that of functions that leave
"side effects" in their wake. Such side effects are usually in the
form of changed variable bindings, although there are other
possibilities, such as causing input or output to take place. A
typical "harmful" command is a setq, and proponents of the
"applicative" school of programming - the school that says you should
never make any side effects whatsoever - are profoundly disturbed by
the mere mention of setq. For them, all results must come about purely
by the way that functions compute their values and hand them to other
functions.</p>
<p dir="auto">The only bindings that the advocates of the applicative style approve
of are transitory "lambda bindings" - those that arise when a function
is applied to its arguments. Whenever any function is called, that
function's dummy variables temporarily assume "lambda bindings". These
bindings are just like those caused by a setq, except that they are
fleeting. That is, the moment the function is finished computing, they
go away - vanishing without a trace. For example, during the
computation of <code>(rac '(a b c))</code>, the lambda binding of the dummy
variable lyst is the list <code>(a b c)</code>; but as soon as the answer c is
passed along to the function or person that requested the rac, the
value of the atom lyst used in getting that answer is totally
forgotten. The Lisp interpreter will tell you that lyst is an "unbound
atom" if you ask for its value. Applicative programmers much prefer
lambda bindings to ordinary setq bindings.</p>
<p dir="auto">I personally am not a fanatic about avoiding setq's and other
functions that cause side effects. Though I find the applicative style
to be jus-telegant, I find it impractical when it comes to the
construction of large AI-style programs. Therefore I shall not
advocate the applicative style here, though I shall adhere to it when
possible. Strictly speaking, in applicative programming, you cannot
even define new functions, since a def statement causes a permanent
change to take place in the genie's memory - namely, the permanent
storage in memory of the function definition. So the ideal applicative
approach would have functions, like variable bindings, being created
only temporarily, and their definitions would be discarded the moment
after they had been used. But this is extreme "applicativism".</p>
<p dir="auto">For your edification, here are a few more simple function definitions.</p>
<div dir="auto"><pre><span>&gt;</span> (def rdc (<span>lambda</span> (lyst) (<span>reverse</span> (<span>cdr</span> (<span>reverse</span> lyst)))))
<span>&gt;</span> (def snoc (<span>lambda</span> (x lyst) (<span>reverse</span> (<span>cons</span> x (<span>reverse</span> lyst)))))
<span>&gt;</span> (def twice (<span>lambda</span> (n) (plus n n)))</pre></div>
<p dir="auto">The functions rdc and snoc are analogous to cdr and cons, only
backwards. Thus, the rdc of <code>(a b c d e)</code> is <code>(a b c d)</code>, and if you type
<code>(snoc 5 '(1 2 3 4))</code>, you will get <code>(1 2 3 4 5)</code> as your answer.</p>
<p dir="auto">All of this is mildly interesting so far, but if you want to see the
genie do anything truly surprising, you have to allow it to make some
decisions based on things that happen along the way. These are
sometimes called "conditional wishes". A typical example would be the
following:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>cond</span> ((<span>eq</span> x <span>1</span>) <span>'</span>land) ((<span>eq</span> x <span>2</span>) <span>'</span>sea))</pre></div>
<p dir="auto">The value returned by this statement will be the atom land if x has
value 1, and the atom sea if x has value 2. Otherwise, the value
returned will be nil (i.e., if x is 5). The atom eq (pronounced "eek")
is the name of a common Lisp function that returns the atom t
(standing for "true") if its two arguments have the same value, and
nil (for "no" or "false") if they do not.</p>
<p dir="auto">A cond statement is a list whose car is the function name cond,
followed by any number of cond clauses, each of which is a two-element
list. The first element of each clause is called its condition, the
second element its result. The clauses' conditions are checked out by
the Lisp genie one by one, in order; as soon as it finds a clause
whose condition is "true" (meaning that the condition returns anything
other than nil!), it begins calculating that clause's result, whose
value gets returned as the value of the whole cond statement. None of
the further clauses is even so much as glanced at! This may sound more
complex than it ought to. The real idea is no more complex than saying
that it looks for the first condition that is satisfied, then it
returns the corresponding result.</p>
<p dir="auto">Often one wants to have a catch-all clause at the end whose condition
is sure to be satisfied, so that, if all other conditions fail, at
least this one will be true and the accompanying result, rather than
nil, will be returned. It is easy as pie to make a condition whose
value is non-nil; just choose it to be t for instance, as in the
following:</p>
<div dir="auto"><pre>(<span>cond</span> ((<span>eq</span> x <span>1</span>) <span>'</span>land)
      ((<span>eq</span> x <span>2</span>) <span>'</span>sea)
       (<span>t</span> <span>'</span>air))</pre></div>
<p dir="auto">Depending on what the value of x is, we will get either land, sea, or
air as the value of this cond, but we'll never get nil. Now here are a
few sample cond statements for you to play genie to:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>cond</span> ((<span>eq</span> (oval <span>pi</span>) pie) (oval (snot pie <span>pi</span>)))
(<span>t</span> (<span>eval</span> (snoc (rac <span>pi</span>) <span>pi</span>))))
<span>&gt;</span> (<span>cond</span> ((<span>eq</span> <span>2</span> <span>2</span>) <span>2</span>) ((<span>eq</span> <span>3</span> <span>3</span>) <span>3</span>))
<span>&gt;</span> (<span>cond</span> (<span>nil</span> <span>'</span>no-no-no)
((<span>eq</span> <span>'</span>(<span>car</span> <span>nil</span>) <span>'</span>(<span>cdr</span> <span>nil</span>)) <span>'</span>hmmm)
(<span>t</span> <span>'</span>yes-yes-yes))</pre></div>
<p dir="auto">The answers are: 8, 2, and yes-yes-yes. Did you notice that <code>(car nil)</code>
and <code>(cdr nil)</code> were quoted?</p>
<p dir="auto">I shall close this portion of the column by displaying a patterned
family of function definitions, so obvious in their pattern that you
would think that the Lisp genie would just sort of "get the hang of
it" after seeing the first few... Unfortunately, though, Lisp genies
are frustratingly dense (or at least they play at being dense), and
they will not jump to any conclusion unless it has been completely
spelled out. Look first at the family:</p>
<div dir="auto"><pre><span>&gt;</span> (def square (<span>lambda</span> (k) (times k k)))
<span>&gt;</span> (def cube (<span>lambda</span> (k) (times k (square k))))
<span>&gt;</span> (def 4th-power (<span>lambda</span> (k) (times k (cube k))))
<span>&gt;</span> (def 5th-power (<span>lambda</span> (k) (times k (4th-power k))))
<span>&gt;</span> (def 6th-power (<span>lambda</span> (k) (times k (5th-power k))))
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span></pre></div>
<p dir="auto">My question for you is this: Can you invent a definition for a two
parameter function that subsumes all of these in one fell swoop? More
concretely, the question is: How would one go about defining a
two-parameter function called power such that, for instance, <code>(power 9 3)</code>
yields 729 on being evaluated, and <code>(power 7 4)</code> yields 2,401 ? I
have supplied you, in this column, with all the necessary tools to do
this, provided you exercise some ingenuity.</p>
<p dir="auto">I thought I would end this column with a newsbreak about a freshly
discovered beast - the homely Glazunkian porpuquine, so called because
it is found only on the island of Glazunkia (claimed by Upper Bitbo,
though it is just off the coast of Burronymede). And what is a
porpuquine, you ask? Why, it's a strange breed of porcupine, whose
quills - of which, for some reason, there are always exactly nine (in
Outer Glazunkia) or seven (in Inner Glazunkia) - are smaller
porpuquines. Oho! This would certainly seem to be an infinite regress!
But no. It's just that I forgot to mention that there is a smallest
size of porpuquine: the zero-inch type, which, amazingly enough, is
totally bald of quills. So, quite luckily (or perhaps unluckily,
depending on your point of view), that puts a stop to the threatened
infinite regress. This remarkable beast is shown in a rare photograph
in Figure 17-1.</p>
<p dir="auto">Students of zoology might be interested to learn that the quills on
5-inch porpuquines are always 4-inch porpuquines, and so on down the
line. And students of anthropology might be equally intrigued to know
that the residents of Glazunkia (both Outer and Inner) utilize the
nose (yes, the nose) of the zero-inch porpuquine as a unit of barter -
an odd thing to our minds; but then, who are you and I to question the
ancient wisdom of the Outer and Inner Glazunkians? Thus, since a
largish porpuquine - say a 3-incher or 4-incher - contains many, many
such tiny noses, it is a most valuable commodity. The value of a
porpuquine is sometimes referred to as its "buying power", or just
"power" for short. For instance, a 2-incher found in Inner Glazunkia
is almost twice as powerful as a 2-incher found in Outer Glazunkia. Or
did I get it backward? It's rather confusing!</p>
<p dir="auto">Anyway, why am I telling you all this? Oh, I just thought you'd like
to hear about it. Besides, who knows? You just might wind up visiting
Glazunkia (Inner or Outer) one of these fine days. And then all of
this could come in mighty handy.</p>
<hr>
<p dir="auto"><em>I hope you enjoyed Hofstadter's idiosyncratic tour of Lisp. You can find more like this re-printed in his book <a href="https://en.wikipedia.org/wiki/Metamagical_Themas" rel="nofollow">Metamagical Themas</a>.</em></p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon buys stake in nuclear energy developer in push to power data centres (120 pts)]]></title>
            <link>https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911</link>
            <guid>41858863</guid>
            <pubDate>Wed, 16 Oct 2024 13:32:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911">https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911</a>, See on <a href="https://news.ycombinator.com/item?id=41858863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offer-9e54fac2-5972-41eb-b33d-6fa67be1b59b" data-component="heroOffer" data-component-unique-name="Hero offer"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Limited time offer</span></h2><h2><strong><span>Save 50% on Standard Digital</span></strong></h2></p><p><span>was </span><span>CHF660</span><span> </span><span>now </span><span>CHF329</span><span> for your first year, equivalent to </span><span>CHF27.42</span><span> per month.
Make up your own mind. Build robust opinions with the FT’s trusted journalism.
Take this offer before 24 October.</span></p></div></div><div id="recommendedOffers-Recommended offers-6615b5d2-334c-4624-9cac-70c882e3db14" data-component="recommendedOffers" data-component-unique-name="Recommended offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_trial.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF1</span><span> for 4 weeks</span></p><p><span>Then </span><span>CHF85</span><span> per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_weekend_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF85</span><span> per month</span></p><p><span>Get Premium &amp; FT Weekend Print edition for the price of Premium. Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_print.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF345</span><span> for your first year</span></p><p><span>FT newspaper delivered Monday-Saturday, plus FT Digital Edition delivered to your device Monday-Saturday.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=00776191-b010-4104-add4-8dc430386911">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC Announces "Click-to-Cancel" Rule Making It Easier to Cancel Subscriptions (1166 pts)]]></title>
            <link>https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring</link>
            <guid>41858665</guid>
            <pubDate>Wed, 16 Oct 2024 13:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring">https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring</a>, See on <a href="https://news.ycombinator.com/item?id=41858665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Federal Trade Commission today announced a <a href="https://www.ftc.gov/legal-library/browse/federal-register-notices/negative-option-rule-final-rule" data-entity-type="node" data-entity-uuid="f9ee6fe1-5b17-4316-8a19-52ae35e0302e" data-entity-substitution="canonical">final “click-to-cancel” rule</a> that will require sellers to make it as easy for consumers to cancel their enrollment as it was to sign up. Most of the final rule’s provisions will go into effect 180 days after it is published in the Federal Register.</p><p>“Too often, businesses make people jump through endless hoops just to cancel a subscription,” said Commission Chair Lina M. Khan. “The FTC’s rule will end these tricks and traps, saving Americans time and money. Nobody should be stuck paying for a service they no longer want.”</p><a href="https://www.ftc.gov/system/files/ftc_gov/images/negoptions-1page-oct2024-thumb-v2_0.png">
<article>
  
      
  </article>
</a><p>The Commission’s updated rule will apply to almost all negative option programs in any media. The rule also will prohibit sellers from misrepresenting any material facts while using negative option marketing; require sellers to provide important information before obtaining consumers’ billing information and charging them; and require sellers to get consumers’ informed consent to the negative option features before charging them.</p><p>The final rule announced today is part of the FTC’s ongoing review of its 1973 Negative Option Rule, which the agency is modernizing to combat unfair or deceptive practices related to subscriptions, memberships, and other recurring-payment programs in an increasingly digital economy where it’s easier than ever for businesses to sign up consumers for their products and services.</p><p>Commission approval and publication follows the&nbsp;<a href="https://www.ftc.gov/news-events/news/press-releases/2023/03/federal-trade-commission-proposes-rule-provision-making-it-easier-consumers-click-cancel-recurring">March 2023 announcement of a notice of proposed rulemaking</a> which resulted in more than 16,000 comments from consumers and federal and state government agencies, consumer groups, and trade associations.</p><p>While negative option marketing programs can be convenient for&nbsp;sellers and consumers,&nbsp;the FTC receives thousands of complaints about negative option and recurring subscription practices each year. The number of complaints has been steadily increasing over the past five years and in 2024 the Commission received nearly 70 consumer complaints per day on average, up from 42 per day in 2021.</p><p>The final rule will provide a consistent legal framework by prohibiting sellers from:</p><ul><li>misrepresenting any material fact made while marketing goods or services with a negative option feature;</li><li>failing to clearly and conspicuously disclose material terms prior to obtaining a consumer’s billing information in connection with a negative option feature;</li><li>failing to obtain a consumer’s express informed consent to the negative option feature before charging the consumer; and</li><li>failing to provide a simple mechanism to cancel the negative option feature and immediately halt charges.</li></ul><p>Following an evaluation of public comments, the Commission has voted to adopt a final rule with certain changes, most notably dropping a requirement that sellers provide annual reminders to consumers of the negative option feature of their subscription, and dropping a prohibition on sellers telling consumers seeking to cancel their subscription about plan modifications or reasons to keep to their existing agreement without first asking if they want to hear about them.</p><p>The Commission vote approving publication of the final rule in the Federal Register was&nbsp;3-2, with Commissioners Melissa&nbsp;Holyoak and Andrew N.&nbsp;Ferguson voting no. Commissioner Rebecca Kelly Slaughter <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-commissioner-rebecca-kelly-slaughter-regarding-final-trade-regulation-rule-concerning" data-entity-type="node" data-entity-uuid="55347a75-1471-4b9c-b8bf-060d50eb8cd9" data-entity-substitution="canonical">issued a separate statement</a> and Commissioner Holyoak <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/dissenting-statement-commissioner-melissa-holyoak-re-negative-option-rule" data-entity-type="node" data-entity-uuid="744ff40f-0d01-47d6-be80-78cf755c20cc" data-entity-substitution="canonical">issued a separate dissenting statement</a>.</p><p>FTC staff has developed a&nbsp;<a href="https://www.ftc.gov/system/files/ftc_gov/pdf/NegOptions-1page-Oct2024-v2.pdf">fact sheet</a> summarizing the changes to the rule.&nbsp;The primary staffer on this matter is Katherine Johnson in the FTC’s Bureau of Consumer Protection.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Internet Archive is back online (316 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/</link>
            <guid>41857754</guid>
            <pubDate>Wed, 16 Oct 2024 11:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/">https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/</a>, See on <a href="https://news.ycombinator.com/item?id=41857754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Last week, hackers defaced the Internet Archive website with a message that said, "Have you ever felt like the Internet Archive runs on sticks and is constantly on the verge of suffering a catastrophic security breach? It just happened. See 31 million of you on HIBP!"</p>
<p>HIBP is a reference to <a href="https://haveibeenpwned.com/">Have I Been Pwned</a>, which was created by security researcher Troy Hunt and provides information and notifications on data breaches. The hacked Internet Archive data was sent to Have I Been Pwned and "contains authentication information for registered members, including their email addresses, screen names, password change timestamps, Bcrypt-hashed passwords, and other internal data," <a href="https://www.bleepingcomputer.com/news/security/internet-archive-hacked-data-breach-impacts-31-million-users/">BleepingComputer wrote</a>.</p>
<p>Kahle <a href="https://x.com/brewster_kahle/status/1844183111514603812">said on October 9</a> that the Internet Archive fended off a DDoS attack and was working on upgrading security in light of the data breach and website defacement. The next day, he <a href="https://x.com/brewster_kahle/status/1844326137499177312">reported</a> that the "DDoS folks are back" and had knocked the site offline. The Internet Archive "is being cautious and prioritizing keeping data safe at the expense of service availability," he added.</p>
<p>"Services are offline as we examine and strengthen them... Estimated Timeline: days, not weeks," he <a href="https://x.com/brewster_kahle/status/1844790609573277792">wrote</a> on October 11. "Thank you for the offers of pizza (we are set)."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floss/fund: $1M per year for free and open source projects (372 pts)]]></title>
            <link>https://floss.fund/blog/announcing-floss-fund/</link>
            <guid>41857032</guid>
            <pubDate>Wed, 16 Oct 2024 09:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://floss.fund/blog/announcing-floss-fund/">https://floss.fund/blog/announcing-floss-fund/</a>, See on <a href="https://news.ycombinator.com/item?id=41857032">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    
    <article>
      <div>
        <div>
              <p><img src="https://avatars1.githubusercontent.com/u/547147?s=64&amp;v=4" alt="Kailash Nadh photo">
              </p>
              <div>
                <p><span>Kailash Nadh</span>
                <span>CTO @ Zerodha</span></p><p><a href="https://nadh.in/"><img src="https://floss.fund/static/ico-www.svg" alt="Homepage link"></a>
                  
                  
                    <a href="https://github.com/knadh"><img src="https://floss.fund/static/ico-github.svg" alt="GitHub link"></a>
                  
                </p>
              </div>
            </div><!-- meta -->

        <div>
          
          <p>15 Oct 2024</p>

          <p>TLDR; <a href="https://dir.floss.fund/submit">Apply now</a></p>
<hr>
<p>We are excited to announce the launch of a dedicated fund aimed at providing financial assistance to Free/Libre and Open Source Software (FOSS/FLOSS) projects globally, with an annual commitment of $1 million. I will use the FOSS acronym in this post hereafter.</p>
<p>This has been in the works for some time at Zerodha<sup><a href="https://zerodha.com/">[↗]</a></sup>, where we have been developing financial technology products and services built on an ever-growing FOSS stack. Without the high-quality FOSS projects that we have freely downloaded and used to build our organisation, products, and services, we would not exist as we do today—free as in both cost and freedom. A significant portion of our success and growth is owed to FOSS, encompassing everything from programming languages to operating systems, to databases, web servers, frontend frameworks, productivity tools, code editors, and absolutely everything. It goes without saying that this holds true for nearly every technology company founded in the last decade, whether it is publicly acknowledged or not.</p>
<p>And yet, funding and financial sustainability, the lack thereof really, has been an increasingly hot topic over the last many years. Well, at least since <em>cloud</em> companies began making massive profits directly repackaging FOSS projects built by hobbyists and communities. The rise of the "open core" model and the unfortunate license changes in many good open projects recently, are clear signs of this growing turmoil. Many potential solutions seem to be emerging and evoling—commercial services, Venture Capital (VC) funding, and programs like GitHub Sponsors<sup><a href="https://github.com/sponsors">[↗]</a></sup>, Open Collective<sup><a href="https://opencollective.com/">[↗]</a></sup>, FUTO<sup><a href="https://futo.org/">[↗]</a></sup>, Polar<sup><a href="https://polar.sh/">[↗]</a></sup>, and <em>Buy me a coffee</em><sup><a href="https://buymeacoffee.com/">[↗]</a></sup>, amongst others. That said, Python libraries raising massive amounts of VC funding in quick time does not look like a healthy trend.</p>
<p>Why are we here, though? The fundamental tenets of FOSS, the spirit of hacking, liberty, and reciprocity, while they have worked beautifully with code, have translated poorly into the highly commercial <em>BigTech</em> era. So far, it has been nearly impossible to quantify and structure ideas of goodwill and reciprocity into financial sustenance for FOSS projects. I recall the log4j incident from a couple of years ago which unleashed a spate of philosophical debates around  FOSS, in which I also participated<sup><a href="https://nadh.in/blog/open-source-is-not-broken/">[↗]</a></sup>, rather ideologically.</p>
<p>For us, FLOSS/fund is about hacker goodwill, reciprocity, and common sense business strategy. We invite you to <a href="https://dir.floss.fund/submit">apply for funding</a>. If you would like to understand the motivations behind this, a bit of storytelling lies ahead.</p>
<h2 id="prelude">Prelude</h2>
<p>The very first thing I did when we started Zerodha Tech more than a decade ago was to install Python and start scripting and automating time-consuming, mundane organisational tasks. Then came Postgres for building a small data warehouse, followed by PHP and WordPress for managing our website. From there, as we slowly grew the organisation, our technology stack expanded one piece of FOSS at a time, eventually leading to us becoming the largest stock broker in India several years later. Personally, my mental markup as a software developer and hacker is rooted in the simple act of copy-pasting open source code from the internet to hack, tinker, learn, and solve problems. An alternate vision is very difficult for me to comprehend, and a non-FOSS path to building technology, let alone an organisation, has never seemed logical.</p>
<p>At Zerodha, over the years, we have contributed upstream to many projects that we use, as well as spun off and released several small and large FOSS projects<sup><a href="https://zerodha.tech/">[↗]</a></sup> from our work. In 2019, we made a sizeable investment in ERPNext<sup><a href="https://erpnext.com/">[↗]</a></sup>, a FOSS ERP that we had begun using extensively. In 2020, we co-founded the FOSS United Foundation<sup><a href="https://fossunited.org/">[↗]</a></sup>, which works on developing the FOSS ecosystem in India, and backed the creation of TinkerSpace<sup><a href="https://www.tinkerhub.org/tinkerspace">[↗]</a></sup>, a physical hackerspace and community center that hosts FOSS tinkering for young people. In 2023, we were a founding member of OASIS (Open-Source Alliance for Social Innovation and Sustainability)<sup><a href="https://oasishq.org/">[↗]</a></sup>, which focuses on FOSS capacity building and adoption in social sector non-profit organisations. Many of us from our team also volunteer at non-profits, helping drive meaningful FOSS adoption in the development sector, where even basic technological requirements are woefully unmet. We fund many of these initiatives with long-term commitments.</p>
<p>In addition, we have given out many sizeable grants to FOSS projects and organisations in India. While funding projects outside India involves significant paperwork and operational overhead, we have reached out to several small and large projects that we use at work and have managed to pay them. This highly ad hoc approach is something that has increasingly bugged me though.</p>
<p>While it is good to provide financial support to FOSS-aligned activities, most importantly, money ought to go directly to the source—invaluable FOSS projects. We have managed to build a commercially successful business on top of FOSS that we have freely, in both cost and freedom, adopted from all over the world. Therefore, "ad hoc" and "reaching out" simply do not suffice—we have to shut up or put up.</p>
<h2 id="thus-structure">Thus, structure.</h2>
<p>And that is how the idea of a structured, dedicated fund for FOSS projects globally, was born. We spent several months speaking to various banks, payment processors, and lawyers to finally arrive at a reasonably streamlined process. The fund will:</p>
<ul>
<li>Have a small, dedicated team to operate it properly in a non-adhoc manner, functioning like an OSPO (Open Source Program Office) but focused on funding projects—an OSFO (Open Source Funding Office), perhaps?</li>
<li>Put money where the mouth is—a minimum of $10,000 and up to $100,000 for a single recipient, totaling $1 million per year, which we will increase once we understand the dynamics of running the fund.</li>
<li>Source applications globally, relying on incoming applications through for discovering projects in need of support rather than the limited visibility we have as a small team.</li>
<li>Form an interim internal selection committee to make discretionary selections. Once potential edge cases and any gotchas in running the program are handled, we will attempt to establish a public selection committee from the FOSS ecosystem with a community voting process for applications.</li>
</ul>
<h2 id="more-structure-funding-json">More structure: funding.json</h2>
<p>Expanding a bit on "ad hoc" and "reaching out" I mentioned earlier, the  majority of our experience paying projects has transpired like this:</p>
<p>On a random day, we realise that a certain FOSS project has become very useful to us. After a bit of online searching, we find the developer's email address. We write to the developer, thanking them for their work, explaining how useful we find it, and expressing our interest in financially supporting it. They respond, thanking us but stating that they have not thought of any specific numbers. After a bit of friendly back and forth, we suggest an arbitrary amount, followed by more discussion about logistics and paperwork. This process of arriving at numbers over personal e-mails is awkward for both parties. It addition, it typically takes weeks, requiring time, commitment, and bandwidth from both the developer and the donor to complete a single transaction. Models like Open Collective and GitHub Sponsors address this to some extent, but there is no open, decentralized mechanism for discovering projects in need of financial assistance nor gaining insights into their specific needs.</p>
<p>Any attempt on funding FOSS projects generally warrants clarity on several questions.</p>
<ul>
<li>Does the project under consideration need financial assistance?</li>
<li>Or perhaps it is not just one particular project, but a developer or a group of developers who maintain several projects that need assistance.</li>
<li>What kind and quantum of financial assistance are needed, and for what activities? Is there a structured support plan that the developers offer?</li>
<li>Has the project received any funding in the past? Is it in dire need of support, or is it doing reasonably well?</li>
<li>What payment methods are accepted? Is there a payment link or address that can be used without manual contact, or is something like a bank wire that is required?</li>
<li>Once there is enough context, and a conversation is warranted, how does one reach out to the right person who address financial or logistical queries?</li>
<li>That's about one project. But what about a particular category of projects? Maybe it is an emerging or critical area, and it would make sense to support multiple projects there. How does one discover them?</li>
</ul>
<p>What if the answers to such questions could be structured in a machine readable format, which could be crawled, indexed, catalogued, and made discoverable—similar to a <code>robots.txt</code> or <code>package.json</code> or <code>sitemap.xml</code>, but for funding. In the process, eliminating a lot of awkwardness and apprehension that would be otherwise transpire over back-and-forth personal e-mails discussing financial matters.</p>
<p>How about a standardised <code>funding.json</code> manifest file that can be added to project repositories and websites signalling their financial needs? Something like this:</p>
<pre data-lang="python"><code data-lang="python"><span>{
</span><span>    </span><span>"version"</span><span>: </span><span>"v1.0.0"</span><span>,
</span><span>    </span><span>"entity"</span><span>: {
</span><span>        </span><span>"type"</span><span>: </span><span>"individual"</span><span>,
</span><span>        </span><span>"role"</span><span>: </span><span>"maintainer"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"The One (demo)"</span><span>,
</span><span>        </span><span>"email"</span><span>: </span><span>"<a href="https://floss.fund/cdn-cgi/l/email-protection" data-cfemail="e48a818ba4819c8589948881ca878b89">[email&nbsp;protected]</a>"</span><span>,
</span><span>        </span><span>"phone"</span><span>: </span><span>""</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"I'm a developer interested in preserving digital freedoms and the decentralised and open nature of the internet. I like breaking down barriers in the cyberspace with FOSS technologies.</span><span>\n\n</span><span>Sometimes I can't shake the feeling that the system we're living in isn't quite what it seems. That there is no spoon.</span><span>\n\n</span><span>PS: This is a dummy listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://example.com"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>""
</span><span>        }
</span><span>    },
</span><span>    </span><span>"projects"</span><span>: [{
</span><span>        </span><span>"guid"</span><span>: </span><span>"zombo-app"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"Zombo App (demo)"</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"The Zombo App is a database application that solves many problems and makes anything possible. Anything at all. Its possibilities are only limited by the user's own imagination.</span><span>\n\n</span><span>It has been in active development for a decade and is used by millions of people worldwide. It is the next frontier.</span><span>\n\n</span><span>PS: This is a dummy demo listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://example.com/projects/zombo"
</span><span>        },
</span><span>        </span><span>"repositoryUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://github.com/example/zombo-app"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://github.com/example/zombo-app/blob/main/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"licenses"</span><span>: [</span><span>"spdx:AGPL-3.0"</span><span>],
</span><span>        </span><span>"tags"</span><span>: [</span><span>"database"</span><span>, </span><span>"columnar-database"</span><span>, </span><span>"high-performance"</span><span>, </span><span>"key-value-store"</span><span>]
</span><span>    },
</span><span>    {
</span><span>        </span><span>"guid"</span><span>: </span><span>"vb-gooey"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"VB Gooey IP tracer (demo)"</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"Using quantum-entangled packet sniffers, this cutting-edge Visual Basic GUI IP Tracer employs hyper-threaded blockchain algorithms to decrypt the target's digital DNA signature. The system's neural network of overclocked RAM crystals generates a real-time holographic map of cyberspace, pinpointing the perp's location with nanosecond precision.</span><span>\n\n</span><span>In addition, its turbo-encabulated flux capacitor and multi-dimensional firewall penetrator, allows any hyper-dimensional air-gapped network to be broken into with ease.</span><span>\n\n\n\n</span><span>PS: This is a dummy demo listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://vb-gooey-ip-tracer.net"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://vb-gooey-ip-tracer.net/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"repositoryUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://github.com/example/vb-gooey-ip-tracer"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://github.com/example/vb-gooey-ip-tracer/blob/main/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"licenses"</span><span>: [</span><span>"spdx:MIT"</span><span>],
</span><span>        </span><span>"tags"</span><span>: [</span><span>"high-performance"</span><span>, </span><span>"security"</span><span>, </span><span>"gui"</span><span>, </span><span>"networking"</span><span>]
</span><span>    }],
</span><span>    </span><span>"funding"</span><span>: {
</span><span>        </span><span>"channels"</span><span>: [
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"mybank"</span><span>,
</span><span>                </span><span>"type"</span><span>: </span><span>"bank"</span><span>,
</span><span>                </span><span>"address"</span><span>: </span><span>""</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Will accept direct bank transfers. Please e-mail me for details."
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"mypay"</span><span>,
</span><span>                </span><span>"type"</span><span>: </span><span>"payment-provider"</span><span>,
</span><span>                </span><span>"address"</span><span>: </span><span>"https://example.com/payme/@myid"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Pay with your debit/credit card through this gateway and setup recurring subscriptions."
</span><span>            }
</span><span>        ],
</span><span>        </span><span>"plans"</span><span>: [
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"hosting-monthly"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Hosting support"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"This will cover the monthly server hosting costs for the projects."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>250</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"monthly"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mypay"</span><span>]
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"developer-time"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Developer compensation"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"This will cover the cost of one developer working part-time on the projects."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>1000</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"monthly"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mybank"</span><span>]
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"angel-plan"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Goodwill plan"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Pay anything you wish to show your goodwill for the project."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>0</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"one-time"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mybank"</span><span>, </span><span>"mypay"</span><span>]
</span><span>            }
</span><span>        ],
</span><span>        </span><span>"history"</span><span>: [
</span><span>            {</span><span>"year"</span><span>: </span><span>2020</span><span>, </span><span>"income"</span><span>: </span><span>10000</span><span>, </span><span>"expenses"</span><span>: </span><span>2000</span><span>, </span><span>"taxes"</span><span>: </span><span>200</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>"Started accepting donations for the first time."</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2021</span><span>, </span><span>"income"</span><span>: </span><span>15000</span><span>, </span><span>"expenses"</span><span>: </span><span>5000</span><span>, </span><span>"taxes"</span><span>: </span><span>500</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>""</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2022</span><span>, </span><span>"income"</span><span>: </span><span>30000</span><span>, </span><span>"expenses"</span><span>: </span><span>10000</span><span>, </span><span>"taxes"</span><span>: </span><span>2000</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>""</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2023</span><span>, </span><span>"income"</span><span>: </span><span>25000</span><span>, </span><span>"expenses"</span><span>: </span><span>15000</span><span>, </span><span>"taxes"</span><span>: </span><span>1500</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>"There was a dip, but we see this improving."</span><span>}
</span><span>        ]
</span><span>    }
</span><span>}
</span><span>
</span></code></pre>
<p>To initiate and give this experiment a serious shot, FLOSS/fund will accept funding requests from projects through a publicly accessible <code>funding.json</code> file hosted on their respositories or websites. This file is not meant to convey everything there is to know—an impossible task—but to solicit interest and communicate enough to ensure discoverability which would not be possible otherwise. Refer to the <a href="https://floss.fund/funding-manifest">funding.json docs</a> to know more.</p>
<p>Applications that come through to the FLOSS/fund will be indexed and published on the <a href="https://dir.floss.fund/">dir.floss.fund</a> directory / portal, making them publicly discoverable by anyone interested in supporting projects. This is going to be an interesting experiment. Fingers crossed!</p>
<h2 id="motivations">Motivations</h2>
<p>What are the motivations behind the fund? On a personal level, it is common sense, goodwill, and reciprocity—the spirit of FOSS. From a for-profit enterprise perspective, however, terms like "goodwill" and "reciprocity" are notoriously problematic, and most likely fundamentally incompatible with their very nature. But, that is a separate philosophical debate altogether.</p>
<p>Setting philosophies aside, it makes perfect logical sense for a business that relies on FOSS to support it, directly or indirectly, when they freely tap into a global ecosystem of unlimited FOSS innovation—free in both cost and freedom. How many technology companies today could even exist without the massive amounts of FOSS they use? Ensuring that this ecosystem thrives, without inadvertently turning parts of it into a classic tragedy of the commons, everything aside, is good, logical business strategy. At the very least, a profitable business should allocate a tiny fraction of its profits to support the projects it is directly reliant on. When many startups have advertising and marketing budgets that often put public spending to shame, one would be hard-pressed to find a reason not to give a bit of money  to the projects they depend on for their very existence.</p>
<p>Thus, FLOSS/fund's motivations are to:</p>
<ul>
<li>Exercise our goodwill and reciprocity on a personal level as FOSS hackers.</li>
<li>Exercise our organisational business sense and strategy to help the FOSS ecosystem thrive, without which our business cannot exist.</li>
<li>Encourage and apply a bit of peer-pressure on other businesses to setup structured financial support programmes for FOSS.</li>
<li>Contribute to existing FOSS funding models and to the sustainability conversations and debates.</li>
<li>As a bonus: Explore whether the <code>funding.json</code> manifest experiment can bring discoverability to the financial needs of FOSS projects on a large scale.</li>
</ul>
<p>Let us see how this goes.</p>


        </div><!-- post -->
      </div>
    </article>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mullvad VPN: macOS sometimes leaks traffic after system updates (368 pts)]]></title>
            <link>https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates</link>
            <guid>41856883</guid>
            <pubDate>Wed, 16 Oct 2024 08:37:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates">https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates</a>, See on <a href="https://news.ycombinator.com/item?id=41856883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!-- HTML_TAG_START --><p>We have found that you could be leaking traffic on macOS after system updates. To our current knowledge a reboot resolves it. We are currently investigating this and will follow up with more information.</p>
<h2>The current state</h2>
<p>In this scenario the macOS firewall does not seem to function correctly and is disregarding firewall rules. Most traffic will still go inside the VPN tunnel since the routing table specifies that it should. Unfortunately apps are not required to respect the routing table and can send traffic outside the tunnel if they try to. Some examples of apps that do this are Apple’s own apps and services since macOS 14.6, up until a recent 15.1 beta.</p>
<h2>What’s next?</h2>
<p>We’ve reported this to Apple and hopefully we’ll see a fix in the near future. In the meanwhile we will continue to investigate this to be able to provide more information to Apple and to see if there are any workarounds that we can implement in the app.</p>
<h2>Check if you are affected</h2>
<p>Run the following commands in a terminal to check if you are affected:</p>
<p>&nbsp;1. Add a firewall rule that blocks all traffic</p>
<pre><code>echo "block drop quick all" | sudo pfctl -ef -</code></pre>
<p>2. Try to send traffic outside the tunnel</p>
<pre><code>curl https://am.i.mullvad.net/connected</code></pre>
<p>To clean up after the experiment, disable the firewall and clear all rules.</p>
<pre><code>sudo pfctl -d</code><br><code>sudo pfctl -f /etc/pf.conf</code></pre>
<p>It is also possible to check if our app is leaking by doing the following:</p>
<p>1. Make sure you are not connected to a VPN<br>2. Find the default interface by running the following command in a terminal</p>
<pre><code>route get mullvad.net | sed -nE 's/.*interface: //p'</code></pre>
<p>3. Connect to a VPN server using our app<br>4. Run the following command (replace “&lt;interface&gt;” with the interface from step 2)</p>
<pre><code>curl --interface &lt;interface&gt; https://am.i.mullvad.net/connected</code></pre>
<p>5. The request should time out if everything is working properly. If there is a response then you are leaking.</p><!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Self-Hosted Llama 3.2 with Coolify on My Home Server (207 pts)]]></title>
            <link>https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide</link>
            <guid>41855886</guid>
            <pubDate>Wed, 16 Oct 2024 05:26:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide">https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide</a>, See on <a href="https://news.ycombinator.com/item?id=41855886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Inspired by numerous people migrating their Next.js applications from Vercel to self-hosted VPS on Hetzner due to pricing concerns, I decided to explore self-hosting some of my non-critical applications. Additionally, I wanted to push my technical boundaries by running Llama 3.2 using Ollama and making its API available to power AI applications for my business, Wisp.</p><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/f532cf09-87ff-435b-bede-be0677b4419f.jpg/public" alt="Home server as a step stool"></p><p>The objective was to breathe new life into an old home server that once ran high-frequency trading and MEV algorithms but had since become a step stool for my daughter to climb onto the TV console.</p><p>This blog post chronicles my journey of setting up Coolify to run Ollama (using Llama 3.2) on my home server, with a particular focus on the challenges and triumphs of enabling GPU acceleration using the CUDA toolkit.</p><p>(Update)</p><p>Since some of you are curious, this is how Llama 3.2 3B perform on a GeForce RTX 2060:</p><p><iframe allowfullscreen="true" src="https://www.youtube.com/embed/3vhJ6fNW8AI"></iframe></p><h2>My Goals</h2><p>The primary idea was to leverage my home server, previously gathering dust, to perform valuable tasks. Specifically, I wanted it to host and automate AI-related functions. Additionally, this setup would provide a centralized location to run Supabase for storing various data. The broader goal includes:</p><ul><li><p><strong>Serving a Next.js website</strong>: This site should be live on the public Internet, auto-deploy from the master branch, work with a public subdomain, and maintain no open public ports for security.</p></li><li><p><strong>Running Llama 3.2</strong>: Utilizing the GPU for agentic tasks and making a locally accessible API.</p></li><li><p><strong>Wildcard domain</strong>: Enabling new services to spin up effortlessly under varied subdomains.</p></li></ul><h2>Overall Experience</h2><p>Setting up this environment was no small feat, but each step was a valuable learning experience. Here's a walkthrough of my journey:</p><ol><li><p><strong>Installing Ubuntu 24</strong>: This was a breeze, requiring only a single reboot.</p></li><li><p><strong>Coolify Installation</strong>: The process was smooth thanks to the handy install script, which ensured most prerequisites were met. A minor hiccup was resolved by running commands as root to avoid permission issues with the <code>/data</code> directory.</p></li><li><p><strong>Configuring Coolify</strong>: Initially, setting the server as <a target="_blank" href="http://localhost/">localhost</a> prevented assigning a domain via Cloudflare Tunnel. The fix involved adding the host as a second 'server'. Moreover, configuring the tunnel and SSL correctly took time but was crucial for security and functionality.</p></li><li><p><strong>Cloudflare Tunnel</strong>: Patience was key here. The wildcard domain setup was essential, and understanding the nuances of Cloudflare’s free SSL certificate coverage saved time and money.</p></li><li><p><strong>Deployment Wins</strong>: Successfully hosting my personal blog using Coolify over a Cloudflare Tunnel was a significant morale boost, fueling the energy needed to proceed with the Ollama setup.</p></li><li><p><strong>Running Ollama</strong>: Coolify made deploying the Ollama service straightforward. However, initial trials showed slow inference speeds and heavy CPU usage.</p></li><li><p><strong>Enabling GPU</strong>: Ubuntu 24 had the NVIDIA drivers pre-installed, but CUDA toolkit installation and configuration posed challenges. Persistent efforts led to discovering the need for the <code>nvidia-container-toolkit</code> and Docker service configuration modifications to enable GPU usage. The results were remarkable, reducing inference time by over 10x.</p></li><li><p><strong>API Exposure</strong>: Securing the LLM API with an API key became the next challenge. After unsuccessful attempts with nginx, I found potential solutions by using Caddy. Something I'll work on next after writing this post.</p></li></ol><h2><strong>Server Specifications</strong></h2><p>For context, here are the specifications of my home server:</p><ul><li><p><strong>CPU</strong>: AMD Ryzen 9 5950X 16-Core</p></li><li><p><strong>GPU</strong>: GeForce RTX 2060</p></li><li><p><strong>RAM</strong>: 4 x 16GB DDR4 3200 MT/s</p></li><li><p><strong>SSD</strong>: 2TB SSD + 8TB SSD</p></li></ul><h2><strong>Step-by-Step Guide</strong></h2><h3><strong>1. Install Ubuntu (For a New Setup)</strong></h3><p>Start by installing Ubuntu on your home server. Follow the detailed guide available on the <a target="_blank" href="https://ubuntu.com/tutorials/install-ubuntu-desktop"><strong>official Ubuntu website</strong></a>.</p><p><strong>Important Settings:</strong></p><ul><li><p>Avoid using LVM or disk encryption for a smoother reboot experience and easier server management. Note that this trade-off means anyone with physical access can read your data.</p></li><li><p>Ensure the installation of third-party drivers to automatically get the NVIDIA driver.</p></li></ul><h3><strong>Install SSH</strong></h3><p>Enable SSH to access your server remotely, which is especially useful if you’re managing it from another machine on your local network. Refer to this <a target="_blank" href="https://linuxize.com/post/how-to-enable-ssh-on-ubuntu-20-04/"><strong>SSH setup guide for Ubuntu 20.04</strong></a>, suitable for Ubuntu 24 as well.</p><h3><strong>Update and Upgrade APT</strong></h3><p>Always perform an update and upgrade for your packages:</p><pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y</code></pre><h3>Useful Commands</h3><p>Here are some additional commands for printing information about your machine and setup:</p><ul><li><p>View CPU usage: <code>htop</code></p></li><li><p>List NVIDIA graphics card information: <code>lspci | grep -i nvidia</code></p></li><li><p>Print architecture, OS distro, release: <code>uname -m &amp;&amp; cat /etc/*release</code></p></li><li><p>Print physical RAM installed: <code>sudo dmidecode --type memory | less</code></p></li><li><p>Print processor info: <code>cat /proc/cpuinfo | grep 'name'| uniq</code></p></li><li><p>Check NVIDIA driver information: <code>nvidia-smi</code></p></li></ul><h3><strong>2. Installing Coolify</strong></h3><p><a target="_blank" href="https://coolify.io/">Coolify</a> is an open-source platform designed to make deploying and managing your applications on self-hosted environments easier. Its key feature is allowing users to manage full-stack applications, databases, and services without relying on complex Kubernetes setups. Coolify streamlines deployments through a user-friendly interface, supporting services like Docker, GitHub, and GitLab.</p><p>To install Coolify, follow the automated installation instructions from <a target="_blank" href="https://coolify.io/docs/installation/">their documentation</a>:</p><pre><code>curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash</code></pre><p><strong>Important Notes</strong>:</p><ul><li><p>Ensure you’re logged in as the root user to avoid permission issues.</p></li><li><p>The installation script checks prerequisites, but you may need to troubleshoot some dependency errors if they arise.</p></li></ul><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/43c2d6eb-aba3-45ab-aad9-0f47e8895fa5.png/public" alt="Coolify onboarding screen"></p><p>Once Coolify is installed:</p><ul><li><p><strong>Visit the coolify dashboard</strong> at <code>http://localhost:8000</code> . This is also available on the network. Replace localhost with the ip address of the server if you are accessing it from another machine.</p></li><li><p><strong>Set up an admin account</strong> - this is stored locally on your server.</p></li><li><p><strong>Create your first project</strong> by adding a resource and deploying it to <code>localhost</code>. In my case, I deployed my personal blog first to test the setup.</p></li></ul><h3><strong>3. Setting Up a Cloudflare Tunnel on Coolify</strong></h3><p>Cloudflare Tunnel is a secure way to expose services running on your local network to the public internet without having to open ports on your router. For my setup, this was a key feature, as I wanted to keep my server behind a firewall while still allowing external access to some services.</p><p>Cloudflare’s Zero Trust platform ensures that all traffic is encrypted and routed securely, preventing unauthorized access.</p><p>To set up a Cloudflare Tunnel, follow this instructions on Coolify’s <a target="_blank" href="https://coolify.io/docs/knowledge-base/cloudflare/tunnels">official documentation</a>. The key is to focus on setting up <strong>wildcard subdomains</strong> for all your services.</p><p>A few key caveats:</p><ol><li><p><strong>Localhost Server Issue</strong>: You cannot assign a domain to the pre-created <code>localhost</code> server directly. To solve this, add your host as a second server within Coolify, using the IP address <code>172.17.0.1</code> for <code>host.docker.internal</code> (since coolify will show an error that <code>host.docker.internal</code> has already been assigned to a server).</p></li><li><p><strong>Wildcard Domain Setup</strong>: Make sure you use a top-level domain like <code>*.example.com</code>. If you use a wildcard on a subdomain, Cloudflare will not provide a free SSL certificate, unless you opt for the ACM plan.</p></li></ol><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/4c338964-bf9d-4466-975a-fca268f56795.png/public"></p><p>After setting up the Cloudflare Tunnel:</p><ul><li><p>Deploy your resources to the newly added server.</p></li><li><p>Change the domain in the service configuration to match your new subdomain.</p></li><li><p>Once everything is deployed, you should be able to access your service live from its custom domain.</p></li></ul><h3><strong>4. Deploying Ollama</strong></h3><p>Once you’ve set up your Coolify project, the next step is to deploy Ollama. This service allows you to run large language models (LLMs) like Llama 3.2 on your server with a web-based interface.</p><ol><li><p><strong>Add a New Resource</strong>: In your Coolify project, select "Add Resource" and choose <strong>Ollama with Open WebUI</strong> as the service you want to deploy to your new server.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/2b634b6c-17db-4f5c-afba-615b4cc1cef0.png/public" alt="Deploying Ollama in Coolify"></li><li><p><strong>Configure the Domain</strong>: After adding Ollama, configure the domain for the Open WebUI service. Assign a domain from the wildcard domain you set up earlier through Cloudflare Tunnel. This will allow you to access the Ollama WebUI directly from the internet.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/d7eb2920-5e28-47b9-9d02-9cb3740ca3b5.png/public" alt="Configuring domain on Coolify resource"></li><li><p><strong>Deploy the Service</strong>: Once everything is set up, click on "Deploy."</p><p>You should now be able to access the Open WebUI via the assigned domain. Upon your first login, you'll be prompted to create an admin account. This is important for managing models and access through the UI.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/69c5be6f-4570-4bea-b334-123c5b9cb25f.png/public" alt="WebUI for Ollama"></li><li><p><strong>Install Llama 3.2</strong>: With your admin account set up, you can now install the latest Llama model. Head to <a target="_blank" href="https://ollama.com/library">Ollama's library</a> and search for the Llama model you want to use. I opted for <strong>Llama 3.2</strong>, which can be installed using the tag <code>llama3.2</code>.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/6d081703-a0eb-4412-97d0-05bb765f3afc.png/public" alt="Downloading models using WebUI with Ollama"></li><li><p><strong>Try Your First Chat</strong>: Once installed, initiate your first chat with Llama 3.2 via the web interface. During this phase, your model will likely run on the CPU, so expect to hear your machine working hard (with increased CPU fan noise).</p><p>To monitor your machine’s performance during this, use the following commands:</p><ul><li><p><code>htop</code> to keep an eye on <strong>CPU usage</strong>.</p></li><li><p><code>watch -n 0.5 nvidia-smi</code> to track <strong>GPU usage</strong> (though at this stage, GPU may not be utilized yet).</p></li></ul><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/6052bfb2-63bb-49cf-a75b-c4f643dee830.png/public" alt="Crazy CPU usage when Llama 3.2 runs using CPU"></li></ol><h3><strong>5. Configuring Ollama to Use GPU</strong></h3><p>Large language models (LLMs) like Llama 3.2 perform significantly better with GPU acceleration. GPUs, particularly those from NVIDIA, are optimized for the heavy parallel computations involved in AI workloads, which is where CUDA (Compute Unified Device Architecture) comes into play. The CUDA toolkit enables direct GPU acceleration for applications like Ollama, drastically reducing inference time and CPU load.</p><p>This is arguably the most challenging step in setting up Ollama on your server, but here’s a breakdown of the process:</p><ol><li><p><strong>(Already Done)</strong>: Install the NVIDIA driver (this should have been handled during your Ubuntu installation).</p></li><li><p><strong>Install the NVIDIA CUDA Toolkit</strong>: This toolkit is necessary to unlock GPU acceleration.</p></li><li><p><strong>(Optional)</strong>: Test that the CUDA toolkit is working correctly.</p></li><li><p><strong>Install the NVIDIA Container Toolkit</strong>: This will allow Docker containers (like Ollama) to access the GPU.</p></li><li><p><strong>Enable the Ollama service in Coolify to use the GPU</strong>.</p></li></ol><p><strong>Install the NVIDIA CUDA Toolkit</strong></p><p>Follow NVIDIA’s official <a target="_blank" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">installation guide</a> to install the CUDA toolkit for your system. I recommend using the <strong>network repository installation method</strong> for the most flexibility and ease of updates.</p><ol><li><p>Install the new <code>cuda-keyring</code> package:</p><pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb</code></pre><p>Replace <code>&lt;distro&gt;/&lt;arch&gt;</code> with the appropriate value for your distribution and architecture:</p><ul><li><p><code>ubuntu2004/arm64</code></p></li><li><p><code>ubuntu2004/sbsa</code></p></li><li><p><code>ubuntu2004/x86_64</code></p></li><li><p><code>ubuntu2204/sbsa</code></p></li><li><p><code>ubuntu2204/x86_64</code></p></li><li><p><code>ubuntu2404/sbsa</code></p></li><li><p><code>ubuntu2404/x86_64</code></p></li></ul></li><li><p>Update the APT repository cache:</p><pre><code>sudo apt-get update</code></pre></li><li><p>Install the CUDA SDK:</p><pre><code>sudo apt-get install cuda-toolkit</code></pre></li><li><p>Set up the environment for CUDA by adding its binaries to your PATH:</p><pre><code>export PATH=/usr/local/cuda-12.6/bin${PATH:+:${PATH}}</code></pre></li><li><p>Reboot the system to ensure all configurations take effect:</p><pre><code>sudo reboot</code></pre></li></ol><p><strong>(Optional) Test that CUDA Toolkit Works</strong></p><p>To ensure that your system is correctly configured for GPU acceleration, test the CUDA installation by compiling and running sample programs provided by NVIDIA (<a target="_blank" href="https://github.com/nvidia/cuda-samples">https://github.com/nvidia/cuda-samples</a>).</p><ol><li><p>First, install the necessary build tools:</p><pre><code>sudo apt install build-essential</code></pre></li><li><p>Clone the CUDA sample repository and build the sample projects:</p><pre><code>git clone https://github.com/nvidia/cuda-samples
cd cuda-samples
make</code></pre></li><li><p>Navigate to the compiled binaries and run the <code>deviceQuery</code> tool to verify your GPU and CUDA installation:</p><pre><code>cd bin/x86_64/linux/release
./deviceQuery</code></pre><p>You should see detailed information about your GPU and CUDA environment, confirming that the toolkit is working correctly.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/fba84378-4c3c-4712-9230-ba2476654826.png/public" alt="deviceQuery showing CUDA Capable device(s)"></li></ol><p><strong>Install NVIDIA Container Toolkit</strong></p><p>To enable Docker containers to access your GPU, you'll need to install the NVIDIA Container Toolkit. This toolkit allows Docker to offload GPU-intensive operations to your NVIDIA GPU, essential for speeding up tasks like model inference with Ollama.</p><p>Follow the steps below from <a target="_blank" href="https://hub.docker.com/r/ollama/ollama">Ollama docker docs</a> to install the NVIDIA Container Toolkit:</p><ol><li><p><strong>Configure the repository</strong>:</p><pre><code>curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \
    | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \
    | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \
    | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update</code></pre></li><li><p><strong>Install the NVIDIA Container Toolkit packages</strong>:</p><pre><code>sudo apt-get install -y nvidia-container-toolkit</code></pre></li></ol><p>With the container toolkit installed, Docker will now be able to use your GPU.</p><p><strong>Enable Ollama Service in Coolify to Use GPU</strong></p><p>To enable GPU support for the Ollama service in Coolify, you'll need to modify the Docker Compose file to allow access to all the GPUs on the host machine.</p><ol><li><p><strong>Edit the Compose File</strong>: Navigate to the Ollama service in Coolify and select "Edit Compose File."</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/b3cff181-410b-49fc-82fe-6bfbe0280854.png/public" alt="Edit compose file in Coolify"></li><li><p><strong>Add GPU Configuration</strong>: Append the following configuration under the <code>ollama-api</code> resource. This enables Docker to utilize all GPUs available on the host system:</p><pre><code>    deploy:
      resources:
        reservations:
          devices:
            -
              driver: nvidia
              count: all
              capabilities:
                - gpu</code></pre></li><li><p><strong>Restart the Service</strong>: After saving the changes, restart the Ollama service by clicking the "Restart" button in Coolify.</p></li></ol><p>Once restarted, Ollama will now leverage your GPU for model inference. You can verify that it's using the GPU by running:</p><ul><li><p><code>htop</code> to check CPU usage (it should remain low).</p></li><li><p><code>watch -n 0.5 nvidia-smi</code> to see the GPU usage in action.</p></li></ul><p><strong>Testing GPU Performance</strong></p><p>Try initiating another conversation with Llama 3.2 via the web UI. This time, you should notice a significant reduction in CPU load, as the GPU will handle the inference tasks.</p><p>Congratulations! You’ve successfully configured Ollama to use GPU acceleration through Coolify on your home server!</p><h3><strong>Next Steps</strong></h3><p>The final step in securing your setup is to expose the LLM API to the internet while ensuring it’s protected by an API key. Using Caddy, you can enforce API key access for the Ollama service.</p><p>For a detailed guide, refer to this <a target="_blank" href="https://github.com/ollama/ollama/issues/849">discussion</a>.</p><h2>Conclusion</h2><p>In this post, I detailed my journey of setting up Llama 3.2 on my home server, utilizing GPU acceleration to handle AI workloads efficiently. Starting from a simple Ubuntu setup, I navigated the complexities of installing NVIDIA drivers, configuring Docker for GPU support, and deploying Ollama using Coolify. With this setup, I now have a powerful AI system running locally, handling agentic tasks with ease.</p><p>This guide walks through the entire process, from software installations to troubleshooting, and provides a blueprint for anyone looking to do the same.</p><h3><strong>References</strong></h3><ul><li><p><a target="_blank" href="https://www.reddit.com/r/ollama/comments/1c8ddv8/ollama_doesnt_use_gpu_pls_help/">Reddit: Ollama Not Using GPU</a></p></li><li><p><a target="_blank" href="https://www.reddit.com/r/LocalLLaMA/comments/1cew9fb/is_ollama_supposed_to_run_on_your_gpu/">Reddit: Is Ollama Supposed to Run on GPU?</a></p></li><li><p><a target="_blank" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/">NVIDIA CUDA Installation Guide</a></p></li><li><p><a target="_blank" href="https://hub.docker.com/r/ollama/ollama">Ollama Docker Hub</a></p></li><li><p><a target="_blank" href="https://stackoverflow.com/questions/70761192/docker-compose-equivalent-of-docker-run-gpu-all-option">StackOverflow: Docker Compose GPU Setup</a></p></li></ul><p><small><a target="_blank" href="https://www.wisp.blog/?utm_source=web&amp;utm_campaign=attribution&amp;utm_content=cm2bbhb1u000111hp13ioe9i3">Powered by wisp</a></small></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let Google decide (151 pts)]]></title>
            <link>https://cupofsquid.com/post/not-real/</link>
            <guid>41855512</guid>
            <pubDate>Wed, 16 Oct 2024 04:07:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cupofsquid.com/post/not-real/">https://cupofsquid.com/post/not-real/</a>, See on <a href="https://news.ycombinator.com/item?id=41855512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<article>
		
		

		<div>
			<h2 id="when-personhood-is-decided-by-the-big-five">When “personhood” is decided by the Big Five</h2>
<p>My partner and I recently moved states in order to benefit from lower rent and a
more affordable living environment. We found a place on Craigslist for the
winter that was not only scam-free, but extremely cute. We visited it in person,
met the landlord, and agreed to tenancy until April after the threat of frost.
The process, despite its rushed quality, was rather straightforward.</p>
<p>However, we started running into problems when we began updating our address.
Google, it seemed, never heard of our road let alone the fact that there were
houses on it.</p>
<p>I first noticed this issue when I went to update my address with my online
credit union. I was told, in no uncertain terms that the street didn’t exist
after I overrode the Google Maps autocomplete. When I switched to our PO Box
number, an error message popped up and said that “PO Boxes were not appropriate
addresses.”</p>
<p>And so our saga began.</p>
<p>The town, thankfully, knew of the road and gave us no problems when it came to
hyper-local needs like car registration at the downtown office. Signing up for a
new phone service left us both screaming at the computer, then eventually
settling with putting our address as the post office (because, again, PO boxes
aren’t “appropriate addresses”). We just hoped that the town being small enough
would make it so they would know where to put mail should something ever come
from the phone company or any other service that used Google to verify
addresses.</p>
<p>Getting a license was also difficult, since mail was rarely delivered to our
physical address. Instead, both of us needed to sign an affadavit…to prove
that the other person lived with us or at least wasn’t lying about living in the
state.</p>
<p>Which, when you think about it, is weird, right?</p>
<p>Go in with enough random people to say you lived at a place and that was more
legitimate than a letter with your address on top from a propane company that
served half the state.</p>
<p>The letter, you see, doesn’t count because it wasn’t a bill with the account
number on it, even though the mysterious street address was. But of course new
tenants wouldn’t have a bill with the account number on it yet since they had
only just moved in! Proof of car insurance wasn’t enough either because it only
had our mailing address, which is a PO Box…and well, we know what Serious
Institutions think of PO Boxes.</p>
<p>And while we have figured at least some of this out, we also had difficulty
discerning where to begin. Since, to get the PO Box at all, USPS had to know
where we lived and that we had proof of living in the town we wanted the PO Box
at…which caused a headache with Google Maps autocomplete again. Because of
Google, our address wasn’t even present for the USPS, who should have more say
than Google about what is and isn’t an address! It took a sympathetic postmaster
to help us out in person, since everyone in that office had delivered local mail
to our address previously, so knew we weren’t making things up.</p>
<p>This entire debacle is worth mentioning in as full of detail as possible for two
reasons: (1) It shows the extent to which Google can dictate our lives and how
we get to live it. (2) Proof of address is needed for so many things, down to the
basic necessities to be legal within this country.</p>
<p>If I don’t have an address, I cannot have a bank account. I cannot get a
driver’s license, register my car, vote in my town. I cannot even get a library
card.</p>
<p>For an entire week, I was a non-person to this country’s bureaucracy, which in
some respects <em>should</em> feel freeing, but in the end was a massive pain in the
ass. It was frightening to consider that something as simple as an address not
showing up on the world’s most popular maps app meant that, without the
intervention of locals who understood what it meant to live in a largely
unmarked rural area, this non-personhood would’ve potentially been permanent.</p>
<p>On a larger scale, it made me concerned for the use of AI in these kinds of
situations. What if I wasn’t able to intercept a human postmaster who could then
look at my documents and say that I was able to have a PO Box to receive mail
from outside of town? Or talk to a DMV associate who could see that my partner
was right beside me and could vouch for my legitimacy as a state resident?</p>
<p>Technology, of course, is falliable. It cannot account for all cases, all
possibilities. And forbid the thought of politics entering into it. These tools
can easily be manipulated further to label anyone outside of the white,
heteronormative, cisgender conglomerate as a non-person in the eyes of the
larger system. All they need is a huge company like Google to “not recognize” a
few key factors like whole neighborhoods in redlined areas or a gender marker
(as compared to a birth certificate or something).</p>
<p>If nothing else, I learned that nothing beats talking to a real, live human
being, especially those that are just down the street.</p>

		</div>
	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Medical student's apparent celiac disease responded to giardiasis treatment (165 pts)]]></title>
            <link>https://www.backpacker.com/skills/outdoor-first-aid/are-those-stomach-troubles-celiac-or-giardia/</link>
            <guid>41855307</guid>
            <pubDate>Wed, 16 Oct 2024 03:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.backpacker.com/skills/outdoor-first-aid/are-those-stomach-troubles-celiac-or-giardia/">https://www.backpacker.com/skills/outdoor-first-aid/are-those-stomach-troubles-celiac-or-giardia/</a>, See on <a href="https://news.ycombinator.com/item?id=41855307">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-inject-ads="" data-inject-ads-options="{ &quot;markup&quot;: [&quot;<div class='js-ad js-hide-elements js-visible-signed-out js-scroll-load o-ad c-ad--inline' data-child-zone='in-content-leaderboard-bp' data-size='[\&quot;fluid\&quot;,[300,50],[300,100],[728,90],[320,50],[320,100],[468,60],[300,250],[1,1]]' data-size-map='[[[1145,0],[\&quot;fluid\&quot;,[728,90],[468,60],[1,1]]],[[850,0],[\&quot;fluid\&quot;,[468,60],[1,1]]],[[0,0],[\&quot;fluid\&quot;,[300,250],[320,100],[300,100],[320,50],[300,50],[1,1]]]]' data-hide-elements='.o-banner-ad__vertical .js-ad'></div>&quot;], &quot;filter&quot;: { &quot;nextExceptions&quot;: &quot;img, blockquote, div&quot;, &quot;nextContainsExceptions&quot;: &quot;img, blockquote, a.btn, a.o-button&quot;} }">
              
  <p>
      Heading out the door? Read this article on the new Outside+ app available now on iOS devices for members!
      <a href="https://outsideapp.onelink.me/wOhi/6wh1kbvw" data-analytics-event="click" data-analytics-data="{&quot;name&quot;:&quot;Element Clicked&quot;,&quot;props&quot;:{&quot;destination_url&quot;:&quot;https://outsideapp.onelink.me/wOhi/6wh1kbvw&quot;,&quot;domain&quot;:&quot;<<analytics_vars.domain>>&quot;,&quot;name&quot;:&quot;in-content-cta&quot;,&quot;type&quot;:&quot;link&quot;}}">Download the app</a>.
    </p>
                    
      
      <p><span>Anders Johnson hadn’t eaten gluten in nearly a decade.&nbsp;</span></p>
<p><span>After coming down with an unidentifiable illness in the summer of 2006 while running high adventure trips at a Boy Scout camp in Southern California, he had been wracked with serious gastrointestinal dysfunction distress, depression, and brain fog. No matter how much he ate, he kept losing weight. At one point, he logged his caloric intake for a college nutrition class and found that he had been eating seven thousand calories a day, despite looking sickly thin. Around Thanksgiving of that year, it got so bad Johnson had to go to an urgent care because he was so dehydrated.&nbsp;</span></p>
<p><span>“I ended up failing a good chunk of my classes that semester just because I didn’t have any energy,” Johnson says.”Then I started hitting the doctors really hard, trying to figure it out.”</span></p>
<p><span>Amid the myriad possible diseases he discussed with his doctors, they started testing for celiac disease, a genetic autoimmune disorder that causes severe intolerance to gluten. Johnson’s results came back borderline; not definitively positive, but not exactly negative either. He ran with it.</span></p>
<p><span>“I started eating gluten-free. I started regaining mental faculties and started getting a little bit of weight back on me,” Johnson says “Whenever I cheated, it would just throw me back into a downward spiral.”</span></p>
<p><span>But doctors never definitively diagnosed Johnson with celiac disease. His doctors wanted to do a biopsy to get a definite answer, but that would require eating gluten again, something Johnson wasn’t willing to chance. Instead, he stuck with his gluten-free diet, which didn’t completely fix his symptoms but seriously improved them. He had to make sure even infinitesimal amounts of gluten wouldn’t end up in his food, like gluten as a binder in spices. Eating rigidly gluten-free can be exhaustingly difficult and makes even simple social engagements involving food complicated, but it was better than the alternative.</span></p>
<p><span>In 2015, however, a college friend who’d had a similarly severe gluten sensitivity texted Johnson that she had eaten a cookie. As it turned out, what that friend had assumed was celiac disease was a very different illness: giardia.</span></p>
<p><a href="https://www.backpacker.com/survival/natural-hazards/backpackers-usually-fear-the-wrong-things/"><i><span>Giardia lamblia,</span></i></a><span> occasionally called “beaver fever,” is an easily treatable intestinal parasite, unlike celiac disease. If you’ve been backpacking long enough, you probably know someone who’s gotten it. Giardia is normally an acute infection that causes diarrhea, horrendous gas, and other intestinal malaise, but doctors can corral it easily with antibiotics. The chronic form of giardiasis is lesser known, however. The friend sent Johnson medical studies showing how chronic Giardia infection can cause celiac-like symptoms.&nbsp;</span></p>
<p><span>“It was like a whole bunch of puzzle pieces fell into place at the same time,” said Johnson.&nbsp;</span></p>
<p><span>The issue was that he kept testing negative for giardiasis. Johnson wasn’t convinced.</span></p>
<p><span>Johnson was a master’s student in microbiology at the time at <a href="https://www.isu.edu/">Idaho State University</a>, so he borrowed some equipment from the school lab.</span></p>
<p><span>“I used the procured stains, a microscope, and slides and started conducting samples of myself. So I was making my own slides; staining them and looking for Giardia,” says Johnson.“At the same time, I also had a commercially prepared slide of giardia. Giardia is a protozoan infection, it’s also cyst forming, which provides a means for transmission and survival outside the body. You ingest the cysts, you get infected. So I started hunting for them.”</span></p>
<p><span>Johnson took pictures of his sample, along with the commercial one, and presented them to a doctor. Johnson asked the doctor if they could tell which sample was his and which was the commercial sample. They couldn’t. Instead, the doctor prescribed him a cocktail of antibiotics, antifungals, and antiprotozoal medications.&nbsp;</span></p>
<p><span>“If my intestines were a warzone, we went full nuclear,” Johnson remarked.</span></p>
<p><span>A few weeks after the last round of medication, Johnson wanted to test if he was still sensitive to gluten. Ever the scientist, he set up a double-blind test so that neither he nor the person administering the test knew if the capsule he was taking contained wheat flour or not. On the first round, after waiting 24 hours to see if he would have a reaction, he checked what he took. It was flour.</span></p>
<p><span>His body had digested it just fine. He could eat gluten again.</span></p>
<p><span>Dr. Leo Galland, a doctor of internal medicine, describes people like Anders Johnson as having a non-celiac gluten intolerance from chronic giardiasis.</span></p>
<p><span>“It’s a diagnosis in which you establish that the person has symptoms provoked by gluten, but they don’t have evidence of celiac disease,” said Dr. Galland. “The border between those two conditions is fuzzy because it’s not always possible to pin down the diagnosis of celiac disease with a high level of precision.”</span></p>
<p><span>Dr. Galland also says that giardiasis can be hard to get accurate results for as well. False negatives from single tests aren’t uncommon.&nbsp;</span></p>
<p><span>“Stool sample tests for acute giardiasis are only accurate about 50% of the time, although with three specimens you can get the accuracy up to around 90%,” Galland says.</span></p>
<p><span>Chronic giardia, like what Johnson had, can be particularly hard to identify. The tests don’t always show the giardia cysts, and the symptoms don’t necessarily present as the classic intestinal distress and diarrhea, according to Dr. Galland, instead presenting as symptoms as varied as constipation, arthritis, or even dizziness.&nbsp;</span></p>
<p><span>Dr. Galland says that if you think you have chronic giardiasis, ask yourself if you think you could have had exposure, like poorly treated water in the backcountry or while traveling. He recommends finding a doctor with experience treating intestinal parasites to order an antigen test, which is much more accurate than microscopy. You can discuss the possibility of an empirical course of treatment with your doctor as well.</span></p>
<p><span>Johnson, currently working on his Ph.D. in microbiology in Sweden, recognizes that not everyone will be able to test themselves the way he did for chronic giardiasis. He was lucky enough to have the skills and resources available to him.</span></p>
<p><span>“If forty thousand dollars of student loan debt paid for anything, it’s to be able to eat chocolate chip cookies again,” he says.</span></p>


      

      

      
      
                    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reflections on Palantir (171 pts)]]></title>
            <link>https://nabeelqu.substack.com/p/reflections-on-palantir</link>
            <guid>41855006</guid>
            <pubDate>Wed, 16 Oct 2024 02:18:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nabeelqu.substack.com/p/reflections-on-palantir">https://nabeelqu.substack.com/p/reflections-on-palantir</a>, See on <a href="https://news.ycombinator.com/item?id=41855006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Palantir is hot now. The company recently </span><a href="https://finance.yahoo.com/news/palantir-just-joined-p-500-113000856.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAAOhI0nvxFIMoY6BdKXkpDj8Nlgq-3MrVWnS9FAmV3XLIkI3tSKCwn6jCxmP6JN4gMEDSdxMsOckEAKtk0CwCD0xbZY9WOfbXut79DN79qZZo6W9rMHiWtKNZ3M9Q7zJy8bDdfnS6tOMpY4-8wbmvP85dJzjutgYYulAzl7JHznB" rel="">joined the S&amp;P 500</a><span>. The stock is on a tear, and the company is nearing a $100bn market cap. VCs chase ex-Palantir founders asking to invest.</span></p><p><span>For long-time employees and alumni of the company, this feels deeply weird. During the 2016-2020 era especially, telling people you worked at Palantir was unpopular. The company was seen as spy tech, NSA surveillance, or worse. There were regular </span><a href="https://www.businessinsider.com/activists-protest-palantir-across-the-us-over-its-ice-contracts-2020-9" rel="">protests outside the office</a><span>. Even among people who didn’t have a problem with it morally, the company was dismissed as a consulting company masquerading as software, or, at best, a sophisticated form of talent arbitrage. </span></p><p>I left last year, but never wrote publicly about what I learned there. There’s also just a lot about the company people don’t understand. So this is my effort to explain some of that, as someone who worked there for eight years. </p><p><em>(Note: I’m writing this in my personal capacity, and don’t have a formal relationship with the company anymore. I’m long $PLTR.)</em></p><p>I joined in summer 2015, initially in the newly-opened London office, before moving to Silicon Valley, and finally DC – as a forward deployed engineer. For context, the company was around 1500 people at the time; it had offices in Palo Alto (HQ), NYC, London, and a few other places. (It’s now 4000 or so people, and headquartered in Denver.) </p><p>Why did I join?</p><p><strong>First, I wanted to work in ‘difficult’ industries on real, meaningful problems</strong><span>. My area of interest – for personal reasons - was healthcare and bio, which the company had a nascent presence in. The company was talking about working in industries like healthcare, aerospace, manufacturing, cybersecurity, and other industries that I felt were very important but that most people were not, at the time, working on. At the time the hot things were social networks (Facebook, LinkedIn, Quora, etc.) and other miscellaneous consumer apps (Dropbox, Uber, Airbnb) but very few companies were tackling what felt like the </span><em>real</em><span>, thorny parts of the economy. If you wanted to work on these ‘harder’ areas of the economy but also wanted a Silicon Valley work culture, Palantir was basically your only option for awhile. </span></p><p>My goal was to start a company, but I wanted (1) to go deep in one of these industries for a while first and learn real things about it; (2) to work for a US company and get a green card that way. Palantir offered both. That made it an easy choice.</p><p><strong>Second, talent density</strong><span>. I talked to some of the early people who started the healthcare vertical (Nick Perry, Lekan Wang, and Andrew Girvin) and was extremely impressed. I then interviewed with a bunch of the early business operations and strategy folks and came away </span><em>even more</em><span> impressed. These were seriously intense, competitive people who wanted to win, true believers; weird, fascinating people who read philosophy in their spare time, went on weird diets, and did 100-mile bike rides for fun. This, it turned out, was an inheritance from the Paypal mafia. Yishan Wong, who was early at Paypal, wrote about the importance of intensity:</span></p><blockquote><p><em><span>"In general, as I begin to survey more startups, I find that the talent level at PayPal is not uncommon for a Silicon Valley startup, but the differentiating factor may have been the level of intensity from the top: </span><strong>both Peter Thiel and Max Levchin were extremely intense people - hyper-competitive, hard-working, and unwilling to accept defeat</strong><span>. I think this sort of leadership is what pushes the "standard" talented team to be able to do great things and, subsequently, contributes to producing a wellspring of later achievements."</span></em></p></blockquote><p><span>Palantir was an unusually intense and weird place. I remember my first time I talked to </span><a href="https://en.wikipedia.org/wiki/Stephen_Cohen_(entrepreneur)" rel="">Stephen Cohen</a><span> he had the A/C in his office set at 60, several weird-looking devices for minimizing CO2 content in the room, and had a giant pile of ice in a cup. Throughout the conversation, he kept chewing pieces of ice. (Apparently there are cognitive benefits to this.)</span></p><p>I also interviewed with the CEO, Alex Karp and talked to other members of the leadership team. I probably don’t need to convince you that Karp is weird - just watch an interview with him. I can’t say what Karp and I talked about, but he gives a good flavor for his style in a 2012 interview:</p><blockquote><p><em>I like to meet candidates with no data about them: no résumé, no preliminary discussions or job description, just the candidate and me in a room. I ask a fairly random question, one that is orthogonal to anything they would be doing at Palantir. I then watch how they disaggregate the question, if they appreciate how many different ways there are to see the same thing. I like to keep interviews short, about 10 minutes. Otherwise, people move into their learned responses and you don’t get a sense of who they really are.</em></p></blockquote><p><span>My interviews were often not about work or software at all – one of my interviews we just spent an hour talking about Wittgenstein. Note that both Peter Thiel and Alex Karp were philosophy grads. Thiel’s lecture notes had come out not long before (</span><a href="https://blakemasters.tumblr.com/peter-thiels-cs183-startup" rel="">https://blakemasters.tumblr.com/peter-thiels-cs183-startup</a><span>) and they discussed Shakespeare, Tolstoy, Girard (then unknown, now a cliché) and more. </span></p><p><span>The combo of intellectual grandiosity and intense competitiveness was a perfect fit for me. It’s still hard to find today, in fact - many people have copied the ‘hardcore’ working culture and the ‘this is the Marines’ vibe, but few have the intellectual atmosphere, the sense of being involved in a rich set of </span><em>ideas</em><span>. This is hard to LARP - your founders and early employees have to be genuinely interesting intellectual thinkers. The main companies that come to mind which have nailed this combination today are </span><a href="https://openai.com/" rel="">OpenAI</a><span> and </span><a href="https://www.anthropic.com/" rel="">Anthropic</a><span>. It’s no surprise they’re talent magnets.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-1-150188028" target="_self" rel="">1</a></span></p><p>When I joined, Palantir was divided up into two types of engineers:</p><ol><li><p>Engineers who work with customers, sometimes known as FDEs, forward deployed engineers.</p></li><li><p>Engineers who work on the core product team (product development - PD), and rarely go visit customers.</p></li></ol><p>FDEs were typically expected to ‘go onsite’ to the customer’s offices and work from there 3-4 days per week, which meant a ton of travel. This is, and was, highly unusual for a Silicon Valley company.</p><p><span>There’s a lot to unpack about this model, but the key idea is that you gain intricate knowledge of business processes in difficult industries (manufacturing, healthcare, intel, aerospace, etc.) and then use that knowledge to design </span><em>software that actually solves the problem</em><span>. The PD engineers then ‘productize’ what the FDEs build, and – more generally – build software that provides leverage for the FDEs to do their work better and faster.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-2-150188028" target="_self" rel="">2</a></span></p><p><span>This is how much of the Foundry product took initial shape: FDEs went to customer sites, had to do a bunch of cruft work manually, and PD engineers built tools that automated the cruft work. Need to bring in data from SAP or AWS? Here’s </span><a href="https://www.palantir.com/docs/foundry/data-connection/overview/" rel="">Magritte</a><span> (a data ingestion tool). Need to visualize data? Here’s </span><a href="https://www.palantir.com/docs/foundry/contour/overview/" rel="">Contour</a><span> (a point and click visualization tool). Need to spin up a quick web app? Here’s </span><a href="https://www.palantir.com/docs/foundry/workshop/overview/" rel="">Workshop</a><span> (a Retool-like UI for making webapps). Eventually, you had a damn good set of tools clustered around the loose theme of ‘integrate data and make it useful somehow’. </span></p><p><span>At the time, it was seen as a radical step to give customers access to these tools — they weren’t in a state for that — but now this drives 50%+ of the company’s revenue, and it’s called </span><a href="https://www.palantir.com/platforms/foundry/" rel="">Foundry</a><span>. Viewed this way, Palantir pulled off a rare services company → product company pivot: in 2016, descriptions of it as a Silicon Valley services company were not totally off the mark, but in 2024 they are deeply off the mark, because the company successfully built an enterprise data platform using the lessons from those early years, and it shows in the gross margins - 80% gross margins in 2023. These are software margins. Compare to Accenture: 32%.</span></p><p><span>Tyler Cowen has a wonderful saying, ‘</span><a href="https://marginalrevolution.com/marginalrevolution/2022/02/context-is-that-which-is-scarce-2.html" rel="">context is that which is scarce</a><span>’, and you could say it’s the foundational insight of this model. Going onsite to your customers – the startup guru Steve Blank calls this “getting out of the building” – means you capture the tacit knowledge of how they work, not just the flattened ‘list of requirements’ model that enterprise software typically relies on. The company believed this to a hilarious degree: it was routine to get a call from someone and have to book a first-thing-next-morning flight to somewhere </span><em>extremely random</em><span>; “get on a plane first, ask questions later” was the cultural bias. This resulted in out of control travel spend for a long time — many of us ended up getting United 1K or similar — but it also meant an intense decade-long learning cycle which eventually paid off.</span></p><p>My first real customer engagement was with Airbus, the airplane manufacturer based in France, and I moved out to Toulouse for a year and worked in the factory alongside the manufacturing people four days a week to help build the version of our software there. </p><p>My first month in Toulouse, I couldn’t fly out of the city because the air traffic controllers were on strike every weekend. Welcome to France. (I jest - France is great. Also, Airbus planes are magnificent. It’s a truly engineering-centric company. The CEO is always a trained aeronautical engineer, not some MBA. Unlike… anyway.)</p><p><span>The CEO told us his biggest problem was scaling up A350 manufacturing. So we ended up building software to </span><em>directly tackle that problem</em><span>. I sometimes describe it as “Asana, but for building planes”. You took disparate sources of data — work orders, missing parts, quality issues (“non-conformities”) — and put them in a nice interface, with the ability to check off work and see what other teams are doing, where the parts are, what the schedule is, and so on. Allow them the ability to search (including fuzzy/semantic search) previous quality issues and see how they were addressed. These are all sort of basic software things, but you’ve seen how crappy enterprise software can be - just deploying these ‘best practice’ UIs to the real world is insanely powerful. This ended up helping to drive the A350 manufacturing surge and successfully 4x’ing the pace of manufacturing while keeping Airbus’s high standards of quality. </span></p><p><span>This made the software hard to describe concisely - it wasn’t just a database or a spreadsheet, it was an end-to-end solution to </span><em>that specific</em><span> problem, and to hell with generalizability. Your job was to solve the problem, and not worry about overfitting; PD’s job was to take whatever you’d built and generalize it, with the goal of selling it elsewhere.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png" width="1456" height="729" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:729,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5569706,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71c4c9a8-1f82-4104-a90f-f1087fceb12b_2918x1462.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><span>The A350 final assembly line, in Toulouse. I hung out here most days. It was awe-inspiring. Screenshot from </span><a href="https://www.youtube.com/watch?v=Yutzg2NLwcU" rel="">here</a><span>.</span></em></p><p>FDEs tend to write code that gets the job done fast, which usually means – politely – technical debt and hacky workarounds. PD engineers write software that scales cleanly, works for multiple use cases, and doesn’t break. One of the key ‘secrets’ of the company is that generating deep, sustaining enterprise value requires both. BD engineers tend to have high pain tolerance, the social and political skills needed to embed yourself deep in a foreign company and gain customer trust, and high velocity – you need to build something that delivers a kernel of value fast so that customers realize you’re the real deal. It helped that customers had hilariously low expectations of most software contractors, who were typically implementors of SAP or other software like that, and worked on years-long ‘waterfall’ style timescales. So when a ragtag team of 20-something kids showed up to the customer site and built real software that people could use within a week or two, people noticed.</p><p>This two-pronged model made for a powerful engine. Customer teams were often small (4-5 people) and operated fast and autonomously; there were many of them, all learning fast, and the core product team’s job was to take those learnings and build the main platform.</p><p><span>When we were allowed to work within an organization, this tended to work </span><em>very well</em><span>. The obstacles were mostly political. Every time you see the government give another </span><a href="https://themarkup.org/coronavirus/2020/07/16/unemployment-benefits-website-failures-deloitte-ibm" rel="">$110 million contract to Deloitte for building a website that doesn’t work</a><span>, or a </span><a href="https://www.businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf" rel="">healthcare.gov style debacle</a><span>, or SFUSD </span><a href="https://sfist.com/2024/03/01/sfusd-finally-replacing-their-disastrous-34-million-payroll-system-that-failed-to-actually-pay-people/" rel="">spending $40 million to implement a payroll system</a><span> that - again - doesn’t work, you are seeing politics beat substance. See </span><a href="https://caseyhandmer.wordpress.com/2024/10/02/sls-is-still-a-national-disgrace/" rel="">SpaceX vs. NASA</a><span> as another example. </span></p><p><span>The world needs more companies like SpaceX, and Palantir, that differentiate on </span><em>execution</em><span> - achieving the outcome - not on playing political games or building narrow point solutions that don’t hit the goal. </span></p><p><span>Another key thing FDEs did was data integration, a term that puts most people to sleep. This was (and still is) the core of what the company does, and its importance was underrated by most observers for years. In fact, it’s only now with the advent of AI that people are starting to realize the importance of having clean, curated, easy-to-access data for the enterprise. (See: </span><a href="https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/" rel="">the ‘it’ in AI models is the dataset</a><span>). </span></p><p>In simple terms, ‘data integration’ means (a) gaining access to enterprise data, which usually means negotiating with ‘data owners’ in an organization (b) cleaning it and sometimes transforming it so that it’s usable (c) putting it somewhere everyone can access it. Much of the base, foundational software in Palantir’s main software platform (Foundry) is just tooling to make this task easier and faster.</p><p><span>Why is data integration so hard? The data is often in different formats that aren’t easily analyzed by computers – PDFs, notebooks, Excel files (my god, so many Excel files) and so on. But often what really gets in the way is organizational politics: a team, or group, controls a key data source, the reason for their existence is that they are the gatekeepers to that data source, and they typically justify their existence in a corporation by being the gatekeepers of that data source (and, often, providing analyses of that data).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-3-150188028" target="_self" rel="">3</a></span><span> This politics can be a formidable obstacle to overcome, and in some cases led to hilarious outcomes – you’d have a company buying an 8-12 week pilot, and we’d spend all 8-12 weeks just getting data access, and the final week scrambling to have something to demo.</span></p><p><span>The other ‘secret’ Palantir figured out early is that data access tussles were partly about genuine data security concerns, and could be alleviated through building security controls into the data integration layer of the platform - at all levels. This meant role-based access controls, row-level policies, </span><a href="https://www.palantir.com/docs/foundry/security/markings/" rel="">security markings</a><span>, audit trails, and a ton of other data security features that other companies are still catching up to. Because of these features, implementing Palantir often made companies’ data </span><em>more</em><span> secure, not less.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-4-150188028" target="_self" rel="">4</a></span></p><p><span>The overall ‘vibe’ of the company was more of a messianic cult than a normal software company. But importantly, it seemed that criticism was highly tolerated and welcomed – one person showed me an email chain where an entry-level software engineer was having an open, contentious argument with a Director of the company with the entire company (around a thousand people) cc’d. As a rationalist-brained philosophy graduate, this particular point was deeply important to me – I wasn’t interested in joining an uncritical cult. But a cult of skeptical people who cared deeply and wanted to argue about where the world was going and how software fit into it – existentially – that was interesting to me.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-5-150188028" target="_self" rel="">5</a></span></p><p><span>I’m not sure if they still do this, but at the time when you joined they sent you a copy of </span><a href="https://www.amazon.com/Impro-Improvisation-Theatre-Keith-Johnstone/dp/0878301178" rel="">Impro</a><span>, </span><a href="https://www.amazon.com/Looming-Tower-Al-Qaeda-Road-11/dp/037541486X" rel="">The Looming Tower</a><span> (9/11 book), </span><a href="https://www.amazon.com/Interviewing-Users-Uncover-Compelling-Insights/dp/193382011X" rel="">Interviewing Users</a><span>, and </span><a href="https://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0142000280" rel="">Getting Things Done</a><span>. I also got an early PDF version of what became Ray Dalio’s </span><a href="https://www.principles.com/" rel="">Principles</a><span>. This set the tone. The Looming Tower was obvious enough – the company was founded partly as a response to 9/11 and what Peter felt were the inevitable violations of civil liberties that would follow, and the context was valuable. But why Impro?</span></p><p>Being a successful FDE required an unusual sensitivity to social context – what you really had to do was partner with your corporate (or government) counterparts at the highest level and gain their trust, which often required playing political games. Impro is popular with nerds partly because it breaks down social behavior mechanistically. The vocabulary of the company was saturated with Impro-isms – ‘casting’ is an example. Johnstone discusses how the same actor can play ‘high status’ or ‘low status’ just by changing parts of their physical behavior – for example, keeping your head still while talking is high status, whereas moving your head side to side a lot is low status. Standing tall with your hands showing is high status, slouching with your hands in your pocket is low status. And so on. If you didn’t know all this, you were unlikely to succeed in a customer environment. Which meant you were unlikely to integrate customer data or get people to use your software. Which meant failure.</p><p>This is one reason why former FDEs tend to be great founders. (There are usually more ex-Palantir founders than there are ex-Googlers in each YC batch, despite there being ~50x more Google employees.) Good founders have an instinct for reading rooms, group dynamics, and power. This isn’t usually talked about, but it’s critical: founding a successful company is about taking part in negotiation after negotiation after negotiation, and winning (on net). Hiring, sales, fundraising are all negotiations at their core. It’s hard to be great at negotiating without having these instincts for human behavior. This is something Palantir teaches FDEs, and is hard to learn at other Valley companies. </p><p><span>Another is that FDEs have to be </span><a href="https://nabeelqu.substack.com/p/understanding" rel="">good at understanding things</a><span>. Your effectiveness directly correlates to how quickly you can learn to speak the customer’s language and really drill down into how their business works. If you’re working with hospitals, you quickly learn to talk about </span><em>capacity management </em><span>and </span><em>patient throughput</em><span> vs. just saying “help you improve your healthcare”. Same with drug discovery, health insurance, informatics, cancer immunotherapy, and so on; all have specialized vocabularies, and the people who do well tend to be great at learning them fast.</span></p><p><span>One of my favorite insights from Tyler Cowen’s book ‘</span><a href="https://www.amazon.com/Talent-Identify-Energizers-Creatives-Winners/dp/1250275814" rel="">Talent</a><span>’ is that the most talented people tend to develop their own vocabularies and memes, and these serve as entry points to a whole intellectual world constructed by that person. Tyler himself is of course a great example of this. Any MR reader can name 10+ Tylerisms instantly - ‘model this’, ‘context is that which is scarce’, ‘solve for the equilibrium’, ‘the great stagnation’ are all examples. You can find others who are great at this. Thiel is one. Elon is another (“multiplanetary species”, “preserving the light of consciousness”, etc. are all memes). </span><a href="https://en.wiktionary.org/wiki/many_such_cases" rel="">Trump</a><span>, </span><a href="https://www.lesswrong.com/tag/reversed-stupidity-is-not-intelligence" rel="">Yudkowsky</a><span>, </span><a href="https://gwern.net/scaling-hypothesis" rel="">gwern</a><span>, </span><a href="https://slatestarcodex.com/2013/06/30/the-lottery-of-fascinations/" rel="">SSC</a><span>, </span><a href="https://www.paulgraham.com/foundermode.html" rel="">Paul Graham</a><span>, all of them </span><em>regularly</em><span> coin memes. It turns out that this is a good proxy for impact.</span></p><p><span>This insight goes for </span><em>companies</em><span>, too, and Palantir had its own, vast set of terms, some of which are obscure enough that “what does Palantir actually do?” became a meme online. ‘Ontology’ is an old one, but then there is ‘impl’, ‘artist’s colony’, ‘compounding’, ‘the 36 chambers’, ‘dots’, ‘metabolizing pain’, ‘gamma radiation’, and so on. The point isn’t to explain all of these terms, each of which compresses a whole set of rich insights; it’s that when you’re looking for companies to join, you could do worse than look for a rich internal language or vocabulary that helps you think about things in a more interesting way.</span></p><p><span>When Palantir’s name comes up, most people think of Peter Thiel. But many of these terms came from early employees, especially Shyam Sankar, who’s now the President of the company. Still, Peter is deeply influential in the company culture, even though he wasn’t operationally involved with the company at all during the time I was there. </span><a href="https://www.8vc.com/resources/lessons-from-peter-thiel" rel="">This document</a><span>, written by Joe Lonsdale, was previously an internal document but made public at some point and gives a flavor for the type of cultural principles.</span></p><p>One of the things that (I think) came from Peter was the idea of not giving people titles. When I was there, everyone had the “forward deployed engineer” title, more or less, and apart from that there were five or six Directors and the CEO. Occasionally someone would make up a different title (one guy I know called himself “Head of Special Situations”, which I thought was hilarious) but these never really caught on. It’s straightforward to trace this back to Peter’s Girardian beliefs: if you create titles, people start coveting them, and this ends up creating competitive politics inside the company that undermines internal unity. Better to just give everyone the same title and make them go focus on the goal instead.</p><p><span>There are plenty of good critiques of the ‘flat hierarchy’ stance -- </span><a href="https://www.jofreeman.com/joreen/tyranny.htm" rel="">The Tyranny of Structurelessness</a><span> is a great one – and it largely seems to have fallen out of fashion in modern startups, where you quickly get CEO, COO, VPs, Founding Engineers, and so on. But my experience is that it worked well at Palantir. Some people were more influential than others, but the influence was usually based on some impressive accomplishment, and most importantly </span><em>nobody could tell anyone else what to do. </em><span>So it didn’t matter if somebody was influential or thought your idea was dumb, you could ignore them and go build something if you thought it was the right thing to do. On top of that, the culture valorized such people: stories were told of some engineer ignoring a Director and building something that ended up being a critical piece of infrastructure, and this was held up as an example to imitate.</span></p><p><span>The cost of this was that the company often felt like there was no clear strategy or direction, more like a Petri dish of smart people building little fiefdoms and going off in random directions. But it was incredibly generative. It’s underrated just how many novel UI concepts and ideas came out of that company. Only some of these now have non-Palantir equivalents, e.g. </span><a href="https://hex.tech/" rel="">Hex</a><span>, </span><a href="https://retool.com/" rel="">Retool</a><span>, </span><a href="https://airflow.apache.org/" rel="">Airflow</a><span> all have some components that were first developed at Palantir. The company’s doing the same for AI now – the </span><a href="https://aip.palantir.com/" rel="">tooling for deploying LLMs at large enterprises</a><span> is powerful.</span></p><p><span>The ‘no titles’ thing also meant that people came in and out of fashion very quickly, inside the company. Because everyone had the same title, you had to gauge influence through other means, and those were things like “who seems really tight with this Director right now” or “who is leading this product initiative which seems important”, not “this person is the VP of so and so”. The result was a sort of </span><a href="https://www.facebook.com/permalink.php?story_fbid=2146412825593223&amp;id=100006735798590&amp;_rdr" rel="">hero-shithead rollercoaster</a><span> at scale – somebody would be very influential for awhile, then mysteriously disappear and not be working on anything visible for months, and you wouldn’t ever be totally sure what happened.</span></p><p><span>Another thing I can trace back to Peter is the idea of talent bat-signals. Having started my own company now (in stealth for the moment), I appreciate this a lot more: recruiting good people is hard, and you need a differentiated source of talent. If you’re just competing against Facebook/Google for the same set of Stanford CS grads every year, you’re going to lose. That means you need a set of talent that is (a) interested in joining </span><em>you</em><span> in particular, over other companies (b) a way of reaching them at scale. Palantir had several differentiated sources of recruiting alpha. </span></p><p><span>First, there were all the people who were </span><em>pro</em><span> defense/intelligence work back when that wasn’t fashionable, which selected for, e.g., smart engineers from the Midwest or red states more than usual, and also plenty of smart ex-army, ex-CIA/NSA types who wanted to serve the USA but also saw the appeal in working for a Silicon Valley company. My first day at the company, I was at my team’s internal onboarding with another guy, who looked a bit older than me. I asked him what he’d done before Palantir. With a deadpan expression, he looked me in the eye and said “I worked at the agency for 15 years”. I was then introduced to my first lead, who was a former SWAT cop in Ohio (!) and an Army vet.</span></p><p><span>There were lots of these people, many </span><em>extremely</em><span> talented, and they mostly </span><a href="https://www.nytimes.com/2018/04/04/technology/google-letter-ceo-pentagon-project.html" rel="">weren’t joining Google</a><span>. Palantir was the only real ‘beacon’ for these types, and the company was loud about supporting the military, being patriotic, and so on, when that was deeply unfashionable. That set up a highly effective, unique bat-signal. (Now there’s Anduril, and a plethora of defence and manufacturing startups).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-6-150188028" target="_self" rel="">6</a></span></p><p><span>Second, you had to be weird to </span><em>want</em><span> to join the company, at least after the initial hype wave died down (and especially during the Trump years, when the company was a pariah). Partly this was the aggressive ‘mission focus’ type branding back when this was uncommon, but also the company was loud about the fact that people worked long hours, were paid lower than market, and had to travel a lot. Meanwhile, we were being kicked out of Silicon Valley job fairs for working with the government. All of this selected for a certain type of person: somebody who can think for themselves, and doesn’t over-index on a bad news story. </span></p><p><span>The morality question is a fascinating one. The company is unabashedly pro-West, a stance I mostly agree with – a world more CCP-aligned or Russia-aligned seems like a bad one to me, and that’s the choice that’s on the table.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-7-150188028" target="_self" rel="">7</a></span><span> It’s easy to critique free countries when you live in one, harder when you’ve experienced the alternative (as I have - I spent a few childhood years in a repressive country). So I had no problem with the company helping the military, even when I disagreed with some of the things the military was doing.</span><em> </em></p><p><span>But doesn’t the military sometimes do bad things? Of course - I was opposed to the Iraq war. This gets to the crux of the matter:</span><em> </em><span>working at the company was neither 100% morally good — because sometimes we’d be helping agencies that had goals I’d disagree with — nor 100% bad: the government does a lot of good things, and helping them do it more efficiently by providing software that doesn’t suck is a noble thing. One way of clarifying the morality question is to break down the company’s work into three buckets – these categories aren’t perfect, but bear with me:</span></p><ol><li><p><strong>Morally neutral</strong><span>. Normal corporate work, e.g. FedEx, CVS, finance companies, tech companies, and so on. Some people might have a problem with it, but on the whole people feel fine about these things.</span></p></li><li><p><strong>Unambiguously good</strong><span>. For example, anti-pandemic response with the CDC; anti-child pornography work with NCMEC; and so on. Most people would agree these are good things to work on.</span></p></li><li><p><strong>Grey areas</strong><span>. By this I mean I mean ‘involve morally thorny, difficult decisions’: examples include health insurance, immigration enforcement, oil companies, the military, spy agencies, police/crime, and so on.</span></p></li></ol><p><span>Every engineer faces a choice: you </span><em>can</em><span> work on things like Google search or the Facebook news feed, all of which seem like marginally good things and basically fall into category 1. You can also go work on category 2 things like GiveDirectly or OpenPhilanthropy or whatever. </span></p><p>The critical case against Palantir seemed to be something like “you shouldn’t work on category 3 things, because sometimes this involves making morally bad decisions”. An example was immigration enforcement during 2016-2020, aspects of which many people were uncomfortable with. </p><p><span>But it seems to me that ignoring category 3 entirely, and just disengaging with it, is also an abdication of responsibility. Institutions in category 3 </span><em>need to exist</em><span>. The USA is defended by people with guns. The police </span><em>have</em><span> to enforce crime, and - in my experience - even people who are morally uncomfortable with some aspects of policing are quick to call the police if their own home has been robbed. Oil companies have to provide energy. Health insurers have to make difficult decisions all the time. Yes, there are unsavory aspects to all of these things. But do we just disengage from all of these institutions entirely, and let them sort themselves out?</span></p><p><span>I don’t believe there </span><em>is</em><span> a clear answer to whether you should work with category 3 customers; it’s a case by case thing. Palantir’s answer to this is something like “we will work with most category 3 organizations, unless they’re clearly bad, and we’ll trust the democratic process to get them trending in a good direction over time”. Thus:</span></p><ul><li><p>On the ICE question, they disengaged from ERO (Enforcement and Removal Operations) during the Trump era, while continuing to work with HSI (Homeland Security Investigations).</p></li><li><p><span>They </span><em>did</em><span> work with most other category 3 organizations, on the argument that they’re mostly doing good in the world, even though it’s easy to point to bad things they did as well. </span></p><ul><li><p>I can’t speak to specific details here, but Palantir software is partly responsible for stopping multiple terror attacks. I believe this fact alone vindicates this stance. </p></li></ul></li></ul><p><span>This is an uncomfortable stance for many, precisely because you’re </span><em>not</em><span> guaranteed to be doing 100% good at all times. You’re at the mercy of history, in some ways, and you’re betting that (a) more good is being done than bad (b) being in the room is better than not. This was good enough for me. Others preferred to go elsewhere. </span></p><p><span>The danger of this stance, of course, is that it becomes a fully general argument for doing whatever the power structure wants. You are just amplifying existing processes. This is where the ‘case by case’ comes in: there’s no general answer, you have to be specific. For my own part, I spent most of my time there working on healthcare and bio stuff, and I feel good about my contributions. I’m betting the people who stopped the terror attacks feel good about theirs, too. Or the </span><a href="https://fedscoop.com/cdc-expands-tiberius-use-again/" rel="">people who distributed medicines during the pandemic</a><span>. </span></p><p><span>Even though the tide has shifted and working on these ‘thorny’ areas is now trendy, these remain relevant questions for technologists. AI is a good example – many people are uncomfortable with some of the consequences of deploying AI. Maybe AI gets used for hacking; maybe deepfakes make the world worse in all these ways; maybe it causes job losses. But there are also major benefits to AI (Dario Amodei articulates some of these well in </span><a href="https://darioamodei.com/machines-of-loving-grace" rel="">a recent essay</a><span>). </span></p><p><span>As with Palantir, working on AI probably isn’t 100% morally good, nor is it 100% evil. Not engaging with it – or calling for a pause/stop, which is a fantasy – is unlikely to be the best stance. Even if you don’t work at OpenAI or Anthropic, if you’re someone who could plausibly work in AI-related issues, you probably want to do so in some way. There are easy cases: build evals, work on alignment, work on societal resilience. But my claim here is that the grey area is worth engaging in too: work on government AI policy. Deploy AI into areas like healthcare. Sure, it’ll be difficult. </span><a href="https://marginalrevolution.com/marginalrevolution/2023/03/existential-risk-and-the-turn-in-human-history.html" rel="">Plunge in</a><span>.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-150188028" href="https://nabeelqu.substack.com/p/reflections-on-palantir#footnote-8-150188028" target="_self" rel="">8</a></span></p><p><span>When I think about the most influential people in AI today, they are almost all </span><em>people in the room</em><span> - whether at an AI lab, in government, or at an influential think tank. I’d rather be one of those than one of the pontificators. Sure, it’ll involve difficult decisions. But it’s better to be in the room when things happen, </span><a href="https://en.wikipedia.org/wiki/Joseph_Rotblat" rel="">even if you later have to leave and sound the alarm</a><span>. </span></p><p>Do I remain bullish on the company? Yes.</p><p><span>The big productivity gains of this AI cycle are going to come when AI starts providing leverage to the large companies and businesses of this era - in industries like manufacturing, defense, logistics, healthcare and more. Palantir has spent a decade working with these companies. AI agents will eventually drive many core business workflows, and these agents will rely on read/write access to critical business data. Spending a decade integrating enterprise data is </span><em>the</em><span> critical foundation for deploying AI to the enterprise. The opportunity is massive. </span></p><p>As for me, I’m carrying out my long-awaited master plan and starting a company next. Yes, there will be a government component to it. The team is great, and yes we’re hiring. We even talk about Wittgenstein sometimes.</p><p><em>Thanks to Rohit Krishnan, Tyler Cowen, Samir Unni, Sebastian Caliri, Mark Bissell, and Vipul Shekhawat for their feedback on this post. </em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eye Contact Correction: Redirecting the eyes to look at the camera (150 pts)]]></title>
            <link>https://www.sievedata.com/functions/sieve/eye-contact-correction</link>
            <guid>41854801</guid>
            <pubDate>Wed, 16 Oct 2024 01:37:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sievedata.com/functions/sieve/eye-contact-correction">https://www.sievedata.com/functions/sieve/eye-contact-correction</a>, See on <a href="https://news.ycombinator.com/item?id=41854801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Sieve's Eye Contact Correction API is a fast and high-quality eye contact correction API built for developers.</p>
<p>Eye contact correction is a technique for ensuring that the eyes in a video appear to be looking at the camera, even when the subject is not actually looking at it. This is achieved by redirecting the eyes to simulate eye contact with the camera.</p>
<h2 id="features">Features</h2>
<ul>
<li><strong>Eye Contact Correction</strong>: Redirects gaze in videos to simulate eye contact with the camera</li>
<li><strong>Customization</strong>: Supports various customization options for fine-tuning the eye redirection</li>
<li><strong>Blink and head movement preservation</strong>: Preserves original blinking and head movements</li>
<li><strong>Look Away</strong>: <code>enable_look_away</code> helps create a more natural look by allowing the eyes to look away randomly from the camera when speaking</li>
<li><strong>Split-Screen View</strong>: Optional split-screen view to compare original and corrected footage</li>
<li><strong>Visualization</strong>: Visualization options for debugging and analysis</li>
</ul>
<h2 id="pricing">Pricing</h2>
<p>This function is billed at $0.10 per minute of video.</p>
<h2 id="notes">Notes</h2>
<ul>
<li>Input must be a video file. Image files are not supported.</li>
<li>Processing time depends on the video length and resolution.</li>
<li>The <code>accuracy_boost</code> option provides more precise results but may increase processing time.</li>
<li>Use <code>split_screen_view</code> and <code>draw_visualization</code> to debug or compare results</li>
<li>Adjust threshold parameters to fine-tune when and how much the gaze is redirected.</li>
</ul>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Works best with frontal face views and moderate head rotations.</li>
<li>Extreme head poses or gaze directions may produce less accurate results.</li>
<li>Very low-resolution or poor-quality videos may affect the accuracy of gaze redirection.</li>
</ul>
<p>For any issues or questions, please get in touch with <a href="mailto:contact@sievedata.com" target="_blank" rel="noopener noreferrer">contact@sievedata.com</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The richest people borrow against their stock (2021) (126 pts)]]></title>
            <link>https://www.forbes.com/sites/johnhyatt/2021/11/11/how-americas-richest-people-larry-ellison-elon-musk-can-access-billions-without-selling-their-stock/</link>
            <guid>41854749</guid>
            <pubDate>Wed, 16 Oct 2024 01:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/johnhyatt/2021/11/11/how-americas-richest-people-larry-ellison-elon-musk-can-access-billions-without-selling-their-stock/">https://www.forbes.com/sites/johnhyatt/2021/11/11/how-americas-richest-people-larry-ellison-elon-musk-can-access-billions-without-selling-their-stock/</a>, See on <a href="https://news.ycombinator.com/item?id=41854749">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Many of the country’s richest people, including Elon Musk and Larry Ellison, borrow against their stock while avoiding capital gains taxes.</h2>



<p><abbr>O</abbr><strong>n Saturday, Elon Musk</strong> promised to sell 10% of his Tesla stake after 58% of people voted in a Twitter poll shared by the Tesla CEO. Yesterday, Musk began to follow through, exercising about 2.15 million Tesla stock options and selling shares to cover the taxes he owed as a result. Prior to this week, he has only ever sold Tesla shares twice—in 2010 and 2016—for pre-tax proceeds of $617 million ($593 million of that went to cover taxes he owed on options). Tesla’s stock has risen over 13,000% since his last sale, and Musk is now worth an estimated $281 billion (based on Wednesday’s closing price).&nbsp;</p>

<p>When the world’s richest man wants cash, he can simply borrow money by putting up—or pledging—some of his Tesla shares as collateral for lines of credit, instead of selling shares and paying capital gains taxes. These pledged shares serve as an evergreen credit facility, giving Musk access to cash when he needs it. Musk currently has pledged 88.3 million Tesla shares, nearly 36.2% of his overall stake (excluding options), as of Wednesday worth more than $94 billion.</p>

<p>Musk is one of 32 billionaires identified in the <a href="https://www.forbes.com/forbes-400/" target="_self" title="https://www.forbes.com/forbes-400/" data-ga-track="InternalLink:https://www.forbes.com/forbes-400/" aria-label="Forbes 400">Forbes 400</a> list<em> </em>of richest Americans to be pledging public stock of companies listed on the NYSE or Nasdaq exchanges as collateral for current or potential lines of credit, as disclosed in company filings. Other pledgers include fellow mega-pledger Oracle chairman Larry Ellison, Walmart heir Jim Walton, and private equity’s richest person, Stephen Schwarzman.&nbsp;(Three others pledged shares of foreign companies are not included in this report.)</p>

<p>Across all companies listed on the NYSE and Nasdaq exchanges, there are 560 executive officers and directors and 5%+ shareholders currently pledging shares; the size of the average pledge is $427 million and the aggregate value of these pledged shares is $239 billion, according to a report from Audit Analytics, an independent provider of audit, regulatory and disclosure intelligence. Within this larger group, Forbes 400 members do most of the pledging—value wise, that is. Musk’s Tesla pledge alone is 47% of that aggregate pledged share value. Removing the extreme outlier Musk, the remaining 31 Forbes 400 members account for 56% of that figure. (Data for this report were calculated Nov. 5; Tesla shares are down nearly 13% since then).</p><hr>
<blockquote><p>“At current interest and tax rates, it is far cheaper to borrow against the value of one's shares than to sell them and pay taxes on the gains.”
</p></blockquote><hr>
<p>Information on companies’ pledging policies—found in annual proxy statements—-offer a window into the murky world of billionaire borrowing. The topic entered the national microscope in June after <em>ProPublica’s </em><a href="https://www.propublica.org/article/the-secret-irs-files-trove-of-never-before-seen-records-reveal-how-the-wealthiest-avoid-income-tax" target="_blank" title="https://www.propublica.org/article/the-secret-irs-files-trove-of-never-before-seen-records-reveal-how-the-wealthiest-avoid-income-tax" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.propublica.org/article/the-secret-irs-files-trove-of-never-before-seen-records-reveal-how-the-wealthiest-avoid-income-tax" aria-label="report">report</a> on leaked IRS data showed that several of the richest people paid nothing in federal income taxes in certain years. Last month, a proposed wealth tax from Senate Democrat Ron Wyden failed to win political support. That measure would have taxed unrealized capital gains of America’s richest individuals.&nbsp;</p>
<p>Most details on billionaire borrowing remain private. Individuals who own less than a 5% stake in a company, or who don’t work for that company, do not report stock ownership or pledging of shares to the SEC. Many of America's wealthiest people—232 billionaires from this year’s Forbes 400 list, to be exact—hold their fortunes primarily in private companies. Any pledges against diversified baskets of stock or private assets are not reported in company filings. Disclosure requirements also do not include reporting whether, or how much, an individual has borrowed against their pledged shares. A few billionaires <em>Forbes </em>contacted said they don’t have outstanding debt against their pledges.&nbsp;</p><fbs-ad position="top" progressive="" ad-id="article-0-top"></fbs-ad>
<p>Most larger companies don’t allow pledging: Over two-thirds (68.4%) of S&amp;P 500 companies ban all company employees and shareholders from pledging shares for debt, 22% prohibit pledging but with exemptions for certain individuals, and only 3.4% fully permit it, according to data provided by proxy advisory firm Institutional Investors Service (ISS). “When executives or directors have a significant percentage of their equity pledged, it creates a concern from the investor perspective,” says Jun Frank, an executive director for ISS’ corporate solutions group, which advises companies on corporate governance matters.&nbsp;</p>
<p>Those concerns include margin calls: forced sales of pledged shares that can sink a company’s stock price, which risks cascading into a broader, panic-induced selloff. An example: Green Mountain Coffee Roaster’s founder Robert Stiller borrowed against his company shares to fund an increasingly extravagant lifestyle, rather than sell shares. That worked fine when the share price was rising but quickly unraveled after a short-seller called into question its accounting in May 2012. The former billionaire was forced to sell 5 million shares, worth $126 million, in one day to cover margin calls on pledged Green Mountain stock. He was then removed as Chairman of the Board.&nbsp;</p>
<p>Pledging can also create friction between directors and executive officers pledging shares and outside shareholders, says Frank: “If you no longer have certain claims to those underlying economic interests and you continue to have the voting right, that creates a mismatch between the control you can exercise over the company and the economic interest you have in the company.”</p><hr>
<h4><strong>THE FORBES 400 PLEDGERS</strong></h4>
<h4>Thirty-two billionaires identified in the&nbsp;<a href="https://www.forbes.com/forbes-400/" target="_self" title="https://www.forbes.com/forbes-400/" data-ga-track="InternalLink:https://www.forbes.com/forbes-400/" aria-label="Forbes 400">Forbes 400</a>&nbsp;list<em>&nbsp;</em>of richest Americans have pledged public stock of companies listed on the NYSE or Nasdaq exchanges.</h4><hr>
<p><strong>Sometimes </strong>what company founders want, in this case to pledge shares, is at odds with what board members and shareholders want, which is to disallow pledging. The software company Oracle, for example, adopted a rule in January 2018 prohibiting its directors and executive officers from pledging company shares, although one individual was exempt: Larry Ellison, Oracle’s cofounder and largest individual shareholder. But then, as now, Ellison was the only Oracle director to ever report pledging any company shares. Ellison, who boasts a fortune of over $100 billion, has been pledging shares since at least 2007, after the Securities and Exchange Commission began requiring it.&nbsp;</p>
<p>In other words, Oracle’s new pledging policy had no immediate impact on the pledging activity of its directors and executives—Ellison least of all. Since 2018, he has increased the number of his pledged Oracle shares to 317 million — worth about $28 billion — equivalent to roughly 27% of his stake and 11% of all outstanding Oracle stock. Ellison did not sell any Oracle shares between December 2010 and June 2020, a near-decade stretch of big spending for the eccentric billionaire, who splashed $300 million in 2012 to buy the Hawaiian island of Lanai and tens of millions of dollars on opulent mansions, <a href="https://www.forbes.com/sites/noahkirsch/2021/04/10/inside-larry-ellisons-1-billion-real-estate-portfolio/?sh=36dbf90756e0" target="_self" title="https://www.forbes.com/sites/noahkirsch/2021/04/10/inside-larry-ellisons-1-billion-real-estate-portfolio/?sh=36dbf90756e0" data-ga-track="InternalLink:https://www.forbes.com/sites/noahkirsch/2021/04/10/inside-larry-ellisons-1-billion-real-estate-portfolio/?sh=36dbf90756e0" aria-label="growing">growing</a> a $1 billion real estate portfolio that includes at least ten&nbsp; properties on Malibu’s glitzy Carbon Beach.</p><fbs-ad position="topx" progressive="" ad-id="article-0-topx-1"></fbs-ad>
<p>While Oracle does not disclose how much Ellison has borrowed against his shares, his penchant for borrowing was revealed in unsealed court documents from a shareholder lawsuit. Those documents, first <a href="https://www.sfgate.com/news/article/Inside-look-at-a-billionaire-s-budget-Larry-2542603.php" target="_blank" title="https://www.sfgate.com/news/article/Inside-look-at-a-billionaire-s-budget-Larry-2542603.php" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.sfgate.com/news/article/Inside-look-at-a-billionaire-s-budget-Larry-2542603.php" aria-label="reported">reported</a> by <em>The San Francisco Chronicle</em> in 2006, showed that Ellison had outstanding loans of more than $1.2 billion in 2001, and that his financial adviser had warned him, “We have a freight train going down a track hitting a debt wall.” (Oracle did not respond to <em>Forbes’ </em>questions<em> </em>about its pledging policy or Ellison’s borrowing.)</p>
<p>Other companies find more creative ways to exempt billionaire founders from pledging bans. Take the oil and gas firm Kinder Morgan, whose prohibition on pledging comes with a caveat: shares owned “in excess of the applicable minimum ownership guidelines'' are able to be pledged. The minimum ownership requirement for directors—such as executive chairman and billionaire Richard Kinder—is <a href="https://www.kindermorgan.com/WWWKM/media/Documents/Governance/Stock_Ownership_Guidelines.pdf" target="_blank" title="https://www.kindermorgan.com/WWWKM/media/Documents/Governance/Stock_Ownership_Guidelines.pdf" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.kindermorgan.com/WWWKM/media/Documents/Governance/Stock_Ownership_Guidelines.pdf" aria-label="three times">three times</a> the value of their “annual cash retainer.” Helpfully, Kinder’s annual salary is $1. That means the eponymous cofounder can effectively pledge as many shares as he likes.&nbsp;</p>
<p>Kinder, whose $7.2 billion fortune makes him the 128th wealthiest American, has pledged 40 million shares of his eponymous company — 15.6% of his overall stake, worth $679 million — for the sole purpose of buying more company stock, as described in the company’s proxy statement. To date, Kinder has purchased 10 million additional shares of Kinder Morgan, financed with debt taken out against his pledged Kinder Morgan shares. A representative for Kinder Morgan confirmed <em>Forbes’ </em>interpretation of its pledging rules but declined to comment further.</p>
<p>Some companies are upfront about their exemptions, but fail to make a convincing argument for them. The medical conglomerate Danaher simply states in its 2021 proxy statement that its sibling founders, Forbes 400 members Steven and Mitchell Rales, are exempt from its pledging ban “because [their] shares had been pledged for decades.” Each brother has pledged a significant portion of their Danaher shares, a potential red flag for margin calls: Steven Rales has pledged 78% of his equity stake (just over $10 billion), and Mitchell has pledged nearly 91% of his equity stake (slightly under $10 billion). Together, their pledges are 9.4% of all outstanding Danaher stock. (Danaher and the Rales brothers did not respond to requests for comment).</p><fbs-ad position="topx" progressive="" ad-id="article-0-topx-2"></fbs-ad>
<p>Of the Forbes 400 billionaires, oil mogul George Kaiser (net worth: $10.7 billion) has the highest ratio of pledged shares to the company’s total outstanding common stock — another red flag for margin calls. His pledge of 21 million shares of bank holding company BOK Financial Corporation (worth nearly $2.3 billion) is equal to nearly 31% of all outstanding stock. But Kaiser says he only occasionally borrows against those pledged shares. “They are just low cost, back-up lines, which we have had in place for a long time and infrequently use,” he told <em>Forbes</em> over email.&nbsp;</p>
<p>Tesla argues that pledging creates a kind of fiduciary relationship between pledgers and shareholders. In 2018 the electric carmaker introduced a 25% loan-to-value limit on borrowing against pledged shares, arguing that pledging gives “executive officers flexibility in financial planning without having to rely on large cash compensation or the sale of Company shares, thus keeping their interests well aligned with those of our stockholders, while also mitigating risk exposure to the Company” — a stance Tesla has reiterated in subsequent proxy filings.&nbsp;</p>
<p>ISS countered this argument in its recent proxy analysis of Tesla’s corporate governance principles. “If an executive who already owns 15 or 20 percent of a company's outstanding shares...is not already motivated to act in the interests of shareholders, there is no credible argument that increasing that stake to 25 or 30 percent will suffice to accomplish that goal,” says the report. “Perhaps a more salient, though unspoken, factor is that at current interest and tax rates, it is far cheaper to borrow against the value of one's shares than to sell them and pay taxes on the gains.”</p><fbs-ad position="topx" progressive="" ad-id="article-0-topx-3"></fbs-ad>
<p>So just how prevalent is pledging assets to borrow among the ultra rich? “Pretty high,” responds Jason Cain, a managing director and chief wealth strategist at advisory firm Boston Private, speaking about his firm's highest bracket of clients: those with above $500 million in assets. (Cain declined to provide an exact percentage figure). “It's not any different than families... who borrow for homes” and other life purchases, says Cain. “Most of these clients are aware of the uses of debt and with interest rates where they have been in the recent past, they understand the arbitrage opportunity.”&nbsp;</p>
<p>Ali Jamal, and ex-Julius Baer banker and founder of Azura, a boutique wealth management firm for billionaire entrepreneurs, says that during the stock market crash of March 2020, about 70% of Azura’s clients took on leverage — by pledging shares, but also artwork and car collections — to take on debt to buy more stock. And over the past year, about 40% of Azura clients have leveraged their way into special purpose acquisition corporations. “You can borrow at 40 basis points, max 50 basis points, to have someone very smart” identify an investment opportunity, says Jamal about the appeal of leveraging into SPACs, “and if you don't like the opportunity, you can pull your money out.”</p>
<p>Borrowing against one’s shares has its risks, but for these billionaires, the rewards seem to outweigh them. “It’s perfectly legal, and it's a little hard to say it's immoral. Like, it's immoral to own a growth stock? It's immoral to borrow money?” says Edward McCaffrey, a tax law professor at USC Gould School of Law who coined the popular term “Buy, Borrow, Die” to describe how the ultra-wealthy borrow to avoid paying taxes. “So the question is, why would anybody not do it?</p>

<h4><a href="https://www.forbes.com/forbes-400/" target="_self" title="https://www.forbes.com/forbes-400/" data-ga-track="InternalLink:https://www.forbes.com/forbes-400/" aria-label="SEE THE FORBES 400 LIST OF 2021"><strong data-ga-track="InternalLink:https://www.forbes.com/forbes-400/">SEE THE FORBES 400 LIST OF 2021</strong></a></h4><p><a href="https://www.forbes.com/sites/lisettevoytko/2021/10/05/the-richest-women-in-america-2021-forbes-400/" target="_blank" aria-label="The Richest Women In America" rel="noopener noreferrer" data-ga-track="forbesEmbedly:https://www.forbes.com/sites/lisettevoytko/2021/10/05/the-richest-women-in-america-2021-forbes-400/"><span><span>Forbes</span><span>The Richest Women In America</span><small>By <span>Lisette Voytko</span></small></span><span><span></span></span></a><a href="https://www.forbes.com/sites/kerryadolan/2021/10/05/the-2021-forbes-400-list-of-richest-americans-facts-and-figures/" target="_blank" aria-label="The 2021 Forbes 400 List Of Richest Americans: Facts And Figures" rel="noopener noreferrer" data-ga-track="forbesEmbedly:https://www.forbes.com/sites/kerryadolan/2021/10/05/the-2021-forbes-400-list-of-richest-americans-facts-and-figures/"><span><span>Forbes</span><span>The 2021 Forbes 400 List Of Richest Americans: Facts And Figures</span><small>By <span>Kerry A. Dolan</span></small></span><span><span></span></span></a><a href="https://www.forbes.com/sites/hanktucker/2021/10/05/15-under-40-the-youngest-billionaires-on-the-2021-forbes-400/" target="_blank" aria-label="15 Under 40: The Youngest Billionaires On The 2021 Forbes 400" rel="noopener noreferrer" data-ga-track="forbesEmbedly:https://www.forbes.com/sites/hanktucker/2021/10/05/15-under-40-the-youngest-billionaires-on-the-2021-forbes-400/"><span><span>Forbes</span><span>15 Under 40: The Youngest Billionaires On The 2021 Forbes 400</span><small>By <span>Hank Tucker</span></small></span><span><span></span></span></a></p>
</div></div>]]></description>
        </item>
    </channel>
</rss>