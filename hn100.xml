<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 06 Sep 2025 11:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GOP Cries Censorship Over Spam Filters That Work (106 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/09/gop-cries-censorship-over-spam-filters-that-work/</link>
            <guid>45146375</guid>
            <pubDate>Sat, 06 Sep 2025 03:32:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/09/gop-cries-censorship-over-spam-filters-that-work/">https://krebsonsecurity.com/2025/09/gop-cries-censorship-over-spam-filters-that-work/</a>, See on <a href="https://news.ycombinator.com/item?id=45146375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>The chairman of the <strong>Federal Trade Commission</strong> (FTC) last week sent a letter to Google’s CEO demanding to know why Gmail was blocking messages from Republican senders while allegedly failing to block similar missives supporting Democrats. The letter followed media reports accusing Gmail of disproportionately flagging messages from the GOP fundraising platform <strong>WinRed</strong> and sending them to the spam folder. But according to experts who track daily spam volumes worldwide, WinRed’s messages are getting blocked more because its methods of blasting email are increasingly way more spammy than that of <strong>ActBlue</strong>, the fundraising platform for Democrats.</p>
<div id="attachment_72095"><p><img aria-describedby="caption-attachment-72095" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/09/nyp-google-spam.png" alt="" width="749" height="255" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/09/nyp-google-spam.png 865w, https://krebsonsecurity.com/wp-content/uploads/2025/09/nyp-google-spam-768x262.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/09/nyp-google-spam-782x267.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p><p id="caption-attachment-72095">Image: nypost.com</p></div>
<p>On Aug. 13, <strong>The New York Post</strong> ran an “exclusive” <a href="https://nypost.com/2025/08/13/business/google-caught-flagging-gop-fundraiser-emails-as-suspicious-sending-them-directly-to-spam-memo/" target="_blank" rel="noopener">story</a> titled, “Google caught flagging GOP fundraiser emails as ‘suspicious’ — sending them directly to spam.” The story cited a memo from Targeted Victory – whose clients include the National Republican Senatorial Committee (NRSC), Rep. Steve Scalise and Sen. Marsha Blackburn – which said it observed that the “serious and troubling” trend was still going on as recently as June and July of this year.</p>
<p>“If Gmail is allowed to quietly suppress WinRed links while giving ActBlue a free pass, it will continue to tilt the playing field in ways that voters never see, but campaigns will feel every single day,” the memo reportedly said.</p>
<p>In an August 28 letter to Google CEO <strong>Sundar Pichai</strong>, FTC Chairman <strong>Andrew Ferguson</strong> cited the New York Post story and warned that Gmail’s parent <strong>Alphabet</strong> may be engaging in unfair or deceptive practices.</p>
<p>“Alphabet’s alleged partisan treatment of comparable messages or messengers in Gmail to achieve political objectives may violate both of these prohibitions under the FTC Act,” Ferguson wrote. “And the partisan treatment may cause harm to consumers.”</p>
<p>However, the situation looks very different when you ask spam experts what’s going on with WinRed’s recent messaging campaigns. <strong>Atro Tossavainen</strong> and <strong>Pekka Jalonen</strong> are co-founders at <a href="https://www.koliloks.eu/" target="_blank" rel="noopener">Koli-Lõks OÜ</a>, an email intelligence company in Estonia. Koli-Lõks taps into real-time intelligence about daily spam volumes by monitoring large numbers of “spamtraps” — email addresses that are intentionally set up to catch unsolicited emails.</p>
<p>Spamtraps are generally not used for communication or account creation, but instead are created to identify senders exhibiting spammy behavior, such as scraping the Internet for email addresses or buying unmanaged distribution lists. As an email sender, blasting these spamtraps over and over with unsolicited email is the fastest way to ruin your domain’s reputation online. Such activity also virtually ensures that more of your messages are going to start getting listed on spam blocklists that are broadly shared within the global anti-abuse community.</p>
<p>Tossavainen told KrebsOnSecurity that WinRed’s emails hit its spamtraps in the .com, .net, and .org space far more frequently than do fundraising emails sent by ActBlue. Koli-Lõks published a graph of the stark disparity in spamtrap activity for WinRed versus ActBlue, showing a nearly fourfold increase in spamtrap hits from WinRed emails in the final week of July 2025.</p>
<div id="attachment_72094"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/09/koli-loks-red-v-blue.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-72094" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/09/koli-loks-red-v-blue.png" alt="" width="749" height="399" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/09/koli-loks-red-v-blue.png 974w, https://krebsonsecurity.com/wp-content/uploads/2025/09/koli-loks-red-v-blue-768x409.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/09/koli-loks-red-v-blue-782x417.png 782w" sizes="(max-width: 749px) 100vw, 749px"></a></p><p id="caption-attachment-72094">Image: Koliloks.eu</p></div>
<p>“Many of our spamtraps are in repurposed legacy-TLD domains (.com, .org, .net) and therefore could be understood to have been involved with a U.S. entity in their pre-zombie life,” Tossavainen explained in the LinkedIn post.<span id="more-72091"></span></p>
<p><strong>Raymond Dijkxhoorn</strong> is the CEO and a founding member of <a href="https://www.surbl.org/" target="_blank" rel="noopener">SURBL</a>, a widely-used blocklist that flags domains and IP addresses known to be used in unsolicited messages, phishing and malware distribution. Dijkxhoorn said their spamtrap data mirrors that of Koli-Lõks, and shows that WinRed has consistently been far more aggressive in sending email than ActBlue.</p>
<p>Dijkxhoorn said the fact that WinRed’s emails so often end up dinging the organization’s sender reputation is not a content issue but rather a technical one.</p>
<p>“On our end we don’t really care if the content is political or trying to sell viagra or penis enlargements,” Dijkhoorn said. “It’s the mechanics, they should not end up in spamtraps. And that’s the reason the domain reputation is tempered. Not ‘because domain reputation firms have a political agenda.’ We really don’t care about the political situation anywhere. The same as we don’t mind people buying penis enlargements. But when either of those land in spamtraps it will impact sending experience.”</p>
<p>The FTC letter to Google’s CEO also referenced a <a href="https://www.techdirt.com/2022/04/11/despite-what-fox-news-tells-you-a-new-study-did-not-prove-that-gmail-is-biased-against-conservatives/" target="_blank" rel="noopener">debunked</a> <a href="https://arxiv.org/pdf/2203.16743.pdf" target="_blank" rel="noopener">2022 study</a> (PDF) by political consultants who found Google caught more Republican emails in spam filters. <strong>Techdirt</strong> editor <strong>Mike Masnick</strong> notes that while the 2022 study also found that other email providers caught more Democratic emails as spam, “Republicans laser-focused on Gmail because it fit their victimization narrative better.”</p>
<p>Masnick said GOP lawmakers then filed both lawsuits and complaints with the <strong>Federal Election Commission</strong> (both of which failed easily), claiming this was somehow an “in-kind contribution” to Democrats.</p>
<p>“This is political posturing designed to keep the White House happy by appearing to ‘do something’ about conservative claims of ‘censorship,'” Masnick <a href="https://www.techdirt.com/2025/09/04/ftc-chair-fergusons-ridiculous-crusade-threatening-google-over-spam-filters-that-actually-work/" target="_blank" rel="noopener">wrote</a> of the FTC letter. “The FTC has never policed ‘political bias’ in private companies’ editorial decisions, and for good reason—the First Amendment prohibits exactly this kind of government interference.”</p>
<p>WinRed did not respond to a request for comment.</p>
<p>The WinRed website says it is an online fundraising platform supported by a united front of the Trump campaign, the <strong>Republican National Committee</strong> (RNC), the NRSC,&nbsp;and the <strong>National Republican Congressional Committee</strong> (NRCC).</p>
<p>WinRed has recently come under fire for aggressive fundraising via text message as well. In June, <strong>404 Media</strong> reported on <a href="https://www.404media.co/winred-texts-class-action-lawsuit-rnc-donations/" target="_blank" rel="noopener">a lawsuit</a> filed by a family in Utah against the RNC for allegedly bombarding their mobile phones with text messages seeking donations after they’d tried to unsubscribe from the missives dozens of times.</p>
<p>One of the family members said they received 27 such messages from 25 numbers, even after sending 20 stop requests. The plaintiffs in that case allege the texts from WinRed and the RNC “knowingly disregard stop requests and purposefully use different phone numbers to make it impossible to block new messages.”</p>
<p>Dijkhoorn said WinRed did inquire recently about why some of its assets had been marked as a risk by SURBL, but he said they appeared to have zero interest in investigating the likely causes he offered in reply.</p>
<p>“They only replied with, ‘You are interfering with U.S. elections,'” Dijkhoorn said, noting that many of SURBL’s spamtrap domains are only publicly listed in the registration records for random domain names.</p>
<p>“They’re at best harvested by themselves but more likely [they] just went and bought lists,” he said. “It’s not like ‘Oh Google is filtering this and not the other,’ the reason isn’t the provider. The reason is the fundraising spammers and the lists they send to.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Developing a Space Flight Simulator in Clojure (158 pts)]]></title>
            <link>https://www.wedesoft.de/software/2025/09/05/clojure-game/</link>
            <guid>45145794</guid>
            <pubDate>Sat, 06 Sep 2025 01:39:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wedesoft.de/software/2025/09/05/clojure-game/">https://www.wedesoft.de/software/2025/09/05/clojure-game/</a>, See on <a href="https://news.ycombinator.com/item?id=45145794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p><span>05 Sep 2025</span></p><p>    <iframe title="YouTube video player" width="640" height="390" src="//www.youtube.com/embed/38FGT7SWVh0" frameborder="0" allowfullscreen=""></iframe></p>

<p>In 2017 I discovered the free of charge <a href="http://orbit.medphys.ucl.ac.uk/">Orbiter 2016</a> space flight simulator which was proprietary at the time and it inspired me to develop a space flight simulator myself.
I prototyped some rigid body physics in C and later in <a href="https://www.gnu.org/software/guile/">GNU Guile</a> and also prototyped loading and rendering of Wavefront OBJ files.
I used GNU Guile (a Scheme implementation) because it has a good native interface and of course it has hygienic macros.
Eventually I got interested in Clojure because unlike GNU Guile it has multi-methods as well as fast hash maps and vectors.
I finally decided to develop the game for real in Clojure.
I have been developing a space flight simulator in Clojure for almost 5 years now.
While using Clojure I have come to appreciate the immutable values and safe parallelism using atoms, agents, and refs.</p>

<p>In the beginning I decided to work on the hard parts first, which for me were 3D rendering of a planet, an atmosphere, shadows, and volumetric clouds.
I read the <a href="https://www.informit.com/store/opengl-superbible-comprehensive-tutorial-and-reference-9780672337475">OpenGL Superbible</a> to get an understanding on what functionality OpenGL provides.
When Orbiter was eventually open sourced and released unter MIT license <a href="https://github.com/orbitersim/orbiter">here</a>, I inspected the source code and discovered that about 90% of the code is graphics-related.
So starting with the graphics problems was not a bad decision.</p>

<h2 id="software-dependencies">Software dependencies</h2>

<p>The following software is used for development.
The software libraries run on both GNU/Linux and Microsoft Windows.</p>

<ul>
  <li><a href="https://clojure.org/">Clojure</a> the programming language</li>
  <li><a href="https://www.lwjgl.org/">LWJGL</a> provides Java wrappers for various libraries
    <ul>
      <li>lwjgl-opengl for 3D graphics</li>
      <li>lwjgl-glfw for windowing and input devices</li>
      <li>lwjgl-nuklear for graphical user interfaces</li>
      <li>lwjgl-stb for image I/O and using truetype fonts</li>
      <li>lwjgl-assimp to load glTF 3D models with animation data</li>
    </ul>
  </li>
  <li><a href="https://github.com/jrouwe/JoltPhysics">Jolt Physics</a> to simulate wheeled vehicles and collisions with meshes</li>
  <li><a href="https://generateme.github.io/fastmath/">Fastmath</a> for fast matrix and vector math as well as spline interpolation</li>
  <li><a href="https://github.com/weavejester/comb">Comb</a> for templating shader code</li>
  <li><a href="https://github.com/Engelberg/instaparse">Instaparse</a> to parse NASA Planetary Constant Kernel (PCK) files</li>
  <li><a href="https://github.com/clj-commons/gloss">Gloss</a> to parse NASA Double Precision Array Files (DAF)</li>
  <li><a href="https://github.com/IGJoshua/coffi">Coffi</a> as a foreign function interface</li>
  <li><a href="https://github.com/clojure/core.memoize">core.memoize</a> for least recently used caching of function results</li>
  <li><a href="https://commons.apache.org/proper/commons-compress/">Apache Commons Compress</a> to read map tiles from tar files</li>
  <li><a href="https://github.com/metosin/malli">Malli</a> to add schemas to functions</li>
  <li><a href="https://github.com/levand/immuconf">Immuconf</a> to load the configuration file</li>
  <li><a href="https://github.com/weavejester/progrock">Progrock</a> a progress bar for long running builds</li>
  <li><a href="https://github.com/clj-commons/claypoole">Claypoole</a> to implement parallel for loops</li>
  <li><a href="https://clojure.org/guides/tools_build">tools.build</a> to build the project</li>
  <li><a href="https://github.com/clojure-goes-fast/clj-async-profiler">clj-async-profiler</a> Clojure profiler creating flame graphs</li>
  <li><a href="https://github.com/fzakaria/slf4j-timbre">slf4j-timbre</a> Java logging implementation for Clojure</li>
</ul>

<p>The <em>deps.edn</em> file contains operating system dependent LWJGL bindings.
For example on GNU/Linux the <em>deps.edn</em> file contains the following:</p>

<figure><pre><code data-lang="clojure"><span>{</span><span>:deps</span><span> </span><span>{</span><span>; ...</span><span>
        </span><span>org.lwjgl/lwjgl</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-opengl</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-opengl$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-glfw</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-glfw$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-nuklear</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-nuklear$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-stb</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-stb$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-assimp</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}</span><span>
        </span><span>org.lwjgl/lwjgl-assimp$natives-linux</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"3.3.6"</span><span>}}</span><span>
        </span><span>; ...</span><span>
        </span><span>}</span></code></pre></figure>

<p>In order to manage the different dependencies for Microsoft Windows, a separate Git branch is maintained.</p>

<h2 id="atmosphere-rendering">Atmosphere rendering</h2>


<p>    <iframe title="YouTube video player" width="640" height="390" src="//www.youtube.com/embed/q9aWd_14qhA" frameborder="0" allowfullscreen=""></iframe></p>

<p>For the atmosphere, <a href="https://ebruneton.github.io/precomputed_atmospheric_scattering/">Bruneton’s precomputed atmospheric scattering</a> was used.
The implementation uses a 2D transmittance table, a 2D surface scattering table, a 4D Rayleigh scattering, and a 4D Mie scattering table.
The tables are computed using several iterations of numerical integration.
Higher order functions for integration over a sphere and over a line segment were implemented in Clojure.
Integration over a ray in 3D space (using fastmath vectors) was implemented as follows for example:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>defn</span><span> </span><span>integral-ray</span><span>
  </span><span>"Integrate given function over a ray in 3D space"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>ray</span><span> </span><span>N</span><span> </span><span>:double</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:double</span><span>]]</span><span> </span><span>:some</span><span>]]</span><span> </span><span>:some</span><span>]}</span><span>
  </span><span>[{</span><span>::keys</span><span> </span><span>[</span><span>origin</span><span> </span><span>direction</span><span>]}</span><span> </span><span>steps</span><span> </span><span>distance</span><span> </span><span>fun</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>stepsize</span><span>      </span><span>(</span><span>/</span><span> </span><span>distance</span><span> </span><span>steps</span><span>)</span><span>
        </span><span>samples</span><span>       </span><span>(</span><span>mapv</span><span> </span><span>#</span><span>(</span><span>*</span><span> </span><span>(</span><span>+</span><span> </span><span>0.5</span><span> </span><span>%</span><span>)</span><span> </span><span>stepsize</span><span>)</span><span> </span><span>(</span><span>range</span><span> </span><span>steps</span><span>))</span><span>
        </span><span>interpolate</span><span>   </span><span>(</span><span>fn</span><span> </span><span>interpolate</span><span> </span><span>[</span><span>s</span><span>]</span><span> </span><span>(</span><span>add</span><span> </span><span>origin</span><span> </span><span>(</span><span>mult</span><span> </span><span>direction</span><span> </span><span>s</span><span>)))</span><span>
        </span><span>direction-len</span><span> </span><span>(</span><span>mag</span><span> </span><span>direction</span><span>)]</span><span>
    </span><span>(</span><span>reduce</span><span> </span><span>add</span><span> </span><span>(</span><span>mapv</span><span> </span><span>#</span><span>(</span><span>-&gt;</span><span> </span><span>%</span><span> </span><span>interpolate</span><span> </span><span>fun</span><span> </span><span>(</span><span>mult</span><span> </span><span>(</span><span>*</span><span> </span><span>stepsize</span><span> </span><span>direction-len</span><span>)))</span><span> </span><span>samples</span><span>))))</span></code></pre></figure>

<p>Precomputing the atmospheric tables takes several hours even though <a href="https://clojuredocs.org/clojure.core/pmap">pmap</a> was used.
When sampling the multi-dimensional functions, <em>pmap</em> was used as a top-level loop and <em>map</em> was used for interior loops.
Using <a href="https://docs.oracle.com/javase/8/docs/api/java/nio/ByteBuffer.html">java.nio.ByteBuffer</a> the floating point values were converted to a byte array and then written to disk using a <a href="https://clojuredocs.org/clojure.java.io/output-stream">clojure.java.io/output-stream</a>:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>defn</span><span> </span><span>floats-&gt;bytes</span><span>
  </span><span>"Convert float array to byte buffer"</span><span>
  </span><span>[</span><span>^</span><span>floats</span><span> </span><span>float-data</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>n</span><span>           </span><span>(</span><span>count</span><span> </span><span>float-data</span><span>)</span><span>
        </span><span>byte-buffer</span><span> </span><span>(</span><span>.order</span><span> </span><span>(</span><span>ByteBuffer/allocate</span><span> </span><span>(</span><span>*</span><span> </span><span>n</span><span> </span><span>4</span><span>))</span><span> </span><span>ByteOrder/LITTLE_ENDIAN</span><span>)]</span><span>
    </span><span>(</span><span>.put</span><span> </span><span>(</span><span>.asFloatBuffer</span><span> </span><span>byte-buffer</span><span>)</span><span> </span><span>float-data</span><span>)</span><span>
    </span><span>(</span><span>.array</span><span> </span><span>byte-buffer</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>spit-bytes</span><span>
  </span><span>"Write bytes to a file"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>non-empty-string</span><span> </span><span>bytes?</span><span>]</span><span> </span><span>:nil</span><span>]}</span><span>
  </span><span>[</span><span>^</span><span>String</span><span> </span><span>file-name</span><span> </span><span>^</span><span>bytes</span><span> </span><span>byte-data</span><span>]</span><span>
  </span><span>(</span><span>with-open</span><span> </span><span>[</span><span>out</span><span> </span><span>(</span><span>io/output-stream</span><span> </span><span>file-name</span><span>)]</span><span>
    </span><span>(</span><span>.write</span><span> </span><span>out</span><span> </span><span>byte-data</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>spit-floats</span><span>
  </span><span>"Write floating point numbers to a file"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>non-empty-string</span><span> </span><span>seqable?</span><span>]</span><span> </span><span>:nil</span><span>]}</span><span>
  </span><span>[</span><span>^</span><span>String</span><span> </span><span>file-name</span><span> </span><span>^</span><span>floats</span><span> </span><span>float-data</span><span>]</span><span>
  </span><span>(</span><span>spit-bytes</span><span> </span><span>file-name</span><span> </span><span>(</span><span>floats-&gt;bytes</span><span> </span><span>float-data</span><span>)))</span></code></pre></figure>

<p>When launching the game, the lookup tables get loaded and copied into OpenGL textures.
Shader functions are used to lookup and interpolate values from the tables.
When rendering the planet surface or the space craft, the atmosphere essentially gets superimposed using ray tracing.
After rendering the planet, a background quad is rendered to display the remaining part of the atmosphere above the horizon.</p>

<h2 id="templating-opengl-shaders">Templating OpenGL shaders</h2>

<p>It is possible to make programming with OpenGL shaders more flexible by using a templating library such as <em>Comb</em>.
The following shader defines multiple octaves of noise on a base noise function:</p>

<figure><pre><code data-lang="glsl"><span>#version 410 core
</span>
<span>float</span> <span>&lt;%=</span> <span>base</span><span>-</span><span>function</span> <span>%&gt;</span><span>(</span><span>vec3</span> <span>idx</span><span>);</span>

<span>float</span> <span>&lt;%=</span> <span>method</span><span>-</span><span>name</span> <span>%&gt;</span><span>(</span><span>vec3</span> <span>idx</span><span>)</span>
<span>{</span>
  <span>float</span> <span>result</span> <span>=</span> <span>0</span><span>.</span><span>0</span><span>;</span>
<span>&lt;%</span> <span>(</span><span>doseq</span> <span>[</span><span>multiplier</span> <span>octaves</span><span>]</span> <span>%&gt;</span>
  <span>result</span> <span>+=</span> <span>&lt;%=</span> <span>multiplier</span> <span>%&gt;</span> <span>*</span> <span>&lt;%=</span> <span>base</span><span>-</span><span>function</span> <span>%&gt;</span><span>(</span><span>idx</span><span>);</span>
  <span>idx</span> <span>*=</span> <span>2</span><span>;</span>
<span>&lt;%</span> <span>)</span> <span>%&gt;</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<p>One can then for example define the function <em>fbm_noise</em> using octaves of the base function <em>noise</em> as follows:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>def</span><span> </span><span>noise-octaves</span><span>
  </span><span>"Shader function to sum octaves of noise"</span><span>
  </span><span>(</span><span>template/fn</span><span> </span><span>[</span><span>method-name</span><span> </span><span>base-function</span><span> </span><span>octaves</span><span>]</span><span> </span><span>(</span><span>slurp</span><span> </span><span>"resources/shaders/core/noise-octaves.glsl"</span><span>)))</span><span>

</span><span>; ...</span><span>

</span><span>(</span><span>def</span><span> </span><span>fbm-noise-shader</span><span> </span><span>(</span><span>noise-octaves</span><span> </span><span>"fbm_noise"</span><span> </span><span>"noise"</span><span> </span><span>[</span><span>0.57</span><span> </span><span>0.28</span><span> </span><span>0.15</span><span>]))</span></code></pre></figure>

<h2 id="planet-rendering">Planet rendering</h2>


<p>    <iframe title="YouTube video player" width="640" height="390" src="//www.youtube.com/embed/Ce3oWQflYOY" frameborder="0" allowfullscreen=""></iframe></p>

<p>To render the planet, <a href="https://visibleearth.nasa.gov/collection/1484/blue-marble">NASA Bluemarble</a> data, <a href="https://earthobservatory.nasa.gov/features/NightLights/page3.php">NASA Blackmarble</a> data, and <a href="https://www.ngdc.noaa.gov/mgg/topo/gltiles.html">NASA Elevation</a> data was used.
The images were converted to a multi resolution pyramid of map tiles.
The following functions were implemented for color map tiles and for elevation tiles:</p>

<ul>
  <li>a function to load and cache map tiles of given 2D tile index and level of detail</li>
  <li>a function to extract a pixel from a map tile</li>
  <li>a function to extract the pixel for a specific longitude and latitude</li>
</ul>

<p>The functions for extracting a pixel for given longitude and latitude then were used to generate a cube map with a quad tree of tiles for each face.
For each tile, the following files were generated:</p>

<ul>
  <li>A daytime texture</li>
  <li>A night time texture</li>
  <li>An image of 3D vectors defining a surface mesh</li>
  <li>A water mask</li>
  <li>A normal map</li>
</ul>

<p>Altogether 655350 files were generated.
Because the Steam ContentBuilder does not support a large number of files, each row of tile data was aggregated into a tar file.
The <em>Apache Commons Compress</em> library allows you to open a tar file to get a list of entries and then perform random access on the contents of the tar file.
A Clojure LRU cache was used to maintain a cache of open tar files for improved performance.</p>

<p>At run time, a future is created, which returns an updated tile tree, a list of tiles to drop, and a path list of the tiles to load into OpenGL.
When the future is realized, the main thread deletes the OpenGL textures from the drop list, and then uses the path list to get the new loaded images from the tile tree, load them into OpenGL textures, and create an updated tile tree with the new OpenGL textures added.
The following functions to manipulate quad trees were implemented to realize this:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>defn</span><span> </span><span>quadtree-add</span><span>
  </span><span>"Add tiles to quad tree"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]</span><span> </span><span>[</span><span>:sequential</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:keyword</span><span>]]</span><span> </span><span>[</span><span>:sequential</span><span> </span><span>:map</span><span>]]</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]]}</span><span>
  </span><span>[</span><span>tree</span><span> </span><span>paths</span><span> </span><span>tiles</span><span>]</span><span>
  </span><span>(</span><span>reduce</span><span> </span><span>(</span><span>fn</span><span> </span><span>add-title-to-quadtree</span><span> </span><span>[</span><span>tree</span><span> </span><span>[</span><span>path</span><span> </span><span>tile</span><span>]]</span><span> </span><span>(</span><span>assoc-in</span><span> </span><span>tree</span><span> </span><span>path</span><span> </span><span>tile</span><span>))</span><span> </span><span>tree</span><span> </span><span>(</span><span>mapv</span><span> </span><span>vector</span><span> </span><span>paths</span><span> </span><span>tiles</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>quadtree-extract</span><span>
  </span><span>"Extract a list of tiles from quad tree"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]</span><span> </span><span>[</span><span>:sequential</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:keyword</span><span>]]]</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:map</span><span>]]}</span><span>
  </span><span>[</span><span>tree</span><span> </span><span>paths</span><span>]</span><span>
  </span><span>(</span><span>mapv</span><span> </span><span>(</span><span>partial</span><span> </span><span>get-in</span><span> </span><span>tree</span><span>)</span><span> </span><span>paths</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>quadtree-drop</span><span>
  </span><span>"Drop tiles specified by path list from quad tree"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]</span><span> </span><span>[</span><span>:sequential</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:keyword</span><span>]]]</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]]}</span><span>
  </span><span>[</span><span>tree</span><span> </span><span>paths</span><span>]</span><span>
  </span><span>(</span><span>reduce</span><span> </span><span>dissoc-in</span><span> </span><span>tree</span><span> </span><span>paths</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>quadtree-update</span><span>
  </span><span>"Update tiles with specified paths using a function with optional arguments from lists"</span><span>
  </span><span>{</span><span>:malli/schema</span><span> </span><span>[</span><span>:=&gt;</span><span> </span><span>[</span><span>:cat</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]</span><span> </span><span>[</span><span>:sequential</span><span> </span><span>[</span><span>:vector</span><span> </span><span>:keyword</span><span>]]</span><span> </span><span>fn?</span><span> </span><span>[</span><span>:*</span><span> </span><span>:any</span><span>]]</span><span> </span><span>[</span><span>:maybe</span><span> </span><span>:map</span><span>]]}</span><span>
  </span><span>[</span><span>tree</span><span> </span><span>paths</span><span> </span><span>fun</span><span> </span><span>&amp;</span><span> </span><span>arglists</span><span>]</span><span>
  </span><span>(</span><span>reduce</span><span> </span><span>(</span><span>fn</span><span> </span><span>update-tile-in-quadtree</span><span>
            </span><span>[</span><span>tree</span><span> </span><span>[</span><span>path</span><span> </span><span>&amp;</span><span> </span><span>args</span><span>]]</span><span>
            </span><span>(</span><span>apply</span><span> </span><span>update-in</span><span> </span><span>tree</span><span> </span><span>path</span><span> </span><span>fun</span><span> </span><span>args</span><span>))</span><span> </span><span>tree</span><span> </span><span>(</span><span>apply</span><span> </span><span>map</span><span> </span><span>list</span><span> </span><span>paths</span><span> </span><span>arglists</span><span>)))</span></code></pre></figure>

<h2 id="other-topics">Other topics</h2>

<h3 id="solar-system">Solar system</h3>

<p>The astronomy code for getting the position and orientation of planets was implemented according to the <a href="https://rhodesmill.org/skyfield/">Skyfield</a> Python library.
The Python library in turn is based on the <a href="https://naif.jpl.nasa.gov/naif/index.html">SPICE</a> toolkit of the NASA JPL.
The JPL basically provides sequences of <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> to interpolate positions of Moon and planets as well as the orientation of the Moon as binary files.
Reference coordinate systems and orientations of other bodies are provided in text files which consist of human and machine readable sections.
The binary files were parsed using <em>Gloss</em> (see <a href="https://github.com/clj-commons/gloss/wiki/Introduction">Wiki</a> for some examples) and the text files using <em>Instaparse</em>.</p>

<h3 id="jolt-bindings">Jolt bindings</h3>

<p>The required Jolt functions for wheeled vehicle dynamics and collisions with meshes were wrapped in C functions and compiled into a shared library.
The <em>Coffi</em> Clojure library (which is a wrapper for Java’s new Foreign Function &amp; Memory API) was used to make the C functions and data types usable in Clojure.</p>

<p>For example the following code implements a call to the C function <em>add_force</em>:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>defcfn</span><span> </span><span>add-force</span><span>
  </span><span>"Apply a force in the next physics update"</span><span>
  </span><span>add_force</span><span> </span><span>[</span><span>::mem/int</span><span> </span><span>::vec3</span><span>]</span><span> </span><span>::mem/void</span><span>)</span></code></pre></figure>

<p>Here <em>::vec3</em> refers to a custom composite type defined using basic types.
The memory layout, serialisation, and deserialisation for <em>::vec3</em> are defined as follows:</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>def</span><span> </span><span>vec3-struct</span><span>
  </span><span>[</span><span>::mem/struct</span><span>
   </span><span>[[</span><span>:x</span><span> </span><span>::mem/double</span><span>]</span><span>
    </span><span>[</span><span>:y</span><span> </span><span>::mem/double</span><span>]</span><span>
    </span><span>[</span><span>:z</span><span> </span><span>::mem/double</span><span>]]])</span><span>


</span><span>(</span><span>defmethod</span><span> </span><span>mem/c-layout</span><span> </span><span>::vec3</span><span>
  </span><span>[</span><span>_vec3</span><span>]</span><span>
  </span><span>(</span><span>mem/c-layout</span><span> </span><span>vec3-struct</span><span>))</span><span>


</span><span>(</span><span>defmethod</span><span> </span><span>mem/serialize-into</span><span> </span><span>::vec3</span><span>
  </span><span>[</span><span>obj</span><span> </span><span>_vec3</span><span> </span><span>segment</span><span> </span><span>arena</span><span>]</span><span>
  </span><span>(</span><span>mem/serialize-into</span><span> </span><span>{</span><span>:x</span><span> </span><span>(</span><span>obj</span><span> </span><span>0</span><span>)</span><span> </span><span>:y</span><span> </span><span>(</span><span>obj</span><span> </span><span>1</span><span>)</span><span> </span><span>:z</span><span> </span><span>(</span><span>obj</span><span> </span><span>2</span><span>)}</span><span> </span><span>vec3-struct</span><span> </span><span>segment</span><span> </span><span>arena</span><span>))</span><span>


</span><span>(</span><span>defmethod</span><span> </span><span>mem/deserialize-from</span><span> </span><span>::vec3</span><span>
  </span><span>[</span><span>segment</span><span> </span><span>_vec3</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>result</span><span> </span><span>(</span><span>mem/deserialize-from</span><span> </span><span>segment</span><span> </span><span>vec3-struct</span><span>)]</span><span>
    </span><span>(</span><span>vec3</span><span> </span><span>(</span><span>:x</span><span> </span><span>result</span><span>)</span><span> </span><span>(</span><span>:y</span><span> </span><span>result</span><span>)</span><span> </span><span>(</span><span>:z</span><span> </span><span>result</span><span>))))</span></code></pre></figure>

<h3 id="performance">Performance</h3>

<p>The <em>clj-async-profiler</em> was used to create flame graphs visualising the performance of the game.
In order to get reflection warnings for Java calls without sufficient type declarations, <em>*unchecked-math*</em> was set to <em>:warn-on-boxed</em>.</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>set!</span><span> </span><span>*unchecked-math*</span><span> </span><span>:warn-on-boxed</span><span>)</span></code></pre></figure>

<p>Furthermore to discover missing declarations of numerical types, <em>*warn-on-reflection*</em> was set to <em>true</em>.</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>set!</span><span> </span><span>*warn-on-reflection*</span><span> </span><span>true</span><span>)</span></code></pre></figure>

<p>To reduce garbage collector pauses, the ZGC low-latency garbage collector for the JVM was used.
The following section in <em>deps.edn</em> ensures that the ZGC garbage collector is used when running the project with <em>clj -M:run</em>:</p>

<figure><pre><code data-lang="clojure"><span>{</span><span>:deps</span><span> </span><span>{</span><span>; ...</span><span>
        </span><span>}</span><span>
 </span><span>:aliases</span><span> </span><span>{</span><span>:run</span><span> </span><span>{</span><span>:jvm-opts</span><span> </span><span>[</span><span>"-Xms2g"</span><span> </span><span>"-Xmx4g"</span><span> </span><span>"--enable-native-access=ALL-UNNAMED"</span><span> </span><span>"-XX:+UseZGC"</span><span>
                            </span><span>"--sun-misc-unsafe-memory-access=allow"</span><span>]</span><span>
                 </span><span>:main-opts</span><span> </span><span>[</span><span>"-m"</span><span> </span><span>"sfsim.core"</span><span>]}}}</span></code></pre></figure>

<p>The option to use ZGC is also specified in the Packr JSON file used to deploy the application.</p>

<h3 id="building-the-project">Building the project</h3>

<p>In order to build the map tiles, atmospheric lookup tables, and other data files using <em>tools.build</em>, the project source code was made available in the <em>build.clj</em> file using a <em>:local/root</em> dependency:</p>

<figure><pre><code data-lang="clojure"><span>{</span><span>:deps</span><span> </span><span>{</span><span>; ...</span><span>
        </span><span>}</span><span>
 </span><span>:aliases</span><span> </span><span>{</span><span>; ...</span><span>
           </span><span>:build</span><span> </span><span>{</span><span>:deps</span><span> </span><span>{</span><span>io.github.clojure/tools.build</span><span> </span><span>{</span><span>:mvn/version</span><span> </span><span>"0.10.10"</span><span>}</span><span>
                          </span><span>sfsim/sfsim</span><span> </span><span>{</span><span>:local/root</span><span> </span><span>"."</span><span>}}</span><span>
                   </span><span>:ns-default</span><span> </span><span>build</span><span>
                   </span><span>:exec-fn</span><span> </span><span>all</span><span>
                   </span><span>:jvm-opts</span><span> </span><span>[</span><span>"-Xms2g"</span><span> </span><span>"-Xmx4g"</span><span> </span><span>"--sun-misc-unsafe-memory-access=allow"</span><span>]}}}</span></code></pre></figure>

<p>Various targets were defined to build the different components of the project.
For example the atmospheric lookup tables can be build by specifying <em>clj -T:build atmosphere-lut</em> on the command line.</p>

<p>The following section in the <em>build.clj</em> file was added to allow creating an “Uberjar” JAR file with all dependencies by specifying <em>clj -T:build uber</em> on the command-line.</p>

<figure><pre><code data-lang="clojure"><span>(</span><span>defn</span><span> </span><span>uber</span><span> </span><span>[</span><span>_</span><span>]</span><span>
  </span><span>(</span><span>b/copy-dir</span><span> </span><span>{</span><span>:src-dirs</span><span> </span><span>[</span><span>"src/clj"</span><span>]</span><span>
               </span><span>:target-dir</span><span> </span><span>class-dir</span><span>})</span><span>
  </span><span>(</span><span>b/compile-clj</span><span> </span><span>{</span><span>:basis</span><span> </span><span>basis</span><span>
                  </span><span>:src-dirs</span><span> </span><span>[</span><span>"src/clj"</span><span>]</span><span>
                  </span><span>:class-dir</span><span> </span><span>class-dir</span><span>})</span><span>
  </span><span>(</span><span>b/uber</span><span> </span><span>{</span><span>:class-dir</span><span> </span><span>class-dir</span><span>
           </span><span>:uber-file</span><span> </span><span>"target/sfsim.jar"</span><span>
           </span><span>:basis</span><span> </span><span>basis</span><span>
           </span><span>:main</span><span> </span><span>'sfsim.core</span><span>}))</span></code></pre></figure>

<p>To create a Linux executable with Packr, one can then run <em>java -jar packr-all-4.0.0.jar scripts/packr-config-linux.json</em> where the JSON file has the following content:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"platform"</span><span>:</span><span> </span><span>"linux64"</span><span>,</span><span>
  </span><span>"jdk"</span><span>:</span><span> </span><span>"/usr/lib/jvm/jdk-24.0.2-oracle-x64"</span><span>,</span><span>
  </span><span>"executable"</span><span>:</span><span> </span><span>"sfsim"</span><span>,</span><span>
  </span><span>"classpath"</span><span>:</span><span> </span><span>[</span><span>"target/sfsim.jar"</span><span>],</span><span>
  </span><span>"mainclass"</span><span>:</span><span> </span><span>"sfsim.core"</span><span>,</span><span>
  </span><span>"resources"</span><span>:</span><span> </span><span>[</span><span>"LICENSE"</span><span>,</span><span> </span><span>"libjolt.so"</span><span>,</span><span> </span><span>"venturestar.glb"</span><span>,</span><span> </span><span>"resources"</span><span>],</span><span>
  </span><span>"vmargs"</span><span>:</span><span> </span><span>[</span><span>"Xms2g"</span><span>,</span><span> </span><span>"Xmx4g"</span><span>,</span><span> </span><span>"XX:+UseZGC"</span><span>],</span><span>
  </span><span>"output"</span><span>:</span><span> </span><span>"out-linux"</span><span>
</span><span>}</span></code></pre></figure>

<p>In order to distribute the game on Steam, three depots were created:</p>

<ul>
  <li>a data depot with the operating system independent data files</li>
  <li>a Linux depot with the Linux executable and Uberjar including LWJGL’s Linux native bindings</li>
  <li>and a Windows depot with the Windows executable and an Uberjar including LWJGL’s Windows native bindings</li>
</ul>

<p>When updating a depot, the Steam ContentBuilder command line tool creates and uploads a patch in order to preserve storage space and bandwidth.</p>

<h2 id="future-work">Future work</h2>

<p>Although the hard parts are mostly done, there are still several things to do:</p>

<ul>
  <li>control surfaces and thruster graphics</li>
  <li>launchpad and runway graphics</li>
  <li>sound effects</li>
  <li>a 3D cockpit</li>
  <li>the Moon</li>
  <li>a space station</li>
</ul>

<p>It would also be interesting to make the game modable in a safe way (maybe evaluating Clojure files in a sandboxed environment?).</p>

<h2 id="conclusion">Conclusion</h2>


<p>    <iframe title="YouTube video player" width="640" height="390" src="//www.youtube.com/embed/1PqmVLUt5_g" frameborder="0" allowfullscreen=""></iframe></p>

<p>You can find the <a href="https://github.com/wedesoft/sfsim">source code on Github</a>.
Currently there is only a playtest build, but if you want to get notified, when the game gets released, you can <a href="https://store.steampowered.com/app/3687560/sfsim/">wishlist it here</a>.</p>

<p>Anyway, let me know any comments and suggestions.</p>

<p>Enjoy!</p>



<ul>
  <li><a href="https://www.wedesoft.de/simulation/2025/06/06/flight-model-physics-venturestar/">Flight dynamics model for simulating Venturestar style spacecraft</a></li>
  <li><a href="https://www.wedesoft.de/software/2022/07/01/tdd-with-opengl/">Test Driven Development with OpenGL</a></li>
  <li><a href="https://www.wedesoft.de/software/2024/05/11/clojure-nuklear/">Implementing GUIs using Clojure and LWJGL Nuklear bindings</a></li>
  <li><a href="https://www.wedesoft.de/software/2023/05/03/volumetric-clouds/">Procedural Volumetric Clouds</a></li>
  <li><a href="https://www.wedesoft.de/software/2023/03/20/procedural-global-cloud-cover/">Procedural generation of global cloud cover</a></li>
  <li><a href="https://www.wedesoft.de/software/2021/09/20/reversed-z-rendering/">Reversed-Z Rendering in OpenGL</a></li>
  <li><a href="https://www.wedesoft.de/software/2023/12/25/clojure-function-schemas-with-malli/">Specifying Clojure function schemas with Malli</a></li>
  <li><a href="https://www.wedesoft.de/software/2024/07/05/clojure-instaparse/">Implement an Interpreter using Clojure Instaparse</a></li>
  <li><a href="https://www.wedesoft.de/simulation/2025/08/09/orbits-with-jolt-physics/">Orbits with Jolt Physics</a></li>
  <li><a href="https://www.wedesoft.de/simulation/2024/09/26/jolt-physics-engine/">Getting started with the Jolt Physics Engine</a></li>
  <li><a href="https://www.wedesoft.de/graphics/2023/09/29/blender-animate-bones-assimp/">Create Blender bones and animate and import with Assimp</a></li>
</ul>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GLM 4.5 with Claude Code (127 pts)]]></title>
            <link>https://docs.z.ai/guides/llm/glm-4.5</link>
            <guid>45145457</guid>
            <pubDate>Sat, 06 Sep 2025 00:45:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.z.ai/guides/llm/glm-4.5">https://docs.z.ai/guides/llm/glm-4.5</a>, See on <a href="https://news.ycombinator.com/item?id=45145457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-page-title="GLM-4.5" data-page-href="/guides/llm/glm-4.5"><h2 id="overview"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-list.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-list.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Overview</span></h2>

<p><span data-as="p">GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.</span>
<span data-as="p">Both models share a similar training pipeline: an initial pretraining phase on 15 trillion tokens of general-domain data, followed by targeted fine-tuning on datasets covering code, reasoning, and agent-specific tasks. The context length has been extended to 128k tokens, and reinforcement learning was applied to further enhance reasoning, coding, and agent performance.</span>
<span data-as="p">GLM-4.5 and GLM-4.5-Air are optimized for tool invocation, web browsing, software engineering, and front-end development. They can be integrated into code-centric agents such as Claude Code and Roo Code, and also support arbitrary agent applications through tool invocation APIs.</span>
<span data-as="p">Both models support hybrid reasoning modes, offering two execution modes: Thinking Mode for complex reasoning and tool usage, and Non-Thinking Mode for instant responses. These modes can be toggled via the <code>thinking.type</code>parameter (with <code>enabled</code> and <code>disabled</code> settings), and dynamic thinking is enabled by default.</span></p>
<h2 id="glm-4-5-serials"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list-ol.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list-ol.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   GLM-4.5 Serials</span></h2>

<h2 id="capability"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/table-cells.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/table-cells.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Capability</span></h2>

<h2 id="introducting-glm-4-5"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/arrow-down-from-line.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/arrow-down-from-line.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Introducting GLM-4.5</span></h2>
<h3 id="overview-2"><span>Overview</span></h3>
<p><span data-as="p">The first-principle measure of AGI lies in integrating more general intelligence capabilities without compromising existing functions. GLM-4.5 represents our first complete realization of this concept. It combines advanced reasoning, coding, and agent capabilities within a single model, achieving a significant technological breakthrough by natively fusing reasoning, coding, and agent abilities to meet the complex demands of agent-based applications.</span>
<span data-as="p">To comprehensively evaluate the model’s general intelligence, we selected 12 of the most representative benchmark suites, including MMLU Pro, AIME24, MATH 500, SciCode, GPQA, HLE, LiveCodeBench, SWE-Bench, Terminal-bench, TAU-Bench, BFCL v3, and BrowseComp. Based on the aggregated average scores, GLM-4.5 ranks second globally among all models, first among domestic models, and first among open-source models.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-0.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=d565bc82527cd77841a018a7e9fe2df0" alt="Description" width="1280" height="519" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=7365968bdde0823d47d300cc47513784 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=148a0bf8b7521d83038120f905dd6405 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=cdd09f501f000d35951a58d40bd4df64 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=13c5518e6b936b26576417406e13b126 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e0fac97416d648104e20863f6df4e7b3 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=fbf4e15b30ce23327b31afadddfb3efa 2500w" data-optimize="true"></picture></span></span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-1.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a296f62a9517735d7af5b0580094065b" alt="Description" width="1280" height="338" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=7081c526e679395aa8dee0e9913da019 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=6cbaf319c9f8da2ed44676b778b2f5ed 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=cae5d25fb5c262fd222636e46da12130 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=272ffdfd95d6f3c2c12f0bd146c7a3a9 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=ed785a2a6b7c309d9ec2554144d92201 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=c20fdadadb52a4a60fa0fe9e6fbcdfaf 2500w" data-optimize="true"></picture></span></span></p><h3 id="higher-parameter-efficiency"><span><strong>Higher Parameter Efficiency</strong></span></h3>
<p><span data-as="p">GLM-4.5 has half the number of parameters of DeepSeek-R1 and one-third that of Kimi-K2, yet it outperforms them on multiple standard benchmark tests. This is attributed to the higher parameter efficiency of GLM architecture. Notably, GLM-4.5-Air, with 106 billion total parameters and 12 billion active parameters, achieves a significant breakthrough—surpassing models such as Gemini 2.5 Flash, Qwen3-235B, and Claude 4 Opus on reasoning benchmarks like Artificial Analysis, ranking among the top three domestic models in performance.</span>
<span data-as="p">On charts such as SWE-Bench Verified, the GLM-4.5 series lies on the Pareto frontier for performance-to-parameter ratio, demonstrating that at the same scale, the GLM-4.5 series delivers optimal performance.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-2.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=0ab97aeb6f7d4cef4e2b33fcb76231b4" alt="Description" width="1280" height="777" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e5462bd8ceb960fc00833ad31277cc71 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=affcf850f56f6592379fb9577bd59d00 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=ba573ed2e9c7995afda5ff2b4fa114f3 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=2cb08db672a6d9695d1cbf94f63cb5aa 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a0b96f5aa3489394465c341141076bcc 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e2114df239206110bf9cb0a6d4270023 2500w" data-optimize="true"></picture></span></span></p><h3 id="low-cost%2C-high-speed"><span><strong>Low Cost, High Speed</strong></span></h3>
<p><span data-as="p">Beyond performance optimization, the GLM-4.5 series also achieves breakthroughs in cost and efficiency, resulting in pricing far lower than mainstream models: API call costs are as low as $0.2 per million input tokens and $1.1 per million output tokens.</span>
<span data-as="p">At the same time, the high-speed version demonstrates a generation speed exceeding 100 tokens per second in real-world tests, supporting low-latency and high-concurrency deployment scenarios—balancing cost-effectiveness with user interaction experience.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark2.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=d39c7575956dbe42a1c437e3cf14279f" alt="Description" width="990" height="305" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=36ded49da55eee897a3c75da1cf8a462 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a66679e1487639408b67b6e09c3c3567 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=1bcb41a8f67aad17e947d332bc4fb851 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=91584a7f2d33cadd159b991cf0bec447 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=aabc285869f2becb3cb49e474fc72837 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=92553133a8200bd6a6adf57ce447e250 2500w" data-optimize="true"></picture></span></span></p><h3 id="real-world-evaluation"><span><strong>Real-World Evaluation</strong></span></h3>
<p><span data-as="p">Real-world performance matters more than leaderboard rankings. To evaluate GLM-4.5’s effectiveness in practical Agent Coding scenarios, we integrated it into Claude Code and benchmarked it against Claude 4 Sonnet, Kimi-K2, and Qwen3-Coder.</span>
<span data-as="p">The evaluation consisted of 52 programming and development tasks spanning six major domains, executed in isolated container environments with multi-turn interaction tests.</span>
<span data-as="p">As shown in the results (below), GLM-4.5 demonstrates a strong competitive advantage over other open-source models, particularly in tool invocation reliability and task completion rate. While there remains room for improvement compared to Claude 4 Sonnet, GLM-4.5 delivers a largely comparable experience in most scenarios.</span>
<span data-as="p">To ensure transparency, we have released all <a href="https://huggingface.co/datasets/zai-org/CC-Bench-trajectories" target="_blank" rel="noreferrer">52 test problems along with full agent trajectories</a> for industry validation and reproducibility.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/expr1.jpeg" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=f8b051792b065926cf99bed4648197e0" alt="Description" width="1280" height="564" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=26e0bf74011f877a3b7fa71a75236a13 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=793e94d145f933d9684b39a145ca814f 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=451457ec301347d9f1a6dc48dbf51032 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=b27b4502c1a38d9745d07c3052dbeb6c 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=776abd81fff1c5f0bf70ad16f540eb34 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=32403d412a1c80d552ce0fe2dbd96fad 2500w" data-optimize="true"></picture></span></span></p><h2 id="usage"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Usage</span></h2>
<div id="web-development"><ul data-component-part="tabs-list"><li id="web-development"></li><li id="ai-assistant"></li><li id="smart-office"></li><li id="intelligent-question-answering"></li><li id="complex-text-translation"></li><li id="content-creation"></li><li id="virtual-characters"></li></ul><div data-component-part="tab-content"><p><span data-as="p"><strong>Core Capability:</strong> <u>Coding Skills</u> → Intelligent code generation | Real-time code completion | Automated bug fixing</span></p><ul>
<li>Supports major languages including Python, JavaScript, and Java.</li>
<li>Generates well-structured, scalable, high-quality code based on natural language instructions.</li>
<li>Focuses on real-world development needs, avoiding templated or generic outputs.</li>
</ul><p><span data-as="p"><strong>Use Case:</strong> Complete refactoring-level tasks within 1 hour; generate full product prototypes in 5 minutes.</span></p><video src="https://cdn.bigmodel.cn/agent-demos/lark/113123.mov" controls=""></video></div></div>
<h2 id="resources"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/bars-sort.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/bars-sort.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Resources</span></h2>
<ul>
<li><a href="https://docs.z.ai/api-reference/llm/chat-completion">API Documentation</a>: Learn how to call the API.</li>
</ul>
<h2 id="quick-start"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-code.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-code.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>    Quick Start</span></h2>
<h3 id="thinking-mode"><span>Thinking Mode</span></h3>
<p><span data-as="p">GLM-4.5 offers a “Deep Thinking Mode” that users can enable or disable by setting the <code>thinking.type</code> parameter. This parameter supports two values: <code>enabled</code> (enabled) and <code>disabled</code> (disabled). By default, dynamic thinking is enabled.</span></p><ul>
<li><strong>Simple Tasks (No Thinking Required):</strong> For straightforward requests that do not require complex reasoning (e.g., fact retrieval or classification), thinking is unnecessary. Examples include:<!-- -->
<ul>
<li>When was Z.AI founded?</li>
<li>Translate the sentence “I love you” into Chinese.</li>
</ul>
</li>
<li><strong>Moderate Tasks (Default/Some Thinking Required):</strong> Many common requests require stepwise processing or deeper understanding. The GLM-4.5 series can flexibly apply thinking capabilities to handle tasks such as:<!-- -->
<ul>
<li>Why does Jupiter have more moons than Saturn, despite Saturn being larger?</li>
<li>Compare the advantages and disadvantages of flying versus taking the high-speed train from Beijing to Shanghai.</li>
</ul>
</li>
</ul>
<p><span data-as="p"><strong>Difficult Tasks (Maximum Thinking Capacity):</strong> For truly complex challenges—such as solving advanced math problems, network-related questions, or coding issues—these tasks require the model to fully engage its reasoning and planning abilities, often involving many internal steps before arriving at an answer. Examples include:</span></p><ul>
<li>Explain in detail how different experts in a Mixture-of-Experts (MoE) model collaborate.</li>
<li>Based on the recent week’s fluctuations of the Shanghai Composite Index and current political information, should I invest in a stock index ETF? Why?</li>
</ul>
<h3 id="samples-code"><span>Samples Code</span></h3>
<div id="curl"><ul data-component-part="tabs-list"><li id="curl"></li><li id="official-python-sdk"></li><li id="official-java-sdk"></li><li id="openai-python-sdk"></li></ul><div data-component-part="tab-content"><p><span data-as="p"><strong>Basic Call</strong></span></p><div data-component-part="code-block-root" numberoflines="25" language="shellscript"><pre language="shellscript"><code language="shellscript" numberoflines="25"><span><span>curl</span><span> -X</span><span> POST</span><span> "https://api.z.ai/api/paas/v4/chat/completions"</span><span> \</span></span>
<span><span>  -H</span><span> "Content-Type: application/json"</span><span> \</span></span>
<span><span>  -H</span><span> "Authorization: Bearer your-api-key"</span><span> \</span></span>
<span><span>  -d</span><span> '{</span></span>
<span><span>    "model": "glm-4.5",</span></span>
<span><span>    "messages": [</span></span>
<span><span>      {</span></span>
<span><span>        "role": "user",</span></span>
<span><span>        "content": "As a marketing expert, please create an attractive slogan for my product."</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        "role": "assistant",</span></span>
<span><span>        "content": "Sure, to craft a compelling slogan, please tell me more about your product."</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        "role": "user",</span></span>
<span><span>        "content": "Z.AI Open Platform"</span></span>
<span><span>      }</span></span>
<span><span>    ],</span></span>
<span><span>    "thinking": {</span></span>
<span><span>      "type": "enabled"</span></span>
<span><span>    },</span></span>
<span><span>    "max_tokens": 4096,</span></span>
<span><span>    "temperature": 0.6</span></span>
<span><span>  }'</span></span>
</code></pre></div><p><span data-as="p"><strong>Streaming Call</strong></span></p><div data-component-part="code-block-root" numberoflines="26" language="shellscript"><pre language="shellscript"><code language="shellscript" numberoflines="26"><span><span>curl</span><span> -X</span><span> POST</span><span> "https://api.z.ai/api/paas/v4/chat/completions"</span><span> \</span></span>
<span><span>  -H</span><span> "Content-Type: application/json"</span><span> \</span></span>
<span><span>  -H</span><span> "Authorization: Bearer your-api-key"</span><span> \</span></span>
<span><span>  -d</span><span> '{</span></span>
<span><span>    "model": "glm-4.5",</span></span>
<span><span>    "messages": [</span></span>
<span><span>      {</span></span>
<span><span>        "role": "user",</span></span>
<span><span>        "content": "As a marketing expert, please create an attractive slogan for my product."</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        "role": "assistant",</span></span>
<span><span>        "content": "Sure, to craft a compelling slogan, please tell me more about your product."</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        "role": "user",</span></span>
<span><span>        "content": "Z.AI Open Platform"</span></span>
<span><span>      }</span></span>
<span><span>    ],</span></span>
<span><span>    "thinking": {</span></span>
<span><span>      "type": "enabled"</span></span>
<span><span>    },</span></span>
<span><span>    "stream": true,</span></span>
<span><span>    "max_tokens": 4096,</span></span>
<span><span>    "temperature": 0.6</span></span>
<span><span>  }'</span></span>
</code></pre></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla changes meaning of 'Full Self-Driving', gives up on promise of autonomy (178 pts)]]></title>
            <link>https://electrek.co/2025/09/05/tesla-changes-meaning-full-self-driving-give-up-promise-autonomy/</link>
            <guid>45144900</guid>
            <pubDate>Fri, 05 Sep 2025 23:23:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/09/05/tesla-changes-meaning-full-self-driving-give-up-promise-autonomy/">https://electrek.co/2025/09/05/tesla-changes-meaning-full-self-driving-give-up-promise-autonomy/</a>, See on <a href="https://news.ycombinator.com/item?id=45144900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="875" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/Tesla-Self-Driving-FSD-Hero.png?w=1600" alt="" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/Tesla-Self-Driving-FSD-Hero.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/Tesla-Self-Driving-FSD-Hero.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/Tesla-Self-Driving-FSD-Hero.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/Tesla-Self-Driving-FSD-Hero.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla has changed the meaning of “Full Self-Driving”, also known as “FSD”, to give up on its original promise of delivering unsupervised autonomy.</p>



<p>Since 2016, Tesla has claimed that all its vehicles in production would be capable of achieving unsupervised self-driving capability.</p>



<p>CEO Elon Musk has claimed that it would happen by the end of every year since 2018.</p>



<p>Tesla has even sold a software package, known as “Full Self-Driving Capability” (FSD), for up to $15,000 to customers, promising that the advanced driver-assist system would become fully autonomous through over-the-air software updates.</p>	
	



<p>Almost a decade later, the promise has yet to be fulfilled, and Tesla has already confirmed that all vehicles produced between 2016 and 2023 don’t have the proper hardware to deliver unsupervised self-driving as promised.</p>



<p>Musk has been discussing the upgrade of the computers in these vehicles to appease owners, but there’s no concrete plan to implement it.</p>



<p>While there’s no doubt that Tesla has promised unsupervised self-driving capabilities to FSD buyers between 2016 and 2023, the automaker has since updated its language and now only sells “Full Self-Driving (Supervised)” to customers:</p>



<figure><img decoding="async" width="630" height="694" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png 630w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png?resize=136,150 136w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png?resize=272,300 272w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png?resize=318,350 318w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png?resize=140,154 140w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.07.54-PM.png?resize=150,165 150w" sizes="(max-width: 630px) 100vw, 630px"></figure>



<p>The fine print mentions that it doesn’t make the vehicle “autonomous” and doesn’t promise it as a feature. </p>



<p>In other words, people buying FSD today are not really buying the capability of unsupervised self-driving as prior buyers did.</p>



<p>Furthermore, Tesla’s board has just submitted <a href="https://electrek.co/2025/09/05/tesla-tsla-board-fully-loses-its-mind-and-offers-elon-musk-a-pay-package-worth-up-to-1-trillion/">a new</a><span><a href="https://electrek.co/2025/09/05/tesla-tsla-board-fully-loses-its-mind-and-offers-elon-musk-a-pay-package-worth-up-to-1-trillion/" target="_blank">, unprecedented CEO compensation package for shareholders’ approval, which could give Musk up to $1 trillion</a>&nbsp;in stock options pending</span> the achievement of certain milestones.</p>



<p>One of these milestones is Tesla having “10 Million Active FSD Subscriptions.”</p>



<p>At first glance, this would be hopeful for FSD buyers since part of Musk’s compensation would be dependent on delivering on the FSD promises.</p>



<p>However, Tesla has changed the definition of FSD in the compensation package with an extremely vague one”</p>



<blockquote>
<p>“FSD” means an advanced driving system, regardless of the marketing name used, that is capable of performing transportation tasks that provide autonomous or similar functionality under specified driving conditions.</p>
</blockquote>



<p>Tesla now considers FSD only an “advanced driving system” that should be “capable of performing transportation tasks that prove autonomous or similar functionality”.</p>



<p>The current version of FSD, which requires constant supervising by the driver, could easily fit that description.</p>



<p>Therefore, FSD now doesn’t come with the inital promise of Tesla owners being able to go to sleep in their vehicles and wake up at their destination – a promise that Musk has used to sell Tesla vehicles for years.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>The way Tesla discusses autonomy with customers and investors versus how it presents it in its court filings and legally binding documents is strikingly different.</p>



<p>It should be worrying to anyone with an interest in this.</p>



<p>With this very vague description in the new CEO compensation package, Tesla could literally lower the price of FSD and even remove base Autopilot to push customers toward FSD and give Musk hundreds of billions of dollars in shares in the process.</p>




	<p>There’s precedent for Tesla decreasing pricing on FSD. Initially, Musk said that Tesla would gradually increase the price of the FSD package as the features improved and approached unsupervised autonomy.</p>



<p>That was true for a while, but then Tesla started slashing FSD prices, which are now down $7,000 from their high in 2023:</p>



<figure><img loading="lazy" decoding="async" height="577" width="1024" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png 1818w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=150,84 150w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=300,169 300w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=768,433 768w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=1024,577 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=1536,865 1536w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=350,197 350w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=140,79 140w, https://electrek.co/wp-content/uploads/sites/3/2025/09/Screenshot-2025-09-05-at-2.33.55-PM.png?resize=1600,901 1600w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure>



<p>The trend is quite apparent and coincidentally began when Tesla’s sales started to decline.</p>



<p>FSD is now a simple ADAS system without any promise of unsupervised self-driving. This might quite honestly be one of the biggest cases of false advertising or bait-and-switch ever.</p>
	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Universe Within 12.5 Light Years (174 pts)]]></title>
            <link>http://www.atlasoftheuniverse.com/12lys.html</link>
            <guid>45144337</guid>
            <pubDate>Fri, 05 Sep 2025 22:20:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.atlasoftheuniverse.com/12lys.html">http://www.atlasoftheuniverse.com/12lys.html</a>, See on <a href="https://news.ycombinator.com/item?id=45144337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h3>About the Map</h3><p>
This map shows all the star systems that lie within 12.5
light years of our Sun.  Most of the stars are red dwarfs - stars with a tenth of
the Sun's mass and less than one hundredth the luminosity.  Roughly eighty percent
of all the stars in the universe are red dwarfs, and the nearest star - Proxima - is
a typical example.
</p></div><p>
Epsilon Eridani is orbited by a large planet which might look like this.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nest 1st gen and 2nd gen thermostats no longer supported from 10/25/2025 (252 pts)]]></title>
            <link>https://community.hubitat.com/t/nest-1st-gen-and-2nd-gen-thermostats-no-longer-supported-by-google-from-10-25-2025/152952</link>
            <guid>45143879</guid>
            <pubDate>Fri, 05 Sep 2025 21:33:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.hubitat.com/t/nest-1st-gen-and-2nd-gen-thermostats-no-longer-supported-by-google-from-10-25-2025/152952">https://community.hubitat.com/t/nest-1st-gen-and-2nd-gen-thermostats-no-longer-supported-by-google-from-10-25-2025/152952</a>, See on <a href="https://news.ycombinator.com/item?id=45143879">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Nest 1st gen and 2nd gen thermostats no longer supported by Google from 10/25/2025">
      
      <meta itemprop="datePublished" content="2025-04-25T20:48:00Z">
        <meta itemprop="articleSection" content="Integrations">
      <meta itemprop="keywords" content="nest">
      


          <div itemprop="text" id="post_1">
              <p>I just received an email from Google stating that they are no longer it's going to support the Nest 1st gen and 2nd gen thermostats. While they will continue to operate locally, it appears that they will no longer work with the Nest app or Home app controls. I currently use the Nest app to control the thermostats, but does this mean that we won't even be able to control the thermostats via a Hubitat integration?</p>
<p>Cheers,<br>
Simon</p>
            </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/Gergor"><span itemprop="name">Gergor</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-27T21:55:29Z">
                    April 27, 2025,  9:55pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-27T21:55:29Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <p>I got email too. WHat a bummer. It says the API will be removed, so my guess is unless someone comes up with a heck, there's no way to interact with the thermostat other than thru the physical dial.</p>

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/aaiyar"><span itemprop="name">aaiyar</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-27T22:41:23Z">
                    April 27, 2025, 10:41pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-27T22:41:23Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/simon5"><span itemprop="name">simon5</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-28T13:00:44Z">
                    April 28, 2025,  1:00pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-28T13:00:44Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <p>Thanks. That's so annoying. I have 8 Nest thermostats in my house and will have to replace them all.</p>

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/aaiyar"><span itemprop="name">aaiyar</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-28T13:04:02Z">
                    April 28, 2025,  1:04pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-28T13:04:02Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              <p>If you have relatively simple HVAC systems (eg. 1H/1C, or single-stage HP with 1 AUX stage), consider getting locally controlled zigbee/z-wave thermostats.</p>
<p>You could also get ecobee thermostats that can be controlled locally, if you are also using Home Assistant.</p>
            </div>

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/GuyMan"><span itemprop="name">GuyMan</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-28T14:32:36Z">
                    April 28, 2025,  2:32pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-28T14:32:36Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>The latest Nests (from 2020 on - G3 or greater?) now support local Matter - So that's a long term option that's not cloud dependant.   That all said, I certainly understand if you don't want to go back to the well with Google/Nest</p>


            </div>

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/jason12"><span itemprop="name">jason12</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-28T19:57:10Z">
                    April 28, 2025,  7:57pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-28T19:57:10Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>G4 or the 'E'. G3 is not matter compatible currently, and i dare say Google will probably never do it. Sadly, the G4 was only released in the US - those of us in Europe are a bit stuck!</p>

            

          </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/nclark"><span itemprop="name">nclark</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-28T20:28:57Z">
                    April 28, 2025,  8:28pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-28T20:28:57Z">
              <span itemprop="position">8</span>
              </span>
            </p>
            <p>Planned obsolescence is exactly this, that is the first reason why you never buy anything that needs the internet to function the way you want it to function. If you do buy it, be sure this will happen and more than less in the coming years, it's either this sh!t or the now ever so popular pay a monthly fee. YOU OWN NOTHING AND WE OWN YOU</p>

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I have 5 2nd gen Thermostats. Not a fan of shelling out $1k to get them all replaced.</p>

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/simon5"><span itemprop="name">simon5</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-29T14:54:33Z">
                    April 29, 2025,  2:54pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-29T14:54:33Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            <div itemprop="text">
              <p>These replies are all really helpful, thank you! I just checked and I have 9 Gen 1 and 2 Nest thermostats, all of which I will need to replace if I want to control them remotely (which I do). Google have offered the Gen 4 thermostats for $150 each, but I don't want to be in the same position as I am now if Google stop supporting them in the future. Is this a concern, or are we saying that these Gen 4 thermostats will ALWAYS be able to be controlled via the Hubitat hub?  If not, what other thermostats do you all recommend that are more futureproof?</p>
<p>Cheers<br>
Simon</p>
            </div>

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/GuyMan"><span itemprop="name">GuyMan</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-29T17:25:12Z">
                    April 29, 2025,  5:25pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-29T17:30:42Z">
              <span itemprop="position">11</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Yes, theoritically this - Assuming your using Matter as the interface protocol.  That said, I think the support for matter T-Stats is fairly limited, setpoints, on/off, mode, and current temps, that's about it.</p>
<p>But you should definitely read the following threads - There is a HE built in Googe Nest Thermostat driver available - But some questions to be considered are:</p>



<p>Hence my comment above about "the technically" are supported, but <a href="https://community.hubitat.com/u/bcopeland">@bcopeland</a> would have to weigh in on what works, and what's actually exposed on the matter side.  - But yes, after provisioning (setup), Matter is all local (so no Google cloud dependancy).  The second thread mentioned above, has a good screenshot at the top that shows what the Matter driver exposes.</p>
<p>Regardless, I would just buy 1 and test (with a site with a good return policy), before going "all in", but obviously, YMMV</p>
            </div>

            

          </div>
          <div itemprop="comment" id="post_12" itemscope="" itemtype="http://schema.org/Comment">
              
<p>If always having local control over your thermostat while maintaining full functionality while being able to control remotely I can't recommend enough getting the Ecobee thermostats and setting up an instance of Home Assistant on a RPi or a cheap second hand computer.</p>
<p>Then through the Homekit Device integration in HA you connect the Ecobee via the Homekit code.  (Just connect the Ecobee to your wifi first, not the Homekit app).</p>
<p>Then using the Home Assistant Device Bridge you can bring in any amount of entities you want of your thermostats into Hubitat and have full use of them.  You can write all your rules/automations in Hubitat.</p>
<p>Then if wifi support is dropped by Ecobee you will always have local control.  The benefit of this above matter is you will have every function you would have through the Ecobee app.  Unless you didn't bring them all over and that choice is yours.</p>
            </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/simon5"><span itemprop="name">simon5</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-29T21:58:48Z">
                    April 29, 2025,  9:58pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-29T21:58:48Z">
              <span itemprop="position">13</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Thank you both! It looks as though the Nest integration is a bit messy/painful and could have limited functionality. I have Ecobee thermostats in another house and I haven't had any trouble with them, so while IMO they don't look as cool or feel as good as the Nest thermostats, it sounds as though they are currently more reliable.</p>
<p><a href="https://community.hubitat.com/u/aaiyar">@aaiyar</a> I have a Hubitat C8-Pro, but are you saying that I can't just pair the Ecobees with the Hubitat and I need to run a RaspberryPi to somehow connect the Ecobees to the Hubitat? I'm afraid I don't have the time right now to play around with it and just need thermostats that can connect to and be controlled by the Hubitat.</p>
<p>EDIT: this article appears to say I can just connect the Ecobees directly to the Hubitat: <a href="https://docs2.hubitat.com/en/apps/ecobee-integration" rel="noopener nofollow ugc">Ecobee Integration | Hubitat Documentation</a></p>
            </div>

            

          </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/aaiyar"><span itemprop="name">aaiyar</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-29T22:17:05Z">
                    April 29, 2025, 10:17pm
                  </time>
                  <meta itemprop="dateModified" content="2025-04-29T22:17:05Z">
              <span itemprop="position">14</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>You can. Using the cloud integration you linked to.</p>
<p>If you want a local (non-cloud) integration, then you have to include Home Assistant in the mix.</p>
            </div>

            

          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/simon5"><span itemprop="name">simon5</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-30T00:17:11Z">
                    April 30, 2025, 12:17am
                  </time>
                  <meta itemprop="dateModified" content="2025-04-30T00:17:11Z">
              <span itemprop="position">15</span>
              </span>
            </p>
            <p>Ah thanks. So I could run the ecobee thermostats with the cloud integration for now and then in a few years time if ecobee stop supporting the cloud integration then I could run a local instance of HA and still be able to control my thermostats via habita?</p>

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.hubitat.com/u/aaiyar"><span itemprop="name">aaiyar</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-04-30T03:03:30Z">
                    April 30, 2025,  3:03am
                  </time>
                  <meta itemprop="dateModified" content="2025-04-30T03:03:30Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <p>Might be easier in a few years when ecobee adds Matter compatibility to their products.</p>

            

          </div>
          <div id="post_17" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Having been burned by Google on their Nest Secure and Nest Protect offerings, I fear it is only a matter of time before they end of life their Nest 3rd generation thermostat. So I have already been researching it's replacement.  Take a look at Go Control z-wave thermostat. Looks promising and it is natively supported in Hubitat.  Plus we won't be bugged by Google into ceeding our autonomy to the utility company over the environmental settings.  I have not which it why they bug me about it.  Do not believe Google about being always being able to override their remote adjustments. A lesson I learned by reading complaints from users in California. Seems the state declared a grid emergency so commanded participant devices to set to much higher cooling temperatures. Ok fine but also locked out any ability to change it back. A "feature" Google never mentions and a permanent deal breaker for me.</p>

            

          </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Hopefully Ecobee comes out with a matter solution before October.</p>

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I kissed comment culture goodbye (193 pts)]]></title>
            <link>https://sustainableviews.substack.com/p/the-day-i-kissed-comment-culture</link>
            <guid>45143077</guid>
            <pubDate>Fri, 05 Sep 2025 20:11:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sustainableviews.substack.com/p/the-day-i-kissed-comment-culture">https://sustainableviews.substack.com/p/the-day-i-kissed-comment-culture</a>, See on <a href="https://news.ycombinator.com/item?id=45143077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>It started out harmlessly, a comment on hacker news roughly 16 years ago. </p><p>From there it expanded to reddit, substack, twitter. And it increased in frequency, from every few months to every week, peaking at several times a day. It became an addictive, productive habit—I would scan the headlines for a catchy title, quickly skim the piece, and then race to the comment section and type one out. </p><p>Sometimes the comments were insightful or funny. At other times, curt or nitpicky. It was an exercise of logic, of ideation, of debate. It was a mix of disdain, delight and discourse. But mostly it was just a fun time. </p><p>Being an active commenter felt like being an internet socialite, part of an elite society of people who put their voice out there instead of lurked. And my fellow internet socialites responded in turn. Some upvoted, responded, debated. Some liked what I said, some hated it. A few of my comments made it to the top and became a fountain of dopamine. A few comments made it to the very bottom too. </p><p>That can happen with 16 years of commenting history. </p><p>I’ve benefited incredibly from commenting. It has sharpened both my writing and logic. It has developed my voice. It has trained me in debate. It has unleashed personas that I would otherwise never become—teacher, supporter, economist, historian, debater, and of course, troll. </p><p>It has made me a (mostly) better person. But I cannot shake the conviction that I need to leave commenting for good.</p><p>Why? Well, I’ve been reflecting on what I want out of the internet (as part of a larger reflection of what I want out of life). I’ve always enjoyed the internet as the frontier of  “new”—its where I find novel ideas, content, thoughts, personalities, achievements and craft. But with the rise of doom scrolling, media echo chambers, AI, and my age, “new” is no longer that exciting. I find myself less satisfied browsing the internet, hoping the next thing I consume to be actually high quality, and I’m realizing that I’d rather just spend my time with a good set of quality friends. </p><p>Unfortunately, this is where comment culture comes in. 16 years of commenting has made me zero friends. </p><p>That scares me. All of that social activity with zero ROI. At first, I thought that I needed to change my commenting habits, and, you know, try to make connections. But the more I considered how to make friends in comment culture, the more I realized that it wasn’t just my own social ineptitude. Comment culture has a problem. Systemically, it produces an internet of strangers.</p><p>Now, making friends in real life is not easy and it doesn’t get easier over time. The social steps of growing your friend pool involve 1) meeting new people, 2) turning strangers into acquantainces, and 3) turning acquantainces into friends. This takes a surprising amount of volume and time. </p><p>Various estimates of lifetime human acquantainces range from 10,000 to 80,000 people, but actual friendships number only in the hundreds, and that’s being generous. And the number of close friends is on average, only 3-5. So, meeting strangers and turning them into close friends is a rather rare occurence that involves a serious investment of focused social energy, something that is harder to do the older you get. One study showed that in order to form a close friendship, you need to spend 200 hours of interaction time with one person. So, making 5 close friends is a 1000 hour investment, equal to a full time job for half a year. </p><p>Comment culture requires your social energy. It’s an interaction with another human being, but one that doesn’t head towards building relationships. Instead, the end result is gaining reputation, fame, and of course, internet points.</p><p>This isn’t a bad thing; besides close friends, the other spend of social energy is towards reputation and influence, especially in small communities. But in comment culture, each post is its own communal space of random strangers. It is the illusion of small community, but really the community appears and dissappears with every new post. Outside of a handful of celebrities or moderators, I rarely find myself spotting someone I know in the comments. </p><p>The end result is that comment culture is a series of one-offs with anonymous strangers upvoting you or responding to you, but never befriending you. In comment culture, you are talking to a random sampling of everybody, which is in itself a collective nobody.</p><p>Broadly speaking, the online platforms we use are not built for connection; they are built for engagement. This is universally true for all internet spaces, from stories to newsfeeds, for the intellectual and the plebian alike. And in the relentless optimization of user engagement, our social engagement is captured and rerouted from its original purpose. Instead of making friends, we are all performing for one collective internet stranger—a being that is sometimes brilliant, sometimes cruel, but always waiting to be impressed.</p><p>It somehow feels like interactions that might have grown a friendship have instead ended up growing ad impressions. This is not strictly true, but I can’t shake the feeling that it isn’t wrong either.</p><p>So this is where I say goodbye to my fellow comment writing socialites. I might miss you a bit, but you will not miss me, because you don’t even know me. I'm a stranger, and you, dear reader, are likely a stranger too. </p><p>Where do I go instead? Well, as long as engagement makes money, the pressure will always be there, from forces far bigger than us, to pull our social instincts out into the open forum where they can be measured, tracked, and sold. This isn’t a problem with comments or our internet spaces. Its a problem of market forces.</p><p>But as long as we want to make and keep good friends, that itself is its own driving force. It’s what drives us to gather a group of people around a campfire. It revives LAN parties from the childhood days. It creates those long chains of memes sent to the few that truly appreciate them. It builds its own spaces not bound to one platform or another, but bound to the people know, care for, and love.</p><p>But… knowing me, I’ll probably be on Discord.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic agrees to pay $1.5B to settle lawsuit with book authors (701 pts)]]></title>
            <link>https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&amp;smid=url-share</link>
            <guid>45142885</guid>
            <pubDate>Fri, 05 Sep 2025 19:52:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&#x26;smid=url-share">https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&#x26;smid=url-share</a>, See on <a href="https://news.ycombinator.com/item?id=45142885">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&smid=url-share: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[My Own DNS Server at Home – Part 1: IPv4 (158 pts)]]></title>
            <link>https://jan.wildeboer.net/2025/08/My-DNS-Part-1/</link>
            <guid>45142397</guid>
            <pubDate>Fri, 05 Sep 2025 19:08:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jan.wildeboer.net/2025/08/My-DNS-Part-1/">https://jan.wildeboer.net/2025/08/My-DNS-Part-1/</a>, See on <a href="https://news.ycombinator.com/item?id=45142397">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        <p><strong>“It’s always DNS” is a famous meme among network people. Name resolution is technically quite simple. It’s “just” translating a hostname like <code>jan.wildeboer.net</code> to an IP address. What could possibly go wrong? I am a radical optimist and detail-obsessed knowledge collector, so I decided to find out. As part of my goal to make my home network a little island of Digital Sovereignty, meaning that everything at home should JustWork™, even with no working internet connection, a DNS server is needed.</strong></p>

<blockquote>
  <p>Based on and extended from my gist <a href="https://codeberg.org/jwildeboer/gists/src/branch/main/2025/20250826DNSHomelabBind9.md">Bind on Fedora 42 as DNS server</a>.</p>
</blockquote>

<p>I admit, I have a lot of experience with DNS and BIND. But I still consider myself to be merely on the GoodEnough™ side of things. I know how to get DNS configured for my domains. And I want you to feel fearless too. The best place to fail with DNS is the network at home. It limits the impact :)</p>

<p>So read this blog post either as report or as a HOWTO. Both ways can be fun!</p>

<p>In my homelab I have a Raspberry Pi 4 that runs infrastructure services. DNS is one of them, my private CA (Certificate Authority) another. The CA runs as a container on Podman. For DNS I use Bind. It thus has to serve 3 networks:</p>

<ul>
  <li><code>192.168.1.0/24</code> My home IPv4 network</li>
  <li><code>172.16.0.0/16</code> IPv4 Network on the second ethernet ports of my homelab servers</li>
  <li><code>10.88.0.0/16</code> The (virtual) podman network</li>
</ul>

<p>It uses my Fritz box (7490) as forwarder, so I can resolve all hosts, including the DHCP entries that the Fritz Box hands out under its default local domain name <code>fritz.box</code>. For my homelab however, I use the <code>homelab.jhw</code> domain name. That’s what the Bind DNS server has to take care of.</p>

<blockquote>
  <p><strong>WARNING</strong> <br>
I really should use the official <code>.internal</code> TLD (Top Level Domain) for my homelab network, but I decided against it. This introduces the risk of name resolution problems, should someone offer a public <code>.jhw</code> TLD in future. It’s a risk I am willing to accept in exchange for using a 3 letter TLD at home. Don’t be like me! Use <code>.internal</code> instead. With that out of the way, let’s continue.</p>
</blockquote>

<h2 id="what-we-well-i-have">What we (well, I) have</h2>

<p>Let’s gather what I have in my home network.</p>

<ul>
  <li><code>inf01.homelab.jhw</code> at <code>192.168.1.10</code>: A Raspberry Pi 4 4GB, running Fedora 42 and podman with my Certificate Authority as a container that should be reachable as <code>ca.homelab.jhw</code>. See <a href="https://jan.wildeboer.net/2025/07/letsencrypt-homelab-stepca/">Be the LetsEncrypt in your homelab with step-ca</a> for more details.</li>
  <li>3 ThinkCentre Tiny PCs in the <code>homelab.jhw</code> zone, called hl01 (<code>192.168.1.11</code>), hl02 (<code>192.168.1.12</code>) and hl03 (<code>192.168.1.13</code>), running RHEL10 (Red Hat Enterprise Linux)</li>
  <li>A Fritz Box 7490 at <code>192.168.1.254</code></li>
</ul>

<h2 id="lets-install-bind-on-inf01">Let’s install BIND on inf01</h2>

<p>We need to do two things. Install BIND and some utilities on <code>inf01</code> and open the firewall for DNS traffic.</p>

<div><pre><code>dnf install bind bind-utils
firewall-cmd --add-service=dns --permanent
</code></pre></div>

<p>That was easy enough :)</p>

<h3 id="configure-bind">Configure BIND</h3>

<p>To run BIND in the correct way, we need to work on 3 configuration files.</p>

<ul>
  <li><code>/etc/named.conf</code> The main configuration file where we tell BIND on which networks it should listen and what zones it will serve.</li>
  <li><code>/var/named/forward.homelab.jhw</code> The forward zone file that maps hostnames in the <code>homelab.jhw</code> domain to IP addresses on my home network</li>
  <li><code>/var/named/reverse.homelab.jhw</code> The reverse zone for the <code>192.168.1.0/24</code> network range, that looks a bit confusing, that does the opposite. It maps IP addresses to hostnames.</li>
  <li><code>/var/named/reverse2.homelab.jhw</code> The second reverse zone for the <code>172.16.0.0/16</code> network range.</li>
</ul>

<p>Let’s start with <code>/etc/named.conf</code>.</p>

<div><pre><code>//
// named.conf
//

options {
  listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
  listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
  allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };

  directory       "/var/named";

  dump-file       "/var/named/data/cache_dump.db";
  statistics-file "/var/named/data/named_stats.txt";
  memstatistics-file "/var/named/data/named_mem_stats.txt";
  secroots-file   "/var/named/data/named.secroots";
  recursing-file  "/var/named/data/named.recursing";

  forwarders { 192.168.1.254; };
  recursion yes;

  dnssec-validation no;

  managed-keys-directory "/var/named/dynamic";
  geoip-directory "/usr/share/GeoIP";

  pid-file "/run/named/named.pid";
  session-keyfile "/run/named/session.key";

  /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */
  include "/etc/crypto-policies/back-ends/bind.config";
};

logging {
        channel default_debug {
                file "data/named.run";
                severity dynamic;
        };
};

zone "." IN {
	type hint;
	file "named.ca";
};

zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};

include "/etc/named.rfc1912.zones";
include "/etc/named.root.key";
</code></pre></div>

<p>The first block declare the general options. Yes, it looks complicated and it is, but let’s walk you through every relevant line (the lines not mentioned are default entries that don’t need to be changed).</p>

<div><pre><code>listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };
</code></pre></div>

<p>Here we tell BIND that it should listen for queries on port 53 on <code>localhost</code>, <code>192.168.1.10</code>, the IPv4 address in my hoem network, <code>172.16.1.10</code>, the second IPv4 address configured and <code>10.88.0.1</code>, the virtual IPv4 address the Raspberry uses to bridge to the local podman containers.</p>

<p>The second line does the same for IPv6, but that is something we will discuss in Part 2.</p>

<p>The third line tells BIND from whom to accept queries. Essentially from everyone on the three IPv4 networks we are listening to.</p>



<p>This is the directory where BIND will look for its zone files, that we will define later.</p>

<div><pre><code>forwarders { 192.168.1.254; };
recursion yes;
</code></pre></div>

<p>Now what if someone asks for a hostname that is outside of <code>homelab.jhw</code>? In that case we tell BIND to forward that question to <code>192.168.1.254</code>, our Fritz Box. We will allow recursion and cache results we get from our Fritz box to avoid unneeded traffic.</p>



<p>Our simple setup will not bother with DNSSEC at the moment. Maybe we will have a Part 3 for that.</p>

<p>OK. That was the options part. We will ignore the <code>logging</code> part and the <code>zone "." IN</code> block.</p>

<p>Next (and finally) we define three zone entries (and zone files). A forward zone called <code>homelab.jhw</code> for our domain and two reverse zones for the IP addresses in the <code>192.168.1.0/24</code> range called <code>1.168.192.in-addr.arpa</code>. Yep. That’s 192.168.1 reversed. 1.168.192. That’s why it’s called the reverse zone ;) We also have <code>16.172.in-addr.arpa</code> for the <code>172.16.0.0/16</code> range. Let’s look at them.</p>

<div><pre><code>zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};
</code></pre></div>

<p>It’s a zone, all right. It’s the <code>master</code> for this zone, meaning that this DNS server will be the Source of Truth to  answer all queries for the <code>homelab.jhw</code> hostnames.</p>

<p>The exact mapping of all hostnames to IP addresses is in a file called <code>forward.homelab.jhw</code> in the directory <code>/var/named</code>. Remember how we defined that path at the beginning in the <code>options</code> part? Great! We also tell BIND that we do not allow dynamic updates for this zone, meaning that what’s in the file is all we will look at. Finally we tell BIND that any machine in the network is allowed to ask for a reply.</p>

<div><pre><code>zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};
</code></pre></div>

<p>The reverse zones with the weird looking zone names are almost the same, except that we define these in two files called <code>reverse.homelab.jhw</code> for the reverse lookup of the <code>192.168.1.0/24</code> range and <code>reverse2.homelab.jhw</code> for the <code>172.16.0.0/16</code> range. Why these zones have weird names will be explained later.</p>

<p>So now we go to the zone files!</p>

<h3 id="forward-zone-for-homelabjhw">Forward zone for homelab.jhw</h3>

<p>The forward zone resolves names to IP addresses using A records (and other types like TXT, CAA and many more exist, but we won’t cover that in this post). It also contains CNAME entries, if you have services on one machine that should be reachable via more than one hostnames. In my homelab the CA (Certificate Authority) server is a container that runs on <code>inf01.homelab.jhw</code>, but should be reachable as <code>ca.homelab.jhw</code> in the home network. The CNAME entry does exactly that. It tells clients that when they want to talk to <code>ca.homelab.jhw</code> they can. By actually talking to <code>inf01.homelab.jhw</code>.</p>

<p>Now here is the big, important lessen for zone files. They have a serial number. Which MUST be incremented with every change. If you don’t, weird things WILL happen. So:</p>

<blockquote>
  <p>NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. OR RISK DNS HELL.</p>
</blockquote>

<p><code>/var/named/forward.homelab.jhw</code></p>

<div><pre><code>$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10

inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13

ca              IN  CNAME inf01.homelab.jhw.

inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13
</code></pre></div>

<p>Again, let’s go through this.</p>



<p>The default Time To Live (TTL) for DNS entries is set at 3600 seconds. That’s 1 hour. This means that when a machine in the network gets a DNS reply, it will not ask again for the same thing until the TTL has passed.</p>

<div><pre><code>@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
</code></pre></div>

<p>The Start Of Authority (SOA) block. Here we say which DNS server is the owner of this domain. It’s <code>inf01.homelab.jhw.</code> (yes, that dot at the end is REALLY important). The <code>root.homelab.jhw</code> actually means <code>root@homelab.jhw</code> and is the email address responsible for this domain. Don’t think to much about why and what :)</p>

<div><pre><code>@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10
</code></pre></div>

<p>The first “real” DNS entries! They are special, as the <code>@</code> indicates, which means they represent the domain itself. We first define the nameserver (again? yes, don*‘t ask) as NS record. And right after that we define the <code>A</code> record as the IP address <code>192.168.1.10</code>.</p>

<p>Did you notice that <code>.</code> at the end of <code>inf01.homelab.jhw.</code>? That’s another VERY important thing. The TL;DR is that this final <code>.</code> tells DNS to stop doing fancy recursion and lookups. Just look for the hostname `inf01.homelab.jhw. Period. (pun intended). Don’t care too much about this. Just remember:</p>

<p><strong>EVERY HOSTNAME RECORD ENDS WITH A <code>.</code> YOU WILL FORGET THIS. YOU WILL FIX THIS.</strong></p>

<div><pre><code>inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13
</code></pre></div>

<p>Here come the <code>A</code> records for <code>192.168.1.0/24</code>! We finally get to map hostnames to IP addresses. For real! It now is quite self-explanatory, isn’t it? The hostname gets an A record that is the IP address in my local network. And as these are IP addresses, no <code>.</code> is needed at the end.</p>

<div><pre><code>ca              IN  CNAME inf01.homelab.jhw.
</code></pre></div>

<p>And here is the CNAME record. Which maps the hostname <code>ca.homelab.jhw</code> to the Canonical NAME (CNAME) <code>inf01.homelab.jhw.</code>. This is a hostname at the end! So it needs the <code>.</code> Period :)</p>

<div><pre><code>inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13
</code></pre></div>

<p>And here we create another set of <code>A</code> records for the same machines, but this time in the <code>172.16.0.0/16</code> range. This range is used for management stuff, hence the <code>-m</code>.</p>

<p>And that’s the gist of it. If you add a new machine to your network, configure it with an IP address (statically or with DHCP) and add it as an A record to the forward zone. Increment the serial and tell DNS to read the updated zone with <code>systemctl reload named</code>. Done.</p>

<h3 id="reverse-zones-for-1921681024-and-172160016">Reverse zones for 192.168.1.0/24 and 172.16.0.0/16</h3>

<p>The reverse zone maps IP addresses to hostnames. Often called the PTR or pointer record. You have to make sure that the entries here are synced to the forward zone.</p>

<blockquote>
  <p>NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. Or risk DNS hell.</p>
</blockquote>

<p>Here is the reverse zone for the <code>192.168.1.0/24</code> range.</p>

<p><code>/var/named/reverse.homelab.jhw</code></p>

<div><pre><code>$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082601  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10      IN  PTR         inf01.homelab.jhw.
11      IN  PTR         hl01.homelab.jhw.
12      IN  PTR         hl02.homelab.jhw.
13      IN  PTR         hl03.homelab.jhw.
</code></pre></div>

<p>As this is more or less the same but the other way round, I will not go through everything but instead explain the differences. It’s the reverse zone, so now we have <code>PTR</code> (pointer) entries that map an IPv4 address in the <code>192.168.1.0/24</code> range to hostnames. WITH A DOT AT THE END. DO NOT FORGET THE DOT!</p>

<p>As this is a /24 block, we only need to set the last digit of the IPv4 address.</p>

<p>You might wonder, where is <code>ca</code> here? Well, it’s CNAME is <code>info1.homelab.jhw</code> and that already is in this reverse zone. That is good enough. No separate entry needed.</p>

<p>We also need the reverse zone for the <code>172.16.0.0/16</code> range:</p>

<p><code>/var/named/reverse2.homelab.jhw</code></p>

<div><pre><code>$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082901  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10.1      IN  PTR         inf01-m.homelab.jhw.
11.1      IN  PTR         hl01-m.homelab.jhw.
12.1      IN  PTR         hl02-m.homelab.jhw.
13.1      IN  PTR         hl03-m.homelab.jhw.
</code></pre></div>

<p>Looks deceivingly similar. But there is a big difference. This is a /16 network, so we have to define the last two parts of the IPv4 address. And as it is a reverse zone file, yep, we have to reverse it. So now we need <code>10.1</code> to define the entry for <code>172.16.1.10</code>, which is the hostname <code>inf01-m.homelab.jhw</code>. WITH THE DOT AT THE END. AND DID YOU UPDATE THE SERIAL? :)</p>

<p>Phew. That’s the config done!</p>

<p>A final check with the <code>named-checkconf</code> command, which should say nothing when all files are OK. If not, it will tell you what is wrong so you get the chance to fix stuff. You did add all the <code>.</code> at the end of hostnames and you did update the serial of that zone file after you made changes, yes?</p>

<h2 id="start-bind">Start Bind</h2>

<p>The only thing remaining is to start BIND. And persist it as a service, so it starts after every boot. It’s DNS. It must always be available.</p>

<div><pre><code>systemctl <span>enable </span>named
systemctl start named
</code></pre></div>

<p>You most likely will make typos in your config. So do check with <code>named-checkconf </code> and <code>systemctl status named</code> and <code>journalctl -u named</code>. If something breaks, read this whole entry again. Find that missing <code>.</code> in a zone file. Increment the <code>serial</code> that you forgot to do. You will get there. Don’t give up!</p>

<h2 id="result">Result</h2>

<p>Machines, containers etc can now be resolved in my home network. All with mow own DNS! Yay!</p>

<div><pre><code>% nslookup jhwfritz.fritz.box
Server:		192.168.1.10
Address:	192.168.1.10#53

Non-authoritative answer:
Name:	jhwfritz.fritz.box
Address: 192.168.1.254

% nslookup ca.homelab.jhw    
Server:		192.168.1.10
Address:	192.168.1.10#53

ca.homelab.jhw	canonical name <span>=</span> inf01.homelab.jhw.
Name:	inf01.homelab.jhw
Address: 192.168.1.10
</code></pre></div>

<p>And now you should be able to <code>ping</code> the machines with their hostname. ssh into them. Get certificates with the CA that runs in the podman container. Life is good!</p>

<p>I hope you enjoyed this post and could learn something new! Feel free to comment or send corrections vie the Toot linked below that collects the comments!</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making a font of my handwriting (266 pts)]]></title>
            <link>https://chameth.com/making-a-font-of-my-handwriting/</link>
            <guid>45141636</guid>
            <pubDate>Fri, 05 Sep 2025 18:06:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chameth.com/making-a-font-of-my-handwriting/">https://chameth.com/making-a-font-of-my-handwriting/</a>, See on <a href="https://news.ycombinator.com/item?id=45141636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>
            Recently I’ve been on a small campaign to try to make my personal website more… personal. Little ways to
            make it obvious it’s <em>mine</em> and <em>personal</em>, not just another piece of the boring corporate
            dystopia that is most of the web these days. I don’t quite want to fully regress to the Geocities era and
            fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.
          </p>
          <p>
            I’d added some bits and pieces along those lines: floating images in articles now look like they’re stuck to
            the page with sellotape, related post links have a wavy border that animates when you hover over them, and
            so on. Next, I wanted to change the heading fonts from a monospace font to something cursive, to resemble
            handwriting. Less terminal output, more handwritten letter. I couldn’t find one I liked, though. So why not
            make my own? It can’t be that hard, right?
          </p>
          <h3>Failing to do it myself</h3>
          <p>
            I set out to try to make the font myself using open source tools. After doing a bit of research, it seemed
            like the general approach was to create vectors of each character and then import them into a font editor.
            That seems to mean either Adobe Illustrator and FontLab (if you have too much money) or Inkscape and
            FontForge (if you like open source). I fall firmly into the latter category, so I grabbed my graphics tablet
            and opened Inkscape.
          </p>
          <p>
            I wrote out my first three letters: capital A, B and C. Saved them in Inkscape, and attempted to import them
            into FontForge. Then I remembered one crucial thing that had slipped my mind: I absolutely loathe using
            FontForge. It’s a bit like when you open an old version of GIMP and get a bunch of weird looking windows
            floating all over the place; it feels like you’re fighting against the tool to do even the most basic
            operations. The difference is I have cause to edit images a <em>lot</em> more than I edit fonts, and GIMP
            has actually significantly improved their UI over the years.
          </p>
          <p>Here are the rough steps I went through with FontForge:</p>
          <ol>
            <li>Launch Font Forge. It shows a weird bit of art in one window, and an open file dialog in another.</li>
            <li>I don’t want to open a file, so I close that dialog. The program exits.</li>
            <li>Relaunch Font Forge, and realise that within the “Open Font” dialog is a “New” button. Click it.</li>
            <li>
              Get to the standard font-editing UI. Right-click on the “A” looking for a way to import an SVG. Don’t see
              one.
            </li>
            <li>
              Click around a bit, exploring the menus. Everything feels a bit off. You can’t open one menu then hover
              over the next to see its content, like basically every UI toolkit in existence. I think FontForge has
              eschewed QT and GTK in favour of doing things itself.
            </li>
            <li>Find the “Import” option in the File menu. Hope it’s for a single glyph not the whole font.</li>
            <li>
              A file picker opens. Again it’s all a bit off from normal desktop conventions. Try to resize it, and just
              get blank gray space at the bottom.
            </li>
            <li>Type the absolute path I want to go to in the text field.</li>
            <li>Get a dialog saying “Not a bdf file /home/chris/etc”. Press OK.</li>
            <li>Get a dialog saying “Could not find a bitmap font in”. Press OK.</li>
            <li>
              Press Ctrl+L to see if that lets me enter a path. Click everything in the dialog to try to find a way to
              enter a path. Get annoyed. Give up. Click through folder-by-folder to get to where I want to be.
            </li>
            <li>
              Get to the folder and don’t see any files. Change the format to “SVG”. Double-click the newly-visible SVG
              file.
            </li>
            <li>Get a dialog saying “You must select a glyph before you can import an image into it”. Press OK.</li>
            <li>The import dialog goes away, having not imported.</li>
            <li>Select the glyph in the main tool area, then repeat the File→Import dance.</li>
            <li>
              It’s actually there now! Open the glyph in the editor and see it’s a complete mess of Bézier curves. I
              can’t click what I want without accidentally moving a handle for an adjacent curve.
            </li>
            <li>Rage-quit.</li>
          </ol>
          <p>
            I’m sure FontForge is less anger inducing once you’re used to it. And you definitely could use it to build a
            font like this if you had much more patience than me. I’d had enough of death-by-a-thousand-paper-cuts
            though.
          </p>
          <p>
            I briefly tried Inkscape’s built-in support for making an SVG font. It annoyed me a lot less, but it’s
            fiddly: it seemed like each font had to be a single path, so you had to convert the glyphs to paths, then
            merge them correctly. If you merge them incorrectly then the wrong bits of your letters end up filled (like
            the inside of the ‘B’). Path manipulation is getting towards the limit of my knowledge of vector editing,
            and it took a bit of trial and error for each letter that had more than a single stroke. I didn’t fancy
            doing that for every letter.
          </p>
          <p>
            I’m usually a big advocate of open source, but this was one of those painful times where it feels like it
            just falls short. Clunky, painful UI and processes where commercial tools just let you get on with your
            work.
          </p>
          <h3>You can exchange money for goods and services</h3>
          <p>
            When I’d been looking for open source tutorials, I found many mentions of a closed source, hosted tool:
            <a href="https://www.calligraphr.com/en/">Calligraphr</a>. It has a free version with limitations (no
            ligatures, no variations, 75 glyphs per font), and a pro version for £8/month. I’d normally balk at the idea
            of a subscription for this, but they have the perfect answer: you can make a one-time payment, and your
            account automatically downgrades back to free after a month. It’s not a hidden option, either, it’s the most
            prominent button on the upgrade page. That made me happy to give them £8 to play around with the service for
            a month.
          </p>
          <p>
            Calligraphr works by having you print templates, write out the letters, then scan them in. It does some
            magical processing to extract the glyphs, provides tools to tidy them up, align them, etc, and then produces
            a TTF file for you. You can see some of my completed templates here:
          </p>
          <figure>
            <picture>
              <source srcset="https://chameth.com/making-a-font-of-my-handwriting/template.avif" type="image/avif">
              <source srcset="https://chameth.com/making-a-font-of-my-handwriting/template.webp" type="image/webp">
              <img src="https://chameth.com/making-a-font-of-my-handwriting/template.jpg" alt="Eight scanned template sheets, filled in with handwritten letters and ligatures" loading="lazy" width="1166" height="841">
            </picture>
            <figcaption>Most of the templates I used for the font</figcaption>
          </figure>
          <p>
            Calligraphr has a nice UI to generate the templates, allowing you to select which glyphs to include. I added
            the “minimal English”, “basic punctuation” and “Ligatures” sets. That gave me four pages to fill out, and I
            did them all twice. That let me filter out versions that didn’t work well, and have variants for some
            letters so the font wasn’t too repetitive. Later on, I went back and added some custom ligatures based on
            blog post titles that didn’t look quite right: “Re”, “To”, “ers”, “ey”, “hy”, “ra”, “re” and “ty”. Ligatures
            like this help it look more natural: when we write we don’t just stamp out identical letters regardless of
            their surroundings, instead they will connect to their neighbours, or overlap slightly, or even share a
            stroke.
          </p>
          <p>
            I filled these templates in with a Sharpie, as I wanted a fairly informal, scrap-booky look, and it would
            also give good solid shapes that should be easy to pick out of the template. I scanned them with the “Scan
            Document” function on my iPhone, and uploaded the PDFs to Calligraphr.
          </p>
          <h3>Iterating and tweaking</h3>
          <p>
            The Calligraphr UI allows you to preview the font, but I found it a lot more useful to just download a copy
            and use it on a local copy of my website. That let me test it with real text, and see how it’d look at the
            different font sizes I use on the site.
          </p>
          <p>
            The first version was not great. Despite the guidelines on the template, I apparently wasn’t good at
            sticking to them. Some letters were floating way off the baseline, and some were sunken below. When those
            opposites met it looked terrible. Fortunately Calligraphr has a pretty easy tool to slide each letter up and
            down, and scale it up or down if needed, and you can see it next to other letters as you do it. It took a
            little bit of time to go through all the variants of all the letters, but the next version looked a lot
            better.
          </p>
          <p>
            Another tweak I ended up doing was reducing the spacing between letters. The defaults Calligraphr uses are
            probably good for a blocky font, but I wanted to put the letters close together to give it more of a
            joined-up look. Again, this is an easy tool to use, you just drag the sides in or out as desired. While
            these tweaking steps were probably as fiddly as some of the Inkscape steps I refused to do earlier, they’re
            a lot more rewarding as you see things improving with each one. It’s a lot easier for me to commit time and
            effort to improving something that’s already working reasonably, than put that time and energy into an
            unknown.
          </p>
          <p>
            Later, I noticed that occasionally there would be a huge gap in a title. Not “the kerning is slightly off”
            but “there’s enough room to park a bus”. It took me a while to figure out what was happening: a couple of
            glyphs hadn’t been isolated perfectly and had picked up a few pixels from the template lines at the edge of
            their boxes. That meant the glyph had a width that covered the actual written glyph, a big gap, and then the
            rogue marks. At first, I fixed this by just adjusting the width, but that left the little pixels floating
            awkwardly down-sentence. The proper fix was to use the editing tool and simply delete them, and then
            Calligraphr snapped the width back to what it should be.
          </p>
          <p>
            These iterations took a while to do, but I just dipped in and out occasionally over the course of a week, so
            it didn’t actually feel like too much work. I quite enjoy the process of refining things, too.
          </p>
          <h3>Result and a surprise</h3>
          <p>
            If you’re viewing this post on my website<sup><a href="#fn1" id="fnref1">[1]</a></sup>, you can see the font in the headers, captions, and a few other places. Here’s how it compares to my
            actual handwriting:
          </p>
          <figure>
            <picture>
              <source srcset="https://chameth.com/making-a-font-of-my-handwriting/sample.avif" type="image/avif">
              <source srcset="https://chameth.com/making-a-font-of-my-handwriting/sample.webp" type="image/webp">
              <img src="https://chameth.com/making-a-font-of-my-handwriting/sample.jpg" alt="A hand-written line of text saying 'Hello World! This is Chris Hand' above the same line of text in the Chris Hand font" loading="lazy" width="763" height="194">
            </picture>
            <figcaption>My handwriting vs my handwriting font</figcaption>
          </figure>
          <p>
            It’s not close enough to forge documents, but I think it definitely gets across my style, and that’s exactly
            what I wanted. It’s surprisingly legible even at smaller font sizes — I think the weight of the Sharpie
            helps here — and at £8 and a bit of manual work was a lot more economical than spending days wresting with
            open source tools.
          </p>
          <p>
            A few weeks after I put the finishing touches on the font, I got an e-mail from Calligraphr. As my account
            had lapsed back to the free version, I was no longer eligible for the “server-side backup” feature. So what
            did they do? They e-mailed me an exported copy! It’s a JSON file with the properties of each glyph and a
            base64 encoded image. Not only can I re-upload this to Calligraphr if I resubscribe, I can probably hook
            something up to edit it should I ever need to. I’m blown away by how pro-user Calligraphr’s business
            practices are. They’re up-front about pricing, don’t try and get you stuck on an auto-renewing subscription,
            and automatically export your data. It’s like a breath of fresh air compared to the barrage of dark patterns
            that other websites foist on us. If you want to make this kind of font, I’d definitely recommend them just
            because of how <em>nice</em> they are.
          </p>
          <hr>
          <section>
            <ol>
              <li id="fn1">
                <p>
                  And I haven’t changed everything since writing this post…
                  <a href="#fnref1">↩︎</a>
                </p>
              </li>
            </ol>
          </section>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-sourcing our text-to-CAD app (144 pts)]]></title>
            <link>https://github.com/Adam-CAD/CADAM</link>
            <guid>45140921</guid>
            <pubDate>Fri, 05 Sep 2025 17:09:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Adam-CAD/CADAM">https://github.com/Adam-CAD/CADAM</a>, See on <a href="https://news.ycombinator.com/item?id=45140921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Adam-CAD/CADAM/raw/master/public/Github-Banner-Dark.png">
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Adam-CAD/CADAM/raw/master/public/Github-Banner-Light.png">
    <img src="https://github.com/Adam-CAD/CADAM/raw/master/public/Github-Banner-Light.png" alt="CADAM Banner" width="100%">
  </picture></themed-picture>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto"> ⛮ The Open Source Text to CAD Web App ⛮ </h2><a id="user-content---the-open-source-text-to-cad-web-app--" aria-label="Permalink:  ⛮ The Open Source Text to CAD Web App ⛮ " href="#--the-open-source-text-to-cad-web-app--"></a></p>
<p dir="auto"><a href="https://github.com/Adam-CAD/cadam/stargazers"><img src="https://camo.githubusercontent.com/31460d2e1dd79e14191c3823df624b83e0399b27f6c602b08e9322db5aa84c04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d2d4341442f636164616d3f7374796c653d736f6369616c266c6f676f3d676974687562" alt="Stars" data-canonical-src="https://img.shields.io/github/stars/Adam-CAD/cadam?style=social&amp;logo=github"></a>
<a href="https://github.com/Adam-CAD/CADAM/network"><img src="https://camo.githubusercontent.com/05552e23c1608a4a9fa48f7aff64be776404f94ceed19029a6135407f441194e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f4164616d2d4341442f434144414d3f7374796c653d666c6174" alt="Forks" data-canonical-src="https://img.shields.io/github/forks/Adam-CAD/CADAM?style=flat"></a>
<a href="https://www.gnu.org/licenses/gpl-3.0" rel="nofollow"><img src="https://camo.githubusercontent.com/5f0f2e1cde35f590c1787d9572f0e91c59b6c0568e6b51b6deea4c302fa48937/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e7376673f7374796c653d666c6174" alt="License: GPL v3" data-canonical-src="https://img.shields.io/badge/License-GPLv3-blue.svg?style=flat"></a>
<a href="https://nodejs.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/4a997ee8d9bd4f9f3bcae395d36ee2b43239869b48a6d4e1c4c4719d7b8f02b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6f64652e6a732d31382b2d677265656e2e7376673f7374796c653d666c6174266c6f676f3d6e6f64652e6a73266c6f676f436f6c6f723d7768697465" alt="Node.js" data-canonical-src="https://img.shields.io/badge/Node.js-18+-green.svg?style=flat&amp;logo=node.js&amp;logoColor=white"></a>
<a href="https://reactjs.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/72bf68eb84dd414151114ed487a87991fce865c8913920d84932068358aea56b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d31392e312d3631444146422e7376673f7374796c653d666c6174266c6f676f3d7265616374266c6f676f436f6c6f723d626c61636b" alt="React" data-canonical-src="https://img.shields.io/badge/React-19.1-61DAFB.svg?style=flat&amp;logo=react&amp;logoColor=black"></a>
<a href="https://supabase.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/15064c310e574f0af23dfb2db452ecd65005983363ad7da45f3e5c89925d1f3f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53757061626173652d4261636b656e642d3345434638452e7376673f7374796c653d666c6174266c6f676f3d7375706162617365266c6f676f436f6c6f723d7768697465" alt="Supabase" data-canonical-src="https://img.shields.io/badge/Supabase-Backend-3ECF8E.svg?style=flat&amp;logo=supabase&amp;logoColor=white"></a>
<a href="https://openscad.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/fe325d445cdc5b056a3d81adea7190f41545f5ef6b05ab218c2d24dd1a5cd4eb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f70656e534341442d5741534d2d4639443634462e7376673f7374796c653d666c6174" alt="OpenSCAD" data-canonical-src="https://img.shields.io/badge/OpenSCAD-WASM-F9D64F.svg?style=flat"></a>
<a href="https://adam.new/" rel="nofollow"><img src="https://camo.githubusercontent.com/f82c5525db9ab4028322d6522d6635b61694168c790ddb97a719f96a5500086a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f776562736974652d6164616d2e6e65772d626c75653f7374796c653d666c6174" alt="Website" data-canonical-src="https://img.shields.io/badge/website-adam.new-blue?style=flat"></a>
<a href="https://discord.com/invite/HKdXDqAHCs" rel="nofollow"><img src="https://camo.githubusercontent.com/bf4929e9efaf566fa8bc3ad53125306961b9c3fddd75f289f123e19217631188/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d4a6f696e2d3538363546323f7374796c653d666c6174266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Discord" data-canonical-src="https://img.shields.io/badge/Discord-Join-5865F2?style=flat&amp;logo=discord&amp;logoColor=white"></a>
<a href="https://x.com/zachdive" rel="nofollow"><img src="https://camo.githubusercontent.com/6beaec951deb7f27ef606fe9eb17b132fc01e04d26501975bffada7b5f736d02/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772d5a616368253230446976652d3144413146323f7374796c653d666c6174266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Follow Zach Dive" data-canonical-src="https://img.shields.io/badge/Follow-Zach%20Dive-1DA1F2?style=flat&amp;logo=x&amp;logoColor=white"></a>
<a href="https://x.com/aaronhetengli" rel="nofollow"><img src="https://camo.githubusercontent.com/d5b83590375bfdc8dad7c358a4d4b357f3cc4bbd7f772e898502e2345fc63d4a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772d4161726f6e2532304c692d3144413146323f7374796c653d666c6174266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Follow Aaron Li" data-canonical-src="https://img.shields.io/badge/Follow-Aaron%20Li-1DA1F2?style=flat&amp;logo=x&amp;logoColor=white"></a>
<a href="https://x.com/tsadpbb" rel="nofollow"><img src="https://camo.githubusercontent.com/f56c00932adeab484d55c51c9b3251dc4cd531f04ddf8bcd55865c3f73ecd874/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772d747361647062622d3144413146323f7374796c653d666c6174266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Follow Dylan Anderson" data-canonical-src="https://img.shields.io/badge/Follow-tsadpbb-1DA1F2?style=flat&amp;logo=x&amp;logoColor=white"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features</h2><a id="user-content--features" aria-label="Permalink: ✨ Features" href="#-features"></a></p>
<ul dir="auto">
<li>🤖 <strong>AI-Powered Generation</strong> - Transform natural language and images into 3D models</li>
<li>🎛️ <strong>Parametric Controls</strong> - Interactive sliders for instant dimension adjustments</li>
<li>📦 <strong>Multiple Export Formats</strong> - Export as .STL or .SCAD files</li>
<li>🌐 <strong>Browser-Based</strong> - Runs entirely in your browser using WebAssembly</li>
<li>📚 <strong>Library Support</strong> - Includes BOSL, BOSL2, and MCAD libraries</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Key Capabilities</h2><a id="user-content--key-capabilities" aria-label="Permalink: 🎯 Key Capabilities" href="#-key-capabilities"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Natural Language Input</strong></td>
<td>Describe your 3D model in plain English</td>
</tr>
<tr>
<td><strong>Image References</strong></td>
<td>Upload images to guide model generation</td>
</tr>
<tr>
<td><strong>Real-time Preview</strong></td>
<td>See your model update instantly with Three.js</td>
</tr>
<tr>
<td><strong>Parameter Extraction</strong></td>
<td>Automatically identifies adjustable dimensions</td>
</tr>
<tr>
<td><strong>Smart Updates</strong></td>
<td>Efficient parameter changes without AI re-generation</td>
</tr>
<tr>
<td><strong>Custom Fonts</strong></td>
<td>Built-in Geist font support for text in models</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">📸 Demo</h2><a id="user-content--demo" aria-label="Permalink: 📸 Demo" href="#-demo"></a></p>


<blockquote>
<p dir="auto">🎬 <strong>Try it live:</strong> <a href="https://adam.new/cadam" rel="nofollow">https://adam.new/cadam</a></p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/Adam-CAD/CADAM.git
cd CADAM

# Install dependencies
npm install

# Start Supabase
npx supabase start
npx supabase functions serve --no-verify-jwt

# Start the development server
npm run dev"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/Adam-CAD/CADAM.git
<span>cd</span> CADAM

<span><span>#</span> Install dependencies</span>
npm install

<span><span>#</span> Start Supabase</span>
npx supabase start
npx supabase functions serve --no-verify-jwt

<span><span>#</span> Start the development server</span>
npm run dev</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📋 Prerequisites</h2><a id="user-content--prerequisites" aria-label="Permalink: 📋 Prerequisites" href="#-prerequisites"></a></p>
<ul dir="auto">
<li>Node.js and npm</li>
<li>Supabase CLI</li>
<li>ngrok (for local webhook development)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Setting Up Environment Variables</h2><a id="user-content--setting-up-environment-variables" aria-label="Permalink: 🔧 Setting Up Environment Variables" href="#-setting-up-environment-variables"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Frontend Environment:</h3><a id="user-content-1-frontend-environment" aria-label="Permalink: 1. Frontend Environment:" href="#1-frontend-environment"></a></p>
<ul dir="auto">
<li>Copy <code>.env.local.template</code> to <code>.env.local</code></li>
<li>Update all required keys in <code>.env.local</code>:
<div data-snippet-clipboard-copy-content="VITE_SUPABASE_ANON_KEY=&quot;<Test Anon Key>&quot;
VITE_SUPABASE_URL='http://127.0.0.1:54321'"><pre><code>VITE_SUPABASE_ANON_KEY="&lt;Test Anon Key&gt;"
VITE_SUPABASE_URL='http://127.0.0.1:54321'
</code></pre></div>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Supabase Functions Environment:</h3><a id="user-content-2-supabase-functions-environment" aria-label="Permalink: 2. Supabase Functions Environment:" href="#2-supabase-functions-environment"></a></p>
<ul dir="auto">
<li>Copy <code>supabase/functions/.env.template</code> to <code>supabase/functions/.env</code></li>
<li>Update all required keys in <code>supabase/functions/.env</code>, including:
<div data-snippet-clipboard-copy-content="ANTHROPIC_API_KEY=&quot;<Test Anthropic API Key>&quot;
ENVIRONMENT=&quot;local&quot;
NGROK_URL=&quot;<NGROK URL>&quot; # Your ngrok tunnel URL, e.g., https://xxxx-xx-xx-xxx-xx.ngrok.io"><pre><code>ANTHROPIC_API_KEY="&lt;Test Anthropic API Key&gt;"
ENVIRONMENT="local"
NGROK_URL="&lt;NGROK URL&gt;" # Your ngrok tunnel URL, e.g., https://xxxx-xx-xx-xxx-xx.ngrok.io
</code></pre></div>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌐 Setting Up ngrok for Local Development</h2><a id="user-content--setting-up-ngrok-for-local-development" aria-label="Permalink: 🌐 Setting Up ngrok for Local Development" href="#-setting-up-ngrok-for-local-development"></a></p>
<p dir="auto">CADAM uses ngrok to send image URLs to Anthropic:</p>
<ol dir="auto">
<li>
<p dir="auto">Install ngrok if you haven't already:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g ngrok
# or
brew install ngrok"><pre>npm install -g ngrok
<span><span>#</span> or</span>
brew install ngrok</pre></div>
</li>
<li>
<p dir="auto">Start an ngrok tunnel pointing to your Supabase instance:</p>

</li>
<li>
<p dir="auto">Copy the generated ngrok URL (e.g., <a href="https://xxxx-xx-xx-xxx-xx.ngrok.io/" rel="nofollow">https://xxxx-xx-xx-xxx-xx.ngrok.io</a>) and add it to your <code>supabase/functions/.env</code> file:</p>
<div data-snippet-clipboard-copy-content="NGROK_URL=&quot;https://xxxx-xx-xx-xxx-xx.ngrok.io&quot;"><pre><code>NGROK_URL="https://xxxx-xx-xx-xxx-xx.ngrok.io"
</code></pre></div>
</li>
<li>
<p dir="auto">Ensure <code>ENVIRONMENT="local"</code> is set in the same file.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">💻 Development Workflow</h2><a id="user-content--development-workflow" aria-label="Permalink: 💻 Development Workflow" href="#-development-workflow"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install Dependencies</h3><a id="user-content-install-dependencies" aria-label="Permalink: Install Dependencies" href="#install-dependencies"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Start Supabase Services</h3><a id="user-content-start-supabase-services" aria-label="Permalink: Start Supabase Services" href="#start-supabase-services"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="npx supabase start
npx supabase functions serve --no-verify-jwt"><pre>npx supabase start
npx supabase functions serve --no-verify-jwt</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ Built With</h2><a id="user-content-️-built-with" aria-label="Permalink: 🛠️ Built With" href="#️-built-with"></a></p>
<ul dir="auto">
<li><strong>Frontend:</strong> React 18 + TypeScript + Vite</li>
<li><strong>3D Rendering:</strong> Three.js + React Three Fiber</li>
<li><strong>CAD Engine:</strong> OpenSCAD WebAssembly</li>
<li><strong>Backend:</strong> Supabase (PostgreSQL + Edge Functions)</li>
<li><strong>AI:</strong> Anthropic Claude API</li>
<li><strong>Styling:</strong> Tailwind CSS + shadcn/ui</li>
<li><strong>Libraries:</strong> BOSL, BOSL2, MCAD</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">Contributions are welcome! Please feel free to submit a Pull Request.</p>
<ol dir="auto">
<li>Fork the Project</li>
<li>Create your Feature Branch (<code>git checkout -b feature/AmazingFeature</code>)</li>
<li>Commit your Changes (<code>git commit -m 'Add some AmazingFeature'</code>)</li>
<li>Push to the Branch (<code>git push origin feature/AmazingFeature</code>)</li>
<li>Open a Pull Request</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Credits</h2><a id="user-content--credits" aria-label="Permalink: 🙏 Credits" href="#-credits"></a></p>
<p dir="auto">This app wouldn't be possible without the work of:</p>
<ul dir="auto">
<li><a href="https://github.com/openscad/openscad">OpenSCAD</a></li>
<li><a href="https://github.com/openscad/openscad-wasm">openscad-wasm</a></li>
<li><a href="https://github.com/openscad/openscad-playground">openscad-playground</a></li>
<li><a href="https://github.com/seasick/openscad-web-gui">openscad-web-gui</a></li>
<li><a href="https://github.com/yacineMTB/dingcad">dingcad</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<p dir="auto">This distribution is licensed under the GNU General Public License v3.0 (GPLv3). See <code>LICENSE</code>.</p>
<p dir="auto">Components and attributions:</p>
<ul dir="auto">
<li>Portions of this project are derived from <code>openscad-web-gui</code> (GPLv3).</li>
<li>This distribution includes unmodified binaries from OpenSCAD WASM under
GPL v2 or later; distributed here under GPLv3 as part of the combined work.
See <code>src/vendor/openscad-wasm/SOURCE-OFFER.txt</code>.</li>
</ul>
<hr>
<div dir="auto">
<p dir="auto"><strong>⭐ If you find CADAM useful, please consider giving it a star!</strong></p>
<p dir="auto"><a href="https://github.com/Adam-CAD/cadam/stargazers"><img src="https://camo.githubusercontent.com/31460d2e1dd79e14191c3823df624b83e0399b27f6c602b08e9322db5aa84c04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d2d4341442f636164616d3f7374796c653d736f6369616c266c6f676f3d676974687562" alt="Stars" data-canonical-src="https://img.shields.io/github/stars/Adam-CAD/cadam?style=social&amp;logo=github"></a></p>
<p dir="auto">Made with 💙 for the 3D printing and CAD community</p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Freeway guardrails are now a favorite target of thieves (121 pts)]]></title>
            <link>https://laist.com/news/transportation/guardrails-aluminum-theft</link>
            <guid>45140786</guid>
            <pubDate>Fri, 05 Sep 2025 16:57:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://laist.com/news/transportation/guardrails-aluminum-theft">https://laist.com/news/transportation/guardrails-aluminum-theft</a>, See on <a href="https://news.ycombinator.com/item?id=45140786">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        
                                            
                                        

                                        

                                        <p>On a recent Thursday evening, traffic was slow on the 10 Freeway as cars crawled into the downtown Los Angeles area. It was an average commute back to Pasadena for Bryan Gonzalez until he saw a man on the other side of the freeway cutting through a guardrail with a reciprocating saw.</p><p>“OK, there's something weird going on,” Gonzalez said about his observations from Aug. 21, which he captured on video and reported to Caltrans. “I was debating whether or not saying anything, but I said, ‘Hey, I'm in slow traffic. He has a saw. No, thank you.’”</p>

<p>What Gonzalez observed was not a fluke. Guardrail theft is a problem that has been on the rise for the last eight years, according to the local Caltrans office covering L.A. and Ventura counties. Over the last two years, the state transportation agency has spent more than $62,000 on repairs related to guardrail theft in the region.</p>

<p>The man who appeared to be trying to steal the guardrail apparently didn’t succeed. A photo Gonzalez shared with LAist the following week shows an intact guardrail with a mark where the saw was used.</p><p>California Highway Patrol, whose jurisdiction includes state-owned highways, said it’s investigating the incident. A spokesperson for the agency said it hasn’t found the man in the video.</p><p>Aluminum, which Caltrans’ guardrails are made from, is just one metal used in public infrastructure that is increasingly stolen and sold to metal scrapyards and recyclers.</p>


<h2>Missing guardrails</h2><p>Over the last several months since he’s been commuting to work in Culver City, Gonzalez said he’s noticed guardrailing disappearing on the 10 Freeway near the 110 Freeway interchange.</p><p>“I was just equating it to normal wear and tear of accidents and the guardrailing doing what it's supposed to do,” Gonzalez said.</p>

<p>When he saw the man with the saw, Gonzalez said the dots began to connect.</p>
<div data-align-center="">  
  
  
    
    
  <ps-infobox-module>
    
    <div>
        
            <p>See an underreported transportation issue? </p>
        
        
            <ul>
                
                    <li>
    <p>LAist learned about guardrail thefts because a listener and reader sent us a video. If there’s a transportation-related issue you feel hasn’t gotten the attention it deserves, let us know. I can be reached at <a href="mailto:kharjai@laist.com" target="_blank" data-cms-ai="0">kharjai@laist.com</a>. Or if you prefer something more secure, you can reach me on Signal under the username kharjai.61 or <a href="https://signal.me/#eu/jYSBvrbojVkW-siQijoNE0SZaa47ws06Fib4W4H3ExVqKafQBzFKlJKcq2niBV95" target="_blank" data-cms-ai="0">follow this link</a>.</p>
</li>
                
            </ul>
        
    </div>
  </ps-infobox-module>


  
</div>
<p>A statement from Caltrans calls guardrail theft an “ongoing” problem in downtown L.A. that causes safety issues for drivers. More specifically, the state transportation agency said there has been “a marked increase in rail theft” along a stretch of the 10 Freeway between Santa Fe Avenue and the 110 interchange.</p><p>Nearly 470 sections of guardrailing were stolen in the last fiscal year alone in L.A. and Ventura counties, costing the state transportation agency $17,000 to replace, the agency said.</p><p>Guardrail theft spiked in 2023 after <a href="https://laist.com/news/transportation/the-10-is-closed-downtown-due-to-huge-pallet-yard-fire" data-cms-ai="0">an arsonist set fire to a storage yard</a> beneath the 10 Freeway. Caltrans said it spent $45,000 on repairs in the 2023-24 fiscal year.</p><p>Google Map Street View images from May 2024 near the San Pedro Street and Central Avenue ramps leading to the 10 Freeway in downtown show additional sections of missing guardrails.</p>



<p>To prevent thefts, Caltrans said it tried welding bolts into the guardrails, but thieves were able to breach that deterrent.</p><p>The next step the agency is considering is using fiberglass composite instead of aluminum to construct guard rails “to remove the value to the thieves.”<br></p>
<h2>The value of aluminum</h2><p>Aluminum is critical to transportation infrastructure, said Lance Hastings, the president and CEO of the California Manufacturers and Technology Association.</p><p>“Like most base metals, the price of aluminum has increased in recent years,” Hastings said. “Tariffs further disrupt the global supply chain, driving up costs and creating market instability.”</p><p>President Donald Trump announced 50% tariffs on imported steel and aluminum earlier this summer. In August, the Department of Commerce announced that hundreds of other “derivative” steel and aluminum products would also be <a href="https://media.bis.gov/press-release/department-commerce-adds-407-product-categories-steel-aluminum-tariffs" target="_blank" data-cms-ai="0"><u>subject to tariffs.</u></a><br></p>
<h2>Metal theft</h2><p>Metal theft in L.A. is a persistent problem that damages telecom, lighting, train and other critical infrastructure. It also hamstrings government agencies, which, as a result of increasing thefts, say they're unable to keep up with repairs.</p>

<p>The head of the L.A.’s street lighting department told LAist earlier this year that copper wire theft <a href="https://laist.com/news/transportation/street-light-repair-plan" data-cms-ai="0">causes 40% of all repairs</a><a href="https://laist.com/news/transportation/street-light-repair-plan" data-cms-ai="0">, </a>up from a quarter just two years ago.</p>

<p>Earlier in August, 60 feet of copper cable was stolen from a portion of the track that services L.A. Metro’s A-line train, resulting in reduced service for about 16 hours, according to a statement from the countywide transportation agency.</p><p>Ally Happel, an executive at security company ECAM, said thieves will target any materials that are “accessible and easy to sell at a high price.”</p><p>ECAM uses AI surveillance systems to “detect and predict suspicious activity.” It has partnered with Foothill Transit, as well as the L.A. Police Department and port police.</p><p>Bronze, brass, iron, lead and steel are also “vulnerable to theft,” Happel said.</p><p>It’s not just an L.A. problem. Nearly a third of all copper theft and telecom infrastructure vandalism nationwide happened in California, <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-holds-roundtable-northern-california-combat-copper-wire" target="_blank" data-cms-ai="0"><u>according to state Attorney General Rob Bonta.&nbsp;</u></a></p><p>It’s unclear what the LAPD is doing to address the problem for metal stolen from city infrastructure. The department disbanded its metal theft detail six years ago, <a href="https://www.lapdpolicecom.lacity.org/042324/BPC_24-075.pdf" target="_blank" data-cms-ai="0">according to a report</a> it delivered to City Council last year.</p><p>There were at least two LAPD metal theft task forces funded by council offices that were active last year. It’s unclear if they still exist.</p><p>LAPD has not responded to LAist’s repeated questions about the continued existence of those task forces and whether there has been more recent metal theft enforcement actions.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Commission fines Google €2.95B over abusive ad tech practices (353 pts)]]></title>
            <link>https://ec.europa.eu/commission/presscorner/detail/en/ip_25_1992</link>
            <guid>45140730</guid>
            <pubDate>Fri, 05 Sep 2025 16:52:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_25_1992">https://ec.europa.eu/commission/presscorner/detail/en/ip_25_1992</a>, See on <a href="https://news.ycombinator.com/item?id=45140730">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[MentraOS – open-source Smart glasses OS (158 pts)]]></title>
            <link>https://github.com/Mentra-Community/MentraOS</link>
            <guid>45140381</guid>
            <pubDate>Fri, 05 Sep 2025 16:25:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Mentra-Community/MentraOS">https://github.com/Mentra-Community/MentraOS</a>, See on <a href="https://news.ycombinator.com/item?id=45140381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p><a href="https://apps.apple.com/us/app/mentra-the-smart-glasses-app/id6747363193" rel="nofollow">
    <img src="https://github.com/Mentra-Community/MentraOS/raw/main/images/AppStoreBadge.png" alt="Download on the App Store" width="180">
  </a>
  <a href="https://play.google.com/store/apps/details?id=com.mentra.mentra" rel="nofollow">
    <img src="https://github.com/Mentra-Community/MentraOS/raw/main/images/GooglePlayBadge.png" alt="Get it on Google Play" width="180">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Smart Glasses</h2><a id="user-content-supported-smart-glasses" aria-label="Permalink: Supported Smart Glasses" href="#supported-smart-glasses"></a></p>
<p dir="auto">Works with Even Realities G1, Mentra Mach 1, Mentra Live. See <a href="https://github.com/Mentra-Community/MentraOS/blob/main/glasses-compatibility.md">smart glasses compatibility list here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Apps on Mentra Store</h2><a id="user-content-apps-on-mentra-store" aria-label="Permalink: Apps on Mentra Store" href="#apps-on-mentra-store"></a></p>
<p dir="auto">The Mentra Store already has a ton of useful apps that real users are running everyday. Here are some apps already published by developers on the Mentra Store:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Write Once, Run on Any Smart Glasses</h2><a id="user-content-write-once-run-on-any-smart-glasses" aria-label="Permalink: Write Once, Run on Any Smart Glasses" href="#write-once-run-on-any-smart-glasses"></a></p>
<p dir="auto"><strong>MentraOS is how developers build smart glasses apps.</strong> We handle the pairing, connection, data streaming, and cross-compatibility, so you can focus on creating amazing apps. Every component is 100% open source (MIT license).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why Build with MentraOS?</h3><a id="user-content-why-build-with-mentraos" aria-label="Permalink: Why Build with MentraOS?" href="#why-build-with-mentraos"></a></p>
<ul dir="auto">
<li><strong>Cross Compatibility</strong>: Your app runs on any pair of smart glasses</li>
<li><strong>Speed</strong>: TypeScript SDK means you're making apps in minutes, not months</li>
<li><strong>Control</strong>: Access smart glasses I/O - displays, microphones, cameras, speakers</li>
<li><strong>Distribution</strong>: Get your app in front of everyone using smart glasses</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">MentraOS Community</h2><a id="user-content-mentraos-community" aria-label="Permalink: MentraOS Community" href="#mentraos-community"></a></p>
<p dir="auto">The MentraOS Community is a group of developers, companies, and users dedicated to ensuring the next personal computer is open, cross-compatible, and user-controlled. That's why we're building MentraOS.</p>
<p dir="auto">To get involved, join the <a href="https://mentra.glass/discord" rel="nofollow">MentraOS Community Discord server</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">Have questions or ideas? We'd love to hear from you!</p>
<ul dir="auto">
<li><strong>Email</strong>: <a href="mailto:team@mentra.glass">team@mentra.glass</a></li>
<li><strong>Discord</strong>: <a href="http://mentra.glass/discord" rel="nofollow">Join our community</a></li>
<li><strong>Twitter</strong>: <a href="https://x.com/mentralabs" rel="nofollow">Follow @mentralabs</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">MentraOS is made by a community and we welcome PRs. Here's the Contributors Guide: <a href="https://docs.mentra.glass/contributing" rel="nofollow">docs.mentra.glass/contributing</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License Copyright 2025 MentraOS Community</p>
<hr>
<div dir="auto">
  
  <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/Mentra-Community/MentraOS/blob/main/images/MentraLogoSquareRound.png"><img width="100" alt="MentraOS" src="https://github.com/Mentra-Community/MentraOS/raw/main/images/MentraLogoSquareRound.png"></a></p><p dir="auto"><h3 tabindex="-1" dir="auto">© 2025 Mentra Labs</h3><a id="user-content--2025-mentra-labs" aria-label="Permalink: © 2025 Mentra Labs" href="#-2025-mentra-labs"></a></p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[South Korea: 'many' of its nationals detained in ICE raid on GA Hyundai facility (241 pts)]]></title>
            <link>https://www.nbcnews.com/news/us-news/ice-hyundai-plant-georgia-enforcement-action-rcna229148</link>
            <guid>45139954</guid>
            <pubDate>Fri, 05 Sep 2025 15:51:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/news/us-news/ice-hyundai-plant-georgia-enforcement-action-rcna229148">https://www.nbcnews.com/news/us-news/ice-hyundai-plant-georgia-enforcement-action-rcna229148</a>, See on <a href="https://news.ycombinator.com/item?id=45139954">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="anchor-c00f77"><a href="https://www.nbcnews.com/world/south-korea/south-korea-must-navigate-trump-risk-key-summits-japan-us-rcna226488" target="_blank">South Korea</a> said Friday that it had expressed “concern and regret” to the U.S. Embassy over an immigration raid on a Hyundai facility in <a href="https://www.nbcnews.com/news/us-news/georgia-dentist-accused-killing-wife-teenage-daughter-rcna228746" target="_blank">Georgia</a> during which it said “many” South Korean nationals had been detained.</p><p id="anchor-814048">“The economic activities of our companies investing in the U.S. and the rights and interests of our nationals must not be unfairly violated,” said Lee Jae-woong, a spokesperson for the foreign ministry of the key U.S. ally, according to the <a href="https://en.yna.co.kr/view/AEN20250905010300315?section=national/diplomacy" target="_blank">Yonhap news agency</a>.</p><p id="anchor-6fedd2">Agents from Immigration and Customs Enforcement (ICE) as well as Homeland Security Investigations and other federal agencies were involved in the operation on Thursday, which an ICE spokesperson said was conducted in connection with an investigation into “unlawful employment practices and other serious federal crimes.” </p><p id="anchor-b2e17b">Steven Schrank, special agent in charge of Homeland Security Investigations in Georgia, <a href="https://www.youtube.com/watch?v=1_oM5o-wq_g" target="_blank">told reporters on Thursday afternoon</a> that the alleged unlawful practices were taking place at the “multi-hundred acre” construction site where South Korean companies Hyundai and LG Energy Solution are jointly building a<a href="https://apnews.com/article/hyundai-georgia-lg-electric-vehicle-battery-58bdbe36e34179db41c95dc120851f77"> new battery plant </a>next to their manufacturing facility for electric vehicles.</p><p id="anchor-2115a9">The facility in the town of Ellabell, about 28 miles west of the city of Savannah, employs about 1,400 people. It is considered one of Georgia’s largest and most high-profile manufacturing sites, <a href="https://apnews.com/article/immigration-raid-hyundai-georgia-electric-vehicles-191904f42f540898035feb2a6623d98e" target="_blank">according to The Associated Press</a>.</p><p id="anchor-b0ca2d">NBC News verified a <a href="https://www.facebook.com/reel/764817449617122" target="_blank">video</a> posted on social media showing HSI agents inside the construction site at Hyundai’s facility in Ellabell. One of the agents can be heard telling workers they had a search warrant for the entire site and asked that construction “be ceased immediately.”</p><p id="anchor-662098">A worker who was there but whose name is being withheld told NBC News that agents came late Thursday morning and asked everyone on the premises whether they were U.S. citizens.</p><p id="anchor-bf3f8b">Other videos on social media show agents lining workers up. In some instances, agents can be seen asking workers questions and searching their bags.</p><p id="anchor-992f88">In a statement to NBC News, Hyundai spokesperson Michael Stewart confirmed the presence of law enforcement at the LG Energy Solution and Hyundai battery joint venture construction site in Bryan County, where Ellabell is located.</p><p id="anchor-a6023e">“We are cooperating with law enforcement and are committed to abiding by all labor and immigration regulations,” Stewart said.</p><p id="anchor-a1a37d">It remains unclear how many people have been taken into custody, but Schrank said, “We are making many arrests of undocumented individuals.”</p><p id="anchor-26daf4"><a href="https://www.wsav.com/news/breaking-heavy-federal-agency-presence-at-hyundai-facility/" target="_blank">NBC affiliate WSAV of Savannah</a> reported that hundreds of undercover law enforcement vehicles and Humvees were reportedly seen at the scene. Large buses were also seen entering the site.</p><p id="anchor-929fdc">Mary Beth Kennedy, a spokesperson for HL-GA Battery Co., LG Energy Solution and Hyundai’s joint venture, told WSAV in a statement that the company “is cooperating fully with the appropriate authorities regarding activity at our construction site. To assist their work, we have paused construction. We do not have further details at this time.”</p><p id="anchor-08b973">Schrank added that the investigation was expected to continue beyond Thursday but did not provide a timeline.</p><p id="anchor-ea30ad">The ICE spokesperson added: “This investigation is focused on ensuring accountability for those who violate the law and upholding the rule of law. Complex cases like this require strong collaboration and extensive investigative efforts.”</p><p id="anchor-20260a">South Korea, the world’s 10th-largest economy, is a major automotive and electronics manufacturer whose companies have multiple plants in the United States. In July, Seoul <a href="https://www.nbcnews.com/business/business-news/trump-hits-india-25-tariff-rcna221907" target="_blank">pledged $350 billion in U.S. investment</a> in an effort to lower President <a href="https://www.nbcnews.com/politics/donald-trump/trump-executive-order-rebranding-defense-department-war-department-rcna229217" target="_blank">Donald Trump</a>’s threatened tariffs on its products, which he ended up setting at 15%.</p><p id="anchor-e292fb">In March, Hyundai said it would <a href="https://www.cnbc.com/2025/03/24/south-korea-hyundai-us-investment.html" target="_blank">invest $21 billion in U.S. onshoring</a> from 2025 to 2028, a number it said last month had <a href="https://www.hyundai.com/worldwide/en/newsroom/detail/hyundai-motor-group-increases-u.s.-investment-to-%252426-billion-to-accelerate-growth-and-innovation-0000001003" target="_blank">increased to $26 billion</a>. </p><p id="anchor-507367">It said the initiatives involved in the investment — including a new $5.8 billion steel plant in Louisiana, expanded U.S. auto production capacity and a state-of-the-art robotics facility — were expected to create about 25,000 new direct jobs in the U.S. over the next four years.</p></div><div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><a href="https://www.nbcnews.com/author/nicole-acevedo-ncpn384476" tabindex="-1"><picture data-testid="picture" data-flavor="focal" data-original-height="48" data-original-width="48"><source media="(min-width: 320px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_avif,q_auto:eco,dpr_2/newscms/2019_29/2934411/190618-nicole-acevedo-byline2043.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_29/2934411/190618-nicole-acevedo-byline2043.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_29/2934411/190618-nicole-acevedo-byline2043.jpg" alt="" height="48" width="48"></picture></a></div><p><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/nicole-acevedo-ncpn384476">Nicole Acevedo</a></span><span><a href="https://x.com/Nicolemarie_A" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:Nicole.Acevedo@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Nicole Acevedo is a national reporter for NBC News and NBC Latino.</p></div><div data-activity-map="expanded-byline-article-bottom"><p><span data-testid="byline-thumbnail"></span><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/laura-strickler-ncpn894696">Laura Strickler</a></span><span><a href="https://x.com/strickdc" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:Laura.Strickler@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Laura Strickler is the senior investigative producer on the national security team where she produces television stories and writes for NBCNews.com.</p></div><div data-activity-map="expanded-byline-article-bottom"><p><span data-testid="byline-thumbnail"></span><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/colin-sheeley-ncpn925916">Colin Sheeley</a></span><span></span></p><p>Colin Sheeley is a senior reporter for NBC News' Social Newsgathering team based in New York.</p></div><div data-activity-map="expanded-byline-article-bottom"><p><span data-testid="byline-thumbnail"></span><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/jennifer-jett-ncpn1278442">Jennifer Jett</a></span><span><a href="mailto:jennifer.jett@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Jennifer Jett is the Asia Digital Editor for NBC News, based in Hong Kong.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Protobuffers Are Wrong (2018) (140 pts)]]></title>
            <link>https://reasonablypolymorphic.com/blog/protos-are-wrong/</link>
            <guid>45139656</guid>
            <pubDate>Fri, 05 Sep 2025 15:25:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reasonablypolymorphic.com/blog/protos-are-wrong/">https://reasonablypolymorphic.com/blog/protos-are-wrong/</a>, See on <a href="https://news.ycombinator.com/item?id=45139656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>I’ve spent a good deal of my professional life arguing against using protobuffers. They’re clearly written by amateurs, unbelievably ad-hoc, mired in gotchas, tricky to compile, and solve a problem that nobody but Google really has. If these problems of protobuffers remained quarantined in serialization abstractions, my complaints would end there. But unfortunately, the bad design of protobuffers is so persuasive that these problems manage to leak their way into your code as well.</p>
<h2 id="ad-hoc-and-built-by-amateurs">Ad-Hoc and Built By Amateurs</h2>
<p>Stop. Put away your email client that is half-way through writing me about how “Google is filled with the world’s best engineers,” and that “anything they build is, by definition, not built by amateurs.” I don’t want to hear it.</p>
<p>Let’s just get this out of the way. Full disclosure: I used to work at Google. It was the first (but unfortunately, not the last) place I ever used protobuffers. All of the problems I want to talk about today exist inside of Google’s codebase; it’s not just a matter of “using protobuffers wrong” or some such nonsense like that.</p>
<p>By far, the biggest problem with protobuffers is their terrible type-system. Fans of Java should feel right at home with protobuffers, but unfortunately, literally nobody considers Java to have a well-designed type-system. The dynamic typing guys complain about it being too stifling, while the static typing guys like me complain about it being too stifling without giving you any of the things you actually want in a type-system. Lose lose.</p>
<p>The ad-hoc-ness and the built-by-amateurs-itude go hand-in-hand. So much of the protobuffer spec feels bolted on as an afterthought that it clearly <em>was</em> bolted on as an afterthought. Many of its restrictions will make you stop, scratch your head and ask “wat?” But these are just symptoms of the deeper answer, which is this:</p>
<p>Protobuffers were obviously built by amateurs because they offer <em>bad solutions to widely-known and already-solved problems.</em></p>
<h3 id="no-compositionality">No Compositionality</h3>
<p>Protobuffers offer several “features”, but none of them see to work with one another. For example, look at the list of orthogonal-yet-constrained typing features that I found by skimming the <a href="https://developers.google.com/protocol-buffers/docs/proto3">documentation</a>.</p>
<ul>
<li><code>oneof</code> fields can’t be <code>repeated</code>.</li>
<li><code>map&lt;k,v&gt;</code> fields have dedicated syntax for their keys and values, but this isn’t used for any other types.</li>
<li>Despite <code>map</code> fields being able to be parameterized, no user-defined types can be. This means you’ll be stuck hand-rolling your own specializations of common data structures.</li>
<li><code>map</code> fields cannot be <code>repeated</code>.</li>
<li><code>map</code> keys <em>can</em> be <code>string</code>s, but <em>can not</em> be <code>bytes</code>. They also can’t be <code>enum</code>s, even though <code>enum</code>s are considered to be equivalent to integers everywhere else in the protobuffer spec.</li>
<li><code>map</code> values cannot be other <code>map</code>s.</li>
</ul>
<p>This insane list of restrictions is the result of unprincipled design choices and bolting on features after the fact. For example, <code>oneof</code> fields can’t be <code>repeated</code> because rather than resulting in a coproduct type, instead the code generator will give you a product of mutually-exclusive optional fields. Such a transformation is only valid for a singular field (and, as we’ll see later, not even then.)</p>
<p>The restriction behind <code>map</code> fields being unable to be <code>repeated</code> is related, but shows off a different limitation of the type-system. Behind the scenes, a <code>map&lt;k,v&gt;</code> is desugared into something spiritually similar to <code>repeated Pair&lt;k,v&gt;</code>. And because <code>repeated</code> is a magical language keyword rather than a type in its own right, it doesn’t compose with itself.</p>
<p>Your guess is as good as mine for why an <code>enum</code> can’t be used as a <code>map</code> key.</p>
<p>What’s so frustrating about all of this is a little understanding of how modern type-systems work would be enough to <em>drastically simplify</em> the protobuffer spec and simultaneously <em>remove all of the arbitrary restrictions.</em></p>
<p>The solution is as follows:</p>
<ul>
<li>Make all fields in a message <code>required</code>. This makes messages <em>product types</em>.</li>
<li>Promote <code>oneof</code> fields to instead be standalone data types. These are <em>coproduct types</em>.</li>
<li>Give the ability to parameterize product and coproduct types by other types.</li>
</ul>
<p>That’s it! These three features are all you need in order to define any possible piece of data. With these simpler pieces, we can re-implement the rest of the protobuffer spec in terms of them.</p>
<p>For example, we can rebuild <code>optional</code> fields:</p>
<div id="cb1"><pre><code><span id="cb1-1">product Unit <span>{</span></span>
<span id="cb1-2">  <span>// no fields</span></span>
<span id="cb1-3"><span>}</span></span>
<span id="cb1-4"></span>
<span id="cb1-5">coproduct Optional<span>&lt;</span>t<span>&gt;</span> <span>{</span></span>
<span id="cb1-6">  t    value <span>=</span> <span>0</span><span>;</span></span>
<span id="cb1-7">  Unit unset <span>=</span> <span>1</span><span>;</span></span>
<span id="cb1-8"><span>}</span></span></code></pre></div>
<p>Building <code>repeated</code> fields is simple too:</p>
<div id="cb2"><pre><code><span id="cb2-1">coproduct List<span>&lt;</span>t<span>&gt;</span> <span>{</span></span>
<span id="cb2-2">  Unit empty <span>=</span> <span>0</span><span>;</span></span>
<span id="cb2-3">  Pair<span>&lt;</span>t<span>,</span> List<span>&lt;</span>t<span>&gt;&gt;</span> cons <span>=</span> <span>1</span><span>;</span></span>
<span id="cb2-4"><span>}</span></span></code></pre></div>
<p>Of course, the actual serialization logic is allowed to do something smarter than pushing linked-lists across the network—after all, <a href="https://reasonablypolymorphic.com/blog/follow-the-denotation/">implementations and semantics don’t need to align one-to-one</a>.</p>
<h3 id="questionable-choices">Questionable Choices</h3>
<p>In the vein of Java, protobuffers make the distinction between <em>scalar</em> types and <em>message</em> types. Scalars correspond more-or-less to machine primitives—things like <code>int32</code>, <code>bool</code> and <code>string</code>. Messages, on the other hand, are everything else. All library- and user-defined types are messages.</p>
<p>The two varieties of types have completely different semantics, of course.</p>
<p>Fields with scalar types are always present. Even if you don’t set them. Did I mention that (at least in proto3<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>) all protobuffers can be zero-initialized with absolutely no data in them? Scalar fields get false-y values—<code>uint32</code> is initialized to <code>0</code> for example, and <code>string</code> is initialized as <code>""</code>.</p>
<p>It’s impossible to differentiate a field that was missing in a protobuffer from one that was assigned to the default value. Presumably this decision is in place in order to allow for an optimization of not needing to send default scalar values over the wire. Presumably, though the <a href="https://developers.google.com/protocol-buffers/docs/encoding">encoding guide</a> makes no mention of this optimization being performed, so your guess is as good as mine.</p>
<p>As we’ll see when we discuss protobuffers’ claim to being god’s gift to backwards- and forwards-compatible APIs, this inability to distinguish between unset and default values is a nightmare. Especially if indeed it’s a design decision made in order to save one bit (set or not) per field.</p>
<p>Contrast this behavior against message types. While scalar fields are dumb, the behavior for message fields is outright <em>insane.</em> Internally, message fields are either there or they’re not—but their behavior is crazy. Some pseudocode for their accessor is worth a thousand words. Pretend this is Java or something similar:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>private</span> Foo m_foo<span>;</span></span>
<span id="cb3-2"></span>
<span id="cb3-3"><span>public</span> Foo foo <span>{</span></span>
<span id="cb3-4">  <span>// only if `foo` is used as an expression</span></span>
<span id="cb3-5">  get <span>{</span></span>
<span id="cb3-6">    <span>if</span> <span>(</span>m_foo <span>!=</span> <span>null</span><span>)</span></span>
<span id="cb3-7">      <span>return</span> m_foo<span>;</span></span>
<span id="cb3-8">    <span>else</span></span>
<span id="cb3-9">      <span>return</span> <span>new</span> <span>Foo</span><span>();</span></span>
<span id="cb3-10">  <span>}</span></span>
<span id="cb3-11"></span>
<span id="cb3-12">  <span>// instead if `foo` is used as an lvalue</span></span>
<span id="cb3-13">  mutable get <span>{</span></span>
<span id="cb3-14">    <span>if</span> <span>(</span>m_foo <span>=</span> <span>null</span><span>)</span></span>
<span id="cb3-15">      m_foo <span>=</span> <span>new</span> <span>Foo</span><span>();</span></span>
<span id="cb3-16">    <span>return</span> m_foo<span>;</span></span>
<span id="cb3-17">  <span>}</span></span>
<span id="cb3-18"><span>}</span></span></code></pre></div>
<p>The idea is that if the <code>foo</code> field is unset, you’ll see a default-initialized copy whenever you ask for it, but won’t actually modify its container. But if you modify <code>foo</code>, it will modify its parent as well! All of this just to avoid using a <code>Maybe Foo</code> type and the associated “headaches” of the nuance behind needing to figure out what an unset value should mean.</p>
<p>This behavior is especially egregious, because it breaks a law! We’d expect the assignment <code>msg.foo = msg.foo;</code> to be a no-op. Instead the implementation will actually silently change <code>msg</code> to have a zero-initialized copy of <code>foo</code> if it previously didn’t have one.</p>
<p>Unlike scalar fields, at least it’s possible to detect if a message field is unset. Language bindings for protobuffers offer something along the lines of a generated <code>bool has_foo()</code> method. In the frequent case of copying a message field from one proto to another, iff it was present, you’ll need to write the following code:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>if</span> <span>(</span>src<span>.</span>has_foo<span>(</span>src<span>))</span> <span>{</span></span>
<span id="cb4-2">  dst<span>.</span>set_foo<span>(</span>src<span>.</span>foo<span>());</span></span>
<span id="cb4-3"><span>}</span></span></code></pre></div>
<p>Notice that, at least in statically-typed languages, this pattern <em>cannot be abstracted</em> due to the nominal relationship between the methods <code>foo()</code>, <code>set_foo()</code> and <code>has_foo()</code>. Because all of these functions are their own <em>identifiers</em>, we have no means of programmatically generating them, save for a preprocessor macro:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>#define COPY_IFF_SET</span><span>(</span>src<span>,</span><span> </span>dst<span>,</span><span> </span>field<span>)</span><span> </span><span>\</span></span>
<span id="cb5-2"><span>if</span><span> </span><span>(</span>src<span>.</span><span>has_</span><span>##</span>field<span>(</span>src<span>))</span><span> </span><span>{</span><span> </span><span>\</span></span>
<span id="cb5-3"><span>  </span>dst<span>.</span><span>set_</span><span>##</span>field<span>(</span>src<span>.</span>field<span>());</span><span> </span><span>\</span></span>
<span id="cb5-4"><span>}</span></span></code></pre></div>
<p>(but preprocessor macros are verboten by the <a href="https://google.github.io/styleguide/cppguide.html#Preprocessor_Macros">Google style guide</a>.)</p>
<p>If instead all optional fields were implemented as <code>Maybe</code>s, you’d get abstract-able, referentially transparent call-sites for free.</p>
<p>To change tack, let’s talk about another questionable decision. While you can define <code>oneof</code> fields in protobuffers, their semantics are <em>not</em> of coproduct types! Rookie mistake my dudes! What you get instead is an optional field for each case of the <code>oneof</code>, and magic code in the setters that will just unset any other case if this one is set.</p>
<p>At first glance, this seems like it should be semantically equivalent to having a proper union type. But instead it is an accursed, unutterable source of bugs! When this behavior teams up with the law-breaking implementation of <code>msg.foo = msg.foo;</code>, it allows this benign-looking assignment to silently delete arbitrary amounts of data!</p>
<p>What this means at the end of the day is that <code>oneof</code> fields do not form law-abiding <code>Prism</code>s, nor do messages form law-abiding <code>Lens</code>es. Which is to say good luck trying to write bug-free, non-trivial manipulations of protobuffers. It is <em>literally impossible to write generic, bug-free, polymorphic code over protobuffers.</em></p>
<p>That’s not the sort of thing anybody likes to hear, let alone those of us who have grown to love parametric polymorphism—which gives us the <em>exact opposite promise.</em></p>
<h2 id="the-lie-of-backwards--and-forwards-compatibility">The Lie of Backwards- and Forwards-Compatibility</h2>
<p>One of the frequently cited killer features of protobuffers is their “hassle-free ability to write backwards- and forwards-compatible APIs.” This is the claim that has been pulled over your eyes to blind you from the truth.</p>
<p>What protobuffers are is <em>permissive.</em> They manage to not shit the bed when receiving messages from the past or from the future because they make absolutely no promises about what your data will look like. Everything is optional! But if you need it anyway, protobuffers will happily cook up and serve you something that typechecks, regardless of whether or not it’s meaningful.</p>
<p>This means that protobuffers achieve their promised time-traveling compatibility guarantees by <em>silently doing the wrong thing by default.</em> Of course, the cautious programmer can (and should) write code that performs sanity checks on received protobuffers. But if at every use-site you need to write defensive checks ensuring your data is sane, maybe that just means your deserialization step was too permissive. All you’ve managed to do is decentralize sanity-checking logic from a well-defined boundary and push the responsibility of doing it throughout your entire codebase.</p>
<p>One possible argument here is that protobuffers will hold onto any information present in a message that they don’t understand. In principle this means that it’s nondestructive to route a message through an intermediary that doesn’t understand this version of its schema. Surely that’s a win, isn’t it?</p>
<p>Granted, on paper it’s a cool feature. But I’ve never once seen an application that will actually preserve that property. With the one exception of routing software, nothing wants to inspect only some bits of a message and then forward it on unchanged. The vast majority of programs that operate on protobuffers will decode one, transform it into another, and send it somewhere else. Alas, these transformations are bespoke and coded by hand. And hand-coded transformations from one protobuffer to another don’t preserve unknown fields between the two, because it’s literally meaningless.</p>
<p>This pervasive attitude towards protobuffers always being compatible rears its head in other ugly ways. Style guides for protobuffers actively advocate against DRY and suggest inlining definitions whenever possible. The reasoning behind this is that it allows you to evolve messages separately if these definitions diverge in the future. To emphasize that point, the suggestion is to fly in the face of 60 years’ worth of good programming practice just in case <em>maybe</em> one day in the future you need to change something.</p>
<p>At the root of the problem is that Google conflates the meaning of data with its physical representation. When you’re at Google scale, this sort of thing probably makes sense. After all, they have an internal tool that allows you to compare the finances behind programmer hours vs network utilization vs the cost to store <span>\(x\)</span> bytes vs all sorts of other things. Unlike most companies in the tech space, paying engineers is one of Google’s smallest expenses. Financially it makes sense for them to waste programmers’ time in order to shave off a few bytes.</p>
<p>Outside of the top five tech companies, none of us is within five orders of magnitude of being Google scale. Your startup <em>cannot afford</em> to waste engineer hours on shaving off bytes. But shaving off bytes and wasting programmers’ time in the process is exactly what protobuffers are optimized for.</p>
<p>Let’s face it. You are not Google scale and you never will be. Stop cargo-culting technology just because “Google uses it” and therefore “it’s an industry best-practice.”</p>
<h2 id="protobuffers-contaminate-codebases">Protobuffers Contaminate Codebases</h2>
<p>If it were possible to restrict protobuffer usage to network-boundaries I wouldn’t be nearly as hard on it as a technology. Unfortunately, while there are a few solutions in principle, none of them is good enough to actually be used in real software.</p>
<p>Protobuffers correspond to the data you want to send over the wire, which is often <em>related</em> but not <em>identical</em> to the actual data the application would like to work with. This puts us in the uncomfortable position of needing to choose between one of three bad alternatives:</p>
<ol type="1">
<li>Maintain a separate type that describes the data you actually want, and ensure that the two evolve simultaneously.</li>
<li>Pack rich data into the wire format for application use.</li>
<li>Derive rich information every time you need it from a terse wire format.</li>
</ol>
<p>Option 1 is clearly the “right” solution, but its untenable with protobuffers. The language isn’t powerful enough to encode types that can perform double-duty as both wire and application formats. Which means you’d need to write a completely separate datatype, evolve it synchronously with the protobuffer, and <em>explicitly write serialization code between the two.</em> Seeing as most people seem to use protobuffers in order to not write serialization code, this is obviously never going to happen.</p>
<p>Instead, code that uses protobuffers allows them to proliferate throughout the codebase. True story, my main project at Google was a compiler that took “programs” written in one variety of protobuffer, and spit out an equivalent “program” in another. Both the input and output formats were expressive enough that maintaining proper parallel C++ versions of them could never possibly work. As a result, my code was unable to take advantage of any of the rich techniques we’ve discovered for writing compilers, because protobuffer data (and resulting code-gen) is simply too rigid to do anything interesting.</p>
<p>The result is that a thing that could have been 50 lines of <a href="https://github.com/passy/awesome-recursion-schemes">recursion schemes</a> was instead 10,000 lines of ad-hoc buffer-shuffling. The code I wanted to write was literally impossible when constrained by having protobuffers in the mix.</p>
<p>While this is an anecdote, it’s not in isolation. By virtue of their rigid code-generation, manifestations of protobuffers in languages are never idiomatic, nor can they be made to be—short of rewriting the code-generator.</p>
<p>But even then, you still have the problem of needing to embed a shitty type-system into the targeted language. Because most of protobuffers’ features are ill-conceived, these unsavory properties leak into our codebases. It means we’re forced to not only implement, but also use these bad ideas in any project which hopes to interface with protobuffers.</p>
<p>While it’s easy to implement inane things out of a solid foundation, going the other direction is challenging at best and the dark path of Eldrich madness at worst.</p>
<p>In short, abandon all hope ye who introduce protobuffers into your projects.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>To this day, there’s a raging debate inside Google itself about proto2 and whether fields should ever be marked as <code>required</code>. Manifestos with both titles “<code>optional</code> considered harmful” <em>and</em> “<code>required</code> considered harmful.” Good luck sorting that out.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

<p>
    <span>
        <a href="https://reasonablypolymorphic.com/blog/book-of-types">←</a>
    </span>
    <span>
        <a href="https://reasonablypolymorphic.com/blog/thinking-with-types">→</a>
    </span>
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A computer upgrade has shut down BART (223 pts)]]></title>
            <link>https://www.bart.gov/news/articles/2025/news20250905</link>
            <guid>45139270</guid>
            <pubDate>Fri, 05 Sep 2025 14:52:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bart.gov/news/articles/2025/news20250905">https://www.bart.gov/news/articles/2025/news20250905</a>, See on <a href="https://news.ycombinator.com/item?id=45139270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><strong>Update 09/05/25, 9:15am:&nbsp;</strong></p><p>Limited East Bay service will start at approximately 9:30am. There is no service to San Francisco.</p><p>Yellow Line will service will resume from Antioch to 12th Street Oakland. Blue Line service will resume from Dublin to MacArthur. Orange line service will resume from Berryessa to Richmond. BART to Antioch service is resuming now.</p><hr><p>A computer equipment problem following network upgrade work is preventing the start of service this morning. Seek alternative means of transportation. <a href="https://planner.bart.gov/?products=364#!P|TP!H|96581">bart.gov/alternatives</a> provides options without BART service.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Purposeful animations (428 pts)]]></title>
            <link>https://emilkowal.ski/ui/you-dont-need-animations</link>
            <guid>45139088</guid>
            <pubDate>Fri, 05 Sep 2025 14:34:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://emilkowal.ski/ui/you-dont-need-animations">https://emilkowal.ski/ui/you-dont-need-animations</a>, See on <a href="https://news.ycombinator.com/item?id=45139088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When done right, animations make an interface feel predictable, faster, and more enjoyable to use. They help you and your product stand out.</p>
<p>But they can also do the opposite. They can make an interface feel unpredictable, slow, and annoying. They can even make your users lose trust in your product.</p>
<p>So how do you know <em>when</em> and <em>how</em> to animate to improve the experience?</p>
<p>Step one is making sure your animations have a purpose.</p>
<a href="#purposeful-animations"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none"><path d="M10 19.0004L9.82843 19.1719C8.26634 20.734 5.73368 20.734 4.17158 19.1719L3.82843 18.8288C2.26634 17.2667 2.26633 14.734 3.82843 13.1719L7.17158 9.8288C8.73368 8.2667 11.2663 8.2667 12.8284 9.8288L13.1716 10.1719C13.8252 10.8256 14.2053 11.6491 14.312 12.5004" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M9.68799 12.5004C9.79463 13.3516 10.1748 14.1752 10.8284 14.8288L11.1715 15.1719C12.7336 16.734 15.2663 16.734 16.8284 15.1719L20.1715 11.8288C21.7336 10.2667 21.7336 7.73404 20.1715 6.17194L19.8284 5.8288C18.2663 4.2667 15.7336 4.2667 14.1715 5.8288L14 6.00037" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg><h2 id="purposeful-animations">Purposeful animations</h2></a>
<p>Before you start animating, ask yourself: what’s the purpose of this animation? <br>As an example, what’s the purpose of this marketing animation we built at Linear?</p>

<p>This animation explains how Product Intelligence (Linear’s feature) works. We could have used a static asset, but the animated version helps the user understand what this feature does, straight in the initial viewport of the page.</p>
<p>Another purposeful animation is this subtle scale down effect when pressing a button. It’s a small thing, but it helps the interface feel more alive and responsive.</p>

<p>Sonner’s enter animation, on the other hand, has two purposes:</p>
<ul>
<li><span>-</span> <!-- -->Having a toast suddenly appear would feel off, so we animate it in.</li>
<li><span>-</span> <!-- -->Because it comes from and leaves in the same direction, it creates spatial consistency, making the swipe-down-to-dismiss gesture feel more intuitive.</li>
</ul>

<p>But sometimes the purpose of an animation might just be to bring delight.</p>
<p>Morphing of the feedback component below helps make the experience more unique and memorable. This works as long as the user will rarely interact with it. It’ll then become a pleasant surprise, rather than a daily annoyance.</p>
<div><p>Press on the button to see it morph.</p></div>
<p>Used multiple times a day, this component would quickly become irritating. The initial delight would fade and the animation would slow users down.</p>
<p>How often users will see an animation is a key factor in deciding whether to animate or not. Let’s dive deeper into it next.</p>
<a href="#frequency-of-use"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none"><path d="M10 19.0004L9.82843 19.1719C8.26634 20.734 5.73368 20.734 4.17158 19.1719L3.82843 18.8288C2.26634 17.2667 2.26633 14.734 3.82843 13.1719L7.17158 9.8288C8.73368 8.2667 11.2663 8.2667 12.8284 9.8288L13.1716 10.1719C13.8252 10.8256 14.2053 11.6491 14.312 12.5004" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M9.68799 12.5004C9.79463 13.3516 10.1748 14.1752 10.8284 14.8288L11.1715 15.1719C12.7336 16.734 15.2663 16.734 16.8284 15.1719L20.1715 11.8288C21.7336 10.2667 21.7336 7.73404 20.1715 6.17194L19.8284 5.8288C18.2663 4.2667 15.7336 4.2667 14.1715 5.8288L14 6.00037" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg><h2 id="frequency-of-use">Frequency of use</h2></a>
<p>I use Raycast hundreds of times a day. If it animated every time I opened it, it would be <em>very</em> annoying. But there’s no animation at all. That’s the optimal experience.</p>
<p>To see it for yourself, try to toggle the open state of the menu below by <span>using the buttons below</span><span>pressing <code>J</code> and then <code>K</code></span>. Which one feels better if used hundreds of times a day?</p>
<div tabindex="-1" cmdk-root=""><p><label cmdk-label="" for="radix-:R1dlduuudbH2:" id="radix-:R1dlduuudbH1:">Command Menu</label></p><div cmdk-group-items="" role="listbox" aria-labelledby="radix-:R7bdlduuudbH1:" cmdk-group="" cmdk-list-sizer="" cmdk-list="" tabindex="-1" aria-label="Suggestions" id="radix-:R1dlduuudb:"><p><img src="https://emilkowal.ski/you-dont-need-animations/linear-app-logo.png" alt="Linear"><span>Linear</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/openai-app-logo.png" alt="ChatGPT"><span>ChatGPT</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/cursor-app-logo.png" alt="Cursor"><span>Cursor</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/figma-app-logo.png" alt="Figma"><span>Figma</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/obsidian-app-icon.png" alt="Obsidian"><span>Obsidian</span><span>Application</span></p></div></div>
<p>When I open Raycast, I have a clear goal in mind. I don’t expect to be “delighted”, I don’t need to be. I just want to do my work with no unnecessary friction.</p>
<p>Think about what the user wants to achieve and how often they will see an animation. A hover effect is nice, but if used multiple times a day, it would likely benefit the most from having no animation at all.</p>
<p><span><div><p>Imagine you interact with this list often during the day.</p></div></span>
<span><div><p>Imagine you interact with this list often during the day.</p></div></span></p><p>The same goes for keyboard-initiated actions. These actions may be repeated hundreds of times a day, an animation would make them feel slow, delayed, and disconnected from the user’s actions. You should <em>never</em> animate them.</p>
<p><span><p>Since we can’t really use a keyboard on touch devices, you can press the buttons below to see how it feels with and without animation.</p></span>
<span><p>To see it for yourself, focus on the input below and use arrow keys to navigate through the list. Notice how the highlight feels delayed compared to the keys you press. Now press <kbd><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none"><path d="M2.91032 11.5511L11.2848 2.98182C11.6771 2.5804 12.3229 2.5804 12.7152 2.98182L21.0897 11.5511C21.7085 12.1843 21.2599 13.25 20.3745 13.25H17.1316V18.25C17.1316 19.3546 16.2361 20.25 15.1316 20.25H8.86842C7.76385 20.25 6.86842 19.3546 6.86842 18.25V13.25H3.62551C2.74013 13.25 2.2915 12.1843 2.91032 11.5511Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="square" stroke-linejoin="round"></path></svg></kbd> (shift) and see how this interaction feels without animation.</p></span></p><div><div tabindex="-1" cmdk-root=""><p><label cmdk-label="" for="radix-:R1dnduuudbH2:" id="radix-:R1dnduuudbH1:">Command Menu</label></p><div cmdk-group-items="" role="listbox" aria-labelledby="radix-:R7bdnduuudbH1:" cmdk-group="" cmdk-list-sizer="" cmdk-list="" tabindex="-1" aria-label="Suggestions" id="radix-:R1dnduuudb:"><p><img src="https://emilkowal.ski/you-dont-need-animations/linear-app-logo.png" alt="Linear"><span>Linear</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/openai-app-logo.png" alt="ChatGPT"><span>ChatGPT</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/cursor-app-logo.png" alt="Cursor"><span>Cursor</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/figma-app-logo.png" alt="Figma"><span>Figma</span><span>Application</span></p><p><img src="https://emilkowal.ski/you-dont-need-animations/obsidian-app-icon.png" alt="Obsidian"><span>Obsidian</span><span>Application</span></p></div></div><p>Press shift to toggle the animation</p></div>
<p>But even if your animation won’t be used too often and it fulfills a clear purpose, you still have to think about its speed…</p>
<a href="#perception-of-speed"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none"><path d="M10 19.0004L9.82843 19.1719C8.26634 20.734 5.73368 20.734 4.17158 19.1719L3.82843 18.8288C2.26634 17.2667 2.26633 14.734 3.82843 13.1719L7.17158 9.8288C8.73368 8.2667 11.2663 8.2667 12.8284 9.8288L13.1716 10.1719C13.8252 10.8256 14.2053 11.6491 14.312 12.5004" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M9.68799 12.5004C9.79463 13.3516 10.1748 14.1752 10.8284 14.8288L11.1715 15.1719C12.7336 16.734 15.2663 16.734 16.8284 15.1719L20.1715 11.8288C21.7336 10.2667 21.7336 7.73404 20.1715 6.17194L19.8284 5.8288C18.2663 4.2667 15.7336 4.2667 14.1715 5.8288L14 6.00037" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg><h2 id="perception-of-speed">Perception of speed</h2></a>
<p>Unless you are working on marketing sites, your animations <em>have</em> to be fast. They improve the perceived performance of your app, stay connected to user’s actions, and make the interface feel as if it’s truly listening to the user.</p>
<p>To give you an example, a faster-spinning spinner makes the app seem to load faster, even though the load time is the same. This improves perceived performance.</p>
<div><p>Which one works harder to load the data?</p></div>
<p>A <code>180ms</code> dropdown animation feels more responsive than a <code>400ms</code> one:</p>
<div><p>Click on the buttons to compare the speed.</p></div>
<p>As a rule of thumb, UI animations should generally stay under <code>300ms</code>.</p>
<p>Another example of the importance of speed: tooltips should have a slight delay before appearing to prevent accidental activation. Once a tooltip is open however, hovering over other tooltips should open them with no delay and no animation.</p>
<p>This feels faster without defeating the purpose of the initial delay.</p>
<p><span><div><p>Radix UI and Base UI skip the delay once a tooltip is shown.</p></div></span>
<span><div><p>Radix UI and Base UI skip the delay once a tooltip is shown.</p></div></span></p><a href="#building-great-interfaces"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none"><path d="M10 19.0004L9.82843 19.1719C8.26634 20.734 5.73368 20.734 4.17158 19.1719L3.82843 18.8288C2.26634 17.2667 2.26633 14.734 3.82843 13.1719L7.17158 9.8288C8.73368 8.2667 11.2663 8.2667 12.8284 9.8288L13.1716 10.1719C13.8252 10.8256 14.2053 11.6491 14.312 12.5004" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M9.68799 12.5004C9.79463 13.3516 10.1748 14.1752 10.8284 14.8288L11.1715 15.1719C12.7336 16.734 15.2663 16.734 16.8284 15.1719L20.1715 11.8288C21.7336 10.2667 21.7336 7.73404 20.1715 6.17194L19.8284 5.8288C18.2663 4.2667 15.7336 4.2667 14.1715 5.8288L14 6.00037" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg><h2 id="building-great-interfaces">Building great interfaces</h2></a>
<p>The goal is not to animate for animation’s sake, it’s to build great user interfaces. The ones that users will happily use, even on a daily basis. Sometimes this requires animations, but sometimes the best animation is no animation.</p>
<p>Knowing when to animate is just one of many things you need to know in order to craft great animations. If you’d like to dive deeper into the theory and practice of it, I’ve created a course that covers everything you need to know:</p>
<a href="https://animations.dev/" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.1161 5.36612C13.6043 4.87796 14.3957 4.87796 14.8839 5.36612L20.6339 11.1161C20.8683 11.3505 21 11.6685 21 12C21 12.3315 20.8683 12.6494 20.6339 12.8839L14.8839 18.6339C14.3957 19.122 13.6043 19.122 13.1161 18.6339C12.628 18.1457 12.628 17.3543 13.1161 16.8661L16.7322 13.25H4.25C3.55964 13.25 3 12.6903 3 12C3 11.3096 3.55964 10.75 4.25 10.75H16.7322L13.1161 7.13388C12.628 6.64573 12.628 5.85427 13.1161 5.36612Z" fill="currentColor"></path></svg>Check out "Animations on the Web"</a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US economy added just 22,000 jobs in August, unemployment highest in 4 yrs (179 pts)]]></title>
            <link>https://www.cnn.com/2025/09/05/economy/us-jobs-report-august-final</link>
            <guid>45138703</guid>
            <pubDate>Fri, 05 Sep 2025 14:01:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/09/05/economy/us-jobs-report-august-final">https://www.cnn.com/2025/09/05/economy/us-jobs-report-august-final</a>, See on <a href="https://news.ycombinator.com/item?id=45138703">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/09/05/economy/us-jobs-report-august-final: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[Development Speed Has Never Been a Bottleneck (183 pts)]]></title>
            <link>https://pawelbrodzinski.substack.com/p/development-speed-is-not-a-bottleneck</link>
            <guid>45138156</guid>
            <pubDate>Fri, 05 Sep 2025 13:13:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pawelbrodzinski.substack.com/p/development-speed-is-not-a-bottleneck">https://pawelbrodzinski.substack.com/p/development-speed-is-not-a-bottleneck</a>, See on <a href="https://news.ycombinator.com/item?id=45138156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ha53!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ha53!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ha53!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ha53!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ha53!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ha53!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg" width="1456" height="818" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:818,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1237469,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://pawelbrodzinski.substack.com/i/172659340?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ha53!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ha53!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ha53!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ha53!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cb306df-4a8b-4ec6-bf86-8b87073a29a7_3473x1951.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><blockquote><p><em>"You are wrong, Pawel. You can vibe code a successful product without any technical skills. Here's one example."</em></p></blockquote><p>I liked the challenge, especially since it referenced a source. What I thought would be a short comment evolved into a series of articles.</p><ul><li><p><a href="https://pawelbrodzinski.substack.com/p/vibe-coded-product-success-stories" rel="nofollow ugc noopener">Vibe-Coded Product Success Stories Ain't What They Look</a><span> covered the marketing/PR part of the story (and the holes in it).</span></p></li><li><p><a href="https://pawelbrodzinski.substack.com/p/vibe-coding-doesnt-replace-tech-skills" rel="nofollow ugc noopener">Vibe Coding Doesn't Replace Tech Skills; It Requires More of Them</a><span> focused on technical challenges triggered by vibe coding.</span></p></li></ul><p>This post is the last one (or at least I believe so at the time of writing), and I will focus on the product management side. Well, just one aspect of it.</p><p><strong>The perception that the pace of shipping features (or building in general) is the bottleneck of product development is a misconception.</strong></p><p>Ultimately, that's what vibe coding tools offer: we can build it for you with no engineering team whatsoever. In fact, the original challenge was worded along the same lines:</p><blockquote><p><em><span>"I'm working with people and I've seen others, who only used AI to create a valid tech business, scaling it up beyond a million dollars, </span><strong>before they hired any software engineer.</strong><span>"</span></em></p></blockquote><p>Let’s unpack it, then.</p><p><span>I'm a fan of vibe coding when it comes to prototyping. </span><a href="https://pawelbrodzinski.substack.com/p/role-of-vibe-coding-in-product-validation" rel="nofollow ugc noopener">It is a fabulous tool to learn whether what we ideate is desirable.</a><span> </span><strong>The first thing about prototypes, though? They are </strong><em><strong>disposable</strong></em><strong>.</strong></p><p><span>Even if we validate that we were right and our idea works (</span><a href="https://pawelbrodzinski.substack.com/p/90-of-times-validation-means-invalidation" rel="nofollow ugc noopener">which happens maybe once every ten attempts</a><span>), the prototype is still </span><em>disposable</em><span>.</span></p><p>The whole idea behind prototyping is that we trade quality for a quick and cheap outcome. It can break. It can be buggy. Sometimes it may even look ugly. The point is: it conveys the idea.</p><p>Conversely, a product has to deliver promised value sustainably over time. Awful UX? I'll move to an alternative. Bugs too annoying? I'll stop using it altogether. It breaks entirely? Why would I use it, let alone pay for it?</p><p>The quality has to be there. Otherwise, customers will go as fast as they come, and that's not a viable product strategy. Sure, we'd still love to build our product quickly and cheaply, but at some level, quality is non-negotiable. Ultimately, we need the thing to work in the long run.</p><p>How do most successful digital products take their shape? Consider any example of your choice and try to reverse-engineer their path. Do you see a clear way, going from one milestone to another, each step an inevitable consequence of all the previous ones?</p><p>Like Amazon figuring out online bookselling as the hit of the internet era, and then, inevitably, taking a shot at music, video, and other industries, while concurrently launching in non-US markets?</p><p>Expanding to include third-party sellers must have been a logical next step, right? And building the biggest cloud infrastructure, their own reading device, and video streaming business... well, by this point, we’re retrofitting the connections and we know it.</p><p><span>Amazon tried a lot of things to land with its key cash cows today. Heck, even with their foundational idea—the marketplace—they famously run thousands of experiments all the time. In fact, </span><a href="https://graphite.dev/blog/how-amazon-deploys-code" rel="nofollow ugc noopener">their whole development culture is designed around rapid experimentation</a><span>.</span></p><p><span>In other words, we never know upfront what will work in a product. </span><strong>We try stuff, see what works, stick with what does, drop what does not.</strong></p><p><a href="https://paulbuchheit.blogspot.com/2009/01/communicating-with-code.html" rel="nofollow ugc noopener">Paul Buchheit is famous for building the first GMail prototype in just a few hours. And then repeating the trick with AdSense.</a><span> All in times where all code had to be manually written, like, you know, by hand.</span></p><p>Yes, we’re talking about two of Google’s product slam dunks. Yet, if you read the story carefully, it was anything but an execution of a well-laid plan.</p><blockquote><p><em><span>"We did </span><strong>a lot of things wrong during the 2.5 years</strong><span> of pre-launch Gmail development."</span></em></p><p><em><span>"We </span><strong>re-wrote the frontend about six times and the backend three times</strong><span> by launch."</span></em></p><p><em><span>"I would just write the code, release the feature, and watch the response. Usually, </span><strong>everyone (including me) would end up hating whatever it was</strong><span> (especially my ideas), but we always learned something from the experience, and we were able to quickly move on to other ideas."</span></em></p><p>Paul Buchheit</p></blockquote><p><span>In other words, there have been numerous dead ends that they explored, invalidated, and moved on from. </span><em>There's no knowing up front.</em></p><p>The same pattern applies to products, not just product features. As an example, we can stick with Google. It is known for a swath of products in line with its mission to organize the world's information. Search, Gmail, Google Workspace, and what have you.</p><p>However, aside from the search, many of these products originated as experiments. Gmail and AdSense, mentioned above, are two notable examples.</p><p>However, for each product idea that survived the test of time, there are a dozen that did not. And for each of the latter, there are probably an order of magnitude more that weren't even released to the public.</p><p><span>I personally used and loved </span><a href="https://en.wikipedia.org/wiki/Google_Reader" rel="nofollow ugc noopener">Google Reader</a><span>, </span><a href="https://en.wikipedia.org/wiki/Google_Talk" rel="nofollow ugc noopener">Google Talk</a><span>, and </span><a href="https://en.wikipedia.org/wiki/Picasa" rel="nofollow ugc noopener">Picasa</a><span>, and the retirement of each broke my heart. There are a few more I didn't cry over, despite being an active user till their sad end.</span></p><p><span>Probably everyone remembers Google's biggest lost bets: </span><a href="https://en.wikipedia.org/wiki/Google_Buzz" rel="nofollow ugc noopener">Buzz</a><span>, </span><a href="https://en.wikipedia.org/wiki/Google%2B" rel="nofollow ugc noopener">Google+</a><span>, and </span><a href="https://en.wikipedia.org/wiki/Google_Wave" rel="nofollow ugc noopener">Google Wave</a><span>.</span></p><p><span>By the end of 2024, </span><a href="https://killedbygoogle.com/" rel="nofollow ugc noopener">the full list of things that Google retired had almost 300 entries</a><span>. It’s not a track record peppered with home runs, is it? And that’s for a company that, from the vantage point of an aspiring startup, has unlimited capabilities.</span></p><p>With all the engineering power Google has, the pace of development could have been set arbitrarily high for any of these products. While no official information is available, it's been rumored that Google had a few hundred engineers working on Google+ alone.</p><p>If the pace of development were all that counted, it would always be the incumbents who would win the product race in any niche. After all, they can pump as much engineering firepower as they want, leveraging their existing revenue streams, customer bases, and whatnot.</p><p>And we know it doesn't work this way.</p><p>Product development, in essence, is continuous discovery. First, we aim to validate the idea, then we switch to validating whether any given change brings us closer to our goals—growth, revenue, retention, or whatever that may be.</p><p><span>The problem is that validation takes time. </span><a href="https://substack.com/@leahtharin" rel="nofollow ugc noopener">Leah Tharin</a><span>, who shares her story about </span><a href="https://substack.com/home/post/p-170083802" rel="nofollow ugc noopener">working on products with tens of millions of users</a><span>, says the following.</span></p><blockquote><p><em><span>"The bottleneck of the team was </span><strong>waiting for statistical significance for most of our experiments</strong><span>, despite all the traffic we had. (...) If we changed a copy of our main website or most prominent tools, the experiments were statistically significant within hours. A more complex down the funnel change for higher value customers? </span><strong>Weeks, sometimes months.</strong><span> Ugh."</span></em></p><p>Leah Tharin</p></blockquote><p>Weeks. Sometimes months. That's before they could have learned whether the change was for the better, worse, or had no effect at all.</p><p><span>Let's make a thought experiment and assume they could reduce the cost and time of </span><em>development</em><span> by a factor of 10. Would they grow faster? Save for the simplest tweaks on the landing page, they would still need to wait to learn the outcomes.</span></p><p>And it's not like they could improve the volume of experiments by tenfold either. Sure, it's technically feasible. Except it would make a mess out of the metrics.</p><p><em>"So we're running these 27 concurrent experiments to improve retention, and the data says it's been better for a week and then got back to what we had before. What does it say about those experiments again?"</em></p><p><span>If you look at what actually matters (growth, revenue, retention), knowing the right thing to build is the most common bottleneck. </span><em>And we can't reliably know what will work from the outset.</em></p><p>But what if we do know exactly what to build? Ultimately, it's the basic pattern of project work. We define the scope, we agree on the payment, and off we go!</p><p>In such a setup, we can conveniently ignore that we might be building the wrong thing entirely. Or, with a bit of luck, it's one of the rather rare cases where we either run a direct replacement project or automate the existing business, and we have a much better initial understanding of the desirability, viability, and feasibility of the idea.</p><p>Still, it's not the development pace that makes or breaks such endeavors.</p><p>At Lunar Logic, when estimating work for a client we've never worked with before, we always go with a wide range. Not as wide as we'd like, as to be brutally honest, we'd need to go with something like "It can take less than a month, or more than a quarter." Still, the bracket is uncomfortably wide for many of our potential customers.</p><p>And that for the work with limited technical uncertainties.</p><p>Why are we all over the place? Can’t we just use 20 years of experience that we so often brag about and tell in plain English how much it will cost? No, we can’t. We don’t yet know how collaboration will look, and that factor alone will sway the actual costs more than anything directly related to the scope. </p><p><span>Poor communication creates rework. It's not unusual that </span><a href="https://brodzinski.com/2025/08/most-underestimated-factor-estimation.html" rel="nofollow ugc noopener">the quality of communication, or rather lack thereof, adds as much as an additional 100% to the effort</a><span>.</span></p><p>That compounds with the development of all unnecessary features. If you look at such a gig in hindsight, the value-adding work may stack up to just several percent of the whole effort.</p><p><span>Adding development speed would only exacerbate the problem. </span><em>The cost of rework doesn't pile up linearly.</em><span> Once you rework the rework, it's like a compound interest rate, except in reverse. Go figure what it does to the costs.</span></p><p><span>One of the many excellent observations Daniel Kahneman explains in his seminal book&nbsp;</span><a href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555" rel="nofollow ugc noopener">Thinking, Fast and Slow</a><span>&nbsp;is the following.</span></p><blockquote><p><em>"This is the essence of intuitive heuristics: when faced with a difficult question, we often answer an easier one instead, usually without noticing the substitution."</em></p><p>Daniel Kahneman</p></blockquote><p>We subconsciously avoid solving difficult problems by finding a similar one that's much easier to address. Then, we pretend the answer to the latter works as the answer to the former.</p><p>In that manner, we respond to the question about successful product development. We have little clue about what makes products successful. However, we certainly see that the most significant part of the effort is development. It takes a great deal of time and money to turn an idea into a product.</p><p>So we focus on the speed of development. And suddenly, we have an easy answer. We can make it faster. How? That's simple. Use AI.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!F-mQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!F-mQ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 424w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 848w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!F-mQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg" width="1129" height="587" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:587,&quot;width&quot;:1129,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:124559,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://pawelbrodzinski.substack.com/i/172659340?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!F-mQ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 424w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 848w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!F-mQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb3462bf-76e5-4c49-add9-6c6e2da3145a_1129x587.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Sorry to break it to you. </span><strong>Code does not equal product. What follows is that more code does not equal a better product.</strong><span> Often, it's the opposite.</span></p><p>Coding speed was never the bottleneck. Not even when we didn't have an AI shortcut.</p><p>If we stick to the context of product development, vibe coding promises us two things.</p><ul><li><p>We'll get the code fast.</p></li><li><p>We don't need to hire expensive technical expertise.</p></li></ul><p>Both parts miss the "coding speed was never the bottleneck" observation. Both respond to the simple question instead of the difficult one.</p><p>To make matters worse, the price we pay for removing ourselves from understanding the code is more rework. Yes, I know, we outsource that rework to an AI agent too, but we still need to drive it. And then all that rework stacks up. Remember compound interest rate in reverse?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Bd83!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Bd83!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 424w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 848w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 1272w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Bd83!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png" width="757" height="757" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:757,&quot;width&quot;:757,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:775135,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://pawelbrodzinski.substack.com/i/172659340?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Bd83!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 424w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 848w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 1272w, https://substackcdn.com/image/fetch/$s_!Bd83!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80e0c5c8-873b-4e21-a7e4-7676925f04dc_757x757.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Ultimately, using vibe coding as the main tactic to build a successful product is like solving a minor issue only to make the main problem a much bigger challenge.</p><p>The previous two parts of this informal vibe coding series:</p><div data-component-name="DigestPostEmbed"><a href="https://pawelbrodzinski.substack.com/p/vibe-coded-product-success-stories" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LFzr!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8075028f-418a-4a26-a9a4-b465db30b27d_1920x1080.jpeg"><img src="https://substackcdn.com/image/fetch/$s_!LFzr!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8075028f-418a-4a26-a9a4-b465db30b27d_1920x1080.jpeg" sizes="100vw" alt="Vibe-Coded Product Success Stories Ain't What They Look" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://pawelbrodzinski.substack.com/p/vibe-coding-doesnt-replace-tech-skills" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!D2Yp!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae64fdb1-9f66-4e2b-b041-2c556280d394_3664x2058.jpeg"><img src="https://substackcdn.com/image/fetch/$s_!D2Yp!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae64fdb1-9f66-4e2b-b041-2c556280d394_3664x2058.jpeg" sizes="100vw" alt="Vibe Coding Doesn't Replace Tech Skills; It Requires More of Them" width="140" height="140"></picture></div></a></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You're absolutely Right! (599 pts)]]></title>
            <link>https://absolutelyright.lol/</link>
            <guid>45137802</guid>
            <pubDate>Fri, 05 Sep 2025 12:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://absolutelyright.lol/">https://absolutelyright.lol/</a>, See on <a href="https://news.ycombinator.com/item?id=45137802">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>Claude Code said it <span id="today-inline">0</span> times today</p>
    

    <section>
      
      <p><span>
          <span></span>
          Absolutely right
        </span>
        <span>
          <span></span>
          Just right
        </span>
      </p>
    </section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI eats jobs, then offers to help you find a new one at Walmart (227 pts)]]></title>
            <link>https://www.theregister.com/2025/09/05/openai_jobs_board/</link>
            <guid>45137658</guid>
            <pubDate>Fri, 05 Sep 2025 12:17:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/09/05/openai_jobs_board/">https://www.theregister.com/2025/09/05/openai_jobs_board/</a>, See on <a href="https://news.ycombinator.com/item?id=45137658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>For those worried that AI is going to disrupt their jobs, OpenAI has the solution – take its certification and use a newly announced jobs board to find a new role.</p>
<p>On Thursday, Fidji Simo, OpenAI's head of applications (and <a target="_blank" href="https://www.theregister.com/2025/05/08/openai_apps_chif_instacart/">former</a> CEO of Instacart), announced the plan for workers to advertise themselves to the company's customers for new jobs. She said that while AI is going to shake up the employment market, who better to solve that problem than the people doing the shaking?</p>
<p>"AI will be disruptive. Jobs will look different, companies will have to adapt, and all of us – from shift workers to CEOs – will have to learn how to work in new ways," she said in a <a target="_blank" rel="nofollow" href="https://openai.com/index/expanding-economic-opportunity-with-ai/">blog post</a>.</p>

    

<p>"At OpenAI, we can't eliminate that disruption. But what we can do is help more people become fluent in AI and connect them with companies that need their skills, to give people more economic opportunities."</p>

        


        

<p>Simo's plan is that workers should take courses in tech literacy at its <a target="_blank" rel="nofollow" href="https://academy.openai.com/">OpenAI Academy</a> and then advertise themselves on a forthcoming jobs platform. She said the company has already signed up some big names to the scheme, although maybe the choice of Walmart as an early adopter might not encourage IT admins in their future career paths.</p>
<p>OpenAI declined to comment further on the plans.</p>

        

<p>"At Walmart, we know the future of retail won't be defined by technology alone – it will be defined by people who know how to use it," Walmart US CEO John Furner said in a canned statement.</p>
<p>"By bringing AI training directly to our associates, we're putting the most powerful technology of our time in their hands – giving them the skills to rewrite the playbook and shape the future of retail."</p>
<ul>

<li><a href="https://www.theregister.com/2025/09/03/ai_hiring_biased/">Biased bots: AI hiring managers shortlist candidates with AI resumes</a></li>

<li><a href="https://www.theregister.com/2025/04/03/openai_copyright_bypass/">OpenAI wants to bend copyright rules. Study suggests it isn't waiting for permission</a></li>

<li><a href="https://www.theregister.com/2025/07/24/white_house_wants_no_woke_ai/">White House bans 'woke' AI, but LLMs don't know the truth</a></li>

<li><a href="https://www.theregister.com/2025/08/28/microsoft_unveils_housemade_models_amid/">Microsoft unveils home-made ML models amid OpenAI negotiations</a></li>
</ul>
<p>The OpenAI Academy has had some big-name sign-ups, <a target="_blank" rel="nofollow" href="https://www.gatech.edu/news/2025/03/27/georgia-tech-leads-way-ai-literacy-openai-academy-collaboration">particularly</a> the respected computer science teachers at Georgia Tech, but Simo says that the business is pushing hard to build on a White House plan to make AI a core skill for American workers – so long as the engines they use aren't <a target="_blank" href="https://www.theregister.com/2025/07/24/white_house_wants_no_woke_ai/">too woke</a>.</p>
<p>What Simo didn't mention directly is that getting into the jobs market would bring the company into competition with Microsoft, one of its biggest backers. LinkedIn is the primary Western jobs site and OpenAI setting up a competitor might get in the way of cordial relations.</p>
<p>Microsoft had no comment on the matter, but OpenAI appears to be only scooping the AI cream, and whatever else floats to the top of the market, on its proposed employment register. There's also the question of whether or not the skills OpenAI is shilling will have any validity in the actual jobs market.</p>

        

<p>Meanwhile, CEO Sam Altman and most of the tech glitterati attended <a target="_blank" rel="nofollow" href="https://thehill.com/homenews/administration/5485218-trump-host-tech-ceos-rose-garden/">a dinner</a> hosted by First Lady Melania Trump to discuss AI last night. Elon Musk wasn't there, but <a target="_blank" rel="nofollow" href="https://x.com/elonmusk/status/1963624123998896368">insists</a> he was invited. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Ditched Docker for Podman (and You Should Too) (906 pts)]]></title>
            <link>https://codesmash.dev/why-i-ditched-docker-for-podman-and-you-should-too</link>
            <guid>45137525</guid>
            <pubDate>Fri, 05 Sep 2025 11:56:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codesmash.dev/why-i-ditched-docker-for-podman-and-you-should-too">https://codesmash.dev/why-i-ditched-docker-for-podman-and-you-should-too</a>, See on <a href="https://news.ycombinator.com/item?id=45137525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><h2 id="heading-beginnings">Beginnings</h2>
<p>I'm old enough to remember when Vagrant looked like a promised land where every development environment would look the same. Differences between language versions, as well as some unusual OS version differences, resulted in a few days of unproductive debugging of your development environment. I've had similar excitement when I started my first Docker Swarm (who uses that these days?!) - it felt revolutionary. Docker wasn't just a tool - it fundamentally changed how we thought about application development and deployment. Having a repeatable, separated environment from your local system was refreshing and looked like a superpower. It has become a must-have tool for every engineer. "<em>Just Dockerize it</em>" became my go-to solution for pretty much everything. Sure, architecture or defining a new Docker image could be a bit finicky at times, but hey, that's just how things worked. Is the persistent dockerd daemon eating upresources in the background with root privileges, just the price of doing business? I thought so.</p>
<p>If you are in this industry long enough, there is one pattern that emerges every day. Everybody begins questioning the "that's just how it's done" mentality. Along the way, the quiet Docker daemon running in the background felt less like a comfortable constant and more like a ticking bomb. More and more ways to explore this vulnerability emerged:</p>
<p><strong>2019-02-11 - CVE-2019-5736 (runC container escape):</strong> lets a process in a container overwrite the host’s runc binary → full host compromise if exploited.</p>
<p><strong>2022-03-07 - CVE-2022-0847 “Dirty Pipe” (Linux kernel):</strong> read-only file overwrite in kernel; practical container-to-host abuse scenarios documented by Docker/Sysdig. </p>
<p><strong>2022-03-07 - CVE-2022-0492 (cgroups v1 release_agent):</strong> privilege escalation / container escape via cgroups v1; mitigations via seccomp/AppArmor/SELinux. </p>
<p><strong>2024-01-31 - CVE-2024-21626 (runC “Leaky Vessels”):</strong> fd leak + process.cwd issues enabling host FS access and potential escape; fixed in runC <strong>1.1.12</strong> (Docker Engine ≥ <strong>25.0.2</strong>). </p>
<p><strong>2024-02-01 - CVE-2024-23651/23652/23653 (BuildKit, “Leaky Vessels”):</strong> build-time issues that can affect host files; fixed in BuildKit <strong>0.12.5</strong>. </p>
<p><strong>2024-09-23 - In-the-wild cryptojacking campaign:</strong> attackers targeted exposed Docker APIs and microservices. </p>
<p><strong>2024-10-01 - Docker API swarm botnet campaign:</strong> cryptojacking via exposed Docker Engine API (<a target="_blank" href="https://securitylabs.datadoghq.com/articles/threat-actors-leveraging-docker-swarm-kubernetes-mine-cryptocurrency/">details</a>).</p>
<p>I had been seeking an alternative (I assumed that someone had already questioned the status quo), and that's how I stumbled into Podman territory. It began as casual curiosity - "<em>Hey, let me check out this thing</em>" - turned into a complete overhaul of my container workflows and pulled me into using Fedora in my home lab. And honestly? I wish I'd made the switch sooner.</p>
<h2 id="heading-daemonless">Daemonless</h2>
<p>Here's the fundamental issue that kept me awake: Docker's entire architecture is built around a persistent background service - the dockerd daemon. Whenever you run a docker command, you're actually talking to this daemon, which then does the heavy lifting. Sounds about right?</p>
<p>Yes?!</p>
<p>Or rather NO, because this daemon runs with root privileges. Always. And if something goes south with a daemon - innocent bug, a crash, or worst case scenario, a security exploit - your entire container ecosystem is potentially compromised. Not just the containers, daemon, or resource that you assigned to it, but the whole host system. It was a huge relief that Podman threw this model out the window. No daemon, no processes running in the background. When you run <code>podman run my-app</code>, the container becomes a direct child of your command. And it is running under your user privileges. Simple architecture change with huge implications:</p>
<h3 id="heading-security-that-actually-makes-sense">Security that actually makes sense:</h3>
<p>Remember those late-night security advisories about Docker daemon vulnerabilities (ex., when dockerd was misconfigured to listen on TCP:2375 without TLS, attackers could spin up privileged containers remotely)? With Podman, even if someone somehow escalates privileges inside a container to root level, they're still just an unprivileged user on the actual host. It significantly reduces the surface of an attack.</p>
<h3 id="heading-no-more-single-points-of-failure">No more single points of failure:</h3>
<p>Usually Docker daemon runs just fine. But when hiccups kick in - oh boy, hold your hats, as it will take down multiple containers at once. With Podman when one container crashed, the other kept running like nothing happened. It makes so much sense, and it's built in the spirit of hermetization.</p>
<h3 id="heading-lighter-resource-footprint">Lighter resource footprint:</h3>
<p>I had been surprised when my MacBook M2 Pro started to get warmer when left unattended. After a brief investigation (with Activity Monitor), it was obvious - Docker never knows when to stop. No constantly running daemon means less memory usage. Unfortunately, running a container using Podman can be a different story (ekhm: <a href="https://blog.podman.io/2025/06/podman-and-apple-rosetta/" target="_blank">blog.podman.io/2025/06/podman-and-apple-ros..</a>) - yet the thing is getting better: <a href="https://blog.podman.io/2025/08/podman-5-6-released-rosetta-status-update/" target="_blank">blog.podman.io/2025/08/podman-5-6-released-..</a>.</p>
<h2 id="heading-where-podman-really-shines">Where Podman Really Shines</h2>
<p>Beyond the obvious daemon advantages, Podman brings some genuinely clever features that make day-to-day container work more pleasant:</p>
<p><strong>Systemd integration that doesn't suck:</strong> This one's huge if you're working on Linux servers (most of us are). Podman justgenerates proper systemd unit files. Boom, your container is a first-class citizen in the Linux service ecosystem. Boot dependencies, automatic restarts, resource limits - it all just works. I can run <code>podman generate systemd --name my-app</code> and get a clean service file. Afterwards, I can enable, start, stop, and monitor with standard systemctl commands. Say bye-bye to third-party process managers.</p>
<p><strong>Kubernetes alignment that's not just marketing:</strong> Since Red Hat (the folks behind Podman) is also a major Kubernetes contributor, the tool feels like it was designed with K8s in mind from day one. The native pod support isn't just a bolt-on feature - it's central to how Podman works. I do not need to run k3s or any local substitute for Kubernetes. Now, I can prototype multi-container applications as Podman pods locally. Then I just generate Kubernetes YAML directly from those pods with podman generate kube. My local development environment actually looks like what I'm going to deploy. This was revolutionary when I had to take over the responsibility of managing and developing a quite complex cluster.</p>
<p><strong>The Unix philosophy done right:</strong> Instead of trying to be everything to everyone, Podman focuses on running containers well and delegates specialized tasks to purpose - built tools. Need to build images with fine - grained control? That's Buildah. Want to inspect or copy images between registries? Skopeo's your friend. I can use the best tool for each job. I'm no longer stuck with whatever image-building quirks Docker decides to implement.</p>
<h2 id="heading-the-migration-that-wasnt-really-a-migration">The Migration That Wasn't Really a Migration</h2>
<p>Here's the part that surprised me most: switching from Docker to Podman was almost seamless. The Podman folks clearly understood that creating the next standard would not let them win the market, and they just adhered to the known CLI tool. I literally just aliased <code>docker=podman</code> in my shell and carried on with life. <code>podman run, podman build, podman ps</code> - they all behave exactly like their Docker counterparts. My existing Dockerfiles worked without modification. My muscle memory didn't need retraining.</p>
<p>Though there were a few places where I did hit differences that were actually improvements in disguise:</p>
<ul>
<li><p>Privileged ports in rootless mode not working? Good! That's security working as intended. A reverse proxy setup is a better architecture anyway.</p>
</li>
<li><p>Some volume permission quirks? Yes - but it's a small price, and again - if you do it right, you are limiting the scope of possible attack.</p>
</li>
<li><p>A few legacy tools that expected the Docker socket? If there is no support by now, just remember that Podman can expose a Docker-compatible API if needed.</p>
</li>
<li><p>If your Docker Compose workflow is overly complex, just convert it to Kubernetes YAML. We all use Kubernetes these days, so why even bother about this? Having the same layout for development and production is a huge bonus of doing so.</p>
</li>
</ul>
<h2 id="heading-the-real-world-difference">The Real-World Difference</h2>
<p>After six months of running Podman in production, here's what I've noticed:</p>
<p>I'm sleeping much better. Because I'm personally responsible for security, I do not have to check if every container is running in rootless mode. Something that I did not think I would benefit from is that my monitoring dashboards show cleaner resource usage patterns. Don't get me wrong - Docker isn't going anywhere. It has massive momentum, a mature ecosystem, and plenty of organizational inertia keeping it in place. But for new projects, or if you are able to make technical decisions based on merit rather than legacy, Podman represents a clear evolution in container technology. More secure by design, more aligned with Linux system management practices, and more thoughtfully architected for the way we actually deploy containers in 2025. The best way forward is to question the assumptions you didn't even realize you were making.</p>
<h2 id="heading-fastapi-migration-guide-from-docker-to-podman">FastAPI Migration Guide: From Docker to Podman</h2>
<p>Just to prove how easy transition can be, here's a practical walkthrough of migrating a FastAPI application from Docker to Podman.  </p>
<h3 id="heading-what-youll-need">What You'll Need</h3>
<p>Your existing FastAPI project with its Dockerfile and requirements.txt</p>
<p>Podman is installed on your system:</p>
<ul>
<li><p>Ubuntu/Debian: sudo apt update &amp;&amp; sudo apt install podman</p>
</li>
<li><p>Fedora/RHEL: sudo dnf install podman</p>
</li>
<li><p>macOS: Grab Podman Desktop for a GUI experience</p>
</li>
<li><p>Windows: If you are not a C# developer - stop doing this to yourself and just use Linux: <a href="https://www.youtube.com/watch?v=S_RqZG6YR5M" target="_blank">youtube.com/watch?v=S_RqZG6YR5M</a></p>
</li>
</ul>
<h3 id="heading-step-1-your-dockerfile-probably-just-works">Step 1: Your Dockerfile Probably Just Works</h3>
<p>This is the beautiful part—Podman uses the same OCI container format as Docker. Your existing Dockerfile should work without any changes. Here's a typical FastAPI setup:</p>
<pre><code>FROM python:3.10-slim-buster

WORKDIR /app

COPY requirements.txt .

RUN pip install --no-cache-dir --upgrade -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
</code></pre>
<h3 id="heading-step-2-build-your-image">Step 2: Build Your Image</h3>
<p>Instead of docker build, just run:</p>
<pre><code>podman build -t my-fastapi-app:latest .
</code></pre>
<p>That's it. Same flags, same behavior, same output. If you want to ease the transition, create an alias:</p>
<pre><code><span>alias</span> docker=podman
</code></pre>
<p>Now you can use your existing docker build commands without thinking about it.</p>
<h3 id="heading-step-3-run-your-container">Step 3: Run Your Container</h3>
<p>For development and testing:</p>
<pre><code>podman run --rm -p 8000:8000 --name my-fastapi-container my-fastapi-app:latest
</code></pre>
<p>For background services:</p>
<pre><code>podman run -d -p 8000:8000 --name my-fastapi-container my-fastapi-app:latest
</code></pre>
<p>Your app should be accessible at <a href="http://localhost:8000/" target="_blank">localhost:8000</a> just like before.</p>
<p><strong>Important note:</strong> <em>By default, Podman runs in rootless mode. This is a security win, but it means you can't bind directly to privileged ports (below 1024). For production, you'll want a reverse proxy anyway, so this pushes you toward better architecture.</em></p>
<h3 id="heading-step-4-production-deployment-with-systemd">Step 4: Production Deployment with Systemd</h3>
<p>This is where Podman really shines. Instead of wrestling with custom service management, generate a proper systemd unit file:</p>
<pre><code><span># First, make sure your container is running</span>

podman run -d -p 8000:8000 --name my-fastapi-container my-fastapi-app:latest

<span># Generate the systemd service file</span>

mkdir -p ~/.config/systemd/user/

podman generate systemd --name my-fastapi-container &gt; ~/.config/systemd/user/my-fastapi-container.service

<span># Enable and start the service</span>

systemctl --user daemon-reload

systemctl --user <span>enable</span> my-fastapi-container.service

systemctl --user start my-fastapi-container.service
</code></pre>
<p>Now your FastAPI app is managed like any other system service. It'll start on boot, restart on failure, and integrate with standard Linux logging and monitoring tools.</p>
<p>For server deployments where you want the service to persist even when you're not logged in:</p>
<p>loginctl enable-linger $(whoami)</p>
<h3 id="heading-step-5-multi-service-applications-with-pods">Step 5: Multi-Service Applications with Pods</h3>
<p>If your FastAPI app needs a database or other services, Podman's pod concept is cleaner than Docker Compose for simple setups:</p>
<pre><code><span># Create a pod that shares networking</span>
podman pod create --name my-fastapi-pod -p 8000:8000 -p 5432:5432

<span># Run your FastAPI app in the pod</span>

podman run -d --pod my-fastapi-pod --name fastapi-app my-fastapi-app:latest

<span># Run PostgreSQL in the same pod</span>

podman run -d --pod my-fastapi-pod --name postgres-db -e POSTGRES_PASSWORD=mysecretpassword postgres:13
</code></pre>
<p>Now your FastAPI app can reach PostgreSQL at localhost:5432 because they share the same network namespace.</p>
<h3 id="heading-step-6-docker-compose-compatibility">Step 6: Docker Compose Compatibility</h3>
<p>For existing Docker Compose setups, you have options:</p>
<p><strong>Option 1:</strong> Use podman-compose as a drop-in replacement:</p>
<pre><code>pip install podman-compose

podman-compose up -d
</code></pre>
<p><strong>Option 2:</strong> Convert to Kubernetes YAML for a more cloud-native approach:</p>
<pre><code><span># Install kompose first</span>

kompose convert -f docker-compose.yml -o k8s-manifest.yaml

podman play kube k8s-manifest.yaml
</code></pre>
<p>This second option is particularly nice if you're planning to deploy to Kubernetes eventually.</p>
<p><strong>Common Gotchas and Solutions</strong></p>
<p><strong>Volume permissions:</strong> If you hit permission issues with mounted volumes, remember that rootless containers run as your user. Make sure your user owns the directories you're mounting:</p>
<pre><code>chown -R $(id -un):$(id -gn) /path/to/your/data
</code></pre>
<p><strong>Legacy tooling:</strong> Some tools expect the Docker socket at /var/run/docker.sock. Podman can provide a compatible API:</p>
<pre><code>systemctl --user <span>enable</span> podman.socket

systemctl --user start podman.socket

<span>export</span> DOCKER_HOST=unix://<span>$XDG_RUNTIME_DIR</span>/podman/podman.sock
</code></pre>
<p><strong>Performance tuning:</strong> For production workloads, you might want to tune the rootless networking stack or consider running specific containers in rootful mode for maximum performance.</p>
<p>The migration process is usually much smoother than people expect. Start with a development environment, get comfortable with the workflow differences, then gradually move production workloads. The security and operational benefits make it worth the effort.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ML needs a new programming language – Interview with Chris Lattner (224 pts)]]></title>
            <link>https://signalsandthreads.com/why-ml-needs-a-new-programming-language/</link>
            <guid>45137373</guid>
            <pubDate>Fri, 05 Sep 2025 11:33:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signalsandthreads.com/why-ml-needs-a-new-programming-language/">https://signalsandthreads.com/why-ml-needs-a-new-programming-language/</a>, See on <a href="https://news.ycombinator.com/item?id=45137373">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
		<h2>Why ML Needs a New Programming Language</h2>
		<h4>with Chris Lattner</h4>
		<h5>
			
				Season 3, Episode 10 &nbsp;&nbsp;|&nbsp;&nbsp;
			
			September 3rd, 2025
		</h5>
		
	</p><div>
		<h3 id="blurb">BLURB</h3>

<p>Chris Lattner is the creator of LLVM and led the development of the Swift language at
Apple. With Mojo, he’s taking another big swing: How do you make the process of getting
the full power out of modern GPUs productive and fun? In this episode, Ron and Chris
discuss how to design a language that’s easy to use while still providing the level of
control required to write state of the art kernels. A key idea is to ask programmers to
fully reckon with the details of the hardware, but making that work manageable and
shareable via a form of type-safe metaprogramming. The aim is to support both
specialization to the computation in question as well as to the hardware platform.
“Somebody has to do this work,” Chris says, “if we ever want to get to an ecosystem where
one vendor doesn’t control everything.”</p>

<h3 id="summary">SUMMARY</h3>

<p>Chris Lattner is the creator of LLVM and led the development of the Swift language at
Apple. With Mojo, he’s taking another big swing: How do you make the process of getting
the full power out of modern GPUs productive and fun? In this episode, Ron and Chris
discuss how to design a language that’s easy to use while still providing the level of
control required to write state of the art kernels. A key idea is to ask programmers to
fully reckon with the details of the hardware, but making that work manageable and
shareable via a form of type-safe metaprogramming. The aim is to support both
specialization to the computation in question as well as to the hardware platform.
“Somebody has to do this work,” Chris says, “if we ever want to get to an ecosystem where
one vendor doesn’t control everything.”</p>

<p>Some links to topics that came up in the discussion:</p>

<ul>
  <li><a href="https://www.modular.com/blog/democratizing-compute-part-1-deepseeks-impact-on-ai">Democratizing AI
compute</a>
(an 11-part series)</li>
  <li><a href="https://www.modular.com/">Modular AI</a></li>
  <li><a href="https://www.modular.com/mojo">Mojo</a></li>
  <li><a href="https://mlir.llvm.org/">MLIR</a></li>
  <li><a href="https://www.swift.org/">Swift</a></li>
</ul>

<h3 id="transcript">TRANSCRIPT</h3>

<h2 id="000003">00:00:03</h2>
<h2 id="ron">Ron</h2>
<p>Welcome to Signals and Threads, in-depth conversations about every layer of the tech
stack, from Jane Street. I’m Ron Minsky. It is my great pleasure to have Chris Lattner on
the show. Typically on Signals and Threads, we end up talking to engineers who work here
at Jane Street, but sometimes we like to grab outside folk, and Chris is an amazing figure
to bring on because he’s been so involved in a bunch of really foundational pieces of
computing that we all use—LLVM, and Clang, and MLIR, and OpenCL, and Swift, and now
Mojo. And this has happened at a bunch of different storied institutions—Apple, and Tesla,
and Google, and SiFive, and now Modular. So anyway, it’s a pleasure to have you joining
us, Chris.</p>

<h2 id="000043">00:00:43</h2>
<h2 id="chris">Chris</h2>
<p>Thank you, Ron. I’m so happy to be here.</p>

<h2 id="000045">00:00:45</h2>
<h2 id="ron-1">Ron</h2>
<p>I guess I want to start by just hearing a little bit more about your origin story. How did
you get into computing and how did you get into this world of both compiler engineering
and programming language design?</p>

<h2 id="000054">00:00:54</h2>
<h2 id="chris-1">Chris</h2>
<p>So I grew up in the ’80s and back before computers were really a thing. We had PCs, but
they weren’t considered cool. And so I fell in love with understanding how the computer
worked. And back then, things were way simpler. I started with a BASIC interpreter, for
example, and you’d get a book from the store. Remember when we had books? [laughs] And
you’d learn things from books?</p>

<h2 id="000114">00:01:14</h2>
<h2 id="ron-2">Ron</h2>
<p>Did you do the thing where you’d get the hobbyist magazine and copy out the listing of the
program?</p>

<h2 id="000119">00:01:19</h2>
<h2 id="chris-2">Chris</h2>
<p>That’s exactly right. And so we didn’t have vibe coding, but we did have books. And so
just by typing things in, you could understand how things work, and then when you broke
it—because inevitably you’re typing something in and you don’t really know what you’re
doing—you have to figure out what went wrong and so it encouraged a certain amount of
debugging. I really love computer games. Again, back then, things were a little bit
simpler. Computer games drove graphics and performance and things like this. And so I
spent some time on these things called bulletin board systems and the early internet
reading about how game programmers are trying to push the limits of the hardware. And so
that’s where I got interested in performance and computers and systems. I went on to
college and had an amazing professor at my school, shout out to University of Portland in
Portland, Oregon, and he was a compiler nerd.</p>

<p>And so, I think that his love for compilers was infectious. His name was Steven Vegdahl,
and that caused me to go on to pursue compilers at University of Illinois. And there
again, continue to fall down this rabbit hole of compilers and systems, and build
LLVM. And ever since I got into the compiler world, I loved it. I love compilers because
they’re large-scale systems, there’s multiple different components that all work
together. And in the university setting, it was really cool in the compiler class, because
unlike most of the assignments where you do an assignment, turn it in, forget about it—in
compilers, you would do an assignment, turn it in, get graded, and then build on it. And
it felt much more realistic like software engineering, rather than just doing a project to
get graded.</p>

<h2 id="000235">00:02:35</h2>
<h2 id="ron-3">Ron</h2>
<p>Yeah, I think for a lot of people, the OS class is their first real experience of doing a
thing where you really are building layer on top of layer. I think it’s an incredibly
important experience for people as they start engineering.</p>

<h2 id="000244">00:02:44</h2>
<h2 id="chris-3">Chris</h2>
<p>It’s also one where you get to use some of those data structures. I took this, almost
academic, here’s what a binary tree is, and here’s what a graph is. And particularly when
I went through it, it was taught from a very math-forward perspective, but it really made
it useful. And so that was actually really cool. I’m like, ‘Oh, this is why I learned this
stuff.’</p>

<h2 id="000259">00:02:59</h2>
<h2 id="ron-4">Ron</h2>
<p>So one thing that strikes me about your career is that you’ve ended up going back and
forth between compiler engineering and language design space, whereas I feel like a lot of
people are on one side or the other—they’re mostly compilers people and they don’t care
that much about the language, and just, how do we make this thing go fast? And there are
some people who are really focusing on language design and the work on the compiler is a
secondary thing towards that design. And you’ve both popped back and forth. And then also
a lot of your compiler engineering work, really starting with LLVM, in some sense is
itself, very language-forward. With LLVM, there’s a language in there that’s this
intermediate language that you’re surfacing as a tool for people to use. So I’m just
curious to hear more about how you think about the back and forth between compiler
engineering and language design.</p>

<h2 id="000339">00:03:39</h2>
<h2 id="chris-4">Chris</h2>
<p>The reason I do this is that effectively, my career is following my own interests. And so
my interests are not static. I want to work on different kinds of problems and solve
useful problems and build into things. And so the more technology and capability you have,
the higher you can reach. And so with LLVM, for example, built and learned a whole bunch
of cool stuff about deep code generation for an X86 chip and that category of technology
with register allocation, stuff like this. But then it made it possible to go, say, let’s
go tackle C++ and let’s go use this to build the world’s best implementation of something
that lots more people use and understand than deep backend code generation technology. And
then with Swift, it was, build even higher and say, ‘Okay, well C++, maybe some people
like it, but I think we can do better and let’s reach higher.’ I’ve also been involved in
AI systems, been involved in building an iPad app to help teach kids how to code. And so,
lots of different things over time. And so for me, the place I think I’m most useful and
where a lot of my experience is valuable ends up being at this hardware-software boundary.</p>

<h2 id="000436">00:04:36</h2>
<h2 id="ron-5">Ron</h2>
<p>I’m curious how you ended up making the leap to working on Swift. From my perspective,
Swift looks from the outside, like one of these points of arrival in mainstream
programming contexts of a bunch of ideas that I have long thought are really great ideas
in other programming languages. And I’m curious, in some ways a step away from like, oh,
I’m going to work on really low-level stuff and compiler optimization, and then we will go
much higher level and do a C++ implementation, which is still a pretty low level. How did
the whole Swift thing happen?</p>

<h2 id="000500">00:05:00</h2>
<h2 id="chris-5">Chris</h2>
<p>Great question. I mean, the timeframe for people that aren’t familiar is that LLVM started
in 2000. So by 2005, I had exited university and I joined Apple. And so LLVM was an
advanced research project at that point. By the 2010 timeframe, LLVM was much more mature
and we had just shipped C++ support in Clang, and so it could bootstrap itself, which
means the compiler could compile itself. It’s all written in C++, it could build advanced
libraries like the Boost template library, which is super crazy advanced template
stuff. And so the C++ implementation that I and the team had built was real. Now, C++ in
my opinion, is not a beautiful programming language. And so implementing it is a very
interesting technical challenge. For me, a lot of problem-solving ends up being, how do
you factor the system the right way?</p>

<p>And so Clang has some really cool stuff that allowed it to scale and things like that, but
I was also burned out. We had just shipped it. It was amazing. I’m like, there has to be
something better. And so, Swift really came starting in 2010. It was a nights and weekends
project. It wasn’t like top-down management said, ‘Let’s go build a new programming
language.’ It was ‘Chris being burned out’—I was running a 20 to 40 person team at the
time, being an engineer during the day, and being a technical leader, but then needing an
escape hatch. And so I said, ‘Okay, well, I think we can have something better. I have a
lot of good ideas. Turns out, programming languages are a mature space. It’s not like you
need to invent pattern matching at this point. It’s embarrassing that C++ doesn’t have
good pattern matching.</p>

<h2 id="000623">00:06:23</h2>
<h2 id="ron-6">Ron</h2>
<p>We should just pause for a second, because I think this is like a small but really
essential thing. I think the single best feature coming out of language like ML in the
mid-seventies is, first of all, this notion of an algebraic data type, meaning every
programming language on earth has a way of saying this and that and the other, a record,
or a class, or a tuple.</p>

<h2 id="000638">00:06:38</h2>
<h2 id="chris-6">Chris</h2>
<p>A weird programming language, I think it was Barbara Liskov?</p>

<h2 id="000641">00:06:41</h2>
<h2 id="ron-7">Ron</h2>
<p>Yeah. And she did a lot of the early theorizing about, ‘What are abstract data types?’ But
the ability to do this or that or the other, to have data types that are a union of
different possible shapes of the data—and then having this pattern matching facility that
lets you basically in a reliable way do the case analysis so you can break down what the
possibilities are—is just incredibly useful. And very few mainstream languages have picked
it up. I mean Swift again is an example, but languages like ML, SML, and Haskell, and
OCaml—</p>

<h2 id="000709">00:07:09</h2>
<h2 id="chris-7">Chris</h2>
<p>Standard!</p>

<h2 id="000710">00:07:10</h2>
<h2 id="ron-8">Ron</h2>
<p>That’s right. SML. Standard ML. It’s been there for a long time.</p>

<h2 id="000712">00:07:12</h2>
<h2 id="chris-8">Chris</h2>
<p>I mean pattern matching, it is not an exotic feature. Here we’re talking about 2010. C#
didn’t have it. C++ didn’t have it. Obviously Java didn’t have it. I don’t think
JavaScript had it. None of these mainstream languages had it, but it’s obvious. And so
part of my opinion about that—and so by the way, I represent as engineer, I’m not actually
a mathematician, and so type theory goes way over my head. I don’t really understand
this. The thing that gets me frustrated about the academic approach to programming
languages is that people approach it by saying there’s sum types, and there’s intersection
types, and there’s these types, and they don’t start from utility forward. And so pattern
matching, when I learned OCaml, it’s so beautiful. It makes it so easy and expressive to
build very simple things. And so to me, I always identify to the utility and then yes,
there’s amazing formal type theory behind it, and that’s great and that’s why it actually
works and composes. But bringing that stuff forward and focusing on utility and the
problems it solves, and how it makes people happy, ends up being the thing that I think
moves the needle in terms of adoption, at least in mainstream.</p>

<h2 id="000809">00:08:09</h2>
<h2 id="ron-9">Ron</h2>
<p>Yeah, I mean I think that’s right. My approach also, and my interest in language is also
very much not from the mathematical perspective, although my undergraduate degree is in
math. I like math a lot, but I mostly approach these things as a practitioner. But the
thing I’ve been struck by over the years is the value of having these features have a
really strong mathematical foundation is they generalize, and as you were saying, compose
much better. If they are in the end mathematically simple, you’re way more likely to have
a feature that actually pans out as it gets used way beyond your initial view as to what
the thing was for.</p>

<h2 id="000839">00:08:39</h2>
<h2 id="chris-9">Chris</h2>
<p>That’s right. This is actually a personal defect because I don’t understand the math in
the way that maybe theoretically would be ideal. I end up having to rediscover certain
truths that are obvious. The cliche, ‘If the Russian mathematician invented it 50 years
ago…’ And so a lot of what I find is that I can find truth and beauty when things compose
and things fit together, and often I’ll find out it’s already been discovered because
everything in programming language has been done. There’s almost nothing novel, but still
that design process of saying, let’s pull things together, let’s reason about why it
doesn’t quite fit together. Let’s go figure out how to better factor this. Let’s figure
out how to make it simpler these days. That process to me, I think is kind of like people
working on physics, [from what] I hear. The simpler the outcome becomes, the more close to
truth it feels like it is. And so I share that—and maybe it’s more design gene or
engineer-design combination, but it’s probably what you mathematicians actually know
inherently, and I just haven’t figured it out yet.</p>

<h2 id="000933">00:09:33</h2>
<h2 id="ron-10">Ron</h2>
<p>Do you find yourself doing things after you come to it from an engineering perspective,
trying to figure out whether there are useful mathematical insights? Do you go back and
read the papers? Do you have other PL people who are more mathematically oriented who you
talk to? How do you extend your thinking to cover some of that other stuff?</p>

<h2 id="000947">00:09:47</h2>
<h2 id="chris-10">Chris</h2>
<p>See, the problem is math is scary to me. So I see Greek letters and I run away. I do
follow arXiv and things like this, and there’s a programming language section on that. And
so I get into some of it, but what I get attracted to in that is the examples and the
results section and the future-looking parts of it. And so it’s not necessarily the ‘how,’
it’s the ‘what it means.’ And so I think a lot of that really speaks to me. The other
thing that really speaks to me when you talk about language design and things like this is
blog posts from some obscure academic programming language that I’ve never heard of. You
just have somebody talking about algebraic effect systems for this and that and the other
thing, or something really fancy, but they figure out how to explain it in a way that’s
useful. And so when it’s not just, ‘Let me explain to you the type system,’ but it’s, ‘Let
me explain this problem this fancy feature enables,’ that’s where I get excited. That’s
where it speaks to me because, again, I’m problem-oriented, and having a beautiful way to
express and solve problems, I appreciate.</p>

<h2 id="001038">00:10:38</h2>
<h2 id="ron-11">Ron</h2>
<p>I think there’s a lot of value in the work that’s done in papers of really working out in
detail the theory and the math and how it all fits together. [And] I think the fact that
the world has been filled with a lot of interesting blog posts from the same people has
been great because I think it’s another modality where it often encourages you to pull out
the simpler and easier-to-consume versions of those ideas. And I think that is just a
different kind of insight and it’s valuable to surface that too.</p>

<h2 id="001059">00:10:59</h2>
<h2 id="chris-11">Chris</h2>
<p>And also when I look at those blog posts, sometimes they design smell. Particularly the
C++ community, there’s a lot of really good work to fix C++. They’re adding a lot of stuff
to it, and C++ will never get simpler—you can’t really remove things, right? And so a lot
of the challenge there is, it’s constrained problem-solving. And so when I look at that,
often what I’ll see when I’m reading one of those posts, and again, these are brilliant
people and they’re doing God’s work trying to solve problems with C++, best of luck with
that. But you look at that and you realize there’s a grain of sand in the system that
didn’t need to be there. And so to me, it’s like if you remove that grain of sand, then
the entire system gets relaxed and suddenly all these constraints fall away and you can
get to something much simpler. Swift, for example, it’s a wonderful language and it’s
grown really well and the community is amazing, but it has a few grains of sand in it that
cause it to be a lot more complicated. And so this is where I’m not just happy with things
that got built. LLVM is amazing, it’s very practical, but it has lots of problems. That’s
why when I get a chance to build a next generation system, I want to learn from that and
actually try to solve these problems.</p>

<h2 id="001156">00:11:56</h2>
<h2 id="ron-12">Ron</h2>
<p>So this is the great privilege of getting to work on a new language, which is a thing
you’re doing now. There’s this new language called Mojo, and it’s being done by this
company that you co-founded called Modular. Maybe just so we understand the context a
little bit, can you tell me a little bit about, what is Modular? What’s the basic
offering? What’s the business model?</p>

<h2 id="001212">00:12:12</h2>
<h2 id="chris-12">Chris</h2>
<p>Before I even get there, I’ll share more of how I got here. If you oversimplify my
background, I did this LLVM thing and its foundational compiler technology for CPUs. It
helped unite a lot of CPU-era infrastructure and it provided a platform for languages like
Swift, but also Rust, and Julia, and many different systems that all got built on top of,
and I think it really catalyzed and enabled a lot of really cool applications of
accelerated compiler technology. People use LLVM in databases and for query engine
optimization, lots of cool stuff. Maybe you use it for trading or something. I mean, there
can be tons of different applications for this kind of technology—and then [I] did
programming language stuff with Swift. But in the meantime, AI happened. And so with AI
brought this entirely new generation of compute: GPUs, tensor processing units,
large-scale AI training systems, FPGAs, and ASICs and all this complexity for compute, and
LLVM never really worked in that system.</p>

<p>And so one of the things that I built when I was at Google was a bunch of foundational
compiler technology for that category of systems. And there’s this compiler technology
called MLIR. MLIR is basically LLVM 2.0. And so take everything you learn from building
LLVM and helping solve this, but then bring it forward into this next generation of
compiler technology so that you can go hopefully unify the world’s compute for this GPU
and AI and ASIC kind of world. MLIR has been amazingly successful, and I think it’s used
in roughly every one of these AI systems and GPUs. It’s used by Nvidia, it’s used by
Google, it’s used by roughly everybody in this space. But one of the challenges is that
there hasn’t been unification. And so you have these very large-scale AI software
platforms. You have CUDA from Nvidia, you have XLA from Google, you have ROCm from AMD.</p>

<p>It’s countless. Every company has their own software stack. And one of the things that I
discovered and encountered, and I think the entire world sees, is that there’s this
incredible fragmentation driven by the fact that each of these software stacks built by a
hardware maker are just all completely different. And some of them work better than
others, but regardless, it’s a gigantic mess. And there’s these really cool high-level
technologies like PyTorch that we all love and we want to use. But if PyTorch is built on
completely different stacks and schooling together these megalithic worlds from different
vendors, it’s very difficult to get something that works.</p>

<h2 id="001417">00:14:17</h2>
<h2 id="ron-13">Ron</h2>
<p>Right. They’re both complicated trade-offs around the performance that you get out of
different tools and then also a different set of complicated trade-offs around how hard
they are to use, how complicated it is to write something in them, and then what hardware
you can target from each individual one. And each of these ecosystems is churning just
incredibly fast. There’s always new hardware coming out and new vendors in new places, and
there’s also new little languages popping up into existence, and it makes the whole thing
pretty hard to wrangle.</p>

<h2 id="001442">00:14:42</h2>
<h2 id="chris-13">Chris</h2>
<p>Exactly. And AI is moving so fast. There’s a new model every week. It’s crazy. And new
applications, new research, the amount of money being dumped into this by everybody is
just incredible. And so how does anybody keep up? It’s a structural problem in the
industry. And so the structural problem is that the people doing this kind of work, the
people doing code generation for advanced GPUs and things like this, they’re all at
hardware companies. And the hardware companies, every single one of them is building their
own stack because they have to. There is nothing to plug into. There’s nothing like ‘LLVM
but for AI,’ that doesn’t exist. And so as they go and build their own vertical software
stack, of course they’re focused on their hardware, they got advanced roadmaps, they have
a new chip coming out next year, they’re plowing their energy and time into solving for
their hardware. But we, out in the industry, we actually want something else. We want to
be able to have software that runs across multiple pieces of hardware. And so, if
everybody doing the work is at a hardware company, it’s very natural that you get this
fragmentation across vendors because nobody’s incentivized to go work together. And even
if they’re incentivized, they don’t have time to go work on somebody else’s chip. AMD is
not going to pay to work on Nvidia GPUs or something like this.</p>

<h2 id="001545">00:15:45</h2>
<h2 id="ron-14">Ron</h2>
<p>That’s true when you think about this, kind of, a split between low-level and high-level
languages. So Nvidia has CUDA and AMD has ROCm, which is mostly a clone of CUDA, and then
the XLA tools from Google work incredibly well on TPUs, and so on and so forth. Different
vendors have different things. Then there’s the high-level tools, PyTorch, and JAX, and
Triton, and various things like that. And those are typically actually not made by the
hardware vendors. Those are made by different kinds of users—I guess Google is responsible
for some of these and they’re also sometimes a hardware vendor—but a lot of the time it’s
more stepped back. Although even there, the cross-platform support is complicated and
messy and incomplete.</p>

<h2 id="001622">00:16:22</h2>
<h2 id="chris-14">Chris</h2>
<p>Because they’re built on top of fundamentally incompatible things. And so that’s the
fundamental nature. And so again, you go back to Chris’s dysfunction and my weird career
choices, I always end up back at the hardware-software boundary, and there’s a lot of
other folks that are really good at adding very high-level abstractions. If you go back a
few years ago, MLOps was the cool thing, and it was, ‘Let’s build a layer of Python on top
of TensorFlow and PyTorch and build a unified AI platform.’ But the problem with that, is
that building abstractions on top of two things that don’t work very well, can’t solve
performance, or liability, or management, or these other problems. You can only add a
layer of duct tape, but as soon as something goes wrong, you end up having to debug this
entire crazy stack of stuff that you really didn’t want to have to know about.</p>

<p>And so it’s a leaky abstraction. And so the genesis of Modular (bringing it back to this)
was realizing there are structural problems in the industry. There is nobody that’s
incentivized to go build a unifying software platform and do that work at the bottom
level. And so what we set off to do is we said, ‘Okay, let’s go build…’—and there’s
different ways of explaining this. You could say ‘a replacement for CUDA,’ that’s like a
flamboyant way to say this, but ‘let’s go build a successor to all of this technology that
is better than what the hardware makers are building, and is portable.’ And so what this
takes, is doing the work that these hardware companies are doing, and I set the goal for
the team of saying, let’s do it better than, for example, Nvidia is doing it for their own
hardware.</p>

<h2 id="001738">00:17:38</h2>
<h2 id="ron-15">Ron</h2>
<p>Which is no easy feat, right? They’ve got a lot of very strong engineers and they
understand their hardware better than anyone does. Beating them on their own hardware is
tough.</p>

<h2 id="001745">00:17:45</h2>
<h2 id="chris-15">Chris</h2>
<p>That is really hard. And they’ve got a 20-year head start, because CUDA is about 20 years
old. They’ve got all the momentum. They’re a pretty big company. As you say, lots of smart
people. And so that was a ridiculous goal. Why did I do that? Well, I mean a certain
amount of confidence in understanding how the technology worked, having a bet on what I
thought we could build and the approach, and some insight and intuition, but also
realizing that it’s actually destiny. Somebody has to do this work. If we ever want to get
to an ecosystem where one vendor doesn’t control everything, if we want to get the best
out of the hardware, if we want to get new programming language technologies, if we want
pattern matching on a GPU—I mean, come on, this isn’t rocket science—then we need at some
point to do this. And if nobody else is going to do it, I’ll step up and do that. That’s
where Modular came from—saying, ‘Let’s go crack this thing open. I don’t know how long it
will take, but sometimes it’s worthwhile doing really hard things if they’re valuable to
the world.’ And the belief was it could be profoundly impactful and hopefully get more
people into even just being able to use this new form of compute with GPUs and
accelerators and all this stuff, and just really redemocratize AI compute.</p>

<h2 id="001848">00:18:48</h2>
<h2 id="ron-16">Ron</h2>
<p>So you pointed out that there’s a real structural problem here, and I’m actually wondering
how, at a business model level, do you want to solve the structural problem? Which is, the
history of computing is these days littered with the bodies of companies that try to sell
a programming language. It’s a really hard business. How is Modular set up so that it’s
incented to build this platform in a way that can be a shared platform that isn’t subject
to just one other vendor’s lock-in?</p>

<h2 id="001911">00:19:11</h2>
<h2 id="chris-16">Chris</h2>
<p>First answer is, don’t sell a programming language. As you say, that’s very difficult. So
we’re not doing that. Go take Mojo, go use it for free. We’re not selling a programming
language. What we’re doing is we’re investing in this foundational technology to unify
hardware. Our view is, as we’ve seen in many other domains, once you fix the foundation,
now you can build high-value services for enterprises. And so our enterprise layer, often
what we talk to, you end up with these groups where you have hundreds or thousands of
GPUs. Often it’s rented from a cloud on a three-year commit. You have a platform team
that’s carrying pagers and they need to keep all this stuff running and all the production
workloads running. And then you have these product teams that are inventing new stuff all
the time, and there’s new research, there’s a new model that comes out and they want to
get it on the production infrastructure, but none of this stuff actually works.</p>

<p>And so the software ecosystem we have with all these brilliant but crazy open source tools
that are thrashing around, all these different versions of CUDA and libraries, all this
different hardware happening, is just a gigantic mess. And so, helping solve this for the
platform engineering team that actually needs to have stuff work, and want to be able to
reason about it, and want good observability and manageability and scalability and things
like this is actually, we think, very interesting. We’ve gotten a lot of good responses
from people on that. The cost of doing this is we want to actually make it work, that’s
where we do fundamental language compiler underlying systems technology and help bring
together these accelerators so that we can get, for example, the best performance on an
AMD GPU and get it so that the software comes out in the same release train as support for
an Nvidia GPU. And being able to pull that together, again, it just multiplicatively
reduces complexity, which then leads to a product that actually works, which is really
cool and very novel in AI.</p>

<h2 id="002049">00:20:49</h2>
<h2 id="ron-17">Ron</h2>
<p>So the way that Mojo plays in here, is it basically lets you provide the best possible
performance and I guess the best possible performance across multiple different hardware
platforms. Are you primarily thinking about this as an inference platform, or, how does
the training world fit in?</p>

<h2 id="002057">00:20:57</h2>
<h2 id="chris-17">Chris</h2>
<p>So let me zoom in and I’ll explain our technology components. I have a blog post series I
encourage you and any viewers or listeners to check out, called, ‘Democratizing AI
Compute.’ It goes through the history of all the systems and the problems and challenges
that they’ve run into, and it gets to, ‘What is Modular doing about it?’ So Part 11 talks
about our architecture and the inside is Mojo, which is a programming language. I’ll
explain Mojo in a second. Next level out is called MAX. And so you can think of MAX as
being a PyTorch replacement or a vLLM replacement, something that you can run on a single
node and then get high performance LLM surveying, that kind of use case. And then the next
level out is called Mammoth, and this is the cluster management Kubernetes layer. And so
if you zoom in all the way back to Mojo, you say—your experience, you know what
programming languages are, they’re incredibly difficult and expensive to build.</p>

<p>Why would you do that in the first place? And the answer is, we had to. In fact, when we
started Modular, I was like, ‘I’m not going to invent a programming language.’ I know
that’s a bad idea, it takes too long, it’s too much work. You can’t convince people to
adopt a new language. I know all the reasons why creating language is actually a really
bad idea. But it turns out, we were forced to do this because there is no good way to
solve the problem. And the problem is, how do you write code that is portable across
accelerators? So, that problem, I want portability across—for example, make it simple AMD
and Nvidia GPUs, but then you layer on the fact that you’re using a GPU because you want
performance. And so I don’t want a simplified, watered down—I want Java that runs on a
GPU.</p>

<p>I want the full power of the GPU. I want to be able to deliver performance that meets and
beats Nvidia on their own hardware. I want to have portability and unify this crazy
compute where you have these really fancy heterogeneous systems and you have tensor cores
and you have this explosion of complexity and innovation happening in this hardware
platform layer. Most programming languages don’t even know that there’s an 8-bit floating
point that exists. And so we looked around and I really did not want to have to do this,
but it turns out that there really is no good answer. And again, we decided that, hey, the
stakes are high, we want to do something impactful. We’re willing to invest. I know what
it takes to build a programming language. It’s not rocket science, it’s just a lot of
really hard work and you need to set the team up to be incentivized the right way. But we
decided that, yeah, let’s do that.</p>

<h2 id="002308">00:23:08</h2>
<h2 id="ron-18">Ron</h2>
<p>So I want to talk more about Mojo and its design, but before we do, maybe let’s talk a
little bit more about the pre-existing environment. I did actually read that blog post
series. I recommended it to everyone. I think it’s really great, and I want to talk a
little bit about what the existing ecosystem of languages looks like, but even before
then, can we talk more about the hardware? What does the space of hardware look like that
people want to run these ML models on?</p>

<h2 id="002329">00:23:29</h2>
<h2 id="chris-18">Chris</h2>
<p>Yeah, so the one that most people zero in on is the GPU. And so GPUs are, I think, getting
better understood now. And so if you go back before that though, you have CPUs. So, modern
CPUs in a data center, often you’ll have—I mean today you guys are probably riding quite
big iron, but you got 100 cores in a CPU and you got a server with two-to-four CPUs on a
motherboard, and then you go and you scale that. And so, you’ve got traditional threaded
workloads that have to run on CPUs, and we know how to scale that for internet servers and
things like this. If you get to a GPU, the architecture shifts. And so they have basically
these things called SMs. And now the programming model is that you have effectively much
more medium-sized compute that’s now put together on much higher performance memory
fabrics and the programming model shifts. And one of the things that really broke CUDA,
for example, was when GPUs got this thing called a tensor core—and the way to think about
a tensor core is it’s a dedicated piece of hardware for matrix multiplication. And so,
why’d we get that? Well, a lot of AI is matrix multiplication. And so, if you design the
hardware to be good at a specific workload, you can have dedicated silicon for that and
you can make things go really fast.</p>

<h2 id="002436">00:24:36</h2>
<h2 id="ron-19">Ron</h2>
<p>There are really these two quite different models sitting inside of the GPU space. Of
course, the name itself is weird. GPU is ‘graphics processing unit,’ which is what they
were originally for. And then this SM model is really interesting. They have this notion
of a warp. A warp is a collection of typically 32 threads that are operating together in
lockstep, always doing the same thing—a slight variation on what’s called the SIMD model,
same instruction, multiple data. It’s a little more general than that, but more or less,
you can think of it as the same thing. And you just have to run a lot of them. And then
there’s a ton of hardware inside of these systems basically to make switching between
threads incredibly cheap. So you pay a lot of silicon to add extra registers. So the
context switch is super cheap, so you can do a ton of stuff in parallel.</p>

<p>Each thing you’re doing is itself 32-wise parallel. And then because you can do all this
very fast context switching, you can hide a lot of latency. And that worked for a
while. And then we’re like, actually, we need way more of this matrix multiplication
stuff. And you can sort of do reasonably efficient matrix multiplication through this warp
model, but not really that good. And then there’s a bunch of quite idiosyncratic hardware,
which changes its performing characteristics from generation to generation, just for doing
these matrix multiplications. So that’s the Nvidia GPU story, and Volta is like V100 and
A100 and H100. They just keep on going and changing, pretty materially from generation to
generation in terms of the performance characteristics, and then also the memory model,
which keeps on changing.</p>

<h2 id="002557">00:25:57</h2>
<h2 id="chris-19">Chris</h2>
<p>You go back to intuition, CUDA was never designed for this world. CUDA was not designed
for modern GPUs. It was designed for a much simpler world. And CUDA being 20 years old, it
hasn’t really caught up. And it’s very difficult because, as you say, the hardware keeps
changing. And so CUDA was designed from a world where—almost like C is designed for a very
simple programming model that it expected to scale, but then as the hardware changed, it
couldn’t adapt. Now, if you get beyond GPUs, you get to Google TPU and many other
dedicated AI systems. They blow this way out and they say, ‘Okay, well, let’s get rid of
the threads that you have on a GPU and let’s just have matrix multiplication units and
have really big matrix multiplication units and build the entire chip around that. And you
get much more specialization, but you get a much higher throughput for those AI workloads.</p>

<p>Going back to, ‘Why Mojo?’ Well, Mojo was designed from first principles to support this
kind of system. Each of these chips, as you’re saying, even within Nvidia’s family, from
Volta, to Ampere, to Hopper, to Blackwell, these things are not compatible with each
other. Actually, Blackwell just broke compatibility with Hopper, so it can’t run Hopper
kernels always on Blackwell. Oops, well, why are they doing that? Well, AI software is
moving so fast. They decided that was the right trade-off to make. And meanwhile, we all
software people need the ability to target this. When you look at other existing systems,
with Triton for example, their goal was, ‘Let’s make it easier to program a GPU,’ which I
love, that’s awesome. But then they said, ‘We’ll just give up 20% of the performance of
the silicon to do it.’ Wait a second. I want all the performance. And so if I’m using a
GPU—GPUs are quite expensive by the way—</p>

<p>I want all the performance. And if it’s not going to be able to deliver the same quality
of results you get by writing CUDA, well then, you’re always going to run to this head
room, where you get going quickly, but then you run into a ceiling and then have to switch
to a different system to get full performance. And so this is where Mojo is really trying
to solve this problem where we can get more usability, more portability, and full
performance of the silicon because it’s designed for these wacky architectures like tensor
cores.</p>

<h2 id="002751">00:27:51</h2>
<h2 id="ron-20">Ron</h2>
<p>And if we look at the other languages that are out there, there’s languages like CUDA, and
OpenCL, which are low level, typically look like variations on C++, in that tradition are
unsafe languages, which means that there’s a lot of rules you have to follow. And if you
don’t exactly follow the rules, you’re in undefined behavior land, it’s very hard to
reason about your program.</p>

<h2 id="002810">00:28:10</h2>
<h2 id="chris-20">Chris</h2>
<p>And just let me make fun of my C++ heritage because I’ve spent so many years, like, you
just have a variable that you forget to initialize, it just shoots your foot off. [laughs]
Like, it’s just unnecessary violence to programmers.</p>

<h2 id="002821">00:28:21</h2>
<h2 id="ron-21">Ron</h2>
<p>Right. And it’s done in the interest of making performance better because the idea is C++
and its related languages don’t really give you enough information to know when you’re
making a mistake, and they want to have as much space as they can to optimize the programs
they get. So the stance is just, if you do anything that’s not allowed, we have no
obligation to maintain any kind of reasonable semantics or debug ability around that
behavior. And we’re just going to try really, really hard to optimize correct programs,
which is a super weird stance to take, because nobody’s programs are correct. There are
bugs and undefined behavior in almost any C++ program of any size. And so, you’re in a
very strange position in terms of the guarantees that you get from the compiler system
you’re using.</p>

<h2 id="002902">00:29:02</h2>
<h2 id="chris-21">Chris</h2>
<p>Well, so I mean, I can be dissatisfied. I can also be sympathetic with people that work on
C++. So again, I’ve spent decades in this language and around this ecosystem, and building
compilers for it. I know quite a lot about it. The challenge is that C++ is established,
and so there’s tons of code out there. By far, the code that’s already written is the code
that’s the most valuable. And so if you’re building a compiler, or you have a new chip, or
you have an optimizer, your goal is to get value out of the existing software. And so you
can’t invent a new programming paradigm that’s a better way of doing things and defines
away the problem. Instead, you have to work with what you’ve got. You have a SPEC
benchmark you’re trying to make go fast, and so you invent some crazy heroic hack that
makes some important benchmark work because you can’t go change the code.</p>

<p>In my experience, particularly for AI, but also I’m sure within Jane Street, if
something’s going slow, go change the code. You have control over the architecture of the
system. And so, what I think the world really benefits from, unlike benchmark hacking, is
languages that give control and power and expressivity to the programmer. And this is
something where I think that, again, you take a step back and you realize history is the
way it is for lots of structural and very valid reasons, but the reasons don’t apply to
this new age of compute. Nobody has a workload that they can pull forward to next year’s
GPU—doesn’t exist. Nobody solved this problem. I don’t know the timeframe, but once we
solve that problem, once we solve portability, you can start this new era of software that
can actually go forward. And so now, to me, the burden is—make sure it’s actually
good. And so, to your point about memory safety, don’t make it so that forgetting to
initialize a variable is just going to shoot your foot off. [Instead] produce a good
compiler error saying, ‘Hey, you forgot to initialize a variable,’ right? These basic
things are actually really profound and important, and the tooling and all this usability
and this DNA, these feelings and thoughts, are what flow into Mojo.</p>

<h2 id="003049">00:30:49</h2>
<h2 id="ron-22">Ron</h2>
<p>And GPU programming is just a very different world from traditional CPU programming just
in terms of the basic economics and how humans are involved. You end up dealing with much
smaller programs. You have these very small but very high-value programs whose performance
is super critical, and in the end, a relatively small coterie of experts who end up
programming in it. And so it pushes you ever in the direction, you’re saying, of
performance engineering, right? You want to give people the control they need to make the
thing behave as it should, and you want to do it in a way that allows people to be highly
productive. And the idea that you have an enormous amount of legacy code that you need to
bring over, it’s like, actually you kind of don’t. The entire universe of software is
actually shockingly small, and it’s really about how to write these small programs as well
as possible.</p>

<h2 id="003132">00:31:32</h2>
<h2 id="chris-22">Chris</h2>
<p>And also there’s another huge change. And so this is something that I don’t think that the
programming language community has recognized yet, but AI coding has massively changed the
game because now you can take a CUDA kernel and say, ‘Hey, Claude, go make that into
Mojo.’</p>

<h2 id="003145">00:31:45</h2>
<h2 id="ron-23">Ron</h2>
<p>And actually, how good have you guys found the experience of that? Of doing translation?</p>

<h2 id="003148">00:31:48</h2>
<h2 id="chris-23">Chris</h2>
<p>Well, we do hackathons and people do amazing things, having never touched Mojo, having
never done GPU programming, and within a day they can make things happen that are just
shocking. Now, AI coding tools are not magic. You cannot just vibe code DeepSeek-R1 or
something, right? But it’s amazing what that can do in terms of learning new languages,
learning new tools, and getting into and catalyzing ecosystems. And so this is one of the
things where, again, you go back five or 10 years—everybody knows nobody can learn a new
language, and nobody’s willing to adopt new things. But the entire system has changed.</p>

<h2 id="003220">00:32:20</h2>
<h2 id="ron-24">Ron</h2>
<p>So let’s talk a little bit more in detail about the architecture of Mojo. What kind of
language is Mojo, and what are the design elements that you chose in order to make it be
able to address this set of problems?</p>

<h2 id="003230">00:32:30</h2>
<h2 id="chris-24">Chris</h2>
<p>Yeah, again, just to relate how different the situation is—back when I was working on
Swift, one of the major problems to solve was, objective C was very difficult for people
to use, and you had pointers, and you had square brackets, and it was very weird. And so
the goal in the game of the day was, invent new syntax and bring together modern
programming language features to build a new language. Fast forward to today, actually,
some of that is true. AI people don’t like C++. C++ has pointers, and it’s ugly, and it’s
a 40-year-old-plus language, and has actually the same problem that Swift had to solve
back in the day. But today there’s something different, which is that AI people do
actually love a thing. It’s called Python. And so, one of the really important things
about Mojo is, it’s a member of the Python family. And so, this is polarizing to some,
because yes—I get it that some people love curly braces, but it’s hugely powerful because
so much of the AI community is Pythonic already.</p>

<p>And so we started out by saying, let’s keep the syntax like Python and only diverge from
that if there’s a really good reason. But then what are the good reasons? Well, the good
reasons are, we want—as we were talking about—performance, power, full control over the
system. And for GPUs, there’s these very important things you want to do that require
metaprogramming. And so Mojo has a very fancy metaprogramming system, kind of inspired by
this language called Zig, that brings runtime and compile time together to enable really
powerful library designs. And the way you crack open this problem with tensor cores and
things like this, is you enable really powerful libraries to be built in the language as
libraries, instead of hard coding into the compiler.</p>

<h2 id="003357">00:33:57</h2>
<h2 id="ron-25">Ron</h2>
<p>Let’s take it a little bit to the metaprogramming idea. What is metaprogramming and why
does it matter for performance in particular?</p>

<h2 id="003403">00:34:03</h2>
<h2 id="chris-25">Chris</h2>
<p>Yeah, it’s a great question, and I think you know the answer to this too, and I know you,
but—</p>

<h2 id="003408">00:34:08</h2>
<h2 id="ron-26">Ron</h2>
<p>[Laughs] We are also working on metaprogramming features in our own world.</p>

<h2 id="003411">00:34:11</h2>
<h2 id="chris-26">Chris</h2>
<p>Exactly. And so the observation here is, when you’re writing a for loop in a programming
language, for example, typically that for loop executes at runtime, so you’re writing code
that when you execute the program, it’s the instructions that the computer will follow to
execute the algorithm within your code. But when you get into designing higher level type
systems, suddenly you want to be able to run code at compile time as well. And so there’s
many languages out there. Some of them have macro systems, C++ has templates. What you end
up getting is, you end up getting, in many languages, this duality between what happens at
runtime, and then a different language almost that happens at compile time. And C++ is the
most egregious, because templates that you have a for loop in runtime, but then you have
unrolled recursive templates, or something like that at compile time.</p>

<p>Well, so the insight is, hey, these two problems are actually the same. They just run at
different times. And so what Mojo does is says, let’s allow the use of effectively any
code that you would use at runtime to also work at compile time. And so you can have a
list, or a string, or whatever you want in the algorithms—go do memory allocation,
deallocation—and you can run those at compile time, enabling you to build really powerful
high-level abstractions and put them into libraries. So why is this cool? Well, the reason
it’s cool is that on a GPU, for example, you’ll have a tensor core. Tensor cores are
weird. We probably don’t need to deep dive into all the reasons why, but the indexing and
the layout that tensor cores use is very specific and very vendor different. And so the
tensor core you have on AMD, or the tensor cores you have on different versions of Nvidia
GPUs are all very different.</p>

<p>And so what you want, is you want to build as a GP programmer a set of abstractions so you
can reason about all of these things in one common ecosystem and have the layouts much
higher level. And so what this enables, it enables very powerful libraries—and very
powerful libraries where a lot of the logic is actually done at compile time, but you can
debug it because it’s the same language that you use at runtime. And it makes the language
much more simpler, much more powerful, and just be able to scale into these complexities
in a way that’s possible with C++. But in C++, you get some crazy template stack trace
that is maddening and impossible to understand. In Mojo, you can get a very simple error
message. You can actually debug your code, and debugger things like this.</p>

<h2 id="003617">00:36:17</h2>
<h2 id="ron-27">Ron</h2>
<p>So maybe an important point here is that metaprogramming is really an old solution to this
performance problem. Maybe a good way of thinking about this is, imagine you have some
piece of data that you have that represents a little embedded domain-specific language
that you’ve written, that you want to execute via a program that you wrote. You can, in a
nice high-level way, write a little interpreter for that language that just—you know, I
have maybe a Boolean expression language or who knows what else. Maybe it’s a language for
computing on tensors in a GPU. And you could write a program that just executes that mini
domain-specific language and does the thing that you want and you can do it, but it’s
really slow. Writing an interpreter is just inherently slow because of all this
interpretation overhead where you are dynamically making decisions about what the behavior
of the program is. And sometimes what you want, is, you just want to actually emit exactly
the code that you want and boil away the control structure and just get the direct lines
of machine code that you want to do the thing that’s necessary.</p>

<p>And various forms of code generation let you get past in a simpler way, lets you get past
all of this control structure that you have to execute at runtime and instead be able to
execute it at compile time and get this minified program that just does exactly the thing
that you want. So that’s a really old idea. It goes back to all sorts of programming
languages. There’s a lot of Lisps that did a lot of this metaprogramming stuff, but then
the problem is this stuff is super hard to think about and reason about and debug. And
that’s certainly true if you think about in C, all this macro language, if you use the
various C preprocessors to do this kind of stuff in C, it’s pretty painful to reason
about. And then C++ made it richer and more expressive, but still really hard to reason
about. And you write a C++ template and you don’t really know what it’s going to do or if
it’s going to compile until you give it all the inputs and let it go and it—</p>

<h2 id="003755">00:37:55</h2>
<h2 id="chris-27">Chris</h2>
<p>Feels good in the simple case. But then when you get to more advanced cases, suddenly the
complexity compounds and it gets out of hand.</p>

<h2 id="003801">00:38:01</h2>
<h2 id="ron-28">Ron</h2>
<p>And it sounds like the thing that you’re going for in Mojo is it feels like one
language. It has one type system that covers both the stuff you’re generating statically
and the stuff that you’re doing at runtime. It sounds like debugging works in the same way
across both of these layers, but you still get the actual runtime behavior you want from a
language that you could more explicitly just be like, here’s exactly the code that I want
to generate.</p>

<h2 id="003824">00:38:24</h2>
<h2 id="chris-28">Chris</h2>
<p>[…] metaprogramming is one of the fancy features. One of the cool features is it feels
and looks like Python, but with actual types.</p>

<h2 id="003831">00:38:31</h2>
<h2 id="ron-29">Ron</h2>
<p>Right.</p>

<h2 id="003832">00:38:32</h2>
<h2 id="chris-29">Chris</h2>
<p>And let’s not forget the basics. Having something that looks and feels like Python but
it’s a thousand times faster or something is actually pretty cool. For example, if you’re
on a CPU, you have access to SIMD, the SIMD registers that allow you to do multiple
operations at a time and [to] be able to get the full power of your hardware even without
using the fancy features is also really cool. And so the challenge with any of these
systems is, how do you make something that’s powerful, but it’s also easy to use? I think
your team’s been playing with Mojo and doing some cool stuff. I mean, what have you seen
and what’s your experience been?</p>

<h2 id="003902">00:39:02</h2>
<h2 id="ron-30">Ron</h2>
<p>We’re all still pretty new to it, but I think it’s got a lot of exciting things going for
it. I mean, the first thing is, yeah, it gives you the kind of programming model you want
to get the performance that you need. And actually, in many ways the same kind of
programming model that you get out of something like CUTLASS or CuTe DSL, which are these
Nvidia-specific, some at the C++ level, some at the Python DSL level—and by the way, every
tool you can imagine nowadays is done once in C++ and once in Python. We don’t need to
implement programming languages in any other way anymore. They’re all either skins on C++
or skins on Python. But depending on which path you go down, whether you go the C++ path
or the Python path, you get all sorts of complicated trade-offs.</p>

<p>Like in the C++ path in particular, you get very painful compilation times. The thing you
said about template metaprogramming is absolutely true. The error messages are super
bad. If you look at these more Python-embedded DSLs, the compile times tend to be
better. It still can be hard to reason about though. One nice thing about Mojo is the
overall discipline seems very explicit when you want to understand: Is this a value that’s
happening at execution time at the end, or is it a value that is going to be dealt with at
compile time? It’s just very explicit in the syntax, you can look and understand. Whereas
in some of these DSLs, you have to actively go and poke the value and ask it what kind of
value it is. And I think that kind of explicitness is actually really important for
performance engineering, making it easy to understand just what precisely you’re doing.</p>

<p>You actually see this a ton, not even with these very low-level things, but if you look at
PyTorch, which is a much higher level tool, PyTorch does this thing where you get to write
a thing that looks like an ordinary Python program, but really it’s got a much trickier
execution model. Python’s an amazing and terrible ecosystem in which to do this kind of
stuff, because what guarantees do you have when you’re using Python? None. What can you
do? Anything. You have an enormous amount of freedom. The PyTorch people in particular
have leveraged this freedom in a bunch of very clever ways, where you can write a Python
program that looks like it’s doing something very simple and straightforward that would be
really slow, but no—it’s very carefully delaying and making some operations lazy so it can
overlap compute on the GPU and CPU and make stuff go really fast. And that’s really nice,
except sometimes it just doesn’t work.</p>

<h2 id="004104">00:41:04</h2>
<h2 id="chris-30">Chris</h2>
<p>This is the trap again, this is my decades of battle scars now. So as a compiler guy, I
can make fun of other compiler people. There’s this trap and it’s an attractive trap,
which is called the ‘sufficiently smart compiler.’ And so what you can do is you can take
something and you can make it look good on a demo and you can say, ‘Look! I make it super
easy and I’m going to make my compiler super smart, and it’s going to take care of all
this and make it easy through magic.’ But magic doesn’t exist. And so anytime you have one
of those ‘sufficiently smart compilers,’ if you go back in the days, it was like
auto-parallelization, just write C code is sequential logic, and then we’re going to
automatically map it into running on 100 cores on a supercomputer or something like that.</p>

<p>They often actually do work, they work in very simple cases and they work in the
demos. But the problem is that you go and you’re using them and then you change one thing
and suddenly everything breaks. Maybe the compiler crashes, it just doesn’t work. Or you
go and fix a bug and now instead of 100-times speedup, you get 100-times slowdown because
it foiled the compiler. A lot of AI tools, a lot of these systems, particularly these
DSLs, have this design point of, let me pretend like it’s easy and then I will take care
of it behind the scenes. But then when something breaks, you have to end up looking at
compiler dumps, right? And this is because magic doesn’t exist. And so this is where
predictability and control is really, I think, the name of the game, particularly if you
want to get the most out of a piece of hardware, which is how we ended up here.</p>

<h2 id="004223">00:42:23</h2>
<h2 id="ron-31">Ron</h2>
<p>It’s funny, the same issue of, “How clever is the underlying system you’re using?” comes
up when you look at the difference between CPUs and GPUs. CPUs themselves are trying to do
a weird thing where a chip is a fundamentally parallel substrate. It’s got all of these
circuits that in principle could be running in parallel and then it is yoked to running
this extremely sequential programming language, which is just trying to do one thing after
another. And then how does that actually work with any reasonable efficiency? Well,
there’s all sorts of clever dirty tricks happening under the covers where it’s trying to
predict what you’re going to do, this speculation that allows it to dispatch multiple
instructions in a row by guessing what you’re going to do in the future. There’s things
like memory prefetching where it has heuristics to estimate what memory you’re going to
ask in the future so it can dispatch multiple memory requests at the same time.</p>

<p>And then if you look at things like GPUs, and I think even more, TPUs, and then also
totally other things like FPGAs, the field-programmable gate arrays where you put
basically a circuit design on it. It’s a very different kind of software system. But all
of them are in some sense simpler and more deterministic and more explicitly
parallel. Like when you write down your program, you have to write an explicitly parallel
program—that’s actually harder to write. I don’t want to complain too much about CPUs. The
great thing about CPUs is they’re extremely flexible and incredibly easy to use and all of
that dark magic actually works a pretty large fraction of the time.</p>

<h2 id="004342">00:43:42</h2>
<h2 id="chris-31">Chris</h2>
<p>Yeah, remarkably well. But your point here, I think it’s really great, and what you’re
saying is, you’re saying CPUs are the magic box that makes sequential code go in parallel
pretty fast. And then we have new, more explicit machines, somewhat harder to program
because they’re not a magic box, but you get something from it. You get performance and
power because that magic box doesn’t come without a cost. It comes with a very significant
cost, often the amount of power that your machine dissipates. And so it’s not
efficient. And so a lot of the reasons we’re getting these new accelerators is because
people really do care about it being a hundred times faster, or using way less power, or
things like this. And I’d never thought about it, but your analogy of Triton to Mojo kind
of follows a similar pattern, right? Triton is trying to be the magic box, and it doesn’t
give you the full performance, and it burns more power, and all that kind of stuff. And so
Mojo is saying, look, let’s go back to being simple. Let’s give the programmer more
control. And that more explicit approach, I think, is a good fit for people that are
building crazy advanced hardware like you’re talking about—but also people that want to
get the best performance out of the existing hardware we have.</p>

<h2 id="004442">00:44:42</h2>
<h2 id="ron-32">Ron</h2>
<p>So we talked about how metaprogramming lets you write faster programs by boiling away this
control structure that you don’t really need. So that part’s good. How does it give you
portable performance? How does it help you on the portability front?</p>

<h2 id="004454">00:44:54</h2>
<h2 id="chris-32">Chris</h2>
<p>Yeah, so this is another great question. So in this category of ‘sufficiently smart
compilers,’ and particularly for AI compilers, there’s been years of work and MLIR has
catalyzed a lot of this work building these magic AI compilers that take TensorFlow or
even the new PyTorch stuff and trying to generate optimal code for some chip. So take some
PyTorch model and put it through a compiler, and magically get out high performance. And
so there’s tons of these things, and there’s a lot of great work done here, and a lot of
people have shown that you can take kernels and accelerate them with compilers. The
challenge with this is that people don’t ever measure—what is the full performance of the
chip? And so people always measure from a somewhat unfortunate baseline and then try to
climb higher instead of saying—what is the speed of light? And so if you measure from
speed of light, suddenly you say, okay, how do I achieve several different things?</p>

<p>Even if you zero into one piece of silicon, how do I achieve the best performance for one
use case? And then how do I make it so the software I write can generalize even within the
domain? And so for example, take a matrix multiplication, well, you want to work on maybe
float32, but then you want to generalize it to float16. Okay, well, templates and things
like this are easy ways to do this. Then programming allows you to say, okay, I will
tackle that. And then the next thing that happens is, because you went from float32 to
float16, your effective cache size has doubled, because twice as many elements fit into
cache if there’s 16 bits than if there are 32 bits. Well, if that’s the case, now suddenly
the access pattern needs to change. And so you get a whole bunch of this conditional logic
that now changes in a very parametric way as a result of one simple change that happened
with float32 to float16.</p>

<p>Now you play that forward and you say, okay, well actually matrix multiplication is a
recursive hierarchical problem. There’s specializations for tall and skinny matrices, and
a dimension is one or something. There’s all these special cases. Just one algorithm for
one chip becomes this very complicated subsystem that you end up wanting to do a lot of
transformations to so you can go specialize it for different use cases. And so Mojo with
the metaprogramming allows you to tackle that. Now you bring in other hardware, and so
think of matrix multiplication these days as being almost an operating system, and there’s
so many different subsystems, and special cases, and different D types, and crazy float4
and six and other stuff going on.</p>

<h2 id="004707">00:47:07</h2>
<h2 id="ron-33">Ron</h2>
<p>At some point they’re going to come out with a floating point number so small that it will
be a joke. But every time I think that they’re just kidding, it turns out it’s real.</p>

<h2 id="004714">00:47:14</h2>
<h2 id="chris-33">Chris</h2>
<p>Seriously, I heard somebody talking about 1.2-bit floating point, right? It’s exactly like
you’re saying, is that a joke? You can’t be serious. And so now when you bring in other
hardware, other hardware brings in more complexity because suddenly the tensor core has a
different layout in AMD than it does on Nvidia. Or maybe to your point about warps, you
have 64 threads in a warp on one and 32 threads in a warp on the other. But what you
realize is, wait a second—this really has nothing to do with hardware vendors. This is
actually true even within, for example, the Nvidia line, because across these different
data types, the tensor cores are changing. The way the tensor core works for float32 is
different from the way it works for float4 or something. And so you already—within one
vendor—have to have this very powerful metaprogramming to be able to handle the complexity
and do so in the scaffolding of a single algorithm like matrix multiplication.</p>

<p>And so now as you bring in other vendors, well it turns out hey, they all have things that
look roughly like tensor cores. And so we’re coming at this with a software engineering
perspective, and so we’re forced to build abstractions. We have this powerful
metaprogramming system so we can actually achieve this. And so even for one vendor, we get
this thing called LayoutTensor. LayoutTensor is saying, okay, well I have the ability to
reason about not just an array of numbers or a multidimensional array of numbers, but also
how it’s laid out in memory and how it gets accessed. And so now we can declaratively map
these things onto the hardware that you have and these abstractions stack. And so it’s
this really amazing triumvirate between having a type system that works well and this very
important basis. I know you’re a fan of type systems also.</p>

<p>You then bring in metaprogramming, and so you can build powerful abstractions and run a
compile time so you get no runtime overhead. And then you bring in the most important part
of this entire equation, which is programmers who understand the domain. I am not going to
write a fast matrix multiplication. I’m sorry, that’s not my experience. But there are
people in that space that are just fricking brilliant. They understand exactly how the
hardware works, they understand the use cases and the latest research and the new crazy
quantized format of the day, but they’re not compiler people. And so the magic of Mojo is
it says, ‘Hey, you have a type system, you have metaprogramming, you have effectively the
full power of a compiler that you have when you’re building libraries.’ And so now these
people that are brilliant at unlocking the power of the hardware can actually do this. And
now they can write software that scales both across the complexity of the domain but also
across hardware. And to me, that’s what I find so exciting and so powerful about
this. It’s unlocking the power of the Mojo programmer instead of trying to put it into the
compiler, which is what a lot of earlier systems have tried to do.</p>

<h2 id="004949">00:49:49</h2>
<h2 id="ron-34">Ron</h2>
<p>So maybe the key point here is that you get to build these abstractions that allow you to
represent different kinds of hardware, and then you can conditionally have your code
execute based on the kind of hardware that it’s on. It’s not like an #ifdef where you’re
picking between different hardware platforms. There are complicated data structures like
these layout values that tell you how you traverse data.</p>

<h2 id="005007">00:50:07</h2>
<h2 id="chris-34">Chris</h2>
<p>Which is kind of a tree. This isn’t just a simple int that you’re passing around. This is
like a recursive hierarchical tree that you need at compile time.</p>

<h2 id="005013">00:50:13</h2>
<h2 id="ron-35">Ron</h2>
<p>The critical thing is you get to write a thing that feels like one synthetic program with
one understandable behavior, but then parts of it are actually going to execute at compile
time, so that the thing that you generate is in fact specialized for the particular
platform that you’re going to run it on. So one concern I have over this is it sounds like
the configuration space of your programs is going to be massive, and I feel like there are
two directions where this seems potentially hard to do from an engineering
perspective. One is, can you really create abstractions that within the context of the
program hide the relevant complexity? So it’s possible for people to think in a modular
way about the program they’re building, so their brains don’t explode with the 70
different kinds of hardware that they might be running it on. And then the other question
is, how do you think about testing? Because there’s just so many configurations. How do
you know whether it’s working in all the places? Because it sounds like it has an enormous
amount of freedom to do different things, including wrong things in some cases. How do you
deal with those two problems, both controlling the complexity of the abstractions and then
having a testing story that works out?</p>

<h2 id="005111">00:51:11</h2>
<h2 id="chris-35">Chris</h2>
<p>Okay, Ron, I’m going to blow your mind. I know you’re going to be resistant to this, but
let me convince you that types are cool.</p>

<h2 id="005116">00:51:16</h2>
<h2 id="ron-36">Ron</h2>
<p>Okay!</p>

<h2 id="005118">00:51:18</h2>
<h2 id="chris-36">Chris</h2>
<p>I know you’re going to fight me on this. Well, so this is again, you go back to the
challenges and opportunities of working with either Python or C++. Python doesn’t have
types really. I mean it has some stuff, but it doesn’t really have a type system. C++ has
a type system, but it’s just incredibly painful to work with. And so what Mojo does is it
says, again, it’s not rocket science. We see it all around us. Let’s bring in
traits. Let’s bring in a reasonable way to write code so that we can build abstractions
that are domain-specific and they can be checked modularly. And so one of the big problems
with C++ is that you get error messages when you instantiate layers and layers and layers
and layers of templates. And so if you get some magic number wrong, it explodes
spectacularly in a way that you can’t reason about. And so what Mojo does, it says, cool,
let’s bring in traits that feel very much like protocols in Swift, or traits in Rust, or
type classes in Haskell. Like, this isn’t novel.</p>

<h2 id="005208">00:52:08</h2>
<h2 id="ron-37">Ron</h2>
<p>This is like a mechanism for what’s called ad hoc polymorphism, meaning I want to have
some operation or function that has some meaning, but actually it’s going to get
implemented in different ways for different types. And these are basically all mechanisms
of a way of, given the thing that you’re doing and the types involved, looking up the
right implementation that’s going to do the thing that you want.</p>

<h2 id="005225">00:52:25</h2>
<h2 id="chris-37">Chris</h2>
<p>Yeah, I mean a very simple case is an iterator. So Mojo has an iterator trait and you can
say, ‘Hey, what is an iterator over a collection?’ Well, you can either check, see if
there’s an element, or you can get the value at the current element. And then as you keep
pulling things out of an iterator, it will eventually decide to stop. And so this concept
can be applied to things like a linked list, or an array, or a dictionary, or an unbounded
sequence of packets coming off a network. And so you can write code that’s generic across
these different—call them “backends” or “models”—that implement this trait. And what the
compiler will do for you is it will check to make sure when you’re writing that generic
code, you’re not using something that won’t work. And so what that does, is it means that
you can check the generic code without having to instantiate it, which is good for compile
time. It’s good for user experience, because if you get something wrong as a programmer,
that’s important. It’s good for reasoning about the modularity of these different
subsystems, because now you have an interface that connects the two components.</p>

<h2 id="005322">00:53:22</h2>
<h2 id="ron-38">Ron</h2>
<p>I think it’s an underappreciated problem with the C++ templates approach to the world,
where C++ templates seem like a deep language feature, but really they’re just a code
generation feature.</p>

<h2 id="005332">00:53:32</h2>
<h2 id="chris-38">Chris</h2>
<p>They’re like C macros.</p>

<h2 id="005333">00:53:33</h2>
<h2 id="ron-39">Ron</h2>
<p>That’s right. It both means they’re hard to think about and reason about because it sort
of seems at first glance not to be so bad—this property that you don’t really know when
your template expands, if it’s actually going to compile. But as you start composing
things more deeply, it gets worse and worse because something somewhere is going to fail,
and it’s just going to be hard to reason about and understand. Whereas when you have
type-level notions of genericity that are guaranteed to compose correctly and won’t just
blow up, you just drive that error right down. So that’s one thing that’s nice about
getting past templates as a language feature. And then the other thing is it’s just
crushingly slow. You’re generating the code, almost exactly the same code, over and over
and over again. And so that just means you can’t save any of the compilation work. You
just have to redo the whole thing from scratch.</p>

<h2 id="005421">00:54:21</h2>
<h2 id="chris-39">Chris</h2>
<p>That’s exactly right. And so this is where again, we were talking about the sand in the
system—these little things that if you get wrong, they play forward and they cause huge
problems. The metaprogramming approach in Mojo is cool, both for usability and compile
time and correctness. Coming back to your point about portability, it’s also valuable for
portability because what it means is that the compiler parses your code, and it parses it
generically and has no idea what the target is. And so when Mojo generates the first level
of intermediate representation, the compiler representation for the code, it’s not hard
coding and the pointers are 32 bit or 64 bit, or that you’re on a x86 or whatever. And
what this means is that you can take generic code in Mojo and you can put it on a CPU and
you can put it on a GPU. Same code, same function. And again, these crazy compilery things
that Chris gets obsessed about, it means that you can slice out the chunk of code that you
want to put onto your GPU in a way that it looks like a distributed system, but it’s a
distributed system where the GPU is actually a crazy embedded device that wants this tiny
snippet of code and it wants it fully self-contained. These worlds of things that normal
programming languages haven’t even thought about.</p>

<h2 id="005529">00:55:29</h2>
<h2 id="ron-40">Ron</h2>
<p>So does that mean when I compile a Mojo program, I get a shippable executable that
contains within it another little compiler that can take the Mojo code and specialize it
to get the actual machine code for the final destination that you need? Do I bundle
together all the compilers for all the possible platforms in every Mojo executable?</p>

<h2 id="005545">00:55:45</h2>
<h2 id="chris-40">Chris</h2>
<p>The answer is no. The world’s not ready for that. And there are use cases for JIT
compilers and things like this, and that’s cool, but the default way of building, if you
just run mojo build, then it will give you just an a.out executable, a normal thing. But
if you build a Mojo package, the Mojo package retains portability. This is a big
difference. This is what Java does. If you think about Java in a completely different way
and for different reasons in a different ecosystem universe, it parses all your source
code without knowing what the target is, and it generates Java bytecode. And so it’s not
1995 anymore. The way we do this is completely different. And we’re not Java obviously,
and we have a type system that’s very different. But this concept is something that’s been
well known, and is something that at least the world of compiled languages like Swift, and
C++, and Rust have kind of forgotten.</p>

<h2 id="005628">00:56:28</h2>
<h2 id="ron-41">Ron</h2>
<p>So the Mojo package is kind of shipped with the compiler technology required to specialize
to the different domains.</p>

<h2 id="005634">00:56:34</h2>
<h2 id="chris-41">Chris</h2>
<p>Yes. And so again, by default, if you’re a user, you’re sitting on your laptop and you
say, ‘Compile a Mojo program,’ you just want an executable. But the compiler technology
has all of these powerful features and they can be used in different ways. This is similar
to LLVM, where LLVM had a just-in-time compiler, and that’s really important if you’re
Sony Pictures and you’re rendering shaders for some fancy movie, but that’s not what you’d
want to use if you’re just running a C++ code that needs to be ahead-of-time compiled.</p>

<h2 id="005657">00:56:57</h2>
<h2 id="ron-42">Ron</h2>
<p>I mean, there’s some echoes here also of the PTX story with Nvidia. Nvidia has this thing
that they sort of hide that it’s an intermediate representation, but this thing called
PTX, which is a portable bytecode essentially. And they for many years maintained
compatibility across many, many different generations of GPUs. They have a thing called
the assembler that’s part of the driver thing for loading on, and it’s really not an
assembler. It’s like a real compiler that takes the PTX and compiles it down to SASS, the
accelerator-specific machine code, which they very carefully do not fully document because
they don’t want to give away all of their secrets. And so there’s a built-in portability
story there where it’s meant to actually be portable in the future across new
generations. Although as you were pointing out before, it in fact doesn’t always
succeed. And there are now some programs that will not actually make the transition to
Blackwell.</p>

<h2 id="005742">00:57:42</h2>
<h2 id="chris-42">Chris</h2>
<p>So that’s in the category that I’d consider to be like a virtual machine, a very low-level
virtual machine by the way. And so when you’re looking at these systems, the thing I’d ask
is, what is the type system? And so if you look at PTX, because as you’re saying, you’re
totally right, it’s an abstraction between a whole bunch of source code on the top end and
then that specific SASS hardware thing on the backend, but the type system isn’t very
interesting. It’s pointers and registers and memory. And so Java, what is the type system?
Well, Java achieves portability by making the type system in its bytecode expose
objects. And so it’s a much higher level abstraction, dynamic virtual dispatch, that’s all
part of the Java ecosystem. It’s not a bytecode, but the representation that’s portable
maintains the full generic system. And so this is what makes it possible to say, ‘Okay,
well I’m going to take this code, compile it once to a package, and now go specialize and
instantiate this for a device.’ So the way that works is a little bit different, but it
enables, coming back to your original question of safety and correctness, it enables all
the checking to happen the right way.</p>

<h2 id="005840">00:58:40</h2>
<h2 id="ron-43">Ron</h2>
<p>Right, there’s also a huge shift in control. With PTX, the machine-specific details of how
it’s compiled are totally out of the programmer’s control. You can generate the best PTX
you can, and then it’s going to get compiled. How? Somehow, don’t ask too many questions,
it’s going to do what it’s going to do. Whereas here, you’re preserving in the portable
object, the programmer-driven instructions about how the specialization is going to
work. You’ve just partially executed your compilation, you’ve got partway down, and then
there’s some more that’s going to be done at the end when you pick actually where you’re
going to run it.</p>

<h2 id="005908">00:59:08</h2>
<h2 id="chris-43">Chris</h2>
<p>Exactly. And so these are all very nerdy pieces that go into the stack, but the thing that
I like is if you bubble out of that, it’s easy to use. It works. It gives good error
messages, right? I don’t understand the Greek letters, but I do understand a lot of the
engineering that goes into this. The way this technology stack builds up, the whole
purpose is to unlock compute, and we want new programmers to be able to get into the
system. And if they know Python, if they understand some of the basics of the hardware,
they can be effective and then they don’t get limited to 80% of the performance. They can
keep driving and keep growing in sophistication, and maybe not everybody wants to do
that. They can stop at 80%, but if you do want to go all the way, then you can get there.</p>

<h2 id="005944">00:59:44</h2>
<h2 id="ron-44">Ron</h2>
<p>One thing I’m curious about is, how do you actually manage to keep it simple? You said
that Mojo is meant to be Pythonic and you talked a bunch about the syntax, but actually
one of the nice things about Python is it’s simple in some ways in a deeper sense. The
fact that there isn’t by default a complicated type system with complicated type errors to
think about—there’s a lot of problems with that, but it’s also a real source of simplicity
for users who are trying to learn the system. Dynamic errors at runtime are in some ways
easier to understand. ‘I wrote a program and it tried to do a thing and it tripped over
this particular thing and you can see it tripping over,’ and in some ways that’s easier to
understand when you’re going to a language which, for both safety and performance reasons,
needs much more precise type level control. How do you do that in a way that still feels
Pythonic in terms of the base simplicity that you’re exposing to users?</p>

<h2 id="010028">01:00:28</h2>
<h2 id="chris-44">Chris</h2>
<p>I can’t give you the perfect answer, but I can tell you my current thoughts. So again,
learn from history. Swift had a lot of really cool features, but it spiraled and got a lot
of complexity that got layered in over time. And also one of the challenges with Swift is
it had a team that was paid to add features to swift.</p>

<h2 id="010046">01:00:46</h2>
<h2 id="ron-45">Ron</h2>
<p>It’s never a good thing.</p>

<h2 id="010047">01:00:47</h2>
<h2 id="chris-45">Chris</h2>
<p>Well, you have a C++ committee, what is the C++ committee going to do? They’re going to
keep adding features to C++. Don’t expect C++ to get smaller. It’s common sense. And so
with Mojo, there’s a couple of different things. So one of which is, start from Python. So
Python being the surface-level syntax enables me as management to be able to push back and
say, ‘Look, let’s make sure we’re implementing the full power of the Python
ecosystem. Let’s have lists, and for-comprehensions, and all this stuff before just
inventing random stuff because it might be useful.’ But there’s also, for me personally, a
significant back pressure on complexity. How can we factor these things? How can we get,
for example, the metaprogramming system to subsume a lot of complexity that would
otherwise exist? And there are fundamental things that I want us to add.</p>

<p>For example, checked generics, things like this because they have a better UX, they’re
part of the metaprogramming system, they’re part of the core addition that we’re adding,
but I don’t want Mojo to turn into a ‘add every language feature’ that every other
language has just because it’s useful to somebody. I was actually inspired by and learned
a lot from Go, and it’s a language that people are probably surprised to hear me talk
about. Go, I think, did a really good job of intentionally constraining the language with
Go 1. And they took a lot of heat for that. They didn’t add a generic system, and
everybody, myself included, were like, ‘Ha ha ha, why doesn’t this language even have a
generic system? You’re not even a modern language.’ But they held the line, they
understood how far people could get, and then they did a really good job of adding
generics to Go 2, and I thought they did a great job.</p>

<p>There was a recent blog post I was reading, talking about Go, and apparently they have an
80-20 rule, and they say they want to have 80% of the features with 20% of the complexity,
something like that. And the observation is that that’s a point in the space that annoys
everybody, because everybody wants 81% of the features, but 81% of the features maybe
gives you 35% of the complexity. And so, figuring out where to draw that line and figuring
out where to say no—for example, we have people in the community that are asking for very
reasonable things that exist in Rust. And Rust is a wonderful language. I love it. There’s
a lot of great ideas and we shamelessly pull good ideas from everywhere. But I don’t want
the complexity.</p>

<h2 id="010302">01:03:02</h2>
<h2 id="ron-46">Ron</h2>
<p>I often like to say that one of the most critical things about a language design is
maintaining the power-to-weight ratio.</p>

<p>You want to get an enormous amount of good functionality, and power, and good user
experience while minimizing that complexity. I think it is a very challenging thing to
manage, and it’s actually a thing that we are seeing a lot as well. We are also doing a
lot to extend OCaml in all sorts of ways, pulling from all sorts of languages, including
Rust, and again, doing it in a way where the language maintains its basic character and
maintains its simplicity is a real challenge. And it’s kind of hard to know if you’re
hitting the actual right point on that. And it’s easier to do in a world where you can
take things back, try things out and decide that maybe they don’t work, and then adjust
your behavior. And we’re trying to iterate a lot in that mode, which is a thing you can do
under certain circumstances. It gets harder as you have a big open-source language that
lots of people are using.</p>

<h2 id="010347">01:03:47</h2>
<h2 id="chris-46">Chris</h2>
<p>That’s a really great point. And so one of the other lessons I’ve learned with Swift, is
that with Swift, I pushed very early to have an open design process where anybody could
come in, write a proposal, and then it would be evaluated by the language committee, and
then if it was good, it would be implemented and put into Swift. Again, be careful what
you wish for. That enabled a lot of people with really good ideas to add a bunch of
features to Swift. And so with Mojo as a counterbalance, I really want the core team to be
small. I want the core team not just to be able to add a whole bunch of stuff because it
might be useful someday, but to be really deliberate about how we add things, how we
evolve things.</p>

<h2 id="010420">01:04:20</h2>
<h2 id="ron-47">Ron</h2>
<p>How are you thinking about maintaining backwards compatibility guarantees as you evolve it
forward?</p>

<h2 id="010425">01:04:25</h2>
<h2 id="chris-47">Chris</h2>
<p>We’re actively debating and discussing what Mojo 1.0 looks like. And so I’m not going to
give you a timeframe, but it will hopefully not be very far away. And what I am fond of is
this notion of semantic versioning, and saying we’re going to have a 1.0, and then we’re
going to have a 2.0, and we’re going to have a 3.0, and we’re going to have a 4.0, et
cetera. And each of these will be able to be incompatible, but they can link together. And
so one of the big challenges and a lot of the damage in the Python ecosystem was from the
Python two-to-three conversion. It took 15 years and it was a heroic mess for many
different reasons. The reason it took so long is because you have to convert the entire
package ecosystem before you can be 3.0. And so if you contrast that to something like
C++, let me say good things about C++, they got the ABI right.</p>

<p>And so once the ABI was set, then you could have one package built in C++ 98, and one
package built in C++ 23, and these things would interoperate and be compatible even if you
took new keywords or other things in the future language version. And so what I see for
Mojo is much more similar to the—maybe the C++ ecosystem or something like this, but that
allows us to be a little bit more aggressive in terms of migrating code, in terms of
fixing bugs, and in moving language forward. But I want to make sure that Mojo 2.0 and
Mojo 1.0 packages work together and that there’s good tooling, probably AI-driven, but
good tooling to move from 1.0 to 2.0 and be able to manage the ecosystem that way.</p>

<h2 id="010549">01:05:49</h2>
<h2 id="ron-48">Ron</h2>
<p>I think the type system also helps an enormous amount. I think one of the reasons the
Python migration was so hard is that you couldn’t be like, ‘And then let me try and build
this with Python 3 and see what’s broken.’ You could only see what’s broken by actually
walking all of the execution paths of your program. And if you didn’t have enough testing,
that would be very hard. And even if you did, it wasn’t that easy. Whereas with a strong
type system, you can get an enormous amount of very precise guidance. And actually the
combination of a strong type system and an agentic coding system is awesome. We actually
have a bunch of experience of just trying these things out now, where you make some small
change to the type of something and then you’re like, ‘Hey, AI system, please run down all
the type errors, fix them all.’ And it does surprisingly well.</p>

<h2 id="010626">01:06:26</h2>
<h2 id="chris-48">Chris</h2>
<p>I absolutely agree. There’s other components to it. So Rust has done a very good job with
the stabilization approach with crates and APIs. And I think that’s a really good
thing. And so I think we’ll take good ideas from many of these different ecosystems and
hopefully do something that works well, and works well for the ecosystem, and allows us to
scale without being completely constrained by never being able to fix something once you
ship a 1.0.</p>

<h2 id="010645">01:06:45</h2>
<h2 id="ron-49">Ron</h2>
<p>I’m actually curious, just to go to the agentic programming thing for a second, which is
having AI agents that write good kernels is actually pretty hard. And I’m curious what
your experience is of how things work with Mojo. Mojo is obviously not a language deeply
embedded in the training set that these models were built on, but on the other hand, you
have this very strong type structure that can guide the process of the AI agent trying to
write and modify code. I’m curious how that pans out in practice as you try and use these
tools.</p>

<h2 id="010712">01:07:12</h2>
<h2 id="chris-49">Chris</h2>
<p>So this is why Mojo being open source, and—so we have hundreds of thousands of lines of
Mojo code that are public with all these GPU kernels, and like, all this other cool
stuff. And we have a community of people writing more code. Having hundreds of thousand
lines of Mojo code is fantastic. You can point your coding tool cursor, or whatever it is,
at that repo and say, ‘Go learn about this repo and index it.’ So it’s not that you have
to train the model to know the language, just having access to it—that enables it to do
good work. And these tools are phenomenal. And so that’s been very, very, very
important. And so we have instructions on our webpage for how to set up these tools, and
there’s a huge difference if you set it up right, so that it can index that, or if you
don’t, and make sure to follow that markdown file that explains how to set up the tool.</p>

<h2 id="010754">01:07:54</h2>
<h2 id="ron-50">Ron</h2>
<p>So, I want to talk a little bit about the future of Mojo. I think that the current way
that Modular and you have been talking about Mojo, these days at least—it’s a replacement
for CUDA, an alternate full top-to-bottom stack for building GPU kernels, for writing
programs that execute on GPUs. But that’s not the only way you’ve ever talked about
Mojo. You’ve also, especially earlier on I think, there was more discussion of Mojo as an
extension, and maybe evolution of, and maybe eventually replacement of Python. And I’m
curious, how do you think about that now? To what degree do you think of Mojo as its own
new language that takes inspiration and syntax from Python, and to what degree do you want
something that’s more deeply integrated over time?</p>

<h2 id="010832">01:08:32</h2>
<h2 id="chris-50">Chris</h2>
<p>So today, to pull it back to, ‘What is Mojo useful for today, and how do we explain it?’
Mojo is useful if you want code to go fast. If you have code on a CPU or a GPU and you
want it to go fast, Mojo is a great thing. One of the really cool things that is available
now—but it’s in preview and it’ll solidify in the next month or something—is it’s also the
best way to extend Python. And so if you have a large-scale Python code base, again, tell
me if this sounds familiar, you are coding away and you’re doing cool stuff in Python and
then it starts to get slow. Typically what people do is, they have to either go rewrite
the whole thing in Rust or C++, or they carve out some chunk of it and move some chunk of
that package to C++ or Rust. This is what NumPy, or PyTorch, or all modern large-scale
Python code bases end up doing.</p>

<h2 id="010913">01:09:13</h2>
<h2 id="ron-51">Ron</h2>
<p>If you look up on the mirrors and look at the percentage of programs that have C
extensions in them, it’s shockingly high. A really large fraction of Python stuff is
actually part Python and part some other language, almost always C and C++, a little bit
of Rust.</p>

<h2 id="010927">01:09:27</h2>
<h2 id="chris-51">Chris</h2>
<p>That’s right. And so today—this isn’t distant future—today, you can take your Python
package and you can create a Mojo file and you can say, ‘Okay, well these for loops are
slow, move it over to Mojo.’ And we have people, for example, doing bioinformatics and
other crazy stuff I know nothing about, saying, ‘Okay, well I’m just taking my Python
code, I move it over to Mojo. Wow, now I get types, I get these benefits, but there’s no
bindings. The pip experience is beautiful. It’s super simple.’ You don’t have to have
FFI’s and nanobind and all this complexity to be able to do this. You also are not moving
from Python with its syntax to curly braces and borrow checkers and other craziness. You
now get a very simple and seamless way to extend your Python package. And we have people
that say, okay, well I did that and I got it first 10x, and 100x, and 1000x faster on CPU.</p>

<p>But then because it was easy, I just put it on a GPU. And so to me, this is amazing
because these are people that didn’t even think and would never have gotten it on a GPU if
they switched to Rust or something like that. Again, the way I explain it is, Mojo is good
for performance. It’s good if you want to go fast on a GPU, on a CPU, if you want to make
Python go fast, or if you want to—I mean, some people are crazy enough to go whole hog and
just write entirely from scratch Mojo programs, and that’s super cool. If you fast forward
six, nine months, something, I think that Mojo will be a very credible top-to-bottom
replacement for Rust.</p>

<p>And so we need a few more extensions to the generic system. And there’s a few things I
want to bake out a little bit. Some of the dynamic features that Rust has for the
existentials, the ability to make a runtime trait is missing in Mojo. And so we’ll add a
few of those kinds of features. And as we do that, I think that’ll be really interesting
as an applications-level programming language for people who care about this kind of
stuff. You fast forward, I might even project a timeframe, maybe a year, 18 months from
now, it depends on how we prioritize things, and we’ll add classes. And so as we add
classes, suddenly it will look and feel to a Python programmer much more familiar. The
classes in Mojo will be intentionally designed to be very similar to Python, and at that
point we’ll have something that looks and feels kind of like a Python 4.</p>

<p>It’s very much cut from the same mold as Python. It integrates really well from
Python. It’s really easy to extend Python, and so it’s very much a member of the Python
family, but it’s not compatible with Python. And so what we’ll do over the course of N
years, and I can’t predict exactly how long that is, is continue to run down the line of,
okay, well how much compatibility do we want to add to this thing? And then I think that
at some point people will consider it to be a Python superset, and effectively it will
feel just like the best way to do Python in general. And I think that that will come in
time. But to bring it all the way back, I want us to be very focused on, ‘What is Mojo
useful for today?’ Great claims require great proof.</p>

<p>We have no proof that we can do this. I have a vision and a future in my brain, and I’ve
built a few languages and some scale things before, and so I have quite high confidence
that we can do this. But I want people to zero back into, okay, if you’re writing
performance code, if you’re writing GPU kernels or AI, if you have Python code, you don’t
want it to go slow, a few of us have that problem, then Mojo can be very useful. And
hopefully it’ll be even more useful to more people in the future.</p>

<h2 id="011226">01:12:26</h2>
<h2 id="ron-52">Ron</h2>
<p>And I think that already, the practical short-term thing is already plenty ambitious and
exciting on its own. Seems like a great thing to focus on.</p>

<h2 id="011232">01:12:32</h2>
<h2 id="chris-52">Chris</h2>
<p>Yeah, let’s solve heterogeneous compute and AI. That’s actually a pretty useful thing,
right?</p>

<h2 id="011237">01:12:37</h2>
<h2 id="ron-53">Ron</h2>
<p>Alright, that seems like a great place to stop. Thank you so much for joining me.</p>

<h2 id="011241">01:12:41</h2>
<h2 id="chris-53">Chris</h2>
<p>Yeah, well thank you for having me. I love nerding out with you and I hope it’s useful and
interesting to other people too. But even if not, I had a lot of fun with you.</p>

<h2 id="011249">01:12:49</h2>
<h2 id="ron-54">Ron</h2>
<p>You’ll find a complete transcript of the episode along with show notes and links at
signalsandthreads.com. Thanks for joining us. See you next time.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nepal moves to block Facebook, X, YouTube and others (250 pts)]]></title>
            <link>https://www.aljazeera.com/news/2025/9/4/nepal-moves-to-block-facebook-x-youtube-and-others</link>
            <guid>45137363</guid>
            <pubDate>Fri, 05 Sep 2025 11:31:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aljazeera.com/news/2025/9/4/nepal-moves-to-block-facebook-x-youtube-and-others">https://www.aljazeera.com/news/2025/9/4/nepal-moves-to-block-facebook-x-youtube-and-others</a>, See on <a href="https://news.ycombinator.com/item?id=45137363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>The restrictions come after the social media giants failed to meet state registration requirements, says government.</em></p></div><div aria-live="polite" aria-atomic="true"><p>Nepal’s government has said it will shut off access to major social media platforms, including Facebook and X, after they failed to comply with authorities’ registration requirements.</p><p>The move, announced on Thursday, is part of what the government says is an effort to curb online hate, rumours and cybercrime.</p><section><h2>Recommended Stories<!-- --> </h2><span>list of 3 items</span><ul><li><span>list 1 of 3</span><a href="https://www.aljazeera.com/news/2025/5/27/nepali-breaks-world-record-with-31st-summit-of-mount-everest">‘Everest Man’ breaks own record for climbing world’s highest mountain</a></li><li><span>list 2 of 3</span><a href="https://www.aljazeera.com/video/newsfeed/2025/7/8/dozens-missing-after-monsoon-triggers-nepal-china-floods">Dozens missing after monsoon triggers Nepal-China floods</a></li><li><span>list 3 of 3</span><a href="https://www.aljazeera.com/gallery/2025/5/5/the-last-nomads-of-nepal">Photos: The last nomads of Nepal</a></li></ul><span>end of list</span></section><p>Companies were given a deadline of Wednesday to register with the Ministry of Communications and Information Technology and provide a local contact, grievance handler and person responsible for self-regulation – or face shutdown.</p><p>“Unregistered social media platforms will be deactivated today onwards,” ministry spokesman Gajendra Kumar Thakur told AFP.</p><p>Communications and IT Minister Prithvi Subba Gurung said, “We gave them enough time to register and repeatedly requested them to comply with our request, but they ignored [this], and we had to shut their operations in Nepal.”</p><p>Meta, which owns Facebook, Instagram and WhatsApp, YouTube parent Alphabet, X, Reddit, and LinkedIn were asked to register by Wednesday’s deadline.</p><p>AFP reported that the platforms remained accessible on Thursday.</p><h2 id="directly-hits-fundamental-rights">‘Directly hits fundamental rights’</h2><p>The online restrictions follow a 2023 directive requiring social media platforms – which have millions of users in Nepal with accounts for entertainment, news and business – to register and establish a local presence.</p><p>Only five, including TikTok and Viber, have since formally registered, while two others are in the process.</p><p>Bhola Nath Dhungana, president of Digital Rights Nepal, said that the sudden closure shows the “controlling” approach of the government.</p><p>“This directly hits the fundamental rights of the public,” Dhungana said. “It is not wrong to regulate social media, but we first need to have the legal infrastructure to enforce it. A sudden closure like this is controlling.”</p><p>Nepal has restricted access to popular online platforms in the past.</p><p>Access was blocked to the Telegram messaging app in July, with the government citing a rise in online fraud and money laundering.</p><p>In August last year, Nepal lifted a nine-month ban on TikTok after the platform’s South Asia division agreed to comply with Nepali regulations.</p><p>Governments worldwide, including the United States, European Union, Brazil and Australia, are also <a href="https://www.aljazeera.com/economy/2025/7/25/meta-to-suspend-political-advertising-in-the-eu-as-transparency-law-looms">tightening oversight of social media and big tech</a>, citing concerns over misinformation, data privacy, online harm and national security. India has mandated local compliance officers and takedown mechanisms, while China maintains strict censorship and licensing controls.</p></div></div>]]></description>
        </item>
    </channel>
</rss>