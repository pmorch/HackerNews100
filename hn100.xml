<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 01 Jan 2026 01:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Warren Buffett steps down as Berkshire Hathaway CEO after six decades (334 pts)]]></title>
            <link>https://www.latimes.com/business/story/2025-12-31/warren-buffett-steps-down-as-berkshire-hathaway-ceo-after-six-decades</link>
            <guid>46448705</guid>
            <pubDate>Wed, 31 Dec 2025 21:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/story/2025-12-31/warren-buffett-steps-down-as-berkshire-hathaway-ceo-after-six-decades">https://www.latimes.com/business/story/2025-12-31/warren-buffett-steps-down-as-berkshire-hathaway-ceo-after-six-decades</a>, See on <a href="https://news.ycombinator.com/item?id=46448705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Greg Abel faces the challenge of taking over Berkshire Hathaway from the legendary Warren Buffett .</p><p>Many regard Buffett as the world‚Äôs greatest investor after he grew Berkshire from a struggling New England textile mill that he starting buying up for $7.60 a share in 1962, to the massive conglomerate it is today with shares that go for more than $750,000 a pop. Buffett‚Äôs personal fortune of Berkshire stock is worth roughly $150 billion even after giving away more than $60 billion over the last 20 years.</p><p>Berkshire for decades has routinely outpaced the S&amp;P 500 as Buffett bought up insurance companies like Geico and National Indemnity, manufacturers like Iscar Metalworking, retail brands like Dairy Queen, major utilities and even one of the nation‚Äôs biggest railroads, BNSF. Along the way, Buffett bought and sold hundreds of billions of dollars of stocks and profited handsomely from his famously long-term bets on companies like American Express, Coca-Cola and Apple.</p><p>Berkshire has struggled to keep that pace in recent years because it has grown so huge and also struggled to find new and significant acquisitions. Even this fall‚Äôs $9.7-billion acquisition of OxyChem probably isn‚Äôt big enough to make a difference in Berkshire‚Äôs profits.</p><p>Investors will be watching closely to see what changes Abel might make in Berkshire‚Äôs trajectory, but don‚Äôt expect any seismic shifts. </p><p>Buffett isn‚Äôt going anywhere and Abel has already been managing all of Berkshire‚Äôs noninsurance businesses since 2018. Buffett will remain chairman and plans to continue coming into the office each day to help spot new investments and offer Abel any advice he asks for. </p><h2 id="some-changes-are-likely">Some changes are likely</h2><p>CFRA Research analyst Cathy Seifert said it is natural for Abel to make some changes in the way Berkshire is run. Taking a more traditional approach to leadership with nearly 400,000 employees spread across dozens of subsidiaries makes a lot of sense, she said. </p><p>But Berkshire operates under an extremely decentralized structure that trusts its executives with significant decisions. Everyone associated with the company has said there are no plans to change that. </p><p>The world learned that Abel was to become the designated successor at Berkshire in 2021 when Buffett‚Äôs longtime business partner, the late Charlie Munger, assured shareholders at an annual meeting that Abel would maintain the company‚Äôs culture.</p><p>Part of Buffett‚Äôs sales pitch to company founders and CEOs thinking of selling their companies has always been that Berkshire would largely allow them to continue running their companies the same way as long as they delivered results.</p><p>‚ÄúI think the investment community would likely applaud Greg‚Äôs management style to the degree that it sort of buttons things up,‚Äù Seifert said. ‚ÄúAnd if it helps performance, that can‚Äôt really be faulted.‚Äù</p><h2 id="abel-plays-an-active-role-managing-companies">Abel plays an active role managing companies</h2><p>Abel has already shown himself to be a more hands-on manager than Buffett, but he still follows the Berkshire model of autonomy for acquired companies. Abel asks tough questions of company leaders and holds them accountable for their performance. </p><p>Abel did announce some leadership changes in December after investment manager and Geico CEO Todd Combs departed, and Chief Financial Officer Marc Hamburg announced his retirement. Abel also said he‚Äôs appointing NetJets CEO Adam Johnson as manager of all of Berkshire‚Äôs consumer, service and retail businesses. That essentially creates a third division of the company and takes some work off of Abel‚Äôs plate. He will continue to manage the manufacturing, utility and railroad businesses. </p><p>Abel will eventually face more pressure to start paying a dividend. From the beginning, Berkshire has held the position that it is better to reinvest profits rather than make quarterly or annual payouts to shareholders. </p><p>But if Abel can‚Äôt find a productive use of the $382 billion cash that Berkshire is sitting on, there may be a push from investors to start paying dividends or to adopt a traditional stock buyback program that would boost the value of shares they hold. Currently, Berkshire only repurchases shares when Buffett thinks they are a bargain, and he hasn‚Äôt done that since early 2024.</p><p>Still, Abel will be insulated from such pressure for some time since Buffett controls nearly 30% of the voting power in the stock. That will diminish gradually after his death as his children distribute his shares to charity as agreed. </p><h2 id="berkshire-has-a-solid-foundation">Berkshire has a solid foundation</h2><p>Many of Berkshire‚Äôs subsidiaries tend to follow the economy and profit handsomely whenever the country is prosperous. Berkshire‚Äôs utilities typically generate a reliable profit, and its insurance companies like Geico and General Reinsurance supply more than $175 billion worth of premiums that can be invested until claims come due. </p><p>Investor Chris Ballard, who is managing director at Check Capital, said most of Berkshire‚Äôs businesses ‚Äúcan almost take care of themselves.‚Äù He sees a bright future for Berkshire under Abel. </p><p>One of the biggest questions right now may be how much additional change there will be in company leadership after Combs‚Äô departure, if any at all. The head of the insurance unit, Vice Chairman Ajit Jain, who Buffett has long lavished with praise, is now 74. Many of the CEOs of the various companies have continued working long after retirement age because they like working for Buffett. </p><p>‚ÄúAs a long-term shareholder, we aren‚Äôt too concerned with Todd‚Äôs departure and don‚Äôt think this is the tip of some sort of iceberg,‚Äù said Ballard, whose firm counts Berkshire as its largest holding. ‚ÄúTodd‚Äôs situation is unique. It‚Äôs just a reminder that Warren‚Äôs pending departure is imminent and they‚Äôre preparing for a new phase ‚Äî one that we‚Äôre still excited to see unfold.‚Äù </p><p><i>Funk writes for the Associated Press. </i></p><div data-impression-sr="25.0" data-list-id="00000192-be42-da32-a3db-ff76fc3b0000" data-module-id="00000192-be42-da32-a3db-ff76fc3b0000" data-impression-threshold="1000" data-click="enhancement" data-align-center="">  <p data-element="element-header" data-click="liZZListTitleCTA">  <h3 data-element="element-header-title" data-counter="3">More to Read </h3>  </p>      </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy and control. My tech setup (140 pts)]]></title>
            <link>https://toidiu.com/blog/2025-12-25-privacy-and-control/</link>
            <guid>46446938</guid>
            <pubDate>Wed, 31 Dec 2025 18:39:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://toidiu.com/blog/2025-12-25-privacy-and-control/">https://toidiu.com/blog/2025-12-25-privacy-and-control/</a>, See on <a href="https://news.ycombinator.com/item?id=46446938">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>"I don't need to care about privacy because I have nothing to hide." is an
argument that I have heard countless times. I found this argument difficult to
counter in the past, yet deep-down I knew the reasoning was flawed.</p>
<p>The problem is that the word "privacy" is dialuted and mean different things to
different people. Instead of "privacy" we really should be talking about
"control". Framed in this context, we can more concretely talk about why it's
important to protect your digital identity.</p>
<p>For me privacy is not the primary driver, because like you mentioned, it doesn't
make sense for the common folk and doesn't actually fall into people's threat
model (journalists on the other hand should care). I am personally motivated by
the notion of "control". Can someone else meditate how I experience the world
and what information I consume? Whether that is censoring, influencing how much
time I have to spend watching ads or which ads I am allowed to watch. Can they
influence how I vote? Watch the talk <a href="https://www.youtube.com/watch?v=1oCDLbCyalM">In Defense of
Privacy</a> for a more on this.</p>
<p>Many of the convenient tools we use today (email, messaging, social media,
password manager) are essential for daily life but they also yield control over
to organizations (Google, Facebook, Amazon) that don't necessarily have our best
interst in mind [1][2].</p>
<h2 id="my-setup">My setup</h2>
<blockquote>
<p>Questioning how "incentives align" is a really good litmus test for most
things.</p>
</blockquote>
<p>Most of the following recommendations are based on my own threat model and
comfort level. There will always be a compromise between effort and easy. It's
best to pick what fits your lifestyle.</p>
<h3 id="password-manager">Password manager</h3>
<p>Use a password manager! I use <a href="https://www.passwordstore.org/">GNU pass</a> because
I don't want to hand over my passwords to a 3rd party. I typically only use the
password manager from my laptop and don't access passwords from my phone (I
consider this a better security practice). I have been meaning to try out
<a href="https://github.com/FiloSottile/passage">passage</a>. I would also recommend
<a href="https://bitwarden.com/">Bitwarden</a> for those who want a better UI experience.</p>
<h3 id="messanging">Messanging</h3>
<p>(Whatsapp is an unfortunate exception and I hate that I need it to stay
connected to friends and family). Signal for messaging is preferable [3]. Venmo
is disabled.</p>
<h3 id="phone">Phone</h3>
<p>I run <a href="https://grapheneos.org/features">GrapheneOS</a> on my Android. This allows
me to sandbox, disable or uninstall apps rather than allowing super-privileged
Google/ISP apps from doing whatever they wany on my personal device. By default,
<a href="https://grapheneos.org/features#sandboxed-google-play">Google Play apps are
unpriviledged</a> and have
to work within the sandbox model. GrapheneOS also allows you to restrict
permissions at a granular level, including network access. You can also disable
apps that you only use occasionally (Venmo, ride-sharing, Google play store).</p>
<p>I try to use opensource alternatives for apps on F-Droid. Did you know disabling
Google play store (also location services) increases your battery life by a lot!
Not running bloated stock OS also means your 5 year old phone is still fast and
usable (wtf do I need to but a new phone every 2 years?). I barely use social
media and don't install it on my phone (I use social media in Browser containers
to limit 3rd party cookies).</p>
<h3 id="email">Email</h3>
<p>I have a personal domain, which I use for email i.e. <a href="https://toidiu.com/cdn-cgi/l/email-protection" data-cfemail="1d75787171725d697274797468337e7270">[email&nbsp;protected]</a>. This
allows me to switch providers whenever I want (e.g. lack of trust in Google,
ProtonMail can raise their prices). These days I am using <a href="https://toidiu.com/blog/2025-12-25-privacy-and-control/tuta.com">Tuta</a> as my
email provider because they are fast, offer a better price and have a strong
focus on secure email. Also I can't be bothered to host my own email server.</p>
<h3 id="browsing">Browsing</h3>
<p>I use firefox with privacy badger and uOrigin because I do not opt into
companies personally targeting me (can be contentious since some sites use this
to make money).</p>
<h3 id="calendar-contacts">Calendar/Contacts</h3>
<p>I host my calendar and contacts on a raspberrypi, which you can only access on
localhost. The Caldav server is https://sabre.io/baikal, gets the job done.
I use <a href="https://www.davx5.com/">DAVx‚Åµ</a> to sync the contacts on my phone.</p>
<h3 id="domain">Domain</h3>
<p>Disclaimer: Cloudflare is my current employer. I switched to Cloudflare
Registrar recently because they offered a lower price when my previous Registrar
raised the price at renewal. I don't think Cloudflare really cares to make money
on domain registration.</p>
<h3 id="dns-resolution">DNS resolution</h3>
<p>I use Cloudflare's  DNS because I trust them more than other companies; purely
based on their business and how their incentives align
(https://one.one.one.one/). There are other secure/anaonymous ones out there.</p>
<h2 id="resources">Resources</h2>
<ul>
<li>[1] https://arstechnica.com/tech-policy/2024/03/facebook-secretly-spied-on-snapchat-usage-to-confuse-advertisers-court-docs-say/</li>
<li>[2] https://arstechnica.com/security/2025/06/meta-and-yandex-are-de-anonymizing-android-users-web-browsing-identifiers/</li>
<li>[3] https://www.youtube.com/live/AyH7zoP-JOg?t=222s</li>
</ul>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta created 'playbook' to fend off pressure to crack down on scammers (198 pts)]]></title>
            <link>https://www.reuters.com/investigations/meta-created-playbook-fend-off-pressure-crack-down-scammers-documents-show-2025-12-31/</link>
            <guid>46446838</guid>
            <pubDate>Wed, 31 Dec 2025 18:28:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/investigations/meta-created-playbook-fend-off-pressure-crack-down-scammers-documents-show-2025-12-31/">https://www.reuters.com/investigations/meta-created-playbook-fend-off-pressure-crack-down-scammers-documents-show-2025-12-31/</a>, See on <a href="https://news.ycombinator.com/item?id=46446838">Hacker News</a></p>
Couldn't get https://www.reuters.com/investigations/meta-created-playbook-fend-off-pressure-crack-down-scammers-documents-show-2025-12-31/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[I canceled my book deal (321 pts)]]></title>
            <link>https://austinhenley.com/blog/canceledbookdeal.html</link>
            <guid>46446815</guid>
            <pubDate>Wed, 31 Dec 2025 18:26:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://austinhenley.com/blog/canceledbookdeal.html">https://austinhenley.com/blog/canceledbookdeal.html</a>, See on <a href="https://news.ycombinator.com/item?id=46446815">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
				  <h2>Austin Z. Henley</h2>
				  <p>
						Associate Teaching Professor<br>
						Carnegie Mellon University
					</p>
				</div>

	  <hr>
	  
    
	  <hr>

	
	<small>12/31/2025</small><p>

<img src="https://austinhenley.com/blog/images/challengingprojectsbook.png" alt="An AI-generated book cover for the book I was working on, 'Challenging Programming Projects'."></p><p>Back in 2020-2022, my blog was getting a lot of attention. Some of the big tech book publishers reached out about whether I was interested in writing a book. I had a few conversations but decided against it. I did want to write a book but self-publishing seemed like the better option.</p>

<p>Then an acquisitions editor for another big publisher asked to chat. He had a similar background to me, an academic who enjoys coding and writing. He had written a few books for multiple publishers so he knew the process and wasn't shy to share the good and bad. He even made decent money from his books.</p>

<p>I was intrigued. Writing a book was one of those goals that I liked the idea of but never made any progress on. I went and talked to a few other people that had published technical books and they gave me their reviews of the process and of each of the big publishers.</p>

<ul>
<li>Pros of a publisher: They are a forcing function to make progress, they handle a lot of logistics for you around the book, they provide <i>some</i> feedback on the content, they have large distribution channels, and it looks more "real" when a publisher's name is on your book.</li>
<li>Cons of a publisher: They nag you constantly, they may try to steer your book in other directions, the money is peanuts, they can stop printing the book whenever they want, they have control over future editions, and they actually do little to no marketing of your book.</li>
</ul>

<p>I decided to write a book and sign with the publisher!</p>


<h3>The topic</h3>

<p>Before the actual deal, we had to agree on the book. Each publisher has their own template for pitching an idea. I did that and we went back and forth on some of the details. This part felt collaborative, they were trying to help me flesh out the concept based on their data and experience.</p>

<p>A lot of my blog posts involve classic programming projects that were relevant 30 years ago and will be just as fun 30 years from now. What if the book is a collection of tutorials on building these projects, each self-contained and teach fundamental computing concepts along the way?</p>

<p>To motivate that there is a market for this, I showed them that several of my blog posts in this space collectively had millions of views. Most notably, <a href="https://austinhenley.com/blog/challengingprojects.html">Challenging programming projects every programmer should try</a> (and the two sequels). My readers seem to resonate with <a href="https://austinhenley.com/blog/makinguselessstuff.html">making useless stuff</a> and <a href="https://austinhenley.com/blog/programmingasplay.html">programming for fun</a>. Who doesn't love hacking on a ray tracer or compiler or game or operating system just for fun?!</p>

<figure>
<img src="https://austinhenley.com/blog/images/websiteviewschart.png" alt="Screenshot of my page view analytics showing 20+ large spikes when many thousands of people came to my website on individual days.">
<figcaption><small>Page view spikes from my blog hitting up to 80,000 unique viewers a day.</small></figcaption>
</figure>

<p>They liked it! It was quite different than many of their other books. I wrote a high-level outline of the entire book. The projects were going to be:</p>

<ul>
    <li>Web crawler</li>
    <li>2d game</li>
    <li>Compiler</li>
    <li>HTTP server</li>
    <li>Drawing app</li>
    <li>CHIP-8 emulator</li>
    <li>TBD</li>
    <li>A list of mini projects</li>
</ul>

<p>The compiler chapter would be a revised version of my <a href="https://austinhenley.com/blog/teenytinycompiler1.html">Let's make a Teeny Tiny compiler</a> blog series. The last project chapter would list a bunch of smaller scale projects that are less of a commitment but still worthwhile for learning (e.g., an image file format converter). Also, each chapter would end with a bunch of suggestions on how to continue with the project. If I got to the end and the book was a bit short, I was planning to squeeze in one more project chapter too.</p>

<h3>The contract</h3>

<p>There was some negotiation of the contract terms. We had to agree specifically on what the book was going to be. This included the pitch for the book, who the intended audience is, and a very detailed Table of Contents (down to the subsubsection headings). I had to give a tentative schedule of when I'd deliver drafts for major milestones.</p>

<p>The weirdest thing in the contract was the number of illustrations that the book must contain. I asked to bump that up. In the end we agreed to 115,500 to 132,000 words in length, approximately 350 to 400 printed pages, with 10 to 30 illustrations. </p>

<p>They offered a $5000 advance with the first half paid out when they approve of the first third of the book and the second half when they accept the final manuscript for publication.</p>

<p>I didn't even bother negotiating this because it is essentially nothing. I have a day job so I don't need the money sooner to pay rent (it is just an advance after all!) and if I don't sell way, way more than that then this was a bad use of my time financially anyway.</p>

<p>The royalties offered were surprisingly low. I did negotiate these and got them bumped up a tiny bit. They agreed to 12% of total sales for print and e-book on the first 7000 copies and then 15% on sales after that. 50% royalty on foreign translation sales.</p>

<p>I was later told that some people negotiated up to 18%. Meh. The finances don't look great regardless unless you have one of their top books.</p> 

<p>They refused to share statistics. I was able to get out of them that their median book sells in the range of single thousands of copies. Their top sellers are in the range of hundreds of thousands of copies but they only shared one example of a book that did that. Most are on the shelf for only a few years.</p>

<p>Oh, and I get 25 copies for myself and I can buy copies at a 50% discount.</p>

<p>We kicked the project off in early 2023.</p>


<h3>Get to writing!</h3>

<p>They assigned me an editor that I met with regularly. This was my main contact with the publisher.</p>

<p>He walked me through the process and got me set up. I was required to use AsciiDoc or Microsoft Word for my drafts. Nope, I can't use LaTeX. He gave me a very detailed style guide that I had to follow.</p>

<p>He emailed me, a lot. We had initially agreed to a chapter draft every 3 or 4 weeks (I was overly optimistic, and felt pressured...). Once that first soft deadline passed, the constant emails asking to see drafts began.</p>

<p>When I delivered a draft, I quickly got a marked-up version back. The feedback was mostly formatting and styling. The helpful feedback was pointing out rough transitions or assumptions I made about prior knowledge.</p>

<p>The unhelpful feedback was a consistent push to dumb down the book (which I don't think is particularly complex but I do like to leave things for the reader to try) to appease a broader audience and to mellow out my personal voice. He also wanted me to add a chapter that acts as an intro to programming with Python... üòµ</p>

<blockquote>"There needs to be an initial chapter for teaching Python in case the reader doesn't have the background. What if they don't know how to use pip to install packages?"</blockquote>

<p>It became clear that they were following a formula for technical books. Don't show too much personality, don't be too technical, and hand hold the reader through a linear task. Just crank out the book so they get the book on the shelf. What you say on page 120 doesn't matter because the reader has already bought the book.</p>

<p>This rubbed me the wrong way but I pushed through. They are just following their incentives and I should push back.</p>


<h3>AI, AI, AI</h3>

<p>The book was started only a few months after the release of ChatGPT. The entire world was talking about AI!</p>

<p>So it wasn't long before the publisher asked to chat. <i>"Hey, is there any way you can incorporate AI into the book?"</i>, I politely declined.</p>

<p>A bit later they come back basically saying <i>The Powers That Be</i> are requiring AI to be part of every book. I offered a few compromises (i.e., a chapter about implementing an ML algorithm or a note at the end of each chapter about leveraging AI in the creation of the projects). I got a mixed response.</p>

<blockquote>"All of our future books will involve AI."</blockquote>

<p>In the end, I firmly told them no. It is antithetical to the premise of the book (<b>classic</b> programming projects!) that they agreed to publish. They went away.</p>


<h3>Getting closer?</h3>

<p>I kept missing deadlines. I was busy with work (AI!) and life. Apparently every book's timeline gets pushed at least once, so they were flexible. I eventually sent the editor the first third of the book and we made a few back-and-forths revising it.</p>

<p>This triggered the next stage: getting feedback on the technical content. We would do a round or two of this with a technical editor, then the draft would go off to strangers for review. If they hated it, the publisher had the right to cancel the project. If they don't hate it, then the draft would go live for early readers to buy (and they'd receive future chapters as they are completed).</p>

<p>The first notes I got back from the technical editor didn't seem like a good fit. Everything he said was correct, but indicated a mismatch in expectations. He was critiquing the project in the chapter as if it was supposed to be production quality software. But my projects are a balancing act of what can any programmer with very little knowledge on the subject make in a weekend that gives them a broad understanding of the concepts.</p>

<p>The second chapter of feedback from the technical editor was far more helpful to me. I think he "got" what I was going for and pointed out many flaws and suggested many improvements I could make. It was nice. Iterating on existing content is a very different workflow than writing new content so I slowed down even more. For example, it can be quite tedious to make sure that code snippets are consistent with snippets from 20 pages prior.</p>


<h3>Life</h3>

<p>I continued to get further behind on delivering my revised draft of the first 1/3. This is a big milestone in the publisher's process (soliciting external reviewers, determining whether the project should continue, putting the early adopters e-book up for sale, and paying out the first half of the advance).</p>

<p>The publisher was getting grumpy. I was getting grumpy. They were bringing up pivoting the book to be about AI again. They were "reevaluating" their portfolio. My editor left the company and I was assigned a new one. Things were piling on.</p>

<p>There was also a daunting voice in the back of my head that LLMs have eliminated the need for books like this. Why buy this book when ChatGPT can generate the same style of tutorial for <b>ANY</b> project that is customized to you?</p>

<p>The process with the publisher wasn't enjoyable. I had hoped for it to be a positive motivator to keep me focused but it felt like a chore. And I was worried that the finished product would be void of personality and would be yet another boring programming book.</p>

<p>Around this time, there was a possibility of me <a href="https://austinhenley.com/blog/leavingmicrosoft.html">changing jobs</a>. Oh, and my wedding was coming up. That was the final nail in the coffin.</p>

<figure>
<img src="https://austinhenley.com/blog/images/ocean.jpg" alt="Photo of the sunsetting over the ocean.">
<figcaption><small>Photo from my honeymoon while not working on the book.</small></figcaption>
</figure>


<h3>The end</h3>

<p>There were too many things going on and I didn't enjoy working on the book anymore, so what is the point? I made up my mind to ask to freeze the project.</p>

<p>They agreed.</p>

<p>I think they thought of this as a temporary cooldown where I could sporadically work on the book without the stress of the deadlines. The new editor still pinged me regularly asking if I made progress. Repeatedly. (I suppose they are following the incentives again‚Äîthey only get paid if people ship books.) Eventually I asked him to stop until I reached out first.</p>

<p>And then... life went on. I never got un-busy.</p>

<p>Fast forward, I just got notification from the publisher that the <b>contract has been officially terminated</b> and all rights of the work were transferred back to me.</p>

<p>I still love my book idea. Maybe I'll just publish the chapters as blog posts or self-publish it. Or maybe I'll work on something entirely unrelated!</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Court report detailing ChatGPT's involvement with a recent murder suicide [pdf] (123 pts)]]></title>
            <link>https://storage.courtlistener.com/recap/gov.uscourts.cand.461878/gov.uscourts.cand.461878.1.0.pdf</link>
            <guid>46446800</guid>
            <pubDate>Wed, 31 Dec 2025 18:25:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.461878/gov.uscourts.cand.461878.1.0.pdf">https://storage.courtlistener.com/recap/gov.uscourts.cand.461878/gov.uscourts.cand.461878.1.0.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=46446800">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Stewart Cheifet, creator of The Computer Chronicles, has died (188 pts)]]></title>
            <link>https://obits.goldsteinsfuneral.com/stewart-cheifet</link>
            <guid>46446359</guid>
            <pubDate>Wed, 31 Dec 2025 17:41:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://obits.goldsteinsfuneral.com/stewart-cheifet">https://obits.goldsteinsfuneral.com/stewart-cheifet</a>, See on <a href="https://news.ycombinator.com/item?id=46446359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                            <p>Stewart Douglas Cheifet, age 87, of Philadelphia, PA, passed away on December 28, 2025.</p><p id="isPasted">Stewart was born on September 24, 1938, to Paul and Anne Cheifet in Philadelphia, where he spent his childhood and attended Central High School. He later moved to California to attend college, graduating from the University of Southern California in 1960 with degrees in Mathematics and Psychology. He went on to earn his law degree from Harvard Law School.&nbsp;</p><p>In 1967, Stewart met his future wife, Peta Kennedy, while the two were working at CBS News in Paris. They returned to the United States and married later that year. Stewart‚Äôs career in television production took them around the world, and they lived together in the Samoan Islands, Hawaii, San Francisco, and Los Angeles, before eventually settling back in Philadelphia.&nbsp;</p><p>Stewart and Peta had two children, Stephanie and Jonathan.&nbsp;</p><p>Stewart is best known for producing and hosting the nationally broadcast PBS television programs Computer Chronicles and Net Cafe. Computer Chronicles aired from 1984 to 2002, producing more than 400 episodes that documented the rise of the personal computer from its earliest days. Net Cafe, which aired from 1996 to 2002, explored the emergence of the internet. Both programs were widely regarded as visionary, capturing the evolution of personal computing and the early development of the digital age.&nbsp;</p><p>Stewart‚Äôs professional interests and talents were wide-ranging. After leaving television production, he worked as a consultant for the Internet Archive, helping to preserve and provide public access to cultural and technological media, including Computer Chronicles and other technology programs. He also shared his knowledge as an educator, teaching broadcast journalism at the Donald W. Reynolds School of Journalism at the University of Nevada, Reno. After retirement, he spent his remaining years enjoying time with Peta, his children, his grandchildren, and his brothers.&nbsp;</p><p>Stewart is survived by his brothers Lanny and Bruce, his children Stephanie and Jonathan, and his grandchildren Gussy, Josephine, Benjamin, Freya, and Penny.</p><p>Services will be held for immediate family only.</p>

                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2025 was a disaster for Windows 11 (188 pts)]]></title>
            <link>https://www.windowscentral.com/microsoft/windows-11/2025-has-been-an-awful-year-for-windows-11-with-infuriating-bugs-and-constant-unwanted-features</link>
            <guid>46445491</guid>
            <pubDate>Wed, 31 Dec 2025 16:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windowscentral.com/microsoft/windows-11/2025-has-been-an-awful-year-for-windows-11-with-infuriating-bugs-and-constant-unwanted-features">https://www.windowscentral.com/microsoft/windows-11/2025-has-been-an-awful-year-for-windows-11-with-infuriating-bugs-and-constant-unwanted-features</a>, See on <a href="https://news.ycombinator.com/item?id=46445491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN.jpg" alt="Windows 11" srcset="https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/oufEx2VJJSiJJpD745PddN.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Windows Central / Zac Bowden)</span>
</figcaption>
</div>
<div id="article-body">

<p id="35955687-6d73-4501-8bf9-25e7b441438e">The last 12 months have been an incredibly frustrating time for Windows fans. For the first time in a long while, it feels like Windows is suffering from a lack of focus from the people at the top.</p><p><a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-10/windows-10-is-officially-dead" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-10/windows-10-is-officially-dead">Support for Windows 10 ended in October</a>, and this year was the perfect time to strengthen Windows 11 as a viable replacement for millions of users. Instead, Microsoft spent most of it <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/ai-in-windows-11-bloat-brilliance-or-something-in-between" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/ai-in-windows-11-bloat-brilliance-or-something-in-between">shoving the OS full of half-baked AI features</a>, all while letting the quality bar slip and <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/october-update-windows-11-winre-input-bug" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/october-update-windows-11-winre-input-bug">shipping new bugs and issues</a> on an almost monthly cadence.</p><h2 id="ai-obsession-is-hurting-windows-3">AI obsession is hurting Windows</h2><figure data-bordeaux-image-check="" id="50bdbb36-0f1b-4ac8-90e1-6998571f031e"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj.jpg" alt="Microsoft 365 Copilot icon" srcset="https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/JfzQPBVnFagawFN4bNgqbj.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Every big Windows announcement this year was tied to some kind of AI feature or event. </span><span itemprop="copyrightHolder">(Image credit: Windows Central)</span></figcaption></figure><p id="27796049-a0b7-418f-9377-c8f9f2078f90">Of course, the issue that made headlines the most this year is AI, as Microsoft falls over itself trying to make Windows 11 a frontier platform for <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/artificial-intelligence" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence">artificial intelligence</a>. Unfortunately, this effort feels like it has been prioritized above everything else, including quality of life and overall platform stability.</p><p>Copilot has forced its way into almost every surface and intention on the platform. Heck, even <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-11-notepad-will-soon-let-you-generate-text-using-on-device-ai-models-no-subscription-required" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-11-notepad-will-soon-let-you-generate-text-using-on-device-ai-models-no-subscription-required">Notepad now has a Copilot button</a>, which is something literally nobody has ever asked for. Microsoft's AI intentions feel obsessive and forced, almost as if the company is just throwing everything at the wall to see what sticks.</p><p>Under the hood, Microsoft has been moving to make Windows 11 agentic. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-just-revealed-how-windows-11-is-evolving-into-an-agentic-os-finally-the-explanation-weve-all-been-waiting-for" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-just-revealed-how-windows-11-is-evolving-into-an-agentic-os-finally-the-explanation-weve-all-been-waiting-for">It unveiled the agentic workspace</a>, along with a set of APIs that will allow AI developers to build tools that can automate workflows on your behalf. Sounds great on paper, until you read the fine print and discover that it comes with <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-warns-security-risks-agentic-os-windows-11-xpia-malware" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-warns-security-risks-agentic-os-windows-11-xpia-malware">serious security implications and warnings. </a></p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-DjgB8CDooXtXtjAxRbocvW"><section><p>All the latest news, reviews, and guides for Windows and Xbox diehards.</p></section></div><p>You'd like to think that a feature with such serious security concerns wouldn't make it out of the lab, but because this is AI, Microsoft doesn't seem to mind. The feature even ships off by default, which tells you everything you need to know about how the company views this feature.</p><p>A large chunk of the AI features that were announced this year also aren't Copilot+ PC exclusive, which means most of them require an internet connection and your data sent to the cloud to be useful, which is another privacy concern to add to all the other privacy concerns on Windows 11.</p><p>In November, Windows president Pavan Davuluri mentioned that Windows would evolve into an agentic OS, <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-president-confirms-os-will-become-ai-agentic-generates-push-back-online" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-president-confirms-os-will-become-ai-agentic-generates-push-back-online">sparking one of the biggest amounts of backlash</a> I've seen around Windows this year. His post was so negatively received, he had to disable replies and issue a follow up statement reassuring customers that <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-president-addresses-current-state-of-windows-11-after-ai-backlash-we-know-we-have-a-lot-of-work-to-do" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-president-addresses-current-state-of-windows-11-after-ai-backlash-we-know-we-have-a-lot-of-work-to-do">Windows would continue to innovate outside of AI too.</a></p><p>I want to stress that AI <em>can </em>be beneficial. I've always said that AI is best when it's invisible, which is why I'm so confused about Microsoft's approach to AI on Windows 11. It seems like Microsoft wants AI to be <em>the </em>selling point, but that's totally backwards. AI should be a helpful extra, not an all-encompassing, sole reason for the platform's existence.</p><h2 id="continuous-innovation-more-like-continuous-irritation-3">Continuous Innovation? More like Continuous Irritation!</h2><figure data-bordeaux-image-check="" id="67d4affe-db9f-4f7f-91ec-d2fe299b0ca8"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU.jpg" alt="Windows Update" srcset="https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/R9fj76rTfHoxg4GXCp3UzU.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Your Windows 11 install is at risk of being "improved" on a monthly cadence these days. </span><span itemprop="copyrightHolder">(Image credit: Windows Central)</span></figcaption></figure><p id="944c1d64-9c9c-49fe-a761-8df1a750617a">I think the biggest issue users are dealing with right now is Microsoft's "Continuous Innovation" strategy for Windows 11, which is designed to allow the company to build new features and get them out the door faster than ever before.</p><p>In the past, new Windows features were often timed with a significant OS update. Once a year, Windows would receive a big upgrade, which would introduce new features and improvements from the core up. This allowed Microsoft plenty of time to bake and fine-tune new features and changes, ironing out bugs before general availability.</p><p>Today, thanks to Continuous Innovation, Microsoft is able to ship new features whenever the company <em>deems </em>them ready. Every. Single. Month. This means there's now a constant churn of new features, with no breaks or respite. Users never get a chance to breathe.</p><p>On top of this is Microsoft's Controlled Feature Rollout (CFR) system, which makes it so some users don't see the new features even after installing the update that supposedly includes them, making it literally impossible to predict and prepare for when a new feature might actually arrive on your PC.</p><p>The new Windows 11 <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/start-menu" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/start-menu">Start menu</a> is a perfect example of this. It only began rolling out in October, but thanks to Controlled Feature Rollout, many users didn't get it right away after installing the October update. For those people, it randomly appeared a few days or weeks later, without any warning or prompt, letting the user know what happened and why.</p><p>In this scenario, going into your update history to see what changed is going to confuse you, because the update that includes the new Start menu was installed on your system weeks ago. You're only seeing the new features now because Microsoft allowed you to see it, which is insane and frustrating beyond belief.</p><figure data-bordeaux-image-check="" id="ba911589-a255-4e16-8ba6-ffb740115e5e"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC.jpg" alt="Windows 11 Hero Surfaces" srcset="https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/DcHbdc7uoWTNGW5E7NtpGC.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Two identical installs of Windows might present themselves differently thanks to CFR. </span><span itemprop="copyrightHolder">(Image credit: Future)</span></figcaption></figure><p id="5721c7ca-3c21-43f9-b36d-ed23211d6589">As a result, no two Windows PCs are the same these days. Two identical systems, running the same build and update of Windows 11, might appear completely different feature-wise, which is confusing to your average user, and more than likely one of the reasons why Windows feels so much buggier these days. There are too many moving parts.</p><p>Continuous Innovation essentially boils down to allowing Microsoft to force new features onto you whenever it wants, because the company ties these new features to monthly security updates, which are essentially required if you want to use your computer safely on the internet.</p><p>But it's beyond frustrating when said features or changes randomly appear on your system without any warning, and even more frustrating when you can't disable or undo them. Users have to make do with Microsoft constantly moving the deck chairs, and people are getting tired.</p><p>I mean, Microsoft has even built a <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/microsoft-publishes-windows-roadmap-as-it-promises-transparency-around-feature-availability" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/microsoft-publishes-windows-roadmap-as-it-promises-transparency-around-feature-availability">Windows Roadmap website</a> designed to try and make it easier to see where new features are in their rollout. Except, the website is so confusing and frustrating to navigate, and digest, it's actually not very useful at all. That's how complicated the Windows update situation is right now.</p><p>Above all else, it renders the annual version update essentially irrelevant. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-confirms-windows-11-version-25h2-no-new-features" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-confirms-windows-11-version-25h2-no-new-features">Version 25H2</a>, which shipped a couple of months back, includes no new features or changes over version 24H2, because Microsoft ships new features to both at the same time. They are the same version. Why even do this? Surely it makes more sense just to extend support for version 24H2?</p><h2 id="a-noticeable-decline-in-quality-3">A noticeable decline in quality </h2><figure data-bordeaux-image-check="" id="9280ebf5-22dd-4cdc-80d3-918dc3b08519"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM.jpg" alt="File Explorer white flash" srcset="https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/pyfeM55as54YPZs2FAZfsM.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>A non-security preview update that was released to the public ended up flash banging users in dark mode when opening File Explorer. </span><span itemprop="copyrightHolder">(Image credit: Windows Central)</span></figcaption></figure><p id="e185c048-3735-4283-ba68-766e7d19ef7a">Unfortunately, Microsoft's ability to ship new features quickly appears to have also contributed to a noticeable decline in quality over the last year or two. It feels like <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai">many new features that actually ship are half-baked</a>, and in some cases<a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-says-latest-windows-11-updates-might-break-the-start-menu-taskbar-and-other-integral-ui-bits-heres-what-you-need-to-know" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-says-latest-windows-11-updates-might-break-the-start-menu-taskbar-and-other-integral-ui-bits-heres-what-you-need-to-know">, outright break other things as they are introduced.</a></p><p>Every single week, there's a new headline about how a recent Microsoft update has broken something on Windows, with fixes for said bugs either coming a couple of weeks later or an entire month later, depending on the schedule. Rarely, if ever, does Microsoft pull an update that is causing bugs, though it has happened a couple of times.</p><p>I wouldn't be surprised if CFR is playing a part in this decline in quality. With the same version of Windows being able to present itself differently depending on what I can only describe as random factors, it may be just becoming harder to keep Windows stable when there are so many moving parts and variables at play.</p><p>Windows 11 today is a much more complex beast than previous versions of Windows have been. Microsoft has been obsessed with A/B testing for a long while, but CFR takes it to a whole other level, to the point where you literally can't guarantee the version of Windows 11 you're installing will be "feature complete" when you want it to be.</p><p>Some users have reported never getting the chance to test a particular feature before it's made generally available because of CFR. That's how detrimental the system is to the development and availability of new Windows features. As a real-life example of this, my main Windows 11 Insider PC is still stuck with the old Start menu, even though the new Start menu is now rolling out and generally available.</p><figure data-bordeaux-image-check="" id="6866115a-f499-4ed1-990e-83aafab5b9c6"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS.jpg" alt="Windows 11 Recovery Drive" srcset="https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Sqcu6yCMhr5QH6DpmmvyRS.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>One update even broke Windows recovery for a period of time this year. </span><span itemprop="copyrightHolder">(Image credit: Daniel Rubino / Windows Central)</span></figcaption></figure><p id="7bdfcdec-eaed-42e0-ae19-75f975c312eb">There's no built-in option in the OS to override this, meaning there's nothing I can do to get the new Start menu without relying on third-party tools to trick the system into letting me test it.</p><p>In some ways, CFR feels like a way for Microsoft to hide behind the fact that it knows the features it ships to production aren't always 100% ready, as it allows them to disable access to said features server-side if a problem arises.</p><p>There's also the issue of consistency, which continues to be a problem on Windows 11. The company has done well to attempt to address UI consistency, though there are still glaring issues in areas like the File Explorer. But what frustrates me most is the inconsistent use of its own native Windows UI framework in in-box apps and the OS shell.</p><p>Outlook is the built-in mail client on Windows 11, and it's genuinely <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/i-actually-hate-the-new-outlook-for-windows" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/i-actually-hate-the-new-outlook-for-windows">the worst included OS email client I've ever used</a>. It's a website that's slow to open, unreliable at sending notifications, and eats up a chunk of memory when in use. There's nothing optimized or delightful about the Outlook app on Windows 11.</p><p>Microsoft also just announced that it's<a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-11-will-finally-get-its-missing-agenda-view-but-microsoft-rebuilt-it-in-the-worst-way" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-11-will-finally-get-its-missing-agenda-view-but-microsoft-rebuilt-it-in-the-worst-way"> bringing back the agenda view</a> to the calendar flyout on the Taskbar, but it looks like that feature is built using web tech instead of Windows 11's native UI stack. That's frankly unacceptable, but this is the sort of thing Microsoft does on a frequent basis these days.</p><h2 id="the-competition-is-circling-3">The competition is circling</h2><figure data-bordeaux-image-check="" id="f3046ec8-729b-462b-b151-9560e62a032d"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei.jpg" alt="Valve Steam Machine render showing the cube-shaped desktop PC on a cream-colored background" srcset="https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/zss39QuqnFWaeGS6WLLaei.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Valve is coming for Microsoft's lunch. </span><span itemprop="copyrightHolder">(Image credit: Valve)</span></figcaption></figure><p id="b7b621cb-04f0-4f50-9b96-a95d3d1814ff">Unfortunately for Microsoft, its competitors have been quietly capitalizing on Windows' downfall in the last year or so. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/google-is-building-the-android-pc-and-phone-convergence-platform-that-microsoft-failed-to-deliver-with-windows-qualcomm-calls-it-incredible" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/google-is-building-the-android-pc-and-phone-convergence-platform-that-microsoft-failed-to-deliver-with-windows-qualcomm-calls-it-incredible">Google has been working behind closed doors on Android PCs</a>, which are expected to debut next year as a viable alternative to Windows in the low-end to mid-range PC space.</p><p>This is an area that Windows woefully struggled in in recent years. Windows 11 is just too big, bloated, and unoptimized to run well on low-end hardware, to the point where many schools and enterprises are switching to <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/chrome-os" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/chrome-os">Chrome OS</a> or even the iPad because Windows just sucks on these devices.</p><p>I'm still blown away by how quick Chrome OS is at both updating the system and factory resetting the system. Installing a system update on Chrome OS is as quick as restarting an app, taking less than a few seconds in most cases. On Windows 11, installing an update can take anywhere from a few minutes to hours, depending on how big the update is.</p><p>With Android PCs, Windows might finally have a real challenger in this low-end space. If Lenovo, Dell, HP, and the other top-name OEMs are on board to build Android PCs, I really don't see how Windows 11 in its current state will be able to compete. The Android system is just better optimized for these low-end devices, and Windows needs a real architectural slim down even to stand a chance.</p><p>It's not just Google coming for Microsoft's lunch either;<a data-analytics-id="inline-link" href="https://www.windowscentral.com/gaming/pc-gaming/valve-already-gambled-on-steam-machine-which-brands-would-return" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/gaming/pc-gaming/valve-already-gambled-on-steam-machine-which-brands-would-return"> Valve is interested in taking some of that sweet gamer market share</a> from Windows. It's made its intentions very clear this year: <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/steamos" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/steamos">SteamOS</a> is the future of PC gaming, and it wants as many Windows users to make the switch as possible.</p><p>This couldn't have come at a worse time for Microsoft, given the backlash and frustration from users about Windows 11. Gamers are all but ready to abandon ship, and Valve is offering up a viable alternative on a plate. The Steam Machine is going to light a fire under Windows PC gaming.</p><p>Then you've got Apple, which is always slowly pecking away at Windows market share with the Mac. Since Apple Silicon, Mac has only gained market share, and its latest laptops are some of the best out there. These days, the only reason not to buy a Mac is if you need a laptop with a touch screen or 5G, or just don't like MacOS.</p><p>Now, <a data-analytics-id="inline-link" href="https://www.windowscentral.com/hardware/laptops/its-more-bad-news-for-microsoft-and-windows-11-apples-cheap-macbook-actually-sounds-good" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/hardware/laptops/its-more-bad-news-for-microsoft-and-windows-11-apples-cheap-macbook-actually-sounds-good">Apple is rumored to be building a cheap MacBook</a> that will ship sometime next year. This could be potentially devastating for Windows, because for a lot of people, the only reason they don't own a Mac is that they're too expensive. If Apple can ship a new MacBook for $600, that's going to be hard to say no to over any Windows laptop in the same price range.</p><h2 id="it-s-not-all-bad-3">It's not all bad</h2><figure data-bordeaux-image-check="" id="9bc8896a-5850-4808-8103-74b6676281da"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP.jpg" alt="A Legion Go 2 standing up on its kickstand and displaying Xbox Full Screen Experience." srcset="https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/7mpfq947x9TB7Qq3B9opP.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Gaming was an area of great improvement on Windows 11 in 2025. </span><span itemprop="copyrightHolder">(Image credit: Rebecca Spear / Windows Central)</span></figcaption></figure><p id="ab459807-c787-40c8-8bd2-e09e31fb368b">I don't want this article to be all doom and gloom, and it shouldn't be, because for all of Windows' faults, Microsoft has done some good things with the platform this year.</p><p>It finally committed to refocusing on small but important details and experiences in the OS. The company understands that Windows 11 currently feels incomplete in a lot of areas, likely because it is, and is addressing those key complaints. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-makes-it-official-dark-mode-is-getting-a-major-and-sorely-needed-upgrade-on-windows-11" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-makes-it-official-dark-mode-is-getting-a-major-and-sorely-needed-upgrade-on-windows-11">Things like Dark Mode are being more consistently applied across the OS now</a>, which is an improvement I've been waiting a decade for.</p><p>The company is also adding back things like smooth animations when hovering over open app icons on the Taskbar, or the Agenda view in the Calendar flyout on the Taskbar (albeit with web tech). It's also introduced new features like the share drag tray, which makes sharing files super easy.</p><p><a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/windows-11s-new-start-menu-is-ready-for-testing-and-its-a-massive-upgrade" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/windows-11s-new-start-menu-is-ready-for-testing-and-its-a-massive-upgrade">The new Start menu</a> is also a significant improvement over the old one, with more icons on show, the ability to turn off Recommended ads and recent files, and the ability to show your apps list on the main home page.</p><p>Microsoft also introduced a number of<a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/microsoft-windows-bsod-removed-replaced-black-screen" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/microsoft-windows-bsod-removed-replaced-black-screen"> improvements to the Windows BSOD and recovery options screen</a>, which makes recovering a Windows system that has been taken offline due to a faulty update or driver much more straightforward and streamlined. It's a lot harder to take a PC offline today than it was a year ago.</p><p>For gamers, Windows 11 is better than ever. The Xbox app is being positioned as a hub for all of gaming on Windows, and is now <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-launches-xbox-full-screen-experience-preview-for-gaming-pcs-expanding-beyond-handhelds-for-the-first-time" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-launches-xbox-full-screen-experience-preview-for-gaming-pcs-expanding-beyond-handhelds-for-the-first-time">capable of replacing the desktop interface</a> for when you just want to navigate the system with a controller. The company has also promised even more optimizations to come in the following year.</p><p>While there is a lot to complain about, there's also quite a bit to like about Windows 11 this year. I just wish there were more good than bad.</p><h2 id="something-needs-to-change-3">Something needs to change</h2><figure data-bordeaux-image-check="" id="33769560-f239-46b1-87f5-27d4a5aaae0a"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV.jpg" alt="Windows 11 Start" srcset="https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/8pKVtzj25m9zbDtnTZRUzV.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>The way things are going isn't working for Microsoft or users. </span><span itemprop="copyrightHolder">(Image credit: Daniel Rubino)</span></figcaption></figure><p id="4af59356-992c-4fa5-a246-b2e566a8ea96">Ultimately, I think it's very clear that something needs to change. The public has decided that Windows 11 is a bad operating system, and Microsoft does need to address this.</p><p>If I were in charge, the very first thing I would do is throw out the Continuous Innovation strategy. There's simply no need to ship new features on a monthly cadence, users don't want it, and Microsoft would have an easier time developing and testing new features thoroughly without it.</p><p>Instead, I would introduce quarterly feature drops, with big new features coming once a year timed with the annual version update. Microsoft can ship smaller quality of life improvements, features, and updates every three months, and any big user experience changes or improvements once a year. Security updates can remain monthly.</p><p>This would allow Microsoft more time to test features as they are developed before shipping them, which would ideally improve the overall stability of the system. I'd also scrap the CFR system and ship new features to everyone as the updates are released.</p><p>I'd also love to see Microsoft tone things down when it comes to AI. Windows 11 should be AI capable, of course, but I really don't think it needs to be shoved into every UI surface possible. Notepad doesn't need an AI button, for goodness sake. AI is best when it's invisible, not when it's shoved in your face at every turn.</p><p>Given the current reputation of Windows 11, if I were in charge of Windows, I'd certainly be thinking about pivoting to <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/windows-12-ai-new-ui-features-and-everything-else-we-know-so-far" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/windows-12-ai-new-ui-features-and-everything-else-we-know-so-far">Windows 12</a> in an attempt to give Windows a clean slate and a fresh start. As long as the company doesn't market it as an AI-first OS, pivoting to Windows 12 would be nothing but a good thing for Microsoft, especially if it's a free update for everyone that doesn't bump system requirements.</p><p>That doesn't mean Windows 12 should have no AI features. The fact of the matter is, AI is here to stay, and I'd be very interested to see what a desktop UX can be like if it's built from scratch with AI in mind. But it needs to be optional, and it cannot be the sole reason for Windows 12 to exist. AI should complement the platform, not become the platform.</p><figure data-bordeaux-image-check="" id="6ebd8b73-b66c-4f5b-8042-ca7fdd364961"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png" alt="A pink banner that says &amp;quot;What do you think?&amp;quot; and shows a dial pointing to a mid-range hue on a gradient." srcset="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png">
</picture></p></div></figure><hr id="8e4208a8-8e01-46df-95ab-2bf8ab71408e"><a href="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" id="0bc68d92-634a-4de7-9d06-cf0a09bbea11" data-url="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png" alt="Click to follow Windows Central on Google News" srcset="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 1200w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 1024w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 970w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png">
</picture></p></div></figure></a><p id="751ff644-a2e2-42dd-8df6-9923af02dd26"><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" target="_blank" data-url="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em>Windows Central on Google News</em></a><em> to keep our latest news, insights, and features at the top of your feeds!</em></p><hr id="6c7fed2e-c7e7-43e4-8c01-f79ba4d8c1f8">
</div>


<div id="slice-container-authorBio-DjgB8CDooXtXtjAxRbocvW"><p>Zac Bowden is a Senior Editor at Windows Central and has been with the site since 2016. Bringing you exclusive coverage into the world of Windows, Surface, and hardware. He's also an avid collector of rare Microsoft prototype devices! Keep in touch on <a href="https://twitter.com/zacbowden">Twitter</a> and <a href="https://threads.net/@zacbowden">Threads</a></p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.windowscentral.com/about#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris (116 pts)]]></title>
            <link>https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/</link>
            <guid>46445195</guid>
            <pubDate>Wed, 31 Dec 2025 15:52:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/">https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/</a>, See on <a href="https://news.ycombinator.com/item?id=46445195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Training gaming agents is an addictive game. A game of sleepless nights, grinds, explorations, sweeps, and prayers. <a href="https://github.com/PufferAI/PufferLib"><strong>PufferLib</strong></a> allows anyone with a gaming computer to play the RL game, but getting from ‚Äúpretty good‚Äù to ‚Äúsuperhuman‚Äù requires tweaking every lever, repeatedly.</p>

<p>This is the story of how I trained agents that beat massive (few-TB) search-based solutions on <strong>2048</strong> using a 15MB policy trained for 75 minutes and discovered that bugs can be features in <strong>Tetris</strong>. TLDR? PufferLib, Pareto sweeps, and curriculum learning.</p>

<h2 id="speed-and-iteration">Speed and Iteration</h2>

<p>PufferLib‚Äôs C-based environments run at 1M+ steps per second per CPU core. Fast enough to solve Breakout in under one minute. It also comes with advanced RL upgrades like optimized vectorized environments, LSTM, Muon, and <a href="https://x.com/jsuarez5341/status/1938287195305005500"><strong>Protein</strong></a>: a cost-aware hyperparameter sweep framework. Since 1B-step training takes minutes, RL transforms from ‚ÄúYOLO and pray‚Äù into systematic search, enabling hundreds of hyperparameter sweeps in hours rather than days.</p>

<p>All training ran on two high-end gaming desktops with single RTX 4090s. Compute was sponsored by <a href="https://puffer.ai/">Puffer.ai</a>, thanks!</p>

<h3 id="the-recipe">The Recipe</h3>

<ol>
  <li>Augment observations: Give the policy the information it needs.</li>
  <li>Tweak rewards: Shape the learning signal and adjust weights.</li>
  <li>Design curriculum: Control what the agent experiences and when.</li>
</ol>

<p>Network scaling comes last. Only after exhausting observations, rewards, and curriculum should you scale up. Larger networks make training slower; nail the obs and reward first. Once you do scale, the increased capacity may (or may not) reach new heights and reveal new insights, kicking off a fresh iteration cycle.</p>

<p>Sweep methodology: I ran 200 sweeps, starting broad and narrowing to fine-tune. Protein samples from the cost-outcome Pareto front, using small experiments to find optimal hyperparameters before committing to longer runs.</p>

<hr>

<h2 id="2048-beating-the-few-tb-endgame-table">2048: Beating the Few-TB Endgame Table</h2>

<p>2048 strikes a unique balance between simplicity and complexity. The rules are trivial: merge the same tiles to reach 2048, or 131,072. But the game is NP-hard with a massive state space. Random tile spawns (2s or 4s in random positions) force agents to develop probabilistic strategies rather than memorizing solutions.</p>

<p>The previous state-of-the-art search solution uses a few terabytes of endgame tables to reach the 32,768 tile reliably and the 65,536 tile at an 8.4% rate (<a href="https://github.com/game-difficulty/2048EndgameTablebase">repo</a>).</p>

<p>My 15MB policy achieved a 14.75% 65k tile rate and a 71.22% 32k tile rate (115k episodes). Here is the <a href="https://wandb.ai/kywch/pufferlib/runs/5thsjr61?nw=nwuserkywch">training log</a>. You can play it in your browser <a href="https://kywch.github.io/games/2048.html">here</a>.</p>

<p><img src="https://kywch.github.io/images/posts/2048_65k.png" alt="2048 Agent reaching 65k tile"></p>

<h3 id="what-made-it-work">What Made It Work</h3>

<p>Details are in <a href="https://github.com/PufferAI/PufferLib/blob/3.0/pufferlib/ocean/g2048/g2048.h">g2048.h</a>. Obviously, these didn‚Äôt come from one shot. Guess how many?</p>

<p><strong>Observation design</strong> (18 features per 4√ó4 cell): These were fixed early and did not change.</p>

<ul>
  <li>Normalized tile value (raised to power 1.5 via lookup table for speed).</li>
  <li>Empty cell flag (one-hot).</li>
  <li>Tile value one-hots (16 features for 2^1 through 2^16).</li>
  <li>One ‚Äúsnake state‚Äù flag (indicating if the board matches the ideal ‚Äúsnake pattern‚Äù).</li>
</ul>

<p><strong>Reward structure</strong>: Details were tweaked frequently.</p>

<ul>
  <li>Merge rewards: Proportional to tile value (weight: 0.0625).</li>
  <li>Penalties: Invalid moves (-0.05) and Game Over (-1.0).</li>
  <li>State rewards: Bonuses for filled top rows and max tiles in corners.</li>
  <li>Monotonicity rewards: Encourage specific directional patterns (weight: 0.00003).</li>
  <li>Snake rewards: Large bonus for the pre-defined snake configuration. I experimented with the length of the snake, and settled with the sorted top row + the max_tile_in_row234 in the second row right. For example, top row: 14-13-12-11, second row: ()-()-()-10.</li>
</ul>

<p><strong>Curriculum was the key</strong>. To learn, agents must experience high-value states, which are hard (or impossible) for untrained agents to reach. The endgame-only envs were the final piece to crack 65k. The endgame requires tens of thousands of correct moves where a single mistake ends the game, but to practice, agents must first get there. Curriculum was manually curated and tweaked repeatedly.</p>

<ul>
  <li>Scaffolding curriculum (episode-level): Spawns pre-placed high tiles (8k-65k) at the start. Early training gets single high tiles. Later training gets specific configurations (e.g., 16k+8k, or 32k+16k+8k). Saves thousands of moves, letting agents experience endgame scenarios faster.</li>
  <li>Endgame-only environments (env-level): Dedicated training that only practices endgame because a single mistake ends the game. Always starts with high-value tiles pre-placed (e.g., 32k, 16k, 8k, 4k).</li>
</ul>

<p><strong>Policy architecture</strong>: 3.7M parameters with LSTM memory. It changed rarely.</p>

<ul>
  <li>Encoder: Three FC layers with GELU (1024 -&gt; 512 -&gt; 512).</li>
  <li>Memory: LSTM layer (512x512) for long-horizon planning.</li>
  <li>The LSTM is critical for 2048‚Äôs 45k+ move games (when reaching the 65k tile).</li>
</ul>

<h3 id="the-road-ahead-shooting-for-132k">The Road Ahead: Shooting for 132k</h3>

<p>Reaching the 65,536 tile requires 40k+ moves with precise sequencing. The strategy you start at move 20k affects whether you succeed at move 25k.</p>

<p>So how can we shoot for 132k? On top of more training steps, these two directions seem promising:</p>

<ul>
  <li><strong>Deeper networks</strong>: The <a href="https://arxiv.org/abs/2503.14858">1000 Layer Networks</a> research shows that extreme depth can unlock new goal-reaching capabilities in RL.</li>
  <li><strong>Automated curriculum</strong>: The <a href="https://arxiv.org/abs/1901.10995">Go-Explore algorithm</a> could automatically discover the ‚Äústepping stones‚Äù to higher tiles more efficiently than manual scaffolding.</li>
</ul>

<hr>

<h2 id="tetris-when-bugs-become-features">Tetris: When Bugs Become Features</h2>

<p>Tetris is forgiving early on but becomes impossible as speed increases. My journey here led to an unexpected insight about curriculum learning.</p>

<p>I started with hyperparameter sweeps and increased network width from 128 to 256. Better hyperparameters alone made the agent much better. The agent kept playing endlessly, which was boring to watch. So I made the game harder:</p>

<ul>
  <li>Garbage lines: Random filled rows at the bottom.</li>
  <li>Progression: Quicker ramps in drop speed and garbage frequency.</li>
</ul>

<p>The breakthrough came from a bug.</p>

<p>A bug caused the one-hot encoding for the next two pieces to persist between steps. Over time, the observation array would fill with 1s, essentially becoming noise.</p>

<p>When I fixed this bug, the agents did well in the beginning but couldn‚Äôt handle when gaps started to appear. With the bug, the agents performed much better overall, though early-stage play was somewhat off. Why? Early exposure to chaos made the agents robust. When they encountered genuinely difficult late-game situations (fast drops, lots of garbage), they‚Äôd already learned to handle messy, unpredictable states. The bug had accidentally implemented curriculum learning through randomization.</p>

<p>So I implemented two curriculum approaches:</p>

<ol>
  <li><strong>External</strong>: Injecting random garbage lines during early training.</li>
  <li><strong>Internal</strong>: Mimicking the bug by adding observation noise that decays over time.</li>
</ol>

<p>Both create early-game ‚Äúhard states‚Äù that teach robustness. I don‚Äôt know which is better; sometimes external works, other times internal. So I left both versions in the <a href="https://github.com/PufferAI/PufferLib/blob/3.0/pufferlib/ocean/tetris/tetris.h">code</a>.</p>

<p>Here is the <a href="https://wandb.ai/kywch/pufferlib/runs/era6a8p6?nw=nwuserkywch">training log</a>. You can play it in your browser <a href="https://kywch.github.io/games/tetris.html">here</a>.</p>

<p>Overall, Tetris is easier because you‚Äôre mostly reacting to the current piece and next few pieces, not planning 40k+ moves ahead like 2048.</p>

<hr>

<h2 id="lessons-what-actually-mattered">Lessons: What Actually Mattered</h2>

<ul>
  <li><strong>Speed giveth</strong>: Training on a single RTX 4090 worked because the environment was fast enough to run hundreds of hyperparameter sweeps. Fast simulation transforms RL from ‚ÄúYOLO and pray‚Äù into systematic search.</li>
  <li><strong>Hyperparameters matter</strong>: They can easily double performance without other changes.</li>
  <li><strong>Nail obs and reward first</strong>: A bigger network won‚Äôt fix poor observation or reward design. Scale the network last.</li>
  <li><strong>Curriculum makes superhuman</strong>: Agents cannot learn what they haven‚Äôt experienced. Curriculum learning lets agents experience critical states that would take too long (or be impossible) to reach naturally.</li>
  <li><strong>Systematic grind &gt; Clever one-shot</strong>: Progress came from disciplined grind, sleepless nights, with little inspiration sprinkled in between.</li>
  <li><strong>Bug luck</strong>: Don‚Äôt let a lucky bug slip by; it might teach you something good.</li>
</ul>

<h2 id="try-it-yourself">Try It Yourself</h2>

<p>Watch the agents play: <a href="https://kywch.github.io/games/2048.html">2048</a>, <a href="https://kywch.github.io/games/tetris.html">Tetris</a></p>

<p>Code: <a href="https://github.com/PufferAI/PufferLib">PufferLib</a></p>

<p>Training commands: After installing PufferLib, run <code>puffer train puffer_g2048</code> or <code>puffer train puffer_tetris</code></p>

<p>These results show that a single person with a gaming desktop can achieve much more than you‚Äôd think. Also, if you‚Äôre considering scaling up, think again. Having many CPUs and GPUs to throw at a problem is nice, but it‚Äôs much more fun squeezing the last drop of perf out (but yeah, I also saw Sutton‚Äôs <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</a>).</p>

<h2 id="hn--hny-update">HN &amp; HNY Update</h2>

<p>This post was briefly trending on HackerNews on the last day of 2025. What a way to wrap up the year. Happy New Year everyone!</p>

<p><img src="https://kywch.github.io/images/posts/2048_hn_update.png" alt="HackerNews upate"></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The compiler is your best friend (133 pts)]]></title>
            <link>https://blog.daniel-beskin.com/2025-12-22-the-compiler-is-your-best-friend-stop-lying-to-it</link>
            <guid>46445131</guid>
            <pubDate>Wed, 31 Dec 2025 15:46:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daniel-beskin.com/2025-12-22-the-compiler-is-your-best-friend-stop-lying-to-it">https://blog.daniel-beskin.com/2025-12-22-the-compiler-is-your-best-friend-stop-lying-to-it</a>, See on <a href="https://news.ycombinator.com/item?id=46445131">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Note: this is a "script" for a podcast that I recently recorded, as such it's more conversational and less technical than the usual content of this blog. Not a single code block in sight...</p>
<h2 id="prologue">Prologue<a href="#prologue"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Imagine you wake up one night to find out that production is crashing. It takes you a while to unearth the root cause. It turns out to be a null pointer exception deep inside a service. It crashed the whole system. How did it get there? Where did it come from?</p>
<p>Now imagine a different story. One day a developer had to struggle for a whole of 20 minutes fixing some informative compilation errors. And that's it, that's the whole story. Nobody had to wake up at night, production never crashed.</p>
<p>One of these stories is a story of lies and deceit, the other a story of dialogue and cooperation. Today we will learn how to stop lying to the compiler, and how to get a good night's sleep.</p>
<h2 id="part-i-the-compiler">Part I: The Compiler<a href="#part-i-the-compiler"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>(If you're familiar at high-level with how compilers work, feel free to skip to the next <a href="#part-ii-lying-to-the-compiler">part</a>)</p>
<p>But first things first. What is a compiler?</p>
<p>In the broadest sense, a compiler is a function, that takes an input in one format and produces an output in another format. This definition is so broad as to be useless... Although, if you take this definition seriously, it has some interesting implications on how we approach solving problems in everyday code. But I digress.</p>
<p>Let's try again, more concretely this time. A typical compiler takes source code in some programming language and produces an output in some other language. For example, a C compiler takes files written in C, and produces assembly code.</p>
<p>A typical compiler pipeline might have the following steps:</p>
<ol>
<li>Parsing the source code into an intermediate representation, an abstract syntax tree (AST)</li>
<li>Typechecking the code, make sure that all the types line up</li>
<li>Optimization, going over the AST and finding opportunities to make the code more efficient</li>
<li>Code generation, converting the AST into the output format, like machine code.</li>
</ol>
<p>As we will soon see, the typechecking step is probably the most relevant for most developers.</p>
<p>Like most things, nothing is that simple. Different languages have differently flavored compilers, doing a wide range of things. This is not a thorough review on all things compilers, so instead, let's take a sample of languages and see what kind of compilers they have.</p>
<h3 id="rust">Rust<a href="#rust"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Rust is similar to C, in that it compiles directly to machine code. To distinguish this "classic" compiler from the rest, we call this style an "ahead of time" compiler. This means that everything that the compiler does starts and ends before runtime. Once we created the binary output, the work of the compiler is done.</p>
<p>But, this doesn't mean that the job of the compiler is easy. Rust is quite sophisticated, apart from parsing the source code the compiler needs to do things like macro expansion, type checking, borrow checking, and lots, and lots of optimizations.</p>
<p>Optimization, and generally performance is a common benefit of using compiled languages. Compiled languages tend to be faster than languages that don't use a classic compiler, but are instead dynamically interpreted on the fly (like Python). And Rust is famous for its optimizations in the style of "zero cost abstractions".</p>
<p>Zero cost abstraction means that despite Rust being a low-level language, in many cases one can write pretty high-level code and still get the performance of handwritten low-level code. This is possible because the compiler analyzes the code, and manages to translate a high-level construct like <code>map</code> on an iterator into a low-level, fast loop. This includes optimizations like inlining and loop fusion.</p>
<p>As a developer writing in Rust though, the thing that you would notice the most during development is all the memory safety checks the compiler does for you at every step.</p>
<p>Rust makes it possible to safely manage memory without using a garbage collector, probably one of the biggest pain points of using low-level languages like C and C++. It boils down to the fact that many of the common memory issues that we can experience, things like dangling pointers, double freeing memory, and data races, all stem from the same thing: uncontrolled sharing of mutable state. For example, if two different variables share a pointer to the same data, if one of them frees the pointer, the other will end up with an invalid pointer without knowing it. Likely breaking something upon pointer dereference.</p>
<p>So Rust forbids us from freely sharing pointers. Each pointer has exactly one owner at every moment of time. Once the owner goes out of scope, memory is freed automatically. Since there are no other owners, this is safe and cannot lead to dangling pointers and the like.</p>
<p>What makes Rust special is that all of this happens at compile-time. The compiler tracks pointer ownership, using something called a borrow checker, forbidding us from doing anything that violates the single ownership of pointers. Memory unsafe code will simply fail to compile.</p>
<p>Rust's powerful type system is one very compelling (and painful) reason to use it. A broken elevator and walking 21 floors up the stairs can really motivate you to invent such a safe language.</p>
<p>Then we have Java.</p>
<h3 id="java">Java<a href="#java"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>People often think of Java as a static, compiled language. But actually, the Java compiler doesn't produce machine code. Instead, it produces bytecode. An intermediate (stack-based) language that is then <em>dynamically</em> interpreted by the Java Virtual Machine (JVM) when the bytecode is executed.</p>
<p>The reason for going through all this trouble is portability. By using intermediate bytecode, Java can be compiled once on any platform, but then executed on any other platform that has an implementation of the JVM. That's cool and all, but didn't we just say that interpreted languages are slow?</p>
<p>True, in the early days of Java, people were worried that running such a "dynamic" language will be too slow to be useful, and surely will never be able to compete with something like C++. And that's why we have "just in time" compilation. Or JIT for short.</p>
<p>The Java compiler does a lot less than Rust's. The translation from Java to bytecode is comparatively simple. The compiler doesn't make optimizations as far reaching as the Rust compiler. And if we left things that way Java would indeed be quite slow.</p>
<p>The real fun begins at runtime. The Java runtime has a JIT compiler enabled. The JIT compiler monitors the execution of the bytecode, as it gets slowly interpreted step by step. After a while, the JIT starts recognizing various hotspots in the code, like long loops, or common branching points. It then takes the bytecode for the hotspot and compiles it down to an efficient machine code representation. From that point onwards, that segment of code should run much more quickly.</p>
<p>Like a sophisticated ahead of time (AOT) compiler, the JIT compiler can apply nontrivial optimizations to the code. But unlike an AOT compiler, the JIT compiler has access to the actual usage patterns at runtime. Meaning that it can be more aggressive in optimizing the real bottlenecks in code. Things like dynamic dispatch in an object-oriented class hierarchy can be converted to static dispatch at runtime.</p>
<p>If you ever wondered why your JVM app takes time to "warm up" before it's actually fast, the JIT compiler is your answer. It takes time for the JIT compiler to recognize and compile the actual hotspots in code.</p>
<p>These days, Java has an AOT compiler as well, called Graal. As a result we can use the very same Java code and produce two completely different artifacts, either in bytecode or machine code (with some limitations).</p>
<p>More generally compilers can have more than one compilation target, or "backends". For example, both Scala and Kotlin can be compiled to either JVM bytecode, JavaScript, and native machine code. To support such use cases, and to avoid repetition between different backends, the compiler will have some intermediate representation of the language that is being compiled, the AST. This way, most of the compiler's work like parsing, typechecking, and various optimizations can produce one AST, but then that one AST can be converted into different outputs.</p>
<p>Despite all that complex work being done by the various compilers, most of the interaction that Java programmers have with the compiler is with the type checker. Java's type-system is not nearly as strict as Rust's, often being more annoying than helpful. So it's not uncommon for us the developers to "know better" than the compiler and use a cast every now and then. These are the first signs of trouble...</p>
<p>Seeing that a compiler can be quite the complex beast, you would be quite correct in asking:</p>
<h3 id="aside-who-compiles-the-compilers">Aside: Who Compiles the Compilers?<a href="#aside-who-compiles-the-compilers"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Or more specifically, in what language is the compiler written? It would seem natural for the developers of a new language X to write the compiler in X. Surely it's their favorite language. At the very least, it's a good idea for them to dogfood their own creation.</p>
<p>Among people who write compilers, writing the compiler in the very same language it's supposed to compile is considered an important milestone. It shows that the language is mature enough to be able to implement such a complex piece of code. When a language does it, it is said to be "self-hosting".</p>
<p>Here we have a paradox. If I have a compiler written in X, to be able to use it I first need to compile it, and for that I need a compiler for language X. But I don't have one compiled, I need to compile it first... And so we find ourselves with a chicken and egg problem.</p>
<p>The way to get out of this conundrum is by a procedure called "bootstrapping". Here things are going to get a bit meta.</p>
<p>It goes like this. First write a compiler in language X, the "bootstrapp<strong>ed</strong> compiler". Ideally you do that using as few features of X as possible. Then choose another existing language Y (can be assembly or some high-level language), and write a compiler for X in Y, the "bootstrapp<strong>ing</strong> compiler". It doesn't have to handle all of the features of X, only the ones that were used in the code for the bootstrapp<strong>ed</strong> compiler. Once you run the bootstrapp<strong>ing</strong> compiler on the code for the bootstrapp<strong>ed</strong> compiler, congratulations, you now have a brand new self-hosting compiler for X. From this point onwards, you can improve the compiler and add features to it all without leaving the comfort of your favorite language X.</p>
<p>We can follow this process with the Rust compiler. Originally, it was written in the OCaml language. But the current Rust compiler was rewritten in Rust, which makes it a proper self-hosting compiler.</p>
<p>This is all good and well, but most of the time us simple developers don't really care about the language the compiler uses, we just need it to compile code. The reason I'm telling you all this is that it gives us an interesting insight into the development of programming languages.</p>
<p>The people who write compilers are usually the same people that design the language itself. And most of what they do all day long is writing compiler code. This might skew their incentives. They really enjoy using languages that are a good fit for writing compilers. Even more so, since in the early stages of a new language the compiler is probably the biggest piece of code written in it. That's the chance for the new language to really shine.</p>
<p>We shouldn't be surprised then, to find that many new languages tend to accumulate features that are very convenient for compiler writers. Things like pattern matching, and implicit parameters.</p>
<p>But seeing how compilers are not very representative of the code most of us write daily, this might not be the best way to spend the complexity budget when designing a new language. Lucky for us, some of those features are useful for plain-old, boring business code as well. Especially code written in the functional style.</p>
<p>Let's wrap up this exploration of compilers with one more language.</p>
<h3 id="typescript">TypeScript<a href="#typescript"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>The TypeScript compiler is special in that the target is not a low-level format like assembly and bytecode, but instead another high-level language, JavaScript. Although definitions are a bit fluid, but in this case we say that the TypeScript compiler is actually a "transpiler". Even more curiously, since JavaScript is a strict subset of TypeScript, we can say that TypeScript is compiling into itself.</p>
<p>There are two main reasons to want to do that: nicer syntax for various features of JavaScript (like classes and enums), and the type-system that TypeScript adds on top of JavaScript.</p>
<p>Microsoft, who developed TypeScript, was motivated by the pain they experienced when scaling large JavaScript codebases. Adding a robust type-system to a language makes it much easier to tame large codebases over time (things like refactoring become safer). We can see the same trend with Dropbox investing in Mypy, an optional type checker for Python, to help scaling their Python codebase.</p>
<p>Adding a type-system to an existing programming language is very different from designing a language with types from the ground up. With an existing language you must be able to add types to as much existing code as possible. And codebases in dynamic language sure do tend to be... Dynamic.</p>
<p>To mitigate this, TypeScript uses gradual typing. With gradual typing you don't have to add types to the whole codebase all at once, like you would in, say, Java. Instead, you can do it gradually, and the compiler verifies that whatever is annotated is consistent with itself, and ignores the rest. This smoothes migration from an untyped code and mindset to a typed one.</p>
<p>There is also the question of which type system is most appropriate for an ex-dynamic language. Did you know that type-systems come in different flavors? Most mainstream languages use "nominal" type-systems. This means that each type gets a unique name, and types that have different names are treated as distinct types by the compiler. In contrast, TypeScript uses a "structural" type-system. Two types are considered the same if they have the same structure, e.g., the same fields and methods. The name of the type doesn't matter.</p>
<p>Structural typing seems to be better suited when gradually typing a dynamic language. "If it walks like a duck and quacks like a duck, then it must be a duck" is a common viewpoint in dynamic languages, and structural typing is the way to capture this mindset with types.</p>
<p>In a curious turn of events, TypeScript and Mypy went the other way around with bootstrapping and self-hosting. The current TypeScript compiler is self-hosting, but a rewrite in Go is in the works. In Mypy, the compiler was rewritten from plain Python into a special almost-Python dialect that compiles directly to C. The motivation for both rewrites is performance. Turns out that it's difficult to get a sufficiently fast compiler that can quickly process large codebases in dynamic runtimes like JavaScript and Python.</p>
<p>Like before, we can't help but notice that the type-system is the main interface between the developer and the compiler. In the case of TypeScript I would say that it's also the main reason to even want to use the language.</p>
<p>And yet, so many developers hate the compiler. It seems that all it does is yell at us about trivialities like "string is not int" and such. Is it worth bothering with a compiled language just for that?</p>
<h2 id="part-ii-lying-to-the-compiler">Part II: Lying to the Compiler<a href="#part-ii-lying-to-the-compiler"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>The compiler is always angry. It's always yelling at us for no good reason. It's only happy when we surrender to it and do what it tells us to do. Why do we agree to such an abusive relationship?</p>
<p>And for someone who yells that much, it's not even that smart. Remember all the times when the compiler yelled at you something about a type mismatch, but turns out that you were right and the compiler was wrong? In the end you had to use a cast (or mark something as <code>any</code>) just to shut the compiler up.</p>
<p>We can solve these issues by quitting the relationship, and jumping ship to a dynamic language. I suspect that compiler abuse is why in the past Python grew in popularity compared to Java (that, and Java's verbosity). But we just saw that even in historically dynamic languages, like JavaScript and Python, there's a trend towards a more static, more compiler-centric way of writing code. These days Python has not just one, but <em>multiple</em> competing tools for typechecking (mypy, pyright, pyrefly, ty). Why do people lean that way?</p>
<p>Maybe it's performance. We talked before about how compiled languages tend to be faster than dynamic languages. But that doesn't seem quite right. In many contexts, where the language's performance is not the bottleneck, people will still use types. And TypeScript, for example, doesn't give us a runtime performance benefit, all the type information is discarded after compilation. Are people really just that masochistic?</p>
<p>Maybe Rust is the answer. Rust's compiler brings significant improvements in code safety where memory management is involved. True, its compiler is even more difficult to satisfy than average, but it solves a very tangible problem that would be very difficult to safely solve otherwise. Still, most of us don't write low-level code, and we mostly use garbage-collected, memory-safe languages. Not many mainstream languages have a type-system that is as powerful as Rust's, so we don't usually get that much extra safety.</p>
<p>We can imagine that in very large codebases, like the ones managed by Microsoft and Dropbox, there's some magical advantage to having types checked by the compiler (we mentioned safer refactoring before), despite the obvious pains. But most of us don't maintain code that large, why bother with types then?</p>
<p>It seems that all the compiler can do for us is act as simple, and not very reliable, guard rails. Sure it would sometimes notice that this or that int is actually a string. But if that's all it can do for us, then we might as well write a couple of unit tests, and remove this nuisance from our lives.</p>
<h3 id="the-lies">The Lies<a href="#the-lies"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>I think that this is a false premise. The compiler is actually much more useful and powerful than it might appear. So useful in fact, that relying on it is beneficial in any codebase, large and small. The problem is that we are used to lie to the compiler all the time, in return all it can do for us is yell about strings not being ints and do little else.</p>
<p>What do I mean by lying to the compiler?</p>
<p>The compiler, or rather the type-system, is only aware of things that are known at compile-time. A "lie" would be to write code that communicates one thing at compile-time while doing something else at runtime. On the other hand, the more facts that we can truthfully state to the compiler at compile-time, the more useful the compiler can be. But first, let's see some concrete examples of lies.</p>
<h3 id="null">Null<a href="#null"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>When we say that some variable <code>x</code> is a string. What do we mean by that? It means that the runtime values that <code>x</code> can take are things "a", "ab", "abc", and many other reasonable strings. This also means that we can apply various methods to <code>x</code> like <code>substring</code> or <code>endsWith</code>. Unfortunately, in most modern languages this also means that at runtime it can be <code>null</code>.</p>
<p>Unlike the other non-null values, you cannot call <code>substring</code> or any other method on <code>null</code>. Calling a method on <code>null</code> will trigger an <code>NullPointerException</code>, possibly far away in code and time from where that <code>null</code> was created. We could adopt a policy of "defensive programming" checking for <code>null</code> every step of the way. But in practice nobody does that. Instead, in many places in our code we implicitly <em>assume</em> that values are non-null unless stated otherwise (in a comment that nobody actually reads).</p>
<p>This is one of the most common lies we tell the compiler. We state that something is a valid string, but at runtime it can just as well be <code>null</code>. In most mainstream languages the compiler cannot distinguish between nullable and non-nullable values. And so it cannot help us out when our nullability assumptions turn out to be wrong. That's when things crash.</p>
<p>How many times did you find yourself setting something to <code>null</code> because you couldn't come up with something better, only to discover that some other place starts crashing?</p>
<h3 id="exceptions">Exceptions<a href="#exceptions"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Speaking of crashing, another source of lies we tell the compiler are exceptions. More specifically, unchecked exceptions.</p>
<p>If we write that some method returns string, what do we mean by this? Ideally, we mean that every time we call the method a string value will be returned. But in reality, there's another, sneaky way of returning from a method: we can throw an exception.</p>
<p>Similar to <code>null</code>, unchecked exceptions might be discovered away from the origin (although not as bad as <code>null</code>, they have to walk up the stack, and are not stored as data). And similar to <code>null</code> the compiler won't track them for us. If we don't go into a full defensive mode, we're assuming that the code is exception-free, and assumptions tend to break over time. But we lied to the compiler, so it won't be there to help when they finally break.</p>
<p>How many times did you leave a comment on some branch of code stating "this CANNOT happen" and thrown an exception? Did you ever find yourself surprised when eventually it <em>did</em> happen? I know I did, since then I at least add some logs even if I think I'm sure that it really cannot happen.</p>
<h3 id="casts">Casts<a href="#casts"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>So far things happened by accident, due to implicit assumptions being broken. But sometimes we are smarter than the compiler. Sometimes we know better and we can force the compiler to obey. We can use type casting.</p>
<p>Suppose that there's some interface, let's call it <code>Animal</code>. And it has two different implementations: <code>Cat</code> and <code>Dog</code>. Sorry for the cliche example, it's difficult to be original without written code.</p>
<p>Now we are working on some code that got an <code>Animal</code> argument, call it <code>x</code>. In this particular flow we know for certain that <code>x</code> must be a <code>Dog</code>. We can follow the code ourselves and show that <code>x</code> is unquestionably a <code>Dog</code>. So we want to use <code>Dog</code>-specific methods. But the silly compiler won't let us. It only knows about <code>Animal</code> methods.</p>
<p>The compiler won't budge, and we won't budge. So we take out our hammer, and use a cast. Now <code>x</code> is a <code>Dog</code>, and the compiler doesn't argue anymore. All is well, until some new feature request that requires supporting <code>Cat</code>s in our flow. When we make the change, we forget about that cast we did a while ago to make things work, and the code explodes.</p>
<p>The compiler didn't help us because we silenced it by lying to it. There are two lies going on here, why wasn't the initial type precise enough? If we can see that it must be <code>Dog</code>, why weren't we able to show that to the compiler? Then there's the cast itself, which blatantly tells one thing to the compiler (<code>x</code> is a <code>Dog</code>), when the reality might be something else (<code>x</code> is a <code>Cat</code>).</p>
<p>How often do you think you know better than the compiler?</p>
<h3 id="side-effects">Side-Effects<a href="#side-effects"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Up until now the examples are quite obvious lies. We all feel a bit dirty when doing a cast, or throwing a runtime exception with the comment "this should NEVER happen". But here's a more subtle example.</p>
<p>Let's say there's a function called <code>foo</code>. When we see that <code>foo</code> takes no arguments and returns <code>void</code>, what can we say about what <code>foo</code> does without looking at its implementation? Nothing really. It's clearly doing something, and that something is not reflected in its inputs or outputs. We can only conclude that the function is doing some kind of side-effect, like changing a variable or writing to a file.</p>
<p>Just like us, the compiler doesn't know anything useful about <code>foo</code> either. So we have a function that is clearly doing something important, otherwise it won't be there. But all we tell the compiler is that "nope, move along, nothing interesting to see here". But that's a blatant lie, something interesting is going on here, but the type of <code>foo</code> doesn't reflect that.</p>
<p>The compiler gets so confused that even if we comment out a call to <code>foo</code> it won't complain, it's as if it doesn't even know it exists.</p>
<p>If you look at a typical codebase, many, many functions return void. Every time we do that we prevent the compiler from knowing something useful about the flow of the code.</p>
<p>With all these lies all over the place, it's no wonder that the compiler is not particularly useful. What happens if we stop lying to it?</p>
<h2 id="part-iii-no-more-lies">Part III: No More Lies<a href="#part-iii-no-more-lies"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>If we want develop a serious, constructive relationship with the compiler, we must first stop lying to it. Only then can we open channels for serious dialogue.</p>
<p>We are so used to using <code>null</code>, exceptions, casting, and side-effects, that at first sight it might seem impossible to give those up.</p>
<p>But that's just an illusion.</p>
<h3 id="null-1">Null<a href="#null-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Some languages like Rust and Haskell have no <code>null</code> at all. Can you imagine what it's like to work that way?</p>
<p>Liberating, that's how it feels. You no longer have to keep worrying about an accidental <code>null</code> slipping through, because there aren't any. But, you might ask, what if something <em>really is</em> missing, how do I represent that without <code>null</code>?</p>
<p>In a world without <code>null</code> there are a number of ways to represent a thing that might be missing. The most common one is to use something like an <code>Option</code> type, that can be in one of two states, present with a value, or missing. When you want say that a <code>String</code> might not exist you use the type "option-of-<code>String</code>". And that makes all the difference to the compiler.</p>
<p>Now the compiler knows what's going on, since option-of-<code>String</code> is a distinct type from just <code>String</code>, it's no longer possible to call <code>String</code> methods, like <code>substring</code>, on it. Every time you deal with an option-of-<code>String</code> value the compiler will helpfully remind you to deal with the possibility that the value is missing.</p>
<p>On the flip side of that, now every time you have a <code>String</code> value you no longer have to worry that it might be missing. You can just use it without any defensive programming involved. And if you mistakenly break the rules and try to assign an option value to a non-option value the compiler will point that out and force you to think whether that's what you really want and what the consequences across the codebase will be.</p>
<p>Some languages, like Typescript and Kotlin have builtin support for nullable values. If you mark a <code>String</code> as nullable, it will become a distinct type from a plain <code>String</code>, giving us similar benefits to <code>Option</code>. In Java we can emulate something similar with <code>Nullable</code> and <code>Nonnull</code> annotation. But that requires some additional tooling to make it work.</p>
<p>What all those approaches have in common is that all of them involve the compiler. Instead of hiding our assumptions from the compiler we make them explicit in a way that the type-system can track.</p>
<p>We can do the same with exceptions.</p>
<h3 id="exceptions-1">Exceptions<a href="#exceptions-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>I'm personally not aware of languages that completely remove exceptions from the language. But working mostly without exceptions, at least as a convention, is definitely possible.</p>
<p>Inspired by the <code>null</code> case, we can take a similar approach with exceptions and make them explicit in our types.</p>
<p>The most common way to do that is to use another container type like <code>Result</code> or <code>Try</code>. A return type like "result-of-<code>String</code>" means that we can have one of two cases, either a success with a <code>String</code> value, or a failure with some exception.</p>
<p>This approach makes it explicit to both us and the compiler what's going in a function. Now the compiler can track possible errors for us, and force us to deal with them as appropriate. And if we change some piece of code from <code>String</code> to "result-of-<code>String</code>", the compiler will helpfully shows where this needs to be handled.</p>
<p>In Java we can take an alternative approach and use checked exceptions. But industry experience over the years seems to indicate that people don't enjoy using them. It's probably a matter of ergonomics. Using a wrapper type instead might be a more ergonomic alternative.</p>
<p>While avoiding nulls and exceptions is fairly straightforward, casts can be trickier.</p>
<h3 id="casts-1">Casts<a href="#casts-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Unless forced to by some external library, I think that the presence of casts in our code should be considered a design smell. My first (possibly controversial) suggestion would be to configure your tooling to just forbid them by default.</p>
<p>When feeling the need to use a cast, we should consider whether the current design is doing a good job of reflecting our intentions. Recall that when doing a cast we can ask one of two questions, why was the type not precise enough to begin with? And why do we need to cast here?</p>
<p>There's no generic answer to these questions, but finding a good answer to either of them will make the compiler's life easier.</p>
<p>Some times the solution would be to add more methods on a parent interface (like <code>Animal</code>). Some times you might discover that you could've started out with the more specific type (<code>Dog</code>, for example) from the very beginning.</p>
<p>Another class of solutions is to remodel the problem from using open interfaces to using sealed/union types. Many modern languages support them. Using sealed types retains some of the flexibility of using open interfaces, but still allows the compiler to be in the loop. Instead of blindly assuming that some case is true, we can safely match on the sealed type and the compiler will gladly inform us about all the cases we must handle at this point. Some languages can even magically auto-complete all the relevant cases.</p>
<p>As code evolves, the compiler will keep track of the cases over time. And if something changed in the sealed type, the compiler will tell us about all the locations where the new case should be handled. Giving us a chance to handle whatever new logic that was added, before it crashes at runtime. Something that it was powerless to do when you used a plain cast.</p>
<p>Now for the thorniest issue of them all.</p>
<h3 id="side-effects-1">Side-Effects<a href="#side-effects-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Software exists to make side-effects, otherwise we would just have overheating boxes without any useful output. So side-effects cannot be completely eliminated from code. But they can be better managed.</p>
<p>This is even a deeper design issue than casting, and there isn't a one size fits all solution. My suggestion would be to separate as much pure computation from side-effects as possible.</p>
<p>In practical terms that would mean that every time you see a void return, or something that performs some side-effects mixed with other useful computation, you try to extract a pure function, with well-defined inputs and outputs, that only does computation, and another function that does the side-effects (similar to the Command Query Separation principle).</p>
<p>A common pattern would be to separate pure business logic from data fetching/writing. So instead of intertwining database calls with computation, you split into three separate phases: fetch, compute, store (a tiny ETL). First fetch all the data you need from a database, then you pass it to a (pure) function that produces some output, then pass the output of the pure function to a store procedure.</p>
<p>Now instead of having one big flow that takes no inputs and produces no outputs, you have three building blocks, and one of them has well-defined inputs and outputs. Not only is having this separation makes it easier to focus on your business logic, especially when writing tests. But now that we have inputs and outputs the compiler can follow along as well and help out.</p>
<p>Taking these ideas seriously leads us toward architectures that are known as "functional core, imperative shell". Within the functional core the compiler is much more useful, because it has actual types for inputs and outputs that it can follow and enforce. More "interesting stuff" is happening within the knowledge of the compiler.</p>
<p>Let's see what happens when we maximize that knowledge.</p>
<h2 id="part-iv-the-compiler-as-our-friend">Part IV: The Compiler as Our Friend<a href="#part-iv-the-compiler-as-our-friend"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Okay, so we stopped lying to the compiler as much as we can, and we are already seeing some gains in safety. No more null pointers, surprising exceptions, or fragile code. We can stop here and pat ourselves on our backs.</p>
<p>But we can do even better. Not lying is just the first step in a productive relationship. The next step would be to start sharing knowledge. The simplest way to start doing that is to sprinkle our code with more types.</p>
<h3 id="typed-wrappers">Typed wrappers<a href="#typed-wrappers"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>When we use a string or an int in our code, what do they actually mean? Rarely is it just an arbitrary number or some raw text. Usually they represent some concept like a user ID or a file name. The thing is that this special meaning of the int or string are not reflected anywhere outside our head, or maybe a comment.</p>
<p>As time goes by we have more and more different meanings that an int can take in our system. Maybe it's an app ID, or a post ID, or a feed ID? Who knows. And so confusion arises, you start mixing up your ints, weird bugs creep up.</p>
<p>While this is happening, the compiler remains silent, "an int is an int, what can you do...". We didn't share our knowledge with the compiler, we have no one to blame.</p>
<p>The fix is simple: use small, typed wrappers, sometimes called "tiny types". Each concept you have in your system deserves to have a unique type, something for the compiler to hold on to. So you would have a <code>UserID</code> type, an <code>AppID</code> type, and so on. Underneath they might all be simple ints, but now both you and, more importantly, the compiler can distinguish the different concepts in code.</p>
<p>The difference might seem small, but the consequences are far reaching. Extra safety, the compiler will no longer let us confuse the different ints, is just the beginning.</p>
<p>Once the compiler gained knowledge of a concept you can use it for various tasks. For example, suppose you want to find out where are all the usages of user IDs in code. If we were still using ints, asking the compiler for all usages of the type int is meaningless, there are too many of those and they mean different things. Searching variable names is easy, but the results might not be complete. But if we have a dedicated type for <code>UserID</code>, that's easy, just ask your editor to find usages of the type and you get the precise results you need. The compiler keeps track.</p>
<p>For the same reasons, refactoring becomes easy. You want to change the representation of the <code>UserID</code>? Add some extra salt for security? No need to search for all the relevant ints and pray for the best. Modify the type and follow the compilation errors. Done.</p>
<p>Need some special validation for user IDs? Hide the constructor of <code>UserID</code>, add an alternative "smart" constructor, follow compilation errors. Done. No need to chase different ints across the system.</p>
<p>And for us humans, descriptive, domain-specific types make function signatures more readable, both for developers and for the occasional stakeholder. What's not to like about it?</p>
<p>Simple typed wrappers are, well, simple. But sometimes we need more sophisticated types to express ourselves to the compiler.</p>
<h3 id="union-types">Union Types<a href="#union-types"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Did you ever stumble on a class <code>Foo</code> that has too many fields with a long comment that explains something along the lines of "if field <code>a</code> is <code>true</code> then fields <code>b</code> and <code>c</code> must not be <code>null</code>". And so on and so forth for a few more different conditions?</p>
<p>Then when you actually start trusting <code>Foo</code>'s comment and check that <code>a</code> is <code>true</code>, you discover, with a production null pointer exception, that <code>b</code> was actually <code>null</code>.</p>
<p>To describe this more formally, <code>Foo</code> had some invariants, and those invariants were violated. Not every combination of field values makes sense for our application.</p>
<p>How much nicer it would if the compiler could tell us "hey, look here, this invariant breaks if you use this set of field values"? Unfortunately, most compilers are incapable of expressing invariants that depend in such a way on runtime values.</p>
<p>The solution to many such problems is to remodel the type to better reflect the invariants that we want to encode, in such a way that the compiler will be able to follow along and only allow for legal combinations.</p>
<p>One of the most versatile tools for this is to use union, or sealed types (enums in some languages). With a union type we create one variant per case. And each case can only have a legal combination of values. So the case where <code>a</code> is true will become one variant with two non-nullable fields <code>b</code> and <code>c</code>. And that's it.</p>
<p>The advantage of taking this approach is that the union type doesn't even allow us to write down an invalid combination. You can only choose from valid ones, anything else is a compilation error.</p>
<p>The way you work with union types is that every time you need to access some data you need to match on the value. And then you act according to the case you're on. If you're in case <code>a</code>, you're <em>guaranteed</em> to have the <code>b</code> and <code>c</code> values. The compiler makes sure they are consistently there no matter how you got to this point of code.</p>
<p>This can make union types more powerful than tests that check invariants. Unlike a unit test, which can only test for a specific code paths you currently know about, the compiler can track <em>all</em> code paths, now and forever.</p>
<p>As mentioned before, in some languages the compiler can auto-complete the different cases relevant for the point in code you're at. Sometimes it feels like the code is writing itself, you just have to fill in the blanks.</p>
<p>When the code evolves over time and more cases are added, the compiler will notify you about all the relevant places where you need to update the logic to handle new cases. This is a great way to assess the consequences of changes you're about to make and help you with decisions at the design phase.</p>
<p>Using union types this way is a great way to model alternative states in code, and it's part of a more general approach to programming where you strive to "make illegal states unrepresentable". That is, encode your invariants as facts that the compiler can enforce and makes it impossible to even <em>write</em> code that will break those invariants.</p>
<p>This opens up a whole new way of approaching types.</p>
<h3 id="typed-guarantees">Typed Guarantees<a href="#typed-guarantees"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>We are used to think about types as just a way to distinguish different values. This one's a string, that one an int. But as we rely more on the compiler to help us we can start thinking about types as guarantees that we want from the type-system. Or facts that we expect to hold, and that the compiler should verify <em>for</em> us.</p>
<p>A common scenario is that we want to make sure that the list we got as an argument contains at least one item. A classic example is when we need to compute some average, it's undefined for empty lists. Or choose a payment method in a payments system, you must have at least one to be able to proceed.</p>
<p>What we could do is revert to defensive programming, check the list before proceeding, and throw an exception if it's empty. But being defensive all the time is tedious (and eventually you forget about it), and we are back to lying to the compiler. Instead, we can signal our intentions with a type: <code>NonEmptyList</code>, a list type that cannot be even constructed without at least one element (some languages have it builtin, but it's also easy to implement in a library).</p>
<p>Not only does this communicate our intent to our callers better than any comment can do, but it also forces the compiler to make sure that nobody can call us with an illegal value. Once we encoded a guarantee as a type, we don't have to worry about it anymore. No defensive programming, no need to write extra tests for it. No more fear that some future refactor will break our invariants.</p>
<p>Once we start thinking about guarantees the compiler can make for us, the opportunities are endless. You can come up with a type for pretty much anything (within reason):</p>
<ul>
<li><code>PositiveNumber</code>, how much code that we write would be invalid if it got a negative number?</li>
<li><code>AgeOver18</code>, maybe it's mission critical to limit certain flows based on user data</li>
<li><code>SortedByPriority</code>, because it might be expensive to re-sort stuff just to be defensive</li>
</ul>
<p>And the list goes on, for almost any kind of custom validation logic you might want. Some can be encoded with union types, some might require techniques like smart constructors. You don't have to get too fancy for this to become a valuable tool.</p>
<p>Once you start sprinkling these types around, not only is the intent of the code becomes clearer, but the compiler can help verify that everything is consistent, and that any new code knows what it's required to do.</p>
<p>With enough types in place you might get the feeling that "if it compiles, ship it".</p>
<h3 id="dialogue">Dialogue<a href="#dialogue"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>In the prologue we saw what I think is a fairly common story, <code>null</code> unexpectedly crashing a production system. But we can make this story very concrete. I'm sure that many of us felt the Google Cloud outage in June 2025. So many services around the world were affected that it was very hard to miss.</p>
<p>From the <a href="https://status.cloud.google.com/incidents/ow5i3PPK96RduMcb1SsW" rel="noreferrer noopener" target="_blank">incident report</a> we learn that the root cause of it all was a <code>null</code> value where it was unexpected (along with some other operational compounding issues, like a lack of randomized backoff). And it's not really surprising. We saw that <code>null</code>s are lies that we tell the compiler, values that it cannot track for us. In a large enough system, you are bound to lose track of them.</p>
<p>With the lessons that we learned, can we imagine another outcome? An outcome that doesn't involve a big chunk of the internet crashing?</p>
<p>So we already know that using <code>null</code> is lying to the compiler. If we are motivated enough we will never use a <code>null</code> in our code, opting instead for something that the compiler can track, an option-like type. The first step of not lying to the compiler might be the most difficult one, but once we take it a whole new world opens up for us.</p>
<p>The incident report mentions some "unintended blank fields" in <code>Policy</code> datatype that triggered the whole thing. Although I don't know the actual details, let's imagine that those fields used to be non-empty and now we want to open the possibility for making them empty. But we no longer have <code>null</code> at our disposal, what do we do? We change the type of the fields to be "option-of-X", and run the compiler. This is where the magic of dialogue starts to shine.</p>
<p>In a large codebase and a central entity like <code>Policy</code> you can imagine that you'll have many compilation errors the moment you set some fields to be optional. That sounds scary, but that's way better than <code>null</code> silently propagating all over the code and not knowing the consequences. With the compilation errors you now have a full report of all the code sites you need to reconsider.</p>
<p>You start going over them, one by one, fixing the errors. But the more errors you fix the more you feel that something's not right. Adapting the code feels like too much effort, too hacky, "a maze of twisty little ifs, all alike". That's the compiler trying to tell you something:</p>
<blockquote>
<p>Maybe you need to reconsider the design?</p>
</blockquote>
<p>And that's what you do, with all those changes that you had to make it becomes more obvious that these are not just fields that you made optional, what you really did is uncover a new flow in the system, with new rules. In the old flow the fields really are mandatory, in the new flow they are no longer needed. So you combined the two flows and made the fields optional. But by just setting the fields to be options the new flow becomes implicit in a combination of empty values and flags, something that the compiler can't track, and is not apparent when reading the code.</p>
<p>Instead of riding on the existing flow and tweaking it, you can make things explicit and turn <code>Policy</code> into a union type. If it already was a union, you add another case to describe the new flow, and you compile again. There are still many compilation errors, matches that are incomplete, but now they are telling you something different:</p>
<blockquote>
<p>If you want to support this new flow, here are all the things you need to consider</p>
</blockquote>
<p>And that's what you do reviewing the compilation errors and figuring out what the new flow implies at each site. Maybe along the way you discover that the new <code>Policy</code> type requires different validations that you didn't think of before. As a result in the new <code>Policy</code> you start using a <code>NonEmptyList</code> of <code>AvailabilityZone</code>s which guarantees that you can't run the new flow without at least one applicable <code>AvailabilityZone</code>. (Of course <code>AvailabilityZone</code> is not some plain string, you have a dedicated type that tells you exactly what it means and gets validates accordingly.)</p>
<p>You compile again and somewhere along the edges of the system where you process user input the compiler tells you:</p>
<blockquote>
<p>Listen, I don't have any way to prove that you actually have at least on availability zone provided by the user</p>
</blockquote>
<p>And the compiler is right, if you were just using a regular list to represent the availability zones you would've missed this. Input processing happens far away from where we actually require the availability zones to not be empty and your unit tests missed this. So you add the appropriate user input validation. And lo and behold, it compiles. Ship it!</p>
<p>Yes, you struggled with the compiler, and yes it took some time. But guess who's getting good night's sleep tonight?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stardew Valley developer made a $125k donation to the FOSS C# framework MonoGame (506 pts)]]></title>
            <link>https://monogame.net/blog/2025-12-30-385-new-sponsor-announcement/</link>
            <guid>46445068</guid>
            <pubDate>Wed, 31 Dec 2025 15:39:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://monogame.net/blog/2025-12-30-385-new-sponsor-announcement/">https://monogame.net/blog/2025-12-30-385-new-sponsor-announcement/</a>, See on <a href="https://news.ycombinator.com/item?id=46445068">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>
                ¬© 2009-2025 MonoGame Foundation, Inc. is a 501(c)(3) non-profit. EIN 93-3803929<br>Designed with
                <span>‚ù§</span>
                by
                <a href="https://github.com/MonoGame/monogame.github.io/graphs/contributors">MonoGame Community</a>
            </p>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France targets Australia-style social media ban for children next year (184 pts)]]></title>
            <link>https://www.theguardian.com/world/2025/dec/31/france-plans-social-media-ban-for-under-15s-from-september-2026</link>
            <guid>46444743</guid>
            <pubDate>Wed, 31 Dec 2025 15:06:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2025/dec/31/france-plans-social-media-ban-for-under-15s-from-september-2026">https://www.theguardian.com/world/2025/dec/31/france-plans-social-media-ban-for-under-15s-from-september-2026</a>, See on <a href="https://news.ycombinator.com/item?id=46444743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>France intends to follow Australia and ban social media platforms for children from the start of the 2026 academic year.</p><p>A draft bill preventing under-15s from using social media will be submitted for legal checks and is expected to be debated in parliament early in the new year.</p><p>The French president, Emmanuel Macron, has made it clear in recent weeks that he wants France to swiftly follow <a href="https://www.theguardian.com/australia-news/2025/dec/12/australia-teen-social-media-ban-launch-test-to-come" data-link-name="in body link">Australia‚Äôs world-first ban on social media platforms for under-16s</a>, which came into force in December. It includes Facebook, Snapchat, TikTok and YouTube.</p><p><a href="https://www.lemonde.fr/pixels/article/2025/12/31/le-gouvernement-veut-interdire-les-reseaux-sociaux-aux-moins-de-15-ans-des-la-rentree-2026_6660160_4408996.html" data-link-name="in body link">Le Monde</a> and <a href="https://www.franceinfo.fr/internet/reseaux-sociaux/info-franceinfo-le-projet-de-loi-pour-interdire-les-reseaux-sociaux-aux-moins-de-15-ans-est-pret-et-sera-examine-debut-janvier_7712140.html" data-link-name="in body link">France Info</a> reported on Wednesday that a draft bill was now complete and contained two measures: a ban on social media for under-15s and a ban on mobile phones in high schools, where 15- to 18-year-olds study. Phones have already been <a href="https://www.theguardian.com/world/2018/jun/22/mobile-phones-french-school-ban" data-link-name="in body link">banned in primary and middle schools</a>.</p><p>The bill will be submitted to France‚Äôs Conseil d‚Äô√âtat for legal review in the coming days. Education unions will also look at the proposed high-school ban on phones.</p><p>The government wants the social media ban to come into force from September 2026.</p><p>Le Monde reported the text of the draft bill cited ‚Äúthe risks of excessive screen use by teenagers‚Äù, including the dangers of being exposed to inappropriate social media content, online bullying, and altered sleep patterns. The bill states the need to ‚Äúprotect future generations‚Äù from dangers that threaten their ability to thrive and live together in a society with shared values.</p><figure id="f426a266-c8a3-4874-88c6-e61f34ba626d" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:7,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Will other countries follow Australia‚Äôs social media ban for under-16s?&quot;,&quot;elementId&quot;:&quot;f426a266-c8a3-4874-88c6-e61f34ba626d&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/australia-news/2025/dec/13/will-other-countries-follow-australia-social-media-ban-under-16s&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Earlier this month, Macron confirmed at a public debate in Saint Malo that he wanted a social media ban for young teenagers. He said there was ‚Äúconsensus being shaped‚Äù on the issue after Australia introduced its ban. ‚ÄúThe more screen time there is, the more school achievement drops ‚Ä¶ the more screen time there is, the more mental health problems go up,‚Äù he said.</p><p>He used the analogy of a teenager getting into a Formula One racing car before they had learned to drive. ‚ÄúIf a child is in a Formula One car and they turn on the engine, I don‚Äôt want them to win the race, I just want them to get out of the car. I want them to learn the highway code first, and to ensure the car works, and to teach them to drive in a different car.‚Äù</p><p>Several other countries are considering social media bans for under-15s after Australia‚Äôs ban including <a href="https://www.theguardian.com/world/2025/oct/07/danish-pm-plans-to-ban-social-media-for-under-15s-warning-it-is-stealing-childhood" data-link-name="in body link">Denmark</a>, whose government hopes to <a href="https://www.theguardian.com/world/2025/oct/07/danish-pm-plans-to-ban-social-media-for-under-15s-warning-it-is-stealing-childhood" data-link-name="in body link">introduce a ban in 2026</a>, and <a href="https://www.theguardian.com/world/2024/oct/23/norway-to-increase-minimum-age-limit-on-social-media-to-15-to-protect-children" data-link-name="in body link">Norway</a>. Malaysia is also planning a social media ban for under-16s from 2026. In the UK, the Labour government has not ruled out a ban, saying ‚Äúnothing is off the table‚Äù but any ban must be ‚Äúbased on robust evidence‚Äù.</p><p>Anne Le H√©nanff, the French minister in charge of digital development and artificial intelligence, told <a href="https://www.leparisien.fr/politique/on-veut-aller-vite-anne-le-henanff-ministre-du-numerique-annonce-un-projet-de-loi-pour-interdire-les-reseaux-sociaux-avant-15-ans-19-12-2025-WZH4KUCI7RDZBKNVVBC3H4AVWU.php" data-link-name="in body link">Le Parisien</a> this month that the social media ban for under-15s was a government priority, and that the bill would be ‚Äúshort and compatible with European law‚Äù, namely the EU‚Äôs Digital Services Act (DSA) ‚Äì regulation intended to combat hateful speech, misinformation and disinformation.</p><p>The social media ban is part of Macron‚Äôs attempt to shape his legacy as he enters his difficult final year as president with a divided parliament.</p><p>On 23 December, last-minute legislation was passed to keep the government in business into January after parliament failed to agree a full budget for 2026. Attempts to agree a budget will resume next month.</p><p>A <a href="https://www.theguardian.com/world/2025/sep/11/lawmaker-calls-for-french-criminal-investigation-into-tiktok" data-link-name="in body link">French parliamentary inquiry</a> into TikTok‚Äôs psychological effects concluded in September that the platform was like a ‚Äúslow poison‚Äù to children. The co-head of the inquiry, the centrist lawmaker Laure Miller, told France Info that TikTok was an ‚Äúocean of harmful content‚Äù that was very visible to children through algorithms that kept them in a bubble. TikTok responded that it was being unfairly scapegoated for ‚Äúindustry-wide and societal challenges‚Äù.</p><p>The French parliament report recommended more broadly that children under 15 in <a href="https://www.theguardian.com/world/france" data-link-name="in body link">France</a> should be banned entirely from using social media, and those between 15 and 18 should face a night-time ‚Äúdigital curfew‚Äù, meaning social media would be made unavailable to them between 10pm and 8am.</p><p>The inquiry was set up after a 2024 French lawsuit against TikTok by seven families who accused it of exposing their children to content that was pushing them towards ending their lives.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Efficient method to capture CO2 from the atmosphere / Univ of Helsinki (250 pts)]]></title>
            <link>https://www.helsinki.fi/en/news/innovations/efficient-method-capture-carbon-dioxide-atmosphere-developed-university-helsinki</link>
            <guid>46444076</guid>
            <pubDate>Wed, 31 Dec 2025 13:59:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.helsinki.fi/en/news/innovations/efficient-method-capture-carbon-dioxide-atmosphere-developed-university-helsinki">https://www.helsinki.fi/en/news/innovations/efficient-method-capture-carbon-dioxide-atmosphere-developed-university-helsinki</a>, See on <a href="https://news.ycombinator.com/item?id=46444076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
      <hy-paragraph-text variant="news" placement="external">
        
                    <p>A new method to capture carbon dioxide from the air has been developed at the University of Helsinki's chemistry department.</p>
<p>The method developed by Postdoctoral Researcher <ds-link ds-href="https://researchportal.helsinki.fi/fi/persons/zahra-eshaghi-gorji/" ds-text="Zahra Eshaghi Gorji" ds-weight="bold"></ds-link><strong>&nbsp;</strong>is based on a compound of superbase and alcohol. Tests done in professor <ds-link ds-href="https://researchportal.helsinki.fi/fi/persons/timo-repo/" ds-text="Timo Repo‚Äôs" ds-weight="bold"></ds-link> group show that the compound appears promising: one gram of the compound can absorb 156 milligrams of carbon dioxide directly from untreated ambient air. However, the compound does not react with nitrogen, oxygen or other atmospheric gases. Capasity clearly outperforms the CO<sub>2</sub> capture methods currently in use.</p>
<p>The CO<sub>2</sub> captured by the compound can be released by heating the compound at 70‚ÄØ¬∞C in 30 minutes. Clean CO<sub>2</sub> is recovered and can be recycled.</p>
<p>The ease of releasing CO<sub>2</sub> is the key advantage of the new compound. In current compounds, releasing CO<sub>2</sub> typically requires heat above 900 degrees Celsius.&nbsp;</p>
<p>‚Äì In addition, the compound can be used multiple times: the compound retained 75 percent of its original capacity after 50 cycles, and 50 percent after 100 cycles.</p>
<p>Non-toxic and cost-effective</p>
<p>The new compound was discovered by experimenting with a number of bases in different compounds, says Eshagi Gorji. The experiments lasted more than a year in total.</p>
<p>The most promising base proved to be <em>1,5,7-triazabicyclo [4.3.0] non-6-ene&nbsp;</em>(TBN), developed at in the professor <ds-link ds-href="https://www.helsinki.fi/fi/tutustu-meihin/ihmiset/henkilohaku/ilkka-kilpelainen-9027543" ds-text="Ilkka Kilpel√§inen‚Äôs" ds-weight="bold"></ds-link> group, which was combined with benzyl alcohol to produce the final compound.</p>
<p>‚Äì None of the components is expensive to produce, Eshaghi Gorji points out. In addition, the fluid is non-toxic.</p>
<p>The compound will now be tested in pilot plants at a near-industrial scale, rather than in grams. A solid version of the liquid compound must be made for this purpose.</p>
<p>‚Äì The idea is to bind the compound to compounds such as silica and graphene oxide, which promotes the interaction with carbon dioxide.</p>
<p>More information: Postdoctoral Researcher Zahra Eshaghi Gorji (in English)<strong>&nbsp;</strong><ds-link ds-href="mailto:zahra.eshaghigorji@helsinki.fi" ds-text="zahra.eshaghigorji@helsinki.fi" ds-target="_self"></ds-link>, 046 540 89 78</p>
<p>Communications Specialist Juha Merimaa, <ds-link ds-href="mailto:juha.merimaa@helsinki.fi" ds-text="juha.merimaa@helsinki.fi" ds-target="_self"></ds-link>, 050 3017905&nbsp;</p>
<p>Link to article <ds-link ds-href="https://pubs.acs.org/doi/10.1021/acs.est.5c13908" ds-text="https://pubs.acs.org/doi/10.1021/acs.est.5c13908"></ds-link></p>

            
      </hy-paragraph-text>

                    <hy-box mb="1.75, 1.75, 2, 2.5"></hy-box>
      
              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How AI labs are solving the power problem (116 pts)]]></title>
            <link>https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power</link>
            <guid>46444020</guid>
            <pubDate>Wed, 31 Dec 2025 13:50:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power">https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power</a>, See on <a href="https://news.ycombinator.com/item?id=46444020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Nearly two years ago, we were the first to predict a looming power crunch. In our report </span><strong><a href="https://newsletter.semianalysis.com/p/ai-datacenter-energy-dilemma-race" rel="">AI Datacenter Energy Dilemma - Race for AI Datacenter Space</a><span>, w</span></strong><span>e forecasted AI Power Demand in the US to grow from ~3GW in 2023 to over 28GW by 2026 ‚Äì a pressure that would overwhelm America‚Äôs supply chains. Our prediction proved very accurate. </span></p><div data-component-name="DigestPostEmbed"><a href="https://newsletter.semianalysis.com/p/ai-datacenter-energy-dilemma-race" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!cFqp!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc797a7e7-79d1-4fa9-89e1-30f27c344a1b_1792x1024.png"><img src="https://substackcdn.com/image/fetch/$s_!cFqp!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc797a7e7-79d1-4fa9-89e1-30f27c344a1b_1792x1024.png" sizes="100vw" alt="AI Datacenter Energy Dilemma - Race for AI Datacenter Space" width="140" height="140"></picture></div></a></div><p><span>The chart below tells the story: in Texas alone, </span><strong>tens of gigawatts of datacenter load requests</strong><span> pour in </span><strong>each month</strong><span>. Yet in the past 12 months, barely more than a gigawatt has been approved. The grid is sold out.</span></p><p><span>However, AI infrastructure cannot wait for the grid‚Äôs multiyear transmission upgrades. An AI cloud can generate revenue of $10-12 billion dollars per gigawatt, </span><em>annually</em><span>. Getting a 400 MW datacenter online even six months earlier is worth billions. Economic need dwarfs problems like an overloaded electric grid. The industry is already searching for new solutions. </span></p><p><span>Eighteen months ago, Elon Musk shocked the datacenter industry by building a 100,000-GPU cluster in four months. Multiple innovations enabled this incredible achievement, but the energy strategy was the most impressive. xAI entirely bypassed the grid and generated power onsite, using truck-mounted gas turbines and engines. As shown below, xAI has already deployed over 500MW of turbines near its datacenters. In a world where </span><a href="https://newsletter.semianalysis.com/p/xais-colossus-2-first-gigawatt-datacenter" rel="">AI Labs are racing to be first with a Gigawatt datacenter</a><span>, </span><strong>speed is the moat</strong><span>.</span></p><p><span>One by one, hyperscalers and AI Labs are following suit and temporarily abandoning the grid to build their own onsite power plant. As we discussed months ago in the </span><a href="https://www.semianalysis.com/p/datacenter-model" rel="">Datacenter Model</a><span>, in October 2025, OpenAI and Oracle placed the largest order ever for onsite gas generation, with a 2.3GW plant in Texas. The market for onsite gas generation is entering an era of triple-digit growth annual growth.</span></p><p>The beneficiaries extend far beyond the usual suspects. Yes, GE Vernova and Siemens Energy have seen their stocks surge. But we‚Äôre witnessing an unprecedented wave of new entrants, such as:</p><ul><li><p><strong>Doosan Enerbility</strong><span>, the Korean industrial giant, timing its H-class turbine launch perfectly. It already </span><a href="https://semianalysis.com/institutional/xais-1-9gw-gas-turbine-order-with-doosan-colossus-2-progress/" rel="">booked a 1.9GW order to serve Elon‚Äôs xAI - as we exclusively unpacked to our Datacenter Industry Model subscribers several weeks ago</a><span>.</span></p></li><li><p><strong>W√§rtsil√§</strong><span>, historically a ship engine manufacturer, realized the same engines that power cruise ships can power large AI clusters. It has already signed 800MW of US datacenter contracts.</span></p></li><li><p><strong>Boom Supersonic</strong><span>‚Äîyes, the supersonic jet company‚Äîannounced a </span><strong>1.2 GW turbine contract with Crusoe</strong><span>, treating the margin from datacenter power generation as another round of funding for their Mach 2 passenger jets.</span></p></li></ul><p><span>To understand growth and market share by supplier, we built a building-by-building tracker of sites deploying onsite gas in our </span><a href="https://semianalysis.com/datacenter-industry-model/" rel="">Datacenter Model</a><span>. The results surprised us: </span><strong>12 different suppliers have now secured &gt;400 MW of datacenter orders each in the US alone, for onsite gas generation.</strong></p><p><span>However, onsite power generation brings its own set of challenges. Power costs are often (much) more expensive than via the grid, as detailed below. Permitting can be a lengthy and complicated process. And it‚Äôs already causing some datacenter delays - most notably one of the Oracle/Stargate GW-scale facilities, which our </span><a href="https://semianalysis.com/datacenter-industry-model/" rel="">Datacenter Industry Model</a><span> predicted three weeks prior to the Bloomberg headlines by analyzing the whole permitting process. </span></p><p>Again, clever firms like xAI have found remedies. Elon's AI Lab even pioneered a new site selection process - building at the border of two states to maximize the odds of getting a permit early! While Tennessee couldn't deliver on time, Mississippi happily enabled Elon to build a GW-scale power plant.</p><p>This report is a deep dive into Bring Your Own Generation (BYOG). We begin with why the grid can‚Äôt keep up, then provide a technical breakdown of every generation technology available to datacenters‚ÄîGE Vernova‚Äôs aeroderivatives, Siemens‚Äô industrial turbines, Jenbacher‚Äôs high-speed engines, W√§rtsil√§‚Äôs medium-speed engines, Bloom Energy‚Äôs fuel cells, and much more.</p><p>Then we examine deployment configurations and operational challenges: fully islanded datacenters, gas + battery hybrids, Energy-as-a-Service models, and the economics that determine which solutions win. Behind the paywall, we share our views on manufacturer positioning, d and the future of onsite generation.</p><p>Before we dive into solutions, we need to understand why the grid is failing. To be fair, America‚Äôs electrical system has been the primary enabler of AI infrastructure so far. Elon aside, every major GPU &amp; XPU clusters today runs on grid power. We‚Äôve covered many of them in prior SemiAnalysis deep dives:</p><ul><li><p><a href="https://newsletter.semianalysis.com/p/microsofts-ai-strategy-deconstructed" rel="">Microsoft‚Äôs AI Strategy</a><span> showing the massive grid-connected facilities for OpenAI in Wisconsin, Georgia and Arizona.</span></p></li><li><p><span>Our </span><a href="https://www.semianalysis.com/p/multi-datacenter-training-openais" rel="">Multi-Datacenter Training report</a><span>, digging into Google‚Äôs massive grid-powered clusters in Ohio and Iowa/Nebraska, as well as OpenAI‚Äôs gigawatt cluster in Abilene, TX with Oracle, Crusoe and Lancium.</span></p></li><li><p><span>Our </span><a href="https://newsletter.semianalysis.com/p/meta-superintelligence-leadership-compute-talent-and-data" rel="">Meta Superintelligence article</a><span> laying out their AI large plans, which include some onsite gas generation, but remain primarily served by AEP‚Äôs system in Ohio and Entergy in Louisiana.</span></p></li><li><p><span>Our </span><a href="https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion" rel="">Amazon‚Äôs AI Resurgence</a><span> thesis, discussing AWS‚Äô massive Trainium clusters for Anthropic, connected as well to AEP and Entergy‚Äôs infrastructure.</span></p></li></ul><p><span>These insights appeared in our </span><a href="https://semianalysis.com/datacenter-industry-model/" rel="">Datacenter Industry Model</a><span> months or years before official announcements. Our model tracks dozens more large-scale clusters under construction for 2026 delivery and beyond‚Äîincluding their exact start dates, full capacity, end-users, and energy strategies.</span></p><p><span>But we‚Äôve hit a tipping point. The large datacenters coming online in 2024-25 secured their power in 2022-23, before the gold rush. Since then, the scramble has been relentless. We estimate </span><strong>roughly a terawatt of load requests</strong><span> have been submitted to US utilities and grid operators.</span></p><p><span>The result is gridlock - literally. As we explained in </span><strong><a href="https://newsletter.semianalysis.com/p/ai-training-load-fluctuations-at-gigawatt-scale-risk-of-power-grid-blackout" rel="">AI Training Load Fluctuations at Gigawatt-Scale</a></strong><span>, the grid is slow by design:</span></p><ol><li><p><strong>Real-time balancing</strong><span>: Electricity supply and demand must match nearly perfectly, every second. A mismatch risks blackouts for millions, as we saw with the Iberian Peninsula blackout in April 2025.</span></p></li><li><p><strong>System studies</strong><span>: Every large new load (datacenter) or supply (power plant) triggers deep engineering studies to ensure it won‚Äôt destabilize the network. And in some places, grid topology changes so quickly that load studies go obsolete before they‚Äôre completed.</span></p></li></ol><p>When hundreds of developers simultaneously submit interconnection requests, the system seizes up. It becomes a prisoner‚Äôs dilemma:</p><ul><li><p>If everyone coordinated, the grid could handle more requests faster.</p><ul><li><p><span>FERC Order 2023 has pushed grid operators to adopt </span><strong>cluster studies</strong><span> for this purpose, but those reforms were solidified only in 2025.</span></p></li></ul></li><li><p>In practice, ‚Äúgold rush‚Äù behavior means developers submit multiple speculative requests to different utilities simultaneously</p><ul><li><p><span>For example as of mid-2024, AEP Ohio had </span><strong>35 GW of load requests</strong><span>‚Äîand 68% didn‚Äôt even have land control</span></p></li></ul></li><li><p>Speculative requests clog the queue for everyone, encouraging more speculative requests elsewhere</p></li><li><p>The vicious cycle accelerates</p></li></ul><p><span>The supply side is equally constrained. The timeline from interconnection request to commercial operation now stretches to </span><strong>five years</strong><span> for most generation types.</span></p><p><span>AI infrastructure developers cannot wait five years. In many cases, they cannot wait six months, because </span><em>waiting six months costs billions of dollars of lost opportunities.</em></p><p><span>The core value proposition of BYOG is simple: </span><strong>start operating without waiting for the grid.</strong><span> A datacenter can run indefinitely on local generation, then convert that equipment to backup power once grid service eventually arrives.</span></p><p>That‚Äôs exactly xAI‚Äôs strategy. They built Colossus using mobile gas turbines, bringing the facility online in months rather than years. Now everyone is following the playbook.</p><p>Let‚Äôs examine how.</p><p>BYOG involves a complete re-thinking of the way we build power plants. Traditionally, we deliver power via large, centralized GW-scale baseload generators ‚Äì accompanied by smaller peaker plants to handle spikes in grid-wide load. Heavy-duty gas turbines in combined cycle mode are the most common modern deployment. Their unmatched fuel efficiency (&gt;60%) provides the backbone of our modern civilization. However, their main issue is deployment speed:</p><ul><li><p>There is typically a multi-year lead time to get large turbines, and current lead times are at an all-time high.</p></li><li><p><span>Once delivered, construction and commissioning of a large combined-cycle power plant takes </span><strong>~2 years - an eternity in the AI era.</strong></p></li></ul><p>AI Datacenter ‚ÄúBYOG‚Äù power plants re-shape the playbook, and xAI led the way for the industry. To deploy faster, Elon‚Äôs AI Lab relied on small modular 16MW turbines from Solar Turbines, a CAT subsidiary. The turbines are small enough to be transported by standard long-haul trucks. They‚Äôre deployed in a matter of weeks. Elon didn‚Äôt even buy them ‚Äì he rented from Solaris Energy Infrastructure to bypass the equipment lead time. He also leveraged VoltaGrid‚Äôs fleet of mobile truck-mounted gas engines to deliver faster!</p><p>Other hyperscalers quickly followed suit. Meta‚Äôs deployment in Ohio, with Williams, is illustrative ‚Äì with their power plant comprising five different types of turbines &amp; engines, clearly the design pattern was ‚ÄúI‚Äôll deploy whatever I can get on time!‚Äù</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!22Zm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!22Zm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 424w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 848w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1272w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png" width="624" height="428" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c0c11789-f392-49d6-8874-060fa89a919d_624x428.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:428,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:519855,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!22Zm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 424w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 848w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1272w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Socrates South Satellite Image (Nov 11, 2025)</figcaption></figure></div><p>Let‚Äôs now dig into the different types of equipment available to datacenter operators.</p><p>Among gas generators available to datacenter developers, there are three broad categories:</p><ol><li><p><span>Gas Turbines (GTs) - low-temp, slow-to-ramp </span><strong>industrial gas turbines (IGTs)</strong><span>; high-temp, fast-to-ramp </span><strong>aeroderivative gas turbines (Aeros)</strong><span>; very large </span><strong>heavy-duty gas turbines</strong><span>.</span></p></li><li><p><span>Reciprocating Internal Combustion Engines (RICEs) - both smaller, 3-7 MW </span><strong>high-speed engines</strong><span>; and larger, 10-20 MW </span><strong>medium-speed engines. </strong><span>Sometimes called ‚Äúrecips‚Äù for short.</span></p></li><li><p>Solid-oxide fuel cells (SOFCs) - the main option available so far is from Bloom Energy.</p></li></ol><p>There are additional onsite power options such as co-locating with an existing nuclear power plant, building onsite SMRs, Geothermal, and many more, but we won‚Äôt discuss them in this report. For the most part, these other solutions are not driving net new power generation in the next ~3 years.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SCxw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SCxw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 424w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 848w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 1272w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SCxw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png" width="814" height="260" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f589386c-9931-4b77-8cb8-4cc838319d53_814x260.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:260,&quot;width&quot;:814,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57830,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!SCxw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 424w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 848w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 1272w, https://substackcdn.com/image/fetch/$s_!SCxw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff589386c-9931-4b77-8cb8-4cc838319d53_814x260.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Understanding which solutions are the best fit for certain use-cases requires digging into the core tradeoffs. We see the following as most relevant: </p><ul><li><p><strong>Cost:</strong><span> Usually listed as $/kW. These cost estimates vary wildly and are consistently rising across every generator category. Note that maintenance expenses are also relevant: certain systems have lower useful life, i.e. higher annual maintenance costs.</span></p></li><li><p><strong>Lead Time (shipment and installation): </strong><span>Usually listed in months or years. Lead times are increasing across every generator category as demand growth outstrips supply.</span></p><ul><li><p>Note that other factors outside generator availability can affect time-to-power. Most notably, air permitting for onsite generation can take a year or more, even in fast-to-permit states like Texas.</p></li><li><p>In addition, installation time varies widely across systems. Some can take barely a few weeks from delivery onsite to power generation, such as small truck-mounted turbines or engines, as well as fuel cells. Large CCGTs can take over 24 months to assemble.</p></li></ul></li><li><p><strong>Redundancy &amp; uptime</strong><span>: the expected availability of the generator, expressed in % of uptime over a year, or in ‚Äúnines‚Äù of uptime. The US Electric grid averages 99.93% (3 nines) over the last ten years, with some areas even higher. For an onsite power plant, redundancy can be managed by adding hot spares and cold spares, or by having additional backup power. The larger the individual turbines, the more difficult managing spares &amp; backup is.</span></p></li><li><p><strong>Ramp Rate:</strong><span> Measured as minutes between cold start and maximum output. A ramp rate of less than 10 minutes makes a generator eligible as reserve generation for an electric grid or backup power. A slow ramp-rate means that the unit is primarily focused on baseload power.</span></p></li><li><p><strong>Land Use: </strong><span>Measured as MW/acre. This matters more in space-constrained areas. Water use for small generation systems is insubstantial, even as a fleet. However, very large turbines do require significant water use for cooling.</span></p></li><li><p><strong>Heat Rate and Fuel Efficiency:</strong><span> Measured as BTU of natural gas per kWh. A higher heat rate means lower efficiency‚Äîmore fuel in, same electricity out, more waste left behind. Nameplate heat rate assumes ‚Äúpeak‚Äù operating conditions, typically maximum output. Efficiency drops substantially below 50% output.</span></p><ul><li><p><span>Many of these onsite gas systems can be configured as </span><strong>combined heat and power (CHP) </strong><span>systems. For datacenters, this would entail using the waste heat from a gas generator for an </span><strong>absorption cooling</strong><span> system, allowing for reduced electricity use in cooling the datacenter.</span></p></li></ul></li></ul><p>In reality, we observe that whoever has an open orderbook and can provide good timelines tends to win deals, regardless of most other specs!</p><p>Having said that, let‚Äôs now deep dive into the different types of gas power plants.</p><p><span>Gas turbines run on a Brayton Cycle: compress air, burn fuel in it, and route the hot gas through a turbine. Turbines are differentiated by </span><strong>inlet temperatures</strong><span>. Lower temperatures correspond to lower installation costs, lower maintenance costs, lower peak efficiency, and slower ramp rates.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!9NYx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!9NYx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 424w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 848w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 1272w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!9NYx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png" width="1129" height="594" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:594,&quot;width&quot;:1129,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:253973,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!9NYx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 424w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 848w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 1272w, https://substackcdn.com/image/fetch/$s_!9NYx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbdea229-e3c1-46f2-bc1a-d4790ea57eee_1129x594.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>An aeroderivative gas turbine is simply a jet engine bolted to the ground. GE Vernova‚Äôs aeros derive from GE jet engines; Mitsubishi Power‚Äôs from Pratt &amp; Whitney; Siemens Energy‚Äôs from Rolls-Royce. Because jet engines are designed to deliver massive power in a compact, flight-worthy package, they are relatively easy to adapt for stationary power. Extend the turbine shaft, bolt a generator coil to the end, add intake and exhaust mufflers, and feed fuel from tanks or a pipeline. This is, in part, why Boom Supersonic could pivot so quickly into aeroderivative gas turbines: most of their engineering and manufacturing is carryover.</p><p>We show below a view of the Martin Drake power plant, w/ 6x GE Vernova LM2500XPRESS units. This is how electric utilities deploy aeroderivatives, as ‚Äúpeaker plants‚Äù for sudden supply shortages in the grid.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6cUt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6cUt!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 424w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 848w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 1272w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6cUt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png" width="584" height="495.95979899497485" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:676,&quot;width&quot;:796,&quot;resizeWidth&quot;:584,&quot;bytes&quot;:986615,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6cUt!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 424w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 848w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 1272w, https://substackcdn.com/image/fetch/$s_!6cUt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37829f1d-54b2-4235-a7e2-0e31424b03bd_796x676.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The core manufacturers for aeroderivative gas turbines are similar to those of heavy-duty gas turbines: GE Vernova, Mitsubishi Power, and Siemens Energy dominate the market, selling both aeros and lower-temp </span><strong>industrial gas turbines (IGTs)</strong><span>. Additionally Caterpillar also produces IGTs under the Solar brand name, as does Everllence (formerly MAN Energy Systems).</span></p><p>Two GE Vernova designs dominate the aeroderivative market:</p><ul><li><p><strong>LM2500</strong><span> ‚Äì ~34 MW, optimized for fast deployment, especially as LM2500XPRESS.</span></p></li><li><p><strong>LM6000</strong><span> ‚Äì ~57 MW, now available in fast-deploy LM6000VELOX configurations.</span></p></li></ul><p>Aeros are reasonably efficient with fuel but extremely efficient with respect to space and weight. They can fit in tight footprints, and in some configurations can be transported on a pair of tractor trailers. Simple-cycle aeros typically come in 30-60 MW packages and can ramp from cold to full output in 5-10 minutes. However, efficiency suffers if they are at less than full steady load. Aeros can also be configured as small combined-cycle plants:</p><ul><li><p>1x1 (one combustion turbine feeding one steam turbine), or</p></li><li><p>2x1 (two combustion turbines feeding one steam turbine).</p></li></ul><p>These combined-cycle setups deliver higher efficiency and more output at the cost of ramp speed. Startup times lengthen to 30‚Äì60 minutes.</p><p><span>At current rates, aeros cost </span><strong>$1,700-2,000/kW</strong><span> in all-in capital expenditure, and based on recent orders, they have lead times of </span><strong>18-36 months</strong><span> and rising. Smaller turbines can have lead times as short as 12 months, and larger aeros (~50 MW) can take up to 36 months. These systems are quick to install (2-4 weeks usually), but the factories are heavily booked. One workaround is truck-mounted turbines, which can be rented and deployed quickly, if available. xAI used this exact strategy, partnering with Solaris Energy Infrastructure to shrink their time-to-power for Colossus 1 and 2.</span></p><p>Industrial gas turbines work on the same cycle as aeros and share benefits like compact footprints, modularity, and relatively fast lead times. But they are designed from scratch for stationary use rather than adapted from aviation. They typically run at lower inlet temperatures and use simpler designs, which lowers service costs at the expense of efficiency and ramp speed.</p><p>Simple-cycle IGTs span roughly 5‚Äì50 MW and ramp from cold to full output in ~20 minutes. That makes them too slow, on their own, to serve as peaker plants or emergency backup without help from batteries or diesel units. Like aeros, IGTs can be upgraded to combined-cycle configurations, improving efficiency while further slowing ramp rate.</p><p><span>The most common dedicated industrial gas turbines are the </span><strong>Siemens Energy SGT-800</strong><span> and </span><strong>Solar Titan Series</strong><span>. However, smaller heavy-duty gas turbines like the </span><strong>GE Vernova 6B</strong><span> also sometimes take on similar use cases.</span></p><p><span>At current rates, IGTs cost </span><strong>$1,500-1,800/kW</strong><span> in all-in capital expenditure, with lead times of approximately </span><strong>12-36 months</strong><span>, similar to aeros. However, procuring a used or refurbished IGT can shrink lead times to under 12 months, which is how Fermi America is procuring power.</span></p><p>Overall, we believe that aeroderivatives and IGTs are a very attractive solution for onsite power generation, because:</p><ul><li><p>They are the ‚Äúright‚Äù size: small enough to facilitate redundancy, large enough to avoid having too many units onsite and complexifying maintenance.</p></li><li><p>They have a fast ramp-rate: while they aren‚Äôt as energy-efficient as others, they can more easily be repurposed for backup power.</p></li><li><p>They are quick to deploy, normal trucks and construction crews can transport and install them, instead of the insane heavy-lift infrastructure necessary for heavy-duty turbines.</p></li></ul><p>We‚Äôll discuss these concepts later in the report when discussing deployment considerations. The main issue with aeros and IGTs is, increasingly, lead times.</p><p><span>The most supply-constrained component in gas turbines are the turbine blades and cores, which must handle high temperatures and speeds. These blades use exotic monocrystalline nickel alloys that include rare-earth metals like rhenium, cobalt, tantalum, tungsten, and yttrium. Notably, yttrium is among the rare earths </span><a href="https://www.china-briefing.com/news/chinas-rare-earth-export-controls-impacts-on-businesses/" rel="">under export control</a><span> from the Chinese government. The cores, meanwhile, require high-temperature ceramics that are in short supply.</span></p><p>Reciprocating engines function like automotive engines, but at a much larger scale, an 11MW engine can be more than 45 feet (14 m) long. They use four-stroke combustion cycles and are divided by rotation speed:</p><ul><li><p><strong>High-speed engines</strong><span> ‚Äì ~1,500 rpm; smaller in footprint and output.</span></p></li><li><p><strong>Medium-speed engines</strong><span> ‚Äì ~750 rpm; generally lower maintenance costs due to lower mechanical stress.</span></p></li></ul><p>RICEs can ramp from cold to full output in 10 minutes, similar to aeros in practice. This lets RICEs work as peaker plants or as backup generators, eliminating the need for diesel backups. On paper, RICE O&amp;M looks higher than for turbines because there are more moving parts. In practice, they handle fuel impurities, dust, and high ambient temperatures better than many turbines and suffer less de-rating in hot climates.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!p6G-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!p6G-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 424w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 848w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 1272w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!p6G-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png" width="946" height="570" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a722cd1c-5759-413a-952c-f31727d7fba9_946x570.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:570,&quot;width&quot;:946,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:144797,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!p6G-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 424w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 848w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 1272w, https://substackcdn.com/image/fetch/$s_!p6G-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa722cd1c-5759-413a-952c-f31727d7fba9_946x570.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Medium-speed engine manufacturing is fairly consolidated, with the primary manufacturers being W√§rtsil√§, Bergen Engines, and Everllence (formerly MAN Energy).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!w7M2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!w7M2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 424w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 848w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 1272w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!w7M2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png" width="725" height="312.5400641025641" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7e9d65c0-b354-4170-b9dc-99eafb25de88_624x269.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:269,&quot;width&quot;:624,&quot;resizeWidth&quot;:725,&quot;bytes&quot;:127741,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e9d65c0-b354-4170-b9dc-99eafb25de88_624x269.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!w7M2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 424w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 848w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 1272w, https://substackcdn.com/image/fetch/$s_!w7M2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36502d2-404f-4d3c-b963-b9f2410c1733_624x269.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Bergen B36:45V20AG (rated for 11.3 MW). Person for scale. Source: </span><a href="https://www.bergenengines.com/wp-content/uploads/2021/12/B3645V_Rev_D.pdf" rel="">Bergen Engines</a></figcaption></figure></div><p><span>High-speed engine manufacturing is not as consolidated as turbines. Outside the prominent players in Jenbacher, CAT, Cummins, and Rolls Royce subsidiary MTU, there are a wide range of manufacturers, because high-speed gas engines are functionally equivalent to the diesel engine designs currently used for backup power at many datacenters. The most consequential reciprocating engine is the </span><strong>Jenbacher J624</strong><span>, a 4.5MW turbocharged gas engine that can be containerized for easier logistics. This system is the preferred generator for VoltaGrid‚Äôs energy integration services.</span></p><p>RICE systems typically generate less power per unit than equivalent turbines. Medium-speed engines run between 7 MW and 20 MW, with the higher power outputs enabled by turbocharging. High-speed engines are even smaller, with per-unit outputs between 3 MW and 5 MW. However, RICE generators are more efficient than turbines when running at partial loads between 50% and 80%.</p><p>Reciprocating engines operate at much lower temperatures than gas turbines, closer to 600¬∞-700¬∞C. This dramatically reduces their need for high-performance alloys. Only the high-temperature components in the pistons, combustion chambers, and turbochargers still need rare nickel and cobalt alloys, and the rest can be manufactured with simple cast iron, steel, and aluminum. However, RICEs overall are less dependent on critical minerals, especially if emissions controls are relaxed during a materials supply crunch.</p><p><span>At current rates, reciprocating engines cost </span><strong>$1,700-2,000/kW</strong><span> in all-in capital expenditure and have lead times of </span><strong>15-24 months</strong><span>. Compared to turbines, these systems are less delayed in manufacturing; the manufacturing timeline is closer to 12-18 months. However, medium-speed RICEs are considerably heavier than turbines, and installation and commissioning can take up to ~10 months.</span></p><p><span>High-speed engines can be much faster to deploy. For example, at the initial Colossus 1 deployment, xAI leveraged 34 VoltaGrid truck-mounted systems, incorporating high-speed engines from Jembacher. High-speed engines, in particular, are popular with </span><strong>energy procurement vendors</strong><span> (described later). Their wide availability and small unit size offer faster time-to-power. We show below a VoltaGrid 50MW deployment in San Antonio, with twenty Jembacher J620 (rated 3.36kW per unit).</span></p><p><span>The tradeoff is scale: to build a 2 GW onsite gas system with 5 MW engines, you need </span><strong>500 units! </strong><span>That has major operational consequences. If each engine needs minor servicing every 2,000 hours, the maintenance staff would perform more than 2,000 services per year, almost 40 per week. These costs are more predictable than turbine overhauls (which can involve swapping entire cores), but they add up, especially for fleets with many small units. Space and spares inventories grow similarly, although vertical stacking of small generators can mitigate land use, a trick not available for medium-speed engines.</span></p><p><span>A fairly niche solution is now taking an increasingly large share of the pie: fuel cells. Often associated with hydrogen, Bloom Energy‚Äôs SOFC fuel cells can run on natural gas too and are pitched as baseload generation. We first called out Bloom Energy as a big winner in last 2024 in the </span><a href="https://semianalysis.com/datacenter-industry-model/" rel="">datacenter model</a><span>. Since then the orders have skyrocketed.</span></p><p>Bloom‚Äôs ‚ÄúEnergy Server‚Äù is made up multiple ~1kW stacks, assembled into ~65kW modules, and packaged into a 325kW power generator. To date, the largest operational SOFC-based power plants are in the tens of MW, mostly in the US and Korea.</p><p><span>The way they generate energy is very different from that of traditional generators. There is </span><strong>no combustion process</strong><span>. Instead, oxygen is electrochemically reduced to oxide ions, which flows through a ceramic electrolyte. At the other end of the fuel cell, these ions combine with hydrogen atoms stripped from methane natural gas. This combination releases water, CO2, and electricity.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2jTq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2jTq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 424w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 848w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 1272w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2jTq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png" width="726" height="547" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:547,&quot;width&quot;:726,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:91611,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2jTq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 424w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 848w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 1272w, https://substackcdn.com/image/fetch/$s_!2jTq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c6fea39-20de-4b4f-ae57-fe8584103bed_726x547.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This fundamental difference provides Bloom‚Äôs fuel cells with a key advantage: they do NOT generate material air pollution, besides CO2. The permitting at the EPA level is significantly smoother and easier than that of combustion generators. That‚Äôs why we often see them in population centers, such as near offices.</p><p>Bloom‚Äôs killer feature is the speed of deployment. It barely requires precast pads and a simple installation of modules. Once factoring-in the electrical work, installation &amp; commissioning can be done in a matter of weeks, matching the speed of aeroderivatives and high-speed RICE.</p><p>In the AI era where speed is the moat, that advantage alone is enough to place Bloom on the map.</p><figure data-drag-handle="true" data-component-name="ImageGallery"><div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Dn77!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a47e4f-78d3-4fb9-be28-194a66e88720_1248x650.png 424w, https://substackcdn.com/image/fetch/$s_!Dn77!,w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a47e4f-78d3-4fb9-be28-194a66e88720_1248x650.png 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Dn77!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a47e4f-78d3-4fb9-be28-194a66e88720_1248x650.png" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Dn77!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a47e4f-78d3-4fb9-be28-194a66e88720_1248x650.png 424w, https://substackcdn.com/image/fetch/$s_!Dn77!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a47e4f-78d3-4fb9-be28-194a66e88720_1248x650.png 474w" width="474"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!hzbJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F011458d2-bb9d-4327-83a1-f848357d2289_1248x660.png 424w, https://substackcdn.com/image/fetch/$s_!hzbJ!,w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F011458d2-bb9d-4327-83a1-f848357d2289_1248x660.png 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!hzbJ!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F011458d2-bb9d-4327-83a1-f848357d2289_1248x660.png" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!hzbJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F011458d2-bb9d-4327-83a1-f848357d2289_1248x660.png 424w, https://substackcdn.com/image/fetch/$s_!hzbJ!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F011458d2-bb9d-4327-83a1-f848357d2289_1248x660.png 474w" width="474"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!fuiD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a71c73-1fe4-48bc-9ea7-46343b5e22fd_1248x733.png 424w, https://substackcdn.com/image/fetch/$s_!fuiD!,w_474,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a71c73-1fe4-48bc-9ea7-46343b5e22fd_1248x733.png 474w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!fuiD!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a71c73-1fe4-48bc-9ea7-46343b5e22fd_1248x733.png" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!fuiD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a71c73-1fe4-48bc-9ea7-46343b5e22fd_1248x733.png 424w, https://substackcdn.com/image/fetch/$s_!fuiD!,w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a71c73-1fe4-48bc-9ea7-46343b5e22fd_1248x733.png 474w" width="474"></picture></div><figcaption>Source: Bloom Energy Installation [YouTube]</figcaption></div></figure><p><span>Bloom‚Äôs main challenge is cost. Fuel cell efficiency is quite good, with an equivalent heat rate of 6,000-7,000 BTU/kWh, which is on-par with CCGTs. However, the costs for fuel cell systems are notably higher than turbines or RICE systems, at a capex cost between </span><strong>$3,000-$4,000/kW</strong><span>. Bloom does not advertise ramp rates, suggesting these units are too slow to function as peakers or emergency backup.</span></p><p><span>Maintenance has historically also been notably higher than other solutions. Individual fuel cell stacks last roughly </span><strong>5-6 years</strong><span>, then must be replaced and refurbished. This per-cell replacement makes up ~65% of service costs, although specific numbers are kept close to vest. Bloom discloses little about its materials beyond the use of ceramics in the cell core, but claim that their fuel cells have no critical mineral dependence on China or other contested regions.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6GCg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6GCg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 424w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 848w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 1272w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6GCg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png" width="1456" height="762" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:762,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:505177,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6GCg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 424w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 848w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 1272w, https://substackcdn.com/image/fetch/$s_!6GCg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79098fb0-5f05-49f3-91af-1e4cec6c5a31_1505x788.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We provide TCO estimates for Bloom fuel cells behind the paywall. </p><p>Before ChatGPT, only utilities and independent power producers (IPPs) had any reason to buy a gas turbine larger than 250 MW, because turbines above that threshold are simply too large to use for most industrial applications. As explained above, speed of deployment is an issue, however, we‚Äôre increasingly seeing developers provide ‚Äúbridge power‚Äù via smaller aeroderivatives/RICE then shift them as backup/redundancy once the big CCGT is operational.</p><p>Large turbines are grouped into classes based on combustion (turbine inlet) temperature and technology stack:</p><p><strong>E-Class and F-Class</strong><span> ‚Äì Older, lower-temperature, lower-efficiency designs. Some F-class units are still sold, usually into developing markets, because they offer decent efficiency at lower capex. The line between ‚Äúindustrial‚Äù turbines and small E/F-class frames is fuzzy, with the below famous models straddling that boundary:</span></p><ul><li><p>GE Vernova 6B</p></li><li><p>GE Vernova 7E</p></li><li><p>Siemens Energy SGT6-2000E</p></li></ul><p><strong>H-Class and equivalents</strong><span> ‚Äì Modern, high-temperature designs. These run firing temperatures comparable to modern aeros and jet engines, but with roughly 10x the per-unit power. The most prominent examples are:</span></p><ul><li><p><strong>GE Vernova</strong><span> </span><strong>HA</strong><span> series (e.g., HA.02)</span></p></li><li><p><span>Siemens Energy </span><strong>H/HL</strong></p></li><li><p><span>Mitsubishi Heavy Industries </span><strong>J</strong><span> series (e.g., H510J)</span></p></li><li><p><span>More recently, Korean firm </span><strong>Doosan Enerbility</strong><span> has started production of a new H-class turbine, the </span><strong>DGT6</strong><span>. It‚Äôs rare to see new entrants in a decade-old market, but Doosan has deep experience in steam turbine production and a track record of building Mitsubishi-designed F-class turbines.</span></p></li></ul><p>As shown below, these systems are both very large and heavy. The installation and commissioning process can take a while.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ORUY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ORUY!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 424w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 848w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 1272w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ORUY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png" width="740" height="814" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:814,&quot;width&quot;:740,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1189585,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ORUY!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 424w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 848w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 1272w, https://substackcdn.com/image/fetch/$s_!ORUY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea7ede7b-a314-4d9c-b59f-d7593149bf3e_740x814.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A view of the Three Rivers CCGT in Grundy County, IL. Satellite Image.</figcaption></figure></div><p>Combined-cycle gas turbines (CCGTs) exploit the fact that simple-cycle exhaust is still very hot, hot enough to boil water into steam. Routing exhaust through a heat recovery steam generator (HRSG) produces steam for a separate steam turbine and generator. The result is a second round of power from the same fuel. By turning one turbine‚Äôs trash into another turbine‚Äôs treasure, CCGTs can run 50-80% more efficiently than a simple-cycle turbine.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!jqfC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!jqfC!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 424w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 848w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 1272w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!jqfC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png" width="1216" height="700" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/27759ab0-bc15-4f96-8334-804f10759535_1216x700.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:700,&quot;width&quot;:1216,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:260570,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!jqfC!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 424w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 848w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 1272w, https://substackcdn.com/image/fetch/$s_!jqfC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27759ab0-bc15-4f96-8334-804f10759535_1216x700.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The CCGTs most vaunted for large loads are heavy-duty CCGTs, which can reach gigawatt-scale outputs. However, even small aeroderivative or industrial gas turbines can be sold with an integrated steam turbine, which can dramatically increase power output with near-identical fuel inputs. Common configurations are:</p><ul><li><p><strong>1x1</strong><span> ‚Äì One gas turbine feeding one steam turbine</span></p></li><li><p><strong>2x1</strong><span> ‚Äì Two gas turbines feeding one steam turbine</span></p></li></ul><p>In theory, more gas turbines can feed a single steam turbine but returns diminish. The primary drawback of a CCGT system is the ramp rate: the addition of the steam turbine slows the time from cold start to full output to 30 minutes or more.</p><p>The other major drawback is the lead time. Installation &amp; commissioning is even longer than for a simple cycle deployment.</p><p>Understanding the equipment landscape is necessary but not sufficient. The real complexity in onsite gas isn‚Äôt choosing between an LM2500 and a Jenbacher J624‚Äîit‚Äôs figuring out how to configure, deploy, and operate these systems to meet datacenter uptime requirements.</p><p><span>The electric grid is a marvel of systems engineering: thousands of generators, hundreds of transmission lines, and sophisticated market mechanisms that together deliver 99.93% average uptime. When you go off-grid, you‚Äôre taking on that complexity yourself‚Äîwith a single plant that has to match grid-level reliability. Redundancy and uptime are the key reason why </span><strong>onsite gas power costs are, in most cases, structurally much more expensive than power delivered by the grid</strong><span>. </span></p><p>The next section examines how leading deployments are solving this challenge, and what it means for equipment selection.</p><p>One of the most popular onsite gas strategies so far has been ‚Äúbridge power‚Äù. The datacenter campuses have an active discussion with the grid to get electrical service, but begin operations before via onsite power.</p><p><span>Bridge power clears electricity as a bottleneck to operation, allowing a datacenter to start training models or generating revenue several months earlier. This speedup is significant! </span><strong>AI cloud revenue can net $10-12M per MW annually, meaning that getting 200 MW of datacenter powered and online even six months earlier can net $1-1.2 billion in revenue.</strong></p><p>Bridge power brings two advantages:</p><ol><li><p>The uptime requirements can be matched to the workload. For example, in Abilene TX and Memphis TN, both xAI and Crusoe/OpenAI are deploying large training clusters. Training jobs don‚Äôt need particularly elevated uptime, given the inherent unreliability of large GPU clusters. As such, ‚Äúoverbuilding‚Äù the power plant for redundancy can be avoided. Once a grid connection is secured, the campus can be more fungible and also used for inference.</p></li><li><p>Favorable economics via removal of diesel generator backup. In both Memphis and Abilene, the absence of backup reduces datacenter capex/MW. Once a grid connection is secured, the turbines can act as backup ‚Äì as such, fast ramp-rate systems are preferred, e.g. aeroderivatives.</p></li></ol><p>To ensure reasonable uptime, xAI paired the turbines with MegaPacks. That also enables to smooth out load fluctuations ‚Äì an issue we‚Äôll discuss below.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6JEN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6JEN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 424w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 848w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 1272w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6JEN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png" width="728" height="547.1666666666666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/69174cc7-ee76-482f-9b84-692835cd08aa_1248x938.png&quot;,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:938,&quot;width&quot;:1248,&quot;resizeWidth&quot;:728,&quot;bytes&quot;:1616920,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69174cc7-ee76-482f-9b84-692835cd08aa_1248x938.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6JEN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 424w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 848w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 1272w, https://substackcdn.com/image/fetch/$s_!6JEN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ab9185-d960-4f39-964b-1ac2ab6c757c_1248x938.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Satellite image over xAI Memphis</figcaption></figure></div><p>Many generator vendors suggest that datacenter owners should never bother interconnecting with the broader electric grid; instead, they argue that their datacenter customers should stay off-grid forever. Firms like VoltaGrid offer a full ‚ÄúEnergy-as-a-Service‚Äù package managing all aspects of electric service:</p><ul><li><p><strong>Electric energy</strong><span> ‚Äì MW of capacity and MWh of energy</span></p></li><li><p><strong>Power quality</strong><span> ‚Äì Voltage and frequency tolerances</span></p></li><li><p><strong>Reliability</strong><span> ‚Äì Targeted ‚Äúnines‚Äù of uptime</span></p></li><li><p><strong>Time-to-power</strong><span> ‚Äì Months from contract to operation</span></p></li></ul><p>They typically sign long-term PPAs with customers who pay for electric service ‚Äì the EaaS vendors essentially acts as a utility. They procure equipment, design the deployment, sometimes assemble the BoM, and maintain &amp; operate the power plant.</p><p>A key challenge when deploying off-grid generation is managing redundancy. For example, the 1.4GW Vantage DC campus in Shackelford County, TX will deploy 2.3GW of VoltaGrid systems. These systems being small facilitates redundancy ‚Äì but if you were to deploy onsite power with large heavy duty turbines, redundancy might be to simply have two power plants, if not more.</p><p><span>Generation vendors will suggest at minimum an N+1 configuration, if not an N+1+1 configuration. An N+1 configuration maintains full generation capacity even if one generator unexpectedly shuts down, whereas an N+1+1 configuration enables this flexibility </span><em>while also </em><span>keeping another generator on standby to enable maintenance cycles. It‚Äôs the equivalent of driving a car with a spare tire </span><em>and</em><span> a tire repair kit. Note that N+1 or N+1+1 does not necessarily refer to a literal count of generators, given that datacenter loads are typically much larger than individual onsite gas generators. For example, consider a datacenter with an all-in (IT + non-IT) power demand of 200 MW:</span></p><ul><li><p><strong>Generation fleet</strong><span>: 26 √ó 11 MW RICE units</span></p></li><li><p><strong>Total capacity</strong><span>: 286 MW</span></p></li></ul><p>Under normal operation:</p><ul><li><p>23 engines run at ~80% load to produce 200+ MW.</p></li><li><p>One generator failure: 22 engines ramp modestly to ~82% load.</p></li><li><p>3 spare engines remain for maintenance or as cold standby.</p></li></ul><p>Running engines below full load reduces O&amp;M, and the extra units provide a buffer for maintenance scheduling.</p><p>Nexus Datacenter is using a similar approach: they have recently applied for an air permit for a fleet of thirty Everllence 18V51/60G gas engines, each good for 20.4 MW, for a total of 613 MW of generation. This site will also include 152 MW of diesel backup generation, which likely fulfills the N+1 redundancy requirements for the total site.</p><ul><li><p><strong>Generation fleet</strong><span>: 9 √ó 30 MW aeros</span></p></li><li><p><strong>Total capacity</strong><span>: 270 MW</span></p></li></ul><p>Under normal operation:</p><ul><li><p>7 turbines run at ~95% load for best efficiency.</p></li><li><p>One turbine failure: the 8th turbine starts, maintaining output.</p></li><li><p>The 9th turbine remains in reserve for maintenance.</p></li></ul><p><span>Because turbine overhauls are more disruptive than engine maintenance, some vendors offer </span><strong>hot-swap</strong><span> programs: a turbine due for major service is swapped out for a replacement core.</span></p><p><span>In hot climates, such as the American Southwest, derating may require </span><strong>10‚Äì11 aeros</strong><span> to maintain N+1+1 redundancy.</span></p><p>Crusoe‚Äôs Abilene site for Oracle and OpenAI uses a version of this setup, with a deployed fleet of ten turbines, with five GE Vernova LM2500XPRESS aeroderivative gas turbines and five Titan 350, good for 360MW of nameplate generation.</p><p><span>Meta and Williams are building a pair of 200 MW behind-the-meter gas plants to power Meta‚Äôs New Albany Hub, which we have covered in this article: </span><a href="https://semianalysis.com/core-research/metas-new-ultra-fast-tent-datacenters-in-ohio/" rel="">Meta‚Äôs new ultra-fast ‚Äútent‚Äù datacenters in Ohio ‚Äì SemiAnalysis</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!22Zm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!22Zm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 424w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 848w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1272w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png" width="624" height="428" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c0c11789-f392-49d6-8874-060fa89a919d_624x428.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:428,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:519855,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!22Zm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 424w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 848w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1272w, https://substackcdn.com/image/fetch/$s_!22Zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0c11789-f392-49d6-8874-060fa89a919d_624x428.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Socrates South Satellite Image (Nov 11, 2025)</figcaption></figure></div><p><span>The </span><strong>Socrates South</strong><span> project is a hybrid fleet:</span></p><ul><li><p>3 √ó Solar Titan 250 IGTs (23 MW)</p></li><li><p>9 √ó Solar Titan 130 IGTs (16.5 MW)</p></li><li><p>3 √ó Siemens SGT-400 IGTs (14.3 MW)</p></li><li><p>15 √ó Caterpillar 3520 fast-start engines (3.1 MW)</p></li></ul><p><span>Nameplate capacity inside the fence is </span><strong>306 MW</strong><span>: roughly </span><strong>260 MW</strong><span> from turbines and </span><strong>46 MW</strong><span> from engines. Under normal conditions, a subset of IGTs runs steadily to deliver 200 MW. If one or two IGTs trip, the RICE fleet can ramp quickly to cover the gap. Additional IGTs remain available for maintenance switchover. This supports an N+1+1 behind-the-meter design.</span></p><p>However, this is a patchwork implementation compared to the first two examples. The turbines don‚Äôt match, and the engines used are smaller, 1800-rpm high-speed gas engines. This suggests that Williams prioritized time-to-power over standardized maintenance schedules.</p><p>To match the ‚Äúthree nines‚Äù of uptime provided by the grid, an onsite power plant must be ‚Äúoverbuilt‚Äù for redundancy. This is typically the key reason for higher onsite generation power costs, relative to the grid.</p><p>Redundancy introduces a new headache for operators: there is a tradeoff between the size of a system and the ‚Äúoverbuild‚Äù ratio. While H class and F class turbines are more energy-efficient than aeros, the higher redundancy needs means than, if poorly designed, an islanded system based on heavy duty turbines can yield higher power costs than aeros. Other solutions than a simple ‚Äúoverbuild‚Äù must be considered, such as using smaller turbines as ‚Äúbackup‚Äù, batteries, or even a grid connection.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!aLdg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!aLdg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 424w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 848w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!aLdg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg" width="1456" height="769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:769,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1116192,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!aLdg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 424w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 848w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!aLdg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdac23d-4633-4d53-9af9-00056a9fe69c_2848x1504.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>To understand the overbuild ratio, we can use a practical example. In Shackelford County, TX, VoltaGrid is poweing a 1.4GW datacenter (IT capacity) with 2.3GW of Jembacher systems (64% overbuild). We can break this down in the following way:</p><ul><li><p>Peak PUE overbuild: as is typical for a grid-connected sites in Texas, there is a 1.4x - 1.5x over provisioning, largely related to cooling.</p></li><li><p>There is an additional 10-17% overbuild related to redundancy. </p></li></ul><p>For H/F class systems, a simple overbuild is often not the most economical path. Some operators are considering a grid connection solely for backup purposes - but that introduces interconnection timeline challenges, and complicates the site selection process (need access to high-voltage lines). A huge battery plant can also be built - as we illustrate below with xAI‚Äôs Colossus 2 deployment - but that‚Äôs both expensive and impractical, given 2-4hrs of typical storage duration. Lastly, a combination of different sizes of turbines and engines can be used, with H-class in combined-cycle mode operating as baseload, and IGTs/aeros/RICE as backup‚Äîbut that‚Äôs typically more expensive than a grid connection or a 2-4hr BESS.</p><p><span>AI compute load, particularly training, is highly variable, including megawatt-scale power surges and dips on a sub-second basis. The more </span><strong>inertia</strong><span> a power system has, the better it can manage short-term power fluctuations while maintaining power frequency. If frequency deviates too far from the 50 Hz or 60 Hz baseline, the power fluctuations can trip breakers or cause malfunctions. All thermal generators have some inertia, because they are generating electricity with a spinning heavy object. However, a developer can increase inertia with auxiliary systems:</span></p><ul><li><p><strong>Synchronous condensers</strong><span> ‚Äì These are essentially generators spun up as motors, with no mechanical load. Once synchronized to the grid, they consume only small losses. During sudden load changes, they absorb or supply </span><strong>reactive power</strong><span>, stabilizing voltage and adding short-duration inertia. Their energy capacity is small, so they help for seconds, not minutes.</span></p></li></ul><ul><li><p><strong>Flywheels</strong><span> ‚Äì These add a real rotational energy buffer. A motor-generator is coupled to a large flywheel and connected between generation and load. Flywheels can inject or absorb </span><strong>real power</strong><span> (not just reactive) for </span><strong>5‚Äì30 seconds</strong><span>, smoothing transients, generator trips, and voltage dips. Bergen, for example, packages flywheels alongside its engines via an affiliate vendor.</span></p></li></ul><ul><li><p><strong>Battery energy storage systems (BESS)</strong><span> ‚Äì Batteries can ramp as quickly as the load changes, providing ‚Äúsynthetic inertia‚Äù through high-speed control, </span><a href="https://newsletter.semianalysis.com/p/ai-training-load-fluctuations-at-gigawatt-scale-risk-of-power-grid-blackout" rel="">as described in an earlier article</a><span>. They excel at frequency regulation, but because inverters are current-limited, they contribute less to reactive power and fault currents than synchronous machines.</span></p></li></ul><p>VoltaGrid combines RICE fleets with synchronous condensers. Bergen Engines has sold engines with flywheels from a vendor under the same parent company. Engine manufacturer W√§rtsil√§ has a battery energy storage vertical that they may bundle with datacenter projects. Bloom claims that their fuel cell systems don‚Äôt need any equipment to manage load fluctuations. The exact system used depends a bit on local constraints and mostly on what the vendor prefers to use. xAI prefers to use Tesla‚Äôs Megapacks for backup and handling load fluctuations.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!vNpH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!vNpH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 424w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 848w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 1272w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!vNpH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png" width="1248" height="1118" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6498b055-e478-4700-9f7b-d33d8bc4a787_1248x1118.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1118,&quot;width&quot;:1248,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2170030,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6498b055-e478-4700-9f7b-d33d8bc4a787_1248x1118.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!vNpH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 424w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 848w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 1272w, https://substackcdn.com/image/fetch/$s_!vNpH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F881af022-a429-4287-bd7e-bdf87ed4337a_1248x1118.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Megapacks + MACROHARD</figcaption></figure></div><p>Current lead times for gas generation systems are unprecedented. Historically, gas turbine manufacturers have only taken orders on average 20 months in advance of shipment from factories, but now the Big Three of manufacturers, GE Vernova, Siemens Energy, and Mitsubishi Power, are accepting orders into 2028 and 2029, with nonrefundable reservation slots beyond that Every public manufacturer of gas systems reports rising datacenter demand, but most are responding with caution, not a full-send buildout.</p><ul><li><p><strong>GE Vernova</strong><span> has promised to increase production to </span><strong>24 GW/year</strong><span>, but that only returns them to its 2007‚Äì2016 levels. They are investing in new staff in machinery, but do not intend to increase factory footprint.</span></p></li><li><p><strong>Siemens Energy</strong><span> also plans to invest in production </span><em>without</em><span> increasing factory footprint. They are instead prioritizing price increases, leaning on service revenue, and prioritizing investments with short payback periods. They plan to scale annual capacity from ~20GW to &gt;30GW by 2028-30.</span></p></li><li><p><strong>Mitsubishi Heavy Industries</strong><span> has guided to increase gas turbine &amp; combined-cycle production by </span><strong>30%</strong><span> in recent earnings calls, contrary to </span><a href="https://www.bloomberg.com/news/articles/2025-08-31/mitsubishi-heavy-to-double-gas-turbine-capacity-as-demand-soars" rel="">Bloomberg reporting</a><span> about plans to double capacity by 2027.</span></p></li><li><p><strong>Caterpillar</strong><span> plans to double engine production and 2.5x turbine production between 2024 and 2030, but their Solar-branded turbine production averaged ~600 MW/year between 2020‚Äì2024, with a 2022 peak production of 1.2 GW.</span></p></li><li><p><strong>W√§rtsil√§</strong><span> has promised only incremental expansion, preferring to ‚Äúwait and see‚Äù on datacenter demand and preserve relationships with marine customers.</span></p></li></ul><p>Of the major gas generation manufacturers, only Bloom Energy, Caterpillar, and newcomer Boom Supersonic have announced ambitious expansion plans. Bloom Energy has claimed they can reach 2 GW/year of production capacity by end of 2026, and Boom Supersonic plans to reach 2 GW/year by end of 2028. At first glance, few manufacturers appear fully ‚ÄúAGI-pilled‚Äù despite surging demand. Some of that hesitation reflects real manufacturing limits; much of it reflects PTSD from 30 years of boom-bust cycles in gas generation. Notably, the worst bottlenecks are in heavy-duty turbines. Aeros, IGTs, and RICE systems are less constrained.</p><p><span>Since the mid-‚Äò90s, the gas turbine industry has seen </span><em>two</em><span> boom-bust cycles rock the industry. The first boom, between 1997 and 2002, was driven by electric power deregulation in parts of the United States, which pulled in new companies as </span><strong>independent power producers</strong><span>, as well as (ironically enough) high expectations of electric demand growth coming from the dotcom bubble, as popularized by the Huber and Mills paper ‚ÄúThe Internet Begins with Coal.‚Äù Large players like Calpine, Duke, Williams, and NRG placed block orders for turbines, sending GE Vernova (then GE Power) and Siemens Energy (then Siemens AG‚Äôs power segment) into lunar order volumes. GE shipped more than </span><strong>60 GW</strong><span> of gas turbines in 2001; Siemens peaked at </span><strong>20+ GW</strong><span> in 2002.</span></p><p><span>The crash came fast. The dot-com bubble burst, the Enron scandal shook the power trading business, and orders dried up, leaving GE and Siemens in a manufacturing winter for the next few years. The second ‚Äúboom‚Äù in the gas turbine industry was less a boom than a stabilization of orders. Between 2006 and 2016, GE averaged about </span><strong>20 GW/year</strong><span> of turbine shipments, and Siemens about </span><strong>15 GW/year</strong><span>. Then, between 2017 and 2022, the bottom fell out on the market, with both GE and Siemens seeing production lows under 10 GW/year.</span></p><p><span>These two large companies have both institutional memory of the Y2K gas turbine boom and recent memory of generationally low sales. Notably, Mitsubishi Heavy Industries has largely escaped these boom-bust cycles. Until extremely recently, MHI has sold a fraction of the hardware of GE Vernova and Siemens Energy. It has only become part of a ‚ÄúBig Three‚Äù because the larger companies have shrunk to its sales volume </span><em>and</em><span> other players like Alstom Energy and Westinghouse have shuttered or been acquired. This may in part explain MHI‚Äôs interest in expansion, although its supposed doubling plan has not been corroborated in earnings calls.</span></p><p>However, within gas turbines, even a guarantee of high future demand may not push forward increased production, because of internal bottlenecks in the production and logistics of gas turbine cores.</p><p>Gas turbine blades and vanes are among the high watermarks for civilizational technological competence, requiring an insane quality of metallurgy and machining to manufacture properly.</p><p>Turbine blades and vanes are among the most demanding components modern industry makes. Manufacturing them requires extraordinary metallurgical and machining precision. As a result, Western production is concentrated in four firms:</p><ul><li><p><strong>Precision Castparts Corporation (PCC)</strong></p></li><li><p><strong>Howmet Aerospace</strong></p></li><li><p><strong>Consolidated Precision Products (CPP)</strong></p></li><li><p><strong>Doncasters</strong></p></li></ul><p>These companies supply not only industrial and electrical gas turbines but also civilian and military jet engines as well. All except CPP have vertically-integrated metals supply, but they are a fraction of the size of their customers, and thus much more vulnerable to market shocks. The second gas turbine bust coincided with a COVID-driven slump in aerospace orders, meaning these companies have recently been hit quite hard. An increase in demand would require these companies not only to hire more specialized staff, but also to reckon with their supply chain for materials like yttrium, rhenium, single-crystal nickel, and cobalt. More importantly, they are likely reluctant to make these investments because they stand to lose the most if they follow an AI bubble off a cliff.</p><p>Additionally, heavy-duty gas turbine production is constrained by logistics. The turbine cores alone are 300-500-ton systems that need specialized barges, rail cars, and truck trailers to transport. Even after permitting, heavy-duty gas turbines need 24-30 months to build, install, and test before they are ready to run. Aftermarket OEMs can build new plants around refurbished cores, but moving and integrating those cores remains a major challenge. These constraints are less severe for aeros and IGTs, which are small enough to ship on standard containers or conventional trailers.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SPjw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SPjw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 424w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 848w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!SPjw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:310959,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.semianalysis.com/i/182091994?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!SPjw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 424w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 848w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!SPjw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F563ad592-27dd-4381-9f6e-7c30aa41be91_1619x1079.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Siemens SGT5-800H H-Class turbine on a self-propelled modular transport (SPMT). Source: </span><a href="https://w1.siemens.com.cn/press/NewsDetail_en.aspx?ColumnId=9&amp;ArticleId=7976" rel="">Siemens China</a></figcaption></figure></div><p>As often, in times of constraints, many smart firms are exploring solutions. ProEnergy was one of the first to come with innovations. Its PE6000 program retrofits CF6-80C2 engine cores from Boeing 747 and delivers operational aeroderivative gas turbines with near-identical specs and packaging to the GE Vernova LM6000.</p><p><span>More recently, Boom Supersonic has announced the development of the </span><strong>Superpower</strong><span> aeroderivative gas turbine, based on their supersonic jet engine design. Its proposed form factor looks remarkably similar to the GE Vernova LM2500, and it operates on the same principle: a small jet engine that can fit in one shipping container (with auxiliary intake, controls, and exhaust equipment fitting in 1-2 more shipping containers). Testing for this engine is still underway, but preliminary advertised specs suggest the Superpower will produce 42 MW per unit, even at high ambient air temperatures.</span></p><p>The first 1.2 GW of production has already been booked for Crusoe, with a targeted 200 MW of production in 2027 and 1 GW in 2028, and 2 GW in 2029. The initial order price suggests a hardware cost of $1,000/kW, but that figure does not include balance of plant, shipping, or commissioning, and should not be directly compared against all-in cost figures. Boom Supersonic have vertically integrated production for blade and vane production, but rely on external vendors for metallurgy, which may remain a supply chain bottleneck.</p><p>We haven‚Äôt yet seen other firms jump on the retrofit wagon. However, medium-speed engines are largely manufactured by firms with a long experience building ship engines ‚Äì such as W√§rtsila. In fact, they are largely the same engines and can be manufactured in the same facility. When will we see old ship engines retrofitted to power datacenters?</p><p>Let‚Äôs now turn our attention to comparing the different solutions and manufacturers. We‚Äôll also analyze the economics and TCO of onsite power generation, and compare it to the electric grid in the US.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When square pixels aren't square (108 pts)]]></title>
            <link>https://alexwlchan.net/2025/square-pixels/</link>
            <guid>46443988</guid>
            <pubDate>Wed, 31 Dec 2025 13:44:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexwlchan.net/2025/square-pixels/">https://alexwlchan.net/2025/square-pixels/</a>, See on <a href="https://news.ycombinator.com/item?id=46443988">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" tabindex="-1"><article><hgroup></hgroup><p>When I embed videos in web pages, I specify an <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/aspect-ratio">aspect ratio</a>. For example, if my video is 1920‚ÄØ√ó‚ÄØ1080 pixels, I‚Äôd write:</p><pre><code><span>&lt;video</span> <span>style=</span><span>"aspect-ratio: 1920 / 1080"</span><span>&gt;</span>
</code></pre><p>If I also set a width or a height, the browser now knows exactly how much space this video will take up on the page ‚Äì even if it hasn‚Äôt loaded the video file yet. When it initially renders the page, it can leave the right gap, so it doesn‚Äôt need to rearrange when the video eventually loads. (The technical term is ‚Äúreducing <a href="https://developer.mozilla.org/en-US/docs/Glossary/CLS">cumulative layout shift</a>‚Äù.)</p><p>That‚Äôs the idea, anyway.</p><p>I noticed that some of my videos weren‚Äôt fitting in their allocated boxes. When the video file loaded, it could be too small and get letterboxed, or be too big and force the page to rearrange to fit. Clearly there was a bug in my code for computing aspect ratios, but what?</p><h2 id="three-aspect-ratios-one-video">Three aspect ratios, one video</h2><p>I opened one of the problematic videos in QuickTime Player, and the resolution listed in the Movie Inspector was rather curious: <code>Resolution: 1920‚ÄØ√ó‚ÄØ1080 (1350‚ÄØ√ó‚ÄØ1080)</code>.</p><p>The first resolution is what my code was reporting, but the second resolution is what I actually saw when I played the video. Why are there two?</p><p>The <a href="https://en.wikipedia.org/wiki/Aspect_ratio_(image)#Distinctions"><strong>storage aspect ratio (SAR)</strong></a> of a video is the pixel resolution of a raw frame. If you extract a single frame as a still image, that‚Äôs the size of the image you‚Äôd get. This is the first resolution shown by QuickTime Player, and it‚Äôs what I was reading in my code.</p><p>I was missing a key value ‚Äì the <a href="https://en.wikipedia.org/wiki/Pixel_aspect_ratio"><strong>pixel aspect ratio (PAR)</strong></a>. This describes the shape of each pixel, in particular the width-to-height ratio. It tells a video player how to stretch or squash the stored pixels when it displays them. This can sometimes cause square pixels in the stored image to appear as rectangles.</p><figure id="pixel_aspect_ratios"><svg viewBox="0 0 95 170" aria-labelledby="svg_pixel_aspect_ratio_lt" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="25" x="0" y="0"></rect><rect height="50" width="25" x="35" y="0"></rect><rect height="50" width="25" x="70" y="0"></rect><rect height="50" width="25" x="0" y="60"></rect><rect height="50" width="25" x="35" y="60"></rect><rect height="50" width="25" x="70" y="60"></rect><rect height="50" width="25" x="0" y="120"></rect><rect height="50" width="25" x="35" y="120"></rect><rect height="50" width="25" x="70" y="120"></rect><title id="svg_pixel_aspect_ratio_lt">A 3√ó3 grid of pixels, where each pixel is a rectangle that's taller than it is wide.</title></svg><svg viewBox="0 0 170 170" aria-labelledby="svg_pixel_aspect_ratio_eq" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="50" x="0" y="0"></rect><rect height="50" width="50" x="60" y="0"></rect><rect height="50" width="50" x="120" y="0"></rect><rect height="50" width="50" x="0" y="60"></rect><rect height="50" width="50" x="60" y="60"></rect><rect height="50" width="50" x="120" y="60"></rect><rect height="50" width="50" x="0" y="120"></rect><rect height="50" width="50" x="60" y="120"></rect><rect height="50" width="50" x="120" y="120"></rect><title id="svg_pixel_aspect_ratio_eq">A 3√ó3 grid of pixels, where each pixel is a square.</title></svg><svg viewBox="0 0 320 170" aria-labelledby="svg_pixel_aspect_ratio_gt" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="100" x="0" y="0"></rect><rect height="50" width="100" x="110" y="0"></rect><rect height="50" width="100" x="220" y="0"></rect><rect height="50" width="100" x="0" y="60"></rect><rect height="50" width="100" x="110" y="60"></rect><rect height="50" width="100" x="220" y="60"></rect><rect height="50" width="100" x="0" y="120"></rect><rect height="50" width="100" x="110" y="120"></rect><rect height="50" width="100" x="220" y="120"></rect><title id="svg_pixel_aspect_ratio_gt">A 3√ó3 grid of pixels, where each pixel is a rectangle that's wider than it is tall.</title></svg><figcaption>PAR &lt; 1<br> portrait pixels</figcaption><figcaption>PAR = 1<br> square pixels</figcaption><figcaption>PAR &gt; 1<br> landscape pixels</figcaption></figure><p>This reminds me of <a href="https://alexwlchan.net/2025/create-thumbnail-is-exif-aware/">EXIF orientation</a> for still images ‚Äì a transformation that the viewer applies to the stored data. If you don‚Äôt apply this transformation properly, your media will look wrong when you view it. I&nbsp;wasn‚Äôt accounting for the pixel aspect ratio in my code.</p><p>According to Google, the primary use case for non-square pixels is standard-definition televisions which predate digital video. However, I‚Äôve encountered several videos with an unusual PAR that were made long into the era of digital video, when that seems unlikely to be a consideration. It‚Äôs especially common in vertical videos like YouTube Shorts, where the stored resolution is a square 1080‚ÄØ√ó‚ÄØ1080, and the aspect ratio makes it a portrait.</p><p>I wonder if it‚Äôs being introduced by a processing step somewhere? I don‚Äôt understand why, but I don‚Äôt have to ‚Äì I‚Äôm only displaying videos, not producing them.</p><p>The <a href="https://en.wikipedia.org/wiki/Display_aspect_ratio"><strong>display aspect ratio (DAR)</strong></a> is the size of the video as viewed ‚Äì what happens when you apply the pixel aspect ratio to the stored frames. This is the second resolution shown by QuickTime Player, and it‚Äôs the aspect ratio I should be using to preallocate space in my video player.</p><p>These three values are linked by a simple formula:</p><p>DAR = SAR‚Äâ√ó‚ÄâPAR</p><p>The size of the viewed video is the stored resolution times the shape of each pixel.</p><h2 id="the-stored-frame-may-not-be-what-you-see">The stored frame may not be what you see</h2><p>One video with a non-unit pixel aspect ratio is my download of <a href="https://www.youtube.com/watch?v=HHhyznZ2u4E">Mars EDL 2020 Remastered</a>. This video by Simeon Schmau√ü tries to match what the human eye would have seen during the landing of NASA‚Äôs <a href="https://en.wikipedia.org/wiki/Perseverance_rover"><em>Perseverance</em> rover</a> in 2021.</p><p>We can get the width, height, and <strong>sample aspect ratio</strong> (which is another name for pixel aspect ratio) using ffprobe:</p><pre><code><span>$</span><span> </span>ffprobe -v error <span>\</span>
      -select_streams v:0 <span>\</span>
      -show_entries stream=width,height,sample_aspect_ratio <span>\</span>
      <span>"Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4"</span>
<span>[STREAM]
width=1920
height=1080
sample_aspect_ratio=45:64
[/STREAM]
</span></code></pre><p>Here <code>1920</code> is the stored width, and <code>45:64</code> is the pixel aspect ratio. We can multiply them together to get the display width: <code>1920‚ÄØ√ó‚ÄØ45‚Äâ/‚Äâ64 = 1350</code>. This matches what I saw in QuickTime Player.</p><p>Let‚Äôs extract a single frame using <a href="https://ffmpeg.org/ffmpeg.html">ffmpeg</a>, to get the stored pixels. This command saves the 5000th frame as a PNG image:</p><pre><code><span>$</span><span> </span>ffmpeg <span>-i</span> <span>"Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4"</span> <span>\</span>
    <span>-filter</span>:v <span>"select=eq(n</span><span>\,</span><span>5000)"</span> <span>\</span>
    <span>-frames</span>:v 1 <span>\</span>
    frame.png
</code></pre><p>The image is 1920‚ÄØ√ó‚ÄØ1080 pixels, and it looks wrong: the circular parachute is visibly stretched.</p><picture><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.avif 750w,https://alexwlchan.net/images/2025/mars_edl_frame_raw_2x.avif 1500w" type="image/avif"><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.webp 750w,https://alexwlchan.net/images/2025/mars_edl_frame_raw_2x.webp 1500w" type="image/webp"><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.png 750w,https://alexwlchan.net/images/2025/mars_edl_frame_raw_2x.png 1500w" type="image/png"><img alt="Photo looking up towards a parachute against a dark brown sky. The parachute is made of white-and-orange segments, and is stretched horizontally. The circle is wider than it is tall." src="https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.png" width="750"></picture><p>Suppose we take that same image, but now apply the pixel aspect ratio. This is what the image is meant to look like, and it‚Äôs not a small difference ‚Äì now the parachute actually looks like a circle.</p><figure><picture><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.avif 750w" type="image/avif"><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.webp 750w" type="image/webp"><source sizes="(max-width: 750px) 100vw, 750px" srcset="https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.png 750w" type="image/png"><img alt="The same photo as before, but now the parachute is a circle." src="https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.png" width="750"></picture></figure><p>Seeing both versions side-by-side makes the problem obvious: the stored frame isn‚Äôt how the video is displayed. The video player in my browser will play it correctly using the pixel aspect ratio, but my layout code wasn‚Äôt doing that. I&nbsp;was telling the browser the wrong aspect ratio, and the browser had to update the page when it loaded the video file.</p><h2 id="getting-the-correct-display-dimensions-in-python">Getting the correct display dimensions in Python</h2><p>This is my old function for getting the dimensions of a video file, which uses a <a href="https://pypi.org/project/MediaInfo/">Python wrapper around MediaInfo</a> to extract the width and height fields. I&nbsp;now realise that this only gives me the storage aspect ratio, and may be misleading for some videos.</p><pre><code>from <span>pathlib</span> import <span>Path</span>

from <span>pymediainfo</span> import <span>MediaInfo</span>


def <span>get_storage_aspect_ratio</span><span>(</span><span>video_path</span><span>:</span> Path<span>)</span> -&gt; tuple<span>[</span>int<span>,</span> int<span>]:</span>
    <span>"""</span><span>
    Returns the storage aspect ratio of a video, as a width/height ratio.
    </span><span>"""</span>
    <span>media_info</span> = MediaInfo<span>.</span>parse<span>(</span>video_path<span>)</span>
    
    try<span>:</span>
        <span>video_track</span> = next<span>(</span>
            tr
            for tr <span>in</span> media_info<span>.</span>tracks
            if tr<span>.</span>track_type == <span>"</span><span>Video</span><span>"</span>
        <span>)</span>
    except StopIteration<span>:</span>
        raise ValueError<span>(</span><span>f</span><span>"</span><span>No video track found in </span><span>{</span>video_path<span>}</span><span>"</span><span>)</span>
    
    return video_track<span>.</span>width<span>,</span> video_track<span>.</span>height
</code></pre><p>I can‚Äôt find an easy way to extract the pixel aspect ratio using pymediainfo. It does expose a <code>Track.aspect_ratio</code> property, but that‚Äôs a string which has a rounded value ‚Äì for example, <code>45:64</code> becomes <code>0.703</code>. That‚Äôs close, but the rounding introduces a small inaccuracy. Since I can get the complete value from ffprobe, that‚Äôs what I‚Äôm doing in my revised function.</p><p>The new function is longer, but it‚Äôs more accurate:</p><pre><code>from <span>fractions</span> import <span>Fraction</span>
import <span>json</span>
from <span>pathlib</span> import <span>Path</span>
import <span>subprocess</span>


def <span>get_display_aspect_ratio</span><span>(</span><span>video_path</span><span>:</span> Path<span>)</span> -&gt; tuple<span>[</span>int<span>,</span> int<span>]:</span>
    <span>"""</span><span>
    Returns the display aspect ratio of a video, as a width/height fraction.
    </span><span>"""</span>
    <span>cmd</span> = <span>[</span>
        <span>"</span><span>ffprobe</span><span>"</span><span>,</span>
        <span>#
</span>        <span># verbosity level = error
</span>        <span>"</span><span>-v</span><span>"</span><span>,</span> <span>"</span><span>error</span><span>"</span><span>,</span>
        <span>#
</span>        <span># only get information about the first video stream
</span>        <span>"</span><span>-select_streams</span><span>"</span><span>,</span> <span>"</span><span>v:0</span><span>"</span><span>,</span>
        <span>#
</span>        <span># only gather the entries I'm interested in
</span>        <span>"</span><span>-show_entries</span><span>"</span><span>,</span> <span>"</span><span>stream=width,height,sample_aspect_ratio</span><span>"</span><span>,</span>
        <span>#
</span>        <span># print output in JSON, which is easier to parse
</span>        <span>"</span><span>-print_format</span><span>"</span><span>,</span> <span>"</span><span>json</span><span>"</span><span>,</span>
        <span>#
</span>        <span># input file
</span>        str<span>(</span>video_path<span>)</span>
    <span>]</span>
    
    <span>output</span> = subprocess<span>.</span>check_output<span>(</span>cmd<span>)</span>
    <span>ffprobe_resp</span> = json<span>.</span>loads<span>(</span>output<span>)</span>
    
    <span># The output will be structured something like:
</span>    <span>#
</span>    <span>#   {
</span>    <span>#       "streams": [
</span>    <span>#           {
</span>    <span>#               "width": 1920,
</span>    <span>#               "height": 1080,
</span>    <span>#               "sample_aspect_ratio": "45:64"
</span>    <span>#           }
</span>    <span>#       ],
</span>    <span>#       ‚Ä¶
</span>    <span>#   }
</span>    <span>#
</span>    <span># If the video doesn't specify a pixel aspect ratio, then it won't
</span>    <span># have a `sample_aspect_ratio` key.
</span>    <span>video_stream</span> = ffprobe_resp<span>[</span><span>"</span><span>streams</span><span>"</span><span>][</span><span>0</span><span>]</span>
    
    try<span>:</span>
        <span>pixel_aspect_ratio</span> = Fraction<span>(</span>
            video_stream<span>[</span><span>"</span><span>sample_aspect_ratio</span><span>"</span><span>].</span>replace<span>(</span><span>"</span><span>:</span><span>"</span><span>,</span> <span>"</span><span>/</span><span>"</span><span>)</span>
        <span>)</span>
    except KeyError<span>:</span>
        <span>pixel_aspect_ratio</span> = <span>1</span>
    
    <span>width</span> = round<span>(</span>video_stream<span>[</span><span>"</span><span>width</span><span>"</span><span>]</span> * pixel_aspect_ratio<span>)</span>
    <span>height</span> = video_stream<span>[</span><span>"</span><span>height</span><span>"</span><span>]</span>
    
    return width<span>,</span> height
</code></pre><p>This is calling the <code>ffprobe</code> command I showed above, plus <code>-print_format json</code> to print the data in JSON, which is easier for Python to parse.</p><p>I have to account for the case where a video doesn‚Äôt set a sample aspect ratio ‚Äì in that case, the displayed video just uses square pixels.</p><p>Since the aspect ratio is expressed as a ratio of two integers, this felt like a good chance to try the <a href="https://docs.python.org/3.13/library/fractions.html"><code>fractions</code> module</a>. That avoids converting the ratio to a floating-point number, which potentially introduces inaccuracies. It doesn‚Äôt make a big difference, but in my video collection treating the aspect ratio as a <code>float</code> produces results that are 1 or 2 pixels different from QuickTime Player.</p><p>When I multiply the stored width and aspect ratio, I‚Äôm using the <a href="https://docs.python.org/3.13/library/functions.html#round"><code>round()</code> function</a> to round the final width to the nearest integer. That‚Äôs more accurate than <code>int()</code>, which always rounds down.</p><h2 id="conclusion-use-display-aspect-ratio">Conclusion: use display aspect ratio</h2><p>When you want to know how much space a video will take up on a web page, look at the display aspect ratio, not the stored pixel dimensions. Pixels can be squashed or stretched before display, and the stored width/height won‚Äôt tell you that.</p><p>Videos with non-square pixels are pretty rare, which is why I ignored this for so long. I‚Äôm glad I finally understand what‚Äôs going on.</p><p>After switching to ffprobe and using the display aspect ratio, my pre-allocated video boxes now match what the browser eventually renders ‚Äì no more letterboxing, no more layout jumps.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Happy New Year (247 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46443744</link>
            <guid>46443744</guid>
            <pubDate>Wed, 31 Dec 2025 13:02:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46443744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46444834"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444834" href="https://news.ycombinator.com/vote?id=46444834&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>2025 highlights</p><p>- Got 300+ stars on GitHub for my free, open-source project EasyInvoicePDF
<a href="https://github.com/VladSez/easy-invoice-pdf" rel="nofollow">https://github.com/VladSez/easy-invoice-pdf</a></p><p>- Received a lot of great and useful feedback about my project on social media</p><p>- Moved to a new apartment - better and bigger</p><p>- Lost 5+ kg and exercised more than last year</p><p>- Visited Hungary, Austria, and Italy for the first time - Hungary and Italy exceeded expectations</p><p>- My project was featured in a large startup-related Telegram channel (50k+ subscribers)</p><p>Happy New Year</p></div></td></tr></tbody></table></td></tr><tr id="46444512"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444512" href="https://news.ycombinator.com/vote?id=46444512&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>Happy New Year, everyone. To the entrepreneurs, may you get sticky customers with negative churn, and may they subscribe to your highest $$ plan.</p></div></td></tr></tbody></table></td></tr><tr id="46444809"><td></td></tr><tr id="46444275"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444275" href="https://news.ycombinator.com/vote?id=46444275&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>2025 wrap</p><p>Got an internship</p><p>Rejected a lowpay job offer</p><p>Quit the 9 ‚Äì 5</p><p>Built my own SaaS in 15 days as a self-taught dev</p><p>Got 250+ users on my app</p><p>Made my first sales before even consuming my 1-month stipend savings</p><p>Crossed $100+ in December revenue</p><p>Learned coding + marketing</p><p>Didn‚Äôt skip the gym</p><pre><code>  Deadlift PR: 400 lbs @ 130 lbs BW

 Betting on myself in 2026

 Happy New Year</code></pre></div></td></tr></tbody></table></td></tr><tr id="46444942"><td></td></tr><tr id="46444658"><td></td></tr><tr id="46444803"><td></td></tr><tr id="46444519"><td></td></tr><tr id="46444532"><td></td></tr><tr id="46444504"><td></td></tr><tr id="46444945"><td></td></tr><tr id="46444146"><td></td></tr><tr id="46444928"><td></td></tr><tr id="46444920"><td></td></tr><tr id="46444230"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444230" href="https://news.ycombinator.com/vote?id=46444230&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>Happy New Year from Shenzhen. Countdown in 1h45m. If anyone in Shenzhen wants to cheers, I shall be at Revolucion Cocktail.</p></div></td></tr></tbody></table></td></tr><tr id="46444654"><td></td></tr><tr id="46444428"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444428" href="https://news.ycombinator.com/vote?id=46444428&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>I wish everyone a gentle start into the new year, and that it may bring you much health, love, and joy!</p><p>May 2026 be a much, much better year than this one!</p></div></td></tr></tbody></table></td></tr><tr id="46444755"><td></td></tr><tr id="46444122"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444122" href="https://news.ycombinator.com/vote?id=46444122&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>I wonder what events will transpire that will shape our world by this time next year.</p><p>There will be a new FIFA World Cup champion unless Argentina does the unthinkable.</p><p>No doubt regime change somewhere. Probably a massive cyber event that cripples critical infra. A magnitude 8+ earthquake in a populated area?</p></div></td></tr></tbody></table></td></tr><tr id="46444508"><td></td></tr><tr id="46444505"><td></td></tr><tr id="46444520"><td></td></tr><tr id="46444416"><td></td></tr><tr id="46444897"><td></td></tr><tr id="46444081"><td></td></tr><tr id="46444815"><td></td></tr><tr id="46444003"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444003" href="https://news.ycombinator.com/vote?id=46444003&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>Exactly one year ago, we started tirreno on New Year‚Äôs night at Show HN.
Today, we‚Äôre nearly at 1k stars and dozens of releases in.</p><p>Thanks so much, HN, for this year.</p><p>H_N_Y from the Alps!</p></div></td></tr></tbody></table></td></tr><tr id="46444239"><td></td></tr><tr id="46444705"><td></td></tr><tr id="46444779"><td></td></tr><tr id="46444560"><td></td></tr><tr id="46444362"><td></td></tr><tr id="46444588"><td></td></tr><tr id="46444351"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46444351" href="https://news.ycombinator.com/vote?id=46444351&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>Happy New Year's Eve.</p><p>Hoping to see the start of the AI-powered technological singularity in 2026. The end of humanity is nigh and I can't wait to be melded to the machine. This life was kind of boring anyway.</p></div></td></tr></tbody></table></td></tr><tr id="46444342"><td></td></tr><tr id="46444248"><td></td></tr><tr id="46443827"><td></td></tr><tr id="46444593"><td></td></tr><tr id="46444252"><td></td></tr><tr id="46444182"><td></td></tr><tr id="46443991"><td></td></tr><tr id="46444522"><td></td></tr><tr id="46444496"><td></td></tr><tr id="46444039"><td></td></tr><tr id="46444021"><td></td></tr><tr id="46444269"><td></td></tr><tr id="46444498"><td></td></tr><tr id="46444293"><td></td></tr><tr id="46443913"><td></td></tr><tr id="46444142"><td></td></tr><tr id="46444651"><td></td></tr><tr id="46444321"><td></td></tr><tr id="46443882"><td></td></tr><tr id="46444276"><td></td></tr><tr id="46444198"><td></td></tr><tr id="46444347"><td></td></tr><tr id="46444209"><td></td></tr><tr id="46444185"><td></td></tr><tr id="46444068"><td></td></tr><tr id="46444097"><td></td></tr><tr id="46443966"><td></td></tr><tr id="46443972"><td></td></tr><tr id="46443962"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46443962" href="https://news.ycombinator.com/vote?id=46443962&amp;how=up&amp;goto=item%3Fid%3D46443744"></a></center></td><td><br>
<div><p>Happy New Year from Arkansas, USA!</p><p>This year let‚Äôs all act kindly towards others and learn and discuss things in civil tones.  In a world where Reddit is the norm, make Hacker News a beacon of hope.</p></div></td></tr></tbody></table></td></tr><tr id="46444916"><td></td></tr><tr id="46443897"><td></td></tr><tr id="46443907"><td></td></tr><tr id="46444308"><td></td></tr><tr id="46443748"><td></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The most famous transcendental numbers (140 pts)]]></title>
            <link>https://sprott.physics.wisc.edu/pickover/trans.html</link>
            <guid>46443579</guid>
            <pubDate>Wed, 31 Dec 2025 12:32:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sprott.physics.wisc.edu/pickover/trans.html">https://sprott.physics.wisc.edu/pickover/trans.html</a>, See on <a href="https://news.ycombinator.com/item?id=46443579">Hacker News</a></p>
<div id="readability-page-1" class="page">


<b><a href="http://www.pickover.com/">Cliff Pickover</a></b>.
Follow me on <a href="http://twitter.com/pickover">Twitter</a> 
<p>

<a href="https://sprott.physics.wisc.edu/pickover/noodlead.html"><img src="https://sprott.physics.wisc.edu/pickover/noodlelit.jpg"></a>
I am in love with the mysterious transcendental numbers.
Did you know that there
are "more" transcendental numbers than the more familiar 
algebraic ones?  Even so, only a few classes of transcendental numbers are widley known 
to humans, and it's very difficult to prove that a particular
number is transcendental.  
In 1844, math genius Joseph Liouville (1809-1882) 
 was the first to prove the existence of transcendental
 numbers. 
 (More precisely, he was the first to prove that a specific number was 
transcendental.)
 
Hermite proved that the number <i>e</i>
was transcendental in 1873. Lindeman proved that pi was transcendental in 1882.
For more information, see my book
<a href="https://sprott.physics.wisc.edu/pickover/noodlead.html">Wonders
of Numbers</a>
from
which this is excerpted.
</p><!--
<center>
Pickover Navigation Bar:  <a href="/pickover/contact.html"
onmouseover="image2.src='buttonon.jpg';" onmouseout="image2.src='contactoff.jpg';"><img name="image2"src="contactoff.jpg" border=0></a><a href="/pickover/pc/realitycarnival.html"
onmouseover="image3.src='buttonon.jpg';"onmouseout="image3.src='newsoff.jpg';"><img name="image3" src="newsoff.jpg" border=0></a><a href="bookscp.html"
onmouseover="image4.src='buttonon.jpg';"onmouseout="image4.src='booksoff.jpg';"><img name="image4" src="booksoff.jpg" border=0></a><a href="home.htm"
onmouseover="image5.src='buttonon.jpg';" onmouseout="image5.src='homeoff.jpg';"><img name="image5"src="homeoff.jpg" border=0></a>
</center> <BR>
-->
<div>

<p><img width="150" height="100" src="https://sprott.physics.wisc.edu/pickover/ant.jpg">          The mathematical constant pi represents
the ratio of the circumference of a circle to its
diameter. It is the most famous ratio in mathematics both on Earth and
probably for any advanced civilization in the universe.  The number pi,
like other fundamental constants of mathematics such as e = 2.718...,
is a transcendental number. The digits of pi and e never end, nor has
anyone detected an orderly pattern in their arrangement.  Humans know
the value of pi to over a trillion digits.
</p><p>
    Transcendental numbers cannot be expressed as the root of any
algebraic equation with rational coefficients.  This means that pi
could not exactly satisfy equations of the type: pi<sup>2</sup> = 10, or
9pi<sup>4</sup> -
240pi<sup>2</sup>  + 1492 = 0. These are equations involving simple integers with
powers of pi. The numbers pi and e can be expressed as an endless
continued fraction or as the limit of an infinite series. The
remarkable fraction 355/113 expresses pi accurately to six decimal
places.
</p><p>
In 1882, German mathematician F. Lindemann proved that
pi
is transcendental, finally putting an end to 2,500 years
of speculation.
In effect, he proved that
pi
transcends the power of algebra to display it in its totality.
It can't be expressed in any finite series of arithmetical or
algebraic operations.  Using a fixed-size font, it can't be written on a piece of paper
as big as the universe.
</p><p>
I also talk about all the mysteries of pi in my
<a href="https://sprott.physics.wisc.edu/pickover/bookscp.html">book</a> <i>Keys to Infinity</i>.

</p><p>
     Many of you have probably heard of pi and e.  But are there other
famous transcendental numbers?  After conducting a brief survey of
readers, I made a list of the fifteen most famous
transcendental numbers.   Can you list these in order of relative fame
and/or usage?

</p></div><ol>
<li>
pi = 3.1415 ...
</li><li>
e = 2.718 ...
</li><li>Euler's constant,
gamma = 0.577215 ...
= lim n -&gt; infinity &gt; (1 + 1/2 + 1/3
+ 1/4 + ... + 1/n - ln(n))
(Not proven to be transcendental, but generally believed to be
by mathematicians.)

</li><li>Catalan's constant,
G = sum  (-1)^k / (2k + 1 )^2 =
1 - 1/9 + 1/25 - 1/49 + ...

(Not proven to be transcendental, but generally believed to be
by mathematicians.)

</li><li>Liouville's number
0.110001000000000000000001000 ...
which has a one in the 1st, 2nd, 6th, 24th, etc. places and zeros
elsewhere.

</li><li>Chaitin's "constant", the probability that a random
algorithm halts.  (Noam Elkies of Harvard notes that not only is this
number
transcendental but it is also incomputable.)

</li><li>Chapernowne's
number, 0.12345678910111213141516171819202122232425...
This is constructed by concatenating the digits of the positive
integers.
(Can you see the pattern?)

</li><li>Special values of the zeta function, such as
zeta (3).
(Transcendental functions can usually be expected to give
transcendental results at rational points.)

</li><li>
ln(2).

</li><li>Hilbert's number,
2<sup>(sqrt 2 )</sup>.
(This is called Hilbert's number because the proof of whether or
not it is transcendental was one of Hilbert's
famous problems.
In fact, according to the Gelfond-Schneider theorem, any number
of the form
a<sup>b</sup>
is transcendental where
a
and
b
are algebraic
(a ne 0, a ne 1 )
and
b
is not a rational number.
Many
trigonometric or hyperbolic functions of non-zero algebraic numbers
are transcendental.)

</li><li>
e<sup>pi</sup>

</li><li>
pi<sup>e</sup>
(Not proven to be transcendental, but generally believed to be
by mathematicians.)

</li><li>Morse-Thue's number, 0.01101001 ...

</li><li>
i<sup>i</sup> = 0.207879576... 
(Here
i
is the imaginary number
sqrt(-1).  Isn't this a real beauty?  How many people have actually
considered rasing i to the i power?
If
a
is algebraic and
b
is algebraic but irrational
then
a<sup>b</sup>
is transcendental.  Since
i
is algebraic but irrational, the theorem applies.
Note also:
i<sup>i</sup>
is equal to
e<sup>(- pi / 2 )</sup>
and several other values.
Consider
i<sup>i</sup> = e<sup>(i log i )</sup> =
e<sup>( i times i pi / 2 )</sup> .
Since log is multivalued, there are other possible values for
i<sup>i</sup>.
<br>Here is how you can compute the value of i<sup>i</sup> = 0.207879576... 
<blockquote>
1. Since e^(ix) = Cos x + i Sin x, then let x = Pi/2.
<br>
2. Then e^(iPi/2) = i = Cos Pi/2 + i Sin Pi/2; since Cos Pi/2 = Cos 
90 deg. = 0. But Sin 90 = 1 and i Sin 90 deg. = (i)*(1) = i.
<br>
3. Therefore e^(iPi/2) = i.
<br>
4. Take the ith power of both sides, the right side being i^i and 
the 
left side = [e^(iPi/2)]^i = e^(-Pi/2).
<br>
5. Therefore i^i = e^(-Pi/2) = .207879576... 
</blockquote>



</li><li>Feigenbaum numbers, e.g.
4.669 ... .
(These are related to properties of dynamical systems with
period-doubling.  The ratio of successive differences between
period-doubling bifurcation parameters approaches the number
4.669 ... ,
and it has been discovered in many physical systems before
they enter the chaotic regime.  It has not been proven
to be transcendental, but is generally believed to be.)
</li></ol>
Long ago, Keith Briggs from the Mathematics Department of the
University of Melbourne in Australia
computed what he believed to be the world-record
for the number of digits for the Feigenbaum number:
<blockquote>
4.
669201609102990671853203820466201617258185577475768632745651
343004134330211314737138689744023948013817165984855189815134
408627142027932522312442988890890859944935463236713411532481
714219947455644365823793202009561058330575458617652222070385
410646749494284981453391726200568755665952339875603825637225
</blockquote>
Briggs carried out the computation using special-purpose
software designed by David Bailey of NASA Ames running
on an IBM RISC System/6000.  The computation required a few
hours of computation time.
<p>
Today, we know far more digits for the Feigenbaum constant.  See <a href="http://converge.to/feigenbaum/">this page</a>
for more than 10,000 digits. 

<!--  Related fascinating information can be found 
<a href=https://juliacomputing.com/blog/2017/11/27/high-precision-feigenbaum-alpha-calc-using-julia.html>here</a>.
-->



</p><h3>Ants and Transcendental Numbers</h3>
<img width="150" height="100" src="https://sprott.physics.wisc.edu/pickover/ant.jpg"> Imagine  a race of talking ants.
    The ants can compress
the infinite digits of
pi
in an interesting way.  For example, let us
imagine that the ants can speak by manipulating their crude jaws.
The first ant in the long parade of ants screams out the first
digit,
"3".  The next yells the number on its back, a
"1". The
next yells a "4", and so on.  Further imagine that each ant
speaks its digit in
only half the time of the preceding ant.  Each ant has a turn to
speak.  Only the most recent digit is spoken at any instant.  If
the first digit of
pi
requires 30
seconds to speak (due to the ant's cumbersome jaws and little
brain), might the entire ant colony will speak <i>all</i> the
digits of
pi
in
a minute?
(Again, this
is because
the infinite
sum
1/2 minute + 1/4 minute + 1/8 minute + ...
is equal to 1 minute.)

    Astoundingly, at the end of the minute, might there be a
quick-talking ant that will actually say the "last" digit of
pi?
The geometer God, upon
hearing this last digit, may cry, "That's impossible,
because
pi
has no last digit!" <br>(See below for an email from Brian B. on the talking ants.)
<p> Here are some nice web pages on transcendental numbers:
<a target="trans" href="https://web.archive.org/web/20080621143903/http://mathforum.org/library/drmath/sets/high_transcendental.html">1</a>,
<a target="trans" href="http://mathworld.wolfram.com/TranscendentalNumber.html">2</a>, and
<a target="trans" href="http://www.wikipedia.org/wiki/Transcendental_number">3</a>.
</p><p>

 
Here is a
<a href="https://sprott.physics.wisc.edu/pickover/noodlead.html">book</a> on transcendental numbers.

</p><h3>Dottie Number</h3>

Dottie number is the unique real root of cosx = x (namely, the unique real fixed point of the cosine function), which is 0.739085...
<br>
<img src="http://mathworld.wolfram.com/images/eps-gif/CosineFixedPoint_800.gif">
<br>
Dottie noticed that whenever she typed a number into her calculator and pressed the cosine button repeatedly, the result always converged to this value.
Wow. The number is well-known, having appeared in numerous elementary works on algebra already by the late 1880s.
The Dottie number is transcendental as a consequence of the the Lindemann-Weierstrass theorem. 
This text about Dottie is adpoted from <a href="http://mathworld.wolfram.com/DottieNumber.html">MathWorld</a>.

<h3>Comments from Colleagues on <br>
Their Passion for Transcendental Numbers</h3>

RM Mentock comments:
<blockquote>
Although they are not often recognized as such even by mathematicians,
there are a lot of commonly-used numbers that are also transcendental,
which can easily be shown by the Gelfond-Schneider theorem mentioned
in the tenth item on the list.  If a is algebraic, and c is algebraic,
and b = logarithm (base a) of c is not rational, then b must be
transcendental or else the theorem would imply that c must be
transcendental--a contradiction.  Then, with a=10 and c=2, the log of
two, base ten, is transcendental, and so is any base ten logarithm of
any rational number other than rational powers of ten.  The same holds
for any other rational logarithm base--so there are a lot of transcendental
numbers that are in common use.  Or they were forty years ago, before
handheld calculators!
    <p>
I'd also like to point out that any number can be used to produce a
transcendental by using Liouville's algorithm (see item number five).  If
the number is terminating, convert it to non-terminating by subtracting one
from the last digit, and adding an infinite string of 9's to the end.  Then
just put each of its digits where Liouville puts a one, even if the digit is
zero.  The result will be a transcendental number.
</p></blockquote>
<p>
Brian B. comments on the talking ants above:</p><blockquote>
On your transcendental number page (https://sprott.physics.wisc.edu/Pickover/trans.html), you say: "Astoundingly, at the end of the minute, there will be a quick-talking ant that will actually say the 'last' digit of pi!"

 

This is not correct. There is no last ant in an infinite line of ants, just as there's no last digit of pi. 
This can be seen easily by having all the ants announce their digit at exactly the same time.
It takes zero seconds to say all the digits, but there is still no last digit, or last ant. 
Or forget about the ants entirely and just have each digit announce itself at the same moment.
 Still no last digit, though, just like there's no end to the natural numbers.

 

I hope you'll fix this on your page. I think it would probably be best just to remove the entire "ant" section. Thanks.
</blockquote>
<center>
  <a target="_blank" href="https://sprott.physics.wisc.edu/pickover/math-book.html"><img width="200" height="219" src="https://sprott.physics.wisc.edu/pickover/mathbook-litcover.jpg"></a>
  ‚Üê Interested in more mathematical weirdness through history?
  </center>
<p>
This page has been translated into perfect Russian, <a target="_blank" href="https://mygpstools.com/15-samykh-izvestnykh-transcendentnykh-chisel">here</a>.

</p><hr>
<a href="https://sprott.physics.wisc.edu/pickover/home.htm">
Return to Cliff Pickover's home page </a> which includes
the Wishing Project
cataloging wishes from various cultures,
computer art, educational puzzles,
fractals, virtual caverns, JAVA/VRML, alien creatures, black hole
artwork, and animations.

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Akin's Laws of Spacecraft Design [pdf] (261 pts)]]></title>
            <link>https://www.ece.uvic.ca/~elec399/201409/Akin%27s%20Laws%20of%20Spacecraft%20Design.pdf</link>
            <guid>46442903</guid>
            <pubDate>Wed, 31 Dec 2025 10:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ece.uvic.ca/~elec399/201409/Akin%27s%20Laws%20of%20Spacecraft%20Design.pdf">https://www.ece.uvic.ca/~elec399/201409/Akin%27s%20Laws%20of%20Spacecraft%20Design.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=46442903">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The rise of industrial software (209 pts)]]></title>
            <link>https://chrisloy.dev/post/2025/12/30/the-rise-of-industrial-software</link>
            <guid>46442597</guid>
            <pubDate>Wed, 31 Dec 2025 09:09:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrisloy.dev/post/2025/12/30/the-rise-of-industrial-software">https://chrisloy.dev/post/2025/12/30/the-rise-of-industrial-software</a>, See on <a href="https://news.ycombinator.com/item?id=46442597">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><blockquote>
<p><em><strong>Industrial</strong></em></p>
<p><em>adj. (sense 3a)</em></p>
<p>Of or relating to productive work, trade, or manufacture, esp. mechanical industry or large-scale manufacturing; (
also) resulting from such industry.</p>
<p>‚Äî<em>Oxford English Dictionary</em></p>
</blockquote>
<p>For most of its history, software has been closer to craft than manufacture: costly, slow, and dominated by the need for
skills and experience. AI coding is changing that, by making available paths of production which are cheaper, faster,
and increasingly disconnected from the expertise of humans.</p>
<p>I have written previously about how <a href="https://chrisloy.dev/post/2025/09/28/the-ai-coding-trap">AI coding can be a trap</a>
for today‚Äôs practitioners, offering shortcuts to incomplete solutions at the expense of the understanding needed for
sustainable development practices. But as we collectively address the shortcomings of our current toolset, it is clear
that we are heading into a world in which the production of software is becoming increasingly automated.</p>
<p>What happens to software when its production undergoes an <em>industrial revolution</em>?</p>
<h2>Software as a disposable commodity</h2>
<p>Traditionally, software has been expensive to produce, with expense driven largely by the labour costs of a highly
skilled and specialised workforce. This workforce has also constituted a bottleneck for the possible scale of
production, making software a valuable commodity to produce effectively.</p>
<p>Industrialisation of production, in any field, seeks to address both of these limitations at once, by using automation
of processes to reduce the reliance on human labour, both lowering costs and also allowing greater scale and elasticity
of production. Such changes relegate the human role to oversight, quality control, and optimisation of the industrial
process.</p>
<p>The first order effect of this change is a disruption in the supply chain of high quality, working products. Labour is
disintermediated, barriers to entry are lowered, competition rises, and rate of change accelerates. All of these effects
are starting to be in evidence today, with the traditional software industry grappling with the ramifications.</p>
<p>A second order effect of such industrialisation is to enable additional ways to produce low quality, low cost products
at high scale. Examples from other fields include:</p>
<ul>
<li>industrialisation of printing processes led to paperback genre fiction</li>
<li>industrialisation of agriculture led to ultraprocessed junk food</li>
<li>industrialisation of digital image sensors led to user-generated video</li>
</ul>
<p>In the case of software, the industrialisation of production is giving rise to a new class of software artefact, which
we might term <em>disposable software</em>: software created with no durable expectation of ownership, maintenance, or
long-term understanding.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-1.svg" alt="Where traditional software is high cost and high value, disposable software is low cost and low value." title="Where traditional software is high cost and high value, AI disposable software is low cost and low value."></p>
<p>Advocates might refer to this as <em>vibe-coded software</em>, and sceptics will invariably talk about <em>AI slop</em>. Regardless of
its merits, it is clear that the economics of this class of software are quite different, as each software output has
less economic value, due to its easy reproducibility. This lack of perceived value might tempt you to dismiss the trend as
a passing fad, but this would be unwise. To understand why, we need to consider the historical precedents for
commoditisation of previously scarce goods.</p>
<h2>Jevons paradox and the addictive nature of slop</h2>
<p><a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons paradox</a>
is an old bit of economic theory that has been much quoted recently. The observation dates to the
nineteenth century, noting that improved efficiency in coal consumption would lead to lower costs, fueling higher
demand, and ultimately resulting in higher overall coal consumption.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-2.svg" alt="Jevons paradox describes how increased efficiency can result in higher overall consumption." title="Jevons paradox describes how increased efficiency can result in higher overall consumption."></p>
<p>This is relevant today, because we are seeing the same surge in demand for AI compute: as models become more efficient
at token prediction, demand is surging and results in ever greater consumption. Will the same effect ripple through
software development itself, with lower cost of effort driving higher consumption and output? History suggests it will.</p>
<p>Consider the industrialisation of agriculture. In the early twentieth century, scientific advances were expected to
eradicate hunger and usher in an era of abundant, nourishing food. Instead, hunger and famine persist. In 2025, there
are <a href="https://www.wfp.org/ending-hunger">318 million people experiencing acute hunger</a>, even in countries with an
agricultural surplus. Meanwhile, in the wealthiest nations, industrial food systems have produced abundance of a
different kind: the United States has an adult obesity rate of 40% and a growing diabetes crisis. Ultraprocessed foods
are widely recognised as harmful,
yet <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8408879/">the overwhelming majority of Americans consume them each day</a>.</p>
<p>Industrial systems reliably create economic pressure toward excess, low quality goods. This is not because producers are
careless, but because
once production is cheap enough, junk is what maximises volume, margin, and reach. The result is not abundance of the
best things, but overproduction of the most consumable ones. And consume them we do.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-3.svg" alt="The economic pressure of industrialisation will drive adoption of disposable software." title="The economic pressure of industrialisation will drive adoption of disposable software."></p>
<p>Our appetite for AI slop is likely to be similarly insatiable. The adoption curve we‚Äôve seen so far may pale beside what
happens when disposable software production becomes truly mainstream. If the democratisation of software mirrors the
impact of ubiquitous photo, video, and audio capture enabled by the smartphone, we may see user-generated software
created, shared, and discarded at social-media scale. Should that happen, the feedback loops of novelty and reward will
drive an explosion of software output that makes the past half-century of development look quaint by comparison.</p>
<h2>Will traditional software survive?</h2>
<p>Ultraprocessed foods are, of course, not the only game in town. There is a thriving and growing demand for healthy,
sustainable production of foodstuffs, largely in response to the harmful effects of industrialisation. Is it possible
that software might also resist mechanisation through the growth of an ‚Äúorganic software‚Äù movement? If we look at other
sectors, we see that even those with the highest levels of industrialisation also still benefit from small-scale,
human-led production as part of the spectrum of output.</p>
<p>For example, prior to industrialisation, clothing was largely produced by specialised artisans, often coordinated
through guilds and manual labour, with resources gathered locally, and the expertise for creating durable fabrics
accumulated over years, and frequently passed down in family lines. Industrialisation changed that completely, with raw
materials being shipped intercontinentally, fabrics mass produced in factories, clothes assembled by machinery, all
leading to today‚Äôs world of fast, disposable, exploitative fashion. And yet handcrafted clothes still exist: from
tailored suits to knitted scarves, a place still exists for small-scale, slow production of textile goods, for reasons
ranging from customisation of fit, signalling of wealth, durability of product, up to enjoyment of the craft as a
pastime.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-4.svg" alt="Might human written software become little more than a boutique industry?" title="Might human written software become little more than a boutique industry?"></p>
<p>So, might human-written software be confined to niches mirroring high fashion or homemade knitwear? That might have been
the case were software a physical product, in which industrialisation could lead to mass production of reusable
components. But software is an intangible good, and unlike other industrialised fields, it has a long history of
component reuse that is intrinsic to the nature of the good itself. Innovation is not limited to better or cheaper
versions of existing products, as with clothing, but also encompasses growth of the solution space, more akin to how the
steam engine enabled reusable machine parts, enabled the production line, enabled the motor car, etc.</p>
<p>As such, the mechanism for technological progress in the history of software development has been not only
industrialisation, but also innovation. Research and development is expensive, but offers the only path to greater value
over time.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-5.svg" alt="Innovation is the historical and future driver of increased value from software." title="Innovation is the historical and future driver of increased value from software."></p>
<p>Innovation is fundamentally different to industrialisation, because it is not focused on more efficiently replicating
what already exists today. It instead advances through finding and solving new problems, building on what came before,
and delivering capabilities that could not previously have existed. Industrialisation <em>then</em> steps in and provides scale
and commoditisation, providing a foundation upon which the next round of innovation can build. The interplay of these
two forces is what we term <em>progress</em>.</p>
<h2>The endless cycle of progress</h2>
<p><a href="https://chrisloy.dev/post/2025/08/03/context-engineering">Large language models</a> are a steam engine moment for
software. They collapse the cost of a class of work previously fully dependent on scarce human labour, and in doing so
unlock an extraordinary acceleration in output.</p>
<p>But remember that the steam engine did not appear in a vacuum. Windmills and watermills preceded turbines by centuries.
Mechanisation did not begin with coal and steel; it merely reached an inflection point at which automation, scale, and
capital aligned to power economic transformation. Similarly, software has been industrialising for a long time: through
reusable components (open source code), portability (containerisation, the cloud), democratisation (low-code / no-code
tools), interoperability (API standards, package managers) and many other ways.</p>
<p>We are entering an industrial revolution for software, then, not as a moment of rupture, but one of huge acceleration.
Industrialisation does not replace technological progress, but it will greatly accelerate both the absorption of new
ideas and the commoditisation of new capabilities. In turn, innovation is more quickly unlocked, as the cost of building
on top of novel technology drops more quickly. The cycle of progress continues, but in an era of mass automation, the
wheel spins faster than ever before.</p>
<p><img src="https://chrisloy.dev/images/2025/industry-6.svg" alt="The cycle of progress is driven by innovation and industrialisation happening in tandem." title="The cycle of progress is driven by innovation and industrialisation happening in tandem."></p>
<p>The open question, then, is not whether industrial software will dominate, but what that dominance does to the
surrounding ecosystem. Previous industrial revolutions externalised their costs onto environments that seemed infinite
until they weren't. Software ecosystems are no different: dependency chains, maintenance burdens, security surfaces that
compound as output scales. Technical debt is the pollution of the digital world, invisible until it chokes the systems
that depend on it. In an era of mass automation, we may find that the hardest problem is not production, but
stewardship. Who maintains the software that no one owns?</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Use Claude Code to Query 600 GB Indexes over Hacker News, ArXiv, etc. (296 pts)]]></title>
            <link>https://exopriors.com/scry</link>
            <guid>46442245</guid>
            <pubDate>Wed, 31 Dec 2025 07:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://exopriors.com/scry">https://exopriors.com/scry</a>, See on <a href="https://news.ycombinator.com/item?id=46442245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><!--[!--><!--]--> <header><h2>Ask unprecedentedly <br> <span>nuanced questions.</span></h2> <div><p>We give you and Claude full <span>ARBITRARY SQL</span> + <span>VECTOR ALGEBRA</span> search power over a growing index of documents relevant to the intelligence explosion.</p> <p><span>‚óá</span> arXiv<br> <span>‚óá</span> Hacker News<br> <span>‚óá</span> LessWrong<br> <span>‚óá</span> community-archive.org<br> <span>‚óá</span> etc. <span>(recommend us sources @ <a href="https://exopriors.com/cdn-cgi/l/email-protection" data-cfemail="82eae7eeeeedc2e7faedf2f0ebedf0f1ace1edef">[email&nbsp;protected]</a>)</span></p></div></header> <div data-dev-only="true"><p>Alpha experiment</p> <h2>Lens Studio</h2> <p>Exploration-first LessWrong lensing. Steerable axes, bridge posts, and a personal attribute profile.
              Designed to be easy to delete if it is not worth keeping.</p></div> <div><div><h2>Claude prompt + public key</h2> <p>Paste this into <a href="https://code.claude.com/docs/en/overview">Claude Code</a> to start exploring immediately. For full functionality (higher limits + private vectors), create an account.</p> <p>Claude Code and Codex are essentially AGI at this point‚Äîwe recommend getting acquainted with these tools even if you are not a software developer. For maximum ergonomics (else you'll be manually approving each time Claude tries to query our API), we think you can get away with <code>claude --dangerously-skip-permissions</code>, but that is your risk to accept. We would not recommend this with a model less smart than Opus 4.5. The risk even if you trust us is prompt injection attacks in one of our ingested entities, even though we generally scrape content from reputable sources.</p> <div><h3>Claude Web (easiest setup, but less agentic)</h3> <p>Use this prompt directly inside the Claude web app. No MCP, no installs: just allow access to our API once.</p> <div><ol><li>Open Claude ‚Üí Settings ‚Üí Capabilities.</li> <li>Enable <span>Code execution and file creation</span>.</li> <li>Toggle <span>Allow network egress</span>.</li> <li>In <span>Domain allowlist</span>, add <code>api.exopriors.com</code>.</li> <li>Paste the prompt below and start querying in claude.ai.</li></ol> <figure> <figcaption>Domain allowlist in Claude settings. <span>Click to expand.</span></figcaption></figure></div> <p>This gives Claude web permission to call our API from its sandbox.</p></div></div> <details><summary>Show full prompt</summary> <div><pre># ExoPriors Alignment Scry (Public Access)

You have **public** access to the ExoPriors alignment research corpus.

## API Key (Public - No Signup Required)
```
exopriors_public_readonly_v1_2025
```
(This key is intentionally embedded for ergonomics.)

## Capabilities
- **Query**: SQL over 60M documents (posts, papers, tweets, comments)
- **Embed**: Store named embeddings for semantic search
- **Timeout**: adaptive, roughly 20‚Äì120s per query depending on load

## Strategy (public access)
Start with quick exploratory queries (LIMIT 10‚Äì50) to confirm schema and search semantics, then build a small candidate set and join/aggregate. Keep result sets small to avoid flooding context. Let Postgres choose join order when possible; if public timeouts bite, intersect small candidate sets client-side as a fallback. Use `alignment.search()` + LIMIT as your candidate generator.

## Public @handles
Public handle names must match `p_&lt;8 hex&gt;_&lt;name&gt;` (e.g., `p_8f3a1c2d_myhandle`).
Handles are write-once. Create an account for a private namespace with overwrites.

---

## Quick Reference

### SQL Query
```bash
curl -X POST https://api.exopriors.com/v1/alignment/query \
  -H "Authorization: Bearer exopriors_public_readonly_v1_2025" \
  -H "Content-Type: application/json" \
  -d '{{"sql": "SELECT * FROM alignment.search('\''mesa optimization'\'') LIMIT 10"}}'
```

### Query Estimate (No Execution)
```bash
curl -X POST https://api.exopriors.com/v1/alignment/estimate \
  -H "Authorization: Bearer exopriors_public_readonly_v1_2025" \
  -H "Content-Type: application/json" \
  -d '{{"sql": "SELECT id FROM alignment.entities WHERE source = '\''hackernews'\'' AND kind = '\''comment'\'' LIMIT 1000"}}'
```

### Schema Discovery
```bash
curl -X GET https://api.exopriors.com/v1/alignment/schema \
  -H "Authorization: Bearer exopriors_public_readonly_v1_2025"
```

**All `source` values (external_system enum):**
`manual`, `lesswrong`, `eaforum`, `twitter`, `bluesky`, `arxiv`, `chinarxiv`,
`community_archive`, `hackernews`, `datasecretslox`, `ethresearch`, `ethereum_magicians`,
`openzeppelin_forum`, `devcon_forum`, `eips`, `ercs`, `sep`, `exo_user`,
`coefficientgiving`, `slatestarcodex`, `marginalrevolution`, `rethinkpriorities`,
`crawled_url`, `wikipedia`, `other`

### Store Embedding
```bash
curl -X POST https://api.exopriors.com/v1/alignment/embed \
  -H "Authorization: Bearer exopriors_public_readonly_v1_2025" \
  -H "Content-Type: application/json" \
  -d '{{"text": "concept description", "name": "p_8f3a1c2d_shared_concept"}}'
```

### Semantic Search with @handle
```sql
SELECT e.id, e.original_author, e.metadata-&gt;&gt;'title'
FROM alignment.embeddings emb
JOIN alignment.entities e ON e.id = emb.entity_id
WHERE emb.chunk_index = 0
  AND emb.embedding IS NOT NULL
ORDER BY emb.embedding &lt;=&gt; @p_8f3a1c2d_shared_concept
LIMIT 20;
```

### Good Starting Views (Materialized)
Prefer materialized views for fast, filtered semantic search:
- `mv_lesswrong_posts`, `mv_eaforum_posts`, `mv_hackernews_posts`
- `mv_af_posts` (Alignment Forum posts)
- `mv_high_karma_comments` (high-score comments; filter by `source`)
- `mv_lesswrong_comments`, `mv_eaforum_comments` (all comments; embedding may be NULL)
- `mv_hackernews_comments` (HN comments)
- `mv_arxiv_papers` (papers; filter `WHERE embedding IS NOT NULL`)
Note: `mv_*` are exposed under the **alignment** schema. If you qualify with a schema, use `alignment.mv_*`.
Canonical MV columns include: `entity_id`, `uri`, `source`, `kind`, `original_author`, `original_timestamp`, `title`, `score`, `comment_count`, `vote_count`, `word_count`, `is_af`, `preview`, `embedding` (nullable).

### Lexical Search (BM25)
```sql
SELECT * FROM alignment.search('mesa optimization');
SELECT * FROM alignment.search('"inner alignment"');  -- phrase search
SELECT * FROM alignment.search('corrigibility', kinds =&gt; ARRAY['post', 'paper']);
```

**Completeness warning**: `alignment.search()` hard-caps `limit_n` at 100. It returns top BM25 results, not all matches. Use `alignment.search_exhaustive()` with pagination if missing results is worse than waiting:
```sql
SELECT *
FROM alignment.search_exhaustive(
  'left brain',
  kinds =&gt; ARRAY['post'],
  limit_n =&gt; 500,
  offset_n =&gt; 0
);
```

**Search semantics (important):**
- Default `mode =&gt; 'auto'`: quoted phrases ‚Üí phrase search, otherwise AND semantics.
- Use `mode =&gt; 'or'` for any-term matching.
- Use `mode =&gt; 'phrase'` for exact sequences; `mode =&gt; 'fuzzy'` for typos.
- Common `kinds`: `post`, `comment`, `paper`, `tweet`, `twitter_thread`, `text` (others exist but are rare).

**Return schema**: `alignment.search()` returns `(id, score, snippet, uri, kind, original_author, title, original_timestamp)`.
`original_author` may be NULL (especially tweets). It does **not** return `metadata` or `payload`. Join to `alignment.entities` if you need them:
```sql
SELECT s.title, s.score, e.metadata-&gt;&gt;'baseScore' AS base_score
FROM alignment.search('rust programming', kinds =&gt; ARRAY['post'], limit_n =&gt; 50) s
JOIN alignment.entities e ON e.id = s.id
ORDER BY s.score DESC
LIMIT 20;
```

**Performance pattern (avoid timeouts):**
Keep CTEs small by limiting inside the candidate set, then join:
```sql
WITH candidates AS (
  SELECT id FROM alignment.search('alignment', kinds =&gt; ARRAY['post'], limit_n =&gt; 200)
)
SELECT e.original_author, COUNT(*) AS n
FROM candidates c
JOIN alignment.entities e ON e.id = c.id
GROUP BY e.original_author
ORDER BY n DESC
LIMIT 25;
```
Prefer the `kinds =&gt; ARRAY[...]` parameter over `WHERE kind IN (...)` to keep the BM25 scan focused.

**Completeness vs performance (explicit)**:
- `alignment.search()` returns only the top 100 BM25 matches. Treat it as a sample.
- For completeness-sensitive tasks, use `alignment.search_exhaustive()` + pagination, start with the rarest term, and intersect author sets.

**Author topic intersection helper:**
```sql
SELECT *
FROM alignment.author_topics(
  NULL,
  ARRAY['alignment', 'rationality', 'governance'],
  kinds =&gt; ARRAY['post'],
  limit_n =&gt; 200
);
```

**Performance tips (ballpark, load-dependent):**
- Simple searches: ~1‚Äì5s
- Embedding joins (&lt;500K rows): ~5‚Äì20s
- Complex aggregations (&lt;2M rows): ~20‚Äì60s
- Large scans (&gt;5M rows): may timeout under load
- `alignment.search()` is capped at 100 rows; use `alignment.search_exhaustive()` + pagination if completeness matters
- If a query times out: reduce sample size, use fewer embeddings, or pre-filter with `alignment.search()`. For public keys, intersect small candidate lists client-side as a fallback.

---

## Upgrade
Sign up at **exopriors.com/scry** for:
- Private @handle namespace
- Up to ~10-minute query timeout when load allows; estimates may show lower caps under load
- 1.5M embedding token budget</pre></div></details></div>  <section><div><h2>Primitive Operations</h2> <p><span>&lt;=&gt;</span> is pgvector's cosine distance operator. Smaller = more similar. 0 = identical.</p></div> <div><!--[--><div><div><p><span>@</span></p><h3>Stored Vectors</h3></div> <p>Store concept embeddings server-side, reference by name. No 8KB vectors in your context.</p> </div><div><div><p><span>¬±</span></p><h3>Vector Mixing</h3></div> <p>Blend concepts algebraically. Add what you want, subtract what you don't.</p> <div><pre><!----><span>scale</span>(<span>@rigor</span>,<span>.6</span>) <span>-</span> <span>scale</span>(<span>@hype</span>,<span>.3</span>)<!----></pre></div></div><div><div><p><span>√ò</span></p><h3>Centroids</h3></div> <p>Average embeddings to capture an author's essence or an era's vibe.</p> <div><pre><!----><span>SELECT</span> <span>AVG</span>(embedding) <span>FROM</span> <span>...</span><!----></pre></div></div><div><div><p><span>Œî</span></p><h3>Temporal Deltas</h3></div> <p>Track intellectual drift. Where did a thinker move over time?</p> <div><pre><!---->(<span>c</span>('25) <span>&lt;=&gt;</span> <span>@idea</span>) <span>-</span> (<span>c</span>('22) <span>&lt;=&gt;</span> <span>@idea</span>)<!----></pre></div></div><div><div><p><span>&amp;</span></p><h3>BM25 Lexical</h3></div> <p>Full-text search with fuzzy matching, phrase search, and BM25 scoring.</p> <div><pre><!----><span>alignment.search</span>(<span>'corrigibility'</span>)<!----></pre></div></div><div><div><p><span>‚äï</span></p><h3>Hybrid Search</h3></div> <p>Lexical candidates, semantic re-rank. Best of both worlds.</p> <div><pre><!----><span>WITH</span> hits <span>AS</span> (<span>search</span>(<span>...</span>)) <span>&lt;=&gt;</span> <span>@q</span><!----></pre></div></div><!--]--></div></section>  <div><!--[!--><h2>Get Started</h2> <p>Free for researchers. 1.5M embedding tokens included.</p> <p><a href="https://exopriors.com/auth/login?return=/console">Go to Console</a></p><!--]--></div> </main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Opal (175 pts)]]></title>
            <link>https://opal.google/landing/</link>
            <guid>46441068</guid>
            <pubDate>Wed, 31 Dec 2025 03:49:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opal.google/landing/">https://opal.google/landing/</a>, See on <a href="https://news.ycombinator.com/item?id=46441068">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[We don't need more contributors who aren't programmers to contribute code (211 pts)]]></title>
            <link>https://discourse.llvm.org/t/rfc-llvm-ai-tool-policy-human-in-the-loop/89159</link>
            <guid>46440833</guid>
            <pubDate>Wed, 31 Dec 2025 03:06:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discourse.llvm.org/t/rfc-llvm-ai-tool-policy-human-in-the-loop/89159">https://discourse.llvm.org/t/rfc-llvm-ai-tool-policy-human-in-the-loop/89159</a>, See on <a href="https://news.ycombinator.com/item?id=46440833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="[RFC] LLVM AI tool policy: human in the loop">
      
      <meta itemprop="datePublished" content="2025-12-17T19:09:48Z">
        <meta itemprop="articleSection" content="LLVM Project">
      <meta itemprop="keywords" content="">
      


          <div id="post_1">
            <div>
              


              <p><span>
                  <time datetime="2025-12-17T19:09:48Z">
                    December 17, 2025,  7:09pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-17T19:30:50Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Hey folks, I got a lot of feedback from various meetings on the proposed LLVM AI contribution policy, and I made some significant changes based on that feedback. The current draft proposal focuses on the idea of requiring a <strong>human in the loop</strong> who understands their contribution well enough to <strong>answer questions about it during review</strong>. The idea here is that contributors are not allowed to offload the work of validating LLM tool output to maintainers. I‚Äôve mostly removed the Fedora policy in an effort to move from the vague notion of ‚Äúowning the contribution‚Äù to a more explicit ‚Äúcontributors have to review their contributions and be prepared to answer questions about them‚Äù. Contributors should never find themselves in the position of saying ‚ÄúI don‚Äôt know, an LLM did it‚Äù. I felt the change here was significant, and deserved a new thread.</p>
<p>From an informal show of hands at the round table at the US LLVM developer meeting, most contributors (or at least the subset with the resources and interest in attending this round table in person) are interested in using LLM assistance to increase their productivity, and I really do want to enable them to do so, while also making sure we give maintainers a useful policy tool for pushing back against unwanted contributions.</p>
<p>I‚Äôve updated <a href="https://github.com/llvm/llvm-project/pull/154441">the PR</a>, and I‚Äôve pasted the markdown below as well, but you can also <a href="https://github.com/rnk/llvm-project/blob/tool-policy/llvm/docs/AIToolPolicy.md">view it on GitHub</a>.</p>
<hr>
<h2><a name="p-355841-llvm-ai-tool-use-policy-1" href="#p-355841-llvm-ai-tool-use-policy-1" aria-label="Heading link"></a>LLVM AI Tool Use Policy</h2>
<h2><a name="p-355841-policy-2" href="#p-355841-policy-2" aria-label="Heading link"></a>Policy</h2>
<p>LLVM‚Äôs policy is that contributors can use whatever tools they would like to<br>
craft their contributions, but there must be a <strong>human in the loop</strong>.<br>
<strong>Contributors must read and review all LLM-generated code or text before they<br>
ask other project members to review it.</strong> The contributor is always the author<br>
and is fully accountable for their contributions. Contributors should be<br>
sufficiently confident that the contribution is high enough quality that asking<br>
for a review is a good use of scarce maintainer time, and they should be <strong>able<br>
to answer questions about their work</strong> during review.</p>
<p>We expect that new contributors will be less confident in their contributions,<br>
and our guidance to them is to <strong>start with small contributions</strong> that they can<br>
fully understand to build confidence. We aspire to be a welcoming community<br>
that helps new contributors grow their expertise, but learning involves taking<br>
small steps, getting feedback, and iterating. Passing maintainer feedback to an<br>
LLM doesn‚Äôt help anyone grow, and does not sustain our community.</p>
<p>Contributors are expected to <strong>be transparent and label contributions that<br>
contain substantial amounts of tool-generated content</strong>. Our policy on<br>
labelling is intended to facilitate reviews, and not to track which parts of<br>
LLVM are generated. Contributors should note tool usage in their pull request<br>
description, commit message, or wherever authorship is normally indicated for<br>
the work. For instance, use a commit message trailer like Assisted-by: . This transparency helps the community develop best practices<br>
and understand the role of these new tools.</p>
<p>An important implication of this policy is that it bans agents that take action<br>
in our digital spaces without human approval, such as the GitHub <a href="https://github.com/claude/"><code>@claude</code><br>
agent</a>. Similarly, automated review tools that<br>
publish comments without human review are not allowed. However, an opt-in<br>
review tool that <strong>keeps a human in the loop</strong> is acceptable under this policy.<br>
As another example, using an LLM to generate documentation, which a contributor<br>
manually reviews for correctness, edits, and then posts as a PR, is an approved<br>
use of tools under this policy.</p>
<p>This policy includes, but is not limited to, the following kinds of<br>
contributions:</p>
<ul>
<li>Code, usually in the form of a pull request</li>
<li>RFCs or design proposals</li>
<li>Issues or security vulnerabilities</li>
<li>Comments and feedback on pull requests</li>
</ul>
<h2><a name="p-355841-extractive-contributions-3" href="#p-355841-extractive-contributions-3" aria-label="Heading link"></a>Extractive Contributions</h2>
<p>The reason for our ‚Äúhuman-in-the-loop‚Äù contribution policy is that processing<br>
patches, PRs, RFCs, and comments to LLVM is not free ‚Äì it takes a lot of<br>
maintainer time and energy to review those contributions! Sending the<br>
unreviewed output of an LLM to open source project maintainers <em>extracts</em> work<br>
from them in the form of design and code review, so we call this kind of<br>
contribution an ‚Äúextractive contribution‚Äù.</p>
<p>Our <strong>golden rule</strong> is that a contribution should be worth more to the project<br>
than the time it takes to review it. These ideas are captured by this quote<br>
from the book <a href="https://press.stripe.com/working-in-public">Working in Public</a> by Nadia Eghbal:</p>
<blockquote>
<p>"When attention is being appropriated, producers need to weigh the costs and<br>
benefits of the transaction. To assess whether the appropriation of attention<br>
is net-positive, it‚Äôs useful to distinguish between <em>extractive</em> and<br>
<em>non-extractive</em> contributions. Extractive contributions are those where the<br>
marginal cost of reviewing and merging that contribution is greater than the<br>
marginal benefit to the project‚Äôs producers. In the case of a code<br>
contribution, it might be a pull request that‚Äôs too complex or unwieldy to<br>
review, given the potential upside." -- Nadia Eghbal</p>
</blockquote>
<p>Prior to the advent of LLMs, open source project maintainers would often review<br>
any and all changes sent to the project simply because posting a change for<br>
review was a sign of interest from a potential long-term contributor. While new<br>
tools enable more development, it shifts effort from the implementor to the<br>
reviewer, and our policy exists to ensure that we value and do not squander<br>
maintainer time.</p>
<p>Reviewing changes from new contributors is part of growing the next generation<br>
of contributors and sustaining the project. We want the LLVM project to be<br>
welcoming and open to aspiring compiler engineers who are willing to invest<br>
time and effort to learn and grow, because growing our contributor base and<br>
recruiting new maintainers helps sustain the project over the long term. Being<br>
open to contributions and <a href="https://llvm.org/docs/DeveloperPolicy.html#obtaining-commit-access">liberally granting commit access</a><br>
is a big part of how LLVM has grown and successfully been adopted all across<br>
the industry.  We therefore automatically post a greeting comment to pull<br>
requests from new contributors and encourage maintainers to spend their time to<br>
help new contributors learn.</p>
<h2><a name="p-355841-handling-violations-4" href="#p-355841-handling-violations-4" aria-label="Heading link"></a>Handling Violations</h2>
<p>If a maintainer judges that a contribution is <em>extractive</em> (i.e. it doesn‚Äôt<br>
comply with this policy), they should copy-paste the following response to<br>
request changes, add the <code>extractive</code> label if applicable, and refrain from<br>
further engagement:</p>
<pre><code>This PR appears to be extractive, and requires additional justification for
why it is valuable enough to the project for us to review it. Please see
our developer policy on AI-generated contributions:
http://llvm.org/docs/AIToolPolicy.html
</code></pre>
<p>Other reviewers should use the label to prioritize their review time.</p>
<p>The best ways to make a change less extractive and more valuable are to reduce<br>
its size or complexity or to increase its usefulness to the community. These<br>
factors are impossible to weigh objectively, and our project policy leaves this<br>
determination up to the maintainers of the project, i.e. those who are doing<br>
the work of sustaining the project.</p>
<p>If a contributor responds but doesn‚Äôt make their change meaningfully less<br>
extractive, maintainers should escalate to the relevant moderation or admin<br>
team for the space (GitHub, Discourse, Discord, etc) to lock the conversation.</p>
<h2><a name="p-355841-copyright-5" href="#p-355841-copyright-5" aria-label="Heading link"></a>Copyright</h2>
<p>Artificial intelligence systems raise many questions around copyright that have<br>
yet to be answered. Our policy on AI tools is similar to our copyright policy:<br>
Contributors are responsible for ensuring that they have the right to<br>
contribute code under the terms of our license, typically meaning that either<br>
they, their employer, or their collaborators hold the copyright. Using AI tools<br>
to regenerate copyrighted material does not remove the copyright, and<br>
contributors are responsible for ensuring that such material does not appear in<br>
their contributions. Contributions found to violate this policy will be removed<br>
just like any other offending contribution.</p>
<h2><a name="p-355841-examples-6" href="#p-355841-examples-6" aria-label="Heading link"></a>Examples</h2>
<p>Here are some examples of contributions that demonstrate how to apply<br>
the principles of this policy:</p>
<ul>
<li><a href="https://github.com/llvm/llvm-project/pull/142869">This PR</a> contains a proof from Alive2, which is a strong signal of<br>
value and correctness.</li>
<li>This <a href="https://discourse.llvm.org/t/searching-for-gsym-documentation/85185/2">generated documentation</a> was reviewed for correctness by a<br>
human before being posted.</li>
</ul>
<h2><a name="p-355841-references-7" href="#p-355841-references-7" aria-label="Heading link"></a>References</h2>
<p>Our policy was informed by experiences in other communities:</p>
<ul>
<li><a href="https://communityblog.fedoraproject.org/council-policy-proposal-policy-on-ai-assisted-contributions/">Fedora Council Policy Proposal: Policy on AI-Assisted Contributions (fetched<br>
2025-10-01)</a>: Some of the text above was copied from the Fedora<br>
project policy proposal, which is licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons<br>
Attribution 4.0 International License</a>. This link serves as attribution.</li>
<li><a href="https://github.com/rust-lang/compiler-team/issues/893">Rust draft policy on burdensome PRs</a></li>
<li><a href="https://sethmlarson.dev/slop-security-reports">Seth Larson‚Äôs post</a><br>
on slop security reports in the Python ecosystem</li>
<li>The METR paper <a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/">Measuring the Impact of Early-2025 AI on Experienced<br>
Open-Source Developer Productivity</a>.</li>
<li><a href="https://www.qemu.org/docs/master/devel/code-provenance.html#use-of-ai-content-generators">QEMU bans use of AI content generators</a></li>
<li><a href="https://simonwillison.net/2024/May/8/slop/">Slop is the new name for unwanted AI-generated content</a></li>
</ul>
            </div>

            

                

            
          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/cmtice"><span itemprop="name">cmtice</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-17T19:27:38Z">
                    December 17, 2025,  7:27pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-17T19:27:38Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Hi Reid,</p>
<p>I understand and generally agree with the sentiment that prompted this proposal, but I think maybe your current policy is <strong>too</strong> restrictive and you are throwing out the baby with the bathwater.  In particular I can imagine cases where we might want to make exceptions to the general policy, e.g. for AI tools that are designed to handle a small, restricted, and easily automatable set of maintenance-type changes.  I think this policy should include a well-defined path for obtaining exceptions to the general rule (that a human must be in the loop before a PR can be posted).</p>
<p>An example of such a path might be:</p>
<ul>
<li>
<p>Post an RFC detailing what problem the proposed AI agent will solve and how it will solve it.</p>
</li>
<li>
<p>Get approval for the RFC</p>
</li>
<li>
<p>Have a short testing period, where humans must check their proposed changes before allowing them to be posted upstream, and must comment in the PR both that the original content came from AI, and whether or not the human needed to update the original content.</p>
</li>
<li>
<p>Final review by small committee (possibly one of the area leads teams) on whether or not the AI is generating acceptable quality PRs; grants the exception (or not).</p>
</li>
</ul>
<p>Note that‚Äôs just a rough outline, and would probably need refinement.  Just my 2 cents.</p>
            </div>

            


            
          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/shafik"><span itemprop="name">shafik</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-17T20:58:14Z">
                    December 17, 2025,  8:58pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-17T20:58:14Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Thank you, this feels like it take a lot of the feedback into account. one aspect that I don‚Äôt see covered here but I have had trouble with is that results from LLMs tend to be very very verbose. Often they feel like giant walls of text. There is important and useful information there but I have to put a lot more work into getting it. It is not that anything is necessarily incorrect or wrong but a human would have said in a few sentences and still conveyed the important information.</p>
<p>It feels very hard to push back on this because it feels to some degree subjective (but I know it when I see it) but if a serious amounts of reviews became that much more verbose it would be a large cost in reviewer time. I will feel highly unmotivated to review PRs/issues that are walls of text. Especially if (as I often am) making hard trade-offs on my time.</p>
<p>There is some degree on irony here, in that I am often pushing folks on PRs to provide more and more detailed information but as the meme‚Äôs often say ‚Äúnot like that‚Äù.</p>
            </div>

            


            
          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/danilaml"><span itemprop="name">danilaml</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-18T15:19:19Z">
                    December 18, 2025,  3:19pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-18T15:19:19Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <p>Not sure if it‚Äôs explicit from the current wording but I assume the intention for ‚Äúhuman in the loop‚Äù is that the human won‚Äôt just forward questions to LLM and post its answers as if they are their own instead of just going ‚ÄúI don‚Äôt know, an LLM did it‚Äù either (because it‚Äôs essentially the same as the latter but wastes way more reviewer time).</p>

            


            
          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/Endill"><span itemprop="name">Endill</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-18T18:29:59Z">
                    December 18, 2025,  6:29pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-18T18:29:59Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>I don‚Äôt agree with this characterization. The problem we have today is not that we have a lot of LLM-based tools we desperately need to integrate into our automation. Instead, I think the problem is that reviewers struggle with a wave of LLM output coming as contributions, where contributors don‚Äôt have enough understanding of their PRs. Policy that Reid drafted in this thread is a great step towards addressing that later problem.</p>
<p>We‚Äôve been months into AI policy discussions, and I don‚Äôt think that hypothetical future LLM automation is worth delaying much needed changes any longer.</p>
            </div>

            


            
          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/Sirraide"><span itemprop="name">Sirraide</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-18T18:43:01Z">
                    December 18, 2025,  6:43pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-18T18:43:01Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Yeah, agreed. If we eventually do find that we want to carve out some sort of exception for some tool, we can just update the policy at that point.</p>
            </div>

            


            
          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/jrtc27"><span itemprop="name">jrtc27</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-18T19:11:22Z">
                    December 18, 2025,  7:11pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-18T19:11:22Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>I don‚Äôt see why this is incompatible with that. A policy introduced by this RFC can be overridden by a future RFC, including one for a specific case that would like an exception.</p>

            


            
          </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/cmtice"><span itemprop="name">cmtice</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-19T16:11:10Z">
                    December 19, 2025,  4:11pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-19T16:11:10Z">
              <span itemprop="position">8</span>
              </span>
            </p>
            <p>While I am fully convinced that we will end up needing well-defined path for exceptions to this policy, which I why I brought it up, if everyone else would prefer to skip that for now, I can live with the policy going in as is. With the full expectation that we will need to update it in the future to define a principled way to obtain exceptions. <img src="https://emoji.discourse-cdn.com/google/slight_smile.png?v=15" title=":slight_smile:" alt=":slight_smile:" loading="lazy" width="20" height="20"></p>

            


            
          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/artagnon"><span itemprop="name">artagnon</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-23T22:01:35Z">
                    December 23, 2025, 10:01pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-23T22:01:35Z">
              <span itemprop="position">9</span>
              </span>
            </p>
            <div itemprop="text">
              <p>I thought some more about why crafting an AI policy for an open source project is so hard, and why so many projects are struggling with it. For a large open source project like LLVM or Linux, a large share of the contributors are working at corporations ‚Äì and a large majority of corporations have adopted AI coding-assistants org-wide, many of them seeing material benefits from the adoption. It would be natural to question whether the same productivity gain can be replicated in an open source project like ours. The interest in drafting a policy may also come from the perspective of being welcoming to new contributors ‚Äì a lot of young people today are playing with coding-assistants prior to joining industry. My earlier position was that it wouldn‚Äôt be useful in LLVM, from personal experience, but I‚Äôm probably old-fashioned and biased.</p>
<p>The core issue is that the people writing code in corporations are very different from the general public ‚Äì rouge entities misusing AI in corporations can be let go, but the general public is the wild west. Several open source projects are burdened with a flood of AI-generated bug reports, and huge AI-generated PRs. I think that, due to the inherent nature of this technology, it will always be a corporate thing, and is perhaps a poor fit for an open source project ‚Äì I know this is somewhat defeatist, but I really don‚Äôt know what kind of safeguards will protect us and our valuable time.</p>
            </div>

            


            
          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/ms178"><span itemprop="name">ms178</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-26T09:41:30Z">
                    December 26, 2025,  9:41am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-26T09:41:30Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            <p>True, but there is a higher argumentative and social effort needed to deviate from a once established policy.</p>

            


            
          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/ms178"><span itemprop="name">ms178</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-26T09:51:53Z">
                    December 26, 2025,  9:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-26T09:51:53Z">
              <span itemprop="position">11</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Without any empirical evidence this remains a unsubstantiated claim. I‚Äôd argue that such a LLM-assisted review could be part of the learning curve. It also does not reflect the rapid improvements in AI quality which might mitigate the issues related to bad output quality over time.</p>
<p>Instead of shutting the door for non-programmers with such language, I propose hard objective criteria to act as the AI quality filter, e.g. measurable and reproducable improvements (performance numbers, crash fixes etc.) that need to be explicitly mentioned within the MR/issue.</p>
            </div>

            


            
          </div>
          <div itemprop="comment" id="post_12" itemscope="" itemtype="http://schema.org/Comment">
              
<p>This is a very strange statement - the burden of proof of the value of <code>&lt;X_NEW_THING&gt;</code> is on  <code>&lt;X_NEW_THING&gt;</code> (and its proponents) not everyone else.</p>
            </div>
          <div itemprop="comment" id="post_13" itemscope="" itemtype="http://schema.org/Comment">
              <p>I can share a few practices from ASF communities.</p>
<p>Some ASF projects (e.g., Apache DataFusion and Apache Kvrocks) have already published AI-assisted contribution policies, and they converge with the LLVM proposal: if you use an LLM, you‚Äôre still expected to understand the change and be able to explain and iterate on it.</p>
<p>When the author can‚Äôt really explain what the LLM produced, a high-quality issue is often a better outcome than a PR. It can avoid wasted review cycles - especially for smaller communities where maintainer bandwidth and review burnout are real constraints. In projects I maintain, I‚Äôve seen more LLM-generated PRs recently, and many stall because the author can‚Äôt effectively respond to review feedback beyond acting as an LLM ‚Äúproxy‚Äù, which increases communication cost and slows everything down.</p>
<p>Overall, ‚Äúhuman in the loop‚Äù feels like the most practical policy today. If LLM capability improves significantly, we can revisit the policy, but based on what I‚Äôm seeing, I think we‚Äôre not there yet.</p>
<p>References:</p>
<ul>
<li><a href="https://datafusion.apache.org/contributor-guide/index.html#ai-assisted-contributions" rel="noopener nofollow ugc">Apache DataFusion: AI-Assisted contributions</a></li>
<li><a href="https://kvrocks.apache.org/community/contributing#guidelines-for-ai-assisted-contributions" rel="noopener nofollow ugc">Apache Kvrocks: Guidelines for AI-assisted Contributions</a></li>
<li><a href="https://www.apache.org/legal/generative-tooling.html" rel="noopener nofollow ugc">ASF Generative Tooling Guidance</a></li>
</ul>
<p>AI policies from more communities:</p>
<ul>
<li><a href="https://github.com/zulip/zulip/blob/main/CONTRIBUTING.md#ai-use-policy-and-guidelines" rel="noopener nofollow ugc">Zulip: AI use policy and guidelines</a></li>
<li><a href="https://devguide.python.org/getting-started/generative-ai/" rel="noopener nofollow ugc">CPython: Generative AI</a></li>
<li><a href="https://lore.kernel.org/ksummit/20251114183528.1239900-1-dave.hansen@linux.intel.com/" rel="noopener nofollow ugc">Linux Kernel: Kernel Guidelines for Tool Generated Content</a></li>
</ul>
            </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/shafik"><span itemprop="name">shafik</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-27T18:34:14Z">
                    December 27, 2025,  6:34pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-27T18:34:14Z">
              <span itemprop="position">14</span>
              </span>
            </p>
            <p>Thank you so much for sharing your communities experience. It is good to know that we are not the only one struggling with these issues and it is also good to know how other communities are attempting to deal with them.</p>

            


            
          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/ms178"><span itemprop="name">ms178</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-27T22:19:51Z">
                    December 27, 2025, 10:19pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-27T23:06:59Z">
              <span itemprop="position">15</span>
              </span>
            </p>
            <div itemprop="text">
              <p>No, it makes total sense: As I read it, this new AI policy introduces restrictions and additional burden on contributors, effectively excluding non-programmers that want to contribute AI-assisted code changes. The burden of proof is on the proponents of such restrictions to show that there is a neccessity for introducing such a change. It‚Äôs not the other way around as there is currently no AI policy with such restrictions (e.g. everything that is not specifically forbidden is allowed).</p>
<p>Again, I argue that some ‚ÄúAI slop filter‚Äù needs to be based on objective criteria. It is not about the status of the people contributing code or their lack of programming experience but about the (minimum) quality of the code contribution to warrent further reviewer time and effort. In my view, it makes more sense to define such a set of objective criteria for the expected (minimum) code quality which need to be met than to exclude people due to the lack of programming experience.</p>
            </div>

            


            
          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/resistor"><span itemprop="name">resistor</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-28T00:59:16Z">
                    December 28, 2025, 12:59am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-28T00:59:16Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <div itemprop="text">
              <p>It‚Äôs worth noting that the current permissiveness is quite new in the overall history of the project. The reality is that the LLVM community has discouraged automated and/or bulk changes of any form for a very long time, including changes generated by tooling as straightforward as a <code>sed</code> script. When such changes have been allowed in the past, it has been after receiving prior approval from the community. I view AI-generated changes as falling into precisely the same bucket.</p>
<p>I will restate my outlook from the earlier thread: while being inclusive and welcoming is <em>a</em> goal of the LLVM project, it does not supersede <em>the</em> goal of building a suite of compiler &amp; toolchain components that benefit our users. Most of the time these goals are not in conflict, but (again IMO) an overly permissive AI contribution policy betrays the duty of care we have to our users.</p>
            </div>

            


            
          </div>
          <div itemprop="comment" id="post_17" itemscope="" itemtype="http://schema.org/Comment">
              
<p>At first glance, this sounds reasonable, but I don‚Äôt think it works in practice. In theory you can define ‚Äúobjective‚Äù standards, but determining whether a PR actually meets those standards still costs maintainer time and attention. And I strongly suspect that cost is often close to what it would take to just do a full review anyway.</p>
<p>Let‚Äôs also acknowledge something: in open source we generally <em>don‚Äôt</em> judge contributions by a contributor‚Äôs r√©sum√© or claimed experience. But interpersonal trust and publicly earned merit (see <a href="https://www.apache.org/foundation/how-it-works/#meritocracy" rel="noopener nofollow ugc">ASF‚Äôs explanation of Meritocracy</a> and <a href="https://www.apache.org/theapacheway/#what-makes-the-apache-way-so-hard-to-define" rel="noopener nofollow ugc">the Apache Way</a>, for example) are genuinely important in open-source communities. That‚Äôs not because people are biased; it‚Äôs because, as imperfect as it may be, it‚Äôs the lowest-cost way to make decisions at scale. If we discard that dynamic entirely, I‚Äôm not sure open source would function as effectively as it does today.</p>
            </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/ms178"><span itemprop="name">ms178</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-28T08:36:53Z">
                    December 28, 2025,  8:36am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-28T08:36:53Z">
              <span itemprop="position">18</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>I fully understand the implications of being swamped with AI contributions on the reviewer side (AI only accelerates the problem, a ton of new novice contributors would expose essentially the same scaling problem). But this is an area were open source communities need to evolve and find new ways to 1) stay as open as possible to harness new discoveries and 2) remain functioning effectively at scale.</p>
<p>I‚Äôve lobbied for an more open alternative approach <a href="https://seylaw.blogspot.com/2025/10/the-shepherd-and-flux-capacitor.html" rel="noopener nofollow ugc">publicly</a> that aims to serve both goals (admittedly without much acceptance from the LLVM community so far):</p>
<p><em>‚Äù[‚Ä¶] this entire defensive model is value-destructive. It is a system designed with only one success state (accepting a perfect contribution) and one failure state (rejecting an imperfect one). It has no mechanism for a third, more productive outcome: refinement. When a contribution with a verifiable, valuable payload is rejected because its packaging is flawed, the value is not put on hold; it is permanently lost. The performance gain I found is not sitting in a queue waiting for me to learn C++; it is simply gone from the project. The fortress, in its zeal to keep out the ‚Äúslop,‚Äù has also barred the door to the raw ore from which treasure might have been forged.</em></p>
<p><em>This is not a sustainable model in an era where the tools of discovery are becoming democratized at an explosive rate. The fundamental misunderstanding is that ownership is not a ticket that one must purchase before entering the park. Ownership is the outcome of a successful collaborative journey. By demanding it at the very beginning, we are ensuring that for a growing class of potential innovators, that journey never even begins. The fortress may remain pure, but it will also become stagnant, isolated from the very world it is meant to serve. [</em>‚Ä¶]</p>
<p><em>To critique the fortress is not enough. We must offer a blueprint for a better structure: a harbor. A harbor, unlike a fortress, does not have a simple binary function of letting things in or keeping them out. It is an active, intelligent system with channels, docks, workshops, and expert pilots, all designed to guide valuable cargo safely to shore, no matter the state of the vessel that carries it. This is the model we must adopt for open source in a post-AI world. The anxiety over ‚Äúextractive‚Äù contributions is real, but the solution is not a higher wall; it is a smarter intake process. <a href="https://discourse.llvm.org/t/rfc-llvm-ai-tool-policy-start-small-no-slop/88476/28">I propose a concrete, actionable framework for this harbor</a>: the Contribution Triage Pipeline.‚Äù</em></p>
            </div>

            


            
          </div>
          <div id="post_19" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/rengolin"><span itemprop="name">rengolin</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-28T15:07:33Z">
                    December 28, 2025,  3:07pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-28T15:07:33Z">
              <span itemprop="position">19</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>This is categorically false. LLVM‚Äôs review policy is directly and wholeheartedly based on refinement, and the new AI policy does not goes against it.</p>
<p>LLVM‚Äôs policy also focus on code quality, which requires the author being able to explain the changes, and defend their choices to the wider community. Here the fail-safe is a human author being able to explain the changes without offloading that role to maintainers and the wider community.</p>
<p>LLMs are, by construction, unable to defend their own choices (without hallucination) with the technical rigour that we need for tools like compilers, kernels and other key infrastructure components of modern societies.</p>

<p>Tools of discovery should be used to find solutions in a large sea of choices, not to accept the output without validation, nor to offload the validation to the wider community.</p>
<p>The <em>‚Äúvalue‚Äù</em> created by some automatic tool, as well as humans, may be acceptable to some people, but not all. It may be relevant to a set of problems, but not all. It may be correct with certain assumptions, but not all. Without understanding of those limitations, contributions provide <em>negative</em> value, as they waste the time of more people than their contributions would provide.</p>
<p>Anyone willing to provide justifications and explanations for decisions made in a PR, be it created by humans or machines, are absolutely encouraged to contribute. But if their justifications are not at the level of rigour we require to merge a PR, the code should not be merged, and upon insistence without further merit, maintainers are encouraged to ignore and/or close the PRs. This is true regardless of how the code was produced.</p>

<p>I believe the policy offers exactly that. The ‚Äúwall‚Äù is the same size as it has always been: technical rigour, honest justification, willingness to adapt.</p>
<p>Extractive contributions are not just dangerous due to their net-negative costs on merge, but also their accumulated extraction of whole-system knowledge and reuse of bad practices that just <em>‚Äúhappen to work‚Äù</em>. This is a human action as well, but code review exposes refactory opportunities, which are much more costly than normal code review.</p>
<p>Accepting generated code without human review, and without human justification, increases the difficulty of refactory over time. This is not exclusive to machines, but it is unrestricted on machines contributions.</p>
<p>Until such a day when code generators can have the same technical rigour as humans (for example generate proofs of quality or trigger reasonable refactory actions), we should not allow auto-generated code to merge without human review and justification.</p>
            </div>

            


            
          </div>
          <div id="post_20" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.llvm.org/u/amara"><span itemprop="name">amara</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-30T05:02:42Z">
                    December 30, 2025,  5:02am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-30T05:02:42Z">
              <span itemprop="position">20</span>
              </span>
            </p>
            <div itemprop="text">
              <blockquote>
<p>No, it makes total sense: As I read it, this new AI policy introduces restrictions and additional burden on contributors, effectively excluding non-programmers that want to contribute AI-assisted code changes. The burden of proof is on the proponents of such restrictions to show that there is a neccessity for introducing such a change. It‚Äôs not the other way around as there is currently no AI policy with such restrictions (e.g. everything that is not specifically forbidden is allowed).</p>
</blockquote>
<p>I really don‚Äôt agree with this. LLVM is, at its core, a compiler framework that‚Äôs responsible for the running code on the majority of the world‚Äôs computing systems. From embedded devices to servers and everything in between. Like the Linux kernel, quality and stability are IMO the highest priorities here. We don‚Äôt need <em>more</em> contributors who aren‚Äôt programmers to contribute code. That may suck for those people who want to feel good by having some code accepted into a prestigious project like LLVM for their resum√© without learning compilers, but I couldn‚Äôt care less about those people. Those people can take their contributions to one of the other million OSS projects, LLVM will be just fine without them.</p>
<p>What we need more of are contributors who‚Äôve built experience, can review code, learn and teach others through discussions. We need people with good <em>taste</em> that comes with years of interaction with LLVM. We need people who can look at a PR that seems to do a correct thing on a local level, but explain that it‚Äôs not the right place to be making those changes in the long term.</p>
<p>To sum it all up, I strongly agree with this RFC and we can evolve it as needed in future.</p>
            </div>

            


            
          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Readings in Database Systems (5th Edition) (2015) (141 pts)]]></title>
            <link>http://www.redbook.io/</link>
            <guid>46440510</guid>
            <pubDate>Wed, 31 Dec 2025 02:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.redbook.io/">http://www.redbook.io/</a>, See on <a href="https://news.ycombinator.com/item?id=46440510">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container">

<p><em>Readings in Database Systems</em> (commonly known as
  the "Red Book") has offered readers an opinionated take on both
  classic and cutting-edge research in the field of data management
  since 1988. Here, we present the Fifth Edition of the Red Book ‚Äî
  the first in over ten years.</p>

<p>CHAPTERS</p>
<ol id="entries">
<li><a href="http://www.redbook.io/preface.html">Preface<i></i></a> <div><p>[<a href="http://www.redbook.io/preface.html">HTML</a>] [<a href="http://www.redbook.io/pdf/preface.pdf">PDF</a>]</p></div></li>
<li value="1"><a href="http://www.redbook.io/ch1-background.html">Background<i> introduced by Michael Stonebraker</i></a> <div><p>[<a href="http://www.redbook.io/ch1-background.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch1-background.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch2-importantdbms.html">Traditional RDBMS Systems<i> introduced by Michael Stonebraker</i></a> <div><p>[<a href="http://www.redbook.io/ch2-importantdbms.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch2-importantdbms.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch3-techniques.html">Techniques Everyone Should Know<i> introduced by Peter Bailis</i></a> <div><p>[<a href="http://www.redbook.io/ch3-techniques.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch3-techniques.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch4-newdbms.html">New DBMS Architectures<i> introduced by Michael Stonebraker</i></a> <div><p>[<a href="http://www.redbook.io/ch4-newdbms.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch4-newdbms.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch5-dataflow.html">Large-Scale Dataflow Engines<i> introduced by Peter Bailis</i></a> <div><p>[<a href="http://www.redbook.io/ch5-dataflow.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch5-dataflow.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch6-isolation.html">Weak Isolation and Distribution<i> introduced by Peter Bailis</i></a> <div><p>[<a href="http://www.redbook.io/ch6-isolation.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch6-isolation.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch7-queryoptimization.html">Query Optimization<i> introduced by Joe Hellerstein</i></a> <div><p>[<a href="http://www.redbook.io/ch7-queryoptimization.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch7-queryoptimization.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch8-interactive.html">Interactive Analytics<i> introduced by Joe Hellerstein</i></a> <div><p>[<a href="http://www.redbook.io/ch8-interactive.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch8-interactive.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch9-languages.html">Languages<i> introduced by Joe Hellerstein</i></a> <div><p>[<a href="http://www.redbook.io/ch9-languages.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch9-languages.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch10-webdata.html">Web Data<i> introduced by Peter Bailis</i></a> <div><p>[<a href="http://www.redbook.io/ch10-webdata.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch10-webdata.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch11-complexanalytics.html">A Biased Take on a Moving Target: Complex Analytics<br><i> by Michael Stonebraker</i></a> <div><p>[<a href="http://www.redbook.io/ch11-complexanalytics.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch11-complexanalytics.pdf">PDF</a>]</p></div></li>
<li><a href="http://www.redbook.io/ch12-dataintegration.html">A Biased Take on a Moving Target: Data Integration<br><i> by Michael Stonebraker</i></a> <div><p>[<a href="http://www.redbook.io/ch12-dataintegration.html">HTML</a>] [<a href="http://www.redbook.io/pdf/ch12-dataintegration.pdf">PDF</a>]</p></div></li>
</ol>

<div>
  <p><b>Complete Book:</b> [<a href="http://www.redbook.io/all-chapters.html">HTML</a>] [<a href="http://www.redbook.io/pdf/redbook-5th-edition.pdf">PDF</a>]
</p></div>
<div>
  <p><b>Readings Only:</b> [<a href="http://www.redbook.io/all-readings.html">HTML</a>] [<a href="http://www.redbook.io/pdf/all-readings.pdf">PDF</a>]
</p></div>
<p><b>Previous Editions:</b> [<a href="http://www.redbook.io/archive">HTML</a>]
</p><br>

    <div id="license">
      <p><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"></a><br>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative
      Commons Attribution-NonCommercial-ShareAlike 4.0
      International License</a>.
     </p></div>

     <p>Comments to pbailis@cs.stanford.edu or <a href="https://twitter.com/pbailis">@pbailis</a>.</p>
      
    </div></div>]]></description>
        </item>
    </channel>
</rss>