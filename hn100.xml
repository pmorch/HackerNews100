<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 08 Feb 2026 18:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Vouch (120 pts)]]></title>
            <link>https://github.com/mitchellh/vouch</link>
            <guid>46935980</guid>
            <pubDate>Sun, 08 Feb 2026 16:45:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mitchellh/vouch">https://github.com/mitchellh/vouch</a>, See on <a href="https://news.ycombinator.com/item?id=46935980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Vouch</h2><a id="user-content-vouch" aria-label="Permalink: Vouch" href="#vouch"></a></p>
<p dir="auto">A project trust management system. People must be <strong>vouched for</strong> before
interacting with certain parts of a project (the exact parts are
configurable to the project to enforce). People can also be explicitly
<strong>denounced</strong> to block them from interacting with the project.</p>
<p dir="auto">The implementation is generic and can be used by any project on any code forge,
but we provide <strong>GitHub integration</strong> out of the box via GitHub actions
and the CLI.</p>
<p dir="auto">The vouch list is maintained in a single flat file using a minimal format
that can be trivially parsed using standard POSIX tools and any programming
language without external libraries.</p>
<p dir="auto"><strong>Vouch lists can also form a web of trust.</strong> You can configure Vouch to
read other project's lists of vouched or denounced users. This way,
projects with shared values can share their trust decisions with each other
and create a larger, more comprehensive web of trust across the ecosystem.
Users already proven to be trustworthy in one project can automatically
be assumed trustworthy in another project, and so on.</p>
<div dir="auto"><p dir="auto">Warning</p>
<p dir="auto">This is an experimental system in use by <a href="https://github.com/ghostty-org/ghostty">Ghostty</a>.
We'll continue to improve the system based on experience and feedback.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Open source has always worked on a system of <em>trust and verify</em>.</p>
<p dir="auto">Historically, the effort required to understand a codebase, implement
a change, and submit that change for review was high enough that it
naturally filtered out many low quality contributions from unqualified people.
For over 20 years of my life, this was enough for my projects as well
as enough for most others.</p>
<p dir="auto">Unfortunately, the landscape has changed particularly with the advent
of AI tools that allow people to trivially create plausible-looking but
extremely low-quality contributions with little to no true understanding.
Contributors can no longer be trusted based on the minimal barrier to entry
to simply submit a change.</p>
<p dir="auto">But, open source still works on trust! And every project has a definite
group of trusted individuals (maintainers) and a larger group of probably
trusted individuals (active members of the community in any form). So,
let's move to an explicit trust model where trusted individuals can vouch
for others, and those vouched individuals can then contribute.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Who is Vouched?</h2><a id="user-content-who-is-vouched" aria-label="Permalink: Who is Vouched?" href="#who-is-vouched"></a></p>
<p dir="auto"><strong>Who</strong> and <strong>how</strong> someone is vouched or denounced is left entirely up to the
project integrating the system. Additionally, <strong>what</strong> consequences
a vouched or denounced person has is also fully up to the project.
Implement a policy that works for your project and community.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">GitHub</h3><a id="user-content-github" aria-label="Permalink: GitHub" href="#github"></a></p>
<p dir="auto">Integrating vouch into a GitHub project is easy with the
<a href="https://github.com/mitchellh/vouch/tree/main/action">provided GitHub Actions</a>.
By choosing which actions to use, you can fully control how
users are vouched and what they can or can't do.</p>
<p dir="auto">For an example, look at this repository! It fully integrates vouch.</p>
<p dir="auto">Below is a list of the actions and a brief description of their function.
See the linked README in the action directory for full usage details.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Action</th>
<th>Trigger</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/check-pr/README.md">check-pr</a></td>
<td><code>pull_request_target</code></td>
<td>Check if a PR author is vouched on open or reopen. Bots and collaborators with write access are automatically allowed. Optionally auto-close PRs from unvouched or denounced users.</td>
</tr>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/manage-by-discussion/README.md">manage-by-discussion</a></td>
<td><code>discussion_comment</code></td>
<td>Let collaborators vouch, denounce, or unvouch users via discussion comments. Updates the vouched file and commits the change.</td>
</tr>
<tr>
<td><a href="https://github.com/mitchellh/vouch/blob/main/action/manage-by-issue/README.md">manage-by-issue</a></td>
<td><code>issue_comment</code></td>
<td>Let collaborators vouch or denounce users via issue comments. Updates the vouched file and commits the change.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI</h3><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<p dir="auto">The CLI is implemented as a Nushell module and only requires
Nushell to run. There are no other external dependencies.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Integrated Help</h4><a id="user-content-integrated-help" aria-label="Permalink: Integrated Help" href="#integrated-help"></a></p>
<p dir="auto">This is Nushell, so you can get help on any command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use vouch *
help add
help check
help denounce
help gh-check-pr
help gh-manage-by-issue"><pre>use vouch <span>*</span>
<span>help</span> add
<span>help</span> check
<span>help</span> denounce
<span>help</span> gh<span>-</span>check<span>-</span>pr
<span>help</span> gh<span>-</span>manage<span>-</span>by<span>-</span>issue</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Local Commands</h4><a id="user-content-local-commands" aria-label="Permalink: Local Commands" href="#local-commands"></a></p>
<p dir="auto"><strong>Check a user's vouch status:</strong></p>

<p dir="auto">Exit codes: 0 = vouched, 1 = denounced, 2 = unknown.</p>
<p dir="auto"><strong>Add a user to the vouched list:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Preview new file contents (default)
vouch add someuser

# Write the file in-place
vouch add someuser --write"><pre><span><span>#</span> Preview new file contents (default)</span>
vouch add someuser

<span><span>#</span> Write the file in-place</span>
vouch add someuser --write</pre></div>
<p dir="auto"><strong>Denounce a user:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Preview new file contents (default)
vouch denounce badactor

# With a reason
vouch denounce badactor --reason &quot;Submitted AI slop&quot;

# Write the file in-place
vouch denounce badactor --write"><pre><span><span>#</span> Preview new file contents (default)</span>
vouch denounce badactor

<span><span>#</span> With a reason</span>
vouch denounce badactor --reason <span><span>"</span>Submitted AI slop<span>"</span></span>

<span><span>#</span> Write the file in-place</span>
vouch denounce badactor --write</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">GitHub Integration</h4><a id="user-content-github-integration" aria-label="Permalink: GitHub Integration" href="#github-integration"></a></p>
<p dir="auto">Requires the <code>GITHUB_TOKEN</code> environment variable. If not set and <code>gh</code>
is available, the token from <code>gh auth token</code> is used.</p>
<p dir="auto"><strong>Check if a PR author is vouched:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Check PR author status (dry run)
vouch gh-check-pr 123 --repo owner/repo

# Auto-close unvouched PRs (dry run)
vouch gh-check-pr 123 --repo owner/repo --auto-close

# Actually close unvouched PRs
vouch gh-check-pr 123 --repo owner/repo --auto-close --dry-run=false

# Allow unvouched users, only block denounced
vouch gh-check-pr 123 --repo owner/repo --require-vouch=false --auto-close"><pre><span><span>#</span> Check PR author status (dry run)</span>
vouch gh-check-pr 123 --repo owner/repo

<span><span>#</span> Auto-close unvouched PRs (dry run)</span>
vouch gh-check-pr 123 --repo owner/repo --auto-close

<span><span>#</span> Actually close unvouched PRs</span>
vouch gh-check-pr 123 --repo owner/repo --auto-close --dry-run=false

<span><span>#</span> Allow unvouched users, only block denounced</span>
vouch gh-check-pr 123 --repo owner/repo --require-vouch=false --auto-close</pre></div>
<p dir="auto">Outputs status: <code>skipped</code> (bot/collaborator), <code>vouched</code>, <code>allowed</code>, or <code>closed</code>.</p>
<p dir="auto"><strong>Manage contributor status via issue comments:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Dry run (default)
vouch gh-manage-by-issue 123 456789 --repo owner/repo

# Actually perform the action
vouch gh-manage-by-issue 123 456789 --repo owner/repo --dry-run=false"><pre><span><span>#</span> Dry run (default)</span>
vouch gh-manage-by-issue 123 456789 --repo owner/repo

<span><span>#</span> Actually perform the action</span>
vouch gh-manage-by-issue 123 456789 --repo owner/repo --dry-run=false</pre></div>
<p dir="auto">Responds to comments from collaborators with write access:</p>
<ul dir="auto">
<li><code>vouch</code> — vouches for the issue author</li>
<li><code>vouch @user</code> — vouches for a specific user</li>
<li><code>vouch &lt;reason&gt;</code> — vouches for the issue author with a reason</li>
<li><code>vouch @user &lt;reason&gt;</code> — vouches for a specific user with a reason</li>
<li><code>denounce</code> — denounces the issue author</li>
<li><code>denounce @user</code> — denounces a specific user</li>
<li><code>denounce &lt;reason&gt;</code> — denounces the issue author with a reason</li>
<li><code>denounce @user &lt;reason&gt;</code> — denounces a specific user with a reason</li>
</ul>
<p dir="auto">Keywords are customizable via <code>--vouch-keyword</code> and <code>--denounce-keyword</code>.</p>
<p dir="auto">Outputs status: <code>vouched</code>, <code>denounced</code>, or <code>unchanged</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library</h3><a id="user-content-library" aria-label="Permalink: Library" href="#library"></a></p>
<p dir="auto">The module also exports a <code>lib</code> submodule for scripting:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use vouch/lib.nu *

let records = open VOUCHED.td
$records | check-user &quot;mitchellh&quot; --default-platform github  # &quot;vouched&quot;, &quot;denounced&quot;, or &quot;unknown&quot;
$records | add-user &quot;newuser&quot;                                # returns updated table
$records | denounce-user &quot;badactor&quot; &quot;reason&quot;                 # returns updated table
$records | remove-user &quot;olduser&quot;                             # returns updated table"><pre>use vouch<span>/lib.nu *</span>
<span></span>
<span>let records = open VOUCHED.td</span>
<span>$records | check-user "mitchellh" --default-platform github  # "vouched", "denounced", or "unknown"</span>
<span>$records | add-user "newuser"                                # returns updated table</span>
<span>$records | denounce-user "badactor" "reason"                 # returns updated table</span>
<span>$records | remove-user "olduser"                             # returns updated table</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Vouched File Format</h2><a id="user-content-vouched-file-format" aria-label="Permalink: Vouched File Format" href="#vouched-file-format"></a></p>
<p dir="auto">The vouch list is stored in a <code>.td</code> file. See
<a href="https://github.com/mitchellh/vouch/blob/main/VOUCHED.example.td">VOUCHED.example.td</a> for an example. The file is
looked up at <code>VOUCHED.td</code> or <code>.github/VOUCHED.td</code> by default.</p>
<div data-snippet-clipboard-copy-content="# Comments start with #
username
platform:username
-platform:denounced-user
-platform:denounced-user reason for denouncement"><pre><code># Comments start with #
username
platform:username
-platform:denounced-user
-platform:denounced-user reason for denouncement
</code></pre></div>
<ul dir="auto">
<li>One handle per line (without <code>@</code>), sorted alphabetically.</li>
<li>Optionally specify a platform prefix: <code>platform:username</code> (e.g., <code>github:mitchellh</code>).</li>
<li>Denounce a user by prefixing with <code>-</code>.</li>
<li>Optionally add details after a space following the handle.</li>
</ul>
<p dir="auto">The <code>from td</code> and <code>to td</code> commands are exported by the module, so
Nushell's <code>open</code> command works natively with <code>.td</code> files to decode
into structured tables and encode back to the file format with
comments and whitespace preserved.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><strong>What is <code>.td</code>?</strong> This stands for "Trustdown," a play on the
word "Markdown." I intend to formalize a specification for trust
lists (with no opinion on how they're created or used) so that software
systems like this Vouch project and others can coordinate with each
other. I'm not ready to publish a specification until vouch itself
stabilizes usage more.</p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI fatigue Is real and nobody talks about it (336 pts)]]></title>
            <link>https://siddhantkhare.com/writing/ai-fatigue-is-real</link>
            <guid>46934404</guid>
            <pubDate>Sun, 08 Feb 2026 14:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://siddhantkhare.com/writing/ai-fatigue-is-real">https://siddhantkhare.com/writing/ai-fatigue-is-real</a>, See on <a href="https://news.ycombinator.com/item?id=46934404">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><!----><p>I shipped more code last quarter than any quarter in my career. I also felt more drained than any quarter in my career. These two facts are not unrelated.</p>
<p>I build AI agent infrastructure for a living. I'm one of the core maintainers of <a href="https://openfga.dev/">OpenFGA</a> (CNCF Incubating), I built <a href="https://github.com/Siddhant-K-code/agentic-authz">agentic-authz</a> for agent authorization, I built <a href="https://distill.siddhantkhare.com/">Distill</a> for context deduplication, I shipped MCP servers. I'm not someone who dabbles with AI on the side. I'm deep in it. I build the tools that other engineers use to make AI agents work in production.</p>
<p>And yet, I hit a wall. The kind of exhaustion that no amount of tooling or workflow optimization could fix.</p>
<p>If you're an engineer who uses AI daily - for design reviews, code generation, debugging, documentation, architecture decisions - and you've noticed that you're somehow more tired than before AI existed, this post is for you. You're not imagining it. You're not weak. You're experiencing something real that the industry is aggressively pretending doesn't exist. And if someone who builds agent infrastructure full-time can burn out on AI, it can happen to anyone.</p>
<p>I want to talk about it honestly. Not the "AI is amazing and here's my workflow" version. The real version. The one where you stare at your screen at 11pm, surrounded by AI-generated code you still need to review, wondering why the tool that was supposed to save you time has consumed your entire day.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/1.png" alt="An overwhelmed engineer surrounded by code, errors, and notifications"></p>
<h2>The paradox nobody warned us about</h2>
<p>Here's the thing that broke my brain for a while: AI genuinely makes individual tasks faster. That's not a lie. What used to take me 3 hours now takes 45 minutes. Drafting a design doc, scaffolding a new service, writing test cases, researching an unfamiliar API. All faster.</p>
<p>But my days got harder. Not easier. Harder.</p>
<p>The reason is simple once you see it, but it took me months to figure out. When each task takes less time, you don't do fewer tasks. You do more tasks. Your capacity appears to expand, so the work expands to fill it. And then some. Your manager sees you shipping faster, so the expectations adjust. You see yourself shipping faster, so your own expectations adjust. The baseline moves.</p>
<p>Before AI, I might spend a full day on one design problem. I'd sketch on paper, think in the shower, go for a walk, come back with clarity. The pace was slow but the cognitive load was manageable. One problem. One day. Deep focus.</p>
<p>Now? I might touch six different problems in a day. Each one "only takes an hour with AI." But context-switching between six problems is brutally expensive for the human brain. The AI doesn't get tired between problems. I do.</p>
<p>This is the paradox: <strong>AI reduces the cost of production but increases the cost of coordination, review, and decision-making. And those costs fall entirely on the human.</strong></p>
<h2>You became a reviewer and you didn't sign up for it</h2>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/3.png" alt="AI dropping code onto a conveyor belt faster than a human can review"></p>
<p>Before AI, my job was: think about a problem, write code, test it, ship it. I was the creator. The maker. That's what drew most of us to engineering in the first place - the act of building.</p>
<p>After AI, my job increasingly became: prompt, wait, read output, evaluate output, decide if output is correct, decide if output is safe, decide if output matches the architecture, fix the parts that don't, re-prompt, repeat. I became a reviewer. A judge. A quality inspector on an assembly line that never stops.</p>
<p>This is a fundamentally different kind of work. Creating is energizing. Reviewing is draining. There's research on this - the psychological difference between generative tasks and evaluative tasks. Generative work gives you flow states. Evaluative work gives you decision fatigue.</p>
<p>I noticed it first during a week where I was using AI heavily for a new microservice. By Wednesday, I couldn't make simple decisions anymore. What should this function be named? I didn't care. Where should this config live? I didn't care. My brain was full. Not from writing code - from judging code. Hundreds of small judgments, all day, every day.</p>
<p>The cruel irony is that AI-generated code requires more careful review than human-written code. When a colleague writes code, I know their patterns, their strengths, their blind spots. I can skim the parts I trust and focus on the parts I don't. With AI, every line is suspect. The code looks confident. It compiles. It might even pass tests. But it could be subtly wrong in ways that only surface in production, under load, at 3am.</p>
<p>So you read every line. And reading code you didn't write, that was generated by a system that doesn't understand your codebase's history or your team's conventions, is exhausting work.</p>
<p>This is also why I think agent security and authorization matter so much. If we can't review everything AI produces - and we can't, not at scale - then we need systems that constrain what agents can do in the first place. Least-privilege access, scoped tokens, audit trails. The less you have to worry about "did the AI do something dangerous," the more cognitive budget you have for the work that actually matters. This isn't just a security problem. It's a human sustainability problem.</p>
<h2>The nondeterminism problem</h2>
<p>Engineers are trained on determinism. Same input, same output. That's the contract. That's what makes debugging possible. That's what makes reasoning about systems possible.</p>
<p>AI broke that contract.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/4.png" alt="Same prompt, same AI, different results - clean code or spaghetti"></p>
<p>I had a prompt that worked perfectly on Monday. Generated clean, well-structured code for an API endpoint. I used the same prompt on Tuesday for a similar endpoint. The output was structurally different, used a different error handling pattern, and introduced a dependency I didn't ask for.</p>
<p>Why? No reason. Or rather, no reason I can access. There's no stack trace for "the model decided to go a different direction today." There's no log that says "temperature sampling chose path B instead of path A." It just... happened differently.</p>
<p>For someone whose entire career is built on "if it broke, I can find out why," this is deeply unsettling. Not in a dramatic way. In a slow, grinding, background-anxiety way. You can never fully trust the output. You can never fully relax. Every interaction requires vigilance.</p>
<p>I tried to fight this. I version-controlled my prompts. I built elaborate system messages. I created templates. Some of it helped. None of it solved the fundamental problem: <strong>you are collaborating with a probabilistic system, and your brain is wired for deterministic ones.</strong> That mismatch is a constant, low-grade source of stress.</p>
<p>This frustration is actually what led me to build <a href="https://distill.siddhantkhare.com/">Distill</a> - deterministic context deduplication for LLMs. No LLM calls, no embeddings, no probabilistic heuristics. Pure algorithms that clean your context in ~12ms. I wanted at least one part of the AI pipeline to be something I could reason about, debug, and trust. If the model's output is going to be nondeterministic, the least I can do is make sure the input is clean and predictable.</p>
<p>The engineers I've talked to who handle this best are the ones who've made peace with it. They treat AI output like a first draft from a smart but unreliable intern. They expect to rewrite 30% of it. They budget time for that rewriting. They don't get frustrated when the output is wrong because they never expected it to be right. They expected it to be useful. There's a difference.</p>
<h2>The FOMO treadmill</h2>
<p>Take a breath and try to keep up with just the last few months. Claude Code ships sub-agents, then skills, then an Agent SDK, then Claude Cowork. OpenAI launches Codex CLI, then GPT-5.3-Codex - a model that literally helped code itself. New coding agents announce background mode with hundreds of concurrent autonomous sessions. Google drops Gemini CLI. GitHub adds an MCP Registry. Acquisitions happen weekly. Amazon Q Developer gets agentic upgrades. CrewAI, AutoGen, LangGraph, MetaGPT - pick your agent framework, there's a new one every week. Google announces A2A (Agent-to-Agent protocol) to compete with Anthropic's MCP. OpenAI ships its own Swarm framework. Kimi K2.5 drops with agent swarm architecture orchestrating 100 parallel agents. "Vibe coding" becomes a thing. OpenClaw launches a skills marketplace and within one week, researchers find 400+ malicious agent skills uploaded to ClawHub. And somewhere in the middle of all this, someone on LinkedIn posts "if you're not using AI agents with sub-agent orchestration in 2026, you're already obsolete."</p>
<p>That's not a year. That's a few months. And I'm leaving stuff out.</p>
<p>I fell into this trap hard. I was spending weekends evaluating new tools. Reading every changelog. Watching every demo. Trying to stay at the frontier because I was terrified of falling behind.</p>
<p>Here's what that actually looked like: I'd spend Saturday afternoon setting up a new AI coding tool. By Sunday I'd have a basic workflow. By the following Wednesday, someone would post about a different tool that was "way better." I'd feel a pang of anxiety. By the next weekend, I'd be setting up the new thing. The old thing would sit unused. One coding assistant to the next to the next and back to the first one. Each migration cost me a weekend and gave me maybe a 5% improvement that I couldn't even measure properly.</p>
<p>Multiply this by every category - coding assistants, chat interfaces, agent frameworks, multi-agent orchestration platforms, MCP servers, context management tools, prompt libraries, swarm architectures, skills marketplaces - and you get a person who is perpetually learning new tools and never getting deep with any of them. The Hacker News front page alone is enough to give you whiplash. One day it's "Show HN: Autonomous Research Swarm" and the next it's "Ask HN: How will AI swarms coordinate?" Nobody knows. Everyone's building anyway.</p>
<p>The worst part is the knowledge decay. I spent two weeks building a sophisticated prompt engineering workflow in early 2025. Carefully crafted system prompts, few-shot examples, chain-of-thought templates. It worked well. Three months later, the model updated, the prompting best practices shifted, and half my templates produced worse results than a simple one-liner. Those two weeks were gone. Not invested. Spent. The same thing happened with my MCP server setup - I built five custom servers (Dev.to publisher, Apple Notes integration, Python and TypeScript sandboxes, more), then the protocol evolved, then the MCP Registry launched on GitHub and suddenly there were thousands of pre-built ones. Some of my custom work became redundant overnight.</p>
<p>The agent framework churn is even worse. I watched teams go from LangChain to CrewAI to AutoGen to custom orchestration in the span of a year. Each migration meant rewriting integrations, relearning APIs, rebuilding workflows. The people who waited and did nothing often ended up in a better position than the people who adopted early and had to migrate twice.</p>
<p>I've since adopted a different approach. Instead of chasing every new tool, I go deep on the infrastructure layer underneath them. Tools come and go. The problems they solve don't. Context efficiency, agent authorization, audit trails, runtime security - these are durable problems regardless of which framework is trending this month. That's why I built <a href="https://github.com/Siddhant-K-code/agentic-authz">agentic-authz</a> on OpenFGA instead of tying it to any specific agent framework. That's why Distill works at the context level, not the prompt level. Build on the layer that doesn't churn.</p>
<p>I still track the landscape closely - you have to when you're building infrastructure for it. But I track it to understand where the ecosystem is going, not to adopt every new thing. There's a difference between being informed and being reactive.</p>
<h2>The "just one more prompt" trap</h2>
<p>This one is insidious. You're trying to get AI to generate something specific. The first output is 70% right. So you refine your prompt. The second output is 75% right but broke something the first one had correct. Third attempt: 80% right but now the structure is different. Fourth attempt: you've been at this for 45 minutes and you could have written the thing from scratch in 20.</p>
<p>I call this the prompt spiral. It's the AI equivalent of yak shaving. You started with a clear goal. Thirty minutes later you're debugging your prompt instead of debugging your code. You're optimizing your instructions to a language model instead of solving the actual problem.</p>
<p>The prompt spiral is especially dangerous because it feels productive. You're iterating. You're getting closer. Each attempt is slightly better. But the marginal returns are diminishing fast, and you've lost sight of the fact that the goal was never "get the AI to produce perfect output." The goal was to ship the feature.</p>
<p>I now have a hard rule: three attempts. If the AI doesn't get me to 70% usable in three prompts, I write it myself. No exceptions. This single rule has saved me more time than any prompting technique I've ever learned.</p>
<h2>Perfectionism meets probabilistic output</h2>
<p>Engineers tend toward perfectionism. We like clean code. We like tests that pass. We like systems that behave predictably. This is a feature, not a bug - it's what makes us good at building reliable software.</p>
<p>AI output is never perfect. It's always "pretty good." 70-80% there. The variable names are slightly off. The error handling is incomplete. The edge cases are ignored. The abstraction is wrong for your codebase. It works, but it's not right.</p>
<p>For a perfectionist, this is torture. Because "almost right" is worse than "completely wrong." Completely wrong, you throw away and start over. Almost right, you spend an hour tweaking. And tweaking AI output is uniquely frustrating because you're fixing someone else's design decisions - decisions that were made by a system that doesn't share your taste, your context, or your standards.</p>
<p>I had to learn to let go. Not of quality - I still care about quality. But of the expectation that AI would produce quality. I now treat every AI output as a rough draft. A starting point. Raw material. I mentally label it "draft" the moment it appears, and that framing change alone reduced my frustration by half.</p>
<p>The engineers who struggle most with AI are often the best engineers. The ones with the highest standards. The ones who notice every imperfection. AI rewards a different skill: the ability to extract value from imperfect output quickly, without getting emotionally invested in making it perfect.</p>
<h2>The thinking atrophy</h2>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/5.png" alt="A brain on a couch watching AI, its thinking muscles covered in cobwebs"></p>
<p>This is the one that scares me most.</p>
<p>I noticed it during a design review meeting. Someone asked me to reason through a concurrency problem on the whiteboard. No laptop. No AI. Just me and a marker. And I struggled. Not because I didn't know the concepts - I did. But because I hadn't exercised that muscle in months. I'd been outsourcing my first-draft thinking to AI for so long that my ability to think from scratch had degraded.</p>
<p>It's like GPS and navigation. Before GPS, you built mental maps. You knew your city. You could reason about routes. After years of GPS, you can't navigate without it. The skill atrophied because you stopped using it.</p>
<p>The same thing is happening with AI and engineering thinking. When you always ask AI first, you stop building the neural pathways that come from struggling with a problem yourself. The struggle is where learning happens. The confusion is where understanding forms. Skip that, and you get faster output but shallower understanding.</p>
<p>I now deliberately spend the first hour of my day without AI. I think on paper. I sketch architectures by hand. I reason through problems the slow way. It feels inefficient. It is inefficient. But it keeps my thinking sharp, and that sharpness pays dividends for the rest of the day when I do use AI - because I can evaluate its output better when my own reasoning is warmed up.</p>
<h2>The comparison trap</h2>
<p>Social media is full of people who seem to have AI figured out. They post their workflows. Their productivity numbers. Their "I built this entire app in 2 hours with AI" threads. And you look at your own experience - the failed prompts, the wasted time, the code you had to rewrite - and you think: what's wrong with me?</p>
<p>Nothing is wrong with you. Those threads are highlight reels. Nobody posts "I spent 3 hours trying to get Claude to understand my database schema and eventually gave up and wrote the migration by hand." Nobody posts "AI-generated code caused a production incident because it silently swallowed an error." Nobody posts "I'm tired."</p>
<p>The comparison trap is amplified by the fact that AI skill is hard to measure. With traditional engineering, you can look at someone's code and roughly gauge their ability. With AI, the output depends on the model, the prompt, the context, the temperature, the phase of the moon. Someone's impressive demo might not reproduce on your machine with your codebase.</p>
<p>I became much more selective about AI content on social media. I still follow the space closely - I have to, it's my job. But I shifted from consuming everyone's hot takes to focusing on people who are actually building and shipping, not just demoing. The ratio of signal to anxiety matters. If a feed is making you feel behind instead of informed, it's not serving you.</p>
<h2>What actually helped</h2>
<p>I'll be specific about what changed my relationship with AI from adversarial to sustainable.</p>
<p><strong>Time-boxing AI sessions.</strong> I don't use AI in an open-ended way anymore. I set a timer. 30 minutes for this task with AI. When the timer goes off, I ship what I have or switch to writing it myself. This prevents the prompt spiral and the perfectionism trap simultaneously.</p>
<p><strong>Separating AI time from thinking time.</strong> Morning is for thinking. Afternoon is for AI-assisted execution. This isn't rigid - sometimes I break the rule. But having a default structure means my brain gets both exercise and assistance in the right proportions.</p>
<p><strong>Accepting 70% from AI.</strong> I stopped trying to get perfect output. 70% usable is the bar. I'll fix the rest myself. This acceptance was the single biggest reducer of AI-related frustration in my workflow.</p>
<p><strong>Being strategic about the hype cycle.</strong> I track the AI landscape because I build infrastructure for it. But I stopped adopting every new tool the week it launches. I use one primary coding assistant and know it deeply. I evaluate new tools when they've proven themselves over months, not days. Staying informed and staying reactive are different things.</p>
<p><strong>Logging where AI helps and where it doesn't.</strong> I kept a simple log for two weeks: task, used AI (yes/no), time spent, satisfaction with result. The data was revealing. AI saved me significant time on boilerplate, documentation, and test generation. It cost me time on architecture decisions, complex debugging, and anything requiring deep context about my codebase. Now I know when to reach for it and when not to.</p>
<p><strong>Not reviewing everything AI produces.</strong> This was hard to accept. But if you're using AI to generate large amounts of code, you physically cannot review every line with the same rigor. I focus my review energy on the parts that matter most - security boundaries, data handling, error paths - and rely on automated tests and static analysis for the rest. Some roughness in non-critical code is acceptable.</p>
<h2>The sustainability question</h2>
<p>The tech industry has a burnout problem that predates AI. AI is making it worse, not better. Not because AI is bad, but because AI removes the natural speed limits that used to protect us.</p>
<p>Before AI, there was a ceiling on how much you could produce in a day. That ceiling was set by typing speed, thinking speed, the time it takes to look things up. It was frustrating sometimes, but it was also a governor. You couldn't work yourself to death because the work itself imposed limits.</p>
<p>AI removed the governor. Now the only limit is your cognitive endurance. And most people don't know their cognitive limits until they've blown past them.</p>
<p>I burned out in late 2025. Not dramatically - I didn't quit or have a breakdown. I just stopped caring. Code reviews became rubber stamps. Design decisions became "whatever AI suggests." I was going through the motions, producing more than ever, feeling less than ever. It took me a month to realize what had happened and another month to recover.</p>
<p>The recovery wasn't about using less AI. It was about using AI differently. With boundaries. With intention. With the understanding that I am not a machine and I don't need to keep pace with one. Working at <a href="https://ona.com/">Ona</a> helped me see this clearly - when you're building AI agent infrastructure for enterprise customers, you see the human cost of unsustainable AI workflows at scale. The problems aren't just personal. They're systemic. And they need to be solved at the tooling level, not just the individual level.</p>
<p>Ironically, the burnout period is when some of my best work happened. When I stopped trying to use every AI tool and started thinking about what was actually broken, I saw the problems clearly for the first time. Context windows filling up with garbage - that became Distill. Agents with all-or-nothing API key access - that became agentic-authz. The inability to audit what an agent actually did - that's becoming AgentTrace. The fatigue forced me to stop consuming and start building. Not building more features faster, but building the right things deliberately.</p>
<h2>The real skill</h2>
<p>Here's what I think the real skill of the AI era is. It's not prompt engineering. It's not knowing which model to use. It's not having the perfect workflow.</p>
<p>It's knowing when to stop.</p>
<p><img src="https://siddhantkhare.com/blog/ai-fatigue-is-real/6.png" alt="A hand pulling the STOP switch - good enough, ship it, go outside, rest"></p>
<p>Knowing when the AI output is good enough. Knowing when to write it yourself. Knowing when to close the laptop. Knowing when the marginal improvement isn't worth the cognitive cost. Knowing that your brain is a finite resource and that protecting it is not laziness - it's engineering.</p>
<p>We optimize our systems for sustainability. We add circuit breakers. We implement backpressure. We design for graceful degradation. We should do the same for ourselves.</p>
<p>AI is the most powerful tool I've ever used. It's also the most draining. Both things are true. The engineers who thrive in this era won't be the ones who use AI the most. They'll be the ones who use it the most wisely.</p>
<p>If you're tired, it's not because you're doing it wrong. It's because this is genuinely hard. The tool is new, the patterns are still forming, and the industry is pretending that more output equals more value. It doesn't. Sustainable output does.</p>
<p>I'm still building in this space every day. Agent authorization, context engineering, audit trails, runtime security - the infrastructure that makes AI agents actually work in production. I'm more committed to AI than ever. But I'm committed on my terms, at my pace, building things that matter instead of chasing things that trend.</p>
<p>Take care of your brain. It's the only one you've got, and no AI can replace it.</p>
<hr>
<p><em>I write about AI agent infrastructure, security, context engineering, and the human side of building with AI. You can find all my writing on my <a href="https://siddhantkhare.com/writing">writing page</a>.</em></p>
<!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am happier writing code by hand (297 pts)]]></title>
            <link>https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/</link>
            <guid>46934344</guid>
            <pubDate>Sun, 08 Feb 2026 14:12:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/">https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/</a>, See on <a href="https://news.ycombinator.com/item?id=46934344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work
and my phone. “What’s the point of it all?” I thought, LLMs can generate decent-ish and correct-ish looking code
while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same
feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow? Every. Single. Time.
I rediscovered the joy of coding.</p><p>Yes, coding is not software engineering, but for me, it is a fun and essential part of it.
In order to be effective at software engineering, you must be familiar with the problem space, and this requires
thinking and wrestling with the problem. You can’t truly know the pain of using an API by just reading its documentation or implementation.
You have to use it to experience it.
The act of writing code, despite being slower, was a way for me to wrestle with the problem space, a way for me to find out that my initial ideas didn’t work, a way for thinking.
Vibe coding interfered with that.</p><blockquote><p>If you’re thinking without writing, you only think you’re thinking.</p><p>– Leslie Lamport</p></blockquote><p>The other major part of the job is to ensure correctness. For me, it is much harder to verify the correctness of code
I didn’t write compared to code I wrote. The process of writing code helps internalize the context and is
easier for my brain to think deeply about it. If I outsource this to an LLM, I skip over the process of internalizing
the problem domain and I can’t be certain that the generated code is correct.</p><p>By design, vibe coding has an addictive nature to it, you write some instructions, and code that <em>looks</em> correct is generated.
Bam! Dopamine hit! If the code isn’t correct, then it’s just one prompt away from being correct,
right? <em>right?</em></p><p>Vibe coding also has the profound effect of turning my brain off and passively accepting changes.
When it is time to use my brain, the inertia is much harder to overcome and it is easy to choose the lazy way out.
At my lowest point, I even asked it to do a find-and-replace in a file. Something that takes a few seconds, now took
minutes and a network call.</p><p>Even if I generate a 1,000 line PR in 30 minutes I still need to understand and review it.
Since I am responsible for the code I ship, this makes me the bottleneck.</p><p>The common view of vibe coding is that it is neither good nor bad, it is a tool. But tools shape your workflow and
your thought process, and if a tool prevents you from thinking deeply, I don’t think it is a good tool.
If you are a knowledge worker, your core competency is your ability to think, and if a tool interferes with that, be
afraid, be very afraid.</p><p>Now, I would be lying if I said I didn’t use LLMs to generate code. I still use Claude, but I do so in a more
controlled manner. I copy-paste files that I think are necessary to provide the context, and then I copy-paste code and
ask it to make changes to it or write tests for it. This friction has several benefits. I can’t make changes that span
multiple files, this means the generated diff isn’t too large, and if I have to manually change other files I know how
the code fits in. Manually giving claude the context forces me to be familiar with the codebase myself, rather than tell
it to just “cook”. It turns code generation from a passive action to a deliberate <em>thoughtful</em> action.
It also keeps my brain engaged and active, which means I can still enter the <a href="https://en.wikipedia.org/wiki/Flow_(psychology)">flow state</a>.
I have found this to be the best of both worlds and a way to preserve my happiness at work.</p><p>Ultimately, life is too short to not optimize for happiness. <strong>Maybe</strong> (a big maybe) generating entire features would make me more
productive, but if it causes existential dread and makes me depressed, I don’t see it being productive in the long
run. Maybe you relate to some of the feelings. Maybe you don’t. But don’t be afraid to choose differently.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dave Farber has died (137 pts)]]></title>
            <link>https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/</link>
            <guid>46933401</guid>
            <pubDate>Sun, 08 Feb 2026 11:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/">https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/</a>, See on <a href="https://news.ycombinator.com/item?id=46933401">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>----- Forwarded message from "Cherry, Hei Yui WONG" &lt;cherry.heiyui@keio.jp&gt; -----</p><div><p>From: "Cherry, Hei Yui WONG" &lt;cherry.heiyui@keio.jp&gt;
Date: Sun, 8 Feb 2026 11:06:40 +0900
Subject: Sad news: Dave Farber has passed away</p>
<p>We are heartbroken to report that our colleague -- our mentor, friend, and
conscience -- David J. Farber passed away suddenly at his home in Roppongi,
Tokyo. He left us on Saturday, Feb. 7, 2026, at the too-young age of 91.</p>
<p>To his son Manny, he was simply ???Dad???, his bedrock whom he will miss
immeasurably. They spoke almost daily by video throughout his time in
Japan, and shared special times on numerous visits. He is survived by son
Manny Farber and daughter-in-law Mei Xu, daughter-in-law Carol Hagan and
grandsons Nate Farber and Sam Farber. He was preceded in death by his wife
Gloria (G.G.) and son Joe Farber.</p>
<p>Dave???s career began with his education at Stevens Institute of Technology,
which he loved deeply and served as a Trustee. He joined the legendary Bell
Labs during its heyday, and worked at the Rand Corporation. Along the way,
among countless other activities, he served as Chief Technologist of the
U.S. Federal Communications Commission; became a proficient
(instrument-rated) pilot; and was an active board member of the Electronic
Frontier Foundation, a digital civil-liberties organization.</p>
<p>His professional accomplishments and impact are almost endless, but often
captured by one moniker: ???grandfather of the Internet,??? acknowledging the
foundational contributions made by his many students at the University of
California, Irvine; the University of Delaware; the University of
Pennsylvania; and Carnegie Mellon University</p>
<p>In 2018, at the age of 83, Dave moved to Japan to become Distinguished
Professor at Keio University and Co-Director of the Keio Cyber Civilization
Research Center (CCRC). He loved teaching, and taught his final class on
January 22, 2026.</p>
<p>At CCRC, one of his most enjoyable activities was co-hosting the IP-Asia
online gathering, which has met every Monday for more than five years and
has addressed many aspects of the impact of technology on civilization.
Dave thrived in Japan in every way.</p>
<p>We, the IP-Asia community, will gather for an online remembrance of Dave at
the usual time and place, 2100 JST on Monday, February 9, 2026.</p>
<p>It???s impossible to summarize a life and career as rich and long as Dave???s
in our few words here. And each of us, even those who knew him for decades,
represent just one facet of his life.  But because we are here at its end,
we have the sad duty of sharing this news. Further information and a more
formal obituary are forthcoming.</p>
<p>With condolences to Manny and the rest of the family,</p>
<p>Jiro Kokuryo
Cherry Wong
Kaori Suzuki
Rodney Van Meter
Dan Gillmor</p>
<p>Manny can be reached at manny.farber@gmail.com.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why E cores make Apple silicon fast (162 pts)]]></title>
            <link>https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/</link>
            <guid>46933365</guid>
            <pubDate>Sun, 08 Feb 2026 11:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/">https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/</a>, See on <a href="https://news.ycombinator.com/item?id=46933365">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-90559">
	
	<!-- .entry-header -->

	
		<div data-first_letter="I">
		<p>If you use an Apple silicon Mac I’m sure you have been impressed by its performance. Whether you’re working with images, audio, video or building software, we’ve enjoyed a new turn of speed since the M1 on day 1. While most attribute this to their Performance cores, as it goes with the name, much is in truth the result of the unsung Efficiency cores, and how they keep background tasks where they should be.</p>
<p>To see what I mean, start your Apple silicon Mac up from the cold, and open Activity Monitor in its CPU view, with its CPU History window open as well. For the first five to ten minutes you’ll see its E cores are a wall of red and green with Spotlight’s indexing services, CGPDFService, mediaanalysisd, BackgroundShortcutRunner, Siri components, its initial Time Machine backup, and often an XProtect Remediator scan. Meanwhile its P cores are largely idle, and if you were to dive straight into using your working apps, there’s plenty of capacity for them to run unaffected by all that background mayhem.</p>
<p><span><img data-attachment-id="83626" data-permalink="https://eclecticlight.co/handecpuhistory/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg" data-orig-size="1396,1388" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="handecpuhistory" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=940" src="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg" alt="handecpuhistory" width="1396" height="1388" srcset="https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg 1396w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=150&amp;h=150 150w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=300&amp;h=298 300w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=768&amp;h=764 768w, https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg?w=1024&amp;h=1018 1024w" sizes="(max-width: 1396px) 100vw, 1396px"></span></p>
<p>It’s this stage that scares those who are still accustomed to using Intel Macs. Seeing processes using more than 100% CPU is terrifying, because they know that Intel cores can struggle under so much load, affecting user apps. But on an Apple silicon Mac, who notices or cares that there’s over a dozen mdworker processes each taking a good 50% CPU simultaneously? After all, this is what the Apple silicon architecture is designed for. Admittedly the impression isn’t helped by a dreadful piece of psychology, as those E cores at 100% are probably running at a frequency a quarter of those of P cores shown at the same 100%, making visual comparison <a href="https://eclecticlight.co/2024/11/08/why-cpu-in-activity-monitor-isnt-what-you-think/">completely false</a>.</p>
<p>This is nothing new. Apple brought it to the iPhone 7 in 2016, in its first SoC with separate P and E cores. That’s an implementation of Arm’s <a href="https://en.wikipedia.org/wiki/ARM_big.LITTLE" target="_blank">big.LITTLE</a> announced in 2011, and <a href="https://www.linuxjournal.com/article/8368" target="_blank">development work at Cray</a> and elsewhere in the previous decade. What makes the difference in Apple silicon Macs is how threads are allocated to the two different CPU core types on the basis of a metric known as <a href="https://eclecticlight.co/2025/05/09/what-is-quality-of-service-and-how-does-it-matter/">Quality of Service</a>, or QoS.</p>
<p>As with so much in today’s Macs, QoS has been around since <a href="https://developer.apple.com/documentation/foundation/qualityofservice" target="_blank">OS X 10.10 Yosemite</a>, six years before it became so central in performance. When all CPU cores are the same, it has limited usefulness over more traditional controls like Posix’s <code>nice</code> scheduling priority. All those background tasks still have to be completed, and giving them a lower priority only prolongs the time they take on the CPU cores, and the period in which the user’s apps are competing with them for CPU cycles.</p>
<p>With the experience gained from its iPhones and other devices, Apple’s engineers had a better solution for future Macs. In addition to providing priority-based queues, QoS makes a fundamental distinction between those threads run in the foreground, and those of the background. While foreground threads will be run on P cores when they’re available, they can also be scheduled on E cores when necessary. But background threads aren’t normally allowed to run on P cores, even if they’re delayed by the load on the E cores they’re restricted to. We know this from our inability to promote existing background threads to run on P cores using St. Clair Software’s <a href="https://www.stclairsoft.com/AppTamer/" target="_blank" rel="noopener">App Tamer</a> and the command tool <code>taskpolicy</code>.</p>
<p>This is why, even if you sit and watch all those background processes loading the E cores immediately after starting up, leaving the P cores mostly idle, macOS won’t try running them on its P cores. If it did, even if you wanted it to, the distinction between foreground and background, P and E cores would start to fall apart, our apps would suffer as a consequence, and battery endurance would decline. Gone are the days of <a href="https://eclecticlight.co/2020/06/10/what-to-do-when-a-process-is-using-excessive-cpu/">crashing mdworker processes</a> bringing our Macs to their knees with a spinning beachball every few seconds.</p>
<p>If seeing all those processes using high % CPU can look scary, the inevitable consequence in terms of software architecture might seem terrifying. Rather than building monolithic apps, many of their tasks are now broken out into discrete processes run in the background on demand, on the E cores when appropriate. The fact that an idle Mac has over 2,000 threads running in over 600 processes is good news, and the more of those that are run on the E cores, the faster our apps will be. The first and last M-series chips to have only two E cores were the M1 Pro and Max, since when every one has had at least four E cores, and some as many as six or eight.</p>
<p>Because Efficiency cores get the background threads off the cores we need for performance.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slop Terrifies Me (232 pts)]]></title>
            <link>https://ezhik.jp/ai-slop-terrifies-me/</link>
            <guid>46933067</guid>
            <pubDate>Sun, 08 Feb 2026 10:31:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ezhik.jp/ai-slop-terrifies-me/">https://ezhik.jp/ai-slop-terrifies-me/</a>, See on <a href="https://news.ycombinator.com/item?id=46933067">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <main> <article> <h2>🦔 🦔 🦔</h2> <figure>
										<a href="https://ezhik.jp/assets/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.png" target="_blank">
											<img src="https://ezhik.jp/assets/thumbnails/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.jpg">
										</a>
										
									</figure>
								
<p>What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?</p>

<p>Imagine if this is as good as AI gets. If this is where it stops, you'd still have models that can almost code a web browser, almost code a compiler—and can even present a pretty cool demo if allowed to take a few shortcuts. You'd still get models that can kinda-sorta simulate worlds and write kinda-sorta engaging stories. You'd still get self-driving cars that almost work, except when they don't. You get AI that can make you like 90% of a thing!</p>
<p>90% is a lot. Will you care about the last 10%?</p>
<p>I'm terrified that you won't.</p>
<p>I'm terrified of the <em>good enough to ship</em>—and I'm terrified of nobody else caring. I'm less afraid of AI agents writing apps that they will never experience than I am of the AI herders who won't care enough to actually learn what they ship. And I sure as hell am afraid of the people who will experience the slop and will be fine with it.</p>
<p>As a <a href="https://ezhik.jp/losing-the-plot-that-was-never-there">woodworking enthusiast</a> I am slowly making my peace with standing in the middle of an IKEA. But at the rate things are going in this dropshipping hell, IKEA would be the dream. Software <em>temufication</em> stings much more than software commoditization.</p>

<p>I think Claude and friends can help with crafting good software and with learning new technologies and programming languages—though I sure as hell move slower when I stop to learn and understand than the guy playing Dwarf Fortress with 17 agents. But at the same time AI models seem to constantly nudge towards that same median Next-React-Tailwind, <em>good enough</em> app. These things just don't handle going off the beaten path well.</p>
<figure>
										<a href="https://ezhik.jp/assets/claudes-mid-paper-clone.png" target="_blank">
											<img src="https://ezhik.jp/assets/thumbnails/claudes-mid-paper-clone.jpg" alt="Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired.">
										</a>
										<figcaption>Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired.</figcaption>
									</figure>
								
<p>Mind you, it's not like slop is anything new. A lot of human decisions had to happen before your backside ended up in an extremely uncomfortable chair, your search results got polluted by poorly-written SEO-optimized articles, and your brain had to deal with a ticket booking website with a user interface so poorly designed that it made you cry. So it's a people problem. Incentives just don't seem to align to make good software. Move fast and break things, etc, etc. You'll make a little artisan app, and if it's any good, Google will come along with a free clone, kill you, then kill its clone—and the world will be left with net zero new good software. And now, with AI agents, it gets even worse as agent herders can do the same thing much faster.</p>
<p>Developers aside, there's also the users. AI models can't be imaginative, and the developers can't afford to, but surely with AI tools, the gap between <em>users</em> and <em>developers</em> will be bridged, ChatGPT will become the new HyperCard and people will turn their ideas into reality with just a few sentences? There's so many people out there who are coding without knowing it, from Carol in Accounting making insane Excel spreadsheets to all the kids on TikTok automating their phones with Apple Shortcuts and hacking up cool Notion notebooks.</p>
<p>But what if those people are an aberration? What if this state of <em>tech learned helplessness</em> cannot be fixed? What if people really do just want a glorified little TV in their pocket? What if most people truly just don't care about tech problems, about privacy, about Liquid Glass, about Microsoft's upsells, about constantly dealing with apps and features which just <em>don't work</em>? What if there will be nobody left to carry the torch? What if the future of computing belongs not to artisan developers or Carol from Accounting, but to whoever can churn out the most software out the fastest? What if <em>good enough</em> really is good enough for most people?</p>
<p>I'm terrified that our craft will die, and nobody will even care to mourn it.</p> <h2>🦔 🦔 🦔</h2> <center><sub><time>2026-02-08</time>  • <a href="https://mastodon.social/@Ezhik/116034520904489092">Discuss on Mastodon</a> • <a href="https://bsky.app/profile/did:plc:png3xhpd6ccblcrcrxsxmfrs/post/3medprdipoc2l">Discuss on Bluesky</a></sub></center></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curating a Show on My Ineffable Mother, Ursula K. Le Guin (104 pts)]]></title>
            <link>https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/</link>
            <guid>46932985</guid>
            <pubDate>Sun, 08 Feb 2026 10:13:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/">https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/</a>, See on <a href="https://news.ycombinator.com/item?id=46932985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://hyperallergic.com/tag/opinion/">Opinion</a>
            
                <p>I would never have proposed this exhibition in her lifetime. This is, after all, a writer who said in an interview, “Don’t shove me into your damn pigeonhole, where I don’t fit, because I’m all over.”</p>

            <div>
                <p><a href="https://hyperallergic.com/author/theo/">
                                <img src="https://hyperallergic.com/content/images/size/w160/2026/01/theo-leguin.jpeg" alt="Theo Downes-Le Guin">
                            </a>
                </p>
                <div>
                    
                    <p><time datetime="2026-01-13">January 13, 2026</time>
                            <span><span>—</span> 5 min read</span>
                    </p>
                </div>
            </div>

                <figure>
        <img srcset="https://hyperallergic.com/content/images/size/w320/2026/01/0315_ORE_70s_uklwtheo-1.JPG 320w,
                    https://hyperallergic.com/content/images/size/w600/2026/01/0315_ORE_70s_uklwtheo-1.JPG 600w,
                    https://hyperallergic.com/content/images/size/w960/2026/01/0315_ORE_70s_uklwtheo-1.JPG 960w,
                    https://hyperallergic.com/content/images/size/w1200/2026/01/0315_ORE_70s_uklwtheo-1.JPG 1200w,
                    https://hyperallergic.com/content/images/size/w2400/2026/01/0315_ORE_70s_uklwtheo-1.JPG 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://hyperallergic.com/content/images/size/w1200/2026/01/0315_ORE_70s_uklwtheo-1.JPG" alt="Curating a Show on My Ineffable Mother, Ursula K. Le Guin">
            <figcaption><span>Theo Downes-Le Guin with his mother, Ursula K. Le Guin, photographed for the </span><i><em>Oregonian</em></i><span> c. 1968–69 (image courtesy the author)</span></figcaption>
    </figure>

        </header>

        <section>
            <p>PORTLAND — Under an acrylic case in an <a href="https://www.oregoncontemporary.org/a-larger-reality?ref=hyperallergic.com">exhibition</a> I curated about my mother, the writer Ursula K. Le Guin (1929–2018), sits the first typewriter she purchased. Compact and impossibly heavy, the machine comes from an era of word production so distant as to feel alien. The keyboard has no exclamation point. To create the favorite punctuation of tyrants and optimists, one must type an apostrophe, then backspace and type a period.</p><p>The Underwood waited in my parents’ attic for decades as Ursula and the world moved on to electronic typewriters and eventually to computers. I hoped visitors to <em>A Larger Reality</em>, at Oregon Contemporary through February 8, could experience a little of the residual magic that I find clings to it, pecking out whatever they please, taking home the original and leaving a carbon copy for posterity.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/ursula-le-guin-typewriter.jpg" alt="" loading="lazy" width="2000" height="1592" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/ursula-le-guin-typewriter.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/ursula-le-guin-typewriter.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/ursula-le-guin-typewriter.jpg 1600w, https://hyperallergic.com/content/images/2026/01/ursula-le-guin-typewriter.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Ursula K. Le Guin's Underwood typewriter (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>I’m happiest when the case is removed and the gallery is filled with the sound of metal meeting paper. Visitors who’ve never used a manual typewriter, or who don’t touch type, peck tentatively. Others engage physically, producing the familiar percussive <em>clack-clack</em> sound of my childhood. Either way, I feel I’m sharing not just a machine but a sacred trust with strangers who love <a href="https://www.loa.org/news-and-views/1375-fellow-writers-remember-ursula-k-le-guin-1929-2018/?ref=hyperallergic.com">my mother’s writing and words in general</a>.</p><p>People type poetry, memoir, fiction, epistles, articles, political statements, and fan mail on the Underwood. Some offer short tributes to Ursula or variations on “I can’t believe I’m typing on Ursula K. Le Guin’s typewriter.” Others compose prose or poetry on the spot. A few write nothing, go home to draft several pages, and return later to type something polished.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/ursula-note.jpg" alt="" loading="lazy" width="2000" height="1328" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/ursula-note.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/ursula-note.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/ursula-note.jpg 1600w, https://hyperallergic.com/content/images/2026/01/ursula-note.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>A scan of one of Le Guin's replies to fan mail (image courtesy Ursula K. Le Guin Foundation)</span></figcaption></figure><p>One visitor’s letter wondered how Ursula would feel knowing that her writing and cultural presence are no longer her own after death. The question is apt for me as curator and literary executor. Even a very private writer, while she is alive, exercises a restraining influence on people’s ability to misinterpret her words or life story. I can take comfort in my mother’s respect for the agency and necessity of readers in creating literature. For many years, her stock fan mail reply was a thank-you note, in her handwriting, acknowledging that “a book is just a box of words until a reader opens it.”</p><p>Over the past year, I’ve experienced cycles of grief and joy as I pored over my mother’s letters, manuscripts, and drawings to exhibit. I listened to hours of her voice, recreated an oak tree from her childhood and the room she wrote in from my childhood home. Curating an exhibition about your parent is a strange experience. Many visitors intuit this; the most common question I’m asked about the exhibition is what my mother would think about it.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg" alt="" loading="lazy" width="2000" height="1321" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 1600w, https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_3002-web.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Muralist Ursula Barton's 38-foot-long (~11.6-meter-long) painting of a dragon on the gallery walls (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>Honestly, I have no idea. I’ve learned not to second-guess my decisions by constantly asking myself, “What would Ursula do?” I would never have proposed this exhibition in her lifetime, for fear that she might see it as reductionist. This is, after all, a writer who said in an <a href="https://www.theparisreview.org/interviews/6253/the-art-of-fiction-no-221-ursula-k-le-guin?ref=hyperallergic.com">interview</a>, “Don’t shove me into your damn pigeonhole, where I don’t fit, because I’m all over. My tentacles are coming out of the pigeonhole in all directions.” Biographical and retrospective exhibitions exist in large part to assert and codify who an artist is. That is, at some level, a type of pigeon-holing.</p><p>This icon-production takes various forms, from hagiography to “objective” centrism to critique. True, if anyone is going to codify my mother, I prefer it to be me. I’m granted an advantage due to proximity and memory. But my version of Ursula is just one version. Even her version of herself was not authoritative. My mother remade herself, through her art, constantly and over decades. She revised everything from her early centering of male characters, to her <a href="https://lareviewofbooks.org/blog/essays/left-hand-darkness-light-metoo/?ref=hyperallergic.com">use of he/him</a> as the default pronoun in an imagined ambisexual world, to <a href="https://www.ursulakleguin.com/blog/95-are-they-going-to-say-this-is-fantasy?ref=hyperallergic.com">her critique</a> of a Kazuo Ishiguro novel. Rather than worship an immutable icon, we should aspire to her willingness to learn and change.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg" alt="" loading="lazy" width="2000" height="1333" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 1600w, https://hyperallergic.com/content/images/2026/01/OX-A-Larger-Reality-DZ2_2927-web.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>Installation view of </span><i><em>A Larger Reality</em></i><span> at Oregon Contemporary (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>From a technical, curatorial perspective, however, the mandate of narrative was my greatest hindrance. We’ve had it drummed into us that humans learn through stories, so anyone in an educative role must tell a story. For biographical exhibitions, however, linearity flattens the subject and condescends to the audience. I would go so far as to say this may be true for linearity imposed on any kind of exhibition.</p><p>My mother had something useful to say on this subject. Her essay <a href="http://bookshop.org/a/539/9781838003982?ref=hyperallergic.com"><em>The Carrier Bag Theory of Fiction</em></a><em> </em>(1986)<em>, </em>long a touchstone for writers, has recently become one for curators as well. Ursula posits, to simplify, that the reduction of narrative to linear, techno-heroic stories of conflict and conquest doesn’t serve us well. The hero’s journey remains a default model for storytelling in our culture, including for exhibitions. Ursula argues that the carrier bag, a humble yet capacious tool for gathering, is a better model for storytelling.</p><figure><img src="https://hyperallergic.com/content/images/2026/01/urs.jpg" alt="" loading="lazy" width="2000" height="1333" srcset="https://hyperallergic.com/content/images/size/w600/2026/01/urs.jpg 600w, https://hyperallergic.com/content/images/size/w1000/2026/01/urs.jpg 1000w, https://hyperallergic.com/content/images/size/w1600/2026/01/urs.jpg 1600w, https://hyperallergic.com/content/images/2026/01/urs.jpg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>The scales on Barton's dragon mural contain snippets of photos, book covers, and other visual ephemera from Le Guin's life. (photo by Mario Gallucci, courtesy Oregon Contemporary)</span></figcaption></figure><p>Exhibitions can be superb carrier bags for culture and knowledge. Few experiences offer so many chances for discursion and recursion, negative space and introspection. A carrier bag can expand to make room for the needs of the moment, for participation, spectacle, and immersion. In a carrier bag, none of these qualities, in balance, is antithetical.</p><p>For my part, releasing myself from the need to tell a tidy story about my mother led to an exhibition that is wordy, baggy, and inconclusive — but also, I believe, engaging and true to the subject.</p>

                  <ul>
                      <li>
                        <a href="https://hyperallergic.com/tag/opinion/">Opinion</a>
                      </li>
                      <li>
                        <a href="https://hyperallergic.com/tag/portland/">Portland</a>
                      </li>
                      <li>
                        <a href="https://hyperallergic.com/tag/ursula-k-le-guin/">Ursula K. Le Guin</a>
                      </li>
                  </ul>

        </section>

      

    </article>
    
        
                

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matchlock – Secures AI agent workloads with a Linux-based sandbox (111 pts)]]></title>
            <link>https://github.com/jingkaihe/matchlock</link>
            <guid>46932343</guid>
            <pubDate>Sun, 08 Feb 2026 08:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jingkaihe/matchlock">https://github.com/jingkaihe/matchlock</a>, See on <a href="https://news.ycombinator.com/item?id=46932343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Matchlock</h2><a id="user-content-matchlock" aria-label="Permalink: Matchlock" href="#matchlock"></a></p>
<p dir="auto">Matchlock is a CLI tool for running AI agents in ephemeral microVMs - with network allowlisting, secret injection via MITM proxy, and everything else blocked by default. Your secrets never enter the VM.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Matchlock?</h2><a id="user-content-why-matchlock" aria-label="Permalink: Why Matchlock?" href="#why-matchlock"></a></p>
<p dir="auto">AI agents need to run code, but giving them unrestricted access to your machine is a risk. Matchlock lets you hand an agent a full Linux environment that boots in under a second - isolated, disposable, and locked down by default.</p>
<p dir="auto">When your agent calls an API the real credentials are injected in-flight by the host. The sandbox only ever sees a placeholder. The network is sealed by default and nothing gets out unless you say so. Even if the agent is tricked into running something malicious your keys don't leak and there's nowhere for data to go. Inside the agent gets a full Linux environment to do whatever it needs. It can install packages and write files and make a mess. Outside your machine doesn't feel a thing. Every sandbox runs on its own copy-on-write filesystem that vanishes when you're done. Same CLI and same behaviour whether you're on a Linux server or a MacBook.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">System Requirements</h3><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<ul dir="auto">
<li><strong>Linux</strong> with KVM support</li>
<li><strong>macOS</strong> on Apple Silicon</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap jingkaihe/essentials
brew install matchlock"><pre>brew tap jingkaihe/essentials
brew install matchlock</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Basic
matchlock run --image alpine:latest cat /etc/os-release
matchlock run --image alpine:latest -it sh

# Network allowlist
matchlock run --image python:3.12-alpine \
  --allow-host &quot;api.openai.com&quot; python agent.py

# Secret injection (never enters the VM)
export ANTHROPIC_API_KEY=sk-xxx
matchlock run --image python:3.12-alpine \
  --secret ANTHROPIC_API_KEY@api.anthropic.com python call_api.py

# Long-lived sandboxes
matchlock run --image alpine:latest --rm=false   # prints VM ID
matchlock exec vm-abc12345 -it sh                # attach to it

# Lifecycle
matchlock list | kill | rm | prune

# Build from Dockerfile (uses BuildKit-in-VM)
matchlock build -f Dockerfile -t myapp:latest .

# Pre-build rootfs from registry image (caches for faster startup)
matchlock build alpine:latest

# Image management
matchlock image ls                                           # List all images
matchlock image rm myapp:latest                              # Remove a local image
docker save myapp:latest | matchlock image import myapp:latest  # Import from tarball"><pre><span><span>#</span> Basic</span>
matchlock run --image alpine:latest cat /etc/os-release
matchlock run --image alpine:latest -it sh

<span><span>#</span> Network allowlist</span>
matchlock run --image python:3.12-alpine \
  --allow-host <span><span>"</span>api.openai.com<span>"</span></span> python agent.py

<span><span>#</span> Secret injection (never enters the VM)</span>
<span>export</span> ANTHROPIC_API_KEY=sk-xxx
matchlock run --image python:3.12-alpine \
  --secret ANTHROPIC_API_KEY@api.anthropic.com python call_api.py

<span><span>#</span> Long-lived sandboxes</span>
matchlock run --image alpine:latest --rm=false   <span><span>#</span> prints VM ID</span>
matchlock <span>exec</span> vm-abc12345 -it sh                <span><span>#</span> attach to it</span>

<span><span>#</span> Lifecycle</span>
matchlock list <span>|</span> <span>kill</span> <span>|</span> rm <span>|</span> prune

<span><span>#</span> Build from Dockerfile (uses BuildKit-in-VM)</span>
matchlock build -f Dockerfile -t myapp:latest <span>.</span>

<span><span>#</span> Pre-build rootfs from registry image (caches for faster startup)</span>
matchlock build alpine:latest

<span><span>#</span> Image management</span>
matchlock image ls                                           <span><span>#</span> List all images</span>
matchlock image rm myapp:latest                              <span><span>#</span> Remove a local image</span>
docker save myapp:latest <span>|</span> matchlock image import myapp:latest  <span><span>#</span> Import from tarball</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">SDK</h2><a id="user-content-sdk" aria-label="Permalink: SDK" href="#sdk"></a></p>
<p dir="auto">Matchlock also ships with Go and Python SDKs for embedding sandboxes directly in your application. Allows you to programmatically launch VMs, exec commands, stream output and write files.</p>
<p dir="auto"><strong>Go</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/jingkaihe/matchlock/pkg/sdk&quot;
)

func main() {
	client, _ := sdk.NewClient(sdk.DefaultConfig())
	defer client.Close()

	sandbox := sdk.New(&quot;alpine:latest&quot;).
		AllowHost(&quot;dl-cdn.alpinelinux.org&quot;, &quot;api.anthropic.com&quot;).
		AddSecret(&quot;ANTHROPIC_API_KEY&quot;, os.Getenv(&quot;ANTHROPIC_API_KEY&quot;), &quot;api.anthropic.com&quot;)

	client.Launch(sandbox)
	client.Exec(&quot;apk add --no-cache curl&quot;)

	// The VM only ever sees a placeholder - the real key never enters the sandbox
	result, _ := client.Exec(&quot;echo $ANTHROPIC_API_KEY&quot;)
	fmt.Print(result.Stdout) // prints &quot;SANDBOX_SECRET_a1b2c3d4...&quot;

	curlCmd := `curl -s --no-buffer https://api.anthropic.com/v1/messages \
  -H &quot;content-type: application/json&quot; \
  -H &quot;x-api-key: $ANTHROPIC_API_KEY&quot; \
  -H &quot;anthropic-version: 2023-06-01&quot; \
  -d '{&quot;model&quot;:&quot;claude-haiku-4-5-20251001&quot;,&quot;max_tokens&quot;:1024,&quot;stream&quot;:true,
       &quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Explain TCP to me&quot;}]}'`
	client.ExecStream(curlCmd, os.Stdout, os.Stderr)
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"os"</span>

	<span>"github.com/jingkaihe/matchlock/pkg/sdk"</span>
)

<span>func</span> <span>main</span>() {
	<span>client</span>, <span>_</span> <span>:=</span> <span>sdk</span>.<span>NewClient</span>(<span>sdk</span>.<span>DefaultConfig</span>())
	<span>defer</span> <span>client</span>.<span>Close</span>()

	<span>sandbox</span> <span>:=</span> <span>sdk</span>.<span>New</span>(<span>"alpine:latest"</span>).
		<span>AllowHost</span>(<span>"dl-cdn.alpinelinux.org"</span>, <span>"api.anthropic.com"</span>).
		<span>AddSecret</span>(<span>"ANTHROPIC_API_KEY"</span>, <span>os</span>.<span>Getenv</span>(<span>"ANTHROPIC_API_KEY"</span>), <span>"api.anthropic.com"</span>)

	<span>client</span>.<span>Launch</span>(<span>sandbox</span>)
	<span>client</span>.<span>Exec</span>(<span>"apk add --no-cache curl"</span>)

	<span>// The VM only ever sees a placeholder - the real key never enters the sandbox</span>
	<span>result</span>, <span>_</span> <span>:=</span> <span>client</span>.<span>Exec</span>(<span>"echo $ANTHROPIC_API_KEY"</span>)
	<span>fmt</span>.<span>Print</span>(<span>result</span>.<span>Stdout</span>) <span>// prints "SANDBOX_SECRET_a1b2c3d4..."</span>

	<span>curlCmd</span> <span>:=</span> <span>`curl -s --no-buffer https://api.anthropic.com/v1/messages \</span>
<span>  -H "content-type: application/json" \</span>
<span>  -H "x-api-key: $ANTHROPIC_API_KEY" \</span>
<span>  -H "anthropic-version: 2023-06-01" \</span>
<span>  -d '{"model":"claude-haiku-4-5-20251001","max_tokens":1024,"stream":true,</span>
<span>       "messages":[{"role":"user","content":"Explain TCP to me"}]}'`</span>
	<span>client</span>.<span>ExecStream</span>(<span>curlCmd</span>, <span>os</span>.<span>Stdout</span>, <span>os</span>.<span>Stderr</span>)
}</pre></div>
<p dir="auto"><strong>Python</strong> (<a href="https://pypi.org/project/matchlock/" rel="nofollow">PyPI</a>)</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install matchlock
# or
uv add matchlock"><pre>pip install matchlock
<span><span>#</span> or</span>
uv add matchlock</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import os
import sys

from matchlock import Client, Config, Sandbox

sandbox = (
    Sandbox(&quot;alpine:latest&quot;)
    .allow_host(&quot;dl-cdn.alpinelinux.org&quot;, &quot;api.anthropic.com&quot;)
    .add_secret(
        &quot;ANTHROPIC_API_KEY&quot;, os.environ[&quot;ANTHROPIC_API_KEY&quot;], &quot;api.anthropic.com&quot;
    )
)

curl_cmd = &quot;&quot;&quot;curl -s --no-buffer https://api.anthropic.com/v1/messages \
  -H &quot;content-type: application/json&quot; \
  -H &quot;x-api-key: $ANTHROPIC_API_KEY&quot; \
  -H &quot;anthropic-version: 2023-06-01&quot; \
  -d '{&quot;model&quot;:&quot;claude-haiku-4-5-20251001&quot;,&quot;max_tokens&quot;:1024,&quot;stream&quot;:true,
       &quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Explain TCP/IP.&quot;}]}'&quot;&quot;&quot;

with Client(Config()) as client:
    client.launch(sandbox)
    client.exec(&quot;apk add --no-cache curl&quot;)
    client.exec_stream(curl_cmd, stdout=sys.stdout, stderr=sys.stderr)"><pre><span>import</span> <span>os</span>
<span>import</span> <span>sys</span>

<span>from</span> <span>matchlock</span> <span>import</span> <span>Client</span>, <span>Config</span>, <span>Sandbox</span>

<span>sandbox</span> <span>=</span> (
    <span>Sandbox</span>(<span>"alpine:latest"</span>)
    .<span>allow_host</span>(<span>"dl-cdn.alpinelinux.org"</span>, <span>"api.anthropic.com"</span>)
    .<span>add_secret</span>(
        <span>"ANTHROPIC_API_KEY"</span>, <span>os</span>.<span>environ</span>[<span>"ANTHROPIC_API_KEY"</span>], <span>"api.anthropic.com"</span>
    )
)

<span>curl_cmd</span> <span>=</span> <span>"""curl -s --no-buffer https://api.anthropic.com/v1/messages <span>\</span></span>
<span><span></span>  -H "content-type: application/json" <span>\</span></span>
<span><span></span>  -H "x-api-key: $ANTHROPIC_API_KEY" <span>\</span></span>
<span><span></span>  -H "anthropic-version: 2023-06-01" <span>\</span></span>
<span><span></span>  -d '{"model":"claude-haiku-4-5-20251001","max_tokens":1024,"stream":true,</span>
<span>       "messages":[{"role":"user","content":"Explain TCP/IP."}]}'"""</span>

<span>with</span> <span>Client</span>(<span>Config</span>()) <span>as</span> <span>client</span>:
    <span>client</span>.<span>launch</span>(<span>sandbox</span>)
    <span>client</span>.<span>exec</span>(<span>"apk add --no-cache curl"</span>)
    <span>client</span>.<span>exec_stream</span>(<span>curl_cmd</span>, <span>stdout</span><span>=</span><span>sys</span>.<span>stdout</span>, <span>stderr</span><span>=</span><span>sys</span>.<span>stderr</span>)</pre></div>
<p dir="auto">See full examples in <a href="https://github.com/jingkaihe/matchlock/blob/main/examples/go/main.go"><code>examples/go</code></a> and <a href="https://github.com/jingkaihe/matchlock/blob/main/examples/python/main.py"><code>examples/python</code></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<section data-identity="7411e843-c8cb-4028-b1f4-0130f21db874" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;graph LR\n    subgraph Host\n        CLI[\&quot;Matchlock CLI\&quot;]\n        Policy[\&quot;Policy Engine\&quot;]\n        Proxy[\&quot;Transparent Proxy + TLS MITM\&quot;]\n        VFS[\&quot;VFS Server\&quot;]\n\n        CLI --&amp;gt; Policy\n        CLI --&amp;gt; Proxy\n        Policy --&amp;gt; Proxy\n    end\n\n    subgraph VM[\&quot;Micro-VM (Firecracker / Virtualization.framework)\&quot;]\n        Agent[\&quot;Guest Agent\&quot;]\n        FUSE[\&quot;/workspace (FUSE)\&quot;]\n        Image[\&quot;Any OCI Image (Alpine, Ubuntu, etc.)\&quot;]\n\n        Agent --- Image\n        FUSE --- Image\n    end\n\n    Proxy -- \&quot;vsock :5000\&quot; --&amp;gt; Agent\n    VFS -- \&quot;vsock :5001\&quot; --&amp;gt; FUSE\n&quot;}" data-plain="graph LR
    subgraph Host
        CLI[&quot;Matchlock CLI&quot;]
        Policy[&quot;Policy Engine&quot;]
        Proxy[&quot;Transparent Proxy + TLS MITM&quot;]
        VFS[&quot;VFS Server&quot;]

        CLI --> Policy
        CLI --> Proxy
        Policy --> Proxy
    end

    subgraph VM[&quot;Micro-VM (Firecracker / Virtualization.framework)&quot;]
        Agent[&quot;Guest Agent&quot;]
        FUSE[&quot;/workspace (FUSE)&quot;]
        Image[&quot;Any OCI Image (Alpine, Ubuntu, etc.)&quot;]

        Agent --- Image
        FUSE --- Image
    end

    Proxy -- &quot;vsock :5000&quot; --> Agent
    VFS -- &quot;vsock :5001&quot; --> FUSE
">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph LR
    subgraph Host
        CLI["Matchlock CLI"]
        Policy["Policy Engine"]
        Proxy["Transparent Proxy + TLS MITM"]
        VFS["VFS Server"]

        CLI --&gt; Policy
        CLI --&gt; Proxy
        Policy --&gt; Proxy
    end

    subgraph VM["Micro-VM (Firecracker / Virtualization.framework)"]
        Agent["Guest Agent"]
        FUSE["/workspace (FUSE)"]
        Image["Any OCI Image (Alpine, Ubuntu, etc.)"]

        Agent --- Image
        FUSE --- Image
    end

    Proxy -- "vsock :5000" --&gt; Agent
    VFS -- "vsock :5001" --&gt; FUSE
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h3 tabindex="-1" dir="auto">Network Modes</h3><a id="user-content-network-modes" aria-label="Permalink: Network Modes" href="#network-modes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Mode</th>
<th>Mechanism</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td>Transparent proxy</td>
<td>nftables DNAT on ports 80/443</td>
</tr>
<tr>
<td>macOS</td>
<td>NAT (default)</td>
<td>Virtualization.framework built-in NAT</td>
</tr>
<tr>
<td>macOS</td>
<td>Interception (with <code>--allow-host</code>/<code>--secret</code>)</td>
<td>gVisor userspace TCP/IP at L4</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<p dir="auto">See <a href="https://github.com/jingkaihe/matchlock/blob/main/AGENTS.md">AGENTS.md</a> for the full developer reference.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DoNotNotify is now Open Source (330 pts)]]></title>
            <link>https://donotnotify.com/opensource.html</link>
            <guid>46932192</guid>
            <pubDate>Sun, 08 Feb 2026 07:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://donotnotify.com/opensource.html">https://donotnotify.com/opensource.html</a>, See on <a href="https://news.ycombinator.com/item?id=46932192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
      
    </header>

    <section>
      <h2>DoNotNotify is Now Open Source</h2>
      <p>
        We're excited to announce that DoNotNotify has been open sourced. The full source code for the app
        is now publicly available for anyone to view, study, and contribute to.
      </p>
      <p>
        You can find the source code on GitHub:
      </p>
      <p>
        <a href="https://github.com/anujja/DoNotNotify" target="_blank">github.com/anujja/DoNotNotify</a>
      </p>
    </section>

    <section>
      <h2>Why Open Source?</h2>
      <p>
        DoNotNotify was built with a strong commitment to privacy. By open sourcing the app, we're backing
        that commitment with full transparency. You no longer have to take our word for it — you can verify
        for yourself that the app does exactly what it says and nothing more.
      </p>
    </section>

    <section>
      <h2>Get Involved</h2>
      <p>
        We welcome contributions from the community. Whether it's reporting bugs, suggesting features,
        or submitting pull requests, your involvement helps make DoNotNotify better for everyone.
      </p>
      <ul>
        <li><a href="https://github.com/anujja/DoNotNotify/issues" target="_blank">Report a bug or request a feature</a>
        </li>
        <li><a href="https://github.com/anujja/DoNotNotify" target="_blank">Browse the source code</a></li>
      </ul>
    </section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The world heard JD Vance being booed at the Olympics. Except for viewers in USA (224 pts)]]></title>
            <link>https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics</link>
            <guid>46931948</guid>
            <pubDate>Sun, 08 Feb 2026 07:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics">https://www.theguardian.com/sport/2026/feb/07/jd-vance-boos-winter-olympics</a>, See on <a href="https://news.ycombinator.com/item?id=46931948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The modern Olympics sell themselves on a simple premise: the whole world, watching the same moment, at the same time. On Friday night in Milan, that illusion fractured in real time.</p><p>When Team USA entered the San Siro during the parade of nations, the speed skater Erin Jackson led the delegation into a wall of cheers. Moments later, when cameras cut to US vice-president JD Vance and second lady Usha Vance, large sections of the crowd responded with boos. Not subtle ones, but audible and sustained ones. <a href="https://x.com/donkoclock/status/2019887497891696788" data-link-name="in body link">Canadian viewers heard them</a>. Journalists seated in the press tribunes in the upper deck, <a href="https://www.theguardian.com/sport/2026/feb/06/intimate-and-enormous-milano-cortina-opening-ceremony-winter-olympics-2026" data-link-name="in body link">myself included</a>, clearly <a href="https://x.com/cbrennansports/status/2019884436121125181" data-link-name="in body link">heard them</a>. But as I quickly realized from a groupchat with friends back home, American viewers <a href="https://www.youtube.com/watch?v=H7Um9gPUoA0" data-link-name="in body link">watching NBC did not</a>.</p><figure id="60a9b2dc-fbb1-42da-a579-ddbed3a0a525" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;NBC appears to cut crowd’s booing of JD Vance from Winter Olympics broadcast&quot;,&quot;elementId&quot;:&quot;60a9b2dc-fbb1-42da-a579-ddbed3a0a525&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2026/feb/06/nbc-appears-to-cut-crowds-booing-of-jd-vance-from-winter-olympics-broadcast&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:8,&quot;display&quot;:0,&quot;theme&quot;:2}}"></gu-island></figure><p>On its own, the situation might once have passed unnoticed. But the defining feature of the modern sports media landscape is that no single broadcaster controls the moment any more. CBC carried it. The BBC liveblogged it. <a href="https://x.com/donkoclock/status/2019887497891696788" data-link-name="in body link">Fans clipped it</a>. Within minutes, multiple versions of the same happening were circulating online – some with boos, some without – turning what might once have been a routine production call into a case study in information asymmetry.</p><p>For its part, <a href="https://awfulannouncing.com/nbc/denies-editing-jd-vance-boos-olympics-opening-ceremony-audio.html" data-link-name="in body link">NBC has denied</a> editing the crowd audio, although it is difficult to resolve why the boos so audible in the stadium and on other broadcasts were absent for US viewers. But in a broader sense, it is becoming harder, not easier, to curate reality when the rest of the world is holding up its own camera angles. And that raises an uncomfortable question as the United States moves toward hosting two of the largest sporting events on the planet: the 2026 men’s World Cup and the 2028 Los Angeles Olympics.</p><p>If a US administration figure is booed at the Olympics in Los Angeles, or a World Cup match in New Jersey or Dallas, will American domestic broadcasts simply mute or avoid mentioning the crowd audio? If so, what happens when the world feed, or a foreign broadcaster, shows something else entirely? What happens when 40,000 phones in the stadium upload their own version in real time?</p><p>The risk is not just that viewers will see through it. It is that attempts to manage the narrative will make American broadcasters look less credible, not more. Because the audience now assumes there is always another angle. Every time a broadcaster makes that trade – credibility for insulation – it is a trade audiences eventually notice.</p><p>There is also a deeper structural pressure behind decisions like this. The Trump era has been defined in part by sustained <a href="https://www.theguardian.com/us-news/2024/nov/15/trump-sues-media-outlets-bias" data-link-name="in body link">hostility toward media institutions</a>. Broadcasters do not operate in a vacuum; they operate inside regulatory environments, political climates and corporate risk calculations. When presidents and their allies openly threaten or target networks, it is naive to pretend that has no downstream effect on editorial choices – especially in high-stakes live broadcasts tied to billion-dollar rights deals.</p><p>But there is a difference between contextual pressure and visible reality distortion. When global audiences can compare feeds in real time, the latter begins to resemble something else entirely: not editorial judgment, but narrative management. Which is why comparisons to Soviet-style state-controlled broadcasting models – once breathless rhetorical exaggerations – are starting to feel less hyperbolic.</p><p>The irony is that the Olympics themselves are built around the idea that sport can exist alongside political tension without pretending it does not exist. The International Olympic Committee’s own language – athletes should not be punished for governments’ actions – implicitly acknowledges that governments are part of the Olympic theater whether organizers like it or not.</p><p>Friday night illustrated that perfectly. American athletes were cheered, their enormous contingent given one of the most full-throated receptions of the night. The political emissaries were not universally welcomed. Both things can be true at once. Crowd dissent is not a failure of the Olympic ideal. In open societies, it is part of how public sentiment is expressed. Attempting to erase one side of that equation risks flattening reality into something audiences no longer trust. And if Milan was a warning shot, Los Angeles is the main event.</p><p>Since Donald Trump’s first term, American political coverage around sport has fixated on the micro-moments: Was the president booed or cheered? Did the broadcast show it? Did he attend or skip events likely to produce hostile crowds? The discourse has often felt like a Rorschach test, filtered through partisan interpretation and selective clips.</p><p>The LA Olympics will be something else entirely. There is no hiding from an opening ceremony. No ducking a stadium when the Olympic Charter requires the host country’s head of state to officially declare the Games open. No controlling how 200 international broadcasters carry the moment.</p><p>If Trump is still in the White House in mid-2028, one month after his 82nd birthday and in the thick of another heated US presidential campaign, he will stand in front of a global television audience as a key part of the opening ceremony. He will do so in California, in a political environment far less friendly than many domestic sporting venues he has appeared in over the past decade. And he will do it in a city synonymous with the political opposition, potentially in the back yard of <a href="https://www.theguardian.com/us-news/2025/oct/26/gavin-newsom-2028-presidential-race" data-link-name="in body link">the Democratic presidential candidate</a>.</p><p>There will be some cheers. There will almost certainly be boos. There will be everything in between. And there will be no way to make them disappear. The real risk for American broadcasters is not that dissent will be visible. It is that audiences will start assuming anything they do not show is being hidden. In an era when trust in institutions is already fragile, that is a dangerous place to operate from.</p><p>The Olympics have always been political, whether through boycotts, protests, symbolic gestures or crowd reactions. What has changed is not the politics. It is the impossibility of containing the optics.</p><p>Milan may ultimately be remembered as a small moment – a few seconds of crowd noise during a long ceremony. But it also felt like a preview of the next phase of global sport broadcasting: one where narrative control is shared, contested and instantly verifiable. The world is watching. And this time, it is also recording.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenClaw is changing my life (107 pts)]]></title>
            <link>https://reorx.com/blog/openclaw-is-changing-my-life/</link>
            <guid>46931805</guid>
            <pubDate>Sun, 08 Feb 2026 06:21:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reorx.com/blog/openclaw-is-changing-my-life/">https://reorx.com/blog/openclaw-is-changing-my-life/</a>, See on <a href="https://news.ycombinator.com/item?id=46931805">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>I want to share some thoughts on my recent experience with OpenClaw. Over the past year, I’ve been actively using Claude Code for development. Many people believed AI could already assist with programming—seemingly replacing programmers—but I never felt it brought any revolutionary change to the way I work.</p><p>Sure, agentic coding tools like Claude Code and Cursor have made writing code easier, but at the end of the day, I was still the one writing. It might look like the AI is doing the work, but “writing” is a broad term—writing is execution. As the person making code happen, I’m the one writing code. Whether I’m editing line by line, copy-pasting, or telling an AI what I want and letting it finish—it’s still me “writing.” My role as the programmer responsible for turning code into reality hasn’t changed.</p><p>My productivity did improve, but for any given task, I still had to jump into the project, set up the environment, open my editor and Claude Code terminal. I was still the operator; the only difference was that instead of typing code manually, I was typing intent into a chat box. That only changed one dimension. Testing, debugging—most of it still fell on me. There was some change, sure, but it wasn’t mature, and there was no fundamental shift. I still had to stay deeply involved and monitor everything. And it was exactly this deep involvement that kept me stuck in the role of code executor.</p><p>Then OpenClaw came along, and everything changed.</p><p>I once discussed with my wife: in the age of AI, should you aim to be a “super individual” or build a “super team”? My answer is: become a “super manager.” A super individual who can juggle multiple threads and coordinate numerous AI tools is essentially demonstrating great management skills. Being a super individual means using AI tools to lift yourself from a basic executor to a higher-level one, and eventually into a manager. So even if you’re going the super individual route, you need solid management awareness and methods to keep everything running smoothly.</p><p>OpenClaw gave me the chance to become that super manager. After a few rounds of practice, I found that I could completely step away from the programming environment and handle an entire project’s development, testing, deployment, launch, and usage—all through chatting on my phone. That’s something Claude Code simply can’t do, or rather, it was never designed to.</p><p>As a general-purpose agent, OpenClaw interacts through messaging apps via voice, accurately understands what I mean, works independently for extended periods, and has solid memory—it can persist the methods and rules it picks up during work, gradually evolving through use. These are the capabilities that make it the real turning point for replacing me as the code executor. The biggest change is this: I just need to express my intent, and it automatically creates the project, writes up a plan for me to review. I can discuss changes with it by voice, and then it executes—even directing Claude Code to do the actual coding.</p><p>It replaced the “me” that used to write code, truly stepping into the programmer role and freeing me to act as a manager. A manager shouldn’t get bogged down in the specifics—they should focus on the higher-level, abstract work. That’s what management really is. You could even flip it around: you’re only a true manager when you can get things done purely through communication. Before, Claude Code alone couldn’t get you there. But when you have a dedicated machine running 24/7, set up with all your tools, and an agent that understands your intent sitting at the computer writing and debugging code for you—that’s when things truly change. That’s when the revolution arrives.</p><p>This is the biggest shift OpenClaw has brought—it completely transformed my workflow. Whether it’s personal or commercial projects, I can step back and look at things from a management perspective. It’s like having a programmer who’s always on standby, ready to hop into meetings, discuss ideas, take on tasks, report back, and adjust course at any time. It can even juggle multiple roles, like having several programmers working on different projects simultaneously. Meanwhile, I can be the tech lead keeping tabs on specific project progress, or the project manager steering the overall schedule and direction.</p><p>This has truly freed up my productivity, letting me pursue so many ideas I couldn’t move forward on before. I feel like my life genuinely changed at this moment. I used to have way too many ideas but no way to build them all on my own—they just kept piling up. But now, everything is different.</p><p>It’s like I suddenly have a team, achieving the dream scenario I always imagined: owning a company, hiring people to bring my ideas to life, while I just focus on product design and planning. I’m closer than ever to that dream state. Before, that required serious capital. Without money, you can’t hire anyone, and you can’t just be the idea person. Unless you’re some trust fund kid doing it for fun, you’re stuck bouncing between “indie developer who wants to build multiple projects” and “solo hustler just trying to survive.”</p><p>But now, I can finally break out of that trap and move toward actually having a team. It keeps all my projects moving forward at any time. It’s not perfect yet, but I’ve taken the first step.</p><p>Thank you, OpenClaw. Thank you, AGI—for me, it’s already here. The gears of fate are turning in directions I never imagined.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LineageOS 23.2 (124 pts)]]></title>
            <link>https://lineageos.org/Changelog-31/</link>
            <guid>46931595</guid>
            <pubDate>Sun, 08 Feb 2026 05:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lineageos.org/Changelog-31/">https://lineageos.org/Changelog-31/</a>, See on <a href="https://news.ycombinator.com/item?id=46931595">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <h2 id="232-halftime-release">23.2 Halftime Release</h2>

<p>Hello again!</p>

<p>The last few months have been quite the endeavor, as we have been busy rebasing and updating LineageOS, on not one but two large AOSP releases. Nevertheless, we have persevered and are pleased to present LineageOS 23.2.</p>

<h3 id="changes-in-aosp">Changes in AOSP</h3>

<p>Over the last few years, AOSP has been shifting to a quarterly release cadence, meaning that new features and bug fixes are released every three months. Google recently announced that AOSP will be shifting to a biannual release cadence, meaning that the latest fixes and features will drop every six months now.</p>

<p>Android Security Bulletins will still be released, and picked to all supported LineageOS versions monthly.</p>

<p>While this change does not significantly alter our development process, it is worth noting that LineageOS will adopt a six-month cadence, with work on each new point release starting every six months.</p>

<h3 id="whats-changed">What’s Changed</h3>

<p>When you install or upgrade to this release, you will immediately notice the new UI and color scheme. This is because LineageOS is now officially using Google’s Material Expressive design system which focuses on expressive colors, and emotive design elements.</p>

<p>In addition, you may notice the updated UI of the Quick Settings panel, which now contains fully customizable tiles, which in our opinion are much more pleasant to use! In this release, you will also find an expanded dark theme, and more powerful file utilities surrounding private spaces.</p>

<h3 id="updated-apps">Updated Apps</h3>

<p>This release mainly focuses on the Material Expressive design language, and in the interest of keeping up with these guidelines, we have been working diligently at updating the default apps to Material Expressive.</p>

<h4 id="updater">Updater</h4>

<p>Contributor pjgowtham has been hard at work on updating the Updater app, and when those changes are merged, you will be treated to a completely redesigned UI, improved update management, delightful animations and various bugs fixed. It wasn’t quite ready for the 23.2 launch, but will be soon, so be on the lookout!</p>

<h4 id="other-apps">Other apps</h4>

<p>In addition to the Updater, Twelve (the default music app), Deskclock and ExactCalculator have received Material 3 Expressive updates, which brings them into the modern era. Stay tuned for similar updates to the other default apps!</p>

<h3 id="development-tools">Development Tools</h3>

<p>In the previous release changelog, we teased some development tools that were in the midst of being reviewed. These have now been merged, and developers have some new tools in their arsenal:</p>

<ul>
  <li><code>beautify_rro.py</code>: Beautifies multiple existing RROs given a directory.</li>
  <li><code>generate_rro.py</code>: Extracts RROs from a prebuilt overlays directory.</li>
  <li><code>update_certificates.py</code>: Updates app certificates given a stock dump directory.</li>
  <li><code>decompile_cil.py</code>: Extracts sepolicy rules from a prebuilt SELinux image.</li>
  <li><code>extract_aconfig.py</code>: Extracts config files from stock dumps.</li>
  <li><code>match_manifest_tarball.py</code>: Matches kernel (or source) tarball releases against public Git history.</li>
</ul>

<h3 id="leadership-changes">Leadership Changes</h3>

<p>After roughly seven years with Lineage, and another five with CyanogenMod, we’re sad to announce Rashed is stepping away from the project to spend more time offline. We wish him the best!</p>

<p>We’re also glad to announce that the current directors group have voted Nolen Johnson (npjohnson) in as the ninth director. Welcome!</p>

<h3 id="deprecations">Deprecations</h3>

<p>Overall, we feel that the 23.2 branch has reached feature and stability parity with 23.0 and is
ready for initial release.</p>

<p>We will still allow new LineageOS 21 submissions to be forked to the organization, but we will continue our policy of no longer
allowing newly submitted LineageOS 21 devices to ship.</p>

<p>LineageOS 23.2 will launch building for a decent selection of devices, with additional devices to
come as they meet the requirements specified by the
<a href="https://github.com/LineageOS/charter/blob/main/device-support-requirements.md">Charter</a> and are
marked as ready for builds by their maintainer.</p>

<h3 id="upgrading-to-lineageos-232">Upgrading to LineageOS 23.2</h3>

<p>To upgrade, please follow the upgrade guide for your device by clicking on it <a href="https://wiki.lineageos.org/devices/">here</a> and then on “Upgrade to a higher version of LineageOS”.</p>

<p>If you’re coming from an unofficial build, you need to follow the good ole’ install guide for your
device, just like anyone else looking to
install LineageOS for the first time. These can be found at the same place
<a href="https://wiki.lineageos.org/devices/">here</a> by clicking on your device and then on “Installation”.</p>

<p>Please note that if you’re currently on an official build, you <em>DO NOT</em> need to wipe your device,
unless your device’s wiki page specifically dictates otherwise, as is needed for some devices with
massive changes, such as a repartition.</p>

<h3 id="developers-developers-developers">Developers, Developers, Developers</h3>

<p>Or, in this case, maintainers, maintainers, maintainers. We want your device submissions!</p>

<p>If you’re a developer and would like to submit your device for officials, it’s easier than ever.
Just follow the instructions <a href="https://wiki.lineageos.org/submitting_device.html">here</a>.</p>

<p>The above also applies to people looking to bring back devices that were at one point official but
are no longer supported - seriously - even if it’s not yet completely compliant, submit it! Maybe
we can help you complete it.</p>

<p>After you submit, within generally a few weeks, but in most cases a week, you’ll receive some
feedback on your device submission; and if it’s up to par, you’ll be invited to our communications
instances and your device will be forked to LineageOS’s official repositories.</p>

<p>Don’t have the knowledge to maintain a device, but want to contribute to the platform? We have lots
of other things you can contribute to.
For instance, our apps suite is always looking for new people to help
<a href="https://wiki.lineageos.org/how-to/contributing-apps/">improve them</a>, or you can
<a href="https://wiki.lineageos.org/contributing_wiki">contribute to the wiki</a> by adding
more useful information &amp; documentation.
<a href="https://wiki.lineageos.org/usinggerrit-howto.html">Gerrit</a> is always open for submissions! Once
you’ve contributed a few things, send an email to devrel(at)lineageos.org detailing them, and we’ll
get you in the loop.</p>

<p>Also, if you sent a submission that didn’t get a response in the last few months, please follow up,
we’ve swapped providers again!</p>

<h3 id="generic-targets">Generic Targets</h3>

<p>We’ve talked about these before, but these are important, so we will cover them again.</p>

<p>Although we’ve had buildable generic targets since 2019, to make LineageOS more accessible to
developers, and really anyone interested in giving LineageOS a try, we’ve documented how to use
them in conjunction with the Android
<a href="https://wiki.lineageos.org/emulator.html">Emulator/Android Studio</a>!</p>

<p>Additionally, similar targets can now be used to build GSI in mobile, Android TV configurations,
and Android Automotive making LineageOS more accessible than ever to
devices using Google’s
<a href="https://android-developers.googleblog.com/2017/05/here-comes-treble-modular-base-for.html">Project Treble</a>.
We won’t be providing official builds for these targets, due to the fact the user experience varies
entirely based on how well the device manufacturer complied with Treble’s requirements, but feel
free to go build them yourself and give it a shot!</p>

<p>Please note that Android 12 (and by proxy all later Android versions) diverged GSI and Emulator
targets. Emulator targets reside in <code>lineage_sdk_$arch</code>, while GSI targets reside in
<code>lineage_gsi_$arch</code>.</p>

<p>Additionally, experimental targets now exist for QEMU-based virtual machine software (libvirt,
UTM, etc). Instructions on building and utilizing these targets can be found on
<a href="https://wiki.lineageos.org/libvirt-qemu">the Wiki</a>.</p>

<h3 id="translations">Translations</h3>

<p>Bilingual? Trilingual? Anything-lingual?</p>

<p>If you think you can help translate LineageOS to a different language, jump over to
<a href="https://wiki.lineageos.org/how-to/translate">our wiki</a> and have a go!
If your language is not supported natively in Android, reach out to us on Crowdin and we’ll take
the necessary
steps to include your language.
For instance, LineageOS is the first Android custom distribution that has complete support
for the Welsh (Cymraeg) language thanks to its community of translators.</p>

<p>Please, contribute to translations only if you are reasonably literate in the target language;
poor translations waste both our time and yours.</p>

<h3 id="build-roster">Build roster</h3>

<h4 id="added-232-devices">Added 23.2 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ASUS ZenFone 8</td>
      <td><a href="https://wiki.lineageos.org/devices/sake">sake</a></td>
      <td>DD3Boh, mikooomich</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>F(x)tec Pro¹ X</td>
      <td><a href="https://wiki.lineageos.org/devices/pro1x">pro1x</a></td>
      <td>BadDaemon, bgcngm, mccreary, npjohnson, qsnc, tdm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Fairphone 4</td>
      <td><a href="https://wiki.lineageos.org/devices/FP4">FP4</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Fairphone 5</td>
      <td><a href="https://wiki.lineageos.org/devices/FP5">FP5</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4 XL</td>
      <td><a href="https://wiki.lineageos.org/devices/coral">coral</a></td>
      <td>mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4</td>
      <td><a href="https://wiki.lineageos.org/devices/flame">flame</a></td>
      <td>mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4a 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/bramble">bramble</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 4a</td>
      <td><a href="https://wiki.lineageos.org/devices/sunfish">sunfish</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 5</td>
      <td><a href="https://wiki.lineageos.org/devices/redfin">redfin</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 5a</td>
      <td><a href="https://wiki.lineageos.org/devices/barbet">barbet</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/raven">raven</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6</td>
      <td><a href="https://wiki.lineageos.org/devices/oriole">oriole</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 6a</td>
      <td><a href="https://wiki.lineageos.org/devices/bluejay">bluejay</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cheetah">cheetah</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7</td>
      <td><a href="https://wiki.lineageos.org/devices/panther">panther</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 7a</td>
      <td><a href="https://wiki.lineageos.org/devices/lynx">lynx</a></td>
      <td>mikeioannina, niclimcy</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/husky">husky</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8</td>
      <td><a href="https://wiki.lineageos.org/devices/shiba">shiba</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 8a</td>
      <td><a href="https://wiki.lineageos.org/devices/akita">akita</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro Fold</td>
      <td><a href="https://wiki.lineageos.org/devices/comet">comet</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro XL</td>
      <td><a href="https://wiki.lineageos.org/devices/komodo">komodo</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/caiman">caiman</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9</td>
      <td><a href="https://wiki.lineageos.org/devices/tokay">tokay</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel 9a</td>
      <td><a href="https://wiki.lineageos.org/devices/tegu">tegu</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel Fold</td>
      <td><a href="https://wiki.lineageos.org/devices/felix">felix</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Google Pixel Tablet</td>
      <td><a href="https://wiki.lineageos.org/devices/tangorpro">tangorpro</a></td>
      <td>LuK1337, mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Lenovo Z5 Pro GT</td>
      <td><a href="https://wiki.lineageos.org/devices/heart">heart</a></td>
      <td>themard, optionaltoast</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Lenovo Z6 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/zippo">zippo</a></td>
      <td>Lucchetto, themard, einargednochsson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola defy 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/bathena">bathena</a></td>
      <td>Deivid Ignacio Parra (Deivid21), Francisco Sanchez (Fraaxius)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 20 pro</td>
      <td><a href="https://wiki.lineageos.org/devices/pstar">pstar</a></td>
      <td>npjohnson, SGCMarkus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 20</td>
      <td><a href="https://wiki.lineageos.org/devices/berlin">berlin</a></td>
      <td>npjohnson, SGCMarkus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/berlna">berlna</a></td>
      <td>SyberHexen</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 2024</td>
      <td><a href="https://wiki.lineageos.org/devices/avatrn">avatrn</a></td>
      <td>elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30 fusion</td>
      <td><a href="https://wiki.lineageos.org/devices/tundra">tundra</a></td>
      <td>themard, electimon</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30 neo</td>
      <td><a href="https://wiki.lineageos.org/devices/miami">miami</a></td>
      <td>marcost2</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 30</td>
      <td><a href="https://wiki.lineageos.org/devices/dubai">dubai</a></td>
      <td>themard, sb6596, Demon000</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge 40 pro / Motorola moto X40 / Motorola edge+ (2023)</td>
      <td><a href="https://wiki.lineageos.org/devices/rtwo">rtwo</a></td>
      <td>sgcmarkus, themard</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola edge s / Motorola moto g100</td>
      <td><a href="https://wiki.lineageos.org/devices/nio">nio</a></td>
      <td>dianlujitao</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto e7 plus / Lenovo K12</td>
      <td><a href="https://wiki.lineageos.org/devices/guam">guam</a></td>
      <td>Rajin Gangadharan (GRajin), Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g 5G - 2024</td>
      <td><a href="https://wiki.lineageos.org/devices/fogo">fogo</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g power 2021</td>
      <td><a href="https://wiki.lineageos.org/devices/borneo">borneo</a></td>
      <td>Syed Fawwaz Hussain (Fazwalrus), Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g stylus 5G (2022)</td>
      <td><a href="https://wiki.lineageos.org/devices/milanf">milanf</a></td>
      <td>AnierinBliss</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g stylus 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/denver">denver</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g10 / Motorola moto g10 power / Lenovo K13 Note</td>
      <td><a href="https://wiki.lineageos.org/devices/capri">capri</a></td>
      <td>Deivid Ignacio Parra (Deivid21), Sultanahamer</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g200 5G / Motorola Edge S30</td>
      <td><a href="https://wiki.lineageos.org/devices/xpeng">xpeng</a></td>
      <td>themard, rogers2602</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g30 / Lenovo K13 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/caprip">caprip</a></td>
      <td>mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g32</td>
      <td><a href="https://wiki.lineageos.org/devices/devon">devon</a></td>
      <td>Dhina17, mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g34 5G / Motorola moto g45 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/fogos">fogos</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g42</td>
      <td><a href="https://wiki.lineageos.org/devices/hawao">hawao</a></td>
      <td>Dhina17, mikeioannina, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g52</td>
      <td><a href="https://wiki.lineageos.org/devices/rhode">rhode</a></td>
      <td>Dhina17, mikeioannina, tomoms, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g82 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/rhodep">rhodep</a></td>
      <td>AnandSuresh02, sevenrock</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g84 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/bangkk">bangkk</a></td>
      <td>mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g9 play / Motorola moto g9 / Lenovo K12 Note</td>
      <td><a href="https://wiki.lineageos.org/devices/guamp">guamp</a></td>
      <td>DelightReza, Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Motorola moto g9 power / Lenovo K12 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cebu">cebu</a></td>
      <td>Deivid Ignacio Parra (Deivid21)</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nothing Phone (1)</td>
      <td><a href="https://wiki.lineageos.org/devices/Spacewar">Spacewar</a></td>
      <td>zlewchan, ko_ko_konb</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nothing Phone (2)</td>
      <td><a href="https://wiki.lineageos.org/devices/Pong">Pong</a></td>
      <td>chandu078</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Nubia Mini 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/TP1803">TP1803</a></td>
      <td>ArianK16a, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 11 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/salami">salami</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 12</td>
      <td><a href="https://wiki.lineageos.org/devices/waffle">waffle</a></td>
      <td>chandu078</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 12R</td>
      <td><a href="https://wiki.lineageos.org/devices/aston">aston</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 13</td>
      <td><a href="https://wiki.lineageos.org/devices/dodge">dodge</a></td>
      <td>bgcngm, chandu078, dianlujitao, ItsVixano</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 13R</td>
      <td><a href="https://wiki.lineageos.org/devices/giulia">giulia</a></td>
      <td>chandu078, madmax</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7 Pro / OnePlus 7 Pro (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/guacamole">guacamole</a></td>
      <td>LuK1337, elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7</td>
      <td><a href="https://wiki.lineageos.org/devices/guacamoleb">guacamoleb</a></td>
      <td>shantanu-sarkar</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7T / OnePlus 7T (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/hotdogb">hotdogb</a></td>
      <td>LuK1337, Onelots</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 7T Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/hotdog">hotdog</a></td>
      <td>qsnc</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8 / OnePlus 8 (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/instantnoodle">instantnoodle</a></td>
      <td>jabashque</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/instantnoodlep">instantnoodlep</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 8T / OnePlus 8T (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/kebab">kebab</a></td>
      <td>LuK1337, mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9 / OnePlus 9 (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonade">lemonade</a></td>
      <td>mikeioannina, tangalbert919, ZVNexus</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9 Pro / OnePlus 9 Pro (T-Mobile)</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonadep">lemonadep</a></td>
      <td>LuK1337, bgcngm, mikeioannina</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9R</td>
      <td><a href="https://wiki.lineageos.org/devices/lemonades">lemonades</a></td>
      <td>DaemonMCR, Tuan Anh</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus 9RT</td>
      <td><a href="https://wiki.lineageos.org/devices/martini">martini</a></td>
      <td>basamaryan</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/corvette">corvette</a></td>
      <td>chandu078, LucasBlackLu</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3</td>
      <td><a href="https://wiki.lineageos.org/devices/astonc">astonc</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 3V</td>
      <td><a href="https://wiki.lineageos.org/devices/audi">audi</a></td>
      <td>anky894</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Ace 5</td>
      <td><a href="https://wiki.lineageos.org/devices/giuliac">giuliac</a></td>
      <td>chandu078, madmax</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord 4</td>
      <td><a href="https://wiki.lineageos.org/devices/avalon">avalon</a></td>
      <td>anky894</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord 5</td>
      <td><a href="https://wiki.lineageos.org/devices/lexus">lexus</a></td>
      <td>grepfox</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE 2 Lite 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/oscaro">oscaro</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE 3 Lite 5G / OnePlus Nord N30 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/larry">larry</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord CE4</td>
      <td><a href="https://wiki.lineageos.org/devices/benz">benz</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord N20</td>
      <td><a href="https://wiki.lineageos.org/devices/gunnar">gunnar</a></td>
      <td>tangalbert919</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Nord N200</td>
      <td><a href="https://wiki.lineageos.org/devices/dre">dre</a></td>
      <td>tangalbert919, elginsk8r</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Pad 2 Pro / OnePlus Pad 3</td>
      <td><a href="https://wiki.lineageos.org/devices/erhai">erhai</a></td>
      <td>LuK1337, bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>OnePlus Pad Pro / OnePlus Pad 2</td>
      <td><a href="https://wiki.lineageos.org/devices/caihong">caihong</a></td>
      <td>inferno0230</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Razer Edge 5G / Razer Edge WiFi</td>
      <td><a href="https://wiki.lineageos.org/devices/nicole">nicole</a></td>
      <td>AnierinBliss, balika011, mikeioannina, npjohnson</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Realme 10 Pro 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/luigi">luigi</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Realme 9 Pro 5G / Realme 9 5G / Realme Q5</td>
      <td><a href="https://wiki.lineageos.org/devices/oscar">oscar</a></td>
      <td>Vivekachooz</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy A21s</td>
      <td><a href="https://wiki.lineageos.org/devices/a21s">a21s</a></td>
      <td>DaemonMCR</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy A71</td>
      <td><a href="https://wiki.lineageos.org/devices/a71">a71</a></td>
      <td>Haky86</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy F62 / Samsung Galaxy M62</td>
      <td><a href="https://wiki.lineageos.org/devices/f62">f62</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/d1x">d1x</a></td>
      <td>Rocky7842, Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10</td>
      <td><a href="https://wiki.lineageos.org/devices/d1">d1</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10+ 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/d2x">d2x</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Note10+</td>
      <td><a href="https://wiki.lineageos.org/devices/d2s">d2s</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/beyondx">beyondx</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond1lte">beyond1lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10+</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond2lte">beyond2lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S10e</td>
      <td><a href="https://wiki.lineageos.org/devices/beyond0lte">beyond0lte</a></td>
      <td>Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 (4G/5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/x1s">x1s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 FE (Exynos)</td>
      <td><a href="https://wiki.lineageos.org/devices/r8s">r8s</a></td>
      <td>CmdCtrlDevic3</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 FE (Snapdragon) / Samsung Galaxy S20 FE 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/r8q">r8q</a></td>
      <td>ata-kaner</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20 Ultra (5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/z3s">z3s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy S20+ (4G/5G)</td>
      <td><a href="https://wiki.lineageos.org/devices/y2s">y2s</a></td>
      <td>ExtremeXT, fcuzzocrea</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab A7 10.4 2020 (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4l">gta4l</a></td>
      <td>chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab A7 10.4 2020 (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4lwifi">gta4lwifi</a></td>
      <td>chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S6 Lite (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4xl">gta4xl</a></td>
      <td>haggertk, Linux4</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S6 Lite (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gta4xlwifi">gta4xlwifi</a></td>
      <td>Linux4, haggertk</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S7 (LTE)</td>
      <td><a href="https://wiki.lineageos.org/devices/gts7l">gts7l</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Samsung Galaxy Tab S7 (Wi-Fi)</td>
      <td><a href="https://wiki.lineageos.org/devices/gts7lwifi">gts7lwifi</a></td>
      <td>bgcngm</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Solana Saga</td>
      <td><a href="https://wiki.lineageos.org/devices/ingot">ingot</a></td>
      <td>mikeioannina, npjohnson, tomoms</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 II</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx203">pdx203</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 III</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx215">pdx215</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx223">pdx223</a></td>
      <td>Tuan Anh</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 1 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx234">pdx234</a></td>
      <td>hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx225">pdx225</a></td>
      <td>LuK1337, jmpfbmx</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 Plus</td>
      <td><a href="https://wiki.lineageos.org/devices/mermaid">mermaid</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx235">pdx235</a></td>
      <td>jmpfbmx, LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 10</td>
      <td><a href="https://wiki.lineageos.org/devices/kirin">kirin</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 II</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx206">pdx206</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 III</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx214">pdx214</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 IV</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx224">pdx224</a></td>
      <td>Tuan Anh, wolfhechel</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia 5 V</td>
      <td><a href="https://wiki.lineageos.org/devices/pdx237">pdx237</a></td>
      <td>kyasu, hellobbn</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2 Plus</td>
      <td><a href="https://wiki.lineageos.org/devices/voyager">voyager</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2 Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/discovery">discovery</a></td>
      <td>LuK1337</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Sony Xperia XA2</td>
      <td><a href="https://wiki.lineageos.org/devices/pioneer">pioneer</a></td>
      <td>LuK1337, jmpfbmx</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/zeus">zeus</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12</td>
      <td><a href="https://wiki.lineageos.org/devices/cupid">cupid</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12S Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/unicorn">unicorn</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12S Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/thor">thor</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi 12T Pro / Xiaomi Redmi K50 Ultra</td>
      <td><a href="https://wiki.lineageos.org/devices/diting">diting</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi MIX Fold 2</td>
      <td><a href="https://wiki.lineageos.org/devices/zizhan">zizhan</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/cmi">cmi</a></td>
      <td>luffitys</td>
      <td>22.2</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10</td>
      <td><a href="https://wiki.lineageos.org/devices/umi">umi</a></td>
      <td>0xCAFEBABE, przekichane</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 10T Lite 5G / Xiaomi Mi 10i 5G / Xiaomi Redmi Note 9 Pro 5G</td>
      <td><a href="https://wiki.lineageos.org/devices/gauguin">gauguin</a></td>
      <td>Penguin766, Lynnrin</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi 9T / Xiaomi Redmi K20 (China) / Xiaomi Redmi K20 (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/davinci">davinci</a></td>
      <td>ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Mi Note 10 / Xiaomi Mi Note 10 Pro / Xiaomi Mi CC9 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/tucana">tucana</a></td>
      <td>SanyaPilot</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F3 / Xiaomi Redmi K40 / Xiaomi Mi 11X</td>
      <td><a href="https://wiki.lineageos.org/devices/alioth">alioth</a></td>
      <td>SahilSonar, SebaUbuntu, althafvly, chrmhoffmann</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F5 (Global) / Xiaomi POCO F5 (India) / Xiaomi Redmi Note 12 Turbo</td>
      <td><a href="https://wiki.lineageos.org/devices/marble">marble</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F5 Pro / Xiaomi Redmi K60</td>
      <td><a href="https://wiki.lineageos.org/devices/mondrian">mondrian</a></td>
      <td>Adrianyyy, ArianK16a</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 3S / Xiaomi Redmi 3X / Xiaomi Redmi 4 (India) / Xiaomi Redmi 4X / Xiaomi Redmi Note 5A Prime / Xiaomi Redmi Y1 Prime</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi8937">Mi8937</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 4A / Xiaomi Redmi 5A / Xiaomi Redmi Note 5A Lite / Xiaomi Redmi Y1 Lite</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi8917">Mi8917</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi 7A / Xiaomi Redmi 8 / Xiaomi Redmi 8A / Xiaomi Redmi 8A Dual</td>
      <td><a href="https://wiki.lineageos.org/devices/Mi439">Mi439</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 10 Pro / Xiaomi Redmi Note 10 Pro (India) / Xiaomi Redmi Note 10 Pro Max (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/sweet">sweet</a></td>
      <td>basamaryan, danielml3</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 13 Pro 5G / Xiaomi Redmi Note 13 Pro 5G (India) / Xiaomi Redmi Note 13 Pro 5G (China) / Xiaomi POCO X6 5G / Xiaomi POCO X6 5G (India)</td>
      <td><a href="https://wiki.lineageos.org/devices/garnet">garnet</a></td>
      <td>adarshgrewal</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 7 Pro</td>
      <td><a href="https://wiki.lineageos.org/devices/violet">violet</a></td>
      <td>0xCAFEBABE</td>
      <td>23.0</td>
    </tr>
    <tr>
      <td>Xiaomi Redmi Note 8 / Xiaomi Redmi Note 8T</td>
      <td><a href="https://wiki.lineageos.org/devices/ginkgo">ginkgo</a></td>
      <td>Skyblueborb, mikeioannina, programminghoch10</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>

<h4 id="added-23-devices">Added 23 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>LG V60 ThinQ</td>
      <td><a href="https://wiki.lineageos.org/devices/timelm">timelm</a></td>
      <td>pnguyen879</td>
      <td>22.2</td>
    </tr>
    <tr>
      <td>Xiaomi POCO F6 Pro / Xiaomi Redmi K70</td>
      <td><a href="https://wiki.lineageos.org/devices/vermeer">vermeer</a></td>
      <td>Lunark</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<h4 id="added-222-devices">Added 22.2 devices</h4>

<table>
  <thead>
    <tr>
      <th>Device name</th>
      <th>Wiki</th>
      <th>Maintainers</th>
      <th>Moved from</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Google Jamboard [Android TV]</td>
      <td><a href="https://wiki.lineageos.org/devices/baracus">baracus</a></td>
      <td>npjohnson, webgeek1234</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Google Jamboard [Tablet]</td>
      <td><a href="https://wiki.lineageos.org/devices/baracus_tab">baracus_tab</a></td>
      <td>npjohnson, webgeek1234</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Nubia X</td>
      <td><a href="https://wiki.lineageos.org/devices/nx616j">nx616j</a></td>
      <td>rtx4d</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Xiaomi Mi Note 2</td>
      <td><a href="https://wiki.lineageos.org/devices/scorpio">scorpio</a></td>
      <td>Onelots</td>
      <td>18.1</td>
    </tr>
  </tbody>
</table>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vouch (133 pts)]]></title>
            <link>https://twitter.com/mitchellh/status/2020252149117313349</link>
            <guid>46930961</guid>
            <pubDate>Sun, 08 Feb 2026 03:09:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/mitchellh/status/2020252149117313349">https://twitter.com/mitchellh/status/2020252149117313349</a>, See on <a href="https://news.ycombinator.com/item?id=46930961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Haskell for all: Beyond agentic coding (213 pts)]]></title>
            <link>https://haskellforall.com/2026/02/beyond-agentic-coding</link>
            <guid>46930565</guid>
            <pubDate>Sun, 08 Feb 2026 01:55:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haskellforall.com/2026/02/beyond-agentic-coding">https://haskellforall.com/2026/02/beyond-agentic-coding</a>, See on <a href="https://news.ycombinator.com/item?id=46930565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I'm generally pretty pro-AI with one major exception: agentic coding.  My consistent impression is that agentic coding does not actually improve productivity and deteriorates the user's comfort and familiarity with the codebase.  I formed that impression from:</p>
<ul>
<li>
<p><a href="https://haskellforall.com/2026/02/my-experience-with-vibe-coding">my own personal experiences</a></p>
<p>Every time I use agentic coding tools I'm consistently unimpressed with the quality of the results.</p>
</li>
<li>
<p>my experiences interviewing candidates</p>
<p>I allow interview candidates to use agentic coding tools and candidates who do so consistently performed <em>worse</em> than other candidates, failing to complete the challenge or producing incorrect results<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.  This was a huge surprise to me at first because I expected agentic coding to confer an unfair advantage but … nope!</p>
</li>
<li>
<p>research studies</p>
<p>Studies like the <a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/">Becker study</a> and <a href="https://arxiv.org/abs/2601.20245">Shen study</a> show that users of agentic coding perform no better and sometimes worse when you measure productivity in terms of fixed outcomes rather than code velocity/volume.</p>
</li>
</ul>
<p>I don't believe agentic coding is a lost cause, but I do believe agentic coding in its present incarnation is doing more harm than good to software development.  I also believe it is still worthwhile to push on the inadequacies of agentic coding so that it empowers developers and improves code quality.</p>
<p>However, in this post I'm taking a different tack: I want to present other ways to leverage AI for software development.  I believe that agentic coding has so captured the cultural imagination that people are sleeping on other good and underexplored solutions to AI-assisted software development.</p>
<h2>The master cue</h2>
<p>I like to design tools and interfaces from first principles rather than reacting to industry trends/hype and I've accrued quite a few general design principles from over a decade of working in DevProd and also an even longer history of open source projects and contributions.</p>
<p>One of those design principles is my personal "master cue", which is:</p>
<blockquote>
<p>A good tool or interface should keep the user in a flow state as long as possible</p>
</blockquote>
<p>This principle isn't even specific to AI-assisted software development, and yet still highlights why agentic coding sometimes misses the mark.  Both studies and developer testimonials show that agentic coding breaks flow and keeps developers in an idle/interruptible holding pattern more than ordinary coding.</p>
<p>For example, the <a href="https://arxiv.org/abs/2507.09089">Becker study</a> took screen recordings and saw that idle time approximately doubled:</p>
<p><img src="https://haskellforall.com/imgs/beyond-agentic-coding/idle-time.png" alt=""></p>
<p>I believe we can improve AI-assisted coding tools (agentic or not) if we set our north star to “preserve flow state”.</p>
<h2>Calm technology</h2>
<p><a href="https://calmtech.com/">Calm technology</a> is a design discipline that promotes flow state in tools that we build.  The design principles most relevant to coding are:</p>
<ul>
<li>
<p>tools should minimize demands on our attention</p>
<p>Interruptions and intrusions on our attention break us out of flow state.</p>
</li>
<li>
<p>tools should be built to be “pass-through”</p>
<p>A tool is not meant to be the object of our attention; rather the tool should <em>reveal</em> the true object of our attention (the thing the tool acts upon), rather than obscuring it.  The more we use the tool the more the tool fades into the background of our awareness while still supporting our work.</p>
</li>
<li>
<p>tools should create and enhance calm (thus the name: calm technology)</p>
<p>A state of calm helps users enter and maintain flow state.</p>
</li>
</ul>
<h2>Non-LLM examples of calm technology</h2>
<p>Engineers already use “calm” tools and interfaces as part of our work and here are a couple of examples you're probably already familiar with:</p>
<h3>Inlay hints</h3>
<p>IDEs (like VSCode) can support <a href="https://code.visualstudio.com/docs/typescript/typescript-editing#_inlay-hints">inlay hints</a> that sprinkle the code with useful annotations for the reader, such as inferred type annotations:</p>
<p><img src="https://haskellforall.com/imgs/beyond-agentic-coding/inlay-hints.png" alt=""></p>
<p>These types of inlay hints embody calm design principles because:</p>
<ul>
<li>
<p>they minimize demands on our attention</p>
<p>They exist on the periphery of our attention, available for us if we're interested but unobtrusive if we're not interested.</p>
</li>
<li>
<p>they are built to be “pass-through”</p>
<p>They don't replace or substitute the code that we are editing.  They enhance the code editing experience but the user is still in direct contact with the edited code.  The more we use type hints the more they fade into the background of our awareness and the more the code remains the focus of our attention.</p>
</li>
<li>
<p>they create and enhance calm</p>
<p>They promote a sense of calm by informing our understanding of the code <strong>passively</strong>.  As one of the <a href="https://calmtech.com/">Calm Technology</a> principles puts it: <em>“Technology can communicate, but doesn't need to speak”.</em></p>
</li>
</ul>
<h3>File tree previews</h3>
<p>Tools like VSCode or GitHub's pull request viewer let you preview at a glance changes to the file tree, like this:</p>
<p><img src="https://haskellforall.com/imgs/beyond-agentic-coding/file-tree-1.png" alt=""></p>
<p>You might think to yourself “this is a very uninteresting thing to use as an example” but that's exactly the point.  The best tools (designed with the principles of calm technology) are pervasive and <strong>boring</strong> things that we take for granted (like light switches) and that have faded so strongly into the background of our attention that we forget they even exist as a part of our daily workflow (also like light switches).</p>
<p>File tree previews:</p>
<ul>
<li>
<p>minimize demands on our attention</p>
<p>They're there if we need the information, but easy to ignore (or even forget they exist) if we don't use them.</p>
</li>
<li>
<p>are built to be “pass-through”</p>
<p>When we interact with the file tree viewer we are interacting directly with the filesystem and the interaction between the representation (the viewer) and the reality (the filesystem) feels direct, snappy, and precise.  The more we use the viewer the more the representation becomes indistinguishable from the reality in our minds.</p>
</li>
<li>
<p>create and enhance calm</p>
<p>We do not need to constantly interact with the file tree to gather up-to-date information about our project structure.  It passively updates in the background as we make changes to the project and those updates are unobtrusive and not attention-grabbing.</p>
</li>
</ul>
<h2>Chat-based coding agents are not calm</h2>
<p>We can think about the limitations of chat-based agentic coding tools through this same lens:</p>
<ul>
<li>
<p>they place high demands on our attention</p>
<p>The user has to either sit and wait for the agent to report back or do something else and run the LLM in a semi-autonomous manner.  However, even semi-autonomous sessions prevent the user from entering flow state because they have to remain interruptible.</p>
</li>
<li>
<p>they are not built to be “pass-through”</p>
<p>Chat agents are a highly mediated interface to the code which is <strong>indirect</strong> (we interact more with the agent than the code), <strong>slow</strong> (we spend a lot of time waiting), and <strong>imprecise</strong> (English is a <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD06xx/EWD667.html">dull interface</a>).</p>
</li>
<li>
<p>they undermine calm</p>
<p>The user needs to constantly stimulate the chat to gather new information or update their understanding of the code (the chat agent doesn't inform the user's understanding passively or quietly).  Chat agents are also fine-tuned to maximize engagement.</p>
</li>
</ul>
<h2>Prior art for calm design</h2>
<h3>Inline suggestions from GitHub Copilot</h3>
<p>One of the earliest examples of an AI coding assistant that begins to model calm design principles is the OG AI-assistant: <a href="https://code.visualstudio.com/docs/copilot/ai-powered-suggestions">GitHub Copilot's support for inline suggestions</a>, with some caveats I'll go into.</p>
<p><img src="https://haskellforall.com/imgs/beyond-agentic-coding/inline-suggestions.png" alt=""></p>
<p>This does one thing really well:</p>
<ul>
<li>
<p>it's built to be “pass-through”</p>
<p>The user is still interacting directly with the code and the suggestions are reasonably snappy.  The user can also ignore or type through the suggestion.</p>
</li>
</ul>
<p>However, by default these inline suggestions violate other calm technology principles:</p>
<ul>
<li>
<p>they demand our attention</p>
<p>By default Copilot presents the suggestions quite frequently and the user has to pause what they're doing to examine the output of the suggestion.  After enough times the user begins to condition themselves into regularly pausing and waiting for a suggestion which breaks them out of a flow state.  Now instead of being proactive the user's been conditioned by the tool to be reactive.</p>
</li>
<li>
<p>they undermine calm</p>
<p>GitHub Copilot's inline suggestion interface is visually busy and intrusive.  Even if the user ignores every suggestion the effect is still disruptive: suggestions appear on the user's screen in the center of their visual focus and the user has to decide on the spot whether to accept or ignore them before proceeding further.  The user also can't easily passively absorb information presented in this way: understanding each suggestion requires the user's focused attention.</p>
</li>
</ul>
<p>… <em>buuuuut</em> these issues are partially fixable by disabling the automatic suggestions and requiring them to be explicitly triggered by <code>Alt</code> + <code>\</code>.  However, unfortunately that also disables the next feature, which I like even more:</p>
<h3>Next edit suggestions (also from GitHub Copilot)</h3>
<p><a href="https://code.visualstudio.com/docs/copilot/ai-powered-suggestions#_next-edit-suggestions">Next edit suggestions</a> are a related GitHub Copilot feature that display related follow-up edits throughout the file/project and let the user cycle between them and possibly accept each suggested change.  They behave like a “super-charged find and replace”:</p>
<video controls="" preload="metadata" playsinline="">
  <source src="https://code.visualstudio.com/assets/docs/copilot/inline-suggestions/nes-video.mp4" type="video/mp4">
</video>
<p>These suggestions do an amazing job of keeping the user in a flow state:</p>
<ul>
<li>
<p>they minimize demand on the user's attention</p>
<p>The cognitive load on the user is smaller than inline suggestions because the suggestions are more likely to be bite-sized (and therefore easier for a human to review and accept).</p>
</li>
<li>
<p>they're built to be “pass-through”</p>
<p>Just like inline suggestions, next edit suggestions still keep the user in close contact with the code they are modifying.</p>
</li>
<li>
<p>they create and enhance calm</p>
<p>Suggestions are presented in an unobtrusive way: they aren't dumped in the dead center of the user's attention and they don't demand immediate review.  They exist on the periphery of the user's attention as code suggestions that the user can ignore or focus on at their leisure.</p>
</li>
</ul>
<h2>AI-assisted calm technology</h2>
<p>I believe there is a lot of untapped potential in AI-assisted coding tools and in this section I'll sketch a few small examples of how we can embody calm technology design principles in building the next generation of coding tools.</p>
<h3>Facet-based project navigation</h3>
<p>You could browse a project by a tree of semantic facets.  For example, if you were editing <a href="https://github.com/dhall-lang/dhall-haskell">the Haskell implementation of Dhall</a> the tree viewer might look like this prototype I hacked up<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>:</p>
<video controls="" preload="metadata" playsinline="">
  <source src="https://haskellforall.com/imgs/beyond-agentic-coding/semantic-facets.mp4" type="video/mp4">
</video>
<p>The goal here is to not only provide a quick way to explore the project by intent, but to also improve the user's understanding of the project the more they use the feature.  "String interpolation regression" is so much more informative than <code>dhall/tests/format/issue2078A.dhall</code><sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>.</p>
<p>Also, the above video is based on a real tool and not just a mock.  You can find the code I used to generate that tree of semantics facets <a href="https://github.com/Gabriella439/facet-navigator">here</a> and I'll write up another post soon walking through how that code works.</p>
<h3>Automated commit refactor</h3>
<p>You could take an editor session, a diff, or a pull request and automatically split it into a series of more focused commits that are easier for people to review.  This is one of the cases where the AI can <em>reduce</em> human review labor (most agentic coding tools <em>create</em> more human review labor).</p>
<p>There is <a href="https://softwareengineering.stackexchange.com/questions/458416/how-to-decompose-a-large-git-commit-with-an-ai">some prior art here</a> but this is still a nascent area of development.</p>
<h3>File lens</h3>
<p>You could add two new tools to the user's toolbar or context menu: <em>“Focus on…”</em> and <em>“Edit as…”.</em></p>
<p><em>“Focus on…”</em> would allow the user to specify what they're interested in changing and present only files and lines of code related to their specified interest.  For example, if they want to focus on “command line options” then only related files and lines of code would be shown in the editor and other lines of code would be hidden/collapsed/folded.  This would basically be like “Zen mode” but for editing a feature domain of interest.</p>
<p><em>“Edit as…”</em> would allow the user to edit the file or selected code as if it were a different programming language or file format.  For example, someone who was new to Haskell could edit a Haskell file “as Python” and then after finishing their edits the AI attempts to back-propagate their changes to Haskell.  Or someone modifying a command-line parser could edit the file “as YAML” and be presented with a simplified YAML representation of the command line options which they could modify to add new options.</p>
<h2>Conclusion</h2>
<p>This is obviously not a comprehensive list of ideas, but I wrote this to encourage people to think of more innovative ways to incorporate AI into people's workflows besides just building yet another chatbot.  I strongly believe that <a href="https://haskellforall.com/2026/01/chat-is-least-interesting-interface-to">chat is the least interesting interface to LLMs</a> and AI-assisted software development is no exception to this.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Getting the correct output wasn't even supposed to be the hard part of the coding challenge.  The standard interview challenge provided the candidate with a golden output that their program needed to match and despite that agentic coders would not only fail to match the golden output but sometimes <em>not even realize</em> their program didn't match the golden output because they hadn't even run their agentically coded solution to check if it was correct.  The actual hard part of the coding challenge was supposed to be follow-up questions about the journey to production, which vibe coders also performed worse on. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>The cluster labeler still needs work but you get the idea. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>That's on me since I named the file 😅. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: LocalGPT – A local-first AI assistant in Rust with persistent memory (295 pts)]]></title>
            <link>https://github.com/localgpt-app/localgpt</link>
            <guid>46930391</guid>
            <pubDate>Sun, 08 Feb 2026 01:26:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/localgpt-app/localgpt">https://github.com/localgpt-app/localgpt</a>, See on <a href="https://news.ycombinator.com/item?id=46930391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">LocalGPT</h2><a id="user-content-localgpt" aria-label="Permalink: LocalGPT" href="#localgpt"></a></p>
<p dir="auto">A local device focused AI assistant built in Rust — persistent memory, autonomous tasks, ~27MB binary. Inspired by and compatible with OpenClaw.</p>
<p dir="auto"><code>cargo install localgpt</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why LocalGPT?</h2><a id="user-content-why-localgpt" aria-label="Permalink: Why LocalGPT?" href="#why-localgpt"></a></p>
<ul dir="auto">
<li><strong>Single binary</strong> — no Node.js, Docker, or Python required</li>
<li><strong>Local device focused</strong> — runs entirely on your machine, your memory data stays yours</li>
<li><strong>Persistent memory</strong> — markdown-based knowledge store with full-text and semantic search</li>
<li><strong>Autonomous heartbeat</strong> — delegate tasks and let it work in the background</li>
<li><strong>Multiple interfaces</strong> — CLI, web UI, desktop GUI</li>
<li><strong>Multiple LLM providers</strong> — Anthropic (Claude), OpenAI, Ollama</li>
<li><strong>OpenClaw compatible</strong> — works with SOUL, MEMORY, HEARTBEAT markdown files and skills format</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Initialize configuration
localgpt config init

# Start interactive chat
localgpt chat

# Ask a single question
localgpt ask &quot;What is the meaning of life?&quot;

# Run as a daemon with heartbeat, HTTP API and web ui
localgpt daemon start"><pre><span><span>#</span> Initialize configuration</span>
localgpt config init

<span><span>#</span> Start interactive chat</span>
localgpt chat

<span><span>#</span> Ask a single question</span>
localgpt ask <span><span>"</span>What is the meaning of life?<span>"</span></span>

<span><span>#</span> Run as a daemon with heartbeat, HTTP API and web ui</span>
localgpt daemon start</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How It Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<p dir="auto">LocalGPT uses plain markdown files as its memory:</p>
<div data-snippet-clipboard-copy-content="~/.localgpt/workspace/
├── MEMORY.md            # Long-term knowledge (auto-loaded each session)
├── HEARTBEAT.md         # Autonomous task queue
├── SOUL.md              # Personality and behavioral guidance
└── knowledge/           # Structured knowledge bank (optional)
    ├── finance/
    ├── legal/
    └── tech/"><pre><code>~/.localgpt/workspace/
├── MEMORY.md            # Long-term knowledge (auto-loaded each session)
├── HEARTBEAT.md         # Autonomous task queue
├── SOUL.md              # Personality and behavioral guidance
└── knowledge/           # Structured knowledge bank (optional)
    ├── finance/
    ├── legal/
    └── tech/
</code></pre></div>
<p dir="auto">Files are indexed with SQLite FTS5 for fast keyword search, and sqlite-vec for semantic search with local embeddings</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Stored at <code>~/.localgpt/config.toml</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[agent]
default_model = &quot;claude-cli/opus&quot;

[providers.anthropic]
api_key = &quot;${ANTHROPIC_API_KEY}&quot;

[heartbeat]
enabled = true
interval = &quot;30m&quot;
active_hours = { start = &quot;09:00&quot;, end = &quot;22:00&quot; }

[memory]
workspace = &quot;~/.localgpt/workspace&quot;"><pre>[<span>agent</span>]
<span>default_model</span> = <span><span>"</span>claude-cli/opus<span>"</span></span>

[<span>providers</span>.<span>anthropic</span>]
<span>api_key</span> = <span><span>"</span>${ANTHROPIC_API_KEY}<span>"</span></span>

[<span>heartbeat</span>]
<span>enabled</span> = <span>true</span>
<span>interval</span> = <span><span>"</span>30m<span>"</span></span>
<span>active_hours</span> = { <span>start</span> = <span><span>"</span>09:00<span>"</span></span>, <span>end</span> = <span><span>"</span>22:00<span>"</span></span> }

[<span>memory</span>]
<span>workspace</span> = <span><span>"</span>~/.localgpt/workspace<span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI Commands</h2><a id="user-content-cli-commands" aria-label="Permalink: CLI Commands" href="#cli-commands"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Chat
localgpt chat                     # Interactive chat
localgpt chat --session <id>      # Resume session
localgpt ask &quot;question&quot;           # Single question

# Daemon
localgpt daemon start             # Start background daemon
localgpt daemon stop              # Stop daemon
localgpt daemon status            # Show status
localgpt daemon heartbeat         # Run one heartbeat cycle

# Memory
localgpt memory search &quot;query&quot;    # Search memory
localgpt memory reindex           # Reindex files
localgpt memory stats             # Show statistics

# Config
localgpt config init              # Create default config
localgpt config show              # Show current config"><pre><span><span>#</span> Chat</span>
localgpt chat                     <span><span>#</span> Interactive chat</span>
localgpt chat --session <span>&lt;</span>id<span>&gt;</span>      <span><span>#</span> Resume session</span>
localgpt ask <span><span>"</span>question<span>"</span></span>           <span><span>#</span> Single question</span>

<span><span>#</span> Daemon</span>
localgpt daemon start             <span><span>#</span> Start background daemon</span>
localgpt daemon stop              <span><span>#</span> Stop daemon</span>
localgpt daemon status            <span><span>#</span> Show status</span>
localgpt daemon heartbeat         <span><span>#</span> Run one heartbeat cycle</span>

<span><span>#</span> Memory</span>
localgpt memory search <span><span>"</span>query<span>"</span></span>    <span><span>#</span> Search memory</span>
localgpt memory reindex           <span><span>#</span> Reindex files</span>
localgpt memory stats             <span><span>#</span> Show statistics</span>

<span><span>#</span> Config</span>
localgpt config init              <span><span>#</span> Create default config</span>
localgpt config show              <span><span>#</span> Show current config</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">HTTP API</h2><a id="user-content-http-api" aria-label="Permalink: HTTP API" href="#http-api"></a></p>
<p dir="auto">When the daemon is running:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Endpoint</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GET /health</code></td>
<td>Health check</td>
</tr>
<tr>
<td><code>GET /api/status</code></td>
<td>Server status</td>
</tr>
<tr>
<td><code>POST /api/chat</code></td>
<td>Chat with the assistant</td>
</tr>
<tr>
<td><code>GET /api/memory/search?q=&lt;query&gt;</code></td>
<td>Search memory</td>
</tr>
<tr>
<td><code>GET /api/memory/stats</code></td>
<td>Memory statistics</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Blog</h2><a id="user-content-blog" aria-label="Permalink: Blog" href="#blog"></a></p>
<p dir="auto"><a href="https://localgpt.app/blog/why-i-built-localgpt-in-4-nights" rel="nofollow">Why I Built LocalGPT in 4 Nights</a> — the full story with commit-by-commit breakdown.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Built With</h2><a id="user-content-built-with" aria-label="Permalink: Built With" href="#built-with"></a></p>
<p dir="auto">Rust, Tokio, Axum, SQLite (FTS5 + sqlite-vec), fastembed, eframe</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<a href="https://github.com/localgpt-app/localgpt/graphs/contributors">
  <img src="https://camo.githubusercontent.com/53322a9af1540810eb1bfce4c1593005ef0312874e15f2e69f9921e9aef48a20/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6c6f63616c6770742d6170702f6c6f63616c677074" data-canonical-src="https://contrib.rocks/image?repo=localgpt-app/localgpt">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers</h2><a id="user-content-stargazers" aria-label="Permalink: Stargazers" href="#stargazers"></a></p>
<p dir="auto"><a href="https://star-history.com/#localgpt-app/localgpt&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/f1cbec084c4d378ff8f14c3cc56ffabef4aec64f05a2ad63836aff7d4042a4f0/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c6f63616c6770742d6170702f6c6f63616c67707426747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=localgpt-app/localgpt&amp;type=Date"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/localgpt-app/localgpt/blob/main/LICENSE">Apache-2.0</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The silent death of good code (119 pts)]]></title>
            <link>https://amit.prasad.me/blog/rip-good-code</link>
            <guid>46929391</guid>
            <pubDate>Sat, 07 Feb 2026 23:23:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://amit.prasad.me/blog/rip-good-code">https://amit.prasad.me/blog/rip-good-code</a>, See on <a href="https://news.ycombinator.com/item?id=46929391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I’ve been passionate about writing “Good Code™” since before I started my career, beginning way back when I was still a kid in middle school.</p> <blockquote><p>What is “Good Code™“?</p></blockquote> <p>Good Question™ :)</p> <p>Good Code is code that is easy to read and understand. Good Code is code that is pleasing to develop with and maintain. Good Code is code that exists for a specific reason, and no more. Good Code is a product of the rare combination of talent, experience, passion, and the investment of time that may not be immediately useful for the business. And most unfortunately, Good Code is rare.</p> <p>That being said, by trade, I am a Software Engineer. Not a “Computer Programmer”, nor a “Coder”, nor any other title that implies that my job is to “write good code”. In fact, nothing about my job title necessitates that I read or write code at all! My job is to create useful software that solves real problems.</p> <p>Recently, a colleague of mine at <a href="https://modal.com/"><!--[!--><!--]--> Modal</a><!----> rewrote an external system that integrated deeply with the Linux kernel. The initial rewrite was a simple translation of a C codebase to a Rust one, in preparation for some custom feature work. The resulting code wasn’t bad, nor was it un-idiomatic Rust. What it also wasn’t was Good Code. It was hard to read and understand, would have been difficult to extend and maintain, and it wasn’t even clear to us why we’d taken the burden of rewriting and maintaining this extra system.</p> <p>The initial rewrite also relied heavily on coding agents.</p> <p>This same colleague then invested time into understanding the kernel subsystem, the exact reasons why the original C program was written how it was, and rewrote the Rust translation himself. The difference was night and day; the code flowed naturally, explained itself and the underlying subsystems, and may genuinely be some of the nicest parts of the entire codebase. Better, I think, than even the original C, despite this type of program being arguably one of the best places to use C over Rust.</p> <p>It was the first time in weeks, maybe months, that I’d felt something that used to be common in my day-to-day: excitement about the lines of code in front of me. I used to write (approximations of) Good Code most days. Somewhere along the way, everything changed. Nowadays I don’t even write the first version of most of the code I commit. I’m definitely far more productive with an agent at my side. They’re not at all <em>horrible</em> at this coding stuff, just not truly <strong>great</strong> at it. At the end of the day, the code they spit out is… acceptable. It gets the job done, it passes my litmus tests, but it certainly isn’t Good Code.</p> <p>Perhaps the age of caring about these lines of code is over. I’m sure that there were folks passionate about Good Assembly or Good Circuits whose passions have quietly faded into the echoes of “how things used to be,” forgotten as they and their fields evolved. From my (biased) perspective, the change in Software Engineering feels uniquely sudden, and I can’t help but mourn the silent death of Good Code.</p><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA intends to take action against non-FDA-approved GLP-1 drugs (135 pts)]]></title>
            <link>https://www.fda.gov/news-events/press-announcements/fda-intends-take-action-against-non-fda-approved-glp-1-drugs</link>
            <guid>46928810</guid>
            <pubDate>Sat, 07 Feb 2026 22:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fda.gov/news-events/press-announcements/fda-intends-take-action-against-non-fda-approved-glp-1-drugs">https://www.fda.gov/news-events/press-announcements/fda-intends-take-action-against-non-fda-approved-glp-1-drugs</a>, See on <a href="https://news.ycombinator.com/item?id=46928810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                                 <article id="main-content" role="article">
          
                                                                <header>
                         






                      </header>
                              
                                                          
                              
              
                                                          
              <div role="main">

                            
                            
                            
                            
                                              
    <div>
    <dl>
        <dt>For Immediate Release:</dt>
                  <dd><time datetime="2026-02-06T21:45:00Z">February 06, 2026</time>
</dd>
                 
                         <dt>Statement From:</dt>
         <dd>
                                
                                    
            Martin A Makary, M.D., M.P.H.            <br>
                                                                                                    
                                
<span>Commissioner of Food and Drugs - Food and Drug Administration</span>
  
                                </dd>
        
      </dl>
    </div>
 

  
      
       

  <p>Today, the U.S. Food and Drug Administration is announcing its intent to take decisive steps to restrict GLP-1 active pharmaceutical ingredients (APIs) intended for use in non-FDA-approved compounded drugs that are being mass-marketed by companies — including Hims &amp; Hers and other compounding pharmacies — as similar alternatives to FDA-approved drugs. These actions are aimed to safeguard consumers from drugs for which the FDA cannot verify quality, safety, or efficacy. &nbsp;We take seriously any potential violations of the Federal Food, Drug, and Cosmetic Act.</p><p>The FDA is also taking steps to combat misleading direct-to-consumer advertising and marketing following warning letters that were sent in the fall of 2025. In promotional materials, companies cannot claim that non-FDA-approved compounded products are generic versions or the same as drugs approved by FDA. They also cannot state compounded drugs use the same active ingredient as the FDA-approved drugs or that compounded drugs are clinically proven to produce results for the patient.</p><p>The FDA will use all available compliance and enforcement tools within its authorities to address unsubstantiated claims and associated public health concerns. Entities engaged in the manufacture, distribution, or marketing of unapproved compounded GLP-1 products should be aware that failure to adequately address any violations may result in legal action without further notice, including, without limitation, seizure and injunction.</p>
  <h2>Related Information</h2>
  
  

<p>###</p>
  <div data-quickedit-field-id="node/427966/field_generic_long_text/en/full">
      <p>Boilerplate</p>
      <p>The FDA, an agency within the U.S. Department of Health and Human Services, protects the public health by assuring the safety, effectiveness, and security of human and veterinary drugs, vaccines and other biological products for human use, and medical devices. The agency also is responsible for the safety and security of our nation’s food supply, cosmetics, dietary supplements, radiation-emitting electronic products, and for regulating tobacco products.</p>
    </div>
<hr>

 
<br>

<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->
<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->



              
                                            
              
            </div>

                                                  
                          
            
                 </article>        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny C Compiler (161 pts)]]></title>
            <link>https://bellard.org/tcc/</link>
            <guid>46928435</guid>
            <pubDate>Sat, 07 Feb 2026 21:45:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bellard.org/tcc/">https://bellard.org/tcc/</a>, See on <a href="https://news.ycombinator.com/item?id=46928435">Hacker News</a></p>
<div id="readability-page-1" class="page">
<img src="https://bellard.org/tcc/tcc-logo.png">
<p><b><span size="+3">Tiny C Compiler</span></b></p>
<h2>News</h2>

[Note: I am no longer working on TCC. Check the mailing list to get up
to date information.]

<h2>Features</h2>
<ul>

<li> <b>SMALL!</b> You can compile and execute C code everywhere, for
  example on rescue disks (about 100KB for x86 TCC executable,
  including C preprocessor, C compiler, assembler and linker).</li>

<li> <b>FAST!</b> tcc generates x86 code. No byte code
  overhead. Compile, assemble and link several times <a href="#speed">faster</a> than <tt>GCC</tt>.</li>

<li> <b>UNLIMITED!</b> Any C dynamic library can be used directly. TCC is
  heading torward full <b>ISOC99</b> compliance. TCC can of course compile
  itself.</li>

<li> <b>SAFE!</b> tcc includes an optional <b>memory and bound
checker</b>. Bound checked code can be mixed freely with standard
code.

</li><li> Compile and execute C source directly. No linking or assembly
  necessary. Full C preprocessor and GNU-like assembler
  included. </li>

<li> C script supported : just add <tt>'#!/usr/local/bin/tcc -run'</tt> at the first
  line of your C source, and execute it directly from the command
  line.</li>

<li> With <code>libtcc</code>, you can use TCC as a backend for dynamic code
generation. </li>

</ul>

<h2><a href="http://download.savannah.gnu.org/releases/tinycc/">Download</a></h2>

<h2>Compilation Speed</h2>
<a name="speed"></a>


Compilation speed for the <a href="http://links.twibright.com/download.php">Links
Browser project</a>. There are 76936 lines (including
headers). 1950947 lines (67.2 MBytes) are compiled because the same headers are
included in many files. TinyCC is about <b>9 times</b> faster than
GCC.
<table><tbody><tr><td>Compiler</td><td>Time(s)</td><td>lines/second</td><td>MBytes/second</td>

</tr><tr> <td>TinyCC 0.9.22</td> <td>2.27</td> <td>859000</td> <td>29.6</td>

</tr><tr> <td>GCC 3.2 -O0</td> <td>20.0</td> <td>98000</td> <td>3.4</td>

</tr></tbody></table>
<br>
Measures were done on a 2.4 GHz Pentium 4. Real time is measured. Compilation
time includes compilation, assembly and linking.
<p>
More up to date tests are available:
<a href="http://lists.nongnu.org/archive/html/tinycc-devel/2013-02/msg00056.html">1</a><a>,
</a><a href="http://lists.nongnu.org/archive/html/tinycc-devel/2013-02/msg00039.html">2</a>,
<a href="http://lists.nongnu.org/archive/html/tinycc-devel/2013-02/msg00043.html">3</a>,
<a href="http://lists.nongnu.org/archive/html/tinycc-devel/2013-01/msg00007.html">4</a>.

</p><h2><a href="https://bellard.org/tcc/tcc-doc.html">Online Documentation</a></h2>

<h2>You want to help ?</h2>
Here are some suggestions:
<ul>
<li> Report bugs to the mailing list (and eventually fix them).</li>
</ul>

<h2>Links</h2>
<ul>
<li><a href="https://lists.nongnu.org/mailman/listinfo/tinycc-devel">TinyCC mailing list</a>
</li><li><a href="http://savannah.gnu.org/projects/tinycc">Savannah project page and git repository</a>
</li><li><a href="https://bellard.org/otcc/">OTCC - The smallest self
compiling pseudo C compiler</a>
</li><li><a href="https://bellard.org/ffasn1/">FFASN1</a> - My small but powerful ASN.1 compiler.
</li><li><a href="http://llvm.org/">LLVM Compiler Infrastructure</a></li><a href="http://llvm.org/">
</a><li><a href="http://llvm.org/"></a><a href="http://smarteiffel.loria.fr/">SmartEiffel</a> - With TCC you can compile your Eiffel code faster
</li><li><a href="http://gcc.gnu.org/">The GNU C Compiler</a></li>
<li><a href="http://www.cs.princeton.edu/software/lcc/">The LCC Compiler</a></li>
<li><a href="http://sdcc.sourceforge.net/">The Small Device C Compiler</a></li>
<li><a href="http://cyclone.thelanguage.org/">Cyclone</a>, A Safe Dialect of C</li>
<li><a href="http://www.digitalmars.com/d/">The D language</a>
</li><li><a href="http://www.lysator.liu.se/c/"> Programming in C </a></li>
<li>The <a href="http://rigaux.org/language-study/scripting-language/">Scriptometer</a> evaluates various scripting
languages (including TCC).</li>
</ul>

<h2>License</h2>

TCC is distributed under the GNU Lesser General Public License. 

<hr>
Copyright (c) 2001-2018 Fabrice Bellard <hr>

Fabrice Bellard - <a href="https://bellard.org/">
https://bellard.org/ </a> - <a href="https://bellard.org/tcc/"> https://bellard.org/tcc/ </a>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Italy Railways Sabotaged (103 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/czr4rx04xjpo</link>
            <guid>46928412</guid>
            <pubDate>Sat, 07 Feb 2026 21:43:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/czr4rx04xjpo">https://www.bbc.co.uk/news/articles/czr4rx04xjpo</a>, See on <a href="https://news.ycombinator.com/item?id=46928412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="rich-text" data-block="text"><p>Police said a track switch was set alight near Pesaro, on the Adriatic coast. Several hours later, police discovered severed electric cables near Bologna, along with a rudimentary explosive device left by a track nearby. </p><p>Bologna's rail station is a major transport hub, linking cities in the north and south, and east to west lines. </p><p>"These actions of unprecedented seriousness do not in any way tarnish Italy's image in the world, an image that the Games will make even more compelling and positive," said Deputy Prime Minister and Transport Minister Matteo Salvini. </p><p>A police spokesperson earlier said that they were investigating the incidents and that no one had claimed responsibility. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft account bugs locked me out of Notepad – Are thin clients ruining PCs? (174 pts)]]></title>
            <link>https://www.windowscentral.com/microsoft/windows-11/windows-locked-me-out-of-notepad-is-the-thin-client-era-ruining-pcs</link>
            <guid>46927098</guid>
            <pubDate>Sat, 07 Feb 2026 19:51:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windowscentral.com/microsoft/windows-11/windows-locked-me-out-of-notepad-is-the-thin-client-era-ruining-pcs">https://www.windowscentral.com/microsoft/windows-11/windows-locked-me-out-of-notepad-is-the-thin-client-era-ruining-pcs</a>, See on <a href="https://news.ycombinator.com/item?id=46927098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ.jpg" alt="Notepad icon from Windows 11 in a cartoon jail cell, generated by Gemini" srcset="https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/wPJcMXqD44weR2UTFWd8fJ.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>If I can lose access to something as simple as Notepad, then Microsoft has probably take cloud integrations too far.</span>
<span>(Image credit: Microsoft | Edited with Gemini)</span>
</figcaption>
</div>
<div id="article-body">

<p id="0d38a78f-3354-4f86-b602-38f93fb8d4e4">A couple of weeks ago, I found that I couldn't open Notepad on my desktop PC. It wasn't because Windows 11 had crashed, but rather, Microsoft told me it wasn't <em>"available in (my) account". </em>It turned out that <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-11-apps-like-notepad-arent-loading-what-is-error-code-0x803f8001-and-how-d" data-url="https://www.windowscentral.com/microsoft/windows-11/windows-11-apps-like-notepad-arent-loading-what-is-error-code-0x803f8001-and-how-d" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-11-apps-like-notepad-arent-loading-what-is-error-code-0x803f8001-and-how-d">an error (0x803f8001) with Microsoft Store's licensing service</a> stopped me from opening a few first-party apps, including the Snipping Tool.</p><p>Yes, even the app I usually use to screenshot error messages was busted. Ironic. Now, I'm usually a fairly level-headed Windows enthusiast who can relate to users who both love and loathe Microsoft's operating system, <em>but I couldn't open Notepad.exe — are we serious?</em></p><div data-nosnippet="" id="qYb1es6A7Zw">
<div>
<p><span>I was locked out of Notepad due to Microsoft's server bug — is this the 'Thin Client' era? - YouTube</span>
<img src="https://img.youtube.com/vi/qYb1es6A7Zw/maxresdefault.jpg" alt="I was locked out of Notepad due to Microsoft's server bug — is this the 'Thin Client' era? - YouTube" data-aspect-ratio="16/9" loading="lazy">
</p>
</div>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 234.67 165.33"><path fill="red" d="M229.763 25.817c-2.699-10.162-10.65-18.165-20.748-20.881C190.716 0 117.333 0 117.333 0S43.951 0 25.651 4.936C15.553 7.652 7.6 15.655 4.903 25.817 0 44.236 0 82.667 0 82.667s0 38.429 4.903 56.85C7.6 149.68 15.553 157.681 25.65 160.4c18.3 4.934 91.682 4.934 91.682 4.934s73.383 0 91.682-4.934c10.098-2.718 18.049-10.72 20.748-20.882 4.904-18.421 4.904-56.85 4.904-56.85s0-38.431-4.904-56.85"></path><path fill="#fff" d="m93.333 117.559 61.333-34.89-61.333-34.894z"></path></svg>
<a href="https://youtu.be/qYb1es6A7Zw" target="_blank" data-url="https://youtu.be/qYb1es6A7Zw" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Watch On <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 507.9 113.39"><g fill="#fff"><path d="M64.792 80.99V32.396l42.082 24.297zm93.803-63.285a20.285 20.285 0 0 0-14.32-14.32C131.642 0 80.99 0 80.99 0S30.337 0 17.705 3.385a20.286 20.286 0 0 0-14.32 14.32C0 30.338 0 56.693 0 56.693S0 83.049 3.385 95.68A20.285 20.285 0 0 0 17.705 110c12.632 3.386 63.285 3.386 63.285 3.386s50.652 0 63.285-3.386a20.284 20.284 0 0 0 14.32-14.32c3.385-12.632 3.385-38.988 3.385-38.988s0-26.355-3.385-38.988m94.473 74.326c.887-2.314 1.332-6.098 1.332-11.35V58.556c0-5.097-.445-8.822-1.332-11.178-.888-2.355-2.452-3.533-4.69-3.533-2.163 0-3.69 1.178-4.577 3.533-.888 2.356-1.332 6.081-1.332 11.178V80.68c0 5.25.424 9.035 1.275 11.35.848 2.318 2.392 3.475 4.633 3.475 2.239 0 3.803-1.157 4.691-3.475zm-17.953 11.122c-3.207-2.16-5.486-5.52-6.835-10.079-1.352-4.554-2.027-10.617-2.027-18.185v-10.31c0-7.644.771-13.784 2.316-18.417 1.544-4.633 3.956-8.011 7.24-10.135 3.282-2.123 7.587-3.186 12.916-3.186 5.251 0 9.459 1.082 12.626 3.243 3.165 2.162 5.482 5.542 6.95 10.136 1.466 4.595 2.2 10.715 2.2 18.36v10.31c0 7.567-.714 13.65-2.142 18.243-1.43 4.595-3.747 7.955-6.951 10.077-3.205 2.124-7.548 3.186-13.03 3.186-5.64 0-10.06-1.082-13.263-3.243m248.053-57.981c-.81 1.005-1.352 2.646-1.621 4.923-.272 2.278-.404 5.734-.404 10.367v5.097h11.697V60.46c0-4.555-.155-8.011-.463-10.367-.309-2.355-.868-4.014-1.678-4.98-.812-.966-2.067-1.449-3.766-1.449-1.7 0-2.954.503-3.765 1.506zm-2.025 29.886v3.591c0 4.557.132 7.974.404 10.251.269 2.279.828 3.94 1.68 4.982.849 1.041 2.16 1.564 3.938 1.564 2.392 0 4.035-.927 4.923-2.781.887-1.853 1.37-4.942 1.447-9.268l13.785.812c.077.62.116 1.469.116 2.548 0 6.565-1.795 11.47-5.387 14.712-3.589 3.242-8.669 4.865-15.232 4.865-7.876 0-13.398-2.47-16.564-7.414-3.168-4.94-4.75-12.586-4.75-22.935V63.589c0-10.657 1.641-18.436 4.924-23.342 3.281-4.903 8.9-7.355 16.854-7.355 5.482 0 9.691 1.004 12.626 3.012 2.933 2.01 5 5.137 6.197 9.383 1.197 4.247 1.796 10.117 1.796 17.607v12.163h-26.757m-284.953-1.33-18.187-65.68h15.869l6.37 29.77c1.623 7.339 2.82 13.594 3.591 18.766h.464c.54-3.706 1.738-9.922 3.591-18.65l6.603-29.886h15.869l-18.417 65.68v31.51h-15.754v-31.51M322.115 34.23v71.007h-12.511l-1.39-8.688h-.347c-3.399 6.564-8.496 9.845-15.291 9.845-4.71 0-8.185-1.543-10.425-4.633-2.24-3.087-3.359-7.915-3.359-14.48V34.23h15.985v52.126c0 3.168.348 5.426 1.043 6.776.695 1.353 1.853 2.027 3.475 2.027 1.39 0 2.722-.423 3.996-1.275 1.274-.849 2.22-1.928 2.838-3.241V34.229h15.986m81.995.001v71.007h-12.511l-1.391-8.688h-.345c-3.402 6.564-8.498 9.845-15.292 9.845-4.711 0-8.186-1.543-10.426-4.633-2.24-3.087-3.358-7.915-3.358-14.48V34.23h15.985v52.126c0 3.168.347 5.426 1.041 6.776.696 1.353 1.855 2.027 3.476 2.027 1.391 0 2.723-.423 3.996-1.275 1.275-.849 2.22-1.928 2.839-3.241V34.229h15.985"></path><path d="M365.552 20.908h-15.87v84.329h-15.637v-84.33h-15.869V8.05h47.376v12.858m76.811 53.636c0 5.174-.215 9.229-.639 12.162-.424 2.937-1.139 5.021-2.143 6.255-1.004 1.236-2.357 1.854-4.053 1.854a7.404 7.404 0 0 1-3.65-.927c-1.12-.618-2.026-1.544-2.722-2.78V50.796c.54-1.93 1.467-3.513 2.78-4.749 1.313-1.234 2.74-1.853 4.285-1.853 1.623 0 2.876.637 3.766 1.91.886 1.275 1.505 3.418 1.853 6.43.348 3.011.523 7.297.523 12.857zm14.652-28.964c-.967-4.478-2.531-7.721-4.692-9.73-2.163-2.007-5.136-3.011-8.919-3.011-2.935 0-5.676.83-8.224 2.49a16.926 16.926 0 0 0-5.908 6.545h-.117l.001-37.416h-15.405v100.777h13.204l1.622-6.717h.347c1.235 2.393 3.088 4.285 5.56 5.675 2.47 1.39 5.213 2.085 8.225 2.085 5.404 0 9.382-2.491 11.931-7.471 2.548-4.982 3.823-12.76 3.823-23.341V64.23c0-7.953-.484-14.17-1.448-18.65"></path></g></svg></a>
</div><p id="482a1e73-307d-4fff-9d74-1feb00ff5c5b">After all, Notepad is <em>supposed </em>to be the absolute barebones, most ultra-basic app in the entire OS. Well, it was, before <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/microsoft-integrates-notepad-with-copilot-on-windows-11" data-url="https://www.windowscentral.com/software-apps/windows-11/microsoft-integrates-notepad-with-copilot-on-windows-11" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/microsoft-integrates-notepad-with-copilot-on-windows-11">Microsoft added Copilot</a> and users started looking for <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-notepads-extra-features-for-a-classic-experience-on-windows-11" data-url="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-notepads-extra-features-for-a-classic-experience-on-windows-11" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-notepads-extra-features-for-a-classic-experience-on-windows-11">a way to disable the unusual AI addition</a>. Sure, you can still type C:\Windows\notepad.exe into 'Run' with Windows + R for a legacy fallback, but many perhaps wouldn't know about it.</p><p>I'm still a Windows guy, and I always will be. Nevertheless, I can't ignore that Windows 11 regularly feels less like an operating system and more like a thin client; just a connection to Microsoft's cloud with fewer options for you to act as the administrator of your own PC.</p><h2 id="this-pc-vs-my-computer-3">This PC vs. My Computer</h2><figure data-bordeaux-image-check="" id="c09c3a67-2dc5-4645-98ed-78bad2e87bb6"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4.jpg" alt="Notepad failing to open on Windows 11" srcset="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4.jpg">
</picture><a href="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4.jpg" target="_blank" data-url="https://cdn.mos.cms.futurecdn.net/uB63mkuXsPCpTNxJ8SY5R4.jpg" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"></a></p></div><figcaption itemprop="caption description"><span>I was completely locked out of the modern Notepad </span><span itemprop="copyrightHolder">(Image credit: Ben Wilson | Windows Central)</span></figcaption></figure><p id="12f94efd-2ae5-4c17-b1a8-41a8311b8863">To be clear, I don't have <em>major</em> problems with <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/i-accepted-all-of-microsofts-suggested-windows-11-setup-settings" data-url="https://www.windowscentral.com/microsoft/windows-11/i-accepted-all-of-microsofts-suggested-windows-11-setup-settings" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/i-accepted-all-of-microsofts-suggested-windows-11-setup-settings">the default, out-of-box experience</a> (OOBE) of Windows 11. In fact, it doesn't take me long to make changes when installing fresh copies on new desktop builds. Default pins on the <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/start-menu" data-auto-tag-linker="true" data-url="https://www.windowscentral.com/tag/start-menu" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/start-menu">Start menu</a> don't matter because I barely use it, and <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-annoying-ads-on-windows-11" data-url="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-annoying-ads-on-windows-11" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-11/how-to-disable-annoying-ads-on-windows-11">disabling ads is straightforward enough</a>. The major points pretty much boil down to:</p><ul id="840c3f83-bce3-48c3-88a6-072041f5de41"><li><strong>Uninstalling OneDrive</strong>: The web app is fine for manual backups, but I definitely don't want my files automatically synced.</li><li><strong>Creating a local account</strong>: Microsoft keeps making it harder, but I'll always use workarounds.</li></ul><p id="8d1271d3-ac20-453a-a0d1-a4e69a6c7caa">After that, I don't take issue with the normal desktop — unless something unexpectedly breaks. Our Editor-in-Chief, <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/from-the-editors-desk-microsofts-biggest-windows-11-problem-isnt-technical-its-trust" data-url="https://www.windowscentral.com/microsoft/windows-11/from-the-editors-desk-microsofts-biggest-windows-11-problem-isnt-technical-its-trust" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/from-the-editors-desk-microsofts-biggest-windows-11-problem-isnt-technical-its-trust">Daniel Rubino, said it best, "People don’t hate change. <em><strong>They hate surprise.</strong></em><em>"</em></a> It was certainly a surprise to lose access to my plain text editor, loaded up with more than what an extended (Windows + V) clipboard would be useful for. Nobody asked for this.</p><p id="6eb52cd1-d69b-4b97-987f-8760ab15edec">So, is the solution to look for <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows/legacy-notepad-github-alternative" data-url="https://www.windowscentral.com/microsoft/windows/legacy-notepad-github-alternative" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows/legacy-notepad-github-alternative">open‑source Notepad clones?</a> Maybe for some enthusiasts, but that's just another app to add to a growing <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/windows-package-manager-is-so-good-i-wont-use-anything-else-now" data-url="https://www.windowscentral.com/software-apps/windows-package-manager-is-so-good-i-wont-use-anything-else-now" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/windows-package-manager-is-so-good-i-wont-use-anything-else-now">Winget list</a>, and I'd rather Microsoft stay true to its word about <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-is-reevaluating-its-ai-efforts-on-windows-11-plans-to-reduce-copilot-integrations-and-evolve-recall" data-url="https://www.windowscentral.com/microsoft/windows-11/microsoft-is-reevaluating-its-ai-efforts-on-windows-11-plans-to-reduce-copilot-integrations-and-evolve-recall" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-is-reevaluating-its-ai-efforts-on-windows-11-plans-to-reduce-copilot-integrations-and-evolve-recall">walking back Windows 11's AI overload</a>. I can't abide by comments on social platforms suggesting people <em>"just use a debloater" </em>on a new Windows PC, either — we shouldn't have to.</p><figure id="c1c8abf6-cdfc-4d7e-86d2-0745f42d2077"><blockquote><p>I generally avoid recommending Windows debloat scripts from GitHub to anyone in the first place.</p></blockquote></figure><p id="9a188e89-ca41-4989-a0ae-b9d5ee8d1b2a">That, and I generally avoid recommending Windows debloat scripts from <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/github" data-auto-tag-linker="true" data-url="https://www.windowscentral.com/tag/github" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/github">GitHub</a> to anyone in the first place. Windows can be adjusted to your liking if you <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows/windows-11/how-to" data-url="https://www.windowscentral.com/microsoft/windows/windows-11/how-to" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows/windows-11/how-to">follow the right guides</a>, and while you can inspect open-source code for yourself and generally trust some well-respected coders on that platform, it's a strange solution that needn't exist.</p><h2 id="stop-nudging-your-users-towards-danger-3">Stop nudging your users towards danger</h2><figure data-bordeaux-image-check="" id="f72bb7bc-ba1f-4e57-b428-06847663f6ed"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4.jpg" alt="AMD Ryzen 7 9800X3D processor in motherboard socket" srcset="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4.jpg">
</picture><a href="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4.jpg" target="_blank" data-url="https://cdn.mos.cms.futurecdn.net/jpcGvDABMZj38C822ogAX4.jpg" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"></a></p></div><figcaption itemprop="caption description"><span>I built my PC around the 9800X3D, but is it really mine? </span><span itemprop="copyrightHolder">(Image credit: Ben Wilson | Windows Central)</span></figcaption></figure><p id="ed11e6b6-692b-4d86-85eb-f8c3564201fb">I'm not naive enough to think Windows is Microsoft's top priority. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/cloud-computing" data-auto-tag-linker="true" data-url="https://www.windowscentral.com/tag/cloud-computing" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/cloud-computing">Cloud computing</a> and <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/microsoft-365" data-auto-tag-linker="true" data-url="https://www.windowscentral.com/tag/microsoft-365" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/microsoft-365">Microsoft 365</a> are far more valuable than a consumer-level operating system, though <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/windows-11-has-seemingly-burst-through-the-wall-market-share-skyrockets-as-os-passes-1-billion-users" data-url="https://www.windowscentral.com/microsoft/windows-11/windows-11-has-seemingly-burst-through-the-wall-market-share-skyrockets-as-os-passes-1-billion-users" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/windows-11-has-seemingly-burst-through-the-wall-market-share-skyrockets-as-os-passes-1-billion-users">Microsoft <em>does </em>have a staggering lead</a> over the competition — one that would be absurd to jeopardize.</p><p>Still, my problems with Notepad and Snipping Tool are a raindrop in the Pacific Ocean of Microsoft's broader plans, but I don't want first-party apps asking for authentication from its servers — nor do I want our readers to download the first debloat script they find on the web.</p><div id="2014004332270596226"><blockquote data-lang="en"><p lang="en" dir="ltr">Windows 11 won't allow me to open notepad.exe because of.. some error linked to my Microsoft account?It's getting harder to defend the weird choices this company makes in its world-leading OS 😵‍💫 pic.twitter.com/WAYjlhGdWC<a href="https://twitter.com/cantworkitout/status/2014004332270596226" data-url="https://twitter.com/cantworkitout/status/2014004332270596226" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">January 21, 2026</a></p></blockquote></div><p id="5ae8a523-e337-42ca-b460-4a2e59cd14ca">There are justifications for Microsoft adding elements of its cloud business to Windows, but I wish it wouldn't force it in a way that locks people into an online-only experience. My PC should be entirely functional without an Internet connection — especially when I need a few scribbles from Notepad.</p><p><a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence" data-auto-tag-linker="true" data-url="https://www.windowscentral.com/artificial-intelligence" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/artificial-intelligence" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence">AI</a> is undoubtedly the future, at least in <em>some </em>capacity. Even if <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/microsoft-ceo-satya-nadella-says-ai-needs-to-prove-its-worth" data-url="https://www.windowscentral.com/artificial-intelligence/microsoft-ceo-satya-nadella-says-ai-needs-to-prove-its-worth" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/microsoft-ceo-satya-nadella-says-ai-needs-to-prove-its-worth">Satya Nadella says artificial intelligence needs to prove its worth</a>, there's no believable chance that it's going away, especially now that Copilot is so deeply ingrained in practically everything Microsoft owns.</p><p>Still, if online-only services are all active by default and <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-teases-windows-12-next-version-os-agentic-ai-ambient-computing-copilot" data-url="https://www.windowscentral.com/microsoft/windows-11/microsoft-teases-windows-12-next-version-os-agentic-ai-ambient-computing-copilot" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-teases-windows-12-next-version-os-agentic-ai-ambient-computing-copilot">Windows 12 is ultimately an agentic AI OS</a>, I wouldn't be surprised if more people stick with a debloated Windows 11, just as <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-10/windows-10-eol-esu-faq" data-url="https://www.windowscentral.com/microsoft/windows-10/windows-10-eol-esu-faq" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-10/windows-10-eol-esu-faq">others did with Windows 10</a>. Do you think the next version of Windows will return some control back to the user, or will it be even more Internet-dependent?</p><figure data-bordeaux-image-check="" id="43ff7d36-93ad-4f28-8f31-dcee3d27c365"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png" alt="A pink banner that says &amp;quot;What do you think?&amp;quot; and shows a dial pointing to a mid-range hue on a gradient." srcset="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/djwPLGk9JSFVpMAYJuxrqj.png">
</picture></p></div></figure><hr id="5a8070b5-e522-4342-b327-cd180d23623a"><a href="https://www.reddit.com/r/windowscentral/" id="307ebca1-2747-4255-96cd-35b583b46d5b" data-url="https://www.reddit.com/r/windowscentral/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk.png" alt="Click to join us on r/WindowsCentral" srcset="https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/A6reKbxte8beqkHY8wjDgk.png">
</picture></p></div></figure></a><p id="d1295d20-6445-4ceb-b94c-c4af13369db7"><em>Join us on </em><a data-analytics-id="inline-link" href="https://www.reddit.com/r/windowscentral/" data-url="https://www.reddit.com/r/windowscentral/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em>Reddit at r/WindowsCentral </em></a><em>to share your insights and discuss our latest news, reviews, and more.</em></p><hr id="15f3a899-eddf-410b-a0c4-7485abeb7ae6">
</div>



<div data-hydrate="true" id="slice-container-authorBio-2ui82G2oYhs4aYo6gqhjAV"><p>Ben is a Senior Editor at Windows Central, covering everything related to technology hardware and software. He regularly goes hands-on with the latest Windows laptops, components inside custom gaming desktops, and any accessory compatible with PC and Xbox. His lifelong obsession with dismantling gadgets to see how they work led him to pursue a career in tech-centric journalism after a decade of experience in electronics retail and tech support.</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.windowscentral.com/about#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>" data-join-the-conversation-text="Join the Conversation">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Mourn Our Craft (527 pts)]]></title>
            <link>https://nolanlawson.com/2026/02/07/we-mourn-our-craft/</link>
            <guid>46926245</guid>
            <pubDate>Sat, 07 Feb 2026 18:32:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2026/02/07/we-mourn-our-craft/">https://nolanlawson.com/2026/02/07/we-mourn-our-craft/</a>, See on <a href="https://news.ycombinator.com/item?id=46926245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>I didn’t ask for this and neither did you.</p>
<p>I didn’t ask for a robot to consume every blog post and piece of code I ever wrote and parrot it back so that some hack could make money off of it.</p>
<p>I didn’t ask for the role of a programmer to be reduced to that of a glorified TSA agent, reviewing code to make sure the AI didn’t smuggle something dangerous into production.</p>
<p>And yet here we are. The worst fact about these tools is that they work. They can write code better than you or I can, and if you don’t believe me, wait six months.</p>
<p>You could abstain out of moral principle. And that’s fine, especially if you’re at the tail end of your career. And if you’re at the beginning of your career, you don’t need me to explain any of this to you, because you already use Warp and Cursor and Claude, with ChatGPT as your therapist and pair programmer and maybe even your lover. This post is for the 40-somethings in my audience who don’t realize this fact yet.</p>
<p>So as a senior, you could abstain. But then your junior colleagues will eventually code circles around you, because they’re wearing bazooka-powered jetpacks and you’re still riding around on a fixie bike. Eventually your boss will start asking why you’re getting paid twice your zoomer colleagues’ salary to produce a tenth of the code.</p>
<p>Ultimately if you have a mortgage and a car payment and a family you love, you’re going to make your decision. It’s maybe not the decision that your younger, more idealistic self would want you to make, but it does keep your car and your house and your family safe inside it.</p>
<p>Someday years from now we will look back on the era when we were the last generation to code by hand. We’ll laugh and explain to our grandkids how silly it was that we typed out JavaScript syntax with our fingers. But secretly we’ll miss it.</p>
<p>We’ll miss the feeling of holding code in our hands and molding it like clay in the caress of a master sculptor. We’ll miss the sleepless wrangling of some odd bug that eventually relents to the debugger at 2 AM. We’ll miss creating something we feel proud of, something true and right and good. We’ll miss the satisfaction of the artist’s signature at the bottom of the oil painting, the GitHub repo saying “I made this.”</p>
<p>I don’t celebrate the new world, but I also don’t resist it. The sun rises, the sun sets, I orbit helplessly around it, and my protests can’t stop it. It doesn’t care; it continues its arc across the sky regardless, moving but unmoved.</p>
<p>If you would like to grieve, I invite you to grieve with me. We are the last of our kind, and those who follow us won’t understand our sorrow. Our craft, as we have practiced it, will end up like some blacksmith’s tool in an archeological dig, a curio for future generations. It cannot be helped, it is the nature of all things to pass to dust, and yet still we can mourn. Now is the time to mourn the passing of our craft.</p>
							</div></div>]]></description>
        </item>
    </channel>
</rss>