<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 28 Dec 2024 23:30:15 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple Photos phones home on iOS 18 and macOS 15 (177 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2024/12/3.html</link>
            <guid>42533685</guid>
            <pubDate>Sat, 28 Dec 2024 19:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2024/12/3.html">https://lapcatsoftware.com/articles/2024/12/3.html</a>, See on <a href="https://news.ycombinator.com/item?id=42533685">Hacker News</a></p>
Couldn't get https://lapcatsoftware.com/articles/2024/12/3.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Google's Results Are Infested, Open AI Is Using Their Playbook from the 2000s (299 pts)]]></title>
            <link>https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</link>
            <guid>42532441</guid>
            <pubDate>Sat, 28 Dec 2024 17:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook">https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</a>, See on <a href="https://news.ycombinator.com/item?id=42532441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You know when you go on a picnic, sometimes there's a fly that decides to join you.</p>
<p>You wave your hand to shoo it away from the tasty lunch you're about to enjoy and think nothing more of it.</p>
<p>But it returns, only for you to swipe again, and that tinge of frustration starts to bloom. It returns, and now your lunch is no longer the focus, but this annoying fly whose buzzing is now an obstacle to a perfectly nice picnic.</p>
<h2>The 2000s were a picnic</h2>
<p>When Google came onto the scene, I credit its success to the tried and true paradigm that makes companies successful: <strong>simple and easy to use</strong>.</p>
<p>Yahoo was dominant back then, and it tried to put everyone and everything in front of you. Then we learned about the paralysis of choice. Too many choices, the mental fatigue weighed in, and the product became difficult to use.</p>
<p><img src="https://chuckwnelson.com/images/yahoo-vs-google.jpg" alt="Yahoo vs Google"></p>
<p>Enter Google, and it was <strong>Feeling Lucky</strong>. Just a search input, logo, and some minor text. The next step was clear. And the search results were a simple list. Sequential to avoid mental fatigue, and just enough description to make an informed choice.</p>
<p><img src="https://chuckwnelson.com/images/google-serp.jpg" alt="Trustworthy Google"></p>
<p>Then a fly came buzzing to the picnic.</p>
<h2>Enter the buzz</h2>
<p>Google added advertising. Their first iteration was clearly marked and outside the search list. Trust in the organic results mattered to Google, and it would be off-brand to show you could pay to be at the top of that list.</p>
<p>And even these ads weren't that bad. What made Google successful was showing ads you wanted to see. I'm searching for a bottle of wine, and ads for bottles of wine were shown to me. This is okay because it's not interrupting the picnic. Google's success is from active intent advertising.</p>
<p>But then ads were placed over search results, still clearly marked, but pushing down organic results. Buzz.</p>
<p>Then the SEO industry got its footing. Organic results are now optimized advertorials, or aggregation websites like Yelp and Pinterest, which have their own ad models.</p>
<p>It's a layer cake of ads all the way down the list.</p>
<p>Google lost its credibility.</p>
<h2>Google is infested with these little annoyances</h2>
<p>Enter 2024 with AI. The top 20% of search results are a wall of text from AI, then a Google product such as maps or shopping listings (with ads), then search ads, then YouTube videos, then search results (hidden ads), then some sprinkling of what you are looking for.</p>
<p>I don't want to watch a 10-minute video for a quick answer.</p>
<p>No longer can you flip back and forth from search results quickly to find the answer.</p>
<p>You need a machete to cut through the visual noise in order to find even a website that may have your lunch.</p>
<p>We are back to Yahoo in the 2000s, choice paralysis, visual clutter, and no trust in the results I do see.</p>
<p>I'm no longer feeling lucky.</p>
<p><img src="https://chuckwnelson.com/images/google-serp-today.jpg" alt="Google Search Results Today"></p>
<h2>OpenAI's search is becoming Google in the 2000s, if it can remain trustworthy.</h2>
<p>Open AI's ChatGPT search results have entered the scene. It's not perfect, but it's not Google.</p>
<p>The visual clutter is not there because it's a conversation, not a list. It's one answer instead of 10.</p>
<p>It's active intent searching, the thing that made Google successful. Plus, it's conversational. We are trained monkeys to be able to keep asking questions, with the context of the information that came before. It's simple because we are use to it.</p>
<p><strong>Active intent conversations</strong> is just a overly fancy way to say "recommendations." Just like a friend would recommend a restaurant to you based on what you ask for. But we trust our friends.</p>
<p><img src="https://chuckwnelson.com/images/openai-serp.jpg" alt="Open AI Search Results"></p>
<p>Does ChatGPT Search have trust? Open AI isn't monetizing its search just yet, but AI has its own issues with hallucinations.</p>
<p>If Open AI can build its brand and its trust with the consumer, it can dethrone the king.</p>
<p>They know this is important as well. Their website is littered with media quotes stating <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT's search</a> links to trustworthy sources, and bringing premium journalism.</p>
<p>This is the fork in the road. There are entire industries waiting to see the direction this goes in. If Open AI goes the way of Google with tons of choices and mental fatigue, it can still be successful, but will be battling to be king of the hill.</p>
<p>But if it can keep it simple <strong>and trustworthy</strong>, it can own the most valuable digital real estate as the sidekick with the single answer.</p>
<p>Google is losing trust with all these buzzing results, and its answer is to throw more spaghetti at the wall to see what sticks. But this just attracts more problems.</p>
<p>In order for Google to keep its crown, it needs to remember what it was in the 2000s and a bit of luck.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. homelessness jumps to record high amid affordable housing shortage (101 pts)]]></title>
            <link>https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</link>
            <guid>42532311</guid>
            <pubDate>Sat, 28 Dec 2024 16:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants">https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</a>, See on <a href="https://news.ycombinator.com/item?id=42532311">Hacker News</a></p>
Couldn't get https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Are you unable to find employment? (213 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42531830</link>
            <guid>42531830</guid>
            <pubDate>Sat, 28 Dec 2024 15:48:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42531830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="42531830">
      <td><span></span></td>      <td><center><a id="up_42531830" href="https://news.ycombinator.com/vote?id=42531830&amp;how=up&amp;goto=item%3Fid%3D42531830"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=42531830">Ask HN: Are you unable to find employment?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_42531830">117 points</span> by <a href="https://news.ycombinator.com/user?id=w4ffl35">w4ffl35</a> <span title="2024-12-28T15:48:02 1735400882"><a href="https://news.ycombinator.com/item?id=42531830">3 hours ago</a></span> <span id="unv_42531830"></span> | <a href="https://news.ycombinator.com/hide?id=42531830&amp;goto=item%3Fid%3D42531830">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Are%20you%20unable%20to%20find%20employment%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=42531830&amp;auth=53e534d335780effb0dc1b295eec39a0de8d5081">favorite</a> | <a href="https://news.ycombinator.com/item?id=42531830">136&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I am seeing many anecdotal experiences shared online on various platforms stating that it is difficult to find employment in tech. I myself have had a difficult time landing an interview over the last year despite having two decades of experience.</p><p>I am attempting to gain some insight into the issue. My situation is somewhat unique in that I am self-taught without a CS degree. I'm a very experienced, diligent worker, etc, but an algorithm doesn't care about this and so getting through the filters is difficult.</p><p>However I see many discussions being posted (primarily on X) stating that it is nearly impossible for people with CS degrees (especially white males) to get an interview let alone a job. There have been mass layoffs, less money being invested etc. 
Many people have claimed AI is taking jobs, or that there aren't as many jobs available, yet at the same time, Elon Musk and others claim there is an engineer shortage and we must increase the number of H-1B visas in order to fill this gap. When I apply to a position on linkedin I can see that even the most Jr positions have over 100 applicants.</p><p>I know that X can be slanted, and really anything posted online must be taken with a grain of salt - but I'm seeing many people claiming to be in the same situation as myself, and most of them claim to be white males.</p><p>Furthermore, in the last two years I experienced two layoffs. In both situations it was white males let go in favor of Indian and KZ foreigners. Again - this is anecdotal and could be a coincidence, but its awfully telling that Vivek and Elon are calling American tech workers uncultured, lazy and stupid in the wake of these experiences and those that I've read about online.</p><p>I don't want to start a war here on hackernews, but I'm looking for people's personal experiences. Do they match up? Are you having a hard time finding employment? Have you been fired in favor of foreign workers? Is this racism / ageism / sexism at play or is that being overblown by political actors?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Automated My Job Application Process (223 pts)]]></title>
            <link>https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</link>
            <guid>42531695</guid>
            <pubDate>Sat, 28 Dec 2024 15:26:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1">https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</a>, See on <a href="https://news.ycombinator.com/item?id=42531695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>Look, I'll be honest - job hunting sucks.</p>
<p>It's this soul-crushing cycle of copying and pasting the same information over and over again, tweaking your resume for the 100th time, and writing cover letters that make you sound desperate without actually sounding desperate.</p>
<p>But here's the thing: repetitive tasks + structured process = perfect automation candidate.</p>
<p>So I did what any sane developer would do - I built a system to automate the whole damn thing. By the end, I had sent out 250 job applications in 20 minutes. (The irony? I got a job offer before I even finished building it. More on that later.)</p>
<p>Let me walk you through how I did it.</p>
<h2 id="heading-the-job-application-process-is-broken">The Job Application Process is Broken</h2>
<p>Think about it - every job application follows the same basic pattern:</p>
<ol>
<li><p>Find job posting</p>
</li>
<li><p>Check if you're qualified</p>
</li>
<li><p>Research company (let's be real, most people skip this)</p>
</li>
<li><p>Submit resume + cover letter</p>
</li>
<li><p>Wait... and wait... and wait...</p>
</li>
</ol>
<p>It's like a really boring video game where you do the same quest over and over, hoping for different results.</p>
<h2 id="heading-building-the-proof-of-concept">Building the Proof of Concept</h2>
<p>I started by writing some quick Python scripts to test if this crazy idea could work. Here's how I broke it down:</p>
<h3 id="heading-step-1-getting-the-job-listings-the-manual-part">Step 1: Getting the Job Listings (The Manual Part)</h3>
<p>First challenge: getting job listings at scale. I tried web scraping but quickly realized something: job boards are like snowflakes - each one is uniquely annoying to scrape.</p>
<p>I tested dumping entire web pages into an LLM to clean the data, but:</p>
<ul>
<li><p>It was expensive as hell</p>
</li>
<li><p>I didn't want the AI hallucinating job requirements (imagine explaining that in an interview)</p>
</li>
</ul>
<p>So I went old school - manual HTML copying. Yes, it's primitive. Yes, it works. Sometimes the simplest solution is the best solution.</p>
<h3 id="heading-step-2-cleaning-the-raw-html">Step 2: Cleaning the Raw HTML</h3>
<p>The raw HTML was a mess, but I needed structured data like this:</p>
<pre><code>{
    <span>"job_link"</span>: <span>"https://example.com/job/12345"</span>,
    <span>"job_id"</span>: <span>"12345"</span>,
    <span>"job_role"</span>: <span>"software developer"</span>,
    <span>"employer"</span>: <span>"Tech Corp Inc"</span>,
    <span>"location"</span>: <span>"San Francisco, CA"</span>,
    <span>"work_arrangement"</span>: <span>"Remote"</span>,
    <span>"salary"</span>: <span>"$150,000"</span>
}
</code></pre>
<p>Pro tip: You can just show ChatGPT a sample of your HTML and the output format you want, and it'll write the parsing script for you. Work smarter, not harder.</p>
<h3 id="heading-step-3-getting-the-full-job-details">Step 3: Getting the Full Job Details</h3>
<p>This part was straightforward but required some finesse. For each job listing, I made a GET request to fetch the full description. Each request returns raw HTML that still has all the website scaffolding - navigation bars, popups, footer junk, the works.</p>
<p>I wrote a simple HTML parser to strip out everything except the actual job description. Sometimes you'll hit extra hurdles - like having to click a button to reveal the recruiter's email or company details. The good news? Since you're working with one job board at a time, you only need to figure out these patterns once.</p>
<p>Pro tip: Always add delays between requests. I set mine to 2-3 seconds. Sure, it makes the process slower, but it's better than getting your IP banned. Don't be that person who DDOSes job boards - I added delays between requests because I'm not a monster.</p>
<h3 id="heading-step-4-converting-raw-html-to-structured-data">Step 4: Converting Raw HTML to Structured Data</h3>
<p>This is where it gets interesting. Job postings are like people - they all have the same basic parts but the organization is chaos. Some list skills at the top, others bury them in paragraphs of corporate speak.</p>
<p>Enter the LLM prompt that saved my sanity:</p>
<pre><code><span>const</span> prompt = <span>`Please analyze these HTML contents from a job posting and extract information into a structured JSON format.

[... HTML content ...]

Format the response as valid JSON object with these exact keys:
- contact_email
- application_instructions
- job_posting_text (in markdown)
- job_posting_link
- additional_info (salary, location, etc.)
- job_title
- job_company
- job_department
- job_location
- job_skills
- job_instructions (how to apply)

optional keys

- hiring_manager_name
- 
- job_portal
`</span>
</code></pre>
<h3 id="heading-step-5-generating-cover-letters-that-dont-suck">Step 5: Generating Cover Letters That Don't Suck</h3>
<p>The secret to good cover letters? Context. I fed my resume into the LLM along with the job details. This way, the AI could match my experience with their requirements. Suddenly, those "I'm excited about this opportunity" letters actually had substance.</p>
<p>Here's the prompt that made it happen:</p>
<pre><code><span>const</span> prompt = <span>`Please help me write a professional job application email based on the following information:

=== MY RESUME ===
<span>${resumeMarkdown}</span>

=== JOB DETAILS ===
Job Title: <span>${job_title}</span>
Company: <span>${job_company}</span>
Department: <span>${job_department || <span>''</span>}</span>
Location: <span>${job_location || <span>''</span>}</span>
Job Description: <span>${job_posting_text }</span>
Required Skills: <span>${job_skills?.join(<span>', '</span>) || <span>''</span>}</span>
Application Instructions: <span>${job_instructions || <span>''</span>}</span>

Additional Context:
- Hiring Manager Name: <span>${hiring_manager_name || <span>''</span>}</span>
- Referral Source: <span>${referral_source || <span>'Job board'</span>}</span>
- Application Portal: <span>${job_portal || <span>''</span>}</span>

Instructions:
1. Create an email that is ready to send without any placeholders or edits needed
2. If any critical information is missing (like company name or job title), respond with an error message instead of generating incomplete content
3. Skip any optional fields if they're empty rather than including placeholder text
4. Use natural sentence structure instead of obvious template language
5. Include specific details from both the resume and job description to show genuine interest and fit
6. Any links or contact information should be properly formatted and ready to use

Format the response as a JSON object with these keys:
{
  "status": "success" or "error",
  "error_message": "Only present if status is error, explaining what critical information is missing",
  "email": {
    "subject": "The email subject line",
    "body_html": "The email body in HTML format with proper formatting",
    "body_text": "The plain text version of the email",
    "metadata": {
      "key_points_addressed": ["list of main points addressed"],
      "skills_highlighted": ["list of skills mentioned"],
      "resume_matches": ["specific experiences/skills from resume that match job requirements"],
      "missing_recommended_info": ["optional fields that were missing but would strengthen the application if available"],
      "tone_analysis": "brief analysis of the email's tone"
    }
  }
}

Critical required fields (will return error if missing):
- Job title
- Company name
- Job description
- Resume content

Recommended but optional fields:
- Hiring manager name
- Department
- Location
- Application instructions
- Referral source
- Required skills list

Please ensure all HTML in body_html is properly escaped for JSON and uses only basic formatting tags (p, br, b, i, ul, li) to ensure maximum email client compatibility.
`</span>
</code></pre>
<p>The prompt does a few clever things:</p>
<ol>
<li><p>Forces structured output - no wishy-washy responses</p>
</li>
<li><p>Tracks which of your skills match the job requirements</p>
</li>
<li><p>Identifies any missing info that could strengthen the application</p>
</li>
<li><p>Generates both HTML and plain text versions (because some job portals hate formatting)</p>
</li>
</ol>
<p>And here's the kicker - it fails fast if critical info is missing. No more generic "I saw your job posting" emails. Either the cover letter has substance, or it doesn't get sent. Period.</p>
<p>(I start all all my prompts with ‘please’, so that when AI eventually takes over, they would consider me friendly 😁)</p>
<h3 id="heading-step-6-sending-the-emails-the-moment-of-truth">Step 6: Sending the Emails (The Moment of Truth)</h3>
<p>Last step - actually sending these beautifully crafted applications. Sounds simple, right? Just hook up an email service and blast away?</p>
<p>Not so fast. I needed a way to:</p>
<ul>
<li><p>Send professional-looking emails</p>
</li>
<li><p>Track what was actually sent</p>
</li>
<li><p>Monitor responses (can't ghost the recruiters)</p>
</li>
<li><p>Not get flagged as spam (crucial!)</p>
</li>
</ul>
<p>For testing, I sent all emails to a test account first. Pro tip: when you do send to actual recruiters, BCC yourself. Nothing worse than wondering "did that email actually go through?"</p>
<p>At this stage of the POC, I just used a simple email provider like Mailgun. Quick, dirty, but effective. Don't worry - in Part 2, I'll tell you about the rabbit hole I went down trying to build a full email management system. (Spoiler: it involves rejected AWS applications and a failed attempt at running my own email server. Good times.)</p>
<h2 id="heading-the-results">The Results</h2>
<p>The proof of concept worked better than expected. I could take a job board, extract listings, parse them, and generate personalized applications - all with a few Python scripts.</p>
<p>But this was just the beginning. The real challenge? Turning these scripts into a proper application that could:</p>
<ul>
<li><p>Handle multiple job boards</p>
</li>
<li><p>Track applications</p>
</li>
<li><p>Manage email responses</p>
</li>
<li><p>Not get me blacklisted from every HR system in existence</p>
</li>
</ul>
<p>In Part 2, I'll show you how I built the actual application, complete with all the technical decisions, trade-offs, and "what was I thinking" moments.</p>
<p>Stay tuned - it gets even better.</p>
<hr>
<p><em>Want to know when Part 2 drops? Follow me on</em> <a target="_blank" href="https://x.com/DavidDodda_"><em>Twitter</em></a> <em>or</em> <a target="_blank" href="https://www.linkedin.com/in/arundavidreddy/"><em>LinkedIn</em></a><em>. And yes, I'll eventually tell you how I got a job offer before finishing this project. It's a good story.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf 2024 Notes (223 pts)]]></title>
            <link>https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</link>
            <guid>42531217</guid>
            <pubDate>Sat, 28 Dec 2024 14:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sachachua.com/blog/2024/12/emacsconf-2024-notes/">https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</a>, See on <a href="https://news.ycombinator.com/item?id=42531217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    <nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav><article id="index0">
<header>
Posted: <time>Dec 27, 2024</time> - Modified: <time>Dec 28, 2024</time>| <span><a href="https://sachachua.com/blog/category/emacs">emacs</a>, <a href="https://sachachua.com/blog/category/emacsconf">emacsconf</a></span>
</header>
<div>
<p>
<span><span>[2024-12-28 Sat]</span></span>: Added talk and Q&amp;A count, added note about BBB max simultaneous users, added note about BBB, added thanks
</p>

<p>
<a href="https://emacsconf.org/2024/talks">The videos have been uploaded</a>, thank-you notes
have been sent, and the kiddo has decided to play
a little Minecraft on her own, so now I get to
write some quick notes on <a href="https://emacsconf.org/2024">EmacsConf 2024</a>.
</p>


<div id="outline-container-emacsconf-2024-notes-stats">
<h2 id="emacsconf-2024-notes-stats">Stats</h2>
<div id="text-emacsconf-2024-notes-stats">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Talks</td>
<td>31</td>
</tr>

<tr>
<td>Hours</td>
<td>10.7</td>
</tr>

<tr>
<td>Q&amp;A web conferences</td>
<td>21</td>
</tr>

<tr>
<td>Hours</td>
<td>7.8</td>
</tr>
</tbody>
</table>


<ul>
<li>Saturday:
<ul>
<li>gen: 177 peak + 14 peak lowres</li>
<li>dev: 226 peak + 79 peak lowres</li>
</ul></li>
<li>Sunday:
<ul>
<li>gen: 89 peak + 10 peak lowres</li>
</ul></li>
</ul>

<p>
Server configuration:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>meet</td>
<td>16GB 8core dedicated</td>
<td>peak 409% CPU (100% is 1 CPU), average 69.4%</td>
</tr>

<tr>
<td>front</td>
<td>32GB 8core shared</td>
<td>peak 70.66% CPU (100% is 1 CPU)</td>
</tr>

<tr>
<td>live</td>
<td>64GB 16core shared</td>
<td>peak 552% CPU (100% is 1 CPU) average 144%</td>
</tr>

<tr>
<td>res</td>
<td>46GB 12core</td>
<td>peak 81.54% total CPU (100% is 12 CPUs); each OBS ~250%), mem 7GB used</td>
</tr>

<tr>
<td>media</td>
<td>3GB 1core</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>

<p>
YouTube livestream stats:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Shift</th>
<th scope="col">Peak</th>
<th scope="col">Avg</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gen Sat AM</td>
<td>46</td>
<td>28</td>
</tr>

<tr>
<td>Gen Sat PM</td>
<td>24</td>
<td>16</td>
</tr>

<tr>
<td>Dev Sat AM</td>
<td>15</td>
<td>7</td>
</tr>

<tr>
<td>Dev Sat PM</td>
<td>20</td>
<td>12</td>
</tr>

<tr>
<td>Gen Sun AM</td>
<td>28</td>
<td>17</td>
</tr>

<tr>
<td>Gen Sun PM</td>
<td>26</td>
<td>18</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-timeline">
<h2 id="emacsconf-2024-notes-timeline">Timeline</h2>
<div id="text-emacsconf-2024-notes-timeline">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Call for proposals</td>
<td><span><span>[2024-06-30 Sun]</span></span></td>
</tr>

<tr>
<td>CFP deadline</td>
<td><span><span>[2024-09-20 Fri]</span></span></td>
</tr>

<tr>
<td>Speaker notifications</td>
<td><span><span>[2024-09-27 Fri]</span></span></td>
</tr>

<tr>
<td>Publish schedule</td>
<td><span><span>[2024-10-25 Fri]</span></span></td>
</tr>

<tr>
<td>Video target date</td>
<td><span><span>[2024-11-08 Fri]</span></span></td>
</tr>

<tr>
<td>EmacsConf</td>
<td><span><span>[2024-12-07 Sat]</span></span>-<span><span>[2024-12-07 Sat]</span></span></td>
</tr>
</tbody>
</table>

<p>
We did early acceptances again this year. That was
nice. I wasn't sure about committing longer
periods of time early in the scheduling process,
so I usually tried to nudge people to plan a
20-minute video with the option of possibly doing
more, and I okayed longer talks once we figured
out what the schedule looked like.
</p>

<p>
There were 82 days between the call for proposals
and the CFP deadline, another 49 days from that to
the video target date, and 29 days between the
video target date and EmacsConf. It felt like
there was a good amount of time for proposals and
videos. Six videos came in before or on the target
date. The rest trickled in afterwards, which was
fine because we wanted to keep things low-pressure
for the speakers. We had enough capacity to
process and caption the videos as they came in.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-data">
<h2 id="emacsconf-2024-notes-data">Data</h2>
<div id="text-emacsconf-2024-notes-data">
<p>
We continued to use an Org file to store the talk information.
It would be great to add some validation functions:
</p>

<ul>
<li>Check permissions and ownership for files</li>
<li>Check case sensitivity for Q&amp;A type detection</li>
<li>Check BBB redirect pages to make sure they exist</li>
<li>Check transcripts for ` because that messes up formatting;
consider escaping for the wiki</li>
<li>Check files are public and readable</li>
<li>Check captioned by comment vs caption status vs captioner</li>
</ul>

<p>
Speakers uploaded their files via <a href="https://github.com/psi-4ward/psitransfer">PsiTransfer</a>
again. I didn't get around to setting up the FTP
server. I should probably rename
ftp-upload.emacsconf.org to upload.emacsconf.org
so that people don't get confused.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-communication">
<h2 id="emacsconf-2024-notes-communication">Communication</h2>
<div id="text-emacsconf-2024-notes-communication">
<p>
As usual, we announced the EmacsConf call for
proposals on <a href="https://lists.gnu.org/archive/html/emacs-tangents/2024-06/msg00004.html">emacs-tangents</a>, <a href="https://sachachua.com/blog/2024/07/2024-07-01-emacs-news/">Emacs News</a>,
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a>, <a href="https://lists.gnu.org/archive/html/emacsconf-org/2024-06/msg00000.html">emacsconf-org</a>,
<a href="https://reddit.com/r/emacs">https://reddit.com/r/emacs</a>. <a href="https://systemcrafters.net/live-streams/july-12-2024/">System Crafters</a>,
<a href="https://irreal.org/blog/?p=12280">Irreal</a>, and <a href="https://emacs-apac.gitlab.io/announcements/november-2024/">Emacs APAC</a>, mentioned it, and people
also posted about EmacsConf on <a href="https://mastodon.social/tags/emacsconf">Mastodon</a>, <a href="https://x.com/search?q=%23emacsconf&amp;src=typed_query&amp;f=live">X</a>,
<a href="https://bsky.app/hashtag/emacsconf">BlueSky</a>, and <a href="https://www.facebook.com/story.php?story_fbid=538504738701826&amp;id=100076269125316&amp;_rdr">Facebook</a>. <a href="https://toot.si/@len/113392360015917614">@len@toot.si suggested</a>
submitting EmacsConf to <a href="https://foss.events/">https://foss.events</a>, so I
did. There was some other <a href="https://www.reddit.com/r/emacs/comments/1h5c778/which_emacsconf_2024_talks_have_your_attention/">EmacsConf-related
discussions</a> in r/emacs. <a href="https://200ok.ch/posts/2024-09-16_announcing_emacsconf__official_swiss_satellite.html">200ok and Ardeo</a> organized
an in-person meetup in Switzerland, and <a href="https://dogodki.kompot.si/events/00a6f9ee-9087-400d-9d9b-d51b98561424">emacs.si got together in Ljubljana</a>.
</p>

<p>
For communicating with speakers and volunteers, I
used lots of mail merge
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-mail.el">emacsconf-mail.el</a>). Most of the
templates only needed a little tweaking from last
year's code. I added a function to help me
double-check delivery, since the batches that I
tried to send via async sometimes ran into errors.
</p>

<p>
Next time, I think it could be interesting to add
more blog posts and Mastodon toots.
</p>

<p>
Also, maybe it would be good to get in touch with podcasts like
</p>

<ul>
<li><a href="https://systemcrafters.net/">System Crafters</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLbFVcOQ-YH_LRP687N0YeN78YZmBp5wqF">This Week in Linux</a></li>
<li><a href="https://linuxunplugged.com/">Linux Unplugged</a></li>
<li><a href="http://asknoahshow.com/">Ask Noah</a></li>
<li><a href="https://linuxafterdark.net/">Linux After Dark</a></li>
<li><a href="https://anonradio.net/">Lispy Gopher Show</a></li>
</ul>

<p>
to give a heads up on EmacsConf before it
happens and also let them know when videos are
available.
</p>

<p>
We continued to use <a href="https://www.mumble.info/">Mumble</a> for backstage coordination. It worked out well.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-schedule">
<h2 id="emacsconf-2024-notes-schedule">Schedule</h2>
<div id="text-emacsconf-2024-notes-schedule">
<p>
The schedule worked out to two days of talks, with
two tracks on the first day, and about 15-20
minutes between each talk. We were able to adapt
to late submissions, last-minute cancellations,
and last-minute switches from Q&amp;A to live.
</p>

<p>
We added an open mic session on Sunday to fill in
the time from a last-minute cancellation. That
worked out nicely and it might be a good idea to
schedule in that time next year. It was also good
to move some of the usual closing remarks earlier.
We were able to wrap up in a timely manner, which
was great for some hosts and participants because
they didn't have to stay up so late.
</p>

<p>
Sunday was single-track, so it was nice and
relaxed. I was a little worried that people might
get bored if the current talk wasn't relevant to
their interests, but everyone managed just fine. I
probably should have remembered that Emacs people
are good at turning extra time into more
configuration tweaks.
</p>

<p>
Most of the scheduling was determined by people's
time constraints, so I didn't worry too much about
making the talks flow logically. I accidentally
forgot to note down one speaker's time
constraints, but he caught it when we e-mailed the
draft schedule and I was able to move things
around for a better time for him.
</p>

<p>
There was a tiny bit of technical confusion
because the automated schedule publishing on res
had case-sensitive matching (<code>case-fold-search</code>
was set to <code>nil</code>), so if a talk was set to "Live"
Q&amp;A, it didn't announce it as a live talk because
it was looking for <code>live</code>. Whoops. I've added that
configuration setting to my
<code>emacsconf-stream-config.el</code>, so the ansible
scripts should get it next time.
</p>

<p>
I asked Leo and Corwin if they wanted to manually
control the talks this year. They opted to leave
it automatically managed by crontab so that they
wouldn't have to worry as much about timekeeping.
It worked reliably. Hooray for automation! The
only scheduling hiccup was because I turned off
the crontab so that we could do Saturday closing
remarks when we wanted to and I forgot to reenable
autopilot the next day. We noticed when the
opening remarks didn't start right on the dot, and
I got everything back on track.
</p>

<p>
Like last year, I scheduled the dev track to start
a little later than the gen track. That made for a
less frantic morning. Also, this year we scheduled
Sunday morning to start with more IRC Q&amp;A instead
of live Q&amp;A. We didn't notice any bandwidth issues
on Sunday morning this time.
</p>

<p>
It would be nice to have Javascript countdowns in
some kind of web interface to make it easier for
hosts, especially if we can update it with the
actual time the current video will end in MPV.
</p>

<p>
I can also update the <a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-stream.el">emacsconf-stream.el</a> code to
make it easier to automatically count down to the
next talk or to a specific talk.
</p>

<p>
We have Javascript showing local time on the
individual talk pages, but it would be nice to
localize the times on all the schedule/watch pages
too.
</p>

<p>
Most of my stuff (scheduling, publishing, etc.) is
handled by automation with just a little bit of
manual nudging every so often, so it might be
possible to organize an event that's more friendly
to Europe/APAC timezones.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-videos">
<h2 id="emacsconf-2024-notes-recorded-videos">Recorded videos</h2>
<div id="text-emacsconf-2024-notes-recorded-videos">
<p>
As usual, we strongly encouraged speakers to
record videos to lower everyone's stress levels
and allow for captioning by volunteers, so that's
what most speakers did. We were able to handle
a few last-minute submissions as well as a
live talk. Getting videos also meant we could
publish them as each talk went live, including
automatically putting the videos and transcripts
on the wiki.
</p>

<p>
We didn't have obvious video encoding cut-offs, so
re-encoding in a screen was a reliable way to
avoid interruptions this year. Also, no one
complained about tiny text or low resolution, so
the talk preparation instructions seem to be
working out.
</p>

<p>
Automatically normalizing the audio with
ffmpeg-normalize didn't work out, so Leo Vivier
did a last-minute scramble to normalize the audio
the day before the conference. Maybe that's
something that volunteers can help with during the
lead-up to the conference, or maybe I can finally
figure out how to fit that into my process. I
don't have much time or patience to listen to
things, but it would be nice to get that sorted
out early.
</p>

<p>
Next year we can try remixing the audio to mono.
One of the talks had some audio moving around,
which was a little distracting. Also, some people
listen to the talks in one ear, so it would be
good to drop things down to mono for them.
</p>

<p>
We think 60fps videos stressed the res server a
bit, resulting in dropped frames. Next year, we
can downsample those to 30fps and add a note to
the talk preparation instructions. The hosts also
suggested looking into setting up streaming from
each host's computer instead of using our shared
VNC sessions.
</p>

<p>
There was some colour smearing and weirdness when
we played some videos with mpv on res. Upgrading
MPV to v0.38 fixed it.
</p>

<p>
Some people requested dark mode (light text on
dark background), so maybe we can experiment with
recommending that next year.
</p>

<p>
I did a last-minute change to the shell scripts to
load resources from the cache directory instead of
the assets/stream directory, but I didn't get all
of the file references, so sometimes the test
videos played or the introductions didn't have
captions. On the plus side, I learned how to use
<code>j</code> in MPV to reload a subtitle file.
</p>

<p>
Sometimes we needed to play the videos manually.
If we get the hang of starting MPV in a screen or
tmux session, it might be easier for hosts to
check how much time is left, or to restart a video
at a specific point if needed. Leo said he'll work
on figuring out the configuration and the Lua
scripts.
</p>

<p>
I uploaded all the videos to YouTube and scheduled
them. That was nice because then I didn't have to
keep updating things during the conference. It
turns out that Toobnix also has a way to schedule
uploads. I just need to upload it as unlisted
first, and then choose Scheduled from the
visibility. I wonder if <a href="https://www.npmjs.com/package/%40peertube%2Fpeertube-cli">peertube-cli</a> can be
extended to schedule things. Anyway, since I
didn't know about that during the conference, I
just used <code>emacsconf-publish-upload-talk</code> function
to upload videos.
</p>

<p>
It was fun playing <a href="https://www.youtube.com/watch?v=urcL86UpqZc">Interview with an Emacs
Enthusiast in 2023 [Colorized] - YouTube</a> at lunch.
I put together some captions for it after the
conference, so maybe we can play it with captions
next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-introductions">
<h2 id="emacsconf-2024-notes-recorded-introductions">Recorded introductions</h2>
<div id="text-emacsconf-2024-notes-recorded-introductions">
<p>
We record introductions so that hosts don't have
to worry about how to say things on air. I should
probably send the intro check e-mail
earlier–maybe on the original video target date,
even if speakers haven't submitted their videos
yet. This will reduce the last-minute scramble to
correct intros.
</p>

<p>
When I switched the shell scripts to use the cache
directory, I forgot to get it to do the intros
from that directory as well, so some of the
uncorrected intros were played.
</p>

<p>
I forgot to copy the intro VTTs to the cache
directory. This should be handled by the
subed-record process for creating intros, so it'll
be all sorted out next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-captioning">
<h2 id="emacsconf-2024-notes-captioning">Captioning</h2>
<div id="text-emacsconf-2024-notes-captioning">
<p>
We used <a href="https://github.com/m-bain/whisperX">WhisperX</a> for speech-to-text this year. It
did a great job at preparing the first drafts of
captions that our wonderful army of volunteer
captioners could then edit. WhisperX's built-in
voice activity detection cut down a lot on the
hallucinations that <a href="https://github.com/openai/whisper">OpenAI Whisper</a> had during
periods of silence in last year's captions, and
there was only one instance of WhisperX missing a
chunk of text from a speaker that I needed to
manually fill in. I upgraded to a Lenovo P52 with
64GB RAM, so I was able to handle last-minute
caption processing on my computer. It might be
handy to have a smaller model ready for those
last-minute requests, or have something ready to
go for the commercial APIs.
</p>

<p>
The timestamps were a little bit off. It was
really helpful that speakers and volunteers used
the backstage area to check video quality. I used
<a href="https://www.readbeyond.it/aeneas/">Aeneas</a> to re-align the text, but Aeneas was also
confused by silences. I've added some code to
<a href="https://github.com/sachac/subed">subed</a> so that I can realign regions of subtitles
using Aeneas or WhisperX timestamps, and I also
wrote some code to <a href="https://sachachua.com/blog/2024/11/checking-caption-timing-by-skimming-with-emacs-lisp-or-js/">skim timestamps for easy
verification</a>.
</p>

<p>
Anush V experimented with using machine learning
for <a href="https://gitlab.com/jun8git/sub-seg">subtitle segmentation</a>, so that might be
something to explore going forward.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-bigbluebutton-web-conference">
<h2 id="emacsconf-2024-notes-bigbluebutton-web-conference">BigBlueButton web conference</h2>
<div id="text-emacsconf-2024-notes-bigbluebutton-web-conference">
<p>
This year we set up a new <a href="https://demo.bigbluebutton.org/">BigBlueButton</a> web conferencing server. The server with our previous BigBlueButton instance had been donated by a defunct nonprofit, so it finally got removed on October 27. After investigating whether Jitsi or Galene might be a good fit for EmacsConf, we decided to continue with BigBlueButton. There were some concerns about <a href="https://github.com/bigbluebutton/bbb-install/issues/261">non-free Mongo</a> for BBB versions &gt;= 2.3 and &lt; 3, so I installed BBB 3.0. This was hard to get working on a Docker on the existing res server. <a href="https://emacsconf.org/2024/organizers-notebook/#bbb">We decided</a> it was worth spinning up an additional Linode virtual private server. It turned out that BBB refused to run on anything smaller than 8GB/4core, so I scaled up to that during testing, scaled back down to 1GB/1core in between, and scaled up to 16GB/8core dedicated during the conference.
</p>

<p>
I'm still not 100% sure I set everything up
correctly or that everything was stable. Maybe
next year BBB 3.0 will be better-tested, someone
more sysad-y can doublecheck the setup, or we can
try <a href="https://galene.org/">Galene</a>.
</p>

<p>
One of the benefits of upgrading to BBB 3.0 was
that we could use the smart layout feature to drag
the webcam thumbnails to the side of the shared
screen. This made shared screens much easier to
read. I haven't automated this yet, but it was
easy enough for us to do via the shared VNC
session.
</p>

<p>
On the plus side, it was pretty straightforward to use the Rails console to create all the rooms. We used moderator access codes to give all the speakers moderator access. Mysteriously, superadmins didn't automatically have moderator access to all the rooms even if they were logged in, so we needed to add host access by hand so that they could start the recordings.
</p>

<p>
Since we self-hosted and were budgeting more for the full-scale node, I didn't feel comfortable scaling it up to production size until a few days before the conference. I sent the access codes with the check-in e-mails to give speakers time to try things out.
</p>

<p>
<a href="https://sachachua.com/blog/2023/12/emacsconf-backstage-figuring-out-our-maximum-number-of-simultaneous-bigbluebutton-users/">Compared to last year's stats</a>:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">2023</th>
<th scope="col">2024</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max number of simultaneous users</td>
<td>62</td>
<td>107</td>
</tr>

<tr>
<td>Max number of simultaneous meetings</td>
<td>6</td>
<td>7</td>
</tr>

<tr>
<td>Max number of people in one meeting</td>
<td>27</td>
<td>25</td>
</tr>

<tr>
<td>Total unique people</td>
<td>84</td>
<td>102</td>
</tr>

<tr>
<td>Total unique talking</td>
<td>36</td>
<td>40</td>
</tr>
</tbody>
</table>

<p>
(Max number of simultaneous users wasn't deduplicated, since we need that number for server load planning)
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-tech-checks-and-hosting">
<h2 id="emacsconf-2024-notes-tech-checks-and-hosting">Tech checks and hosting</h2>
<div id="text-emacsconf-2024-notes-tech-checks-and-hosting">
<p>
FlowyCoder did a great job getting everyone
checked in, especially once I figured out the
right checklist to use. We used people's emergency
contact information a couple of times.
</p>

<p>
Corwin and Leo were able to jump in and out of the
different streams for hosting. Sometimes they were
both in the same Q&amp;A session, which made it more
conversational especially when they were covering
for technical issues. We had a couple of crashes
even though the tech checks went fine, so that was
weird. Maybe something's up with BBB 3.0 or how I
set it up.
</p>

<p>
Next time, we can consider asking speakers what
kind of facilitation style they like. A chatty
host? Someone who focuses on reading the questions
and then gets out of the way? Speakers reading
their own questions and the host focusing on
timekeeping/troubleshooting?
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-streaming">
<h2 id="emacsconf-2024-notes-streaming">Streaming</h2>
<div id="text-emacsconf-2024-notes-streaming">
<p>
I experimented with setting up the live0 streaming
node as a 64GB 32core dedicated CPU server, but
that was overkill, so we went back down to 64GB
16core and it still didn't approach the CPU
limits.
</p>

<p>
The 480p stream seemed stable, hooray! I had set
it up last year to automatically kick in as soon
as I started streaming to Icecast, and that worked
out. I think I changed a loop to be <code>while true</code>
instead of making it try 5 times, so that probably
helped.
</p>

<p>
I couldn't get Toobnix livestreaming to work this
year. On the plus side, that meant that I could
use OBS to directly stream to YouTube instead of
trying to set up multicasting. I set up one
YouTube livestreaming event for each shift and
added the RTMP keys to our shift checklists so
that I could update the settings before starting
the stream. That was pretty straightforward.
</p>

<p>
This year, I wrote a little randomizer function to
display things on the countdown screen. At first I
just dumped in
<a href="https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html">https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html</a>,
but some of those were not quite what I was
looking for. (… Probably should've read them all
first!) Then I added random packages from GNU ELPA
and NonGNU ELPA, and that was more fun. I might
add MELPA next time too. The code for dumping
random packages is probably worth putting into a
different blog post, since it's the sort of thing
people might like to add to their dashboards or
screensavers.
</p>

<p>
I ran into some C-s annoyances in screen even with
flow control turned off, so it might be a good
idea to switch to tmux instead of screen.
</p>

<p>
Next year, I think it might be a good idea to make
intro images for each talk. Then we can use that
as the opening slide in BigBlueButton (unless
they're already sharing something else) as well as
a video thumbnail.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-publishing">
<h2 id="emacsconf-2024-notes-publishing">Publishing</h2>
<div id="text-emacsconf-2024-notes-publishing">
<p>
The automated process for publishing talks and
transcripts to the wiki occasionally needed
nudging when someone else had committed a change
to the wiki. I thought I had a <code>git pull</code> in there
somewhere, but maybe I need to look at it some
more.
</p>

<p>
I forgot to switch the conference publishing phase
and enable the inclusion of Etherpads, but
fortunately Ihor noticed. I did some last-minute
hacking to add them in, and then I remembered the
variables I needed to set. Just need to add it to
our process documentation.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-etherpad">
<h2 id="emacsconf-2024-notes-etherpad">Etherpad</h2>
<div id="text-emacsconf-2024-notes-etherpad">
<p>
We used <a href="https://etherpad.org/">Etherpad</a> 1.9.7 to collect Q&amp;A again this
year. I didn't upgrade to Etherpad v2.x because I
couldn't figure out how to get it running within
the time I set aside for it, but maybe that's
something for next year.
</p>

<p>
I wrote some Elisp to copy the current ERC line
(unwrapped) for easier pasting into Etherpad. That
worked out really well, and it let me keep up with
copying questions from IRC to the pad in between
other bits of running around.
(<code>emacsconf-erc-copy</code> in
<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>)
</p>

<p>
Next year, I'll add pronouns and pronunciations to
the Etherpad template so that hosts can refer to
them easily.
</p>

<p>
If I rejig the template to move the next/previous
links so that notes can be added to the end, I
might be able to use the Etherpad API to add text
from IRC.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-irc">
<h2 id="emacsconf-2024-notes-irc">IRC</h2>
<div id="text-emacsconf-2024-notes-irc">
<p>
We remembered to give the libera.chat people a
heads-up before the conference, so we didn't run
into usage limits for <a href="https://chat.emacsconf.org/">https://chat.emacsconf.org</a>. Yay!
</p>

<p>
Aside from writing <code>emacsconf-erc-copy</code>
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>) to make it easier
to add text from IRC to the Etherpad, I didn't
tinker much with the IRC setup for this year. It
continued to be a solid platform for discussion.
</p>

<p>
I think a keyboard shortcut for inserting a talk's
URL could be handy and should be pretty easy to
add to my Embark keymap.
</p>
</div>
</div>

<div id="outline-container-emacsconf-2024-notes-budget-and-donations">
<h2 id="emacsconf-2024-notes-budget-and-donations">Budget and donations</h2>
<div id="text-emacsconf-2024-notes-budget-and-donations">
<p>
The total hosting cost for the conference was USD
42.92 + tax and the BBB testing in the lead-up to
the conference was USD 3.11 + tax, so a total of
USD 46.03+tax. The web node and the livestreaming
node are kept as 1GB nanodes the rest of the year
(USD 5 x 2 servers + tax, so USD 110). Very
manageable.
</p>

<p>
The Free Software Foundation also provided
<a href="https://media.emacsconf.org/">media.emacsconf.org</a> for serving media files. Ry P
provided res.emacsconf.org for OBS streaming over
VNC sessions.
</p>

<p>
Amin Bandali was away during the conference
weekend and no one else knew how to get the list
of donors and current donation stats from the FSF
Working Together program on short notice. Next
time, we can get that sorted out beforehand so
that we can thank donors properly.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-documentation-and-time">
<h2 id="emacsconf-2024-notes-documentation-and-time">Documentation and time</h2>
<div id="text-emacsconf-2024-notes-documentation-and-time">
<p>
I think my biggest challenge was having less time
to prepare for EmacsConf this year because the
kiddo wanted more of my attention. In many ways,
the automation that I'd been gradually building up
paid off. We were able to pull together EmacsConf
even though I had limited focus time.
</p>

<p>
Here's my Emacs-related time data (including Emacs
News and tweaking my config):
</p>

<table>


<colgroup>
<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Year</th>
<th scope="col">Jan</th>
<th scope="col">Feb</th>
<th scope="col">March</th>
<th scope="col">April</th>
<th scope="col">May</th>
<th scope="col">June</th>
<th scope="col">July</th>
<th scope="col">Aug</th>
<th scope="col">Sept</th>
<th scope="col">Oct</th>
<th scope="col">Nov</th>
<th scope="col">Dec</th>
<th scope="col">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>23.4</td>
<td>15.9</td>
<td>16.2</td>
<td>11.2</td>
<td>4.4</td>
<td>11.5</td>
<td>6.5</td>
<td>13.3</td>
<td>36.6</td>
<td>86.6</td>
<td>93.2</td>
<td>113.0</td>
<td>432</td>
</tr>

<tr>
<td>2024</td>
<td>71.2</td>
<td>12.0</td>
<td>5.6</td>
<td>6.6</td>
<td>3.3</td>
<td>9.6</td>
<td>11.0</td>
<td>4.7</td>
<td>36.0</td>
<td>40.3</td>
<td>52.3</td>
<td>67.7</td>
<td>320</td>
</tr>
</tbody>
</table>

<p>
(and here's a <a href="https://sachachua.com/blog/2023/12/analyzing-my-emacs-time-over-the-last-11-years-or-so/">longer-term analysis going back to 2012</a>.)
</p>

<p>
I spent 92.6 hours total in October and November
2024 doing Emacs-related things, compared to 179.8
hours the previous year – so, around half the
time. Part of the 2023 total was related to
preparing my presentation for EmacsConf, so I was
much more familiar with my scripts then.
Apparently, there was still a lot more that I
needed to document. As I scrambled to get
EmacsConf sorted out, I captured quick tasks/notes
for the things I need to add to our organizers
notebook. Now I get to go through all those notes
in my inbox. Maybe next year will be even
smoother.
</p>

<p>
On the plus side, all the process-related
improvements meant that the other volunteers could
jump in pretty much whenever they wanted,
including during the conference itself. I didn't
want to impose firm commitments on people or bug
them too much by e-mail, so we kept things very
chill in terms of scheduling and planning. If
people were available, we had stuff people could
help with. If people were busy, that was fine, we
could manage. This was nice, especially when I
applied the same sort of chill approach to myself.
</p>

<p>
I'd like to eventually get to the point of being
able to mostly follow my checklists and notes from
the start of the conference planning process to
the end. I've been moving notes from year-specific
organizer notebooks to the main <a href="https://emacsconf.org/organizers-notebook/">organizers'
notebook</a>. I plan to keep that one as the main file
for notes and processes, and then to have specific
dates and notes in the yearly ones.
</p>
</div>
</div>
<div id="outline-container-orgf96c4c3">
<h2 id="orgf96c4c3">Thanks</h2>
<div id="text-orgf96c4c3">
<ul>
<li>Thank you to all the speakers, volunteers, and participants, and to all those other people in our lives who make it possible through time and support.</li>
<li>Thanks to Leo Vivier and Corwin Brust for hosting the sessions, and to FlowyCoder for checking people in.</li>
<li>Thanks to our proposal review volunteers James Howell, JC Helary, and others for helping with the early acceptance process.</li>
<li>Thanks to our captioning volunteers: Mark Lewin, Rodrigo Morales, Anush, annona, and James Howell, and some speakers who captioned their own talks.</li>
<li>Thanks to Leo Vivier for fiddling with the audio to get things nicely synced.</li>
<li>Thanks to volunteers who kept the mailing lists free from spam.</li>
<li>Thanks to Bhavin Gandhi, Christopher Howard, Joseph Turner, and screwlisp for quality-checking.</li>
<li>Thanks to shoshin for the music.</li>
<li>Thanks to Amin Bandali for help with infrastructure and communication.</li>
<li>Thanks to Ry P for the server that we're using for OBS streaming and for processing videos.</li>
<li>Thanks to the Free Software Foundation for Emacs itself, the mailing lists, the media.emacsconf.org server, and handling donations on our behalf through the FSF Working Together program. <a href="https://www.fsf.org/working-together/fund">https://www.fsf.org/working-together/fund</a></li>
<li>Thanks to the many users and contributers and project teams that create all the awesome free software we use, especially: BigBlueButton, Etherpad, Icecast, OBS, TheLounge, libera.chat, ffmpeg, OpenAI Whisper, WhisperX, the aeneas forced alignment tool, PsiTransfer, subed, and many, many other tools and services we used to prepare and host this years conference</li>
<li>Thanks to everyone!</li>
</ul>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-overall">
<h2 id="emacsconf-2024-notes-overall">Overall</h2>
<div id="text-emacsconf-2024-notes-overall">
<p>
Good experience. Lots of fun. I'd love to do it
again next year. EmacsConf feels like a nice, cozy
get-together where people share the cool things
they've been working on and thinking about. People had fun!
They said:
</p>

<ul>
<li>"emacsconf is absolutely knocking it out of the park when it comes to conference logistics"</li>
<li>"I think this conference has defined the terms for a successful online conference."</li>
<li>"EmacsConf is one of the big highlights of my year every year. Thank you a ton for running this 😊"</li>
</ul>

<p>
It's one of the highlights of my year too. =) Looking forward to the next one!
</p>

<p>
In the meantime, y'all can stay connected via <a href="https://sachachua.com/blog/category/emacs-news/">Emacs News</a>, <a href="https://emacs-berlin.org/">meetups (online and in person)</a>, <a href="https://planet.emacslife.com/">Planet Emacslife</a>, and now <a href="https://emacs.tv/">emacs.tv</a>. Enjoy!
</p>

<p>
p.s. I'd love to learn from other people's conference blog posts, EmacsConf or otherwise. I'm particularly interested in virtual conferences and how we can tinker with them to make them even better. I'm having a hard time finding posts; please feel free to send me links to ones you've liked or written!</p>
</div>
</div>

</div>

</article><nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So You Want to Write Java in Neovim (120 pts)]]></title>
            <link>https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</link>
            <guid>42530991</guid>
            <pubDate>Sat, 28 Dec 2024 13:41:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/">https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</a>, See on <a href="https://news.ycombinator.com/item?id=42530991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
        

        

        <section>
            <p>Note: I plan on keeping this post updated if I need to add more content or change something</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-test.png" alt="alt text"></p>
<p>I have been doing Java in Neovim for quite a while at work, and it’s been a very pleasant experience. As Neovim usage grows (especially amongst the younger crowd), I want to share how I do it.</p>
<p>I think historically it's been considered a painful experience, but with guidance, it can be very straightforward!</p>
<p>I’ll preface this by saying that if Neovim isn’t your primary editor, you should first try an IDE specifically for Java (they should all have a Vim plugin):</p>
<ul>
<li>Eclipse</li>
<li>IntelliJ</li>
<li>Apache Netbeans</li>
</ul>
<p>If Neovim is your primary editor, you probably hate opening *insert IDE that turns you into snail* for a specific language, and so did I.</p>
<h2 id="lsp">LSP</h2>
<p>Java has one LSP option for Neovim, and that’s JDTLS (Java Development Tools Language Server) by Eclipse. You should read the project README for a high-level overview on it (including features): <a href="https://github.com/eclipse-jdtls/eclipse.jdt.ls">JDTLS GitHub</a></p>
<p>It’s a great LSP for Java, and I think it’s all you need to work with Java projects. My personal workflow usually involves one tmux window with a project open and another window handling the compiling, testing etc</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-k.png" alt="alt text"></p>
<p>To use JDTLS in Neovim, there are two plugins you can choose from, and which you decide on depends on your preferences.</p>
<h2 id="you-use-a-distro">YOU USE A DISTRO</h2>
<p>If you're happy accepting out-of-the-box, all-in-one setups, then <a href="https://github.com/nvim-java/nvim-java">nvim-java</a> might be for you.
It attempts to be a comprehensive solution with popular defaults, and be hassle-free when it comes to LSP, debugging, testing setups.
It’s not completely flexible, so if you need more control, you should try the next option.</p>
<h2 id="you-read-the-friendly-manual">YOU READ THE FRIENDLY MANUAL</h2>
<p>I expect the majority to fit here, and <a href="https://github.com/mfussenegger/nvim-jdtls">nvim-jdtls</a> is the go-to Java plugin for LSP support in Neovim. You have full access to configure JDTLS, and I highly recommend reading through the available options.</p>
<p>Just remember to install <strong>JDTLS</strong> via <strong>Mason</strong>.</p>
<p>Sometimes you will need to provide a reference JAR that the LSP can hook into loading. I downloaded a Lombok JAR and added it at the JDTLS install path (you will see this in my nvim-jdtls config below), and I at least know this had to be done for Playwright under 'referencedLibraries'.</p>
<h2 id="debugging">DEBUGGING</h2>
<p>Debugging can be done inside Neovim, but again, keep in mind that you <em>may</em> have a better experience in a Java-focused IDE.</p>
<p>I recommend installing <a href="https://github.com/mfussenegger/nvim-dap">nvim-dap</a> and <a href="https://github.com/rcarriga/nvim-dap-ui">nvim-dap-ui</a>.</p>
<p>You will need to install <a href="https://github.com/microsoft/java-debug">java-debug-adapter</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-dap.png" alt="alt text"></p>
<h2 id="testing">TESTING</h2>
<p>Working with tests inside Neovim is also possible, follows a similar setup to the above.</p>
<p>You will need to install <a href="https://github.com/microsoft/vscode-java-test">java-test</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<h2 id="my-setup">MY SETUP</h2>
<p>I will show what I have as a point of reference:</p>
<p>I imagine you are also using treesitter, lspzero etc.</p>
<p><strong>JDTLS</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>java_cmds </span><span>= </span><span>vim</span><span>.api.</span><span>nvim_create_augroup</span><span>('</span><span>java_cmds</span><span>', { </span><span>clear </span><span>= </span><span>true </span><span>})
</span><span>local </span><span>cache_vars </span><span>= {}
</span><span>
</span><span>local </span><span>root_files </span><span>= {
</span><span>    '</span><span>.git</span><span>',
</span><span>    '</span><span>mvnw</span><span>',
</span><span>    '</span><span>gradlew</span><span>',
</span><span>    '</span><span>pom.xml</span><span>',
</span><span>    '</span><span>build.gradle</span><span>',
</span><span>    '</span><span>build.sbt</span><span>'
</span><span>}
</span><span>
</span><span>local </span><span>features </span><span>= {
</span><span>    </span><span>-- change this to `true` to enable codelens
</span><span>    </span><span>codelens </span><span>= </span><span>true</span><span>,
</span><span>
</span><span>    </span><span>-- change this to `true` if you have `nvim-dap`,
</span><span>    </span><span>-- `java-test` and `java-debug-adapter` installed
</span><span>    </span><span>debugger </span><span>= </span><span>true</span><span>,
</span><span>}
</span><span>
</span><span>local function </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>if </span><span>cache_vars</span><span>.paths </span><span>then
</span><span>        </span><span>return </span><span>cache_vars</span><span>.paths
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= {}
</span><span>
</span><span>    </span><span>path</span><span>.data_dir = </span><span>vim</span><span>.fn.</span><span>stdpath</span><span>('</span><span>cache</span><span>') .. '</span><span>/nvim-jdtls</span><span>'
</span><span>
</span><span>    </span><span>local </span><span>jdtls_install </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>jdtls</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>path</span><span>.java_agent = </span><span>jdtls_install </span><span>.. '</span><span>/lombok.jar</span><span>'
</span><span>    </span><span>path</span><span>.launcher_jar = </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>jdtls_install </span><span>.. '</span><span>/plugins/org.eclipse.equinox.launcher_*.jar</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>mac</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_mac</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>unix</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_linux</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>win32</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_win</span><span>'
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>path</span><span>.bundles = {}
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-test bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_test_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-test</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_test_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_test_path </span><span>.. '</span><span>/extension/server/*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_test_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_test_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-debug-adapter bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_debug_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-debug-adapter</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_debug_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_debug_path </span><span>.. '</span><span>/extension/server/com.microsoft.java.debug.plugin-*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_debug_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_debug_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Useful if you're starting jdtls with a Java version that's
</span><span>    </span><span>-- different from the one the project uses.
</span><span>    </span><span>---
</span><span>    </span><span>path</span><span>.runtimes = {
</span><span>        </span><span>-- Note: the field `name` must be a valid `ExecutionEnvironment`,
</span><span>        </span><span>-- you can find the list here:
</span><span>        </span><span>-- https://github.com/eclipse/eclipse.jdt.ls/wiki/Running-the-JAVA-LS-server-from-the-command-line#initialize-request
</span><span>        </span><span>--
</span><span>        </span><span>-- This example assume you are using sdkman: https://sdkman.io
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-21</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/21.0.2-tem</span><span>'),
</span><span>        },
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-23</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/23-tem</span><span>'),
</span><span>        }
</span><span>
</span><span>    }
</span><span>
</span><span>    </span><span>cache_vars</span><span>.paths = </span><span>path
</span><span>
</span><span>    </span><span>return </span><span>path
</span><span>end
</span><span>
</span><span>local function </span><span>enable_codelens</span><span>(bufnr)
</span><span>    </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>
</span><span>    </span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>BufWritePost</span><span>', {
</span><span>        </span><span>buffer </span><span>= </span><span>bufnr</span><span>,
</span><span>        </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>        </span><span>desc </span><span>= '</span><span>refresh codelens</span><span>',
</span><span>        </span><span>callback </span><span>= </span><span>function</span><span>()
</span><span>            </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>        </span><span>end</span><span>,
</span><span>    })
</span><span>end
</span><span>
</span><span>local function </span><span>enable_debugger</span><span>(bufnr)
</span><span>    </span><span>require</span><span>('</span><span>jdtls</span><span>').</span><span>setup_dap</span><span>({ </span><span>hotcodereplace </span><span>= '</span><span>auto</span><span>' })
</span><span>    </span><span>require</span><span>('</span><span>jdtls.dap</span><span>').</span><span>setup_dap_main_class_configs</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;df</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_class()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;dn</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_nearest_method()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_on_attach</span><span>(client, bufnr)
</span><span>    </span><span>--vim.lsp.inlay_hint(bufnr, true)
</span><span>    </span><span>if </span><span>features</span><span>.debugger </span><span>then
</span><span>        </span><span>enable_debugger</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>if </span><span>features</span><span>.codelens </span><span>then
</span><span>        </span><span>enable_codelens</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The following mappings are based on the suggested usage of nvim-jdtls
</span><span>    </span><span>-- https://github.com/mfussenegger/nvim-jdtls#usage
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;A-o&gt;</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').organize_imports()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_variable()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_variable(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_constant()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_constant(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crm</span><span>', "</span><span>&lt;esc&gt;&lt;Cmd&gt;lua require('jdtls').extract_method(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;pjp</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').javap()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_setup</span><span>(event)
</span><span>    </span><span>local </span><span>jdtls </span><span>= </span><span>require</span><span>('</span><span>jdtls</span><span>')
</span><span>    </span><span>local </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities;
</span><span>    </span><span>extendedClientCapabilities</span><span>.onCompletionItemSelectedCommand = "</span><span>editor.action.triggerParameterHints</span><span>"
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>local </span><span>data_dir </span><span>= </span><span>path</span><span>.data_dir .. '</span><span>/</span><span>' .. </span><span>vim</span><span>.fn.</span><span>fnamemodify</span><span>(</span><span>vim</span><span>.fn.</span><span>getcwd</span><span>(), '</span><span>:p:h:t</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>cache_vars</span><span>.capabilities == </span><span>nil </span><span>then
</span><span>        </span><span>jdtls</span><span>.extendedClientCapabilities.resolveAdditionalTextEditsSupport = </span><span>true
</span><span>
</span><span>        </span><span>local </span><span>ok_cmp</span><span>, </span><span>cmp_lsp </span><span>= </span><span>pcall</span><span>(</span><span>require</span><span>, '</span><span>cmp_nvim_lsp</span><span>')
</span><span>        </span><span>cache_vars</span><span>.capabilities = </span><span>vim</span><span>.</span><span>tbl_deep_extend</span><span>(
</span><span>            '</span><span>force</span><span>',
</span><span>            </span><span>vim</span><span>.lsp.protocol.</span><span>make_client_capabilities</span><span>(),
</span><span>            </span><span>ok_cmp </span><span>and </span><span>cmp_lsp</span><span>.</span><span>default_capabilities</span><span>() or {}
</span><span>        )
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The command that starts the language server
</span><span>    </span><span>-- See: https://github.com/eclipse/eclipse.jdt.ls#running-from-the-command-line
</span><span>    </span><span>local </span><span>cmd </span><span>= {
</span><span>        '</span><span>java</span><span>',
</span><span>
</span><span>        '</span><span>-Declipse.application=org.eclipse.jdt.ls.core.id1</span><span>',
</span><span>        '</span><span>-Dosgi.bundles.defaultStartLevel=4</span><span>',
</span><span>        '</span><span>-Declipse.product=org.eclipse.jdt.ls.core.product</span><span>',
</span><span>        '</span><span>-Dlog.protocol=true</span><span>',
</span><span>        '</span><span>-Dlog.level=ALL</span><span>',
</span><span>        '</span><span>-javaagent:</span><span>' .. </span><span>path</span><span>.java_agent,
</span><span>        '</span><span>-Xms1g</span><span>',
</span><span>        '</span><span>--add-modules=ALL-SYSTEM</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.util=ALL-UNNAMED</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.lang=ALL-UNNAMED</span><span>',
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-jar</span><span>',
</span><span>        </span><span>path</span><span>.launcher_jar,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-configuration</span><span>',
</span><span>        </span><span>path</span><span>.platform_config,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-data</span><span>',
</span><span>        </span><span>data_dir</span><span>,
</span><span>    }
</span><span>
</span><span>    </span><span>local </span><span>lsp_settings </span><span>= {
</span><span>        </span><span>java </span><span>= {
</span><span>            </span><span>-- jdt = {
</span><span>            </span><span>--   ls = {
</span><span>            </span><span>--     vmargs = "-XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xmx1G -Xms100m"
</span><span>            </span><span>--   }
</span><span>            </span><span>-- },
</span><span>            </span><span>project </span><span>= {
</span><span>                </span><span>referencedLibraries </span><span>= {
</span><span>                    </span><span>-- add any library jars here for the lsp to pick them up
</span><span>                },
</span><span>            },
</span><span>            </span><span>eclipse </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>configuration </span><span>= {
</span><span>                </span><span>updateBuildConfiguration </span><span>= '</span><span>interactive</span><span>',
</span><span>                </span><span>runtimes </span><span>= </span><span>path</span><span>.runtimes,
</span><span>            },
</span><span>            </span><span>maven </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>implementationsCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>referencesCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>references </span><span>= {
</span><span>                </span><span>includeDecompiledSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>inlayHints </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>--parameterNames = {
</span><span>                </span><span>--   enabled = 'all' -- literals, all, none
</span><span>                </span><span>--}
</span><span>            },
</span><span>            </span><span>format </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>-- settings = {
</span><span>                </span><span>--   profile = 'asdf'
</span><span>                </span><span>-- },
</span><span>            }
</span><span>        },
</span><span>        </span><span>signatureHelp </span><span>= {
</span><span>            </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>completion </span><span>= {
</span><span>            </span><span>favoriteStaticMembers </span><span>= {
</span><span>                '</span><span>org.hamcrest.MatcherAssert.assertThat</span><span>',
</span><span>                '</span><span>org.hamcrest.Matchers.*</span><span>',
</span><span>                '</span><span>org.hamcrest.CoreMatchers.*</span><span>',
</span><span>                '</span><span>org.junit.jupiter.api.Assertions.*</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNull</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNullElse</span><span>',
</span><span>                '</span><span>org.mockito.Mockito.*</span><span>',
</span><span>            },
</span><span>        },
</span><span>        </span><span>contentProvider </span><span>= {
</span><span>            </span><span>preferred </span><span>= '</span><span>fernflower</span><span>',
</span><span>        },
</span><span>        </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities,
</span><span>        </span><span>sources </span><span>= {
</span><span>            </span><span>organizeImports </span><span>= {
</span><span>                </span><span>starThreshold </span><span>= </span><span>9999</span><span>,
</span><span>                </span><span>staticStarThreshold </span><span>= </span><span>9999</span><span>,
</span><span>            }
</span><span>        },
</span><span>        </span><span>codeGeneration </span><span>= {
</span><span>            </span><span>toString </span><span>= {
</span><span>                </span><span>template </span><span>= '</span><span>${object.className}{${member.name()}=${member.value}, ${otherMembers}}</span><span>',
</span><span>            },
</span><span>            </span><span>useBlocks </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>    }
</span><span>
</span><span>    </span><span>-- This starts a new client &amp; server,
</span><span>    </span><span>-- or attaches to an existing client &amp; server depending on the `root_dir`.
</span><span>    </span><span>jdtls</span><span>.</span><span>start_or_attach</span><span>({
</span><span>        </span><span>cmd </span><span>= </span><span>cmd</span><span>,
</span><span>        </span><span>settings </span><span>= </span><span>lsp_settings</span><span>,
</span><span>        </span><span>on_attach </span><span>= </span><span>jdtls_on_attach</span><span>,
</span><span>        </span><span>capabilities </span><span>= </span><span>cache_vars</span><span>.capabilities,
</span><span>        </span><span>root_dir </span><span>= </span><span>jdtls</span><span>.setup.</span><span>find_root</span><span>(</span><span>root_files</span><span>),
</span><span>        </span><span>flags </span><span>= {
</span><span>            </span><span>allow_incremental_sync </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>init_options </span><span>= {
</span><span>            </span><span>bundles </span><span>= </span><span>path</span><span>.bundles,
</span><span>            </span><span>extendedClientCapabilities </span><span>= </span><span>extendedClientCapabilities</span><span>,
</span><span>        },
</span><span>    })
</span><span>end
</span><span>
</span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>FileType</span><span>', {
</span><span>    </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>    </span><span>pattern </span><span>= { '</span><span>java</span><span>' },
</span><span>    </span><span>desc </span><span>= '</span><span>Setup jdtls</span><span>',
</span><span>    </span><span>callback </span><span>= </span><span>jdtls_setup</span><span>,
</span><span>})
</span></code></pre>
<p><strong>DAP</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>dap </span><span>= </span><span>require</span><span>('</span><span>dap</span><span>')
</span><span>
</span><span>dap</span><span>.configurations.java = {
</span><span>    {
</span><span>        </span><span>type </span><span>= '</span><span>java</span><span>',
</span><span>        </span><span>request </span><span>= '</span><span>launch</span><span>',
</span><span>        </span><span>name </span><span>= '</span><span>Launch Java Program</span><span>'
</span><span>    },
</span><span>}
</span><span>
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapBreakpoint</span><span>',
</span><span>    {
</span><span>        </span><span>text </span><span>= '</span><span>🔴</span><span>',
</span><span>        </span><span>texthl </span><span>= '</span><span>DapBreakpointSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>DapBreakpoint</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapStopped</span><span>',
</span><span>    {
</span><span>        </span><span>texthl </span><span>= '</span><span>DapStoppedSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>CursorLine</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F5&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>continue</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F10&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_over</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F11&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_into</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F12&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_out</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;b</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>toggle_breakpoint</span><span>() </span><span>end</span><span>)
</span><span>
</span><span>local </span><span>dapui </span><span>= </span><span>require</span><span>('</span><span>dapui</span><span>')
</span><span>dapui</span><span>.</span><span>setup</span><span>()
</span><span>
</span><span>dap</span><span>.listeners.before.attach.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.launch.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_terminated.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_exited.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;du</span><span>', </span><span>function</span><span>() </span><span>dapui</span><span>.</span><span>toggle</span><span>() </span><span>end</span><span>)
</span><span>
</span></code></pre>
<p>I hope this helps you get started working with Java in Neovim!</p>

        </section>

        

    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify Shuts Down ‘Unwrapped’ Artist Royalty Calculator with Legal Threats (178 pts)]]></title>
            <link>https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/</link>
            <guid>42530410</guid>
            <pubDate>Sat, 28 Dec 2024 12:00:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/">https://www.digitalmusicnews.com/2024/12/23/billionaire-daniel-ek-shuts-down-spotify-unwrapped-calculator/</a>, See on <a href="https://news.ycombinator.com/item?id=42530410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cb-outer-container" role="main"><article id="post-310901" role="article"><section itemprop="articleBody"><div id="attachment_310904"><p><img decoding="async" aria-describedby="caption-attachment-310904" src="https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-1024x576.png" alt="Spotify Unwrapped calculator" width="750" height="422" srcset="https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-1024x576.png 1024w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-300x169.png 300w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-65x37.png 65w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down-768x432.png 768w, https://www.digitalmusicnews.com/wp-content/uploads/2024/12/spotify-unwrapped-site-shut-down.png 1200w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-310904">Photo Credit: Spotify Unwrapped</p></div><h2>Spotify CEO Daniel Ek has been busy selling stock this year, becoming a multi-billionaire worth around $7.3 billion according to Forbes. Now, the calculator for showcasing how relatively little Spotify pays to artists — and the absurd contrast to top-level Spotify executive compensation — has been shut down due to the threat of legal action.</h2><p>Digital Music News reported on the existence of <a href="https://www.digitalmusicnews.com/2024/12/04/spotify-unwrapped-how-much-did-you-pay-your-favorite-artist/" data-wpel-link="internal" rel="follow">Spotify Unwrapped</a> this year as a calculator to show music lovers how little artists are paid from streaming services. Plugging in the data generated by Spotify Wrapped was relatively straight forward; now the calculator is gone with a message in its place.</p><p>“This site used to be a parody of Spotify Wrapped that called the company out for its predatory treatment of artists,” the message begins. “It has been removed at the request of Spotify’s legal team. You can still join our fight for Justice at Spotify at the United musicians and Allied Workers <a href="https://www.unionofmusicians.org/justice-at-spotify" data-wpel-link="external" rel="nofollow external noopener noreferrer">(UMAW) website</a>.”</p><h4>Despite the shutdown, the site still includes the formula behind the calculator for artists and music lovers who are curious. “Artists can multiply their Spotify Wrapped <a href="https://www.digitalmusicnews.com/2023/12/28/how-much-does-spotify-pay-per-stream/" data-wpel-link="internal" rel="follow">total streams by $0.003 to calculate royalties</a> Spotify paid out for music. If you have a label and/or bandmates that share these earnings, you might also want to divide that total appropriately.”</h4><p>Spotify is a money-maker for investors, with the stock popping off this year and reaching nearly $500 per share. Daniel Ek took advantage of the high tide and sold around $350 million in shares according to U.S. Securities and Exchange Commission (SEC) filings. Stock sales accelerated in the month of December with around 20 Spotify insiders dumping stock at its new highs.</p><p>Those new heights were achieved after massive cost-cutting measures last year, including a 25% reduction of the workforce in 2023. Spotify also <a href="https://www.digitalmusicnews.com/2024/06/05/spotify-price-hike-consumer-comments-2024/" data-wpel-link="internal" rel="follow">increased the price of its Spotify Premium subscription</a> across several markets in 2023. The stock sell-off among Spotify insiders has reached $1.25 billion in 2024 alone.</p><h4>How Much Stock Did Spotify Insiders Sell This Year?</h4><ol><li><ol><li><strong>Daniel Ek</strong>, CEO — $350 million</li><li><strong>Martin Lorentzon</strong>, Co-Founder — $550 million</li><li><strong>Gustav Söderström</strong>, Chief Product &amp; Technology Officer — $106 million</li><li><strong>Katarina Berg</strong>, Chief Human Resources Officer — $38 million</li><li><strong>Alex Norström</strong>, Chief Business Officer — $63 million</li><li><strong>Dustee Jenkins</strong>, Head of Public Relations — $6 million</li></ol></li></ol><p><a href="https://www.digitalmusicnews.com/2024/12/10/spotify-stock-cooldown-december-2024/" data-wpel-link="internal" rel="follow">SPOT stock value nearly tripped in 2024</a> and the company is approaching a $100 billion market capitalization. The stock sell-offs by executives accelerated throughout November and December and it comes as music fans were left groaning about the poor state of Spotify Wrapped this year.</p><!-- END .ss-inline-share-wrapper --></section> <!-- end article section --> <!-- end article footer --> <!-- Feature FM	--> <!--<div><center><div id='div-gpt-ad-1505443152192-0' style='height:1px; width:1px;'> <script> googletag.cmd.push(function() { googletag.display('div-gpt-ad-1505443152192-0'); }); </script></div></center></div> --><!-- #respond --></article> <!-- end article --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Where can you go in Europe by train in 8h? (348 pts)]]></title>
            <link>https://www.chronotrains.com/en</link>
            <guid>42530332</guid>
            <pubDate>Sat, 28 Dec 2024 11:43:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chronotrains.com/en">https://www.chronotrains.com/en</a>, See on <a href="https://news.ycombinator.com/item?id=42530332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Where can you go by train in 8h?</h2><p>This map shows you how far you can travel from each station in Europe in less than 8 hours.</p><p>Hover your mouse on the map to see the isochrones from that city, search for a station, or click on one of the examples below.</p></div><div><h2>Discover the Best European Train Routes</h2><p>Traveling by train in Europe offers a blend of speed, convenience, and scenic beauty. Whether you're planning a quick getaway or an extended tour, our interactive map helps you find the best destinations reachable with any time budget around any city in Europe.</p><h3>Why Choose Train Travel in Europe?</h3><p>Efficiency: High-speed trains connect major cities, reducing travel time significantly compared to other modes of transportation.</p><p>Comfort: Enjoy spacious seating, onboard amenities, and the ability to move freely during your journey.</p><p>Sustainability: Trains are an eco-friendly alternative, helping reduce your carbon footprint.</p><h3>FAQs</h3><div><p><strong>Q: How accurate are the travel times on the map?</strong></p><p>A: The map is based on estimated travel times from Deutsche Bahn data, but actual times may vary. Always check the latest schedules before traveling.</p></div><div><p><strong>Q: Can I use this map for planning multi-city trips?</strong></p><p>A: Yes, the map is a great tool for planning extended itineraries, allowing you to explore multiple cities efficiently.</p></div><div><p><strong>Q: Are there any discounts available for railway tickets in Europe?</strong></p><p>A: Many rail services offer discounts for early bookings, youth travelers, and frequent travelers. Check the respective rail service websites for the latest deals. You can access the main train ticket providers from Chronotrains directly.</p></div></div><p>This map is based on estimated travel times, using data from the <a href="https://www.bahn.de/" target="_blank" rel="noopener noreferrer">Deutsche Bahn</a> through <a href="https://direkt.bahn.guru/" target="_blank" rel="noopener noreferrer">Direkt Bahn Guru</a>. Actual timetables may vary.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chess: Magnus Carlsen disqualified in N.Y. after refusing to change out of jeans (103 pts)]]></title>
            <link>https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend</link>
            <guid>42530237</guid>
            <pubDate>Sat, 28 Dec 2024 11:18:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend">https://www.theguardian.com/sport/2024/dec/27/chess-carlsen-targets-rapid-and-blitz-gold-on-wall-street-this-weekend</a>, See on <a href="https://news.ycombinator.com/item?id=42530237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Magnus Carlsen, the world No 1, has been disqualified from the World Rapid Championship in New York due to a dress code violation, refusing to change from jeans, after a previous warning. He is also withdrawing from the World Blitz which starts on 30 December.</p><p>Fide (the World Chess Federation) explained its decision <a href="https://www.fide.com/news/3363" data-link-name="in body link">in a statement</a> while Carlsen said: “I said I’ll change tomorrow … but they said you have to change now it became a matter of principle for me so here we are! Honestly I’m too old at this point to care too much. If this is what they want to do I’ll probably set off to somewhere where the weather is a bit nicer.”</p><p>At the time of his default, Carlsen had scored 5/8 and was a point and a half behind the leaders, with little chance of retaining his title.</p><p>After eight of the 13 rounds, Jan-Krzysztof Duda (Poland), Arjun Erigaisi (India) and Alexander Grischuk (Russia) <a href="https://chess-results.com/tnr1074690.aspx?lan=1&amp;art=1&amp;rd=5&amp;flag=30include" data-link-name="in body link">led on 6.5/8</a>. Nine players on 6/8 include Russia’s 18-year-old Volodar Murzin, who <a href="https://lichess.org/broadcast/fide-world-rapid--blitz-championships-2024--rapid-open-1-30/round-2/RZi09iMn/Z6ggMI0K" data-link-name="in body link">beat the No 2 seed</a> and US champion, Fabiano Caruana, and the world No 3 and speed specialist, Hikaru Nakamura.</p><figure id="debf81bb-5011-47b6-a8a7-f87c18f14a3a" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Chess 3952" src="https://i.guim.co.uk/img/media/9f5e7c2390c1e593d0fe02176cf9493d339dac8f/0_0_1127_1126/master/1127.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="444.6051464063886" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span><strong>3952:</strong> Albert Sandrin v Pal Eros, Pula 1972. White to move and win.</span></figcaption></figure><p>The early rounds of the 11-round Women’s World Rapid were a triumph for the <a href="https://www.theguardian.com/sport/2023/jun/23/teenager-alice-lee-sets-new-landmark-for-us-womens-chess-after-online-feats" data-link-name="in body link">rising US star Alice Lee</a>, 15, who won all her four games and was the sole leader. However Lee, who burst into prominence last year, lost to the top seed and reigning world women’s champion, China’s Ju Wenjun, in a crucial fifth-round pairing.</p><p>After six of the 11 rounds Ju had 5.5/6, half a point ahead of Alexandra Kosteniuk (Switzerland) and Kateryna Lagno (Russia), with Lee in the chasing group on 4.5/6.</p><p>The field of 182 for the World Rapid/Blitz <a href="https://chess-results.com/tnr1074690.aspx?lan=1" data-link-name="in body link">includes 30 Americans</a> while China has the top three seeds in the Women’s World Rapid/Blitz, which has 113 entries. The total prize fund is $1m for the open Rapid and Blitz, with $428,500 for the two women’s events.</p><p>This is the first time that the popular speed world championships have been staged on American soil, let alone at the centre of international finance. Rapid is defined as 15 minutes per player per game, plus an increment of 10 seconds a move from move one, while Blitz is three minutes per player per game, plus a two seconds per move increment.</p><p>Carlsen has already won five world rapids and seven world blitzes in his illustrious career, and captured both titles in 2022 and 2023. The <a href="https://x.com/chesscom/status/1870558410925818264" data-link-name="in body link">list of his lifetime victories</a> is impressively long, and underlines the task ahead for the new classical world champion, Gukesh Dommaraju, as the Indian 18-year-old, who is not competing in New York, aims to match the Norwegian’s achievements.</p><p>Carlsen’s chess curriculum vitae lists 64 major titles, all but nine of them over the board. Gukesh so far has just six – one world championship, one Candidates, three Olympiad golds, and one Fide Circuit, albeit with a 16-year age advantage.</p><p>Rapid is now Carlsen’s favourite format, and he scored again in last week’s Champions Tour, where most events were held online while the eight-player final pool was staged across the board in Oslo.</p><p>It ended up with a final between Carlsen and his old rival Ian Nepomniachtchi, whom he defeated in their 2021 world title match, where their <a href="https://www.chessgames.com/perl/chessgame?gid=2127373" data-link-name="in body link">136-move sixth game</a> was the longest in world championship history. This time there was a much faster outcome, as Carlsen won 4-1 including a <a href="https://www.chessgames.com/perl/chessgame?gid=2813014" data-link-name="in body link">23-move crush</a> in the final game.</p><p>Carlsen is always alert to new developments, and his 7 a3 repeated Gukesh’s novelty against Ding Liren from game 13 of the Fide world title match in Singapore, a drawn encounter where the teenager overlooked a win.</p><p>Nepomniachtchi varied from Ding by early castling, but he missed the power of the rook lift 17 Rh3! This is an ancient and strong strategy against the French, which I recall the shock of experiencing as Black at London 1948 against Oliver Penrose. Here, White’s attack on the king quickly proved the irrelevance of the Russian queen excursion on the opposite flank, and Carlsen’s final 23 Qg6! created the unanswerable threat of Ng5 and Qh7 mate.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-15">skip past newsletter promotion</a><p id="EmailSignup-skip-link-15" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><figure id="0e11f979-ce42-448a-9ad0-e54b99f83a09" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:16,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Chess: Gukesh and India celebrate after win but new challenges are emerging&quot;,&quot;elementId&quot;:&quot;0e11f979-ce42-448a-9ad0-e54b99f83a09&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/sport/2024/dec/20/chess-gukesh-and-india-celebrate-after-win-but-new-challenges-are-emerging&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:2}}"></gu-island></figure><p>The World Rapid started on Thursday, and continues at 7pm GMT on Friday and Saturday. You can watch free, with grandmaster and computer commentary and assessments, on <a href="https://lichess.org/broadcast/fide-world-rapid--blitz-championships-2024--rapid-open/round-1/kTmtGlGP#boards" data-link-name="in body link">lichess.org</a> and other major chess sites.</p><p>In between the three-day, 13-round Rapid on 26-28 December and the two-day Blitz on 30-31 December, Fide has organised the Wall Street Gambit, a conference to explore the fusion between chess and finance.</p><p>Its highlight will be a keynote address by the renowned economist and GM Kenneth Rogoff, who will speak on chess, AI, and economics. Caruana and India’s former world champion Vishy Anand will be present. Standard <a href="https://tickets.fide.com/events/fide/1478195" data-link-name="in body link">tickets cost $1,000</a>, while VIP tickets at $5,000, which include a blitz game and selfies with Caruana, are already sold out.</p><p>No UK players have travelled to the World Rapid/Blitz due to the high cost and the low chances of a prize. For England’s experts, the annual £10,000 <a href="https://chess-results.com/tnr1088363.aspx?lan=1from" data-link-name="in body link">Caplin Hastings Masters</a> from 28 December to 5 January is the event of the moment. More than 100 entries range from at least seven 2500+ grandmasters to a long tail where over half the field are rated below 2000.</p><p>England’s youngest-ever GM, 15-year-old Shreyas Royal, is the top home seed, while a likely candidate for an international title is 21-year-old FM Alex Golding, who already has two IM norms and a 2400+ rating and has just won the traditional Richmond pre-Christmas blitz at Orleans Park School from an entry of over 100.</p><p><strong>3952</strong><strong>:</strong> 1 Nh6+ Kf8 2 Nf5! (threat 3 Rh8 mate) g6 3 Qh6+ Kg8 4 Qh7+ Kf8 5 Qh8+! Bxh8 6 Rxh8 mate. Black can sacrifice his bishops and queen at g2 and f2, but this only delays mate.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casual Viewing – Why Netflix looks like that (264 pts)]]></title>
            <link>https://www.nplusonemag.com/issue-49/essays/casual-viewing/</link>
            <guid>42529756</guid>
            <pubDate>Sat, 28 Dec 2024 09:32:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nplusonemag.com/issue-49/essays/casual-viewing/">https://www.nplusonemag.com/issue-49/essays/casual-viewing/</a>, See on <a href="https://news.ycombinator.com/item?id=42529756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>U<span>ntil recently</span></span> no Hollywood studio had ever released two movies with the same name at the same time. At most studios, such a strategy would be unthinkable. Audiences might accidentally buy tickets to the wrong film, and the PR fallout would be disastrous: snipes from trade-magazine writers; angry calls from investors questioning the studios’ business acumen; angrier calls from agents demanding to know why their clients’ images were being intentionally sabotaged.</p><p>Netflix, however, is not most studios. On April Fools’ Day, 2022, the company released a Judd Apatow comedy titled <span><i>The Bubble</i></span>, which takes place on the set of a Hollywood dinosaur franchise that’s forced to quarantine in the middle of the Covid-19 pandemic. Four weeks later, it released an animated film by Tetsurō Araki, director of the popular Japanese anime shows <span><i>Death Note </i></span>and <span><i>Attack on Titan</i></span>, about a postapocalyptic world in which the law of gravity ceases to exist. Araki’s film was called <span><i>Bubble</i></span>.</p><p><span>There were no box office mix-ups, no snipes from the press, no angry calls. The few critics who bothered to write about it panned Apatow’s </span><span><i>Bubble</i></span><span>, an unfunny comedy that’s duller than the blockbuster franchises it makes fun of. Nobody had anything to say about Araki’s </span><span><i>Bubble</i></span><span>, a TV movie better suited to a graveyard slot on a children’s cable network. Like all Netflix movies, </span><span><i>Bubble</i></span><span> and</span><span><i> The Bubble</i></span><span> floated away as quickly as they appeared, becoming tiles in the company’s sprawling mosaic of content, destined to be autoplayed on laptops whose owners have fallen asleep.</span></p><p>For years Ted Sarandos, the Netflix co-CEO who pioneered this distribution strategy, has been hailed by the press as a visionary. Even after the streaming giant faltered in 2022, recording an overall loss of subscribers for the first time in a decade, the podcast impresario Scott Galloway raced to Sarandos’s defense in the <span><i>New York Times</i></span>, comparing him and Netflix cofounder Reed Hastings to “A-Rod and Barry Bonds.” He added, “You don’t want to bet against these guys.” Galloway had apparently forgotten that the two baseball players he named had tested positive for performance-enhancing drugs at the height of their careers. In this way his comparison was more accurate than he intended. Netflix is a steroidal company, pumped up by lies and deceit, and has broken all of Hollywood’s rules.</p><p>For a century, the business of running a Hollywood studio was straightforward. The more people watched films, the more money the studios made. With Netflix, however, audiences don’t pay for individual films. They pay a subscription to watch everything, and this has enabled a strange phenomenon to take root. Netflix’s movies don’t have to abide by any of the norms established over the history of cinema: they don’t have to be profitable, pretty, sexy, intelligent, funny, well-made, or anything else that pulls audiences into theater seats. Netflix’s audiences watch from their homes, on couches, in beds, on public transportation, and on toilets. Often they aren’t even watching.</p><p>Over the past decade, Netflix, which first emerged as a destroyer of video stores, has developed a powerful business model to conquer television, only to unleash its strange and destructive power on the cinema. In doing so, it has brought Hollywood to the brink of irrelevance. Because Netflix doesn’t just survive when no one is watching<span> </span>—<span> </span>it thrives.</p><hr><p><span>A<span>s Reed Hastings</span> tells it,</span> the Netflix eureka moment came in 1997, when he rented a VHS of <span><i>Apollo 13 </i></span>from Blockbuster Video. Some weeks later, he discovered the tape under a pile of papers in his dining room. He had forgotten to return it. When he did return it, Hastings was shocked to learn that he owed $40 in late fees. “I felt so stupid,” he later said of the experience. “I was embarrassed about it.”</p><p><span>Hastings wasn’t alone. In the 1990s, Blockbuster was reviled by its customers. As the journalist Gina Keating found in her 2012 history </span><span><i>Netflixed</i></span><span>, Blockbuster’s own research showed that customers usually had to visit stores for five weekends in a row to get what they wanted. Stores were overstocked with movies no one cared about and employees left empty VHS boxes on shelves, giving the appearance that a store’s inventory was larger than it actually was. Worst of all were the late fees: a late return often tripled the price of a Blockbuster rental, and a lost tape could set you back as much as $200. The system was widely despised</span><span> </span><span>—</span><span> </span><span>customers filed twenty-three separate class-action lawsuits against Blockbuster over unfair late charges</span><span> </span><span>—</span><span> </span><span>but outrageously profitable. In 2000, near the company’s peak, Blockbuster collected nearly $800 million in late fees, accounting for 16 percent of its annual revenue. Internally, company executives described its business model as one of “managed dissatisfaction.”</span></p><blockquote><p><b>Every week Netflix seemed to deliver a new movie no one had ever heard of that somehow broke every viewing record in the world.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Every+week+Netflix+seemed+to+deliver+a+new+movie+no+one+had+ever+heard+of+that+somehow+broke+every+viewing+record+in+the+world.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Every+week+Netflix+seemed+to+deliver+a+new+movie+no+one+had+ever+heard+of+that+somehow+broke+every+viewing+record+in+the+world.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>The year of the <span><i>Apollo 13 </i></span>incident, Hastings sold his software business Pure Atria to another tech company for more than $700 million. His experience at Blockbuster got him thinking. “Was there another model,” he wondered, “to provide the pleasure of watching movies in your own living room without inflicting the pain of paying a lot when you forgot to return them?” Hastings and Marc Randolph, Pure Atria’s chief of product marketing, began to brainstorm a new kind of movie rental business. They had noticed Amazon’s success selling books over the internet. Why not do the same with movies?</p><p>Using $2 million of Hastings’s own money, the duo began testing hundreds of ways to sell and rent DVDs by mail. The model Hastings and Randolph eventually solidified, in 1999, was simple. Netflix would charge customers a fixed monthly fee to rent up to four movies at a time. (This was soon reduced to three.) Customers could keep the discs as long as they wanted<span> </span>—<span> </span>no more late fees<span> </span>—<span> </span>but could only rent new movies after they mailed back the old ones. The open-ended approach was more convenient for customers than Blockbuster’s. But for Hastings and Randolph, customer satisfaction was secondary. The duo was trying to solve a logistical problem.</p><p>Netflix’s DVD catalog was not constrained by the size and shelf space of a brick-and-mortar store. Whereas Blockbuster might have to stock fourteen copies of a “big” title<span> </span>—<span> </span>like Steven Spielberg’s <span><i>A.I.</i></span><span> </span>—<span> </span>at the expense of other options, Netflix could stock <span><i>A.I.</i></span> and Mario Bava’s <span><i>Four Times That Night </i></span>and Richard Lester’s <span><i>The Three Musketeers</i></span>, too. But even with fewer spatial constraints, housing several hundred thousand DVDs in the Netflix warehouse was inefficient. “Reed and I began riffing,” Randolph later explained. “‘It’s kind of a shame that we have all these DVDs sitting here in a warehouse doing no good. I wonder if there was some way to store them in our customers’ houses? Can we let them keep the DVDs? Can they just hold on to them as long as they want?’”</p><p>A decade before Airbnb persuaded homeowners to transform their homes into hotels, Netflix convinced its users to turn theirs into mini Netflix warehouses. Customers who held onto their DVDs for longer meant fewer shipping costs for Netflix, and fewer DVDs for the company to manage and store. Netflix tracked heavy users of its service<span> </span>—<span> </span>labeling them internally as “pigs”<span> </span>—<span> </span>and secretly throttled their deliveries. It didn’t matter if Netflix rented fewer DVDs than Blockbuster, because the company would keep collecting its monthly fee. The difference between Blockbuster and Netflix was this: Blockbuster punished customers for being forgetful; Netflix rewarded them for being mindless.</p><hr><p><span>N<span>etflix grew</span> its business</span> by targeting companies that Americans hated, and the only company that Americans hated more than Blockbuster was their local cable provider. In the early 1990s, cable providers began working with the television networks to push the limits of what they could extort from customers, building on a rich history of viewer-screwing innovations like fees for set-top boxes and annual contracts that were impossible to cancel. Between 1995 and 2005, providers doubled the number of channels in the average cable package and raised prices at three times the rate of inflation. In 2007, FCC chairman Kevin Martin wrote in a letter to advocacy groups that “the average cable subscriber was paying for more than eighty-five channels that she didn’t watch in order to obtain the approximately sixteen channels that she does.” The average cable package cost more than $700 per year.</p><p>Hastings had always wanted to push Netflix toward cable television. Film producer Mynette Louie learned this firsthand in the late ’90s. Before she entered the film industry, Louie worked for a market-research firm that specialized in internet companies. It was the height of the dot-com bubble, and each week different start-up CEOs dropped by Louie’s office to pitch their businesses. She still remembers the day Hastings came in to speak about Netflix. “He said, ‘We’re not in the DVD business. The only reason why we have these DVDs is to scale the customer base for what we ultimately want to do, which is streaming,’” Louie told me in an interview this year.</p><p>Out of all the start-up founders Louie met, Hastings stuck out. “He was so impressive,” she said. “We didn’t know it was going to destroy the film business as we knew it.” During its first decade of operations, Netflix waited patiently for broadband internet speeds to become fast enough to support a streaming platform, draining Blockbuster of its customers and insinuating itself into the homes of millions of Americans in the process. In 2007, the same year Martin wrote his letter, the technology was finally sufficient, and Netflix launched its streaming platform.</p><blockquote><p><b>Blockbuster punished customers for being forgetful; Netflix rewarded them for being mindless.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Blockbuster+punished+customers+for+being+forgetful%3B+Netflix+rewarded+them+for+being+mindless.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Blockbuster+punished+customers+for+being+forgetful%3B+Netflix+rewarded+them+for+being+mindless.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>The service, initially called Watch Now, was primitive. Netflix made just one thousand titles available, which users could access only through Internet Explorer on PCs. Still, long-oppressed cable subscribers immediately recognized Watch Now’s appeal. Netflix’s streaming site offered viewers many of the shows and films they’d find on cable for a fraction of the price, as little as $5 per month. Hollywood studios were happy to license their second-run content to Netflix, which at first seemed incapable of threatening their cable interests. But the studios overlooked that streaming was more convenient than cable, as Netflix beamed images directly onto viewers’ laptops<span> </span>—<span> </span>and, soon enough, televisions and smartphones<span> </span>—<span> </span>with no annual contracts, cancelable at any time. Above all, there were no ads.</p><p>Streaming made perfect sense for Netflix. Since it began shipping DVDs, Netflix had hoarded customer data to improve its recommendation algorithms, and Watch Now gave the company access to granular insights about audience behavior in real time. The streaming platform eventually noted when viewers watched from their computers, televisions, or phones; which scenes they skipped, paused, or rewound; and how long it took them to abandon a show they didn’t like or finish a season that they loved. This proved useful when Netflix produced its first original series, in 2013, <span><i>House of Cards</i></span>. Company executives claimed that they acquired the show, a political thriller starring Kevin Spacey and directed by David Fincher, based on data that showed Netflix users flocked to Spacey and Fincher films. Data helped with the show’s release, too. Netflix engineers had observed that most viewers consumed episodes of television in large batches, often without breaks in between. Company executives called this “binge-watching.” Ted Sarandos, then Netflix’s chief content officer, decided to feed the habit, releasing all thirteen episodes of <span><i>House of Cards </i></span>at once in defiance of the television industry’s model of appointment viewing.</p><p>Netflix argued in its 2013 “Long-Term View” report to shareholders that the company’s “originals” acquisition strategy was just one of many reasons that “the linear TV experience” was “ripe for replacement.” “The data we have on our members’ viewing habits,” Netflix stated, “enables us to avoid overpaying for content” and “do as good or [a] better job than our linear TV peers in choosing projects.” The company explained how its formal advantages<span> </span>—<span> </span>its lack of prime-time slots, its varying episode and season lengths<span> </span>—<span> </span>“provide a platform for more creative storytelling.” “A show that is taking a long time to find its audience is one we can keep nurturing. This allows us to prudently commit to a whole season, rather than just a pilot episode.”</p><p>None of this was true. Netflix did commit to producing two seasons of <span><i>House of Cards </i></span>without seeing a pilot (outbidding HBO and AMC with an up-front offer of over $100 million<span> </span>—<span> </span>the very definition of “overpaying”), but this had little to do with “nurturing” the show. “More creative storytelling” was also a stretch: <span><i>House of Cards</i></span> resembled much of the bland and high-budget television that had dominated premium cable channels since the late 1990s. And it wasn’t clear how much insight into Netflix’s members’ viewing habits was really needed to green-light the show. After all, it didn’t take complex data analysis to know that <span><i>House of Cards</i></span><span> </span>—<span> </span>an adaptation of an already popular British series, remade with Hollywood stars<span> </span>—<span> </span>would find an audience.</p><hr><p><span>F<span>or decades,</span></span> television<span> </span>—<span> </span>with its episodic, high-volume format<span> </span>—<span> </span>had been Hollywood’s most powerful economic engine. With a successful pilot, a television producer could employ actors, directors, writers, and crew for as many as thirty-four episodes over a single season. After a string of successful seasons, the producer could sell the show in foreign territories, screen it in other formats (DVDs, video on demand, airplanes), and eventually syndicate it for reruns. All these sales produced residual payments: shares of the profits for the writers, actors, and directors who worked on the show.</p><p>Residuals had been a fixture of Hollywood since the collapse of the studio system in the 1950s, providing job security for tens of thousands of professional artists. But streamers, which by 2014 included Hulu and Amazon, saw residuals in a new light. They had no intention of rebroadcasting their shows on linear television networks, in foreign territories, or on planes. They already owned exhibition platforms<span> </span>—<span> </span>Netflix.com, Hulu.com, and Amazon.com<span> </span>—<span> </span>that were increasingly accessible from all over the world and from the most common internet-connected devices.</p><p><span>“The philosophy of the guilds was always, ‘If you reuse our material, and you make money off the reuse of our material, then we should be compensated for that,’” a former Writers Guild of America officer told me. The officer recalled a 2014 conversation he had had with a studio executive about streaming. “His response was, ‘I don’t pay my plumber every time I flush my toilet.’” Netflix pioneered a different model. Instead of residuals, the streamer offered producers a payment model known as “cost-plus.” With cost-plus, Netflix offered to pay for an entire season up front</span><span> </span><span>—</span><span> </span><span>as it did with </span><span><i>House of Cards</i></span><span> </span><span>—</span><span> </span><span>plus a “premium” that Netflix calculated, as Sarandos once explained in an interview, “via what we think the back end would have been.”</span></p><blockquote><p><b>Until Netflix, one of cinema’s essential qualities, the thing that distinguished it from television, was the way it commanded an audience’s attention.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=Until+Netflix%2C+one+of+cinema%E2%80%99s+essential+qualities%2C+the+thing+that+distinguished+it+from+television%2C+was+the+way+it+commanded+an+audience%E2%80%99s+attention.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=Until+Netflix%2C+one+of+cinema%E2%80%99s+essential+qualities%2C+the+thing+that+distinguished+it+from+television%2C+was+the+way+it+commanded+an+audience%E2%80%99s+attention.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>Initially, the guilds didn’t see Netflix as a threat. “The WGA had its head in the sand,” the former guild officer told me. “The guild thought, ‘If and when Netflix becomes a proper studio, we’ll deal with it like how we deal with the other studios.’”</p><p>But the guilds like the WGA and the Screen Actors Guild under-estimated just how quickly Netflix would take over the industry. Suddenly, most of the work in Hollywood was in streaming. And as the journalist Nicole LaPorte found in an investigation for <span><i>Fast Company </i></span>in 2018, little of it paid well. While A-list showrunners like Shonda Rhimes and Ryan Murphy signed nine-figure streaming production deals, everyone else saw their salaries shrink. Writers who were paid per episode noticed that Netflix’s varying season lengths really meant shorter seasons and smaller paychecks overall. Without residuals, small jobs that used to generate reliable income for years became worthless. Some actors learned they were making thirty times less than they would have on a network show. Five years before the WGA and SAG’s historic overlapping strike, which in part sought to redress the streamers’ elimination of back-end payments, LaPorte concluded what it would take major newspapers and magazines years to report: streaming had brought about “the death of Hollywood’s middle class.”</p><p>In the years after <span><i>House of Cards </i></span>debuted, Netflix flooded the market with television shows. Its spending on content ballooned from $2.4 billion in 2013 to $12 billion in 2018. The other streamers<span> </span>—<span> </span>Hulu, Amazon, and Apple<span> </span>—<span> </span>clamored to outspend one another and fill their content pipelines. Studios like Disney withdrew their content licensed to Netflix and started their own streaming services. By 2018, Netflix had taken over television, just as it had taken over the video store. But by the time the other studios followed suit, Netflix already had a new target: the film industry.</p><hr><p><span>A <span>few years</span></span> after Mynette Louie had her run-in with Hastings, she quit her job at the market-research firm and eventually became an independent film producer, shepherding films by Andrew Bujalski and Karyn Kusama. In 2013, she helped launch a financing company called Gamechanger Films that specialized in funding narrative feature films directed by women. By then Netflix had already been streaming for half a decade, and Louie’s timing seemed ideal. While Netflix already had its eye on the mainstream<span> </span>—<span> </span>in 2014 it announced a $250 million four-picture deal with Adam Sandler<span> </span>—<span> </span>much of its film budget was devoted to funding small- to mid-budget projects and aggressively acquiring finished independent films at top American festivals.</p><p>Louie benefited from Netflix’s splurge. In 2015 the company picked up the streaming rights to Kusama’s <span><i>The Invitation</i></span> after the film’s premiere at South by Southwest. Louie sold two more films to the streamer the following year, both for generous fees. “We were made whole by those sales, which was amazing,” Louie told me. “Amazing for our filmmakers, amazing for our investors, and at the time we thought, ‘Great, we’ll just keep making movies.’ We were all very hopeful about indie film having a place.”</p><p><span>It had been a long time since independent film had occupied anything like a prominent place in Hollywood. In the 1990s, the emergence of home video and foreign television outlets provided a rising generation of auteurs</span><span> </span><span>—</span><span> </span><span>Richard Linklater, Allison Anders, Gus Van Sant, and so on</span><span> </span><span>—</span><span> </span><span>with a deluge of new markets that multiplied their commercial success. Ted Hope, a film producer and cofounder of the indie production company Good Machine, recalled how foreign buyers helped his films thrive. “If you picture about one hundred different territories where you could find an audience,” he told me, “and a minimum of five different distributors in each market, you had five hundred different ways to find success. Everybody had a structure where they could take more chances.” The sheer number of buyers meant that indie filmmakers could fund their entire movies through foreign distribution sales alone, all before they shot a single scene. The competitive environment was good for audiences, too, as new indie distributors like Miramax, Fine Line, and October, aiming to make a name for themselves, raced to acquire work made by the most audacious filmmakers from the United States and abroad.</span></p><p>Rather than cultivate this success, the largest Hollywood studios spent the first decade of the new millennium stamping it out. Despite launching and acquiring indie film wings of their own, the Hollywood majors began focusing their resources on IP-driven, family-oriented blockbuster franchises and used their vast resources to book these films on thousands of screens at once, crowding out competition from smaller films. After the 2008 crash, risk-averse executives increasingly gave themselves permission to drop their mid-budget fare entirely and produce predictable blockbusters about superheroes that, when successful, generated billions of dollars in box-office revenue.</p><p>The optimism Louie felt when Netflix and Amazon began acquiring indie films in the mid-2010s was warranted. What Hope described as five hundred ways to find success had always involved a degree of risk. Producing an indie film required cobbling together funding sources, many of which were contingent and could fall through at a moment’s notice. With Netflix and Amazon, there was just one deal for global distribution, and the streamers’ cost-plus premiums guaranteed that investors made a profit. As the streamers increasingly paid enormous sums for the global rights to independent films<span> </span>—<span> </span>like Amazon’s $10 million for Dan Fogelman’s <span><i>Life Itself</i></span>, or Netflix’s $8 million for Marti Noxon’s <span><i>To the Bone</i></span><span> </span>—<span> </span>they simplified the indie film production process and enriched investors all at once.</p><p>And global distribution meant larger audiences, or so the thinking went. Speaking to Business Insider in 2017, Elijah Wood, the star of that year’s Netflix film <span><i>I Don’t Feel at Home in This World Anymore</i></span>, was enthusiastic. “There was a time in the ’90s that this would have been a title that would have gone direct to video, which would have been some certain kind of death,” Wood told his interviewer. “But that’s not the case anymore. If anything, [Netflix] created this equal opportunity for filmmakers.”</p><p>As many journalists have pointed out, Netflix and Amazon weren’t traditional Hollywood studios in any sense. The streamers were tech companies, outsiders whose business models didn’t rely on making a billion dollars at the box office from a single franchise film. “The tech giants have more leeway to experiment,” wrote <span><i>Wired</i></span>’s Julia Greenberg<i> </i>in 2016. “A single movie or show on Netflix and Amazon needn’t appeal to everyone; the key for both platforms is making sure they offer enough of everything to attract anyone.” The streamers could acquire fringe and pathbreaking films that the largest studios had ignored. Perhaps indie cinema could rise once again.</p><p>Netflix took risks on films from distinguished auteurs, like Bong Joon-ho’s <span><i>Okja</i></span>, a science fantasy about ecoterrorists trying to rescue an enormous bioengineered pig, and Alice Rohrwacher’s portrait of an ingenuous sharecropper in the Italian countryside, <span><i>Happy as Lazzaro</i></span>. And it acquired ambitious documentaries, like <span><i>13th</i></span>, Ava DuVernay’s history of the American prison–industrial complex, and <span><i>Icarus</i></span>, Bryan Fogel’s film about a Russian sports scientist who helped his athletes avoid doping regulations for years. (The latter delivered Netflix its first Academy Award for a feature-length film.)</p><p>But its commitment to good filmmaking was short-lived. As with its DVD-rental business and its pivot into streaming, Netflix’s concern was scale, rather than the cinema it was scaling. Movies, as the founder had told Louie, were merely a means to an end: acquiring subscribers who paid for access to Netflix’s entire library of content every month.</p><p><span>The range of indie films on Netflix didn’t resemble the ’90s boom and its cultivation of new auteurs. As the years went on, the streamer picked up lifeless vehicles for A-list talent like </span><span><i>The</i></span> <span><i>Polka King</i></span><span>, a comedy starring Jack Black as Jan Lewan, the real-life Polish immigrant and polka band leader who launched a multimillion-dollar Ponzi scheme; preposterous directorial feature-length debuts like Brie Larson’s </span><span><i>Unicorn Store</i></span><span>, a fantasy-comedy starring Larson as a failing artist who learns that unicorns are real and that Samuel L. Jackson wants to sell her one; and found-object curios not worth remembering, like the 2016 biopic </span><span><i>Barry, </i></span><span>starring</span><i> </i><span>Anya Taylor-Joy as Barack Obama’s white college girlfriend.</span></p><p>Film studios have always released duds: movies that fail to gain traction and are shuttled to the studios’ archives, where they disappear into obscurity. Until recently, for most studios, a forgotten film was a sign of failure. But Netflix, uniquely, seemed to relish making its films vanish as soon as they were released, dumping them onto its platform and doing as little as possible to distinguish one from the next. “Your film ends up as a thumbnail, and culturally it doesn’t make a splash. It’s not the same,” one producer with movies on Netflix told me. “Unless you’re Scorsese or something, the streamers don’t craft custom bespoke marketing campaigns for these films.”</p><p><span>Netflix’s antimarketing strategies made no sense to anyone in the movie business. Marketing had always been part of the lifeblood of cinema, the driving force that raised audience awareness, drove ticket sales, and aided films as they wormed their way through their ancillary windows. It was especially vital to independent films. “In the old days,” Hope told me, “one of the great inefficiencies that existed was when you made a movie, you had to go ahead and tell everyone about it in order to get the small percentage of people that you’d actually be able to drive to become a ticket buyer. Whether your movie was crap or beautiful, you still had to tell everybody.” Print advertising, TV and radio spots, press junkets, magazine interviews and profiles, college screenings, cast appearances on the late-night talk-show circuit: all this was part of the playbook for cementing a small-budget film in the memory of the moviegoing public and turning it into an enduring hit that could generate profits in perpetuity.</span></p><p>None of this mattered to Netflix. All viewing of its movies was confined to its platform, which supplied users with algorithmic recommendations tailored to their every whim. As Sarandos bragged in 2015 during an interview with TV Insider about Netflix’s television series: “A lot of the heavy lifting of getting audiences to the show is done with the user interface.<span> </span>.<span> </span>.<span> </span>. Marketing spends we do mostly to attract subscribers to join Netflix. The actual viewing of shows, the user interface is driving almost all of that.”</p><p>But Netflix’s user interface was hardly a replacement for the traditional marketing distributors once used to get audiences into theaters. Between 2016 and 2017, Netflix spent tens of millions of dollars acquiring indie films and documentaries to fill out its platform: <span><i>The Polka King</i></span> and <span><i>Unicorn Store</i></span>, but also <span><i>The Incredible Jessica James</i></span>, <span><i>The Mars Generation</i></span>, a movie called <span><i>Fun Mom Dinner</i></span>, and many, many more. The vast majority of these films have effectively disappeared, like the thousands of silent films from the 1910s and ’20s that Hollywood studios lost before they standardized film preservation.</p><p>Unlike those films, Netflix’s movies still exist and can be watched on their website. But for the most part they aren’t. If Netflix’s executives learned anything from indie film it was this: on the platform, you didn’t need to make a hit to succeed. You didn’t even need your film to be remembered. You just needed, in Greenberg’s words, “enough of everything to attract anyone.”</p><hr><p><span>I<span>t didn’t</span> <span>take long</span> </span>for the streamers to abandon independent film altogether. Ted Hope learned this the hard way. Back in 2015, when Amazon was first attempting to break into original movies, the streamer hired Hope as the head of development of its film division. It seemed like a natural fit. Amazon was trying to distinguish itself by distributing sophisticated auteurs, the kinds of filmmakers Hope had been producing since the early 1990s. The pairing started off well. In 2016, the studio’s first full year of releases, Hope acquired Kenneth Lonergan’s <span><i>Manchester by the Sea</i></span> and Asghar Farhadi’s <span><i>The Salesman</i></span>, which together collected three Oscars: best screenplay, best actor, and best foreign-language film.</p><p>But as Hope learned, making a successful movie on a streaming platform didn’t necessarily make a streaming platform successful. At Amazon, Hope discovered he was in the customer acquisition business, not the film business. “And the way you win the customer acquisition business,” Hope said, “is by maintaining a regular cadence at a consistent quality in an environment that people trust.” Competition intensified, with Apple, Disney, Paramount, and NBCUniversal all entering the fray, and “it became tougher to keep a customer,” said Hope, “as people would dip in and dip out.”</p><p><span>In an effort to reduce “churn,” the rate at which customers canceled their subscriptions, the streamers began pushing a different kind of production model. Instead of acquiring films by auteurs, which had gotten them into trouble</span><span> </span><span>—</span><span> </span><span>Maïmouna Doucouré’s </span><span><i>Cuties</i></span><span>, a film about preteen dancers in Paris, sparked a baseless right-wing panic that Netflix was sexualizing children</span><span> </span><span>—</span><span> </span><span>they turned to a safer, more uniform product that could be made in-house, and replicated and tailored to the diverse tastes of their enormous subscriber bases. (This also guaranteed they’d keep global distribution rights instead of having to negotiate for them.) “They no longer wanted that outlier,” Hope said. “They wanted someone to have correct expectations: ‘Oh, look at those two couples kissing. One’s wearing pool flippers. That must be a romantic comedy. I get it, do you want to watch a romantic comedy tonight?’ And that’s what it reduced down to. As long as people got what they expected, they stayed in tune.”</span></p><p>In documentaries, too, executives shifted to conventional feed. “It’s not enough to do something that a few million people might really love when you’re trying to reach twenty-five million people or fifty million people,” a former Netflix executive told the journalist Reeves Wiedeman in a 2023 article in <span><i>New York </i></span>about the documentary streaming “boom.” “A lot of documentaries<span> </span>—<span> </span>I would say the majority of documentaries<span> </span>—<span> </span>don’t meet that bar.” So what did? Grisly true crime, garish cult exposés, celebrity hagiography, sports and food miniseries, pop science, and pets. Netflix’s documentary slate quickly became a supermarket aisle of tabloid magazines.<sup id="rf1-54865"><a href="#fn1-54865" title="As Wiedeman reported in his article, the streamers have made once-unthinkable documentary practices commonplace: locking up interview sources to exclusive contracts with six-figure payouts and bringing in reality television producers who tell directors “we need a scene where X happens.” The streamers’ celebrity documentaries, like Netflix’s Beckham or Apple’s Billie Eilish: The World’s a Little Blurry, are particularly egregious, serving as little more than publicity reels for their powerful subjects. The stars of these productions often retain significant creative control and routinely interfere with the cutting of the project.">1</a></sup></p><p>In 2021 Netflix announced that it would start releasing a new original movie every week. A certain style soon began to take shape, a mind-numbing anticinema that anyone who has subscribed to Netflix in recent years knows by sight. I’ll call it the Typical Netflix Movie (TNM). From the outside, the TNM looks algorithmically constructed, as if designed to cater to each of Netflix’s two thousand “taste clusters,” the genre-like groupings Netflix uses to segment its audience, green-light programs, and recommend films and shows to subscribers. The TNM covers every niche interest and identity category in existence, such as a movie about a tall girl, <span><i>Tall Girl</i></span>, but also <span><i>Horse Girl</i></span>, <span><i>Skater Girl</i></span>, <span><i>Sweet Girl</i></span>, <span><i>Lost Girls</i></span>, and<span><i> Nice Girls</i></span>. Seemingly optimized for search engines, the title of a TNM announces exactly what it is<span> </span>—<span> </span>hence a romantic comedy about a wine executive called <span><i>A Perfect Pairing</i></span>, or a murder mystery called <span><i>Murder Mystery</i></span>. The opening credit sequence looks thrown together, as if its designer were playing roulette with Adobe templates in After Effects. A typical shot frames two characters, waist up, in profile as the camera slowly dollies across them, a slow and constant whir meant to inject motion into an otherwise inert frame. There is a preponderance of drone shots. The characters’ dialogue is stilted, filled with overexplanation, clichés, and lingo no human would ever use, like two bots stuck in a loop. “Want to catch a beer?” a buddy asks Adam Sandler in <span><i>Murder Mystery</i></span>:</p><blockquote><p><span>Nick (Adam Sandler)</span>: I can’t<span> </span>. I gotta run a few errands.</p><p><span>Jimmy</span>: What? You don’t want a beer? What’s wrong?</p><p><span>Nick</span>: I got the results back from the detective exam.</p><p><span>Jimmy</span>: You failed again. This is why I never took that test<span> </span>. All the anxiety and disappointment<span> </span>. At some point you have to realize you have hit your ceiling and just give up<span> </span>.</p></blockquote><p>The editors of these films seem to have just given up, too. The cutting between shots is frenetic. The lighting is terrible. The TNM looks both oversaturated and flat, with the blacks brightened and the highlights dulled, a result of Netflix’s insistence that its originals be shot with powerful digital cameras that compress poorly on viewers’ laptops and televisions. (Netflix might be the first studio in Hollywood history to consistently make daylight look bad.) The TNM also never turns down an opportunity to use CGI for shots that don’t need it, such as the kicking of a soccer ball in <span><i>The Kissing Booth</i></span>. Worst of all is the music: in the absence of any mise-en-scène, the TNM pipes in recognizable tunes from expensive, blue-chip artists to create moods, such as the vacuous, third-order use of David Bowie’s “Let’s Dance” in <span><i>Irish Wish</i></span>, the mercilessly random Lindsay Lohan body-swap fantasy in which she schemes to marry a rich Irish novelist who lives in a castle.</p><p>In 2022, after Netflix’s subscriber numbers dipped and its stock tanked, journalists were quick to link the company’s excessive output with a drop in what they tepidly referred to as “quality control.” Responding to claims that Netflix had pursued “drunken sailor spending,” Sarandos provided a justification to Maureen Dowd in the <span><i>New York Times</i></span>: “We were trying to build a library to make up for not having ninety years of storytelling.”</p><p>But high output alone can’t account for Netflix’s garbage quality. In the 1920s and ’30s, studios like Paramount and Warner Bros. put out as many as seventy movies per year. Around its peak in the ’90s, Miramax tried releasing a new film almost every week. The difference between Netflix and its predecessors is that the older studios had a business model that rewarded cinematic expertise and craft. Netflix, on the other hand, is staffed by unsophisticated executives who have no plan for their movies and view them with contempt. Cindy Holland, the first employee Sarandos hired, who eventually served as vice president of original content, once compared Netflix’s rapacious DVD acquisition strategy to “shoveling coal in the side door of the house.” This remained true as Netflix ramped up its original-film production. In researching this essay, I was told by sources about two high-level Netflix executives who have been known to green-light projects without reading the scripts at all.</p><p>Such slipshod filmmaking works for the streaming model, since audiences at home are often barely paying attention. Several screenwriters who’ve worked for the streamer told me a common note from company executives is “have this character announce what they’re doing so that viewers who have this program on in the background can follow along.” (“We spent a day together,” Lohan tells her lover, James, in <span><i>Irish Wish</i></span>. “I admit it was a beautiful day filled with dramatic vistas and romantic rain, but that doesn’t give you the right to question my life choices. Tomorrow I’m marrying Paul Kennedy.” “Fine,” he responds. “That will be the last you see of me because after this job is over I’m off to Bolivia to photograph an endangered tree lizard.”)</p><p>One tag among Netflix’s thirty-six thousand microgenres offers a suitable name for this kind of dreck: “casual viewing.” Usually reserved for breezy network sitcoms, reality television, and nature documentaries, the category describes much of Netflix’s film catalog<span> </span>—<span> </span>movies that go down best when you’re not paying attention, or as the <span><i>Hollywood Reporter</i></span> recently described <span><i>Atlas</i></span>, a 2024 sci-fi film starring Jennifer Lopez, “another Netflix movie made to half-watch while doing laundry.” A high-gloss product that dissolves into air. Tide Pod cinema.</p><hr><p><span>M<span>arc Randolph,</span></span> who quit Netflix in 2002, has explained that his cofounder’s origin story about the Blockbuster late fee for <span><i>Apollo 13</i></span> was made up. “[It was] a lot of crap,” Randolph told the <span><i>Netflixed</i></span> writer Gina Keating. “It never happened.” According to Randolph, the <span><i>Apollo 13</i></span> story began as “a convenient fiction” to explain the benefits of Netflix’s subscription model but took on a life of its own. In the mid-2000s, Blockbuster demanded that Hastings stop repeating the anecdote in public. “Blockbuster had searched its databases after hearing the story,” Keating reported, “and never found such a transaction.”</p><p>Hastings’s lie marked the beginning of a campaign of deception and obfuscation. Despite harvesting large troves of data on users’ viewing habits, Netflix for years refused to release any of it<span> </span>—<span> </span>not even to the producers, directors, and stars of its supposed “hit” movies and shows. Keeping talent in the dark proved to be a useful negotiating tactic when the streamer renewed a television show or green-lit a movie sequel. At the same time, withholding data protected the company from public scrutiny by obscuring how little audiences were watching its original programming in a meaningful way<span> </span>—<span> </span>from start to finish, or even at all.</p><blockquote><p><b>The TNM covers every niche interest and identity category in existence, such as a movie about a tall girl, <em>Tall Girl</em>, but also <em>Horse Girl</em>, <em>Skater Girl</em>, <em>Sweet Girl</em>, <em>Lost Girls</em>, and <em>Nice Girls</em>.</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=The+TNM+covers+every+niche+interest+and+identity+category+in+existence%2C+such+as+a+movie+about+a+tall+girl%2C+%3Cem%3ETall+Girl%3C%2Fem%3E%2C+but+also+%3Cem%3EHorse+Girl%3C%2Fem%3E%2C+%3Cem%3ESkater+Girl%3C%2Fem%3E%2C+%3Cem%3ESweet+Girl%3C%2Fem%3E%2C+%3Cem%3ELost+Girls%3C%2Fem%3E%2C+and+%3Cem%3ENice+Girls%3C%2Fem%3E.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=The+TNM+covers+every+niche+interest+and+identity+category+in+existence%2C+such+as+a+movie+about+a+tall+girl%2C+%3Cem%3ETall+Girl%3C%2Fem%3E%2C+but+also+%3Cem%3EHorse+Girl%3C%2Fem%3E%2C+%3Cem%3ESkater+Girl%3C%2Fem%3E%2C+%3Cem%3ESweet+Girl%3C%2Fem%3E%2C+%3Cem%3ELost+Girls%3C%2Fem%3E%2C+and+%3Cem%3ENice+Girls%3C%2Fem%3E.+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>Netflix was no different from its competitors. “The number of things that tank on Amazon is remarkable,” a former Amazon Studios executive told me. “There are so many things that people hardly watch and it would be embarrassing to release those streaming numbers. I used to get this daily email, which basically said, ‘here are the one hundred movies that people are watching most on Amazon SVOD today by the minute.’ It was always a lot of Tom Cruise sci-fi movies, action movies from the ’90s and aughts, and <span><i>Talladega Nights</i></span>.”</p><p>That audiences clearly prefer the films of the past has been an inconvenient fact for the streamers who tout themselves as the future of entertainment.<sup id="rf2-54865"><a href="#fn2-54865" title="Netflix and the other streamers are, of course, aware of the appeal of TV and films of the past, and they have pursued remakes, reboots, and reimaginings with a voraciousness even greater than that of Marvel Studios. But for the most part, their sequels and spin-offs are little more than TNMs featuring aging stars. No one assumed Coming 2 America or Fuller House would generate the fandoms of the originals, and they were right.">2</a></sup> But rather than address the problem by improving the quality of their programming and distribution, the streamers obscure the failure of their originals even further with PR bluster. Ever since it moved into original content, Netflix had been making ridiculous claims about its films and shows with little to no pushback from the Hollywood press. In a 2018 article about Netflix published in <span><i>New York</i></span>, Sarandos described <span><i>The Kissing Booth</i></span>, an unmemorable teen romance starring Jacob Elordi and Joey King, as “one of the most-watched movies in the country, and maybe in the world.” His evidence? The rankings of Elordi and King on something called the “Star-o-Meter,” a user-derived measurement for the popularity of celebrities on IMDb.com. “Three weeks ago on the IMDb Star-o-Meter, which is how they rank their popularity, [Elordi] was No. 25,000. Today he is the No. 1 star in the world,” Sarandos claimed. “And Joey King, the female lead, went from like No. 17,000 to No. 6. This is a movie that I bet you’d never heard of until I just mentioned it to you.”</p><p><span>Every week Netflix seemed to deliver a new movie no one had ever heard of that somehow broke every viewing record in the world. There was </span><span><i>Army of the Dead</i></span><span>, Zack Snyder’s 2021 zombie heist film whose ensemble cast included retired wrestler Dave Bautista and the comedian Tig Notaro; according to Netflix’s bottom-of-the-barrel PR organ Tudum, it was “the #1 film around the world and is projected to be one of Netflix’s most popular films ever in its first 4 weeks.” </span><span><i>Airplane Mode</i></span><span>, a 2020 Brazilian comedy about an influencer, wasn’t covered by any major outlet. But on Twitter, Tudum issued a “</span><span>✈</span><span> hit alert </span><span>✈</span><span>” calling it “the most popular non-English film on Netflix” of 2020. A few months later, Tudum announced a new record breaker: </span><span><i>The Old Guard</i></span><span>, an action movie starring Charlize Theron released at the height of the pandemic. No one could claim with a serious face that the film was as popular as the junk television Netflix released during the company’s pandemic boom, like </span><span><i>Tiger King </i></span><span>and </span><span><i>Emily in Paris</i></span><span>. Still, Tudum described </span><span><i>The Old Guard</i></span><span> as a “blockbuster” that was “already among the top 10 most popular Netflix films ever,” and “on track to reach 72M households in its first 4 weeks!” </span></p><p>Reaching seventy-two million households didn’t mean what it sounded like it meant. What it actually meant was that seventy-two million accounts watched at least two minutes of <span><i>The</i></span> <span><i>Old Guard</i></span>. According to Netflix, two minutes was “long enough to indicate the choice was intentional,” even though Netflix designed its viewing experience to be totally <span><i>unintentional</i></span>. An essential part of Netflix’s platform is its autoplay feature, which launches users into the next episode of a television series, or an algorithmically chosen movie, seconds after a program ends and sometimes just before the credits roll.</p><p>In 2023, in response to industry pressure, and as a flex against other less successful streaming platforms, the company began releasing biannual reports that contained the total number of “views” for each of its eighteen-thousand-plus titles over the previous six months. On a conference call with reporters, Sarandos claimed this was the most transparent representation of its data ever shown to the public.</p><p>Netflix’s “views” might look impressive on paper (even <span><i>Sweet Girl</i></span>, the TNM starring Jason Momoa as a vengeance-seeking survivalist whose MMA-trained daughter takes up his cause, was viewed 6.7 million times in the first half of 2024), but these figures remain a sham. To get to 6.7 million, Netflix first tallies the film’s “viewing hours,” the total amount of time that users have spent streaming the movie. Here, Netflix makes no distinction between users who watch <span><i>Sweet Girl</i></span> all the way through, those who watch less than two minutes, and those who watch just a few seconds thanks to autoplay, or skip around, or watch at 1.5x speed. All this distracted, piecemeal activity is rolled into <span><i>Sweet Girl</i></span>’s total viewing hours (12.3 million at last count), which the company then divides by the program’s runtime (110 minutes, or 1.83 hours) to produce those 6.7 million views. According to Netflix’s rubric, two users who watch the first half of <span><i>Sweet Girl </i></span>and close their laptops equal one full “view”<span> </span>—<span> </span>as do 110 users who each watch a single minute.</p><p>Such sleight of hand would be illegal in any other industry. Ford could never tell its shareholders that it sold two hundred thousand F-150 trucks over a single quarter, when in truth the company sold one hundred thousand F-150s to married couples who co-owned their vehicles. But for Netflix, a movie is an accounting trick<span> </span>—<span> </span>a tranche of pixels that allows the company to release increasingly fantastical statements about its viewership, such as the absurd notion that <span><i>Leave the World Behind</i></span>, a dubious Julia Roberts apocalypse movie produced by Barack and Michelle Obama, was “viewed” 121 million times. How could anyone believe that?</p><hr><p><span>“T<span>here’s a movie</span></span> on Paramount+ right now called <span><i>On the Come Up</i></span>,” a Hollywood producer told me in 2022. “I’m sure you haven’t heard about it because you don’t hear about any of these movies. It’s about a Black female rapper in Chicago and her journey in rap battling. It’s like the Black, female <span><i>8 Mile</i></span>. It’s not a great movie, but in another era, it would have been a crowd-pleaser that could cross over and play a few hundred screens, like <span><i>Set It Off </i></span>or <span><i>Down in the Delta</i></span>. That was a film by a major poet in her directorial debut, with Wesley Snipes, and that movie comfortably played on four to five hundred screens, a smallish-medium release from Miramax in 1998. What has happened to that movie is that it has become <span><i>On the Come Up</i></span>, which just disappears into the ether, and the studios put up two billboards in LA because they know the creators live in LA and want some sort of vision that they are being marketed. Like with Amazon<span> </span>—<span> </span>if you drive through Culver City you will see billboards for Amazon movies everywhere. Why? Because the directors who come to the studio lot to take a meeting there to make a movie, they drive there and they’re like, ‘Oh they’re marketing my movie.’ But they’re not.”</p><p>Last winter, while visiting Los Angeles, I went to see the signage for myself. Encircling the intersection of Venice and La Cienega Boulevards were eight towering billboards promoting the latest Amazon original movies and shows. Two advertised <span><i>The Burial</i></span>, a legal drama starring Jamie Foxx and Tommy Lee Jones. I hadn’t heard of it, nor had anyone else I talked to that week. I drove to more studios, down Sunset Boulevard past Netflix’s headquarters, toward Melrose Avenue and the Paramount lot. Every studio had token billboards for their latest pseudomovies, designed to be played but not watched.</p><p>In the past, whenever the movies in Hollywood went stale and executives exerted too much control over artists, the industry had an important hand brake: the audience. If a movie bombed with audiences and box office numbers plummeted, then studios would have to change course. After all, the box office has always been viewed as the gold standard of metrics in Hollywood for a reason: it’s the most distilled and straightforward measurement of audience interest. Moviegoers must choose to buy tickets. They cannot skip around, fast-forward, or order groceries through the Prime app on their phone. No moviegoer enters a theater expecting to leave after two minutes. Until Netflix, one of cinema’s essential qualities, the thing that distinguished it from television, was the way it commanded an audience’s attention. Whether a movie grossed big numbers or bombed, a box office report carried an inadmissible truth: the vast majority of the audience experienced the movie in full, and its taste couldn’t be ignored.</p><p>How to predict the audience’s taste<span> </span>—<span> </span>what will make money and what won’t<span> </span>—<span> </span>is a question that’s plagued Hollywood since its inception. The problem was captured by the screenwriter William Goldman in 1983. “Nobody knows anything,” he wrote in his book <span><i>Adventures in the Screen Trade</i></span>. “Not one person in the entire motion picture field knows for a certainty what’s going to work.” Netflix’s greatest innovation was that it found a way around this uncertainty: it provided a platform on which there are no failures, where everything works.</p><p>This is an important milestone for the largest Hollywood studios as they all set their sights on integrating artificial intelligence into their productions. In March, news outlets reported that OpenAI CEO Sam Altman had held meetings with top studios to showcase his company’s text-to-video generator, Sora. Clips generated by Sora that circulated online alternated between drone shots of cityscapes that look ripped from video-game cut scenes and animals rendered in the 3D animated style common to Hollywood productions today. Streaming platforms are the only place where this garbage makes any sense<span> </span>—<span> </span>a place where it would never be watched at all.</p><p>But by insulating their films from failure, the streamers have destroyed the meaning of success. Thierry Frémaux, head of the Cannes Film Festival and a vocal critic of streamers, understood this well when he presented the dilemma at a Cannes press conference in 2021. “What directors have been discovered by [streaming] platforms?” he asked. It wasn’t a rhetorical question. Frémaux began calling on journalists to name an auteur whose career had been launched by a streamer. By this point, Netflix had released more than seven hundred films in the US alone, with hundreds of directors attached. Yet as the <span><i>Guardian</i></span> later reported of the scene, “nobody could name any at all, in fact.”</p><p><span>Here, streaming platforms have achieved a strange paradox. Never has a group of studios gained so much control over the production, distribution, exhibition, and reception of movies by making movies no one cares about or remembers. Having not only failed to discover a new generation of auteurs, the streamers have also ensured that their filmmakers are little more than precarious content creators, ineligible to share the profits of any hit. It’s a shift that has induced a profound sense of confusion.</span></p><p>“What are these movies?” the Hollywood producer asked me. “Are they successful movies? Are they not? They have famous people in them. They get put out by major studios. And yet because we don’t have any reliable numbers from the streamers, we actually don’t know how many people have watched them. So what are they? If no one knows about them, if no one saw them, are they just something that people who are in them can talk about in meetings to get other jobs? Are we all just trying to keep the ball rolling so we’re just getting paid and having jobs, but no one’s really watching any of this stuff? When does the bubble burst? No one has any fucking clue.”</p><p>Netflix has created a pyramid scheme of attention, with no end in sight. And yet if the streamer admitted how little impact its movies make, it would undermine its long-running pitch to audiences, Hollywood talent, and their business representatives that the company is a grand star-making enterprise that produces great cinema with commercial appeal. This was always the logic behind Netflix’s superficial foray into funding established auteurs like Alfonso Cuarón with <span><i>Roma</i></span>, Jane Campion with <span><i>The</i></span> <span><i>Power of the Dog</i></span>, and Alejandro Iñárritu with <span><i>Bardo</i></span>. Netflix gives these films exclusive theatrical runs for a few weeks<span> </span>—<span> </span>just long enough to qualify them for Academy Awards<span> </span>—<span> </span>in a small number of theaters, a few of which the company owns or operates like the Paris in New York, or the Egyptian in Los Angeles. After that it dumps them on the platform. Some of these films, including Martin Scorsese’s <span><i>The Irishman</i></span>, have been rescued by the Criterion Collection, whose Blu-Ray editions offer an escape route out of Netflix’s walled garden. Most of the auteurs who end up at the streamer, however, simply languish. To Netflix, auteurs are a means of legitimacy, nothing more.</p><blockquote><p><b>“If no one knows about them, if no one saw them, are they just something that people who are in them can talk about in meetings to get other jobs?”</b></p><b> <a onclick="return popitup('https://twitter.com/share?text=%E2%80%9CIf+no+one+knows+about+them%2C+if+no+one+saw+them%2C+are+they+just+something+that+people+who+are+in+them+can+talk+about+in+meetings+to+get+other+jobs%3F%E2%80%9D+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865')" href="https://twitter.com/share?text=%E2%80%9CIf+no+one+knows+about+them%2C+if+no+one+saw+them%2C+are+they+just+something+that+people+who+are+in+them+can+talk+about+in+meetings+to+get+other+jobs%3F%E2%80%9D+%7C+n%2B1+%7C&amp;lang=en&amp;url=https%3A%2F%2Fwww.nplusonemag.com%2F%3Fp%3D54865">Tweet</a></b></blockquote><p>After all, Netflix has a more important coterie of stakeholders to keep happy: Wall Street investors. In an attempt to keep its stock price high, Netflix has moved away from auteurs and embraced big-budget projects that telegraph the company’s supposed mass appeal. Since 2019, Netflix has increasingly funded blockbuster-style event movies with expensive actors like Ryan Reynolds (<span><i>6 Underground</i></span>, <span><i>Red Notice</i></span>, <span><i>The Adam Project</i></span>), Ryan Gosling (<span><i>The Gray Man</i></span>), Mark Wahlberg (<span><i>The Union</i></span>), and Eddie Murphy (<span><i>Beverly Hills Cop: Axel F</i></span>). As giant burning piles of money that barely register in the cultural sphere, these attempts at generating beloved IP make the least sense in the company’s production slate. “Apparently for Netflix, Ryan Reynolds has made $50 million on this movie and $50 million on that movie,” Quentin Tarantino told a Deadline reporter last year at Cannes. “Well, good for him that he’s making so much money. But those movies don’t exist in the zeitgeist. It’s almost like they don’t even exist.” What everyone in Hollywood knows but doesn’t care to admit is that no Netflix film has ever achieved the name recognition of the streamer’s most popular television shows: <span><i>Stranger Things</i></span>, <span><i>Bridgerton</i></span>, and <span><i>Squid Game</i></span>.</p><p>Netflix is first and foremost a television company, one whose recent business strategies have made the company resemble the cable providers it’s tried to make irrelevant. Netflix is no longer the cheap service that freed cable subscribers from the tyranny of the bundle. The company’s standard subscription price has risen almost 100 percent over the past thirteen years, and any cord-cutter who wants access to the major networks’ latest shows must subscribe to several streaming platforms, whose prices have also shot up. Netflix is also no longer ad-free, as the company launched a lower-cost, ad-supported subscription tier in 2022. (When the streamer debuted its ad tier, it sought to charge advertisers around $65 to reach one thousand viewers, an eye-watering sum on par with NFL games. Perhaps an indication that advertisers aren’t buying Netflix’s astounding viewership numbers, this dollar amount has since dropped by more than half.) Netflix is also no longer dedicated to giving subscribers purely on-demand content. Over the past several years, the streamer has flirted with live programming, and this year it made its first big commitment, inking a $5 billion, ten-year deal for the exclusive rights to stream WWE’s live flagship program, <span><i>Raw</i></span>. It won’t be long before Netflix starts packaging shows into preprogrammed “channels” that run synchronously 24/7, and claiming it’s something brand new.</p><p>But if Netflix now occupies a place in the market similar to cable companies, the business it’s most spiritually aligned with is Blockbuster: a widely disliked service staffed by people who know nothing about movies, stocked with thousands of titles to see, few of them worth watching. Even Netflix knows its users can’t find titles that they like. In 2021, the company briefly introduced a new feature on its home page, called “Play Something,” to help in what the streamer called “times when we just don’t want to make decisions.” When clicked, Play Something instantly began playing for users an algorithmically chosen series or film. “Whether you’re in the mood for a new or familiar favorite,” Netflix wrote, “just ‘Play Something’ and let Netflix handle the rest.”</p><p>“Play Something,” as in: play anything. It doesn’t matter if it’s good or bad, if a user is on their phone or cleaning their room. What matters is that it’s on, and that it stays on until Netflix asks its perennial question, a prompt that appears when the platform thinks a user has fallen asleep: “Are you still watching?”</p><ol><li id="fn1-54865"><p>As Wiedeman reported in his article, the streamers have made once-unthinkable documentary practices commonplace: locking up interview sources to exclusive contracts with six-figure payouts and bringing in reality television producers who tell directors “we need a scene where X happens.” The streamers’ celebrity documentaries, like Netflix’s <em>Beckham</em> or Apple’s <em>Billie Eilish: The World’s a Little Blurry</em>, are particularly egregious, serving as little more than publicity reels for their powerful subjects. The stars of these productions often retain significant creative control and routinely interfere with the cutting of the project.&nbsp;<a href="#rf1-54865" title="Jump back to footnote 1 in the text.">↩</a></p></li><li id="fn2-54865"><p>Netflix and the other streamers are, of course, aware of the appeal of TV and films of the past, and they have pursued remakes, reboots, and reimaginings with a voraciousness even greater than that of Marvel Studios. But for the most part, their sequels and spin-offs are little more than TNMs featuring aging stars. No one assumed <em>Coming 2 America</em> or <em>Fuller House</em> would generate the fandoms of the originals, and they were right.&nbsp;<a href="#rf2-54865" title="Jump back to footnote 2 in the text.">↩</a></p></li></ol></div><p>If you like this article, please <a href="https://www.nplusonemag.com/subscribe/?affid=article">subscribe</a> or leave a tax-deductible tip below to support n+1.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Nvidia Way – Review of Tae Kim's New Book (157 pts)]]></title>
            <link>https://thechipletter.substack.com/p/the-nvidia-way</link>
            <guid>42529564</guid>
            <pubDate>Sat, 28 Dec 2024 08:45:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thechipletter.substack.com/p/the-nvidia-way">https://thechipletter.substack.com/p/the-nvidia-way</a>, See on <a href="https://news.ycombinator.com/item?id=42529564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg" width="800" height="1218" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1218,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:615771,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2a37d8c-69e1-4cf8-acb4-47d38a5f095c_800x1218.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>On the most superficial level, Nvidia’s rapid rise to vie for the title of the world’s most valuable company is easy to explain. AI is emerging as a technology that will be both pervasive and revolutionary. Nvidia makes the best chips for AI. QED.</p><p>Dig a little deeper, though, and there are lots of questions. How did Nvidia, a designer of graphics chips, make its products essential as the engines of AI? Was it luck or foresight? Why are other companies struggling to compete? And perhaps the most crucial question of all: Will Nvidia be able to maintain its lead?</p><p>At the end of his new book on the GPU-turned-AI chip designer, Tae Kim says he had assumed there must already be several books describing Nvidia's rise and the story of its now-famous CEO, Jensen Huang. It turns out that Kim’s new book, ‘The Nvidia Way,’ is the first.</p><p>On reflection, it’s perhaps not surprising, as Nvidia’s ascent and appearance in the wider public consciousness have been sudden and dramatic. As recently as 2019, Nvidia’s stock was trading below $4, a far cry from the $130+ where it stands, with a market capitalization of more than three trillion dollars, at the end of 2024.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg" width="1418" height="988" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:988,&quot;width&quot;:1418,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:116945,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d79659b-9730-49c5-9792-831de93fd3ca_1418x988.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>But Nvidia is a remarkable company with an eventful history. It has a culture and approach to business that are highly distinctive, even compared to its closest peers. At the center of that culture is its founding CEO, Jensen Huang, still leading the firm after more than three decades. It’s a firm that deserves closer inspection, independent of its recent success.</p><p>So does Kim’s book do justice to Nvidia’s remarkable story? Does it help to answer the questions we posed above?</p><p><span>The Nvidia Way is two, intertwined, books in one. The first is a straightforward retelling of Nvidia’s history since it was founded by Huang, Curtis Priem, and Chris Malachowsky at a </span><a href="https://blogs.nvidia.com/blog/nvidia-dennys-trillion/" rel="">Denny’s</a><span> in 1993. There are triumphs and there are (near-fatal) disasters. </span></p><p>The disasters came early.</p><p>Nvidia’s very first design, the NV1 a graphics chip for the PC, was a story of a firm that had badly misjudged what its customers wanted. Put simply, they wanted to play ‘DOOM’ on their PCs and DOOM used VGA graphics:</p><blockquote><p>John Carmack, the game's designer and cofounder of its publisher, id Software. Carmack built the game using the 2-D Video Graphics Array (VGA) standard and leveraged every hardware-level trick he knew for maximum visual impact.</p></blockquote><p>but </p><blockquote><p>… the NV1 chip only partially supported VGA graphics and relied on a software emulator to supplement its VGA capabilities-which resulted in slow performance for gamers playing DOOM.</p></blockquote><p>With audio support for DOOM’s soundtrack that was arguably even worse, gamers shunned the NV1 in favor of one of Nvidia’s competitor’s products.</p><p>The company fared no better with its next product, the NV2 which was abandoned by Sega after a seemingly promising start.</p><p>Nvidia was now quickly running out of cash and had a track record of two failed products. Many CEOs would have been deterred and retreated into, likely fatal, caution.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg" width="1080" height="1080" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:531957,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F395af1e7-2bc8-4297-a2c5-02eeaac91db1_1080x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Nvidia’s RIVA 128 - By © Raimond Spekking / CC BY-SA 4.0 (via Wikimedia Commons), CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=53922955</figcaption></figure></div><p>Not Huang. Nvidia’s next product, the RIVA 128, would be even more ambitious and risky than its predecessors:</p><blockquote><p>"I wasn't worried about my cost," Jensen said years later, when asked to explain his decision-making process. "I built a chip that physically was as large as anyone could build at the time. We just wanted to make sure this is the most powerful chip the world's ever seen."</p></blockquote><p>And the bet wasn’t just on the size of the chip. The company also needed to take huge risks with its schedule:</p><blockquote><p>Given its financial position, Nvidia would have to make the RIVA 128 in record time, and without the safety net of multiple quality-assurance runs. Standard chip development usually spans two years, involving multiple revisions to identify and fix bugs after a chip "tape-out," when a finalized chip design is sent for prototype manufacturing. The NV1, for example, had three or four physical tape-outs. Nvidia could afford just one physical tape-out for the NV3 before the company had to send it to production.</p></blockquote><p>The answer was a novel and expensive machine that enabled the Nvidia team to emulate their new design in software. Using the machine was a painful process:</p><blockquote><p>The emulator did not produce any bug reports automatically. Instead, when a program froze, all Levin could do was take a screenshot and call over one of the hardware engineers to figure out what happened or where the corruption occurred. If it was a significant problem, the engineers would go back to redesign a part of the chip.</p></blockquote><p>But it enabled Nvidia to get the chip working, and to market, in record time. </p><p>Huang would later say that the RIVA 128 was a ‘miracle’. But he was determined to turn it into a repeatable miracle:</p><blockquote><p>“There's got to be a way to solve this problem of the design cycles.”</p></blockquote><p>The answer was again software, but this time running on Nvidia’s chips. Curtis Priem developed the idea of the ‘resource manager’ which was ‘a miniature operating system that sat on top of the hardware itself’:</p><blockquote><p>The resource manager allowed Nvidia's engineers to emulate certain hardware features that normally needed to be physically printed onto chip circuits. This involved a performance cost but accelerated the pace of innovation, because Nvidia's engineers could take more risks. If the new feature wasn't ready to work in the hardware, Nvidia could emulate it in software. At the same time, the engineers could take hardware features out when there was enough leftover computing power, saving chip die area.</p></blockquote><p>The approach gave Nvidia a decisive advantage. Rivals, including the once-market leader 3dfx, struggled to keep up. 3dfx made several mistakes and in 2002 Nvidia was able to buy its patents and other assets out of bankruptcy and hire around a hundred 3dfx employees.</p><p>Even in Nvidia’s early years, the characteristics that would form the foundation of its recent success were visible. The relentless execution, the risk-taking, and the way it combined hardware and software to give it a decisive advantage over its, perhaps more hardware-focused competitors, were all essential components in its later successes.</p><p>A few words about how ‘The Nvidia Way’ handles the most technology-intense parts of Nvidia’s story. Kim does a masterful job. Whilst accessible to the general reader, there is enough detail on Nvidia’s products and technologies to ensure that more technically oriented readers remain engaged.</p><p data-attrs="{&quot;url&quot;:&quot;https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>As ‘The Nvidia Way’ continues the second intertwined book comes to the fore. It’s a book that focuses on Nvidia’s culture and Huang and his approach to management.</p><p>Many aspects of Huang’s unique management style are now well known: his 60+ direct reports; the ‘top five’ emails; the long-hours culture; and the public way he gives negative feedback.</p><p>If you aspire to reproduce ‘Jensen’s Way’ then ‘The Nvidia Way’ might almost be read as a manual for his management style.</p><p>But you’ll probably run into several problems. The approach must be uniquely demanding, both for Huang and his wider Nvidia team. It must take unusual stamina to endure the intensity of the approach over several decades as Huang and several of his senior team have done.</p><p>Then, and it’s a cliche but here it’s true, Nvidia has been ‘an overnight success that has been thirty years in the making’. Huang might have benefited from the scale of the ‘AI boom’ launched by ChatGPT and other LLMs. But it’s taken thirty years to build a company with the characteristics that have made Nvidia uniquely well-positioned to cash in. Who else has the patience and resilience - or the opportunity - to shape an organization over many decades?</p><p>Still, there is more than enough material for readers to understand how Nvidia and Huang operate.</p><p>If ‘The Nvidia Way’ has a gap it’s on Nvidia’s recent corporate strategy. There is nothing on the attempted acquisition of CPU designer Arm. Why did Huang want Arm? What was his reaction to the takeover being thwarted? What is his relationship with Arm owner and Softbank CEO Masayoshi Son? We’ll have to wait for a second book on Nvidia for insights into each of these points and more.</p><p>Let’s return to two of the questions that we started with. How did Nvidia make itself essential to AI and was it luck or foresight?</p><p>Huang has admitted that he didn’t foresee the current LLM-focused AI boom. But Nvidia’s success isn’t luck either. The company positioned itself as the leader in massively parallel computing and ensured that its products were accessible to anyone who wanted to use those capabilities. That positioning has involved heavy investment over almost two decades.</p><p>And then, will Nvidia be able to maintain its lead? </p><p>Here there is a simple point to be made. As the book makes clear, Nvidia gained leadership in the brutally competitive graphics card market against numerous bigger competitors. It did so on the back of a culture that combined risk-taking with a relentless focus on execution. During its early years, it had no moat and often had limited financial resources.</p><p>Today, that culture seems to have largely endured under Huang’s leadership. It has built a strong moat around its ecosystem in the form of CUDA and it now has a scale and resources that no rival can remotely match. </p><p>In these circumstances, it would be brave to bet against Nvidia.</p><p>This takes us to one final question, which, as you read The Nvidia Way, comes to mind repeatedly. What will happen to Nvidia when Huang leaves? </p><p>Huang is 61 and seems as fit and energized by his job as he ever was. Morris Chang was 55 when he founded TSMC and finally retired as CEO at 86. I suspect that a lot will happen between now and Huang’s retirement. Perhaps it’s one question we can leave aside for a few years yet.</p><p data-attrs="{&quot;url&quot;:&quot;https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://thechipletter.substack.com/p/the-nvidia-way?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><strong>The Nvidia Way is highly recommended. It’s an outstanding book that provides a thorough overview of Nvidia’s history and culture whilst also being a great read.</strong></p><p><span>For readers who want more than the book, Tae Kim’s recent interview with </span></p><p><span> in Jon’s Asianometry Newsletter is terrific.</span></p><p><span>Author </span></p><p><span> himself is on Substack: </span></p><p>With links to more on the Nvidia way here:</p><p>Finally, if you like your history in podcast rather than book form, the Acquired team did a great job with their three-part history of Nvidia. The Acquired telling of the Nvidia story is, I think, highly complementary to Kim’s book as it focuses more on strategy than culture. The three parts (with transcripts) are linked below:</p><ul><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-gpu-company-1993-2006" rel="">Part 1: The GPU Company (1993-2006)</a></p></li><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-machine-learning-company-2006-2022" rel="">Part 2: The Machine Learning Company (2006-2022)</a></p></li><li><p><a href="https://www.acquired.fm/episodes/nvidia-the-dawn-of-the-ai-era" rel="">Part 3: Dawn of the AI Era (2022-2023)</a></p></li></ul><p><span>Plus a great </span><a href="https://www.acquired.fm/episodes/jensen-huang" rel="">interview</a><span> with Jensen Huang himself.</span></p><div id="youtube2-y6NfxiemvHg" data-attrs="{&quot;videoId&quot;:&quot;y6NfxiemvHg&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/y6NfxiemvHg?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Machine-Assisted Proof by Terence Tao [pdf] (175 pts)]]></title>
            <link>https://www.ams.org/notices/202501/rnoti-p6.pdf</link>
            <guid>42529023</guid>
            <pubDate>Sat, 28 Dec 2024 06:20:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ams.org/notices/202501/rnoti-p6.pdf">https://www.ams.org/notices/202501/rnoti-p6.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42529023">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to Cure Acid Reflux with Simple Exercise: An Anecdotal Study (141 pts)]]></title>
            <link>https://pmc.ncbi.nlm.nih.gov/articles/PMC9106553/</link>
            <guid>42528399</guid>
            <pubDate>Sat, 28 Dec 2024 03:48:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9106553/">https://pmc.ncbi.nlm.nih.gov/articles/PMC9106553/</a>, See on <a href="https://news.ycombinator.com/item?id=42528399">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><section id="abstract1"><h2>Abstract</h2>
<p>A novel exercise is described for resistance training of the lower esophageal sphincter. Resistance is provided by gravity as food is swallowed and pushed up an incline into the stomach. The incline is established by kneeling with the head bowed lower than the stomach. After several months of daily repetitions, symptoms of gastroesophageal reflux ceased and the exercise was discontinued without relapse.&nbsp;</p>
<section id="kwd-group1"><p><strong>Keywords:</strong> esophageal resistance training, lower esophageal sphincter, autobiographical case report, gastroesophageal reflux, eliminate gastroesophageal reflux</p></section></section><section id="sec1"><h2>Introduction</h2>
<p>Gastroesophageal reflux results from weakness or relaxation of the lower esophageal sphincter (LES) [<a href="#REF1" aria-describedby="REF1">1</a>]. Personal experience with this problem lead me to think about it, repeatedly. I came to entertain the hope that strengthening the LES might alleviate my reflux problem. Voluntary muscle can be strengthened by resistance training, but involuntary muscle like the LES characteristically cannot be strengthened in this manner. The esophagus, however, offers a special case. The swallowing process begins as a voluntary act which ultimately initiates a peristaltic wave of involuntary contractions through the smooth muscle in the lower two-thirds of the esophagus [<a href="#REF2" aria-describedby="REF2">2</a>].&nbsp;It occurred to me that that the LES might be strengthened if it were made to do a little extra work. The novel resistance training described here accomplishes this by requiring the LES to push food upward against gravity.</p></section><section id="sec2"><h2>Case presentation</h2>
<p>I had been experiencing gastroesophageal reflux for a number of years. The symptoms became dramatically worse immediately after an endoscopy in 2016 in which an inexplicably large biopsy (estimated to be 0.3 x 0.5 x 0.2 cm, but not actually measured in three dimensions) was taken from my esophagus to rule out Barrett’s Esophagus. Nonetheless, all of my symptoms were eventually substantially controlled with ranitidine (150 mg three times a day) and a bed wedge. The ranitidine was a minor nuisance, but even after several refinements, the bed wedge remained intolerable.</p>
<p>Eventually, I devised the following regimen with the intent of&nbsp;providing the LES with some resistance training. The resistance was provided by positioning my head below my stomach in a kneeling posture. This required food being swallowed to be pushed up an incline. I began eating part of each breakfast (oatmeal) and sometimes lunch (a sandwich) in the exercise position. I would kneel on a platform (which happened to be 6 ½” high), take a normal mouthful, chew it as needed, and prepare to swallow. I would then lay my forearms and the backs of my hands on the floor, rest my head on my hands, and complete the swallowing process. With a little practice, I was soon able to initiate and complete the swallowing process with my head resting on my hands on the floor. I did not attempt to determine what the optimal height of the platform might be or if, indeed, any was necessary.&nbsp;</p>
<p>Sixty-eight days after beginning daily LES exercises, I noticed that I could bend over at the hip and pull weeds in my garden without acid running into the back of my throat. This was not possible the previous year. I then tried sleeping without the bed wedge but found that it was still needed. I interpreted these observations to indicate that the LES was getting stronger, but still not strong enough. For about five more months I remained ambivalent as to whether the exercise would fully correct my problem and eventually sought help at the Cleveland Clinic. A 24-hour pH and manometry test was done, which yielded completely normal results. I then discontinued the use of the bed wedge and now have no symptoms that I can attribute to gastroesophageal reflux. I considered the possibility that a continuing training regimen might be necessary to maintain full LES function, so rather than risk a relapse, I continued to do the exercise a few times each week for a few months and then less frequently. I have not done the exercise at all for the past two years with no relapse.</p>
<p>My elimination of gastroesophageal reflux includes benefits beyond the ability to sleep comfortably on a horizontal surface. I can again do vehicle maintenance lying on my back with no esophageal discomfort. On one occasion I needed to do a minor repair to the gutter on my house in a location where the placement of a ladder was somewhat inconvenient. I was able to do the repair in about 10 minutes while lying prone looking downward near the edge of the sloping roof with no esophageal discomfort. Estimating from the pitch of the roof and my orientation with respect to the edge of the roof, my stomach was about two to three inches higher than my throat during this repair. These observations further attest to the restored competence of my LES.</p></section><section id="sec3"><h2>Discussion</h2>
<p>In retrospect, I probably should have tested sleeping without the bed wedge at intervals after I first noticed an improvement in LES function. But once I had determined that I no longer needed the bed wedge, I would probably never have gotten the pH and manometry test, and this report, were it to be made, would have been based entirely on my interpretation of symptoms.</p>
<p>These observations clearly constitute proof of the concept of the LES exercise. Hopefully, others will benefit from this exercise,&nbsp;and their experiences may become the basis of a standardized protocol for its use. Many details, which I simply guessed at, could be optimized by systematic study. The height of or need for a kneeling platform, the frequency and duration that constitute effective training sessions, and a time frame in which results may be expected might all be determined. The texture and amount of food being swallowed may have some significance. It also remains to be seen if any contraindications exist for the LES exercise. This exercise is probably quite safe for any otherwise healthy person, but anyone beginning this exercise should use reasonable caution while developing his or her technique so as to avoid any discomfort.</p></section><section id="sec4"><h2>Conclusions</h2>
<p>The resistance training exercise to strengthen the LES has many desirable attributes. It may eliminate the cause of gastroesophageal reflux rather than treat its symptoms and may well be a permanent solution to the problem. The exercise involves little or no risk or cost, and its use may be beneficial to many people.</p></section><section id="notes1"><p>The content published in Cureus is the result of clinical experience and/or research by independent individuals or organizations. Cureus is not responsible for the scientific accuracy or reliability of data or conclusions published herein. All content published within Cureus is intended only for educational, research and reference purposes. Additionally, articles published within Cureus should not be deemed a suitable substitute for the advice of a qualified health care professional. Do not disregard or avoid professional medical advice due to content published within Cureus.</p></section><div id="fn-group1"><p>The authors have declared that no competing interests exist.</p></div><section id="fn-group2"><h2>Human Ethics</h2>
<div><p>Consent was obtained or waived by all participants in this study</p></div></section><section id="ref-list1"><h2>References</h2>
<section id="ref-list1_sec2"><ul>
<li id="REF1">
<span>1.</span><cite>GERD (Chronic Acid Reflux)  [
Feb;
2022 
];<a href="https://my.clevelandclinic.org/health/diseases/17019-gerd-or-acid-reflux-or-heartburn-overview" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://my.clevelandclinic.org/health/diseases/17019-gerd-or-acid-reflux-or-heartburn-overview</a> 2022 </cite>
</li>
<li id="REF2">
<span>2.</span><cite>Anatomy and physiology of feeding and swallowing: normal and abnormal. Matsuo K, Palmer JB. Phys Med Rehabil Clin N Am. 2008;19:691–707. doi: 10.1016/j.pmr.2008.06.001.</cite> [<a href="https://doi.org/10.1016/j.pmr.2008.06.001" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2597750/">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18940636/">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Phys%20Med%20Rehabil%20Clin%20N%20Am&amp;title=Anatomy%20and%20physiology%20of%20feeding%20and%20swallowing:%20normal%20and%20abnormal&amp;volume=19&amp;publication_year=2008&amp;pages=691-707&amp;pmid=18940636&amp;doi=10.1016/j.pmr.2008.06.001&amp;" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ada's dependent types, and its types as a whole (216 pts)]]></title>
            <link>https://nytpu.com/gemlog/2024-12-27</link>
            <guid>42528302</guid>
            <pubDate>Sat, 28 Dec 2024 03:22:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nytpu.com/gemlog/2024-12-27">https://nytpu.com/gemlog/2024-12-27</a>, See on <a href="https://news.ycombinator.com/item?id=42528302">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
			
			<h3>December 27, 2024 (Updated: December 27, 2024)</h3>
			<!-- automatically generated by gemroff <https://git.sr.ht/~nytpu/gemroff/> -->
<p>So I like to joke occasionally on the Fediverse that when looking at Wikipedia's <a href="https://en.wikipedia.org/wiki/Dependent_type#Comparison_of_languages_with_dependent_types">list of programming languages supporting dependent types</a>:</p>
<blockquote>
<p>It's tons of extremely complex functional languages, formal theorem provers, and… Ada, a random Government Language dating back to 1983.</p>
<p>Also you'll note that at no point in any Ada documentation anywhere do they feel the need to bring up set theory or the λ cube when explaining how dependent types work :P</p>
</blockquote>
<p>I just love the juxtaposition of the highly formalized academic/research/for-fun languages with a very bureaucratic-feeling language whose design philosophy is very similar to COBOL's.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>
<p>But then I'll usually get one of a few functional programmers/type theory people that follow me to ask about Ada's dependent types, and this time I felt the motivation to write a big post explaining dependent types in Ada. And I really want to illustrate how how the designers were really just trying to achieve a specific goal, and coincidentally their solution meets the formal definition of dependent types.</p>
<p>Note that I'm really not knowledgeable about functional programming or type theory at all so I can't really speak much about it, although I am fairly skilled with Ada.</p>

<h2 id="adas-dependent-types">Ada's Dependent Types</h2>

<p>First-off, for context here's a very simplified summary of what I'm talking about since it is a rare feature: dependent types are just <q>types that depend on some concrete value</q>. So, for example, a structure with an array field whose length depends on another field in the struct—one of the primary applications of Ada's dependent types<sup id="fnref:2"><a href="#fn:2">2</a></sup>.</p>
<p>I also need to touch on one of Ada's design philosophies, which is to avoid dynamic allocation unless actually necessary for safety reasons, since it doesn't have a borrow checker for fully-safe allocation like Rust does<sup id="fnref:3"><a href="#fn:3">3</a></sup>. The key problem is that when you use one single call stack to both store return addresses and local variables, a called function can't return the contents of one of its stack-allocated variables <q>upwards</q> because the callee needs to be able to pop off the return address and have the stack pointer be precisely where it was before it got called. Instead, any larger-than-register returned value has to have its stack slots be allocated by the caller, <em>with a size known to the caller</em>. Ada solves this by having a second non-call stack<sup id="fnref:4"><a href="#fn:4">4</a></sup> that functions can allocate compile-time unknown space on and return that upward, without needing dynamic allocation and preserving the nice scoping and free lexical deallocation that a stack provides. The only time you really need dynamic allocation in Ada is when you're interworking with C/C++/Fortran/COBOL<sup id="fnref:5"><a href="#fn:5">5</a></sup>, or if you have an aggregate type that contains an object of unknown length, e.g. an array of strings, where you have to dynamically allocate all the strings and then the array of pointers can be handled like normal (Ada has a rich container library so it's rare you need to think about it at all). Allowing use of the second stack rather than dynamic allocation (i.e. avoiding needing a pointer elsewhere in order to encapsulate an undefined-length objects within another object) is a key motivator for one style of Ada's dependent types.</p>
<p><a href="https://nytpu.com/gemlog/2024-12-27-2">Here is an addendum detailing dynamic allocation and the secondary stack in much more detail.</a></p>

<p>And now an overview of Ada's type system because I feel them developing dependent types mostly-independently is really just a natural extension of its type system. If you're familiar with Ada already, I'm just going over basic derived types and subtypes, discriminated records, and type predicates. And tangentially things like indefinite types and how they work with subprograms and being nested in other aggregate types.</p>
<p>Firstly, Ada's type system was ahead of its time in 1983, in the sense that it's focused on modeling (and enforcing) the <em>intent</em> of the type, and letting the compiler do the work of mapping your intent to underlying machine types<sup id="fnref:6"><a href="#fn:6">6</a></sup>. So, for instance, while there is an <code>Integer</code> type that corresponds to some efficient machine integer like C's <code>int</code>, unless you need a generic integer you'd typically prefer to do something like this (this is probably not an ideal way to represent a social security number, it's just an example):</p>
<pre>type Social_Security_Number is range 0 .. 999_99_9999;
</pre>
<p>This is a completely new numeric type, but you could also make it derived type of <code>Integer</code> to allow well-defined type conversions, (although the conversions would require an explicit typecast since they're distinct but compatible types. To avoid needing explicit casts you'd use the <code>subtype</code> keyword instead of <code>type</code>).</p>
<p>As an extension of that, arrays allow using arbitrary integer types as their indices. They actually don't need to start at 0 or 1 or anything, they can use any bounds that make the most sense for your application (with the main caveat being that you have to use <code>Arr'First</code> &amp; <code>Arr'Last</code> or <code>Arr'Range,</code> rather than being able to just go from 0 to <code>Arr'Length - 1</code>). So, for instance, here's an array type:</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array_Constrained is array (My_Integer) of Whatever_Type;
</pre>
<p>Or, more concisely if the integer type isn't needed anywhere outside of the array type:</p>
<pre>type My_Array_Constrained is array (-20 .. 20) of Whatever_Type;
</pre>

<p>But that's fairly limiting, because instances of <code>My_Array</code> must always be exactly 41 elements long with bounds from -20 to 20. So you can make an array with bounds determined at instantiation instead of at the type declaration:</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array is array (My_Integer range &lt;&gt;) of Whatever_Type;
</pre>
<p><code>&lt;&gt;</code> is called <q>box</q> and is used all over Ada as a placeholder for some unknown thing (e.g. a placeholder type in generics). Any specific instance of <code>My_Array</code> can have arbitrary lower and upper bounds as long as they're contained within the range of <code>My_Integer</code>.</p>
<p>To use that type, you could make an instance like this:</p>
<pre>Arr_1 : My_Array(-15 .. -5);
Arr_2 : My_Array := (11 =&gt; 0, 12 =&gt; 1, 13 =&gt; 2, 14 =&gt; 3); -- implicitly determined length and bounds
</pre>
<p>It should be noted that while these instances are descendants of <code>My_Array</code>, they are still distinct types that are implicitly created on-the-fly, and are unnamed. You could declare it a new named type instead if you wanted:</p>
<pre>type My_Array_Constrained is new My_Array(-15 .. -5);
Arr_1 : My_Array_Constrained;
</pre>
<p>Both declarations of <code>Arr_1</code> are nearly equivalent, except the second one has a named type and could be easily assigned to another instance of <code>My_Array_Constrained</code> without explicitly copying slices of the same length.</p>
<p>And now we already technically have dependent types, because arrays with indefinite bounds can be created based off of a function parameter or other compile-time unknown value. For example (this is being excessively explicit about named types to prove it's true dependent typing):</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array is array (My_Integer range &lt;&gt;) of Integer;
subtype My_Length is My_Integer range 0 .. My_Integer'Last; -- Technically unnecessary

function Make_Array (Len : My_Length) return My_Array is
   -- Declarative area, where all of the local variables and types and nested
   -- functions and whatever would be declared

   -- Make a subtype using the provided length.  Will raise an exception if
   -- the upper bound is outside of the range of My_Integer.
   subtype Dynamically_Created_Array is My_Array(My_Integer'First .. My_Integer'First + Len);

   -- Create an instance of that subtype with all-zero contents.
   Arr : Dynamically_Created_Array := (others =&gt; 0);
begin
   -- Function body, where the procedural stuff is done.  Presumably we
   -- would do some processing here rather than just returning the array.
   -- Returning Dynamically_Created_Array is safe because it's a compatible
   -- subtype of My_Array.
   return Arr;
end Make_Array;
</pre>

<p>But of course there's more, what if you want to use <code>My_Array</code> inside of a record (Ada's term for a structure)? You could just have one of a fixed length of course:</p>
<pre>type My_Record_Constrained is record
   Field : My_Array(-15 .. -5);
end record;
</pre>
<p>And note that that Field's length can be computed at runtime if you need, just by using a function to compute one or both bounds instead of specifying literals. But all instances of <code>My_Record_Constrained</code> in the entire program would still have the same sized field that's only calculated once, at program startup<sup id="fnref:7"><a href="#fn:7">7</a></sup>.</p>
<p>It'd be really convenient to keep the flexibility to determine the size at instantiation time like we have with standalone arrays. So there's the concept of <q>discriminants</q>, which are like standard record fields but are treated specially and can be depended on by the types of normal fields of the record. For instance:</p>
<pre>type My_Record (Top : My_Integer) is record
   Field : My_Array(My_Integer'First .. Top);
end record;
</pre>
<p><code>My_Integer'First</code> gives the lowest valid value for the integer type. <code>Top</code> can be read like any other record field but you can't modify it after the type is instantiated since that would require reallocation and moving stuff around if there were fields before and after the discriminated array. You'd declare an instance like this to make <code>Rec.Field</code> have bounds from -20 to -5:</p>
<pre>Rec : My_Record(-5);
</pre>

<p>That example could be extended with a second discriminant to allow defining both the start and end bounds, etc. And there, that's it, that's also a dependent type! There is an implicit unnamed type that's recognized by the type system, that depends on a value at runtime. There's other things you can do rather than just using the discriminant as the length of an array. And you can do things like have an embedded record whose discriminant depends on a discriminant in the outer record and such. And there's also <q>variant records</q> which are just tagged unions where the tag (any signed/unsigned integer or enumeration type) is declared in the same place as the discriminant is above.</p>
<p>But Ada 2012 introduced even more capable dependent types as part of its <a href="https://en.wikipedia.org/wiki/Design_by_contract">design by contract system</a><sup id="fnref:8"><a href="#fn:8">8</a></sup>. Say you want to allow <code>My_Record</code> to specify both the lower and upper bounds as discriminants. Well, you can just do that, even though the instantiator could specify a lower bound that's greater than the upper bound, that's fine because in Ada that's just how you make an array with a length of 0. But say, in a contrived example, that you always want at least one element. You could add a type predicate, which is I think is somewhat analogous to what theorem provers would call <q>tactics</q>? You provide an expression acting on the value of the type and will be enforced as being true either at compile-time (for static predicates) or at runtime (for dynamic predicates). For example:</p>
<pre>type My_Record (Top, Bottom : My_Integer) is record
   Field : My_Array(Bottom .. Top);
end record
   with Dynamic_Predicate =&gt; Bottom &lt;= Top;
</pre>

<p>Or you could not use discriminants at all:</p>
<pre>type Pair is record
   A, B : Integer;
end record
   with Dynamic_Predicate =&gt; B &gt; A;
</pre>

<p>Type predicates and invariants (and also function pre/postconditions) are great for non-dependent type uses too, but that's getting too off-topic for this already plodding post. Although it is neat to be able to do things like</p>
<pre>type Even is new Integer
   with Dynamic_Predicate =&gt; Even mod 2 = 0;
</pre>
<pre>type Day_Of_Week is (Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday);
subtype Weekday is Day_Of_Week range Monday .. Friday;
-- Filthy Americans creating this problem for themselves
subtype Weekend is Day_Of_Week
   with Static_Predicate =&gt; Weekend in Saturday | Sunday;
</pre>


<h2 id="the-strange-interplay-between-academic-languages-and-business-languages">The Strange Interplay Between “Academic Languages” and “Business Languages”</h2>

<p>Something I find very interesting is that there's a strange interplay between a very get-things-done oriented language like SPARK (the formally verified subset of Ada) which wants to verify correctness in a program, and functional programming theory that provides ways to reason about the correctness of programs. And yet functional programming languages themselves nor the theory directly isn't suited for what SPARK does, because they prefer purity and usefulness <em>for developing the theory further</em> over things like allowing side-effects in a way that doesn't confuse imperative programmers (*cough*​monads​*cough*) or the compiled code being efficient enough for low-power embedded targets.</p>
<p>Note that I'm not implying that functional programming languages can't <q>get things done</q>, they just tend to be focused on different goals than Ada and SPARK are. Because if you're interested in the theory why would you care about the small set of high-integrity embedded developers over being able to express what you need to in the most natural way possible? And similarly, SPARK had concrete requirements for a specific set of tasks different from what academics want, and it just happened that theorem provers and FP theory can be applied to those problems to great effect.</p>
<p>I feel somewhat like this with Ada as a whole. Really, lots of its type system often stumbles across interesting concepts in type theory, but just from them reaching for some goal of correctness or flexibility rather than because of actual type theory. Although I haven't had more than a casual IRC chat with any of the standardizers so maybe they did actually get their ideas directly from type theory and just fit them into a non-academic language, rather than stumbling across the concept like I hypothesize here.</p>
<ol>
<li id="fn:1" value="1"><p>Like, Ada's entire design is basically the U.S. DoD making a <a href="https://en.wikisource.org/wiki/Steelman_language_requirements">list of requirements that they considered mandatory for a high-integrity, embedded programming language</a>, and then paying government contractors to design a language meeting those requirements, without caring if it's <q>fun</q> or <q>breaking new ground</q> or <q>mathematical purity</q>. Not that that's necessarily a good design philosophy, it just makes the language very different from many; and is what reminds me of COBOL which was made similarly: businesses designing a language to their requirements without regard for any of the things academic computer scientists of the time cared about. <a href="#fnref:1">↩︎</a></p></li>
<li id="fn:2" value="2"><p>And a natural extension of C's flexible array members if their length was enforced to match to the field in the struct storing it. <a href="#fnref:2">↩︎</a></p></li>
<li id="fn:3" value="3"><p>SPARK, the formally verified subset of Ada, does have a borrow checker though! <a href="#fnref:3">↩︎</a></p></li>
<li id="fn:4" value="4"><p><a href="https://gcc.gnu.org/git/?p=gcc.git;a=blob;f=gcc/ada/libgnat/s-secsta.adb;hb=HEAD#l39">Comments in the GCC GNAT source code</a> and some <a href="https://docs.adacore.com/gnat_ugx-docs/html/gnat_ugx/gnat_ugx/the_stacks.html#the-secondary-stack">documentation on configuring the second stack for embedded targets</a> is the only real documentation on how the second stack works in detail that I know of. Probably because while I consider it a brilliant solution, the secondary stack is actually an implementation detail and the standard just mandates <q>you have to be able to return indefinite types</q>. An implementation could in theory dynamically allocate and insert malloc and free calls appropriately in the caller and callee code. <a href="#fnref:4">↩︎</a></p></li>
<li id="fn:5" value="5"><p>The Ada specification has official, albeit optional-to-implement, APIs for interfacing with all of those languages lol <a href="#fnref:5">↩︎</a></p></li>
<li id="fn:6" value="6"><p>Not relevant to the point I'm making in this post, but if in a given application you do care about the machine types, there is a whole featureset of <q>representation clauses</q> that allow you to very precisely state the underlying size and layout of a primitive type, array, or structure/record. The compiler will generate the required bit-shifts and masks for you when reading or writing fields of an object of that type, and the specified representation is always how it's stored in memory and doesn't need a separate (de)serialization step, making it convenient for memory-mapped I/O (since Ada also lets you specify the precise address of a variable without needing pointers or poking the linker directly).</p>
<p>These features, amongst a few others similarly intended for easy low-level programming, are actually the main reason I personally use Ada since their convenience and simplicity is unmatched in any other programming language in existence AFAIK. <a href="#fnref:6">↩︎</a></p></li>
<li id="fn:7" value="7"><p>To be precise: it is calculated when the <q>elaboration code</q> for the package containing that type is called, which is typically but not always at program startup or when dlopened; but may be at any point prior to the containing package or any dependent package being used. The precise point and order in which elaboration is performed is determined by the <q>binder</q> and may be delayed from program startup if the main() is overridden to be a program in some other language rather than the entrypoint emitted by the binder. <a href="#fnref:7">↩︎</a></p></li>
<li id="fn:8" value="8"><p>The other main thing that I love about the language <a href="#fnref:8">↩︎</a></p></li>
</ol>
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PCIe trouble with 4TB Crucial T500 NVMe SSD for >1 power cycle on MSI PRO X670-P (144 pts)]]></title>
            <link>https://forum.level1techs.com/t/bizarre-pcie-trouble-with-4tb-crucial-t500-nvme-ssd/222915</link>
            <guid>42528216</guid>
            <pubDate>Sat, 28 Dec 2024 03:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.level1techs.com/t/bizarre-pcie-trouble-with-4tb-crucial-t500-nvme-ssd/222915">https://forum.level1techs.com/t/bizarre-pcie-trouble-with-4tb-crucial-t500-nvme-ssd/222915</a>, See on <a href="https://news.ycombinator.com/item?id=42528216">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="Bizarre PCIe trouble with 4TB Crucial T500 NVMe SSD">
      
      <meta itemprop="datePublished" content="2024-12-27T06:53:23Z">
        <meta itemprop="articleSection" content="Storage">
      <meta itemprop="keywords" content="">
      


          <div id="post_1">
            <div>
              


              <p><span>
                  <time datetime="2024-12-27T06:53:23Z">
                    December 27, 2024,  6:53am
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T11:15:21Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>So I just got this drive, and it has worked flawlessly in every other system I’ve tried it in, including my ancient Skylake testbench board.</p>
<p>I have an MSI PRO X670-P WIFI, which while otherwise working fine, including with other NVMe drives, is displaying a truly bizarre behavior with this particular drive.</p>
<p>And yes, I’ve just swapped out the CPU with a brand new one and the behavior is unchanged, so this isn’t some CPU PCIe circuitry degradation or something.</p>
<p>When I install this drive, in <em>any</em> M.2 slot on the board, it will work <em>flawlessly</em> for exactly <em>one</em> power cycle. I can reboot, I can hit the reset switch, the drive works just fine.</p>
<p>Until I turn off the machine. After that has been done, the drive will never ever detect ever again. Until I physically remove and reinstall the drive, then it works completely perfectly for exactly one power cycle.</p>
<p>What the eff? This screams BIOS issue to me, though MSI just blames the SSD.</p>
<p>I have a working Linux/SystemRescueCD environment on the machine, so if any PCIe geniuses here have any ideas, I’m all ears.</p>
<p>I’ve compared lspci outputs in three states - ‘not installed’, ‘installed and working’, and ‘installed and not working’. The ‘installed and not working’ outputs are absolutely identical to the ‘not installed’ outputs. The relevant host bridge registers are exactly the same between ‘installed and working’ and ‘installed and not working’.</p>
            </div>

            

            

          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://forum.level1techs.com/u/skyhawk"><span itemprop="name">skyhawk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-12-27T06:54:41Z">
                    December 27, 2024,  6:54am
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T06:56:27Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>lspci tree outputs<br>
<a href="https://forum.level1techs.com/uploads/short-url/iNfGpa2xEnvScEmUrAkCsZpBk3.txt">broken-tree.txt</a> (3.4 KB)<br>
<a href="https://forum.level1techs.com/uploads/short-url/8Ra21LCEBh3HbErSFY1Tcdbc8QT.txt">working-tree.txt</a> (3.5 KB)</p>
<p>lspci -vvv outputs<br>
<a href="https://forum.level1techs.com/uploads/short-url/xFGpNGF7HEcB2ivJW8IhjhG50oO.txt">broken-details.txt</a> (161.1 KB)<br>
<a href="https://forum.level1techs.com/uploads/short-url/7dbQZ2EuSI1ZP3TYFjNkDLgaM0y.txt">working-details.txt</a> (170.3 KB)</p>
            </div>

            

            

          </div>
          <div itemprop="comment" id="post_3" itemscope="" itemtype="http://schema.org/Comment">
              
<p>Does it reset to working again if, rather than removing the drive, you switch the PSU off/pull the plug for a while? I.e. is it the complete loss of power that makes it work again?</p>
<p>Or do you have to boot the computer without the drive installed once before it starts working again after reinstall?</p>
<p>If the latter it clearly points to an UEFI bug IMO. Otherwise, it’s perhaps more difficult to say where the problem is? Either way, bizzare, as you say!</p>
            </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://forum.level1techs.com/u/skyhawk"><span itemprop="name">skyhawk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-12-27T10:04:41Z">
                    December 27, 2024, 10:04am
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T10:04:41Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Nope. From a not-working state, just turning the machine off, pulling the drive and plugging it back in is all that’s needed to return to working order. For one power cycle.</p>
            </div>

            

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://forum.level1techs.com/u/skyhawk"><span itemprop="name">skyhawk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-12-27T10:08:01Z">
                    December 27, 2024, 10:08am
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T11:08:54Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>I started following this line of thought by pulling the BIOS button cell and disconnecting the ATX power supply, but this board seems to have some quite considerable capacitance somewhere. I was quite surprised to measure 1.9V across some of the pins on the ATX plug in this state.</p>
<p>I think my KVM switch was supplying some kind of voltage to the board via the HDMI and USB plugs. Once I disconnected those these phantom voltages went away, and the board was completely inert. I then reconnected the PSU and KVM, and the SSD works. (For one power cycle)</p>
<p>Is this some kind of phantom voltage keeping the SSD with just enough voltage to crash the controller, but not low enough to trigger a reset signal of some kind?</p>
<p>I think this line of inquiry is going somewhere. After shutting down the computer, ensuring the coin cell is not present, and disconnecting the 24pin ATX and 8-pin ATX12V for the CPU, there’s 1.9V consistently present on the 3.3V pins on the 24-pin ATX socket (Ergo all the 3.3v logic and devices on the board are getting 1.9V, unless my understanding is off) until I disconnect the HDMI cable from my KVM, at which point it almost instantly goes to zero.</p>
<p>Plugging the HDMI cable back in does not restore the 1.9V - The 3.3v line remains at zero… Is disconnecting the HDMI cable between power cycles all that’s needed here?</p>
<p>Yes. Yes it is. And the fault isn’t limited to my KVM. I took the KVM out of the picture and just connected my HP ZR24w monitor (via DVI-&gt;HDMI adapter) directly to the HDMI socket on the motherboard, and the issue persists. The issue does <em>not</em> occur when the monitor is connected via DisplayPort.</p>
<p>I’d be really curious to know if my board is somehow defective, or if MSI made an oopsie on this design? Hilariously, if I <em>wasn’t</em> simplifying for troubleshooting by relying on the integrated graphics instead of an add-on board, this problem would not have occurred.</p>
            </div>

            

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://forum.level1techs.com/u/fDrot"><span itemprop="name">fDrot</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-12-27T13:20:32Z">
                    December 27, 2024,  1:20pm
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T13:20:32Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <p>I suspect a problem with BIOS. Might sound stupid, but do you have the latest BIOS version?</p>

            

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://forum.level1techs.com/u/skyhawk"><span itemprop="name">skyhawk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2024-12-27T19:42:01Z">
                    December 27, 2024,  7:42pm
                  </time>
                  <meta itemprop="dateModified" content="2024-12-27T19:42:01Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>I’ve tried several recent BIOSes, none of them have made any difference. This seems like an electrical design fault on the board, they’ve got some transistor that NPNs when it should have PNPd when the board is turned off, or something.</p>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Carlsen disqualified from World Rapid and Blitz championship for wearing jeans (183 pts)]]></title>
            <link>https://www.timesnownews.com/sports/magnus-carlsen-disqualified-from-world-rapid-and-blitz-championship-for-wearing-jeans-article-116727852</link>
            <guid>42527572</guid>
            <pubDate>Sat, 28 Dec 2024 00:54:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.timesnownews.com/sports/magnus-carlsen-disqualified-from-world-rapid-and-blitz-championship-for-wearing-jeans-article-116727852">https://www.timesnownews.com/sports/magnus-carlsen-disqualified-from-world-rapid-and-blitz-championship-for-wearing-jeans-article-116727852</a>, See on <a href="https://news.ycombinator.com/item?id=42527572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="progressBarContainer_0" data-msid="116727852"><div><div><p><img loading="lazy" src="https://static.tnn.in/authorthumb/479257188.cms?width=70&amp;height=70&amp;quality=100" alt="author-479257188" title="author-479257188" onerror="this.onerror=null;this.src='https://www.timesnownews.com/assets/icons/svg/user.jpg';"></p></div><div><p>Updated Dec 28, 2024, 05:45 IST</p></div></div><div><p><h2>Magnus Carlsen was disqualified from the World Rapid and Blitz Championship for violating the FIDE dress code and wearing jeans. The chess legend said that he was 'tired' of FIDE and revealed that he was asked to change his jeans.<!-- --> <span id="read_more_toggle">Read More</span></h2></p></div><div><p><img src="https://static.tnn.in/thumb/msid-88386381,width-448,height-252,resizemode-75/88386381.jpg" data-src="https://static.tnn.in/thumb/msid-116727854,thumbsize-1810069,width-448,height-252,resizemode-75/116727854.jpg" data-width="450" data-height="254" width="450" height="254" data-placeholder="https://static.tnn.in/thumb/msid-88386381,width-448,height-252,resizemode-75/88386381.jpg" alt="Magnus Carlsen" title="Magnus Carlsen"></p></div><div><p>Magnus Carlsen was disqualified for violating dress code. Photo: FIDE</p></div><div><p><span>Magnus Carlsen</span> was disqualified from the <span>World Rapid and Blitz Championship</span> for violating the <span>FIDE</span> dress code and wearing jeans. Carlsen, who entered the tournament as the defending champion, broke his silence minutes after being disqualified and said that he was 'tired' of FIDE. "I am pretty tired of FIDE, so I want no more of this. I don’t want anything to do with them. I am sorry to everyone at home, maybe it’s a stupid principle, but I don’t think it’s any fun," Carlsen told NRK broadcasting company.</p></div><div><p>The World Rapid and Blitz Championship is taking place in New York. "I said I will change tomorrow but they said you have to change now &amp; it became a matter of principle for me so here we are! Honestly, I’m too old at this point to care too much. If this is what they want to do I” ll probably set off to somewhere where the weather is a bit nicer," the <span>chess</span> legend told Take Take Take.</p></div><div><p>"FIDE regulations for the World Rapid and Blitz Chess Championships, including the dress code, are designed to ensure professionalism and fairness for all participants," FIDE said in its statement.</p></div><div><p>"Today, Mr. Magnus Carlsen breached the dress code by wearing jeans, which are explicitly prohibited under long-standing regulations for this event. The Chief Arbiter informed Mr. Carlsen of the breach, issued a $200 fine, and requested that he change his attire. Unfortunately, Mr. Carlsen declined, and as a result, he was not paired for round nine. This decision was made impartially and applies equally to all players.</p></div><div><p>Earlier in the day, another participant, Mr. Ian Nepomniachtchi, was also fined for breaching the dress code by wearing sports shoes. However, Mr. Nepomniachtchi complied, changed into approved attire, and continued to play in the tournament," the statement added.</p></div><div><p>Get <a href="https://www.timesnownews.com/latest-news">Latest News</a> Live on Times Now along with Breaking News and Top Headlines from <a href="https://www.timesnownews.com/sports">Sports</a> and around the world.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Liberating Wi-Fi on the ESP32 [video] (298 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32</link>
            <guid>42527265</guid>
            <pubDate>Sat, 28 Dec 2024 00:03:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32">https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32</a>, See on <a href="https://news.ycombinator.com/item?id=42527265">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
<ol>
<li>
<a href="https://media.ccc.de/b">
browse
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress">
congress
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress/2024">
2024
</a>
</li>
<li>
<span></span>
event
</li>
</ol>
</div>

<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Frostie314159">Frostie314159</a> and
<a href="https://media.ccc.de/search?p=Jasper+Devreker">Jasper Devreker</a>

</p>

<p><a href="https://media.ccc.de/c/38c3/2024" rel="tag">2024</a>
<a href="https://media.ccc.de/c/38c3/Saal%201" rel="tag">Saal 1</a>
Playlists:
<a href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32/playlist">'38c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32/audio">audio</a></p>
<!-- %h3 About -->
<p>Reverse engineering the Wi-Fi peripheral of the ESP32 to build an open source Wi-Fi stack.</p>

<p>During the 38c3, there are probably multiple thousands of ESP32s in the CCH, all of which run a closed source Wi-Fi stack.  And while that stack works, it would be nicer to have an open source stack, which would grant us the ability to modify and audit the software, which carries potentially sensitive data.</p>

<p>So we set to work, reverse engineering the proprietary stack and building a new open source one. We soon discovered just how versatile the ESP32 can be, both as a tool for research and IoT SoC, when its capabilities are fully unlocked. This includes using it as a pentesting tool, a B.A.T.M.A.N. mesh router or an AirDrop client.</p>

<p>You'll learn something about Wi-Fi, the ESP32, reverse engineering in general and how to approach such a project.</p>

<p>Licensed to the public under http://creativecommons.org/licenses/by/4.0</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>

</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]></description>
        </item>
    </channel>
</rss>