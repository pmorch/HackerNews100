<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 06 Feb 2024 14:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Destruction of nuclear bombs using ultra-high energy neutrino beam (2003) [pdf] (123 pts)]]></title>
            <link>https://arxiv.org/pdf/hep-ph/0305062.pdf</link>
            <guid>39271472</guid>
            <pubDate>Tue, 06 Feb 2024 06:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/pdf/hep-ph/0305062.pdf">https://arxiv.org/pdf/hep-ph/0305062.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39271472">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OKRs Are Bullshit (236 pts)]]></title>
            <link>https://blog.appliedcomputing.io/p/okrs-are-bullshit</link>
            <guid>39271083</guid>
            <pubDate>Tue, 06 Feb 2024 05:25:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.appliedcomputing.io/p/okrs-are-bullshit">https://blog.appliedcomputing.io/p/okrs-are-bullshit</a>, See on <a href="https://news.ycombinator.com/item?id=39271083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg" width="735" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:735,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:72261,&quot;alt&quot;:&quot;Buzz and Woody meme; Buzz says \&quot;OKRs!  OKRs are everywhere!\&quot; and Woody looks terrified&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Buzz and Woody meme; Buzz says &quot;OKRs!  OKRs are everywhere!&quot; and Woody looks terrified" title="Buzz and Woody meme; Buzz says &quot;OKRs!  OKRs are everywhere!&quot; and Woody looks terrified" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbef1a329-3d3f-46fb-9d49-48ce38035415_735x500.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>It's a new year, time for a new rant</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-1-141320305" target="_self" rel="">1</a></span><span>! And yes, before you ask, the post title is deliberately provocative. You might say this is my ploy to get more paid subscribers, because only paid subscribers can leave comments and I expect that the title alone will make many of you want to comment. üòù</span></p><p><span>Anyways, I expect that many of my readers just finished up their quarterly (and/or yearly) planning cycle, so I thought this would be a good time to remind you all that the process we've all settled on in the tech industry is nonsense: I am, of course, referring to the </span><a href="https://en.wikipedia.org/wiki/Objectives_and_key_results" rel="">Objectives and Key Results</a><span> framework. So let's talk about OKRs, what they are and where they come from, and why they're a terrible idea</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-2-141320305" target="_self" rel="">2</a></span><span>.</span></p><p>The OKR framework was originally developed by Google back in‚Äî</p><p>Wait a minute, I just read the Wikipedia article I linked in the previous section, and it turns out I'm starting this off not only by being rude, but also spreading misinformation! How could I. Let's try this again.</p><p><span>OKRs were introduced by Andrew Grove at Intel, all the way back in the 1970s! He wrote about them in a book on management in 1983, and later they were introduced at Google, I guess sometime in the early 2000s. And while Google didn't </span><em>invent</em><span> the concept of OKRs, Google certainly helped popularize them</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-3-141320305" target="_self" rel="">3</a></span><span>. Now it doesn't matter where you go, every company has OKRs. The term has become like "Kleenex"‚Äîit's used ubiquitously to mean "planning", regardless of how similar or not the planning process actually is to the original OKR framework</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-4-141320305" target="_self" rel="">4</a></span><span>.</span></p><p><span>So with the backstory out of the way, what </span><em>are</em><span> OKRs? In short, they're a way of goal-setting and then measuring your progress towards the goals. The "Objective" is your goal, and the "Key Results" are the things you need to accomplish to know whether you've hit your goal. Of course because we want to be data-driven organizations, the key results need to be measurable and metrics-based.</span></p><p>Typically, OKRs are supposed to be cascading. In other words, the CEO (or whoever's in charge) sets some OKRs for the organization as a whole, and then the individual business units set OKRs that support the global OKRs, and then each team sets OKRs that support the business unit's, and (potentially) each team member sets their own personal OKRs. At each level, you should have between one and three objectives, which are short statements about "what" you want to accomplish in the next quarter, or year, or whatever, and each objective should have between one and three key results which indicate the success or failure of the objective.</p><p><span>In addition to the core framework, there are a few guiding principles that organizations should use when setting OKRs. Most (in)famously, you should set your OKRs so you only achieve 70% of them. If you're consistently hitting 100% on your goals, that means you're not being ambitious enough. Secondly, you should avoid "binary" OKRs, that is, OKRs whose only metric is "I did the thing" or "I didn't do the thing". Thirdly, OKRs aren't supposed to encompass all of your organization's activities: normal, day-to-day maintenance work, on-call support, etc. are "extra" things that don't get captured by your OKRs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-5-141320305" target="_self" rel="">5</a></span><span>. And lastly, the only way to learn OKRs is by doing OKRs.</span></p><p><span>Now, some of you are all prepared to whip out your credit cards and subscribe so you that you can angrily tell me that I've got it all wrong and that I don't understand the framework at all. That's fine‚ÄîI'm happy to have you as a subscriber, but I think gets at my fundamental complaint about the OKR framework: if the "only way to learn OKRs is by doing OKRs", then by definition everybody is gonna do OKRs differently, which means that in practice the framework becomes whatever you want it to become. But then, when anybody comes out with </span><em>any</em><span> criticism of the OKR process, the response is always, in classic "</span><a href="https://en.wikipedia.org/wiki/No_true_Scotsman" rel="">no true Scotsman</a><span>" style, "well, you're just not doing OKRs correctly." But I guess my question is: if nobody in the industry does OKRs "correctly", why are we still trying to do them at all?</span></p><p><span>Now look: I'm not arguing that we shouldn't have goals. I'm not arguing that we shouldn't make plans and try to hold ourselves accountable to those plans. We absolutely should! Engineers like to rage against process, bureaucracy, and friction, but I'll be the first to tell you that‚Äîespecially in larger organizations‚Äî</span><em>some</em><span> process is important. My only point in this article is to hopefully convince you that OKRs ain't it.</span></p><p>So let's talk about the problems with OKRs. I want to preface this section by saying that my background is an infra engineer, and a lot of the points I make come from that perspective. But I've heard enough similar complaints from product people that I think my objections are valid in that setting as well.</p><p><span>First of all, let's start with the frankly ridiculous claim that you should target 70% completion for your OKRs. Setting aside the fact that this is very nebulous (should you complete 70% of your goals to 100%? Or should you complete 100% of your goals at 70%?) consider that much of the work we do doesn't actually have any value unless you do it </span><em>all the way</em><span>. Now maybe if your key result was "increase clickthrough rate by 100%" and you only increased it by 70%, you could argue that is still pretty good. But if your key result is "migrate 100% of users to the new system" and you only migrate 70%, guess what? Now you're stuck maintaining two systems in perpetuity. Fortunately, I haven't heard people espouse this tenet as much lately‚ÄîI think people are realizing that it incentivizes the wrong things.</span></p><p><span>But this leads us straight into the second problem with OKRs: actually measuring things. Some people might argue that the migration example I used above is actually bad because it's a binary OKR‚Äîeither you migrated or you didn't. This leads to all kinds of contortions to develop a metric that still says "I migrated the thing" but isn't binary. Maybe you interview your customers and you want 100% of them to be happy on the new thing, but you'll count it as a success if only 70% of them are happy. Or maybe you measure the number of outages caused by the new thing, and your goal is "zero outages"</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-6-141320305" target="_self" rel="">6</a></span><span>.</span></p><p><span>However, there are additional problems here: one is that you just invented a bunch of extra work for yourself, because chances are whatever metric you concocted to measure your migration success didn't exist before: so you have to go build some tooling to collect the metric before you can even start working on the actual thing you care about‚Äîtooling and metrics that will probably languish and be forgotten about in a quarter or two after priorities change. Another is that often, the metrics you invent have no relation to the work you're doing‚Äîthe happiness (or not) of your users probably has between five and zero percent to do with how good a job you did on the migration, and is 90% related to whether or not the new system was well-designed by somebody else who probably isn't even at the company anymore. A third is that some of these metrics are really hard to reason about. For example, in the "number of outages" metric, your target value is 0, which means that if you have </span><em>any outages at all</em><span> your score for that key result is undefined. You have to divide the number of outages you had by zero to get your percentage. Congratulations! Your metric value is whatever you want it to be!</span></p><p><span>I think the biggest problem with OKR's laser focus on measurement, though, is that </span><em>not everything should be measured</em><span>, even if you can! Being "data-driven" is a huge buzzword in the industry. We want to improve, we want to see how much we improved by, and then we want to tell the world how much we improved by so our stock price goes up. But there's a tremendous amount of work that shouldn't or can't be measured, or is very easy to misinterpret even if you </span><em>can</em><span> measure it. I think this article by Richard Marmorstein sums it up really nicely: </span><a href="https://twitchard.github.io/posts/2022-08-26-metrics-schmetrics.html" rel="">be good-argument driven, not data-driven</a><span>. Being data-driven requires a) that you have the metrics, b) that you know enough statistics to interpret the metrics correctly, and c) that you don't care about anything that can't be measured.</span></p><p>The last complaint I have about OKRs comes from their cascading nature. As an industry, we mostly rejected waterfall-style development a long time ago, and then promptly introduced a planning framework that encourages waterfall-style development. There's no room in the OKR framework for research or experimentation (because how do you measure research?), so you have to know what you want to do in excruciating detail at the point when you write down your OKR, because otherwise something might come up that prevents you from completing (or even getting 70%) on your OKR. But raise your hand if you've ever written down all your OKRs and then two months into the cycle, something comes up that obsoletes all of your goals.</p><p><span>"But wait, you're just doing it wrong!" I can hear you exclaim from here. "You're supposed to be agile! OKRs can change! You should react to new information!" Right, yep, I've heard that one before. But I can guarantee you that come performance review time, the people who decide whether you're being successful or not as an engineer are going to grade you on your original goals for the year, and if you have to change them it's going to be viewed as a failure. I mean, maybe this doesn't happen </span><em>everywhere</em><span>, but it will require a significant amount of cultural backpressure to prevent this outcome. So maybe just let's use a planning process that actually has room for change built in, instead of trying to shoehorn in one that just doesn't work.</span></p><p>You know what I didn't talk about at all in this blog post? Spreadsheets. Nowhere in the OKR framework does it say that you should list all your objectives and key results in a spreadsheet, and then check in on the metrics every month by updating some values in the spreadsheet. Nobody ever said that you should have a JIRA epic for your objectives, and then track all your tickets by which OKR they belong to. Nobody ever said anything about "internal OKRs" versus "external OKRs" or roadmaps or planning meetings or‚Ä¶ the list goes on.</p><p><span>And yet, my prediction is that every single manager in existence, as soon as they hear ‚ÄúOKR‚Äù will immediately think "spreadsheet"</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-7-141320305" target="_self" rel="">7</a></span><span>. And I think that's a problem too. See, as an industry, we've conflated "OKRs" with "planning", when I don't think they should be conflated at all. Even if you brush aside all the problems I pointed out with OKRs in the previous section, and go back to the original (or at least, "original" as "made popular by Google") definition, the purpose of OKRs is to be aspirational. That's where the whole 70% thing comes from in the first place. We want to set hard goals that will inspire people to do their best work, and then recognize that the goals were hard and not penalize people for failing to meet them 100% of the way.</span></p><p><span>And honestly? When taken through that lens, I love OKRs</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-141320305" href="https://blog.appliedcomputing.io/p/okrs-are-bullshit#footnote-8-141320305" target="_self" rel="">8</a></span><span>! We </span><em>should</em><span> be trying to do hard things, and we shouldn't be punishing folks when they fail at them. And, also: we </span><em>should</em><span> have a plan, and we should understand the work that we're going to be doing over the next few weeks-to-months, and </span><em>maybe</em><span> we need a spreadsheet or something to help manage that plan. But please, for the love of god, let's stop trying to shove metrics into our goal-setting framework, let's stop shoving our goal-setting framework into our quarterly planning process, and let's stop spending months on end planning only to have the whole thing upended two days into the cycle.</span></p><p>Anyways, that's all I've got for now. I promise next week I'll be less inflammatory.</p><p>Thanks for reading,</p><p>~drmorr</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LineageOS is currently installed on 1.5M Android devices (193 pts)]]></title>
            <link>https://9to5google.com/2023/11/20/lineageos-number-of-devices/</link>
            <guid>39270215</guid>
            <pubDate>Tue, 06 Feb 2024 02:54:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2023/11/20/lineageos-number-of-devices/">https://9to5google.com/2023/11/20/lineageos-number-of-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=39270215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?quality=82&amp;strip=all&amp;w=1250" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/Lineage-OS-20-setup.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1250" height="625" alt="" fetchpriority="high">
	
	</figure>

<p>The custom ROM scene for Android devices isn‚Äôt nearly what it once was, but down to today, 1.5 million devices are currently running on LineageOS.</p>



<p>LineageOS is the project that took up the work of the once-great CyanogenMod, with the custom ROM having debuted its first builds back in 2016 and still running down to today. LineageOS is available on a <a href="https://wiki.lineageos.org/devices/">variety of different devices</a> from different Android brands, including Google, Fairphone, Samsung, OnePlus, Xiaomi, and more. It even keeps some long-gone brands going, like Essential and LG.</p>



<p>But how popular is LineageOS <em>really</em>?</p>



<p>That‚Äôs a question we have an answer to, thanks to a recent podcast episode.</p>



<p>David Imel of MKBHD‚Äôs WVFRM podcast sat down with members of the LineageOS team recently in a special episode, which went over the history of custom ROMs on Android. The episode is a great watch/listen, but <a href="https://youtu.be/TDOMekBPR4U?t=5107">one stat</a> in particular that caught our attention was that LineageOS is currently installed on around 1.5 million devices. There‚Äôs no word on how active those devices are, what they consist of, or how many different users that entails, but it‚Äôs the first look we‚Äôve had in a while into how popular LineageOS actually is in a world where ROMs just aren‚Äôt as popular or necessary as they once were.</p>



<p>You can tune into <a href="https://youtu.be/TDOMekBPR4U">the full episode</a> below. </p>



<figure><p>
<iframe id="post-youtube-video-1" title="CyanogenMod and the Death of the Android ROM" width="500" height="281" data-src="https://www.youtube.com/embed/TDOMekBPR4U?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<h2 id="h-more-on-android">More on Android:</h2>



<ul>
<li><a href="https://9to5google.com/2023/07/27/pixel-tablet-lineageos-20/">Google Pixel Tablet gets support for LineageOS</a></li>



<li><a href="https://9to5google.com/2023/11/19/android-iphone-bullying-rcs/">Will RCS be enough to end the Android vs iPhone peer pressure and bullying?</a></li>



<li><a href="https://9to5google.com/2023/11/17/link-to-windows-oneplus-oppo-realme/">Link to Windows on PC now compatible with OnePlus, Oppo, and Realme phones</a></li>
</ul>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/3SWmaVQ"><img src="https://9to5google.com/wp-content/uploads/sites/4/2023/11/ROBOROCK-BF-BANNER-on-all-3-sites-Nov-20-26-750x150-1.jpg?quality=82&amp;strip=all" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla's Abandoned Web Engine 'Servo' Project Is Getting a Well-Deserved Reboot (217 pts)]]></title>
            <link>https://news.itsfoss.com/servo-rust-web-engine/</link>
            <guid>39269949</guid>
            <pubDate>Tue, 06 Feb 2024 02:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.itsfoss.com/servo-rust-web-engine/">https://news.itsfoss.com/servo-rust-web-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=39269949">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <div>



      <p>The developers of Servo are starting 2024 by going all in. </p><p>Spotted by <a href="https://mstdn.io/@codewiz/111868362077005163?ref=news.itsfoss.com" rel="noreferrer">Bernie Innocenti</a> when he was visiting <a href="https://fosdem.org/2024/?ref=news.itsfoss.com" rel="noreferrer">FOSDEM 2024</a>, the Servo Project team were there showing off the work done so far.</p><figure><img src="https://news.itsfoss.com/content/images/2024/02/Servo_a-1.jpg" alt="a photo showing a servo project member presenting servo's journey so far" loading="lazy" width="2000" height="1278" srcset="https://news.itsfoss.com/content/images/size/w600/2024/02/Servo_a-1.jpg 600w, https://news.itsfoss.com/content/images/size/w1000/2024/02/Servo_a-1.jpg 1000w, https://news.itsfoss.com/content/images/size/w1600/2024/02/Servo_a-1.jpg 1600w, https://news.itsfoss.com/content/images/size/w2400/2024/02/Servo_a-1.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Pic Credits: </span><a href="https://mstdn.io/@codewiz/111868362077005163?ref=news.itsfoss.com" rel="noreferrer"><span>Bernie Innocenti</span></a></figcaption></figure><p>That got me wondering; <strong>What's the progress with Servo nowadays?</strong> ü§î</p><p>If you were not familiar, <a href="https://servo.org/?ref=news.itsfoss.com" rel="noreferrer">Servo</a> is <strong>an experimental browser engine</strong> that leverages the power of Rust to provide a memory-safe and modular experience that is highly adaptable.</p><p>After Mozilla created Servo back in 2012 as a research project, it saw its share of ups and downs over the years, with it <a href="https://news.itsfoss.com/mozilla-servo-web-engine/" rel="noreferrer">making a comeback</a> in 2023; thanks to a fresh approach by the developers on how Servo should move forward.</p><p>Even though there are plenty of <a href="https://itsfoss.com/open-source-browsers-linux/?ref=news.itsfoss.com" rel="noreferrer">open source Chrome alternatives</a>; With this, there's a chance that we will get some really cool options based on Servo that just might give Blink and Gecko a run for the money! üòÉ</p><p>Let's see how The Servo Project has fared so far, and what's in store for it in 2024.</p><div><p>üìã</p><p><a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)?ref=news.itsfoss.com" rel="noreferrer">Blink</a> is used by Chromium, and other browsers based on it, whereas <a href="https://en.wikipedia.org/wiki/Gecko_(software)?ref=news.itsfoss.com" rel="noreferrer">Gecko</a> is used by Firefox and a few others.</p></div><h2 id="servo-what-to-expect">Servo: What to Expect?</h2><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/9lkIX5ryZZ4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Servo Web Rendering Engine Reboot - Manuel Rego, Igalia"></iframe></figure><p>Just a few months back, in September 2023, after The Servo Project <a href="https://www.igalia.com/2023/09/07/The-Servo-project-is-joining-Linux-Foundation-Europe.html?ref=news.itsfoss.com" rel="noreferrer">officially joined</a> Linux Foundation Europe, the existing contributors from <a href="https://www.igalia.com/?ref=news.itsfoss.com" rel="noreferrer">Igalia</a> stepped up their game by taking over the project maintenance.</p><p>To complement that, at Open Source Summit Europe last year, <a href="https://twitter.com/regocas?ref=news.itsfoss.com" rel="noreferrer">Manuel Rego</a> from Igalia shared some really <a href="https://www.youtube.com/watch?v=9lkIX5ryZZ4&amp;ref=news.itsfoss.com" rel="noreferrer">useful insights</a> when he presented.</p><p>He showcased stuff like the <strong>WebGL support</strong>, <strong>cross-platform support</strong> including <strong>mobile support</strong> for Android and Linux, among other things. </p><p>They have experimented with Servo for embedded applications use-cases (like running it on Raspberry Pi), and have plans to make advances on it. As far as I can see, it looks like, Servo is faster for Raspberry Pi compared to Chromium ü§©</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/oDqDrvxLxyI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Servo On Raspberry Pi"></iframe></figure><p>You can explore more such demos on <a href="https://demo.servo.org/?ref=news.itsfoss.com" rel="noreferrer">Servo's demo webpage</a>.</p><p>Not to forget, a new layout engine is also in the works, where new features and compatibility arrangements are being made within its development.</p><p><strong>Did you know that even though Mozilla dropped the experimental project, Firefox still utilizes some servo components in the browser? </strong>üòâ</p><p>Naturally, that makes us wonder if the newer Servo layout engine (or any other component) might make it into the Firefox (<em>never say never!</em>).</p><p>Back then, Servo was still considered experimental, and in 2024, I hope that progresses a bit further.</p><p>Seeing this is an independent project, <strong>the progress so far looks very promising</strong>, the official website <a href="https://servo.org/about/?ref=news.itsfoss.com" rel="noreferrer">now lists</a> an updated roadmap for 2024 that pretty much has the same things for all of 2024.</p><figure><img src="https://news.itsfoss.com/content/images/2024/02/Servo_b.png" alt="a screenshot of the 2024 roadmap for servo" loading="lazy" width="2000" height="449" srcset="https://news.itsfoss.com/content/images/size/w600/2024/02/Servo_b.png 600w, https://news.itsfoss.com/content/images/size/w1000/2024/02/Servo_b.png 1000w, https://news.itsfoss.com/content/images/size/w1600/2024/02/Servo_b.png 1600w, https://news.itsfoss.com/content/images/size/w2400/2024/02/Servo_b.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>There's <strong>project maintenance and outreach</strong> that will include the usual project maintenance tasks alongside community management, then there's the <strong>implementation of CSS support</strong> which will see work being done on providing basic CSS features for the Servo layout engine.</p><p>With <strong>embedding API definition</strong>, the Servo team will finish work on defining the Servo webview API in collaboration with <a href="https://tauri.app/?ref=news.itsfoss.com" rel="noreferrer">Tauri</a> while also implementing new features and requirements for the API.</p><p>And, finally, we have <strong>Initial Android support</strong>, that will see Servo being made to build on modern Android versions, with the developers publishing nightly APKs on the official website some time in the future.</p><p>For staying in sync with the Servo roadmap, you can follow the <a href="https://github.com/servo/servo/wiki/Roadmap?ref=news.itsfoss.com" rel="noreferrer">official roadmap</a>, and for more details regarding this project, you may head over to its <a href="https://github.com/servo/servo?ref=news.itsfoss.com" rel="noreferrer">GitHub repo</a> or its official <a href="https://servo.zulipchat.com/?ref=news.itsfoss.com" rel="noreferrer">Zulip chat</a>.</p><p><em>üí¨ What do you think of Servo? Will it rise to become a strong contender to the likes of Blink and Gecko?</em></p>

      <interaction data-token="63fb391e4c763100127fc03a" data-context="true" data-tags="" data-fallback="true"></interaction>

      <hr>
      
      <h2 id="more-from-its-foss">More from It's FOSS...</h2>
      <ul>
          <li>Learn Bash scripting for FREE with this <a href="https://itsfoss.com/bash-scripting-tutorial/">Bash Tutorial series</a>.</li>
          <li>Join our <a href="https://itsfoss.community/">community forum</a>.</li>
          <li>üì© Stay updated with the latest on Linux and Open Source. Get our <a href="https://itsfoss.com/newsletter/">weekly Newsletter</a>.</li>
      </ul>
      
    </div>


        

    
    

    

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New viruslike entities found in human gut microbes (130 pts)]]></title>
            <link>https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes</link>
            <guid>39269497</guid>
            <pubDate>Tue, 06 Feb 2024 01:10:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes">https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes</a>, See on <a href="https://news.ycombinator.com/item?id=39269497">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/it-s-insane-new-viruslike-entities-found-human-gut-microbes: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Companies embracing SMS for account logins should be blamed for SIM-swap attacks (403 pts)]]></title>
            <link>https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/</link>
            <guid>39269327</guid>
            <pubDate>Tue, 06 Feb 2024 00:48:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/">https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/</a>, See on <a href="https://news.ycombinator.com/item?id=39269327">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-823">
	<!-- .entry-header -->

	<div>
		
<p>SIM-swap attacks continue year after year because companies (that know better) <em>leaned into</em> the awful idea of using SMS for password resets and account logins. These companies include Apple, Dropbox, PayPal, Block, Google, and many others.</p>



<p>What is a SIM-swap attack? It‚Äôs where a bad guy asks a carrier to port your cell-phone number to their phone. (Carriers are required to port your number easily because of <a href="https://en.wikipedia.org/wiki/Local_number_portability#:~:text=In%20the%20United%20States%2C%2047,Federal%20Communications%20Commission%20(FCC).">pro-competition laws in the US</a>.) Then, the crook triggers and receives account login info via SMSes from companies and proceeds to steal money and sensitive info from the victim. It happens all the time‚Ä¶ Here are just <a href="https://techmeme.com/search/query?q=sim&amp;wm=false">a few of the higher profile instances</a>:</p>



<figure><img fetchpriority="high" decoding="async" width="988" height="1024" src="https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-988x1024.png" alt="" srcset="https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-988x1024.png 988w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-289x300.png 289w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-768x796.png 768w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-1482x1536.png 1482w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-1976x2048.png 1976w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-982x1018.png 982w, https://keydiscussions.com/wp-content/uploads/2024/02/smsswap-386x400.png 386w" sizes="(max-width: 988px) 100vw, 988px"></figure>



<p>Is there a way to stop SIM swap attacks? Yes, it‚Äôs simple: Companies SHOULD NOT LET CUSTOMERS LOG IN via SMS, or allow password resetting via SMS. If SMS 2FA is offered, it should <strong><em>only</em> be</strong> if they provide more secure options like Authy or Google Authenticator (and SMS should not serve as a fallback for account recovery).</p>



<p>For many years, people in the industry have invariably said something like: ‚ÄúWell‚Ä¶ offering SMS-based authentication is better *overall* for customer security, because of its <em>convenience</em> (despite its shortcomings) vs other methods‚Äù (such as the far-more secure-able use of email for verification).  To that I say: ‚Äúwho are *YOU* to deprive your customers of security?‚Äù Defending against targeted attacks must be an integral part of any company‚Äôs defense posture. It‚Äôs so arrogant to say otherwise, and it boils my blood, it really does. Offering SMS-based logins is a bad idea, and it never had a chance of being a good one. </p>



<p>Sending an SMS to a customer is like sending a postcard through the mail. It‚Äôs plaintext (not encrypted), and anyone can open your mailbox and intercept/read it (which is what happens in a SIM-swap attack). The protocol was never designed to be secure.</p>



<p>Is SMS the best option for password resets? NO! Reseting passwords via an email is far more secure. Is SMS a good 2FA option? No! Apps like Authy or using email is better. Is logging your customer in via SMS ever acceptable? No! [After reading Hacker News comments, let me be clear ‚Äì I‚Äôm not <em>just</em> talking about SMS 2FA, in fact I‚Äôm primarily talking about the ubiquitous state of SMS-based password reseting, user onboarding, and account recovery. All are varying degrees of weak. SMS-based 2FA is, when offered as an option alongside stronger 2FA, the least bad of the weak-security scenarios but is not the focus of the post.]</p>



<p>Much of the ire relating to SIM-swap attacks has, understandably, been directed at carriers. Indeed, carriers do a terrible job of securing customers‚Äô phone numbers, and <a href="https://www.techmeme.com/190723/p15#a190723p15">may be liable for that shortcoming</a>. But here‚Äôs the thing: carriers‚Äô security <em>has always</em> been bad, it has even been legislated into being bad, and other companies have still <strong>chosen</strong> to build mission-critical systems on top of that weak link.</p>



<p>Despite it being commonplace, it is important to remember that baking SMS into authentication flows was an awful, shortsighted <strong><em>choice</em></strong> made by companies. Despite offering poor security, SMS offers a nearly frictionless way to sign up new customers (think of Uber‚Äôs onboarding) and handle password resets, and companies felt they had to match competitors‚Äô adoption of this technique. They dug the hole, pushed us in, and now they must get us out.</p>



<p>Companies adopt the naive outlook that, somehow, crooks won‚Äôt try hard enough to SIM swap individuals. Clearly the criminals will ‚Äì even to the point of <a href="https://www.techmeme.com/240130/p39#a240130p39">pretending to be customers at physical store locations</a>. It‚Äôs time for them to call it on this experiment. It failed.</p>



<p>And I‚Äôm sorry, but after nearly a decade, we can call it: efforts to strengthen telephony protocols like SHAKEN/STIR, will never happen. If the willpower had existed in the industry, it would have happened 5 years ago. Promises of protocol upgrades never were (and certainly are not now) a satisfactory excuse to continue to send password reset codes over SMS. Nor would a stronger protocol even stop SIM swap attacks. People are being harmed day-in and day-out, while the industry equivocates. </p>



<p>While SIM-swapping attacks are prevalent and headline-grabbing, SMSes are also vulnerable to man-in-the-middle attacks. These are likely carried out frequently by nation states. The fact that nation states can abuse SMS verification may even explain some of the overall inertia in allowing a broken system to remain.</p>



<p>If I sound heated, it‚Äôs because I‚Äôve been banging this drum for over 7 years. Others <a href="https://www.forbes.com/sites/zakdoffman/2020/10/11/apple-iphone-imessage-and-android-messages-sms-passcode-security-update/">have written</a> about it years ago, and yet SIM-swap attacks continue unabated. I‚Äôm frustrated because many of these companies talk a big game about putting their customers‚Äô safety and security first. I‚Äôm mad because, with all the intractable problems facing tech nowadays like deepfakes (including audio deepfakes that <a href="https://keydiscussions.com/2021/12/07/despite-the-prevalence-of-deepfake-audio-tech-banks-and-isps-rush-ahead-with-voice-print-authentication-%f0%9f%92%80/">I wrote about here</a>) and disinformation, this is one that <em>can actually be solved</em>, and yet nothing (concrete) is being done. We need a win, and here‚Äôs one for the taking!</p>



<p>To repeat: If some random person convinces T-Mobile, AT&amp;T, Verizon, etc to port my number, MY DIGITAL SAFETY SHOULD NOT BE PORTED AS WELL.</p>



<h2>How companies embraced this broken tech</h2>



<p><strong>Apple</strong>:</p>



<p>Apple helped seal SMS‚Äô role in password resets and account logins via its keyboard feature it announced in 2018: <a href="https://support.apple.com/guide/iphone/automatically-fill-in-sms-passcodes-iphc89a3a3af/ios">Automatically fill in SMS passcodes on iPhone</a> . It also allows scenarios where SMS <a href="https://twitter.com/SpencerDailey/status/855190987370618881">can be used</a> to reset your Apple account. </p>



<p><strong>Google</strong>:</p>



<p>In 2019, Google followed Apple‚Äôs bad idea with the same thing for Android, <a href="https://www.xda-developers.com/google-play-services-sms-code-auto-fill/">SMS autofill</a> for one time codes.</p>



<p><strong>Cloud providers like Twilio/Amazon/Microsoft/Google etc</strong>:</p>



<p>There is a large industrial complex behind SMS codes. Many companies have profit incentives to continue offering SMS one time codes to customers.   <a href="https://azure.microsoft.com/en-us/updates/generally-available-azure-communication-services-short-code-functionality-for-sms/">Azure</a>, <a href="https://docs.aws.amazon.com/pinpoint/latest/developerguide/send-validate-otp.html">AWS</a>, <a href="https://www.twilio.com/en-us/pricing">Twilio</a>, <a href="https://www.google.com/search?q=google+cloud+sms+codes&amp;rlz=1C5CHFA_enUS975US978&amp;oq=google+cloud+sms+codes&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhA0gEINTY2M2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8">Google</a>, etc. Selling these services is unethical.  It‚Äôs a fundamentally broken technology, sold as a secure solution.<br></p>



<p><strong>Money management services</strong></p>



<p>Unbelievably, SMS reset/account login functionality is completely ubiquitous even when it comes to your money: <a href="https://www.wellsfargo.com/privacy-security/advanced-access/">Wells Fargo</a>, <a href="https://www.reddit.com/r/Scams/comments/f0cuyq/cash_app_texting_me_with_signin_code_out_of_the/">Cash App (Block)</a>, <a href="https://robinhood.com/us/en/support/articles/verifying-its-you/">Robinhood</a>, <a href="https://www.schwab.com/legal/deviceid">Schwab</a>, <a href="https://www.paypal.com/us/cshelp/article/what-can-i-do-if-ive-changed-my-mobile-number-and-cant-log-in-help678">Paypal</a>, etc etc. Again, these are SMS options offered as a way of ‚Äúverifying that it‚Äôs you‚Äù, something that SIM-swapping crooks love to hear. Also, never <a href="https://www.paypal.com/us/cshelp/article/what-can-i-do-if-ive-changed-my-mobile-number-and-cant-log-in-help678">carelessly change</a> your phone number, you‚Äôll be locked out of your PayPal!</p>



<p><strong>Basically every</strong> other company at this point:</p>



<p>From food ordering services to <a href="https://www.techmeme.com/240122/p18#a240122p18">social <strong>networks</strong></a> and even data storage firms like <a href="https://help.dropbox.com/account-access/enable-two-step-verification"><strong>Dropbox</strong></a> ‚Äî SMS is unfortunately, by default, a way to reset your account. If there‚Äôs even a way to turn it off, it‚Äôs incumbent upon <em>you the user</em>, to go in and opt out ‚Äìservice by service‚Äì and disable the crappy tech. Many services don‚Äôt offer an opt out.</p>



<h2>Customers think they like SMS reset options</h2>



<p>Customers don‚Äôt understand the broken nature of SMS resets. It‚Äôs not their job to. They appreciate that it‚Äôs more convenient than resets via email (an actually-secure option) or log in codes via 2FA apps like authenticator. iPhone‚Äôs SMS autofill is oftentimes (dubiously) <a href="https://journa.host/deck/@spencerdailey/111585692105278478">heralded</a> as the best thing in iOS. The issue is: it‚Äôs not the customer‚Äôs job to understand whether systems are secure, it‚Äôs tech companies‚Äô. </p>



<p>And tech companies have failed, leaving all of their customers exposed in the process. </p>



<p>Hopefully a combination of lawsuits and legislation will eventually change the status quo. In the meantime, <strong>companies need to be brave</strong> and call the situation for what it is: a complete shit show. And then roll back their support of SMS verification services.</p>



<h2><strong>A few more things:</strong> </h2>



<p><strong>Robust Identity services are more important than ever in the age of deepfakes.</strong></p>



<p>Moving away from telephone-number-based identity services is a major and necessary step in realizing robust means of customer identification, which is even more important these days. The era of old school KYC (Know Your Customer) enforcement is over, <a href="https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/">with fake ID AI services going mainstream</a>. We should move away from unencrypted, SIM-swap-prone verification identity services like SMS.</p>



<p><strong>Many ransomware attacks are downstream of SIM-swap attacks</strong></p>



<p>Another seemingly intractable problem facing IT around the world is <a href="https://www.theverge.com/2024/2/5/24059486/ransomware-victims-palo-alto-networks-unit-42">ransomware</a>. SIM-swapping attacks represent a significant vector for compromising a company‚Äôs network. Again, rolling back support for SMS logins could take a bite out of the ransomware scourge.</p>



<p><strong>One <a href="https://news.ycombinator.com/item?id=39269643">HN commenter mentioned</a> the <a href="https://www.sfrpay.fr/Nos-solutions/Mobile-ID/SIM-Verify">‚ÄúSIM Verify‚Äù initiative in the EU</a>, </strong>where companies relying on SMS can at least check to see if a SIM had recently been ported. That‚Äôs something, and we‚Äôll see if it goes anywhere, but if the SHAKEN/STIR rollout has taught me anything, changes like this may happen in a decade not a year.</p>



<p><strong>Finally, a dedicated home to this question</strong></p>



<p>I <a href="https://www.metafruit.com/smssecurity/">created a site at a permanent URL</a> that bluntly answers the question ‚ÄúIs using SMS for logins a good idea?‚Äù, for sharing with people in the industry.</p>








			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I worked 80 hour weeks to deliver a platform for a hedge fund,then they fired me (162 pts)]]></title>
            <link>https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me</link>
            <guid>39269284</guid>
            <pubDate>Tue, 06 Feb 2024 00:42:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me">https://www.efinancialcareers.com/news/i-worked-80-hour-weeks-to-deliver-a-platform-for-a-hedge-fund-then-they-fired-me</a>, See on <a href="https://news.ycombinator.com/item?id=39269284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div _ngcontent-ng-c2603034510="" id="articleDetail" ngskiphydration=""><p>I built a systematic trading platform for a <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/finance/how-to-get-a-hedge-fund-job">hedge fund</a>. I delivered an excellent platform ahead of time, but then they fired me, and now I can‚Äôt find a new job in what's a very difficult employment market.</p><p><a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/myefc/preferences/subscribe?newsletter=network_newsletter">Get Morning Coffee&nbsp;</a><span>‚òï</span><a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/myefc/preferences/subscribe?newsletter=network_newsletter">&nbsp;in your inbox. Sign up here.</a><o:p></o:p></p><p>I shouldn‚Äôt even be looking for a job right now. I‚Äôm only on the market because I became surplus to requirements. Effectively, I was ‚Äúfired‚Äù for being too effective in my previous role.<o:p></o:p></p><p>I joined the startup hedge fund last year. In the short period while I worked there, I built an order management system which allowed the firm to make its first eve trades. A typical week for me included working between 70 and 80 hours a week. I worked almost every weekend, and almost every day for the entire time, without a single day of holiday.<o:p></o:p></p><p>I did this for two reasons. Firstly, I was told repeatedly that the faster the firm was able to start trading, the faster I would start earning bonuses from the firm's PnL, assuming that the strategies indeed were profitable. (It is my understanding that they are highly profitable.)<o:p></o:p></p><p>Secondly, I loved my job. Every day, I got to build really cool stuff, all while learning a new language which was unfamiliar to me ‚Äì <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/2023/03/rust-jobs-in-finance">Rust. </a>Every day, I was learning more about <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/news/2020/09/rust-vs-c-hedge-fund-jobs">Rust,</a> Kafka, and the range of other technologies which we were leveraging. It was pretty great.<o:p></o:p></p><p>After months of hard work, the system finally went into production, and trades started flowing around the system. Two days later I was let go. I arrived in the office the morning after 48 hours of profit making, and was called into a private office. I was told it was ‚Äúwith regret‚Äù that my contract would be terminated that day, and that the ‚Äúsubstantial bonus‚Äù which would be paid to me was ‚Äúthanks‚Äù for the critical role I played in starting the company.<o:p></o:p><o:p></o:p></p><p>While I in no way regret working for the fund, as I gained a fast amount of experience in a relatively short period of time, I do regret not being more tactical with my work. I could have simply worked 40 hours a week. Had I done so, it is likely I would still be employed, still building the platform today.<o:p></o:p></p><p>Since the day I left, I have been relentlessly job searching. But so far I have found nothing. I was told in an interview for a <a target="_blank" rel="noopener noreferrer" href="https://www.efinancialcareers.com/jobs/quantitative-analyst">junior quant</a> position that it was ‚Äúa bit of a red flag‚Äù that I worked somewhere for such a short period of time.&nbsp;<o:p></o:p></p><p>So is that it? I know the job market is tough right now, but have I snookered myself and made myself unemployable for working too effectively during my last role?&nbsp;<o:p></o:p></p><p>I think I have applied to every hedge fund and investment bank in London. My applications either received an automatic rejection, or simply no response in the majority of cases. In the handful of cases where I have been offered an interview, most have been initial conversations, followed by radio silence ‚Äì not even a rejection email.<o:p></o:p></p><p>It seems that during such a dire economy, the dream of a junior quant role is out of reach, for now. Any advice would be greatly appreciated.&nbsp;</p><p><i>Milan Gill is a pseudonym&nbsp;</i></p><p>&nbsp;<i><strong>Have a confidential story, tip, or comment you‚Äôd like to share?&nbsp;Contact: +44&nbsp;7537 182250 (SMS, Whatsapp or voicemail).&nbsp;Telegram: @SarahButcher.&nbsp;</strong></i><a rel="noreferrer noopener" target="_blank" title="https://www.efinancialcareers.co.uk/about/editor-tips"><i><strong>Click here to fill in our anonymous form</strong></i></a><i><strong>, or email editortips@efinancialcareers.com. Signal also available.</strong></i></p><p><i>Bear with us if you leave a comment at the bottom of this article: all our comments are moderated by human beings. Sometimes these humans might be asleep, or away from their desks, so it may take a while for your comment to appear. Eventually it will ‚Äì unless it‚Äôs offensive or libelous (in which case it won‚Äôt.)</i><span>.</span><o:p></o:p></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The little SSH that sometimes couldn't (2012) (164 pts)]]></title>
            <link>https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html</link>
            <guid>39268530</guid>
            <pubDate>Mon, 05 Feb 2024 23:14:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html">https://mina.naguib.ca/blog/2012/10/22/the-little-ssh-that-sometimes-couldnt.html</a>, See on <a href="https://news.ycombinator.com/item?id=39268530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h3 id="preface">Preface</h3>
<p>This is a technical article chronicling one of the most interesting bug hunts I‚Äôve had the pleasure of chasing down.</p>
<p>At <a href="http://adgear.com/">AdGear Technologies Inc.</a> where I work, ssh is king.  We use it for management, monitoring, deployments, log file harvesting, even some event streaming.  It‚Äôs solid, reliable, has all the predictability of a native unix tool, and just works.</p>
<p>Until one day, random cron emails started flowing about it not working.</p>
<h3 id="the-timeout">The timeout</h3>
<p>The machines in our London data center were randomly failing to send their event log files to our data machines in our Montreal data center.  This job is initiated periodically from cron, and the failure manifested itself as:</p>
<ul>
<li>cron emails stating that the ssh was unsuccessful
<ul>
<li>Sometimes hangs</li>
<li>Sometimes exits with a timeout error</li>
</ul>
</li>
<li>monitoring warnings down the line for in-house sanity checks detecting the missing data in Montreal</li>
</ul>
<p>We logged into the London machines, manually ran the push command, and it worked successfully.  We brushed it off as temporary network partitions.</p>
<h3 id="the-timeouts">The timeouts</h3>
<p>But the failures kept popping up randomly.  Once a day, a couple of times a day, then one Friday morning, several times an hour.  It was clear something‚Äôs getting worse.  We kept up with manually pushing the files until we figure out what the problem was.</p>
<p>There were 17 hops between London and Montreal.  We built a profile of latency and packet loss for them, and found that a couple were losing 1-3% of packets.  We filed a ticket with our London DC ops to route away from them.</p>
<p>While London DC ops were verifying the packet loss, we started seeing random timeouts from London to our SECOND data center in Montreal, and hops to that data center did not share the same routes we observed the packet loss at.  We concluded packet loss is not the main problem around the same time London DC ops replied saying they‚Äôre not able to replicate the packet loss or timeouts and that everything looked healthy on their end.</p>
<h3 id="the-revelation">The revelation</h3>
<p>While manually keeping up with failed cron uploads, we noticed an interesting pattern.  A file transfer either succeeded at a high speed, or didn‚Äôt succeed at all and hung/timed out.  There were no instances of a file uploading slowly and finishing successfully.</p>
<p>Removing the large volume of data from the equation, we were able to recreate the scenario via simple vanilla ssh.  On a London machine an ‚Äússh mtl-machine‚Äù would either work immediately, or hang and never establish a connection.  Eyebrows started going up.</p>
<h3 id="where-the-wild-packets-are">Where the wild packets are</h3>
<p>We triple-checked the ssh server configs and health in Montreal:</p>
<ul>
<li>The servers appeared healthy by all measures</li>
<li>SSHd DNS reverse lookup was not enabled</li>
<li>SSHd Maximum client connections was high enough</li>
<li>We were not under attack</li>
<li>Bandwidth usage was nowhere near saturation</li>
</ul>
<p>Besides, even if something was off, we were observing the hangs talking to 2 completely distinct data centers in Montreal.  Furthermore, our other data centers (non-London) were talking happily to Montreal.  Something about London was off.</p>
<p>We fired up tcpdump and started looking at the packets, both in summary and in captured pcaps loaded into wireshark.  We saw telltale signs of packet loss and retransmission, but it was minimal and not particularly worrisome.</p>
<p>We then captured full connections from cases where ssh established successfully, and full connections from cases where the ssh connection hung.</p>
<p>Here‚Äôs what we logically saw when a connection from London to Montreal hung:</p>
<ul>
<li>Normal TCP handshake</li>
<li>Bunch of ssh-specific back and forth, with normal TCP ACK packets where they should be</li>
<li>A particular packet sent from London and received in Montreal</li>
<li>The same packet re-sent (and re-sent, several times) from London and received in Montreal</li>
<li>Montreal‚Äôs just not responding to it!</li>
</ul>
<p>It didn‚Äôt make sense why Montreal was not responding (hence London re-transmitting it).  The connection was stalled at this point, as the layer 4 protocol was at a stalemate.  More infuriatingly, if you kill the ssh attempt in London and re-launched it immediately, odds are it worked successfully.  When it did, tcpdump showed Montreal receiving the packet but responding to it, and things moved on.</p>
<p>We enabled verbose debugging (-vvv) on the ssh client in London, and the hang occurred after it logged:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>debug2: kex_parse_kexinit: first_kex_follows 0 
</span></span><span><span>debug2: kex_parse_kexinit: reserved 0 
</span></span><span><span>debug2: mac_setup: found hmac-md5
</span></span><span><span>debug1: kex: server-&gt;client aes128-ctr hmac-md5 none
</span></span><span><span>debug2: mac_setup: found hmac-md5
</span></span><span><span>debug1: kex: client-&gt;server aes128-ctr hmac-md5 none
</span></span><span><span>debug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024&lt;1024&lt;8192) sent
</span></span><span><span>debug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP</span></span></code></pre></div>
<p>Googling ‚Äússh hang SSH2_MSG_KEX_DH_GEX_GROUP‚Äù has many results - from bad WiFi, to windows TCP bugs, to buggy routers discarding TCP fragments.  One solution for LANs was to figure out the path‚Äôs MSS and set that as the MTU on both ends.</p>
<p>I kept decrementing the MTU on a London server down from 1500 - it didn‚Äôt help until I hit the magic value 576.  At that point, I was no longer able to get the ssh hanging behavior replicated.  I had an ssh loop script running, and it was on-demand that I could cause timeouts by bringing the MTU back up to 1500, or make them disappear by setting it to 576.</p>
<p>Unfortunately these are public web servers and globally setting the MTU to 576 won‚Äôt cut it, but the above did suggest that perhaps packet fragmentation or reassembly is broken somewhere.</p>
<p>Going back to check the received packets with tcpdump, there was no evidence of fragmentation.  The received packet size matched exactly the packet size sent.  If something did fragment the packet at byte 576+, something else reassembled it successfully.</p>
<h3 id="twinkle-twinkle-little-mis-shapen-star">Twinkle twinkle little mis-shapen star</h3>
<p>Digging in some more, I was now looking at full packet dumps (tcpdump -s 0 -X) instead of just the headers.  Comparing that magic packet in instances of ssh success vs ssh hang showed very little difference aside from TCP/IP header variations.  It was however clear that this is the first packet in the TCP connection that had enough data to bypass the 576-byte mark - all previous packets were much smaller.</p>
<p>Comparing the same packet, during a hanging instance, as it left London, and as captured in Montreal, something caught my eye.  Something very subtle, and I brushed it off as fatigue (it was late Friday at this point), but sure enough after a few refreshes and comparisons, I wasn‚Äôt imagining things.</p>
<p>Here‚Äôs the packet as it left London (minus the first few bytes identifying the IP addresses):</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0040:  0b7c aecc 1774 b770 ad92 0000 00b7 6563  .|...t.p......ec
</span></span><span><span>0x0050:  6468 2d73 6861 322d 6e69 7374 7032 3536  dh-sha2-nistp256
</span></span><span><span>0x0060:  2c65 6364 682d 7368 6132 2d6e 6973 7470  ,ecdh-sha2-nistp
</span></span><span><span>0x0070:  3338 342c 6563 6468 2d73 6861 322d 6e69  384,ecdh-sha2-ni
</span></span><span><span>0x0080:  7374 7035 3231 2c64 6966 6669 652d 6865  stp521,diffie-he
</span></span><span><span>0x0090:  6c6c 6d61 6e2d 6772 6f75 702d 6578 6368  llman-group-exch
</span></span><span><span>0x00a0:  616e 6765 2d73 6861 3235 362c 6469 6666  ange-sha256,diff
</span></span><span><span>0x00b0:  6965 2d68 656c 6c6d 616e 2d67 726f 7570  ie-hellman-group
</span></span><span><span>0x00c0:  2d65 7863 6861 6e67 652d 7368 6131 2c64  -exchange-sha1,d
</span></span><span><span>0x00d0:  6966 6669 652d 6865 6c6c 6d61 6e2d 6772  iffie-hellman-gr
</span></span><span><span>0x00e0:  6f75 7031 342d 7368 6131 2c64 6966 6669  oup14-sha1,diffi
</span></span><span><span>0x00f0:  652d 6865 6c6c 6d61 6e2d 6772 6f75 7031  e-hellman-group1
</span></span><span><span>0x0100:  2d73 6861 3100 0000 2373 7368 2d72 7361  -sha1...#ssh-rsa
</span></span><span><span>0x0110:  2c73 7368 2d64 7373 2c65 6364 7361 2d73  ,ssh-dss,ecdsa-s
</span></span><span><span>0x0120:  6861 322d 6e69 7374 7032 3536 0000 009d  ha2-nistp256....
</span></span><span><span>0x0130:  6165 7331 3238 2d63 7472 2c61 6573 3139  aes128-ctr,aes19
</span></span><span><span>0x0140:  322d 6374 722c 6165 7332 3536 2d63 7472  2-ctr,aes256-ctr
</span></span><span><span>0x0150:  2c61 7263 666f 7572 3235 362c 6172 6366  ,arcfour256,arcf
</span></span><span><span>0x0160:  6f75 7231 3238 2c61 6573 3132 382d 6362  our128,aes128-cb
</span></span><span><span>0x0170:  632c 3364 6573 2d63 6263 2c62 6c6f 7766  c,3des-cbc,blowf
</span></span><span><span>0x0180:  6973 682d 6362 632c 6361 7374 3132 382d  ish-cbc,cast128-
</span></span><span><span>0x0190:  6362 632c 6165 7331 3932 2d63 6263 2c61  cbc,aes192-cbc,a
</span></span><span><span>0x01a0:  6573 3235 362d 6362 632c 6172 6366 6f75  es256-cbc,arcfou
</span></span><span><span>0x01b0:  722c 7269 6a6e 6461 656c 2d63 6263 406c  r,rijndael-cbc@l
</span></span><span><span>0x01c0:  7973 6174 6f72 2e6c 6975 2e73 6500 0000  ysator.liu.se...
</span></span><span><span>0x01d0:  9d61 6573 3132 382d 6374 722c 6165 7331  .aes128-ctr,aes1
</span></span><span><span>0x01e0:  3932 2d63 7472 2c61 6573 3235 362d 6374  92-ctr,aes256-ct
</span></span><span><span>0x01f0:  722c 6172 6366 6f75 7232 3536 2c61 7263  r,arcfour256,arc
</span></span><span><span>0x0200:  666f 7572 3132 382c 6165 7331 3238 2d63  four128,aes128-c
</span></span><span><span>0x0210:  6263 2c33 6465 732d 6362 632c 626c 6f77  bc,3des-cbc,blow
</span></span><span><span>0x0220:  6669 7368 2d63 6263 2c63 6173 7431 3238  fish-cbc,cast128
</span></span><span><span>0x0230:  2d63 6263 2c61 6573 3139 322d 6362 632c  -cbc,aes192-cbc,
</span></span><span><span>0x0240:  6165 7332 3536 2d63 6263 2c61 7263 666f  aes256-cbc,arcfo
</span></span><span><span>0x0250:  7572 2c72 696a 6e64 6165 6c2d 6362 6340  ur,rijndael-cbc@
</span></span><span><span>0x0260:  6c79 7361 746f 722e 6c69 752e 7365 0000  lysator.liu.se..
</span></span><span><span>0x0270:  00a7 686d 6163 2d6d 6435 2c68 6d61 632d  ..hmac-md5,hmac-
</span></span><span><span>0x0280:  7368 6131 2c75 6d61 632d 3634 406f 7065  sha1,umac-64@ope
</span></span><span><span>0x0290:  6e73 7368 2e63 6f6d 2c68 6d61 632d 7368  nssh.com,hmac-sh
</span></span><span><span>0x02a0:  6132 2d32 3536 2c68 6d61 632d 7368 6132  a2-256,hmac-sha2
</span></span><span><span>0x02b0:  2d32 3536 2d39 362c 686d 6163 2d73 6861  -256-96,hmac-sha
</span></span><span><span>0x02c0:  322d 3531 322c 686d 6163 2d73 6861 322d  2-512,hmac-sha2-
</span></span><span><span>0x02d0:  3531 322d 3936 2c68 6d61 632d 7269 7065  512-96,hmac-ripe
</span></span><span><span>0x02e0:  6d64 3136 302c 686d 6163 2d72 6970 656d  md160,hmac-ripem
</span></span><span><span>0x02f0:  6431 3630 406f 7065 6e73 7368 2e63 6f6d  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="e98dd8dfd9a986998c879a9a81c78a8684">[email&nbsp;protected]</a>
</span></span><span><span>0x0300:  2c68 6d61 632d 7368 6131 2d39 362c 686d  ,hmac-sha1-96,hm
</span></span><span><span>0x0310:  6163 2d6d 6435 2d39 3600 0000 a768 6d61  ac-md5-96....hma
</span></span><span><span>0x0320:  632d 6d64 352c 686d 6163 2d73 6861 312c  c-md5,hmac-sha1,
</span></span><span><span>0x0330:  756d 6163 2d36 3440 6f70 656e 7373 682e  umac-64@openssh.
</span></span><span><span>0x0340:  636f 6d2c 686d 6163 2d73 6861 322d 3235  com,hmac-sha2-25
</span></span><span><span>0x0350:  362c 686d 6163 2d73 6861 322d 3235 362d  6,hmac-sha2-256-
</span></span><span><span>0x0360:  3936 2c68 6d61 632d 7368 6132 2d35 3132  96,hmac-sha2-512
</span></span><span><span>0x0370:  2c68 6d61 632d 7368 6132 2d35 3132 2d39  ,hmac-sha2-512-9
</span></span><span><span>0x0380:  362c 686d 6163 2d72 6970 656d 6431 3630  6,hmac-ripemd160
</span></span><span><span>0x0390:  2c68 6d61 632d 7269 7065 6d64 3136 3040  ,hmac-ripemd160@
</span></span><span><span>0x03a0:  6f70 656e 7373 682e 636f 6d2c 686d 6163  openssh.com,hmac
</span></span><span><span>0x03b0:  2d73 6861 312d 3936 2c68 6d61 632d 6d64  -sha1-96,hmac-md
</span></span><span><span>0x03c0:  352d 3936 0000 0015 6e6f 6e65 2c7a 6c69  5-96....none,zli
</span></span><span><span>0x03d0:  6240 6f70 656e 7373 682e 636f 6d00 0000  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="3153715e41545f4242591f525e5c">[email&nbsp;protected]</a>...
</span></span><span><span>0x03e0:  156e 6f6e 652c 7a6c 6962 406f 7065 6e73  .none,zlib@opens
</span></span><span><span>0x03f0:  7368 2e63 6f6d 0000 0000 0000 0000 0000  sh.com..........
</span></span><span><span>0x0400:  0000 0000 0000 0000 0000 0000            ............</span></span></code></pre></div>
<p>And here‚Äôs the same packet as it arrived in Montreal:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0040:  0b7c aecc 1774 b770 ad92 0000 00b7 6563  .|...t.p......ec
</span></span><span><span>0x0050:  6468 2d73 6861 322d 6e69 7374 7032 3536  dh-sha2-nistp256
</span></span><span><span>0x0060:  2c65 6364 682d 7368 6132 2d6e 6973 7470  ,ecdh-sha2-nistp
</span></span><span><span>0x0070:  3338 342c 6563 6468 2d73 6861 322d 6e69  384,ecdh-sha2-ni
</span></span><span><span>0x0080:  7374 7035 3231 2c64 6966 6669 652d 6865  stp521,diffie-he
</span></span><span><span>0x0090:  6c6c 6d61 6e2d 6772 6f75 702d 6578 6368  llman-group-exch
</span></span><span><span>0x00a0:  616e 6765 2d73 6861 3235 362c 6469 6666  ange-sha256,diff
</span></span><span><span>0x00b0:  6965 2d68 656c 6c6d 616e 2d67 726f 7570  ie-hellman-group
</span></span><span><span>0x00c0:  2d65 7863 6861 6e67 652d 7368 6131 2c64  -exchange-sha1,d
</span></span><span><span>0x00d0:  6966 6669 652d 6865 6c6c 6d61 6e2d 6772  iffie-hellman-gr
</span></span><span><span>0x00e0:  6f75 7031 342d 7368 6131 2c64 6966 6669  oup14-sha1,diffi
</span></span><span><span>0x00f0:  652d 6865 6c6c 6d61 6e2d 6772 6f75 7031  e-hellman-group1
</span></span><span><span>0x0100:  2d73 6861 3100 0000 2373 7368 2d72 7361  -sha1...#ssh-rsa
</span></span><span><span>0x0110:  2c73 7368 2d64 7373 2c65 6364 7361 2d73  ,ssh-dss,ecdsa-s
</span></span><span><span>0x0120:  6861 322d 6e69 7374 7032 3536 0000 009d  ha2-nistp256....
</span></span><span><span>0x0130:  6165 7331 3238 2d63 7472 2c61 6573 3139  aes128-ctr,aes19
</span></span><span><span>0x0140:  322d 6374 722c 6165 7332 3536 2d63 7472  2-ctr,aes256-ctr
</span></span><span><span>0x0150:  2c61 7263 666f 7572 3235 362c 6172 6366  ,arcfour256,arcf
</span></span><span><span>0x0160:  6f75 7231 3238 2c61 6573 3132 382d 6362  our128,aes128-cb
</span></span><span><span>0x0170:  632c 3364 6573 2d63 6263 2c62 6c6f 7766  c,3des-cbc,blowf
</span></span><span><span>0x0180:  6973 682d 6362 632c 6361 7374 3132 382d  ish-cbc,cast128-
</span></span><span><span>0x0190:  6362 632c 6165 7331 3932 2d63 6263 2c61  cbc,aes192-cbc,a
</span></span><span><span>0x01a0:  6573 3235 362d 6362 632c 6172 6366 6f75  es256-cbc,arcfou
</span></span><span><span>0x01b0:  722c 7269 6a6e 6461 656c 2d63 6263 406c  r,rijndael-cbc@l
</span></span><span><span>0x01c0:  7973 6174 6f72 2e6c 6975 2e73 6500 0000  ysator.liu.se...
</span></span><span><span>0x01d0:  9d61 6573 3132 382d 6374 722c 6165 7331  .aes128-ctr,aes1
</span></span><span><span>0x01e0:  3932 2d63 7472 2c61 6573 3235 362d 6374  92-ctr,aes256-ct
</span></span><span><span>0x01f0:  722c 6172 6366 6f75 7232 3536 2c61 7263  r,arcfour256,arc
</span></span><span><span>0x0200:  666f 7572 3132 382c 6165 7331 3238 2d63  four128,aes128-c
</span></span><span><span>0x0210:  6263 2c33 6465 732d 6362 632c 626c 6f77  bc,3des-cbc,blow
</span></span><span><span>0x0220:  6669 7368 2d63 6263 2c63 6173 7431 3238  fish-cbc,cast128
</span></span><span><span>0x0230:  2d63 6263 2c61 6573 3139 322d 6362 632c  -cbc,aes192-cbc,
</span></span><span><span>0x0240:  6165 7332 3536 2d63 6263 2c61 7263 666f  aes256-cbc,arcfo
</span></span><span><span>0x0250:  7572 2c72 696a 6e64 6165 6c2d 6362 7340  ur,rijndael-cbs@
</span></span><span><span>0x0260:  6c79 7361 746f 722e 6c69 752e 7365 1000  lysator.liu.se..
</span></span><span><span>0x0270:  00a7 686d 6163 2d6d 6435 2c68 6d61 732d  ..hmac-md5,hmas-
</span></span><span><span>0x0280:  7368 6131 2c75 6d61 632d 3634 406f 7065  sha1,umac-64@ope
</span></span><span><span>0x0290:  6e73 7368 2e63 6f6d 2c68 6d61 632d 7368  nssh.com,hmac-sh
</span></span><span><span>0x02a0:  6132 2d32 3536 2c68 6d61 632d 7368 7132  a2-256,hmac-shq2
</span></span><span><span>0x02b0:  2d32 3536 2d39 362c 686d 6163 2d73 7861  -256-96,hmac-sxa
</span></span><span><span>0x02c0:  322d 3531 322c 686d 6163 2d73 6861 322d  2-512,hmac-sha2-
</span></span><span><span>0x02d0:  3531 322d 3936 2c68 6d61 632d 7269 7065  512-96,hmac-ripe
</span></span><span><span>0x02e0:  6d64 3136 302c 686d 6163 2d72 6970 756d  md160,hmac-ripum
</span></span><span><span>0x02f0:  6431 3630 406f 7065 6e73 7368 2e63 7f6d  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="ddb9ecebed9db2adb8b3aeaeb5f3bef3b0">[email&nbsp;protected]</a>
</span></span><span><span>0x0300:  2c68 6d61 632d 7368 6131 2d39 362c 786d  ,hmac-sha1-96,xm
</span></span><span><span>0x0310:  6163 2d6d 6435 2d39 3600 0000 a768 7d61  ac-md5-96....h}a
</span></span><span><span>0x0320:  632d 6d64 352c 686d 6163 2d73 6861 312c  c-md5,hmac-sha1,
</span></span><span><span>0x0330:  756d 6163 2d36 3440 6f70 656e 7373 782e  umac-64@openssx.
</span></span><span><span>0x0340:  636f 6d2c 686d 6163 2d73 6861 322d 3235  com,hmac-sha2-25
</span></span><span><span>0x0350:  362c 686d 6163 2d73 6861 322d 3235 362d  6,hmac-sha2-256-
</span></span><span><span>0x0360:  3936 2c68 6d61 632d 7368 6132 2d35 3132  96,hmac-sha2-512
</span></span><span><span>0x0370:  2c68 6d61 632d 7368 6132 2d35 3132 3d39  ,hmac-sha2-512=9
</span></span><span><span>0x0380:  362c 686d 6163 2d72 6970 656d 6431 3630  6,hmac-ripemd160
</span></span><span><span>0x0390:  2c68 6d61 632d 7269 7065 6d64 3136 3040  ,hmac-ripemd160@
</span></span><span><span>0x03a0:  6f70 656e 7373 682e 636f 6d2c 686d 7163  openssh.com,hmqc
</span></span><span><span>0x03b0:  2d73 6861 312d 3936 2c68 6d61 632d 7d64  -sha1-96,hmac-}d
</span></span><span><span>0x03c0:  352d 3936 0000 0015 6e6f 6e65 2c7a 7c69  5-96....none,z|i
</span></span><span><span>0x03d0:  6240 6f70 656e 7373 682e 636f 6d00 0000  <a href="https://mina.naguib.ca/cdn-cgi/l/email-protection" data-cfemail="e183a18e91848f929289cf828e8c">[email&nbsp;protected]</a>...
</span></span><span><span>0x03e0:  156e 6f6e 652c 7a6c 6962 406f 7065 6e73  .none,zlib@opens
</span></span><span><span>0x03f0:  7368 2e63 6f6d 0000 0000 0000 0000 0000  sh.com..........
</span></span><span><span>0x0400:  0000 0000 0000 0000 0000 0000            ............</span></span></code></pre></div>
<p>Did something there catch your eye ?  If not, I don‚Äôt blame you.  Feel free to copy each into a text editor and rapidly switch back-and-forth to see some characters dance.  Here‚Äôs what it looks like when they‚Äôre placed in vimdiff:</p>
<p><img src="https://mina.naguib.ca/images/blog/vimdiff_packets.png" alt="Vim diff packet"></p>
<p>Well well well. It‚Äôs not packet loss, it‚Äôs packet corruption!  Very subtle, very predictable packet corruption.</p>
<p>Some interesting notes:</p>
<ul>
<li>The lower part of the packet (&lt;576 bytes) is unaffected</li>
<li>The affected portion is predictably corrupted on the 15th byte of every 16</li>
<li>The corruption is predictable.  All instances of ‚Äúh‚Äù become ‚Äúx‚Äù, all instances of ‚Äúc‚Äù become ‚Äús‚Äù</li>
</ul>
<p>Some readers might have already checked ASCII charts and reached the conclusion:  There‚Äôs a single bit statically stuck at ‚Äú1‚Äù somewhere.  Flipping the 4th bit in a byte to 1 would reliably corrupt the above letters on the left side to the value on the right side.</p>
<p>The obvious culprits within our control (NIC cards, receiving machines) are not suspect due to the pattern of failure observed (several London machines -&gt; Several Montreal data centers and machines).  It‚Äôs got to be something upstream and close to London.</p>
<p>Going back to validate, things started to make sense.  I also noticed a little hint in tcpdump verbose mode (tcp cksum bad) which was missed before.  A Montreal machine receiving this packet discarded it at the kernel level after realizing it‚Äôs corrupt, never passing it to the userland ssh daemon.  London then re-transmitted it, going through the same corruption, getting the same silent treatment.  From ssh and sshd‚Äôs perspective, the connection was at a stalemate.  From tcpdump‚Äôs perspective, there was no loss, and Montreal machines appeared to be just ignoring data.</p>
<p>We sent these findings to our London DC ops, and within a few minutes they changed outbound routes dramatically.  The first router hop, and most hops afterwards, were different.  The hanging problem disappeared.</p>
<p>Late Friday night fixes are nice because you can relax and not carry problems and support staff into the weekend :)</p>
<h3 id="wheres-waldo">Where‚Äôs Waldo</h3>
<p>Happy that we were no longer suffering from this problem and that our systems are caught up with the backlog, I decided I‚Äôd try my hand at actually finding the device causing the corruption.</p>
<p>Having the London routes updated to not go through the old path meant that I couldn‚Äôt reproduce the problem easily.  I asked around until I found a friend with a FreeBSD box in Montreal I could use, which was still accessed through the old routes from London.</p>
<p>Next, I wanted to make sure that the corruption is predictable even without ssh involvement.  This was trivially proven with a few pipes.</p>
<p>In Montreal:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>nc -l -p 4000 &gt; /dev/null</span></span></code></pre></div>
<p>Then in London:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>cat /dev/zero | nc mtl 4000</span></span></code></pre></div>
<p>Again, accounting for the randomness factor and settings things up in a retry loop, I got a few packets which remove any doubt about the previous conclusions.  Here‚Äôs part of one - remember that we‚Äôre sending just a stream of nulls(zeroes):</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>0x0210  .....
</span></span><span><span>0x0220  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0230  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0240  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x0250  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0260  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0270  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0280  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0290  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02a0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02b0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02c0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02d0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02e0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x02f0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0300  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0310  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0320  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0330  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0340  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0350  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0360  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0370  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0380  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x0390  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03a0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03b0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03c0  0000 0000 0000 0000 0000 0000 0000 1000 ................
</span></span><span><span>0x03d0  0000 0000 0000 0000 0000 0000 0000 0000 ................
</span></span><span><span>0x03e0  .....</span></span></code></pre></div>
<p>With the bug replicated, I needed to find a way to isolate which of the 17 hops along that path cause the corruption.  There was simply no way to call up the provider of each cluster to ask them to check their systems.</p>
<p>I decided pinging each router, incrementally, might be the way to go.  I crafted special ICMP packets that are large enough to go over the 576 safety margin, and filled entirely with NULLs.  Then pinged the Montreal machine with them from London.</p>
<p>They came back perfectly normal.  There was no corruption.</p>
<p>I tried all variations of speed, padding, size - to no avail.  I simply could not observe corruption in the returned ICMP ping packets.</p>
<p>I replaced the netcat pipes with UDP instead of TCP.  Again there was no corruption.</p>
<p>The corruption needed TCP to be reproducible - and TCP needs 2 cooperating endpoints.  I tried in vain to see if all 17 router hops had an open TCP port I can talk to directly, to no avail.</p>
<p>It seemed there was no easy way an external party can pinpoint the bad apple. Or was there ?</p>
<h3 id="mirror-mirror-on-the-wall">Mirror mirror on the wall</h3>
<p>To detect whether corruption occurred or not, we need one of these scenarios:</p>
<ul>
<li>Control over the TCP peer we‚Äôre talking to inspect the packet at the destination
<ul>
<li>Not just in userland, where the packet would not get delivered if the TCP checksum failed, but root + tcpdump to inspect it as it arrives</li>
</ul>
</li>
<li>A TCP peer that acts as an echo server to mirror back the data it received, so we get to inspect it at the sending node and detect corruption there</li>
</ul>
<p>It suddenly occurred to me that the second data point is available to us.  Not per-se, but consider this:  In our very first taste of the problem, we observed ssh clients hanging when talking to ssh servers over the corrupting hop.  This is a good passive signal that we can use instead of the active ‚Äúecho‚Äù signal.</p>
<p>‚Ä¶ and there are lots of open ssh servers out there on the internet to help us out.</p>
<p>We don‚Äôt need actual accounts on these servers - we just need to kickstart the ssh connection and see if the cipher exchange phase succeeds or hangs (with a reasonable number of retries to account for corruption randomness).</p>
<p>So this plan was hatched:</p>
<ul>
<li>Use the wonderful <strong>nmap</strong> tool - specifically - its ‚Äúrandom IP‚Äù mode - to make a list of geographically distributed open ssh servers</li>
<li>Test each server to determine whether it is:
<ul>
<li>Unresponsive/unpredictable/firewalled -&gt; Ignore it</li>
<li>Negotiates successfully after being retried N times -&gt; mark as ‚Äúgood‚Äù</li>
<li>Negotiates with hangs at the telltale phase after being retried N times -&gt; mark as ‚Äúbad‚Äù</li>
</ul>
</li>
<li>For both ‚Äúgood‚Äù and ‚Äúbad‚Äù servers, remember the traceroute to them</li>
</ul>
<p>The idea was this:  All servers marked as ‚Äúbad‚Äù will share a few hops in their traceroute.  We can then take that set of suspect hops, and subtract from it any that appear in the traceroutes of the ‚Äúgood‚Äù servers.  Hopefully what‚Äôs left is only one or two.</p>
<p>After spending an hour manually doing the above exercise, I stopped to inspect the data.  I had classified 16 servers as ‚ÄúBAD‚Äù and 25 servers as ‚ÄúGOOD‚Äù.</p>
<p>The first exercise was to find the list of hops that appear in all the traceroutes of the ‚ÄúBAD‚Äù servers.  As I cleaned and trimmed the list, I realized I won‚Äôt even need to get to the ‚ÄúGOOD‚Äù list to remove false positives.  Within the ‚ÄúBAD‚Äù lists alone, there remained only 1 that was common to all of them.</p>
<p>For what it‚Äôs worth, it was 2 providers away:  London -&gt; N hops upstream1 -&gt; Y hops upstream2</p>
<p>It was the first in Y hops of upstream2 - right at the edge between upstream1 and upstream2, corrupting random TCP packets, causing many retries, and, depending on the protocol‚Äôs logical back-and-forth, hangs, or reduced transmission rates.  You may have been a telephony provider who sufferred dropped calls, a retailer who lost a few customers or sales, the possibilities really are endless.</p>
<p>I followed up with our London DC ops with the single hop‚Äôs IP address.  Hopefully with their direct relationship with upstream1 they can escalate through there and get it fixed.</p>
<p>/filed under crazy devops war stories</p>
<h3 id="update">Update</h3>
<p>Through upstream1, I got confirmation that the hop I pointed out (first in upstream2) had an internal ‚Äúmanagement module failure‚Äù which affected BGP and routing between two internal networks.  It‚Äôs still down (they‚Äôve routed around it) until they receive a replacement for the faulty module.</p>
<p>Thanks for the kind words and great comments here on Disqus, Reddit (<a href="http://www.reddit.com/r/linux/comments/11x7ld/the_little_ssh_that_sometimes_couldnt/">/r/linux</a> &amp; <a href="http://www.reddit.com/r/sysadmin/comments/129bpf/the_little_ssh_that_sometimes_couldnt/">/r/sysadmin</a>) and <a href="http://news.ycombinator.com/item?id=4709438">hacker news</a></p>
<h3 id="if-you-liked-this-you-might-also-like">If you liked this, you might also like</h3>
<ul>
<li><a href="http://www.fragmentationneeded.net/2012/01/dispatches-from-trading-floor-moldudp.html">Dispatches From The Trading Floor - MoldUDP</a></li>
<li><a href="http://blog.krisk.org/2013/02/packets-of-death.html">Packets of Death</a></li>
<li><a href="http://www.ibiblio.org/harris/500milemail.html">The case of the 500-mile email</a></li>
<li><a href="https://code.facebook.com/posts/1499322996995183/solving-the-mystery-of-link-imbalance-a-metastable-failure-state-at-scale/">Solving the Mystery of Link Imbalance: A Metastable Failure State at Scale</a></li>
<li><a href="http://www.pagerduty.com/blog/the-discovery-of-apache-zookeepers-poison-packet/">The Discovery of Apache ZooKeeper‚Äôs Poison Packet</a></li>
<li><a href="https://blog.cloudflare.com/the-story-of-one-latency-spike/">The story of one latency spike</a> &amp; <a href="https://blog.cloudflare.com/revenge-listening-sockets/">The revenge of the listening sockets</a></li>
<li><a href="https://mailman.nanog.org/pipermail/nanog/2018-September/096871.html">Service provider story about tracking down TCP RSTs</a></li>
<li><a href="https://cloud.google.com/blog/products/management-tools/sre-keeps-digging-to-prevent-problems">Finding a problem at the bottom of the Google stack</a></li>
<li><a href="https://news.sherlock.stanford.edu/posts/tracking-nfs-problems-down-to-the-sfp-level">Tracking NFS problems down to the SFP level</a></li>
<li><a href="https://engineering.skroutz.gr/blog/uncovering-a-24-year-old-bug-in-the-linux-kernel/">Uncovering a 24-year-old bug in the Linux Kernel</a></li>
<li><a href="https://dirtypipe.cm4all.com/">The Dirty Pipe Vulnerability</a></li>
<li><a href="https://blog.ando.fyi/posts/diagnosing-an-unsual-wifi-issue/">Resolving an unusual wifi issue</a></li>
<li><a href="https://patrickthomson.tumblr.com/post/2499755681/the-best-debugging-story-ive-ever-heard">The Best Debugging Story I‚Äôve Ever Heard</a></li>
<li><a href="https://notes.valdikss.org.ru/jabber.ru-mitm/">Encrypted traffic interception on Hetzner and Linode targeting the largest Russian XMPP (Jabber) messaging service</a></li>
<li><a href="https://medium.com/adevinta-tech-blog/its-not-always-dns-unless-it-is-16858df17d3f">It‚Äôs not always DNS ‚Äî unless it is</a></li>
<li><a href="https://www.youtube.com/watch?v=XrlrbfGZo2k">37C3 - Breaking ‚ÄúDRM‚Äù in Polish trains</a></li>
</ul>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My business card runs Linux and Ultrix (2022) (137 pts)]]></title>
            <link>https://dmitry.gr/?r=05.Projects&amp;proj=33.+LinuxCard</link>
            <guid>39268460</guid>
            <pubDate>Mon, 05 Feb 2024 23:06:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmitry.gr/?r=05.Projects&#x26;proj=33.+LinuxCard">https://dmitry.gr/?r=05.Projects&#x26;proj=33.+LinuxCard</a>, See on <a href="https://news.ycombinator.com/item?id=39268460">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><span>My business card runs Linux (and Ultrix), yours can too</span>

<b>UPDATES:</b>: See "<a href="#fwv2">Version 2</a>"</p><h2>Table of Contents</h2>
<p><img src="https://dmitry.gr/images/linuxCardPromo.jpg" alt="Linux card project cover image"></p><ol type="1"><li><a href="#_TOC_2673ce8234cc65bf5d5e81743172700b">Why?</a></li><li><a href="#_TOC_544a3f85f27429ab93dcd5ab2a63de0f">Parts selection</a></li><li><a href="#_TOC_7c1edc4d9290405fda54122244529141">What to emulate</a><ol type="a"><li><a href="#_TOC_d30f50757568b8cfaf8978a26d616b30">A MIPS primer</a></li><li><a href="#_TOC_1f0bd75c3792469488787400675c6973">What system?</a></li></ol></li><li><a href="#_TOC_7e76ca59b9efa6e1895f99d810e88da7">Let's emulate!</a><ol type="a"><li><a href="#_TOC_2e782d97f878671469dbb579dab9819e">The CPU</a></li><li><a href="#_TOC_d26852db28343b84596911de435caac9">The FPU</a></li><li><a href="#_TOC_5568f04140f1e9c2bde99c4e9c3572c9">The MMU</a><ol type="I"><li><a href="#_TOC_f05af7a1cabb44e206600aa7d7074fbc">MMU basics</a></li><li><a href="#_TOC_68fe0e8a8517a9a939dc8ad830f3ed3f">The MIPS MMU</a></li><li><a href="#_TOC_3ec65a91b377c508e2a27543e95858ca">Emulating the MMU efficiently</a></li></ol></li><li><a href="#_TOC_07a3dd247ad6bec7fe401aa11619959f">Communication</a></li><li><a href="#_TOC_3a173782d010897c6136c3b4ca51cd47">Hypercalls</a></li></ol></li><li><a href="#_TOC_d2ce354603c45f5e016fd47b9b5c8524">Bring on the hardware!</a><ol type="a"><li><a href="#_TOC_30aace8835696930f69a264dd89cbc60">The honeymoon period</a></li><li><a href="#_TOC_da93b232e827178270bfa561bdf6569c">How not to design a DMA unit</a></li><li><a href="#_TOC_e8ee65a238a03dd3a641faaff13a9c8a">Clocks again</a></li><li><a href="#_TOC_f53cca91f548c50486dcd52bac3efe7c">SD card support</a></li><li><a href="#_TOC_03751c187a665141b52e489852323619">Coolness enhancement</a></li></ol></li><li><a href="#_TOC_9ffdb95250e26c7a6b468126ac7c75b0">How it works</a><ol type="a"><li><a href="#_TOC_ddd6939c0f0cff6ceb8b36172e02b459">How a normal DECstation boots</a></li><li><a href="#_TOC_f9ff15b5ee1683a37691730e23cbd714">How uMIPS boots</a></li><li><a href="#_TOC_55a0a5396aa1bd6b11c6eb5f8ce8d62a">How uMIPS runs</a></li><li><a href="#_TOC_d70d07edc2b683000e09c709f5921fe9">Linux changes</a></li></ol></li><li><a href="#_TOC_9a98bd63857ec302fcec693aae109dde">Improving performance</a><ol type="a"><li><a href="#_TOC_0f63c0f6caf6daba30629abfa403d51a">Instruction cache</a></li><li><a href="#_TOC_fc5278bbec5501f7f5fe590fb59653f2">Improving CPU speed</a></li><li><a href="#_TOC_aee3d0e166f8b8358baf265cb949a756">Improving RAM bandwidth</a></li><li><a href="#_TOC_73dc18b03073c31c5a2bbf1264aff327">Dirty hacks specifically for Linux</a></li></ol></li><li><a href="#_TOC_23b5439c727c2e8557d28f8495da9977">How to build and use one</a><ol type="a"><li><a href="#_TOC_c39b56d4489fb2507289e7ae19567b80">Building</a></li><li><a href="#_TOC_b3abf203d70a08b6d9725f0000f27122">Building from source</a></li><li><a href="#_TOC_7b797cff6f4cf0ca82225d6125fe1861">If you are lazy</a></li><li><a href="#_TOC_3f05d6f38862a5b18b2eb4e867a61fb1">Using</a></li></ol></li><li><a href="#_TOC_425d8e1e777a03c3e220dfaac38dbf1f">Version 2</a><ol type="a"><li><a href="#_TOC_2b50d6628ed817de809605854d478f68">Booting Ultrix</a><ol type="I"><li><a href="#_TOC_2375a25fb86a26c24006ed1d6e2c1c47">About Ultrix</a></li><li><a href="#_TOC_c7bce03d32236f53d1a3d5c04e680838">First time booting Ultrix</a></li><li><a href="#_TOC_87e05c1a936fe8f08f1621e5cd10c534">SCSI</a></li><li><a href="#_TOC_938bce276b64c8ccdaeb079ff7a0bd84">LANCE</a></li><li><a href="#_TOC_2b0d0fb2ee0246234fe0fd9845b87021">ESAR</a></li><li><a href="#_TOC_73d22765ace36f09f4bab935a1608d3c">Memory probing &amp; proper PROM API</a></li><li><a href="#_TOC_c6323dca5b2dcaf05756b569ad13f4b9">Ultrix Loader</a></li></ol></li><li><a href="#_TOC_fd2d1e73f2cd71a4c375685b4abed537">Making Ultrix work</a><ol type="I"><li><a href="#_TOC_42badd9e49002a3cefeaaf28867add83">Framebuffer</a></li><li><a href="#_TOC_347b8386b145ced18ea02f2654e00883">Mouse, Keyboard, ... and Tablet</a></li><li><a href="#_TOC_c4d283323af70979073f5cb6145f3a4b">Patches</a></li></ol></li><li><a href="#_TOC_9f744f0f0ac29e818b7b95da8ad8ee40">Improvements in the emulator</a><ol type="I"><li><a href="#_TOC_7c775bb4800b345425796dce2acef3a8">USB improvements</a></li><li><a href="#_TOC_c5f0dc32adc4e66649115eef7e76f94f">More perf improvements</a></li><li><a href="#_TOC_819a79dcd016b5a99e05c56515825abb">Removing the TLB refill fast path</a></li><li><a href="#_TOC_dda4cbe5c1a77c2c9bf66b0adc6fff4b">Cache geometry changes</a></li><li><a href="#_TOC_b3c8fd852368b78e09e2fc8b39a6ea5c">Serial improvements</a></li></ol></li><li><a href="#_TOC_cb1862398dbf0b5f7d8a7dbe73bee626">More Floating Point Unit work</a></li><li><a href="#_TOC_244cd79fc0c2e4a295228e647cf88dbc">A bootloader</a></li><li><a href="#_TOC_7fa430e699655fa918b84f63d1c5fae5">Hardware improvements</a><ol type="I"><li><a href="#_TOC_9183d42e96c2104c27070b535e3793d9">v1.3 hardware</a></li><li><a href="#_TOC_8971392389323f2057db749c94dcba05">And old hardware too</a></li></ol></li><li><a href="#_TOC_1a574cfae32687e675d081616b06e0a0">Building from source (updated)</a><ol type="I"><li><a href="#_TOC_3d2780b0eeabee178926de36f72658b8">The emulator</a></li><li><a href="#_TOC_7213a2cd3fa80d577b3092f614b7fdb3">The loader</a></li></ol></li><li><a href="#_TOC_d8926db6c437f738792454ba22ec2755">Further Updates</a><ol type="I"><li><a href="#_TOC_52cbfe3bfc8a13d03124dd2283d83807">Firmware v2.1.1</a></li><li><a href="#_TOC_6b3ae1897005585fd36708ff39e693cf">Firmware v2.2.0</a></li></ol></li></ol></li><li><a href="#_TOC_3cd960e7edc378fd94d8777b595ea515">In conclusion</a><ol type="a"><li><a href="#_TOC_0407c27180c9b019e644e8ad4c6a9324">Acknowledgements</a></li><li><a href="#_TOC_c20c35ef53bf1b70789ce94e66800147">Downloads</a></li></ol></li><li><a href="#_TOC_7e1e75c32bc9b275daf70df8cba8efb5">Comments...</a></li></ol>







<h2>Why?</h2>
<p><a href="https://dmitry.gr/images/linuxCardWhole.jpg"><img src="https://dmitry.gr/images/linuxCardWholeSmall.jpg" alt="Linux card in action"></a></p><p>A long long time ago (in 2012) I <a href="https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">ran Linux on an 8-bit AVR</a>. It was kind of a cool record at the time. I do not think anyone has beaten it - nobody's managed to run Linux on a lower-end device than that 8-bit AVR. The main problem was that is was too slow to be practical. The effective speed was 10KHz, the boot time was 6 hours. Cool, but I doubt that any one of those people who built one of those devices based on my design ever waited for the device to boot more than once. It was time to improve it!
</p>
<p>So what could I improve? A number of things. First, I wanted the new design to be speedy enough to boot in a few minutes and reply to commands in seconds. This would make using the device practical and not a test of patience. Second, I wanted it to be easy to assemble for anyone. This meant no components with tight spacing, no components with too many pins, and no components with contacts hidden underneath them. A part of this wish was also that someone could <em>actually</em> assemble one, meaning that I had to select components that are <em>actually</em> buyable in the middle of the current ongoing shortage of, well, everything. Additionally, I wanted the device to be easy to interface with. The original project required a USB-to-serial adapter. This would not do. And, finally, I wanted the whole thing to be cheap and compact enough to serve as my business card.
</p>

<h2>Parts selection</h2>
<p><a href="https://dmitry.gr/images/linuxCardSchem.png"><img src="https://dmitry.gr/images/linuxCardSchemSmall.jpg" alt="Linux card schematics"></a></p><p>Some things were pretty easy to decide on. For storage, for example, microSD is perfect - easy to interface with, widely available, cheap. I picked a simple microSD slot that is easy to solder and easy to buy: <a href="https://octopart.com/1140084168-amphenol-25513977?r=sp">Amphenol 1140084168</a>.
</p>
<p>Some choices were a litle harder, but not too much so. For example, I was surely not going to use DRAM again. It requires too many pins, necessitating more soldering than I would consider acceptable, given that I wanted this device to be easy to assemble. SRAM in megabyte sizes does not really exist. But there is a cool thing called PSRAM. It is basically DRAM, but in easy mode. It itself takes care of all the refreshing and externally acts just like SRAM. Ok, cool, but still that would usually be a lot of pins. Right? Enter "AP Memory" and "ISSI". They make QSPI PSRAM chips in nice SOIC-8 packages. AP Memory has models with <a href="https://octopart.com/search?q=APS1604M-3&amp;currency=USD&amp;specs=0">2MB</a> and <a href="https://octopart.com/search?q=APS6404L-3&amp;currency=USD&amp;specs=0">8MB</a> of RAM per chip, ISSI has them in <a href="https://octopart.com/search?q=IS66WVS1M8BLL&amp;currency=USD&amp;specs=0">1MB</a>, <a href="https://octopart.com/search?q=IS66WVS2M8BLL&amp;currency=USD&amp;specs=0">2MB</a>, and <a href="https://octopart.com/search?q=IS66WVS4M8BLL&amp;currency=USD&amp;specs=0">4MB</a> sizes. I decided to use these. They are available and my code supports them all!
</p>
<p>There were some miscellaneous choices, like which regulator to use. I chose <a href="https://octopart.com/search?q=MIC5317-3.3YM5TR&amp;currency=USD&amp;specs=0">MIC5317-3.3YM5TR</a> due to having worked with it before and it being available in my "random chips" box. It is also easily available to buy.
</p>
<p>The USB connector was also a fun choice. I settled on: none. With the proper PCB thickness, one can lay out the board edge to fit into the end of a USB-C cable. I've seen this done before for micro-USB and figured it could be done for USB-C as well. At the end, though, I did not even need to do it, since <a href="https://github.com/Pinuct/Eagle_PCB_USB_connectors">someone else</a> already saved me the 30 minutes it would have taken. I just had to remember that the board thickness needs to be 0.8mm for this to work. 
</p>
<p>The last choice was the hardest - which microcontroller to use. The criteria were: built-in USB, no more than 32 pins with at least 0.65mm spacing, no pin-less packages, actually available to buy, QSPI support, as fast as possible. I did not get my last two wishes. After much searching and filtering for "in stock", I was forced to settle for an ATSAMD21 series chip, specifically the <a href="https://octopart.com/search?q=ATSAMDA1E16b-a&amp;currency=USD&amp;specs=0">ATSAMDA1E16</a>. It is not fast (specced to 48MHz, I clock it at 90MHz), it has many bugs (especially in its DMA engine), but it can be bought, it is easy to solder, and it'll have to do... <b>UPDATE</b>: another chip is now supported too, see later in this article.
</p>

<h2>What to emulate</h2>
<p><a href="https://dmitry.gr/images/linuxCardWholeBoot.png"><img src="https://dmitry.gr/images/linuxCardWholeBootSmall.png" alt="Linux card boot log"></a></p><p>I could have just taken my old ARM emulator (uARM) and used that. But what's the fun there? I decided to pick a new target. The ideal emulation target will: (1) be a RISC chip so that I have to spend fewer cycles on decoding instructions, (2) have no condition codes (like MIPS) or only set them on demand (like ARM), so that I am not wasting time calculating them every virtual cycle, (3) be 32-bit since 16-bit machines are all funky and 64 bit is a pain to emulate, (4) be known, and (5) have a workable set of GNU tools and Linux userspaces available. This set of requirements actually only leaves a few candidates: PowerPC, ARM, MIPS. I've done ARM, and I had no desire to mess with an endian-switchable CPU, so MIPS it was! This gives rise to the internal name of the project: uMIPS.
</p>
<h3>A MIPS primer</h3>
<p>MIPS is old - one of the original RISC designs. If you are a RISC-V fanboy(/girl/being), MIPS will look familiar - it is where 99.9994% of the initial RISC-V spec was copied from. The original MIPS was a 32-bit design, optimized for ease-of-designing-it. It has (and does not hide) a delay slot, has a lot of registers, including a hard-wired zero register, and does not use condition codes. The original design was R2000, back in 1986, followed soon by the improved R3000 in 1988. These were the last chips implementing the MIPS-I instruction set. MIPS-II was short lived and only included the R6000, which barely saw the light of day. The real successors were the MIPS-III R4000-series chips, released in 1991. These were 64-bit already in 1991! Clearly, the easiest target would be the R2000/R3000 chips with their simple MIPS-I instruction set.
</p>
<p>MIPS-I is a <a href="https://vhouten.home.xs4all.nl/mipsel/r3000-isa.html">rather simple instruction set</a>. So much so that a complete emulator of just the instructions can be written in under 1000 lines of C code without any dirty tricks. The floating point unit is optional, so it can be skipped (for now). The MMU is weird. It is just a TLB that the software must fill manually. This may seem like a rather unusual choice, but in reality it is a clever one, if you're in 1986 and tring to minimize the number of transistors in your chip. Why have a hardware pagetable walker, when you can make the software do it? You may ask how it handles the situation where the code that would do the walking is itself not mapped? Well, a part of physical memory is always hard-mapped at a certain address, and all exception handlers live there. Even if this were not the case, since the software manages the TLB, it would not be hard to reserve an entry for this purpose. The hardware even has support for some "wired" entries that are meant to be permanent. More on all of this later.
</p>
<h3>What system?</h3>
<p>MIPS R2000/R3000 is a processor. A processor does not a complete system make. What system to emulate? I searched around for a cool system and settled on DECstation2100 (or its big brother - DECstation3100). Why bother? It seemed like a simple system that Linux does support. Initially I was not planning to emulate the whole thing. Why? I had no plans to emulate the LANCE network adapter or the SII SCSI adapter. The last part might surprise you, since we will need a disk to use as our root fs. I did later add emulation of both of these parts, to make Ultrix happy.
</p>

<h2>Let's emulate!</h2>
<h3>The CPU</h3>
<p>MIPS is a rather old instruction set, which shows in a few places. The main one is that it attempts to prevent signed overflow. The normal instructions used for addition and subtraction will cause an actual exception if they cause an overflow. This does not map to how CPUs are used today, so nobody cares, but I still had to emulate it. There are "unsigned" versions of the instructions for addition and subtraction that do not do this, which is what all modern compilers will emit on MIPS.
</p>
<p>I wrote an emulator for the CPU in C first, to allow easy testing on my desktop, while the PCBs were being manufactured. It was not fast, nor meant to be, but it did allow for testing. You can see this emulator in <span>cpu.c</span>. Along the way here, I implemented some features of the R4000 CPU optionally. It turned out that to boot Linux compiled with modern compilers, this is necessary, as the compilers assume these instructions exist. Technically this is a bug. Realistically, I am likely the only person to ever notice. So, which features did I need to add? Likely branches (<span>BxxL</span> instructions), conditional traps (<span>Tcc/TccI</span> instructions), and atomics (<span>LL/CC</span> instructions).
</p>
<p>Of course, C is not the language one uses when one wants to go fast. I wrote an emulator in assembly too, targetting ARMv6-M (for the Cortex-M0 MCU I chose). I later added a sprinking of enhancements for ARMv7-M (in case I ever upgrade the project to a fancier CPU). This was tested on a Cortex-M7 and worked well too. The assembly emulator core is contained in <span>cpuAsm.S</span> and the ARMv6-M specific parts are in <span>cpuM0.inc</span>
</p>
<p>I mentioned delay slots earlier. What is a delay slot? Well, back in the day it was considered cool to expose your CPU's pipeline to the world. Just kiding, it was just a way to save some more transistors. Basically, the instruction after a jump will be executed even if the jump happens. This is called the delay slot. A naive way to avoid dealing with this is to place a <span>NOP</span> after each jump instruction. But with a good compiler, the delay slot can be put to a good use in almost all cases. Obviously one cannot place a jump instruction in the delay slot, since the CPU is already jumping somewhere. Doing this is illegal and undefined. An issue arises, however, if the instruction in the delay slot causes an exception of any sort. The CPU will record that the instruction was in the delay slot, and point the exception handler to the <em>jump</em> whose delay slot we're in. There is no way to return to this "in delay slot" state, so the exception handler is expected to take steps to somehow execute the delay-slot instruction and then complete the jump.
</p>

<h3>The FPU</h3>
<p>The DECstation came with an FPU, so that floating point operations would be fast. Back then this was a separate chip, which was optional in a MIPS R2000/R3000 system. Linux, in fact, will more-or-less corectly emulate the FPU if it is not present, but this is slow. I used this mode initially, and even fixed a few bugs in Linux's emulation, but, in the end, I implemented an FPU emulator. This was necessary since it seems like a lot of MIPS binaries I could find all assume the FPU is available and use it freely. I never reimplemented the FPU emulator in assembly, instead calling out to the C FPU emulator when needed. I figure that squeezing a few cycles out of each instruction is meaningless when the actual FPU operation takes hundreds. The code for this is in <span>fpu.c</span>. I include Linux patches to remove FPU emulation support from the kernel. This saves some RAM. Later, I also added support for a "minimal" FPU - it supports the registers but no operations. This is allowed by the spec, since the FPU may refuse to execute any operation it is not sure it cna di perfectly correctly, so ay compliant OS must implement a full FPU fallback anyways. Why? This saves 16K of code size in the binary, opening the possibility of running uMIPS on smaller devices yet.
</p>
<h3>The MMU</h3>
<h4>MMU basics</h4>
<p>(this is a <em>very</em> oversimplified summary, feel free to skip if you know this, and do not complain to me that it is not perfectly accurate!)
</p>
<p>Most CPUs access memory using virtual addresses (<span>VA</span>). The hardware works in terms of physical addresses (<span>PA</span>). Ability to map one to the other is the underpinning of memory safety in modern operating systems. The purpose of an <span>MMU</span> (Memory Management Unit) is to translate virtual addresses to physical addresses, to allow for this mapping. Normally this is done using a tree-like structure in RAM, called a <span>pagetable</span>. Most CPUs have a component whose job it is to walk that structure to resolve what physical address a given virtual address maps to. This component is a <span>pagetable walker</span>. In most cases the <span>pagetable</span> has 3 or 4 levels, which means that resolving a <span>VA</span> to a <span>PA</span> requires reading 3 or 4 words from main memory. Clearly you do not want to do 3 useless memory accesses for every useful one. So usually another component is included in an <span>MMU</span> - a <span>TLB</span> (Translation Lookaside Buffer). Basically you can think of a <span>TLB</span> as a cache of some of the current <span>pagetable</span>'s contents. The idea is that before you go off doing those 3-4 memory reads into the <span>pagetables</span>, you can check and see if the <span>TLB</span> has a matching entry. If so, you can skip the <span>pagetable walk</span>.
</p>
<p>Clearly, like any cache, the <span>TLB</span> needs to stay in sync with the things it caches (the current <span>pagetables</span>). So, if the OS changes the <span>pagetables</span>, it needs to flush the <span>TLB</span>, since it might have stale entries. Usually, <span>TLB</span>s expose very little interface to the CPU, so there isn't a way to go read all the entries and remove only the newly-invalid ones. Additionally, this would be slow, so this is not usually done. However, invalidating the entire <span>TLB</span> also has costs - it needs to be re-filled, at the cost of 3-4 memory accesses per entry. This could hurt performance. A solution commonly used is called an <span>ASID</span>.
</p>
<p>What are the four main cases when <span>pagetables</span> might be modified? (1) Adding a new mapping over a virtual address that previously was not mapped to anything, (2) changing permissions on on existing mapping, (3) removing a mapping, and (4) entirely changing the memory map (for example to switch to a completely different process). In case 1, no <span>TLB</span> flush is necessary, since no stale <span>TLB</span> entry can exist. Cases 2 and 3 do indeed require flushing the <span>TLB</span>, but they aren't that common. Case 4 is quite common, though. It is done at every context switch. One might point out that since we're changing the entire memory map, the entire <span>TLB</span> would be invalid, and thus flushing it isn't a problem. This is wrong. Besides mapping userspace things, the <span>MMU</span> also maps various kernel structures, and there is no point penalizing them.
</p>
<p>If we could somehow tag which entries in the <span>TLB</span> go with which process, and temporarily disable them when another process runs, we could avoid a lot of context-swich flushing and the performance costs imposed by it. It would also be cool if we could tag entires that belong to the kernel and are valid in every process. Well, this exact technology exists in many <span>MMU</span>s. The idea here is that each <span>pagetable</span> entry will have a bit marking it as "global" (valid in all memory maps) or not. There should also be a register in the CPU setting the current <span>ASID</span> (Address Space ID). When a <span>TLB</span> entry is populated from the <span>pagetables</span>, the current <span>ASID</span> is recorded in it. When a lookup in the <span>TLB</span> is done, only entries matching the current <span>ASID</span> or those marked "global" will match. Cool!
</p>
<h4>The MIPS MMU</h4>
<p>The idea at the time was to save transistors. Which of the above could be cut? Well, cutting out the <span>TLB</span> guarantees terrible performance in all cases. But that <span>pagetable walker</span>, do we really need it? What if we make the sotware do it? We can add a little bit of assistance, like ability to manage the <span>TLB</span> efficiently, but skip on the <span>pagetable walker</span> hardware. This is what MIPS did. Here is the MIPS virtual address space:
</p>
<p>Addresses               Name   Mapping
0x00000000..0x7fffffff  kuseg  mapped via MMU
0x80000000..0x9fffffff  kseg0  mapped to physical 0x00000000..0x1fffffff, cached if there is a cache, only accessible in priviledged mode
0xa0000000..0xbfffffff  kseg1  mapped to physical 0x00000000..0x1fffffff, not cached, only accessible in priviledged mode
0xc0000000..0xffffffff  kseg2  mapped via MMU, only accessible in priviledged mode
</p>
<p>So, as you can see, some <span>VA</span>s do not map via the <span>MMU</span> at all. This means that code living there is able to run no matter the state of the <span>MMU</span>. Linux and Ultrix, predictably, put the kernel in <span>kseg0</span>. The kernel does, however, need to be able to dynamically map things in as well. <span>kseg2</span> is one gigabyte of address space that is mappable via the <span>MMU</span> that the kernel can use. Memory-mapped devices will usually be accessed via <span>kseg1</span>. The 2 gigabytes at the bottom of the address range(<span>kuseg</span>) are for userspace tasks.
</p>
<p>What entry in a <span>TLB</span> should one replace when one needs to insert a new entry? An obvious answer might be "the one least recently used", but that would require tracking use, which costs transistors too. A simplification is "the one least recently added". This is easy, but it hides a fatal flaw. Imagine your <span>TLB</span> has N entries, and your workload sequentially uses N + 1 addresses, such that each would need a <span>TLB</span> entry. Now you'll always be replacing the entry you're about to need, guaranteeing that you <em>NEVER</em> hit the <span>TLB</span> and do a lot of pointless <span>pagetable</span> walks. How do we avoid this? The simplest method is replace a random entry. Sure, it might be the entry you're about to need, but for an N-entry <span>TLB</span> the chances are 1/N.
</p>
<p>Generating random numbers is slow in software, so MIPS R2000/R3000 provide some help. The CPU has a register called, literally <span>RANDOM</span> which is supposed to be constantly incrementing, every cycle. Since the "when" of "when will you next need a new <span>TLB</span> entry" is not predictable, this is as good as random, and requires very few transistors. The idea is that whenever you need to replace a <span>TLB</span> entry, you use a special instruction <span>TLBWR</span> to write to a random entry. I did not tell you about <span>ASID</span>s by accident either. The MIPS R3000 <span>MMU</span> implements a 6-bit <span>ASID</span>.
</p>
<h4>Emulating the MMU efficiently</h4>
<p>Emulating the R3000 <span>MMU</span> is a bit of a pain. Since any entry can be in any location, the proper way to do a lookup is to check each one. Doing a 64-cycle loop for every memory access is a non-starter speed-wise, of course. I use a hashtable indexed by the virtual address to keep all the TLB entries in buckets for faster checking. Using 128 buckets virtually guarantees that most buckets have zero or one entry in them, permitting much faster lookups. Initially this was a simple table of pointers, but this used too much RAM, so now it is a table of indices.
</p>
<h3>Communication</h3>
<p>The DECstation had a few ways to communicate with the outside world. It had a built-in network card<s>, which I do not emulate</s>. It was optional<s>, and I haven't found a use for it yet</s>. Maybe I will later - it does not look complex. It also had a SCSI controller which one could attach hard disks and other SCSI peripherals to. Emulating this would be a fun challenge, and I'll probably get to it later, but I did not do it now - it was not necessary - I wrote a paravirtualized disk driver for Linux using hypercalls, more on this later. There was also an optional framebuffer card one could install that added support for a monochrome or a color display. Emulating these would also not be too hard, but my business card lacks a display, <s>so I did not do it either</s> - plus I am not even sure that Linux can make a use of it.
</p>
<p>The last method of communications that the DECstation had was <span>DC7085</span> - a serial port controller that is basically a clone of a PDP11-era <a href="https://gunkies.org/wiki/DZ11_asynchronous_serial_line_interface"><span>DZ-11</span></a>. It supports four serial ports at a blistering 9,600bps speed (or any integer division thereof). Each serial port was allocated a purpose, and they were wired to different connectors indicating this purpose. #0 was for the keyboard, #1 for the mouse, #2 for modem, and #3 for printer. To the machine they are all the same, this was just the purpose DEC assigned to them. The stock <span>PROM</span> would use #3 as serial console instead if it did not detect a keyboard at #0, thus it is customary to use #3 as serial console for Linux on the DECstation. My <span>PROM</span> surrogate does not bother looking for or supporting external keyboard, and just defaults to serial console on #3. That being said, since it is cool to allow multiple login sessions, I also export <s>#0</s> #2 as a second virtual serial port, so that you may login from two serial consoles at once, and do two things at once. How cool is that?
</p>
<p>So, how do I export these serial ports? When you connect the card to a computer, it'll show up as a USB composite device comprised of two CDC-ACM virtual serial ports. One of them is port #3, another is port <s>#0</s> #2 on the virtual <span>DZ-11</span>. How will you know which is which? #3 has the boot console printing and will have the initial <span>sh</span> prompt. If you do not see this, try the other one, computers do not always number them in the order I export them.
</p>
<h3>Hypercalls</h3>
<p>In the real world the <span>PROM</span> had to probe the real hardware to detect what was present where. As my <span>PROM</span> is running in an emulator, there is no need for such mess. We can simply request things from the emulator in an agreed-upon way. That way is a <span>hypercall</span> - a special invalid instruction that, if encounted in supervisor mode, the emulator will treat as a request for some kind of service. The instruction I chose is <span>0x4f646776</span>, which is in the <span>COP3</span> (coprocessor 3) decode space that was not allocated to any real purpose in these chips. The calling convention is close to the normal C calling convention on MIPS: parameters are passed in <span>$a0</span>, <span>$a1</span>, <span>$a2</span>, and <span>$a3</span>, return values are in <span>$v0</span> and <span>$v1</span>. The <span>$at</span> register gets the "hypercall number" - the specific service we're requesting.
</p>
<p>A few hypercalls are implemented. #0 is used to get the memory map. The parameter is word index of the memory map to read. Word 0 is "how many bits the memory map bitmap contains", word 1 is "how many bytes of RAM each bit represents", words 2 and on are the bits of the map, up to the total specified in word 0. This can be used to build a memory map that the <span>PROM</span> can furnish to the running OS and allows me to have discontinuous RAM. Linux supports this and I tried it, but did not end up needing it. It is here in case I change my mind and need it again.
</p>
<p>Hypercall #1 outputs a single byte to the debug console (which is the same as <span>DZ-11</span> port 3). This is used by the <span>PROM</span> and <span>mbrboot</span> to output debug strings without needing to have a complete <span>DZ-11</span> driver in there. Hypercall #5 will terminate emulation. This can be used on the PC version of the emulator to quit peacefully.
</p>
<p>Hypercalls #2, #3, and #4 are used for SD card access. #2 will return card size in sectors, #3 will request a read of a given sector to a given physical RAM address and reply with a nonzero value if that worked. #4 will do the same for a card write.
</p>

<h2>Bring on the hardware!</h2>
<h3>The honeymoon period</h3>
<p><a href="https://dmitry.gr/images/linuxCardBoard.png"><img src="https://dmitry.gr/images/linuxCardBoardSmall.jpg" alt="Linux card board layout"></a></p><p>The first revision of this board came up well initially, after I sorted out the mess that is ATSAMD21's clocking system. I appreciate flexibility as much as the next guy, but this thing is <em>TOO</em> flexible. It took a lot longer than I'd care to admit to get this thing running at a sane speed and to enable some peripherals. The docs were too sparse to be of much use, too. Atmel, what happened to you? You used to have the best docs!
</p>
<p>The first revision of the board had two memory chips, each on their own SPI bus, an SD card on an SPI bus, and USB with the proper resistors. The USB was perfect. Unlike everyone and their grandmother (STMicro, I am glaring at you), Atmel did not license annoying Synopsis USB IP. They made their own. It is easy to use, elegant, and works well. Seriously, it just worked. In two days I got the hardware to work and wrote a USB device stack. I tip my hat to the team that worked on the USB controller. That being said, I have concerns. My main issue: USB descriptors aren't small. They are constant. I'd prefer to keep them in flash. I'd prefer to, but cannot. The USB unit uses a built-in DMA unit to read the data to send. This DMA unit <em>CAN</em> access flash, but if you have any flash wait states enabled, it sends garbage. I suspect that Atmel only tested it for reading from RAM, forgot that some memories have wait states, and did not account for that. Keeping all my descriptors in RAM is a colossal waste of RAM, which there is only 8KB of. Remember that tiped hat? I rescind it, Atmel. I had to work around the issue by sending the descriptors one piece at a time (rather than letting the hardware DMA it all automatically) just to save the valuable RAM.
</p>
<p>Using the SPI units directly worked well enough, until I tried to speed them up. Past about 18MHz The received data was garbled (missing a bit or two, all the following bits shifted). No amount of searching found an issue in my code, and all sample code did more or less the same things. My bus analyzer showed no issues. What gives? <a href="https://microchipsupport.force.com/s/article/SPI-max-clock-frequency-in-SAMD-SAMR-devices">THIS GIVES</a> (<a href="https://archive.ph/IJTHU">archived</a>)! I was beyond furious when I found this forum post. Here I was, trying to build a fast device, and my SPI bus was going to be limited to the speed of a tired snail calmly strolling through peanut butter! With some more testing I found that the SPI units will work fine to about 16MHz, which I'll have to live with.
</p>
<p>The SPI units have no FIFOs, so code must manually feed them one byte at a time and read one byte at a time. This means that there is space between bytes on the bus as code wrangles bytes in and out of registers and memory. This is a waste of potential speed. The solution is DMA. Luckily this chip has DMA. Unluckily, it is fucked beyond belief, to a point where I am beginning to suspect that it was designed by a sleep-deprived stark raving lunatic.
</p>
<h3>How not to design a DMA unit</h3>
<p>A normal garden-variety DMA unit has some minimal global configuration, and a few channels, each independent from the rest. Each channel will usually have a source address, a destination address, a length, and some configuration, to store things like transfer chunk size, trigger, interrupt enable bits, etc. Thus it is common in ARM MCUs to have each channel have precisely these 4 32-bit configuration registeres: SRC, DST, LEN, CFG. This is 16 bytes of SRAM per channel. ATSAMD21 has 12 DMA channels, so that would be 192 bytes of config data for the DMA unit as a whole. Not that much. Well, Atmel was having none of this! Instead, the unit itself only has a <em>POINTER</em> to where in the user RAM all this config data lives. For every transfer, the DMA unit will load its internal state for the active channel from this structure in RAM, and then operate on the channel. If another channel's data was already loaded, it will be written out to RAM first. Depending on your experience level, you may already be on your third or fourth "oh, hell fucking no" as you read this...
</p>
<p>Why is this bad? Let's imagine two SPI units being fed by DMA. Each one will have two DMA channels, one for receive, one for transmit. Four channels are active in total. Now what happens as both the SPI units are enabled? Two DMA channels (the transmit ones) will go active and attempt to send a byte. One will go first, then the second. This will generate <em>14</em>(!!) bus transactions to the RAM! Four to read config data for one channel, one to read the byte to send, four to write back this config data, four to read the config data for the next channel, and one more to read the byte to send. So in order to send 2 bytes, the DMA unit did 14 RAM accesses. Not great. But wait...there's more. Let's take a look what happens next, as the SPI units finish sending this byte and clocking in the received byte, but are also ready for the next byte to send! At this point in time, logically only four bytes need to be moved (two from the units into the receive buffers, two from the transmit buffers into the units). Let's see how this plays out. Remember the DMA unit's internal config data is currently loaded to the second transmit channel's. First, it'll have to do 4 writes to write that data out, then 4 reads to load the first receive channel's structures, one write to memory to write the received byte to RAM, 4 writes to write out this channel's structures out, 4 reads to load structures for receive channel number 2, one write of the received byte to RAM, 4 bytes to write out the config structure for this channel back out to RAM, and then the 14 we already discussed to send the next two bytes. That adds up to 36 RAM accesses to simply read two bytes and write two bytes. All this pain, simply to save the transistors on the 192 bytes of SRAM it would have taken for the DMA unit to store all the config data internally.
</p>
<p>So, why is this bad? Let's say our MCU is running at its designed speed of 48MHz, its SPI units running at their designed max speed of 12MHz. At the point the second bytes need to be sent and first received bytes need to be received, we'll need to perform 36 accesses to RAM, but also 4 accesses to the SPI unit. The SPI unit is on an APB bus, which means that any access to it takes at least 4 cycles. This means that in between each sent and received byte we'll need 36 + 4 * 4 = 52 cycles. If the SPI unit runs at 1/4 the CPU speed, then it will send/receive a byte every 8 * 4 = 32 cycles. So every 32 cycles we'll need to do 52 cycles' worth of work. When they do not get enough cycles, the DMA channels give up and stop working... Oops... 
</p>
<p>So, what can be done? I worked out a hybrid method where I send data using CPU writes and receive using DMA. This worked for two channels, but would not work for more. Once I got rev2 boards that had 4 RAM chips, even this failed, as just the 4 receive DMA units starved each other of bandwidth and got cancelled. Why was Atmel so damn stingy with internal SRAM? We'll probably never know. But they could have solved this exact issue simpler than with 192 bytes of SRAM in the DMA unit. Just adding a 4-byte FIFOs into the SPI units would do as well, then each DMA transaction could transfer more than a single byte, alleviating this traffic jam. Sadly, apparently nobody at Atmel has even tried to actually use their chip for anything. Atmel, what happened to you?
</p>
<h3>Clocks again</h3>
<p>My clocking woes were not over yet. This chip has a number of internal oscillators, one of which is supposed to be a rather precise 32KHz oscillator called <span>OSC32K</span>. I wanted to use that as a source clock for a timer to implement my virtual real time clock. Well, despite much pain and many tears, the damn clock would not start... ever. The code should be simple: <span>SYSCTRL-&gt;OSC32K.bit.EN32K = 1; SYSCTRL-&gt;OSC32K.bit.ENABLE = 1; while (!SYSCTRL-&gt;PCLKSR.bit.OSC32KRDY); </span> Yeah... that did not happen. At the end, I decided that I can use a less-precise <span>OSC32KULP</span> to clock my timer. That one did start and I was able to use it. By this point in the project I was worn out, desensitized to this chip's many faults, and completely out of WTFs, so I resigned myself to a slightly imprecise real-time clock and trudged on.
</p>
<h3>SD card support</h3>
<p>Not really much to say about SD card support. Been there, done that, got the t-shirt. My initial code for the prototype used multi-block reads and writes for better card access speed, but in the final prototype I was forced to abandon it since one of the RAM chips on the b2 boards shared the SPI bus with the SD card, so leaving the card selected was not an option. This was not that big a deal since SD access is rarely, if ever, a bottleneck here. Any card up to 2TB is supported.
</p>
<p>In the v2 revision of the board I wired up card detect pin to the MCU. It was not used, but I thought that I might find a use for it. I did not, so in v3 boards it was removed. I also added a card "activity" LED which lights up when card is accessed. It is simply a LED between the card's chip select line and Vcc. Whenever the card is selected, it is on. This LED also surves a second purpose. If at boot time the SD card or SPI SRAMs fail to initialize, it'll blink out an error code to help identify the problem.
</p>
<h3>Coolness enhancement</h3>
<p>Now that the prototype worked and I was doing the layout for the final version, I decided to do some things to make it look cool. I buried all the traces in layers 2 and 3, leaving layers 1 and 4 uninterrupted copper. It loooks super cool! Of course the top layer copper is interrupted for the actual SMT pads, but other than that, it is all perfectly smooth and looks amazing!
</p>

<h2>How it works</h2>
<h3>How a normal DECstation boots</h3>
<p>Normally there is a built in 256KB ROM (called <span>PROM</span> by DEC) at physical address <span>0x1fc00000</span> that contains enough code to show messages onscreen and accept keyboard input, talk to SCSI devices, load files from disk to RAM and jump to them. This <span>PROM</span> also provides a lot of services to the loaded operating system via an array of callbacks. This includes things like console logging, EEPROM-backed environment variables, memory mapping info, etc. This is rather similar to UEFI. Normally this <span>PROM</span> would read the environment variables from EEPROM that would tell it which device to boot, and then load a kernel and boot from that device if all goes well. This emulator does not boot this way
</p>
<h3>How uMIPS boots</h3>
<p>I had no desire to include a large ROM in the emulator, as the flash space in the microcontroller is limited. I also do not have a graphical console or a keyboard per se. That being said, I had to implement a sizeable subset of the <span>PROM</span> somehow, since MIPS Linux uses it. What to do? I decided to come up with my own boot process, which can still work just as well. There is indeed a ROM at <span>0x1fc00000</span>. This is necessary for rebooting to work from Linux. <s>That rom is tiny - 32 bytes</s>. Its source code is found in the "romboot" directory. It <s>merely</s> loads the first sector of the SD card to the start of RAM at <span>0x80000000</span> and jumps to it. The first sector of the SD card contains a standard MBR partition table and up to 446 bytes of code. The code that lives here can found in the "mbrboot" directory. It is also rather simple. It looks through the partition table for a partition with type byte of <span>0xBB</span>. If not found, an error is shown. Else, the partition in its entirety is read into RAM at <span>0x80001000</span>, and then jumped to. This partition can be arbitrarily large, and this is where my implementation of the "PROM" lives. The actual size limit on it is placed by the fact that MIPS Linux expects to be loaded at <span>0x80040000</span>. This is no accident - the first 192K of RAM is reserved for the <span>PROM</span> to use as long as the operating system expects to use <span>PROM</span>'s services. Thus the limit on the loader's size is 188K. 
</p>
<p>My <span>PROM</span> implementation's code can be found in the "loader" directory. It will search the SD card for a partition marked as active, attempt to mount it as FAT12/16/32, and look for a file called "VMLINUX" in the root directory. If found, it will be parsed as an ELF file, properly loaded, and run. Else an error will be shown. As this code has no serious size limits, it implements a proper ability to log to console, printf, and all sort of such creature comforts. As far as <span>PROM</span> services go, it provides console logging, memory mapping info, and reading environment variables, at least enough to make Linux happy. I have not tried to boot other operating systems on uMIPS (yet?).
</p>
<p>The kernel commandline I pass is rather simple: <span>earlyprintk=prom0 console=ttyS3 root=/dev/pvd3 rootfstype=ext4 rw init=/bin/sh</span>. The first parameter provides for early boot logging via the <span>PROM</span> console, which is useful to see. After the kernel is up, it'll use the third serial port for console. Originally for the DECstation that was the printer serial port, but Linux users on DECstation use that for serial console due to that being the easiest port to convert into a simple serial port. The rest just tells the kernel how to boot. I prefer to boot into sh, and then issue <span>exec init</span> myself, thus the <span>init=/bin/sh</span>
</p>
<h3>How uMIPS runs</h3>
<p>After all the optimizations (which I'll detail in a bit) the effective speed of my virtual MIPS R2000/R3000 on this infernal ATSAMD21 chip is around <s>900KHz</s> 1.2MHz. The CPU spends around 8% of its time handling timer interrupts, and thus around <s>0.83MIPS</s> 1.06MIPS of CPU cycles are left for useful work. With this, the kernel takes around 2 minutes to boot and run <span>sh</span>. Executing busybox's <span>init</span> and getting to the login prompt takes another minute. Overall not too bad. Commands reply instantly, or in a few seconds. It takes gcc around 2 minutes to compile a hello world C program, and I estimate that in a few days' time, one could rebuild the kernel on the device itself, copy it to <span>/boot</span>, and reboot into it. Yes, I <s>do intend to try this and time it</s> did do this and it worked!
</p>
<p>The emulated real time clock is actually real time, plus or minus the inaccuracies of ATSAMD21's ultra-low-power 32KHz timer. It is ok enough that you will not notice. Try the <span>uptime</span> command.
</p>
<p>There is just one thing I did not yet address concerning running Linux on uMIPS. The storage. I said that it is an SD card, but surely DECstation had no SD card slot. However, Linux is open source. I simply created my own very simple paravirtualized disk driver which uses a hypercall to talk directly to the emulator and request sectors to be read or written directly into the virtual RAM. To Linux, this looks just like DMA, except instant. The whole implementation of the driver is under 200 lines of code and can be seen in <span>pvd.patch</span>
</p>

<h3>Linux changes</h3>
<p>I made some changes to the kernel to make life easier. They are provided as patches against the 4.4.292 kernel, and as is a working kernel image. Why that version? Because when I started that project, it was an LTS version of the kernel, and since RAM is short, I wanted the smallest possible kernel, so this was preferable to a later version. The config I am using is available in <span>kernel_4.4.292.config</span>. A config for an even smaller kernel (that requires uMIPS to emulate the full FPU) is available in <span>kernel_4.4.292.config_nofpu</span>
</p>
<p>I did a lot of work making the kernel as small as possible. Since Linux does not support paging out pieces of the kernel, every byte of kernel code is one byte fewer available to use for user space. I ruthlessly removed options that were not needed. In the end I got the kernel down to just under 4MB, which is pretty damn good, considering that MIPS instructions are not very dense.
</p>
<p>As part of this work, I made a few code patches. For various reasons (cough..delay slots..cough) the kernel can find itself needing to interpret userspace code, or parse userspace instructions. No matter what kernel configs I gave, the code to handle microMIPS (a future MIPS expansion not known in the days of R2000/R3000) was present. It was wasting space and time trying to handle things that would never happen. The patch <span>useless_exc_code.patch</span> removes this code if the target CPU does not support microMIPS</p>
<p>Before I implemented my FPU emulator, I was using the kernel's FPU emulation code that traps and executes FPU instructions. It had a bug. If compiled for a 32-bit MIPS processor it did not properly emulate some FPU instructions that operate on the double type. I believe this is wrong. It was causing crashes in code compiled for R3000. The patch <span>fpu.patch</span> modifies the kernel's MIPS FPU emulator by adding a config option to enable the full FPU emulation even on MIPS-I chips.
</p>
<p>Due to the differences between the R2000/R3000 and the R4000 the kernel needs to know at build time which CPU it is being built for. If you attempt to run the wrong kind of kernel on the wrong kind of CPU, it only gets far enough to panic about it. Fine, OK, but then why does this flag not affect a lot of TLB-handling code. Both kinds are always compiled in, despite us knowing at build time with 100% certainty that at least half of it will not ever be of any use? The patch <span>tlbex_shrinkify.patch</span> wraps the useless code in checks for the compile-time-selected CPU type and thus removes some kernel code, saving valuable bytes.
</p>
<p>As uMIPS runs with a real real-time clock, I did not want Linux to spent too much time handling timer interrupts. Normally, a 128Hz timer is used on DECstations by Linux. I added options for 64Hz, 32Hz, and 16Hz timer ticks as well. This reduces effective timer resolution, but effectively unloads the virtual CPU from having to spend most of its time handling timer interrupts. The patch <span>clocksrc.patch</span> does this, and the one called <span>kill_clocksrc_warning.patch</span> silences a pointless warning about timer resolution.
</p>
<p>If you do build uMIPS with full FPU emulation, there is aso a patch to remove all of the FPU emulation code from the kernel to save a few KB of RAM: <span>fpu.patch</span>. 
</p>

<h2>Improving performance</h2>
<h3>Instruction cache</h3>
<p><a href="https://dmitry.gr/images/linuxCardCompileTime.png"><img src="https://dmitry.gr/images/linuxCardCompileTimeSmall.jpg" alt="Linux card board layout"></a></p><p>One thing the processor will surely do every cycle is fetch an instruction. This means that every cycle begins with a memory access. For us that is a painful subject thanks to Atmel's errata-ridden SPI unit. And not just that, memory translation also needs to happen, and that also takes time. A good way to avoid both of these problems is a VIVT instruction cache. It'll read instructions 32 bytes at a time, and allow us to hopefully often not need to translate addresses or reach for main memory. I allocated 2KB of RAM to this cache. It is 32 sets of 2 ways of 32 byte lines. Whenever memory mappings change, it needs to be invalidated. I do this automatically and thus the running code on the virtual MIPS CPU does not need to know about it. The measured hit rate while booting Linux is around 95%, which is pretty nice for such a small cache. The geometry was determined experimentally by profiling how long a boot takes with various cache geometries. This one was found to be the best.
</p>
<h3>Improving CPU speed</h3>
<p>ATSAMD21 series is specified to run at 48MHz. In my testing they run perfectly well up to 96MHz, with some specific chips able to hit 110MHz. I found no chip unstable at 96MHz, so I decided to just run at 90MHz, for some safety margin. This immediately got me a pretty serious performance uplift. No, it is not really 100%, since (1) SPI RAM is still limited by the SPI speed limit, and (2) flash memory has wait states which had to increase for the larger speed. But this did give me an honest 65% improvement. Still a good start. Now RAM SPI runs at CPU / 6 = 15MHz.
</p>
<h3>Improving RAM bandwidth</h3>
<p>Since I could not make the RAM SPI units go faster due to Atmel's incompetence, I decided to go wider! I can drive four units at once. Given, there is overhead to each read and write command, but still this is faster than one or two. <s>My code initially supported one, two, or four RAM chips, but for simplification I dropped that support and now only support four-channel RAM.</s> Quite the statement eh? This microcontroller has four-channel RAM! The emulator accesses RAM in increments of 32 bytes. The RAM read/write commands themselves are 4 bytes each. This means that for a single-RAM chip situation, reading 32 bytes takes (4 + 32) * 8 = 288 SPI bits. In dual-channel configuration it'll take (4 + 16) * 8 = 160 SPI bits, since the command is still 4 bytes long, but we only read 16 bytes from each RAM , for a total of 32. For quad-channel RAM, we thus have (4 + 8) * 8 = 96 SPI bits to read 32 bytes. This is a 66% improvement from the single-channel case! In reality the improvement is less, since quad-channel mode cannot use DMA at all, so it is a bit slower. Real-life measurement shows that quad-channel mode is a 50% improvement over the single-channel case. But still, given this damn chip, any improvement is an improvement I'll take.
</p>
<p>But, why are all the RAM acceses 32 bytes in size? Well, as you see RAM accesses are slow. A typical 32-byte access takes 140-ish SPI cycles, which is around 12 microseconds. If every access took that long, my emulated CPU would be limited to no more than 85,000 memory accesses per second. That is too slow to be practical. Something had to be done. I decided on a cache. Sadly, my microcontroller has a very limited amount of RAM, so the cache had to be small. I evaluated various cache geometries, and found that a 20-set 2-way cache with 32-byte lines produced the best performance uplift for the emulator. It gets a 91% hit rate while bootling the kernel, which is a pretty good payoff for 1.25KB of RAM. With a hit taking around half a microsecond and a miss taking around 12 microseconds, adding this cache improved the average memory access by 87%! Yes, this is effectively an L2 cache. Now, how many emulators do you know that have an L2 cache to paper over the terrible performance of their chosen host hardware, eh? The cache allocates on reads and writes, except for reads and writes of precisely 32 bytes in size. Those are passed through directly because they are either SD card access DMA or icache fetches that do not need to also be cached in this cache.
</p>
<p>After some more profiling, I rewrote the "hot" part of the memory access code in assembly for some more speed gain. GCC may have come a long way since a decade ago, but it still does not hold a candle up to hand-written assembly. I removed support I had for one and two-channel RAM to simplify the hot path as well. So now you need to populate all four RAM slots for the card to boot. If you populate different RAM sizes, the smallest one will dictate the final usable RAM size. The usable RAM size will always be four times the size of the smallest RAM chip. This isn't a big deal, the DECstation came with 4MB of RAM, and could be outfitted with a maximum of 24MB. This card can be outfitted with 32MB, so you'll be living like a king! That being said, due to the size of the Linux kernel, you're not going to get a successfull Linux boot unless you have at least 6MB of RAM<s>, and uMIPS will refuse to boot if that is the case (eg: if you populate 4x 1MB chip)</s>.
</p>
<h3>Dirty hacks specifically for Linux</h3>
<p><s>Remember how on MIPS the operating system must do its own pagetable walking and filling of the TLB? As you can imagine this happens often. Very often. How could I speed this up without causing any correctness issues? On taking the <span>TLB refill</span> exception, I verify the handler has not changed and matches the expected bytes, if so, I do what it would have done, but in native code, not emulated MIPS. This helps this particular code run quite a bit faster. Correctness is not compromised since this is only done if the handler matches what is expected, byte for byte.</s>
</p>
<p>I also mentioned that due to how delay slots work, if a CPU takes an exception on an instruction in the delay slot, the kernel must be able to completely emulate that instruction, or in other way execute it and then jump to the right place? Linux uses the fact that MIPS has no PC-relative instructions, except jumps, and it is illegal to place a jump in the delay slot. How? Instead of emulating the delay-slot instruction, Linux copies it out to a special page in memory, where it is followed by a trap. Linux then jumps there in user mode to let it execute, catches the trap, and then re-directs execution where it should go. Now, if this sounds like a giant hassle to you, you are right. What can we do? Well, if an instruction in a delay slot causes an actual exception (like an illegal access, or a TLB refill exception, or some such thing), not much can be done. But what we <em>CAN</em> do is not make things worse. uMIPS will not deliver IRQs before executing an instruction in the delay slot of a branch. At worst, this will delay an IRQ by a cycle, which makes no difference to correctness. The benefit is that this sort of instruction copying and juggling can be done less.
</p>

<h2>How to build and use one</h2>
<h3>Building</h3>

<p><a href="https://dmitry.gr/images/linuxCardPcb.jpg"><img src="https://dmitry.gr/images/linuxCardPcb.jpg" alt="Linux card PCBs"></a></p><p>Now, why you really came here. How do you get one? Well, you could try knowing me personally and asking for my business card, I have a few to give out, but other than that, here is how to do it.
</p>
<p>You'll need to order the board from a board fabrication place. I am a fan of <a href="https://jlcpcb.com/">JLPCB</a> and recommend them. The gerber files I provide come in two flavours. One as you see my card exactly, and one without my name and contact info :). This is a four-layer board, the board house will ask you for layer order, it is: GTL, G1, G2, GBL. At least JLPCB has options to also cover the edge connector in gold for better contact, called "gold fingers" and to grind the board edge to 45¬∞ for easier insertion. I suggest selecting both of these options - they are free. Remember to set the board thickness to 0.8mm.
</p>
<p>While you wait for the board to arrive, you'll want to order the parts. You'll need four of the same memory chip (I have the links above), an ATSAMDA1E16, an AMPHENOL 11400841 SD card slot, and a MIC5317-3.3YM5TR regulator. You'll also want to (optionally) order an 0603 sized blue or white LED for SD activity light. If you choose to have that LED, you'll also need a 430 ohm resistor in 0603 or 0805 size. Besides that, you'll need in 0603 or 0805 sizes: 2x 5.1Kohm resistor, 1x 1Kohm resistor, 3x 0.1uF capacitor, and 7x 1.0uF capacitor. You will also need an SD card and any SWD programmer capable of programming the ATSAMD chip. There are many out there. Pick your favourite.
</p>
<p>You'll need an SD card as well. 128MB is the bare minimum here if you want to fit the busybox-based rootfs in. To fit the debian or hybrid image I am providing, you'll want at least 512MB. You can write the image to the card using your favourite tool for that. On Linux and MacOS that is probably <span>dd</span>, on windows, <span>Win32DiskImager</span>.
</p>
<p>Once you've assembled the board, program the MCU with the provided binary <span>software/emu/uMIPS.bin</span> and you're done!
</p>
<h3>Building from source</h3>
<p>You'll want to build a few things. You'll need both an ARM (CodeSourcery) and a MIPS GCC toolchain (I used mips-mti-linux I found online). First, build "romboot", "mbrboot", and "loader". Then, build the kernel. I provided the config, patches, etc. Then you'll want to build the emulator. To build for the MCU, use <s><span>make CPU=atsamd21</span></s>(<b>UPDATE</b>: proper target name changed, see updates later in the article). To build for PC, try <span>make CPU=pc</span>. Then you can build the SD card image. You'll want to copy the MBR from one of mine and modify it, then use <span>mkdisk.sh</span> to embed your kernel, mbrboot, and loader. Use a loopback mount to copy in your rootfs.
</p>
<p>If you want to run the emulator on PC, there are a few things to note. First of all, Ctrl^C will kill it :). Second, unlike the MCU version, the PC version does not incorporate the rom loader in the binary, so you'll need to provide a pointer to it on the command line. A typical command line is <span>./uMIPS ../romboot/loader.bin ../disk.wheezy</span>
</p>

<h3>If you are lazy</h3>
<p>For the lazy ones I am trialing selling all the parts and the board together as a kit on tindie. I'll see how this goes. My suspicion is that it'll end up being a giant pain in my ass and not worth the time, but I am giving it a fair shot. <b>EDIT:</b> Apparently not, and not even with a good reason. I quote: <em>Please resubmit for admin approval once you have addressed: Other Reason.</em>. LOL, how about <em>NO</em>? As a sidenote, if anyone knows companies that do this sort of thing for me (sell a kit I designed), please drop me a line <a href="mailto:tips@dmitry.gr">by email</a>. If you are <em>really really</em> lazy, I might consider having a batch of these factory-assembled by JLPCB as well. If you are interested, click <a href="mailto:assembled_requests_linuxcard@dmitry.gr">here</a> and let me know. No promises yet.
</p>
<h3>Using</h3>
<p>I provide a few disk images. The smallest is the busybox-based one (disk.busybox) - it is small, fast, and cool. I built the busybox from source for MIPS-I with as many applets enabled as I could imagine being needed. The second image is a full debian wheezy (last version to support MIPS-I) rootfs. I should warn you that debian's "init" starts around 3000 processes while it boots, so that takes a long time. If you are using the debian disk image (disk.wheezy), I strongly suggest to just mount proc and sys, and do your things in "sh" without running "init", but it will work if you do ... eventually. I also provide a hybrid image (disk.hybrid). It has a busybox shell and init, but has all of the debian binaries, so things not provided by busybox are still there and work, like gcc and vim. This is the "hybrid" image.
</p>
<p>Using the LinuxCard is easy, insert the SD card, connect USB-C to a computer, and open your favourite serial console app (minicom, PuTTY, etc), if you do not see the boot log, try the other virtual serial port (two exist). In case of a boot error, the SD card LED will blink in an infinite pattern, you can see the code for details on what various numbers of blinks mean.
</p>
<p>Once you see the shell prompt, you can play around, or continue boot to login by typing <span>exec init</span>. After this you'll be able to login as "root" with the password of <s>"mips"</s> "mipsmips". There will also be a login prompt on the second serial port as well. So cool!
</p>


<h2>Version 2</h2>


<h3>Booting Ultrix</h3>
<h4>About Ultrix</h4>
<p>Ultrix is the period-correct UNIX for the DECstation2100/3100. The latest version is 4.5 and with some google-fu you can find ISOs of the install media. It supports the DECstation2100/3100 perfectly, and even has an X11-based UI! The goal of the v2 firmware was to properly run Ultrix on the card. This ended up requiring a lot of work. I had to improve emulation accuracy and implement more hardware. But it did work!
</p>
<h4>First time booting Ultrix</h4>
<p>My first attempts were simple - copy the kernel to my "boot" partition and attempt to load it. It would, of course, not find its root filesystem and panic, but I wanted to see how far I would get at all. The first roadblock was an obvious one - the kernel is not in the <span>ELF</span> format that the linux kernel uses and my loader expects. It is in an older format called <span>COFF</span>. I dug up docs and started working on a parser for <span>COFF</span>. After a little work, I was able to load the kernel and let it run, just to see how far it would go. To my susprise, it got far enough to log some messages to the console! It crashed soon after, when it asked my PROM code for an env variable that I did not know about "scsiid0". Not a bad start. At this point I figured that in a week or so I would have Ultrix booting. It took a little longer...
</p>
<p>Ultrix was designed for this machine, and it was designed to support all parts of it. It does not probe for hardware since it knows that a DECstation2100/3100 should have. It assumes that the requisite hardware is there and starts initializing it. This was a problem for me - I still was not emulating the graphics, SCSI, or the network card. Linux has no support for them so I had not bothered.
</p>
<h4>SCSI</h4>
<p>As this was my first time attempting to emulate SCSI, it took a while. SCSI is so over-engineered, the very word "overengineered" does not do justice to just how much so it it. There are messages, commands, statusses, selects and reselects, and oh so very much more. The SCSI chip in the DECstation2100/3100 is a very strange one that DEC designed just for this device. It is called SII or SMII and I found no docs for it other than the official summary in the <a href="http://www.bitsavers.org/pdf/dec/mips/DS3100_Functional_Specification_Rev3.1_Aug1990.pdf">DECstation3100 specification</a>. It was helpful, as it listed the register bits and values. It was a start. Watching the Ultrix kernel try to access it before it gave up and paniced provided some more help, and reading the SCSI-I and SCSI-II specs filled in the rest. After much work it seemed like the kernel was happy enough to try to enumerate the bus. It would try to select each device in order. Progress!
</p>
<p>From there, the next step was to write a virtual SCSI disk. If you haven't dealt with SCSI before, it is rather unlike most sane designs. A sane design would have a host controller be a heavy/expensive/complex machine that talks to cheap simple devices. This makes sense because typically one would have more devices than host controllers. Not here. A SCSI device drives the bus and determines what it does and when. The only thing the host can do is reqest attention from the device. This took a little while to wrap my head around as it is rather backwards. It is actually even more complex since the target device can disconnect from the bus to do things and later reconnect and continue a transaction. It <em>really</em> is quite complex. Luckily, some of that is optional. A device can also reply without disconnecting, and my virtual disk does that. With a lot of work, I was able to figure out the proper state machinery to make Ultrix indeed identify and talk to my virtual SCSI disk. I split the code into two layers. The bottom handles the basics of just being a SCSI device and the top handles actual disk-specific things.</p>
<p>The code later got expanded to support emulating a CDROM too, to allow me to do an Ultrix install from a virtual CDROM. While working on this, I noticed that the bus enumeration is slowing down the boot a lot. The issue is that there is no way to detect that "no device with this ID exists on the bus". One must attempt a select, and then wait for a timeout. This was taking a while since Ultrix implemented a timeout using a loop with a counter (not using the RTC), and at my virtal CPU speed it was taking seconds. The solution was a dummy SCSI device that does reply to some commands enough to be identified and tell the host that it has no media and is of an unknown type. This device is the "SCSI nothing".
</p>
<p>The SII controller has 128KB of SRAM for DMA-ing data to/from devices. The idea is that one schedules the transfer and it goes on at its pace, when done, an interrupt occurs and data can be copied in/out of this memory. On the PC, this is simple - i can allocate 128KB of RAM and be done with it. On the microcontroller, I do not have that much SRAM, so I steal some memory from my external memory for this, and present less than the full amount to the virtual OS. This works fine for Ultrix as it probes the memory amount page-by-page. Linux probes in 4MB increments, but I have a patch <span>allow_64K_memory_multiples.patch</span> that changes it to probe in smaller increments so that this memory stealing does not cost 4MB of usable RAM.
</p>
<p>Linux has no support for SII SCSI controller, so it continues to use the <span>pvd</span> device.
</p>
<h4>LANCE</h4>
<p>The network card in the DECstation2100/3100 is LANCE. It is somewhat documented in the DECstation2100/3100 specification sheet and I implemented it enought to please Ultrix. It never sends or receives any packets (I can add that later), but it does initialize and interrupt as needed. LANCE has a 64KB SRAM buffer for packets. The PC build of uMIPS fully supports this, the "micro" build of uMIPS will just ignore writes and produce zero reads of this area to avoid wasting 64KB of memory. This works well enough to please Ultrix. Linux has no support for LANCE, so I have no idea if it would be ok with this setup.
</p>
<h4>ESAR</h4>
<p>The MAC address for the network card is stored in a on-board EPROM called the "ESAR" (Ethernet Station AddRess). It lives at the same address as the real time clock, except it is wired to the upper byte of every word, while the DS1287 is wired to the bottom byte. This is a weird thing to do but it works. It does mean that some weird things are possible, like reading both the ESAR and the real time clock registers at once with one read. Luckily this is not usualy done. The ESAR data has some checksums and redundancy (so that its correctness is easy to verify). I implemented an ESAR for uMIPS, assigned the ethernet address <span>66:44:22:44:66:22</span> to the device, and provided for all the required redundancy and checksums. Ultrix is satisfied with this.
</p>
<h4>Memory probing &amp; proper PROM API</h4>
<p>While booting Ultrix I notied that it directly probed the amount of RAM in the system. This is strange since Linux simply queried the memory amount from a PROM API that conveniently exists for this. This was actually my mistake since I was emulating a much newer PROM iterface than the real DECstation2100/3100 had, and Linux was happy to use it. The newer standard (called REX) provides the OS a function pointer table with a lot of API. To signal REX support, a magic value is also passed. DECstation2100/3100 predate the REX API and used a different method of providing API to the OS - a table of jumps is placed at known offsets from the start of the PROM in the <span>0xbfcXXXXX</span> address space. This API is also more primitive, and lacks, for example, the ability to tell the OS how much RAM there is. The pieces now fall into place... My only problem is that I do not have an ability to have a huge PROM, as I wrote earlier. I needed another method to offer this API. I decided to indeed have this jump table, but redirect all the jumps to an address in the RAM area reserved for the PROM <span>0x80001000..0x8002ffff</span>. You'll recall that my OS loader loads there. Now it can provide this PROM API, just like it did the REX API. Cool! Testing Linux also shows that it happily uses this API properly as well. It is, of course, now also forced to <em>probe</em> the RAM amount. No big deal. I did find a bona fide bug in the kernel here! While it means (as per comments) to probe for a maximum of 480MB of RAM, but actually only probes for up to 30. The fix is in <span>fix_mem_limit.patch</span>.
</p>
<h4>Ultrix Loader</h4>
<p>At this point, the kernel was loading far enough to panic about not finding the root filesystem, so it was time to figure out a good way to make this work. The problem is that Ultrix uses a completely different partitioning system than the well-familiar MBR I had been using. The Ultrix "disklabel" allows for 8 "partitions" but with some assumptions, like that the first (caled "a") is always the rootfs, the second (called "b") is always swap, the third ("c") always covers the entire disk (yes it does and is expected to overlap others), and another one ("g") is <span>/usr</span>. Now, if this was not fun enough yet, the partition table itself is expected to be <em>inside</em> the rootfs partition, and a whole lot of tools (including the installer) assume that this all starts at sector zero. Fun, eh?
</p>
<p>I spent a lot of time trying to figure out how to make the installer be happy to not start the rootfs at the 0th sector, but this was a lost cause. A large number of scripts involved assume that both the "a" and the "c" partition start at zero. The kernel also has similar assumptions. With some patching, I got it to work with an offset, but this was not a good approach. I decided to see if I could live with how Ultrix does things, instead of trying to force it to do things my way. Even though the rootfs and the partition table both start at the 0th sector, they both reserve some space up front for "boot code". Specifically, the first 16 sectors (8KB) are always free. I decided to simply place my loader there and teach it how to understand the Ultrix disklabel. As part of this work, I refactored the loader into a few pieces. One part was a partition table handler. There is an option for MBR, one for Ultrix, and one for NetBSD disk labels. One of these (build-time determined) is linked in to the loader, as needed. Another module was a binary loader. Two exist: ELF for Linux and NetBSD, and COFF for Ultrix. Same as before, only one is linked into the loader, as needed. The third modue is the filesystem driver. There is one for FAT12/16/32 (used for my Linux boot sequence), one for old UFS (for Ultrix), and one for modern UFS (for NetBSD). Again, just one is linked in, as needed.
</p>
<p>The cool part now is that I can mix and match these pieces as needed to create a loader for the OS I want to boot. The Linux loader is thus <span>FAT + ELF + MBR</span>, for Ultrix, the loader is <span>UFS.old + COFF + Ultrix disklabel</span>, and for NetBSD, it is <span>UFS.new + ELF + NetBSD disklabel</span>. I was too lazy to implement proper CD-booting, so installing Ultrix is a bit weird. I make a disk image with just the installer kernel (extracted from the CD), in a FAT partition, attach the CDROM to the emulator, and then boot. The installer will then re-partition the disk. For this, yet another loader combination is used: <span>FAT + COFF + MBR</span>. The modularity pays for itself!
</p>
<h3>Making Ultrix work</h3>
<p><a href="https://dmitry.gr/images/linuxCardUltrixUiBig.png"><img src="https://dmitry.gr/images/linuxCardUltrixUiSmall.jpg" alt="Ultrix UI fully booted with a graphical paint program and a terminal open"></a>
<a name="_TOC_42badd9e49002a3cefeaaf28867add83"></a></p><h4>Framebuffer</h4>
<p>Once I had the Ultrix kernel booting properly, at least in the PC build of uMIPS, I <em>really</em> wanted to get the GUI working. Who wouldn't‚ÄΩ The framebuffer came in two varieties for this machine. There was a monochrome one and a 8-bit color one. They both supported hardware cursor as well. I implemented most of the normally-used modes in the cursor hardware, but not any test modes. I emulated both the framebuffer types and they both work! The 8-bit framebuffer can display up to 259 colors onscreen at a time, out of a 24-bit palette. That is not a typo. The display itself can display 256 colors, and the cursor has its own 3-entry palette, which need not use any of the same colors. The resolution is 1024x1024 in memory, and 1024x864 onscreen. The remaining memory is free for the OS to use however it wishes. I steal memory from the main RAM, same as for the SII buffer. 128KB is used for the mono framebuffer, and a whole megabyte for the color one. The palette is also stored in stolen ram (just about a kilobyte).
</p>
<h4>Mouse, Keyboard, ... and Tablet</h4>
<p>Of course, to make this work, I also had to make the keyboard and mouse work. They talk to the DECstation via serial, and the protocol is somewhat known, from various shreds available online. I was able to put together a passable keyboard emulator rather quickly. It is <em>not</em> a dumb keyboard. It has regions of keys, a bell, some lights, and can support differing autorepeat settings per key group. It is actually pretty cool. The mouse is a pretty basic one, with three buttons. I got that working rather quickly. The problem with emulating mice is a well known one - they are relative device, and most OSs apply acceleration to the mouse as you keep moving it to allow for better reach. Now, if you are running another OS, and passing these accelerated movements to it, it will re-accelerate them even more. This ends up being a mess. This is why most virtualization solutions prefer to load an absolute-pointing-device driver into the guest. I was not prepared to hack up Ultrix or find a way to load a different mouse driver in it. But then I noticed that DEC wrote about a "graphical tablet" that they were selling, that hooked up to the mouse port. Could it be that Ultrix supports this? Yup... Ultrix does. I wrote an emulator for the tablet and it worked wondefully - no more over-accelerated mouse for me! Sweet!
</p>
<h4>Patches</h4>
<p>Ultrix assumes that it is booting on a real DECstation2100/3100, and that includes expecting the CPU to have caches. My virtual CPU does not expose caches to the guest OS, and while Linux handles that fine, Ultrix does not. It correctly probes the cache and finds its size as zero. But there is a logic bug in <span>r3_kn01flush_cache</span>, where if the cache size is zero, it gets into an almost-infinite loop. As uMIPS exposes no cache, it makes sense to patch the function away into just a return. There is another function of interest: <span>kn01delay</span>. It is used for short busy-wait delays when dealing with hardware. All of our virtual hardware is instant-fast, and thus no delays are needed. As long as I am patching a kernel, might as well make it faster. There is also a third area of interest - the periodic timer. In Linux, I was able to change the tick to 16Hz, but I cannot build Ultrix from source, so I cannot modify it easily. Ultrix uses a 256Hz tick. At that rate, on uMIPS hardware we'd never get any useful work done while only handling interrupts. I attempted to patch Ultrix to use a 16Hz timer and account for it correctly. This does not work - there are mathematical errors that happen. 64Hz works, but that is still too freqent for the uMIPS hardware to be usefully fast. I ended up patching the init code to set the timer to 16Hz, but accounting code to act like it is 64Hz. This means that "realtime" in Ultrix runs 4x slower than actual real time, but this is not really a big deal. Just keep in mind that a <span>sleep 1</span> will delay 4 seconds and not 1.
</p>
<p>So how does one even apply such patches? How does one find the proper places to patch? I spent a <em>LOT</em> of time learning about the barely-documented symbol format used in the Ultrix kernel. It worked! I made a working parser for it and was able to properly identify the symbols I needed and to patch the places that needed patching. This was good until I realized that while the installer kernel does ship with symbols, the kernel installed for first boot does not (after first boot, the kernel is recompiled again, with options you choose, and that version DOES have symbols). No symbols means that I cannot use them to find the proper locations to patch. I decided on a different method - binary matching. Look for the proper set of bytes in a row, it should be unique in the kernel. If you find just one case - it's the right one. To save space in the loader (as it is limited to 8KB), I compress the "pattern to look for" cleverly. Cool. This is the final approach I used and you can see it in <span>loadUltrix.c</span>.
</p>
<h3>Improvements in the emulator</h3>
<h4>USB improvements</h4>
<p>After a lot of googling, I learned about interface association descriptors. Turns out that without them, windows will not load the USB CDC-ACM drivers for a device. After adding them, Windows would properly load the driver and it would show up as a COM port. I also learned about the peculiar ways that Windows enumerates devices. Sometimes it'll ask for a descriptor, stating that it'll accept 64 bytes, but after receiving just one 8-byte packet it will reset the bus. This was breaking my USB code, and this is now fixed. Windows now properly supports uMIPS and shows it as two COM ports. Sweet!
</p>
<h4>More perf improvements</h4>
<p>At the end of emulating every instruction, the emulator jumps "to the top", fetching a new instruction to execute. In most cases before this a check is done for whether there is an interrupt pending. This jump was done using a <span>BL</span> - the only long-distance branch available on the Cortex-M0. It takes 3 cycles. The check involved loading a byte from memory (2 cycles), checking if it is zero (1 cycle), and jumping to the interrupt exception creation code if so (1 cycle if not - the common case). That means that the entire "jump and begin handling the next instruction" step took 6 cycles. I wanted to make it faster somehow. I decided that if I could free up a register, I could. Some reworking freed <span>r11</span>. There is a parameter you can pass to gcc to tell it to not use a given register in any C code it compiles: <span>--ffixed-r11</span>. Now that this register is not being used by anyone ever, we can do the clever thing. We keep the address of the "load next instruction and execute it" label in it. Now we can jump to it using just <span>bx r11</span>. This takes just 2 cycles - 4 cycles saved per virtual instruction - a significant speed up. But what if we do have a virtual interrupt to report? Whenever we have one to deliver, we just set <span>r11</span> to point to the "report a virtual interrupt" label, and whenever the current virtual instruction is done being emulated, the interrupt will be reported and <span>r11</span> will be reset. There is a bit more machinery needed to make this work, but this is it in general terms, and it does work!
</p>
<p>I also changed how the TLB hash works (from a table of 32-bit pointers to a table of 8-bit indices) to make the table and each entry smaller (from 24 bytes to 16). This saved a bit under a kilobyte of RAM, which I was able to allocate to the L2 cache. It has now grown from 1.25KB to a full 2KB for a measurable perf improvement!
</p>
<h4>Removing the TLB refill fast path</h4>
<p>For Linux, I had implemented a fast-path for the TLB refill code - it executed in native code what he TLB refill handler would do. In my measurements it slightly improved performance. With all the other performance improvements I had implemented, it no longer offered a measurable improvement. Plus, it did not help Ultrix at all, by definition. Removing it saved flash space and removed complexity. Less complexity is always better. It is gone.
</p>
<h4>Cache geometry changes</h4>
<p>Previously, when profiling to find the best L1i geometry, I used the Linux boot process. I decided to try harder. Now I profiled that, gcc compiling some code, a few other Linux binaries, Ultrix boot, and some Ultrix userspace utilities. The result of this investigation was that a direct-mapped L1i is slightly faster than a 2-way L1i cache. The hit rate goes down slightly, but checking only one cache line instead of two speeds up the checking enough to make up for it. I thus reconfigured the cache as a direct-mapped cache.
</p>
<h4>Serial improvements</h4>
<p>Previously, the emulator would wait a fixed 20ms to send a character to the PC before giving up. I changed this to a permanent wait for the main console. This allows the user to not miss any output if they close their terminal. The emulator also shows its version up front, since it will definitely not be missed now. As of firmware v2.1.1, uMIPS also shows the RAM configuration in terms of the number of chips, each chip's size, and the bit width of the per-chip interface.
</p>
<h3>More Floating Point Unit work</h3>
<p>I had already implemented a full virtual FPU, but now I wanted to see how necessary it really was. I knew that Linux would run if I emulated no FPU at all and would emulate it. I wanted to see if Ultrix would. It did not - it crashed with an invalid instruction trap in the kernel. This was not all that surprising. Once again, it was compiled for a particular machine - a machine that had an FPU. Its assumption that an FPU exists was sane. But there was still more to investigate. The MIPS spec says that the FPU may refuse to execute any instruction if it is not sure that it can perform it perfectly accurately. Since the spec is not clear on what that really means, basically any OS running on such a MIPS chip must implement a complete FPU fallback, capable of emulating any FPU instruction. But then why am I hitting an exception?
</p>
<p>The trick is that the FPU must still exist, it must refuse to do math. This is strictly different from not existing at all. I thus implemented a "minimal" FPU. It implements the instructions to identify itself, move data in and out of the floating point registers, and load and store floating point registers to memory. Any attempts to do actual floating point math report a "coprocessor usage exception" which is the proper way for the FPU to refuse to do math. This worked correctly for Ultrix - it now will not crash at boot, all applications that do floating point math still run, with the kernel emulating the math. I checked and Linux also supports this setup. Thus uMIPS now has three FPU configs that it can be built with: <span>full</span>, <span>minimal</span>, and <span>none</span>.
</p>
<h3>A bootloader</h3>
<p>As I handed out more and more of these cards, the update story needed to be improved. Not everyone has a <a href="https://cortexprog.com/">CortexProg</a> lying around to reflash the firmare. I decided to make it simple and require as little user interaction as possible. The bootloader is just under 3K, I allocated 4K of flash to it, and relocated the main firmware to start 4K into the flash. So, how does it work? At boot, the bootloader will minimally initialize the SD card, attempt to find a FAT16 partition on it, see if it contains a properly-sized file called <span>FIRMWARE.BIN</span> on it, and if so, the firmware will be flashed from this file. On error, the error number will be blinked out on the LED, repeatedly. On success, a varying-frequency pattern of the LED will be repeated forever.
</p>
<p>If the card fails to be initialized, if it fails to mount, if the update file does not exist, or if it is not correctly sized, the bootloader will continue to boot the existing firmware, if any exists (some sanity checking is peformed). This means that when you insert a card with my Linux image or the Ultrix image, all will work as expected. Only FAT16 is supported, so some partitioning may be required on larger cards. I can live with that.
</p>

<h3>Hardware improvements</h3>
<h4>v1.3 hardware</h4>
<p><a href="https://dmitry.gr/images/linuxCardSchem2.png"><img src="https://dmitry.gr/images/linuxCardSchemSmall2.jpg" alt="Linux card schematics"></a>
<a href="https://dmitry.gr/images/linuxCardBoard2.png"><img src="https://dmitry.gr/images/linuxCardBoardSmall2.jpg" alt="Linux card board layout"></a></p><p>After reading my original article, a few people wrote in (including in the comments section here, on twitter, and in email) to suggest that maybe I should entirely abandon the shitty SPI units in this chip. Initially I was worried that the SPI unit speed issue was really an IO port speed issue, but a quick test showed that I could toggle a pin at half my CPU clock reliably and get nice square edges. I prototyped bit-banging SPI on the existing board to see what speeds I could attain and it was promising. I then laid out a new board, with different wiring, to allow me to actually use QSPI mode. The images for the new schematics and the layouts are the ones you see here!
</p>
<p>The ATSAMD21 series features a single-cycle IO port. This optional Cortex-M0+ feature is pretty useful for bit-banging. It really is single-cycle-fast. Normal loads and stores take two cycles minimum on a Cortex-M0+, but ones targetting this kind of a unit take just one. That is <em>how</em> I could toggle a pin at half the cpu speed for my test that I had just mentioned.
</p>
<p>With big-banging, the trick is to do as few operations per cycle as possible. Given this, it would be ideal to do minimal bit-twiddling. It would be super-awesome if I could wire up the four QSPI chips to GPIOS numbered 0..15, allowing me to just read/write the bottom 16 bits of the GPIO port for simple access. Alas, this was not meant to be. This chip has no contiguous 16 GPIO pins wired to the physical pins, so I settled for wiring RAM0 to GPIO0..3, RAM1 to GPIO4..7, RAM2 to GPIO8..11, and RAM3 to GPIO14..17. Since I will be driving them all together, the clock and chip select lines are all wired together. After all was said and done, after the assembly was coded, and the dust settled, I was able to get around a 9MHz clock speed on average. Since the command and address are also sent 4-bits-wide, the speed increase is nice. Previously (using hardware SPI) it took around 8 microseconds to read/write 32 bytes, now it took just under 4 microseconds. A nice speedup.
</p>
<p>An astute reader might notice that the first three RAMS <em>ARE</em> on consecutive GPIO pins. Three is not of much use to us, as it is not a power of two, but <em>two</em>... Yes indeed using only two RAMs i can attain faster speeds (but at half the width). The actual time to read/write 32 bytes is around 5 microseconds. Given this, I decided to re-add the previously-removed support for using less than 4 RAMs on the board. And I did. The newest firmware now supports 1, 2, or 4 RAMs populated on the new boards. I then went futher, and re-added this support for the old boards. That is not as well optimized - it is in C, not ASM, but good enough to play with. This will allow assembling these boards cheaper. Plus, Ultrix happily boots and runs in 4MB (it does need 5MB to start the GUI though).
</p>
<h4>And old hardware too</h4>
<p>I did not want to maintain two separate-but-almost-equal branches of code for the older v1.2 hardware and the new v1.3 hardware. There was also no easy way to tell them apart in software from first glance. But a bit more investigation does provide an idea. The wiring for the RAMs is different enough that we can try each way and see if we detect a plausible RAM chip. It helps that not having RAM0 populated is never supported. This is precisely what I did, in fact. I tried both configs and see which produces a valid-looking ID from RAM0. From there, all four RAMs are probed, identified, and a configuration is picked.
</p>
<p>Support for less than 4 populated RAMs raises a few interesting questions. For speed, all RAMs are treated as if they are the same size, so the size of the smallest RAM determines the total amount of available RAM. This is because I stripe the data across them, of course. So, what if RAM0 is populated with 8MB, and RAM1 with 2MB? We could use just RAM0 and get 8MB of RAM or we could use both and get just 4MB, but faster, since more RAMs in parallel is always faster. I decided that more RAM is better than faster RAM, so in case of such conflicts, more RAM is always chosen. When there is a tie, the faster configuration is used, eg: 4MB, 1MB, 1MB, 1MB RAMs populated add up to 4MB in both the x1 and x4 configs. In this case the x4 config will be chosen and all the RAMs will be used.
</p>
<h3>Building from source (updated)</h3>
<h4>The emulator</h4>
<p>A new parameter called <span>FPU</span> is now passed to uMIPS build to specify the FPU type desired. Options are: <span>none</span> - no FPU at all, Ultrix will not like this but it makes the smallest image; <span>minimal</span> - an FPU that can store values but refuses to do math - Ultrix and Linux will support this, it is slightly larger; and <span>full</span> - a full FPU that does all the math - the fastest option that bloats the Cortex-M0 image by 17KB or so.
</p>
<h4>The loader</h4>
<p>To build the proper loader, pass the <span>BUILD</span> parameter to <span>make</span>. The options are <span>linux</span>, <span>ultrix</span>, <span>ultrix_install</span>, or <span>netbsd</span>. The install loader is just for clean installs, which you have no reason to do since I already did it for you. The netbsd one is to attempt boots of NetBSD on this machine, as it is supported by NetBSD. The proper loader needs to be built and integrated into a disk image for a working system.
</p>
<p>The integration step also changed, <span>mkdisk.sh</span> is gone, replaced by a number of different tools, depending on the intended system. They are: <span>mkdisk-linux.sh</span>, <span>mkdisk-netbsd.sh</span>, <span>mkdisk-unix.sh</span>, and <span>mkdisk-unixinstall.sh</span>. Unix here refers to Ultrix, of course. The scripts are small and self explanatory. Open them for more details. They all operate on a disk image called "disk"
</p>
<p>To enable GUI in Ultrix, the env variable "console" needs to be properly set. In <span>loader.c</span>, find it and set it to "0,0" for text mode or "1,0" for console mode.
</p>
<h3>Further Updates</h3>
<h4>Firmware v2.1.1</h4>
<p>In this version, BBQSPI memory access sped up by 11% for 4-chip case, 6% for others. Ram config shown on boot.
</p>
<h4>Firmware v2.2.0</h4>
<p>In this version, the bootloader was updated to better support other ATSAMD21 parts, including those with more flash &amp; RAM. It now also exposes a version byte at offset <span>0x08</span>. The previous bootloader was version <span>0x10</span>, making this one version <span>0x11</span>. The version will be shows on the serial console at boot now.
</p>
<p>Also, as ATSAMDA1E16 is now apparently out of stock everywhere, I added support for <a href="https://octopart.com/atsamd21e17a-au-microchip-77761547?r=sp">ATSAMD21E17A-AU</a>/<a href="https://octopart.com/atsamd21e17a-aut-microchip-77761548?r=sp">ATSAMD21E17A-AUT</a>. The sad news is that this non-automotive part does not overclock nearly as well. It gets unstable much past 76MHz, so I decided to clock it at 72MHz. It does have more RAM (16KB), which allowed me to allocate a lot more memory to L1i and L2 caches. In most measurements, the performance loss due to lower speed is papered over by the gains of larger caches.
</p>
<p>On the topic of performance, I also rewrote the L2 cache code in assembly for speed and size gains. The speed gains are significant. For extra speed, there is now an option to move the actual access functions to RAM (which is faster than flash). This gains an extra 8% speed, but at the cost of using RAM. On the old 8KB-of-RAM parts this is not always worth it, since it necessitates shrinking the L2 from 2KB to 1.625KB to make space. On the new 16KB-of-RAM parts, though, it is we;ll worth it. It should be noted that there are 6 variants of RAM access low level functions as there are 2 possible access types (SERCOM or bit-banged) and 3 possible chip counts (1, 2, or 4). Only the ones you plan to use need to be moved to RAM. Others will still work from flash, if you want to make a universal firmware. The firmware I provide now moves the 4-chip bit-banged functions to RAM for ATSAMD21E17. See <span>RAM_FUNCS_IN_RAM</span> in the Makefile and the contents of <span>spiRamAtsamd21.c</span>
</p>
<p>While moving functions to RAM, it is easy to accidentally use too much RAM and end up with random crashes as stack collides with data. These are a pain to debug, so I decided to improve this experience. As an option in the Makefile, there is now ability to enable <span>STACKGUARD</span>. What does this do? As the very last word in the pre-allocated RAM (and thus the very first one that stack would overflow over) the code will keep a magic cookie, whose value depends on the current <span>ticks.hi</span> value. This value is checked and updated in the <span>SysTick</span> interrupt which happens every 16 million cycles. If the check fails, an error will be blinked out the LED and the execution will be halted. 
</p>
<p>Starting with this version, the proper make incantations are now <span>make CPU=atsamda1e16</span> and <span>make CPU=atsamd21e17</span>
</p>
<p>The downloads have been updated with the new code and binaries for both chip types. They can be updated using the bootloader and an SD card
</p>





<h2>In conclusion</h2>
<h3>Acknowledgements</h3>
<p>I send a great many thanks to my cats for cutely lying under my table to keep me company during the many hours spent on this project. I send a giant, Mount Rushmore-sized middle finger to Atmel for this sorry excuse of a chip. <b>UPDATE:</b> I even gave up on using the SPI units here, so at this point, I send <em>two</em> of those fingers. Thanks for nothing, Atmel.
</p>
<h3>Downloads</h3>
<p>The source code, gerbers, schematics, and all else <em>except</em> the disk images can be downloaded [<a href="https://dmitry.gr/images/LinuxCard2.7z?v=220">here</a>]. The license on my code is simple: free for all non-commercial use, including using as your own business card. For commercial use (like if you wish to sell kits of this project), <a href="mailto:licensing@dmitry.gr">contact me</a>.
</p>
<p>The disk images (<b>updated</b>) are large so I have no desire to host them on my site, so: [<a href="https://drive.google.com/file/d/14fhdW4Vdz4-ZKucB-iIP4MLTk8OLB7dI/view?usp=sharing">Google Drive</a>] or [<a href="https://mega.nz/file/p9ZWzLrK#saRKVlgBthOFE4Cp-6sb2fMTM7JXtuXMlsYQaaWrEAI">MEGA</a>].
</p>


<!--- We do not show this to the user, but ToC system will index this and we'll get a link to comments in the ToC -->






					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We've already seen category 6 hurricanes ‚Äì scientists want to make it official (222 pts)]]></title>
            <link>https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official</link>
            <guid>39268106</guid>
            <pubDate>Mon, 05 Feb 2024 22:27:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official">https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official</a>, See on <a href="https://news.ycombinator.com/item?id=39268106">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-220146">
	<div>

		
		
<p>Five tropical cyclones in the past 9 years have hit wind speeds far above the category 5 threshold, causing thousands of fatalities and billions of dollars of damage. Such ultrastrong, highly destructive hurricanes are becoming more likely as climate change increases the amount of energy available to storms.&nbsp;</p>

<figure><blockquote><p>‚ÄúStorms are getting stronger and stronger, so category 5 underestimates actual risk.‚Äù</p></blockquote></figure>

<p>In a <a href="https://www.pnas.org/cgi/doi/10.1073/pnas.2308901121" target="_blank" rel="noreferrer noopener">new study</a> published in the <em>Proceedings of the National Academy of Sciences of the United States of America</em>, scientists suggest that the growing intensification of tropical cyclones may necessitate adding a sixth category to the <a href="https://www.weather.gov/hgx/tropical_scale" target="_blank" rel="noreferrer noopener">Saffir-Simpson Hurricane Wind Scale</a>. Doing so could be one useful tool not only to indicate hurricane risk but also to convey the increasing dangers of climate change.</p>

<p>‚ÄúStorms are getting stronger and stronger, so category 5 underestimates actual risk,‚Äù said <a href="https://experts.news.wisc.edu/experts/james-kossin" target="_blank" rel="noreferrer noopener">James Kossin</a>, an author on the paper and an atmospheric scientist at the University of Wisconsin‚ÄìMadison.</p>


<h3>Warming Winds</h3>

<p>The Saffir-Simpson scale is the most widely recognized hurricane intensity scale, ranking storms from ‚Äútropical depression,‚Äù at wind speeds less than 38 miles per hour (61 kilometers per hour), to ‚Äúcategory 5 hurricane,‚Äù at wind speeds greater than 157 miles per hour (253 kilometers per hour).</p>

<p>That scale may <a href="https://eos.org/articles/probing-the-power-of-pacific-supertyphoons" target="_blank" rel="noreferrer noopener">not capture the risk posed by the most intense storms</a> as the world warms, the authors wrote. They suggest a sixth category that encompasses storms with winds greater than 192 miles per hour (309 kilometers per hour).</p>

<p>The authors used three lines of evidence to support the creation of a sixth category. First, multiple storms have already spilled over into the hypothetical category 6. <a href="https://www.climate.gov/news-features/understanding-climate/2013-state-climate-record-breaking-super-typhoon-haiyan" target="_blank" rel="noreferrer noopener">Typhoon Haiyan</a>, for example, made landfall in the Philippines in 2013 and had winds that reached 195 miles per hour (314 kilometers per hour). Haiyan was the costliest storm ever to hit the country and one of the deadliest, causing more than 6,000 fatalities. In 2015, <a href="https://en.wikipedia.org/wiki/Hurricane_Patricia" target="_blank" rel="noreferrer noopener">Hurricane Patricia</a>‚Äîconsidered the strongest hurricane ever recorded‚Äîbrought winds of up to 215 miles per hour (346 kilometers per hour) to southwest Mexico.</p>

<p>Climate change has likely contributed to the intensification of tropical storms, <a href="https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter11.pdf" target="_blank" rel="noreferrer noopener">according to the Intergovernmental Panel on Climate Change</a>, the United Nations body that assesses climate science.</p>

<p>The authors also analyzed the maximum potential intensity of storms in recent decades. That metric refers to the highest wind speeds that are possible on a given day given that day‚Äôs weather conditions. They found that in the Gulf of Mexico between 1979 and 2019, conditions were conducive to category 6 hurricanes about 10 days a year.</p>

<p>The number of days conducive to category 6 wind speeds has increased because of climate change, said Kossin.</p>

<p>Last, the authors modeled future hurricanes under various climate change scenarios and found that under each possible scenario, the risk of a category 6 hurricane increased. ‚ÄúOver the next decade, there will be category 6 [hurricanes],‚Äù said <a href="https://crd.lbl.gov/divisions/amcr/computational-science-dept/acsd/staff/staff-members/michael-wehner/" target="_blank" rel="noreferrer noopener">Michael Wehner</a>, an author on the paper and a climate scientist at the Lawrence Berkeley National Laboratory.</p>

<h3>Communicating Climate Change</h3>

<p>Communication of risks shouldn‚Äôt focus only on the Saffir-Simpson scale, according to <a href="https://www.weather.gov/organization/michael-brennan" target="_blank" rel="noreferrer noopener">Michael Brennan</a>, the director of NOAA‚Äôs National Hurricane Center (NHC). Most fatalities caused by hurricanes occur not from wind but from water, including storm surges and rain.</p>

<p>‚ÄúAt NHC, we‚Äôve tried to steer the focus toward the individual hazards, which include storm surge, wind, rainfall, tornadoes and rip currents, instead of the particular category of the storm,‚Äù he wrote in an email. ‚ÄúCategory 5 on the Saffir-Simpson scale already captures ‚ÄòCatastrophic Damage‚Äô from wind, so it‚Äôs not clear that there would be a need for another category even if storms were to get stronger.‚Äù</p>

<figure><blockquote><p>‚ÄúThe reality is that hurricanes have changed already. This creates the need to discuss whether the systems that we currently have in place are adequate for the future.‚Äù</p></blockquote></figure>

<p>The question of whether a category 6 would be an effective communication tool requires a larger discussion, with input from social scientists, psychologists, emergency managers, and city planners, Kossin said. He said he hopes the idea of a hypothetical category 6 will spark more discussion of how to warn people about all hurricane-related risks, including wind, storm surge, and rainfall, as hurricanes continue to intensify.</p>

<p>‚ÄúWhat we‚Äôre trying to highlight is not the immediate danger of an impending storm,‚Äù Wehner said. ‚ÄúThat kind of thing is already out there. What we‚Äôre trying to communicate is that the risk of the most intense storms is increasing because of climate change.‚Äù</p>

<p><a href="https://www.stonybrook.edu/commcms/somas/people/_profiles/kevin-reed" target="_blank" rel="noreferrer noopener">Kevin Reed</a>, a climate and atmospheric scientist at Stony Brook University who was not involved in the new study, said that expanding the Saffir-Simpson scale would not only indicate increased risks from individual storms but highlight the worsening risks of climate change in general.</p>

<p>‚ÄúThe reality is that hurricanes have changed already,‚Äù Reed said. ‚ÄúThis creates the need to discuss whether the systems that we currently have in place are adequate for the future.‚Äù</p>

<p>‚ÄîGrace van Deelen (<a href="https://twitter.com/GVD__" target="_blank" rel="noreferrer noopener">@GVD__</a>), Staff Writer</p>

<h5><strong>Citation:</strong>&nbsp;van Deelen, G. (2024), We‚Äôve already seen category 6 hurricanes‚Äînow scientists want to make it official,&nbsp;<em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240060" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2024EO240060</a>. Published on 5 February 2024.</h5>

<h6>Text ¬© 2024. AGU.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a><br>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chris Wanstrath "defunkt" GitHub cofounder and former CEO is banned on GitHub (108 pts)]]></title>
            <link>https://twitter.com/defunkt/status/1754610843361362360</link>
            <guid>39267200</guid>
            <pubDate>Mon, 05 Feb 2024 21:08:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/defunkt/status/1754610843361362360">https://twitter.com/defunkt/status/1754610843361362360</a>, See on <a href="https://news.ycombinator.com/item?id=39267200">Hacker News</a></p>
Couldn't get https://twitter.com/defunkt/status/1754610843361362360: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Meta cuts off third-party access to Facebook Groups (105 pts)]]></title>
            <link>https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/</link>
            <guid>39266874</guid>
            <pubDate>Mon, 05 Feb 2024 20:43:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/">https://techcrunch.com/2024/02/05/meta-cuts-off-third-party-access-to-facebook-groups-leaving-developers-and-customers-in-disarray/</a>, See on <a href="https://news.ycombinator.com/item?id=39266874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">The recent surprise announcement that Meta will soon be shutting down its Facebook Groups API is throwing some businesses and social media marketers into disarray.</p>
<p>On January 23, Meta <a href="https://developers.facebook.com/blog/post/2024/01/23/introducing-facebook-graph-and-marketing-api-v19/">announced the release</a> of its Facebook Graph API v19.0, which included the news that the company would be deprecating its existing Facebook Groups API. The latter, which is used by developers and businesses to schedule posts to Facebook Groups, will be removed within 90 days, Meta said. This includes all the Permissions and Reviewable Features associated with the API, it also noted.</p>
<p>Meta explained that a major use case for the API was a feature that <a href="https://developers.facebook.com/docs/messenger-platform/discovery/private-replies/">allowed developers to privately reply</a> in Facebook Groups. For example, a small business that wanted to send a single message to a person who posted on their Facebook Group or who had commented in the group could be messaged through the API. However, Meta said that another change in the new v19.0 API would enable this feature, without the need for the Groups API.</p>
<p>But developers told TechCrunch that the shutdown of the API would cause problems for companies that offer solutions to customers who want to schedule and automate their social media posts. For example, explained Adam Peterson, the CEO of <a href="https://vipecloud.com/">VipeCloud</a>, which provides a suite of tools for scheduling social media posts, the API‚Äôs closure will have a ‚Äúnoticeable impact‚Äù on his business, as about 8% of his total revenue is on the chopping block. His company serves some 5,000 Facebook accounts, primarily those belonging to female entrepreneurs, he noted.</p>
<p>These customers rely on VipeCloud‚Äôs access to Facebook‚Äôs APIs to publish publicly to their Facebook Pages, but also post privately to Groups to communicate with their team. The private groups are used as something of a Slack alternative by these small businesses, he says.</p>
<p>‚ÄúEvery single one of our customers is freaking out,‚Äù says Peterson.</p>
<p>Other customers of the Groups API may rely on automations that are scheduled by the business‚Äôs agency partners, some of which will be disproportionally impacted by the API‚Äôs closure.</p>
<p>Peterson explains that customers often rely on agencies to handle various aspects of their posting, like team building or team motivation. ‚ÄúThose agencies, this is their entire business. This is their livelihood,‚Äù he adds.</p>
<p>The move also impacts VipeCloud‚Äôs competitors, often non-venture-funded companies that build market-specific services and whose revenue may be in the single-digit millions to low double-digit millions.</p>
<p>‚ÄúSome of these other companies ‚Äî they‚Äôre going to be killed,‚Äù notes Peterson. ‚ÄúAnd that‚Äôs just never fun to watch, even if we compete with them. You‚Äôd rather win on service or product or something,‚Äù he continues. ‚ÄúThis is platform risk in real time.‚Äù</p>
<p>A company by the name of<a href="https://postmyparty.com/"> PostMyParty</a>, which helps social sellers and others schedule and automate online parties, says the API‚Äôs closure will put the company out of business.</p>
<p>‚ÄúI will lose seven years of work and over 10,000 customers,‚Äù owner Daniel Burge tells TechCrunch. ‚ÄúA multimillion-dollar loss. Let alone the impact on all of our customers that rely on our software,‚Äù he adds.</p>
<p>PostMyParty is used by small micro-businesses, including health and fitness coaches who do online boot camps in Facebook Groups, work-at-home moms engaged in social sales and others with coaching groups or customer groups, says Burge.</p>
<p>The entrepreneur pointed out this is not the first time Meta has done something like this.</p>
<p>‚ÄúA number of years ago [Meta] abruptly ended their Events API, with zero notice,‚Äù Burge says. ‚ÄúWe just came in one day and everything was broken, we had thousands of support requests open from our customers and it almost destroyed our business that time as well.‚Äù</p>
<p>What‚Äôs more, developers tell us that Meta‚Äôs motivation behind the API‚Äôs shutdown is unclear. On the one hand, it could be that Facebook Groups don‚Äôt generate ad revenue and the shutdown of the API will leave developers without a workaround. But Meta hasn‚Äôt clarified if that‚Äôs the case. Instead, Meta‚Äôs blog post only mentioned one use case that would be addressed through the new v.19.0 API.</p>
<p>Maurice W. Evans, a Meta Certified Community Manager, believes the move will pose challenges for small businesses, developers and digital markets, but also represents a ‚Äúpivotal shift in Meta‚Äôs operational philosophy.‚Äù</p>
<p>‚ÄúThe removal of third-party access to Facebook Groups could significantly alter the digital landscape, creating both hurdles and opportunities for community managers and businesses alike. As a Meta Certified Community Manager, I‚Äôve seen firsthand the value these tools bring to fostering vibrant, engaged online communities. This change underscores the need for adaptability and innovation in our strategies,‚Äù Evans tells TechCrunch.</p>
<p>Elsewhere on social media, website design firm Archer Web Design <a href="https://twitter.com/ArcherWebsites/status/1752687220639650066">called the news of the API‚Äôs closure ‚Äúdevastating</a>‚Äù and said that ‚Äúbusinesses and social media marketers will be thrown into the stone age with this!,‚Äù they wrote in a post on X, formerly Twitter.</p>
<p>On Meta‚Äôs forum for developers, <a href="https://developers.facebook.com/community/threads/2076398286093257/">one developer says</a> they‚Äôre ‚Äúpretty shocked‚Äù by the company‚Äôs announcement, noting their app relies on the Groups API and will essentially no longer work when the shutdown occurs.</p>
<p>Others are frustrated that Meta hasn‚Äôt clearly explained if posting on Groups will be done with a Page Access token going forward, as the way the announcement is worded it seems that part is only relevant for those posting private replies, not posting to the group as a whole. Burge, for instance, wonders if the whole thing could just be some messaging mistake ‚Äî like Meta perhaps forgot to include the part where it was going to note what its new solution would be.</p>
<p>There is concern, however, that Meta is deprioritizing developers‚Äô interests having recently shut down its <a href="https://developers.facebook.com/support/bugs/">developer bug portal</a> as well.</p>
<p>Reps from Facebook haven‚Äôt replied to the developers‚Äô comments in its forums (as of the time of writing), leaving everyone in the dark.</p>
<p><a href="https://developers.facebook.com/community/threads/584177870580474/">Laments another developer</a> in the forum, ‚Äúit affects my ongoing projects and projects that will be launched soon. I don‚Äôt know what to do.‚Äù</p>
<p><em>This story is developing. Meta has been asked for comment and we‚Äôll update as we know more.&nbsp;</em></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Want to build a sequencer? 454.bio opens up their plans (128 pts)]]></title>
            <link>http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html</link>
            <guid>39266859</guid>
            <pubDate>Mon, 05 Feb 2024 20:41:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html">http://omicsomics.blogspot.com/2024/02/want-to-build-sequencer-454bio-opens-up.html</a>, See on <a href="https://news.ycombinator.com/item?id=39266859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-965125533024651667" itemprop="description articleBody">
<p>Just as the AGBT hype cycle was firing up (with me contributing multiple sparks), serial entrepreneur Jonathan Rothberg's latest sequencing startup 454.bio fully de-stealthed their technology this weekend, going so far as to release<a href="https://454.bio/docs/"> open source plans</a> to build an instrument prototype.&nbsp; 454.bio&nbsp; is aiming to build a Keurig-sized device to retail for $100, with sequencing runs in the $20 range.&nbsp; To accomplish this, they're attempting a novel twist on sequencing-by-synthesis.&nbsp; It's an unconventional strategy by someone who has succeeded twice before in DNA sequencing (454 and Ion Torrent) and has multiple other companies going (if I've counted correctly)&nbsp; - QuantumSI in protein sequencing (a future topic for this space, I promise!), ButterflyNetworks with inexpensive, compact diagnostics ultrasound and Hyperfine with inexpensive, compact MRI diagnostic devices.&nbsp; Then I went to the <a href="https://www.4catalyzer.com/">4Catalyzer site</a> - Rothberg's incubator - and discovered a bunch of companies I hadn't heard of or had forgotten about -- Protein Evolution in synthetic biology for plastics production, Detect for home-based diagnostics instruments, AI Therapeutics in the rare disease space and Liminal with what looks like consumer brain scanning.&nbsp; That's quite a series of companies!&nbsp; &nbsp;But the one closest to my heart (sorry QuantumSI :-) is&nbsp; 454.bio, and their announcements have many interesting facets which I'll dive into.</p><h2><span><a name="more"></a></span>New Wine in an Old Bottle</h2><p>Rothberg loves the 454 story and the 454 moniker, and so went and bought all the trademarks back from Roche.&nbsp; 454, after all, launched the first commercial post-Sanger sequencer and also generated the first genome of a previously-named individual, controversial DNA pioneer (and knucklehead) James D. Watson (yes, everybody knew Celera sequenced J.Craig Venter, but there was a claim of anonymity at first).&nbsp; &nbsp;Whether reviving the name was a great idea is good over-drinks conversation - already I've seen confusion as to why anyone would reboot 454 technology -- and 454.bio's approach has essentially nothing to do with 454's approach.&nbsp;&nbsp;</p><p>In the molecular biology analytics space, Rothberg has been responsible for founding 4&nbsp; companies before 454.bio, starting with what I'll refer to after this as 454 classic.</p><p>Raindance was the least successful, due to never finding a good market for their really cool picoliter droplet technology.&nbsp; They first tried to go after target enrichment for NGS, but soon were plowed over by in-solution technologies from Agilent and Nimblegen.&nbsp; Later they pivoted to digital PCR, but that market was still developing and the Raindance instrument was too big and expensive.&nbsp; Perhaps there was another product pivot or two in between.&nbsp; Eventually it was sold for IP to BioRad.</p><p>Ion Torrent did not achieve the lofty goals it set out to hit - we never saw a single chip generate an entire human genome - but did create a working sequencer and was enough of a threat that Illumina brought out MiSeq to compete with the PGM.&nbsp; Ion Torrent was also the first non-optical detection NGS instrument, and found at least some showcase uses (if not much market) in places where optical sequencers wouldn't perform well, such as on a boat.&nbsp; And Ion carved out a lucrative niche in genetic panel testing, driven by being paired with AmpliSeq multiplex PCR technology - another great example (like Nextera which I cited in my previous piece) of lock-down a complementary technology driving market share.&nbsp; But even that wasn't enough - eventually ThermoFisher capitulated and licensed AmpliSeq for Illumina platforms.&nbsp; Ion is still on the market, but hasn't innovated in years in terms of performance.&nbsp; Indeed, it was around the time Rothberg left that performance improvement tanked; he picked a good time to leave.</p><p>QuantumSI, which I'll cover sometime in the future, is the first (and so far only) entrant in next-gen protein sequencing.&nbsp; There's an important parallel between the technical approaches of QuantumSI and 454.bio: one pot operation.</p><h2>One Pot Sequencing</h2><p>Every short read sequencer to date has used a cyclic chemistry scheme.&nbsp; Each base (or series of the same base for flow chemistries such as 454classic, Ion Torrent, Genapsys and Ultima) requires adding reagents, and then there are stripping steps (for reversible terminator schemes) and washes.&nbsp; Then another cycle happens.&nbsp; Each cycle is distinct and requires fresh reagents.&nbsp;&nbsp;</p><p>Delivering those reagents requires microfluidic pumps and lines.&nbsp; Delivery to the flowcell can be dogged by challenges of even dispersal; Ion Torrent raw signals had patterns of light and dark looking like flow lines.&nbsp; The smaller Ion chips had almond-shaped gaskets which lost much surface area but had more uniform fluid flow.&nbsp; Later, higher capacity chips tried to go for something more like a square to maximize area, but the corners could be troublesome -- and if reagent from one cycle hung up there it would contaminate the next cycle.&nbsp;&nbsp;</p><p>Also troublesome is that the reagents are very highly concentrated, to drive the reaction to near completion.&nbsp; But only tiny amounts of the volume actually go anywhere useful and very little of those expensive reagents actually are consumed by the sequencing reactions; most are just flushed away each cycle.&nbsp; That adds to the expense.</p><p>454.bio is introducing "One Pot Sequencing" - there are no cycles of reagents.&nbsp; QuantumSI's chemistry has a similar notion, though that is a degradative not synthesis chemistry, but again no cycles -- the "one pot" of reagents runs the reactions continuously.&nbsp; &nbsp;454.bio is using a reversible terminator chemistry, except instead of using chemical cleavage to remove the terminator and fluorescent moieties, ultraviolet light is employed.&nbsp; These "Lightning Terminators" were once the basis of LaserGen - a company that was acquired by Agilent and then somewhat quietly shuttered.&nbsp; LaserGen was developing a more conventional cycling instrument, but with very fast cycle times.</p><p>Like all other optical readout short read sequencers (except 454!), 454.bio employs Total Internal Reflection Fluorescence (TIRF) microscopy.&nbsp; The basic idea of TIRF is that if you aim light at the right angle, by the precepts of conventional physics it will all reflect off the interface between the glass surface and the reagents above -- but in quantum land the light's field extends a bit beyond that surface - evanescent illumination.&nbsp; So only a tiny volume of reagent will give any signal - the tiny volume that contains polonies.&nbsp; PacBio uses a similar logic with Zero Mode Waveguides - when they are imaging fluorescence can only occur close to the surface and so the huge background of unincorporated nucleotides and released labels is essentially invisible.&nbsp;&nbsp;</p><p>For 454.bio, this is also how the removal of the fluorophore/terminating moiety occurs - a cycle of illumination with the appropriate wavelength of light to cleave the terminator moiety.&nbsp; Lighting Terminators are 3' unblocked; the 3' hydroxyl is always there but steric effects prevent the polymerase from accessing it.&nbsp; So the evanescent illumination is critical again - you don't want to be deblocking all the terminators that haven't been incorporated.&nbsp; Of course, there will be free terminators that do get into the critical zone -- such as blank areas with no polony or diffusion into the polony and so forth.&nbsp; So 454.bio will build up problematic unterminated nucleotide triphosphates after every deblock cycle.&nbsp;&nbsp;</p><p>And that is their current problem - read lengths are in the single digits because the polymerase they are using prefers the unterminated nucleotides to terminated ones, so after a few cycles of deblocking there's enough unterminated nucleotides to cause serious dephasing -- the molecules in the polony are no longer moving in lockstep.&nbsp; In one of their unconventional steps (more on this below), 454.bio has announced a contest for improving the discrimination of the polymerase.&nbsp; If you win by delivering a much improved polymerase a year from now, you get $200K&nbsp; and can patent and/or public - but grant 454.bio a royalty-free license to use your invention and they have the rights to further engineer based on your design.&nbsp;&nbsp;</p><p>Here's a plot of the <a href="https://454.bio/blog/2023/12/18/s0592-sequencing-results/">most recent sequencing run described on their blog</a>.&nbsp; I'd still prefer to see the error rate plotted log scale, but in this range it's not that important a point.&nbsp; Claim is those first five bases are in the phred 20-25 range.&nbsp; Plotting it log scale would help resolve to what degree is that jump from 4 to 5 truly a discontinuity or is it where the trend was going.&nbsp;&nbsp;</p><div><p><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjJu7bl8nCoH0HzxA06xxC8EkOlXqZQZVpMXYnN05jtX8yNxYVSUYRX06ay6FWSn_GA7EAaPksTrMDHG3liFjedlT-_4dXTvp1ZOe051G8_Z563K8Mvisc5iwebnCIVnS2sx3gaPNLfCUAogItEpPy7be7hNQgH2EUKNU1GT_l0I_moyApCs_P_lw"><img alt="" data-original-height="339" data-original-width="480" height="226" src="https://blogger.googleusercontent.com/img/a/AVvXsEjJu7bl8nCoH0HzxA06xxC8EkOlXqZQZVpMXYnN05jtX8yNxYVSUYRX06ay6FWSn_GA7EAaPksTrMDHG3liFjedlT-_4dXTvp1ZOe051G8_Z563K8Mvisc5iwebnCIVnS2sx3gaPNLfCUAogItEpPy7be7hNQgH2EUKNU1GT_l0I_moyApCs_P_lw" width="320"></a></p><p>And from the prior post we can see the degree of color chaos going on in a cluster.&nbsp; If I understand the note on the sequence of the templates, this should read TCAGG which appears to map to red, blue, green, yellow, yellow -- but the majority color here is red red green yellow yellow.&nbsp; So it would appear the deprotection of the cycle 1 T (red) did not go very well (again, I'd prefer to see a log plot of the intensities!!) as we see intense red in cycle 2 and still a bunch in cycle 3 and a bit in 4 and 5 -- and the next T in the template isn't until position 10!&nbsp; I'd be tempted to design the molecules at this point to go a really long ways before the first base shows up again, so could measure very carefully the degree of lagging phasing.&nbsp; We see the yellow prephasing as a blip in 2 but significant in 3 -- again, it would be interesting to design some libraries where there are more positions before the first instance of a given base.&nbsp; If I were working on this, I'd probably be designing a whole library of templates to use in given runs -- complexity of four in each run but various choices of design to stress-test various aspects of the chemistry.&nbsp; Okay, I'm getting sucked into the challenge here...</p></div><div><p><a href="https://blogger.googleusercontent.com/img/a/AVvXsEjBrwdcerJnSkC9bY10hDUC8THFpSOM9BAL6WccajQ3qOExXl6fOkEbSaZgCmiWmZ3PKBpPNAeICeMSMLFNeJHNXilKIWeS-EVi5YkVUK2yMreUlLS5uqLkkxXgn-mtHPFM1H5Wv_zcDnX3Y8IOszeWWAqH6US8zQ10HpMRt1k-4UCtVQQZ91BwHw"><img alt="" data-original-height="180" data-original-width="475" height="121" src="https://blogger.googleusercontent.com/img/a/AVvXsEjBrwdcerJnSkC9bY10hDUC8THFpSOM9BAL6WccajQ3qOExXl6fOkEbSaZgCmiWmZ3PKBpPNAeICeMSMLFNeJHNXilKIWeS-EVi5YkVUK2yMreUlLS5uqLkkxXgn-mtHPFM1H5Wv_zcDnX3Y8IOszeWWAqH6US8zQ10HpMRt1k-4UCtVQQZ91BwHw" width="320"></a></p></div><p>By the way, how are polonies (or clusters, if you prefer) formed?&nbsp; 454.bio is using circular library molecules which are isothermally amplified by something I see as rolling circle amplification (RCA) crossed with bridge amplification.&nbsp; The surface has forward and reverse primers covalently bound, and initial amplification is by one of those primers driving an RCA reaction - but those products can now find other bound primers to drive more reactions and so on.&nbsp; The result is a hyperbranched structure.&nbsp; The reverse primers all contain deoxyuracil, so a USER reaction destroys these to loosen up the snarl.&nbsp; Note that because each cluster results from multiple priming events, this style of cluster generation will make copies of copies, unlike pure RCA cluster generation on platforms such as AVITI and Complete Genomics.</p><h2>Unconventional Company</h2><p>Going open source is certainly not the usual strategy for a company - most companies stay in stealth mode, then get some alpha sites without revealing much to the world - Ultima's technology first ran at the Broad in a locked room that only a select cadre of Broad employees had access to or even knew existed.&nbsp; Oxford Nanopore went a bit differently by <a href="https://omicsomics.blogspot.com/2012/02/oxford-nanopore-doesnt-disappoint.html">suddenly destealthing at AGBT 2012</a>, then going relatively quiet for two years, but then executing the MinION Access Program (MAP) for many researchers around the world.&nbsp;&nbsp;</p><p>Appealing to the idea of garage hobbyists has an almost romantic appeal.&nbsp; When I was about 8, my brother and father got a kit-based computer for a few hundred dollars when there were many such kits and no fully functional home computers yet.&nbsp; Ours was a <a href="http://retro.hansotten.nl/6502-sbc/datac-1000-a-tim-6502-sbc-from-1976/">DATAC-1000</a>, the input method was a series of metal pads and the only output device was a row of LEDs above the metal pads.&nbsp; Well, it had a cassette tape interface for storing programs.&nbsp; There were others like the KIM-1 and the Altair and some tree fruit named one we started hearing about.&nbsp; For at most a few thousand dollars you could flesh these out with calculator-style keypad+display or even simple video interfaces.&nbsp; From that era came many early programmers and hardware tinkerers -- big brother put together our video display (he may have even designed it).&nbsp; &nbsp;In terms of financial outlays, a serious computer building habit cost not much different than diving into 35mm photography.</p><p>Sequencing technology seems so digital and potentially as impactful, plus there is so much burnishing of the legend of the early computers or companies like Hewlett-Packard that started in garages.&nbsp; Ion Torrent tried to tap into this, but the catch was that their claimed price of $50K isn't hobbyist money - and the real upfront outlay was $100K.&nbsp; It's also a lot harder to get things running the first time - with some coaching an 8-year old me could write a simple 6502 machine code program to add two numbers but making a sequencing library is a much bigger lift.&nbsp; Plus all the accessories you need.&nbsp; Those old computing days you mostly got by with pliers and a soldering iron (we did have not one but two oscilloscopes - didn't everyone in the 1970s have one in their house?).&nbsp; But for even the most basic library prep, you must have temperature control of liquids, a complete set of pipettors, a minfuge and probably a few more bits.&nbsp;&nbsp;</p><p>There was a <a href="https://omicsomics.blogspot.com/2009/10/pondering-polonators.html">build-it-from-plans sequencer called the Polonator</a>, but at the time it cost around $200K to put one together.&nbsp; &nbsp;Some academics did so, but it never had a large user base - and then the supplier of reagents was bought by QIAGEN and that was the end of Polonator.&nbsp;</p><p>Oxford Nanopore tried to tap into the vibe with MinION, but discovered its not easy.&nbsp; They certainly reaped large dividends from the MAP getting MinIONs into the hands of many early career folks who didn't have a vested interest in sustaining the Illumina ecosystem and could make a name for themselves pioneering nanopore sequencing.&nbsp; So folks like Josh Quick, Nick Loman, Miten Jain, Matt Loose (and far too many I'll omit here - my apologies!) held on through ONT's initial unreliability and zigzagging platform changes and showed novel applications and strengths of nanopore sequencing and shared their protocols and software with the world.&nbsp; But for better or worse, you didn't actually build any of the hardware.</p><p>Mid last decade I did have one sequencer startup offer to send me plans to build a very low cost instrument -- they claimed around $1000 in parts.&nbsp; It never came to fruition - and I'm not sure sending me lab plans made much sense though I was game to try it out, but the idea has been out there before.&nbsp; The NDA I had with them is probably enforceable, so I won't spill who it was (sorry!).</p><p>Now 454.bio is really, truly releasing complete plans.&nbsp; I'm not sure I'm capable of quite following them and I would expect that early users will be sending in pointers about where they can be improved.&nbsp; But the directions are there as are the design files for the many 3D-printed parts in the instrument.&nbsp;&nbsp;</p><p>I tried my best to price out the most expensive components - it would have been nice if this happened about two years ago as I could have asked a favor of my nephew, who was in customer support at one of the optical houses listed in the parts inventory.&nbsp; So please check yourself.&nbsp; The biggest ticket item is the camera, which I have at $700 -- but the description in the parts brings up many variations with variation in price range -- perhaps one thing 454.bio could nail down a bit better.&nbsp; There's a positioning table for $300, four different bandpass filters for $1000 total ($250 each), and 16 UV LEDs that add up to $130.&nbsp; No other component seems to be more than $100, and my total is up to about $2500.&nbsp; That doesn't include things that look inexpensive like nuts and bolts and such or the 3D printing, but suppose that somehow added $500.&nbsp; $3K is less than it can be easy to spend on a mirrorless digital camera and a few lenses for it. So not unreasonable.</p><p>The announcement shows some signs of being rushed - one image talked about "complimentary strands" of DNA in two different locations. But worst, the original price in the store for the critical reversible terminator mix was $33,999!&nbsp; That's a hell of a lot more than I ever spent on film, photo prints or photo paper! After pushback, Rothberg declared "typo"&nbsp; and the price changed to $1299&nbsp; - the Levenshtein distance between that and 33,999 engenders skepticism of the typo explanation.&nbsp; That $1299 is said to enable 60 runs.&nbsp; That was the advantage of the old kit computers - once you bought them the only consumable was blank cassette tapes, which were cheap, reusable and you didn't need many.&nbsp;</p><p>You'll also need the sequencing reservoir components, $49.99 for a pack of 5.&nbsp; As my colleague (and synthetic biology legend) Tom Knight pointed out on X/Twitter, the finishing directions for the reservoirs aren't for amateurs, involving several solvents and something he called "piranha".&nbsp; Yikes!&nbsp; Rothberg responded that they'll work towards something more consumer friendly.&nbsp; &nbsp;So that brings running costs to about $33 per run - $23 dollars of terminators and $10 for the reservoir (note: unlike their store, I like to round!)</p><h2>What's The Market?</h2><p>In the short term, you'll need to be very interested in playing with a novel technology that doesn't really do very much.&nbsp; The early kit computers, and even the first all-in-one home computers such at PET and TRS-80, weren't much better - you could learn to program or you could play games, but not very much else no matter how many journalists tried to claim it could organize recipes or help prepare taxes -- that was all long in the future (and who organizes recipes when you can just google them?).&nbsp; With the current tiny readlength, you'll be very hard pressed to get much interesting biology out - though it will certainly be hyped as "go explore the biosphere".&nbsp; With custom sequencing primers, it should be possible to make those 5 or so bases count, but the current 454.bio don't make the process for designing such obvious.</p><p>It may well be that many people will be excited to through their machine learning skills at trying to improve the basecalling and deal with the rampant phasing.&nbsp; It sounds like some diversity of the initial bases is required for good cluster finding - a common aspect of systems using unpatterned flowcells - but it would seem that a set of templates could be cloned (don't want oligo synthesis errors confounding) and sequenced conventionally, then used as 454.bio targets.&nbsp; Each one should have the first 5 bases as a barcode that defines the rest of the sequence -- I'll leave figuring out the number of distinct barcodes with different Hamming or Levenshtein distances as an exercise for the reader..&nbsp; Perhaps some big open repositories will be built for 454.bio data, to increase the training set sizes.&nbsp; And perhaps an advanced machine learning algorithm could make the downstream snarl useful for some basic tasks like "which RNA virus" is this -- at least if you only want "flu A vs COVID vs RSV" level differentiation.</p><p>Longer term, if the phasing issue can be solved and reads could get in the 50 to 100 range, I could imagine diagnostics applications.&nbsp; Maybe.&nbsp;&nbsp;<span>It will depend in part on how many reads per floral - I didn‚Äôt see that described but it‚Äôs likely to change over the evolution of the chemistry and software. Clearly some evolution of the hardware will be required to get to the goal of $100 a box.&nbsp;</span></p><p><span id="docs-internal-guid-d87fd403-7fff-4b6c-efdd-e6c31220b180"><p dir="ltr"><span>The low end sequencing market has neither gotten much love nor been very successful. Ion Torrent pretended to go for this market, but an all-in upfront cost of $100K isn‚Äôt hobbyist territory. Genapsys officially launched their $20K solution, but I never saw one in the field nor ever heard from a customer - and they‚Äôre gone. Illumina has used, but that‚Äôs instrument has never seen upgrades and is all but ghosted by Illumina management</span></p><p dir="ltr"><span>But the market does have MinION, a fully functional sequencing device you can get for $2K (not a typo!) that‚Äôs really works now. In theory the Flongle (another $ for the adaptor) gets run costs in the low double digits. In the home computer market, the arrival of fully featured machines was the death knell of the kit computers, only much later revived with concepts like Raspberry Pi</span></p><p dir="ltr"><span>So how many people will buy in to the 454.bio concept early? During the MAP, ONT saw significant attrition in the user base because the platform was still very buggy and reagent availability was erratic. Others were hooked;&nbsp; for me it was seeing in our first run one very noisy but alignable 48 kilobase read with the entire lambda phage genome.&nbsp;Maybe some novices who build a 454.bio will have a similar epiphany with their first sequence data, but I'm skeptical it will be a wide-spread phenomenon -- though it would make be happy to be proved wrong on that point.</span></p><p dir="ltr"><span>Unconventional operations, an innovative technology at proof-of-concept and appealing to tech hobbyists -- 454.bio should be fun to watch even if they don't succeed in carving out a major presence in the sequencing technology landscape.</span></p></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Relativistic Spaceship (897 pts)]]></title>
            <link>https://dmytry.github.io/space/</link>
            <guid>39266396</guid>
            <pubDate>Mon, 05 Feb 2024 20:07:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmytry.github.io/space/">https://dmytry.github.io/space/</a>, See on <a href="https://news.ycombinator.com/item?id=39266396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="all_ui" ondblclick="toggleFullscreen()">
        <div id="info">
          <br>
          <div onclick="hide_button_click()"><p>The ship is flying at </p><p>0%</p><p> of the speed of light.</p></div>
            <div id="more_info">
              <div><p>Œ≥ = </p><p>1</p></div>
              <div><p>Distance (light years) = </p><p>0</p></div>
              <div><p>Screen center Doppler factor = </p><p>1</p></div>
              <div><p>Max Doppler factor = </p><p>1</p></div>
              <div><p>Ship time (years) = </p><p>0</p></div>
              <div><p>World time (years) = </p><p>0</p></div>
          </div>
        </div>
        <p>¬© 2020 Dmytry Lavrov.</p>

        <div id="acceleration">
        <p>
        A<br>C<br>C<br>E<br>L<br>E<br>R<br>A<br>T<br>I<br>O<br>N
        </p>
        
        <p>1</p>
        </div>

        <div id="exposure">
        <p>
        B<br>R<br>I<br>G<br>H<br>T<br>N<br>E<br>S<br>S<br>
        </p>
        
        <p>1</p>
        </div>

        <p>Relativistic flight visualizer by <a href="http://dmytry.com/">Dmytry Lavrov</a>.<br>
        This project is open source; you can obtain sources at<br>
        <a href="https://github.com/Dmytry/space">https://github.com/Dmytry/space</a><br>
        It uses Three.JS webgl framework; the three.js license is <a href="https://dmytry.github.io/space/three.js.LICENSE.txt">here</a>.
        </p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: CLI for generating PDFs for offline reading (146 pts)]]></title>
            <link>https://github.com/dvcoolarun/web2pdf</link>
            <guid>39265756</guid>
            <pubDate>Mon, 05 Feb 2024 19:24:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dvcoolarun/web2pdf">https://github.com/dvcoolarun/web2pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39265756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:dvcoolarun/web2pdf" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="eSSKYYS7EbGjjRguiBYjJ7lGbNj2aCgpxTlMxGQipBehPuU0dqDfTai8FxakWBA_zGZ8M6oRV9UnGKmgRMx0fw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="dvcoolarun/web2pdf" data-current-org="" data-current-owner="dvcoolarun" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=vAHFOlJTS%2FND5QxX4%2FYCR2C4tep%2FQNEU4ArCjHYR6O90hif61me8%2Fy6G%2FZEbaMs2gA9Scmr8wz6b%2FxHGF6%2Bi0A0Ci8mRWcU5gmTjnmC16KZqrhxwBQeBLeZXAE3yaTypvLyov7RuRGDNCqH%2BEsXN7h%2BnW7sRmUnz%2BC61KMbzRcEDONzpvanjbLrFfcO68aEGtjA99ESFdooupn%2BcQPYn8DoZU8E4tziT2XyxnBZDnC1uy2STcnFhtv57Ss4fNHJrxbgS4ctg3Q9lr4t%2FnqdUoTkxZTPeHTbinhxFrCsRCxXhuWCsmKdnD2PoWQYwwPGHTRo0Qf9VgiULSehrAVoH4QYXwE6%2BR5qYc6%2FWM0xlPsw8UV1pY7OhtJfgHFwvgCbTVlEONSy15ZBsWVNu7Du16PD1LimmWGQAg14zi4dsq7ZJCyRYBm8na7UgTDdiHdfONC0nMRF2MdlRnqiZwdPM5jy6PCINrMAsJZJu%2FTIGTgOpATBgpsVLDfd40orGAggUpA7jhxPgrTiaQVtxfaI%3D--qhW8IwPNQAp7LyH7--M2soVlKNT2NA6IRDQkxtjg%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=dvcoolarun%2Fweb2pdf" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/dvcoolarun/web2pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="69f6307eabf4b6a81ab42be9217bde61923dc50db6bdbf79021d2b7a2d74615c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Out-of-bounds read and write in the glibc's qsort() (149 pts)]]></title>
            <link>https://www.openwall.com/lists/oss-security/2024/01/30/7</link>
            <guid>39264396</guid>
            <pubDate>Mon, 05 Feb 2024 18:04:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openwall.com/lists/oss-security/2024/01/30/7">https://www.openwall.com/lists/oss-security/2024/01/30/7</a>, See on <a href="https://news.ycombinator.com/item?id=39264396">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>

<td>
<a href="https://www.openwall.com/"><img src="https://www.openwall.com/logo.png" width="182" height="80" alt="Openwall"></a>
</td><td>
<div>
<ul>
<li><a href="https://www.openwall.com/">Products</a>
<ul>
<li><a href="https://www.openwall.com/Owl/">Openwall GNU/*/Linux &nbsp; <i>server OS</i></a>
</li><li><a href="https://www.openwall.com/lkrg/">Linux Kernel Runtime Guard</a>
</li><li><a href="https://www.openwall.com/john/">John the Ripper &nbsp; <i>password cracker</i></a>
<ul>
<li><a href="https://www.openwall.com/john/">Free &amp; Open Source for any platform</a>
</li><li><a href="https://www.openwall.com/john/cloud/">in the cloud</a>
</li><li><a href="https://www.openwall.com/john/pro/linux/">Pro for Linux</a>
</li><li><a href="https://www.openwall.com/john/pro/macosx/">Pro for macOS</a>
</li></ul>
</li><li><a href="https://www.openwall.com/wordlists/">Wordlists &nbsp; <i>for password cracking</i></a>
</li><li><a href="https://www.openwall.com/passwdqc/">passwdqc &nbsp; <i>policy enforcement</i></a>
<ul>
<li><a href="https://www.openwall.com/passwdqc/">Free &amp; Open Source for Unix</a>
</li><li><a href="https://www.openwall.com/passwdqc/windows/">Pro for Windows (Active Directory)</a>
</li></ul>
</li><li><a href="https://www.openwall.com/yescrypt/">yescrypt &nbsp; <i>KDF &amp; password hashing</i></a>
</li><li><a href="https://www.openwall.com/yespower/">yespower &nbsp; <i>Proof-of-Work (PoW)</i></a>
</li><li><a href="https://www.openwall.com/crypt/">crypt_blowfish &nbsp; <i>password hashing</i></a>
</li><li><a href="https://www.openwall.com/phpass/">phpass &nbsp; <i>ditto in PHP</i></a>
</li><li><a href="https://www.openwall.com/tcb/">tcb &nbsp; <i>better password shadowing</i></a>
</li><li><a href="https://www.openwall.com/pam/">Pluggable Authentication Modules</a>
</li><li><a href="https://www.openwall.com/scanlogd/">scanlogd &nbsp; <i>port scan detector</i></a>
</li><li><a href="https://www.openwall.com/popa3d/">popa3d &nbsp; <i>tiny POP3 daemon</i></a>
</li><li><a href="https://www.openwall.com/blists/">blists &nbsp; <i>web interface to mailing lists</i></a>
</li><li><a href="https://www.openwall.com/msulogin/">msulogin &nbsp; <i>single user mode login</i></a>
</li><li><a href="https://www.openwall.com/php_mt_seed/">php_mt_seed &nbsp; <i>mt_rand() cracker</i></a>
</li></ul>
</li><li><a href="https://www.openwall.com/services/">Services</a>
</li><li id="narrow-li-1"><a>Publications</a>
<ul>
<li><a href="https://www.openwall.com/articles/">Articles</a>
</li><li><a href="https://www.openwall.com/presentations/">Presentations</a>
</li></ul>
</li><li><a>Resources</a>
<ul>
<li><a href="https://www.openwall.com/lists/">Mailing lists</a>
</li><li><a href="https://openwall.info/wiki/">Community wiki</a>
</li><li><a href="https://github.com/openwall">Source code repositories (GitHub)</a>
</li><li><a href="https://cvsweb.openwall.com/">Source code repositories (CVSweb)</a>
</li><li><a href="https://www.openwall.com/mirrors/">File archive &amp; mirrors</a>
</li><li><a href="https://www.openwall.com/signatures/">How to verify digital signatures</a>
</li><li><a href="https://www.openwall.com/ove/">OVE IDs</a>
</li></ul>
</li><li id="last-li"><a href="https://www.openwall.com/news">What's new</a>
</li></ul>
</div>


</td></tr></tbody></table>




<a href="https://www.openwall.com/lists/oss-security/2024/01/30/6">[&lt;prev]</a> <a href="https://www.openwall.com/lists/oss-security/2024/01/30/8">[next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2024/02/04/1">[thread-next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2024/01/30/">[day]</a> <a href="https://www.openwall.com/lists/oss-security/2024/01/">[month]</a> <a href="https://www.openwall.com/lists/oss-security/2024/">[year]</a> <a href="https://www.openwall.com/lists/oss-security/">[list]</a>
<pre>Date: Tue, 30 Jan 2024 18:39:37 +0000
From: Qualys Security Advisory &lt;qsa@...lys.com&gt;
To: "oss-security@...ts.openwall.com" &lt;oss-security@...ts.openwall.com&gt;
Subject: Out-of-bounds read &amp; write in the glibc's qsort()


Qualys Security Advisory

For the algorithm lovers: Nontransitive comparison functions lead to
out-of-bounds read &amp; write in glibc's qsort()


========================================================================
Contents
========================================================================

Summary
Background
Experiments
Analysis
Patch
Discussion
Acknowledgments
Timeline

    CUT MY LIST IN TWO PIECES
    THAT'S HOW YOU START QUICK SORT
        -- <a href="https://twitter.com/QuinnyPig/status/1710447650112438710" rel="nofollow">https://twitter.com/QuinnyPig/status/1710447650112438710</a>


========================================================================
Summary
========================================================================

We discovered a memory corruption in the glibc's qsort() function, due
to a missing bounds check. To be vulnerable, a program must call qsort()
with a nontransitive comparison function (a function cmp(int a, int b)
that returns (a - b), for example) and with a large number of attacker-
controlled elements (to cause a malloc() failure inside qsort()). We
have not tried to find such a vulnerable program in the real world.

All glibc versions from at least September 1992 (glibc 1.04) to the
current release (glibc 2.38) are affected, but the glibc's developers
have independently discovered and patched this memory corruption in the
master branch (commit b9390ba, "stdlib: Fix array bounds protection in
insertion sort phase of qsort") during a recent refactoring of qsort().

About our advisory, the glibc security team issues the following
statement:

------------------------------------------------------------------------
This memory corruption in the GNU C Library through the qsort function is
invoked by an application passing a non-transitive comparison function, which
is undefined according to POSIX and ISO C standards.  As a result, we are of
the opinion that the resulting CVE, if any, should be assigned to any such
calling applications and subsequently fixed by passing a valid comparison
function to qsort and not to glibc.  We however acknowledge that this is a
quality of implementation issue and we fixed this in a recent refactor of
qsort.  We would like to thank Qualys for sharing their findings and helping
us validate our recent changes to qsort.
------------------------------------------------------------------------


========================================================================
Background
========================================================================

While browsing through Postfix's HISTORY file, we stumbled across a
puzzling entry from February 2002:

------------------------------------------------------------------------
        Bugfix: make all recipient comparisons transitive, because
        Solaris qsort() causes SIGSEGV errors otherwise. Victor
        Duchovni, Morgan Stanley. File: *qmgr/qmgr_message.c.
------------------------------------------------------------------------

Segmentation faults in qsort()? Transitive comparison functions?

As explained in the manual page for qsort(), "The comparison function
must return an integer less than, equal to, or greater than zero if the
first argument is considered to be respectively less than, equal to, or
greater than the second." Of course, such a comparison function cmp()
must be transitive:

- if a &lt; b (i.e., if cmp(pointer_to(a), pointer_to(b)) &lt; 0);

- and if b &lt; c (i.e., if cmp(pointer_to(b), pointer_to(c)) &lt; 0);

- then necessarily a &lt; c (i.e., cmp(pointer_to(a), pointer_to(c)) &lt; 0).

For example, the following comparison function (which compares integers)
is transitive (and perfectly correct):

------------------------------------------------------------------------
int
cmp(const void * const pa, const void * const pb)
{
    const int a = *(const int *)pa;
    const int b = *(const int *)pb;
    if (a &gt; b) return +1;
    if (a &lt; b) return -1;
    return 0;
}
------------------------------------------------------------------------

A shorter and more efficient version of this comparison function could
simply "return (a &gt; b) - (a &lt; b);" and still be transitive and perfectly
correct:

- if a &gt; b, it returns 1 - 0 = +1;

- if a &lt; b, it returns 0 - 1 = -1;

- if a = b, it returns 0 - 0 = 0.

The question, then, is: how can a comparison function be nontransitive?
A comparison function cmp() is nontransitive if there exist a, b, and c
such that:

- a &lt; b (because cmp(pointer_to(a), pointer_to(b)) &lt; 0);

- b &lt; c (because cmp(pointer_to(b), pointer_to(c)) &lt; 0);

- but a &gt;= c (because cmp(pointer_to(a), pointer_to(c)) &gt;= 0 by
  mistake).

Although the following comparison function seems correct at first, it is
in fact nontransitive, because the subtraction in "return (a - b);" is
prone to integer overflows:

------------------------------------------------------------------------
int
cmp(const void * const pa, const void * const pb)
{
    const int a = *(const int *)pa;
    const int b = *(const int *)pb;
    return (a - b);
}
------------------------------------------------------------------------

For example, if a = INT_MIN, b = 0, and c = INT_MAX, then:

- a &lt; b (because cmp(pointer_to(a), pointer_to(b)) returns INT_MIN - 0,
  which is correctly negative);

- b &lt; c (because cmp(pointer_to(b), pointer_to(c)) returns 0 - INT_MAX,
  which is also correctly negative);

- but a &gt; c by mistake (because cmp(pointer_to(a), pointer_to(c))
  returns INT_MIN - INT_MAX = +1, which is incorrectly positive because
  this subtraction overflows).

Unfortunately, such nontransitive comparison functions are extremely
common, as discussed in this excellent blog post from Ted Unangst:

  <a href="https://flak.tedunangst.com/post/subtraction-is-not-comparison" rel="nofollow">https://flak.tedunangst.com/post/subtraction-is-not-comparison</a>

and as hinted at in OpenBSD's manual page for qsort(): "It is almost
always an error to use subtraction to compute the return value of the
comparison function."

Fortunately, when passed to a robust qsort() implementation, these
nontransitive comparison functions should (at the worst) result in an
incorrectly sorted array; certainly not in a memory corruption. However,
the aforementioned entry from Postfix's HISTORY file suggests that not
all qsort() implementations are robust.


========================================================================
Experiments
========================================================================

We therefore decided to assess the robustness of the glibc's qsort()
implementation, by calling it with a nontransitive comparison function:

------------------------------------------------------------------------
  1 #include &lt;limits.h&gt;
  2 #include &lt;stdlib.h&gt;
  3 #include &lt;sys/time.h&gt;
  4 
  5 static int
  6 cmp(const void * const pa, const void * const pb)
  7 {
  8     const int a = *(const int *)pa;
  9     const int b = *(const int *)pb;
 10     return (a - b);
 11 }
 12 
 13 int
 14 main(const int argc, const char * const argv[])
 15 {
 16     if (argc != 2) return __LINE__;
 17     const size_t nmemb = strtoul(argv[1], NULL, 0);
 18     if (nmemb &lt;= 0 || nmemb &gt;= (1&lt;&lt;28)) return __LINE__;
 19 
 20     int * const pcanary1 = calloc(1 + nmemb + 1, sizeof(int));
 21     if (!pcanary1) return __LINE__;
 22     int * const array = pcanary1 + 1;
 23     int * const pcanary2 = array + nmemb;
 24 
 25     struct timeval tv;
 26     if (gettimeofday(&amp;tv, NULL)) return __LINE__;
 27     srandom((tv.tv_sec &lt;&lt; 16) ^ tv.tv_usec);
 28 
 29     const int canary1 = *pcanary1 = (random() &lt;&lt; 16) ^ random();
 30     const int canary2 = *pcanary2 = (random() &lt;&lt; 16) ^ random();
 31     array[random() % nmemb] = INT_MIN;
 32 
 33     qsort(array, nmemb, sizeof(int), cmp);
 34     if (*pcanary1 != canary1) abort();
 35     if (*pcanary2 != canary2) abort();
 36     return 0;
 37 }
------------------------------------------------------------------------

- at lines 5-11, cmp() is the nontransitive comparison function
  introduced in the previous "Background" section;

- at lines 16-18, the number of elements to be sorted (simple integers)
  is read from the command line;

- at lines 20-23, the array of elements to be sorted is calloc()ated,
  along with a canary element below this array, and a canary element
  above this array;

- at lines 29-30, these two canary elements are randomized, and copied
  to the stack for later comparison;

- at line 31, one random element of the array is initialized to INT_MIN
  (all other elements are initialized to 0 by calloc());

- at line 33, the elements of this array are sorted by qsort();

- at lines 34-35, the two canary elements (below and above the sorted
  array) are checked against their stack copies, and if they differ (an
  out-of-bounds write in qsort()), abort() is called.

We chose the array elements a = INT_MIN and b = 0 because they directly
exhibit the problematic behavior of this cmp() function:

- a &lt; b, because cmp(pointer_to(a), pointer_to(b)) returns INT_MIN - 0,
  which is correctly negative;

- but b &lt; a by mistake, because cmp(pointer_to(b), pointer_to(a))
  returns 0 - INT_MIN = INT_MIN (the "Leblancian Paradox"), which is
  incorrectly negative (because this subtraction overflows).

We then executed our test program in a loop, on Fedora 39 (which uses
the latest glibc version, 2.38):

------------------------------------------------------------------------
$ while true; do n=$((RANDOM*64+RANDOM+1)); ./qsort $n; done
------------------------------------------------------------------------

Unsurprisingly, nothing happened: our program did not crash or abort().
While this loop was still running (and not crashing), we started to read
the glibc's qsort() implementation; to our great surprise, we discovered
that the glibc's qsort() is not, in fact, a quick sort by default, but a
merge sort (in stdlib/msort.c).

Most likely, merge sort was chosen over quick sort to avoid quick sort's
worst-case performance, which is O(n^2); on the other hand, merge sort's
worst-case performance is O(n*log(n)). But merge sort suffers from one
major drawback: it does not sort in-place -- it malloc()ates a copy of
the array of elements to be sorted. As a result, if this array is very
large (lines 212-217), or if this malloc() fails (lines 219-229), then
the glibc's qsort() falls back to a quick sort (in stdlib/qsort.c),
because quick sort does sort in-place:

------------------------------------------------------------------------
163 void
164 __qsort_r (void *b, size_t n, size_t s, __compar_d_fn_t cmp, void *arg)
165 {
166   size_t size = n * s;
...
170   /* For large object sizes use indirect sorting.  */
171   if (s &gt; 32)
172     size = 2 * n * sizeof (void *) + s;
173 
174   if (size &lt; 1024)
175     /* The temporary array is small, so put it on the stack.  */
176     p.t = __alloca (size);
177   else
178     {
...
212       /* If the memory requirements are too high don't allocate memory.  */
213       if (size / pagesize &gt; (size_t) phys_pages)
214         {
215           _quicksort (b, n, s, cmp, arg);
216           return;
217         }
218 
219       /* It's somewhat large, so malloc it.  */
220       int save = errno;
221       tmp = malloc (size);
222       __set_errno (save);
223       if (tmp == NULL)
224         {
225           /* Couldn't get space, so use the slower algorithm
226              that doesn't need a temporary array.  */
227           _quicksort (b, n, s, cmp, arg);
228           return;
229         }
230       p.t = tmp;
231     }
...
299 }
------------------------------------------------------------------------

We therefore decided to assess the robustness of the glibc's quick sort
(instead of its merge sort, which was clearly not crashing), by forcing
qsort() to call _quicksort(). Locally, forcing the malloc() at line 221
to fail is very easy: we simply execute our program with a low RLIMIT_AS
("The maximum size of the process's virtual memory", man setrlimit); and
this works even when executing a SUID-root program. So we executed our
program in the following loop instead:

------------------------------------------------------------------------
$ while true; do n=$((RANDOM*64+RANDOM+1)); prlimit --as=$((n*4/2*3)) ./qsort $n; done
Aborted (core dumped)
Aborted (core dumped)
Aborted (core dumped)
...
------------------------------------------------------------------------

Incredibly, we almost immediately observed crashes of our test program:
calls to abort(), because one of our canary elements (below or above the
sorted array) was overwritten (i.e., an out-of-bounds write in qsort()).
To understand these crashes, we examined one of them in gdb:

------------------------------------------------------------------------
$ gdb prlimit
(gdb) run --as=8104854 ./qsort 1350809
Starting program: /usr/bin/prlimit --as=8104854 ./qsort 1350809
...
Program received signal SIGABRT, Aborted.
__pthread_kill_implementation (threadid=&lt;optimized out&gt;, signo=signo@...ry=6, no_tid=no_tid@...ry=0) at pthread_kill.c:44
44            return INTERNAL_SYSCALL_ERROR_P (ret) ? INTERNAL_SYSCALL_ERRNO (ret) : 0;

(gdb) backtrace
#0  __pthread_kill_implementation (threadid=&lt;optimized out&gt;, signo=signo@...ry=6, no_tid=no_tid@...ry=0) at pthread_kill.c:44
#1  0x00007ffff7e698a3 in __pthread_kill_internal (signo=6, threadid=&lt;optimized out&gt;) at pthread_kill.c:78
#2  0x00007ffff7e178ee in __GI_raise (sig=sig@...ry=6) at ../sysdeps/posix/raise.c:26
#3  0x00007ffff7dff8ff in __GI_abort () at abort.c:79
#4  0x0000555555555334 in main (argc=2, argv=0x7fffffffe338) at qsort.c:34

(gdb) select-frame 4
(gdb) p/x canary1
$1 = 0xc6109e4c
(gdb) p/x *pcanary1
$2 = 0x0

(gdb) x/xw pcanary1 - 2
0x7ffff78af008: 0x00528002
0x7ffff78af00c: 0x80000000
0x7ffff78af010: 0x00000000
0x7ffff78af014: 0xc6109e4c
0x7ffff78af018: 0x00000000
------------------------------------------------------------------------

- at address 0x7ffff78af010 (pcanary1), the original value of the canary
  (0xc6109e4c) was overwritten with 0x0 -- an out-of-bounds write;

- at address 0x7ffff78af00c (below pcanary1), the most significant word
  of an mchunk_size (heap metadata) was overwritten with 0x80000000
  (INT_MIN) -- another out-of-bounds write;

- at address 0x7ffff78af014 (above pcanary1), the first element of the
  array was overwritten with 0xc6109e4c (the original value of the
  canary), which was therefore read out-of-bounds beforehand (from
  pcanary1).


========================================================================
Analysis
========================================================================

To identify the root cause of these out-of-bounds memory accesses, we
must analyze the implementation of the glibc's quick sort:

------------------------------------------------------------------------
 87 void
 88 _quicksort (void *const pbase, size_t total_elems, size_t size,
 89             __compar_d_fn_t cmp, void *arg)
 90 {
 91   char *base_ptr = (char *) pbase;
...
108       while (STACK_NOT_EMPTY)
109         {
...
193         }
...
206     char *tmp_ptr = base_ptr;
...
214     for (run_ptr = tmp_ptr + size; run_ptr &lt;= thresh; run_ptr += size)
215       if ((*cmp) ((void *) run_ptr, (void *) tmp_ptr, arg) &lt; 0)
216         tmp_ptr = run_ptr;
217 
218     if (tmp_ptr != base_ptr)
219       SWAP (tmp_ptr, base_ptr, size);
...
223     run_ptr = base_ptr + size;
224     while ((run_ptr += size) &lt;= end_ptr)
225       {
226         tmp_ptr = run_ptr - size;
227         while ((*cmp) ((void *) run_ptr, (void *) tmp_ptr, arg) &lt; 0)
228           tmp_ptr -= size;
...
246       }
...
248 }
------------------------------------------------------------------------

- at lines 108-193, when quick sort's partitions become smaller than
  MAX_THRESH (4 elements), _quicksort() switches to a final insertion
  sort (at lines 206-246), which is faster than quick sort for small or
  mostly sorted arrays;

- at lines 206-219, this insertion sort makes sure that the very first
  element of the array (base_ptr) is the smallest element of the array;

- at lines 226-228, this first element acts as a natural barrier that
  prevents tmp_ptr from being decremented below the array (because if
  tmp_ptr reaches base_ptr, then necessarily cmp(run_ptr, tmp_ptr) &gt;= 0
  because tmp_ptr is base_ptr, the smallest element of the array);

- unfortunately this does not hold true if cmp() is nontransitive, in
  which case cmp(run_ptr, tmp_ptr) can be &lt; 0 even if tmp_ptr is
  base_ptr, so tmp_ptr can be decremented below the array, where
  out-of-bounds elements are read and overwritten.


========================================================================
Patch
========================================================================

To patch these out-of-bounds memory accesses in _quicksort(), a simple
check "tmp_ptr &gt; base_ptr &amp;&amp;" can be added in front of the cmp() call at
line 227 (of course this does not magically result in a correctly sorted
array if cmp() is nontransitive, but at least it does not result in a
memory corruption anymore).

In fact, while drafting this advisory, we discovered that such a check
("tmp_ptr != base_ptr &amp;&amp;") has already been added to the glibc's master
branch (which will become glibc 2.39 in February 2024), by the following
commit ("stdlib: Fix array bounds protection in insertion sort phase of
qsort"):

  <a href="https://sourceware.org/git?p=glibc.git;a=commit;h=b9390ba93676c4b1e87e218af5e7e4bb596312ac" rel="nofollow">https://sourceware.org/git?p=glibc.git;a=commit;h=b9390ba93676c4b1e87e218af5e7e4bb596312ac</a>

Indeed, the glibc developers have recently refactored qsort() and
replaced the merge sort (and its fallback to quick sort) with an
introspective sort (a combination of quick sort, heap sort, and
insertion sort):

  <a href="https://en.wikipedia.org/wiki/Introsort" rel="nofollow">https://en.wikipedia.org/wiki/Introsort</a>
  <a href="https://sourceware.org/pipermail/libc-alpha/2023-October/151907.html" rel="nofollow">https://sourceware.org/pipermail/libc-alpha/2023-October/151907.html</a>

During this refactoring, the glibc developers have proactively
discovered (and patched) the out-of-bounds memory accesses in the
insertion sort (probably because these out-of-bounds memory accesses
became directly exposed to the misbehavior of nontransitive comparison
functions, instead of being safely hidden behind a malloc() failure in
the merge sort).

Last-minute note: in January 2024, the glibc developers have reverted
this refactoring of qsort(), back to the original merge sort, plus a
fallback to heap sort instead of quick sort; for more information:

  <a href="https://sourceware.org/pipermail/libc-alpha/2024-January/154051.html" rel="nofollow">https://sourceware.org/pipermail/libc-alpha/2024-January/154051.html</a>


========================================================================
Discussion
========================================================================

We have not tried to find a vulnerable program (i.e., a program that
uses a nontransitive comparison function to qsort() attacker-controlled
elements); however, vulnerable programs are certain to exist in the real
world:

- calls to qsort() are extremely common;

- nontransitive comparison functions are also common;

- all glibc versions from at least September 1992 (glibc 1.04, the first
  version that we could find online) to the current release (glibc 2.38)
  are affected by this memory corruption.

Locally, forcing a malloc() failure in qsort() (which is necessary to
reach the memory corruption) is easy: either execute the target program
(e.g., a SUID-root program) with a low RLIMIT_AS, or allocate a large
amount of memory with another program on the same machine.

Remotely, forcing this malloc() failure is harder: either allocate a
large amount of memory (e.g., a memory leak) in the network service that
is being targeted, or in another network service on the same machine.


========================================================================
Acknowledgments
========================================================================

We thank the glibc security team and the linux-distros@...nwall.


========================================================================
Timeline
========================================================================

2023-12-12: We sent a draft of our advisory to the glibc security team.
They immediately acknowledged receipt of our email.

2023-12-19: The glibc security team decided to not treat this memory
corruption in qsort() as a vulnerability in the glibc itself, as
explained in the "Summary" of our advisory.

2024-01-16: We backported commit b9390ba to all current and past stable
versions of the glibc, and sent this patch and a draft of our advisory
to the linux-distros@...nwall (to piggyback on the glibc embargo for
CVE-2023-6246). They immediately acknowledged receipt of our email.

2024-01-30: Coordinated Release Date (18:00 UTC).
</pre>
<p><a href="http://www.openwall.com/blists/">Powered by blists</a> - <a href="http://lists.openwall.net/">more mailing lists</a>


</p><p>
Please check out the
<a href="https://oss-security.openwall.org/wiki/">
Open Source Software Security Wiki</a>, which is counterpart to this
<a href="https://oss-security.openwall.org/wiki/mailing-lists/oss-security">mailing list</a>.
</p><p>
Confused about <a href="https://www.openwall.com/lists/">mailing lists</a> and their use?
<a href="https://en.wikipedia.org/wiki/Electronic_mailing_list">Read about mailing lists on Wikipedia</a>
and check out these
<a href="https://www.complang.tuwien.ac.at/anton/mail-news-errors.html">guidelines on proper formatting of your messages</a>.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WA House bill would make it illegal for police to lie during interrogations (282 pts)]]></title>
            <link>https://www.seattletimes.com/seattle-news/politics/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations/</link>
            <guid>39264383</guid>
            <pubDate>Mon, 05 Feb 2024 18:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/seattle-news/politics/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations/">https://www.seattletimes.com/seattle-news/politics/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations/</a>, See on <a href="https://news.ycombinator.com/item?id=39264383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>OLYMPIA ‚Äî&nbsp;Victims of false confessions that lead to wrongful convictions, like Ted Bradford, want to prohibit police from using deceptive tactics during interrogations, and they have the backing of some lawmakers.</p><p>‚ÄúIt was the worst experience of my life,‚Äù said Bradford, <a href="https://www.seattletimes.com/seattle-news/law-justice/will-new-dna-evidence-vindicate-yakima-man-cleared-in-1995-rape/">Washington‚Äôs first DNA exoneree</a>, when recalling his 1996 interrogation when he was accused of sexual assault. ‚ÄúI knew I was innocent ‚Ä¶ no matter how many times I told them over and over, I didn‚Äôt do this.‚Äù</p><p><a href="https://app.leg.wa.gov/billsummary?BillNumber=1062&amp;Initiative=false&amp;Year=2023" target="_blank">House Bill 1062</a>, sponsored by Rep. Strom Peterson, D-Edmonds, aims to make defendants‚Äô statements inadmissible in court if police use deceptive tactics during interrogations to get those statements. Nine states have passed similar laws, but they only apply to juveniles. The bill has received two hearings in the House this legislative session.</p><p>Advocates say this legislation, aside from keeping innocent people out of prison, is also about building trust between the public and law enforcement. Some in law enforcement argue that deception is not coercion and taking away this tactic decreases their effectiveness in convicting people and solving cases. </p><p>‚ÄúI think there‚Äôs this space in the middle that often gets looked over, post-arrest, pre-conviction,‚Äù Peterson said. ‚ÄúThere are a lot of things that happen there that I don‚Äôt think we‚Äôve paid enough attention to.‚Äù</p><p>The majority of interrogations happen in the back of a patrol car or on the side of the road, according to Derick Sanders, Thurston County sheriff. He argues police tactics are always under the microscope.</p>
<p>James McMahan, policy director of the Washington Association of Sheriffs and Police Chiefs, argued in public testimony on Jan 8 that deception is required to get to the truth. An example, he said, would be not telling a suspect in cases involving the exploitation of children the true age and identity of an undercover trooper who was posing as a minor. </p><p>‚ÄúSometimes, it‚Äôs an unfortunate reality, we have to lie to people to get them to tell the truth,‚Äù McMahan said. ‚ÄúIf we could somehow get people to actually be required to tell the truth, we wouldn‚Äôt have to lie. That‚Äôs just an unfortunate reality of law enforcement.‚Äù</p><p>However, current police interrogations encourage bias and leave people vulnerable to the power imbalances between law enforcement and citizens, said Dave Thompson, president of Wicklander-Zulawski &amp; Associates, a firm that provides interrogation training to law enforcement.</p><h3>How a false confession is generated </h3><p>In 1996, Bradford, 22 at the time, was asked to come to the Yakima Police Department to help with a case. He said he was asked to waive his rights and when he asked police whether he needed an attorney they said no because they were only asking a few questions. He signed the waiver thinking he was going to help, but a few questions turned into a nearly nine-hour interrogation, with no food and a small cup of water, he said.</p><p>Identifying the wrong person begins with faulty evidence, and often police make people fit the evidence rather than the other way around, says James Trainum, a former detective with the Washington, D.C., Police Department who now does law enforcement consulting. </p><p>‚ÄúRather than develop your case, develop your suspect, develop your evidence, you‚Äôre taught that you can use this to bypass all of that, and just quickly identify a suspect, and then move on,‚Äù Trainum said.</p>
<p>In Washington state, 23% of exonerations involve false confessions, according to data from the Washington Innocence Project. However, this number could be higher because<strong> </strong>there‚Äôs not enough data to know the actual number of wrongful convictions in the state according to Lara Zarowsky, executive director of the Washington Innocence Project.</p><p>In the 1969 case Frazier v. Cupp, the U.S. Supreme Court ruled in favor of police using deception tactics during interrogations. The Reid technique, the most common technique used by police, includes using guilt-presumptive questions during interrogations. By lying to people about false evidence, Trainum says police hope to persuade a confession.</p><p>‚ÄúJust because the courts find it permissible doesn‚Äôt mean that they‚Äôre not problematic,‚Äù said Trainum, who said he garnered a false confession in a 1994 high-profile kidnapping and murder case using the Reid technique.</p><p>Bradford‚Äôs battle to prove his innocence to police left him feeling threatened and intimidated after aggressive questioning and accusations. At the end of the day, he couldn‚Äôt handle it anymore and signed a confession. </p><p>Interrogations can differ depending on the situation, according to Sanders, the Thurston County sheriff.</p><p>‚ÄúThe type of crime, the temperament of the officer, the temperament of the suspect, those are all things that play a pretty big factor into how people are interrogated,‚Äù he said.</p>
<p>Sanders says not every case requires a ruse, but when they do, they‚Äôre used when police need people to think they know more than they do to close an investigation.</p><p>According to Sanders, there are already procedures in place that can dispute false confessions in what are called criminal rule 3.5 hearings, where defendants can have evidence dismissed if they assert police lied inappropriately or violated case law. He believes fewer wrongful convictions will exist as technology improves. </p><p>However, because of Frazier v. Cupp, decisions from criminal rule 3.5 hearings make their way to court anyway, said John Marlow, litigation director of the Washington Innocence Project. The court decides whether the confession is allowed as evidence and the jury ultimately decides whether it‚Äôs believable, Marlow said.</p>      <p>‚ÄúThe criminal legal system in practice does not operate in the way that we think it does when you just read the rules on paper,‚Äù Zarowsky said. </p><h3>Why confess to a crime you didn‚Äôt commit?</h3><p>In 2007, Amanda Knox was a 20-year-old college student at the University of Washington. She garnered worldwide attention after being wrongfully convicted of murdering her roommate Meredith Kercher in Italy during a study abroad trip. During her interrogation, Knox, who testified in support of <a href="https://app.leg.wa.gov/billsummary?BillNumber=1062&amp;Initiative=false&amp;Year=2023" target="_blank">HB 1062</a>, recalls police making her feel like she was going insane.</p><p>‚ÄúThe extent to which I was unprepared for people who I trusted to lie to me was what led me as an innocent person to be particularly vulnerable and which is what led to my eventual wrongful conviction,‚Äù Knox said in an interview.  </p>
<p>The more successful a strategy is in eliciting confessions from guilty suspects, the more likely it is that this strategy will also produce false confessions from innocent suspects, according to a 2004 <a href="https://www.sciencedirect.com/topics/psychology/reid-technique#:~:text=Research%20has%20revealed%20that%20confronting,in%20several%20Western%20European%20countries." target="_blank">research paper</a> published by the Encyclopedia of Applied Psychology.</p><p>Juveniles and people with intellectual disabilities are more susceptible to deception, the research showed. But under the right circumstances, this can happen to anyone, Zarowsky said.</p><p>Bradford recalls police making threats and lying to him about DNA evidence they said proved he committed the crime. After hours of interrogation, he confessed, hoping the evidence would acquit him.</p><p>‚ÄúI started thinking to myself, the only way out of this is if I just give them a statement,‚Äù Bradford said. ‚ÄúThen they can test their evidence and they‚Äôll find out that I‚Äôm innocent. I‚Äôll be done. I‚Äôll be free of all of this.‚Äù</p><p>Experts call this a coerced-complaint confession.</p><p>For Knox, during her 53-hour interrogation in Italy, she rarely had a translator and became tired and confused. Police accused her of having amnesia and she recalls an officer hitting her in the head and telling her to remember. By attempting to make sense of the situation, she ended up creating a false memory and signed what‚Äôs called a coerced-internalized confession. </p><p>‚ÄúI was put in a position where I was made to feel insane because the police lied to me,‚Äù Knox said. ‚ÄúThey told me that I had amnesia and that I didn‚Äôt remember what the truth was.‚Äù</p>
<h3>What alternatives exist?</h3><p>Prosecutors sometimes are reluctant to believe someone‚Äôs innocence even after DNA acquits someone, Saul Kassin, a professor of psychology at The City University of New York, wrote in his 2005 research paper, ‚ÄúOn the Psychology of Confessions: Does Innocence Put Innocents at Risk?‚Äù</p><p>In Bradford‚Äôs case, he was charged again for the same crime, after serving his 10-year sentence, when he challenged his conviction with new DNA evidence.<strong> </strong>In Knox‚Äôs case, she<strong> </strong>went through the appeals process twice in Italy, but was ultimately not convicted. </p><p>For jurors, a confession is one of the most compelling pieces of evidence regardless of how unreliable it is, according to Matt Jones, president of Evocavi, a firm that trains law enforcement in interrogation techniques.</p><p>Advocates of HB 1062 say accountability measures like these raise law enforcement‚Äôs professionalism.</p><p>‚ÄúI have absolutely not gone to the police for help as a result of my experience, because I didn‚Äôt feel like I could trust them and I don‚Äôt want to live in a world like that,‚Äù Knox said.</p><p>Peterson‚Äôs bill, which would also provide law enforcement with interrogation training, is currently in the House Appropriations Committee.</p><p>‚ÄúA bill like this would just focus more on not just getting a conviction, but getting the right conviction,‚Äù Bradford said. ‚ÄúFor every person that‚Äôs wrongly convicted, the real perpetrators out there, possibly committing more crimes.‚Äù</p>    
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: Atopile ‚Äì Design circuit boards with code (540 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39263854</link>
            <guid>39263854</guid>
            <pubDate>Mon, 05 Feb 2024 17:30:50 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39263854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39266077"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266077" href="https://news.ycombinator.com/vote?id=39266077&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I think this is a wonderful idea and begins to create a foundation of data richness and interoperability for a very exciting new approach to PCB design, as I commented elsewhere in this thread<p>However I do want to mention that I think it might be necessary to be able to "cross-compile" to visual schematic format, and back. Or perhaps there is an open schematic tool that can be extended?</p><p>The issue is that I think electrical schematics are significantly more familiar to EE types, contain more legible information. Instead of reinventing the wheel there, it'd be nice to see a system that can switch back and forth between text and visual schematic.</p><p>How are schematics described as files currently? Is there an open standard? Can it be converted to atopile format, and back?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266216"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266216" href="https://news.ycombinator.com/vote?id=39266216&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Yeah that‚Äôs an interesting aspect. We did implement a viewer very early on. And we then removed it from the project.<p>What we discovered is that:</p><p>- making a visual viewer is a non trivial endeavor. It takes a lot of time but the value add is marginal for an average viewer. 
- people tend to spend a lot of time making the viewer look good instead of improving the circuit</p><p>We think that in the long run, a viewer could be awesome to inspect what is going on or get a general understanding of the circuit. But it‚Äôll be difficult to justify the time spent on it early on in the project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265675"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265675" href="https://news.ycombinator.com/vote?id=39265675&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>One thing that surprised me when moving from mechanical CAD to EDA programs is the lack of "relations." I have not used the more professional tools, just KiCad, but it surprised me that there are not more variables, relations, constraints, subassemblies, for things like buck converters and these types of things. KiCad has 'netclasses' which let you set trace widths, but it's all manual, same with the design rules checker. Each vendor seems to have their own design manual for these things, which is nice to have but so tedious -- I have to read a PDF to know what size decoupling cap goes with this IC? Why is that information not encoded in the footprint somehow?<p>I understand that auto-routing is not a solved problem by any means, but there should be more efficient tools to make it easier. I shudder to imagine laying out some big LED matrix without more advanced tooling.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265769"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265769" href="https://news.ycombinator.com/vote?id=39265769&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>For sure, its a big benefit of using language, it is comparatively very fast and easy to define custom relationships of component values, trace widths etc that would quickly become untenable in a point and click tool. We think the path forward is to be able to encode the governing equations that you would get in say a buck controllers data sheet directly into our source code. That way from a user perspective you can define your circuit simply by importing modules, defining them (for example input voltage, output voltage and current) we can then solve the component values and pick them from our component database for you. One of our early users wrote a plugin to do LED arrays in an afternoon. Our compiler is all open so its pretty easy to add on custom scripts for whatever you might be wanting to do.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265821"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265821" href="https://news.ycombinator.com/vote?id=39265821&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>look at OpenSCAD, it's a scripting language to generate models. I used this a lot to generate subpieces and build off of that. easy as saying Bolt("M5", 1.5) or something</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266046"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266046" href="https://news.ycombinator.com/vote?id=39266046&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Ya OpenSCAD is great for in/cross project re-usable components.<p>The only issues I've had is how it outputs circular things for cutting - it does a series of polygons (configurable number), rather than an arc/circular - places like send-cut-send won't accept it, claiming it causes issues with their machines.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266070"><td></td></tr>
                        <tr id="39265162"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265162" href="https://news.ycombinator.com/vote?id=39265162&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Yes yes yes! I love it when people make the things I think would be a good idea, and then stay on the hobby project idea list for years to come. (I'm struggling to make that not sound sarcastic - maybe it's just my British reading! - but I really am sincere.)<p>When I was thinking about it, a couple of further directions I had in mind were 1) ecosystem/library/sharing of modules, so something like the voltage divider example is not something you'd need to do (even once) for every project; if it really took off the pipedream would be that application notes examples were just provided as modules, so you could take whatever IC wnd just import the module if you were using it in a standard way; 2) if you did a similar thing for layout constraints, you could then have that as part of the same module, and when you compile the whole thing (in hand-wavey generalised theory if sufficiently constrained) you could generate the overall layout for a project with say a SMPS and also sensitive analogue circuitry in a way that makes sense without either of those modules having to know that the other is in use, just because they have rules like distance from transistor, bypass cap to IC could be fully constrained, so you always get exactly the same sensible-looking layout, etc.</p><p>Anyway, looks great, I look forward to trying it properly some time!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265342"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265342" href="https://news.ycombinator.com/vote?id=39265342&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Absolutely love to hear that!<p>100% agreed about the ecosystem too. We've already created a perhaps-too-scrappy package manager, but it works! <a href="https://packages.atopile.io/" rel="nofollow">https://packages.atopile.io/</a>
We're pretty convinced that the awesomeness of the software ecosystem is a function of its openness and open-source and atopile largely came from working out how we could seed a similar shift in the hardware world. I can't wait for the day I can `ato install` SMPS, filters, radios and servo-drives with the confidence they'll just work!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265327"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265327" href="https://news.ycombinator.com/vote?id=39265327&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Specifically on the layout section, I have been thinking along the lines of start with sensible 'seed' layouts that users will contribute, then mutate the layouts with a physics driven solver. Imagine links between components as a spring and repulsion forces to model creepage/clearance distances, you could imagine the layout warping into a suitable shape for your board. I am pretty excited to get to this bit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39265900"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39265900" href="https://news.ycombinator.com/vote?id=39265900&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>As someone who just taught themself Kicad to make a simple MIDI controller PCB usi an STM32F4, I was totally blown away, coming from software, how "manual" everything was, how abstruse and arcane.<p>It's quite difficult as a beginner to know that a design is "correct", or perhaps "correct enough", with respect to component placement and EMI.</p><p>It seems like even top EE who specialize in board design utilize rules of thumb rather than rely on simulation.</p><p>I was also blown away that the state of the art autorouter for traces seems to be from the early 2000's -- no recent AI magic going on here.</p><p>Where is my "autoplacer"? It seems like an AI trained on millions of schematic/pcb combos, even just gerber files via image ingestion, ought to be able to generate a pretty decent layout + routing given constraints.</p><p>Or perhaps I'm spoiled coming from software and web because it's so much further removed from physics. But it's still the case that there are a ton of modular components with "API's" that should have a templating language, so very much bravo to this project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266111"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39266111" href="https://news.ycombinator.com/vote?id=39266111&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Thanks for the support!<p>For the autolayout part, one thing we realized is that it‚Äôs very hard for a computer to do a good job at it when there is a lot of implicit requirements that are not baked into the schematics. We are hoping that by capturing those through code, auto layout can be improved.</p><p>On the design check, we aren‚Äôt doing a lot there for the moment but the comment above also applies: if you have clear requirements in the code, it becomes easier to test if the solution fits those requirement.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39264391"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264391" href="https://news.ycombinator.com/vote?id=39264391&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Very nice!<p>The state of electronics tooling has long been extremely bad - 99% of people who put a regulator into their schematic will want an appropriate input and output capacitor as the datasheet demands. 99% of people who put a microcontroller will want a crystal and a programming port and a reset pin pull-up. It's only because of closed source tools stuck in the stone age that the state of the art is to <i>copy out of a PDF</i>.</p><p>And multiple people working on the same design and merging their changes? Forget about it!</p><p>It'll be very exciting if we can move towards a more modular world, where designs can be composed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39264484"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264484" href="https://news.ycombinator.com/vote?id=39264484&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>For sure, we definitely subscribe to works out of the box / path most taken. We have been working on adding equations to our language so we can solve component values based on requirements like output current and ripple for a regulator to get cap values for example. I hope in the future our component models will capture a good fraction of the info you have to go to the datasheet for today.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265964"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265964" href="https://news.ycombinator.com/vote?id=39265964&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>This is a great start, well done!<p>Eventually it would be amazing to import (for example) a buck converter circuit with a wide voltage input, fixed output suitable for RF, and have it automatically check available components at JLCPCB and then lay it all out with, adhering to best practices (ground planes &amp; capacitors right next to pins etc.) If the available components change, it can tweak the footprints and layout without having to start from scratch.</p><p>Good luck, I‚Äôll be following closely!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266027"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266027" href="https://news.ycombinator.com/vote?id=39266027&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>For sure the goal! Our current component tool will find components that are available on JLC, in stock and to your spec, no more looking for resistor part numbers. The layout side is going to be exciting, we are just scratching the surface there.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265916"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265916" href="https://news.ycombinator.com/vote?id=39265916&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>LOVE IT LOVE IT LOVE IT!!!<p>I'm doing a lot of home automation work, and I absolutely hate that I need to use breadboards, hunt for pre-assembled components, or to spend days designing a PCB for simple things like relay modules with customized IO.</p><p>E.g. I have ratgdo for my garage door opener, but its power supply is an ugly buck convertor taped to the box. I'd love to just re-make the ratgdo board, but with a built-in 12V-to-3V buck convertor.</p><p>I tried that, but PCB manufacturing with custom component placing requires just too much work.</p><p>Is there a way to donate to the project? I'd love to support it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266033"><td></td></tr>
                  <tr id="39265856"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265856" href="https://news.ycombinator.com/vote?id=39265856&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I'm curious if you have component checking - does the circuit overload the regulator? am I going to overvolt this capacitor? what is this LED's lifetime? - or if that's somewhere on the roadmap?<p>I'm also curious if you're able to use an autorouter to minimize board layers. Seems like it should be pretty straightforward to apply some graph theory to this and state the minimal number of layers for a given board, but this also might be NP-hard? I haven't kept up with the theory here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265939"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265939" href="https://news.ycombinator.com/vote?id=39265939&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>We have some basic component parameters that we can define, like value, dielectric and voltage rating for capacitors. I think these become much more powerful once we add in equations to help relate these values and link them together. For example if I configure my powersupply for a 12V input, the tool should know that the capacitors need 12V * some safety factor of rating.<p>I think I see the entry point for auto routing to be taking advantage of the fact that layers have become pretty cheap (atleast for prototyping) and engineering time is the expensive bit. If the tool can help me layout a board in half the time, particularly for test hardware or the likes, that would be huge. Eventually I think we will get to a place where computers will do a better job of layout than most people, but thats a ways off.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39264222"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264222" href="https://news.ycombinator.com/vote?id=39264222&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Looks really useful! As a hardware designer I've had plenty of copy pasting bits of schematics to duplicate common functionality. Seems like this could be really helpful in preventing mistakes and increasing quality once used to it.<p>Have you got any plans for defined interfaces/modularity so devices using SPI, I¬≤C, etc. can be chained together without manually defining pin connections? Also, will there be support for importing schematics from other formats?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39264332"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264332" href="https://news.ycombinator.com/vote?id=39264332&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>We do have interfaces! They are super useful, I am very stoked that I dont have to remember which way around MISO/MOSI go any more.<p>Interfaces are just a collection of signals eg</p><pre><code>  interface I2C:
    signal sda
    signal scl
    signal gnd
</code></pre>
you can connect two together like so:
micro.i2c ~ sensor.i2c<p>Importing schematics would be possible, but IMO not super valuable as all we could import would be the raw connectivity, a big benefit of our language is being able to add a layer of abstraction on that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264808"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264808" href="https://news.ycombinator.com/vote?id=39264808&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Kicad allows you to keep a library of projects containing layouts and schematics of small circuits that you may wish to reuse in other circuits by just simply importing them to the current design. You can then modify as needed.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264881"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39264881" href="https://news.ycombinator.com/vote?id=39264881&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Indeed, Altium has similar features also. I think what has been missing is an effective way to collaborate on hardware projects as a community and be able to share them like you would packages on pypi or npm.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39266219"><td></td></tr>
            <tr id="39265907"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265907" href="https://news.ycombinator.com/vote?id=39265907&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>This has sooo much promise, I can't describe how excited I am and will definitely be contributing if I can.<p>This would make it easy to implement a fancy optimizer. Each component tends to have certain acceptable thresholds for their dependencies like input voltages, current limits, external resistor/capacitor/inductor values/ratings, etc.</p><p>Then, each component could have different implementations. You can have different manufacturers produce the exact same inductor/capacitor/resistor in different packages. You can link it up to your existing BOM or hook into vendor APIs to get pricing.</p><p>Imagine optimizing for cost, removing redundancy, simplifying footprints, and prioritizing in-stock inventory over new order components.</p><p>This could be a huge deal, looking forward to its progress
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266114"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266114" href="https://news.ycombinator.com/vote?id=39266114&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>We have been working on an optimizer for solving components that we will put a post out about soon. But the gist is figuring out which constraints are expensive, for example a precision inductor might be quite expensive, but a precision resistor is comparatively cheap. We can look at where to shift precision in your components to get the desired output for the lowest total cost. We already do a few things like prioritize in stock parts with high availability. I am excited to add more constraints, like board area, multi-sourcing etc.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265791"><td></td></tr>
                <tr id="39265929"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265929" href="https://news.ycombinator.com/vote?id=39265929&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Hey,<p>We did use skidl for a little while as we were figuring things out (see a project here: <a href="https://gitlab.atopile.io/pew-pew-and-friends/sizzle-sack" rel="nofollow">https://gitlab.atopile.io/pew-pew-and-friends/sizzle-sack</a>). But we later ended up moving away from it towards ato for mainly two reasons:</p><p>- Baking a description of a circuit into python describes how to obtain the circuit, but doesn't really describe what the circuit is. Skidl projects quickly become hard to read. The user is also not guided towards writing code that compiles since you need to deal with all the complexity of Python as well as the circuit itself.
- Contributing to the project and adding features was non trivial
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265445"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265445" href="https://news.ycombinator.com/vote?id=39265445&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I think you should do one thing really well, before expanding.<p>Import from public GitHub libraries could be fun.</p><p>Differential pairs.</p><p>Impedance controlled traces.</p><p>Going further, if I have one supplier's stack up with controlled impedance lines, and I need to switch to a different supplier's stack up, what netclasses would change?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265534" href="https://news.ycombinator.com/vote?id=39265534&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I do agree. The package registry (<a href="https://packages.atopile.io/" rel="nofollow">https://packages.atopile.io</a>) is an attempt at importing from existing GitHub/GitLab ato projects. This will need quite a bit more polish until it gets to the level Rust's crates.io or python's pypi.org<p>On the language side there are additional features we would like to work on like traits and types (types would include diff pairs and impedance).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265084"><td></td></tr>
                <tr id="39265671"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265671" href="https://news.ycombinator.com/vote?id=39265671&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Our language is also a markup language more than a programing language. The goal here is that we would want the code to become a description of what the circuit is, instead of how to obtain it. The obtaining part is the job of the compiler. Not the human.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265203"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265203" href="https://news.ycombinator.com/vote?id=39265203&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>We are taking the open-source route (eventually moving to open-core). We think a big part of moving the industry in this direction is building a community around it, much like the way Github started out.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265161"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265161" href="https://news.ycombinator.com/vote?id=39265161&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Hi Tim,<p>I'm just starting with electronics, following the Make Electronics book with my kid. And this seems super useful to understand circuits better (at least for people who code), do you have the plan to make a series of lessons for beginners with the app? Like going from the simple battery-led to complex things?
Feel free to email.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265319"><td></td></tr>
                  <tr id="39265077"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265077" href="https://news.ycombinator.com/vote?id=39265077&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Part of the magic here would be to get your team's hardware engineers to adopt a more software development style workflow.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39265132"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265132" href="https://news.ycombinator.com/vote?id=39265132&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Indeed, the ability to branch and merge is a pretty exciting concept for me as a hardware designer. Another simple one is building artifacts in CI and doing quality checks, I have make some silly manual errors that have been very expensive during export.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265876"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265876" href="https://news.ycombinator.com/vote?id=39265876&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Very neat, nice work.<p>I tooled around with a similar idea sometime back. There are clear advantages of code over graphical-schematics when it comes to automatic generation of component values / re-use of elements / speed of development / automatic SPICE testing / etc.</p><p>The primary issue I ran into was that: electronic circuits are inherently graph-structured  and the traditional circuit schematic is well suited, optimal even, for displaying this kind of information. Trying to understand an analog circuit that is described as code seems awkward.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265768"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265768" href="https://news.ycombinator.com/vote?id=39265768&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I think a compiler for PCBs is a great idea!<p>Are you fully open source today? How has the community aspect been going?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265814"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265814" href="https://news.ycombinator.com/vote?id=39265814&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>I bet you do ;) We are fully opensource today, but we will eventually have some features we sell to enterprise. We have a small community of mostly friends at the moment, we are hoping to grow that very soon now that we have something we believe is worth sharing!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39265873"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39265873" href="https://news.ycombinator.com/vote?id=39265873&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>I've been doing a lot of selling to enterprise recently - mostly US based. Let me know if I can be of support!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266253"><td></td></tr>
                              <tr id="39265976"><td></td></tr>
            <tr id="39266120"><td></td></tr>
                <tr id="39266217"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266217" href="https://news.ycombinator.com/vote?id=39266217&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Pretty similar in concept, a few important nuances that come with building boards in the real world. For example dealing with tolerances. The language is definitely an important part of this, but we think alot of the surrounding infrastructure like package managers, CI pipelines and SPICE integration will be critical also.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265744"><td></td></tr>
                <tr id="39265862"><td></td></tr>
            <tr id="39265882"><td></td></tr>
                <tr id="39266143"><td></td></tr>
                        <tr id="39264345"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264345" href="https://news.ycombinator.com/vote?id=39264345&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Congratulations on the launch and good luck building a business around it! I remember running into you folks at OpenSauce last year and thinking just how useful it could be.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264418"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264418" href="https://news.ycombinator.com/vote?id=39264418&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Thanks for the support! We will try get a booth at open sauce again this year. Hope to see you there :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39264971"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264971" href="https://news.ycombinator.com/vote?id=39264971&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>First off - best of luck to y'all. The HW EDA space is sorely in need of tooling improvements.  I'm curious as to how your product differs from JITX.  They claim the same sort of thing - code based PCB development.  And they've been around for a few years now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39265131"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265131" href="https://news.ycombinator.com/vote?id=39265131&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Thanks!!<p>The open source aspect was really important to us. We are hoping that ato modules can become a convenient language for the community to share modules with each other, in a similar fashion to python and pypi.</p><p>Having an open code base also makes it more convenient for our users to chain tools together. This is currently hard to achieve with the existing close source standards we are dealing with in hardware.</p><p>ato is also a markup language (like markdown or latex) more than an actual programming language. We think this makes it more readable and helps guide the user writing code that compiles.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39264690"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264690" href="https://news.ycombinator.com/vote?id=39264690&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Why ato over existing hardware description languages or things like SPICE (and it's many derivatives)?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264852"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264852" href="https://news.ycombinator.com/vote?id=39264852&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Great question! Current HDLs tend to primarily be focussed on digital circuit design, while at the PCBA level, there's a lot more focus on the "fuzziness" of the physical world (eg. tolerances).<p>We also noticed that most EEs we've worked with were a bit put off by the syntax and preferred something a bit more terse, but more intuitive and easier to read.</p><p>There perhaps an analog here in software - where we started with assembly (~ SPICE), moved up through things like C and now languages like Python and JavaScript are prolific and accessible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265477"><td></td></tr>
                <tr id="39265604"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265604" href="https://news.ycombinator.com/vote?id=39265604&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Interesting! Haven't come across it before but those linked `~&gt;` operators do indeed quite familiar. If you're familiar with GraphDSL do you have some elements we should look into?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266167"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266167" href="https://news.ycombinator.com/vote?id=39266167&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I've only worked with Akka Graph DSL to build some data pipelines or protocol stacks. And I've loved working with it!<p>The equivalent of atopile signal would be port with Akka I think. A combination of ports gives us a shape. A source shape is just one OUT port. A flow shape is one IN and one OUT port, etc.</p><p>I'm very new to electronics so I don't know if it makes sense, but connecting all these ports with directional arrows was really helpful to understand the data flow.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39264286"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264286" href="https://news.ycombinator.com/vote?id=39264286&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>I love that this is human-readable plain text. Plain text is almost always the best format for anything.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264948"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264948" href="https://news.ycombinator.com/vote?id=39264948&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>Worth noting afaik all kicad file formats were already sexprs, can't get much better than that.<p>In that vein, I'd imagine it would make lot of sense to build a lisp on top of that, macros and sexpr manipulation are very much the strong points of lisps.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264398"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264398" href="https://news.ycombinator.com/vote?id=39264398&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Thank you! We've certainly been heavily inspired by python and Guido's insight that code is read more often than it is written.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39264460"><td></td></tr>
                <tr id="39264659"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39264659" href="https://news.ycombinator.com/vote?id=39264659&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Maybe one day, but I‚Äôve asked the various models basic EE interview questions, and it‚Äôs painfully obvious that while it can make a paragraph that has the right words, it‚Äôs incapable of reasoning spatially, or describing complex connections. My job is secure (for this year).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264825"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39264825" href="https://news.ycombinator.com/vote?id=39264825&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>I have noticed a huge improvement in ChatGPTs coding abilities having an interpreter to check its work. I expect we will be able to bring a similar feedback loop to hardware once we can integrate things like simulation and equations. Also having modules that are tricky to configure incorrectly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39264942"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39264942" href="https://news.ycombinator.com/vote?id=39264942&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>I‚Äôve noticed the opposite with chatgpt.<p>To be fair, idk how much elixir code is in the training set.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39264591"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39264591" href="https://news.ycombinator.com/vote?id=39264591&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Absolutely! With only a few dozen lines of context to pick up the syntax, copilot is already able to make useful contributions like configuring regulators and filters.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39264570"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264570" href="https://news.ycombinator.com/vote?id=39264570&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>The Net-list stage of abstraction is the easy part, but auto-routing is not.<p>People have tried many times to build a universal router with physics awareness for decades. The issue is in the real world there are countless edge cases where the EE must make a decision on the layout.</p><p>For low speed digital design... routers have partially worked since the 90's, but for most other things the edge cases make it counter-productive to automate.</p><p>EEs are good people to have around, and some know how to build things reliably.</p><p>Have a wonderful day, and I really hope the project does well. =)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39264694"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39264694" href="https://news.ycombinator.com/vote?id=39264694&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><p><span>For sure, we are starting with the schematic/requirements side of things and will push in the layout direction soon. We have started with some simple layout snippet reuse that is available today. My experience with autorouters is they do not have a good understanding of the problem, we hope to improve that by being able to capture more information about the circuit, for example physical values like voltage and current are captured today.<p>Our goal generally is to automate tasks that are boring/repetitive like multi-day reviews of big schematics to see if anything accidentally changed. Definitely building a lever for EEs, not a replacement.</p><p>Thanks!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265309"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265309" href="https://news.ycombinator.com/vote?id=39265309&amp;how=up&amp;goto=item%3Fid%3D39263854"></a></center>    </td><td><br><div>
                  <p><span>Agree, I wish them the best of luck ‚Äî I‚Äôm not convinced a computer will ever beat me in the single-sided perf board niche, and I‚Äôm but an amateur, but I‚Äôd be happy if one did.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Interoperability Between Rust and C++ (162 pts)]]></title>
            <link>https://security.googleblog.com/2024/02/improving-interoperability-between-rust-and-c.html</link>
            <guid>39263736</guid>
            <pubDate>Mon, 05 Feb 2024 17:22:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2024/02/improving-interoperability-between-rust-and-c.html">https://security.googleblog.com/2024/02/improving-interoperability-between-rust-and-c.html</a>, See on <a href="https://news.ycombinator.com/item?id=39263736">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What have you built with LLMs? (281 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39263664</link>
            <guid>39263664</guid>
            <pubDate>Mon, 05 Feb 2024 17:16:27 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39263664">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39265118"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265118" href="https://news.ycombinator.com/vote?id=39265118&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I don't like selling. I wanted a way to practice cold calling in a realistic way. I set up a phone number you can call and talk to an AI that simulates sales calls.<p>I ended up using it for more general purpose things because being able to have a hands-free phone call with an AI turned out to be pretty useful.</p><p>It's offline now, but here's the code with all the stack and deployment info: <a href="https://github.com/kevingduck/ChatGPT-phone/">https://github.com/kevingduck/ChatGPT-phone/</a></p><p>Edit: forgot to mention this was all running off a $35 raspberry pi.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39267712"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39267712" href="https://news.ycombinator.com/vote?id=39267712&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I like the idea very much! Using an LLM as a "sparring partner" for training in various areas. LLMs tend to hallucinate, so I find it harder to use them reliably in the context of decision making. Training however is a nice idea indeed: mistakes are not as critical, just as in real life any peer can make a mistake.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39267349"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39267349" href="https://news.ycombinator.com/vote?id=39267349&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Now you can turn this into an AI sales cold caller based on the data you could collect from how the AI reacts to your selling. That is to say, the entire system becomes a generative adversarial network.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39267162"><td></td></tr>
                <tr id="39267315"><td></td></tr>
                  <tr id="39265439"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265439" href="https://news.ycombinator.com/vote?id=39265439&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>So the AI tries to sell to you, or you try to sell to the AI? This sounds very intriguing but I can tell by your README that you're an engineer and not a sales guy - there are no distinct value propositions.<p>But it sounds damn creative as a project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266015"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266015" href="https://news.ycombinator.com/vote?id=39266015&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>The AI answers the call and acts as a potential customer. They take on personas to simulate behaviors like difficult or reluctant customers. You then do your pitch, handle objections, etc. At the end you get a transcript that's 'graded' to show you where you could improve your sales approach.<p>And you're right, I'm not a sales guy. This project is for people like me who want a risk-free place to learn the basics of sales so that when I do talk to an actual human, I won't panic and freeze up like I always do.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266268"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39266268" href="https://news.ycombinator.com/vote?id=39266268&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I absolutely love this idea.<p>Most high-level sales people rely on role play partners but that requires a pretty a big commitment. This would make a great product, imo.</p><p>Also (tip): Study, memorize and internalize a sales script for your product/service...along with the objection handlers and closing questions. Practice every single day. You'll gain massive confidence because you know exactly what you are going to say, every time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39266893"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266893" href="https://news.ycombinator.com/vote?id=39266893&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Are you finding response time to be an issue? I can imagine some very long pauses might kill the flow of conversation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39267159"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39267159" href="https://news.ycombinator.com/vote?id=39267159&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>It's not perfect, but it's tolerable, and not unlike some real-world calls where there's a slight delay. There are some "Hmm ..." and "well ..." scripted in as well to make it feels natural if there is a long response.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39267330"><td></td></tr>
                  <tr id="39266954"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266954" href="https://news.ycombinator.com/vote?id=39266954&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>To that point, I would love to hear an audio file of it in action since I see from GitHub the phone number is down.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39265313"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265313" href="https://news.ycombinator.com/vote?id=39265313&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>That's cool. Thanks for sharing the source. What else has it been good at for you?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266075"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266075" href="https://news.ycombinator.com/vote?id=39266075&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>The cold call sales part can be replaced to suit any need. I had another version that was just a generic AI (no sales stuff). I found myself on walks frequently ringing up the chatbot ("Hey siri, call ChatGPT") and just asking it whatever is on my mind. "Tell me about Ghengis Khan" or "where's a good place to catch trout in north Georgia" or "how do I make baked ziti". Makes the walks go by super quickly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39267755"><td></td></tr>
            <tr id="39267685"><td></td></tr>
            <tr id="39267753"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267753" href="https://news.ycombinator.com/vote?id=39267753&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I've been learning about RAG using LlamaIndex, and wrote a small CLI tool to ingest folders of my documents and run RAG queries through a gauntlet of models (CodeLlama 70b, Phind, Mixtral, Gemini, GPT-4, etc etc) as a batch proccess, then consolidate the responses. It is mostly boilerplate but comparing the available models is fun, and the RAG part kind-of works.<p><a href="https://github.com/StuartRiffle/ragtag-tiger">https://github.com/StuartRiffle/ragtag-tiger</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266122"><td></td></tr>
            <tr id="39267611"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267611" href="https://news.ycombinator.com/vote?id=39267611&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I built out a few utilities as experiments.  One app linked to Salesforce to query/analyze sales data.  Another that reads our help documentation and gives instructions via chat.<p>The last app, the only one that was deployed anywhere, is <a href="https://catchingkillers.com/" rel="nofollow">https://catchingkillers.com</a> This app is a simple murder mystery game where the witnesses and the killer are ChatGPT bots.  The first two stories are complete and active, the third is not complete yet.  The first story of the working two is taken from another murder mystery group game <a href="https://www.whodunitmysteries.com/sour.html" rel="nofollow">https://www.whodunitmysteries.com/sour.html</a>. The second story was highly influenced by ChatGPT.</p><p>It's a bit rough because I didn't spend too much time on it, but if anyone does signup to play, I'd love to hear feedback.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265393"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265393" href="https://news.ycombinator.com/vote?id=39265393&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I built an Interactive Resume AI chatbot where anyone can ask questions about my experience and skills: 
<a href="https://www.jon-olson.com/resume_ai/" rel="nofollow">https://www.jon-olson.com/resume_ai/</a><p>The backend is a Python FastAPI that uses ChromaDB to store my resume and Q&amp;A pairs, OpenAI, and Airtable to log requests and responses. The UI is Sveltekit.</p><p>I'm currently building a different tool and will apply some learnings to my Interactive Resume AI. Instead of Airtable, I am going to use LangSmith for observability.</p><p>I started writing and my Substack articles are also linked to via my website. I'm currently working on applying sentence window retrieval and that article will be out shortly. This is part of a #buildinpublic effort to help build my brand as well.</p><p>I've been unemployed since Sept as a Senior Software Engineer. The market is tough so I'm focusing on the above to help get employment or a contract.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265390"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265390" href="https://news.ycombinator.com/vote?id=39265390&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I've built several things! These include bots for code generation that you can tag onto issues, q&amp;a on text etc.<p>The thing I'm working on now is AI mock interviewing. It's basically scratching my own itch, since I hate leetcode prep, and have found I can learn better through interaction. To paste a blurb from an earlier comment of mine:</p><p>I'm building <a href="https://comp.lol/" rel="nofollow">https://comp.lol</a>. It's AI powered mock coding interviews, FAANG style. Looking for alpha testers when I release, sign up if you wanna try it out or just wanna try some mock coding. If its slow to load, sorry, everything runs on free tiers right now.</p><p>I really dislike doing leetcode prep, and I can't intuitively understand the solutions by just reading them. I've found the best way for me to learn is to seriously try the problem (timed, interview like conditions), and be able to 'discuss' with the interviewer without just jumping to reading the solution. Been using and building this as an experiment to try prepping in a manner I like.</p><p>It's not a replacement for real mock interviews - I think those are still the best, but they're expensive and time consuming. I'm hoping to get 80% of the benefit in an easier package.</p><p>I just put a waitlist in case anyone wants to try it out and give me feedback when I get it out</p><p>Gonna apologize in advance about the copywriting. Was more messing around for my own amusement, will probably change later
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265523"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265523" href="https://news.ycombinator.com/vote?id=39265523&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Very cool, I signed up. I agree that practicing a coding interview is better under pressure. It's a much difference skill to solve a coding problem both under time pressure and pressure to speak your thoughts to entertain the interviewer. Only practice can help improve that skill.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39267697"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39267697" href="https://news.ycombinator.com/vote?id=39267697&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Yeah, I agree, the scenario is totally different in an actual pressure situation, I've fumbled so many easy questions. I don't necessarily like leetcode style questions as the standard for the industry for interviewing, but its still a reality and, from what I'm noticing, becoming more difficult in terms of expectations.<p>Thanks for signing up, will send out an email once its ready to take for a spin!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39265127"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265127" href="https://news.ycombinator.com/vote?id=39265127&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>We've made a lot of data tooling things based on LLMs, and are in the process of rebranding and launching our main product.<p>1. sketch (in notebook, ai for pandas) <a href="https://github.com/approximatelabs/sketch">https://github.com/approximatelabs/sketch</a></p><p>2. datadm (open source, "chat with data", with support for the open source LLMs (<a href="https://github.com/approximatelabs/datadm">https://github.com/approximatelabs/datadm</a>)</p><p>3. Our main product: julyp. <a href="https://julyp.com/" rel="nofollow">https://julyp.com/</a> (currently under very active rebrand and cleanup) -- but a "chat with data" style app, with a lot of specialized features. I'm also streaming me using it (and sometimes building it) every weekday on twitch to solve misc data problems (<a href="https://www.twitch.tv/bluecoconut" rel="nofollow">https://www.twitch.tv/bluecoconut</a>)</p><p>For your next question, about the stack and deploy:
We're using all sorts of different stacks and tooling. We made our own tooling at one point (<a href="https://github.com/approximatelabs/lambdaprompt/">https://github.com/approximatelabs/lambdaprompt/</a>), but have more recently switched to just using the raw requests ourselves and writing out the logic ourselves in the product. For our main product, the code just lives in our next app, and deploys on vercel.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266800"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266800" href="https://news.ycombinator.com/vote?id=39266800&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Having a play with datadm. It's really good and intuitive to use - good job! I'm getting errors now, but was having a lot of fun before.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39266025"><td></td></tr>
                  <tr id="39267332"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267332" href="https://news.ycombinator.com/vote?id=39267332&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I'm building a weight-loss app that leverages LLM to do 2 things:<p>1. Analyze calories/macronutrients from a text description or photo</p><p>2. Provide onboarding/feedback/conversations like you'd get from a nutritionist</p><p><a href="https://www.fatgpt.ai/" rel="nofollow">https://www.fatgpt.ai/</a></p><p>My stack is Ruby on Rails, PostgreSQL, OpenAI APIs. I chose Rails because I'm very fast in it, but I've found the combination of Rails+Sidekiq+ActionCable is really nice for building conversational experiences on the web. If I stick with this, I'll probably need a native iOS app though.</p><p>Vendor stack is: GitHub, Heroku (compute), Neon (DB), Loops.so (email), PostHog (analytics), Honeybadger (errors), and Linear.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39267437"><td></td></tr>
                <tr id="39267761"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39267761" href="https://news.ycombinator.com/vote?id=39267761&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Jokes aside, GPT-4 Vision is surprisingly good at noticing facts from food images. For example:<p>- In my chipotle bowl, it can tell if I had brown rice vs white rice</p><p>- In my In-n-out, it can tell if I got it protein style</p><p>It struggles with accurate weights/volumes but I'm excited about where this is going.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39267434"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267434" href="https://news.ycombinator.com/vote?id=39267434&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>LLMs have been game changing productivity-wise for me<p>But I found that LLMs are often wrong and hallucinates, so I have to double check with google or other resources.</p><p>So I built a google and chatgpt alternative to answer any question and hallucinations are more obvious. I do this by using by multiple LLM's including search enabled ones i.e. GPT4, Gemini, Claude, Perplexity, Mistral, and Llama.</p><p>It's been growing healthily <a href="https://labophase.com/" rel="nofollow">https://labophase.com</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39267508"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267508" href="https://news.ycombinator.com/vote?id=39267508&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span><a href="https://www.askaway.bot/" rel="nofollow">https://www.askaway.bot/</a><p>AI concierge for my parents‚Äô vacation rental. Mostly just pulling info from the guest binder, but I‚Äôve also started using some local guides to give better suggestions. Built with NextJs and deployed on Vercel (was really easy and they have a generous free tier).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266296"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266296" href="https://news.ycombinator.com/vote?id=39266296&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I was tired of the need to scroll through dozens of blogs and RSS feeds to learn about technologies and industry news, so I‚Äôve built a service that helps you learn and stay updated about any topic by sending a single fully personalized weekly email digest, making relevant information come to you, instead of you chasing it (push vs pull):<p><a href="https://peekly.ai/" rel="nofollow">https://peekly.ai</a></p><p>It‚Äôs basically an LLM-based RAG that works over the best blogs and websites covering any topic you provided during onboarding.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39267583"><td></td></tr>
                  <tr id="39267638"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267638" href="https://news.ycombinator.com/vote?id=39267638&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I built an app to make dealing with Jira less painful. It caches Jira tickets in a SQLite database, then uses GPT-3.5 to translate natural language queries into SQL that it then executes. It also uses Ollama/Mixtral to summarize Jira tickets and GitHub PRs. It can generate a summary of a single Jira ticket with its associated GitHub PRs or  a whole sprint. It's written in Python and runs in the terminal.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39267468"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267468" href="https://news.ycombinator.com/vote?id=39267468&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>A BERT-based summarization system for financial earnings calls. It can take a 60-minute transcripts of such meetings can compress the contents down into 5 bullet points.<p><a href="https://link.springer.com/chapter/10.1007/978-3-031-28238-6_1" rel="nofollow">https://link.springer.com/chapter/10.1007/978-3-031-28238-6_...</a></p><p>Financial earnings calls are important events in investment managements: CEOs and CFOs present the results of the recent quarter, and a few invited analysts ask them questions at the end in a Q&amp;A block.</p><p>Because this is very different prose from news, traditional summarization methods fail. So we pre-trained a transformer from scratch with a ton of high-quality (REUTERS only) finance news and then fine-tuned with a large (100k sentences) self-curated corpus of expert-created summaries.</p><p>We also implemented a range of other systems for comparison.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39267594"><td></td></tr>
            <tr id="39267647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267647" href="https://news.ycombinator.com/vote?id=39267647&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>We've built <a href="https://agentgold.ai/chat" rel="nofollow">https://agentgold.ai/chat</a>, which is an interface to chat with youtube creators about their content.<p>It looks through past transcripts, topics, view counts, and other metadata so users can quickly learn what a Youtuber is all about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265181"><td></td></tr>
            <tr id="39267300"><td></td></tr>
            <tr id="39267634"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267634" href="https://news.ycombinator.com/vote?id=39267634&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>request - i want an LLM tool that can process raw text or email and update or create salesforce records.<p>Example 1: i get an email from a potential customer that says they want [product A]. I can forward that email (or call notes) to salesforce (or somewhere) and it will understand the preference and the relevant customer and update that customer's profile.</p><p>Example 2: In a B2B context, lets say my customer is a company, and there is a news article about them. I could forward a link to the article to the LLM and it would understand that the article is about a customer, and append that article and key info about it to my saleforce record for that customer. The news item becomes an object that is linked to that customer (for call context, better sales targeting, profiling, etc).</p><p>Can someone help me build that?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39267196"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267196" href="https://news.ycombinator.com/vote?id=39267196&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>A search engine that saves me time by detecting SEO spam, downranks results containing ads, and summarizes click bait descriptions away<p>I made it available to the public aisearch.vip
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39267041"><td></td></tr>
            <tr id="39266755"><td></td></tr>
            <tr id="39265829"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265829" href="https://news.ycombinator.com/vote?id=39265829&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>A Twitter filter to take back control of your social media feed from recommendation engines. Put in natural language instructions like "Only show tweets about machine learning, artificial intelligence, and large language models. Hide everything else" and it will filter out all the tweets that you tell it to.<p>Runs on a local LLM, because even using GPT3 costs would have added up quickly.</p><p>Currently requires CUDA and uses a 10.7B model but if anyone wants to try a smaller one and report results let me know on github and I can give some help.</p><p><a href="https://github.com/thomasj02/AiFilter">https://github.com/thomasj02/AiFilter</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266335"><td></td></tr>
                <tr id="39266612"><td></td></tr>
                        <tr id="39264680"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264680" href="https://news.ycombinator.com/vote?id=39264680&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I wrote a script that takes in my credit card statement line by line and categorized the transactions into a custom set of categories that I cared about as well as generating a human readable description of the transaction.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39267528"><td></td></tr>
                  <tr id="39267040"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39267040" href="https://news.ycombinator.com/vote?id=39267040&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>We built Jumprun. You can use it to research and analyze data sources, and it'll produce beautiful canvases with tables, charts, videos, maps, etc. We're working on automations so you can setup natural language trigger conditions that execute actions.<p>We built it in Kotlin with Ktor server, htmx and tailwind. It uses a mixture of models, including gpt4-turbo, gpt4-vision and gemini-pro-vision. It's deployed using Kamal on bare metal.</p><p>Example canvas that provides a roundup of Apple Vision Pro reviews: <a href="https://jumprun.ai/share/canvas/01HNXB2K3GM7KPRP45Y2CVVJSC" rel="nofollow">https://jumprun.ai/share/canvas/01HNXB2K3GM7KPRP45Y2CVVJSC</a></p><p>Our learn more page with some screenshots to show creating a canvas: <a href="https://jumprun.ai/learn-more" rel="nofollow">https://jumprun.ai/learn-more</a></p><p>It's a free closed beta at the moment to control costs, but let me know if you'd like an invite.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39267807"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39267807" href="https://news.ycombinator.com/vote?id=39267807&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Cool! I like the "intelligent canvas" concept. Not exactly the same but my brother and I have been building a side project that also is all about making the most of a set of information using different views like maps, calendars, tables, etc. We have been looking into adding AI to make it easier to import data without having to manually tag all the data. <a href="https://visible.page/" rel="nofollow">https://visible.page</a></span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39266846"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266846" href="https://news.ycombinator.com/vote?id=39266846&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I'm building <a href="https://www.brief.news/" rel="nofollow">https://www.brief.news</a>, an AI powered newsletter that condenses tens of thousands of news articles into a daily briefing of the top stories, we support 30 topics today and are adding the ability to add your own!<p>Stack is a combination of TypeScript (Next / Node) + Python with a pretty simple deployment setup right now (GHA -&gt; Container -&gt; Cloud Run).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266920"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266920" href="https://news.ycombinator.com/vote?id=39266920&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>This looks awesome - might I suggest splitting the headlines on the homepage into a punchy title and subtitle? The wordiness of them makes it difficult for me to parse them for the topic quickly</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39266036"><td></td></tr>
            <tr id="39266355"><td></td></tr>
            <tr id="39266865"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266865" href="https://news.ycombinator.com/vote?id=39266865&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I'm currently working on an interface for google calendar @ <a href="https://calendarcompanion.io/" rel="nofollow">https://calendarcompanion.io</a>  
My next feature is integrating the functionality with telegram, it's hard to predict the value of these features in the moment - but I do think this could be an extremely interesting "iPhone" moment for technology. 
Just like how the iPhone reduced everything to a single button press, we can now squeeze the functionality of some pretty complicated apps into natural language through text - and as the response time of LLM's improves it will become a short conversation for things that used to dazzle new users! Exciting times!<p>As for the stack, I have Supabase and Typescript on the frontend, python on the backend and k3's as a cluster for my apps (can recommend this if you want to get devops-y on a budget). Next time, I'll just go pure Typescript since python really doesn't add much working this far away from the base models.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265086"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265086" href="https://news.ycombinator.com/vote?id=39265086&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I've made a couple games, though I am still having a hard time finding the soul of the game in the LLM and haven't released them; there's a historical roleplay game (that I plan to release soon), a storytelling game (the player tells stories to the LLM), a wander-a-world-aimlessly-and-chat game, and I never get further than 50% through the way of murder mystery games, though murder mysteries seem like an excellent structure.<p>I've built some abstract content development tools, generally focused on building larger content somewhat top-down (defining vibes, then details).</p><p>I'm working on a general project helper using the GPT-Vision, voice, and regular GPT. You setup the camera above your workspace, work on paper, and chat with the LLM while you do it. I think there's a lot of potential, but the voice stuff is quite hard to deal with... there's just a ton of stuff happening in parallel, and I find it very hard to code something reliable.</p><p>The stack I use is all in the browser, generally Next.js, Preact Signals, and my own code to call into GPT, Whisper, etc. I like having everything available for inspection, and I generally keep all the working bits visible somewhere. (This can be overwhelming when other people see it.)</p><p>But I haven't gotten over the deployment hump... the cost and complexity is a challenge. I've used Openrouter.ai recently in a project, and I think if I leaned on that more completely I'd find the release process easier.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264608"><td></td></tr>
                <tr id="39267415"><td></td></tr>
            <tr id="39265229"><td></td></tr>
                  <tr id="39267075"><td></td></tr>
            <tr id="39266277"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266277" href="https://news.ycombinator.com/vote?id=39266277&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I am currently building an automatic book generator of Rust source code, in which the LLM will write the description of the code of a whole Rust project. It will be a bot, which will connect to the website, generate descriptions, download them, and create the book. It is very early in the project, 3 days in, but it's going well.<p><a href="https://github.com/pramatias/documentdf">https://github.com/pramatias/documentdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266214"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266214" href="https://news.ycombinator.com/vote?id=39266214&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I'm building a spaced-repetition flashcards language learning app, that generates sentences and explanations for a given word.<p>Unfortunately only for German, but I plan on expanding the languages soon.</p><p><a href="https://vokabeln.io/" rel="nofollow">https://vokabeln.io</a></p><p>Tech stack:
- The app is in Flutter.
- Backend I'm nodejs TS.
- GPT4 for generation of sentences and explanations
- GCP text-to-speech for audio
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266266"><td></td></tr>
                  <tr id="39266589"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266589" href="https://news.ycombinator.com/vote?id=39266589&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I've been using a combo of LLMs + live transcription to build a passive assistant that keeps track of talking points and can pull out data/tasks from a conversation you're having (<a href="https://sightglass.ai/" rel="nofollow">https://sightglass.ai</a> or here's a demo of me using it: <a href="https://www.loom.com/share/0220ca03bce341669d314d4254872226" rel="nofollow">https://www.loom.com/share/0220ca03bce341669d314d4254872226</a>)<p>So far this is being used for:</p><p>- Sales -&gt; guiding new recruits during more complex client calls</p><p>- HR -&gt; Capturing respones during screening interviews</p><p>If you'd like to try this out feel free to DM me or email me at andrew at sightglass.ai, we're looking for more testers!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266699"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266699" href="https://news.ycombinator.com/vote?id=39266699&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I'm making two LLM's negotiate the exchange of a product, price is the main issue but I'm trying to make them negotiate another issues too in order to avoid the "bargaining" case.<p>I've tried several models and gpt4 is currently the one that better performs, but OS LLM's like Mixtral and Mixtral-Nous are quite capable too.</p><p><a href="https://github.com/mfalcon/negotia">https://github.com/mfalcon/negotia</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264590"><td></td></tr>
            <tr id="39264967"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264967" href="https://news.ycombinator.com/vote?id=39264967&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I know chat is lame and overdone but here's my open source local AI chat app for macOS :). I wanted something simple enough for the non-technical people in my life who were using ChatGPT. For better or worse, those people are mostly not using chat AI much anymore. Seems like the initial awe wore off.<p><a href="https://github.com/psugihara/FreeChat">https://github.com/psugihara/FreeChat</a></p><p>I'm also working on a little text adventure game that I hope to release soon.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266791"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266791" href="https://news.ycombinator.com/vote?id=39266791&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I built a tool to create "average llm" probability of code for checking how aligned code is with what an LLM would output. Working on adding context from a project to check how the style of a section aligns with the style, content and domain of a project.<p>Idea is to use it to identify code that sticks out, because that usually what's interesting or bad.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266830"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266830" href="https://news.ycombinator.com/vote?id=39266830&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Wrote an application to find myself a flat in Berlin, scans some rental websites every minute, uses Google Maps API to calculate the distance to my office, and summarizes the rental description with the GPT-4 API, sends it to me via Telegram.<p>I have no time to read all that generic "vibrant neighborhood" stuff :D
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39267253"><td></td></tr>
                  <tr id="39264464"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264464" href="https://news.ycombinator.com/vote?id=39264464&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Summarisation for calls, emails. Lots of extraction tasks &amp; closed domain chatbots.<p>Deployment is usually FastAPI for business logic, Langchain or MS/Guidance library, LLM hosted via. HF-TGI server
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39267571"><td></td></tr>
            <tr id="39264995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264995" href="https://news.ycombinator.com/vote?id=39264995&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I have built a webapp for translating srt files: <a href="https://www.subsgpt.com/" rel="nofollow">https://www.subsgpt.com</a><p>GPT-4 excels as a translator, but it often encounters issues with content warnings and formatting errors when translating entire subtitle files via ChatGPT. The solution is straightforward: divide the subtitle file into sections, focusing solely on translating the text and disregarding the timestamps. While it's feasible to have ChatGPT maintain the correct format, I've observed a decline in translation quality when attempting this in a single pass. My preferred approach is a two-phase method: first, translate the text, and then, if necessary, request ChatGPT to adjust the formatting.</p><p>The webapp splits the srt file into batches of 20 phrases and translates each batch. It also allows for manual correction of the final translation.</p><p>Ah and it's also serverless: you input your OpenAI token &amp; select the model of your choice and the webapp makes the requests to OpenAI directly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265497"><td></td></tr>
            <tr id="39266443"><td></td></tr>
            <tr id="39266391"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266391" href="https://news.ycombinator.com/vote?id=39266391&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Me and an colleague working on a language learning app <a href="https://poli.xyz/" rel="nofollow">https://poli.xyz</a>. It integrates in you favorite messenger and offers a wide variety of languages. You can either either do freestyle conversations or play certain scenarios. The bot corrects your Grammatik, translates and explains words and sentences and support tts and stt.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39266558"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266558" href="https://news.ycombinator.com/vote?id=39266558&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>A text to slide based online course video with images workflow.<p>I‚Äôm working for an edTech company. Some students prefer video. So I built a Django app that takes a block of text and formats it into a set of slides, each with a title, some bullet points, an Dalle-3 generated image, and a voiceover.</p><p>It then compiles that all into a video.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265149"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265149" href="https://news.ycombinator.com/vote?id=39265149&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I am building a no code solution. Use case is simple: Write complete programs/software for the browser from natural language input.<p><a href="https://domsy.io/" rel="nofollow">https://domsy.io</a></p><p>Currently running on my little digital ocean droplet. Stack is javascript/python.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265423"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265423" href="https://news.ycombinator.com/vote?id=39265423&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Ooooh, not something i have built, I do want to but suspect someone else has done it better than i could.<p>A tool to RAG a github repo, so i can ask questions of how a certain library or tool works?  Even better if it pulls in issues
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265572"><td></td></tr>
                  <tr id="39265502"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265502" href="https://news.ycombinator.com/vote?id=39265502&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I created a Chrome extension which shows cryptocurrency prices &amp; insights when you hover cash tags on Twitter. I'm a product manager with solid CS understanding, but haven't had the time to learn React or glue frontend stuff together - so about 80% of the code is generated by GPT4. I've mainly architected the code and deployed on Vercel. I feel like AI + Vercel has given me that final push to actually deploy products instead of just building stuff and leave it lying around.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265063"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265063" href="https://news.ycombinator.com/vote?id=39265063&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>An automatic video editor.<p>It should be cheap enough to deploy that it can be applied to relatively low-value content like video meeting recordings, so it can‚Äôt spend a lot of expensive GPU time analyzing video frames.</p><p>It also needs to be easily customizable for various content verticals and visual styling like branding and graphics overlays.</p><p>And everything is meant to be open sourced, so that‚Äôs fun!</p><p>I wrote about it on my employer‚Äôs blog here:</p><p><a href="https://www.daily.co/blog/automatic-short-form-video-highlight-reels-at-scale-with-ai-and-vcsrender/" rel="nofollow">https://www.daily.co/blog/automatic-short-form-video-highlig...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265073"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265073" href="https://news.ycombinator.com/vote?id=39265073&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I use sponsor block and it's really good, I like that it's community-driven but sometimes it's not available for videos so your solution sounds great.<p>I consult to a law firm as their founder-in-residence. For fun, I trained Llama 2 on all the non-client data of the firm so that people could ask it questions like "Who are the lawyers in Montreal who litigate American securities laws, what are their email addresses and what time is it where they are?" It's a njs app running on linode.</p><p>It's extremely simple, but people seem to find it useful.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265175"><td></td></tr>
            <tr id="39266360"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266360" href="https://news.ycombinator.com/vote?id=39266360&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Perhaps a follow on question, as I presume a lot of people reading the comments are looking for inspiration to build things (and those building might not want to reveal yet) what would you like to see built with the capabilities provided by LLMs?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39267429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39267429" href="https://news.ycombinator.com/vote?id=39267429&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>AI/ML that reads my zsh history and suggests automations or other time-savers when asked.<p>Something that reads my teams and outlook, and listens to meetings, and takes notes / remembers stuff for me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39266400"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266400" href="https://news.ycombinator.com/vote?id=39266400&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I wish someone hooked up a chat interface to a CAD program. I find CAD very hard to get in to. It would be really nice to able to ask it how do stuff or to modify parts. Would be very "Star Trek in Holodeck" :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265040"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265040" href="https://news.ycombinator.com/vote?id=39265040&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I‚Äôm working on some tools to help GMs of tabletop games make content for their players.<p>Little demo is up at npcquick.app.</p><p>Doesn‚Äôt look like much rn, but there‚Äôs no openai involved. Currently it doesn‚Äôt even use a gpu.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264705"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264705" href="https://news.ycombinator.com/vote?id=39264705&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I am building textool [1] an app that lets you create endpoints using GPT4. The idea is to make it so you can create "actions" for GPT4 assistants easily.<pre><code>  - Nextjs
  - Deno Deploy for hosting the apis 
  - Supabase - postgres / auth
  - Shadcn
</code></pre>
I want to use the t3 app stack [2] for v2.<p>It's really MVP, but I want to see if anyone is interested at all before I work on v2: creating gpts that come with databases!</p><pre><code>  [1] https://textool.dev
  [2] https://create.t3.gg/</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39265042"><td></td></tr>
                <tr id="39265134"><td></td></tr>
                        <tr id="39265417"><td></td></tr>
            <tr id="39264647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264647" href="https://news.ycombinator.com/vote?id=39264647&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Absurd news article generator using local LLMs. I wanted to create a static website from the articles, but ultimately didn't think anyone would give a damn. In the same vein I create a person + CV generator, and a group chat between simulated crazy people.<p>I made a private Discord bot for me and my friends to talk to, that also generates images using SD 1.5 LCM.</p><p>The self-hosted backend uses the ComfyUI Python API directly for images, and the LLM part uses oobabooga's web API.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266259"><td></td></tr>
            <tr id="39265449"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265449" href="https://news.ycombinator.com/vote?id=39265449&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>"Widjosumarajzer" = video summarizer<p>It's just a hodgepodge of prototype scripts, but one that I actually used on a few occasions already. Most of the work is manual, but does seem easily run as "fire and forget" with maybe some ways to correct afterwards.</p><p>First, I'm using the pyannote for speech recognition: it converts audio to text, while being able to discern speakers: SPEAKER_01, _02, etc. The diarization provides nice timestamps, with resolution down to parts of words, which I later use in the minimal UI to quickly skip around, when a text is selected.</p><p>Next, I'm running a LLM prompt to identify speakers; so if SPEAKER_02 said to SPEAKER_05 "Hey Greg", it will identify SPEAKER_05 = Greg. I think it was my first time using the mistral 7b and I went "wow" out loud, once it got correct.</p><p>After that, I fill in the holes manually in speaker names and move on to grouping a bunch of text - in order to summarize. That doesn't seem interesting at a glance, but removing the filler words, which there are a ton of in any presentation or meeting, is a huge help. I do it chunk by chunk. I'm leaning here for the best LLM available and often pick the dolphin finetune of mixtral.</p><p>Last, I summarize those summarizations and slap that on the front of the google doc.</p><p>I also insert some relevant screenshots in between chunks (might go with some ffmpeg automatic scene change detection in the future).</p><p>aaand that's it. A doc, that is searchable easily. So, previously I had a bunch of 30 min. to 90 min. meeting recordings and any attempt at searching required a linear scan of files. Now, with a lot of additional prompt messaging I was able to:</p><p>- create meeting notes, with especially worthwile "what did I promise to send later" points</p><p>- this is huge: TALK with the transcript. I paste the whole transcript into the mistral 7b with 32k context and simply ask questions and follow-ups. No more watching or skimming an hour long video, just ask the transcript, if there was another round of lay-offs or if parking spaces rules changed.</p><p>- draw a mermaid sequence diagram, of a request flowing across services. It wasn't perfect, but it got me super excited about future possibilities to create or update service documentation based on ad-hoc meetings.</p><p>I guess everybody is actually trying to build the same, seems like a no-brainer based on current tool's capabilities.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266495"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266495" href="https://news.ycombinator.com/vote?id=39266495&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Very interested in this. I have been contemplating building something similar, but am unaware of any existing services that do this. Haven't played with pyannote, how does it compare to whisper?
Also thought it might be useful to be able to OCR screenshots and use the text to inform the summariation and transcription especially for things like code snippets and domain-specifc terms.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266802"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266802" href="https://news.ycombinator.com/vote?id=39266802&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I remember whisper v3 large blowing my mind: it was able to properly transcribe some two language monstrosity (przescreenowaƒá, which is a english word "to screen a candidate", but conjugated according to standard polish rules). Once I saw that I thought "it's finally time: truly good transcription has finally arrived".<p>So I view whisper as sota with excellent accuracy.</p><p>Now, for the type of transcription I need speaker discerning is much more valuable than accurate to the point translation: so it will be summarized anyway and that tends to  gloss over some of errors anyway.</p><p>That said, pyannote has also caught me off guard: it correctly annotated lazily spoken "DP8" with non native speaker accent.</p><p>It looks really good
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39265637"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265637" href="https://news.ycombinator.com/vote?id=39265637&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I am working on building out a better voice interface for LLMs.<p>It is still a work in progress (early beta), but you can check it out at <a href="https://www.bonamiko.com/" rel="nofollow">https://www.bonamiko.com</a></p><p>Currently I have mainly been using it as a tandem conversation partner for a language I'm learning, but it can be used for many more things. As it is right now, you can use it to bounce ideas of, practice interviews, and help answer quick general questions. You just need to tell it what you want.</p><p>The stack is a Next.js application hosted on Vercel using Supabase for the backend. (There is also some plumbing in AWS for email and DNS.) It is automatically deployed via GitHub actions.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266161"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266161" href="https://news.ycombinator.com/vote?id=39266161&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>Very cool, just signed up. What advantages does this have over the one built into the ChatGPT app? Also, it would be great if I could see the text output in addition to the voice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39266614"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39266614" href="https://news.ycombinator.com/vote?id=39266614&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>The main differences fundamentally come down to OpenAI treating it more like a party trick demo, rather than a core functionality. I think it has a lot of potential if I can just fine tune a couple rough edges. (When you chat with someone in person, you don't pull out notebooks a write messages to each other. I see writing as a fallback medium.)<p>To answer your question more specifically,</p><p>Pro Bonamiko:</p><pre><code>  - Faster average first response latency (but higher first audio latency since OpenAI uses a ding). This is the main focus currently, reducing latency as much as I can. I'd like to be able to avoid the ding, but we'll see how low I can get it.
  - Can be used anywhere with a browser, OpenAI requires a mobile app installed. (I.E. Desktop support)
  - In the future we can support deeper customization since we are focused on the audio medium. As soon as you have to run a function in the ChatGPT app there is a long response latency, which could easily be fixed by something as simple as the AI saying "Let me perform a search to get the details"
</code></pre>
Pro ChatGPT:<pre><code>  - Nice animation
  - Already has built in tool support such as web search
  - Supports language switching automatically between messages, Bonamiko requires manually changing the language</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39266665"><td></td></tr>
            <tr id="39265002"><td></td></tr>
            <tr id="39266774"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266774" href="https://news.ycombinator.com/vote?id=39266774&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I wrote an autonomous AI space opera tv show generator. It takes a short topic phrase on one end and spits out a 10-15 minute 3D animated and AI voiced video suitable for upload to YouTube on the other end.<p>Super interesting learning exercise since it intersects with many enterprise topics, but the output is of course more fun.</p><p>In some ways it is more challenging - a summary is still useful if it misses a point or is a little scrambled, whereas when a story drops a thread it‚Äôs much more immediately problematic.</p><p>I‚Äôm working on a blog post as well as getting a dozen episodes uploaded for ‚Äúseason 1‚Äù.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39266487"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266487" href="https://news.ycombinator.com/vote?id=39266487&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>An app that aggregates the news from websites, blogs, YouTube channels and podcasts, and generate easily digestible summaries, along with a small podcast version so you can stay informed in an easy stress-free way.<p>Right now I‚Äôm working on including automatic fact checking and insights on how each source might be opinionated vs. reporting just the facts.</p><p><a href="https://usetailor.com/" rel="nofollow">https://usetailor.com</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39264688"><td></td></tr>
            <tr id="39264947"><td></td></tr>
            <tr id="39264997"><td></td></tr>
            <tr id="39264907"><td></td></tr>
            <tr id="39265305"><td></td></tr>
            <tr id="39266286"><td></td></tr>
            <tr id="39264889"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264889" href="https://news.ycombinator.com/vote?id=39264889&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I built the copilot for flux.ai, which allows LLM-driven interaction with circuit schematics and datasheets.<p>The stack is react / cloud run / job queue / LLMs (several) / vector db.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39263752"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39263752" href="https://news.ycombinator.com/vote?id=39263752&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>Also a Chrome extension [0]! The concept is to use the browser's context menu to run commands on the LLM, so it stays out of your way most of the time but feels like a somewhat native experience.<p>The stack is:
1. TypeScript/Node/tRPC/Postgres/Redis/OpenAI on the backend
2. SolidJS/Crxjs/tRPC on the front end
3. Astro for the docs/marketing site</p><p>And deployment is currently through render.com for the databases and servers, and manually via a zip file to the Chrome webstore for the extension itself.</p><p>[0] <a href="https://smudge.ai/" rel="nofollow">https://smudge.ai</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265797"><td></td></tr>
                  <tr id="39264424"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264424" href="https://news.ycombinator.com/vote?id=39264424&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>My project team in university built a meme generator that uses GPT and Dall-E to generate image macros using Impact font. It was pretty entertaining.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265168"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265168" href="https://news.ycombinator.com/vote?id=39265168&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>An AI agent to answer questions about any github/gitlab repository.
www.useadrenaline.com<p>It does the work of understanding questions in the context of a repo, code snippet, or any programming question in general, and pulls in extra context from the internet with self thought + web searches.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265193"><td></td></tr>
                <tr id="39266239"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39266239" href="https://news.ycombinator.com/vote?id=39266239&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I like this. I tried something similar ~10 years ago, but it didn't go very well. I'm sure an LLM can do much better than the nonsense I hacked together.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39266088"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266088" href="https://news.ycombinator.com/vote?id=39266088&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I built a flask app based chrome extension that takes content from the DOM and sends it to chatGPT for summarization, I also configured it to work on YouTube videos and PDFs, helps when you want to share the tl;dr of a site or video to a friend, I'm thinking I'm going to add some more specific summary functionality next, like listing out a recipe's ingredients and cooking steps<p><a href="https://chromewebstore.google.com/detail/news-article-summarizer/pohjdmofkgcgbihdhiegnhghklhieadc" rel="nofollow">https://chromewebstore.google.com/detail/news-article-summar...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39265285"><td></td></tr>
            <tr id="39266689"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39266689" href="https://news.ycombinator.com/vote?id=39266689&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I built <a href="https://listingstory.com/" rel="nofollow">https://listingstory.com</a> as a way to learn about and play with LLMs. It's unlikely to ever be a commercial success, but it served it's purpose in allowing me to learn much more about how an LLM powered app works.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39265216"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39265216" href="https://news.ycombinator.com/vote?id=39265216&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I made some LLM-powered text-adventure games: <a href="https://cosmictrip.space/gameannouncement" rel="nofollow">https://cosmictrip.space/gameannouncement</a><p>And I'm working on a webapp that is a kanban board where LLM and human collaborate to build features in code. I just got a cool thing working there: like everyone, having LLM generate new code is easy but modifying code is hard. So my attempt at working on modifying code with LLM is starting with HTML and having GPT-4 write beautfulsoup code that then makes the desired modification to the HTML file. Will do with js, python via ast, etc. No link for this one yet :) still in development.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265455"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39265455" href="https://news.ycombinator.com/vote?id=39265455&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I didn't make text-adventures with LLMs. I try to solve them [0].<p>So, far, none of the 7 tested models were able to win even one of the easiest text adventures. I tried many prompting techniques. But only GPT-4 was able to play through the first half of the game.</p><p>[0] <a href="https://github.com/s-macke/AdventureAI">https://github.com/s-macke/AdventureAI</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39265966"><td></td></tr>
                <tr id="39266233"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39266233" href="https://news.ycombinator.com/vote?id=39266233&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>GPT-3 doesn't even manage the first few steps of the tested text adventure.
And GPT-4 is not good at playing these adventures either.<p>However, my code run a newer version of the Z-machine. So Zork and many other text adventures will work. I have not tried many other games though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39266617"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39266617" href="https://news.ycombinator.com/vote?id=39266617&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><p><span>I was surprised how high your costs were. I assume you are putting the entire transcript into each prompt, but even then that seems high. Is GPT's planning also taking up a lot of room?<p>I did find giving GPT some hints about the known commands helped a lot, and I put in some detection of error messages and kept a running log of commands that wouldn't work. Getting it to navigate the parser is kind of half of the skill of playing one of these games. It would be interesting to have it play some, then step back and have it reflect and enumerate things about how the play itself works.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="39266410"><td></td></tr>
            <tr id="39264595"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39264595" href="https://news.ycombinator.com/vote?id=39264595&amp;how=up&amp;goto=item%3Fid%3D39263664"></a></center>    </td><td><br><div>
                  <p><span>I've built a sales bot that would go over a predefined sales scenario like a real human would, being able to jump between steps and work with any complications real conversation would throw at it. It would appear fully human to whoever converted with it. Unfortunately, it was never deployed in production due to business reasons.</span></p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SAT (and ACT) scores are highly predictive of academic achievement at Dartmouth [pdf] (237 pts)]]></title>
            <link>https://home.dartmouth.edu/sites/home/files/2024-02/sat-undergrad-admissions.pdf</link>
            <guid>39263106</guid>
            <pubDate>Mon, 05 Feb 2024 16:35:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://home.dartmouth.edu/sites/home/files/2024-02/sat-undergrad-admissions.pdf">https://home.dartmouth.edu/sites/home/files/2024-02/sat-undergrad-admissions.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39263106">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Weaveworks is shutting down (238 pts)]]></title>
            <link>https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67</link>
            <guid>39262650</guid>
            <pubDate>Mon, 05 Feb 2024 16:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67">https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67</a>, See on <a href="https://news.ycombinator.com/item?id=39262650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" role="main">
      <section>
                <h2>
                  Alexis Richardson‚Äôs Post
                </h2>

                
    

    
      

    <article data-activity-urn="urn:li:activity:7160295096825860096" data-featured-activity-urn="urn:li:activity:7160295096825860096" data-attributed-urn="urn:li:share:7160295095307550720">
      
              
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    

    
    

<!---->  
        

      
            

    
    
    
    
    
    
    
    
    
    
    

    
  
        

      
              

    
    
    
    
    
    
    
    
    
    
    
    
    

      
  
        

        
            
            
  <p dir="ltr" data-test-id="main-feed-activity-card__commentary">Hi everyone

I am very sad to announce - officially - that Weaveworks will be closing its doors and shutting down commercial operations.&nbsp; Customers and partners will be working with a financial trustee whom we shall announce soon. 

The company was turning over double digit (&gt;$10M) revenue and had more than doubled the number of new product logos in 2023.&nbsp; However this sales growth was lumpy and our cash position, consequently volatile.&nbsp; We needed a partner or investor for long term growth.&nbsp; Finally a very promising M&amp;A process with a larger company fell through at the 11th hour.&nbsp; And so we decided to shut down.&nbsp; 

I can only apologize to everyone for this difficult turn. &nbsp; I could say that this should not have happened, but I know that we are not alone in this market.&nbsp; Bigger vessels have gone astray.&nbsp; The Weaveworks team is a special group and it has been a long and tough journey.&nbsp; I know that everyone has been so motivated to do their very best for our customers, our open source community, and each other.&nbsp; You have done well and can be proud.&nbsp; We shall always have a shared story.

Our story has been so exciting - from the first days of containers, struggling to be born.&nbsp; The day when someone got Kubernetes working for the first time on Azure.&nbsp; The start of the CNCF.&nbsp; The day when we wiped out our systems with a keypress.&nbsp; The first months of the Covid pandemic.&nbsp; Then investment and our work to figure out GitOps for a lot of great enterprise customers.&nbsp; And there have been dire moments too but we figured most of them out together. You‚Äôve shared all of this and all deserve every memory of a good place to work, and with the privilege of knowing that all of you are among the best.

The story does not end here - our open source software is used everywhere.&nbsp; I am working with several large organizations to make sure CNCF Flux is in the healthiest state.&nbsp; More on that soon.&nbsp; And I would invite anyone who reads this and wants to know what is next or offer some help, please get in touch with me!&nbsp; Thank you.

We shall not cease from exploration
And the end of all our exploring
Will be to arrive where we started
And know the place for the first time.

Alexis Richardson, 5 Feb 2024</p>



        

      
            
<!---->  
                  

<!---->
      
          
        

      
          
        

      
          
      
    
    
    
    
    
    
    
    
    

<!---->  
  
        

      
              
    
    
    

    
  
                    

      
            
<!----><!---->      
        

      
            

    
    

    
  
        
    </article>
  
      
  
  
            </section>
        <section>

            <h2>
              Explore topics
            </h2>

<!---->
        
      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Working in the Vision Pro [video] (126 pts)]]></title>
            <link>https://www.youtube.com/watch?v=BV9Xy6L_rlM</link>
            <guid>39262087</guid>
            <pubDate>Mon, 05 Feb 2024 15:17:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=BV9Xy6L_rlM">https://www.youtube.com/watch?v=BV9Xy6L_rlM</a>, See on <a href="https://news.ycombinator.com/item?id=39262087">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tenstorrent engineers talk open-sourced bare-metal stack (163 pts)]]></title>
            <link>https://www.eetimes.com/tenstorrent-engineers-talk-open-sourced-bare-metal-stack/</link>
            <guid>39262043</guid>
            <pubDate>Mon, 05 Feb 2024 15:14:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eetimes.com/tenstorrent-engineers-talk-open-sourced-bare-metal-stack/">https://www.eetimes.com/tenstorrent-engineers-talk-open-sourced-bare-metal-stack/</a>, See on <a href="https://news.ycombinator.com/item?id=39262043">Hacker News</a></p>
Couldn't get https://www.eetimes.com/tenstorrent-engineers-talk-open-sourced-bare-metal-stack/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Vesuvius Challenge 2023 Grand Prize awarded: we can read the first scroll (899 pts)]]></title>
            <link>https://scrollprize.org/grandprize</link>
            <guid>39261861</guid>
            <pubDate>Mon, 05 Feb 2024 15:00:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scrollprize.org/grandprize">https://scrollprize.org/grandprize</a>, See on <a href="https://news.ycombinator.com/item?id=39261861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><article><div><p>The 2000-year-old scroll discusses music, food, and how to enjoy life‚Äôs pleasures.</p><p>February 5th, 2024</p><p>We‚Äôre announcing the winners of the Vesuvius Challenge 2023 Grand Prize. We‚Äôll look at how they did it, what the scrolls say, and what comes next.</p><p><em>Join the winners for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. More to come.</em></p><h2 id="victory">Victory<a href="#victory" title="Direct link to heading">‚Äã</a></h2><p>Two thousand years ago, a volcanic eruption buried an ancient library of papyrus scrolls now known as the Herculaneum Papyri.</p><figure><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/grandprize/library-lava-small.jpg"><source src="https://scrollprize.org/img/grandprize/library-lava-small.webm" type="video/webm"><source src="https://scrollprize.org/img/grandprize/library-lava-small.mp4" type="video/mp4"></video><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/grandprize/scroll-lava-small.jpg"><source src="https://scrollprize.org/img/grandprize/scroll-lava-small.webm" type="video/webm"><source src="https://scrollprize.org/img/grandprize/scroll-lava-small.mp4" type="video/mp4"></video><figcaption>The scrolls were <a href="https://twitter.com/natfriedman/status/1703422593670541437" target="_blank" rel="noopener noreferrer">carbonized</a> by the eruption of Mount Vesuvius in 79 AD.</figcaption></figure><p>In the 18th century the scrolls were discovered. More than 800 of them are now stored in a library in Naples, Italy; these lumps of carbonized ash cannot be opened without severely damaging them. But how can we read them if they remain rolled up?</p><div><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/scroll-1-scale.jpg"></p><figcaption>The scroll read by the winners.</figcaption></div><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/unrolled-orig.jpg"></p><figcaption>Result of an attempt to physically unroll a scroll.</figcaption></div></div><p>On March 15th, 2023, Nat Friedman, Daniel Gross, and Brent Seales launched the <a href="https://scrollprize.org/" target="_blank" rel="noopener noreferrer">Vesuvius Challenge</a> to answer this question. Scrolls from the Institut de France were imaged at the Diamond Light Source particle accelerator near Oxford. We released these high-resolution CT scans of the scrolls, and we offered more than $1M in prizes, put forward by many generous donors.</p><div><p><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/tutorials/scanning2.jpg"><source src="https://scrollprize.org/img/tutorials/scanning2.webm" type="video/webm"><source src="https://scrollprize.org/img/tutorials/scanning2.mp4" type="video/mp4"></video><figcaption>Artistic visualization of constructing a 3D volume.</figcaption></p></div><p>A global community of competitors and collaborators assembled to crack the problem with computer vision, machine learning, and hard work.</p><p>Less than a year later, in December 2023, they succeeded. Finally, after 275 years, we can begin to read the scrolls:</p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/text_bcb-smaller.jpg"><img loading="lazy" src="https://scrollprize.org/img/grandprize/text_bcb-smaller.jpg"></a></p><figcaption>Text from PHerc.Paris. 4 (Institut de France), unseen for 2,000 years. Roughly 95% of the scroll remains to be read.</figcaption></div><p>The thoughts of our ancestors, locked in mud and ash for 2000 years, hidden in darkness ‚Äî now, with the light of a worldwide effort shining upon them, finally seen again.</p><h2 id="grand-prize">Grand Prize<a href="#grand-prize" title="Direct link to heading">‚Äã</a></h2><p>We received many excellent submissions for the Vesuvius Challenge Grand Prize, several in the final minutes before the midnight deadline on January 1st.</p><p>We presented these submissions to the review team, and they were met with widespread amazement. We spent the month of January carefully reviewing all submissions. Our team of eminent papyrologists worked day and night to review 15 columns of text in anonymized submissions, while the technical team audited and reproduced the submitted code and methods.</p><p>There was one submission that stood out clearly from the rest. Working independently, each member of our team of papyrologists recovered more text from this submission than any other. Remarkably, the entry achieved the criteria we set when announcing the Vesuvius Challenge in March: 4 passages of 140 characters each, with at least 85% of characters recoverable. This was not a given: most of us on the organizing team assigned a less than 30% probability of success when we announced these criteria! And in addition, the submission includes another 11 (!) columns of text ‚Äî more than 2000 characters total.</p><p>The results of this review were clear and unanimous: the Vesuvius Challenge Grand Prize of $700,000 is awarded to a team of three for their excellent submission. Congratulations to <strong>Youssef Nader, Luke Farritor, and Julian Schilliger</strong>!</p><div><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/youssef-smaller.jpg"></p><figcaption>Youssef Nader</figcaption></div><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/luke-smaller.jpg"></p><figcaption>Luke Farritor</figcaption></div><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/julian-smaller.jpg"></p><figcaption>Julian Schilliger</figcaption></div></div><p>All three winning team members have been strong community contributors since the very beginning of the Vesuvius Challenge. You may remember Youssef. He is the Egyptian PhD student in Berlin who was able to read a few columns of text back in October, winning the second-place <a href="https://scrollprize.org/firstletters">First Letters Prize</a>. His results back then were particularly clear and readable, which made him the natural lead for the team that formed.</p><p>You might remember Luke as well: he is the 21-year-old college student and SpaceX intern from Nebraska, who was the first person in history to read an entire word from the inside of a Herculaneum scroll (Œ†ŒüŒ°Œ¶Œ•Œ°Œëœπ, ‚Äúpurple‚Äù). This won him the first-place First Letters Prize, a few weeks before Youssef‚Äôs results.</p><p>And finally, you might remember Julian. He is the Swiss robotics student at ETH Z√ºrich, who won three Segmentation Tooling prizes for his incredible work on Volume Cartographer. This enabled the 3d-mapping of the papyrus areas you see before you.</p><p>For the Grand Prize, they assembled into a superteam, crushing it by creating what was unanimously deemed the most readable submission.</p><p>The submission contains results from three different model architectures, each supporting the findings of the others, with the strongest images often coming from a <a href="https://arxiv.org/abs/2102.05095" target="_blank" rel="noopener noreferrer">TimeSformer</a>-based model. Multiple measures prevent overfitting and hallucination, including results from multiple architectures, a study across input/output window sizes, label smoothing, and varying validation folds. Like with all our prizes, this ink detection code has been made public as open source (on <a href="https://github.com/younader/Vesuvius-Grandprize-Winner" target="_blank" rel="noopener noreferrer">GitHub</a>), leveling up everyone in the community.</p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/youssef_text_wbb.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/youssef_text_wbb-smaller.png"></a></p><figcaption>The winners‚Äô main submission image (TimeSformer 64x64).</figcaption></div><p>In addition to unparalleled ink detection, the winning submission contained the strongest auto-segmentation approach we have seen to date (more about the process of ‚Äúsegmentation‚Äù below). <a href="https://github.com/schillij95/ThaumatoAnakalyptor" target="_blank" rel="noopener noreferrer">ThaumatoAnakalyptor</a> (roughly: Miracle Uncoverer) by Julian generates massive papyrus segments from multiple scrolls. Re-segmentations of well known areas validate previous ink findings, and entirely new segmentations reveal writing elsewhere, such as the outermost wrap of the scroll!</p><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_paragraph_1.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_paragraph_2.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_paragraph_3_4.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_outermost_sheet.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_recto.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/autoseg_recto_64.jpg"></p><figcaption>Outputs from auto-segmentation. The top row overlaps with the submission image, the bottom row has new segments. Much work remains to improve this promising tool.</figcaption></div><p>Congratulations to Youssef, Luke, and Julian. You are the well-deserved winners of the 2023 Vesuvius Challenge Grand Prize!</p><h2 id="runners-up">Runners up<a href="#runners-up" title="Direct link to heading">‚Äã</a></h2><p>Of the remaining submissions, the scores from our team of papyrologists identify a three-way tie for runner up. These entries show remarkably similar readability to each other, but still stand out from the rest by being significantly more readable. Congratulations to the following teams, each taking home $50,000!</p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/elian_text_wbb.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/elian_text_wbb-smaller.png"></a></p><figcaption>Elian Rafael Dal Pr√°, Sean Johnson, Leonardo Scabini, Ra√≠ Fernando Dal Pr√°, Jo√£o Vitor Brentigani Torezan, Daniel Baldin Franceschini, Bruno Pereira Kellm, Marcelo Soccol Gris, and Odemir Martinez Bruno. <a href="https://github.com/erdpx/vesuvius-grand-prize" target="_blank" rel="noopener noreferrer">GitHub</a></figcaption></div><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/lou_text_wbb.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/lou_text_wbb-smaller.png"></a></p><figcaption>Louis Schlessinger and Arefeh Sherafati. <a href="https://github.com/lschlessinger1/vesuvius-grand-prize-submission" target="_blank" rel="noopener noreferrer">GitHub</a></figcaption></div><p>These teams each brought to the table new approaches to the subtleties of ink labeling and sampling. Be sure to check out their methods at the links above. Other teams may also now choose to share their approaches, so be sure to follow our <a href="https://discord.gg/UtCXDCe4" target="_blank" rel="noopener noreferrer">Discord community</a> for updates. Joining our community also provides access to the CT data and more images under our data agreement, as well as a front-row seat to daily discovery and collaboration!</p><p>To date, our efforts have managed to unroll and read about 5% of the first scroll. Our eminent team of papyrologists has been hard at work and has achieved a preliminary transcription of all the revealed columns. We now know that this scroll is not a duplicate of an existing work; it contains never-before-seen text from antiquity. The papyrology team are preparing to deliver a comprehensive study as soon as they can. You all gave them a lot of work to do! Initial readings already provide glimpses into this philosophical text. From our scholars:</p><p>The general subject of the text is pleasure, which, properly understood, is the highest good in Epicurean philosophy. In these two snippets from two consecutive columns of the scroll, the author is concerned with whether and how the availability of goods, such as food, can affect the pleasure which they provide.</p><p>Do things that are available in lesser quantities afford more pleasure than those available in abundance? Our author thinks not: <em>‚Äúas too in the case of food, we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.‚Äù</em> However, is it easier for us naturally to do without things that are plentiful? <em>‚ÄúSuch questions will be considered frequently.‚Äù</em></p><p>Since this is the end of a scroll, this phrasing may suggest that more is coming in subsequent books of the same work. At the beginning of the first text, a certain Xenophantos is mentioned, perhaps the same man ‚Äî presumably a musician ‚Äî also mentioned by Philodemus in his work <em>On Music</em>.</p><p><a href="https://plato.stanford.edu/entries/philodemus/" target="_blank" rel="noopener noreferrer">Philodemus</a>, of the Epicurean school, is thought to have been the philosopher-in-residence of the villa, working in the small library in which the scrolls were found.</p><p>Initial, rough draft transcriptions:</p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/col-8.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/col-8.png"></a></p><div><pre tabindex="0"><code><span><span>    col. -8, ll. 2-14:</span><br></span><span><span>2   ...]ŒπÃ£ŒºÃ£ŒµŒΩ œÑŒø·Ω∫œ≤Ã£ [œÄŒ±]œÅÃ£[·Ω∞ Œû]ŒµÃ£-</span><br></span><span><span>    ŒΩŒøœÜŒ¨ŒΩœÑœâŒπ œÑŒøÃ£ŒπŒøœçœÑŒøœÖ[œ≤,</span><br></span><span><span>    ·ΩÉ Œ∫Œ±·Ω∂ ·ΩëœÄ‚Äô ·ºÑÃ£ŒªŒªœâŒΩ Œ¥ŒøŒ∫Œµ·øñ</span><br></span><span><span>5   Œ≥Œµ·Ω∑ŒΩŒµœ≤Œ∏Œ±Œπ, œÄŒ±œÅŒ±œÄŒªŒ∑-</span><br></span><span><span>    œ≤·Ω∑œâœ≤ Œ¥Ã£‚Äô ŒøÃ£·ΩêŒ¥·Ω≤ œÄŒ±œÅÃ£‚Äô ·ºëœÑ·Ω≥œÅœâŒπ</span><br></span><span><span>    ·º¥Œ¥ŒπÃ£ŒøŒΩ œÑŒøÃ£·ø¶ Œ¥Ã£ŒøŒ∫Œø·ø¶Ã£ŒΩœÑŒøœ≤Ã£</span><br></span><span><span>    Œµ·º∂ŒΩŒ±Œπ Œ∫Œ±·Ω∂ œÄŒ±œÅ·Ω∞ œÄŒªŒµÃ£·Ω∑-</span><br></span><span><span>    Œøœ≤Ã£ŒπÃ£ŒΩÃ£ ·º•Œ¥ŒπŒøÃ£ŒΩ, ·ºÄŒªŒª‚Äô ·Ω°Ã£œ≤Ã£ Œ∫Œ±·Ω∂</span><br></span><span><span>10  ·ºêÃ£œÄÃ£·Ω∂ œÑ·ø∂ŒΩ Œ≤œÅœâÃ£ŒºÃ£·Ω±œÑÃ£œâŒΩ</span><br></span><span><span>    ŒøÃ£·ΩêÃ£Œ∫ ·º§Œ¥Ã£Œ∑ œÑ·Ω∞ œ≤œÄ·Ω±ŒΩŒπŒ±</span><br></span><span><span>    œÄ·Ω±ŒΩœÑœâœ≤Ã£ Œ∫Œ±·Ω∂ ·º°Œ¥Ã£·Ω∑œâ</span><br></span><span><span>    œÑ·ø∂ŒΩ Œ¥Ã£Œ±œàŒπŒª·ø∂ŒΩÃ£ ŒµÃ£·º∂ŒΩŒ±ŒπÃ£</span><br></span><span><span>14  ŒΩŒøŒº·Ω∑Œ∂Ã£ŒøÃ£ŒºŒµÃ£ŒΩŒá Œø·Ωê Œ≥Ã£·Ω∞œÅÃ£</span><br></span></code></pre></div></div><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/col-7.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/col-7.png"></a></p><div><pre tabindex="0"><code><span><span>    col. -7, ll. 4-10:</span><br></span><span><span>    ŒªÃ£ŒµŒπ œÄŒ±œÅ·Ω∞ œÑ·Ω∞ Œ¥Œ±œàŒπŒª·øÜ.</span><br></span><span><span>5   Œ∏ŒµœâœÅŒ∑Œ∏·Ωµœ≤ŒµœÑŒ±Œπ Œ¥·Ω≤ œÑ·Ω∞</span><br></span><span><span>    œÑŒøŒπŒ±·ø¶Œ∏‚Äô Œø·ΩïœÑœâ{Œπ} œÄŒøŒªÃ£Œª·Ω±-</span><br></span><span><span>    Œ∫Œπœ≤ œÄ·ΩπœÑŒµœÅŒøŒΩ ·ΩÖÃ£œÑŒ±ŒΩ œÄŒ±-</span><br></span><span><span>    œÅ·øÜÕÖ œÑ·Ω∏ Œ¥Œ±œàŒπŒª·Ω≥œ≤œÑŒµœÅŒøŒΩ</span><br></span><span><span>    ·º° œÜ·Ωªœ≤Œπœ≤ ·º•Œ¥ŒπŒøŒΩ ·ºÄœÄŒ±ŒªŒª·Ω±œÑ-</span><br></span><span><span>10  œÑŒµŒπ œÑŒøÃ£·ΩªÃ£œÑÃ£ŒøÃ£œÖÃ£ Œ∫Œ±·Ω∂ œÄ·Ω±ŒªÃ£ŒπÃ£ŒΩÃ£ Ã£ Ã£</span><br></span></code></pre></div></div><p>Later in the scroll:</p><p>In the closing section of the text our author takes a parting shot at his adversaries, who <em>‚Äúhave nothing to say about pleasure, either in general or in particular, when it is a question of definition.‚Äù</em></p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/col-2.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/col-2.png"></a></p><div><pre tabindex="0"><code><span><span>    col. -2, ll. 2-8:</span><br></span><span><span>2   ·ºëÃ£Œ∫·Ω±œ≤œÑŒ∑œ≤ Œ∫œÅŒπœÑŒ∑œÅ·Ω∑œâŒΩ</span><br></span><span><span>    Œ∏ŒµœâœÅŒø·ø¶ŒΩœÑŒ±Œπ. œÄœÅ·Ω∏œ≤ Œ¥·Ω≤</span><br></span><span><span>    Œø·ΩîœÑŒµ Œ∫Œ±Œ∏·ΩπŒªŒøœÖ œÄŒµœÅ·Ω∂</span><br></span><span><span>5   ·º°Œ¥ŒøŒΩ·øÜœ≤ ·ºêœá·ΩπŒΩœÑœâŒΩ œÑŒπ</span><br></span><span><span>    Œª·Ω≥Œ≥ŒµŒπŒΩ Œø·ΩîœÑŒµ œÄŒµœÅ·Ω∂ œÑ·øÜœ≤</span><br></span><span><span>    Œ∫Œ±œÑ·Ω∞ ŒºÃ£·Ω≥Ã£œÅŒøÃ£œ≤Ã£, ·ΩÖÃ£œÑŒµ ·Ω°-</span><br></span><span><span>8   œÅŒπœ≤Œº·Ω≥ŒΩŒøŒΩ œÑŒπ, ·ºÄŒªŒª‚Äô Œø·ΩñŒΩ</span><br></span><span><span>    ‚Ä¶</span><br></span></code></pre></div></div><p>Finally the scroll concludes:</p><p><em>‚Äú‚Ä¶ for we do [not] refrain from questioning some things, but understanding/remembering others. And may it be evident to us to say true things, as they might have often appeared evident!‚Äù</em></p><div><p><a target="_blank" href="https://scrollprize.org/img/grandprize/col-1.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/col-1.png"></a></p><div><pre tabindex="0"><code><span><span>    col. -1, ll. 1-6:</span><br></span><span><span>1   ·Ω∞œÅ ·ºÄœÄÃ£Œµœá·ΩπŒºÃ£ŒµÃ£Œ∏Ã£Œ±Ã£ œÑ·Ω∞</span><br></span><span><span>    Œº·Ω≤ŒΩ Œ∫œÅ·Ω∑ŒΩŒµŒπŒΩ, œÑ·Ω∞ Œ¥·Ω≤</span><br></span><span><span>    Œ∫Œ±œÑ·Ω≥œáŒµŒπŒΩ Œ∫Œ±·Ω∂ ·ºêŒºœÜŒ±·Ω∑</span><br></span><span><span>    ŒΩoŒπŒ∏‚Äô ·º°Œº·øñŒΩ ·ºÄŒªŒ∑Œ∏·øÜ Œª·Ω≥-</span><br></span><span><span>5   Œ≥ŒµŒπŒΩ ·Ω•œ≤œÄŒµœÅ œÄŒøŒªŒª·Ω±Ã£Œ∫Œπœ≤</span><br></span><span><span>    ·ºÇŒΩ ·ºêÃ£ŒºœÜŒ±ŒΩŒµÃ£·Ω∑Œ∑Ã£{Œπ}.</span><br></span></code></pre></div></div><p><a href="https://lsa.umich.edu/classics/people/departmental-faculty/rjanko.html" target="_blank" rel="noopener noreferrer">Richard Janko</a> writes:</p><p>‚ÄúIs the author Epicurus' follower, the philosopher and poet Philodemus, the teacher of Vergil? It seems very likely.</p><p>Is he writing about the effect of music on the hearer, and comparing it to other pleasures like those of food and drink? Quite probably.</p><p>Does this text come from his four-part treatise on music, of which we know Book 4? Quite possibly: the title should soon become available to read.</p><p>Is the Xenophantus who is mentioned the celebrated flute-player, or the man famous in antiquity for being unable to control his laughter, or someone else entirely? So many questions! But improvements to the identification of the ink, which can be expected, will soon answer most of them. I can hardly wait.‚Äù</p><p><a href="https://www.docenti.unina.it/federica.nicolardi" target="_blank" rel="noopener noreferrer">Federica Nicolardi</a> told us:</p><p>‚ÄúEpicureanism says hi, with a text full of music, food, senses, and pleasure!‚Äù</p><p>From <a href="https://www.thebritishacademy.ac.uk/fellows/robert-fowler-FBA/" target="_blank" rel="noopener noreferrer">Bob Fowler</a>:</p><p>‚ÄúLike other Epicureans, he valued pleasure above all - but pleasure rightly understood, not mere indulgence. Living in ancient Rome - a society not known for abstinence - Philodemus could expect to meet with scepticism from his readers.‚Äù</p><p>Scholars might call it a philosophical treatise. But it seems familiar to us, and we can‚Äôt escape the feeling that the first text we‚Äôve uncovered is a 2000-year-old blog post about how to enjoy life. Is Philodemus throwing shade at the stoics in his closing paragraph, asserting that stoicism is an incomplete philosophy because it has ‚Äúnothing to say about pleasure?‚Äù The questions he seems to discuss ‚Äî life‚Äôs pleasures and what makes life worth living ‚Äî are still on our minds today.</p><p>We can expect many more works from Philodemus in the current collection, once we‚Äôre able to scale up this technique. But there could be other text as well ‚Äî an Aristotle dialog, a lost history of Livy, a lost Homeric epic work, a poem from Sappho ‚Äî who knows what treasures are hidden in these lumps of ash.</p><p>And there is the hope of a much bigger library still in the ground, since two levels of the villa remain unexcavated. More about this below!</p><h2 id="how-accurate-are-these-pictures">How accurate are these pictures?<a href="#how-accurate-are-these-pictures" title="Direct link to heading">‚Äã</a></h2><p>Machine learning models are infamous for ‚Äúhallucinating‚Äù: making up text or pictures that look similar to their training data. Similarly, there might be ways for contestants to cheat by making up images themselves, e.g. by embedding those in the model weights. How do we know that that‚Äôs not happening here? There are a couple of answers:</p><ul><li><strong>Technical reproduction.</strong> The Vesuvius Challenge Technical Review Team reproduced the winning submissions manually. We made sure to clearly understand every part of the code, and that when we run it independently we get similar output images. Since all code and training data is now open source, you can do the same!</li><li><strong>Multiple submissions of the same area.</strong> You might have noticed that all submission images above show the same area of the scroll. This is because we released 3d-mapped papyrus sheets within the CT-scan (‚Äúsegments‚Äù) created by our segmentation team, which were then used by all contestants. The resulting output images ‚Äî created by different ML models and training labels ‚Äî have produced extremely similar results. This holds not just for the winners and runner ups, but also for the other submissions that we received.</li><li><strong>Small input/output windows.</strong> The ink detection models are not based on Greek letters, optical character recognition (OCR), or language models. Instead, they independently detect tiny spots of ink in the CT scan, the writing appearing later when these are aggregated. As a result, the text appearing in the images is not the imagined output of a machine learning model, but is instead directly tied to the underlying data in the CT scan.</li></ul><figure><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/tutorials/ink-detection-anim3-dark.jpg"><source src="https://scrollprize.org/img/tutorials/ink-detection-anim3-dark.webm" type="video/webm"><source src="https://scrollprize.org/img/tutorials/ink-detection-anim3-dark.mp4" type="video/mp4"></video><figcaption>The models use small input/output windows. In some cases, the output is even only binary (‚Äúink‚Äù vs ‚Äúno ink‚Äù), as shown in this animation. This makes it extremely unlikely for the model to hallucinate shapes that look like letters.</figcaption></figure><h2 id="how-does-the-unrolling-work">How does the unrolling work?<a href="#how-does-the-unrolling-work" title="Direct link to heading">‚Äã</a></h2><p>Roughly, virtual unwrapping works in <a href="https://scrollprize.org/tutorial1">three steps:</a></p><ol><li><strong>Scanning:</strong> creating a 3D scan of a scroll or fragment using X-ray tomography.</li><li><strong>Segmentation:</strong> tracing the crumpled layers of the rolled papyrus in the 3D scan and then unrolling, or flattening, them.</li><li><strong>Ink Detection:</strong> identifying the inked regions in the flattened segments using a machine learning model.</li></ol><p>These scrolls were scanned at Diamond Light Source, a particle accelerator near Oxford, England. The facility produces a parallel beam of X-rays at high flux, allowing for fast, accurate, and high-resolution imaging. The X-ray photos are turned into a 3D volume of voxels using tomographic reconstruction algorithms, resulting in a stack of slice images.</p><figure><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/grandprize/.jpg"><source src="https://scrollprize.org/img/grandprize/.webm" type="video/webm"><source src="https://scrollprize.org/img/grandprize/scroll1.mp4" type="video/mp4"></video><figcaption>Scrubbing through the slice images of the scroll.</figcaption></figure><p>The next step is to identify individual sheets of papyrus in 3D space. For this we primarily use a tool called <a href="https://scrollprize.org/community_projects#volume-cartographer">Volume Cartographer</a>, created by Seth Parker and others in Brent Seales‚Äô lab, and augmented by our contestants, primarily Julian Schilliger (Grand Prize winner) and Philip Allgaier.</p><p>Volume Cartographer is operated by our team of full-time segmenters: Ben Kyles, David Josey, and Konrad Rosenberg. They use a combination of automatic algorithms and manual adjustments to map out large areas of papyrus. This is still a painstaking process, with lots of room for improvement if we‚Äôre going to segment all the scrolls.</p><figure><video autoplay="" playsinline="" loop="" muted="" poster="https://scrollprize.org/img/tutorials/vc-extrapolation2.jpg"><source src="https://scrollprize.org/img/tutorials/vc-extrapolation2.webm" type="video/webm"><source src="https://scrollprize.org/img/tutorials/vc-extrapolation2.mp4" type="video/mp4"></video><figcaption>Animation showing manual and automatic segmentation in Volume Cartographer.</figcaption></figure><p>Finally, ink detection. Stephen Parsons at Brent‚Äôs lab had <a href="https://uknowledge.uky.edu/cs_etds/138/" target="_blank" rel="noopener noreferrer">shown</a> that Herculaneum ink could theoretically be detected in CT scans, but so far only using smaller fragments ‚Äî detecting ink in the larger scans of complete scrolls had yet to be achieved. For months this part proved elusive, until progress was made on two separate tracks:</p><ol><li><strong>Crackle pattern.</strong> Last summer, Casey Handmer <a href="https://caseyhandmer.wordpress.com/2023/08/05/reading-ancient-scrolls/" target="_blank" rel="noopener noreferrer">discovered</a> a strange pattern of ‚Äúcrackle‚Äù by looking at raw flattened surface volumes. This pattern appeared to form letters. Casey won the First Ink Prize for this monumental discovery and shared it with the community, and a flurry of activity followed.</li></ol><figure><img loading="lazy" src="https://scrollprize.org/img/firstletters/pi1.png"><img loading="lazy" src="https://scrollprize.org/img/firstletters/pi2.png"></figure><p>Luke Farritor (Grand Prize winner), immediately started hunting for more crackle in flattened surface volumes produced by the segmentation team. He then trained a machine learning model on the shapes he found, which led directly to him winning the <a href="https://scrollprize.org/firstletters">First Letters Prize</a> in October.</p><ol start="2"><li><strong>Kaggle competition.</strong> Separately, <a href="https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection" target="_blank" rel="noopener noreferrer">hundreds of teams</a> tried building the best machine learning model for detecting ink in open fragments ‚Äî pieces that had broken off during the physical unrolling process of scrolls, hundreds of years ago. Instead of labeling crackle (which wasn‚Äôt known yet), they had the benefit of ground truth data directly from photos of these fragments.</li></ol><div><div><p><img loading="lazy" src="https://scrollprize.org/img/data/fr1.jpg"></p><figcaption>Photo of Fragment 1</figcaption></div><div><p><img loading="lazy" src="https://scrollprize.org/img/data/ir-fr1.png"></p><figcaption>Aligned infrared</figcaption></div><div><p><img loading="lazy" src="https://scrollprize.org/img/data/inklabels-fr1.png"></p><figcaption>Aligned binary ink labels</figcaption></div></div><p>This resulted in excellent models, but they did not seem to work on the flattened segments which the segmentation team produced. That was, until Youssef Nader (Grand Prize winner) used domain adaptation techniques on them, the start of a technique that ultimately won him the second place First Letters Prize.</p><p>After the success of the First Letters Prize, the Grand Prize seemed within reach. Youssef, Luke, and Julian teamed up, with several other teams putting in strong submissions as well.</p><h2 id="what-did-it-take">What did it take?<a href="#what-did-it-take" title="Direct link to heading">‚Äã</a></h2><p>With the Vesuvius Challenge, we hope not only to solve the problem of reading the Herculaneum Papyri, but also to inspire similar projects. For that, it‚Äôs helpful to know what has contributed to our success in 2023. Here are some things we believe were important:</p><ol><li><strong>An inspiring goal and a clear target.</strong> There are many worthy causes in the world, so it helps that our goal is unusual for a computing competition. It drew more press and donations early on, it attracted an intrinsically motivated community, and it increased our probability of success to begin with (emerging research area =&gt; a higher marginal utility of dollars spent). We‚Äôd love to see more projects that are ‚Äúout there,‚Äù for exactly these reasons!</li></ol><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/banner.jpg"></p><ol start="2"><li><strong>A solid starting point.</strong> The foundation was laid by <a href="https://www2.cs.uky.edu/dri/" target="_blank" rel="noopener noreferrer">Dr. Seales and his team</a>. They spent two decades making the first scroll scans, building <a href="https://scrollprize.org/community_projects#volume-cartographer">Volume Cartographer</a>, demonstrating the <a href="https://www2.cs.uky.edu/dri/the-scroll-from-en-gedi/" target="_blank" rel="noopener noreferrer">first success</a> in virtual unwrapping, and <a href="https://uknowledge.uky.edu/cs_etds/138/" target="_blank" rel="noopener noreferrer">proving</a> that Herculaneum ink can be detected in CT.</li></ol><div><p><img loading="lazy" src="https://scrollprize.org/img/landing/brent1.webp"></p><figcaption>Brent Seales, Seth Parker, and Michael Drakopoulos at the particle accelerator.</figcaption></div><ol start="3"><li><strong>Blending competition and cooperation.</strong> A Grand Prize on its own would suffer from information ‚Äúhoarding‚Äù: no one would share their intermediate work, because others could take it and use it to beat them to the finish line. Without information sharing, the probability of a single team solving all the puzzle pieces to win the Grand Prize would be dramatically lower.</li></ol><p>Instead, we blended competition and cooperation by adding <a href="https://scrollprize.org/winners">‚Äúprogress prizes‚Äù</a> along the way. These were smaller prizes (often in the $1,000-10,000 range) every ~2 months. To win a progress prize, you had to publish your code or research as open source, thereby benefiting the entire community.</p><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/winners1.png"><img loading="lazy" src="https://scrollprize.org/img/grandprize/winners3.png"></p><figcaption>Some of the many prize winners.</figcaption></div><p>Besides ‚Äúleveling up‚Äù the entire community, this had several side benefits. We generated buzz and excitement in the community, which was motivating for everyone. It allowed winners to re-invest their winnings into better equipment, compute time, or even reduced hours at work or study to dedicate more to the competition. And it allowed people to find each other and form teams ‚Äî like we saw with the Grand Prize winners.</p><ol start="4"><li><strong>Hiring an in-house segmentation team.</strong> Every week we asked ourselves: what is the best thing we can do now to maximize the chance that someone wins the Grand Prize? In early summer, this led to the (then somewhat controversial) decision of hiring a full-time team of data labelers to manually trace the papyrus inside the scrolls and open source the flattened segments.</li></ol><p>An alternative was to leave the problem of segmentation to the contestants, or even to award separate prizes for segments, but this had several downsides. First, it‚Äôs hard to judge segment quality before knowing what to look for (we didn‚Äôt have working ink detection yet). Incentivizing segment quantity would automatically penalize quality. Second, labeling work is tedious and time consuming, and turned out to have a long learning curve, so it‚Äôs desirable to guarantee some compensation, which can‚Äôt be done with a prize. Third, the feedback loop with prizes can be pretty long.</p><p>We were not dogmatically attached to just being referees; we were willing to run out onto the field and kick the ball a little. So we did what we thought would maximize success, and for the critical bottleneck of segmentation, that meant hiring a team.</p><div><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/ben-smaller.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/david.jpg"></p><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/konrad-smaller.jpg"></p><figcaption>Our wonderful segmentation team: Ben, David, and Konrad. Also a big shout-out to former team members!</figcaption></div><p>Ultimately, this decision worked out great. It led directly to Casey Handmer‚Äôs <a href="https://caseyhandmer.wordpress.com/2023/08/05/reading-ancient-scrolls/" target="_blank" rel="noopener noreferrer">discovery</a> of the ‚Äúcrackle pattern‚Äù ‚Äî the first directly visible evidence of ink and letters within the complete scrolls. The in-house segmentation expertise also turned out to be invaluable throughout the rest of the competition, discovering areas with potentially high ink signal, and figuring out the intricacies of the structure of the scrolls. And the segmenters worked closely with community contestants, which led to much better segmentation software. It was the best of both worlds!</p><ol start="5"><li><strong>Maximizing surface area for breakthroughs.</strong> Our success was the result of many smaller breakthroughs by a broad group of people. It‚Äôs remarkable how many things had to come together to make this happen. Remove any of these, and we would not have succeeded, at least not within this timeframe.</li></ol><p><img loading="lazy" src="https://scrollprize.org/img/grandprize/steps.png"></p><p>There are many more contributions than we can list here - even ideas and discoveries landing outside the critical path were still important, because a massive search space had to be exhausted to find the ideas that worked. Given the right framework, the collective intelligence of a community like this is very powerful.</p><h2 id="whats-next-announcing-the-2024-vesuvius-challenge-grand-prize">What‚Äôs next? Announcing the 2024 Vesuvius Challenge Grand Prize.<a href="#whats-next-announcing-the-2024-vesuvius-challenge-grand-prize" title="Direct link to heading">‚Äã</a></h2><p>When we started the competition, most of us estimated that we had a less than 30% probability of success within the year. At that point, no letters had yet been discovered inside of a scroll. On top of that, the scrolls had barely been segmented at all. We had doubt as to whether the project could succeed, especially by the deadline we set. Was the ink signal present? Were the scans high-resolution enough? Could the techniques used to identify ink in the fragments be transferred into a scroll? None of this was known at the time. But we knew it was worth trying!</p><p>In Stage 1 of the Vesuvius Challenge, we answered all of these questions, extracting 15 columns of never-before-seen text from inside a lump of carbon. We now have proven techniques for virtually unrolling the papyrus scroll and recognizing ink using machine learning.</p><h3 id="vesuvius-challenge-stage-2">Vesuvius Challenge Stage 2<a href="#vesuvius-challenge-stage-2" title="Direct link to heading">‚Äã</a></h3><p>In 2023 we got from 0% to 5% of a scroll. In 2024 our goal is to go from 5% of one scroll, to 90% of all four scrolls we have scanned, and to lay the foundation to read all 800 scrolls.</p><p>The primary goal for 2024 is to read 90% of the scrolls, and <strong>we will issue the 2024 Grand Prize to the first team that is able to do this</strong>. More details on the exact grand prize judging criteria will be available in March.</p><p>The bottleneck to achieve this milestone is the process of tracing the surface of the papyrus inside the scroll. Today this is extremely manual. It cost us more than $100 per square centimeter in manual labor to produce the text we can read today. At this price, it would cost hundreds of millions or maybe even billions of dollars to segment all of the scrolls. While improvements to our segmentation tools have increased our efficiency, it is still far too manual and expensive. What we need is automation.</p><p>And so our primary goal for stage 2 is to perfect autosegmentation. Done right, this will also allow us to read the most challenging regions within the scroll ‚Äì areas where the scroll was heavily compressed, cracked, delaminated, or otherwise damaged ‚Äì which in many cases our current tools cannot even penetrate.</p><p>In 2023 we were amazed by the community contributions. We loved the competition for the grand prize, which brought out the best in the contestants, but we were also thrilled to see the community collaborate towards intermediate goals. In 2024 we are leaning into that, still offering a grand prize, but allocating even more of the prize pool towards community contributions ‚Äì a pool that will grow as we raise more money.</p><p>We‚Äôre also planning to help speed things along ourselves, balancing prizes and in-house expertise to continue the collaboration that worked so well in 2023. To this end, we‚Äôll hire a small software/ML team, in addition to the full-time segmentation team, who will work in the open with our community to advance the state of the art.</p><p>If you are interested in contributing to our funding, and joining the craziest archeological project in existence, please contact us.</p><h3 id="and-after-that">And after that?<a href="#and-after-that" title="Direct link to heading">‚Äã</a></h3><p>After that, we will scan and read every scroll. We estimate that the scrolls we have in Naples contain more than 16 megabytes of text. Some members of our papyrology team say that revealing this text will be the greatest revolution in the classics since the Renaissance. However it goes, it will certainly be fun to try!</p><p>And as if the prospect of reading hundreds of scrolls isn‚Äôt good enough, there might be an even bigger payoff at the end of all of this (as Nat said on the <a href="https://youtu.be/qcvMjoJdck4?t=646" target="_blank" rel="noopener noreferrer">Dwarkesh podcast</a>: <em>‚Äúthere is gold in this mud‚Äù</em>).</p><p>‚ÄúThe scrolls we have now may be just the beginning. When part of the Villa of the Papyri was cleared in the 1990s, archaeologists realized that the building was much larger than previously thought, with two unexcavated levels. At the very least, these floors likely contain more papyri in cabinets and carrying cases. And it‚Äôs probable that they conceal a far greater treasure.</p><p>We have not yet found the villa‚Äôs main library, which would have contained a much wider range of Greek and Latin literature. That library, with its thousands or even tens of thousands of scrolls, must still be buried. If those texts are discovered, and if even a small fraction can still be read, they will transform our knowledge of classical life and literature on a scale not seen since the Renaissance.‚Äù</p><p>The potential of tens of thousands of scrolls, still buried, waiting to be discovered?! The most exciting days <a href="https://twitter.com/natfriedman/status/1712123310551548222" target="_blank" rel="noopener noreferrer">still lay ahead</a>.</p><p>Read more detail about what comes next in our <a href="https://scrollprize.org/master_plan">Master Plan</a>.</p><p><img loading="lazy" src="https://scrollprize.org/img/landing/rocio-espin-pinar-villa-papyri-small.jpg"></p><h2 id="thank-you">Thank you<a href="#thank-you" title="Direct link to heading">‚Äã</a></h2><p>This couldn‚Äôt have happened without the many, many people who contributed in various ways, and we‚Äôd like to say thanks to all of them:</p><ul><li>Everyone who competed, shared insights, wrote code, made analyses, and brought energy to the project.</li><li>Our adventurous donors, all of whom are private individuals from the tech world, who supported this project when it was not at all clear that there was any chance of success.</li><li>The organizing teams (listed on our homepage): Vesuvius Challenge team, EduceLab team, and Papyrology team.</li><li>Our partners: EduceLab, Institut de France, Diamond Light Source, Biblioteca Nazionale di Napoli, the Getty, and Kaggle ‚Äî and all their respective funders.</li><li>The professional and amateur papyrologists, historians, classicists, and other scholars ‚Äî who helped answer countless questions in Discord.</li><li>The supporting staff on the Vesuvius Challenge side (Sean, Emily, Frank, Lulu), and on the University of Kentucky side (Lindsey, Eric).</li><li>The many contributors to the cause who came before us ‚Äî who did excavations, wrote code, made scans, and built machines out of catgut and pig bladders to try to physically unroll the scrolls.</li><li>And of course the Grand Prize winners!</li></ul><p>Thank you all so much!!</p><p>Now let‚Äôs get on with it and read the rest of the scrolls. The best is yet to come.</p><p><em>Join the winners for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. More to come.</em></p></div></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OnlyFake: A site where ‚Äòneural networks‚Äô churn out fake IDs (141 pts)]]></title>
            <link>https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/</link>
            <guid>39261754</guid>
            <pubDate>Mon, 05 Feb 2024 14:48:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/">https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/</a>, See on <a href="https://news.ycombinator.com/item?id=39261754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p><em>This piece was produced with support from </em><a href="https://thecapitolforum.com/?ref=404media.co"><em><u>The Capitol Forum</u></em></a><em>.&nbsp;</em></p><p>An underground website called OnlyFake is claiming to use ‚Äúneural networks‚Äù to generate realistic looking photos of fake IDs for just $15, radically disrupting the marketplace for fake identities and cybersecurity more generally. This technology, which 404 Media has verified produces fake IDs nearly instantly, could streamline everything from bank fraud to laundering stolen funds.</p><p>In our own tests, OnlyFake created a highly convincing California driver's license, complete with whatever arbitrary name, biographical information, address, expiration date, and signature we wanted. The photo even gives the appearance that the ID card is laying on a fluffy carpet, as if someone has placed it on the floor and snapped a picture, which many sites require for verification purposes. 404 Media then used another fake ID generated by this site to successfully step through the identity verification process on OKX. OKX is a cryptocurrency exchange that has recently <a href="https://www.404media.co/how-a-single-pig-butchering-scam-netted-40-million/"><u>appeared in multiple court records</u></a> because of its use by criminals.</p><p>Rather than painstakingly crafting a fake ID by hand‚Äîa highly skilled criminal profession that can take years to master‚Äîor waiting for a purchased one to arrive in the mail with the risk of interception, OnlyFake lets essentially anyone generate fake IDs in minutes that may seem real enough to bypass various online verification systems. Or at least fool some people.</p><p>‚ÄúThe era of rendering documents using Photoshop is coming to an end,‚Äù an announcement posted to OnlyFake‚Äôs Telegram account reads. As well as ‚Äúneural networks,‚Äù the service claims to use ‚Äúgenerators‚Äù which create up to 20,000 documents a day. The service‚Äôs owner, who goes by the moniker John Wick, told 404 Media that hundreds of documents can be generated at once using data from an Excel table.&nbsp;</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cable Companies, Automakers Try to Derail FTC, FCC Quest to Kill Misleading Fees (187 pts)]]></title>
            <link>https://www.techdirt.com/2024/02/05/cable-companies-automakers-try-to-derail-ftc-fcc-quest-to-kill-misleading-fees/</link>
            <guid>39261511</guid>
            <pubDate>Mon, 05 Feb 2024 14:24:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/02/05/cable-companies-automakers-try-to-derail-ftc-fcc-quest-to-kill-misleading-fees/">https://www.techdirt.com/2024/02/05/cable-companies-automakers-try-to-derail-ftc-fcc-quest-to-kill-misleading-fees/</a>, See on <a href="https://news.ycombinator.com/item?id=39261511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-431331">


<h3>from the <i>this-is-why-we-can't-have-nice-things</i> dept</h3>

<p>For decades now, airlines, hotels, cable companies, banks and a long list of other companies have bilked U.S. consumers out of billions of dollars annually via bullshit fees that unfairly jack up the advertised price of service. More interesting perhaps is the fact that it it took until 2023 for a U.S. federal regulator to even ponder the idea that <em>this was perhaps bad and could or should be stopped</em>.</p>
<p>Last year, the FTC announced it would be cracking down on such fees. That included a <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/P204800%20Auto%20Rule%20NPRM.pdf">126 page proposal</a> aimed at the auto industry‚Äôs use of ‚Äúadministrative fees,‚Äù document fees, and other markups used to fatten up the price consumers pay for new or used cars. </p>
<p>Not surprisingly the auto industry didn‚Äôt much like that, and has been fighting the effort in court. While the rules were supposed to go into effect on July 30, the National Automobile Dealers Association (NADA)&nbsp;and Texas Automobile Dealers Association filed a challenge with the notoriously wacky (and corporate friendly) Fifth Circuit Court of Appeals, which has <a href="https://jalopnik.com/dealers-successfully-force-the-feds-to-temporarily-back-1851178875">suspended the FTC‚Äôs plan upon review</a>.</p>
<p>As with most such challenges, the automakers are trying to claim the FTC doesn‚Äôt have the authority to implement such rules, despite the agency‚Äôs authority to police ‚Äúunfair and deceptive‚Äù behavior being very clear under the FTC Act:</p>
<blockquote>
<p><em>‚ÄúThe dealership groups, in the petition to the Fifth Circuit, called it ‚Äúan abuse of discretion‚Äù and seek the court to block its implementation. The FTC maintains that the rule ‚Äúdoes not impose substantial costs, if any‚Äù on law-abiding dealerships, and instead simply guarantees a more even playing field for both dealerships and consumers by eliminating junk fees and hidden costs.‚Äù</em></p>
</blockquote>
<p>Automakers aren‚Äôt the only well funded corporations fighting the FTC‚Äôs effort. The cable industry is also hard at work fighting <a href="https://www.techdirt.com/2024/01/26/cable-giants-insist-that-forcing-them-to-make-cancellations-easier-violates-their-first-amendment-rights/">FTC</a> and <a href="https://www.techdirt.com/2023/12/21/the-gop-is-very-mad-because-the-fcc-wants-to-ban-shitty-cable-early-termination-fees/">FCC</a> plans to crack down on the billions of dollars cable companies make off of junk fees, again by claiming the agencies don‚Äôt have the legal authority to do their jobs. </p>
<p><strong>Here‚Äôs the thing</strong>: the FTC and FCC aren‚Äôt doing anything crazy here. They‚Äôre doing the <em>absolute bare minimum</em> when it comes to policing obnoxious, misleading fees, often used to help companies falsely advertise a lower price that <em>doesn‚Äôt actually exist</em>. And even here you can see how such efforts face an unrelenting legal and lobbying assault by companies with near-unlimited legal and lobbying budgets. </p>
<p>Now remember that the corrupt Supreme Court is on the precipice of <a href="https://www.americanprogress.org/article/supreme-court-appears-poised-to-overrule-chevron-deference-in-judicial-power-grab/">dismantling Chevron</a>, a cornerstone of regulatory law as we know it, effectively undermining most existing independent regulatory authority. Once Chevron is dead, every last regulatory decision corporations don‚Äôt like will be challenged in court, and it will be left to a (potentially corrupt) judge to determine <a href="https://www.edf.org/media/supreme-court-will-hear-second-case-challenging-chevron-doctrine">what regulators can or can‚Äôt do</a>.</p>
<p>Picture this fight over fees. Now apply it to pretty much <strong>any</strong> regulatory effort to do <strong>anything</strong>. Then apply the assumption that corporations will win most of the time thanks to corrupt, unelected judges (often with lifetime appointments), and you‚Äôll begin to see the full picture. </p>
<p>As it stands, Congress passes a (often vague and badly written) law, and it‚Äôs up to regulators with very tailored knowledge (on subjects ranging from wireless spectrum management to emission controls) to implement useful rules within the confines of the law. The axing of Chevron eliminates much of that independent authority, meaning they can‚Äôt do anything not <em>very specifically outlined</em> by Congress.</p>
<p>The <a href="https://www.nytimes.com/2024/01/21/opinion/supreme-court-chevron.html">flimsy underlying justification</a> for killing Chevron is that it rebalances the constitutional order, shifting power away from the Executive and back to Congress. In reality, corporations captured Congress long ago. They know it‚Äôs hard to get Congress to reform much of anything. Now they‚Äôre aiming to finish the job by all-but lobotomizing what‚Äôs left of regulatory independence (<a href="https://www.techdirt.com/2023/09/26/biden-fcc-prepares-to-restore-net-neutrality-but-the-details-will-matter/">net neutrality was a lovely example</a>). </p>
<p>The goal is the final beheading of what‚Äôs left of the already undermanned and underfunded federal regulatory state. It‚Äôs the final killing blow of regulatory power at the hands of U.S. corruption, dressed up as a good faith effort to restore constitutional balance and free unfairly burdened corporations from the ‚Äútyranny‚Äù of already fairly feckless U.S. corporate oversight.</p>
<p>In reality, the axing of Chevron is going to result in gridlock in the courts, as every last regulatory decision corporations don‚Äôt like are challenged by corporations under the claim regulators have no authority. That‚Äôs going to result not only in the dismantling of existing consumer protections, environmental reforms, and public safety initiatives, but will chill any efforts to craft any new reforms.</p>
<p>That will shift most consumer protection to the handful of states that actually still care about such things. At that point, with federal regulatory oversight dead, corporations can shift all of their attention and resources toward undermining state regulatory power. Again, the goal here isn‚Äôt a good faith concern about free markets or constitutional balance, it‚Äôs <em>completely unchecked corporate power</em>. </p>
<p>The goal is handcuffing regulators‚Äô hands behind their backs as the U.S. is scrapped and sold for parts out the back door, by men who can retreat to their private islands once the girders give way and the roof begins to collapse on the rest of us. Consumer protection, environmental law, election law, and public safety are facing an historic existential threat. </p>
<p>I don‚Äôt think most people really understand the scope and scale of what‚Äôs coming down the road once Chevron is dismantled. And I don‚Äôt expect the broken ‚Äúboth sides,‚Äù billionaire-owned U.S. press will make that threat clear to readers. </p>
<p>But I do think that the full impact of the Supreme Court‚Äôs looming decision will be painfully obvious to U.S. residents in the decade to come. At which point current debates ‚Äî like the auto industry‚Äôs attempt to stop the FTC from policing predatory fees ‚Äî will seem downright adorable by comparison. </p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/automakers/" rel="tag">automakers</a>, <a href="https://www.techdirt.com/tag/cable/" rel="tag">cable</a>, <a href="https://www.techdirt.com/tag/cable-tv/" rel="tag">cable tv</a>, <a href="https://www.techdirt.com/tag/chevron/" rel="tag">chevron</a>, <a href="https://www.techdirt.com/tag/consumer-protection/" rel="tag">consumer protection</a>, <a href="https://www.techdirt.com/tag/consumers/" rel="tag">consumers</a>, <a href="https://www.techdirt.com/tag/fcc/" rel="tag">fcc</a>, <a href="https://www.techdirt.com/tag/ftc/" rel="tag">ftc</a>, <a href="https://www.techdirt.com/tag/junk-fees/" rel="tag">junk fees</a>, <a href="https://www.techdirt.com/tag/regulations/" rel="tag">regulations</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Natural-SQL-7B, a strong text-to-SQL model (297 pts)]]></title>
            <link>https://github.com/cfahlgren1/natural-sql</link>
            <guid>39261486</guid>
            <pubDate>Mon, 05 Feb 2024 14:22:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cfahlgren1/natural-sql">https://github.com/cfahlgren1/natural-sql</a>, See on <a href="https://news.ycombinator.com/item?id=39261486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:cfahlgren1/natural-sql" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="VLq9ZN2Xvxc37ptCWJsHBcPdRp6oXwN4OF5z5kBib6PGhzjJE--c5iLo85VE0TYkmc69qbGv5al9vR1chVVKqA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="cfahlgren1/natural-sql" data-current-org="" data-current-owner="cfahlgren1" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=Awv%2BH1eeFDEluzI%2BWyTMhmwJE219g1zxabJKvN9McQCu2%2FXC%2FxMppyZ8QVvhHE0sxtKr%2BWlijCe7L5vq3FpexBDmUBHQYEiwyBEdEzneZi%2FFDkIYjpEtXjn3ewirX1ZhKMBc2ZzzC6XHXxNk2iY2hjju6Y362KOZNbkoEjTU6yVHT3HDDHQT8Jzt4BVZ5NRD9gROaQ5LpG62R4wbpVD1s3ZeqrMj0Qmwe4Qk5i6YA%2Fhsrv9J3PGQMc4FRVlTfURQOUtHaEg6pFfKDoNz2jZTqLRyXem8L%2BAUDKDkmtzGEH6v0tih1uRYzutZiIdo8zvfBHUCiPakCbCcIZK0TQwHc7%2Bvm1mmDOPJbNzwDNpB%2FpNSRjwvIX0F0JWYmP252V5kTCI%2BVo65yS3%2ByGCyF0JvD%2FadTLb2anw0lnex3thjFBT%2BuRUR%2BR4HysE6X8ho4VGH6TaA9Ch1tuuOx%2BxRk4A4m%2B2xE0jgccriz8FBvwfmv%2BCh%2Bt1ir3rT3I3uz3YJ2d1HFArImE%2FJaw%2Fqh2iIf2eb3dFTZm%2BSMQ%3D%3D--a3lHsGjnHQnceYWg--cavlJYPChnBo98wStvUcoQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=cfahlgren1%2Fnatural-sql" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/cfahlgren1/natural-sql&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="cf0bee28d4a07eb96a607acb4bb09b6c0e86b51271bc67b9f7e4f1a9233c0793" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing Finds More Misdrilled Holes on 737 in Latest Setback (369 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-02-05/boeing-needs-to-fix-faulty-rivet-holes-on-50-undelivered-737s</link>
            <guid>39261482</guid>
            <pubDate>Mon, 05 Feb 2024 14:22:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-02-05/boeing-needs-to-fix-faulty-rivet-holes-on-50-undelivered-737s">https://www.bloomberg.com/news/articles/2024-02-05/boeing-needs-to-fix-faulty-rivet-holes-on-50-undelivered-737s</a>, See on <a href="https://news.ycombinator.com/item?id=39261482">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Programming in 1969 (148 pts)]]></title>
            <link>https://www.ilikebigbits.com/2019_07_08_programming_in_1969.html</link>
            <guid>39261321</guid>
            <pubDate>Mon, 05 Feb 2024 14:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ilikebigbits.com/2019_07_08_programming_in_1969.html">https://www.ilikebigbits.com/2019_07_08_programming_in_1969.html</a>, See on <a href="https://news.ycombinator.com/item?id=39261321">Hacker News</a></p>
<div id="readability-page-1" class="page">


<title>Programming in 1969</title>
# Programming in 1969
<center>An interview with a pioneer (my mum)</center>

<p id="date">July 8, 2019</p>

![Punch cards [(source)](https://commons.wikimedia.org/wiki/File:Box_for_punch_cards.jpg)](2019_07_08_programming_1969/punch_card_box.jpg width="480")

!!! Note
    I conducted this interview with my mother, Marianne Ernerfeldt, in December 2018.
    This is a slightly abridged English translation. The full interview can be [read in Swedish here](2019_07_08_programmering_1969.html).


## Why did you want to become a programmer?
I decided to become a programmer 1965-'66. I had read an article with a picture of a flowchart and I thought "this would suit me". When I graduated high school in 1967 there were no universities teaching programming, but there was a 6-month course in Solna that would become a 12-month course, and it was eligible for student loans. So I applied for that.

At the same time SJ (the Swedish state railway company, then a monopoly) advertised for a trainee program with a one year paid training program where you got to learn all the different parts of the SJ operations. SJ had a computer division, so I applied for the SJ program too with the hope of maybe ending up there.

However, SJ ended up with 700 applicants for 50 positions, so there was a tough selection process with various tests. And I got in! So because I needed the salary to get my own apartment, I accepted.

Incidentally, the SJ management was quite unhappy when they found out that the trainee program brochures had been sent out to both male *and female* students! There weren't many women who got accepted into the program, but we were a few.

During the training we went around to all divisions of SJ and learned about everything from the trains and rails to how the communications worked (SJ had its own electricity and phone lines!). After a year of that I got a job, but it was a boring job. Finally in 1969 I heard that SJ was starting an internal training program for programming, so I applied for that. After more tests I and three others started the programming training in 1969. We were two girls and two guys.

![My reference for IBM System/370 from 1976. To the right I have written in √Ö√Ñ√ñ (Dec. 5B, 7B and 7C), because the Swedish letters were not part of EBCDIC.](2019_07_08_programming_1969/ibm_370_reference.jpg)


## What was the training like?
First we visited the SJ computer division and got a rundown of what computers are etc. Then we took classes at IBM who had an "training machine" in a huge building in Stockholm. We were maybe 50-100 people in the same class, but we were split up so that we were eight people in each room. There we watched two TV screens at the front of the classroom. The teacher and his blackboard were broadcast on the screens from another room. Each teacher had maybe ten rooms with students, and each room could ask questions using a microphone and call attention using a button. It was super modern!

First we learned a bit about IBM OS, and then we learned PL/I which was IBM's own programming language. It was a more modern version of Cobol with features that Cobol did not yet have (but would get later), like making tables and queries. So PL/I was a much better language back then and much simpler: you could write the code using English words, `DO WHILE` etc. A really nice programming language!

It was the government agencies that were at the forefront of data processing in Sweden. Banks and others came far behind. So at the IBM courses it was mostly people from other agencies, but SJ was at the forefront.

After the first IBM course I went back to SJ to do my first practice programs. The four of us made a dating program where you would input men and women and their traits, and then generate a good matching between them with an algorithm of our own invention. And after that we started writing production code!

Later I took more courses, for instance I learned assembler the same way. So my education was really a week here and a class there, and then we had a supervisor at work that helped us.

![My stencil for drawing flowcharts. Used to visualize how the data would flow and in which order things were to happen.](2019_07_08_programming_1969/flowchart_2.jpg width="480")


## What was your job like?
First we would draw flowcharts and then we would write the code using a pencil. We then handed the code to the puncher unit where the code would be punched onto punch cards. The punch cards had 80 columns ‚Äì 72 for the program and 8 for sequencing ‚Äì so each line of code could be at most 72 characters wide.

You had to write the code clearly so that the women operating the punchers could read it. After a few years as SJ we got someone dedicated to reading our code, and that helped a lot. Otherwise they would mostly punch data cards: time reports from SJ, how far each train carriage had traveled (so they could get called in for service), etc. The punch machine looked like a regular typewriter that would punch holes in the cards. Above each column it would also type the letter in clear text.

We also used to serve cake on punch cards, so they were quite versatile.

When I first started, the programs were small, but later they could be several meter-long boxes of cards. Each line of code became one punch card. So one instruction per line and card. So the puncher unit would return the program (thousands of cards) to us. We would also have to create "control cards" which encoded whether the punch cards were to be compiled or executed, and what language it was etc. The control cards had a separate color. The first card was a work card with my name on it, so they knew whom to return everything to.

We put the punch card boxes on a special table. The operators came wearing their white coats and took the boxes and ran the programs.

Sometimes we only got one run per day, because we programmers had the lowest priority in the machine hall. So we had to work on several programs simultaneously to keep busy.

Finally the cards were returned together with "pajama paper" containing lists with error codes and line numbers.

![Pajama paper](2019_07_08_programming_1969/pyjamaspapper.jpg width="480")

We had access to a couple of hole punches so we could make minor corrections ourselves.

Then we had to create test files and see if the program produced the expected result. If not you would sit and "desktop test" (think with pen and paper) and try to figure "what the hell went wrong?". So it could take quite a while to get a program right.

We had several machines. We had IBM 360 from the beginning as well as some even older machines. Later on we got IBM 370.

Towards the end of the 70's we got terminals. We never had our own terminals, but shared a terminal room. We had to fight over terminal time when we wanted to make changes to a program. The program would flash up on the screen, and we could modify it. We had Alfaskop terminals in yellow and brown. I never got my own terminal before quitting SJ in 1979.

![Alfaskop 3700 [(source)](http://www.veteranklubbenalfa.se/veteran/bildarkiv/70330006.htm)](2019_07_08_programming_1969/alfaskop_3700.jpg)


## Tell me about your colleagues
The computer division at SJ had around 40 programmers and system engineers. All my colleagues were, like me, trained in-house, with a few exceptions: there were a few people the same age as me who had gone the 6 month course in Solna I mentioned earlier. But otherwise there was no other way to learn this ‚Äì it was a brand new profession! Some colleagues used to be engine drivers! Most did not even have a high school diploma.

The system engineers worked mostly with specifications, what the inputs and outputs of the programs were to be etc. As programmers, we were the problem solvers, making flowcharts and figuring out how to solve the task.

There were around 10 machine operators in the machine hall. They wore white coats and handled the tape storage, disks and fed the punch cards. We were rarely allowed to enter the inner sanctum of the machine hall. The entrance had a "Closed Shop" sign. The machine hall was big. The earlier machines (IBM 1400) took up 10-20 m¬≤, but later machines were small as refrigerators.

The punch unit was made up of 50 young women. If there were any visits to the computer section from other parts of SJ it was always the punch unit that was the most interesting, as most people at SJ were men!

Of the 40 programmers we were 5 or 6 women. I was part of the young gang, but most programmers were around 10 years older than me (I was born in 1947). Towards the end of the 1970's we got a few new recruits that had done 12-month training courses.

Before I started I met Solveig who worked at the SJ computer division. She told me all doors had signs saying "Miss X" or "Mrs. X", but the guys' doors had no corresponding information about marital status. The women had been so pissed off by this that they had unscrewed the signs. So when I started they just looked at me and said "I guess you don't want a Miss/Mrs either?". "No thanks!", I said.

## What kind of things did you do?
In the spring of 1969 ‚Äì before I started ‚Äì the SJ online booking was launched, with 24/7 uptime. It was extremely advanced for its time, and written entirely in assembler. This was one thing where SJ were really outstanding ‚Äì there was no other company in Sweden that even came close to us. I was very lucky to get my education at a company that was such a trail blazer!

We created the programs, and once they were completed and tested we handed them off. Others were responsible for maintaining them, we just wrote new ones! Mostly it was programs that gathered statistics about the operations (e.g. payroll), and then those programs would be run at regular intervals (e.g. every month).

In 1979, after ten years at SJ, I quit to start working in the bank sector instead.

![Marianne at her desk at SJ](2019_07_08_programming_1969/marianne_sj.jpg width="480")



<!-- Markdeep: -->

<!-- Markdeep: -->
</div>]]></description>
        </item>
    </channel>
</rss>