<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 29 Apr 2025 07:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[LibreLingo – FOSS Alternative to Duolingo (106 pts)]]></title>
            <link>https://librelingo.app</link>
            <guid>43829035</guid>
            <pubDate>Tue, 29 Apr 2025 05:45:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://librelingo.app">https://librelingo.app</a>, See on <a href="https://news.ycombinator.com/item?id=43829035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="LibreLingo Mascot" src="https://librelingo.app/images/mascot-jetpack-noshadow.svg" data-test="mascot-jetpack"> </p> <p><h2><span data-tkey="index.subtitle">an experiment to create a community-driven language-learning platform</span></h2> </p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowledge-based society, my ass (160 pts)]]></title>
            <link>https://mihaiolteanu.me/knowledge-based-society-my-ass</link>
            <guid>43828713</guid>
            <pubDate>Tue, 29 Apr 2025 04:33:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mihaiolteanu.me/knowledge-based-society-my-ass">https://mihaiolteanu.me/knowledge-based-society-my-ass</a>, See on <a href="https://news.ycombinator.com/item?id=43828713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="contents">

            

            <p>
            Right after I get admitted, I inform Professor that I also have a full-time
            job. He insists that we must start working right away. I quit as a result and
            instantly breathe a refined air. I am now a scientist! A week later I approach
            Professor and let him know I'm ready for work.
            </p>

            <p>
            "Ready for what?" he greets me as though our previous conversation didn't
            happen. I remind him that he's my PhD supervisor and that, at his proposal, we
            are studying the effects of electromagnetic fields on patients with carotid
            stent implants. "There is nothing for you to do at the University, you can
            stay home for now," he tells me. Is he really serious? Does he want me to do
            research from bed? I insist on reading materials related to our field of
            research. I want to start right away. But he can't recommend any.
            </p>

            <p>
            My first day of research is over. It's autumn 2009. I spend the following days
            of my academic life oversleeping and strolling the city parks. I actually
            enjoy this newfound freedom from the alarm clock. I think, not without a
            certain longing, of my former factory colleagues. How we used to laugh at the
            stupidest of things, how it all felt like a big family. But I have a new life
            now. An intellectual one.
            </p>

            <p>
            A few weeks go by. No word from Professor. It's exhausting to conduct research
            like this. I need some color. I approach Professor again and ask for basic
            research equipment, "I need an office, Professor," I begin, and, after a short
            while, I raise my stakes, "And a computer, too!"  I've gone too
            far. "Everybody is happy around here, except you!!!" he snaps at me. I get a
            feeling that I'm going nowhere with Professor.
            </p>

            <p>
            I approach the Head of Department. The Head listens carefully for my
            complaints and kindly informs me he doesn't mingle in Professor's business. It
            is up to my advisor to decide where the resources are allocated within his
            team. A nice way of deflecting responsibility.
            </p>

            <p>
            The Faculty's Dean doesn't give a damn either but I think he wants to avoid
            even more troubles seeing that I'm so stubborn. I soon receive an email from
            Professor as a result. He decides to offer me an office and a computer. Two
            months wasted. Even so, I celebrate my first academic victory.
            </p>

            <p>
            "Grab a computer and follow me," Professor instructs me a few days later. I
            can barely hide my enthusiasm. We take the stairs to the first floor. Then
            ground floor. Then basement. "Almost there," I hear Professor in the
            darkness. After two more turns he opens a big door and hands me over the
            keys. My office is a rather spacious but austere room in the University's
            basement. My initial enthusiasm is fading. There's a simple desk with a basic
            chair at one end and a small, too high to reach window at the other. The walls
            are immaculately white. A hospital-style metal locker where Professor keeps his
            valuables under key completes the picture. 
            </p>

            <p>
            "Doctoral Studies in Engineering Sciences for Developing the Knowledge-Based
            Society" is the name of our project. It pays me, and approximately one hundred
            other colleagues of mine, all PhD candidates, our €500/month scholarships, or
            about the average wage. It's one project from among the four thousand projects
            sponsored by the European Union's "Operational Program for Human Resources
            Development." This grandiose program, with an available budget of €5 billion,
            aims to "develop the human capital and increase competitiveness by bringing
            education and life-long learning in sync with a modern, flexible and inclusive
            labor market and increase future opportunities for 1.650.000 people." Yes,
            those are millions, 15.000 of which are to become PhD students! The Government
            says so, I it as fact.
            </p>

            <p>
            For my part, I have to publish at least three scientific papers, present my
            research at one international conference and successfully defend my thesis in
            public. I have exactly three years at my disposal. If I fail, I have to return
            my scholarship in full. It's also up to me to rejoin the labor market and take
            care of my future, possibly as a teaching assistant here, at the
            University. So I take things seriously and go to work each morning. I learn
            and labor as hard as I can.
            </p>

            <p>
            I begin with the documentation phase and I read, among others, a very detailed
            series of experiments: human subjects placed in anechoic chambers with all
            kinds of electromagnetic fields directed at them. They measure changes in
            sweat rate, breathing rate, exhaled humidity, body temperatures, blood
            pressure and everything one can imagine. They try to figure out how the body
            responds and adapts to such an external stimulus.
            </p>

            <p>
            I, for my side, have to see what happens inside the human neck artery when an
            implanted stent heats up under the influence of electromagnetic fields. How
            does the body react and compensate for such a temperature increase, if there
            is one? I have things to discover. But I also have zero lab equipment. Not
            even a digital thermometer, let alone medical equipment of the kind I would
            need. The whole medical engineering's lab, the one I took my computer from, is
            a room twice the size of my basement with ten desktop computers in it, a
            blackboard, a small window blocked by another building and an extra door for a
            special room: Professor's own office.
            </p>

            <p>
            Critically, I do not even get to see or touch a real stent. We don't have
            any. There are no interactions with patients, no collaboration with doctors
            and no conversations with other engineers from our University. I'm alone in my
            office. I'm not sure what people do around here. When the whole Department
            gathers around, I hear professors complaining about "kids these days" but zero
            technical discussions and hardly any interest in scientific topics. We are
            one-man teams, each working in their only little basements, so to speak.
            </p>

            <p>
            Professor reassures me that computer simulations are enough for our study. So
            I try to find software licenses plus realistic computer models for my stents
            and human heads. They all cost money and are hard to find. To develop them
            from scratch is outside my specialty. Ideally, I should understand a bit of
            human biology, too, but that's again outside my specialty. I wonder at this
            point if I actually have a specialty. What makes me qualified to approach
            these issues? Why would my "discoveries", born out of such meager
            possibilities, have any relevance for science?
            </p>

            <p>
            I don't lack motivation, though. I try to get a license for the €20k per year
            software we're using. It proves to be another catacombic adventure. The
            company offers two free licenses per public institution. I ask Professor for a
            license, but "There aren't any left," he informs me. "Don't we have two?" I
            insist. "Well, yes, but one license is on my laptop, which I always carry with
            me, and the other is on my office computer," he replies. I ask permission to
            his office to run some simulations from time to time, but "No, my office is
            closed and only I have the key." I conclude Professor has a terrible fondness
            for locks and keys. I drop it. I'm not sure what he does with two
            licenses. Maybe he sells them on the black market? Maybe Professor is a
            gangster? Who knows.
            </p>

            <p>
            One of my colleagues who is pursuing his PhD in the same Department under a
            different professor and a similar area of research, with whom I only cross
            paths when our blood pressure runs too high, happens to also work for a public
            institution. He applies for the two free licenses and is generous enough to
            offer me one.
            </p>

            <p>
            Another victory. But I'm fed up with these victories. It's exhausting to fight
            all these absurd battles. My time is running out. I have to write some papers
            soon. I accept my fate. I accept I'm not gonna be a scientist the way I've
            imagined more than a year ago. I don't see any future for me here at the
            University. As a result, I simplify things tremendously. I draw a big sphere
            and pretend it's a human head, I place a long metallic cylinder inside it and
            pretend it's a real stent and I place a simple antenna close by. Anything more
            complicated than this crashes my toy computer. I soon realize that I play
            scientist like kids play cop with water pistols.
            </p>

            <p>
            I get to publish my first paper in this way. I'm actually quite proud of it,
            given the circumstances. I actually start to enjoy writing. I put down my
            colleague as a co-author as a thank you for lending me the license. We've
            learned this trick from the professors who do it all the time with their
            books, papers and conferences. They are required, just as we are, to publish
            and look active in the community per their contract with the University.
            </p>
            
            <p>
            Out of curiosity, I start reading our school's newspaper, as my colleague
            calls our University's scientific journal. I soon spot inconsistencies. The
            wording is in plain, boring language with long introductions repeating the
            same generalities and facts known to all. But the style changes unexpectedly
            sometimes. I search these peculiar phrases online and my intuition is
            confirmed. Unacknowledged commandeering of intellectual labor via
            indiscriminate copy and paste practices. Plagiarism, in short. I find dozens
            of such instances. I see the name of our Head in there, too. I try to raise
            awareness for a month or two. Nobody gives a damn.
            </p><p>

            I stop reading the school's newspaper and concentrate on publishing my other
            papers instead. They are nothing more than variations on the first paper with
            different titles and different pictures. I let my computer run overnight and
            invent slightly different simulation scenarios and I underline different
            aspects of my results in each paper. After this, I take a more relaxed
            approach regarding my scientific pursuits, enjoy the show around me
            instead and stop giving a damn about Professor from now on.
            </p>
            
            <p>
            I notice the Head is emphasizing the "academic dress code" all the time. He
            even publishes an official Department guideline on this topic pressing us all
            to read it. I notice professors are always addressing each other formally even
            in informal settings, though they've been acquainted for years. This title
            caries great importance here. I myself make a blunder in this respect when I
            visit Professor's office one day for some official papers. I ask if he's
            around but I refer to him by his family name only. I get admonished for
            skipping the "professor" part. I apologies, add the missing title and address
            the question again. "No, Professor is not here!" comes the reply abruptly.
            </p>

            <p>
            Our Head both informs and threatens us, "Per the Department guidelines, every
            PhD candidate is required to teach for one semester. Find yourselves a seminar
            or a lab or I'll pick one for you." It so happens that I get friendly with an
            electronics department's professor. He asks me to be his teaching assistant. I
            inform the Head with great pleasure about this development and he, in turn,
            informs me with great satisfaction that "I do not give this position to PhD
            candidates." I insist, but in vain. I get used to insisting in vain. I get
            used to failing to figure out how this whole clusterfuck works. One colleague
            is appointed to teach C++ by the Head. "You know C++?" I ask enthusiastically,
            as I am looking to become a software engineer myself at this point. "I don't,"
            she informs me, "but there's enough time until Monday to learn it." It's
            Friday, the last day of my teaching career.
            </p>

            <p>
            Professor becomes my hero for a short time during a Department meeting. He
            insists that the design of high-voltage power lines is not actually a subject
            for his medical students. He wants more biology and medical related courses,
            instead. I truly believe in his vision. My mouth is wide open. But the Head
            again masterfully defends his position insisting on the necessity of assigning
            the minimum required number of hours per semester to each member of our
            Department, per the University guidelines. Nobody backs up my hero, not even
            he himself. The next topic on the agenda is the training of all our staff in
            the arts of digital blackboards "to help improve the teaching experience."
            </p>

            <p>
            I'm sinfully enjoying myself. What else do they do around here? Mrs. S. is our
            Department's team assistant. She's near retirement age and lives up in the
            attic. We visit her monthly to physically sign our presence in the attendance
            register. Sometimes she scolds us for signing in the wrong place, "That was a
            public holiday! You didn't work then, did you?!" There is no "Sir" nor
            "professor" with her. We are inhabiting a prestigious institution of higher
            learning, otherwise she would certainly call us morons. I'm wondering at the
            inefficiency on relying on handwritten notebooks for timekeeping. This
            Technical University has a Computer Science department, after all. But things
            are as they should be around here. There are many advantages to the analog
            methods. For instance, we avoid software bugs so this method is more precise,
            it fosters social interactions so it is more humane, we avoid proprietary
            software so users have complete control to modify the source code. We turn up
            once a month, sign and then we're free to do whatever. The Professor has given
            me the correct advice on that first day.
            </p>

            <p>
            The only constant human presence in the whole building during the warm summer
            days is the cleaning lady. I befriend her and we talk each morning. She
            provides me with paper towels and liquid soap for "When you might need it."
            Summer is vacation for both students and teachers, after all. From time to
            time I meet a stray professor in the hallways and they tell me I do a good
            job, always working, always studying, always present. Then, they excuses
            themselves with "I have to change my car's windshield" and other such
            important matters and then disappear for days or weeks on end.
            </p>

            <p>
            There's a big park with a lake nearby and a small river passes just behind the
            building. I often take small brakes from my academic life and stroll
            aimlessly. I sometimes watch the little fishes from the nearby bridge
            gathering in the shade of the willow trees. A kid approaches me one day, "Did
            you see the big one?" We chat a little. That's how I spend my
            days.
            </p>

            <p>
            With three months left, I send Professor my thesis. Days later, he warmly
            congratulates me, "You are an embarrassment to our city!" I stand
            alarmed. "Yes, you are ruining the prestige of our University!" I move closer.
            He points out a paragraph in my thesis where "almost impossible" is heavily
            underlined in red. "Something is either possible or impossible," he mocks me
            with a noticeable grin on his face. I update the offending sentence. I also
            fix a few typos in the following week and rephrase some paragraphs which were
            not to his liking. He eventually approves it. I present it in front of the
            whole Department, the last step before facing the official commission. It gets
            approved.
            </p>

            <p>
            My celebration is cut short a few days later. For some reason, it is of the
            utmost importance to have an actual, real-life experiment to confirm our
            theoretical results. "We can't present a theoretical thesis, we're a Technical
            University," Professor accuses me. I actually agree with him, though I have no
            soul left in this endeavor. How did he come up with this idea? I don't
            know. He probably got admonished by some higher-up. It was fine without it,
            the Department approved it, the Head approved it, it was ready for
            defending. Now it isn't. I shrug and accept it as another fact I can't
            understand nor influence.
            </p>

            <p>
            Professor finds a public institution to lend us their watermelon-sized
            anechoic chamber for two hours. We visit the supermarket one morning to buy
            pork chops for the human head. I want to bring to Professor's attention that
            we're studying a dynamic system and not dead meat. But it's autumn 2012
            already and the parks are in full color. It's way too late for any dialogue. I
            pull out a small plastic bag with a few miniature temperature sensors I bought
            the other day. Professor glues them to a metallic cylinder and inserts it in
            "the head." I see Professor was inspired by my way of handling the lack of
            real stents. I think it is a nail or wire of some sort but I'm not
            sure. Professor handles all the "sensitive equipment" himself. I take pictures
            and write down the results in a notebook. For the next two hours we gather
            temperature readings. I publish a paper with our findings shortly after,
            attach his name to it, update my thesis and everything is good again. I start
            to develop a faint feeling that I sleep better at night when I play along and
            nod approvingly to things I don't actually agree with instead of being
            pigheaded.
            </p>

            <p>
            The final day is approaching. Mrs. B., from the Department of Doctoral
            Studies, informs me that I personally have to prepare and bring in food,
            drinks and coffee for the commission when I defend my thesis. I refuse. She
            insists. I point out that the University charges €1000 per student for the
            final show, that each member of the commission is actually getting paid for
            their trouble and that all these expenses plus transport and accommodation are
            already sponsored by our project. She shows signs of slowly winning back her
            memory. Mrs. B. also informs me that I won't be able to hold back my tears
            upon successfully defending my thesis in front of family, friends and
            colleagues. I successfully defend my thesis a few days later and I refuse her
            that pleasure, too.
            </p>

            <p>
            We celebrate at a local restaurant with the whole Department and the
            commission of five professors that evening. I join out from politeness. There
            is not much science to celebrate. After dinner I shake hands with Professor
            and the Head. "He did make a lot of noise around here but he did a great job
            and has very nice results," the Professor praises me in front of the Head. I
            smile without saying anything. I leave the place and begin to think about the
            years in front of me. But Professor catches up with me. He is a changed man,
            "Let's keep working together!" He is brimming with enthusiasm. I refuse him
            politely but he keeps talking as though my previous answer carries no weight
            with him, as he always does. "Yes, let's keep cooperating on new projects
            together," he goes on and on. I don't know what's gotten into him. Maybe he
            likes his name on new papers too much? He begins to get on my nerves. I answer
            respectfully with simple no's to all of his questions and proposals. I
            eventually say my goodbyes to him and turn my back. I leave Professor in the
            dark alley and my basement behind for good.
            </p>

            <p>
                © Mihai Olteanu, 2025
            </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Congress passes Take It Down act despite major flaws (128 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</link>
            <guid>43828568</guid>
            <pubDate>Tue, 29 Apr 2025 03:57:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws">https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</a>, See on <a href="https://news.ycombinator.com/item?id=43828568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
        <div>
            <article role="article">
  
  
  <div><p>Today the U.S. House of Representatives passed the <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">TAKE IT DOWN</a> Act<span>, giving the powerful a dangerous new route to manipulate platforms&nbsp;into removing&nbsp;lawful&nbsp;speech that&nbsp;they&nbsp;simply don't like.&nbsp;President Trump himself has said that <a href="https://www.eff.org/deeplinks/2025/03/trump-calls-congress-pass-overbroad-take-it-down-act-so-he-can-use-it-censor">he would use</a> the law to censor his critics. The bill passed the Senate&nbsp;<a href="https://www.eff.org/deeplinks/2025/02/senate-passed-take-it-down-act-threatening-free-expression-and-due-process">in February</a>,&nbsp;and it now heads to the president's&nbsp;desk.&nbsp;</span></p>
<p><span>The takedown provision in TAKE IT DOWN applies to a much broader category of content—potentially any images involving intimate or sexual content—than the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Services will rely on automated filters, which are infamously blunt tools.&nbsp;They frequently flag legal content, from fair-use commentary to news reporting.&nbsp;The law’s tight time frame requires that apps and websites remove speech within 48 hours, rarely enough time to verify whether the speech is actually illegal. As a result, online service providers, particularly smaller ones, will likely choose to avoid the onerous legal risk by simply depublishing the speech rather than even attempting to verify it.<br></span></p>
<p>Congress is&nbsp;using the wrong approach to helping people whose intimate images are shared without their consent.&nbsp;TAKE IT DOWN pressures platforms to actively monitor speech, including speech that is presently encrypted. The law thus presents a huge threat to security and privacy online. While the bill is meant to address a serious problem, good intentions alone are not enough to make good policy.<span>&nbsp;</span>Lawmakers should be strengthening and enforcing existing legal protections for victims, rather than inventing new takedown regimes that are ripe for abuse.&nbsp;</p>

</div>

          </article>
    </div>
<div>
          <h2>Related Issues</h2>
            </div>

<div>
          <h2>Join EFF Lists</h2>
        
    </div>
<div>
          <h2>Related Updates</h2>
        <div>
        
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/texass-war-abortion-now-war-free-speech" rel="bookmark">Texas’s War on Abortion Is Now a War on Free Speech</a></h3>
            
    </header>
  
  
  <div><p><strong>Once again, the Texas legislature is coming after the most common method of safe and effective abortion today—medication abortion.</strong><a href="https://capitol.texas.gov/tlodocs/89R/billtext/pdf/SB02880I.pdf#navpanes=0">Senate Bill (S.B.) 2880</a>* seeks to prevent the sale and distribution of abortion pills—but it doesn’t stop there. By restricting access to certain information online, the bill tries to keep people...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/digital-identities-and-future-age-verification-europe" rel="bookmark">Digital Identities and the Future of Age Verification in Europe</a></h3>
            
    </header>
  
  
  <div><p><i>This is the first part of a three-part series about age verification in the European Union. In this blog post, we give an overview of the political debate around age verification and explore the age verification proposal introduced by the European Commission, based on digital identities. Part two takes a</i>...</p></div>

          </article>
  </div>
  
  
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-joins-7amleh-campaign-reconnectgaza" rel="bookmark">EFF Joins 7amleh Campaign to #ReconnectGaza</a></h3>
            
    </header>
  
  
  <div><p>In times of conflict, the internet becomes more than just a tool—it is a lifeline, connecting those caught in chaos with the outside world. It carries voices that might otherwise be silenced, bearing witness to suffering and survival. Without internet access, communities become isolated, and the flow of critical information...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-stands-perkins-coie-and-rule-law" rel="bookmark">EFF Stands with Perkins Coie and the Rule of Law </a></h3>
            
    </header>
  
  
  <div><p>As a legal organization that has fought in court to defend the rights of technology users for almost 35 years, including numerous legal challenges to federal government overreach, Electronic Frontier Foundation unequivocally supports Perkins Coie’s challenge to the Trump administration’s shocking, vindictive, and unconstitutional <a href="https://www.whitehouse.gov/presidential-actions/2025/03/addressing-risks-from-perkins-coie-llp/" target="_blank" rel="noopener noreferrer">Executive Order</a>....</p></div>

          </article>
  </div>
    </div>    </div>
      </div>

      <div><h2>Related Issues</h2></div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why did Windows 7 log on slower for months if you had a solid color background? (190 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</link>
            <guid>43827214</guid>
            <pubDate>Mon, 28 Apr 2025 23:27:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121">https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</a>, See on <a href="https://news.ycombinator.com/item?id=43827214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-111121">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>Personally, I use a solid color background. It was the default in Windows 95,¹ and I’ve stuck with that bluish-green background color ever since. It’s sort of like my comfort food.</p>
<p>Imagine my surprise when someone pointed me to a support article titled “<a title="The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2" href="https://support.microsoft.com/en-us/topic/the-welcome-screen-may-be-displayed-for-30-seconds-during-the-logon-process-after-you-set-a-solid-color-as-the-desktop-background-in-windows-7-or-in-windows-server-2008-r2-b4565ced-703a-cc85-bf9c-6b3d586d6421">The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2</a>.” Why is logon slower with a solid background?</p>
<p>After your logon has been authenticated, Windows sets up your desktop. There are a lot of things going on. The taskbar gets created. The components that are responsible for various system services are loaded and initialized. The desktop window is created and filled with icons. And the desktop background window loads up the desktop wallpaper and paints it to the screen.</p>
<p>The logon system waits for all of these pieces to report that they are ready, and when the all-clear signal is received from everybody, or when 30 seconds have elapsed, the logon system switches away from the Welcome screen.</p>
<p>Given that design, you can imagine the reason for the 30-second delay: It means that one of the pieces failed to report. Perhaps it was written like this:</p>
<pre>InitializeWallpaper()
{
    if (wallpaper bitmap defined)
    {
        LoadWallpaperBitmap();
    }
}

LoadWallpaperBitmap()
{
    locate the bitmap on disk
    load it into memory
    paint it on screen
    Report(WallpaperReady);
}
</pre>
<p>The code to report that the wallpaper is ready was inside the wallpaper bitmap code, which means that if you don’t have a wallpaper bitmap, the report is never made, and the logon system waits in vain for a report that will never arrive.</p>
<p>Later in the article, it notes a related article that calls out that if you have the “Hide desktop icons” group policy enabled, then you might also suffer from the 30-second delay.</p>
<p>Group policies are susceptible to this problem because they tend to be bolted on after the main code is written. When you have to add a group policy, you find the code that does the thing, and you put a giant “if policy allows” around it.</p>
<pre>// Original code
InitializeDesktopIcons()
{
    bind to the desktop folder
    enumerate the icons
    add them to the screen
    Report(DesktopIconsReady);
}

// Updated with group policy support

InitializeDesktopIcons()
{
    <span>if (desktop icons allowed by policy)</span>
    <span>{                                   </span>
        bind to the desktop folder
        enumerate the icons
        add them to the screen
        Report(DesktopIconsReady);
    <span>}                                   </span>
}
</pre>
<p>Oops, the scope of the “if” block extended past the report call, so if the policy is enabled, the icons are never reported as ready, and the logon system stays on the Welcome screen for the full 30 seconds.</p>
<p>Note that in both of these cases, it’s not that the logon is extended by 30 seconds. Rather, the Welcome screen stays on for the full 30 seconds rather than the actual time it took for all systems to report ready (which could be 5 seconds, or it could be 25 seconds, depending on your system’s performance).</p>
<p>If you look at the timestamps on the articles, you can see that the problem was fixed in November 2009, just a few months after Windows 7 was released in July 2009.</p>
<p>¹ Originally, I avoided bitmap backgrounds because they took up a lot of memory, and when you had only 4 or 8 megabytes of memory, eating three quarters of a megabyte of memory just for wallpaper was not a good return on investment.</p>
<p>Also, I tend to stick with default configurations because it makes bug filing easier. If the repro instructions are “install a system from scratch, then perform these steps”, you’re more likely to get traction than if you say “install a system from scratch, change these 50 settings from their defaults, and then perform these additional steps.” It’s much easier to justify a bug fix that affects the default configuration than a bug fix that requires that the user have changed settings from the default, particularly if those settings are obscure.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 12-bit rainbow palette (207 pts)]]></title>
            <link>https://iamkate.com/data/12-bit-rainbow/</link>
            <guid>43827108</guid>
            <pubDate>Mon, 28 Apr 2025 23:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamkate.com/data/12-bit-rainbow/">https://iamkate.com/data/12-bit-rainbow/</a>, See on <a href="https://news.ycombinator.com/item?id=43827108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>
        I designed the 12-bit rainbow palette for use on <a href="https://grid.iamkate.com/">National Grid: Live</a>. It consists of twelve colours chosen with consideration for how we perceive luminance, chroma, and hue:
      </p>
      <figure>
        <svg viewBox="0 0 480 40" width="480" height="40">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The palette uses a 12-bit colour depth, so each colour requires only four characters when specified as a hexadecimal colour code in a <abbr>CSS</abbr> or <abbr>SVG</abbr> file:
      </p>
      <div id="palette">
        <p><span>#817</span></p>
        <p><span>#a35</span></p>
        <p><span>#c66</span></p>
        <p><span>#e94</span></p>
        <p><span>#ed0</span></p>
        <p><span>#9d5</span></p>
        <p><span>#4d8</span></p>
        <p><span>#2cb</span></p>
        <p><span>#0bc</span></p>
        <p><span>#09c</span></p>
        <p><span>#36b</span></p>
        <p><span>#639</span></p>
      </div>
      <h2>
        Designing the palette
      </h2>
      <p>
        Computers define colours in terms of red, green, and blue components, which are treated equally. However, we perceive these components as having differing luminance: compared to a pure red, a pure green looks much brighter and a pure blue looks much darker. As a result, a simple <abbr>RGB</abbr> rainbow palette has large changes in luminance between neighbouring colours. This can be seen by converting colours to greys of equal perceived luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#ff00ff" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#ff0080" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#ff0000" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#ff8000" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ffff00" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#80ff00" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#00ff00" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#00ff80" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#00ffff" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#0080ff" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#0000ff" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#8000ff" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#696969" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5b5b5b" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#4c4c4c" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#e2e2e2" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#bcbcbc" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#969696" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#a4a4a4" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#b3b3b3" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#686868" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#1d1d1d" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#434343" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The <abbr>LCH</abbr> colour space is an alternative to the <abbr>RGB</abbr> colour space that defines colours in terms of luminance, chroma, and hue components. These components are perceptually uniform, which means that a change by a particular numerical amount will be perceived similarly for any colour.
      </p>
      <p>
        An <abbr>LCH</abbr> rainbow colour palette can be created by choosing fixed chroma and luminance values and varying the hue. However, the resulting palette looks unpleasant because yellow is darkened to brown, red is lightened to pink, and blue becomes very pale.
      </p>
      <p>
        A better approach is to allow the luminance to vary, but in a controlled way. Yellow is given the highest luminance, as it only looks yellow when bright. After choosing two other colours — a red and a blue in this case — the luminance can then be calculated for the other hues.
      </p>
      <p>
        Using a 12-bit colour depth limits the available colours, so slight changes to luminance, chroma, and hue must be made, but these are small enough not to be noticeable. The resulting palette has evenly-spaced hues, only small variations in chroma, and smoothly increasing and decreasing luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#404040" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5c5c5c" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#848484" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#a9a9a9" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#c9c9c9" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#b9b9b9" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#a6a6a6" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#858585" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#717171" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#606060" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#4e4e4e" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The One-Person Framework in Practice (159 pts)]]></title>
            <link>https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</link>
            <guid>43826584</guid>
            <pubDate>Mon, 28 Apr 2025 21:58:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o">https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</a>, See on <a href="https://news.ycombinator.com/item?id=43826584">Hacker News</a></p>
Couldn't get https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3: Think deeper, act faster (585 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen3/</link>
            <guid>43825900</guid>
            <pubDate>Mon, 28 Apr 2025 20:44:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen3/">https://qwenlm.github.io/blog/qwen3/</a>, See on <a href="https://news.ycombinator.com/item?id=43825900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-banner.png" alt="Qwen3 Main Image" width="100%"></figure><p><a href="https://chat.qwen.ai/" target="_blank">QWEN CHAT</a>
<a href="https://github.com/QwenLM/Qwen3" target="_blank">GitHub</a>
<a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f" target="_blank">Hugging Face</a>
<a href="https://modelscope.cn/collections/Qwen3-9743180bdc6b48" target="_blank">ModelScope</a>
<a href="https://www.kaggle.com/models/qwen-lm/qwen-3" target="_blank">Kaggle</a>
<a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo" target="_blank">DEMO</a>
<a href="https://discord.gg/yPEP2vHTu4" target="_blank">DISCORD</a></p><h2 id="introduction">Introduction</h2><p>Today, we are excited to announce the release of <strong>Qwen3</strong>, the latest addition to the Qwen family of large language models. Our flagship model, <strong>Qwen3-235B-A22B</strong>, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, <strong>Qwen3-30B-A3B</strong>, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.</p><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg" width="100%"></figure><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg" width="100%"></figure><p>We are open-weighting two MoE models: <strong>Qwen3-235B-A22B</strong>, a large model with 235 billion total parameters and 22 billion activated parameters, and <strong>Qwen3-30B-A3B</strong>, a smaller MoE model with 30 billion total parameters and 3 billion activated parameters. Additionally, six dense models are also open-weighted, including <strong>Qwen3-32B</strong>, <strong>Qwen3-14B</strong>, <strong>Qwen3-8B</strong>, <strong>Qwen3-4B</strong>, <strong>Qwen3-1.7B</strong>, and <strong>Qwen3-0.6B</strong>, under Apache 2.0 license.</p><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th>Tie Embedding</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-0.6B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-1.7B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-4B</td><td>36</td><td>32 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-8B</td><td>36</td><td>32 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-14B</td><td>40</td><td>40 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-32B</td><td>64</td><td>64 / 8</td><td>No</td><td>128K</td></tr></tbody></table><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th># Experts (Total / Activated)</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-30B-A3B</td><td>48</td><td>32 / 4</td><td>128 / 8</td><td>128K</td></tr><tr><td>Qwen3-235B-A22B</td><td>94</td><td>64 / 4</td><td>128 / 8</td><td>128K</td></tr></tbody></table><p>The post-trained models, such as <strong>Qwen3-30B-A3B</strong>, along with their pre-trained counterparts (e.g., <strong>Qwen3-30B-A3B-Base</strong>), are now available on platforms like <strong>Hugging Face</strong>, <strong>ModelScope</strong>, and <strong>Kaggle</strong>. For deployment, we recommend using frameworks like <strong>SGLang</strong> and <strong>vLLM</strong>. For local usage, tools such as <strong>Ollama</strong>, <strong>LMStudio</strong>, <strong>MLX</strong>, <strong>llama.cpp</strong>, and <strong>KTransformers</strong> are highly recommended. These options ensure that users can easily integrate Qwen3 into their workflows, whether in research, development, or production environments.</p><p>We believe that the release and open-sourcing of Qwen3 will significantly advance the research and development of large foundation models. Our goal is to empower researchers, developers, and organizations around the world to build innovative solutions using these cutting-edge models.</p><p>Feel free to try Qwen3 out in Qwen Chat Web (<a href="https://chat.qwen.ai/">chat.qwen.ai</a>) and mobile APP!</p><h2 id="key-features">Key Features</h2><ul><li><strong>Hybrid Thinking Modes</strong></li></ul><p>Qwen3 models introduce a hybrid approach to problem-solving. They support two modes:</p><ol><li>Thinking Mode: In this mode, the model takes time to reason step by step before delivering the final answer. This is ideal for complex problems that require deeper thought.</li><li>Non-Thinking Mode: Here, the model provides quick, near-instant responses, suitable for simpler questions where speed is more important than depth.</li></ol><p>This flexibility allows users to control how much “thinking” the model performs based on the task at hand. For example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without delay. Crucially, the integration of these two modes greatly enhances the model’s ability to implement stable and efficient thinking budget control. As demonstrated above, Qwen3 exhibits scalable and smooth performance improvements that are directly correlated with the computational reasoning budget allocated. This design enables users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost efficiency and inference quality.</p><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/thinking_budget.png" width="100%"></figure><ul><li><strong>Multilingual Support</strong></li></ul><p>Qwen3 models are supporting <strong>119 languages and dialects</strong>. This extensive multilingual capability opens up new possibilities for international applications, enabling users worldwide to benefit from the power of these models.</p><table><thead><tr><th>Language Family</th><th>Languages &amp; Dialects</th></tr></thead><tbody><tr><td>Indo-European</td><td>English, French, Portuguese, German, Romanian, Swedish, Danish, Bulgarian, Russian, Czech, Greek, Ukrainian, Spanish, Dutch, Slovak, Croatian, Polish, Lithuanian, Norwegian Bokmål, Norwegian Nynorsk, Persian, Slovenian, Gujarati, Latvian, Italian, Occitan, Nepali, Marathi, Belarusian, Serbian, Luxembourgish, Venetian, Assamese, Welsh, Silesian, Asturian, Chhattisgarhi, Awadhi, Maithili, Bhojpuri, Sindhi, Irish, Faroese, Hindi, Punjabi, Bengali, Oriya, Tajik, Eastern Yiddish, Lombard, Ligurian, Sicilian, Friulian, Sardinian, Galician, Catalan, Icelandic, Tosk Albanian, Limburgish, Dari, Afrikaans, Macedonian, Sinhala, Urdu, Magahi, Bosnian, Armenian</td></tr><tr><td>Sino-Tibetan</td><td>Chinese (Simplified Chinese, Traditional Chinese, Cantonese), Burmese</td></tr><tr><td>Afro-Asiatic</td><td>Arabic (Standard, Najdi, Levantine, Egyptian, Moroccan, Mesopotamian, Ta’izzi-Adeni, Tunisian), Hebrew, Maltese</td></tr><tr><td>Austronesian</td><td>Indonesian, Malay, Tagalog, Cebuano, Javanese, Sundanese, Minangkabau, Balinese, Banjar, Pangasinan, Iloko, Waray (Philippines)</td></tr><tr><td>Dravidian</td><td>Tamil, Telugu, Kannada, Malayalam</td></tr><tr><td>Turkic</td><td>Turkish, North Azerbaijani, Northern Uzbek, Kazakh, Bashkir, Tatar</td></tr><tr><td>Tai-Kadai</td><td>Thai, Lao</td></tr><tr><td>Uralic</td><td>Finnish, Estonian, Hungarian</td></tr><tr><td>Austroasiatic</td><td>Vietnamese, Khmer</td></tr><tr><td>Other</td><td>Japanese, Korean, Georgian, Basque, Haitian, Papiamento, Kabuverdianu, Tok Pisin, Swahili</td></tr></tbody></table><ul><li><strong>Improved Agentic Capabilities</strong></li></ul><p>We have optimized the Qwen3 models for coding and agentic capabilities, and also we have strengthened the support of MCP as well. Below we provide examples to show how Qwen3 thinks and interacts with the environment.</p><h2 id="pre-training">Pre-training</h2><p>In terms of pretraining, the dataset for Qwen3 has been significantly expanded compared to Qwen2.5. While Qwen2.5 was pre-trained on 18 trillion tokens, Qwen3 uses nearly twice that amount, with approximately 36 trillion tokens covering 119 languages and dialects. To build this large dataset, we collected data not only from the web but also from PDF-like documents. We used Qwen2.5-VL to extract text from these documents and Qwen2.5 to improve the quality of the extracted content. To increase the amount of math and code data, we used Qwen2.5-Math and Qwen2.5-Coder to generate synthetic data. This includes textbooks, question-answer pairs, and code snippets.</p><p>The pre-training process consists of three stages. In the first stage (S1), the model was pretrained on over 30 trillion tokens with a context length of 4K tokens. This stage provided the model with basic language skills and general knowledge. In the second stage (S2), we improved the dataset by increasing the proportion of knowledge-intensive data, such as STEM, coding, and reasoning tasks. The model was then pretrained on an additional 5 trillion tokens. In the final stage, we used high-quality long-context data to extend the context length to 32K tokens. This ensures the model can handle longer inputs effectively.</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-base.jpg" width="100%"></figure><p>Due to advancements in model architecture, increase in training data, and more effective training methods, the overall performance of Qwen3 dense base models matches that of Qwen2.5 base models with more parameters. For instance, Qwen3-1.7B/4B/8B/14B/32B-Base performs as well as Qwen2.5-3B/7B/14B/32B/72B-Base, respectively. Notably, in areas like STEM, coding, and reasoning, Qwen3 dense base models even outperform larger Qwen2.5 models. For Qwen3-MoE base models, they achieve similar performance to Qwen2.5 dense base models while using only 10% of the active parameters. This results in significant savings in both training and inference costs.</p><h2 id="post-training">Post-training</h2><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png" width="100%"></figure><p>To develop the hybrid model capable of both step-by-step reasoning and rapid responses, we implemented a four-stage training pipeline. This pipeline includes: (1) long chain-of-thought (CoT) cold start, (2) reasoning-based reinforcement learning (RL), (3) thinking mode fusion, and (4) general RL.</p><p>In the first stage, we fine-tuned the models using diverse long CoT data, covering various tasks and domains such as mathematics, coding, logical reasoning, and STEM problems. This process aimed to equip the model with fundamental reasoning abilities. The second stage focused on scaling up computational resources for RL, utilizing rule-based rewards to enhance the model’s exploration and exploitation capabilities.</p><p>In the third stage, we integrated non-thinking capabilities into the thinking model by fine-tuning it on a combination of long CoT data and commonly used instruction-tuning data. This data was generated by the enhanced thinking model from the second stage, ensuring a seamless blend of reasoning and quick response capabilities. Finally, in the fourth stage, we applied RL across more than 20 general-domain tasks to further strengthen the model’s general capabilities and correct undesired behaviors. These tasks included instruction following, format following, and agent capabilities, etc.</p><h2 id="develop-with-qwen3">Develop with Qwen3</h2><p>Below is a simple guide for you to use Qwen3 on different frameworks. First of all, we provide an standard example of using Qwen3-30B-A3B in Hugging Face transformers:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>modelscope</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>model_name</span> <span>=</span> <span>"Qwen/Qwen3-30B-A3B"</span>
</span></span><span><span>
</span></span><span><span><span># load the tokenizer and the model</span>
</span></span><span><span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span>
</span></span><span><span>    <span>model_name</span><span>,</span>
</span></span><span><span>    <span>torch_dtype</span><span>=</span><span>"auto"</span><span>,</span>
</span></span><span><span>    <span>device_map</span><span>=</span><span>"auto"</span>
</span></span><span><span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># prepare the model input</span>
</span></span><span><span><span>prompt</span> <span>=</span> <span>"Give me a short introduction to large language model."</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>prompt</span><span>}</span>
</span></span><span><span><span>]</span>
</span></span><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>True</span> <span># Switch between thinking and non-thinking modes. Default is True.</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>model_inputs</span> <span>=</span> <span>tokenizer</span><span>([</span><span>text</span><span>],</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span><span>.</span><span>to</span><span>(</span><span>model</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># conduct text completion</span>
</span></span><span><span><span>generated_ids</span> <span>=</span> <span>model</span><span>.</span><span>generate</span><span>(</span>
</span></span><span><span>    <span>**</span><span>model_inputs</span><span>,</span>
</span></span><span><span>    <span>max_new_tokens</span><span>=</span><span>32768</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>output_ids</span> <span>=</span> <span>generated_ids</span><span>[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>model_inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span> 
</span></span><span><span>
</span></span><span><span><span># parsing thinking content</span>
</span></span><span><span><span>try</span><span>:</span>
</span></span><span><span>    <span># rindex finding 151668 (&lt;/think&gt;)</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>len</span><span>(</span><span>output_ids</span><span>)</span> <span>-</span> <span>output_ids</span><span>[::</span><span>-</span><span>1</span><span>]</span><span>.</span><span>index</span><span>(</span><span>151668</span><span>)</span>
</span></span><span><span><span>except</span> <span>ValueError</span><span>:</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span><span>thinking_content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[:</span><span>index</span><span>],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span><span>content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[</span><span>index</span><span>:],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>print</span><span>(</span><span>"thinking content:"</span><span>,</span> <span>thinking_content</span><span>)</span>
</span></span><span><span><span>print</span><span>(</span><span>"content:"</span><span>,</span> <span>content</span><span>)</span>
</span></span></code></pre></div><p>To disable thinking, you just need to make changes to the argument <code>enable_thinking</code> like the following:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>False</span>  <span># True is the default value for enable_thinking.</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><p>For deployment, you can use <code>sglang&gt;=0.4.6.post1</code> or <code>vllm&gt;=0.8.4</code> to create an OpenAI-compatible API endpoint:</p><ul><li><p>SGLang:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3
</span></span></code></pre></div></li><li><p>vLLM:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1
</span></span></code></pre></div></li></ul><p>If you use it for local development, you can use ollama by running a simple command <code>ollama run qwen3:30b-a3b</code> to play with the model, or you can use LMStudio or llama.cpp and ktransformers to build locally.</p><h3 id="advanced-usages">Advanced Usages</h3><p>We provide a soft switch mechanism that allows users to dynamically control the model’s behavior when enable_thinking=True. Specifically, you can add /think and /no_think to user prompts or system messages to switch the model’s thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.</p><p>Here is an example of a multi-turn conversation:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>QwenChatbot</span><span>:</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>model_name</span><span>=</span><span>"Qwen/Qwen3-30B-A3B"</span><span>):</span>
</span></span><span><span>        <span>self</span><span>.</span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span> <span>=</span> <span>[]</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>generate_response</span><span>(</span><span>self</span><span>,</span> <span>user_input</span><span>):</span>
</span></span><span><span>        <span>messages</span> <span>=</span> <span>self</span><span>.</span><span>history</span> <span>+</span> <span>[{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>}]</span>
</span></span><span><span>
</span></span><span><span>        <span>text</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>            <span>messages</span><span>,</span>
</span></span><span><span>            <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>            <span>add_generation_prompt</span><span>=</span><span>True</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>inputs</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>(</span><span>text</span><span>,</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span>
</span></span><span><span>        <span>response_ids</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>generate</span><span>(</span><span>**</span><span>inputs</span><span>,</span> <span>max_new_tokens</span><span>=</span><span>32768</span><span>)[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span>
</span></span><span><span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>response_ids</span><span>,</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># Update history</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>})</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>})</span>
</span></span><span><span>
</span></span><span><span>        <span>return</span> <span>response</span>
</span></span><span><span>
</span></span><span><span><span># Example Usage</span>
</span></span><span><span><span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
</span></span><span><span>    <span>chatbot</span> <span>=</span> <span>QwenChatbot</span><span>()</span>
</span></span><span><span>
</span></span><span><span>    <span># First input (without /think or /no_think tags, thinking mode is enabled by default)</span>
</span></span><span><span>    <span>user_input_1</span> <span>=</span> <span>"How many r's in strawberries?"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_1</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_1</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Second input with /no_think</span>
</span></span><span><span>    <span>user_input_2</span> <span>=</span> <span>"Then, how many r's in blueberries? /no_think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_2</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_2</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_2</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_2</span><span>}</span><span>"</span><span>)</span> 
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Third input with /think</span>
</span></span><span><span>    <span>user_input_3</span> <span>=</span> <span>"Really? /think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_3</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_3</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_3</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_3</span><span>}</span><span>"</span><span>)</span>
</span></span></code></pre></div><h3 id="agentic-usages">Agentic Usages</h3><p>Qwen3 excels in tool calling capabilities. We recommend using <a href="https://github.com/QwenLM/Qwen-Agent">Qwen-Agent</a> to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.</p><p>To define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>qwen_agent.agents</span> <span>import</span> <span>Assistant</span>
</span></span><span><span>
</span></span><span><span><span># Define LLM</span>
</span></span><span><span><span>llm_cfg</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>'model'</span><span>:</span> <span>'Qwen3-30B-A3B'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Use the endpoint provided by Alibaba Model Studio:</span>
</span></span><span><span>    <span># 'model_type': 'qwen_dashscope',</span>
</span></span><span><span>    <span># 'api_key': os.getenv('DASHSCOPE_API_KEY'),</span>
</span></span><span><span>
</span></span><span><span>    <span># Use a custom endpoint compatible with OpenAI API:</span>
</span></span><span><span>    <span>'model_server'</span><span>:</span> <span>'http://localhost:8000/v1'</span><span>,</span>  <span># api_base</span>
</span></span><span><span>    <span>'api_key'</span><span>:</span> <span>'EMPTY'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Other parameters:</span>
</span></span><span><span>    <span># 'generate_cfg': {</span>
</span></span><span><span>    <span>#         # Add: When the response content is `&lt;think&gt;this is the thought&lt;/think&gt;this is the answer;</span>
</span></span><span><span>    <span>#         # Do not add: When the response has been separated by reasoning_content and content.</span>
</span></span><span><span>    <span>#         'thought_in_content': True,</span>
</span></span><span><span>    <span>#     },</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span># Define Tools</span>
</span></span><span><span><span>tools</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>'mcpServers'</span><span>:</span> <span>{</span>  <span># You can specify the MCP configuration file</span>
</span></span><span><span>            <span>'time'</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>'command'</span><span>:</span> <span>'uvx'</span><span>,</span>
</span></span><span><span>                <span>'args'</span><span>:</span> <span>[</span><span>'mcp-server-time'</span><span>,</span> <span>'--local-timezone=Asia/Shanghai'</span><span>]</span>
</span></span><span><span>            <span>},</span>
</span></span><span><span>            <span>"fetch"</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>"command"</span><span>:</span> <span>"uvx"</span><span>,</span>
</span></span><span><span>                <span>"args"</span><span>:</span> <span>[</span><span>"mcp-server-fetch"</span><span>]</span>
</span></span><span><span>            <span>}</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>  <span>'code_interpreter'</span><span>,</span>  <span># Built-in tools</span>
</span></span><span><span><span>]</span>
</span></span><span><span>
</span></span><span><span><span># Define Agent</span>
</span></span><span><span><span>bot</span> <span>=</span> <span>Assistant</span><span>(</span><span>llm</span><span>=</span><span>llm_cfg</span><span>,</span> <span>function_list</span><span>=</span><span>tools</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># Streaming generation</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[{</span><span>'role'</span><span>:</span> <span>'user'</span><span>,</span> <span>'content'</span><span>:</span> <span>'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'</span><span>}]</span>
</span></span><span><span><span>for</span> <span>responses</span> <span>in</span> <span>bot</span><span>.</span><span>run</span><span>(</span><span>messages</span><span>=</span><span>messages</span><span>):</span>
</span></span><span><span>    <span>pass</span>
</span></span><span><span><span>print</span><span>(</span><span>responses</span><span>)</span>
</span></span></code></pre></div><h2 id="friends-of-qwen">Friends of Qwen</h2><p>Thanks to the support of so many friends. Qwen is nothing without its friends! We welcome more people or organizations to join our community and help us become better!</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-logo.png" width="100%"></figure><h2 id="future-work">Future Work</h2><p>Qwen3 represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages, enhancing global accessibility.</p><p>Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures and training methodologies to achieve several key objectives: scaling data, increasing model size, extending context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We believe we are transitioning from an era focused on training models to one centered on training agents. Our next iteration promises to bring meaningful advancements to everyone’s work and life.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Million Chessboards (208 pts)]]></title>
            <link>https://eieio.games/blog/one-million-chessboards/</link>
            <guid>43825336</guid>
            <pubDate>Mon, 28 Apr 2025 19:52:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eieio.games/blog/one-million-chessboards/">https://eieio.games/blog/one-million-chessboards/</a>, See on <a href="https://news.ycombinator.com/item?id=43825336">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><a href="https://eieio.games/blog/one-million-chessboards/"></a><div><p>a million chessboards that anyone can play on</p><p>Apr 28, 2025</p></div></div>
<p>I made a website. It’s called <a href="https://onemillionchessboards.com/">One Million Chessboards</a>. It has one million chessboards on it.</p>
<p>Moving a piece moves it for everyone, instantly. There are no turns. You can move between boards.</p>
<div><video controls="" playsinline="" poster="https://eieio.games/images/one-million-chessboards/gameplay-firstframe.png" width="2136" height="1708" preload="metadata" alt="Gameplay from One Million Chessboards. The player moves a queen around on a grid of a million boards as pieces move around him."><p>Loading...</p></video><p>moving some pieces</p></div>
<!-- -->
<h2 id="toc:what">What</h2>
<p>Well last year I made this game called <a href="https://eieio.games/blog/one-million-checkboxes">One Million Checkboxes</a>.</p>
<p>It was a pretty fun time! So I thought I’d do something like this again.</p>
<p>I worked really hard on this one. I hope you like it.</p>
<h2 id="toc:how">How</h2>
<p>This was the most technically challenging thing that I’ve worked on in a long time. I’m going to save a full technical writeup until I see how my decisions pan out, since I think there’s a decent chance I’ll need to make a lot of changes.</p>
<p>But I’ll summarize a few things for you.</p>
<ul>
<li>Unlike One Million Checkboxes, I designed this for scale</li>
<li>The game runs on a single server (!)</li>
<li>The board is stored fully in-memory; it’s a 2D array of 64 million uint64s</li>
<li>The backend is written in go. This is my first go project.</li>
<li>I use a single writer thread, tons of reader threads, and coordinate access to the board with a mutex</li>
<li>The frontend optimistically applies all moves you make immediately. It then builds up a dependency graph of the moves you’ve made, and backs them out if it receives a conflicting update before the server acks your move.</li>
<li>The server ships zstd-compressed protobufs to the clients over websockets for state snapshots (approximately a 100x100 square around the client), move and capture updates, and acks/rejections for moves</li>
<li>Clients are grouped into 50x50 “zones” and only receive moves for zones adjacent to their current zone</li>
<li>Clients fetch global data (game stats, the minimap, etc) by polling via GET; data is cached in Cloudflare with a low TTL so this is much cheaper than shipping it over every websocket</li>
</ul>
<p>That last part - optimistic move application with what games people sometimes call “rollback” - is about 1,600 lines of code that took me a ~7 days of fulltime work to write. I don’t remember the last time I wrestled with a problem that hard!</p>
<p>As of 8 PM, 8 hours after launch, players have made about 1.3 million moves and there are about 400 concurrent users most of the time. Load on my server is neglibible!</p>
<h2 id="toc:can-i-play">Can I play</h2>
<p>Yes! <a href="https://onemillionchessboards.com/">Play it here</a>.</p>
<p>I really hope you like this one. More updates to come :)</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Migrating Away from Rust (520 pts)]]></title>
            <link>https://deadmoney.gg/news/articles/migrating-away-from-rust</link>
            <guid>43824640</guid>
            <pubDate>Mon, 28 Apr 2025 18:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deadmoney.gg/news/articles/migrating-away-from-rust">https://deadmoney.gg/news/articles/migrating-away-from-rust</a>, See on <a href="https://news.ycombinator.com/item?id=43824640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When I started building <strong>Architect of Ruin </strong>in December 2023 I chose to build it in the <a href="https://bevyengine.org/" target="_blank">Bevy</a>&nbsp;game engine. My choice was motivated by a personal interest in <a href="https://www.rust-lang.org/" target="_blank">Rust</a>&nbsp;-- a language I derive a lot of joy in using. This was furthered by <a href="https://bevyengine.org/learn/quick-start/getting-started/ecs/" target="_blank">Bevy's ECS</a> model which I also find fun to work with and the openness of Bevy's community which I have a genuine appreciation for.</p><center><iframe width="500" height="282" src="https://www.youtube.com/embed/vCEbQXeGc3U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Bevy Rap by Tantan"></iframe></center><p>So, it came as a surprise that in&nbsp;January of 2025 we transitioned the game away from Rust and Bevy. I spent about six weeks rewriting the game entirely in C# and we have been using Unity for the past three months.</p><p>Switching engines is a classic project killer. Productivity can nosedive, regressions inevitably emerge, and every step forward seems to lead to three steps back. Not to mention that domain expertise built up in one language and engine doesn't cleanly transfer to a new language and engine.</p><p>But I bit the bullet and I want to explain why.</p><h3>The Bevy Journey</h3><p>A lot of good work was accomplished in Bevy. The tilemap, most of my approach to composing the scene, and a large amount of character and gameplay logic were implemented in Bevy. I learned about the guts of Spine and skeletal animation by tearing apart Rust <a href="https://github.com/jabuwu/rusty_spine" target="_blank">transpiles</a>&nbsp;of the spine runtime. I learned a lot about custom render pipelines by implementing my own rendering features in Bevy's render world. Bevy's pure ECS was a joy to work with and Rust's compile-time checks meant I could refactor large swathes of code quickly and with confidence.</p><p>The Bevy community was also an active source of inspiration - not just ideas about how to use the engine, but a positive community of builders and contributors. This community is very good at being excited about game development and being energetic about debate.</p><p>I had the opportunity to contribute features and fixes to a number of community crates, although most of those contributions were small and were focused on work that moved my own goals forward.</p><p>Despite these positive experiences and the progress made, practical challenges emerged as development continued.</p><h3>Emergent Problems</h3><p>I want to begin by stating that I anticipated many of these challenges before they manifested. I knew that using a game engine early in its development lifecycle would pose unique risks and costs. I considered those costs to be likely worthwhile and surmountable. My love of Rust and Bevy meant that I would be willing to bear some pain that other game developers might choose to avoid. I didn't walk blindly into these specific problems, but they bit harder than I was expecting.</p><p><strong>Collaboration </strong>- I started this project with my brother. While he's sharp and eager, he's new to coding. Onboarding him directly into game dev while simultaneously navigating Rust's unique aspects proved challenging. We found ourselves with a steeper learning curve that slowed his ability to contribute effectively to gameplay logic.</p><center></center><p><strong>Abstraction</strong> - While my initial motivation was the enjoyment of Rust, the project's bottleneck increasingly became the rapid iteration of higher-level gameplay mechanics. As the codebase grew, we found that translating gameplay ideas into code was less direct than we hoped. Rust's (powerful) low-level focus didn't always lend itself to a flexible high-level scripting style needed for rapid prototyping within our specific gameplay architecture. I found that my motivation to build and ship fun gameplay was stronger than my desire to build with Rust.</p><p>I had anticipated that this was going to be a thing, but I wasn't calibrated to the degree it would start to annoy me and slow the project down.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/bevyskeleverbose.png" alt="Rust can be verbose."></p><center><em>(A relatively simple gameplay function signature.)</em></center><center><em></em></center><center><em></em></center><p><strong>Migration&nbsp;</strong>- Bevy is young and changes quickly. Each update brought with it incredible features, but also a substantial amount of API thrash. As the project grew in size, the burden of update migration also grew. Minor regressions were common in core Bevy systems (such as sprite rendering), and these led to moments of significant friction and unexpected debugging effort.</p><p>This came to a head on one specific day where I was frustrated with a sprite rendering issue that had emerged in a new release. Blake had run into the same problem at the same time and our shared frustration boiled over into a kind of table flip moment. He turned to me and said something along the lines of "this shouldn't happen, this kind of thing should just be solved" and that triggered the conversation that led to a re-evaluation.</p><p>The point isn't that specific sprite problem, but that because all systems in Bevy are open to tinkering and improvement, all systems were potentially subject to regressions.</p><p><strong>Learning </strong>- Over the past year my workflow has changed immensely, and I regularly use AI to learn new technologies, discuss methods and techniques, review code, etc. The maturity and vast amount of stable historical data for C# and the Unity API mean that tools like Gemini consistently provide highly relevant guidance. While Bevy and Rust evolve rapidly - which is exciting and motivating - the pace means AI knowledge lags behind, reducing the efficiency gains I have come to expect from AI assisted development. This could change with the introduction of more modern tool-enabled models, but I found it to be a distraction and an unexpected additional cost.</p><p><strong>Modding </strong>- Modding means a lot to me. <a href="https://web.archive.org/web/20160306093336/http://orangesmoothie.org/" target="_blank">I got my start in the industry as a modder</a>&nbsp;and I want my game to be highly moddable. Over time, as I learned more about how to realize this goal, I came to understand many inherent limitations in Rust and Bevy that would make the task more difficult. Lack of a clear solution to scripting and an unstable ABI (application binary interface) raised concerns. I am not an expert in this area, perhaps these are all easily surmounted. I can only say that I did not find a path (after much searching) that I felt confident trusting.</p><p>These factors combined - the desire for a smoother workflow across experience levels, the need for a high-level abstraction for gameplay, optimizing productivity, and modding - pointed towards a re-evaluation of the project's next phase.</p><h3>The Switch</h3><p>To be honest, I completely disregarded Unity when I started the project.</p><p>Some of this stemmed from unforced errors on the part of Unity. They had just gone through a crisis of pricing that culminated in the resignation of their CEO and they seemed out of touch with indie developers.&nbsp;I also made several assumptions. I felt sick of coding in the outdated form of C++ that pervades older game engines and assumed I'd feel similarly about C#. I figured that since Unreal doesn't offer much for 2D render pipelines that Unity wouldn't either. This led me to fail to give serious thought to using Unity in 2023.</p><p>In the first week of January of 2025, Blake and I decided to do a cost-benefit analysis. We wrote down all the options: Unreal, Unity, Godot, continuing in Bevy, or rolling our own. We wrote extensive pros and cons, emphasizing how each option fared by the criteria above: Collaboration, Abstraction, Migration, Learning, and Modding.</p><p>Having some experience with the other options, I decided I needed to understand Unity better. An afternoon's research led me to conclude that it seemed to score high on the pros over the cons.</p><p>We had a team meeting where I laid out the trade-offs. Ulrick pointed out that a bunch of unknowns, like particles, would just be solved in a packaged engine. Blake pointed out that if things went well, and a new engine meant faster gameplay development, we could end up ahead of schedule.</p><h3>10% for 90%</h3><p>The team decided to invest in an experiment. I would pick three core features and see how difficult they would be to implement in Unity. We would spend no more than 3 weeks on the task.  We would invest 10% of effort to see if we should invest the other 90% in a full port.</p><p><strong>Tilemap</strong> - I figured this one would be straightforward, since the basic logic is simple. It would require implementing custom shaders. We wouldn't be using the built in Unity Tilemap because our needs were specific and well-known to us. This was foundational to the game scene and I had a good mental model for how long it took me to write the first time in Rust.</p><p><strong>Characters </strong>- Our characters use Spine and have unique customization requirements and features. This gave me a lot of trouble in Rust, so I figured it would be a good point of comparison in C#.</p><p><strong>UI</strong> - I wanted UI to be easy to build, fast to iterate, and moddable. This was an area where we learned a lot in Rust and again had a good mental model for comparison. Some research led me to conclude that <a href="https://www.noesisengine.com/" target="_blank">Noesis</a>&nbsp;would be a good fit because of its emphasis on data-driven XAML and the fact that the WPF model is very well documented. Even if I didn't know WPF, I knew I could learn it quickly with AI assistance.</p><p>The first two tasks: Tilemap and Characters, were chosen because they were fundamental, but also because let me check my time-expectations against reality on an easy task and a hard task. This would allow me to project the workload of future tasks and the port more broadly. The UI task was chosen because our game is UI heavy and any significant speed improvement in iterating on UI would have compounding returns on future development.</p><p>We finished all three tasks in 3 days!</p><p>Commit 1 was on Jan 8th and the Tilemap was done the same day.&nbsp;</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/tasklog1.png" alt=""></p><p>While I implemented the tilemap, Blake wrote the camera system. This demonstrated a significant boost in his ability to contribute when the technical framework was more scrutable. It was also a huge boost to his confidence and contributed to a new feeling of momentum. I should point out that Blake had never written C# before.</p><p>I implemented the Tilemap shader in Unity Shader Graph, thinking this would be easier for Ulrick to play with. This wasn't the last Shader Graph I wrote, but ultimately, I decided that visual shader creation and iteration was too slow, and refactoring was much slower as well. I now write all shaders in HLSL.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/tilemapshader.png" alt=""></p><p>On Jan 10th we had figured out the basics of building UI in Noesis. Blake wrote a few simple UI widgets and then built the main menu and I built the first part of the game HUD, the toolbar.</p><p>The work went far more smoothly than I expected, and nothing was left on the cutting room floor. The tilemap took a day, a basic panel in Noesis was an afternoon including hooking up the plugin. The rest of the time was on wiring up characters. To be clear, I didn't port the entire UI in an afternoon or implement our equipment system. What we did have were customizable character bodies, a fully ported tilemap, some basic menus and enough knowledge to make projections on how long the rest of the port would take.</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/initialport.png" alt="Very representative of the end of that first week."></p><p><em>This image is very representative of where we were at the end of the first week of porting, although this one is actually from a few days later after items had gone in.</em></p><p>At the end of the week, we convened to discuss what we had learned and made the decision to move ahead with the full port.</p><p>The following six weeks were dedicated to rewriting the remaining systems and content from the Bevy version into Unity/C#. The overall process largely validated the findings from our three-day test. Gameplay systems with the same number of features could be implemented with less verbosity.&nbsp;</p><p><img src="https://manakeep.us-east-1.linodeobjects.com/users/647f40267263835eb33ad65d/2025-04-25/longerconvo.png"></p><center><em>This conversation dates March 4, 2025.</em></center><p>Code size shrank substantially, massively improving maintainability. As far as I can tell, most of this savings was just in the elimination of ECS boilerplate.</p><p>Everything felt tighter and more straightforward. Update migration anxiety was gone and while it was replaced with "we gotta get this done" anxiety, that dissipated quickly as progress was constant.</p><h3>Life Since the Switch</h3><p>We've now been developing <strong>Architect of Ruin</strong> exclusively in Unity for the past three months. The shift has measurably improved our day-to-day development. Iteration feels faster, allowing ideas to flow into the game more easily. We've also been able to leverage ecosystem tools like the <a href="https://arongranberg.com/astar/" target="_blank">AStar Pathfinding Project</a>.</p><p>One area that isn't solved and which will likely cost us some pain is localization. In Rust, the <a href="https://github.com/projectfluent/fluent" target="_blank">Fluent</a>&nbsp;project is excellent and exactly what we needed -- I haven't yet found a comparable solution in Unity.</p><p>I plan to discuss specific elements of the game's implementation in Unity and the porting process in future posts. The goal of today's post was only to explain the reasoning that led us to our current position.</p><p>A few conclusions stand out.</p><p><strong>I failed to fairly evaluate my options at the start of the project. </strong>Rust is great and I love it, but I didn't give alternatives a fair shake. In particular, I didn't spend time examining the differences between Unreal and Unity more closely.</p><p><strong>Sometimes you have to burn time to earn time. </strong>I think we are way ahead of where we would have been had we stuck with Bevy. Our agility in implementing rendering features while also pushing gameplay forward is much higher.</p><p>Rust remains a language I deeply enjoy, and Bevy is an exciting engine with a fantastic community -- I have immense respect for both and may well use them again for different projects. For <strong>Architect of Ruin</strong>, however, the needs for accessible collaboration, rapid gameplay iteration, and leveraging a stable ecosystem pointed towards an alternative.</p><p>It was a difficult decision, one that felt counter to my instincts, but ultimately it put us in a much stronger position to realize our vision for the game.</p>
  
<p>
  <strong>
    Stay in the Loop&nbsp;🗡️
  </strong>
  If you’ve read this far and want to watch our sword-and-sorcery colony grow,
  <a href="https://deadmoney.gg/#block_6802c2b072638302caf714e7" target="_blank" rel="noopener">
    join the newsletter
  </a>
  to get dev updates&nbsp;&amp; first-look builds.
</p>
<center><video controls="controls" autoplay="autoplay" muted="muted" loop="loop" playsinline="playsinline" src="https://manakeep.us-east-1.linodeobjects.com/devlog/videos/2025/4/23/y379zowPZHtDvSKp/lutfix.mp4"></video></center></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reports of the death of California High-Speed Rail have been greatly exaggerated (173 pts)]]></title>
            <link>https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated</link>
            <guid>43824544</guid>
            <pubDate>Mon, 28 Apr 2025 18:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated">https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated</a>, See on <a href="https://news.ycombinator.com/item?id=43824544">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If there is one subject liberals and conservatives can agree on, it might be their shared hatred for California High-Speed Rail. Today, the project is <a href="https://apnews.com/article/california-high-speed-rail-trump-investigation-5b4d6494a8cdd9a3fe3b8949bb5b1bba">under investigation</a> by the Trump administration and is facing a possible withdrawal of federal funds. Even California Democrats seem disinclined to put up a fight. In Ezra Klein and Derek Thompson’s <em>Abundance</em>, it is the example par excellence of blue states’ failure to build, a casualty (if it ever lived) of environmental proceduralism, prohibitive regulatory processes, a bloated bureaucracy, and general infrastructural incompetence. &nbsp;</p><p>All of these challenges are real. What critics miss is that many of them have already been overcome. What they ignore is the reason they exist in the first place. The story of CAHSR is not about a state trying and failing to overcome its own bureaucracy and broken political process. It’s about a state that barely tried.</p><p>In 2008, when the state originally put Prop 1A to voters to build a high-speed rail between Los Angeles and San Francisco, the expectation was that the $9.95 billion in state bonds voters approved would be matched or exceeded by federal funding (as is normally the case for highway projects), and perhaps further complemented by private funding (as with the Brightline West project between Las Vegas and Los Angeles). It passed with 52.6% of the vote.&nbsp;</p></div><div><p>It took four years to even begin work, but not solely because of permitting — release of the funds was delayed until 2012. And they were held up further by a series of court cases that prevented the state from selling the bonds allocated by 1A until it identified the source of the rest of the project’s funding. During this time, the project received around $3 billion in federal funds from the Obama-era American Recovery and Reinvestment Act of 2009, which came with requirements to match federal funds and to begin work in disadvantaged areas of the Central Valley.</p><p>The result was that work on the Central Valley segment’s initial 120 miles was delayed for several years. The first major construction contract, Construction Package 1, was <a href="https://www.railwaygazette.com/high-speed/california-high-speed-rail-authority-invites-interest-in-second-construction-package/38771.article">issued in June 2013</a>. In the meantime, then-Governor Jerry Brown and the legislature worked to grant CAHSR what would be its sole ongoing funding source. In June 2014, the project was awarded a 15% allocation of the revenue from sales in California's cap-and-trade carbon auctions, which in recent years have raised between $3 and $4.7 billion a year. In 2017, this allocation was extended until 2030. With this funding secure, contracts were finally issued for Construction Package 2-3 in 2015 and Construction Package 4 in 2016.&nbsp;</p><p>But the delays in issuing these contracts started a vicious cycle. At multiple points in the rail’s history, approvals and construction plans already started for utility reconstructions, interactions with and crossings of existing freight lines, grade separations, and so on were left incomplete. This led to pauses in work and further delays so that plans could catch up to the ground already broken. The lack of continuity between planning and construction — changes in contractors, personnel, and others with expertise — made necessary change orders that only drove the cost up higher.&nbsp;</p><p>Through Trump’s first term, the initial portion of bond funding, combined with funding from the cap-and-trade fund allocation, was enough to keep <em>some</em> progress moving forward in the Central Valley under rail authority CEO Brian Kelly. Concrete viaducts and grade separations began to rise as visible signs of the work in progress. However, there were strict limits on what could be accomplished because of the piecemeal disbursement of cash. The sum of these funds, the only source of persistent cash flow, was generally about a billion dollars a year. They also varied each year due to the fluctuation in the cap-and-trade auction system. As a result, yearly funds couldn’t be reliably planned against, nor could they be borrowed against. Thus, even when work was finally underway, progress was slower than hoped, as change orders resulting from delayed property acquisition and permitting interactions with freight railroads and local municipalities increased costs and complexity.&nbsp;</p><p>To put this into perspective: Brightline West, the high-speed rail project between Los Angeles and Las Vegas, is hoping to spend the $12 billion they have raised in just over four years. It has taken many times as long for California High-Speed Rail to have their first $12 billion <em>in hand</em>. &nbsp;</p><p>Gavin Newsom’s election as governor in 2018 introduced further problems for the project that continue to plague it today. “There simply isn’t a path to get from Sacramento to San Diego, let alone from San Francisco to LA,” he claimed. “I wish there were.” Instead, he directed the project to focus on the 172-mile stretch between Merced and Bakersfield, through which an eventual route from San Francisco to Los Angeles might run. Crucially, Newsom also cut funding that should have gone to the geological surveys needed for designing the tunnels required to punch through the Diablo range south of San Francisco and San Gabriel Mountains north of Los Angeles — thereby fulfilling his own prophecy.</p><p>Initially, Newsom also didn’t put political capital to work to push for more funding for the project. Indeed, for the first few years of his tenure, $4.1 billion in Prop 1A bond funds remained unallocated by the state legislature and thus unavailable for the project to use. It wasn’t until 2021, as debates about Biden-era federal infrastructure funding began, that Newsom finally began to pressure the legislature to release these funds to the project in hopes of attracting new federal matching funds. The legislature released the remaining bond funds in 2022, and that renewed state investment may indeed have played a role in the <a href="https://pelosi.house.gov/news/press-releases/pelosi-announces-landmark-3-billion-federal-investment-california-high-speed">award of $3.07 billion in federal infrastructure funds in the fall of 2023</a>.</p><p>With all this in mind, we can start to look at common criticisms of California High-Speed Rail in a different light. These critiques — maybe you’ve seen them on Twitter — generally glibly identify solutions or alternatives that are insufficient to address the rail’s real issues, and focus attention on the wrong problems.</p><p>&nbsp;One regular snipe is that it’s “easier to build rail in Morocco than in California.” This critique stems from the fact that the French national railroad company, SNCF, which participated early in the planning process before 1A passed, also helped design the Moroccan Al Boraq high-speed rail service. Such critics often note that the Al Boraq service is operational today and claim that the relative failure of the California High-Speed Rail “boondoggle” represents the political dysfunction of either California, the United States, or the West as a whole. This appears to be based entirely on one quote in the <em>New York Times</em>,<em> </em>from an SNCF project manager, that the company left for Morocco, “which was less politically dysfunctional.” In fact, SNCF has employees in 120 countries and has projects in Israel, Taiwan, and South Korea, among others.</p><p>This criticism also misunderstands one of the main challenges that CAHSR has faced. Al Boraq had full funding lined up before the project began. CAHSR did not. This led to delays that reduced support and encouraged critics, which starved it of funding commitments and thus led to further delays. California undermined CAHSR from the start.&nbsp;</p><p>Another common criticism, as laid out in <a href="https://benjaminschneider.substack.com/p/california-high-speed-rails-original">an article by Benjamin Schneider</a>, is that California High-Speed Rail is built in the wrong place, to the wrong standards, and with the wrong goals — and that’s why it failed. The argument goes like this: The currently planned alignment through the Central Valley makes building unnecessarily complicated. Because it goes through major population centers — Bakersfield, Merced, Fresno — it introduces the necessity of grade separations (bridges or tunnels built so that trains and vehicles pass over or under each other) and requires complex property acquisitions. The right place to build the rail alignment is a direct route between Los Angeles and San Francisco paralleling Interstate 5.&nbsp;</p><p>This was, in fact, the route proposed by SNCF prior to Prop 1A’s passing. The I-5 alignment would save mileage, reduce grade separations and utility relocations, and use property already under the control of the state’s department of transportation. These cities could then perhaps be connected with branch lines to the high-speed rail trunk, establishing a line through the Central Valley with a faster build out and lower cost compared with the more expensive “political” route directly through Central Valley cities and towns.</p><p>&nbsp;Although it has intuitive appeal, this proposal suffers from major issues. First, the I-5 route avoids every major population center in the Central Valley, bypassing more than a million people who would be unserved. The only way to connect them to the line would be through stub-end branch lines. Building these lines would add the same kinds of costs as the as-built line directly through the Central Valley cities while offering them worse service. Second, it’s quite possible the I-5 alignment would never have been popular enough to pass as a ballot proposition. The Central Valley population areas only narrowly voted in favor of 1A. Had the original proposal outlined in the ballot initiative offered a different route from which Central Valley residents would not benefit, it’s possible it would not have passed at all.<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>Third, much has been made of the fact that construction has begun on the middle section of the alignment rather than in Los Angeles or San Francisco. This is, in fact, standard practice in building high-speed rail around the world. The route alignment as selected means that even if the Central Valley portion of the rail is all that operates within the next decade, it will still see service, as it will replace the existing Amtrak line that already carries a million riders a year between the Central Valley population centers. Only if the Central Valley alignment had been selected would CAHSR actually the “train to nowhere” that critics deride it as.&nbsp;</p><p>&nbsp;Perhaps most importantly, critics appear to forget that the Central Valley alignment, political or not, overambitious or not, <em>is nearly built</em>. The property is acquired and cleared, embankments are under construction, and many viaducts and bridges have been completed. Abandoning it in the current state and switching to I-5 would almost certainly cost more than finishing the current alignment.</p><p>And this alignment isn’t the real problem, anyway. The true cost driver for CAHSR isn’t the difference between I-5 and the Central Valley, but access <em>into</em> Los Angeles and San Francisco. There, the challenge is not permits or politics but geology. While rail services like Metrolink’s Antelope Valley commuter line in Los Angeles and the Altamont Corridor Express in San Francisco do already cross the mountains, these are slow trains — necessarily so, because of the tortuous route demanded by the terrain. According to the 2024 California High-Speed Rail business plan, the total cost of the three major required tunnels is expected to make up approximately half of the total project cost. The Central Valley’s 172 miles under construction and advanced planning are estimated to cost up to $33 billion. The total to get from the Central Valley into the Los Angeles region is expected to be $34 billion, while at the north end of the Central Valley, the link from the Central Valley to the San Francisco Bay region is expected to cost $20 billion, including the tunnel and improvements along existing rail corridors from San Jose to Gilroy. These costs can’t be blamed on Californian political dysfunction: These are tunnels on the scale of the Gotthard Base Tunnel through the Alps in Switzerland, which had a similar cost-per-mile.&nbsp;</p><p>A second line of criticism comes from the abundance movement. <a href="https://archive.ph/pYBxj">Critics like Ezra Klein emphasize</a> the problems created by environmental permitting and cooperating with utilities, and other existing interests like the freight railroads and (mostly Republican) landowners. All of these are real problems, and each has been a factor in delaying CAHSR. Environmental review has taken over a decade. Breaking ground sometimes uncovered new lawsuits. The entire project has been negotiated and renegotiated, inflating prices at each step. But every single one of these problems is also faced by other infrastructure projects — new bridges and highways in particular — that manage to proceed in spite of regulatory difficulties. &nbsp;</p><p>One major reason that highway infrastructure succeeds where CAHSR has failed is that such projects are routine. Highways have assured funding from federal and state sources. They also have significant political support from state and federal officials. More to the point, there is an industry of professionals experienced in both building roads and navigating the red tape necessary to make doing so possible. The equivalent network for American high-speed rail does exist — yet.&nbsp; This is part of the reason that high-speed rail costs many times as much in the United States as it does in European countries. Unless we actually commit to building <em>and finishing</em> high-speed rail, that network will never form.</p><p>Many commentators have suggested the project cut its losses and bow out. But one piece missing from the discourse is an accurate understanding of what the project has cost to date and what it needs to be completed. This problem dates to the earliest days of the project. If the CAHSR has an original sin, it is that the bond issue that went before voters didn’t ask for enough money. Early business plans in 2008 expected a total budget of $33 billion to be sufficient, approximately $50 billion today with inflation. Because the expectation was that federal government or private investment would bear much of this cost, the bond issue requested less than a third of the amount needed even in these early estimates.<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>It was only in 2011, once the project was able to finalize more of the route plan in detail, that the projected price rose to $65 billion. Inflation adjusted, that is $94 billion today — close to the base-cost estimate of $106 billion from the 2024 business plan that so many have critiqued. As many critics have rightfully and fairly noted, this is a higher cost-per-mile of track than in many countries that routinely build high-speed rail. But America, of course, does not routinely build high-speed rail, and the project remains only slightly more expensive than it was forecasted to be 13 years ago. Most important, to date, CAHSR has spent only about $15 billion, which has limited the ability to proceed with extensive planning beyond the Central Valley. It has also stopped the award of any new heavy construction contracts since the initial 119 miles of Construction Packages 1 through 4. Work has begun on the next 50 miles of civil construction to bring tracks to Merced, where they will connect with ACE and San Joaquins train services to San Francisco and Sacramento, and to Bakersfield, where connections are available via Amtrak Thruway bus service into Los Angeles. Contracts are also intended to be issued this year for the tracks, overhead electrical system, and trains to run the initial segments.&nbsp;</p><p>This money has also paid for contributions to the electrification of Caltrain in San Francisco, grade separations removing freight crossings from streets in Los Angeles, and the complete environmental clearance and basic geotechnical design of the entire route from Los Angeles to San Francisco. Completing the Central Valley segment will cost between $4 and $7 billion.&nbsp;</p><p>The additional funding required to reach San Francisco and Los Angeles to complete the core route will be approximately $80 billion. This is a lot of money, but as inflation-adjusted estimates show, it is not due purely to incompetence and cost overruns. More to the point, California can afford projects on a similar scale. The recent BART extension to San Jose is expected to cost $12.75 billion, and Caltrans receives a budget of $15 billion a year. California has had substantial budget surpluses in the past decade. In 2022 alone, the surplus totaled nearly $100 billion (although the budget is now roughly balanced). As a matter of practical economics, the project could be paid for. The question now is if the political will is there to fund it either in whole or in some revised form.&nbsp;</p><p>Despite more than a decade of predictions of its failure, the project has persevered — even if its completion is in limbo. The initial operating segment between Merced and Bakersfield is projected to begin operating in 2030. Progress is invisible to those in San Francisco and Los Angeles, and it can’t be seen just driving along I-5. But everything from satellite imagery to drone footage to a drive along State Route 43 reveals the progress being made along the 119 miles of construction underway in the Central Valley. The 22 miles making up Construction Package 4 are effectively complete, from the massive Wasco Viaduct, where the high-speed rail rises to cross over Burlington Northern and Santa Fe freight railroad tracks, to the numerous smaller-grade separation structures rising from the valley floor.</p><p>A ceremony was held in January 2025 to mark the beginning of work on the “construction railhead,” where 10 miles of freight rail yard will be built to support track laying and the erection of overhead wires in coming years. This will also include some of the first permanent high-speed tracks to be laid on the alignment. Of the 81 structures planned between Construction Packages 1-3, all but seven are underway. Seventeen structures are planned to be completed in 2025, including rail viaducts over low-lying swamps and rivers, and underpasses and overpasses that will remove grade crossings with urban streets in Fresno.&nbsp;</p><p>While no final track has yet been laid, this constitutes the vast majority of the work to prepare the route. For comparison, were this project a highway, at this stage it would need only paving and striping. If funding holds from the state, contracts for track laying and the purchase of the first train sets should go out this year. Work is also proceeding on the remainder of the route: Design work and property acquisition are underway for the next 50 miles of right-of-way extending to Merced and Bakersfield, this time phased to allow utility relocations and other local interference to be cleared ahead of construction on the main structures. All of the environmental permits are complete for extending the tunnels through Pacheco Pass to Gilroy and up to San Francisco and from Bakersfield south to Palmdale and Los Angeles. The only thing holding back construction is money.</p><p>Watching the progress has converted some former skeptics. Kings County Supervisor Doug Verboon was once a plaintiff in one of the lawsuits seeking to stop the project in its tracks. As of this year, he’s expressed support for finishing the sections of the project already underway. In an article in the <em>Hanford Sentinel </em>from December 2024, he expressed that, as chair of the San Joaquin Valley Rail Commission, he now wants to see the structures completed to make use of the investment.&nbsp;</p><p>For those who can see every day the tangible progress of the project, opposition has evolved into something quite different: doubt about whether the funding can be provided to finish the job. The dream of a complete line from San Francisco to Los Angeles remains as popular as it did when 1A first passed with 52% of the vote in 2008. <a href="https://ktla.com/news/california/majority-of-californians-still-support-high-speed-rail-project-polling-shows/">An Emerson College poll commissioned by KTLA in February</a> found that 54% of Californians still support the project. When Trump’s secretary of transportation, Sean Duffy, came to Los Angeles to announce the administration was investigating the project, he was met by a large crowd of protestors chanting “build the rail” loud enough to drown him out on press microphones.</p><p>The next four years of the second Trump administration will prove a crucial test of support from the state government. Even before Trump threatened to cut off the awarded federal funding, the Office of the Inspector General raised the possibility that the project could be between $3 and $6.5 billion short of completing the 172 miles from Merced to Bakersfield, depending on the variation in state cap-and-trade auction revenue. The project has sufficient California funds only to last through the Trump administration, complete and electrify the existing 120 miles, purchase train sets, and begin construction of the Merced and Bakersfield extensions — but not fully complete them. &nbsp;</p><p>This is not an easy project. But exaggerating the difficulties of completing it can blind us to both the possibilities and the reasons the project was — and remains — popular. A high-speed rail connection in San Jose would place the Central Valley a mere 30-45 minutes away, opening up options for new housing and commercial opportunities. Effectively, it would make something like the “California Forever” plan possible in a different region of the state, complete with high-speed rail connections directly to Silicon Valley. Long term, connecting Los Angeles to San Francisco by high-speed rail would be time competitive with flying and several times faster than driving.&nbsp;</p><p>If California politicians match action to desires, it is within California’s capability to fund the project itself. Governor Newsom and the California legislature have hinted at such a possibility. Rather than buying into the narratives of predetermined failure pushed by the project’s longtime opposition, Californian citizens and politicians should push for the project’s continuation — and for as much support as the state can give.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is outbound going to die? (106 pts)]]></title>
            <link>https://rnikhil.com/2025/04/25/sales-outbound-ai-dead</link>
            <guid>43823851</guid>
            <pubDate>Mon, 28 Apr 2025 17:28:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rnikhil.com/2025/04/25/sales-outbound-ai-dead">https://rnikhil.com/2025/04/25/sales-outbound-ai-dead</a>, See on <a href="https://news.ycombinator.com/item?id=43823851">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><blockquote><p><a href="https://news.ycombinator.com/item?id=43823851">HN Discussion</a></p></blockquote><p>I see a ton of sales/marketing products all powered by AI, making hyper personalised content to target potential users and customers. These tools now make sophisticated, high-volume paid marketing campaigns accessible to everyone, from large enterprises to individual consumers. With LLMs, the messages and content have gotten to a point where the accuracy and quality of the has improved tremendously at scale. Moreover, the scale of outbound sales has also increased rapidly. You are now able to pump out 1000s of SEO blog posts, generate reels/videos on the fly and even use AI agents to do email/phone outreach at a never before seen scale.</p><p>While I think these AI powered sales products are going to perform very well in the short run, this is also going to cause a certain about of fatigue for the users and customers. <u>(there is a small window here where companies adopting these tools are going to crush it)</u> Eventually, humans are going to get used to the constant spam and start mentally tuning out these hyper personalized initiatives. It will kill the trust, attention and the subsequent conversion rates of these products. The SEO posts won’t be read, emails and calls will go unanswered and people will start tuning out even the personalised videos.</p><p>On top of this, <strong>ALL</strong> the companies will have equal access to these tools to create content and campaigns. Imagine giving out every SaaS company in the world these tools and asking them to sell their products to the same 10000 enterprises which pretty much everybody is targeting. There is going to be so much personalised AI slop in the future.</p><h4 id="so-what-will-happen-how-will-sales-evolve-in-the-future-how-will-new-companies-build-and-acquire-users">So what will happen? How will sales evolve in the future? How will new companies build and acquire users?</h4><p>Your existing distribution will start mattering more. Having private access to the buyers or people will be absolutely important. Making personal relationships to these decision makers and other key people in the network would become compulsory since they essentially become gatekeepers. If outbound doesn’t work and it’s all going to be inbound, referrals and personal relationships will basically be everything.</p><p>We will start seeing companies build all this bottoms up. They will try to create and engineer virality on Twitter(like the <a href="http://icons.com/">icons.com</a> team) and spend a ton of money on branding (for the company and maybe the CEO). Having a good Twitter/social media presence will become a compulsory pre-condition. The company owned channels (like websites, email lists or apps) where you have direct access to customers will become key demand generation pipelines. These will generate organic growth as satisfied customers and partners naturally promote the business.</p><p>The community and network effects will become critical competitive advantages. Companies will invest heavily in building engaged and trusted user communities, starting platforms where users create value for each other, and developing network driven acquisition strategies. These interconnected relationships will generate demand, creating defensible moats against competitors relying solely on paid acquisition.</p><p>If you are working on alternative sales/GTM products working on the above problem, please reach out to me.</p><span><time datetime="2025-04-25T00:00:00+00:00">April 25, 2025</time> · </span></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Side Hustle From Hell (319 pts)]]></title>
            <link>https://blog.jacobstechtavern.com/p/the-side-hustle-from-hell</link>
            <guid>43823620</guid>
            <pubDate>Mon, 28 Apr 2025 17:05:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jacobstechtavern.com/p/the-side-hustle-from-hell">https://blog.jacobstechtavern.com/p/the-side-hustle-from-hell</a>, See on <a href="https://news.ycombinator.com/item?id=43823620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><blockquote><p><em>Being exploited by a startup is almost a rite of passage. I don’t think I can even call this a cautionary tale, because of what I took out of the experience.</em></p></blockquote><blockquote><p><em>Subscribe to Jacob’s Tech Tavern for free to get ludicrously in-depth articles on iOS, Swift, tech, &amp; indie projects in your inbox every week.</em></p><p><em><span>Full subscribers unlock </span><a href="https://blog.jacobstechtavern.com/t/quick-hacks" rel="">Quick Hacks</a><span>, my advanced tips series, and enjoy my long-form articles </span><strong>3 weeks </strong><span>before anyone else.</span></em></p></blockquote><blockquote><p><em><span>To </span><a href="https://news.ycombinator.com/item?id=43823620" rel="">celebrate going viral on Hacker News</a><span>, I’m offering </span><strong>35% off</strong><span> for new subscribers. Grab it today to lock in the price forever!</span></em></p></blockquote><p data-attrs="{&quot;url&quot;:&quot;https://blog.jacobstechtavern.com/subscribe?coupon=8f8f6123&amp;utm_content=155578632&quot;,&quot;text&quot;:&quot;Get 35% off forever&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://blog.jacobstechtavern.com/subscribe?coupon=8f8f6123&amp;utm_content=155578632" rel=""><span>Get 35% off forever</span></a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png" width="1200" height="857.1428571428571" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1040,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:2188644,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://blog.jacobstechtavern.com/i/155578632?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18242a29-2f8d-46e3-8f08-8f164012ce7a_1680x1200.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Gather ‘round, friends. This one has been a long time coming. </p><p>Grab a beer, we’ve got time 🍺. </p><p>This is a cautionary tale—one which left me scarred, jaded, and wiser. I hope that by reading this story, I can protect some of you from 11 months of pain.</p><p>The year was 2019.</p><p>My migration from academic overachiever to professional underachiever was an overwhelming success, as a slightly under-levelled junior at a big consultancy shop. But I couldn’t shake the feeling I was destined for great things.</p><p><span>I was engulfed by the daydreams many 24-year-olds experience when they stop being described as “precocious” and start spending their commutes listening to billionaires on podcasts. As my parasocial relationships to Peter Thiel and Reid Hoffman took hold, I was pretty sure I could become the next Jeff Bezos, or </span><em>at least</em><span> the next Drew Houston—I just had to </span><em>execute</em><span> well. </span></p><p>The chance of a lifetime fell into my inbox through a friend of a friend of a friend. I was put in touch with Jimmy, the cofounder &amp; Chief Financial Officer of a startup. His team was on the lookout for someone that knew mobile apps, to advise their startup and put out a few fires. </p><p><span>Involvement with a </span><em>Startup</em><span>.</span></p><p><span>In an </span><em>Advisory Capacity.</em><span> </span></p><p>If my weeks of tech consultancy training, and several years in mobile development, had prepared me for anything: it was this.</p><p>The venture was operating in stealth mode (if you don’t count the website), so Jimmy was cagey with the details until our initial call. I understood—as (probably) the next Zuckerberg, you need to be careful with your ideas around me.</p><p>We got on great. I briefed him on my credentials and showcased my passion for startups, and he told me I’d be a great fit for the team. It was a done deal. I’d taken the first step to fulfilling my destiny as the next great startup (advisor).</p><p>Fixr was the operating system for your car. It was the one-stop shop connecting you to qualified, vetted mechanics in your local area for anything your car needs—annual MOT, on-demand repair, and even roadside recovery. </p><p>Fixr had been operating for close to 3 years under a crack team of 3 part-time visionaries: </p><ul><li><p>Jimmy (CFO) — an innovation manager at a consultancy </p></li><li><p>Kim (CMO) — a legal associate at an accounting firm </p></li><li><p>Mike (COO) — a mechanic </p></li></ul><blockquote><p><em>*I changed some names and obfuscated a few details outside the public domain; please simply imagine the cast of Better Call Saul. While you’re at it, feel free to picture me as Tony Dalton.</em></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png" width="1456" height="1040" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1040,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2118504,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F807ac2f6-6335-427d-814c-50cfd87cd00e_1680x1200.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In a few short years, the team had an impressive collection of achievements:</p><ul><li><p>Securing some startup capital to fund development, from a personal bank loan.</p></li><li><p>Winning a pitch contest at a local university.</p></li><li><p>Potential interest from VCs and accelerators, subject to getting traction.</p></li><li><p>Registering with the UK SEIS scheme; giving a tax break on seed investment.</p></li><li><p>Arranging a referral partnership, where we could get paid for convincing mechanics to switch banks. </p></li><li><p>Extensive market research, speaking to hundreds of mechanics, with nearly all of them expressing interest in joining the platform when launched. </p></li><li><p>Contriving a financial model demonstrating how £250k of seed funding will be transformed into £3M in revenue, with operations across Europe, by year 3. </p></li><li><p>A live static landing page, hosted on an AWS EC2 Medium server.</p></li><li><p>4 mostly-built apps for customers &amp; mechanics, on iOS &amp; Android.</p></li></ul><p>That final point was where they needed some expertise. Most of their bank loan runway had been burned on an overseas contractor they fired after 2 years, for incompetence. They switched to a Hyderabad-based agency, who were sanding off the rough edges and getting the 4 apps ready for launch day.</p><p><span>I met up with Jimmy for some casual in-person end-to-end testing of the near-finished product and… </span><em>Oh boy.</em></p><p>One could say the app wasn’t quite production-ready.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png" width="1456" height="881" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/acde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:881,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1171217,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Facde6e3d-3cc9-4794-a2ef-197b98b811dc_1902x1151.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Turns out the storyboards were locked to iPhone 4s dimensions—this is how they rendered on my shiny new XR</figcaption></figure></div><p><span>In my advisory capacity, I was in charge of speaking to the agency and communicating the many, many, </span><em>many</em><span> bugs that remained. This is where I got my first taste of gaslighting from a </span><em>client relationship manager</em><span> whose job is to keep suckers on the hook.</span><em> </em></p><blockquote><p><em>“We agreed to the previous list of fixations only and never agreed anywhere as the part of the agreement. Please refer the email snapshot above.”</em></p><p><em>“Look at the specification. It does not specify anywhere we were asked to support screen dimensions larger than iPhone 4s sized.”</em></p><p><em>“The stripe payment integration is not of the phone application, you do not need this from us”</em></p></blockquote><p>Things looked a little bleak with the late 2019 launch date, so I suggested to Jimmy perhaps I could help squash some of these bugs. The cofounders didn’t have access to the code repo, so I had to spend more time battling the relationship manager for access.</p><p>And eventually, I got it.</p><blockquote><p><em>“Far, far below the deepest delving of FAANG and big consultancies, the world is gnawed by nameless devs. Even Bill Gates knows them not. They are older than he. Now I have walked there, but I will bring no report to darken the light of day.”</em></p><p><em>—Gandalf, a famous staff engineer</em><span> </span></p></blockquote><p>I saw only one way to bring Fixr to market. </p><p><span>We would need a </span><em>full rewrite</em><span>. </span></p><p>Despite being £20,000 in the hole across 4 apps, the management team didn’t take  much convincing to let go of a sunk costs. I whipped up a quick live-demo of a modern iOS map app, with custom photo location pin, plus an input form and photo capabilities.</p><p>In one Monster-and-Elvanse-fuelled night of passion, I was light years ahead of a build that had taken 3 years. They were sold.</p><p>In order to justify the extra time investment, I was provisionally brought on as cofounder and CTO. But we had a marketplace to build, and two platforms to serve. We needed an “Android guy”. I knew just the person: Gus. </p><p>Like me, he was keen on the idea, and in the market for a new side project. At a pre-lockdown party, I sold the dream: this product lives or dies via the traction we get in the next couple of months.</p><blockquote><p><em>Dragging my good friend into the blender is a regret, but we kept each other sane through the subsequent 9 months.</em><span> </span></p></blockquote><p>Despite being late to the party, the team valued our potential contributions at 10% apiece—the level required to get into Y Combinator. </p><p>To make things official, and certify our equity stakes, Kim drew up contracts, which were quite obviously rehashed drafts of the contracts they gave the original ill-fated dev agency, plus a very spicy clause pertaining to equity shares.</p><blockquote><p><em>The Management Team may terminate this agreement and reduce or fully remove the equity held by the Developer where the Development Services are not sufficiently met. This clause is to be carried out at the discretion of the Management Team.</em></p></blockquote><p>I was about to sign, when Gus cleverly consulted his dad who, in a brilliant blaze of prescience, suggested we run a mile and block our teammates’ phone numbers. Gus and I knew better, and simply pushed the team to change the wording to “gross negligence”.</p><p>We were officially cofounders. </p><p>It was go-time.</p><p>The prevailing months flew by in a COVID-tinged haze. While everyone else was baking bread and remunerating nursing staff via saucepans, Gus and I spent every free minute turning Fixr into a serious product.</p><p>Our weekly Zoom calls had a regular push-and-pull. Gus and I presented the latest flows. Kim and Jimmy praised our progress, while pushing to expand the scope. We had to add more features to win the market as a one-stop-shop.</p><p>Engineering busywork complete, we turned to our operators.</p><ul><li><p>Kim shared her latest dream for our upcoming “viral marketing campaign” that would land thousands of sign-ups on launch day.</p></li><li><p>Mike spitballed when we might start to acquire mechanics. Perhaps we’d hook into local apprenticeship schemes once we had demand from customers. Achieving liquidity would be straightforward.</p></li><li><p><span>Jimmy went through his latest tinkering with the financial model—the cornerstone of our investment thesis—and talked us through the latest couple of emails from VC analysts who asked us to </span><a href="https://blog.jacobstechtavern.com/p/yes-actually-means-no-the-curious" rel="">“get in touch when we had traction”</a><span>.</span></p></li></ul><p>This early traction would be everything. </p><p>After months of neglecting our families, Gus and I had the MVP ready for prime-time, with a single robust user flow: </p><ul><li><p>Users on the Customer apps can post local repair jobs. They can pay via the app and approve each invoice item during a repair job in real-time.</p></li><li><p>Mechanics on the companion app could bid for jobs, perform vehicle inspections, append work items during a job, and handle invoices automatically.</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png" width="728" height="352.6679245283019" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:1027,&quot;width&quot;:2120,&quot;resizeWidth&quot;:728,&quot;bytes&quot;:1097509,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F676bf9e9-6be8-4ec4-ac9e-1df899844d1e_2120x1027.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Screens from our Android MVP. The iOS build is lost to time.</figcaption></figure></div><blockquote><p><em>Fun fact, this project is how I cut my teeth on SwiftUI 1.0. The screenshots are lost to time (and dodgy source control), but the internal architecture was a hot mess. </em></p><p><em>Early UIKit inter-op was janky and it was difficult to pass state about. This was a problem when two of our major features used the Google Maps SDK (MapView didn’t exist!) and the camera.</em></p><p><em>A gigantic @EnvironmentObject singleton controlled the entire app state, and because NavigationView was so broken in SwiftUI 1.0, every screen transition was a modal. </em></p></blockquote><p>This flow worked phenomenally, across our suite of 2 iOS apps and 2 Android apps. But it wasn’t enough for our cofounders. We had to have on-demand roadside recovery. We needed to include annual MOT checks. Flame decals are a must-have. Anything you need for your car, we had to be.</p><p>Gus and I noticed we actually had vertebrae, and pushed back hard.</p><p><span>Implementing their vision would take a full-time team multiple years. We had the MVP. We had to </span><em>launch</em><span> instead of spinning our wheels for another 3 years. Our cofounders had to stop dreaming and start operating.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png" width="1456" height="571" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:571,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1764067,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff15b1ea8-c14f-49d8-bdb6-8738292646e4_2210x866.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Everything was ready to release in App Store Connect and the Google Play Store. </p><p>4 apps. One dream. Billions in potential.</p><p><span>We pressed the button. </span><strong>Release</strong><span>.</span></p><p>and…</p><p>Crickets.</p><p>Without any waitlisted mechanics, our imaginary viral marketing campaign was dead before it began. We had nothing on either side of our car repair marketplace for anything more than a tech demo.</p><p>Faced with the cold, harsh reality of zero users, zero revenue, and zero funding, Gus and I had a moment of clarity. We asked ourselves one question. </p><blockquote><p><em>WTF had our cofounders been doing this whole time?</em></p></blockquote><p>It’s probably time to tell you that Jimmy and Mike despised each other. Jimmy didn’t respect Mike’s intelligence or commitment. Mike didn’t like Jimmy on a personal level. One of Kim’s primary roles in the business was as mediator between the two.</p><p>Unbeknownst to Gus and myself, our tidy 10% equity packages were mostly carved out of the hog carcass of Mike’s original third share. Jimmy, as chief visionary and de-facto CEO, had a capricious habit of unilaterally reallocating equity based on how much value he thought you brought to the table.</p><p>I was never in the room when these conversations happened, but Gus and I were immune to this chicanery—we’d negotiated our contractual protections up to “gross negligence”—a fairly high legal bar.</p><blockquote><p><em>Gus’ dad is looking preeety smart right now.</em></p></blockquote><p>The incompetence of the original dev agencies concealed a far deeper issue. The apps Gus and I hacked together? Not pretty. Worked brilliantly. </p><p>We were no longer sitting on a product problem, and the abject failure of the startup to achieve anything meaningful in 3 years no longer had anything to hide behind.</p><p>I spent summer hustling to bail out the sinking ship:</p><ul><li><p>I sat with Mike to reach out to mechanics and bootstrap our supply-side, trying to start at the town level.</p></li><li><p>I helped Kim to set up social media ads to bolster the demand-side, running campaigns in target towns to nurture local liquidity. </p></li><li><p>I wanted to go all-in: Jimmy offered to double my equity in exchange for co-signing to the business loan. Uhhh… I said I’d think about it.</p></li><li><p>I picked up some of the load of reaching out to angels, VCs, and business partners on LinkedIn.</p></li></ul><p>This grind actually landed us a potential whale: a meeting with the CTO of RAC, one of the 2 big car recovery companies in the UK.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png" width="954" height="816" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:816,&quot;width&quot;:954,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:143926,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab67bb2a-644f-4dfb-b90b-56a73505594b_954x816.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We pulled out all the stops to demo our product, impressing him with the simplicity and depth of the end-to-end repair flow from the mechanic side. Was this going well?</p><p>Astoundingly, Jimmy kept drawing attention to the £50-per-referral banking partnership we had arranged. Did he not realise they offer this to everyone?!</p><p>We staggered when asked about our sign-ups from mechanics (zero) and daily repair jobs (also zero). None of us had the presence of mind to request a more junior, less busy contact point.</p><p><span>Our collective—really, </span><em>my</em><span>, efforts—yielded nothing substantial. We didn’t have the demand to convince mechanics to sign up. We didn’t have the mechanics to supply any demand that might exist. Marketplaces are hard, it turns out. And we were not the team to build it.</span></p><p>I got a much-needed reality check at a post-lockdown family party. I enthusiastically gave my cousin the rundown on Fixr, talking him through our development process and my summer spent hustling. He simply asked, bewildered:</p><blockquote><p><em>“Why are you doing all this work and not being paid?”</em><span> </span></p></blockquote><p>Come Autumn, things still weren’t going anywhere with Fixr. </p><p>Simultaneously, my underpaid mid-level consultancy role passed me up for promotion again. I wanted out, double-time.</p><p>I performed the reluctant ritual of reaching out to recruiters. On learning about my recent brush with startups, one recruiter suggested they had just the person to introduce me to.</p><p><span>Enter: </span><strong>Carbn</strong><span>. The app for building green habits and offsetting your emissions. </span></p><p>It was everything Fixr was not. </p><ul><li><p>A bootstrapping first-time founder, a commercial strategist who could fund a full-time salary for the right cofounder and was very generous with our equity split. </p></li><li><p>He’d shopped around several ideas, validating a high-potential market niche in the US prepared to spend money on the product.</p></li><li><p>After this validation, he committed: £10k on a solid contractor for a full set of designs; shaping the early roadmap for our early product work and giving us a solid branding foundation. </p></li><li><p>The guy whipped out a rudimentary financial model in a few hours. Turns out it’s not that important—it’s for illustrating your runway and spending plan, not to justify an imaginary revenue number. </p></li><li><p>No clandestine activity with contracts. We hashed it out on SeedLegals over beers.</p></li></ul><p>I tendered my resignation to my cofounders and relinquished my equity. </p><p>Gus quickly followed, immediately landing on his feet as an engineer in the banking sector. With no developers to keep the pretence of activity afloat, Fixr and the team soon dissolved.</p><p>This was cathartic, but bloody hard to write. </p><p>The earliest draft of this article began on August 18, 2023. I wanted to do right by you, and waited until I could tell my story properly.</p><p><span>The temptation to annotate each paragraph with commentary was excruciating. But I wanted my naivety to speak for itself—I hope, by the end, you were also screaming </span><em>“Get out! What are you doing!?”</em><span> to both myself and Gus. </span></p><p>But do you want to know the terrible truth? </p><p><strong>I loved every minute of it.</strong></p><p><span>Like the intrepid doctor, the stoic investment banker, or the wily consultant, suffering is part of the package. I was in my element. I had my finger in every pie. I was </span><em>doing</em><span> a startup. I was </span><em>executing</em><span>, and for the first time in my professional life I wasn’t insulated from the results. I didn’t achieve my destiny of </span><em>great things</em><span>, but I’d </span><em>built</em><span> something.</span></p><p>My story is far from unique—being exploited by a startup is almost a rite of passage. I don’t think I can even call this a cautionary tale, because of what I took out of the experience. My hard-earned learning from Fixr opened another door to Carbn which I was uniquely qualified for.</p><p>If you’re early in your career (and childless), I would even go as far as to recommend a quixotic startup journey. As a 29-year-old developer, I’ve seen first-hand the compounding career benefits of side projects, in many of my colleagues and my friends.</p><blockquote><p><em>Just watch out for some of the red flags which I summarised below!</em></p></blockquote><p>I wanted to end with a quick summary of some red flags you could encounter if you find yourself mired in a satanic side hustle. </p><ol><li><p><span>If a startup has operated for a long time without launching, consider whether the team are serious. Even if you are all very driven, if your cofounders aren’t obviously A-players, your chances of outsized startup success are low (</span><em>but you might still learn a lot).</em></p></li><li><p><span>If your equity share is contingent on being cut in on a business loan, you are being asked to invest your own money. </span><em>Run</em><span>. </span></p></li><li><p>If there is political infighting between cofounders, consider whether you want to raise funds and become legally bound to these people for several years.</p></li><li><p><span>There are 2 jobs at a startup: building and selling. If you aren’t sure what your cofounders are doing, trust your </span><em>git instinct</em><span>.</span></p></li><li><p><span>Building native on multiple platforms is an extremely inefficient allocation of resources when pre-product-market-fit. Building </span><em>two</em><span> apps on each platform is just mad.</span></p></li><li><p>Startup pitch competitions are mostly a waste of time—validation comes from talking to users and iterating, not from impressing a judge. This iterating is the hard part—everyone will tell you they like your app, and most will say they’d pay for it. Unless you have deep domain knowledge, talking to 300 technicians without a working product will not yield useful validation.</p></li><li><p><span>Did I mention that I never met Kim or Mike in person? COVID aside, nothing beats the magic of hacking side-by-side to bring your dream to life. It’s not a great sign if </span><em>all</em><span> your communication is remote.</span></p></li><li><p><span>Marketplace startups are often considered the hardest software startups to build, because you have to create two markets at once. They work best with </span><strong>frequent </strong><span>and </span><strong>inexpensive </strong><span>transactions (from which you can reasonably take a 20% cut).</span></p></li><li><p><span>When VCs tell you “</span><em>talk to us again when you have traction”</em><span>, they mean </span><em><a href="https://blog.jacobstechtavern.com/p/yes-actually-means-no-the-curious" rel="">“if you prove there is a market opportunity and that you can execute as a management team, then we might consider you. But because I don’t believe either of those things will happen, I will not be taking a risk on you”.</a></em></p></li><li><p><span>It’s also a red flag if you aren’t vetted much </span><em>yourself</em><span>. If a company takes you on, consider if they want you based on merit, or whether </span><strong>you are the first engineer who agreed to work for free.</strong></p></li></ol><blockquote><p><em>Thanks for reading Jacob’s Tech Tavern! I hope you enjoyed my story. 🍺 </em></p><p><em><span>If you enjoyed this, please consider paying me. Full subscribers to Jacob’s Tech Tavern unlock </span><strong><a href="https://blog.jacobstechtavern.com/t/quick-hacks" rel="">Quick Hacks</a></strong><span>, my advanced tips series, and enjoy my long-form articles </span><strong>3 weeks </strong><span>before anyone else. </span></em></p><p><em><span>To </span><a href="https://news.ycombinator.com/item?id=43823620" rel="">celebrate going viral on Hacker News</a><span>, I’m offering </span><strong>35% off</strong><span> for new subscribers. Grab it today to lock in the price forever!</span></em></p></blockquote><p data-attrs="{&quot;url&quot;:&quot;https://blog.jacobstechtavern.com/subscribe?coupon=8f8f6123&amp;utm_content=155578632&quot;,&quot;text&quot;:&quot;Get 35% off forever&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://blog.jacobstechtavern.com/subscribe?coupon=8f8f6123&amp;utm_content=155578632" rel=""><span>Get 35% off forever</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reality Check (116 pts)]]></title>
            <link>https://www.wheresyoured.at/reality-check/</link>
            <guid>43823492</guid>
            <pubDate>Mon, 28 Apr 2025 16:53:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/reality-check/">https://www.wheresyoured.at/reality-check/</a>, See on <a href="https://news.ycombinator.com/item?id=43823492">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p>I'm sick and god-damn tired of this! I have written tens of thousands of words about this and still, to this day, people are babbling about the "AI revolution" as the sky rains blood and crevices open in the Earth, dragging houses and cars and domesticated animals into their maws. Things are astronomically fucked outside, yet the tech media continues to tell me to get my swimming trunks and <em>take a nice long dip in the pool.</em></p><p>I apologize, this is going to be a little less reserved than usual.</p><p>I don't know why I'm the one writing what I'm writing, and I frequently feel weird that I, a part-time blogger and podcaster, am writing the things that I'm writing. Since I put out <a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/"><u>OpenAI Is A Systemic Risk To The Tech Industry</u></a>, I've heard <em>nothing</em> in response, as was the case with<a href="https://www.wheresyoured.at/to-serve-altman/"> <u>How Does OpenAI Survive?</u></a> and<a href="https://www.wheresyoured.at/oai-business/"> <u>OpenAI Is A Bad Business</u></a>.&nbsp;</p><p>There seems to be little concern — or belief — that there is <em>any</em> kind of risk at the heart of OpenAI,<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=As%20a%20note,run%20this%20company."> <u>a company that spent $9 billion in 2024 to <em>lose $5 billion</em></u></a><em>. </em>While I'd love to add a "because..." here, if not because it’s important to be intellectually honest and represent views that directly contrast my own, even if I do so in a somewhat sardonic fashion, nobody seems to actually have a cogent response to how they right this ship other than Hard Forker<a href="https://bsky.app/profile/edzitron.com/post/3lmkahymkec2t?ref=wheresyoured.at"> <u>Casey Newton throwing a full-scale tantrum on a podcast</u></a> and saying I'm wrong because "inference costs are coming down."</p><p>Newton is a nakedly-captured booster that<a href="https://www.platformer.news/people-are-using-ai-to-learn-more/?ref=wheresyoured.at"> <u>ran an infographic from Anthropic a few weeks ago the likes of which I haven't seen since 2013</u></a>, but he's far from the only one with a flimsy attachment to reality.</p><p><a href="https://www.theinformation.com/articles/openai-forecasts-revenue-topping-125-billion-2029-agents-new-products-gain?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information ran a piece a couple of weeks ago</u></a> that made me furious, which was a surprise because — for the most part — their coverage of tech, and especially AI, has been some of the best around, and they generally avoid the temptation to be shills for shaky and unsustainable tech companies.&nbsp;</p><p>The story claimed that OpenAI was "forecasting revenue topping $125 billion in 2029" based on "selling agents" and "monetizing free users...as a driver to higher revenue." The piece, reported out based on things "...told [to] some potential and current investors," takes great pains to accept literally everything that OpenAI says as perfectly reasonable, if not gospel, even if said things make absolutely no sense.</p><p>According to The Information's reporting, OpenAI expects "agents" and "new products" to contribute tens of billions of dollars of revenue, both in the near-term (somehow contributing $3 billion in revenue this year, which I'll get to in a little bit) and in the long-term, with an egregious $25 billion in revenue in 2029 projected to come from "new products."&nbsp;</p><p>If you're wondering what those new products might be, I am too, because The Information doesn't seem to know, and instead of saying "OpenAI has no idea what the fuck they're talking about and is just saying stuff," the outlet chooses instead to publish things with the kind of empty optimism that's indistinguishable from GPT-generated LinkedIn posts.</p><p><em>Check out this fucking chart.</em></p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcTvV_KScCMt6maPCLAD5qACLXB0A9UFlxBy7vmR4oO6y99lGkJJOfKhOCB9a3-GeZrY83n6xFepHBUxmf4fUXpDuYAypFPjGBTV-i1B8xYCkhZ1JaIaiAkpUazxVVqwjbiVJF9?key=5iQ8LZzyYfTKSGqXLxb-sOQh" alt="" loading="lazy" width="624" height="624"><figcaption><span>The Information — OpenAI Forecasts Revenue Topping $125 Billion in 2029 as Agents, New Products Gain</span></figcaption></figure><p>I want to be really, really clear: we are nearly in May 2025, and I see no evidence <strong><em>that OpenAI even has a marketable agent product, let alone one that will make it <u>three billion god damn dollars in the next six or seven months.</u></em></strong></p><p><em>For context, that’s triple the revenue OpenAI reportedly made from selling access to its models via its APIs — essentially allowing third-party companies to use GPT in their apps — in the entirety of 2024. And those APIs and models actually exist in a meaningful sense, as opposed to whatever the fuck OpenAI’s half-baked Agents stuff is.&nbsp;</em></p><p>In fact, no, no, I'm not going to be mean, I'm going to explain exactly what The Information is reporting in an objective way, because writing it out really shows how silly it all sounds. I am going to write "they believe" a lot because I must be clear how stupid this is:</p><ul><li>According to The Information's reporting, <strong>they believe that OpenAI will make $3 billion in 2025 from selling access to its agents in 2025</strong>. This appears to come from SoftBank,<a href="https://www.theinformation.com/briefings/softbank-pledges-to-spend-3-billion-annually-on-openai?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>which has said it will buy $3 billion worth of OpenAI products annually</u></a>.</li><li>Earlier this year, we got a bit of extra information about how SoftBank would use those products. It plans to <a href="https://group.softbank/en/news/press/20250203_0?ref=wheresyoured.at"><u>create a system called Cristal Intelligence</u></a> that will be a kind-of general purpose AI agent platform for big enterprises. The exact specifics of what it does is vague (shocker, I know) but SoftBank intends to use the technology internally, across its various portfolio companies, as well as market it to other large enterprise companies in Japan.&nbsp;&nbsp;</li><li>I also want to add that The Information can't keep its story straight on this issue.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?ref=wheresyoured.at&amp;rc=kz8jh3"> <u>Back in February</u></a>, they reported that OpenAI would make $3 billion in revenue <em>only from agents,</em> with a big, beautiful chart that said $3 billion would come from “it," only to add that “it” would be SoftBank "...[using] OpenAI's products across its companies."&nbsp;</li><li>Based on these numbers, it seems like SoftBank will be the <em>only</em> customer for OpenAI’s agents. While this won’t be the case — and isn’t, because it excludes anyone willing to pay a few bucks to test it out — it nonetheless doesn’t signal good things for Agents as a mass market product.&nbsp;&nbsp;<ul><li>Agents do not exist as a product that can be sold at that scale.<a href="https://www.theinformation.com/articles/ai-agents-fall-short-shopping?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information's own reporting from last week</u></a> highlighted how OpenAI’s "Operator" agent "struggle[d] with comparison shopping on financial products," and how Operator and other agents are "...tripped by pop-ups or logins, as well as prompts asking for email addresses and phone numbers for marketing purposes," which I think accurately describes <em>most of the internet.</em></li><li><strong>To summarize, The Information is saying that the above product will make OpenAI <em><u>three billion dollars by the end of the year.</u></em></strong></li></ul></li><li>According to The Information's reporting, <strong>they believe that OpenAI will basically double revenue every single year for the next four years</strong> and make $13 billion in revenue in 2025, more than doubling that to $29 billion in 2026, nearly doubling that to $54 billion in 2027, nearly doubling that to $86 billion in 2028, and eventually hitting $125 billion in 2029.<ul><li>Said revenue estimates, as of 2026, include billions of dollars of "new products" that include "free user monetization."<ul><li>If you are wondering what that means, I have no idea. The Information does not explain. They do, however, say that "OpenAI won’t start generating much revenue from free users and other products until next year. In 2029, however, it projects revenue from free users and other products will reach $25 billion, or one-fifth of all revenue," and said that "shopping is another potential avenue."</li></ul></li></ul></li></ul><p>I cannot express my disgust about how willing publications are to blindly publish projections like these, especially when they're so utterly ridiculous. Check out this quote:</p><blockquote>OpenAI has already begun experimenting with launching software features for shopping. Starting in January, some users can access web-browsing agent Operator as part of their pro ChatGPT subscription tier to order groceries from Instacart and make restaurant reservations on OpenTable.</blockquote><p>So you're saying this <strong><em>experimental software launched to an indeterminate amount of people that barely works is going to make OpenAI $13 billion in 2025, and $29 billion in 2026, and later down the line $125 billion in 2029? How? <u>How?</u></em></strong></p><p>What fucking universe are we all living in? There's no proof that OpenAI can do this other than the fact that it has a lot of users and venture capital!&nbsp;</p><p>In fact, I think we have reason to worry about whether OpenAI even makes its current projections.<a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/#:~:text=Bloomberg%20reported%20recently,to%20%243.43%20billion)."> <u>In my last piece</u></a> I wrote that Bloomberg had estimated that OpenAI would triple revenue to $12.7 billion in 2025, and based on its current subscriber base,<a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/#:~:text=The%20Information%20reported%20back%20in%20January"> <u>OpenAI would have to effectively double its <em>current</em> subscription revenue <em>and massively increase its API revenue </em>to hit these targets</u></a>.</p><p>These projections rely on <strong><em>one entity (SoftBank) spending $3 billion on OpenAI's services, meaning that it’d make enough API calls to generate more revenue than OpenAI made in subscriptions in the entirety of 2024, and something else that I can only describe as “an act of God.”</em></strong></p><blockquote>That, I admit, assumes that Softbank’s spending commitment is based on usage, and not a flat fee (where Softbank pays $3bn and gets a set — or infinite — level of access). Assuming it’s the former, I’d be stunned if SoftBank’s consumption hits $3bn this year, even with the massive cost of the reasoning models that Cristal Intelligence will be based on. Softbank announced its deal with OpenAI in February.&nbsp;<p>Cristal Intelligence, if it works — and that is possibly the most load-bearing “if” of all time — will be a massive, complicated, ambitious product. Details are vague, but from what I understand, SoftBank wants to create an AI that handles the infinitely varied tasks that knowledge workers perform on a daily basis.&nbsp;</p><p>To be clear, OpenAI’s agents cannot consistently do, well… <em>anything</em>.&nbsp;</p></blockquote><p>What I believe is happening is that reporters are taking<a href="https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html?ref=wheresyoured.at"> <u>OpenAI's rapid growth in revenue from 2023 to 2024</u></a> (from tens of millions a month at the start of 2023 to $300 million in August 2024) to mean that the company will always effectively double or triple revenue every single year forever, with their evidence being "OpenAI has projected this will be the case."</p><p>It's bullshit! I'm sorry!<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=ChatGPT%20is%20popular,and%20unsustainable."> <u>As I wrote before</u></a>, OpenAI effectively <em>is</em> the generative AI industry, and nothing about the <em>rest</em> of the generative AI industry suggests that the revenue exists to sustain these ridiculous, obscene and fantastical projections. Believing this — and yes, reporting it objectively is both endorsing and believing these numbers — is engaging in childlike logic, where you take one event (OpenAI's revenue grew 1700% from 2023 to 2024! Wow!) to mean another will take place (OpenAI will continue to double revenue literally every other year! Wow!), consciously ignoring difficult questions such as "how?" and "what's the total addressable market of Large Language Model subscriptions exactly?" and "how does this company even survive when it "expects the costs of inference to triple this year to $6 billion alone"?</p><p>Wait, wait, sorry, I need to be really clear with that last one, this is a direct quote from The Information:</p><blockquote>The company also expects growth in inference costs—the costs of running AI products such as ChatGPT and underlying models—to moderate over the next half-decade. Those costs will triple this year, to about $6 billion and rise to nearly $47 billion in 2030. Still, the annual growth rate will fall to about 30% then.</blockquote><p>Are you <em>fucking kidding me?</em></p><p><em>Six billion fucking dollars for inference alone? </em>Hey Casey, I thought those costs were coming down! Casey, are you there? Casey? <em>Casey?????</em></p><p><strong>Anyway, </strong>that's not great at all! That's really bad! The Information reports that OpenAI will make "about $8 billion" from subscriptions to ChatGPT in 2025, meaning that <strong><em>75% of OpenAI's largest revenue source is eaten up by the price to provide it</em></strong>. This is meant to be the cheaper part! This is the one fucking thing people say is meant to come down in price!</p><p>Are we living in different dimensions? Are there large parts of the tech media that have gas leaks in their offices? What am I missing? Tell me what I'm missing!</p><p><strong><em>Nerr, Ed, you haven't talked to the people building these things, you don't know what you're-</em></strong> shut the fuck up! Shut up! I am sick and tired of people (<a href="https://bsky.app/profile/edzitron.com/post/3lmkahymkec2t?ref=wheresyoured.at"><u>like Casey</u></a>!) suggesting that what's missing from my analysis is to "interview people who work at these companies and understand how this technology works." What would these people say to me, exactly? What response would they have to these numbers?</p><h2 id="forgive-me-im-going-to-be-a-little-rude"><strong>Forgive Me I'm Going To Be A Little Rude</strong></h2><p>In fact, you know what, let me just sit down and go through the critiques one-by-one. Some of you are going to say I'm being rude to these people and it weakens my analysis, to which I respond "kiss my entire ass." I can beat you to death with the truth while making fun of you for believing stupid things.</p><ul><li><strong>The costs of inference are coming down:</strong> Source? Because it sure seems like they're increasing for OpenAI, and they're effectively the entire userbase of the generative AI industry!&nbsp;<ul><li><strong>But DeepSeek…</strong> No, my sweet idiot child. <em>DeepSeek is not OpenAI</em>, and OpenAI’s latest models only get more expensive as time drags on. GPT-4.5 costs $75 per million input tokens, and $150 per million output tokens. And at the risk of repeating myself, OpenAI is effectively the generative AI industry — at least, for the world outside China.&nbsp;</li></ul></li><li><strong>This is the company at its growth stage, it can simply "hit the button" and it'll all be profitable:</strong> You have the mind of a child! If this was the case, why would both Anthropic and OpenAI be losing so much money? Why are none of the hyperscalers making profit on AI? Why does nobody want to talk about the underlying economics?</li><li><strong>These are the early days of AI: </strong>Wrong! We have the entire tech industry and more money than has ever been invested into anything piled into generative AI and the result has been utterly mediocre. Nobody's making money but NVIDIA!</li><li><strong>They're already showing signs that it'll be powerful: </strong>No it's not! If it was there'd be people doing crazy, impressive things with it!<ul><li><strong><em>But Ed, look at o-3</em></strong>: Oh you mean<a href="https://techcrunch.com/2025/04/18/openais-new-reasoning-ai-models-hallucinate-more/?ref=wheresyoured.at"> <u>the new and extremely expensive reasoning model that hallucinates <em>more</em> somehow</u></a>? Is that AGI? Is the AGI in the room with us now? Did it tell you it loved you?<a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html?ref=wheresyoured.at"> <u>Did it tell you to leave your wife</u></a>? I hope you're okay!!</li></ul></li><li><strong>But Ed, really, it's the early days, it was just like this in the early days of the internet: </strong>No it wasn't!<a href="https://www.wheresyoured.at/pop-culture/#:~:text=He%20also%20notes%20that%20the%20costs%20are%20so%20high%20that%20even%20if"> <u>Read Jim Covello of Goldman Sachs' note from last year</u></a>, the early days of the internet were absolutely nothing like this-<ul><li><strong>Smartphones! YES! Got you, Ed! Smartphones! People doubted those too-</strong> I am going to drown you in an icy lake! Covello's note also included an entire thing about how smartphones were fully telegraphed to analysts in advance, with "hundreds of presentations" that accurately fit how smartphones rolled out, no such roadmap exists for AI!</li></ul></li><li><strong>Heh, heh, Ed, you're so boned. Check out this article from Newsweek in 1995</strong><a href="https://www.newsweek.com/clifford-stoll-why-web-wont-be-nirvana-185306?ref=wheresyoured.at"><strong> <u>where a guy says that the internet won't be a big business</u></strong></a><strong>. This somehow proves that AI is going to be big, due to the fact one guy was wrong once: </strong>Motherfucker, have you read that piece? He basically says that the internet, at that time, was pretty limited, and yes, he conflated that with the idea that it wouldn't be big in the future. Clifford Stoll's piece also —<a href="https://www.latimes.com/business/hiltzik/la-fi-mh-actually-that-offbase-20150227-column.html?ref=wheresyoured.at"> <u>as Michael Hiltzik wrote for the LA Times</u></a> — was alarmingly accurate about misinformation and sleazy companies selling computerized replacements for education.<ul><li><strong><em>In any case, one guy saying that the internet won't be big doesn't mean a fucking thing about generative AI and you are a simpleton if you think it does. One guy being wrong in some way is not a response to my work. I will crush you like a bug.</em></strong></li><li>Stoll's analysis also isn't based on hundreds of hours of research and endless reporting. Mine is! I will grab you from the ceiling like the Wallmaster from Zelda and you will never be heard from again.</li></ul></li><li><strong>OpenAI and Anthropic are research entities not businesses, they aren't focused on profit:</strong> Okay so are they just going to burn money forever? No, really, is that the case? Or do you think they hit the "be profitable" button sometime?</li></ul><h3 id="record-scratch-wait-a-second"><strong>[Record Scratch] Wait a second...</strong></h3><ul><li><strong>OpenAI has as many as 800 million weekly active users! That's proof of adoption! </strong>Hey, woah, I get that you're really horny about this number, but something don't make no sense here! On March 31 2025, OpenAI said that it had "<a href="https://openai.com/index/march-funding-updates/?ref=wheresyoured.at"><u>...500 million people who use ChatGPT every week</u></a>." <em>Two weeks later, </em>Sam Altman claimed that "something like 10% of the world "uses our systems a lot,"<a href="https://fortune.com/2025/04/14/sam-altman-openai-user-base-doubled-few-weeks-10-of-world-uses-system/?ref=wheresyoured.at"> <u>which the media took to mean that ChatGPT has 800 million weekly active users</u></a>.</li><li><strong>Here are the three ways to interpret this, and you tell me which one sounds real:</strong><ul><li><strong>OpenAI's userbase increased by 300 million weekly active users in two weeks.</strong></li><li><strong>OpenAI understated its userbase <em><u>in the announcement of their funding announcement on OpenAI dot com</u></em></strong> <strong>by 300 million users.</strong></li><li><strong>Sam Altman <em>fucking lied.</em></strong></li></ul></li></ul><p>I get that some members of the media have a weird attachment to this nasty little man, but have any of you ever considered he’s just <em>fucking says things knowing you will print them with the kindest possible interpretation?</em></p><p><a href="https://www.wheresyoured.at/sam-altman-is-full-of-shit/"><u>Sam Altman is a liar! He lies! He's lied before and he'll lie again!</u></a></p><p><em><strong>But wait, Ed! Google says it has 350 million monthly active users on Gemini! Eat shit, Zitron! </strong></em>No, <em>you</em> eat shit! Yes, <a href="https://techcrunch.com/2025/04/23/google-gemini-has-350m-monthly-users-reveals-court-hearing/?ref=wheresyoured.at"><u>Google Gemini has 350 million monthly active users</u></a><u>.</u></p><p><a href="https://www.pcworld.com/article/2638233/so-long-google-assistant-its-geminis-world-now.html?ref=wheresyoured.at"><em><u>And that’s because it started replacing Google Assistant with Google Gemini in early March</u></em></a><em>! You are being <strong>had! You are being swindled! </strong></em>If Google replaced Google Search with Google Gemini it would have billions of monthly active users!&nbsp;</p><h3 id="anyway-back-to-the-critiques"><strong>Anyway, back to the critiques...</strong></h3><ul><li>OpenAI having hundreds of millions of <em>free users, each losing it money</em>, is proof that the <em>free version of ChatGPT is popular, </em>largely because <em>the entirety of the media has written about AI nonstop for two straight years and mentioned ChatGPT every single fucking time. </em><strong>Yes</strong> there is a degree here of marketing, of partnerships, of word of mouth, of <em>some degree of utility</em>, but remove the non-stop free media campaign and ChatGPT would've peetered out by now along with this stupid fucking bubble.<ul><li><em><strong>But Ed it's proof of something right-</strong></em> yeah! It's proof that something is broken in society. Generative AI has never had the kind of meaningful business returns or utility that actually underpins something meaningful, but it has <em>enough to make people give it a try.</em></li></ul></li></ul><h2 id="you-know-what-lets-talk-about-why-this-bubble-actually-inflated"><strong>You know what? Let's talk about why this bubble actually inflated!</strong></h2><p>So, let's start simple: the term "artificial intelligence" is bastardized to the point it effectively means nothing and everything at the same time. When people hear "AI" they think of an autonomous intelligence that can do things <em>for them</em>, and generative AI can "do things for you" like generate an image or text "from a simple prompt." As a result, it's easy to manipulate people who don't know much about tech into believing that this will naturally progress from "it can create a bunch of text for me that I have to write for my job just by me typing in a prompt" to "it can do my job for me just by typing in a prompt."</p><p>Basically everything you read about "the future of AI" extrapolates generative AI's ability to <em>sort of generate something a human would make</em> and turns it into <em>do whatever a human can do</em>, all because tech has, in the past, been bad at the beginning and linearly improved as time drags on.&nbsp;</p><p>This illogical thinking underpins the entire generative AI boom, because we've found out exactly how many people do not know what the fuck they're talking about and are willing to believe the last semi-intelligent person they talked to. Generative AI is a remarkable con — a just-good-enough simulacrum of human expression to get it past the gatekeepers in finance and the media, knowing that neither will apply a second gear of critical thinking beyond "huh guess we're doing AI now."</p><p>The expectation that generative AI will transform into something much, much more powerful requires you to first ignore the existing limitations, believing it to be more capable than it is, and also ignore the fact that these models have yet to show meaningful improvement over the past few years. They still hallucinate. They’re still ungodly expensive to run. They’re still unreliable. <em>And they still don’t do much</em>.&nbsp;&nbsp;</p><p>Worse still, ChatGPT's growth has galvanized these people into believing that this is a legitimate, meaningful movement, rather than the most successful PR campaign of all time.&nbsp;&nbsp;</p><p>Think of it like this: if almost every single media outlet talked about one thing (generative AI), and that one thing was available from one company (OpenAI), wouldn't it look exactly how things look today? You've got OpenAI with hundreds of millions of monthly active users, and then a bunch of other companies — including big tech firms with multi-trillion dollar market caps —<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Is%20Generative%20AI%20A%20Real%20Industry%3F"> <u>with somewhere between 10 and 69 million monthly active users</u></a>.</p><p>What we're seeing is one company taking most of the users and money available and doing so <em>because the media fucking helped them.</em>&nbsp; People aren't amazed by ChatGPT — they're curious! They're curious about why the media won't shut up about it!</p><h2 id="this-bubble-was-also-inflated-by-the-failure-of-google-search"><strong>This Bubble Was Also Inflated By The Failure of Google Search</strong></h2><p>Everybody I talk to that uses ChatGPT regularly uses it as either a way to generate shitty limericks or as a replacement for Google search,<a href="https://www.wheresyoured.at/the-men-who-killed-google/"> <u>a product that Google has deliberately made worse as a means of increasing profits</u></a>.</p><p>ChatGPT is, if I'm honest, better at processing search strings than Google Search, which is not so much a sign that ChatGPT is <em>good</em> at something as it is that <em>Google has stopped innovating in any meaningful way.</em> Over time, Google Search should've become something that was able to interpret your searches into the perfect result, which would require the company to <em>improve how it processes your requests.</em> Instead, Google Search has become <em>dramatically worse</em>, mostly because the company's incentives changed from "help people find something on the web" to "funnel as much traffic and show as many ad impressions as possible on Google.com."</p><p>By this point, Google Search should have been <em>more</em> magical, <em>more</em> capable of taking a dimwitted question and turning it into a great answer, with said answer being a result on the internet. Note that nothing I'm writing here is actually about generating a result — it's about processing a user's query and presenting an answer, the very foundation of computing and the thing that Google, at one point, was the best in the world at doing.<a href="https://podcasts.apple.com/us/podcast/the-man-that-destroyed-google-search/id1730587238?i=1000653621646&amp;ref=wheresyoured.at"> <u>Thanks to Prabhakar Raghavan</u></a>, the former head of ads that led a coup to become head of search, Google was pulled away from being a meaningful source of information.</p><p>And I'd argue that ChatGPT filled that void by doing the thing that people wanted Google Search to do: answer a question, even if the user isn't really sure how to ask it. Google Search has become clunky, obfuscatory, putting the burden of using the service on the user rather than helping fill the gap between query and answer in any meaningful way. Google's AI summaries don't even try to do what ChatGPT does — they generate summaries based on search results and say "okay man, uhh, is this what you want?"&nbsp;</p><blockquote>One note on Google’s AI summaries: They’re designed to answer a question, rather than provide a right answer. That’s a distinction that needs to be made, because it speaks to the underlying utility of this product.&nbsp;<p>One good illustration of this came earlier this week, when someone noticed that you could ask Google to explain the meaning of a completely made-up phrase, and it would dutifully obey. “</p><a href="https://x.com/rose_matt/status/1915355300506325282?ref=wheresyoured.at"><u>Two dry frogs in a situation</u></a>,” Google said, referred to a group of people in an awkward or difficult social situation.&nbsp;<p>“</p><a href="https://x.com/enfyscheese/status/1915356621716307979?ref=wheresyoured.at"><u>Not every insect has a mortgage</u></a>,” Google claimed,” is a humorous way of explaining that not everything is as it seems. My favorite, “<a href="https://x.com/shagbark_hick/status/1915560564065218845?ref=wheresyoured.at"><u>big winky on the skillet bowl</u></a>,” is apparently a slang term that refers to a piece of bread with an egg in the middle.&nbsp;<p>Funny? Sure. But is it useful? No.&nbsp;</p></blockquote><p>With all its data and all its talent, Google has put the laziest version of a Large Language Model on top of a questionably-functional search product as a means of impressing shareholders.</p><p>None of this is to say that ChatGPT is <em>good</em>, just that it is better at understanding a user's request than Google Search.</p><p>Yes, I fundamentally believe that 500 million people a week could be using ChatGPT as some sort of search replacement, and no, I do not believe that's a functional business model, in part because if it was, ChatGPT would've been a functional business.&nbsp;</p><p>That, and it appears that Google's ability to turn search into such a big business was because<a href="https://www.cnbc.com/2025/04/17/google-hit-with-second-antitrust-blow-adding-to-concerns-about-ads.html?ref=wheresyoured.at"> <u>it held a monopoly on search, search advertising and the entire online ads industry</u></a>, and if it was a truly competitive market and it wasn’t allowed to be vertically integrated with the entire digital advertising apparatus of the web, it would likely be making much less revenue per user. And that’s bad if your Google Replacement costs many, many times more than Google to run.&nbsp;</p><blockquote>As an aside: if you're wondering, no, OpenAI cannot "just create a Google Search competitor."<a href="https://www.wheresyoured.at/burst-damage/#:~:text=What%27s%20that%3F%20SearchGPT%3F%20Sam%2C%20you%27re%20crazy!%20There%27s%20no%20way%20you%20can%20build%20a%20Google%20Search%20competitor!%20Trust%20me%2C%20I%20know.%C2%A0"> <u>SearchGPT will be significantly more expensive to run at Google's scale than ChatGPT</u></a> — both infrastructurally and in the cost of revenue, with OpenAI forced to create a massive advertising arm that currently doesn't exist at the company.</blockquote><p>People love the ChatGPT interface — the box where they can type one thing and get another thing out — because it resembles how everybody has always wanted Google Search to work. Does it actually work? Who knows. But people feel like they're getting more out of it.</p><h2 id="lets-talk-about-agi-really-quick"><strong>Let's Talk About AGI Really Quick</strong></h2><p>This newsletter has been a break from the extremely deep and onerous analysis I've been on for the last few months, in part because I needed to have a little fun writing.</p><p>It also comes from a place of frustration. None of this has ever felt substantive or real because the actual things that you can do with generative AI never seem to come close to the things that people like Sam Altman and Dario Amodei seem to be promising, nor do they come close to the bullshit that people like Casey Newton and<a href="https://bsky.app/profile/edzitron.com/post/3ln4p3ms7522j?ref=wheresyoured.at"> <u>Kevin Roose are peddling</u></a>. None of this ever resembled "artificial general intelligence," and if I'm honest, very little of it seems to even suggest it's a functional industry.</p><p>When cynical plants like Roose bumble around asking theoretical questions such as "<a href="https://bsky.app/profile/edzitron.com/post/3ln4p3ms7522j?ref=wheresyoured.at"><u>do you think that there is a 50% chance or greater that AGI, defined as an AI system that outperforms human experts at virtually all cognitive tasks, will be built before 2030</u></a>," we should all be terrified, not of AGI, but that the lead tech columnist at the New York Times appears to have an undiagnosed concussion. Roose's logic (as with Newton's) is based on the idea that he's talked to a bunch of people that say "yeah dude AGI is right around the corner" rather than any kind of proof or tangible evidence, just "the curve is going up."</p><p>Roose’s most egregious example of this company-forward credulousness came last week, when he published <a href="https://www.nytimes.com/2025/04/24/technology/ai-welfare-anthropic-claude.html?ref=wheresyoured.at"><u>a thinly-veiled puff piece</u></a> about what to do if AI models become conscious in the near future. He interviewed two people — both employed by Anthropic, with one holding the genuinely hilarious job description of “AI welfare researcher” — who said batshit things like “there’s only a small chance (maybe 15 percent or so) that Claude or another current A.I. system is conscious” and “It seems to me that if you find yourself in the situation of bringing some new class of being into existence… then it seems quite prudent to at least be asking questions about whether that system might have its own kinds of experiences.”</p><p>What makes this so appalling is that Roose acknowledges that this shit is seen by most level-headed people as nothing less than utter fantasy. He describes the concept of AI consciousness as “a taboo subject” and that many critics will see this as “crazy talk,” but doesn’t bother to speak to any actual critics. He does, however, speculate on the motives of said critics, saying that “they might object to an A.I. company’s studying consciousness in the first place, because it might create incentives to train their systems to act more sentient than they actually are.”</p><p>Yeah Kevin, wouldn’t it be terrible if a company somehow convinced someone that their AI was more powerful than it was? Also, do you bark at the mirror every time you walk past it because you think you see another guy?</p><p>Nothing about anything that Anthropic or OpenAI is building or shipping suggests we are anywhere near any kind of autonomous computing. They've used the concept of "AI safety" — and now, AI welfare — as a marketing term to convince people that their expensive, wasteful software will somehow become conscious because they're having discussions about what to do if it does so, and anyone — literally any reporter — accepting this at face value is doing their readers a disservice and embarrassing themselves in the process.</p><p>If AI safety advocates cared about, say, safety or AI, they'd have cared about the environmental impact, or the fact these models train using stolen material, or the fact that if these models actually delivered on their promises, it would deliver a shock to the labor market that would meaningfully hurt millions — if not billions — of people, and we don’t have anywhere near the social safety net to support them.&nbsp;</p><p>These companies don't care about your safety and they don't have any way to get to AGI. They are full of shit and it's time to start being honest that you don't have any proof they will do <em>anything</em> they say they will.</p><h2 id="oh-by-the-way-the-bubble-might-be-bursting"><strong>Oh, By The Way, The Bubble Might Be Bursting</strong></h2><p>Hey, remember in August of last year when I talked about the pale horses of the AIpocalpyse? One of the major warning signs that the bubble was bursting was<a href="https://www.wheresyoured.at/burst-damage/#:~:text=Any%20suggestion%20that%20Google%20or%20Microsoft%20is%20reducing%20their%20capex%3A%20Venture%20capital%20isn%E2%80%99t%20really%20what%E2%80%99s%20propping%20up%20generative%20AI%20%E2%80%94%20it%E2%80%99s%20Google%20or%20Microsoft.%20If%20either%20of%20them%20decide%20it%E2%80%99s%20time%20to%20slow%20down%20investment%2C%20the%20boom%20is%20done%2C%20as%20referenced%20above."> <u>big tech firms reducing their capital expenditures</u></a>, a call I've made before, with a little more clarity, on April 4 2024:</p><blockquote>While I hope I'm wrong, the calamity I fear is one where the massive over-investment in data centers is met with a lack of meaningful growth or profit, leading to the markets turning on the major cloud players that staked their future on unproven generative AI. If businesses don't adopt AI <em>at scale</em> — not experimentally, but at the core of their operations — the revenue is simply not there to sustain the hype, and once the market turns, it will turn hard, demanding efficiency and cutbacks that will lead to tens of thousands of job cuts.</blockquote><p>We're about to find out if I'm right.</p><p>Last week, Yahoo Finance reported that analyst Josh Beck<a href="https://finance.yahoo.com/news/amazon-stock-falls-as-raymond-james-downgrades-shares-citing-tariff-headwinds-and-limited-ai-monetization-144747355.html?ref=wheresyoured.at"> <u>said that Amazon's generative AI revenue for Amazon Web Services would be $5 billion</u></a>, a remarkably small sum that is A) not profit and B) a drop in the bucket compared to Amazon's projected $105 billion in capital expenditures in 2025, its $78.2 billion in 2024, or its $48.4 billion in 2023.</p><h3 id="is-that-really-it-are-you-kidding-me-amazon-will-only-make-5-billion-from-ai-in-2025-what"><strong>Is That Really It? Are you kidding me? Amazon will only make $5 billion from AI in 2025? What?</strong></h3><p>5 billion dollars? <em>Five billion god damn dollars? Are you fucking kidding me?</em><a href="https://www.youtube.com/watch?v=G07sWzYObnk&amp;ref=wheresyoured.at"> <u>You'd make more money auctioning dogs</u></a>! This is a disgrace! And if you're wondering, yes! All of this is for AI:</p><blockquote>CEO Andy Jassy said in February that the vast majority of this year’s $100 billion in capital investments from the tech giant will go toward building out artificial intelligence capacity for its cloud segment, Amazon Web Services (AWS).</blockquote><p>Well shit, I bet investors are gonna love this! Better save some money, Andy!</p><p>What's that? You already did? How?</p><p>Oh, shit!<a href="https://www.reuters.com/business/retail-consumer/amazon-has-halted-some-data-center-leasing-talks-wells-fargo-analysts-say-2025-04-21/?ref=wheresyoured.at"> <u>A report from Wells Fargo analysts</u></a> (called "Data Centers: AWS Goes on Pause") says that Amazon has "paused a portion of its leasing discussions on the colocation side...[and while] it's not clear the magnitude of the pause...the positioning is similar to what [analysts have] heard recently from Microsoft, [that] they are digesting aggressive recent lease-up deals...pulling back from a pipeline of LOIs or SOQs."</p><blockquote>Some asshole is going to say "LOIs and SOQs aren't a big deal," but they <em>are</em>. I wrote about it<a href="https://www.wheresyoured.at/power-cut/#:~:text=Sidebar%3A%20Let%27s%20explain%20some%20terms!"> <em><u>here</u></em></a><em>.</em></blockquote><p>"Digesting" in this case refers to when hyperscalers sit with their current capacity for a minute, and Wells Fargo adds that these periods typically last 6-12 months, though can be much shorter. It's not obvious <em>how much</em> capacity Amazon is walking away from, but they are walking away from capacity. <em>It's happening.</em></p><p>But what if it wasn't just Amazon? Another report from friend of the newsletter (read: people I email occasionally asking for a PDF) analyst TD Cowen put out a report last week that, while titled in a way that suggested there wasn't a pull back, actually said there was.</p><p>Let's take a look at one damning quote:</p><blockquote>...relative to the hyperscale demand backdrop at PTC, hyperscale demand has moderated a bit (driven by the Microsoft pullback and to a lesser extent Amazon, discussed below), particularly in Europe, 2) there has been a broader moderation in the urgency and speed with which the hyperscalers are looking to take down capacity, and 3) the number of large deals (i.e. +400MW deals) in the market appears to have moderated.</blockquote><p>In plain English, this means "demand has come down, there's less urgency in building this stuff, and the market is slowing down. Cowen also added that it "...observed a moderation in the exuberance around the outlook for hyperscale demand which characterized the market this time last year."&nbsp;</p><p>Brother, isn't this meant to be the next big thing? We need more exuberance! Not less!</p><p>Worse still, Microsoft appears to have pulled back <em>even further</em>, with TD Cowen noting that there has been a "slowdown in demand," and that it saw "very little third-party leasing from Microsoft" this quarter, and, most damningly, and I'll bold this for effect, "<strong>these deals in totality suggest Microsoft's run-rate demand has decelerated materially,</strong>" which for those of you wondering means <strong><em>it’s not getting the fucking demand for generative AI.</em></strong></p><p>Well, at least Meta and Oracle aren't slowing down, right?</p><p><em>Well...</em></p><p>TD Cowen reported that it received "reverse inquiries from industry participants around a potential slowdown in demand from Oracle," leading the analyst to ask around and find that "there had been a NT (near-term) slowdown in decision-making amid organizational changes at Oracle," though it adds this might not mean that this is changing its needs or the speed at which it secures capacity. If you're wondering what else this could mean, you are correct to do so, because "slowing down" traditionally refers to a change in speed.</p><p>TD Cowen also adds that Meta has continued demand "albeit with less volume of MW (Megawatt) signings quarter-over-quarter..." then adding that "Meta's data center activity has historically been characterized by short periods of strong activity followed by digestion." In essence, Meta is signing less megawatts of compute and has, in the past, followed periods of aggressive buildouts with, well, fewer buildouts.</p><h2 id="if-im-wrong-how-am-i-wrong-exactly"><strong>If I'm Wrong, How Am I Wrong Exactly?</strong></h2><p>I dunno man, all of this sure seems like the hyperscalers are reducing their capital expenditures at a time when tariffs and economic uncertainty are making investors more critical of revenues. It sure seems like nobody outside of OpenAI is making any real revenue on generative AI, and they're certainly not making a profit.</p><p>It also, at this point, is pretty obvious that generative AI isn't going to do much more than it does today. If Amazon is only making $5 billion in revenue from <em>the literal only shiny new thing it has, sold on the world's premier cloud platform, at a time when businesses are hungry and desperate to integrate AI,</em> then there's little chance this suddenly turns into a remarkable revenue-driver.</p><p>Amazon made <em>$187.79 billion in its last quarterly earnings</em>, and if $5 billion is all it’s making at the very height of the bubble, it heavily suggests that there may not actually be that much money to make, either because it's too expensive to run these services or because these services don't have the kind of total addressable market as the rest of Amazon's services.</p><p><a href="https://www.geekwire.com/2025/microsoft-earnings-2/?ref=wheresyoured.at"><u>Microsoft reported that it was making a paltry $13 billion a year</u></a> — so the equivalent of $3.25 billion a quarter — selling generative AI services and model access.<a href="https://www.theinformation.com/articles/ai-giving-salesforce-boost?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that Salesforce's "Agentforce" bullshit isn't even going to boost sales growth in 2025</u></a>, in part because it’s pitching it as "digital labor that can essentially replace humans for tasks" and it turns out that it doesn't do that very well at all, costs $2 a conversation, and requires paying Salesforce to use its "data cloud" product.</p><p>What, if anything, suggests that I'm wrong here? That things have worked out in the past with things like the Internet and smartphones, and so it surely must happen for generative AI and, by extension, OpenAI? That companies like Uber lost money and eventually worked out (<a href="https://www.wheresyoured.at/to-serve-altman/#:~:text=As%20another%20aside%2C%20Uber%2C%20a%20company%20famed%20for%20burning%20%2425%20billion%20dollars%20to%20achieve%20profitability%2C%20raised%20a%20total%20of...well%2C%20%2425%20billion%2C%20which%20included%20four%20different%20funding%20rounds%20in%20the%20year%202018%20alone."><u>see my response here</u></a>)? That OpenAI is growing fast, and that somehow discounts the fact it burns billions of dollars and does not appear to have any path to making a profit? That agents will suddenly start working and everything will be fine?</p><p>It's a fucking joke and I'm tired of it!</p><p>Large Language Models and their associated businesses are a $50 billion industry masquerading as a trillion-dollar panacea for a tech industry that’s lost the plot. Silicon Valley is dominated by management consultants that no longer know what innovation looks like, tricked by Sam Altman, a savvy con artist who took advantage of tech’s desperation for growth.&nbsp;</p><p>Generative AI is the perfected nihilistic form of tech bubbles — a way for people to spend a lot of money and power on cloud compute because they don’t have anything better to do. Large Language Models are boring, unprofitable cloud software stretched to their limits — both ethically and technologically — as a means of tech’s collapsing growth era, OpenAI’s non-profit mission fattened up to make foie gras for SaaS companies to upsell their clients and cloud compute companies to sell GPUs at an hourly rate.&nbsp;</p><p><a href="https://www.wheresyoured.at/the-rot-economy/" rel="noreferrer">The Rot Economy</a> has consumed the tech industry. Every American tech firm has become corrupted by the growth-at-all-costs mindset, and thus they no longer know how to make sustainable businesses that solve real problems, largely because the people that run them haven’t experienced them for decades.&nbsp;</p><p>As a result, none of them were ready for when Sam Altman tricked them into believing he was their savior.&nbsp;</p><p>Generative AI isn’t about helping you or me do things — it’s about making new SKUs, new monthly subscription costs for consumers and enterprises, new ways to convince people to pay more for the things that they already used to be slightly different in a way that often ends up being worse.&nbsp;</p><p>Only an industry out of options would choose this bubble, and the punishment for doing so will be grim. I don’t know if you think I’m wrong or not. I don’t know if you think I’m crazy for the way I communicate about this industry. Even if you think I am, think long and hard about why it is you disagree with me, and the consequences of me being wrong.&nbsp;</p><p>There is nothing else after generative AI. There are no other hypergrowth markets left in tech. SaaS companies are out of things to upsell. Google, Microsoft, Amazon and Meta do not have any other ways to continue showing growth, and when the market works that out, there will be hell to pay, hell that will reverberate through the valuations of, at the very least, every public software company, and many of the hardware ones too.</p><p>And I fear it'll go much further, too. The longer this bubble inflates - the longer everybody pretends - the worse the consequences will be.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Books of Earthsea by Ursula K. Le Guin (112 pts)]]></title>
            <link>https://lars.ingebrigtsen.no/2025/04/28/book-club-2025-the-books-of-earthsea-by-ursula-k-le-guin/</link>
            <guid>43823462</guid>
            <pubDate>Mon, 28 Apr 2025 16:50:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lars.ingebrigtsen.no/2025/04/28/book-club-2025-the-books-of-earthsea-by-ursula-k-le-guin/">https://lars.ingebrigtsen.no/2025/04/28/book-club-2025-the-books-of-earthsea-by-ursula-k-le-guin/</a>, See on <a href="https://news.ycombinator.com/item?id=43823462">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28.jpeg"><img decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-scaled.jpeg" alt="" width="840" height="1050" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-scaled.jpeg 2048w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-240x300.jpeg 240w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-819x1024.jpeg 819w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-768x960.jpeg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-1229x1536.jpeg 1229w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-1638x2048.jpeg 1638w" sizes="(max-width: 840px) 100vw, 840px"></a></p><p>I discovered that they’d published a complete, illustrated version of the Earthsea cycle a couple weeks ago.  I’m not overly fond of omnibus editions, but this is illustrated by Charles Vess, and I love his artwork, so I thought that this might be a good time to re-read these books.</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-1.jpeg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-1.jpeg" alt="" width="33" height="15"></a><br> <a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-2.jpeg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/2025-04-28-2.jpeg" alt="" width="191" height="300"></a></p><p>Because of course I’ve read these books before.  I read the first one (in translation) when I was about 10-11 years old, and it had the cover above.  I had that book, so I read it several times, but the other two of the first trilogy I borrowed from the library, so I probably just read them once?</p><p>(Man, that’s a weird cover.  Le Guin complains about horrible covers, but she doesn’t mention this one.)</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01900-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>This book is massive.  It’s just almost 1K pages, but they’re big pages.  Looking at <a href="https://www.goodreads.com/series/40909-earthsea-cycle" data-cached-time="2025-04-28T02:10:17" data-cached-image="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/cache-2025-04-28-web-scaled.webp" onmouseenter="hoverLink(event)">the original editions</a>, it looks like the six books altogether were 1,400 pages, and this one also includes some other short stories and stuff, so there’s some heft to this book.</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01901-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>Vess does illustrations of key scenes, as well as title plates…</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01902-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>… and one colour piece per book.</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01906-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>Charles Vess has done some extremely stylish comics, and those are mostly pen and ink.  This is just pencil, and of course it’s good looking, but I have to admit I’m a bit disappointed.</p><p>I was also going to quibble about how he depicts some things, like the dragons, but the artwork was done over four years, and in collaboration with Le Guin.  I guess if she say’s that that’s correct, I can’t really argue.  Darn!</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01903-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01904-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>Now, as for the text itself…  I mean, just reading it, I don’t think this format is ideal?  I guess they had to limit themselves to under 1K pages or something, so they had to step down the font size slightly.  I mean, it’s not uncomfortable, but it’s just a smidgen too small.  And since the pages are so big, they felt the need to increase the line height, so that your eyes can snap back to the left side of the page without losing place.</p><p>I just thing the look of these pages isn’t ideal.  But it does give you the feeling you’re reading some old huge grimoire, which is probably what they were going for, and that’s fun.</p><p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805.jpg"><img loading="lazy" decoding="async" src="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-scaled.jpg" alt="" width="840" height="560" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-300x200.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-1024x683.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-768x512.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-1536x1024.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2025/04/DSC01805-2048x1365.jpg 2048w" sizes="auto, (max-width: 840px) 100vw, 840px"></a></p><p>But since it’s uncomfortable to hold, and also slightly uncomfortable to read, I just read the old editions I had.  D’oh!  But I did look at the illustrations, too.</p><p>(And I couldn’t find The Other Wind, so I read that from this new collection, along with the afterwords and the extra included short stories and stuff.)</p><p>So how is it?  Presumably, you’ve all read these books — or at least the first three.</p><p>I had forgotten how oldee tymey the first book is.  It’s written in a style halfway between fairy tales and modern “classic” fantasy.  That is, people are introduced like “and then he met Grumbledork, who would go on to sail to Vinklebump and vanquish Zomplefart, the dragon, but that’s a story for another day”, etc etc.  As someone who hates fairy tales…  I really enjoyed it.  As much as I did when I was 11.</p><p>I think the second book, The Tombs of Atuan is generally considered to be the best?  It’s written in a very different way, and it is indeed very good.  But I think of the first three books, I prefer the third, The Farthest Shore.  It’s like a remake of the first book (a road movie, but at sea), but the encounters are more memorable and vivid — like the people who live at sea all their lives, in the floating cities, and so on.  And it has the most moving end.</p><p>Then 30 years passed, and the fourth book came, Tehanu.  If you were 11 years old in 1991, and read the four books in quick succession, you’d get whiplash when you got to the fourth one: It starts with a five year old girl who was raped and then put into a campfire to burn to death.  (And that’s just the first page.)  But if you grew up with the first three books, and then got to the fourth as an adult (as I did), then it seemed quite natural:  It’s a brutal, angry book, and it’s fantastic.</p><p>Ten more years passed, and we got a short story collection — but times have moved on, and “short” isn’t the same as in the olden days.  The first story in the collection is about two thirds the length of the first novel.  All the stories are solid, and we retrench a lot from the harshness of Tehanu.  Le Guin says she wrote the stories to figure out herself how to finish off the series with the fifth novel, and to explore things about Earthsea.  Now, nothing strikes more fear into a reader’s heart than an author who wants to “explore things” in their universe: You’re likely to get a story filling you in on the “lore” of the second lieutenant mentioned in half of a sentence in book two, and nothing in the short story must affect the “proper” novels whatsoever.  But of course, Le Guin does nothing of the kind: She writes interesting stories that fill in the milieu and enriches your love for the world, and not trite info dumps or backstory you’ve never asked for.</p><p>And finally, the sixth and final book came hot on the heels of the fifth, and it’s a novel that manages to be a wonderful ending to the entire series.  I had totally forgotten that.  It echoes the first and third books storytelling wise, and concludes the storylines started in the fourth book, while starring (sort of) Tenar from the second book.  Some people when they finish a series like this seem to have a checklist of points they go through and make everything neat — Le Guin is way too smart to do something like that, but it’s a really solid ending to the cycle.</p><p>(Except that there are a few more short stories included in this collecion.  The final story was published in The Paris Review originally in 2018, after Le Guin had died, and is a very moving coda.)</p><p>So to sum up: These books are still darn good, and even better than I remembered.</p><p>And now I want to read something that’s not fantasy.</p><p><b>The Books of Earthsea (2018)</b> by Ursula K. Le Guin (<a screenshot="true" href="https://bookshop.org/book/9781481465588">buy new</a>, <a screenshot="true" href="https://www.biblio.com/9781481465588">buy used</a>, <a screenshot="true" href="https://www.goodreads.com/search?q=9781481465588">4.46 on Goodreads</a>)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Sim Studio – Open-Source Agent Workflow GUI (143 pts)]]></title>
            <link>https://github.com/simstudioai/sim</link>
            <guid>43823096</guid>
            <pubDate>Mon, 28 Apr 2025 16:14:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/simstudioai/sim">https://github.com/simstudioai/sim</a>, See on <a href="https://news.ycombinator.com/item?id=43823096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/simstudioai/sim/blob/main/sim/public/static/sim.png"><img src="https://github.com/simstudioai/sim/raw/main/sim/public/static/sim.png" alt="Sim Studio Logo" width="500"></a>
</p>
<p dir="auto">
  <a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/859a1a0bc85ce8bbd7a730a274fec5c9e77c4726ffdf6aa762a78685e26033a4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License: Apache-2.0" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
  <a href="https://discord.gg/Hr4UWYEcTT" rel="nofollow"><img src="https://camo.githubusercontent.com/3fd3029bb1d53b3b6f05655b7763d43b6d1d761479537d4c6bd9062e2646fffa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d4a6f696e2532305365727665722d3732383944413f6c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Discord" data-canonical-src="https://img.shields.io/badge/Discord-Join%20Server-7289DA?logo=discord&amp;logoColor=white"></a>
  <a href="https://x.com/simstudioai" rel="nofollow"><img src="https://camo.githubusercontent.com/4adaee445a27f63f4d71fcbc27f9e22981c30561f9fe677caefe22b8c8bd883a/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f73696d73747564696f61693f7374796c653d736f6369616c" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/simstudioai?style=social"></a>
  <a href="https://github.com/simstudioai/sim/pulls"><img src="https://camo.githubusercontent.com/d88d8d77fa79e828eea397f75a1ebd114d13488aeec4747477ffbd2274de95ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a>
  <a href="https://github.com/simstudioai/sim/issues"><img src="https://camo.githubusercontent.com/3e9fd289aaf4070825ad7ea65b389d4b185c4e1986208abf13110dcc8d1dc61c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f72742d636f6e74616374253230617574686f722d707572706c652e737667" alt="support" data-canonical-src="https://img.shields.io/badge/support-contact%20author-purple.svg"></a>
</p>
<p dir="auto">
  <strong>Sim Studio</strong> is a powerful, user-friendly platform for building, testing, and optimizing agentic workflows.
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run</h2><a id="user-content-run" aria-label="Permalink: Run" href="#run"></a></p>
<ol dir="auto">
<li>Run on our <a href="https://simstudio.ai/" rel="nofollow">cloud-hosted version</a></li>
<li>Self-host</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Self-Host</h2><a id="user-content-how-to-self-host" aria-label="Permalink: How to Self-Host" href="#how-to-self-host"></a></p>
<p dir="auto">There are several ways to self-host Sim Studio:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Docker Environment (Recommended)</h3><a id="user-content-option-1-docker-environment-recommended" aria-label="Permalink: Option 1: Docker Environment (Recommended)" href="#option-1-docker-environment-recommended"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone your forked repository
git clone https://github.com/YOUR_USERNAME/sim.git
cd sim

# Create environment file and update with required environment variables (BETTER_AUTH_SECRET)
cp sim/.env.example sim/.env

# Start Sim Studio using the provided script
docker compose up -d --build

or

./start_simstudio_docker.sh"><pre><span><span>#</span> Clone your forked repository</span>
git clone https://github.com/YOUR_USERNAME/sim.git
<span>cd</span> sim

<span><span>#</span> Create environment file and update with required environment variables (BETTER_AUTH_SECRET)</span>
cp sim/.env.example sim/.env

<span><span>#</span> Start Sim Studio using the provided script</span>
docker compose up -d --build

or

./start_simstudio_docker.sh</pre></div>
<p dir="auto">After running these commands:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Access the Application</strong>:</p>
<ul dir="auto">
<li>Open <a href="http://localhost:3000/w/" rel="nofollow">http://localhost:3000/w/</a> in your browser</li>
<li>The <code>/w/</code> path is where the main workspace interface is located</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Useful Docker Commands</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# View application logs
docker compose logs -f simstudio

# Access PostgreSQL database
docker compose exec db psql -U postgres -d simstudio

# Stop the environment
docker compose down

# Rebuild and restart (after code changes)
docker compose up -d --build"><pre><span><span>#</span> View application logs</span>
docker compose logs -f simstudio

<span><span>#</span> Access PostgreSQL database</span>
docker compose <span>exec</span> db psql -U postgres -d simstudio

<span><span>#</span> Stop the environment</span>
docker compose down

<span><span>#</span> Rebuild and restart (after code changes)</span>
docker compose up -d --build</pre></div>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Working with Local Models</h4><a id="user-content-working-with-local-models" aria-label="Permalink: Working with Local Models" href="#working-with-local-models"></a></p>
<p dir="auto">To use local models with Sim Studio, follow these steps:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Pull Local Models</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run the ollama_docker.sh script to pull the required models
./sim/scripts/ollama_docker.sh pull <model_name>"><pre><span><span>#</span> Run the ollama_docker.sh script to pull the required models</span>
./sim/scripts/ollama_docker.sh pull <span>&lt;</span>model_name<span>&gt;</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Start Sim Studio with Local Models</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="#Start Sim Studio with local model support
./start_simstudio_docker.sh --local

# or

# Start Sim Studio with local model support if you have nvidia GPU
docker compose up --profile local-gpu -d --build

# or

# Start Sim Studio with local model support if you don't have nvidia GPU
docker compose up --profile local-cpu -d --build"><pre><span><span>#</span>Start Sim Studio with local model support</span>
./start_simstudio_docker.sh --local

<span><span>#</span> or</span>

<span><span>#</span> Start Sim Studio with local model support if you have nvidia GPU</span>
docker compose up --profile local-gpu -d --build

<span><span>#</span> or</span>

<span><span>#</span> Start Sim Studio with local model support if you don't have nvidia GPU</span>
docker compose up --profile local-cpu -d --build</pre></div>
</li>
</ol>
<p dir="auto">The application will now be configured to use your local models. You can access it at <a href="http://localhost:3000/w/" rel="nofollow">http://localhost:3000/w/</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Dev Containers</h3><a id="user-content-option-2-dev-containers" aria-label="Permalink: Option 2: Dev Containers" href="#option-2-dev-containers"></a></p>
<ol dir="auto">
<li>Open VS Code or your favorite VS Code fork (Cursor, Windsurf, etc.)</li>
<li>Install the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers" rel="nofollow">Remote - Containers extension</a></li>
<li>Open the project in your editor</li>
<li>Click "Reopen in Container" when prompted</li>
<li>The environment will automatically be set up in the <code>sim</code> directory</li>
<li>Run <code>npm run dev</code> in the terminal or use the <code>sim-start</code> alias</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Manual Setup</h3><a id="user-content-option-3-manual-setup" aria-label="Permalink: Option 3: Manual Setup" href="#option-3-manual-setup"></a></p>
<ol dir="auto">
<li><strong>Install Dependencies</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/YOUR_USERNAME/sim.git
cd sim/sim

# Install dependencies
npm install"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/YOUR_USERNAME/sim.git
<span>cd</span> sim/sim

<span><span>#</span> Install dependencies</span>
npm install</pre></div>
<ol start="2" dir="auto">
<li><strong>Set Up Environment</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Copy .env.example to .env
cp .env.example .env

# Configure your .env file with the required environment variables:
# - Database connection (PostgreSQL)
# - Authentication settings (Better-Auth Secret)"><pre><span><span>#</span> Copy .env.example to .env</span>
cp .env.example .env

<span><span>#</span> Configure your .env file with the required environment variables:</span>
<span><span>#</span> - Database connection (PostgreSQL)</span>
<span><span>#</span> - Authentication settings (Better-Auth Secret)</span></pre></div>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <strong>Important Notes:</strong></p>
<ul dir="auto">
<li>If <code>RESEND_API_KEY</code> is not set, verification codes for login/signup will be logged to the console.</li>
<li>You can use these logged codes for testing authentication locally.</li>
<li>For production environments, you should set up a proper email provider.</li>
</ul>
<ol start="3" dir="auto">
<li><strong>Set Up Database</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Push the database schema
npx drizzle-kit push"><pre><span><span>#</span> Push the database schema</span>
npx drizzle-kit push</pre></div>
<ol start="4" dir="auto">
<li><strong>Start Development Server</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Start the development server
npm run dev"><pre><span><span>#</span> Start the development server</span>
npm run dev</pre></div>
<ol start="5" dir="auto">
<li><strong>Open <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> in your browser</strong></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tech Stack</h2><a id="user-content-tech-stack" aria-label="Permalink: Tech Stack" href="#tech-stack"></a></p>
<ul dir="auto">
<li><strong>Framework</strong>: <a href="https://nextjs.org/" rel="nofollow">Next.js</a> (App Router)</li>
<li><strong>Database</strong>: PostgreSQL with <a href="https://orm.drizzle.team/" rel="nofollow">Drizzle ORM</a></li>
<li><strong>Authentication</strong>: <a href="https://better-auth.com/" rel="nofollow">Better Auth</a></li>
<li><strong>UI</strong>: <a href="https://ui.shadcn.com/" rel="nofollow">Shadcn</a>, <a href="https://tailwindcss.com/" rel="nofollow">Tailwind CSS</a></li>
<li><strong>State Management</strong>: <a href="https://zustand-demo.pmnd.rs/" rel="nofollow">Zustand</a></li>
<li><strong>Flow Editor</strong>: <a href="https://reactflow.dev/" rel="nofollow">ReactFlow</a></li>
<li><strong>Docs</strong>: <a href="https://fumadocs.vercel.app/" rel="nofollow">Fumadocs</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions! Please see our <a href="https://github.com/simstudioai/sim/blob/main/.github/CONTRIBUTING.md">Contributing Guide</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the Apache License 2.0 - see the <a href="https://github.com/simstudioai/sim/blob/main/LICENSE">LICENSE</a> file for details.</p>

<p dir="auto">Made with ❤️ by the Sim Studio Team</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A pure WebGL image editor with filters, crop and perspective correction (185 pts)]]></title>
            <link>https://github.com/xdadda/mini-photo-editor</link>
            <guid>43823044</guid>
            <pubDate>Mon, 28 Apr 2025 16:10:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xdadda/mini-photo-editor">https://github.com/xdadda/mini-photo-editor</a>, See on <a href="https://news.ycombinator.com/item?id=43823044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>GitHub Advanced Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:xdadda/mini-photo-editor" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="q_7IPmEIStooSTXYel3i6A5hNJCIixIT2_hurZxYtw1MqERkvSufxC_yBRY_RMOrwtwevc1fpOETpNNQ8HO3Cw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="xdadda/mini-photo-editor" data-current-org="" data-current-owner="xdadda" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=xdadda%2Fmini-photo-editor" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/xdadda/mini-photo-editor&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="bcc2159001bb38ece52e7d700d10d76cbc8dc11bc69e5b5c5ce167e3cd70b80d" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>

              
          
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I built a hardware processor that runs Python (897 pts)]]></title>
            <link>https://www.runpyxl.com/gpio</link>
            <guid>43820228</guid>
            <pubDate>Mon, 28 Apr 2025 11:44:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.runpyxl.com/gpio">https://www.runpyxl.com/gpio</a>, See on <a href="https://news.ycombinator.com/item?id=43820228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <section>
      <h2>🧪 GPIO round-trip at 480ns</h2>
      <p>Python, in hardware. 480ns GPIO. No interpreter. No C. Just PyXL.</p>
      <p>
        <iframe src="https://player.vimeo.com/video/1074893425?h=722d28efd8&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
      </p>
    </section>

    <section>
      <h2>TL;DR</h2>
      <ul>
        <li>⚡ PyXL runs <strong>Python directly in hardware</strong> — no VM, no OS, no JIT.</li>
        <li>🧪 A GPIO roundtrip takes <strong>480ns</strong> on PyXL vs. ~15,000ns on <a href="https://store.micropython.org/product/PYBv1.1" target="_blank" rel="noopener noreferrer">PyBoard</a> (MicroPython).</li>
        <li>📉 PyXL is <strong>30x faster</strong> than MicroPython — or <strong>50x</strong> when normalized for clock speed.</li>
        <li>🎥 The video demo shows both systems in action on real hardware.</li>
        <li>💡 This isn't a C trick — it's actual <strong>Python executed in silicon</strong>.</li>
        <li>🎯 Deterministic timing, real-time behavior, and sub-microsecond precision — in Python.</li>
        <li>🔗 More at <a href="https://runpyxl.com/">runpyxl.com</a> — contact link at the bottom.</li>
      </ul>
    </section>

    <section>
      <h2>What is PyXL?</h2>
      <p>PyXL is a custom hardware processor that executes Python <strong>directly</strong> — no interpreter, no JIT, and no tricks. It takes regular Python code and runs it in silicon.</p>
      <p>A custom toolchain compiles a <code>.py</code> file into CPython ByteCode, translates it to a custom assembly, and produces a binary that runs on a pipelined processor built from scratch.</p>
    </section>

    <section>
      <h2>What PyXL is not</h2>
      <ul>
        <li>❌ Not a native C or inlined loop</li>
        <li>❌ Not MicroPython or JIT</li>
        <li>❌ Not running Linux or any OS</li>
      </ul>
      <p>It's a real processor for Python, built for determinism and speed.</p>
    </section>

    <section>
      <h2>Where does it run?</h2>
      <p>PyXL runs on a <strong>Zynq-7000 FPGA</strong> (Arty-Z7-20 dev board). The PyXL core runs at 100MHz. The ARM CPU on the board handles setup and memory, but the Python code itself is executed entirely in hardware.</p>
      <p>The toolchain is written in Python and runs on a standard development machine using unmodified CPython.</p>
    </section>

    <section>
      <h2>Wait — what’s a GPIO?</h2>
      <p>
        GPIO stands for <strong>General Purpose Input/Output</strong>. It’s a simple hardware pin that software can read from or write to — a way to control the outside world: LEDs, buttons, sensors, motors, and more.
      </p>
      <p>
        In MicroPython (like on the PyBoard), your Python code interacts with C functions that handle hardware registers underneath. It’s reasonably fast, but still goes through a Python VM and a software stack before reaching the pin.
      </p>
      <p>
        PyXL skips all of that. The Python bytecode is executed directly in hardware, and GPIO access is physically wired to the processor — no interpreter, no function call, just native hardware execution.
      </p>
    </section>    

    <section>
      <h2>Now for the GPIO test. What was the video?</h2>
      <p>I have connected two pins in the Arty board with a jumper cable.</p>
      <p>Then, I wrote a python program that measures the time from when GPIO pin1 is set to 1, until 1 is measured on the other pin connected to it.</p>
      <p>The video shows a comparison between PyXL and PyBoard that runs MicroPython VM.<br>Let's focus on how PyXL does its thing.</p>

      <h2>The program</h2>
      <pre>from compiler.intrinsics import *


def main():
    pyxl_write_gpio_pin1(0)              # Reset output pin

    c1 = pyxl_get_cycle_counter()        # Cycle counter (100 MHz)

    pyxl_write_gpio_pin1(1)              # Set output pin
    while pyxl_read_gpio_pin2() == 0:    # Wait until input pin is set to 1
        continue

    c2 = pyxl_get_cycle_counter()        # Cycle counter (100 MHz)

    return (c2 - c1) * 10                # Return result in nano seconds (each cycle is 10 ns)
          </pre>

      <p>As you can see, this is a regular python program, but it also has some unfamiliar function calls.<br>
        These functions originate from compiler.intrinsics module.</p>
        <pre>pyxl_get_cycle_counter()</pre>
        <p>Gets the current cycle counter from the PyXL CPU. This counter advances by 1 on every tick</p>

        <pre>pyxl_write_gpio_pin1()</pre>
        <p>Writes a value (0/1) to a GPIO pin. These are low-level intrinsics exposed by the compiler — currently hardcoded for this test, but will evolve into a more general pyxl_gpio_write(pin, value) API.</p>

        <pre>pyxl_read_gpio_pin2()</pre>
        <p>Reads the value from Pin2. Same API comment is true here as well.</p>
      
    </section>

    <section>
      <h2>Wait, why isn't there a call to the main function?</h2>
      <p>The main function is just defined, but not invoked. why?</p>
      <p>At current stage, PyXL calls the main function automatically when it runs a program.</p>
      <p>This is just a convenience feature (for dev) and will change in the future.</p>
    </section>
    
    <section>
      <h2>So how does it work?</h2>
      <p>As described above, the program is compiled to a CPython Bytecode and then compiled again to PyXL assembly. It is then linked together and a binary is generated.</p>
      <p>This binary is sent via network to the Arty board, where an ARM CPU gets the application, copies it to a shared memory with the PyXL HW and starts running it.</p>
      <p>A typical Python runtime (CPython or MicroPython in case of the PyBoard or Python for embedded in general) has a big overhead that is caused by running the ByteCode on a Software based VM. In PyXL there's no VM, the HW does everything.</p>
      <p>As for reading and writing the GPIO - The GPIO headers are directly mapped to FPGA pins, and physically wired into PyXL's core top-level module. Think of it as the main function of the HW.</p>
      <p>In this test, all code and data reside in predictable low-latency memory, ensuring deterministic behavior (real-time behavior). This means that for the same input, it'll take the exact same time to run.
      </p>
    </section>
      
    <section>
      <h2>So how do these platforms compare?</h2>
      <div>
        <h3>GPIO Roundtrip Latency (ns). Lower is better.</h3>
        
        
        
        <div>
          <p><span>MicroPython (PyBoard)</span><span>14,741ns</span>
          </p>
          
        </div>
      </div>

      <p>As you can see, PyXL is 30x faster than PyBoard.</p>
      <p>Also, remember that PyXL's clock speed is lower than PyBoard.</p>
      <p>The reason for not operating at a higher clock is that PyXL is prototyped on an FPGA and PyBoard has an ASIC. But the gist of it is that it's not a limitation of PyXL and higher clocks can be achieved.</p>
      <p>Since a higher clock is achievable, we need to compare apples-to-apples and normalize the clock frequencies.<br>
      That brings PyXL’s normalized advantage to ~50x over PyBoard.</p>
    </section>

    <section>
      <h2>Why don't both tests run the exact same code?</h2>
      <p>To the keen eyes among you, you may have noticed in the video that the PyBoard code and the PyXL code aren't the same.</p>
      <p>Both are Python, this is obvious, but there're two main differences:</p>
      <p>1. API calls for measuring time and reading/writing GPIO pins. The reason being that this is not CPython that runs on a host, but systems that are aware of the underlying hardware, bringing their own runtime environment with them.<br>
      Each platform has its own hardware access API calls, but regular python code is still portable between the platforms (as long as they support whatever Python feature you want to use).</p>
      <p>2. The PyBoard runs the test in a tight loop to compensate for jitter and cold cache.<br>
      MicroPython running on the PyBoard has runtime jitter. The results are between 14-25 micro seconds in my test. So I wanted to compare to PyBoard after significant warm up to show how much better PyXL is even in such case.<br>
      PyXL, by contrast, is fully deterministic. So long as the jumper is connected, PyXL returns a consistent 480ns every time.<br>
      This makes PyXL suitable for real-time use cases.
    </p>
    </section>

    <section>
      <h2>Big deal, who cares about making a signal go a bit faster?</h2>
      <p>
        This isn’t just a performance boost — it's an unlock. PyXL brings a level of responsiveness and determinism that Python has never had in embedded or real-time contexts.
      </p>
      <p>
        Python VMs — even those designed for microcontrollers — are still built around software interpreters. That introduces overhead and complexity between your code and the hardware.
      </p>
      <p>
        PyXL removes this barrier. Your Python code is executed directly in hardware. GPIO access is physical. Control flow is predictable. Execution is tight and consistent by design.
      </p>
      <p>With this unlock, PyXL can be further developed and adapted to these use cases:</p>
      <ul>
        <li>🕹 Real-time control systems in pure Python</li>
        <li>🧠 ML inference + sensor response loops with hard timing budgets</li>
        <li>🤖 Robotics tasks like motor feedback and sensor fusion with cycle-level precision</li>
        <li>🔧 Embedded industrial systems where timing and reliability matter</li>
      </ul>
      <p>
        With PyXL, you can write performance-critical code once — in Python — and ship it as-is.
      </p>
    </section>

    <section>
      <h2>Sounds interesting? Let's talk.</h2>
      <a href="https://www.runpyxl.com/#contact">Reach out if you're curious.</a>
    </section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep dive into how DOS games do copy protection by making themselves unwinnable (254 pts)]]></title>
            <link>https://mrwint.github.io/winter/writeup/writeup.html</link>
            <guid>43820076</guid>
            <pubDate>Mon, 28 Apr 2025 11:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mrwint.github.io/winter/writeup/writeup.html">https://mrwint.github.io/winter/writeup/writeup.html</a>, See on <a href="https://news.ycombinator.com/item?id=43820076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’ve recently rediscovered an old game called “The Games: Winter Challenge”, a Winter Olympics sports game developed by MindSpan and published by Accolade in 1991 for DOS and Sega Genesis.
I had the DOS version of the game when growing up, so when I was randomly reminded of its existence, I was driven by a mix of nostaliga and curiosity to dig it up again.</p>

<p><img src="https://mrwint.github.io/winter/writeup/winter_titlescreen.webp" alt="Animation of the game's title screen"></p>

<p>Having grown up to become a computer scientist, I was not as much insterested in replaying it (though hearing the iconic music again was fun), but much more how it worked under the hood.
I had spent hours as a kid playing especially the ski jumping event, trying to reach the elusive mark of 100 meters, without success, and was determined to find out not only whether it was possible to achieve, but also what the theoretical optimum would be.
Conveniently, the game features a replay system that allows you to save and rewatch past attempts, which opens up great opportunities for creating a TAS and manufacture a perfect replay file, and push the game to its limts.</p>

<p>My initial plan of attack was simple: Find a copy of the game, crack it open in Ghidra, disassemble it to find out how the ski jumping works, and optimize based on the discovered mechanics.
As it turned out, each step of this plan was way more involved than anticipated, and created more questions along the way that demanded answers, opening up a rabbit hole of early 90s video game development intricasies.
This write-up will take you along on this ride of discovery, learning about how DOS-based programs worked, how video video game developers worked around the hardware limitations, how early copy protection worked, and how GOG sells you a broken version of the game (as of March 2025).</p>

<h2 id="taking-stock---version-chaos-and-copy-protection-circumvention">Taking stock - version chaos and copy protection circumvention</h2>

<p>The game has had multiple releases, including the original release in 1991, two bundle releases with its successor “Summer Challenge” in 1992 (Europe) and 1996 (US), and a GOG release of the bundle in 2020, based on DOS emulation through <a href="https://www.dosbox.com/">DOSBox</a>.
While the original floppy disks from my childhood are likely buried somewhere, they are of limited use today for lack of a floppy drive to read them with, so I searched the internet for the game.
Acquiring these different versions wasn’t too difficult thanks to the Internet Archive hosting various versions of the original media, and of course purchasing it from GOG.</p>

<p>The original game used a code wheel for copy protection.
Code wheels were a typical copy protection of the time: They are a physical set of disks sliding against each other, which you got together with the floppy disks containing the game.
At startup, the game asks you to turn them in a specific configuration, which reveals a code you need to enter into the game for it to work.
For those who are not old like me and have never seen a code wheel before, there is an <a href="https://www.oldgames.sk/codewheel/games-winter-challenge">interactive online version</a> of this game’s code wheel available.</p>

<p>The original 1991 release as expected asks for this code when you try to play any discipline, and boots you out if you answer incorrectly twice.</p>

<blockquote>
  <p><strong>Side investigation 1:</strong> how is the code wheel check implemented?</p>
</blockquote>

<p><img src="https://mrwint.github.io/winter/writeup/winter_code_wheel_input.png" alt="Screen shot of the code wheel input in-game"></p>

<p>The GOG version does not ask you for the code and lets you play without it, so presumably they have removed the copy protection from it instead of distributing the code wheel.
Where it get very insteresting is that multiple people are complaining in the discussion of this game on GOG that the game is “improperly cracked” and doesn’t work correctly as a result.
The descriptions of some of the behaviors, like that you can’t land a ski jump beyond a certain distance, or that you always crash in the last lap of speed skating, actually resonated with my recollection of playing the game as a kid, which means either we had a poorly cracked version back then as well, or that this is not related to copy protection at all and the game is just buggy.</p>

<blockquote>
  <p><strong>Side investigation 2:</strong> Are there hidden copy protection measures which affect gameplay?</p>
</blockquote>

<p>The 1996 US release actually comes with a separate crack, presumably officially sanctioned: Next to the main <code>WINTER.EXE</code>, it has a <code>WINTER.COM</code>, only 879 bytes in size, which when executed removes the code wheel check from the game, otherwise the game still asks for it.</p>

<p>But the version confusion doesn’t end there.
While searching for different versions, I also found other versions of the game, often in the form of online playable images loaded in DOSBox in the browser.
None of these needed a code wheel, and while some were based on the 1996 US release, others used entirely different cracks, created by different release groups of the early 90s.</p>

<p>And to complete the mess, the original game actually offers an option to install the game to disk instead of playing it from floppy, including its very own set of mysteries.
The installation does not work like you might expect, just copying files from floppy to disk; instead, it actually creates a whole new <code>WINTER.EXE</code> executable each time.
During installation, you can choose different options, including which graphics modes to support, and a “fast loading” mode which according to the manual makes the game load faster at the cost of additional hard drive space, and each combination of the options creates a different executable for you.</p>

<blockquote>
  <p><strong>Side investigaton 3:</strong> How are these different versions of the executable being created, and how do they differ?</p>
</blockquote>

<p>So taking stock and comparing all different acquired versions, there are a lot of distinct binaries:</p>

<ol>
  <li>The original floppy version of the game</li>
  <li>Six different versions of the game when installed to hard disk, for each combination of “fast loading” and either or both of the EGA and VGA graphics modes</li>
  <li>The GOG version of the game, which is based on the installed VGA+EGA fast-load version with individual bytes modified</li>
  <li>A cracked binary of unknown origin, which is based on the installed VGA fast-load version with individual bytes modified</li>
</ol>

<p>Furthermore, there are three different stand-alone cracks:</p>

<ol>
  <li>The official <code>WINTER.COM</code> crack (879 bytes) which was provided with the 1996 US release alongside an unmodified floppy version</li>
  <li>A <code>WG.COM</code> crack (366 bytes) by release group “The Humble Guys” from October 17, 1991, within days after the game’s release</li>
  <li>A <code>WINTER.COM</code> crack (291 bytes) by release group “Razor1911” from October 17, 1991, the same day(!) as the other crack</li>
</ol>

<blockquote>
  <p><strong>Side investigation 4:</strong> How do the individual cracks work, and do they use different mechanisms?</p>
</blockquote>

<h2 id="cracking-the-binary-open---obfuscation-and-memory-constraints">Cracking the binary open - obfuscation and memory constraints</h2>

<p>So to start somewhere, I loaded up the floppy version in Ghidra, and was immediately underwhelmed. It only managed to analyze a tiny fraction of the inital code, with most of it remaining binary blobs.
Opening the same file in IDA revealed much of the same picture, but IDA also provided accompanying warnings: It thinks the binary may be packed, and there are lots of unused bytes beyond the end of the code.
I figured that the binary must be packed or obfuscated in some way, and the tiny bit of initial code is the routine to unpack the rest of the binary.</p>

<p>So I began reverse-engineering the unpacking routine, and discovered a suspicious string in the binary, nestled between the assembly: <strong>*FAB*</strong>.</p>

<p><img src="https://mrwint.github.io/winter/writeup/FAB.png" alt="A calling card left by Fabrice Bellard"></p>

<p>As it turns out, “FAB” stands for <a href="https://en.wikipedia.org/wiki/Fabrice_Bellard">Fabrice Bellard</a>, who next to being the original developer of widely used programs such as FFmpeg and QEMU, is also the creator of an executable compression utility called <a href="https://bellard.org/lzexe.html">LZEXE</a>, developed in 1990.
Luckily, the inner workings of LZEXE are widely documented and understood.
I won’t go into the details of how the compression works here, there are great existing write-ups by <a href="https://cosmodoc.org/topics/lzexe/">Scott Smitelli</a> and <a href="https://www.lodsb.com/reversing-lz91-from-commander-keen">Sam Russell</a> if you want to dig deeper.
We just want to unpack the binary to get to the good stuff, and there are plenty existing unpacking utilities available, including UNLZEXE by Mitugu Kurizono from the same era.
The packing and unpacking is its own arms race microcosm, with protectors to prevent the unpacking, and more sophisticated unpackers to do it anyway, but luckily no additional unpacking protections were employed for this game.</p>

<p>The resulting unpacked binary has two surprises right off the bat: Firstly it is only 168kB in size, much smaller than the original executable despite extraction presumably making it grow in size, and secondly the result of unpacking it is identical across all different versions of the game.
This gives us a hint for how the game is structured: It contains a chunk of business logic, which is what we have unpacked and is the same across versions, and then it contains some resrouces, like sprites and sounds, which are included into the executable file and loaded out of it at runtime.
This assumption is supported by the fact that the extracted binary actually still works properly as long as it is placed beside the original <code>WINTER.EXE</code> binary to load the assets out of.</p>

<p>But it also is somewhat surprising for the two cracked versions of the binary, I would have expected those to contain modified business logic in order to facilitate skipping the code wheel check.
The answer to that mystery becomes apparent quickly after opening the new extracted binary in a disassembler.
By looking around some, we find suspicious interrupt calls to <code>int 3fh</code>.</p>

<p><img src="https://mrwint.github.io/winter/writeup/int3fh.png" alt="Instances of a mysterious interrupt 3fh"></p>

<blockquote>
  <h3 id="side-bar-interrupts">Side bar: Interrupts</h3>

  <p><a href="https://en.wikipedia.org/wiki/Interrupt">Interrupts</a> are the main way DOS programs used to communicate with the operating system, analogous to today’s <a href="https://en.wikipedia.org/wiki/System_call">syscalls</a>.
Whenever a program wants to interact with something outside it’s own code, it would call an interrupt and ask DOS to perform that task for it, handing back control to the operating system temporarily, and resuming when it is complete.
Anything from printing text to the screen, reading and writing files from disk, to allocating heap memory, is done through the main interrupt DOS provides, <code>int 21h</code>.
Which action is requested and any arguments are determined by the value of the CPU registers when the interrupt is called.
Other interrupts exist like <code>int 33h</code> for mouse interactions, but notably <code>int 3fh</code> is not one of the DOS-provided interrupts.
Under the hood, the routing of interrupts is handled by an <a href="https://en.wikipedia.org/wiki/Interrupt_vector_table">interrupt vector table</a>, which contain for each interrupt the address of the routine that is executed from when the interrupt is called.
Programs can modify this table (using an interrupt) to add their own custom interrupts, and <code>int 3fh</code> is likely used-defined this way.</p>
</blockquote>

<p>IDA provides a helpful comment to these, that this interrupt is typically used for calling an “Overlay manager”.</p>

<blockquote>
  <h3 id="side-bar-overlays">Side bar: Overlays</h3>

  <p><a href="https://en.wikipedia.org/wiki/Overlay_(programming)">Overlaying</a> is a technique for loading additional pieces of code at runtime, where multiple such pieces, called overlays, can be swapped out in the same place in memory.
This was useful in programs of the time to save on RAM usage: DOS only allowed a maximum of 640kB of memory to be used by a program (aka <a href="https://en.wikipedia.org/wiki/Conventional_memory">Conventional memory</a>), and large applications might themselves already be too big to fit all their code into that limit, not even considering any data.
Overlays are used to circumvent this limitation: By breaking the program code up into multiple overlays, the program only needs to load whatever overlay is needed for the current operation into memory.
Other overlays are loaded from disk as they are needed, replacing the previous overlay, allowing the program to have complex functionality with a small memory footprint.
Loading and managing overlays was the responsibility of an overlay manager, a library which kept track of which overlays are needed when and loaded and unloaded them accordingly.</p>
</blockquote>

<p>As it turns out, the game was written in C and compiled with the Microsoft C compiler version 6, as hinted by an embedded string <code>MS Run-Time Library - Copyright (c) 1990, Microsoft Corp</code> in the binary.
Perusing the compiler’s manual, the linker of that compiler did natively support overlays and would install its own overlay manager as <code>int 3fh</code> by default, so this was my first suspicion for how this structure was created.</p>

<p>Overall, this was not good news.
It means that the unpacked binary is in fact not all the business logic that exists, and there are more pieces of code, presumably in the resources packaged with the executable.
Disassemblers don’t understand these overlays, can’t detect them or automatically disassemble them, so the work to understand the business logic will be more manual than planned.
In order to progress further, we need to find and extract all these overlays, to get a complete picture of the game’s code.</p>

<p>By finding where the interrupt 3fh is installed at the start of the program, we can identfy the overlay manager routine which is called each time an overlay is needed.</p>

<p><img src="https://mrwint.github.io/winter/writeup/int3f_initialization.png" alt="Installing the int3fh"></p>

<p>Based on documentation for how Microsoft’s overlay manager worked, each interrupt call is followed by 3 bytes, one byte for the index number of the overlay that is needed, and two for the 16-bit address within that overlay.
Calling the interrupt then works like a function call: The overlay is loaded, the function at the given address is invoked, and afterwards the control flow returns directly after the interrupt call.
In fact the interrupts are literal replacements for function calls: a the 5 bytes typically needed for a far call instruction (1 byte opcode, 2 bytes address offset, 2 bytes address segment) are replaced by the Linker with the 5 bytes for the interrupt (2 bytes opcode, 1 byte overlay index, 2 bytes address offset) where needed.</p>

<p>This is where the good news ended though.
According to the documentation, each overlay should be appended to the main program, including its own <a href="https://en.wikipedia.org/wiki/DOS_MZ_executable">MZ header</a>, but this is not what we find in our binary.
Worse still, when using DOSBox’ debugger to step through an invocation of the interrupt, the code that was loaded is nowhere to be found in the binary file.
Also, unlike typical overlays, they are not actually occupying the same space in memory, instead new memory is dynamically allocated for each overlay, and deallocated after use.
That is useful because it allows multiple overlays to be loaded at the same time, but also means this game is not actually using the overlay mechanism from Microsoft C, instead it uses what appears to be a bespoke overlay management implementation.</p>



<p>Statically reverse-engineering the overlay manager routine turned out to be a very time-consuming endeavor, but luckily there were still some hints that can help us take some shortcuts.
The DOS emulator <a href="https://dosbox-x.com/">DOSBox-X</a> is a fork of DOSBox, and has additional useful debugging features, including logging of all file IO, and all <code>int 21h</code> interrupts.
Watching those while the game starts up reveals that the game is seeking through the binary to specific locations, which happen to be directly after the bytes of the main program, and then reading many chunks of 22 bytes each.</p>

<div><pre><code>...
4201235 DEBUG FILES:Seeking to 82944 bytes from position type (0) in WINTER.EXE 
4201290 DEBUG FILES:Reading 2 bytes from WINTER.EXE 
4201353 DEBUG FILES:Seeking to 82495 bytes from position type (0) in WINTER.EXE 
4201408 DEBUG FILES:Reading 2 bytes from WINTER.EXE 
4201475 DEBUG FILES:Seeking to 82497 bytes from position type (0) in WINTER.EXE 
4201530 DEBUG FILES:Reading 2 bytes from WINTER.EXE 
4204681 DEBUG FILES:Seeking to 82499 bytes from position type (0) in WINTER.EXE 
4204735 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4204855 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4204975 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4205095 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4205215 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4205335 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
4205455 DEBUG FILES:Reading 22 bytes from WINTER.EXE 
...
</code></pre></div>

<p>These are likely the start of the resources, and when checking the binary at that location we find that the secion begins with two bytes spelling out <code>MB</code>, similar to how the executables themselves start with an <code>MZ</code> magic number.
Looking for this magic number in the disassembly brings us directly to the routine which parses out the structure of the embedded resources.</p>

<div><pre><code>seg000:6D83                 sub     ax, ax                                 ; sets ax to 0
seg000:6D85                 push    ax                                     ; push argument 3 for fseek: 0 = seek relative to start of file
seg000:6D86                 push    winter_exe_overlay_start_index_hi      ; push argument 2 for fseek: the offset to seek to
seg000:6D8A                 push    winter_exe_overlay_start_index_lo      ; it's a 4 byte value and pushed in two halves
seg000:6D8E                 push    winter_exe_file_handle                 ; push argument 1 for fseek: the file handle of WINTER.EXE which was opened earlier
seg000:6D92                 call    fseek                                  ; seek to the start of the resource section in the WINTER.EXE file
seg000:6D97                 add     sp, 8                                  ; clear the arguments for fseek from the stack again
seg000:6D9A                 push    cs                                     ; the function read_2_bytes_from_winter_exe is a far function, but we're making in near call, so we need to push the segment onto the stack manually
seg000:6D9B                 call    near ptr read_2_bytes_from_winter_exe  ; read the next two bytes from the file
seg000:6D9E                 cmp     ax, 424Dh                              ; check if if contains the "MB" magic number
seg000:6DA1                 jz      short mb_marker_found                  ; jump if found
seg000:6DA3                 push    winter_exe_file_handle                 ; if not found, close file and return
seg000:6DA7                 call    fclose
seg000:6DAC                 add     sp, 2
seg000:6DAF                 mov     winter_exe_file_handle, 0
seg000:6DB5                 jmp     short done
seg000:6DB5 ; ---------------------------------------------------------------------------
seg000:6DB8 mb_marker_found:
seg000:6DB8                 sub     ax, ax                                 ; sets ax to 0
seg000:6DBA                 push    ax                                     ; push argument 3 for fseek: 0 = seek relative to start of file
seg000:6DBB                 mov     ax, winter_exe_overlay_start_index_lo  ; load overlay start index and add 2 to it
seg000:6DBE                 mov     dx, winter_exe_overlay_start_index_hi
seg000:6DC2                 add     ax, 2
seg000:6DC5                 adc     dx, 0
seg000:6DC8                 push    dx                                     ; push argument 2 for fseek: the offset to seek to
seg000:6DC9                 push    ax
seg000:6DCA                 push    winter_exe_file_handle                 ; push argument 1 for fseek: the file handle of WINTER.EXE which was opened earlier
seg000:6DCE                 call    fseek                                  ; seek to the next two bytes after the MB marker
seg000:6DD3                 add     sp, 8                                  ; clear the arguments for fseek from the stack again
seg000:6DD6                 push    cs
seg000:6DD7                 call    near ptr read_2_bytes_from_winter_exe  ; read the next two bytes from the file
seg000:6DDA                 mov     resource_chunk_count, ax               ; next two bytes indicate the number of resources
seg000:6DDD done:
....
</code></pre></div>

<blockquote>
  <h3 id="sidebar-16-bit-architecture-and-segments">Sidebar: 16-bit architecture and segments</h3>

  <p>This program, and all DOS programs at the time, were built for a 16-bit architecture, compared to the 64-bit architecture today’s computers are using.
What that means is that all registers in the CPU can hold only 16-bit values, including any pointers.
Since 16-bit registers can only have 2^16 = 65536 different values, it can only address 64kB of memory.
This was too little, even back then, so in order to be able to address more memory, pointers typically consisted of 2 parts, a segment and an offset.</p>

  <p><a href="https://en.wikipedia.org/wiki/Memory_segmentation">Segments</a> are chunks of memory, at most 64kB in size, which were typically assigned different roles: there are typically one or multiple code segments holding the program code, a data segment holding the work memory for any data the program stores, and a stack segment to hold the values which are put on the stack.
Those segments can be considered independent parts of the memory, and to interact with something from another segment, you would need a far pointer, consisting of both a segment and offset within that segment, whereas for referencing something within a segment a near pointer using only the offset is sufficient.</p>

  <p>Under the hood, the memory is still one linear chunk, and the resulting memory address of a far pointer is simply <code>segment * 16 + offset</code>.
That means segments can technically overlap with different segment-offset pairs pointing to the same physical address, but conventionally they were chosen to be distinct blocks.</p>
</blockquote>

<p>The resources are all tabulated in a simple header structure, in entries of 22 bytes each.
Each entry contains two 4-byte numbers, indicating the length of the data and the offset in the file where they are located.
The remaining bytes contains a 0-terminated string spelling out the name of the resource (any byte after the 0 terminator is garbage).
However, this name is obfuscated by adding <code>0x60</code> to all bytes, so they don’t show up in any strings analysis of the binary.
By de-obfuscating the names, we can learn that these additional binary blobs contain both the assets like images, meshes, music and SFX files, and the code overlays in the form of pairs of files with extensions <code>COD</code> and <code>REL</code>.</p>

<div><pre><code>4D 42                                                                  ; "MB" = magic number
F2 00                                                                  ; 242 = number of resources
4A 5C 00 00   10 57 01 00   B4 A9 B4 AC A5 8E AD B3 A8 00  (81 9F A2 01)  ; Resource TITLE.MSH     start 15710  end 1b35a  length 5c4a
26 24 00 00   5A B3 01 00   B4 A9 B4 AC A5 8E AD A7 B3 00  (81 9F A2 01)  ; Resource TITLE.MGS     start 1b35a  end 1d780  length 2426
9E D4 00 00   80 D7 01 00   B4 A9 B4 AC A5 8E AD B0 A9 00  (81 9F A2 01)  ; Resource TITLE.MPI     start 1d780  end 2ac1e  length d49e
00 03 00 00   1E AC 02 00   B4 A9 B4 AC A5 B0 A1 AC 8E A2 A9 AE 00  (01)  ; Resource TITLEPAL.BIN  start 2ac1e  end 2af1e  length 300
2E 4A 00 00   1E AF 02 00   B4 A9 B4 AC A5 92 8E AD B3 A8 00  (AE 00 01)  ; Resource TITLE2.MSH    start 2af1e  end 2f94c  length 4a2e
56 1B 00 00   4C F9 02 00   B4 A9 B4 AC A5 92 8E AD A7 B3 00  (AE 00 01)  ; Resource TITLE2.MGS    start 2f94c  end 314a2  length 1b56
44 CC 00 00   A2 14 03 00   A2 A1 A3 AB A4 B2 AF B0 8E AD B0 A9 00  (01)  ; Resource BACKDROP.MPI  start 314a2  end 3e0e6  length cc44
92 65 00 00   E6 E0 03 00   A9 B3 8E AD B3 A8 00  (B0 8E AD B0 A9 00 01)  ; Resource IS.MSH        start 3e0e6  end 44678  length 6592
CC 18 00 00   78 46 04 00   A9 B3 8E AD A7 B3 00  (B0 8E AD B0 A9 00 01)  ; Resource IS.MGS        start 44678  end 45f44  length 18cc
D8 88 00 00   44 5F 04 00   B4 A1 BF AF B0 A5 AE 8E AD A7 B3 00  (00 01)  ; Resource TA_OPEN.MGS   start 45f44  end 4e81c  length 88d8
D8 73 00 00   1C E8 04 00   B4 A1 BF AF B0 A5 AE 8E AD B3 A8 00  (00 01)  ; Resource TA_OPEN.MSH   start 4e81c  end 55bf4  length 73d8
00 07 00 00   F4 5B 05 00   A5 B6 B4 A1 B7 A1 B2 A4 8E AD A7 B3 00  (01)  ; Resource EVTAWARD.MGS  start 55bf4  end 562f4  length 700
22 24 00 00   F4 62 05 00   A5 B6 B4 A1 B7 A1 B2 A4 8E AD B3 A8 00  (01)  ; Resource EVTAWARD.MSH  start 562f4  end 58716  length 2422
CC 56 00 00   16 87 05 00   A9 B3 A1 B5 B8 8E AD B3 A8 00  (B3 A8 00 01)  ; Resource ISAUX.MSH     start 58716  end 5dde2  length 56cc
32 25 00 00   E2 DD 05 00   A9 B3 A1 B5 B8 8E AD A7 B3 00  (B3 A8 00 01)  ; Resource ISAUX.MGS     start 5dde2  end 60314  length 2532
...
64 27 00 00   96 AF 12 00   AF B6 AC 91 8E A3 AF A4 00  (B3 00 AE 00 01)  ; Resource OVL1.COD      start 12af96 end 12d6fa length 2764
6E 03 00 00   FA D6 12 00   AF B6 AC 91 8E B2 A5 AC 00  (B3 00 AE 00 01)  ; Resource OVL1.REL      start 12d6fa end 12da68 length 36e
35 02 00 00   68 DA 12 00   AF B6 AC 91 95 8E B0 A3 AF 00  (00 AE 00 01)  ; Resource OVL15.PCO     start 12da68 end 12dc9d length 235
11 00 00 00   9E DC 12 00   AF B6 AC 91 95 8E B0 B2 A5 00  (00 AE 00 01)  ; Resource OVL15.PRE     start 12dc9e end 12dcaf length 11
...
</code></pre></div>

<p>One fun pattern to observe is that the garbage data after the file names are leftovers from the previous name, suggesting that when the entries were written, it used the same buffer for all names in order.</p>

<p>Just from the names, we can assume that the <code>COD</code> files contain the actual machine code, and the <code>REL</code> files contain some relocation data.</p>

<blockquote>
  

  <p><a href="https://en.wikipedia.org/wiki/Relocation_(computing)">Relocation</a> is a concept that allows code to become location-independent: When a program is loaded into memory, it may not be loaded at the same address every time.
However, parts of the program refer to other parts by address (e.g. a function call), and in order for those to continue to work regardless of the actual location in memory, they need to be modified.
To achieve this, all addresses are written into the binary as if the program is located at memory address 0, and all the places which correspond to segment values are put in a long list called the relocation table.
For the main program, this is handled by DOS: the MZ header of the executable contains a relocation table with addresses in the code that need to be updated.
After copying the program into memory at some offset, DOS goes through this list and adds the chosen offset to each of the addresses it contains, making all far pointers point to the correct locations again.</p>

  <p>When loading these code overlays, the same problem of relocation will exist, and the <code>REL</code> files likely contain the needed information to facilitate their proper relocation.</p>
</blockquote>

<p>When looking at the different versions of the installed game, we can see that the resources they are bundled with are indeed different.
This finally resolves the first of our side mysteries:</p>

<blockquote>
  <p><strong>Side investigaton 3 complete!</strong>
Depending on the chosen graphics mode, more or fewer assets are included, and each asset can come in two variants, the uncompressed version (e.g. <code>TITLE.MGS</code>), and a compressed version (e.g. <code>TITLE.PMG</code>), indicated by prepending a <code>P</code> to its extension.
The “fast loading” versions of the installation bundle the uncompressed resources, while the floppy version contains the packed versions, providing a trade-off between speed of loading the assets at runtime and the size they take up on disk.</p>
</blockquote>

<p>It’s difficult to imagine nowadays, but hard drive space was a serious concern back then, and the additional kilobytes the unpacked asstes take up could matter a lot.</p>

<p>However, it seems that even in the fast-loading versions, not all assets are actually uncompressed.
Specifically some of the code overlays stay packed even there, presumably as a means to keep them obfuscated even when fast loading is selected during installation.
However, through disassembly we already know where the resources are loaded now, so using a debugger with appropriate breakpoints, we can easily dump the uncompressed versions for these as well out of the program memory, without needing to understand how the compression of the resources actually works.
(If you are still curious how the compression works, I did end up disassembling it to find that it’s a surprisingly sophisticated custom variant of <a href="https://en.wikipedia.org/wiki/Deflate">DEFLATE</a> compression.
You can find a JS re-implementation of it <a href="https://github.com/MrWint/winter/blob/70da5ba230a2161955d2fb9094f3d47bdea46026/patcher/patcher.js#L79">here</a>.)</p>

<p>Conveniently, the game also provides us with a fairly easy way to check whether we extracted all the resources correctly.
It turns out the game is more flexible with where it tries to load the resources from, and not only checks the embedded resources in the binary, but also checks for individual files of the same name, in the root folder or a subfolder called “ART”.
As long as the resource can be found in any of these places, it will use it.
So by writing a program to extract all these recources into their own files and placing them in the ART subfolder, and then manually modifying the binary to delete all embedded resources, we can make the game use our extracted assets instead.
Doing this and running the game, it is indeed still working, confirming that our extracted resources are accurate and we’re not missing anything else coming from the binary file.</p>

<h2 id="combining-all-overlays">Combining all overlays</h2>

<p>So now we finally have all the code comprising the business logic of the game, but they are spread out over 17 files, the main executable and 16 overlays, making them very annoying to work with.
What we would like is one single binary with all the code in it, making it much easier to analyze.
To achieve this, we can try to embed the overlays into the binary, essentially undoing the overlaying and having all of them loaded at once side-by-side.
Even more, doing this allows us to undo the replacement of the function calls with overlay interrupts, eliminating <code>int 3fh</code> altogether and making the automatic analysis by common disassemblers much more accurate.
Available RAM is obviously not a concern anymore today, but we will still need to stay within the 640kB limit DOS imposes.
Luckily, all overlays combined are only around 100kB in size, so together with the main binary of 168kB it should still leave enough room to load the assets as needed, especially since it won’t need to reserve heap space anymore loading the overlays.</p>

<p>Actually fusing the binaries together is not that easy unfortunately.
My first idea of just concatenating all overlays onto the main binary in memory and baking in the relocations to make them all connect sadly wouldn’t work, because of the stack and how dynamic memory allocations work.
The main binary is set up in a way where all code segments come first, then the data segment holding all the work memory the program uses, and lastly the stack segment.
Trying to append the overlays to this will always create some issues: Adding them before the data segment would mean we need to re-write all references to it throughout the code, which are hard to identify because the line between the data and stack areas are fuzzy and the code might do some pointer arithmetic that relies on the relative positions of the segments.
Adding the overlays after data segment by moving the stack back is also impossible, because the game does some weird shenanigans where it sets the stack segment to equal the data segment, adjusting the stack pointer accordingly to compensate.
This is probably useful as an invariant for optimization, but also means that the data and stack segments need to be close together in memory to allow that.
And finally, placing it after the stack, where they are typically loaded using the overlay manager, has problems as well because it would conflict with heap allocations.</p>

<blockquote>
  

  <p>Memory management worked completely differently back in the DOS days compared to now.
While modern operating systems all work with <a href="https://en.wikipedia.org/wiki/Virtual_memory">virtual memory</a> where each program has its own address space completely to itself, and the operating system translates them to the physical RAM addresses, DOS programs ran in what is called 16-bit <a href="https://en.wikipedia.org/wiki/Real_mode">Real Mode</a>, which uses the actual physical addresses directly.
That means programs had direct control over the entire RAM of the system, and could just read and write to it as they pleased.
This worked, mostly because you could only run one DOS program at a time anyway, so they didn’t need to share memory with others.</p>

  <p>So allocating memory really didn’t mean much since it was all yours anyway, and programs typically started out with “owning” the entire memory space.
DOS still provided an allocator, but in order to use it your program first needed to deallocate some of the memory space and give it back to DOS, so that new blocks can be allocated in this space.
This game does this, and in order to determine how much it can free up, it performs some calcuations based on the addresses it happens to be loaded into.</p>
</blockquote>

<p>So by just appending the overlays, we would interfere with the allocated memory, and while we could try to patch the program to avoid this, it may cause other unexpected side effects.</p>

<p>The solution to this conundrum, as always obvious only in hindsight, is to not add the overlays after the main program, but before it.
Since programs are created to be location-independent and can work anywhere in memory, moving it back in order to make space for the overlays can be done completely safely.
And since the overlays are normally heap allocated and can be anywhere in relation to the main program, there is no reason why that anywhere couldn’t be also before the main program.</p>

<p>To test this concept, I first created a new binary which only padded out the beginning of the binary by the needed amount without actually placing the overlays into it.
This can be done without needing to disassemble its contents at all, just using the relocation information in the MZ header to identify all the places where addresses need to be adjusted, and updating the header information to push the segments backwards.
The resulting binary still works perfectly, proving not only that the concept works, but also that the remaining memory is sufficient for everything else the game still needs to load.</p>

<p>In a second step, we can now place all the overlay code in the newly available space, and wire it up.
For each call of the <code>int 3fh</code> interrupt, we can extract which overlay and which location in the overlay it would normally go to, and replace it with a direct <code>far call</code> to that address in the now-embedded overlays.</p>

<p>The overlays themselves also need to be adjusted using their relocation information, with a small additional caveat: within the overlays there are two types of relocations, the addresses that point back into the main program, and the addresses which point to other areas within the same overlay.
The game contains special logic to handle both cases when it loads the overlays, which we need to replicate here, by checking which area of memory an address points to before applying the relocations.</p>

<p>We also need to append all the relocation information for the overlays to the relocation table of the main program, because the new combined binary can of course still be loaded into memory at any location, so the addresses need to be adjusted accordingly.</p>

<p>What we end up with is a completely self-contained binary, which does not need to load any more overlays to work, and which doesn’t contain any overlay interrupts anymore.
Together with the extracted art assets in separate files, we now have an unpacked and unobfuscated, still perfactly playable, version of the game.</p>

<p>It’s worth noting that this was not guaranteed to actually work.
Replacing the overlay interrupts with function calls has the same behavior, but the overlay manager itself which is now sidestepped has additional side effects which could be critical for the game to work.
One notable instance of this in the game is the logic it uses to unload overlays: To detect which memory addresses to deallocate, it inspects the actual code of the program, parses the interrupt call opcodes, and extracts the information out of it in order to determine which overlay is affected.</p>

<div><pre><code>seg000:D91F maybe_unload_overlay_for_call:
seg000:D91F                 push    bp                      ; save base pointer register on the stack, to restore it later
seg000:D920                 mov     bp, sp                  ; set base pointer to current stack pointer. This means all arguments are some fixed offset from bp
seg000:D922                 les     bx, [bp+6]              ; Read the far pointer that was provided as an argument, and store it in es:bx
seg000:D925                 cmp     byte ptr es:[bx], 0CDh  ; Check if at the given address is a CD byte, which is an int instruction
seg000:D929                 jz      short unload            ; if it is any int instruction, proceed (doesn't check what interrupt it actually is)
seg000:D92B                 jmp     short skip_unloading
seg000:D92D ; ---------------------------------------------------------------------------
seg000:D92D unload:
seg000:D92D                 mov     bl, es:[bx+2]           ; Read the overlay index following the int instruction to know which overlay to unload
seg000:D931                 call    unload_overlay          ; unload the overlay
seg000:D934
seg000:D934 skip_unloading:
seg000:D934                 pop     bp                      ; restore the base pointer stored at the start of the function
seg000:D935                 retf
</code></pre></div>

<p>Luckily, the game has built-in fallbacks to skip this step if the code locations don’t actually contain an interrupt but instead a far call.
Presumably, because it was not known ahead of time which pieces of code would end up in which overlay, they couldn’t know for sure which calls would end up being interrupts instead so they needed to handle both cases.
For us this is lucky because it means that even after replacing all interrupts with function calls, the overlay management code can handle it correctly and doesn’t try to unload our baked-in overlays.</p>

<h2 id="the-anti-debugger-check---part-1-obfuscation-and-assembly-trickery">The anti-debugger check - Part 1: obfuscation and assembly trickery</h2>

<p>With all the prep work done, we can now take a look at the inner workings of the game in earnest, starting with looking at the copy protection and the claims of improperly cracked versions causing gameplay issues.
Besides the main code wheel protection, the game actually has another defense mechanism, an anti-debugger check.
That anti-debugger check consists of two parts.</p>

<p>The first and simplest one is that the game checks for the existence of known debuggers in its path.
It tries to open three files with the file names <code>NU-MEGA</code>, <code>SOFTICE1</code> and <code>TDHDEBUG</code>, and if any of these exist, the game will not let you get past the main menu.
As you might guess, these names correspond to popular DOS-based debuggers, so if it detects you are using any of these, it will refuse operation.
The names of these files is obfuscated in the code using the xor operation, similar to the resource file names, and the check is buried inbetween other code initializing the intro sequence, but by logging the file IO the program performs they are easy to spot.</p>

<div><pre><code>seg001:039C check_for_known_debuggers:
seg001:039C                 push    bp                                ; save base pointer register on the stack, to restore it later
seg001:039D                 mov     bp, sp                            ; set base pointer to current stack pointer. This means all arguments are some fixed offset from bp
seg001:039F                 sub     sp, 40h                           ; reserve additional space on the stack
seg001:03A2                 push    di                                ; save di and si registers on the stack, to restore them after the function is done
seg001:03A3                 push    si
seg001:03A4                 sub     si, si                            ; set si to 0
seg001:03A6                 cmp     obfuscatedNuMegaFileName, 0       ; check if file name exists in memory
seg001:03AB                 jz      short file_name_empty_skip        ; skip decoding if its empty
seg001:03AD decode_file_name_loop:
seg001:03AD                 mov     al, obfuscatedNuMegaFileName[si]  ; read next byte of file name
seg001:03B1                 xor     al, 0A5h                          ; de-obfuscate byte
seg001:03B3                 mov     [bp+si+40h], al                   ; store in the space created on the stack
seg001:03B6                 inc     si                                ; move to next byte
seg001:03B7                 cmp     nuMegaFileName[si], 0             ; reached end of file name yet?
seg001:03BC                 jnz     short decode_file_name_loop       ; loop if more characters available
seg001:03BE file_name_empty_skip:
seg001:03BE                 mov     [bp+si+40h], 0                    ; terminate decoded file name with 0
seg001:03C2                 mov     ax, 8000h
seg001:03C5                 push    ax                                ; argument 2 for file read function, not important here
seg001:03C6                 lea     ax, [bp+40h]
seg001:03C9                 push    ax                                ; argument 1 for file read function, pointer to decoded file name
seg001:03CA                 call    open_file_for_read                ; try to open file
seg001:03CF                 add     sp, 4                             ; remove arguments from stack again
seg001:03D2                 mov     di, ax
seg001:03D4                 cmp     di, 0FFFFh                        ; check if opening the file succeeded
seg001:03D7                 jz      short next                        ; opening failed, move on to next file name to check
seg001:03D9                 mov     detected_debugger_binary, 1       ; debugger detected, set flag
seg001:03DF                 push    di                                ; argument 1 for close file, the file handle
seg001:03E0                 call    close_file_handle                 ; close the opened file again
seg001:03E5                 add     sp, 2                             ; remove arguments from stack again
seg001:03E8 next:
...
</code></pre></div>

<p>When we’re trying to follow where this debugger check flag is used, we see it is moved around from one memory address to the next a couple of times.
Here, the game also starts throwing misdirections at us to make deciphering it harder:</p>

<div><pre><code>seg010:0000 propagate_debugger_check_1:
seg010:0000                 push    bp              ; save bp to stack, starndard preamble for a function call
seg010:0001                 mov     bp, sp          ; set base pointer to current stack pointer. This means all arguments are some fixed offset from bp
seg010:0003                 sub     sp, 8           ; make space on stack for local variables
seg010:0006                 mov     ah, 2Ch
seg010:0008                 int     21h             ; int 21h ah=2c returns the current system time
seg010:000A                 push    dx              ; argument 1: seconds and hundreds of the system time
seg010:000B                 call    process_current_time_result
seg010:000E                 add     sp, 2
seg010:0011                 mov     cx, 4A52h
seg010:0014                 mov     bx, data_segment
seg010:0017                 mov     es, bx
seg010:0019                 mov     es:debugger_check_result_4E62A, cl
...
seg010:0029 ; ---------------------------------------------------------------------------
seg010:0029 process_current_time_result:
seg010:0029                 push    bp              ; save bp to stack, starndard preamble for a function call
seg010:002A                 mov     bp, sp          ; set base pointer to current stack pointer. This means all arguments are some fixed offset from bp
seg010:002C                 mov     bx, 0Fh         ; bx = 15 (?)
seg010:002F                 mov     cx, detected_debugger_binary
seg010:0033                 mov     ax, cx
seg010:0035                 imul    bx              ; multiplies detected_debugger_binary by 15 (?)
seg010:0037                 mov     ax, [bp+4]      ; reads seconds and hundreds into ax (?)
seg010:003A                 xchg    al, ah          ; swaps seconds and hundreds part (?)
seg010:003C                 sub     bl, 3           ; bx = 12 (?)
seg010:003F                 sub     bp, 2           ; modifies the base pointer. This is very sneaky, as it fundamentally changes what the operation seg010:0054 below does.
seg010:0042                 add     al, ah          ; add seconds and hundreds part together (?)
seg010:0044                 sub     ah, ah
seg010:0046                 idiv    bx              ; divide by 12 (?)
seg010:0048                 mov     ax, segment_42
seg010:004B                 mov     es, ax
seg010:004D                 mov     es:code_wheel_flag_index_input_4A090, dx  ; this is later used as "random" input for the code wheel check
seg010:0052                 shr     bx, 1           ; bx = 6 (?)
seg010:0054                 add     [bp+4], 6       ; The magic happens here: Because of the modified bp, this doesn't modify the argument, but the return address of the function
seg010:0058                 pop     bp
seg010:0059                 retn                    ; because of the changed return address, it will skip the instructions at seg010:000E and seg010:0011 after returning!
</code></pre></div>

<p>This is a <strong>very misleading</strong> piece of code that would make any malware developer jealous.
At first glance, it appears to read the current time and process it, and then write a constant <code>4A52h</code> to register cx and later into <code>debugger_check_result_4E62A</code>.
However, the <code>process_current_time_result</code> does some weird things instead.
For one, most of the operations (I marked them with question marks) don’t actually contribute anything, they are purely there to confuse you.
The operation that actually matters and is trying to hide is the modification of the base pointer at <code>seg010:003F</code>.
This, in combination with the instruction at <code>seg010:0054</code>, modify the return address of the function, increasing it by 6.
This means instead of returning at <code>seg010:000E</code> like it should, it will instead return at <code>seg010:0014</code>, skipping setting cx to the constant value.
So the value that is actually propagated into <code>debugger_check_result_4E62A</code> is the <code>detected_debugger_binary</code> which was loaded into cx, all the other operations are just misdirection.</p>

<p>This kind of misdirection is clearly intended to make disassembly deliberately harder and stop people from reverse engineering the copy protections.
We will see more of it as we move on.</p>

<h2 id="the-anti-debugger-check---part-2-modern-computers-are-too-fast">The anti-debugger check - Part 2: Modern computers are too fast</h2>

<p>The debugger check result flag is moved around two more times:</p>

<div><pre><code>...
seg011:003C                 mov     al, es:debugger_check_result_4E62A
seg011:0040                 mov     bx, seg segment_39
seg011:0043                 mov     es, bx
seg011:0045                 mov     es:debugger_check_result_47A70, al
...
</code></pre></div>

<p>and finally</p>

<div><pre><code>...
seg000:0355                 mov     al, es:debugger_check_result_47A70
seg000:0359                 sub     ah, ah
seg000:035B                 mov     debugger_check_result, ax
...
</code></pre></div>

<p>These two moves are the second debugger check the game does, which is more technical and based on the <a href="https://en.wikipedia.org/wiki/Intel_8253">Intel 8253</a> timer chip.</p>

<p>The first move is performed inside a timer interrupt handler which the game installs, and which is triggered by the aforementioned timer chip.
Later during the initialization, the game then runs the second move of the flag to its final location, which is ultimately the one that is checked to decide whether you passed or failed.
That means that this timer interrupt is expected to be triggered at the right moment, after the initial known debugger check has been performed, but before the value is looked up later during initialization.
If the timer is triggered too early or too late with respect to the initialization, the the check won’t pass.
This check would prevent you from stepping through the initialization code, because the timer interrupt will fire too early, or emulate it in some way that doesn’t consider hardware interrupts.</p>

<p>For modern DOS emulators like DOSBox, this is not a problem and they are accurate enough to be able to pass the check easily.
The main issue arises from modern computers being <em>too fast</em>: if your emulation speed is too high, especially if you use the fast-loading version of the game, it breezes through the initialization so fast that it is done before the timer interrupt could trigger, making you fail the check.
The simple solution to this problem therefore is to slow down the emulator before starting the game.
After it is in the main menu, you can speed it up again without adverse effects.
Especially our home-cooked fully unpacked version loads so blazingly fast, that I need to slow down the emulator to a crawl in order to still pass the check.
This is because unpacking the resources from the executable is itself much slower than loading individual files, even if they are not compressed, because it needs to linearly scan through the whole resource list for every resource, whereas the (emulated) file IO takes no time at all.</p>

<div><pre><code>seg000:0D42 perform_debugger_check:
seg000:0D42                 push    bp
seg000:0D43                 mov     bp, sp
seg000:0D45                 or      ax, ax              ; ax contains debugger_check_result, check if it succeeded
seg000:0D47                 jz      short check_passed  ; if equals 0, it succeeded
seg000:0D49                 call    sub_12846           ; changes back to text mode
seg000:0D4E                 mov     ax, offset aPleaseRemove ; "Please remove your debugger before running The Games: Winter Challenge"
seg000:0D51                 push    ax
seg000:0D52                 call    println             ; prints error message to screen
seg000:0D57                 mov     sp, bp
seg000:0D59                 sub     ax, ax
seg000:0D5B                 push    ax
seg000:0D5C                 call    sub_2F8CE           ; exits game
seg000:0D61
seg000:0D61 check_passed:
seg000:0D61                 mov     sp, bp
seg000:0D63                 pop     bp
seg000:0D64                 retn
</code></pre></div>

<p>Slowing down the emulator each time to pass the check gets annoying quickly though.
Luckily, the debugger check is done in a single place, and is easily removed without any adverse effects, by modifying the conditional jump at <code>seg000:0D47</code> to be an unconditional jump instead.
We have now partially cracked the game, hurray!
That was the appetizer though, the main course is still to come and it’s a doozy.</p>

<h2 id="the-code-wheel-check---a-honey-pot-for-crackers">The code wheel check - A honey pot for crackers</h2>

<p>The code wheel protection is in principle less technical and more straight-forward: The game reads the number you enter, it then looks up what the answer should have been, and checks whether they match.
Thanks to our fully unpacked executable, finding where this check is made is as simple as finding the error message (“That ticket number is incorrect.  Try again.”) in the binary, and looking for references to it, places in the code where it is used.
Placing debugger breakpoints on this function and stepping through it lets us identfy which sections are roughly responsible for which parts of the process.</p>

<p>Through this process, we can identify the heart of the protection: a function which takes the randomly generated code wheel configuration and the entered ticket number as an input, and decides whether it was entered correctly or not.
It doesn’t do any assembly trickery, but it contains some unnecessary operations as misdirection.
We can translate it to some more compact pseudo code:</p>

<div><pre><code>code_wheel_check_answer(city_index, flag_index, country_index, discipline_index, ticket_number):  # at seg007:0260
    # determine how high the slot cutout for the chosen city is on the inner wheel, values 0(innermost) - 5(outermost)
    slot_height = slot_height_table[city_index]
    code_wheel_ticket_number_4A890 = ticket_number

    # determine slot position relative to chosen discipline, values 0-11 clockwise
    slot_position = (city - ((city + 1) &gt;&gt; 2)) - discipline_index
    code_wheel_ticket_number_4A892 = ticket_number
    if slot_position &lt; 0:
        slot_position += 12

    # determine which sector of the outer wheel is under the slot
    flag_wheel_sector = (flag_index + slot_position) % 12
    code_wheel_ticket_number_4A894 = ticket_number

    # do unnecessary operations as misdirection
    rand = random_number()
    alloc = allocate_memory(rand % 1000)
    deallocate_memory(alloc)

    # determine which sector of the middle wheel is under the slot
    country_wheel_sector = (country_index + slot_position) % 12

    # read expected answer from obfuscated table
    obfuscated_ticket = country_wheel_data[country_wheel_sector * 6 + slot_height]
    code_wheel_ticket_number_4A898 = ticket_number
    if obfuscated_ticket == 0xa283:  # hole in the middle wheel, use outer wheel data instead
        obfuscated_ticket = flag_wheel_data[flag_wheel_sector * 6 + slot_height]

    code_wheel_ticket_number_4A89C = ticket_number
    return ticket_number ^ 0xa283 == obfuscated_ticket
</code></pre></div>

<p>Apart from the random memory allocation and deallocation providing some red herrings, the actual checking logic is fairly straight-forward and directly simulates how the physical code wheel functions.
It considers how the discs are rotated, and then checks which number will be visible on the wheel based on a table of all the possible answers.</p>

<blockquote>
  <p><strong>Side investigaton 1 complete!</strong></p>
</blockquote>

<p>But besides the immediate check, it also places the ticket number into 5 different places in memory.
Those 5 memory locations are where it gets interesting, because looking at where they are used, they all re-appear in the same location:</p>

<div><pre><code>seg015:0000 code_wheel_calculate_derived_ticket_numbers:
seg015:0000                 push    si
seg015:0001                 mov     es, segment_47
seg015:0005                 mov     ax, es:code_wheel_ticket_number_4A890
seg015:0009                 xor     ax, 0C514h
seg015:000C                 mov     cx, ax
seg015:000E                 shl     ax, 1
seg015:0010                 add     ax, cx
seg015:0012                 mov     es, segment_47
seg015:0016                 mov     es:ticket_xor_c514_mul_3, ax
seg015:001A                 mov     es, segment_47
seg015:001E                 mov     ax, es:code_wheel_ticket_number_4A892
seg015:0022                 xor     ax, 0C514h
seg015:0025                 add     ax, 38D9h
seg015:0028                 mov     es, segment_47
seg015:002C                 mov     es:ticket_xor_c514_plus_38d9, ax
seg015:0030                 mov     es, segment_47
seg015:0034                 mov     cx, es:code_wheel_ticket_number_4A89C
seg015:0039                 xor     cx, 0C514h
seg015:003D                 sub     cx, 37Ch
seg015:0041                 mov     es, segment_47
seg015:0045                 mov     es:ticket_xor_c514_sub_37c, cx
seg015:004A                 mov     es, segment_47
seg015:004E                 mov     cx, es:code_wheel_ticket_number_4A898
seg015:0053                 xor     cx, 8E47h
seg015:0057                 mov     es, segment_47
seg015:005B                 mov     es:ticket_xor_8e47, cx
seg015:0060                 mov     bx, 7
seg015:0063                 mov     es, segment_47
seg015:0067                 mov     dx, ax
seg015:0069                 mov     ax, es:code_wheel_ticket_number_4A894
seg015:006D                 xor     ax, 0C514h
seg015:0070                 mov     si, dx
seg015:0072                 sub     dx, dx
seg015:0074 loc_29284:
seg015:0074                 div     bx
seg015:0076                 mov     es, segment_47
seg015:007A                 mov     es:ticket_xor_c514_div_7, ax
seg015:007E                 add     cx, si
seg015:0080                 mov     es, segment_47
seg015:0084                 mov     es:ticket_xor_c514_plus_38d9_allplus_ticket_xor_8e47, cx
seg015:0089                 pop     si
seg015:008A                 retf
</code></pre></div>

<p>In this code snippet, the 5 copies of the ticket number are modified in various ways to create 6 new values derived from it, with some arbitrary opertaions to make them all different.
Each of these six values is used some specific place elsewhere in the code, where it is compared against some reference value.
If we try to find out where those reference values come from, what we find it a second copy of the code wheel answer checking routine from above, complete with a second instance of the table containing all correct answers!
The only difference between the two is that is uses a different value to xor the ticket numbers with, using <code>0xc514</code> instead of <code>0xa283</code>.
Afterwards, the same arbitrary operations are applied to them to create the 6 reference values.</p>

<blockquote>
  <p><strong>Side investigaton 2 complete!</strong></p>

  <p>The hidden copy protection checks are real!
The game performs more hidden code wheel checks throughout the game, in each of these 6 locations.
If the main code wheel check is merely skipped, these hidden checks will fail and the game knows you tried to circumvent the copy protection.
When that happens, it will mess with the game in more subtle ways, to sabotage your illegitimate play session.
This is a sneaky additional layer of copy protection, where if you try to crack the game and remove the obvious checks, you might not even realize these additional checks exist, unless you pick up on the gameplay alterations.</p>
</blockquote>



<p>To find out what gameplay alterations the game performs when the checks fail, the easiest way is to set breakpoints at each of these locations, and then play the various disciplines waiting for them to trigger.
This lets us easily discover what each of the hidden checks do.</p>

<p>Even better, thanks to the replay feature, we can record a replay with a proper version, and then play it back in a version where the hidden checks activate, in order to see what difference they make on the same set of inputs.</p>

<h3 id="ski-jump">Ski Jump</h3>

<p>One of the most obvious changes we find in the skip jump event: When the copy protection check fails, any attempt land a ski jump beyond a certain distance fails.
More specifically, beyond a distance of 86.7m, the game won’t recognize you pressing Enter to land your jump anymore:</p>

<p><img src="https://mrwint.github.io/winter/writeup/ski_jump_success.webp" alt="Ski jump success">
<img src="https://mrwint.github.io/winter/writeup/ski_jump_failed.webp" alt="Ski jump failure">
<br>
(if the two animations are not in sync, try reloading this page in a new tab<a> or click here</a>)</p>

<h3 id="speed-skating">Speed Skating</h3>

<p>This is the second very obvious change: In the third lap in speed skating, the game won’t allow you to turn forcing you to crash into the wall:</p>

<p><img src="https://mrwint.github.io/winter/writeup/speed_skating_success.webp" alt="Speed skating success">
<img src="https://mrwint.github.io/winter/writeup/speed_skating_failed.webp" alt="Speed skating failure">
<br>
(if the two animations are not in sync, try reloading this page in a new tab<a> or click here</a>)</p>

<h3 id="biathlon">Biathlon</h3>

<p>In Biathlon, the copy protection check happens during the shooting sections.
If the check fails, it will move your shot by a random amount to the top right, on the second and fourth target in each segment:</p>

<p><img src="https://mrwint.github.io/winter/writeup/biathlon_success.webp" alt="Biathlon success">
<img src="https://mrwint.github.io/winter/writeup/biathlon_failed.webp" alt="Biathlon failure">
<br>
(if the two animations are not in sync, try reloading this page in a new tab<a> or click here</a>)</p>

<h3 id="downhill">Downhill</h3>

<p>The Downhill event also has a copy protection check.
It is activated partway into the run, and if it fails it changes the physics behavior to lower the gravity, making you fly off the track:</p>

<p><img src="https://mrwint.github.io/winter/writeup/downhill_success.webp" alt="Downhill success">
<img src="https://mrwint.github.io/winter/writeup/downhill_failed.webp" alt="Downhill failure">
<br>
(if the two animations are not in sync, try reloading this page in a new tab<a> or click here</a>)</p>

<h3 id="bobsled">Bobsled</h3>

<p>The alteration in the Bobsled event is probably the most subtle.
When the copy protection check fails, after the first couple of turns, the physics change to give you more drag, slowing you down more than usual:</p>

<p><img src="https://mrwint.github.io/winter/writeup/bobsled_success.webp" alt="Bobsled success">
<img src="https://mrwint.github.io/winter/writeup/bobsled_failed.webp" alt="Bobsled failure">
<br>
(if the two animations are not in sync, try reloading this page in a new tab<a> or click here</a>)</p>

<h3 id="luge">Luge</h3>

<p>The last of the copy protection checks is the most drastic.
During the Luge event, if you are close to the end of the track with a time of below 57.7s, the game just instantly forfeits your run, preventing you from finishing it:</p>

<p><img src="https://mrwint.github.io/winter/writeup/luge_failed.webp" alt="Luge failure">
<br>
(if the two animations are not in sync, try <a href="https://www.youtube.com/watch?v=46btEgKmCTo">building a bridge across the peaks of Mt. Kilimanjaro</a>)</p>



<p>Now that we know what a failed copy protection check looks like, we can check each of the  game versions and cracks we found to see whether they work correctly.</p>

<p>As it turns out, <strong>ALL OF THEM, except for one, FAIL THE COPY PROTECTION CHECK!
That includes even the official releases: Both the 1996 US release and the 2020 GOG release are broken.</strong></p>

<p>Let’s take a look under the hood of each of them and see what they do</p>

<h3 id="the-gog-version-2020">The GOG version (2020)</h3>

<p>The GOG version comes with a pre-patched binary, which is based on the installed VGA+EGA fast-load version of the original 1991 release.
When looking for what has been changed, beside a couple of padding bytes that do nothing, there are only 2 bytes that are different:</p>

<p>The first is at position 0x12bcdd in the file, which corresponds to offset 0xd47 in overlay 1.
That is the location of the debugger check, and if does the exact same modification we did above ourselves: it changes the jump instruction from a conditional <code>je</code> (0x74) to an unconditional <code>jmp</code> (0xeb), skipping the debugger check.</p>

<p>The other modification is similarly simple and happens at position 0x12bca4 in the file, which corresponds to offset 0xd0e in overlay 1.
This is where the code wheel check is started from, and it replaces the initial <code>cmp</code> opcode (0x83) with a simple <code>retn</code> opcode (0xc3), returning immediately and skipping the code wheel check.</p>

<p>But as we saw, simply skipping the code wheel will trigger the hidden copy protection checks, and the GOG version makes no attempt to circumvent these, causing the game to be broken.</p>

<h3 id="the-unknown-cracked-version">The unknown cracked version</h3>

<p>The second of the pre-patched binaries we found, is based on the VGA fast-load version instead.
It has only one meaningfully change compared to the original.
At position 0x122b42, which corresponds to offset 0x406 in overlay 1, it replaces a <code>call</code> instruction with <code>nop</code>s (0x90).
That function is the one leading to the code wheel check, so it is very similar to the GOG version, it just skips the function entirely instead of calling it and then immediately returning from it.
The effects are of course also the same: It trips the hidden copy protections and the game behavior is broken.</p>

<h3 id="the-the-humble-guys-crack-1991">The “The Humble Guys” crack (1991)</h3>

<p>Instead of a pre-patched binary, this crack comes in the form of a program <code>WG.COM</code> which you run separately before the main executable.
It’s only 366 bytes in size, and when we disassemble it we see this (with some unimportant parts omitted):</p>

<div><pre><code>seg000:010D int3f_interrupt_handler_shim:
seg000:010D                 cmp     ax, 0
seg000:0110                 jnz     short exec_original_int3f_handler
seg000:0112                 cmp     bx, 30h
seg000:0115                 jnz     short exec_original_int3f_handler
seg000:0117                 cmp     cx, 140h
seg000:011B                 jnz     short exec_original_int3f_handler
seg000:011D                 cmp     dx, 0C8h
seg000:0121                 jnz     short exec_original_int3f_handler
seg000:0123                 push    bp
seg000:0124                 mov     bp, sp
seg000:0126                 push    bx
seg000:0127                 mov     bx, [bp+2]
seg000:012A                 cmp     bx, 0D28h       ; check that return address is ovl1:d26 - perform_code_wheel_check call
seg000:012E                 jnz     short loc_10133
seg000:0130                 pop     bx
seg000:0131                 pop     bp
seg000:0132                 iret
seg000:0133 ; ---------------------------------------------------------------------------
seg000:0133 loc_10133:
seg000:0133                 pop     bx
seg000:0134                 pop     bp
seg000:0135 exec_original_int3f_handler:
seg000:0135                 jmp     cs:original_int3f_handler_address
seg000:013A
seg000:013A ; ---------------------------------------------------------------------------
seg000:013A int21_interrupt_handler_shim:
...
seg000:0167                 cmp     ax, 2B01h       ; check for expected value in ax
seg000:016A                 jnz     short exec_original_int21_handler
seg000:016C                 push    bp
seg000:016D                 mov     bp, sp
seg000:016F                 push    bx
seg000:0170                 mov     bx, [bp+2]
seg000:0173                 cmp     bx, 0BFBh       ; check that return address is ovl2:bf9 - set time interrupt
seg000:0177                 jnz     short loc_1019C
seg000:0179                 push    ds
seg000:017A                 push    es
seg000:017B                 push    dx
seg000:017C                 push    ax
seg000:017D                 mov     ax, 353Fh
seg000:0180                 int     21h             ; Read interrupt vector for int 3fh, so it can be restored afterwards
seg000:0182                 mov     word ptr cs:original_int3f_handler_address, bx
seg000:0187                 mov     word ptr cs:original_int3f_handler_address+2, es
seg000:018C                 mov     dx, offset int3f_interrupt_handler_shim
seg000:018F                 mov     bx, cs
seg000:0191                 mov     ds, bx
seg000:0193                 mov     ax, 253Fh
seg000:0196                 int     21h             ; Override int 3fh interrupt handler with our own shim
...
seg000:0218 ; ---------------------------------------------------------------------------
seg000:0218 start:
...
seg000:023E                 push    cs
seg000:023F                 pop     ds
seg000:0240                 mov     bx, 2Ch
seg000:0243                 push    word ptr [bx]
seg000:0245                 pop     es
seg000:0246                 mov     ax, 4900h
seg000:0249                 int     21h                        ; Free memory beyond the program, to allow DOS to use it to load other things into it
seg000:024B                 mov     ax, 3521h
seg000:024E                 int     21h                        ; Read interrupt vector for int 21h, so it can be restored afterwards
seg000:0250                 mov     word ptr cs:original_int21_handler_address, bx
seg000:0255                 mov     word ptr cs:original_int21_handler_address+2, es
seg000:025A                 mov     dx, offset int21_interrupt_handler_shim
seg000:025D                 mov     ax, 2521h
seg000:0260                 int     21h                        ; Override interrupt vector for int 21h with our own shim
seg000:0262                 mov     dx, offset aTsrSuccessfull ; Static success message
seg000:0265                 mov     ah, 9
seg000:0267                 int     21h                        ; Print text to screen
seg000:0269                 mov     dx, offset aTheGamesWinter ; this is the byte after the interrupt handlers, indicating which bytes need to be preserved
seg000:026C                 int     27h                        ; Terminate But Stay Resident - This lets the installed interrupt handlers remain active
</code></pre></div>

<p>The crack works by overriding interrupt handlers and injecting its own code into them.
It first overrides the main DOS interrupt <code>int 21h</code>, and looks for a specfic interrupt the game triggers during initialization, at which point it overrides the overlay manager interrupt <code>int 3fh</code> as well.
The reason it needs to do this in two steps is that the <code>int 3fh</code> interrupt is only installed during runtime, so it can only be overridden afterwards.
Why it is looking for that specific random interrupt is beyond me, since there were way more obvious targets, like the interrupt that actually installs the <code>int 3fh</code> handler.</p>

<p>In the overlay manager interrupt, it then looks for one very specific invocation, by checking the register values and return address.
That specific invocation happens from offset 0xd26 in overlay 1, where it tries to load and perform the code wheel check.
When it finds this interrupt, it will simply skip executing it, effectively skipping the code wheel check.</p>

<p>This has essentially the same effect as the modifications from the pre-patched binaries above.
It notably also trips the hidden copy protections and breaks the game.</p>

<h3 id="the-wintersummer-bundle-us-release-1996">The Winter+Summer bundle US release (1996)</h3>

<p>The official 1996 bundle release came with its own crack in the form of a <code>WINTER.COM</code> loader executable that you run instead of the main binary.</p>

<p>Looking at what it does, we actually see a very similar picture:</p>

<div><pre><code>seg000:020A int21_interrupt_handler_shim:
seg000:020A                 push    bp
seg000:020B                 mov     bp, sp
seg000:020D                 cmp     word ptr [bp+2], 0BFBh ; check that return address is ovl2:bf9 - set time interrupt
seg000:0212                 pop     bp
seg000:0213                 jnz     short exec_original_int21_handler
seg000:0215                 push    ds
seg000:0216                 push    es
seg000:0217                 push    dx
seg000:0218                 push    ax
seg000:0219                 mov     ax, 353Fh
seg000:021C                 int     21h             ; Read interrupt vector for int 3fh, so it can be restored afterwards
seg000:021E                 mov     word ptr cs:original_int3f_handler_address, bx
seg000:0223                 mov     word ptr cs:original_int3f_handler_address+2, es
seg000:0228                 mov     dx, offset int3f_interrupt_handler_shim
seg000:022B                 push    cs
seg000:022C                 pop     ds
seg000:022D                 mov     ax, 253Fh
seg000:0230                 int     21h             ; Override int 3fh interrupt handler with our own shim
...
seg000:023D ; ---------------------------------------------------------------------------
seg000:023D int3f_interrupt_handler_shim:
seg000:023D                 or      ax, ax
seg000:023F                 jnz     short exec_original_int3f_handler
seg000:0241                 cmp     bx, 30h
seg000:0244                 jnz     short exec_original_int3f_handler
seg000:0246                 cmp     cx, 140h
seg000:024A                 jnz     short exec_original_int3f_handler
seg000:024C                 cmp     dx, 0C8h
seg000:0250                 jnz     short exec_original_int3f_handler
seg000:0252                 push    bp
seg000:0253                 mov     bp, sp
seg000:0255                 cmp     word ptr [bp+2], 0D28h ; check that return address is ovl1:d26 - perform_code_wheel_check call
seg000:025A                 pop     bp
seg000:025B                 jnz     short exec_original_int3f_handler
seg000:025D                 iret
seg000:025E ; ---------------------------------------------------------------------------
seg000:025E exec_original_int21_handler:
seg000:025E                 jmp     cs:original_int21_handler_address
seg000:0263 ; ---------------------------------------------------------------------------
seg000:0263 exec_original_int3f_handler:
seg000:0263                 jmp     cs:original_int3f_handler_address
...
</code></pre></div>

<p>The opcodes are different, but the check that is performed is exactly the same as the one as in the “The Humble Guys” crack.
It checks the same register state, and it even uses the same weirdly specific <code>int 21h</code> invocation to install the overlay manager shim.</p>

<p>If I were to guess, I’d say someone has taken some “inspiration” from the “The Humble Guys” crack when creating this version.
It’s also just shoddily bolted together, with snippets of unused code everywhere.
It looks like someone repurposed some other similarly structured crack, and insterted the specifics of the “The Humble Guys” crack into it to make it work for this game.</p>

<p>It of course therefore also has the same problem: it trips the hidden copy protections and the game is broken.</p>

<h3 id="the-razor1911-crack-1991">The “Razor1911” crack (1991)</h3>

<p>Finally, we get to the only crack that actually works properly.
Congratulations to Razor1911 for being the only ones not fooled by the game’s trickery.</p>

<p>Let’s take a look at how their crack works:</p>

<div><pre><code>seg000:0100 start           proc near
seg000:0100                 mov     sp, 300h
seg000:0103                 mov     bx, 30h ; '0'
seg000:0106                 mov     ax, 4A00h
seg000:0109                 int     21h             ; Free memory beyond the executable
seg000:010B                 mov     ax, 353Fh
seg000:010E                 int     21h             ; Read interrupt vector for int 3fh, so it can be restored afterwards
seg000:0110                 mov     word ptr original_int3f_handler_address, bx
seg000:0114                 mov     word ptr original_int3f_handler_address+2, es
seg000:0118                 mov     ax, 3521h
seg000:011B                 int     21h             ; Read interrupt vector for int 21h, so it can be restored afterwards
seg000:011D                 mov     word ptr original_int21_handler_jump+1, bx
seg000:0121                 mov     word ptr original_int21_handler_jump+3, es
seg000:0125                 push    cs
seg000:0126                 pop     es
seg000:0127                 mov     ax, 2521h
seg000:012A                 mov     dx, offset int21_interrupt_handler_shim
seg000:012D                 int     21h             ; Override int 21h interrupt handler with our own shim
seg000:012F                 mov     dx, offset aWinterExe ; "WINTER.EXE"
seg000:0132                 mov     bx, offset parameterBlock
seg000:0135                 mov     word ptr [bx+4], cs
seg000:0138                 mov     word ptr [bx+4], cs
seg000:013B                 mov     word ptr [bx+4], cs
seg000:013E                 mov     ax, 4B00h
seg000:0141                 int     21h             ; Run WINTER.EXE
seg000:0143                 mov     dx, word ptr original_int21_handler_jump+1
seg000:0147                 mov     ds, word ptr original_int21_handler_jump+3
seg000:014B                 mov     ax, 2521h
seg000:014E                 int     21h             ; Restore the original int 21h interrupt vector
seg000:0150                 push    cs
seg000:0151                 pop     ds
seg000:0152                 mov     dx, word ptr original_int3f_handler_address
seg000:0156                 mov     ds, word ptr original_int3f_handler_address+2
seg000:015A                 mov     ax, 253Fh
seg000:015D                 int     21h             ; Restore the original int 3fh interrupt vector
seg000:015F                 push    0
seg000:0161                 retn
seg000:0162 ; ---------------------------------------------------------------------------
seg000:0162 int21_interrupt_handler_shim:
seg000:0162                 pushf
seg000:0163                 cmp     ax, 253Fh       ; check for game setting up the int 3fh handler
seg000:0166                 jnz     short loc_10177
seg000:0168                 mov     word ptr cs:game_int3f_handler_jump+1, dx
seg000:016D                 mov     word ptr cs:game_int3f_handler_jump+3, ds
seg000:0172                 push    cs
seg000:0173                 pop     ds
seg000:0174                 mov     dx, offset int3f_interrupt_handler_shim  ; inject our own shim instead of the game's handler
seg000:0177 loc_10177:
seg000:0177                 popf
seg000:0178 original_int21_handler_jump:
seg000:0178                 jmp     far ptr 0:0
seg000:017D ; ---------------------------------------------------------------------------
seg000:017D int3f_interrupt_handler_shim:
seg000:017D                 push    bp
seg000:017E                 mov     bp, sp
seg000:0180                 push    ax
seg000:0181                 push    bx
seg000:0182                 push    cx
seg000:0183                 push    dx
seg000:0184                 push    si
seg000:0185                 push    di
seg000:0186                 push    ds
seg000:0187                 push    es
seg000:0188                 cmp     word ptr [bp+2], 103h   ; ovl3:101, skip check for known debuggers
seg000:018D                 jz      short loc_101E0
seg000:018F                 cmp     word ptr [bp+2], 0D4Bh  ; ovl1:d49, after failing debugger check, jump to success outcome
seg000:0194                 jz      short loc_101E7
seg000:0196                 cmp     word ptr [bp+2], 10Bh   ; ovl8:109, skips over code wheel input screen
seg000:019B                 jz      short loc_101D4
seg000:019D                 cmp     word ptr [bp+2], 11Ch   ; ovl8:11A, overrides end of code wheel check code adding the hook
seg000:01A2                 jz      short loc_101AD
seg000:01A4                 cmp     word ptr [bp+2], 381h   ; ovl8:37F, hook added above, set variables to pretend code wheel check succeeded
seg000:01A9                 jz      short loc_101B9
seg000:01AB                 jmp     short exec_original_overlay_manager
seg000:01AD ; ---------------------------------------------------------------------------
seg000:01AD
seg000:01AD loc_101AD:
seg000:01AD                 push    word ptr [bp+4]
seg000:01B0                 pop     ds
seg000:01B1                 mov     word ptr ds:37Fh, 3FCDh
seg000:01B7                 jmp     short exec_original_overlay_manager
seg000:01B9 ; ---------------------------------------------------------------------------
seg000:01B9
seg000:01B9 loc_101B9:
seg000:01B9                 mov     ax, bx
seg000:01BB                 xor     ax, 0A283h
seg000:01BE                 mov     es:0, ax
seg000:01C2                 mov     es:2, ax
seg000:01C6                 mov     es:4, ax
seg000:01CA                 mov     es:8, ax
seg000:01CE                 mov     es:0Ch, ax
seg000:01D2                 jmp     short skip_original_overlay_manager
seg000:01D4 ; ---------------------------------------------------------------------------
seg000:01D4
seg000:01D4 loc_101D4:
seg000:01D4                 pop     es
seg000:01D5                 assume es:nothing
seg000:01D5                 pop     ds
seg000:01D6                 pop     di
seg000:01D7                 pop     si
seg000:01D8                 pop     dx
seg000:01D9                 pop     cx
seg000:01DA                 pop     bx
seg000:01DB                 pop     ax
seg000:01DC                 pop     bp
seg000:01DD                 inc     si
seg000:01DE                 jmp     short game_int3f_handler_jump
seg000:01E0 ; ---------------------------------------------------------------------------
seg000:01E0
seg000:01E0 loc_101E0:
seg000:01E0                 mov     word ptr [bp+2], 106h
seg000:01E5                 jmp     short skip_original_overlay_manager
seg000:01E7 loc_101E7:
seg000:01E7                 mov     word ptr [bp+2], 0D61h
seg000:01EC                 jmp     short skip_original_overlay_manager
...
</code></pre></div>

<p>The basic mechanism is the same as in the other two cracks: it injects its own code into the <code>int 21h</code> and <code>int 3fh</code> interrupt handlers.
But the logic it performs in the <code>int 3fh</code> shim is slightly more complicated, and makes 5 individual modifications.</p>

<p>The first one skips the check for known debuggers which we looked at before, simply skipping its execution.
The second case is for the main anti-debugger check, hooking the interrupt that is called after it is failed and instead skipping over it back to the success case.</p>

<p>The remaining three all deal with the code wheel check.
The third case hooks the interrupt that is called when the code wheel dialog is being opened, and sets <code>si</code> to 1 which will simulate confirming the dialog instantly.
The fourth case is just a helper, it hooks the next interrupt after the dialog is closed, and overrides two bytes at the end of the routine that checks the provided input to inject an artificial <code>int 3f</code> instruction there.
This is not actually a valid overlay interrupt, it is only used as a place for the fifth case to hook into, because there are no other interrupts to hook into in that function.</p>

<p>So finally, the last case is where the code wheel check is actually defeated.
It hooks at the end of the input checking routine, after the game has computed the expected result to compare the input against, and it overrides all 5 copies of the ticket number with the correct value the game expects, then pretends the comparison was successful.
This way, the code wheel check succeeds, and all the hidden code wheel checks the game will perform later will also work because the correct value has been written everywhere.</p>

<p>With this, the game’s copy protection is completely defeated, with no adverse effects during gameplay.</p>

<blockquote>
  <p><strong>Side investigaton 4 complete!</strong></p>
</blockquote>

<h2 id="help-i-have-a-broken-version-of-the-game">Help, I have a broken version of the game!</h2>

<p>In case you have bought this game from GOG or have one of the many other broken versions out there, I have created a <a href="https://mrwint.github.io/winter/patcher/index.html">tool to fix the game for you</a>.
You can use the tool to patch your binary to remove the hidden copy protection checks (as well as the debugger and code wheel checks themselves in case they are not removed already), so you can enjoy this game without any limitations.</p>

<h2 id="conclusion---what-about-creating-the-perfect-ski-jump">Conclusion - What about creating the perfect ski jump?</h2>

<p>My original goal was to deconstruct the game mechanics, specifically for the ski jumping event, but that quest got so thoroughly side-tracked by all the copy protection related investigations that it moved somewhat into the background.
Now that the copy protection mysteries are solved, I will be able to focus on that, and it will likely end up being its own write-up.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reports of widespread power cuts in Spain and Portugal (326 pts)]]></title>
            <link>https://www.bbc.com/news/live/c9wpq8xrvd9t</link>
            <guid>43820043</guid>
            <pubDate>Mon, 28 Apr 2025 11:26:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/live/c9wpq8xrvd9t">https://www.bbc.com/news/live/c9wpq8xrvd9t</a>, See on <a href="https://news.ycombinator.com/item?id=43820043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="list" spacing="6" tabindex="0" data-testid="postList"><li><div><article data-testid="content-post" id="asset:fa41cf2f-fd21-41ec-9a4a-539f15c0e114"><header><span><h3 type="normal"><span role="text"><span>Tennis tournament Madrid Open suspended due to outage</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 12:35 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p>The Madrid Open - an annual clay tennis tournament - has been suspended due to the power outage currently affecting the Spanish capital and surrounding region. </p><p>British tennis player Jacob Fearnley had to leave the court when play was suspended, PA media reports.</p><p>The loss of power affected scoreboards and a camera above the court, it adds.</p><figure><p><span><img alt="An empty tennis court" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/4/28/d945cfcc-5c49-41c5-a637-bdeed1d41534.jpg.webp 800w" width="1920" height="1080"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>One of the courts was left almost entirely empty after the power outage forced play to be suspended</p></figcaption></figure></article></div></li><li><div><article data-testid="content-post" id="asset:2512133a-f690-4637-856d-1acfa250ef00"><header><span><h3 type="normal"><span role="text"><span>Spanish railway operator says 'entire' grid cut off</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 12:24 British Summer Time</span></span></span></span></h3></span></header><p>Spain's national railway company, Renfe, says the country's "entire National Electricity Grid was cut off" at 12:30 local time (11:30 BST).</p><p>"Trains stopped" and were "without departures" at all stations, the company says.</p></article></div></li><li><div><article data-testid="content-post" id="asset:b41604b4-5915-413d-bc28-d8397f008e15"><header><span><h3 type="normal"><span role="text"><span>Spanish operator confirms power outages</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 12:21 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p>Spain's electricity grid operator Red Electrica has confirmed power outages across the country.</p><p>It is working to restore electricity supplies and says it's working to analyse the causes of the blackouts.</p><p>"All resources are being dedicated to solving it," it says in a post on X.</p></article></div></li><li><div><article data-testid="content-post" id="asset:81ef5595-dab1-420e-a8e5-647e368183d3"><header><span><h3 type="normal"><span role="text"><span>Reports of widespread power cuts in Spain and Portugal</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 12:16 British Summer Time</span><p><span>Breaking</span></p></span></span></span></h3></span></header><p>A huge power outage seems to be affecting swathes of Spain and Portugal. </p><p>Local reports say there are traffic jams in the centre of the Spanish capital, Madrid, due to traffic lights not working.</p><p>Information is coming through thick and fast, and we'll bring you the latest as and when we get it. Stay with us.</p></article></div></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny-LLM – a course of serving LLM on Apple Silicon for systems engineers (259 pts)]]></title>
            <link>https://github.com/skyzh/tiny-llm</link>
            <guid>43820022</guid>
            <pubDate>Mon, 28 Apr 2025 11:24:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/skyzh/tiny-llm">https://github.com/skyzh/tiny-llm</a>, See on <a href="https://news.ycombinator.com/item?id=43820022">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-llm - LLM Serving in a Week</h2><a id="user-content-tiny-llm---llm-serving-in-a-week" aria-label="Permalink: tiny-llm - LLM Serving in a Week" href="#tiny-llm---llm-serving-in-a-week"></a></p>
<p dir="auto"><a href="https://github.com/skyzh/tiny-llm/actions/workflows/main.yml"><img src="https://github.com/skyzh/tiny-llm/actions/workflows/main.yml/badge.svg" alt="CI (main)"></a></p>
<p dir="auto">Still WIP and in very early stage. A tutorial on LLM serving using MLX for system engineers. The codebase
is solely (almost!) based on MLX array/matrix APIs without any high-level neural network APIs, so that we
can build the model serving infrastructure from scratch and dig into the optimizations.</p>
<p dir="auto">The goal is to learn the techniques behind efficiently serving a large language model (i.e., Qwen2 models).</p>
<p dir="auto">Why MLX: nowadays it's easier to get a macOS-based local development environment than setting up an NVIDIA GPU.</p>
<p dir="auto">Why Qwen2: this was the first LLM I've interacted with -- it's the go-to example in the vllm documentation. I spent some time looking at the vllm source code and built some knowledge around it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Book</h2><a id="user-content-book" aria-label="Permalink: Book" href="#book"></a></p>
<p dir="auto">The tiny-llm book is available at <a href="https://skyzh.github.io/tiny-llm/" rel="nofollow">https://skyzh.github.io/tiny-llm/</a>. You can follow the guide and start building.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">You may join skyzh's Discord server and study with the tiny-llm community.</p>
<p dir="auto"><a href="https://skyzh.dev/join/discord" rel="nofollow"><img src="https://github.com/skyzh/tiny-llm/raw/main/book/src/discord-badge.svg" alt="Join skyzh's Discord Server"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Week + Chapter</th>
<th>Topic</th>
<th>Code</th>
<th>Test</th>
<th>Doc</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.1</td>
<td>Attention</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>1.2</td>
<td>RoPE</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>1.3</td>
<td>Grouped Query Attention</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>1.4</td>
<td>RMSNorm and MLP</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>1.5</td>
<td>Transformer Block</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>1.6</td>
<td>Load the Model</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>1.7</td>
<td>Generate Responses (aka Decoding)</td>
<td>✅</td>
<td>✅</td>
<td>🚧</td>
</tr>
<tr>
<td>2.1</td>
<td>KV Cache</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.2</td>
<td>Quantized Matmul and Linear - CPU</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.3</td>
<td>Quantized Matmul and Linear - GPU</td>
<td>✅</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.4</td>
<td>Flash Attention and Other Kernels</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.5</td>
<td>Continuous Batching</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.6</td>
<td>Speculative Decoding</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>2.7</td>
<td>Prompt/Prefix Cache</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.1</td>
<td>Paged Attention - Part 1</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.2</td>
<td>Paged Attention - Part 2</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.3</td>
<td>Prefill-Decode Separation</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.4</td>
<td>Scheduler</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.5</td>
<td>Parallelism</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.6</td>
<td>AI Agent</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
<tr>
<td>3.7</td>
<td>Streaming API Server</td>
<td>🚧</td>
<td>🚧</td>
<td>🚧</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Other topics not covered: quantized/compressed kv cache</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Full power outage in Spain and Portugal (1342 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43819791</link>
            <guid>43819791</guid>
            <pubDate>Mon, 28 Apr 2025 10:50:58 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43819791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="43820052"><td></td></tr>
            <tr id="43820019"><td></td></tr>
                <tr id="43820051"><td></td></tr>
                  <tr id="43820033"><td></td></tr>
            <tr id="43819989"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43819989" href="https://news.ycombinator.com/vote?id=43819989&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>I'm in Valencia and it is indeed happening here. A street parade under my windows continues nonetheless.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43819995"><td></td></tr>
                <tr id="43820007"><td></td></tr>
                <tr id="43820015"><td></td></tr>
                <tr id="43820027"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43820027" href="https://news.ycombinator.com/vote?id=43820027&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>Most of them have batteries. How long they last depends, in my country they can typically manage 4 hours.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43820049"><td></td></tr>
            <tr id="43820041"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43820041" href="https://news.ycombinator.com/vote?id=43820041&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>They still need other infrastructure to get anywhere though (routers and other networking infrastructure).</p>
              </div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="43819921"><td></td></tr>
            <tr id="43819968"><td></td></tr>
                <tr id="43820037"><td></td></tr>
                <tr id="43820059"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43820059" href="https://news.ycombinator.com/vote?id=43820059&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>Neither. Apparently a local grid overload and a cascading failure, but radio and newspapers don’t agree on root cause.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43820058"><td></td></tr>
                        <tr id="43819910"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43819910" href="https://news.ycombinator.com/vote?id=43819910&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>Portugal has no electricity as we speak. Funny enough telcos and 4G/5G are fine for now, I'm guessing batteries and diesel backups kicked in and are doing their job.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43819941"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43819941" href="https://news.ycombinator.com/vote?id=43819941&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div><p>Yeah, we just told you that via Signal - that’s how we built the networks :)</p><p>(No relation to the other infamous Signal chat :))</p><p>There should be 4-8 hours of battery backup on every site - at least.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43819988"><td></td></tr>
                <tr id="43820001"><td></td></tr>
                <tr id="43820047"><td></td></tr>
                        <tr id="43819949"><td></td></tr>
                <tr id="43820042"><td></td></tr>
                  <tr id="43819959"><td></td></tr>
            <tr id="43819996"><td></td></tr>
                <tr id="43820061"><td></td></tr>
                  <tr id="43820002"><td></td></tr>
            <tr id="43819960"><td></td></tr>
                <tr id="43820018"><td></td></tr>
                <tr id="43820046"><td></td></tr>
                <tr id="43820057"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43820057" href="https://news.ycombinator.com/vote?id=43820057&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>Ok...? Is there like more to this narrative or are we supposed to buy that russia just hates all of europe for being europe now? Whatever happened to the "rational actor" canard?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43819964"><td></td></tr>
                  <tr id="43819906"><td></td></tr>
                <tr id="43820039"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43820039" href="https://news.ycombinator.com/vote?id=43820039&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div><p>The European grid is a connected synchronous grid. Usually that would add stability but it also means if a single country's grid blacks out then their neighbours have to respond to that. Portugal and Spain's grids will be intimately connected which won't have helped.</p><p>Not something that's easy to test for.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43820009"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43820009" href="https://news.ycombinator.com/vote?id=43820009&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>The whole European grid is essentially connected at this point, it's a simple trade of resiliency for efficiency. People just forget about the resiliency part until something goes wrong</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43819814"><td></td></tr>
            <tr id="43819859"><td></td></tr>
            <tr id="43819904"><td></td></tr>
                <tr id="43820054"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43820054" href="https://news.ycombinator.com/vote?id=43820054&amp;how=up&amp;goto=item%3Fid%3D43819791"></a></center>    </td><td><br><div>
                  <p>Spain and Portugal are quite big and with harsh terrain, I doubt anyone would bother invading in a traditional sense.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43820048"><td></td></tr>
                  <tr id="43819892"><td></td></tr>
            <tr id="43819844"><td></td></tr>
            <tr id="43819806"><td></td></tr>
                <tr id="43819810"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PhD Timeline (326 pts)]]></title>
            <link>https://xkcd.com/3081/</link>
            <guid>43818614</guid>
            <pubDate>Mon, 28 Apr 2025 07:33:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xkcd.com/3081/">https://xkcd.com/3081/</a>, See on <a href="https://news.ycombinator.com/item?id=43818614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bottom">
<p><img src="https://imgs.xkcd.com/s/a899e84.jpg" width="520" height="100" alt="Selected Comics" usemap="#comicmap"></p><map id="comicmap" name="comicmap">
<area shape="rect" coords="0,0,100,100" href="/150/" alt="Grownups">
<area shape="rect" coords="104,0,204,100" href="/730/" alt="Circuit Diagram">
<area shape="rect" coords="208,0,308,100" href="/162/" alt="Angular Momentum">
<area shape="rect" coords="312,0,412,100" href="/688/" alt="Self-Description">
<area shape="rect" coords="416,0,520,100" href="/556/" alt="Alternative Energy Revolution">
</map>

<p><a href="https://xkcd.com/1732/"><img src="https://imgs.xkcd.com/s/temperature.png" width="520" height="100" alt="Earth temperature timeline"></a></p>
<br>
<div id="comicLinks"><p>
Comics I enjoy:<br>
        <a href="http://threewordphrase.com/">Three Word Phrase</a>,
        <a href="https://www.smbc-comics.com/">SMBC</a>,
        <a href="https://www.qwantz.com/">Dinosaur Comics</a>,
        <a href="https://oglaf.com/">Oglaf</a> (nsfw),
        <a href="https://www.asofterworld.com/">A Softer World</a>,
        <a href="https://buttersafe.com/">Buttersafe</a>,
        <a href="https://pbfcomics.com/">Perry Bible Fellowship</a>,
        <a href="https://questionablecontent.net/">Questionable Content</a>,
        <a href="http://www.buttercupfestival.com/">Buttercup Festival</a>,
        <a href="https://www.homestuck.com/">Homestuck</a>,
	<a href="https://www.jspowerhour.com/">Junior Scientist Power Hour</a>
</p></div>
<br>

<br>
<center>
<p>xkcd.com is best viewed with Netscape Navigator 4.0 or below on a Pentium 3±1 emulated in Javascript on an Apple IIGS<br>at a screen resolution of 1024x1. Please enable your ad blockers, disable high-heat drying, and remove your device<br>from Airplane Mode and set it to Boat Mode. For security reasons, please leave caps lock on while browsing.</p>
</center>

</div></div>]]></description>
        </item>
    </channel>
</rss>